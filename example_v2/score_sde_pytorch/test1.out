WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W0208 12:57:49.051929 22542570456896 utils.py:10] No checkpoint found at experiments/dpm/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0208 12:57:49.054075 22542570456896 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0208 12:57:49.054291 22542570456896 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0208 12:57:49.054371 22542570456896 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0208 12:57:49.055144 22542570456896 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0208 12:57:49.055267 22542570456896 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0208 12:57:49.055354 22542570456896 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0208 12:57:49.058266 22542570456896 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0208 12:57:49.062551 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0208 12:57:49.062675 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0208 12:57:49.062807 22542570456896 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0208 12:57:49.062909 22542570456896 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0208 12:57:49.229959 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0208 12:57:49.230218 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0208 12:57:49.230372 22542570456896 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0208 12:57:49.230468 22542570456896 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0208 12:57:49.341570 22542570456896 run_lib.py:123] Starting training loop at step 0.
I0208 12:57:58.372729 22542570456896 run_lib.py:133] step: 0, training_loss: 9.99617e-01
I0208 12:57:59.899679 22542570456896 run_lib.py:146] step: 0, eval_loss: 1.00356e+00
I0208 12:58:19.537102 22542570456896 run_lib.py:133] step: 50, training_loss: 9.92776e-01
I0208 12:58:38.938248 22542570456896 run_lib.py:133] step: 100, training_loss: 9.55566e-01
I0208 12:58:39.093762 22542570456896 run_lib.py:146] step: 100, eval_loss: 9.65793e-01
I0208 12:58:58.558991 22542570456896 run_lib.py:133] step: 150, training_loss: 8.91180e-01
I0208 12:59:16.228488 22542570456896 run_lib.py:133] step: 200, training_loss: 8.04884e-01
I0208 12:59:16.387307 22542570456896 run_lib.py:146] step: 200, eval_loss: 8.38131e-01
I0208 12:59:33.777011 22542570456896 run_lib.py:133] step: 250, training_loss: 7.06697e-01
I0208 12:59:51.331310 22542570456896 run_lib.py:133] step: 300, training_loss: 5.98116e-01
I0208 12:59:51.488079 22542570456896 run_lib.py:146] step: 300, eval_loss: 6.57949e-01
I0208 13:00:08.948299 22542570456896 run_lib.py:133] step: 350, training_loss: 4.88462e-01
I0208 13:00:26.366629 22542570456896 run_lib.py:133] step: 400, training_loss: 3.71722e-01
I0208 13:00:26.524862 22542570456896 run_lib.py:146] step: 400, eval_loss: 4.50303e-01
I0208 13:00:43.903513 22542570456896 run_lib.py:133] step: 450, training_loss: 2.64188e-01
I0208 13:01:01.391698 22542570456896 run_lib.py:133] step: 500, training_loss: 1.73977e-01
I0208 13:01:01.562173 22542570456896 run_lib.py:146] step: 500, eval_loss: 2.48400e-01
I0208 13:01:18.987039 22542570456896 run_lib.py:133] step: 550, training_loss: 1.09633e-01
I0208 13:01:36.299633 22542570456896 run_lib.py:133] step: 600, training_loss: 5.60537e-02
I0208 13:01:36.457871 22542570456896 run_lib.py:146] step: 600, eval_loss: 1.13022e-01
I0208 13:01:53.967114 22542570456896 run_lib.py:133] step: 650, training_loss: 4.61361e-02
I0208 13:02:11.397075 22542570456896 run_lib.py:133] step: 700, training_loss: 5.47449e-02
I0208 13:02:11.552112 22542570456896 run_lib.py:146] step: 700, eval_loss: 4.14143e-02
I0208 13:02:29.079758 22542570456896 run_lib.py:133] step: 750, training_loss: 4.22573e-02
I0208 13:02:46.556979 22542570456896 run_lib.py:133] step: 800, training_loss: 3.94412e-02
I0208 13:02:46.725491 22542570456896 run_lib.py:146] step: 800, eval_loss: 4.49249e-02
I0208 13:03:04.194205 22542570456896 run_lib.py:133] step: 850, training_loss: 3.91286e-02
I0208 13:03:21.683692 22542570456896 run_lib.py:133] step: 900, training_loss: 4.07929e-02
I0208 13:03:21.849570 22542570456896 run_lib.py:146] step: 900, eval_loss: 3.33471e-02
I0208 13:03:39.449281 22542570456896 run_lib.py:133] step: 950, training_loss: 3.50711e-02
I0208 13:03:56.913946 22542570456896 run_lib.py:133] step: 1000, training_loss: 3.46980e-02
I0208 13:03:57.070210 22542570456896 run_lib.py:146] step: 1000, eval_loss: 3.63577e-02
I0208 13:04:14.493350 22542570456896 run_lib.py:133] step: 1050, training_loss: 3.75380e-02
I0208 13:04:31.960293 22542570456896 run_lib.py:133] step: 1100, training_loss: 3.82094e-02
I0208 13:04:32.119498 22542570456896 run_lib.py:146] step: 1100, eval_loss: 3.16897e-02
I0208 13:04:49.784672 22542570456896 run_lib.py:133] step: 1150, training_loss: 4.94681e-02
I0208 13:05:07.214823 22542570456896 run_lib.py:133] step: 1200, training_loss: 3.50922e-02
I0208 13:05:07.368219 22542570456896 run_lib.py:146] step: 1200, eval_loss: 3.50499e-02
I0208 13:05:24.918386 22542570456896 run_lib.py:133] step: 1250, training_loss: 3.22535e-02
I0208 13:05:42.338188 22542570456896 run_lib.py:133] step: 1300, training_loss: 2.82136e-02
I0208 13:05:42.503532 22542570456896 run_lib.py:146] step: 1300, eval_loss: 3.34172e-02
I0208 13:06:00.166349 22542570456896 run_lib.py:133] step: 1350, training_loss: 4.07605e-02
I0208 13:06:17.595434 22542570456896 run_lib.py:133] step: 1400, training_loss: 3.03951e-02
I0208 13:06:17.754232 22542570456896 run_lib.py:146] step: 1400, eval_loss: 3.39308e-02
I0208 13:06:35.324366 22542570456896 run_lib.py:133] step: 1450, training_loss: 4.13633e-02
I0208 13:06:52.716661 22542570456896 run_lib.py:133] step: 1500, training_loss: 3.70187e-02
I0208 13:06:52.881244 22542570456896 run_lib.py:146] step: 1500, eval_loss: 3.05767e-02
I0208 13:07:10.336620 22542570456896 run_lib.py:133] step: 1550, training_loss: 3.77755e-02
I0208 13:07:27.897181 22542570456896 run_lib.py:133] step: 1600, training_loss: 3.65964e-02
I0208 13:07:28.055762 22542570456896 run_lib.py:146] step: 1600, eval_loss: 3.54764e-02
I0208 13:07:45.534567 22542570456896 run_lib.py:133] step: 1650, training_loss: 2.76487e-02
I0208 13:08:02.969487 22542570456896 run_lib.py:133] step: 1700, training_loss: 2.67881e-02
I0208 13:08:03.122982 22542570456896 run_lib.py:146] step: 1700, eval_loss: 3.29160e-02
I0208 13:08:20.732806 22542570456896 run_lib.py:133] step: 1750, training_loss: 3.36325e-02
I0208 13:08:38.140561 22542570456896 run_lib.py:133] step: 1800, training_loss: 3.81225e-02
I0208 13:08:38.305242 22542570456896 run_lib.py:146] step: 1800, eval_loss: 3.29462e-02
I0208 13:08:55.863643 22542570456896 run_lib.py:133] step: 1850, training_loss: 3.18390e-02
I0208 13:09:13.273253 22542570456896 run_lib.py:133] step: 1900, training_loss: 3.01034e-02
I0208 13:09:13.447312 22542570456896 run_lib.py:146] step: 1900, eval_loss: 4.49623e-02
I0208 13:09:30.915045 22542570456896 run_lib.py:133] step: 1950, training_loss: 4.33371e-02
I0208 13:09:48.522432 22542570456896 run_lib.py:133] step: 2000, training_loss: 3.34198e-02
I0208 13:09:48.679039 22542570456896 run_lib.py:146] step: 2000, eval_loss: 3.14717e-02
I0208 13:10:06.083464 22542570456896 run_lib.py:133] step: 2050, training_loss: 3.02608e-02
I0208 13:10:23.510876 22542570456896 run_lib.py:133] step: 2100, training_loss: 4.13079e-02
I0208 13:10:23.667245 22542570456896 run_lib.py:146] step: 2100, eval_loss: 4.24564e-02
I0208 13:10:41.079616 22542570456896 run_lib.py:133] step: 2150, training_loss: 3.42374e-02
I0208 13:10:58.639108 22542570456896 run_lib.py:133] step: 2200, training_loss: 3.98412e-02
I0208 13:10:58.796617 22542570456896 run_lib.py:146] step: 2200, eval_loss: 2.82924e-02
I0208 13:11:16.253496 22542570456896 run_lib.py:133] step: 2250, training_loss: 3.08876e-02
I0208 13:11:33.776957 22542570456896 run_lib.py:133] step: 2300, training_loss: 3.93552e-02
I0208 13:11:33.942337 22542570456896 run_lib.py:146] step: 2300, eval_loss: 3.64078e-02
I0208 13:11:51.347778 22542570456896 run_lib.py:133] step: 2350, training_loss: 3.59119e-02
I0208 13:12:08.748673 22542570456896 run_lib.py:133] step: 2400, training_loss: 3.01577e-02
I0208 13:12:08.911223 22542570456896 run_lib.py:146] step: 2400, eval_loss: 3.47637e-02
I0208 13:12:26.447584 22542570456896 run_lib.py:133] step: 2450, training_loss: 4.22560e-02
I0208 13:12:44.010932 22542570456896 run_lib.py:133] step: 2500, training_loss: 3.19840e-02
I0208 13:12:44.172200 22542570456896 run_lib.py:146] step: 2500, eval_loss: 2.26466e-02
I0208 13:13:01.599204 22542570456896 run_lib.py:133] step: 2550, training_loss: 3.41390e-02
I0208 13:13:19.009538 22542570456896 run_lib.py:133] step: 2600, training_loss: 3.95318e-02
I0208 13:13:19.162729 22542570456896 run_lib.py:146] step: 2600, eval_loss: 3.91480e-02
I0208 13:13:36.726851 22542570456896 run_lib.py:133] step: 2650, training_loss: 3.99377e-02
I0208 13:13:54.157723 22542570456896 run_lib.py:133] step: 2700, training_loss: 3.97581e-02
I0208 13:13:54.312315 22542570456896 run_lib.py:146] step: 2700, eval_loss: 2.80752e-02
I0208 13:14:11.898476 22542570456896 run_lib.py:133] step: 2750, training_loss: 2.85208e-02
I0208 13:14:29.350039 22542570456896 run_lib.py:133] step: 2800, training_loss: 3.04474e-02
I0208 13:14:29.508445 22542570456896 run_lib.py:146] step: 2800, eval_loss: 3.88222e-02
I0208 13:14:47.144168 22542570456896 run_lib.py:133] step: 2850, training_loss: 3.12158e-02
I0208 13:15:04.564088 22542570456896 run_lib.py:133] step: 2900, training_loss: 3.54186e-02
I0208 13:15:04.728364 22542570456896 run_lib.py:146] step: 2900, eval_loss: 3.19420e-02
I0208 13:15:22.114368 22542570456896 run_lib.py:133] step: 2950, training_loss: 3.57419e-02
I0208 13:15:39.682236 22542570456896 run_lib.py:133] step: 3000, training_loss: 4.10163e-02
I0208 13:15:39.838385 22542570456896 run_lib.py:146] step: 3000, eval_loss: 3.77177e-02
I0208 13:15:57.223060 22542570456896 run_lib.py:133] step: 3050, training_loss: 3.10344e-02
I0208 13:16:14.871049 22542570456896 run_lib.py:133] step: 3100, training_loss: 3.69532e-02
I0208 13:16:15.025430 22542570456896 run_lib.py:146] step: 3100, eval_loss: 3.34579e-02
I0208 13:16:32.456033 22542570456896 run_lib.py:133] step: 3150, training_loss: 3.26781e-02
I0208 13:16:49.870999 22542570456896 run_lib.py:133] step: 3200, training_loss: 3.80814e-02
I0208 13:16:50.027373 22542570456896 run_lib.py:146] step: 3200, eval_loss: 2.64472e-02
I0208 13:17:07.635648 22542570456896 run_lib.py:133] step: 3250, training_loss: 3.52367e-02
I0208 13:17:25.067038 22542570456896 run_lib.py:133] step: 3300, training_loss: 2.88069e-02
I0208 13:17:25.231459 22542570456896 run_lib.py:146] step: 3300, eval_loss: 3.50736e-02
I0208 13:17:42.692201 22542570456896 run_lib.py:133] step: 3350, training_loss: 2.50768e-02
I0208 13:18:00.335011 22542570456896 run_lib.py:133] step: 3400, training_loss: 3.29472e-02
I0208 13:18:00.492619 22542570456896 run_lib.py:146] step: 3400, eval_loss: 2.72077e-02
I0208 13:18:17.921135 22542570456896 run_lib.py:133] step: 3450, training_loss: 3.16122e-02
I0208 13:18:35.595440 22542570456896 run_lib.py:133] step: 3500, training_loss: 3.58662e-02
I0208 13:18:35.749331 22542570456896 run_lib.py:146] step: 3500, eval_loss: 2.52649e-02
I0208 13:18:53.209066 22542570456896 run_lib.py:133] step: 3550, training_loss: 3.76826e-02
I0208 13:19:10.597953 22542570456896 run_lib.py:133] step: 3600, training_loss: 3.14983e-02
I0208 13:19:10.752468 22542570456896 run_lib.py:146] step: 3600, eval_loss: 2.77968e-02
I0208 13:19:28.243014 22542570456896 run_lib.py:133] step: 3650, training_loss: 3.88927e-02
I0208 13:19:45.686424 22542570456896 run_lib.py:133] step: 3700, training_loss: 3.65355e-02
I0208 13:19:45.849291 22542570456896 run_lib.py:146] step: 3700, eval_loss: 3.42024e-02
I0208 13:20:03.419656 22542570456896 run_lib.py:133] step: 3750, training_loss: 4.10317e-02
I0208 13:20:20.866056 22542570456896 run_lib.py:133] step: 3800, training_loss: 3.17061e-02
I0208 13:20:21.030226 22542570456896 run_lib.py:146] step: 3800, eval_loss: 2.82481e-02
I0208 13:20:38.477299 22542570456896 run_lib.py:133] step: 3850, training_loss: 3.48026e-02
I0208 13:20:55.893840 22542570456896 run_lib.py:133] step: 3900, training_loss: 2.55296e-02
I0208 13:20:56.049342 22542570456896 run_lib.py:146] step: 3900, eval_loss: 3.10320e-02
I0208 13:21:13.604808 22542570456896 run_lib.py:133] step: 3950, training_loss: 3.33867e-02
I0208 13:21:31.141149 22542570456896 run_lib.py:133] step: 4000, training_loss: 3.29413e-02
I0208 13:21:31.295506 22542570456896 run_lib.py:146] step: 4000, eval_loss: 3.07754e-02
I0208 13:21:48.738983 22542570456896 run_lib.py:133] step: 4050, training_loss: 2.26354e-02
I0208 13:22:06.224093 22542570456896 run_lib.py:133] step: 4100, training_loss: 4.07965e-02
I0208 13:22:06.379302 22542570456896 run_lib.py:146] step: 4100, eval_loss: 3.57607e-02
I0208 13:22:23.923791 22542570456896 run_lib.py:133] step: 4150, training_loss: 4.31621e-02
I0208 13:22:41.343120 22542570456896 run_lib.py:133] step: 4200, training_loss: 3.62458e-02
I0208 13:22:41.517695 22542570456896 run_lib.py:146] step: 4200, eval_loss: 3.11306e-02
I0208 13:22:59.185637 22542570456896 run_lib.py:133] step: 4250, training_loss: 3.29133e-02
I0208 13:23:16.640021 22542570456896 run_lib.py:133] step: 4300, training_loss: 3.01792e-02
I0208 13:23:16.797367 22542570456896 run_lib.py:146] step: 4300, eval_loss: 2.88109e-02
I0208 13:23:34.340394 22542570456896 run_lib.py:133] step: 4350, training_loss: 3.55693e-02
I0208 13:23:51.717256 22542570456896 run_lib.py:133] step: 4400, training_loss: 2.74521e-02
I0208 13:23:51.874022 22542570456896 run_lib.py:146] step: 4400, eval_loss: 3.20779e-02
I0208 13:24:09.279072 22542570456896 run_lib.py:133] step: 4450, training_loss: 3.42202e-02
I0208 13:24:26.879693 22542570456896 run_lib.py:133] step: 4500, training_loss: 3.52170e-02
I0208 13:24:27.034202 22542570456896 run_lib.py:146] step: 4500, eval_loss: 3.36948e-02
I0208 13:24:44.487220 22542570456896 run_lib.py:133] step: 4550, training_loss: 3.24702e-02
I0208 13:25:02.064263 22542570456896 run_lib.py:133] step: 4600, training_loss: 3.00201e-02
I0208 13:25:02.219147 22542570456896 run_lib.py:146] step: 4600, eval_loss: 3.54778e-02
I0208 13:25:19.594413 22542570456896 run_lib.py:133] step: 4650, training_loss: 3.38483e-02
I0208 13:25:36.991977 22542570456896 run_lib.py:133] step: 4700, training_loss: 3.26926e-02
I0208 13:25:37.156564 22542570456896 run_lib.py:146] step: 4700, eval_loss: 2.80781e-02
I0208 13:25:54.715699 22542570456896 run_lib.py:133] step: 4750, training_loss: 2.91616e-02
I0208 13:26:12.201862 22542570456896 run_lib.py:133] step: 4800, training_loss: 3.10817e-02
I0208 13:26:12.359416 22542570456896 run_lib.py:146] step: 4800, eval_loss: 3.03321e-02
I0208 13:26:29.818228 22542570456896 run_lib.py:133] step: 4850, training_loss: 2.64526e-02
I0208 13:26:47.240868 22542570456896 run_lib.py:133] step: 4900, training_loss: 3.54936e-02
I0208 13:26:47.396249 22542570456896 run_lib.py:146] step: 4900, eval_loss: 2.97258e-02
I0208 13:27:04.969464 22542570456896 run_lib.py:133] step: 4950, training_loss: 3.81405e-02
I0208 13:27:22.373175 22542570456896 run_lib.py:133] step: 5000, training_loss: 3.60393e-02
I0208 13:27:22.525258 22542570456896 run_lib.py:146] step: 5000, eval_loss: 2.85652e-02
I0208 13:27:39.978454 22542570456896 run_lib.py:133] step: 5050, training_loss: 3.28199e-02
I0208 13:27:57.416970 22542570456896 run_lib.py:133] step: 5100, training_loss: 3.13515e-02
I0208 13:27:57.593783 22542570456896 run_lib.py:146] step: 5100, eval_loss: 2.86784e-02
I0208 13:28:15.020037 22542570456896 run_lib.py:133] step: 5150, training_loss: 2.73356e-02
I0208 13:28:32.452074 22542570456896 run_lib.py:133] step: 5200, training_loss: 3.23691e-02
I0208 13:28:32.609184 22542570456896 run_lib.py:146] step: 5200, eval_loss: 2.89899e-02
I0208 13:28:50.173048 22542570456896 run_lib.py:133] step: 5250, training_loss: 3.61048e-02
I0208 13:29:07.606858 22542570456896 run_lib.py:133] step: 5300, training_loss: 3.33456e-02
I0208 13:29:07.764225 22542570456896 run_lib.py:146] step: 5300, eval_loss: 3.11784e-02
I0208 13:29:25.157505 22542570456896 run_lib.py:133] step: 5350, training_loss: 2.53605e-02
I0208 13:29:42.612750 22542570456896 run_lib.py:133] step: 5400, training_loss: 2.57011e-02
I0208 13:29:42.767970 22542570456896 run_lib.py:146] step: 5400, eval_loss: 2.21273e-02
I0208 13:30:00.377259 22542570456896 run_lib.py:133] step: 5450, training_loss: 3.60500e-02
I0208 13:30:17.826808 22542570456896 run_lib.py:133] step: 5500, training_loss: 3.46252e-02
I0208 13:30:17.980221 22542570456896 run_lib.py:146] step: 5500, eval_loss: 2.69132e-02
I0208 13:30:35.375690 22542570456896 run_lib.py:133] step: 5550, training_loss: 3.54329e-02
I0208 13:30:52.789595 22542570456896 run_lib.py:133] step: 5600, training_loss: 3.31962e-02
I0208 13:30:52.964477 22542570456896 run_lib.py:146] step: 5600, eval_loss: 3.29102e-02
I0208 13:31:10.604553 22542570456896 run_lib.py:133] step: 5650, training_loss: 3.46920e-02
I0208 13:31:27.999405 22542570456896 run_lib.py:133] step: 5700, training_loss: 3.53055e-02
I0208 13:31:28.162155 22542570456896 run_lib.py:146] step: 5700, eval_loss: 3.40798e-02
I0208 13:31:45.749531 22542570456896 run_lib.py:133] step: 5750, training_loss: 3.39605e-02
I0208 13:32:03.134221 22542570456896 run_lib.py:133] step: 5800, training_loss: 2.34529e-02
I0208 13:32:03.308394 22542570456896 run_lib.py:146] step: 5800, eval_loss: 3.37768e-02
I0208 13:32:20.922359 22542570456896 run_lib.py:133] step: 5850, training_loss: 2.97209e-02
I0208 13:32:38.361783 22542570456896 run_lib.py:133] step: 5900, training_loss: 3.20832e-02
I0208 13:32:38.524022 22542570456896 run_lib.py:146] step: 5900, eval_loss: 3.12477e-02
I0208 13:32:56.020266 22542570456896 run_lib.py:133] step: 5950, training_loss: 3.65802e-02
I0208 13:33:13.625683 22542570456896 run_lib.py:133] step: 6000, training_loss: 3.73492e-02
I0208 13:33:13.779205 22542570456896 run_lib.py:146] step: 6000, eval_loss: 4.01488e-02
I0208 13:33:31.200269 22542570456896 run_lib.py:133] step: 6050, training_loss: 2.59098e-02
I0208 13:33:48.733793 22542570456896 run_lib.py:133] step: 6100, training_loss: 3.19268e-02
I0208 13:33:48.893480 22542570456896 run_lib.py:146] step: 6100, eval_loss: 2.91445e-02
I0208 13:34:06.309448 22542570456896 run_lib.py:133] step: 6150, training_loss: 2.99506e-02
I0208 13:34:23.708058 22542570456896 run_lib.py:133] step: 6200, training_loss: 2.76210e-02
I0208 13:34:23.879609 22542570456896 run_lib.py:146] step: 6200, eval_loss: 3.04969e-02
I0208 13:34:41.491349 22542570456896 run_lib.py:133] step: 6250, training_loss: 3.43946e-02
I0208 13:34:58.898868 22542570456896 run_lib.py:133] step: 6300, training_loss: 3.33616e-02
I0208 13:34:59.055687 22542570456896 run_lib.py:146] step: 6300, eval_loss: 3.62013e-02
I0208 13:35:16.477236 22542570456896 run_lib.py:133] step: 6350, training_loss: 3.29453e-02
I0208 13:35:33.865691 22542570456896 run_lib.py:133] step: 6400, training_loss: 3.14581e-02
I0208 13:35:34.016999 22542570456896 run_lib.py:146] step: 6400, eval_loss: 3.11512e-02
I0208 13:35:51.605192 22542570456896 run_lib.py:133] step: 6450, training_loss: 3.06851e-02
I0208 13:36:09.001200 22542570456896 run_lib.py:133] step: 6500, training_loss: 3.26933e-02
I0208 13:36:09.168507 22542570456896 run_lib.py:146] step: 6500, eval_loss: 3.34358e-02
I0208 13:36:26.718175 22542570456896 run_lib.py:133] step: 6550, training_loss: 3.21237e-02
I0208 13:36:44.190343 22542570456896 run_lib.py:133] step: 6600, training_loss: 2.78481e-02
I0208 13:36:44.348396 22542570456896 run_lib.py:146] step: 6600, eval_loss: 3.16449e-02
I0208 13:37:01.759959 22542570456896 run_lib.py:133] step: 6650, training_loss: 2.92570e-02
I0208 13:37:19.180212 22542570456896 run_lib.py:133] step: 6700, training_loss: 3.28249e-02
I0208 13:37:19.337272 22542570456896 run_lib.py:146] step: 6700, eval_loss: 3.44428e-02
I0208 13:37:36.907314 22542570456896 run_lib.py:133] step: 6750, training_loss: 3.96872e-02
I0208 13:37:54.487422 22542570456896 run_lib.py:133] step: 6800, training_loss: 2.69548e-02
I0208 13:37:54.641952 22542570456896 run_lib.py:146] step: 6800, eval_loss: 3.26312e-02
I0208 13:38:12.079152 22542570456896 run_lib.py:133] step: 6850, training_loss: 3.34300e-02
I0208 13:38:29.482551 22542570456896 run_lib.py:133] step: 6900, training_loss: 2.95054e-02
I0208 13:38:29.635201 22542570456896 run_lib.py:146] step: 6900, eval_loss: 3.12587e-02
I0208 13:38:47.182066 22542570456896 run_lib.py:133] step: 6950, training_loss: 3.61652e-02
I0208 13:39:04.648566 22542570456896 run_lib.py:133] step: 7000, training_loss: 3.12189e-02
I0208 13:39:04.804872 22542570456896 run_lib.py:146] step: 7000, eval_loss: 3.49476e-02
I0208 13:39:22.211568 22542570456896 run_lib.py:133] step: 7050, training_loss: 2.89630e-02
I0208 13:39:39.648669 22542570456896 run_lib.py:133] step: 7100, training_loss: 3.61654e-02
I0208 13:39:39.833417 22542570456896 run_lib.py:146] step: 7100, eval_loss: 2.36666e-02
I0208 13:39:57.432019 22542570456896 run_lib.py:133] step: 7150, training_loss: 3.03866e-02
I0208 13:40:14.839995 22542570456896 run_lib.py:133] step: 7200, training_loss: 3.15748e-02
I0208 13:40:15.008587 22542570456896 run_lib.py:146] step: 7200, eval_loss: 3.35053e-02
I0208 13:40:32.572407 22542570456896 run_lib.py:133] step: 7250, training_loss: 2.96672e-02
I0208 13:40:49.982546 22542570456896 run_lib.py:133] step: 7300, training_loss: 3.27004e-02
I0208 13:40:50.145236 22542570456896 run_lib.py:146] step: 7300, eval_loss: 3.26762e-02
I0208 13:41:07.701758 22542570456896 run_lib.py:133] step: 7350, training_loss: 3.08722e-02
I0208 13:41:25.186023 22542570456896 run_lib.py:133] step: 7400, training_loss: 2.53504e-02
I0208 13:41:25.345372 22542570456896 run_lib.py:146] step: 7400, eval_loss: 2.45102e-02
I0208 13:41:42.758274 22542570456896 run_lib.py:133] step: 7450, training_loss: 2.81144e-02
I0208 13:42:00.369444 22542570456896 run_lib.py:133] step: 7500, training_loss: 3.27259e-02
I0208 13:42:00.529189 22542570456896 run_lib.py:146] step: 7500, eval_loss: 3.49899e-02
I0208 13:42:17.911922 22542570456896 run_lib.py:133] step: 7550, training_loss: 2.62285e-02
I0208 13:42:35.559620 22542570456896 run_lib.py:133] step: 7600, training_loss: 2.53161e-02
I0208 13:42:35.836466 22542570456896 run_lib.py:146] step: 7600, eval_loss: 3.30554e-02
I0208 13:42:53.234280 22542570456896 run_lib.py:133] step: 7650, training_loss: 3.41126e-02
I0208 13:43:10.756670 22542570456896 run_lib.py:133] step: 7700, training_loss: 2.66350e-02
I0208 13:43:11.003000 22542570456896 run_lib.py:146] step: 7700, eval_loss: 2.44821e-02
I0208 13:43:28.624886 22542570456896 run_lib.py:133] step: 7750, training_loss: 3.07566e-02
I0208 13:43:46.157135 22542570456896 run_lib.py:133] step: 7800, training_loss: 2.77503e-02
I0208 13:43:46.328003 22542570456896 run_lib.py:146] step: 7800, eval_loss: 3.84743e-02
I0208 13:44:03.729784 22542570456896 run_lib.py:133] step: 7850, training_loss: 3.17989e-02
I0208 13:44:21.197762 22542570456896 run_lib.py:133] step: 7900, training_loss: 2.94013e-02
I0208 13:44:21.363230 22542570456896 run_lib.py:146] step: 7900, eval_loss: 2.54226e-02
I0208 13:44:38.896822 22542570456896 run_lib.py:133] step: 7950, training_loss: 2.92197e-02
I0208 13:44:56.304429 22542570456896 run_lib.py:133] step: 8000, training_loss: 3.07970e-02
I0208 13:44:56.480673 22542570456896 run_lib.py:146] step: 8000, eval_loss: 4.09069e-02
I0208 13:45:14.027127 22542570456896 run_lib.py:133] step: 8050, training_loss: 3.26012e-02
I0208 13:45:31.440092 22542570456896 run_lib.py:133] step: 8100, training_loss: 3.36076e-02
I0208 13:45:31.600584 22542570456896 run_lib.py:146] step: 8100, eval_loss: 4.04855e-02
I0208 13:45:49.039038 22542570456896 run_lib.py:133] step: 8150, training_loss: 3.34328e-02
I0208 13:46:06.447143 22542570456896 run_lib.py:133] step: 8200, training_loss: 2.92599e-02
I0208 13:46:06.603398 22542570456896 run_lib.py:146] step: 8200, eval_loss: 3.26038e-02
I0208 13:46:24.185692 22542570456896 run_lib.py:133] step: 8250, training_loss: 3.47455e-02
I0208 13:46:41.724233 22542570456896 run_lib.py:133] step: 8300, training_loss: 2.89106e-02
I0208 13:46:41.878544 22542570456896 run_lib.py:146] step: 8300, eval_loss: 3.83376e-02
I0208 13:46:59.357692 22542570456896 run_lib.py:133] step: 8350, training_loss: 3.27945e-02
I0208 13:47:16.825547 22542570456896 run_lib.py:133] step: 8400, training_loss: 3.31539e-02
I0208 13:47:16.980220 22542570456896 run_lib.py:146] step: 8400, eval_loss: 4.47119e-02
I0208 13:47:34.569833 22542570456896 run_lib.py:133] step: 8450, training_loss: 3.04540e-02
I0208 13:47:52.028419 22542570456896 run_lib.py:133] step: 8500, training_loss: 3.08564e-02
I0208 13:47:52.185405 22542570456896 run_lib.py:146] step: 8500, eval_loss: 2.40625e-02
I0208 13:48:09.616097 22542570456896 run_lib.py:133] step: 8550, training_loss: 3.54900e-02
I0208 13:48:27.046509 22542570456896 run_lib.py:133] step: 8600, training_loss: 2.60878e-02
I0208 13:48:27.212117 22542570456896 run_lib.py:146] step: 8600, eval_loss: 2.98933e-02
I0208 13:48:44.829791 22542570456896 run_lib.py:133] step: 8650, training_loss: 3.34715e-02
I0208 13:49:02.245119 22542570456896 run_lib.py:133] step: 8700, training_loss: 2.92800e-02
I0208 13:49:02.400744 22542570456896 run_lib.py:146] step: 8700, eval_loss: 3.53009e-02
I0208 13:49:19.972478 22542570456896 run_lib.py:133] step: 8750, training_loss: 2.67259e-02
I0208 13:49:37.413902 22542570456896 run_lib.py:133] step: 8800, training_loss: 3.52225e-02
I0208 13:49:37.567061 22542570456896 run_lib.py:146] step: 8800, eval_loss: 3.28940e-02
I0208 13:49:55.127035 22542570456896 run_lib.py:133] step: 8850, training_loss: 3.11929e-02
I0208 13:50:12.545140 22542570456896 run_lib.py:133] step: 8900, training_loss: 3.01345e-02
I0208 13:50:12.722601 22542570456896 run_lib.py:146] step: 8900, eval_loss: 3.25204e-02
I0208 13:50:30.224162 22542570456896 run_lib.py:133] step: 8950, training_loss: 3.02247e-02
I0208 13:50:47.849345 22542570456896 run_lib.py:133] step: 9000, training_loss: 2.93759e-02
I0208 13:50:48.007301 22542570456896 run_lib.py:146] step: 9000, eval_loss: 2.96383e-02
I0208 13:51:05.388063 22542570456896 run_lib.py:133] step: 9050, training_loss: 2.89024e-02
I0208 13:51:22.907227 22542570456896 run_lib.py:133] step: 9100, training_loss: 3.23621e-02
I0208 13:51:23.064299 22542570456896 run_lib.py:146] step: 9100, eval_loss: 2.99409e-02
I0208 13:51:40.525188 22542570456896 run_lib.py:133] step: 9150, training_loss: 3.06498e-02
I0208 13:51:57.972560 22542570456896 run_lib.py:133] step: 9200, training_loss: 2.67334e-02
I0208 13:51:58.129621 22542570456896 run_lib.py:146] step: 9200, eval_loss: 3.10768e-02
I0208 13:52:15.731081 22542570456896 run_lib.py:133] step: 9250, training_loss: 2.78171e-02
I0208 13:52:33.137525 22542570456896 run_lib.py:133] step: 9300, training_loss: 3.75257e-02
I0208 13:52:33.291289 22542570456896 run_lib.py:146] step: 9300, eval_loss: 2.68031e-02
I0208 13:52:50.711079 22542570456896 run_lib.py:133] step: 9350, training_loss: 3.10844e-02
I0208 13:53:08.114182 22542570456896 run_lib.py:133] step: 9400, training_loss: 3.01952e-02
I0208 13:53:08.290280 22542570456896 run_lib.py:146] step: 9400, eval_loss: 3.13975e-02
I0208 13:53:25.885421 22542570456896 run_lib.py:133] step: 9450, training_loss: 2.96739e-02
I0208 13:53:43.312634 22542570456896 run_lib.py:133] step: 9500, training_loss: 2.45620e-02
I0208 13:53:43.470445 22542570456896 run_lib.py:146] step: 9500, eval_loss: 2.51559e-02
I0208 13:54:00.975235 22542570456896 run_lib.py:133] step: 9550, training_loss: 2.76278e-02
I0208 13:54:18.371012 22542570456896 run_lib.py:133] step: 9600, training_loss: 2.55430e-02
I0208 13:54:18.526610 22542570456896 run_lib.py:146] step: 9600, eval_loss: 3.57851e-02
I0208 13:54:35.917399 22542570456896 run_lib.py:133] step: 9650, training_loss: 3.76539e-02
I0208 13:54:53.319003 22542570456896 run_lib.py:133] step: 9700, training_loss: 2.65544e-02
I0208 13:54:53.472067 22542570456896 run_lib.py:146] step: 9700, eval_loss: 3.18732e-02
I0208 13:55:11.118451 22542570456896 run_lib.py:133] step: 9750, training_loss: 3.49816e-02
I0208 13:55:28.592976 22542570456896 run_lib.py:133] step: 9800, training_loss: 2.74391e-02
I0208 13:55:28.745413 22542570456896 run_lib.py:146] step: 9800, eval_loss: 3.35227e-02
I0208 13:55:46.162519 22542570456896 run_lib.py:133] step: 9850, training_loss: 2.92220e-02
I0208 13:56:03.571376 22542570456896 run_lib.py:133] step: 9900, training_loss: 3.31555e-02
I0208 13:56:03.731545 22542570456896 run_lib.py:146] step: 9900, eval_loss: 3.36733e-02
I0208 13:56:21.299154 22542570456896 run_lib.py:133] step: 9950, training_loss: 3.49846e-02
I0208 13:56:38.791041 22542570456896 run_lib.py:133] step: 10000, training_loss: 3.22687e-02
I0208 13:56:39.497126 22542570456896 run_lib.py:146] step: 10000, eval_loss: 2.86938e-02
I0208 13:56:59.798640 22542570456896 run_lib.py:133] step: 10050, training_loss: 2.43569e-02
I0208 13:57:17.324590 22542570456896 run_lib.py:133] step: 10100, training_loss: 2.90191e-02
I0208 13:57:17.480411 22542570456896 run_lib.py:146] step: 10100, eval_loss: 3.72240e-02
I0208 13:57:34.929587 22542570456896 run_lib.py:133] step: 10150, training_loss: 2.64977e-02
I0208 13:57:52.324878 22542570456896 run_lib.py:133] step: 10200, training_loss: 2.61430e-02
I0208 13:57:52.479192 22542570456896 run_lib.py:146] step: 10200, eval_loss: 3.25585e-02
I0208 13:58:10.029817 22542570456896 run_lib.py:133] step: 10250, training_loss: 3.94023e-02
I0208 13:58:27.559586 22542570456896 run_lib.py:133] step: 10300, training_loss: 2.44286e-02
I0208 13:58:27.715469 22542570456896 run_lib.py:146] step: 10300, eval_loss: 2.40043e-02
I0208 13:58:45.185108 22542570456896 run_lib.py:133] step: 10350, training_loss: 3.00542e-02
I0208 13:59:02.620399 22542570456896 run_lib.py:133] step: 10400, training_loss: 2.49375e-02
I0208 13:59:02.780410 22542570456896 run_lib.py:146] step: 10400, eval_loss: 2.22272e-02
I0208 13:59:20.339932 22542570456896 run_lib.py:133] step: 10450, training_loss: 2.62616e-02
I0208 13:59:37.740677 22542570456896 run_lib.py:133] step: 10500, training_loss: 2.36932e-02
I0208 13:59:37.899362 22542570456896 run_lib.py:146] step: 10500, eval_loss: 2.58576e-02
I0208 13:59:55.467419 22542570456896 run_lib.py:133] step: 10550, training_loss: 3.77989e-02
I0208 14:00:12.927830 22542570456896 run_lib.py:133] step: 10600, training_loss: 3.27630e-02
I0208 14:00:13.085002 22542570456896 run_lib.py:146] step: 10600, eval_loss: 3.20933e-02
I0208 14:00:30.701526 22542570456896 run_lib.py:133] step: 10650, training_loss: 3.47279e-02
I0208 14:00:48.113591 22542570456896 run_lib.py:133] step: 10700, training_loss: 3.58897e-02
I0208 14:00:48.270151 22542570456896 run_lib.py:146] step: 10700, eval_loss: 2.91011e-02
I0208 14:01:05.679464 22542570456896 run_lib.py:133] step: 10750, training_loss: 3.71283e-02
I0208 14:01:23.212565 22542570456896 run_lib.py:133] step: 10800, training_loss: 2.99958e-02
I0208 14:01:23.365320 22542570456896 run_lib.py:146] step: 10800, eval_loss: 4.04702e-02
I0208 14:01:40.783337 22542570456896 run_lib.py:133] step: 10850, training_loss: 2.53280e-02
I0208 14:01:58.379098 22542570456896 run_lib.py:133] step: 10900, training_loss: 3.27758e-02
I0208 14:01:58.558383 22542570456896 run_lib.py:146] step: 10900, eval_loss: 2.34370e-02
I0208 14:02:15.975598 22542570456896 run_lib.py:133] step: 10950, training_loss: 4.28506e-02
I0208 14:02:33.377599 22542570456896 run_lib.py:133] step: 11000, training_loss: 2.41933e-02
I0208 14:02:33.534702 22542570456896 run_lib.py:146] step: 11000, eval_loss: 2.90779e-02
I0208 14:02:51.120250 22542570456896 run_lib.py:133] step: 11050, training_loss: 4.12094e-02
I0208 14:03:08.504608 22542570456896 run_lib.py:133] step: 11100, training_loss: 3.38224e-02
I0208 14:03:08.661295 22542570456896 run_lib.py:146] step: 11100, eval_loss: 3.02975e-02
I0208 14:03:26.082429 22542570456896 run_lib.py:133] step: 11150, training_loss: 3.17088e-02
I0208 14:03:43.650990 22542570456896 run_lib.py:133] step: 11200, training_loss: 2.84823e-02
I0208 14:03:43.814751 22542570456896 run_lib.py:146] step: 11200, eval_loss: 2.78683e-02
I0208 14:04:01.290605 22542570456896 run_lib.py:133] step: 11250, training_loss: 3.81375e-02
I0208 14:04:18.709565 22542570456896 run_lib.py:133] step: 11300, training_loss: 3.51475e-02
I0208 14:04:19.051234 22542570456896 run_lib.py:146] step: 11300, eval_loss: 2.83638e-02
I0208 14:04:36.487147 22542570456896 run_lib.py:133] step: 11350, training_loss: 3.09887e-02
I0208 14:04:53.900105 22542570456896 run_lib.py:133] step: 11400, training_loss: 3.30331e-02
I0208 14:04:54.062279 22542570456896 run_lib.py:146] step: 11400, eval_loss: 3.71419e-02
I0208 14:05:11.505064 22542570456896 run_lib.py:133] step: 11450, training_loss: 3.37941e-02
I0208 14:05:28.958444 22542570456896 run_lib.py:133] step: 11500, training_loss: 3.12617e-02
I0208 14:05:29.112688 22542570456896 run_lib.py:146] step: 11500, eval_loss: 3.21876e-02
I0208 14:05:46.689342 22542570456896 run_lib.py:133] step: 11550, training_loss: 3.20689e-02
I0208 14:06:04.174138 22542570456896 run_lib.py:133] step: 11600, training_loss: 3.12447e-02
I0208 14:06:04.329322 22542570456896 run_lib.py:146] step: 11600, eval_loss: 3.06488e-02
I0208 14:06:21.732556 22542570456896 run_lib.py:133] step: 11650, training_loss: 2.44972e-02
I0208 14:06:39.140600 22542570456896 run_lib.py:133] step: 11700, training_loss: 2.81961e-02
I0208 14:06:39.293069 22542570456896 run_lib.py:146] step: 11700, eval_loss: 3.37917e-02
I0208 14:06:56.850605 22542570456896 run_lib.py:133] step: 11750, training_loss: 2.96830e-02
I0208 14:07:14.322237 22542570456896 run_lib.py:133] step: 11800, training_loss: 2.75883e-02
I0208 14:07:14.491398 22542570456896 run_lib.py:146] step: 11800, eval_loss: 3.39290e-02
I0208 14:07:31.961257 22542570456896 run_lib.py:133] step: 11850, training_loss: 2.70437e-02
I0208 14:07:49.451993 22542570456896 run_lib.py:133] step: 11900, training_loss: 3.02390e-02
I0208 14:07:49.611310 22542570456896 run_lib.py:146] step: 11900, eval_loss: 2.41927e-02
I0208 14:08:07.200340 22542570456896 run_lib.py:133] step: 11950, training_loss: 3.31081e-02
I0208 14:08:24.611760 22542570456896 run_lib.py:133] step: 12000, training_loss: 3.43115e-02
I0208 14:08:24.767236 22542570456896 run_lib.py:146] step: 12000, eval_loss: 2.77179e-02
I0208 14:08:42.351166 22542570456896 run_lib.py:133] step: 12050, training_loss: 3.52546e-02
I0208 14:08:59.820209 22542570456896 run_lib.py:133] step: 12100, training_loss: 3.17901e-02
I0208 14:08:59.976555 22542570456896 run_lib.py:146] step: 12100, eval_loss: 3.06790e-02
I0208 14:09:17.599086 22542570456896 run_lib.py:133] step: 12150, training_loss: 2.91365e-02
I0208 14:09:35.025677 22542570456896 run_lib.py:133] step: 12200, training_loss: 3.14265e-02
I0208 14:09:35.177548 22542570456896 run_lib.py:146] step: 12200, eval_loss: 2.38436e-02
I0208 14:09:52.545985 22542570456896 run_lib.py:133] step: 12250, training_loss: 3.05999e-02
I0208 14:10:10.061942 22542570456896 run_lib.py:133] step: 12300, training_loss: 3.72203e-02
I0208 14:10:10.223019 22542570456896 run_lib.py:146] step: 12300, eval_loss: 2.43292e-02
I0208 14:10:27.538540 22542570456896 run_lib.py:133] step: 12350, training_loss: 2.71455e-02
I0208 14:10:45.060457 22542570456896 run_lib.py:133] step: 12400, training_loss: 2.69520e-02
I0208 14:10:45.241535 22542570456896 run_lib.py:146] step: 12400, eval_loss: 2.70323e-02
I0208 14:11:02.760732 22542570456896 run_lib.py:133] step: 12450, training_loss: 3.26369e-02
I0208 14:11:20.270601 22542570456896 run_lib.py:133] step: 12500, training_loss: 3.65039e-02
I0208 14:11:20.426651 22542570456896 run_lib.py:146] step: 12500, eval_loss: 2.13397e-02
I0208 14:11:38.067261 22542570456896 run_lib.py:133] step: 12550, training_loss: 3.63785e-02
I0208 14:11:55.468219 22542570456896 run_lib.py:133] step: 12600, training_loss: 2.01502e-02
I0208 14:11:55.623292 22542570456896 run_lib.py:146] step: 12600, eval_loss: 3.48762e-02
I0208 14:12:13.038786 22542570456896 run_lib.py:133] step: 12650, training_loss: 2.49788e-02
I0208 14:12:30.529977 22542570456896 run_lib.py:133] step: 12700, training_loss: 3.21543e-02
I0208 14:12:30.686513 22542570456896 run_lib.py:146] step: 12700, eval_loss: 4.19556e-02
I0208 14:12:48.320716 22542570456896 run_lib.py:133] step: 12750, training_loss: 2.93885e-02
I0208 14:13:05.777095 22542570456896 run_lib.py:133] step: 12800, training_loss: 3.55026e-02
I0208 14:13:05.941010 22542570456896 run_lib.py:146] step: 12800, eval_loss: 2.69207e-02
I0208 14:13:23.433542 22542570456896 run_lib.py:133] step: 12850, training_loss: 3.22606e-02
I0208 14:13:40.840490 22542570456896 run_lib.py:133] step: 12900, training_loss: 2.81667e-02
I0208 14:13:41.005908 22542570456896 run_lib.py:146] step: 12900, eval_loss: 3.65190e-02
I0208 14:13:58.475327 22542570456896 run_lib.py:133] step: 12950, training_loss: 3.35986e-02
I0208 14:14:15.965260 22542570456896 run_lib.py:133] step: 13000, training_loss: 2.76537e-02
I0208 14:14:16.119027 22542570456896 run_lib.py:146] step: 13000, eval_loss: 3.24697e-02
I0208 14:14:33.746296 22542570456896 run_lib.py:133] step: 13050, training_loss: 2.60628e-02
I0208 14:14:51.254420 22542570456896 run_lib.py:133] step: 13100, training_loss: 4.02316e-02
I0208 14:14:51.407132 22542570456896 run_lib.py:146] step: 13100, eval_loss: 2.63517e-02
I0208 14:15:08.866364 22542570456896 run_lib.py:133] step: 13150, training_loss: 2.83346e-02
I0208 14:15:26.317278 22542570456896 run_lib.py:133] step: 13200, training_loss: 3.10723e-02
I0208 14:15:26.474512 22542570456896 run_lib.py:146] step: 13200, eval_loss: 3.05565e-02
I0208 14:15:44.017432 22542570456896 run_lib.py:133] step: 13250, training_loss: 3.34347e-02
I0208 14:16:01.442294 22542570456896 run_lib.py:133] step: 13300, training_loss: 4.28483e-02
I0208 14:16:01.620474 22542570456896 run_lib.py:146] step: 13300, eval_loss: 3.35879e-02
I0208 14:16:19.407383 22542570456896 run_lib.py:133] step: 13350, training_loss: 4.08657e-02
I0208 14:16:36.836561 22542570456896 run_lib.py:133] step: 13400, training_loss: 3.52982e-02
I0208 14:16:36.993526 22542570456896 run_lib.py:146] step: 13400, eval_loss: 3.27520e-02
I0208 14:16:54.562511 22542570456896 run_lib.py:133] step: 13450, training_loss: 3.75118e-02
I0208 14:17:11.957827 22542570456896 run_lib.py:133] step: 13500, training_loss: 3.16631e-02
I0208 14:17:12.117294 22542570456896 run_lib.py:146] step: 13500, eval_loss: 2.91284e-02
I0208 14:17:29.672259 22542570456896 run_lib.py:133] step: 13550, training_loss: 3.38247e-02
I0208 14:17:47.090903 22542570456896 run_lib.py:133] step: 13600, training_loss: 3.39529e-02
I0208 14:17:47.253367 22542570456896 run_lib.py:146] step: 13600, eval_loss: 2.94070e-02
I0208 14:18:04.713664 22542570456896 run_lib.py:133] step: 13650, training_loss: 3.02639e-02
I0208 14:18:22.309542 22542570456896 run_lib.py:133] step: 13700, training_loss: 3.33212e-02
I0208 14:18:22.469012 22542570456896 run_lib.py:146] step: 13700, eval_loss: 3.09083e-02
I0208 14:18:39.823935 22542570456896 run_lib.py:133] step: 13750, training_loss: 2.26463e-02
I0208 14:18:57.242756 22542570456896 run_lib.py:133] step: 13800, training_loss: 3.91858e-02
I0208 14:18:57.414345 22542570456896 run_lib.py:146] step: 13800, eval_loss: 3.23758e-02
I0208 14:19:15.011732 22542570456896 run_lib.py:133] step: 13850, training_loss: 2.56843e-02
I0208 14:19:32.603082 22542570456896 run_lib.py:133] step: 13900, training_loss: 3.06358e-02
I0208 14:19:32.759920 22542570456896 run_lib.py:146] step: 13900, eval_loss: 3.57236e-02
I0208 14:19:50.163797 22542570456896 run_lib.py:133] step: 13950, training_loss: 3.90008e-02
I0208 14:20:07.547825 22542570456896 run_lib.py:133] step: 14000, training_loss: 3.69225e-02
I0208 14:20:07.703114 22542570456896 run_lib.py:146] step: 14000, eval_loss: 2.52624e-02
I0208 14:20:25.147571 22542570456896 run_lib.py:133] step: 14050, training_loss: 2.97527e-02
I0208 14:20:42.725488 22542570456896 run_lib.py:133] step: 14100, training_loss: 3.52973e-02
I0208 14:20:42.878443 22542570456896 run_lib.py:146] step: 14100, eval_loss: 3.34558e-02
I0208 14:21:00.369294 22542570456896 run_lib.py:133] step: 14150, training_loss: 2.73236e-02
I0208 14:21:17.788271 22542570456896 run_lib.py:133] step: 14200, training_loss: 3.13222e-02
I0208 14:21:17.954335 22542570456896 run_lib.py:146] step: 14200, eval_loss: 3.58175e-02
I0208 14:21:35.403311 22542570456896 run_lib.py:133] step: 14250, training_loss: 3.77594e-02
I0208 14:21:53.028490 22542570456896 run_lib.py:133] step: 14300, training_loss: 2.12066e-02
I0208 14:21:53.189635 22542570456896 run_lib.py:146] step: 14300, eval_loss: 3.28859e-02
I0208 14:22:10.607668 22542570456896 run_lib.py:133] step: 14350, training_loss: 3.28019e-02
I0208 14:22:28.093068 22542570456896 run_lib.py:133] step: 14400, training_loss: 3.07779e-02
I0208 14:22:28.266974 22542570456896 run_lib.py:146] step: 14400, eval_loss: 2.94622e-02
I0208 14:22:45.730724 22542570456896 run_lib.py:133] step: 14450, training_loss: 2.51437e-02
I0208 14:23:03.168491 22542570456896 run_lib.py:133] step: 14500, training_loss: 3.54726e-02
I0208 14:23:03.324557 22542570456896 run_lib.py:146] step: 14500, eval_loss: 3.09188e-02
I0208 14:23:20.875433 22542570456896 run_lib.py:133] step: 14550, training_loss: 3.00924e-02
I0208 14:23:38.321089 22542570456896 run_lib.py:133] step: 14600, training_loss: 3.22528e-02
I0208 14:23:38.474386 22542570456896 run_lib.py:146] step: 14600, eval_loss: 2.99220e-02
I0208 14:23:55.899129 22542570456896 run_lib.py:133] step: 14650, training_loss: 2.74813e-02
I0208 14:24:13.326242 22542570456896 run_lib.py:133] step: 14700, training_loss: 3.71038e-02
I0208 14:24:13.502249 22542570456896 run_lib.py:146] step: 14700, eval_loss: 3.35433e-02
I0208 14:24:31.119125 22542570456896 run_lib.py:133] step: 14750, training_loss: 2.42023e-02
I0208 14:24:48.562332 22542570456896 run_lib.py:133] step: 14800, training_loss: 2.45747e-02
I0208 14:24:48.720472 22542570456896 run_lib.py:146] step: 14800, eval_loss: 3.25729e-02
I0208 14:25:06.292590 22542570456896 run_lib.py:133] step: 14850, training_loss: 2.46793e-02
I0208 14:25:23.717677 22542570456896 run_lib.py:133] step: 14900, training_loss: 3.15095e-02
I0208 14:25:23.874140 22542570456896 run_lib.py:146] step: 14900, eval_loss: 3.54498e-02
I0208 14:25:41.425536 22542570456896 run_lib.py:133] step: 14950, training_loss: 2.78515e-02
I0208 14:25:58.903043 22542570456896 run_lib.py:133] step: 15000, training_loss: 3.83848e-02
I0208 14:25:59.058187 22542570456896 run_lib.py:146] step: 15000, eval_loss: 3.02805e-02
I0208 14:26:16.486679 22542570456896 run_lib.py:133] step: 15050, training_loss: 3.23876e-02
I0208 14:26:34.127463 22542570456896 run_lib.py:133] step: 15100, training_loss: 2.87254e-02
I0208 14:26:34.283272 22542570456896 run_lib.py:146] step: 15100, eval_loss: 3.32504e-02
I0208 14:26:51.684887 22542570456896 run_lib.py:133] step: 15150, training_loss: 3.19303e-02
I0208 14:27:09.269105 22542570456896 run_lib.py:133] step: 15200, training_loss: 2.67277e-02
I0208 14:27:09.428321 22542570456896 run_lib.py:146] step: 15200, eval_loss: 3.28621e-02
I0208 14:27:26.863176 22542570456896 run_lib.py:133] step: 15250, training_loss: 2.89377e-02
I0208 14:27:44.317249 22542570456896 run_lib.py:133] step: 15300, training_loss: 3.11234e-02
I0208 14:27:44.477479 22542570456896 run_lib.py:146] step: 15300, eval_loss: 2.81577e-02
I0208 14:28:02.093913 22542570456896 run_lib.py:133] step: 15350, training_loss: 2.56104e-02
I0208 14:28:19.491342 22542570456896 run_lib.py:133] step: 15400, training_loss: 2.63345e-02
I0208 14:28:19.648338 22542570456896 run_lib.py:146] step: 15400, eval_loss: 2.81266e-02
I0208 14:28:37.113951 22542570456896 run_lib.py:133] step: 15450, training_loss: 3.22692e-02
I0208 14:28:54.662334 22542570456896 run_lib.py:133] step: 15500, training_loss: 2.52730e-02
I0208 14:28:54.821300 22542570456896 run_lib.py:146] step: 15500, eval_loss: 2.86669e-02
I0208 14:29:12.213780 22542570456896 run_lib.py:133] step: 15550, training_loss: 3.17823e-02
I0208 14:29:29.699277 22542570456896 run_lib.py:133] step: 15600, training_loss: 2.69346e-02
I0208 14:29:29.870408 22542570456896 run_lib.py:146] step: 15600, eval_loss: 2.94632e-02
I0208 14:29:47.388567 22542570456896 run_lib.py:133] step: 15650, training_loss: 3.12090e-02
I0208 14:30:04.819092 22542570456896 run_lib.py:133] step: 15700, training_loss: 3.21081e-02
I0208 14:30:04.984102 22542570456896 run_lib.py:146] step: 15700, eval_loss: 2.86198e-02
I0208 14:30:22.400697 22542570456896 run_lib.py:133] step: 15750, training_loss: 3.19448e-02
I0208 14:30:39.834120 22542570456896 run_lib.py:133] step: 15800, training_loss: 2.69554e-02
I0208 14:30:39.989950 22542570456896 run_lib.py:146] step: 15800, eval_loss: 2.53482e-02
I0208 14:30:57.558405 22542570456896 run_lib.py:133] step: 15850, training_loss: 2.64240e-02
I0208 14:31:15.118983 22542570456896 run_lib.py:133] step: 15900, training_loss: 2.60555e-02
I0208 14:31:15.278420 22542570456896 run_lib.py:146] step: 15900, eval_loss: 2.86537e-02
I0208 14:31:32.727107 22542570456896 run_lib.py:133] step: 15950, training_loss: 2.83805e-02
I0208 14:31:50.164811 22542570456896 run_lib.py:133] step: 16000, training_loss: 3.05199e-02
I0208 14:31:50.325451 22542570456896 run_lib.py:146] step: 16000, eval_loss: 2.52211e-02
I0208 14:32:07.924170 22542570456896 run_lib.py:133] step: 16050, training_loss: 2.79009e-02
I0208 14:32:25.347914 22542570456896 run_lib.py:133] step: 16100, training_loss: 2.73588e-02
I0208 14:32:25.509498 22542570456896 run_lib.py:146] step: 16100, eval_loss: 2.90429e-02
I0208 14:32:43.076442 22542570456896 run_lib.py:133] step: 16150, training_loss: 2.70981e-02
I0208 14:33:00.540895 22542570456896 run_lib.py:133] step: 16200, training_loss: 2.57011e-02
I0208 14:33:00.694576 22542570456896 run_lib.py:146] step: 16200, eval_loss: 2.95756e-02
I0208 14:33:18.308420 22542570456896 run_lib.py:133] step: 16250, training_loss: 2.66284e-02
I0208 14:33:35.698616 22542570456896 run_lib.py:133] step: 16300, training_loss: 2.72474e-02
I0208 14:33:35.852384 22542570456896 run_lib.py:146] step: 16300, eval_loss: 3.22435e-02
I0208 14:33:53.461414 22542570456896 run_lib.py:133] step: 16350, training_loss: 3.40837e-02
I0208 14:34:10.897519 22542570456896 run_lib.py:133] step: 16400, training_loss: 3.14499e-02
I0208 14:34:11.053368 22542570456896 run_lib.py:146] step: 16400, eval_loss: 2.73497e-02
I0208 14:34:28.571038 22542570456896 run_lib.py:133] step: 16450, training_loss: 2.66661e-02
I0208 14:34:46.145047 22542570456896 run_lib.py:133] step: 16500, training_loss: 2.40197e-02
I0208 14:34:46.301625 22542570456896 run_lib.py:146] step: 16500, eval_loss: 3.13323e-02
I0208 14:35:03.742470 22542570456896 run_lib.py:133] step: 16550, training_loss: 2.99441e-02
I0208 14:35:21.179688 22542570456896 run_lib.py:133] step: 16600, training_loss: 2.60736e-02
I0208 14:35:21.339221 22542570456896 run_lib.py:146] step: 16600, eval_loss: 3.46340e-02
I0208 14:35:38.912818 22542570456896 run_lib.py:133] step: 16650, training_loss: 3.16449e-02
I0208 14:35:56.402310 22542570456896 run_lib.py:133] step: 16700, training_loss: 2.71215e-02
I0208 14:35:56.570199 22542570456896 run_lib.py:146] step: 16700, eval_loss: 2.69985e-02
I0208 14:36:14.165566 22542570456896 run_lib.py:133] step: 16750, training_loss: 2.69226e-02
I0208 14:36:31.630542 22542570456896 run_lib.py:133] step: 16800, training_loss: 3.53165e-02
I0208 14:36:31.787058 22542570456896 run_lib.py:146] step: 16800, eval_loss: 2.73658e-02
I0208 14:36:49.225650 22542570456896 run_lib.py:133] step: 16850, training_loss: 2.66782e-02
I0208 14:37:06.814190 22542570456896 run_lib.py:133] step: 16900, training_loss: 2.73676e-02
I0208 14:37:06.976300 22542570456896 run_lib.py:146] step: 16900, eval_loss: 2.98581e-02
I0208 14:37:24.457853 22542570456896 run_lib.py:133] step: 16950, training_loss: 3.88254e-02
I0208 14:37:41.904790 22542570456896 run_lib.py:133] step: 17000, training_loss: 3.50996e-02
I0208 14:37:42.073597 22542570456896 run_lib.py:146] step: 17000, eval_loss: 3.85482e-02
I0208 14:37:59.479680 22542570456896 run_lib.py:133] step: 17050, training_loss: 3.29203e-02
I0208 14:38:17.081261 22542570456896 run_lib.py:133] step: 17100, training_loss: 3.23201e-02
I0208 14:38:17.238232 22542570456896 run_lib.py:146] step: 17100, eval_loss: 2.90560e-02
I0208 14:38:34.654736 22542570456896 run_lib.py:133] step: 17150, training_loss: 2.74685e-02
I0208 14:38:52.130476 22542570456896 run_lib.py:133] step: 17200, training_loss: 2.90764e-02
I0208 14:38:52.286154 22542570456896 run_lib.py:146] step: 17200, eval_loss: 2.99078e-02
I0208 14:39:09.744780 22542570456896 run_lib.py:133] step: 17250, training_loss: 4.06121e-02
I0208 14:39:27.250286 22542570456896 run_lib.py:133] step: 17300, training_loss: 3.25355e-02
I0208 14:39:27.405703 22542570456896 run_lib.py:146] step: 17300, eval_loss: 2.47348e-02
I0208 14:39:45.034650 22542570456896 run_lib.py:133] step: 17350, training_loss: 3.12071e-02
I0208 14:40:02.485638 22542570456896 run_lib.py:133] step: 17400, training_loss: 2.86027e-02
I0208 14:40:02.648258 22542570456896 run_lib.py:146] step: 17400, eval_loss: 2.89723e-02
I0208 14:40:20.035525 22542570456896 run_lib.py:133] step: 17450, training_loss: 2.86088e-02
I0208 14:40:37.448996 22542570456896 run_lib.py:133] step: 17500, training_loss: 2.90081e-02
I0208 14:40:37.604258 22542570456896 run_lib.py:146] step: 17500, eval_loss: 2.88418e-02
I0208 14:40:55.183156 22542570456896 run_lib.py:133] step: 17550, training_loss: 2.43179e-02
I0208 14:41:12.665339 22542570456896 run_lib.py:133] step: 17600, training_loss: 2.92142e-02
I0208 14:41:12.825278 22542570456896 run_lib.py:146] step: 17600, eval_loss: 2.53995e-02
I0208 14:41:30.394389 22542570456896 run_lib.py:133] step: 17650, training_loss: 2.67581e-02
I0208 14:41:47.819160 22542570456896 run_lib.py:133] step: 17700, training_loss: 2.59059e-02
I0208 14:41:47.974428 22542570456896 run_lib.py:146] step: 17700, eval_loss: 2.84121e-02
I0208 14:42:05.541352 22542570456896 run_lib.py:133] step: 17750, training_loss: 3.62900e-02
I0208 14:42:22.954724 22542570456896 run_lib.py:133] step: 17800, training_loss: 3.02285e-02
I0208 14:42:23.109220 22542570456896 run_lib.py:146] step: 17800, eval_loss: 2.46126e-02
I0208 14:42:40.524791 22542570456896 run_lib.py:133] step: 17850, training_loss: 2.71653e-02
I0208 14:42:58.124449 22542570456896 run_lib.py:133] step: 17900, training_loss: 2.85344e-02
I0208 14:42:58.280532 22542570456896 run_lib.py:146] step: 17900, eval_loss: 2.89805e-02
I0208 14:43:15.754556 22542570456896 run_lib.py:133] step: 17950, training_loss: 2.93169e-02
I0208 14:43:33.413235 22542570456896 run_lib.py:133] step: 18000, training_loss: 3.01075e-02
I0208 14:43:33.571470 22542570456896 run_lib.py:146] step: 18000, eval_loss: 3.27683e-02
I0208 14:43:51.002497 22542570456896 run_lib.py:133] step: 18050, training_loss: 2.76772e-02
I0208 14:44:08.398858 22542570456896 run_lib.py:133] step: 18100, training_loss: 2.88721e-02
I0208 14:44:08.558437 22542570456896 run_lib.py:146] step: 18100, eval_loss: 2.71650e-02
I0208 14:44:26.183932 22542570456896 run_lib.py:133] step: 18150, training_loss: 3.10713e-02
I0208 14:44:43.679739 22542570456896 run_lib.py:133] step: 18200, training_loss: 2.63865e-02
I0208 14:44:43.837858 22542570456896 run_lib.py:146] step: 18200, eval_loss: 2.95494e-02
I0208 14:45:01.281673 22542570456896 run_lib.py:133] step: 18250, training_loss: 2.88232e-02
I0208 14:45:18.906834 22542570456896 run_lib.py:133] step: 18300, training_loss: 3.76483e-02
I0208 14:45:19.064020 22542570456896 run_lib.py:146] step: 18300, eval_loss: 2.79591e-02
I0208 14:45:36.497758 22542570456896 run_lib.py:133] step: 18350, training_loss: 3.26061e-02
I0208 14:45:53.905387 22542570456896 run_lib.py:133] step: 18400, training_loss: 3.19789e-02
I0208 14:45:54.208306 22542570456896 run_lib.py:146] step: 18400, eval_loss: 3.30033e-02
I0208 14:46:11.653512 22542570456896 run_lib.py:133] step: 18450, training_loss: 3.34676e-02
I0208 14:46:29.081833 22542570456896 run_lib.py:133] step: 18500, training_loss: 3.08820e-02
I0208 14:46:29.241302 22542570456896 run_lib.py:146] step: 18500, eval_loss: 2.85794e-02
I0208 14:46:46.647192 22542570456896 run_lib.py:133] step: 18550, training_loss: 3.47864e-02
I0208 14:47:04.143026 22542570456896 run_lib.py:133] step: 18600, training_loss: 3.60387e-02
I0208 14:47:04.299208 22542570456896 run_lib.py:146] step: 18600, eval_loss: 2.90303e-02
I0208 14:47:21.894895 22542570456896 run_lib.py:133] step: 18650, training_loss: 3.13364e-02
I0208 14:47:39.364545 22542570456896 run_lib.py:133] step: 18700, training_loss: 3.35885e-02
I0208 14:47:39.521540 22542570456896 run_lib.py:146] step: 18700, eval_loss: 3.29761e-02
I0208 14:47:56.949718 22542570456896 run_lib.py:133] step: 18750, training_loss: 3.66579e-02
I0208 14:48:14.431817 22542570456896 run_lib.py:133] step: 18800, training_loss: 2.51735e-02
I0208 14:48:14.588503 22542570456896 run_lib.py:146] step: 18800, eval_loss: 3.01855e-02
I0208 14:48:32.209229 22542570456896 run_lib.py:133] step: 18850, training_loss: 3.42898e-02
I0208 14:48:49.702728 22542570456896 run_lib.py:133] step: 18900, training_loss: 2.87599e-02
I0208 14:48:49.858293 22542570456896 run_lib.py:146] step: 18900, eval_loss: 2.62201e-02
I0208 14:49:07.250303 22542570456896 run_lib.py:133] step: 18950, training_loss: 3.40575e-02
I0208 14:49:24.679229 22542570456896 run_lib.py:133] step: 19000, training_loss: 2.69562e-02
I0208 14:49:24.837476 22542570456896 run_lib.py:146] step: 19000, eval_loss: 2.31658e-02
I0208 14:49:42.411557 22542570456896 run_lib.py:133] step: 19050, training_loss: 3.11577e-02
I0208 14:49:59.889302 22542570456896 run_lib.py:133] step: 19100, training_loss: 3.47376e-02
I0208 14:50:00.046687 22542570456896 run_lib.py:146] step: 19100, eval_loss: 3.41338e-02
I0208 14:50:17.604304 22542570456896 run_lib.py:133] step: 19150, training_loss: 3.21504e-02
I0208 14:50:34.977063 22542570456896 run_lib.py:133] step: 19200, training_loss: 4.19304e-02
I0208 14:50:35.136209 22542570456896 run_lib.py:146] step: 19200, eval_loss: 2.87062e-02
I0208 14:50:52.704440 22542570456896 run_lib.py:133] step: 19250, training_loss: 2.89171e-02
I0208 14:51:10.165919 22542570456896 run_lib.py:133] step: 19300, training_loss: 3.94727e-02
I0208 14:51:10.322515 22542570456896 run_lib.py:146] step: 19300, eval_loss: 2.76162e-02
I0208 14:51:27.784974 22542570456896 run_lib.py:133] step: 19350, training_loss: 2.81229e-02
I0208 14:51:45.402323 22542570456896 run_lib.py:133] step: 19400, training_loss: 3.53197e-02
I0208 14:51:45.559260 22542570456896 run_lib.py:146] step: 19400, eval_loss: 3.73039e-02
I0208 14:52:02.993056 22542570456896 run_lib.py:133] step: 19450, training_loss: 3.84398e-02
I0208 14:52:20.564904 22542570456896 run_lib.py:133] step: 19500, training_loss: 3.14896e-02
I0208 14:52:20.729562 22542570456896 run_lib.py:146] step: 19500, eval_loss: 2.72153e-02
I0208 14:52:38.136605 22542570456896 run_lib.py:133] step: 19550, training_loss: 3.10057e-02
I0208 14:52:55.525135 22542570456896 run_lib.py:133] step: 19600, training_loss: 2.19136e-02
I0208 14:52:55.693208 22542570456896 run_lib.py:146] step: 19600, eval_loss: 2.48725e-02
I0208 14:53:13.304439 22542570456896 run_lib.py:133] step: 19650, training_loss: 3.33270e-02
I0208 14:53:30.774419 22542570456896 run_lib.py:133] step: 19700, training_loss: 4.10176e-02
I0208 14:53:30.929519 22542570456896 run_lib.py:146] step: 19700, eval_loss: 2.76305e-02
I0208 14:53:48.343066 22542570456896 run_lib.py:133] step: 19750, training_loss: 3.82360e-02
I0208 14:54:05.715503 22542570456896 run_lib.py:133] step: 19800, training_loss: 2.77532e-02
I0208 14:54:05.868291 22542570456896 run_lib.py:146] step: 19800, eval_loss: 3.19931e-02
I0208 14:54:23.462764 22542570456896 run_lib.py:133] step: 19850, training_loss: 3.44307e-02
I0208 14:54:40.924362 22542570456896 run_lib.py:133] step: 19900, training_loss: 2.81508e-02
I0208 14:54:41.095299 22542570456896 run_lib.py:146] step: 19900, eval_loss: 2.65018e-02
I0208 14:54:58.606074 22542570456896 run_lib.py:133] step: 19950, training_loss: 2.29535e-02
I0208 14:55:16.072585 22542570456896 run_lib.py:133] step: 20000, training_loss: 3.17412e-02
I0208 14:55:16.781097 22542570456896 run_lib.py:146] step: 20000, eval_loss: 3.33569e-02
I0208 14:55:36.820199 22542570456896 run_lib.py:133] step: 20050, training_loss: 2.67487e-02
I0208 14:55:54.243275 22542570456896 run_lib.py:133] step: 20100, training_loss: 3.37289e-02
I0208 14:55:54.401257 22542570456896 run_lib.py:146] step: 20100, eval_loss: 2.76236e-02
I0208 14:56:11.835749 22542570456896 run_lib.py:133] step: 20150, training_loss: 2.83945e-02
I0208 14:56:29.479246 22542570456896 run_lib.py:133] step: 20200, training_loss: 2.58672e-02
I0208 14:56:29.639707 22542570456896 run_lib.py:146] step: 20200, eval_loss: 2.46178e-02
I0208 14:56:47.203701 22542570456896 run_lib.py:133] step: 20250, training_loss: 2.86123e-02
I0208 14:57:04.644607 22542570456896 run_lib.py:133] step: 20300, training_loss: 2.96973e-02
I0208 14:57:04.797370 22542570456896 run_lib.py:146] step: 20300, eval_loss: 3.41751e-02
I0208 14:57:22.253644 22542570456896 run_lib.py:133] step: 20350, training_loss: 3.55689e-02
I0208 14:57:39.671220 22542570456896 run_lib.py:133] step: 20400, training_loss: 2.35698e-02
I0208 14:57:39.827647 22542570456896 run_lib.py:146] step: 20400, eval_loss: 2.84142e-02
I0208 14:57:57.377058 22542570456896 run_lib.py:133] step: 20450, training_loss: 3.34803e-02
I0208 14:58:15.009253 22542570456896 run_lib.py:133] step: 20500, training_loss: 2.61238e-02
I0208 14:58:15.187371 22542570456896 run_lib.py:146] step: 20500, eval_loss: 2.74789e-02
I0208 14:58:32.621160 22542570456896 run_lib.py:133] step: 20550, training_loss: 3.43181e-02
I0208 14:58:50.057782 22542570456896 run_lib.py:133] step: 20600, training_loss: 2.93475e-02
I0208 14:58:50.224941 22542570456896 run_lib.py:146] step: 20600, eval_loss: 3.67484e-02
I0208 14:59:07.887280 22542570456896 run_lib.py:133] step: 20650, training_loss: 3.27188e-02
I0208 14:59:25.284978 22542570456896 run_lib.py:133] step: 20700, training_loss: 4.11802e-02
I0208 14:59:25.440307 22542570456896 run_lib.py:146] step: 20700, eval_loss: 3.26685e-02
I0208 14:59:43.018196 22542570456896 run_lib.py:133] step: 20750, training_loss: 3.40268e-02
I0208 15:00:00.535236 22542570456896 run_lib.py:133] step: 20800, training_loss: 3.25908e-02
I0208 15:00:00.697563 22542570456896 run_lib.py:146] step: 20800, eval_loss: 3.17484e-02
I0208 15:00:18.358359 22542570456896 run_lib.py:133] step: 20850, training_loss: 3.61859e-02
I0208 15:00:35.778135 22542570456896 run_lib.py:133] step: 20900, training_loss: 2.67189e-02
I0208 15:00:35.935334 22542570456896 run_lib.py:146] step: 20900, eval_loss: 2.98860e-02
I0208 15:00:53.370235 22542570456896 run_lib.py:133] step: 20950, training_loss: 3.11092e-02
I0208 15:01:10.932182 22542570456896 run_lib.py:133] step: 21000, training_loss: 2.96413e-02
I0208 15:01:11.090538 22542570456896 run_lib.py:146] step: 21000, eval_loss: 4.15649e-02
I0208 15:01:28.547797 22542570456896 run_lib.py:133] step: 21050, training_loss: 2.61775e-02
I0208 15:01:46.168347 22542570456896 run_lib.py:133] step: 21100, training_loss: 2.66482e-02
I0208 15:01:46.325478 22542570456896 run_lib.py:146] step: 21100, eval_loss: 3.14856e-02
I0208 15:02:03.732431 22542570456896 run_lib.py:133] step: 21150, training_loss: 3.73829e-02
I0208 15:02:21.160886 22542570456896 run_lib.py:133] step: 21200, training_loss: 2.87297e-02
I0208 15:02:21.328341 22542570456896 run_lib.py:146] step: 21200, eval_loss: 3.75515e-02
I0208 15:02:38.998091 22542570456896 run_lib.py:133] step: 21250, training_loss: 3.27001e-02
I0208 15:02:56.415749 22542570456896 run_lib.py:133] step: 21300, training_loss: 3.07729e-02
I0208 15:02:56.568431 22542570456896 run_lib.py:146] step: 21300, eval_loss: 3.03469e-02
I0208 15:03:14.041925 22542570456896 run_lib.py:133] step: 21350, training_loss: 2.85500e-02
I0208 15:03:31.673182 22542570456896 run_lib.py:133] step: 21400, training_loss: 2.40182e-02
I0208 15:03:31.833335 22542570456896 run_lib.py:146] step: 21400, eval_loss: 2.71848e-02
I0208 15:03:49.281801 22542570456896 run_lib.py:133] step: 21450, training_loss: 2.91817e-02
I0208 15:04:06.696527 22542570456896 run_lib.py:133] step: 21500, training_loss: 3.48805e-02
I0208 15:04:06.853500 22542570456896 run_lib.py:146] step: 21500, eval_loss: 3.36534e-02
I0208 15:04:24.364349 22542570456896 run_lib.py:133] step: 21550, training_loss: 3.09599e-02
I0208 15:04:41.810951 22542570456896 run_lib.py:133] step: 21600, training_loss: 3.00013e-02
I0208 15:04:41.979482 22542570456896 run_lib.py:146] step: 21600, eval_loss: 3.19149e-02
I0208 15:04:59.475550 22542570456896 run_lib.py:133] step: 21650, training_loss: 2.85083e-02
I0208 15:05:16.905924 22542570456896 run_lib.py:133] step: 21700, training_loss: 2.78641e-02
I0208 15:05:17.067088 22542570456896 run_lib.py:146] step: 21700, eval_loss: 2.89446e-02
I0208 15:05:34.678727 22542570456896 run_lib.py:133] step: 21750, training_loss: 2.93841e-02
I0208 15:05:52.166871 22542570456896 run_lib.py:133] step: 21800, training_loss: 3.49881e-02
I0208 15:05:52.322346 22542570456896 run_lib.py:146] step: 21800, eval_loss: 2.57335e-02
I0208 15:06:09.777190 22542570456896 run_lib.py:133] step: 21850, training_loss: 3.19760e-02
I0208 15:06:27.183656 22542570456896 run_lib.py:133] step: 21900, training_loss: 2.40381e-02
I0208 15:06:27.344369 22542570456896 run_lib.py:146] step: 21900, eval_loss: 3.32018e-02
I0208 15:06:44.994444 22542570456896 run_lib.py:133] step: 21950, training_loss: 2.79527e-02
I0208 15:07:02.444988 22542570456896 run_lib.py:133] step: 22000, training_loss: 3.05590e-02
I0208 15:07:02.602528 22542570456896 run_lib.py:146] step: 22000, eval_loss: 2.93640e-02
I0208 15:07:20.231890 22542570456896 run_lib.py:133] step: 22050, training_loss: 3.78217e-02
I0208 15:07:37.630375 22542570456896 run_lib.py:133] step: 22100, training_loss: 2.87496e-02
I0208 15:07:37.788213 22542570456896 run_lib.py:146] step: 22100, eval_loss: 2.69246e-02
I0208 15:07:55.333519 22542570456896 run_lib.py:133] step: 22150, training_loss: 2.64020e-02
I0208 15:08:12.768229 22542570456896 run_lib.py:133] step: 22200, training_loss: 2.87239e-02
I0208 15:08:12.930654 22542570456896 run_lib.py:146] step: 22200, eval_loss: 2.99575e-02
I0208 15:08:30.620974 22542570456896 run_lib.py:133] step: 22250, training_loss: 2.80969e-02
I0208 15:08:48.054996 22542570456896 run_lib.py:133] step: 22300, training_loss: 3.44399e-02
I0208 15:08:48.211526 22542570456896 run_lib.py:146] step: 22300, eval_loss: 3.54922e-02
I0208 15:09:05.660373 22542570456896 run_lib.py:133] step: 22350, training_loss: 2.55160e-02
I0208 15:09:23.299304 22542570456896 run_lib.py:133] step: 22400, training_loss: 3.25475e-02
I0208 15:09:23.459535 22542570456896 run_lib.py:146] step: 22400, eval_loss: 2.61729e-02
I0208 15:09:40.897687 22542570456896 run_lib.py:133] step: 22450, training_loss: 3.08632e-02
I0208 15:09:58.305108 22542570456896 run_lib.py:133] step: 22500, training_loss: 2.80854e-02
I0208 15:09:58.476395 22542570456896 run_lib.py:146] step: 22500, eval_loss: 3.13394e-02
I0208 15:10:16.099847 22542570456896 run_lib.py:133] step: 22550, training_loss: 3.27927e-02
I0208 15:10:33.574985 22542570456896 run_lib.py:133] step: 22600, training_loss: 2.64550e-02
I0208 15:10:33.732605 22542570456896 run_lib.py:146] step: 22600, eval_loss: 2.86068e-02
I0208 15:10:51.390546 22542570456896 run_lib.py:133] step: 22650, training_loss: 3.34497e-02
I0208 15:11:08.808512 22542570456896 run_lib.py:133] step: 22700, training_loss: 3.06716e-02
I0208 15:11:08.961351 22542570456896 run_lib.py:146] step: 22700, eval_loss: 2.86433e-02
I0208 15:11:26.359092 22542570456896 run_lib.py:133] step: 22750, training_loss: 2.64146e-02
I0208 15:11:43.945339 22542570456896 run_lib.py:133] step: 22800, training_loss: 3.05198e-02
I0208 15:11:44.115686 22542570456896 run_lib.py:146] step: 22800, eval_loss: 3.22213e-02
I0208 15:12:01.565682 22542570456896 run_lib.py:133] step: 22850, training_loss: 2.62308e-02
I0208 15:12:19.007561 22542570456896 run_lib.py:133] step: 22900, training_loss: 2.74066e-02
I0208 15:12:19.166609 22542570456896 run_lib.py:146] step: 22900, eval_loss: 2.65923e-02
I0208 15:12:36.575726 22542570456896 run_lib.py:133] step: 22950, training_loss: 2.77460e-02
I0208 15:12:54.193972 22542570456896 run_lib.py:133] step: 23000, training_loss: 3.18382e-02
I0208 15:12:54.351042 22542570456896 run_lib.py:146] step: 23000, eval_loss: 3.47946e-02
I0208 15:13:11.830851 22542570456896 run_lib.py:133] step: 23050, training_loss: 2.89908e-02
I0208 15:13:29.362677 22542570456896 run_lib.py:133] step: 23100, training_loss: 2.99187e-02
I0208 15:13:29.521503 22542570456896 run_lib.py:146] step: 23100, eval_loss: 2.38550e-02
I0208 15:13:46.991707 22542570456896 run_lib.py:133] step: 23150, training_loss: 2.55428e-02
I0208 15:14:04.398742 22542570456896 run_lib.py:133] step: 23200, training_loss: 3.25621e-02
I0208 15:14:04.553294 22542570456896 run_lib.py:146] step: 23200, eval_loss: 3.17509e-02
I0208 15:14:22.144445 22542570456896 run_lib.py:133] step: 23250, training_loss: 3.16325e-02
I0208 15:14:39.629834 22542570456896 run_lib.py:133] step: 23300, training_loss: 3.04177e-02
I0208 15:14:39.789541 22542570456896 run_lib.py:146] step: 23300, eval_loss: 2.86807e-02
I0208 15:14:57.222242 22542570456896 run_lib.py:133] step: 23350, training_loss: 2.29302e-02
I0208 15:15:14.769896 22542570456896 run_lib.py:133] step: 23400, training_loss: 3.62737e-02
I0208 15:15:14.927586 22542570456896 run_lib.py:146] step: 23400, eval_loss: 2.42799e-02
I0208 15:15:32.530191 22542570456896 run_lib.py:133] step: 23450, training_loss: 2.85509e-02
I0208 15:15:49.937042 22542570456896 run_lib.py:133] step: 23500, training_loss: 3.27615e-02
I0208 15:15:50.093399 22542570456896 run_lib.py:146] step: 23500, eval_loss: 4.25690e-02
I0208 15:16:07.684115 22542570456896 run_lib.py:133] step: 23550, training_loss: 2.65970e-02
I0208 15:16:25.116090 22542570456896 run_lib.py:133] step: 23600, training_loss: 3.01419e-02
I0208 15:16:25.269039 22542570456896 run_lib.py:146] step: 23600, eval_loss: 4.18397e-02
I0208 15:16:42.880300 22542570456896 run_lib.py:133] step: 23650, training_loss: 3.39347e-02
I0208 15:17:00.353933 22542570456896 run_lib.py:133] step: 23700, training_loss: 2.55353e-02
I0208 15:17:00.520522 22542570456896 run_lib.py:146] step: 23700, eval_loss: 2.95883e-02
I0208 15:17:18.020594 22542570456896 run_lib.py:133] step: 23750, training_loss: 2.52186e-02
I0208 15:17:35.651408 22542570456896 run_lib.py:133] step: 23800, training_loss: 3.28343e-02
I0208 15:17:35.819567 22542570456896 run_lib.py:146] step: 23800, eval_loss: 2.97682e-02
I0208 15:17:53.284145 22542570456896 run_lib.py:133] step: 23850, training_loss: 3.31481e-02
I0208 15:18:10.839505 22542570456896 run_lib.py:133] step: 23900, training_loss: 2.50686e-02
I0208 15:18:10.997268 22542570456896 run_lib.py:146] step: 23900, eval_loss: 2.84796e-02
I0208 15:18:28.424161 22542570456896 run_lib.py:133] step: 23950, training_loss: 3.17597e-02
I0208 15:18:45.844187 22542570456896 run_lib.py:133] step: 24000, training_loss: 3.38765e-02
I0208 15:18:46.005275 22542570456896 run_lib.py:146] step: 24000, eval_loss: 2.32446e-02
I0208 15:19:03.522325 22542570456896 run_lib.py:133] step: 24050, training_loss: 2.86347e-02
I0208 15:19:20.846199 22542570456896 run_lib.py:133] step: 24100, training_loss: 3.57401e-02
I0208 15:19:20.998601 22542570456896 run_lib.py:146] step: 24100, eval_loss: 2.58084e-02
I0208 15:19:38.344011 22542570456896 run_lib.py:133] step: 24150, training_loss: 3.62711e-02
I0208 15:19:55.930014 22542570456896 run_lib.py:133] step: 24200, training_loss: 3.81337e-02
I0208 15:19:56.087695 22542570456896 run_lib.py:146] step: 24200, eval_loss: 2.49476e-02
I0208 15:20:13.581757 22542570456896 run_lib.py:133] step: 24250, training_loss: 2.81595e-02
I0208 15:20:31.065679 22542570456896 run_lib.py:133] step: 24300, training_loss: 2.88878e-02
I0208 15:20:31.413191 22542570456896 run_lib.py:146] step: 24300, eval_loss: 3.07184e-02
I0208 15:20:48.854454 22542570456896 run_lib.py:133] step: 24350, training_loss: 3.12762e-02
I0208 15:21:06.264923 22542570456896 run_lib.py:133] step: 24400, training_loss: 3.72920e-02
I0208 15:21:06.421310 22542570456896 run_lib.py:146] step: 24400, eval_loss: 2.48740e-02
I0208 15:21:23.863526 22542570456896 run_lib.py:133] step: 24450, training_loss: 3.22523e-02
I0208 15:21:41.272103 22542570456896 run_lib.py:133] step: 24500, training_loss: 3.21592e-02
I0208 15:21:41.434293 22542570456896 run_lib.py:146] step: 24500, eval_loss: 2.70245e-02
I0208 15:21:59.013743 22542570456896 run_lib.py:133] step: 24550, training_loss: 3.65507e-02
I0208 15:22:16.634487 22542570456896 run_lib.py:133] step: 24600, training_loss: 2.71023e-02
I0208 15:22:16.789632 22542570456896 run_lib.py:146] step: 24600, eval_loss: 2.71485e-02
I0208 15:22:34.246750 22542570456896 run_lib.py:133] step: 24650, training_loss: 3.95792e-02
I0208 15:22:51.695281 22542570456896 run_lib.py:133] step: 24700, training_loss: 3.36147e-02
I0208 15:22:51.853154 22542570456896 run_lib.py:146] step: 24700, eval_loss: 3.25803e-02
I0208 15:23:09.379296 22542570456896 run_lib.py:133] step: 24750, training_loss: 3.05943e-02
I0208 15:23:26.850593 22542570456896 run_lib.py:133] step: 24800, training_loss: 2.30418e-02
I0208 15:23:27.034862 22542570456896 run_lib.py:146] step: 24800, eval_loss: 3.19123e-02
I0208 15:23:44.526832 22542570456896 run_lib.py:133] step: 24850, training_loss: 2.63630e-02
I0208 15:24:01.989738 22542570456896 run_lib.py:133] step: 24900, training_loss: 2.35304e-02
I0208 15:24:02.146676 22542570456896 run_lib.py:146] step: 24900, eval_loss: 2.61400e-02
I0208 15:24:19.763949 22542570456896 run_lib.py:133] step: 24950, training_loss: 2.61456e-02
I0208 15:24:37.200756 22542570456896 run_lib.py:133] step: 25000, training_loss: 3.67059e-02
I0208 15:24:37.356312 22542570456896 run_lib.py:146] step: 25000, eval_loss: 2.27567e-02
I0208 15:24:54.913589 22542570456896 run_lib.py:133] step: 25050, training_loss: 3.28899e-02
I0208 15:25:12.377949 22542570456896 run_lib.py:133] step: 25100, training_loss: 2.94376e-02
I0208 15:25:12.541512 22542570456896 run_lib.py:146] step: 25100, eval_loss: 2.51337e-02
I0208 15:25:30.163776 22542570456896 run_lib.py:133] step: 25150, training_loss: 3.21594e-02
I0208 15:25:47.635005 22542570456896 run_lib.py:133] step: 25200, training_loss: 3.23395e-02
I0208 15:25:47.793507 22542570456896 run_lib.py:146] step: 25200, eval_loss: 3.00467e-02
I0208 15:26:05.202180 22542570456896 run_lib.py:133] step: 25250, training_loss: 3.44201e-02
I0208 15:26:22.810599 22542570456896 run_lib.py:133] step: 25300, training_loss: 3.06354e-02
I0208 15:26:22.966664 22542570456896 run_lib.py:146] step: 25300, eval_loss: 3.70064e-02
I0208 15:26:40.401133 22542570456896 run_lib.py:133] step: 25350, training_loss: 3.11030e-02
I0208 15:26:58.039640 22542570456896 run_lib.py:133] step: 25400, training_loss: 3.22902e-02
I0208 15:26:58.195204 22542570456896 run_lib.py:146] step: 25400, eval_loss: 3.01637e-02
I0208 15:27:15.660377 22542570456896 run_lib.py:133] step: 25450, training_loss: 2.69729e-02
I0208 15:27:33.079782 22542570456896 run_lib.py:133] step: 25500, training_loss: 3.00287e-02
I0208 15:27:33.233031 22542570456896 run_lib.py:146] step: 25500, eval_loss: 2.81802e-02
I0208 15:27:50.829901 22542570456896 run_lib.py:133] step: 25550, training_loss: 3.23730e-02
I0208 15:28:08.255593 22542570456896 run_lib.py:133] step: 25600, training_loss: 2.91895e-02
I0208 15:28:08.412600 22542570456896 run_lib.py:146] step: 25600, eval_loss: 3.01764e-02
I0208 15:28:25.898590 22542570456896 run_lib.py:133] step: 25650, training_loss: 2.15557e-02
I0208 15:28:43.369717 22542570456896 run_lib.py:133] step: 25700, training_loss: 3.03931e-02
I0208 15:28:43.529356 22542570456896 run_lib.py:146] step: 25700, eval_loss: 3.37248e-02
I0208 15:29:01.143617 22542570456896 run_lib.py:133] step: 25750, training_loss: 2.27053e-02
I0208 15:29:18.555466 22542570456896 run_lib.py:133] step: 25800, training_loss: 2.90135e-02
I0208 15:29:18.713415 22542570456896 run_lib.py:146] step: 25800, eval_loss: 3.04806e-02
I0208 15:29:36.202800 22542570456896 run_lib.py:133] step: 25850, training_loss: 2.16911e-02
I0208 15:29:53.663283 22542570456896 run_lib.py:133] step: 25900, training_loss: 3.29151e-02
I0208 15:29:53.826292 22542570456896 run_lib.py:146] step: 25900, eval_loss: 2.50791e-02
I0208 15:30:11.325109 22542570456896 run_lib.py:133] step: 25950, training_loss: 2.93009e-02
I0208 15:30:28.757193 22542570456896 run_lib.py:133] step: 26000, training_loss: 3.33437e-02
I0208 15:30:28.908782 22542570456896 run_lib.py:146] step: 26000, eval_loss: 2.81765e-02
I0208 15:30:46.511577 22542570456896 run_lib.py:133] step: 26050, training_loss: 2.59980e-02
I0208 15:31:04.004671 22542570456896 run_lib.py:133] step: 26100, training_loss: 3.15520e-02
I0208 15:31:04.160348 22542570456896 run_lib.py:146] step: 26100, eval_loss: 3.36560e-02
I0208 15:31:21.589295 22542570456896 run_lib.py:133] step: 26150, training_loss: 2.75444e-02
I0208 15:31:39.042655 22542570456896 run_lib.py:133] step: 26200, training_loss: 2.38535e-02
I0208 15:31:39.217290 22542570456896 run_lib.py:146] step: 26200, eval_loss: 3.04231e-02
I0208 15:31:56.843868 22542570456896 run_lib.py:133] step: 26250, training_loss: 2.96777e-02
I0208 15:32:14.259496 22542570456896 run_lib.py:133] step: 26300, training_loss: 3.08194e-02
I0208 15:32:14.415782 22542570456896 run_lib.py:146] step: 26300, eval_loss: 2.47012e-02
I0208 15:32:32.041315 22542570456896 run_lib.py:133] step: 26350, training_loss: 3.58800e-02
I0208 15:32:49.488315 22542570456896 run_lib.py:133] step: 26400, training_loss: 2.75130e-02
I0208 15:32:49.644306 22542570456896 run_lib.py:146] step: 26400, eval_loss: 2.66932e-02
I0208 15:33:07.204662 22542570456896 run_lib.py:133] step: 26450, training_loss: 3.27714e-02
I0208 15:33:24.648460 22542570456896 run_lib.py:133] step: 26500, training_loss: 3.24519e-02
I0208 15:33:24.811374 22542570456896 run_lib.py:146] step: 26500, eval_loss: 2.85256e-02
I0208 15:33:42.450710 22542570456896 run_lib.py:133] step: 26550, training_loss: 4.14745e-02
I0208 15:33:59.913675 22542570456896 run_lib.py:133] step: 26600, training_loss: 3.77560e-02
I0208 15:34:00.068625 22542570456896 run_lib.py:146] step: 26600, eval_loss: 2.81970e-02
I0208 15:34:17.475382 22542570456896 run_lib.py:133] step: 26650, training_loss: 3.04252e-02
I0208 15:34:35.055822 22542570456896 run_lib.py:133] step: 26700, training_loss: 2.31290e-02
I0208 15:34:35.219571 22542570456896 run_lib.py:146] step: 26700, eval_loss: 3.03143e-02
I0208 15:34:52.679010 22542570456896 run_lib.py:133] step: 26750, training_loss: 3.43619e-02
I0208 15:35:10.162100 22542570456896 run_lib.py:133] step: 26800, training_loss: 3.29544e-02
I0208 15:35:10.319168 22542570456896 run_lib.py:146] step: 26800, eval_loss: 2.57550e-02
I0208 15:35:27.956398 22542570456896 run_lib.py:133] step: 26850, training_loss: 2.75917e-02
I0208 15:35:45.518278 22542570456896 run_lib.py:133] step: 26900, training_loss: 2.93295e-02
I0208 15:35:45.675343 22542570456896 run_lib.py:146] step: 26900, eval_loss: 2.31050e-02
I0208 15:36:03.078613 22542570456896 run_lib.py:133] step: 26950, training_loss: 2.63123e-02
I0208 15:36:20.485157 22542570456896 run_lib.py:133] step: 27000, training_loss: 3.37976e-02
I0208 15:36:20.647501 22542570456896 run_lib.py:146] step: 27000, eval_loss: 3.07912e-02
I0208 15:36:38.168459 22542570456896 run_lib.py:133] step: 27050, training_loss: 3.36096e-02
I0208 15:36:55.796619 22542570456896 run_lib.py:133] step: 27100, training_loss: 2.62752e-02
I0208 15:36:55.956235 22542570456896 run_lib.py:146] step: 27100, eval_loss: 3.93643e-02
I0208 15:37:13.423443 22542570456896 run_lib.py:133] step: 27150, training_loss: 3.78290e-02
I0208 15:37:30.783390 22542570456896 run_lib.py:133] step: 27200, training_loss: 3.06904e-02
I0208 15:37:30.939313 22542570456896 run_lib.py:146] step: 27200, eval_loss: 2.93148e-02
I0208 15:37:48.353170 22542570456896 run_lib.py:133] step: 27250, training_loss: 3.25451e-02
I0208 15:38:06.006009 22542570456896 run_lib.py:133] step: 27300, training_loss: 2.86083e-02
I0208 15:38:06.162593 22542570456896 run_lib.py:146] step: 27300, eval_loss: 2.65244e-02
I0208 15:38:23.635888 22542570456896 run_lib.py:133] step: 27350, training_loss: 2.38395e-02
I0208 15:38:41.164707 22542570456896 run_lib.py:133] step: 27400, training_loss: 3.01688e-02
I0208 15:38:41.316084 22542570456896 run_lib.py:146] step: 27400, eval_loss: 3.14703e-02
I0208 15:38:58.740645 22542570456896 run_lib.py:133] step: 27450, training_loss: 2.77561e-02
I0208 15:39:16.197315 22542570456896 run_lib.py:133] step: 27500, training_loss: 2.82483e-02
I0208 15:39:16.353271 22542570456896 run_lib.py:146] step: 27500, eval_loss: 3.00174e-02
I0208 15:39:33.881214 22542570456896 run_lib.py:133] step: 27550, training_loss: 2.52098e-02
I0208 15:39:51.400464 22542570456896 run_lib.py:133] step: 27600, training_loss: 2.88691e-02
I0208 15:39:51.579200 22542570456896 run_lib.py:146] step: 27600, eval_loss: 2.64141e-02
I0208 15:40:09.038689 22542570456896 run_lib.py:133] step: 27650, training_loss: 2.55589e-02
I0208 15:40:26.494461 22542570456896 run_lib.py:133] step: 27700, training_loss: 2.88623e-02
I0208 15:40:26.651538 22542570456896 run_lib.py:146] step: 27700, eval_loss: 2.33608e-02
I0208 15:40:44.279932 22542570456896 run_lib.py:133] step: 27750, training_loss: 3.58486e-02
I0208 15:41:01.656949 22542570456896 run_lib.py:133] step: 27800, training_loss: 3.13493e-02
I0208 15:41:01.817280 22542570456896 run_lib.py:146] step: 27800, eval_loss: 2.88136e-02
I0208 15:41:19.375892 22542570456896 run_lib.py:133] step: 27850, training_loss: 3.13343e-02
I0208 15:41:36.863447 22542570456896 run_lib.py:133] step: 27900, training_loss: 2.12116e-02
I0208 15:41:37.022532 22542570456896 run_lib.py:146] step: 27900, eval_loss: 2.48081e-02
I0208 15:41:54.611753 22542570456896 run_lib.py:133] step: 27950, training_loss: 2.63777e-02
I0208 15:42:12.012966 22542570456896 run_lib.py:133] step: 28000, training_loss: 2.71649e-02
I0208 15:42:12.170334 22542570456896 run_lib.py:146] step: 28000, eval_loss: 3.58693e-02
I0208 15:42:29.602991 22542570456896 run_lib.py:133] step: 28050, training_loss: 2.99246e-02
I0208 15:42:47.234081 22542570456896 run_lib.py:133] step: 28100, training_loss: 2.88588e-02
I0208 15:42:47.394568 22542570456896 run_lib.py:146] step: 28100, eval_loss: 2.48011e-02
I0208 15:43:05.009779 22542570456896 run_lib.py:133] step: 28150, training_loss: 2.86612e-02
I0208 15:43:22.647291 22542570456896 run_lib.py:133] step: 28200, training_loss: 3.36608e-02
I0208 15:43:22.809554 22542570456896 run_lib.py:146] step: 28200, eval_loss: 3.12458e-02
I0208 15:43:40.219210 22542570456896 run_lib.py:133] step: 28250, training_loss: 2.51112e-02
I0208 15:43:57.637982 22542570456896 run_lib.py:133] step: 28300, training_loss: 3.78130e-02
I0208 15:43:57.793356 22542570456896 run_lib.py:146] step: 28300, eval_loss: 3.72979e-02
I0208 15:44:15.336166 22542570456896 run_lib.py:133] step: 28350, training_loss: 3.15875e-02
I0208 15:44:32.814666 22542570456896 run_lib.py:133] step: 28400, training_loss: 2.76687e-02
I0208 15:44:32.971596 22542570456896 run_lib.py:146] step: 28400, eval_loss: 3.25419e-02
I0208 15:44:50.450781 22542570456896 run_lib.py:133] step: 28450, training_loss: 2.96072e-02
I0208 15:45:08.074299 22542570456896 run_lib.py:133] step: 28500, training_loss: 3.61224e-02
I0208 15:45:08.230332 22542570456896 run_lib.py:146] step: 28500, eval_loss: 3.28382e-02
I0208 15:45:25.654981 22542570456896 run_lib.py:133] step: 28550, training_loss: 2.53117e-02
I0208 15:45:43.083636 22542570456896 run_lib.py:133] step: 28600, training_loss: 2.89165e-02
I0208 15:45:43.239461 22542570456896 run_lib.py:146] step: 28600, eval_loss: 3.09778e-02
I0208 15:46:00.734614 22542570456896 run_lib.py:133] step: 28650, training_loss: 2.44965e-02
I0208 15:46:18.226662 22542570456896 run_lib.py:133] step: 28700, training_loss: 2.62838e-02
I0208 15:46:18.398448 22542570456896 run_lib.py:146] step: 28700, eval_loss: 2.50832e-02
I0208 15:46:35.860347 22542570456896 run_lib.py:133] step: 28750, training_loss: 2.55960e-02
I0208 15:46:53.301670 22542570456896 run_lib.py:133] step: 28800, training_loss: 2.97785e-02
I0208 15:46:53.457064 22542570456896 run_lib.py:146] step: 28800, eval_loss: 2.85989e-02
I0208 15:47:11.069962 22542570456896 run_lib.py:133] step: 28850, training_loss: 2.69075e-02
I0208 15:47:28.625178 22542570456896 run_lib.py:133] step: 28900, training_loss: 3.55560e-02
I0208 15:47:28.782394 22542570456896 run_lib.py:146] step: 28900, eval_loss: 3.30081e-02
I0208 15:47:46.185022 22542570456896 run_lib.py:133] step: 28950, training_loss: 3.59485e-02
I0208 15:48:03.609763 22542570456896 run_lib.py:133] step: 29000, training_loss: 3.00317e-02
I0208 15:48:03.787219 22542570456896 run_lib.py:146] step: 29000, eval_loss: 3.49301e-02
I0208 15:48:21.408656 22542570456896 run_lib.py:133] step: 29050, training_loss: 3.00463e-02
I0208 15:48:38.890483 22542570456896 run_lib.py:133] step: 29100, training_loss: 2.69116e-02
I0208 15:48:39.046613 22542570456896 run_lib.py:146] step: 29100, eval_loss: 3.39207e-02
I0208 15:48:56.617225 22542570456896 run_lib.py:133] step: 29150, training_loss: 3.11703e-02
I0208 15:49:14.027994 22542570456896 run_lib.py:133] step: 29200, training_loss: 2.94404e-02
I0208 15:49:14.183998 22542570456896 run_lib.py:146] step: 29200, eval_loss: 2.76939e-02
I0208 15:49:31.750484 22542570456896 run_lib.py:133] step: 29250, training_loss: 2.77097e-02
I0208 15:49:49.227998 22542570456896 run_lib.py:133] step: 29300, training_loss: 2.85423e-02
I0208 15:49:49.390796 22542570456896 run_lib.py:146] step: 29300, eval_loss: 3.04406e-02
I0208 15:50:07.043895 22542570456896 run_lib.py:133] step: 29350, training_loss: 2.96219e-02
I0208 15:50:24.433889 22542570456896 run_lib.py:133] step: 29400, training_loss: 2.51166e-02
I0208 15:50:24.587450 22542570456896 run_lib.py:146] step: 29400, eval_loss: 3.06143e-02
I0208 15:50:42.015159 22542570456896 run_lib.py:133] step: 29450, training_loss: 2.90938e-02
I0208 15:50:59.563158 22542570456896 run_lib.py:133] step: 29500, training_loss: 2.98075e-02
I0208 15:50:59.722719 22542570456896 run_lib.py:146] step: 29500, eval_loss: 2.66095e-02
I0208 15:51:17.136347 22542570456896 run_lib.py:133] step: 29550, training_loss: 3.26202e-02
I0208 15:51:34.615474 22542570456896 run_lib.py:133] step: 29600, training_loss: 2.76220e-02
I0208 15:51:34.790295 22542570456896 run_lib.py:146] step: 29600, eval_loss: 2.96312e-02
I0208 15:51:52.409156 22542570456896 run_lib.py:133] step: 29650, training_loss: 2.60052e-02
I0208 15:52:09.852682 22542570456896 run_lib.py:133] step: 29700, training_loss: 3.37372e-02
I0208 15:52:10.008965 22542570456896 run_lib.py:146] step: 29700, eval_loss: 2.66346e-02
I0208 15:52:27.569638 22542570456896 run_lib.py:133] step: 29750, training_loss: 3.01749e-02
I0208 15:52:44.981097 22542570456896 run_lib.py:133] step: 29800, training_loss: 3.51526e-02
I0208 15:52:45.134452 22542570456896 run_lib.py:146] step: 29800, eval_loss: 3.00524e-02
I0208 15:53:02.565310 22542570456896 run_lib.py:133] step: 29850, training_loss: 2.94810e-02
I0208 15:53:20.164740 22542570456896 run_lib.py:133] step: 29900, training_loss: 2.82044e-02
I0208 15:53:20.334506 22542570456896 run_lib.py:146] step: 29900, eval_loss: 3.73063e-02
I0208 15:53:37.764287 22542570456896 run_lib.py:133] step: 29950, training_loss: 2.72480e-02
I0208 15:53:55.179445 22542570456896 run_lib.py:133] step: 30000, training_loss: 3.69629e-02
I0208 15:53:55.968434 22542570456896 run_lib.py:146] step: 30000, eval_loss: 2.90428e-02
I0208 15:54:16.001790 22542570456896 run_lib.py:133] step: 30050, training_loss: 3.03554e-02
I0208 15:54:33.380654 22542570456896 run_lib.py:133] step: 30100, training_loss: 3.38984e-02
I0208 15:54:33.540443 22542570456896 run_lib.py:146] step: 30100, eval_loss: 2.69935e-02
I0208 15:54:51.165360 22542570456896 run_lib.py:133] step: 30150, training_loss: 2.64793e-02
I0208 15:55:08.607359 22542570456896 run_lib.py:133] step: 30200, training_loss: 2.81392e-02
I0208 15:55:08.764172 22542570456896 run_lib.py:146] step: 30200, eval_loss: 2.64137e-02
I0208 15:55:26.325156 22542570456896 run_lib.py:133] step: 30250, training_loss: 3.20796e-02
I0208 15:55:43.747573 22542570456896 run_lib.py:133] step: 30300, training_loss: 3.30909e-02
I0208 15:55:43.910109 22542570456896 run_lib.py:146] step: 30300, eval_loss: 2.27115e-02
I0208 15:56:01.338766 22542570456896 run_lib.py:133] step: 30350, training_loss: 3.11313e-02
I0208 15:56:18.772870 22542570456896 run_lib.py:133] step: 30400, training_loss: 2.92023e-02
I0208 15:56:18.931409 22542570456896 run_lib.py:146] step: 30400, eval_loss: 4.31697e-02
I0208 15:56:36.553060 22542570456896 run_lib.py:133] step: 30450, training_loss: 2.70602e-02
I0208 15:56:54.048341 22542570456896 run_lib.py:133] step: 30500, training_loss: 3.07054e-02
I0208 15:56:54.207249 22542570456896 run_lib.py:146] step: 30500, eval_loss: 3.14841e-02
I0208 15:57:11.629749 22542570456896 run_lib.py:133] step: 30550, training_loss: 2.69203e-02
I0208 15:57:29.029175 22542570456896 run_lib.py:133] step: 30600, training_loss: 3.21366e-02
I0208 15:57:29.185319 22542570456896 run_lib.py:146] step: 30600, eval_loss: 2.56048e-02
I0208 15:57:46.726839 22542570456896 run_lib.py:133] step: 30650, training_loss: 2.70543e-02
I0208 15:58:04.205425 22542570456896 run_lib.py:133] step: 30700, training_loss: 2.64293e-02
I0208 15:58:04.363889 22542570456896 run_lib.py:146] step: 30700, eval_loss: 2.71918e-02
I0208 15:58:21.953655 22542570456896 run_lib.py:133] step: 30750, training_loss: 3.00420e-02
I0208 15:58:39.390931 22542570456896 run_lib.py:133] step: 30800, training_loss: 3.15536e-02
I0208 15:58:39.543095 22542570456896 run_lib.py:146] step: 30800, eval_loss: 3.15065e-02
I0208 15:58:57.113422 22542570456896 run_lib.py:133] step: 30850, training_loss: 2.97973e-02
I0208 15:59:14.545617 22542570456896 run_lib.py:133] step: 30900, training_loss: 2.53820e-02
I0208 15:59:14.709349 22542570456896 run_lib.py:146] step: 30900, eval_loss: 3.65838e-02
I0208 15:59:32.243344 22542570456896 run_lib.py:133] step: 30950, training_loss: 3.38389e-02
I0208 15:59:49.723092 22542570456896 run_lib.py:133] step: 31000, training_loss: 2.68383e-02
I0208 15:59:49.900017 22542570456896 run_lib.py:146] step: 31000, eval_loss: 3.24275e-02
I0208 16:00:07.389787 22542570456896 run_lib.py:133] step: 31050, training_loss: 3.18028e-02
I0208 16:00:24.964326 22542570456896 run_lib.py:133] step: 31100, training_loss: 2.55865e-02
I0208 16:00:25.120457 22542570456896 run_lib.py:146] step: 31100, eval_loss: 3.15488e-02
I0208 16:00:42.542945 22542570456896 run_lib.py:133] step: 31150, training_loss: 2.21920e-02
I0208 16:00:59.994242 22542570456896 run_lib.py:133] step: 31200, training_loss: 2.70051e-02
I0208 16:01:00.148234 22542570456896 run_lib.py:146] step: 31200, eval_loss: 2.62016e-02
I0208 16:01:17.772827 22542570456896 run_lib.py:133] step: 31250, training_loss: 2.81847e-02
I0208 16:01:35.436617 22542570456896 run_lib.py:133] step: 31300, training_loss: 3.76280e-02
I0208 16:01:35.593464 22542570456896 run_lib.py:146] step: 31300, eval_loss: 2.74812e-02
I0208 16:01:53.028430 22542570456896 run_lib.py:133] step: 31350, training_loss: 2.98136e-02
I0208 16:02:10.463107 22542570456896 run_lib.py:133] step: 31400, training_loss: 3.40660e-02
I0208 16:02:10.615579 22542570456896 run_lib.py:146] step: 31400, eval_loss: 2.61180e-02
I0208 16:02:28.046247 22542570456896 run_lib.py:133] step: 31450, training_loss: 2.80192e-02
I0208 16:02:45.607055 22542570456896 run_lib.py:133] step: 31500, training_loss: 4.06449e-02
I0208 16:02:45.767357 22542570456896 run_lib.py:146] step: 31500, eval_loss: 2.60821e-02
I0208 16:03:03.203248 22542570456896 run_lib.py:133] step: 31550, training_loss: 2.22002e-02
I0208 16:03:20.675278 22542570456896 run_lib.py:133] step: 31600, training_loss: 2.83209e-02
I0208 16:03:20.832598 22542570456896 run_lib.py:146] step: 31600, eval_loss: 3.13783e-02
I0208 16:03:38.272849 22542570456896 run_lib.py:133] step: 31650, training_loss: 3.86373e-02
I0208 16:03:55.833278 22542570456896 run_lib.py:133] step: 31700, training_loss: 3.67990e-02
I0208 16:03:55.988296 22542570456896 run_lib.py:146] step: 31700, eval_loss: 3.15545e-02
I0208 16:04:13.407996 22542570456896 run_lib.py:133] step: 31750, training_loss: 3.22890e-02
I0208 16:04:30.933374 22542570456896 run_lib.py:133] step: 31800, training_loss: 3.15190e-02
I0208 16:04:31.089525 22542570456896 run_lib.py:146] step: 31800, eval_loss: 3.03668e-02
I0208 16:04:48.496529 22542570456896 run_lib.py:133] step: 31850, training_loss: 3.05993e-02
I0208 16:05:05.908691 22542570456896 run_lib.py:133] step: 31900, training_loss: 2.80356e-02
I0208 16:05:06.077831 22542570456896 run_lib.py:146] step: 31900, eval_loss: 3.01968e-02
I0208 16:05:23.812052 22542570456896 run_lib.py:133] step: 31950, training_loss: 2.51655e-02
I0208 16:05:41.268343 22542570456896 run_lib.py:133] step: 32000, training_loss: 3.39533e-02
I0208 16:05:41.435088 22542570456896 run_lib.py:146] step: 32000, eval_loss: 2.69654e-02
I0208 16:05:58.865404 22542570456896 run_lib.py:133] step: 32050, training_loss: 2.18431e-02
I0208 16:06:16.342502 22542570456896 run_lib.py:133] step: 32100, training_loss: 3.19435e-02
I0208 16:06:16.498414 22542570456896 run_lib.py:146] step: 32100, eval_loss: 2.95402e-02
I0208 16:06:34.138972 22542570456896 run_lib.py:133] step: 32150, training_loss: 3.27887e-02
I0208 16:06:51.559368 22542570456896 run_lib.py:133] step: 32200, training_loss: 3.23066e-02
I0208 16:06:51.715075 22542570456896 run_lib.py:146] step: 32200, eval_loss: 3.11115e-02
I0208 16:07:09.275649 22542570456896 run_lib.py:133] step: 32250, training_loss: 3.13788e-02
I0208 16:07:26.692881 22542570456896 run_lib.py:133] step: 32300, training_loss: 2.72891e-02
I0208 16:07:26.845547 22542570456896 run_lib.py:146] step: 32300, eval_loss: 4.07027e-02
I0208 16:07:44.448988 22542570456896 run_lib.py:133] step: 32350, training_loss: 3.66457e-02
I0208 16:08:01.926106 22542570456896 run_lib.py:133] step: 32400, training_loss: 2.55456e-02
I0208 16:08:02.085220 22542570456896 run_lib.py:146] step: 32400, eval_loss: 2.94043e-02
I0208 16:08:19.466991 22542570456896 run_lib.py:133] step: 32450, training_loss: 2.98899e-02
I0208 16:08:37.060307 22542570456896 run_lib.py:133] step: 32500, training_loss: 2.16527e-02
I0208 16:08:37.217441 22542570456896 run_lib.py:146] step: 32500, eval_loss: 2.83951e-02
I0208 16:08:54.623354 22542570456896 run_lib.py:133] step: 32550, training_loss: 2.77461e-02
I0208 16:09:12.240973 22542570456896 run_lib.py:133] step: 32600, training_loss: 2.87732e-02
I0208 16:09:12.400204 22542570456896 run_lib.py:146] step: 32600, eval_loss: 2.89496e-02
I0208 16:09:29.875762 22542570456896 run_lib.py:133] step: 32650, training_loss: 2.31998e-02
I0208 16:09:47.314744 22542570456896 run_lib.py:133] step: 32700, training_loss: 2.80020e-02
I0208 16:09:47.475378 22542570456896 run_lib.py:146] step: 32700, eval_loss: 3.58286e-02
I0208 16:10:05.047100 22542570456896 run_lib.py:133] step: 32750, training_loss: 3.25443e-02
I0208 16:10:22.489609 22542570456896 run_lib.py:133] step: 32800, training_loss: 2.90439e-02
I0208 16:10:22.646653 22542570456896 run_lib.py:146] step: 32800, eval_loss: 2.87022e-02
I0208 16:10:40.071143 22542570456896 run_lib.py:133] step: 32850, training_loss: 2.53804e-02
I0208 16:10:57.647525 22542570456896 run_lib.py:133] step: 32900, training_loss: 3.39702e-02
I0208 16:10:57.821388 22542570456896 run_lib.py:146] step: 32900, eval_loss: 2.99263e-02
I0208 16:11:15.271112 22542570456896 run_lib.py:133] step: 32950, training_loss: 3.41039e-02
I0208 16:11:32.719780 22542570456896 run_lib.py:133] step: 33000, training_loss: 2.57200e-02
I0208 16:11:32.876631 22542570456896 run_lib.py:146] step: 33000, eval_loss: 3.10776e-02
I0208 16:11:50.405102 22542570456896 run_lib.py:133] step: 33050, training_loss: 3.55991e-02
I0208 16:12:07.829420 22542570456896 run_lib.py:133] step: 33100, training_loss: 2.82597e-02
I0208 16:12:07.984348 22542570456896 run_lib.py:146] step: 33100, eval_loss: 3.36682e-02
I0208 16:12:25.401561 22542570456896 run_lib.py:133] step: 33150, training_loss: 2.46755e-02
I0208 16:12:42.919434 22542570456896 run_lib.py:133] step: 33200, training_loss: 2.31147e-02
I0208 16:12:43.083226 22542570456896 run_lib.py:146] step: 33200, eval_loss: 3.16186e-02
I0208 16:13:00.763269 22542570456896 run_lib.py:133] step: 33250, training_loss: 4.02798e-02
I0208 16:13:18.281602 22542570456896 run_lib.py:133] step: 33300, training_loss: 2.94270e-02
I0208 16:13:18.440084 22542570456896 run_lib.py:146] step: 33300, eval_loss: 3.32293e-02
I0208 16:13:35.963616 22542570456896 run_lib.py:133] step: 33350, training_loss: 2.69882e-02
I0208 16:13:53.373895 22542570456896 run_lib.py:133] step: 33400, training_loss: 2.80346e-02
I0208 16:13:53.544348 22542570456896 run_lib.py:146] step: 33400, eval_loss: 3.18169e-02
I0208 16:14:11.222057 22542570456896 run_lib.py:133] step: 33450, training_loss: 3.02148e-02
I0208 16:14:28.636515 22542570456896 run_lib.py:133] step: 33500, training_loss: 3.18774e-02
I0208 16:14:28.793525 22542570456896 run_lib.py:146] step: 33500, eval_loss: 3.47729e-02
I0208 16:14:46.422998 22542570456896 run_lib.py:133] step: 33550, training_loss: 2.77405e-02
I0208 16:15:03.891064 22542570456896 run_lib.py:133] step: 33600, training_loss: 3.18676e-02
I0208 16:15:04.047347 22542570456896 run_lib.py:146] step: 33600, eval_loss: 2.65525e-02
I0208 16:15:21.581227 22542570456896 run_lib.py:133] step: 33650, training_loss: 3.89311e-02
I0208 16:15:39.085012 22542570456896 run_lib.py:133] step: 33700, training_loss: 2.46809e-02
I0208 16:15:39.240628 22542570456896 run_lib.py:146] step: 33700, eval_loss: 3.19422e-02
I0208 16:15:56.901383 22542570456896 run_lib.py:133] step: 33750, training_loss: 2.36064e-02
I0208 16:16:14.305170 22542570456896 run_lib.py:133] step: 33800, training_loss: 1.88582e-02
I0208 16:16:14.472051 22542570456896 run_lib.py:146] step: 33800, eval_loss: 2.83224e-02
I0208 16:16:31.892186 22542570456896 run_lib.py:133] step: 33850, training_loss: 3.20373e-02
I0208 16:16:49.439507 22542570456896 run_lib.py:133] step: 33900, training_loss: 3.04224e-02
I0208 16:16:49.595391 22542570456896 run_lib.py:146] step: 33900, eval_loss: 3.05668e-02
I0208 16:17:07.063930 22542570456896 run_lib.py:133] step: 33950, training_loss: 3.52502e-02
I0208 16:17:24.535673 22542570456896 run_lib.py:133] step: 34000, training_loss: 3.12602e-02
I0208 16:17:24.700725 22542570456896 run_lib.py:146] step: 34000, eval_loss: 3.45233e-02
I0208 16:17:42.340585 22542570456896 run_lib.py:133] step: 34050, training_loss: 2.97324e-02
I0208 16:17:59.755238 22542570456896 run_lib.py:133] step: 34100, training_loss: 3.00930e-02
I0208 16:17:59.913525 22542570456896 run_lib.py:146] step: 34100, eval_loss: 2.26070e-02
I0208 16:18:17.479418 22542570456896 run_lib.py:133] step: 34150, training_loss: 2.73851e-02
I0208 16:18:34.904406 22542570456896 run_lib.py:133] step: 34200, training_loss: 3.17385e-02
I0208 16:18:35.066496 22542570456896 run_lib.py:146] step: 34200, eval_loss: 2.74246e-02
I0208 16:18:52.544998 22542570456896 run_lib.py:133] step: 34250, training_loss: 3.28441e-02
I0208 16:19:10.138242 22542570456896 run_lib.py:133] step: 34300, training_loss: 3.47814e-02
I0208 16:19:10.303263 22542570456896 run_lib.py:146] step: 34300, eval_loss: 2.71983e-02
I0208 16:19:27.725840 22542570456896 run_lib.py:133] step: 34350, training_loss: 2.68201e-02
I0208 16:19:45.114259 22542570456896 run_lib.py:133] step: 34400, training_loss: 2.43146e-02
I0208 16:19:45.278211 22542570456896 run_lib.py:146] step: 34400, eval_loss: 3.07703e-02
I0208 16:20:02.709569 22542570456896 run_lib.py:133] step: 34450, training_loss: 2.77821e-02
I0208 16:20:20.280740 22542570456896 run_lib.py:133] step: 34500, training_loss: 2.96053e-02
I0208 16:20:20.438303 22542570456896 run_lib.py:146] step: 34500, eval_loss: 3.15290e-02
I0208 16:20:37.921934 22542570456896 run_lib.py:133] step: 34550, training_loss: 2.56486e-02
I0208 16:20:55.449046 22542570456896 run_lib.py:133] step: 34600, training_loss: 2.84427e-02
I0208 16:20:55.602066 22542570456896 run_lib.py:146] step: 34600, eval_loss: 3.43034e-02
I0208 16:21:13.033667 22542570456896 run_lib.py:133] step: 34650, training_loss: 4.03888e-02
I0208 16:21:30.445043 22542570456896 run_lib.py:133] step: 34700, training_loss: 3.29944e-02
I0208 16:21:30.601157 22542570456896 run_lib.py:146] step: 34700, eval_loss: 2.84120e-02
I0208 16:21:48.160177 22542570456896 run_lib.py:133] step: 34750, training_loss: 2.71703e-02
I0208 16:22:05.646664 22542570456896 run_lib.py:133] step: 34800, training_loss: 3.12255e-02
I0208 16:22:05.829439 22542570456896 run_lib.py:146] step: 34800, eval_loss: 2.88664e-02
I0208 16:22:23.271340 22542570456896 run_lib.py:133] step: 34850, training_loss: 3.02920e-02
I0208 16:22:40.723934 22542570456896 run_lib.py:133] step: 34900, training_loss: 2.68384e-02
I0208 16:22:40.880542 22542570456896 run_lib.py:146] step: 34900, eval_loss: 2.69233e-02
I0208 16:22:58.476676 22542570456896 run_lib.py:133] step: 34950, training_loss: 2.78817e-02
I0208 16:23:15.896564 22542570456896 run_lib.py:133] step: 35000, training_loss: 2.45968e-02
I0208 16:23:16.058388 22542570456896 run_lib.py:146] step: 35000, eval_loss: 2.33609e-02
I0208 16:23:33.648923 22542570456896 run_lib.py:133] step: 35050, training_loss: 2.83426e-02
I0208 16:23:51.113559 22542570456896 run_lib.py:133] step: 35100, training_loss: 2.78430e-02
I0208 16:23:51.268539 22542570456896 run_lib.py:146] step: 35100, eval_loss: 2.89564e-02
I0208 16:24:09.036950 22542570456896 run_lib.py:133] step: 35150, training_loss: 3.85954e-02
I0208 16:24:26.423041 22542570456896 run_lib.py:133] step: 35200, training_loss: 2.58806e-02
I0208 16:24:26.586141 22542570456896 run_lib.py:146] step: 35200, eval_loss: 3.37912e-02
I0208 16:24:43.978068 22542570456896 run_lib.py:133] step: 35250, training_loss: 3.61131e-02
I0208 16:25:01.560308 22542570456896 run_lib.py:133] step: 35300, training_loss: 2.55628e-02
I0208 16:25:01.718501 22542570456896 run_lib.py:146] step: 35300, eval_loss: 3.09666e-02
I0208 16:25:19.159715 22542570456896 run_lib.py:133] step: 35350, training_loss: 2.69287e-02
I0208 16:25:36.761675 22542570456896 run_lib.py:133] step: 35400, training_loss: 3.15709e-02
I0208 16:25:36.919093 22542570456896 run_lib.py:146] step: 35400, eval_loss: 3.04502e-02
I0208 16:25:54.420347 22542570456896 run_lib.py:133] step: 35450, training_loss: 2.61565e-02
I0208 16:26:11.848973 22542570456896 run_lib.py:133] step: 35500, training_loss: 2.94617e-02
I0208 16:26:12.012347 22542570456896 run_lib.py:146] step: 35500, eval_loss: 2.72353e-02
I0208 16:26:29.629169 22542570456896 run_lib.py:133] step: 35550, training_loss: 3.15015e-02
I0208 16:26:47.067112 22542570456896 run_lib.py:133] step: 35600, training_loss: 3.17842e-02
I0208 16:26:47.220429 22542570456896 run_lib.py:146] step: 35600, eval_loss: 3.05059e-02
I0208 16:27:04.684100 22542570456896 run_lib.py:133] step: 35650, training_loss: 2.78765e-02
I0208 16:27:22.285778 22542570456896 run_lib.py:133] step: 35700, training_loss: 3.17688e-02
I0208 16:27:22.446292 22542570456896 run_lib.py:146] step: 35700, eval_loss: 2.67462e-02
I0208 16:27:39.837220 22542570456896 run_lib.py:133] step: 35750, training_loss: 3.03490e-02
I0208 16:27:57.166247 22542570456896 run_lib.py:133] step: 35800, training_loss: 3.03251e-02
I0208 16:27:57.476161 22542570456896 run_lib.py:146] step: 35800, eval_loss: 3.25878e-02
I0208 16:28:14.804249 22542570456896 run_lib.py:133] step: 35850, training_loss: 3.75311e-02
I0208 16:28:32.206810 22542570456896 run_lib.py:133] step: 35900, training_loss: 3.24303e-02
I0208 16:28:32.363404 22542570456896 run_lib.py:146] step: 35900, eval_loss: 4.09873e-02
I0208 16:28:49.820829 22542570456896 run_lib.py:133] step: 35950, training_loss: 2.74300e-02
I0208 16:29:07.277395 22542570456896 run_lib.py:133] step: 36000, training_loss: 2.63936e-02
I0208 16:29:07.433142 22542570456896 run_lib.py:146] step: 36000, eval_loss: 2.93819e-02
I0208 16:29:25.082690 22542570456896 run_lib.py:133] step: 36050, training_loss: 3.29103e-02
I0208 16:29:42.619134 22542570456896 run_lib.py:133] step: 36100, training_loss: 2.84069e-02
I0208 16:29:42.774393 22542570456896 run_lib.py:146] step: 36100, eval_loss: 3.31621e-02
I0208 16:30:00.177641 22542570456896 run_lib.py:133] step: 36150, training_loss: 3.14998e-02
I0208 16:30:17.611908 22542570456896 run_lib.py:133] step: 36200, training_loss: 2.94461e-02
I0208 16:30:17.789322 22542570456896 run_lib.py:146] step: 36200, eval_loss: 3.30395e-02
I0208 16:30:35.434487 22542570456896 run_lib.py:133] step: 36250, training_loss: 2.67166e-02
I0208 16:30:52.990967 22542570456896 run_lib.py:133] step: 36300, training_loss: 2.67772e-02
I0208 16:30:53.149660 22542570456896 run_lib.py:146] step: 36300, eval_loss: 2.61815e-02
I0208 16:31:10.564549 22542570456896 run_lib.py:133] step: 36350, training_loss: 2.16845e-02
I0208 16:31:27.961660 22542570456896 run_lib.py:133] step: 36400, training_loss: 2.56429e-02
I0208 16:31:28.118627 22542570456896 run_lib.py:146] step: 36400, eval_loss: 2.55874e-02
I0208 16:31:45.735309 22542570456896 run_lib.py:133] step: 36450, training_loss: 2.52538e-02
I0208 16:32:03.256220 22542570456896 run_lib.py:133] step: 36500, training_loss: 2.74602e-02
I0208 16:32:03.418632 22542570456896 run_lib.py:146] step: 36500, eval_loss: 3.16839e-02
I0208 16:32:21.060078 22542570456896 run_lib.py:133] step: 36550, training_loss: 3.19846e-02
I0208 16:32:38.492347 22542570456896 run_lib.py:133] step: 36600, training_loss: 2.65042e-02
I0208 16:32:38.650298 22542570456896 run_lib.py:146] step: 36600, eval_loss: 3.10590e-02
I0208 16:32:56.221560 22542570456896 run_lib.py:133] step: 36650, training_loss: 3.00238e-02
I0208 16:33:13.664719 22542570456896 run_lib.py:133] step: 36700, training_loss: 3.37521e-02
I0208 16:33:13.833567 22542570456896 run_lib.py:146] step: 36700, eval_loss: 2.80549e-02
I0208 16:33:31.325002 22542570456896 run_lib.py:133] step: 36750, training_loss: 2.66333e-02
I0208 16:33:48.996488 22542570456896 run_lib.py:133] step: 36800, training_loss: 3.24082e-02
I0208 16:33:49.153461 22542570456896 run_lib.py:146] step: 36800, eval_loss: 2.87573e-02
I0208 16:34:06.578042 22542570456896 run_lib.py:133] step: 36850, training_loss: 2.62615e-02
I0208 16:34:24.166184 22542570456896 run_lib.py:133] step: 36900, training_loss: 3.10290e-02
I0208 16:34:24.323410 22542570456896 run_lib.py:146] step: 36900, eval_loss: 2.64751e-02
I0208 16:34:41.781663 22542570456896 run_lib.py:133] step: 36950, training_loss: 2.88766e-02
I0208 16:34:59.226670 22542570456896 run_lib.py:133] step: 37000, training_loss: 3.41818e-02
I0208 16:34:59.388528 22542570456896 run_lib.py:146] step: 37000, eval_loss: 3.07184e-02
I0208 16:35:17.077200 22542570456896 run_lib.py:133] step: 37050, training_loss: 3.51473e-02
I0208 16:35:34.532232 22542570456896 run_lib.py:133] step: 37100, training_loss: 3.30061e-02
I0208 16:35:34.689204 22542570456896 run_lib.py:146] step: 37100, eval_loss: 3.13581e-02
I0208 16:35:52.126556 22542570456896 run_lib.py:133] step: 37150, training_loss: 3.01707e-02
I0208 16:36:09.562406 22542570456896 run_lib.py:133] step: 37200, training_loss: 3.10642e-02
I0208 16:36:09.721655 22542570456896 run_lib.py:146] step: 37200, eval_loss: 3.10076e-02
I0208 16:36:27.341139 22542570456896 run_lib.py:133] step: 37250, training_loss: 3.10071e-02
I0208 16:36:44.892012 22542570456896 run_lib.py:133] step: 37300, training_loss: 2.45986e-02
I0208 16:36:45.049784 22542570456896 run_lib.py:146] step: 37300, eval_loss: 2.66389e-02
I0208 16:37:02.550286 22542570456896 run_lib.py:133] step: 37350, training_loss: 2.88821e-02
I0208 16:37:19.942745 22542570456896 run_lib.py:133] step: 37400, training_loss: 3.09645e-02
I0208 16:37:20.098300 22542570456896 run_lib.py:146] step: 37400, eval_loss: 2.89265e-02
I0208 16:37:37.523895 22542570456896 run_lib.py:133] step: 37450, training_loss: 2.43474e-02
I0208 16:37:54.978775 22542570456896 run_lib.py:133] step: 37500, training_loss: 3.57877e-02
I0208 16:37:55.135573 22542570456896 run_lib.py:146] step: 37500, eval_loss: 2.72256e-02
I0208 16:38:12.760110 22542570456896 run_lib.py:133] step: 37550, training_loss: 2.46660e-02
I0208 16:38:30.363881 22542570456896 run_lib.py:133] step: 37600, training_loss: 2.66112e-02
I0208 16:38:30.523324 22542570456896 run_lib.py:146] step: 37600, eval_loss: 2.80321e-02
I0208 16:38:47.965034 22542570456896 run_lib.py:133] step: 37650, training_loss: 2.79146e-02
I0208 16:39:05.385734 22542570456896 run_lib.py:133] step: 37700, training_loss: 2.86851e-02
I0208 16:39:05.544355 22542570456896 run_lib.py:146] step: 37700, eval_loss: 2.71915e-02
I0208 16:39:23.096288 22542570456896 run_lib.py:133] step: 37750, training_loss: 2.76004e-02
I0208 16:39:40.523864 22542570456896 run_lib.py:133] step: 37800, training_loss: 2.79942e-02
I0208 16:39:40.701965 22542570456896 run_lib.py:146] step: 37800, eval_loss: 2.30249e-02
I0208 16:39:58.322495 22542570456896 run_lib.py:133] step: 37850, training_loss: 3.03159e-02
I0208 16:40:15.752696 22542570456896 run_lib.py:133] step: 37900, training_loss: 2.75448e-02
I0208 16:40:15.911059 22542570456896 run_lib.py:146] step: 37900, eval_loss: 2.60213e-02
I0208 16:40:33.548581 22542570456896 run_lib.py:133] step: 37950, training_loss: 2.48004e-02
I0208 16:40:51.024707 22542570456896 run_lib.py:133] step: 38000, training_loss: 3.27516e-02
I0208 16:40:51.181348 22542570456896 run_lib.py:146] step: 38000, eval_loss: 2.96892e-02
I0208 16:41:08.753864 22542570456896 run_lib.py:133] step: 38050, training_loss: 3.07657e-02
I0208 16:41:26.173165 22542570456896 run_lib.py:133] step: 38100, training_loss: 2.54381e-02
I0208 16:41:26.332416 22542570456896 run_lib.py:146] step: 38100, eval_loss: 3.20838e-02
I0208 16:41:43.812755 22542570456896 run_lib.py:133] step: 38150, training_loss: 2.99205e-02
I0208 16:42:01.468004 22542570456896 run_lib.py:133] step: 38200, training_loss: 2.90476e-02
I0208 16:42:01.624583 22542570456896 run_lib.py:146] step: 38200, eval_loss: 2.64098e-02
I0208 16:42:19.029485 22542570456896 run_lib.py:133] step: 38250, training_loss: 3.69070e-02
I0208 16:42:36.421048 22542570456896 run_lib.py:133] step: 38300, training_loss: 2.50562e-02
I0208 16:42:36.577298 22542570456896 run_lib.py:146] step: 38300, eval_loss: 2.87401e-02
I0208 16:42:54.320781 22542570456896 run_lib.py:133] step: 38350, training_loss: 2.97515e-02
I0208 16:43:11.931005 22542570456896 run_lib.py:133] step: 38400, training_loss: 2.60726e-02
I0208 16:43:12.086491 22542570456896 run_lib.py:146] step: 38400, eval_loss: 3.39093e-02
I0208 16:43:29.553199 22542570456896 run_lib.py:133] step: 38450, training_loss: 3.35146e-02
I0208 16:43:46.953607 22542570456896 run_lib.py:133] step: 38500, training_loss: 3.16404e-02
I0208 16:43:47.110278 22542570456896 run_lib.py:146] step: 38500, eval_loss: 3.32581e-02
I0208 16:44:04.568000 22542570456896 run_lib.py:133] step: 38550, training_loss: 3.01536e-02
I0208 16:44:22.187649 22542570456896 run_lib.py:133] step: 38600, training_loss: 2.59673e-02
I0208 16:44:22.353678 22542570456896 run_lib.py:146] step: 38600, eval_loss: 2.80748e-02
I0208 16:44:39.805282 22542570456896 run_lib.py:133] step: 38650, training_loss: 2.87183e-02
I0208 16:44:57.266003 22542570456896 run_lib.py:133] step: 38700, training_loss: 3.38170e-02
I0208 16:44:57.426515 22542570456896 run_lib.py:146] step: 38700, eval_loss: 3.18936e-02
I0208 16:45:14.877817 22542570456896 run_lib.py:133] step: 38750, training_loss: 3.38319e-02
I0208 16:45:32.461354 22542570456896 run_lib.py:133] step: 38800, training_loss: 3.48308e-02
I0208 16:45:32.624971 22542570456896 run_lib.py:146] step: 38800, eval_loss: 3.25973e-02
I0208 16:45:50.037881 22542570456896 run_lib.py:133] step: 38850, training_loss: 2.77008e-02
I0208 16:46:07.534705 22542570456896 run_lib.py:133] step: 38900, training_loss: 2.86894e-02
I0208 16:46:07.689041 22542570456896 run_lib.py:146] step: 38900, eval_loss: 2.59260e-02
I0208 16:46:25.122026 22542570456896 run_lib.py:133] step: 38950, training_loss: 3.11588e-02
I0208 16:46:42.600297 22542570456896 run_lib.py:133] step: 39000, training_loss: 2.81229e-02
I0208 16:46:42.758173 22542570456896 run_lib.py:146] step: 39000, eval_loss: 2.64046e-02
I0208 16:47:00.371358 22542570456896 run_lib.py:133] step: 39050, training_loss: 3.16139e-02
I0208 16:47:17.878049 22542570456896 run_lib.py:133] step: 39100, training_loss: 2.96719e-02
I0208 16:47:18.043569 22542570456896 run_lib.py:146] step: 39100, eval_loss: 2.35598e-02
I0208 16:47:35.449219 22542570456896 run_lib.py:133] step: 39150, training_loss: 3.06643e-02
I0208 16:47:52.911768 22542570456896 run_lib.py:133] step: 39200, training_loss: 2.66350e-02
I0208 16:47:53.081026 22542570456896 run_lib.py:146] step: 39200, eval_loss: 2.69172e-02
I0208 16:48:10.755443 22542570456896 run_lib.py:133] step: 39250, training_loss: 2.88615e-02
I0208 16:48:28.159814 22542570456896 run_lib.py:133] step: 39300, training_loss: 3.10612e-02
I0208 16:48:28.321573 22542570456896 run_lib.py:146] step: 39300, eval_loss: 3.22122e-02
I0208 16:48:45.903346 22542570456896 run_lib.py:133] step: 39350, training_loss: 3.10476e-02
I0208 16:49:03.334398 22542570456896 run_lib.py:133] step: 39400, training_loss: 3.35001e-02
I0208 16:49:03.487435 22542570456896 run_lib.py:146] step: 39400, eval_loss: 2.60113e-02
I0208 16:49:21.056302 22542570456896 run_lib.py:133] step: 39450, training_loss: 2.56153e-02
I0208 16:49:38.504991 22542570456896 run_lib.py:133] step: 39500, training_loss: 2.95088e-02
I0208 16:49:38.682051 22542570456896 run_lib.py:146] step: 39500, eval_loss: 3.72024e-02
I0208 16:49:56.118844 22542570456896 run_lib.py:133] step: 39550, training_loss: 3.44678e-02
I0208 16:50:13.764827 22542570456896 run_lib.py:133] step: 39600, training_loss: 2.47818e-02
I0208 16:50:13.921569 22542570456896 run_lib.py:146] step: 39600, eval_loss: 2.41903e-02
I0208 16:50:31.397620 22542570456896 run_lib.py:133] step: 39650, training_loss: 3.59333e-02
I0208 16:50:48.964070 22542570456896 run_lib.py:133] step: 39700, training_loss: 3.55800e-02
I0208 16:50:49.118974 22542570456896 run_lib.py:146] step: 39700, eval_loss: 2.99552e-02
I0208 16:51:06.574047 22542570456896 run_lib.py:133] step: 39750, training_loss: 3.28545e-02
I0208 16:51:24.068078 22542570456896 run_lib.py:133] step: 39800, training_loss: 4.17244e-02
I0208 16:51:24.220074 22542570456896 run_lib.py:146] step: 39800, eval_loss: 2.48882e-02
I0208 16:51:41.852120 22542570456896 run_lib.py:133] step: 39850, training_loss: 3.27208e-02
I0208 16:51:59.283057 22542570456896 run_lib.py:133] step: 39900, training_loss: 2.71183e-02
I0208 16:51:59.439276 22542570456896 run_lib.py:146] step: 39900, eval_loss: 2.75771e-02
I0208 16:52:16.959222 22542570456896 run_lib.py:133] step: 39950, training_loss: 3.31806e-02
I0208 16:52:34.599280 22542570456896 run_lib.py:133] step: 40000, training_loss: 2.50828e-02
I0208 16:52:35.310563 22542570456896 run_lib.py:146] step: 40000, eval_loss: 2.57641e-02
I0208 16:52:55.446505 22542570456896 run_lib.py:133] step: 40050, training_loss: 4.19919e-02
I0208 16:53:12.870160 22542570456896 run_lib.py:133] step: 40100, training_loss: 2.38204e-02
I0208 16:53:13.029366 22542570456896 run_lib.py:146] step: 40100, eval_loss: 2.72055e-02
I0208 16:53:30.428514 22542570456896 run_lib.py:133] step: 40150, training_loss: 2.97810e-02
I0208 16:53:48.053797 22542570456896 run_lib.py:133] step: 40200, training_loss: 2.41753e-02
I0208 16:53:48.211287 22542570456896 run_lib.py:146] step: 40200, eval_loss: 3.00656e-02
I0208 16:54:05.653800 22542570456896 run_lib.py:133] step: 40250, training_loss: 3.18942e-02
I0208 16:54:23.157491 22542570456896 run_lib.py:133] step: 40300, training_loss: 2.98507e-02
I0208 16:54:23.320612 22542570456896 run_lib.py:146] step: 40300, eval_loss: 2.39418e-02
I0208 16:54:40.965727 22542570456896 run_lib.py:133] step: 40350, training_loss: 3.46053e-02
I0208 16:54:58.400089 22542570456896 run_lib.py:133] step: 40400, training_loss: 2.40869e-02
I0208 16:54:58.560306 22542570456896 run_lib.py:146] step: 40400, eval_loss: 2.88435e-02
I0208 16:55:16.023101 22542570456896 run_lib.py:133] step: 40450, training_loss: 3.19074e-02
I0208 16:55:33.484706 22542570456896 run_lib.py:133] step: 40500, training_loss: 2.48695e-02
I0208 16:55:33.643470 22542570456896 run_lib.py:146] step: 40500, eval_loss: 2.66782e-02
I0208 16:55:51.043853 22542570456896 run_lib.py:133] step: 40550, training_loss: 2.34221e-02
I0208 16:56:08.556847 22542570456896 run_lib.py:133] step: 40600, training_loss: 3.03133e-02
I0208 16:56:08.714474 22542570456896 run_lib.py:146] step: 40600, eval_loss: 3.24106e-02
I0208 16:56:26.322657 22542570456896 run_lib.py:133] step: 40650, training_loss: 2.60614e-02
I0208 16:56:43.817783 22542570456896 run_lib.py:133] step: 40700, training_loss: 3.04038e-02
I0208 16:56:43.975473 22542570456896 run_lib.py:146] step: 40700, eval_loss: 2.87890e-02
I0208 16:57:01.412226 22542570456896 run_lib.py:133] step: 40750, training_loss: 2.43040e-02
I0208 16:57:18.844310 22542570456896 run_lib.py:133] step: 40800, training_loss: 2.89797e-02
I0208 16:57:18.998553 22542570456896 run_lib.py:146] step: 40800, eval_loss: 2.74675e-02
I0208 16:57:36.660179 22542570456896 run_lib.py:133] step: 40850, training_loss: 3.27027e-02
I0208 16:57:54.143747 22542570456896 run_lib.py:133] step: 40900, training_loss: 2.63565e-02
I0208 16:57:54.299220 22542570456896 run_lib.py:146] step: 40900, eval_loss: 3.03629e-02
I0208 16:58:11.892245 22542570456896 run_lib.py:133] step: 40950, training_loss: 3.04783e-02
I0208 16:58:29.312394 22542570456896 run_lib.py:133] step: 41000, training_loss: 3.16707e-02
I0208 16:58:29.471597 22542570456896 run_lib.py:146] step: 41000, eval_loss: 2.66662e-02
I0208 16:58:47.049458 22542570456896 run_lib.py:133] step: 41050, training_loss: 2.85159e-02
I0208 16:59:04.477304 22542570456896 run_lib.py:133] step: 41100, training_loss: 3.31153e-02
I0208 16:59:04.647631 22542570456896 run_lib.py:146] step: 41100, eval_loss: 2.89071e-02
I0208 16:59:22.297124 22542570456896 run_lib.py:133] step: 41150, training_loss: 3.18463e-02
I0208 16:59:39.771406 22542570456896 run_lib.py:133] step: 41200, training_loss: 2.99476e-02
I0208 16:59:39.934104 22542570456896 run_lib.py:146] step: 41200, eval_loss: 3.17113e-02
I0208 16:59:57.356095 22542570456896 run_lib.py:133] step: 41250, training_loss: 2.75518e-02
I0208 17:00:14.903420 22542570456896 run_lib.py:133] step: 41300, training_loss: 2.75938e-02
I0208 17:00:15.062369 22542570456896 run_lib.py:146] step: 41300, eval_loss: 1.90765e-02
I0208 17:00:32.518205 22542570456896 run_lib.py:133] step: 41350, training_loss: 2.91506e-02
I0208 17:00:50.052546 22542570456896 run_lib.py:133] step: 41400, training_loss: 2.70594e-02
I0208 17:00:50.221409 22542570456896 run_lib.py:146] step: 41400, eval_loss: 3.09854e-02
I0208 17:01:07.863467 22542570456896 run_lib.py:133] step: 41450, training_loss: 3.59155e-02
I0208 17:01:25.283275 22542570456896 run_lib.py:133] step: 41500, training_loss: 2.50014e-02
I0208 17:01:25.444111 22542570456896 run_lib.py:146] step: 41500, eval_loss: 3.02400e-02
I0208 17:01:43.016997 22542570456896 run_lib.py:133] step: 41550, training_loss: 3.81668e-02
I0208 17:02:00.479963 22542570456896 run_lib.py:133] step: 41600, training_loss: 2.89392e-02
I0208 17:02:00.636247 22542570456896 run_lib.py:146] step: 41600, eval_loss: 3.38809e-02
I0208 17:02:18.112121 22542570456896 run_lib.py:133] step: 41650, training_loss: 3.65171e-02
I0208 17:02:35.760199 22542570456896 run_lib.py:133] step: 41700, training_loss: 3.47014e-02
I0208 17:02:35.918370 22542570456896 run_lib.py:146] step: 41700, eval_loss: 2.56765e-02
I0208 17:02:53.323478 22542570456896 run_lib.py:133] step: 41750, training_loss: 2.84710e-02
I0208 17:03:10.814797 22542570456896 run_lib.py:133] step: 41800, training_loss: 3.06120e-02
I0208 17:03:10.968282 22542570456896 run_lib.py:146] step: 41800, eval_loss: 2.58227e-02
I0208 17:03:28.397867 22542570456896 run_lib.py:133] step: 41850, training_loss: 3.11207e-02
I0208 17:03:45.980497 22542570456896 run_lib.py:133] step: 41900, training_loss: 2.55223e-02
I0208 17:03:46.147549 22542570456896 run_lib.py:146] step: 41900, eval_loss: 2.81813e-02
I0208 17:04:03.663670 22542570456896 run_lib.py:133] step: 41950, training_loss: 2.83861e-02
I0208 17:04:21.199325 22542570456896 run_lib.py:133] step: 42000, training_loss: 3.11207e-02
I0208 17:04:21.359288 22542570456896 run_lib.py:146] step: 42000, eval_loss: 3.76166e-02
I0208 17:04:38.773495 22542570456896 run_lib.py:133] step: 42050, training_loss: 2.84126e-02
I0208 17:04:56.211451 22542570456896 run_lib.py:133] step: 42100, training_loss: 2.63985e-02
I0208 17:04:56.370303 22542570456896 run_lib.py:146] step: 42100, eval_loss: 2.63633e-02
I0208 17:05:13.956011 22542570456896 run_lib.py:133] step: 42150, training_loss: 3.25384e-02
I0208 17:05:31.462954 22542570456896 run_lib.py:133] step: 42200, training_loss: 3.51325e-02
I0208 17:05:31.619983 22542570456896 run_lib.py:146] step: 42200, eval_loss: 2.71192e-02
I0208 17:05:49.090638 22542570456896 run_lib.py:133] step: 42250, training_loss: 2.98656e-02
I0208 17:06:06.502413 22542570456896 run_lib.py:133] step: 42300, training_loss: 2.94317e-02
I0208 17:06:06.654270 22542570456896 run_lib.py:146] step: 42300, eval_loss: 3.36016e-02
I0208 17:06:24.263322 22542570456896 run_lib.py:133] step: 42350, training_loss: 2.57821e-02
I0208 17:06:41.701551 22542570456896 run_lib.py:133] step: 42400, training_loss: 2.54708e-02
I0208 17:06:41.867146 22542570456896 run_lib.py:146] step: 42400, eval_loss: 2.82117e-02
I0208 17:06:59.417951 22542570456896 run_lib.py:133] step: 42450, training_loss: 2.99743e-02
I0208 17:07:16.858161 22542570456896 run_lib.py:133] step: 42500, training_loss: 2.74961e-02
I0208 17:07:17.039321 22542570456896 run_lib.py:146] step: 42500, eval_loss: 3.00989e-02
I0208 17:07:34.716150 22542570456896 run_lib.py:133] step: 42550, training_loss: 4.31569e-02
I0208 17:07:52.113448 22542570456896 run_lib.py:133] step: 42600, training_loss: 3.55114e-02
I0208 17:07:52.271776 22542570456896 run_lib.py:146] step: 42600, eval_loss: 3.26144e-02
I0208 17:08:09.707666 22542570456896 run_lib.py:133] step: 42650, training_loss: 2.81322e-02
I0208 17:08:27.261688 22542570456896 run_lib.py:133] step: 42700, training_loss: 2.43674e-02
I0208 17:08:27.413061 22542570456896 run_lib.py:146] step: 42700, eval_loss: 3.18016e-02
I0208 17:08:44.836642 22542570456896 run_lib.py:133] step: 42750, training_loss: 3.45147e-02
I0208 17:09:02.439785 22542570456896 run_lib.py:133] step: 42800, training_loss: 2.96813e-02
I0208 17:09:02.596618 22542570456896 run_lib.py:146] step: 42800, eval_loss: 3.09458e-02
I0208 17:09:20.032652 22542570456896 run_lib.py:133] step: 42850, training_loss: 3.24663e-02
I0208 17:09:37.462620 22542570456896 run_lib.py:133] step: 42900, training_loss: 2.75903e-02
I0208 17:09:37.621433 22542570456896 run_lib.py:146] step: 42900, eval_loss: 2.99566e-02
I0208 17:09:55.218096 22542570456896 run_lib.py:133] step: 42950, training_loss: 4.04319e-02
I0208 17:10:12.621772 22542570456896 run_lib.py:133] step: 43000, training_loss: 3.13511e-02
I0208 17:10:12.783399 22542570456896 run_lib.py:146] step: 43000, eval_loss: 2.98760e-02
I0208 17:10:30.214667 22542570456896 run_lib.py:133] step: 43050, training_loss: 2.62131e-02
I0208 17:10:47.838683 22542570456896 run_lib.py:133] step: 43100, training_loss: 3.32727e-02
I0208 17:10:47.997060 22542570456896 run_lib.py:146] step: 43100, eval_loss: 2.59190e-02
I0208 17:11:05.489740 22542570456896 run_lib.py:133] step: 43150, training_loss: 3.47019e-02
I0208 17:11:22.901072 22542570456896 run_lib.py:133] step: 43200, training_loss: 3.14023e-02
I0208 17:11:23.240273 22542570456896 run_lib.py:146] step: 43200, eval_loss: 2.94028e-02
I0208 17:11:40.642307 22542570456896 run_lib.py:133] step: 43250, training_loss: 3.77603e-02
I0208 17:11:58.095144 22542570456896 run_lib.py:133] step: 43300, training_loss: 3.61964e-02
I0208 17:11:58.249383 22542570456896 run_lib.py:146] step: 43300, eval_loss: 2.96445e-02
I0208 17:12:15.711454 22542570456896 run_lib.py:133] step: 43350, training_loss: 2.78316e-02
I0208 17:12:33.177862 22542570456896 run_lib.py:133] step: 43400, training_loss: 2.41855e-02
I0208 17:12:33.341994 22542570456896 run_lib.py:146] step: 43400, eval_loss: 2.64083e-02
I0208 17:12:50.964186 22542570456896 run_lib.py:133] step: 43450, training_loss: 3.28763e-02
I0208 17:13:08.448246 22542570456896 run_lib.py:133] step: 43500, training_loss: 3.03320e-02
I0208 17:13:08.603322 22542570456896 run_lib.py:146] step: 43500, eval_loss: 2.90155e-02
I0208 17:13:26.076036 22542570456896 run_lib.py:133] step: 43550, training_loss: 3.85944e-02
I0208 17:13:43.543791 22542570456896 run_lib.py:133] step: 43600, training_loss: 2.95241e-02
I0208 17:13:43.703344 22542570456896 run_lib.py:146] step: 43600, eval_loss: 2.87446e-02
I0208 17:14:01.303110 22542570456896 run_lib.py:133] step: 43650, training_loss: 2.70367e-02
I0208 17:14:18.860690 22542570456896 run_lib.py:133] step: 43700, training_loss: 2.44585e-02
I0208 17:14:19.012645 22542570456896 run_lib.py:146] step: 43700, eval_loss: 3.38043e-02
I0208 17:14:36.486046 22542570456896 run_lib.py:133] step: 43750, training_loss: 2.80832e-02
I0208 17:14:53.913547 22542570456896 run_lib.py:133] step: 43800, training_loss: 3.33671e-02
I0208 17:14:54.068329 22542570456896 run_lib.py:146] step: 43800, eval_loss: 2.76147e-02
I0208 17:15:11.639439 22542570456896 run_lib.py:133] step: 43850, training_loss: 2.88851e-02
I0208 17:15:29.057231 22542570456896 run_lib.py:133] step: 43900, training_loss: 2.94478e-02
I0208 17:15:29.233285 22542570456896 run_lib.py:146] step: 43900, eval_loss: 3.38876e-02
I0208 17:15:46.931677 22542570456896 run_lib.py:133] step: 43950, training_loss: 2.84083e-02
I0208 17:16:04.333140 22542570456896 run_lib.py:133] step: 44000, training_loss: 3.41026e-02
I0208 17:16:04.489594 22542570456896 run_lib.py:146] step: 44000, eval_loss: 3.34833e-02
I0208 17:16:22.071352 22542570456896 run_lib.py:133] step: 44050, training_loss: 3.10788e-02
I0208 17:16:39.548095 22542570456896 run_lib.py:133] step: 44100, training_loss: 3.16214e-02
I0208 17:16:39.703392 22542570456896 run_lib.py:146] step: 44100, eval_loss: 2.90407e-02
I0208 17:16:57.113740 22542570456896 run_lib.py:133] step: 44150, training_loss: 2.67526e-02
I0208 17:17:14.715145 22542570456896 run_lib.py:133] step: 44200, training_loss: 3.33334e-02
I0208 17:17:14.869420 22542570456896 run_lib.py:146] step: 44200, eval_loss: 3.00740e-02
I0208 17:17:32.312826 22542570456896 run_lib.py:133] step: 44250, training_loss: 3.37097e-02
I0208 17:17:49.974291 22542570456896 run_lib.py:133] step: 44300, training_loss: 3.48067e-02
I0208 17:17:50.133719 22542570456896 run_lib.py:146] step: 44300, eval_loss: 2.79139e-02
I0208 17:18:07.568910 22542570456896 run_lib.py:133] step: 44350, training_loss: 2.51654e-02
I0208 17:18:25.014587 22542570456896 run_lib.py:133] step: 44400, training_loss: 3.09027e-02
I0208 17:18:25.170564 22542570456896 run_lib.py:146] step: 44400, eval_loss: 2.60747e-02
I0208 17:18:42.799299 22542570456896 run_lib.py:133] step: 44450, training_loss: 2.79694e-02
I0208 17:19:00.277873 22542570456896 run_lib.py:133] step: 44500, training_loss: 2.38699e-02
I0208 17:19:00.433027 22542570456896 run_lib.py:146] step: 44500, eval_loss: 2.95341e-02
I0208 17:19:17.854962 22542570456896 run_lib.py:133] step: 44550, training_loss: 2.72961e-02
I0208 17:19:35.296925 22542570456896 run_lib.py:133] step: 44600, training_loss: 2.75579e-02
I0208 17:19:35.453120 22542570456896 run_lib.py:146] step: 44600, eval_loss: 3.34332e-02
I0208 17:19:53.056473 22542570456896 run_lib.py:133] step: 44650, training_loss: 3.02122e-02
I0208 17:20:10.566074 22542570456896 run_lib.py:133] step: 44700, training_loss: 2.29372e-02
I0208 17:20:10.721378 22542570456896 run_lib.py:146] step: 44700, eval_loss: 3.01151e-02
I0208 17:20:28.307997 22542570456896 run_lib.py:133] step: 44750, training_loss: 2.72794e-02
I0208 17:20:45.761955 22542570456896 run_lib.py:133] step: 44800, training_loss: 2.87206e-02
I0208 17:20:45.918896 22542570456896 run_lib.py:146] step: 44800, eval_loss: 2.77681e-02
I0208 17:21:03.322487 22542570456896 run_lib.py:133] step: 44850, training_loss: 2.65617e-02
I0208 17:21:20.731345 22542570456896 run_lib.py:133] step: 44900, training_loss: 2.96175e-02
I0208 17:21:20.891348 22542570456896 run_lib.py:146] step: 44900, eval_loss: 2.77934e-02
I0208 17:21:38.466940 22542570456896 run_lib.py:133] step: 44950, training_loss: 3.34636e-02
I0208 17:21:56.026406 22542570456896 run_lib.py:133] step: 45000, training_loss: 2.84653e-02
I0208 17:21:56.182806 22542570456896 run_lib.py:146] step: 45000, eval_loss: 3.74594e-02
I0208 17:22:13.594879 22542570456896 run_lib.py:133] step: 45050, training_loss: 2.68867e-02
I0208 17:22:31.019497 22542570456896 run_lib.py:133] step: 45100, training_loss: 2.73973e-02
I0208 17:22:31.170788 22542570456896 run_lib.py:146] step: 45100, eval_loss: 3.13760e-02
I0208 17:22:48.698335 22542570456896 run_lib.py:133] step: 45150, training_loss: 3.09371e-02
I0208 17:23:06.110844 22542570456896 run_lib.py:133] step: 45200, training_loss: 2.92430e-02
I0208 17:23:06.279493 22542570456896 run_lib.py:146] step: 45200, eval_loss: 3.31974e-02
I0208 17:23:23.866166 22542570456896 run_lib.py:133] step: 45250, training_loss: 2.52846e-02
I0208 17:23:41.308302 22542570456896 run_lib.py:133] step: 45300, training_loss: 2.87055e-02
I0208 17:23:41.465559 22542570456896 run_lib.py:146] step: 45300, eval_loss: 2.40147e-02
I0208 17:23:59.002206 22542570456896 run_lib.py:133] step: 45350, training_loss: 3.03884e-02
I0208 17:24:16.389815 22542570456896 run_lib.py:133] step: 45400, training_loss: 3.11761e-02
I0208 17:24:16.545396 22542570456896 run_lib.py:146] step: 45400, eval_loss: 2.90622e-02
I0208 17:24:34.114124 22542570456896 run_lib.py:133] step: 45450, training_loss: 2.42062e-02
I0208 17:24:51.569514 22542570456896 run_lib.py:133] step: 45500, training_loss: 2.49007e-02
I0208 17:24:51.724990 22542570456896 run_lib.py:146] step: 45500, eval_loss: 2.93469e-02
I0208 17:25:09.176088 22542570456896 run_lib.py:133] step: 45550, training_loss: 2.58579e-02
I0208 17:25:26.837875 22542570456896 run_lib.py:133] step: 45600, training_loss: 3.48467e-02
I0208 17:25:26.990375 22542570456896 run_lib.py:146] step: 45600, eval_loss: 2.71215e-02
I0208 17:25:44.413325 22542570456896 run_lib.py:133] step: 45650, training_loss: 3.08921e-02
I0208 17:26:01.859125 22542570456896 run_lib.py:133] step: 45700, training_loss: 2.64723e-02
I0208 17:26:02.014635 22542570456896 run_lib.py:146] step: 45700, eval_loss: 3.17240e-02
I0208 17:26:19.609426 22542570456896 run_lib.py:133] step: 45750, training_loss: 3.61209e-02
I0208 17:26:37.229267 22542570456896 run_lib.py:133] step: 45800, training_loss: 3.29135e-02
I0208 17:26:37.387396 22542570456896 run_lib.py:146] step: 45800, eval_loss: 2.88797e-02
I0208 17:26:54.853845 22542570456896 run_lib.py:133] step: 45850, training_loss: 3.34398e-02
I0208 17:27:12.269168 22542570456896 run_lib.py:133] step: 45900, training_loss: 2.97210e-02
I0208 17:27:12.425257 22542570456896 run_lib.py:146] step: 45900, eval_loss: 3.18934e-02
I0208 17:27:29.828619 22542570456896 run_lib.py:133] step: 45950, training_loss: 3.03051e-02
I0208 17:27:47.420789 22542570456896 run_lib.py:133] step: 46000, training_loss: 3.10176e-02
I0208 17:27:47.576658 22542570456896 run_lib.py:146] step: 46000, eval_loss: 3.13912e-02
I0208 17:28:05.086813 22542570456896 run_lib.py:133] step: 46050, training_loss: 2.61498e-02
I0208 17:28:22.523873 22542570456896 run_lib.py:133] step: 46100, training_loss: 3.07428e-02
I0208 17:28:22.675233 22542570456896 run_lib.py:146] step: 46100, eval_loss: 2.98076e-02
I0208 17:28:40.090673 22542570456896 run_lib.py:133] step: 46150, training_loss: 2.27485e-02
I0208 17:28:57.690773 22542570456896 run_lib.py:133] step: 46200, training_loss: 2.54132e-02
I0208 17:28:57.849690 22542570456896 run_lib.py:146] step: 46200, eval_loss: 3.12507e-02
I0208 17:29:15.259655 22542570456896 run_lib.py:133] step: 46250, training_loss: 2.80957e-02
I0208 17:29:32.767068 22542570456896 run_lib.py:133] step: 46300, training_loss: 2.78720e-02
I0208 17:29:32.923351 22542570456896 run_lib.py:146] step: 46300, eval_loss: 3.08742e-02
I0208 17:29:50.390786 22542570456896 run_lib.py:133] step: 46350, training_loss: 2.49342e-02
I0208 17:30:07.806283 22542570456896 run_lib.py:133] step: 46400, training_loss: 3.22748e-02
I0208 17:30:07.961677 22542570456896 run_lib.py:146] step: 46400, eval_loss: 2.03300e-02
I0208 17:30:25.591053 22542570456896 run_lib.py:133] step: 46450, training_loss: 2.81574e-02
I0208 17:30:43.064498 22542570456896 run_lib.py:133] step: 46500, training_loss: 2.89052e-02
I0208 17:30:43.220325 22542570456896 run_lib.py:146] step: 46500, eval_loss: 3.56074e-02
I0208 17:31:00.655958 22542570456896 run_lib.py:133] step: 46550, training_loss: 2.49252e-02
I0208 17:31:18.087431 22542570456896 run_lib.py:133] step: 46600, training_loss: 3.51526e-02
I0208 17:31:18.248527 22542570456896 run_lib.py:146] step: 46600, eval_loss: 2.51901e-02
I0208 17:31:35.898418 22542570456896 run_lib.py:133] step: 46650, training_loss: 2.77375e-02
I0208 17:31:53.333405 22542570456896 run_lib.py:133] step: 46700, training_loss: 3.34420e-02
I0208 17:31:53.491587 22542570456896 run_lib.py:146] step: 46700, eval_loss: 3.11838e-02
I0208 17:32:11.058498 22542570456896 run_lib.py:133] step: 46750, training_loss: 2.76105e-02
I0208 17:32:28.463129 22542570456896 run_lib.py:133] step: 46800, training_loss: 2.89143e-02
I0208 17:32:28.617220 22542570456896 run_lib.py:146] step: 46800, eval_loss: 2.92460e-02
I0208 17:32:46.267131 22542570456896 run_lib.py:133] step: 46850, training_loss: 2.86635e-02
I0208 17:33:03.699086 22542570456896 run_lib.py:133] step: 46900, training_loss: 2.69497e-02
I0208 17:33:03.862738 22542570456896 run_lib.py:146] step: 46900, eval_loss: 2.53747e-02
I0208 17:33:21.318303 22542570456896 run_lib.py:133] step: 46950, training_loss: 3.01007e-02
I0208 17:33:38.905222 22542570456896 run_lib.py:133] step: 47000, training_loss: 3.08248e-02
I0208 17:33:39.056025 22542570456896 run_lib.py:146] step: 47000, eval_loss: 3.87427e-02
I0208 17:33:56.505193 22542570456896 run_lib.py:133] step: 47050, training_loss: 3.08148e-02
I0208 17:34:14.071985 22542570456896 run_lib.py:133] step: 47100, training_loss: 2.80363e-02
I0208 17:34:14.227013 22542570456896 run_lib.py:146] step: 47100, eval_loss: 2.47700e-02
I0208 17:34:31.655262 22542570456896 run_lib.py:133] step: 47150, training_loss: 2.57831e-02
I0208 17:34:49.140455 22542570456896 run_lib.py:133] step: 47200, training_loss: 2.67699e-02
I0208 17:34:49.302172 22542570456896 run_lib.py:146] step: 47200, eval_loss: 2.43576e-02
I0208 17:35:06.929300 22542570456896 run_lib.py:133] step: 47250, training_loss: 2.38838e-02
I0208 17:35:24.317062 22542570456896 run_lib.py:133] step: 47300, training_loss: 3.05038e-02
I0208 17:35:24.472206 22542570456896 run_lib.py:146] step: 47300, eval_loss: 2.67556e-02
I0208 17:35:41.924493 22542570456896 run_lib.py:133] step: 47350, training_loss: 2.47002e-02
I0208 17:35:59.477525 22542570456896 run_lib.py:133] step: 47400, training_loss: 2.97697e-02
I0208 17:35:59.631243 22542570456896 run_lib.py:146] step: 47400, eval_loss: 3.34708e-02
I0208 17:36:17.011241 22542570456896 run_lib.py:133] step: 47450, training_loss: 3.28546e-02
I0208 17:36:34.423334 22542570456896 run_lib.py:133] step: 47500, training_loss: 2.90130e-02
I0208 17:36:34.582328 22542570456896 run_lib.py:146] step: 47500, eval_loss: 2.52703e-02
I0208 17:36:52.038621 22542570456896 run_lib.py:133] step: 47550, training_loss: 3.12648e-02
I0208 17:37:09.365106 22542570456896 run_lib.py:133] step: 47600, training_loss: 2.60415e-02
I0208 17:37:09.519154 22542570456896 run_lib.py:146] step: 47600, eval_loss: 3.07204e-02
I0208 17:37:26.979497 22542570456896 run_lib.py:133] step: 47650, training_loss: 2.93024e-02
I0208 17:37:44.384025 22542570456896 run_lib.py:133] step: 47700, training_loss: 2.56606e-02
I0208 17:37:44.540539 22542570456896 run_lib.py:146] step: 47700, eval_loss: 2.80024e-02
I0208 17:38:02.170558 22542570456896 run_lib.py:133] step: 47750, training_loss: 2.57085e-02
I0208 17:38:19.764006 22542570456896 run_lib.py:133] step: 47800, training_loss: 3.01638e-02
I0208 17:38:19.920794 22542570456896 run_lib.py:146] step: 47800, eval_loss: 2.68191e-02
I0208 17:38:37.360901 22542570456896 run_lib.py:133] step: 47850, training_loss: 3.42536e-02
I0208 17:38:54.769400 22542570456896 run_lib.py:133] step: 47900, training_loss: 2.75365e-02
I0208 17:38:54.922590 22542570456896 run_lib.py:146] step: 47900, eval_loss: 2.58667e-02
I0208 17:39:12.510171 22542570456896 run_lib.py:133] step: 47950, training_loss: 2.70361e-02
I0208 17:39:29.930177 22542570456896 run_lib.py:133] step: 48000, training_loss: 3.09124e-02
I0208 17:39:30.085580 22542570456896 run_lib.py:146] step: 48000, eval_loss: 3.08386e-02
I0208 17:39:47.743783 22542570456896 run_lib.py:133] step: 48050, training_loss: 2.67518e-02
I0208 17:40:05.178918 22542570456896 run_lib.py:133] step: 48100, training_loss: 2.31226e-02
I0208 17:40:05.344436 22542570456896 run_lib.py:146] step: 48100, eval_loss: 2.74100e-02
I0208 17:40:22.937631 22542570456896 run_lib.py:133] step: 48150, training_loss: 3.14418e-02
I0208 17:40:40.366016 22542570456896 run_lib.py:133] step: 48200, training_loss: 2.52691e-02
I0208 17:40:40.528316 22542570456896 run_lib.py:146] step: 48200, eval_loss: 2.85658e-02
I0208 17:40:58.123970 22542570456896 run_lib.py:133] step: 48250, training_loss: 3.58813e-02
I0208 17:41:15.593954 22542570456896 run_lib.py:133] step: 48300, training_loss: 2.91610e-02
I0208 17:41:15.750773 22542570456896 run_lib.py:146] step: 48300, eval_loss: 3.34875e-02
I0208 17:41:33.203547 22542570456896 run_lib.py:133] step: 48350, training_loss: 3.04895e-02
I0208 17:41:50.795773 22542570456896 run_lib.py:133] step: 48400, training_loss: 3.43253e-02
I0208 17:41:50.948804 22542570456896 run_lib.py:146] step: 48400, eval_loss: 3.24885e-02
I0208 17:42:08.360853 22542570456896 run_lib.py:133] step: 48450, training_loss: 3.28217e-02
I0208 17:42:25.815023 22542570456896 run_lib.py:133] step: 48500, training_loss: 3.26552e-02
I0208 17:42:25.968265 22542570456896 run_lib.py:146] step: 48500, eval_loss: 3.21279e-02
I0208 17:42:43.520394 22542570456896 run_lib.py:133] step: 48550, training_loss: 2.92748e-02
I0208 17:43:01.023553 22542570456896 run_lib.py:133] step: 48600, training_loss: 3.38901e-02
I0208 17:43:01.193417 22542570456896 run_lib.py:146] step: 48600, eval_loss: 2.40264e-02
I0208 17:43:18.833391 22542570456896 run_lib.py:133] step: 48650, training_loss: 3.22197e-02
I0208 17:43:36.295483 22542570456896 run_lib.py:133] step: 48700, training_loss: 3.13591e-02
I0208 17:43:36.450636 22542570456896 run_lib.py:146] step: 48700, eval_loss: 3.31431e-02
I0208 17:43:53.943301 22542570456896 run_lib.py:133] step: 48750, training_loss: 2.84291e-02
I0208 17:44:11.546002 22542570456896 run_lib.py:133] step: 48800, training_loss: 1.98342e-02
I0208 17:44:11.702469 22542570456896 run_lib.py:146] step: 48800, eval_loss: 2.94868e-02
I0208 17:44:29.143397 22542570456896 run_lib.py:133] step: 48850, training_loss: 3.49824e-02
I0208 17:44:46.572090 22542570456896 run_lib.py:133] step: 48900, training_loss: 2.20635e-02
I0208 17:44:46.725539 22542570456896 run_lib.py:146] step: 48900, eval_loss: 2.88502e-02
I0208 17:45:04.182826 22542570456896 run_lib.py:133] step: 48950, training_loss: 2.55903e-02
I0208 17:45:21.813131 22542570456896 run_lib.py:133] step: 49000, training_loss: 2.27682e-02
I0208 17:45:21.968294 22542570456896 run_lib.py:146] step: 49000, eval_loss: 3.07204e-02
I0208 17:45:39.381709 22542570456896 run_lib.py:133] step: 49050, training_loss: 3.54032e-02
I0208 17:45:56.865693 22542570456896 run_lib.py:133] step: 49100, training_loss: 2.68110e-02
I0208 17:45:57.022465 22542570456896 run_lib.py:146] step: 49100, eval_loss: 2.68699e-02
I0208 17:46:14.460345 22542570456896 run_lib.py:133] step: 49150, training_loss: 2.74176e-02
I0208 17:46:31.960985 22542570456896 run_lib.py:133] step: 49200, training_loss: 2.74103e-02
I0208 17:46:32.117590 22542570456896 run_lib.py:146] step: 49200, eval_loss: 2.51478e-02
I0208 17:46:49.701360 22542570456896 run_lib.py:133] step: 49250, training_loss: 2.99284e-02
I0208 17:47:07.170806 22542570456896 run_lib.py:133] step: 49300, training_loss: 3.34021e-02
I0208 17:47:07.326339 22542570456896 run_lib.py:146] step: 49300, eval_loss: 3.19841e-02
I0208 17:47:24.760856 22542570456896 run_lib.py:133] step: 49350, training_loss: 4.03519e-02
I0208 17:47:42.195429 22542570456896 run_lib.py:133] step: 49400, training_loss: 2.63034e-02
I0208 17:47:42.348285 22542570456896 run_lib.py:146] step: 49400, eval_loss: 2.72249e-02
I0208 17:47:59.924816 22542570456896 run_lib.py:133] step: 49450, training_loss: 3.54981e-02
I0208 17:48:17.354829 22542570456896 run_lib.py:133] step: 49500, training_loss: 2.27440e-02
I0208 17:48:17.513082 22542570456896 run_lib.py:146] step: 49500, eval_loss: 2.13791e-02
I0208 17:48:35.167250 22542570456896 run_lib.py:133] step: 49550, training_loss: 2.96058e-02
I0208 17:48:52.615273 22542570456896 run_lib.py:133] step: 49600, training_loss: 2.86733e-02
I0208 17:48:52.772686 22542570456896 run_lib.py:146] step: 49600, eval_loss: 2.70571e-02
I0208 17:49:10.340665 22542570456896 run_lib.py:133] step: 49650, training_loss: 3.35870e-02
I0208 17:49:27.765314 22542570456896 run_lib.py:133] step: 49700, training_loss: 3.77814e-02
I0208 17:49:27.929345 22542570456896 run_lib.py:146] step: 49700, eval_loss: 3.33887e-02
I0208 17:49:45.365710 22542570456896 run_lib.py:133] step: 49750, training_loss: 2.77246e-02
I0208 17:50:03.011980 22542570456896 run_lib.py:133] step: 49800, training_loss: 3.26495e-02
I0208 17:50:03.170880 22542570456896 run_lib.py:146] step: 49800, eval_loss: 2.68024e-02
I0208 17:50:20.616586 22542570456896 run_lib.py:133] step: 49850, training_loss: 3.58875e-02
I0208 17:50:38.197006 22542570456896 run_lib.py:133] step: 49900, training_loss: 3.38415e-02
I0208 17:50:38.349289 22542570456896 run_lib.py:146] step: 49900, eval_loss: 2.53869e-02
I0208 17:50:55.739139 22542570456896 run_lib.py:133] step: 49950, training_loss: 3.14566e-02
I0208 17:51:13.189382 22542570456896 run_lib.py:133] step: 50000, training_loss: 3.42302e-02
I0208 17:51:13.889360 22542570456896 run_lib.py:146] step: 50000, eval_loss: 3.24229e-02
I0208 17:51:34.114599 22542570456896 run_lib.py:133] step: 50050, training_loss: 2.63409e-02
I0208 17:51:51.560903 22542570456896 run_lib.py:133] step: 50100, training_loss: 3.33672e-02
I0208 17:51:51.719323 22542570456896 run_lib.py:146] step: 50100, eval_loss: 2.47980e-02
I0208 17:52:09.298969 22542570456896 run_lib.py:133] step: 50150, training_loss: 2.75073e-02
I0208 17:52:26.721089 22542570456896 run_lib.py:133] step: 50200, training_loss: 3.25637e-02
I0208 17:52:26.876516 22542570456896 run_lib.py:146] step: 50200, eval_loss: 3.33522e-02
I0208 17:52:44.290393 22542570456896 run_lib.py:133] step: 50250, training_loss: 3.66582e-02
I0208 17:53:01.876722 22542570456896 run_lib.py:133] step: 50300, training_loss: 2.65353e-02
I0208 17:53:02.044633 22542570456896 run_lib.py:146] step: 50300, eval_loss: 2.56051e-02
I0208 17:53:19.538950 22542570456896 run_lib.py:133] step: 50350, training_loss: 2.73638e-02
I0208 17:53:37.126010 22542570456896 run_lib.py:133] step: 50400, training_loss: 2.81934e-02
I0208 17:53:37.280506 22542570456896 run_lib.py:146] step: 50400, eval_loss: 2.87656e-02
I0208 17:53:54.697752 22542570456896 run_lib.py:133] step: 50450, training_loss: 2.80215e-02
I0208 17:54:12.162076 22542570456896 run_lib.py:133] step: 50500, training_loss: 2.85488e-02
I0208 17:54:12.315270 22542570456896 run_lib.py:146] step: 50500, eval_loss: 3.44634e-02
I0208 17:54:29.703267 22542570456896 run_lib.py:133] step: 50550, training_loss: 3.01271e-02
I0208 17:54:47.266091 22542570456896 run_lib.py:133] step: 50600, training_loss: 3.38812e-02
I0208 17:54:47.442769 22542570456896 run_lib.py:146] step: 50600, eval_loss: 3.28225e-02
I0208 17:55:04.909735 22542570456896 run_lib.py:133] step: 50650, training_loss: 2.56071e-02
I0208 17:55:22.333379 22542570456896 run_lib.py:133] step: 50700, training_loss: 2.83525e-02
I0208 17:55:22.495561 22542570456896 run_lib.py:146] step: 50700, eval_loss: 2.65558e-02
I0208 17:55:40.183372 22542570456896 run_lib.py:133] step: 50750, training_loss: 2.43955e-02
I0208 17:55:57.565485 22542570456896 run_lib.py:133] step: 50800, training_loss: 3.02184e-02
I0208 17:55:57.720338 22542570456896 run_lib.py:146] step: 50800, eval_loss: 2.84135e-02
I0208 17:56:15.199130 22542570456896 run_lib.py:133] step: 50850, training_loss: 2.74332e-02
I0208 17:56:32.636299 22542570456896 run_lib.py:133] step: 50900, training_loss: 2.49043e-02
I0208 17:56:32.787574 22542570456896 run_lib.py:146] step: 50900, eval_loss: 2.43883e-02
I0208 17:56:50.254237 22542570456896 run_lib.py:133] step: 50950, training_loss: 2.90863e-02
I0208 17:57:07.699380 22542570456896 run_lib.py:133] step: 51000, training_loss: 3.34553e-02
I0208 17:57:07.856509 22542570456896 run_lib.py:146] step: 51000, eval_loss: 3.23947e-02
I0208 17:57:25.449861 22542570456896 run_lib.py:133] step: 51050, training_loss: 3.21349e-02
I0208 17:57:42.967396 22542570456896 run_lib.py:133] step: 51100, training_loss: 2.47470e-02
I0208 17:57:43.126580 22542570456896 run_lib.py:146] step: 51100, eval_loss: 2.89580e-02
I0208 17:58:00.616133 22542570456896 run_lib.py:133] step: 51150, training_loss: 2.69340e-02
I0208 17:58:18.072450 22542570456896 run_lib.py:133] step: 51200, training_loss: 3.27900e-02
I0208 17:58:18.235127 22542570456896 run_lib.py:146] step: 51200, eval_loss: 3.40040e-02
I0208 17:58:35.832529 22542570456896 run_lib.py:133] step: 51250, training_loss: 3.05715e-02
I0208 17:58:53.212734 22542570456896 run_lib.py:133] step: 51300, training_loss: 2.59717e-02
I0208 17:58:53.363643 22542570456896 run_lib.py:146] step: 51300, eval_loss: 2.92950e-02
I0208 17:59:10.923257 22542570456896 run_lib.py:133] step: 51350, training_loss: 2.61428e-02
I0208 17:59:28.359359 22542570456896 run_lib.py:133] step: 51400, training_loss: 3.11946e-02
I0208 17:59:28.515428 22542570456896 run_lib.py:146] step: 51400, eval_loss: 2.48933e-02
I0208 17:59:46.191809 22542570456896 run_lib.py:133] step: 51450, training_loss: 2.93526e-02
I0208 18:00:03.609956 22542570456896 run_lib.py:133] step: 51500, training_loss: 2.83212e-02
I0208 18:00:03.768182 22542570456896 run_lib.py:146] step: 51500, eval_loss: 3.21382e-02
I0208 18:00:21.316020 22542570456896 run_lib.py:133] step: 51550, training_loss: 2.23110e-02
I0208 18:00:38.736060 22542570456896 run_lib.py:133] step: 51600, training_loss: 3.12841e-02
I0208 18:00:38.891199 22542570456896 run_lib.py:146] step: 51600, eval_loss: 2.62692e-02
I0208 18:00:56.287411 22542570456896 run_lib.py:133] step: 51650, training_loss: 3.54684e-02
I0208 18:01:13.853770 22542570456896 run_lib.py:133] step: 51700, training_loss: 3.15638e-02
I0208 18:01:14.014990 22542570456896 run_lib.py:146] step: 51700, eval_loss: 2.26804e-02
I0208 18:01:31.471837 22542570456896 run_lib.py:133] step: 51750, training_loss: 2.88974e-02
I0208 18:01:48.882467 22542570456896 run_lib.py:133] step: 51800, training_loss: 2.40199e-02
I0208 18:01:49.034077 22542570456896 run_lib.py:146] step: 51800, eval_loss: 2.36790e-02
I0208 18:02:06.651228 22542570456896 run_lib.py:133] step: 51850, training_loss: 3.44825e-02
I0208 18:02:24.032716 22542570456896 run_lib.py:133] step: 51900, training_loss: 3.03760e-02
I0208 18:02:24.191610 22542570456896 run_lib.py:146] step: 51900, eval_loss: 3.23420e-02
I0208 18:02:41.765975 22542570456896 run_lib.py:133] step: 51950, training_loss: 3.06760e-02
I0208 18:02:59.237340 22542570456896 run_lib.py:133] step: 52000, training_loss: 2.95831e-02
I0208 18:02:59.413265 22542570456896 run_lib.py:146] step: 52000, eval_loss: 2.61492e-02
I0208 18:03:16.863855 22542570456896 run_lib.py:133] step: 52050, training_loss: 3.36346e-02
I0208 18:03:34.489142 22542570456896 run_lib.py:133] step: 52100, training_loss: 3.13677e-02
I0208 18:03:34.641716 22542570456896 run_lib.py:146] step: 52100, eval_loss: 2.27817e-02
I0208 18:03:52.086771 22542570456896 run_lib.py:133] step: 52150, training_loss: 2.81913e-02
I0208 18:04:09.481855 22542570456896 run_lib.py:133] step: 52200, training_loss: 3.09640e-02
I0208 18:04:09.637381 22542570456896 run_lib.py:146] step: 52200, eval_loss: 2.53878e-02
I0208 18:04:27.064172 22542570456896 run_lib.py:133] step: 52250, training_loss: 2.85557e-02
I0208 18:04:44.650961 22542570456896 run_lib.py:133] step: 52300, training_loss: 2.72357e-02
I0208 18:04:44.804388 22542570456896 run_lib.py:146] step: 52300, eval_loss: 2.87527e-02
I0208 18:05:02.271550 22542570456896 run_lib.py:133] step: 52350, training_loss: 2.96847e-02
I0208 18:05:19.763574 22542570456896 run_lib.py:133] step: 52400, training_loss: 3.74106e-02
I0208 18:05:19.919234 22542570456896 run_lib.py:146] step: 52400, eval_loss: 3.07866e-02
I0208 18:05:37.325453 22542570456896 run_lib.py:133] step: 52450, training_loss: 2.71144e-02
I0208 18:05:54.732467 22542570456896 run_lib.py:133] step: 52500, training_loss: 2.38774e-02
I0208 18:05:54.889340 22542570456896 run_lib.py:146] step: 52500, eval_loss: 2.49183e-02
I0208 18:06:12.491820 22542570456896 run_lib.py:133] step: 52550, training_loss: 3.21541e-02
I0208 18:06:30.037252 22542570456896 run_lib.py:133] step: 52600, training_loss: 3.03349e-02
I0208 18:06:30.196617 22542570456896 run_lib.py:146] step: 52600, eval_loss: 2.50025e-02
I0208 18:06:47.630788 22542570456896 run_lib.py:133] step: 52650, training_loss: 2.43219e-02
I0208 18:07:05.044508 22542570456896 run_lib.py:133] step: 52700, training_loss: 2.87580e-02
I0208 18:07:05.205314 22542570456896 run_lib.py:146] step: 52700, eval_loss: 2.64252e-02
I0208 18:07:22.731927 22542570456896 run_lib.py:133] step: 52750, training_loss: 2.98973e-02
I0208 18:07:40.143466 22542570456896 run_lib.py:133] step: 52800, training_loss: 2.23065e-02
I0208 18:07:40.297161 22542570456896 run_lib.py:146] step: 52800, eval_loss: 2.68134e-02
I0208 18:07:57.904434 22542570456896 run_lib.py:133] step: 52850, training_loss: 4.05518e-02
I0208 18:08:15.352547 22542570456896 run_lib.py:133] step: 52900, training_loss: 3.45540e-02
I0208 18:08:15.508296 22542570456896 run_lib.py:146] step: 52900, eval_loss: 2.68467e-02
I0208 18:08:33.131231 22542570456896 run_lib.py:133] step: 52950, training_loss: 2.82269e-02
I0208 18:08:50.581690 22542570456896 run_lib.py:133] step: 53000, training_loss: 2.64808e-02
I0208 18:08:50.744679 22542570456896 run_lib.py:146] step: 53000, eval_loss: 2.96752e-02
I0208 18:09:08.156466 22542570456896 run_lib.py:133] step: 53050, training_loss: 2.64281e-02
I0208 18:09:25.772471 22542570456896 run_lib.py:133] step: 53100, training_loss: 3.15981e-02
I0208 18:09:25.936654 22542570456896 run_lib.py:146] step: 53100, eval_loss: 3.20590e-02
I0208 18:09:43.378008 22542570456896 run_lib.py:133] step: 53150, training_loss: 2.92777e-02
I0208 18:10:00.982745 22542570456896 run_lib.py:133] step: 53200, training_loss: 3.24371e-02
I0208 18:10:01.134358 22542570456896 run_lib.py:146] step: 53200, eval_loss: 3.30321e-02
I0208 18:10:18.531053 22542570456896 run_lib.py:133] step: 53250, training_loss: 3.61394e-02
I0208 18:10:35.980952 22542570456896 run_lib.py:133] step: 53300, training_loss: 2.65176e-02
I0208 18:10:36.133295 22542570456896 run_lib.py:146] step: 53300, eval_loss: 2.89178e-02
I0208 18:10:53.717789 22542570456896 run_lib.py:133] step: 53350, training_loss: 2.67994e-02
I0208 18:11:11.172338 22542570456896 run_lib.py:133] step: 53400, training_loss: 2.81466e-02
I0208 18:11:11.340283 22542570456896 run_lib.py:146] step: 53400, eval_loss: 2.15950e-02
I0208 18:11:28.784591 22542570456896 run_lib.py:133] step: 53450, training_loss: 3.49110e-02
I0208 18:11:46.399926 22542570456896 run_lib.py:133] step: 53500, training_loss: 2.63852e-02
I0208 18:11:46.555325 22542570456896 run_lib.py:146] step: 53500, eval_loss: 2.71520e-02
I0208 18:12:04.007263 22542570456896 run_lib.py:133] step: 53550, training_loss: 2.76123e-02
I0208 18:12:21.416086 22542570456896 run_lib.py:133] step: 53600, training_loss: 3.50152e-02
I0208 18:12:21.725024 22542570456896 run_lib.py:146] step: 53600, eval_loss: 2.76912e-02
I0208 18:12:39.204199 22542570456896 run_lib.py:133] step: 53650, training_loss: 3.44015e-02
I0208 18:12:56.656049 22542570456896 run_lib.py:133] step: 53700, training_loss: 2.90649e-02
I0208 18:12:56.807586 22542570456896 run_lib.py:146] step: 53700, eval_loss: 3.68298e-02
I0208 18:13:14.215740 22542570456896 run_lib.py:133] step: 53750, training_loss: 3.33383e-02
I0208 18:13:31.681077 22542570456896 run_lib.py:133] step: 53800, training_loss: 2.77345e-02
I0208 18:13:31.836450 22542570456896 run_lib.py:146] step: 53800, eval_loss: 2.17109e-02
I0208 18:13:49.389482 22542570456896 run_lib.py:133] step: 53850, training_loss: 2.46046e-02
I0208 18:14:06.909558 22542570456896 run_lib.py:133] step: 53900, training_loss: 2.73768e-02
I0208 18:14:07.085161 22542570456896 run_lib.py:146] step: 53900, eval_loss: 2.47656e-02
I0208 18:14:24.580199 22542570456896 run_lib.py:133] step: 53950, training_loss: 3.74156e-02
I0208 18:14:42.050364 22542570456896 run_lib.py:133] step: 54000, training_loss: 3.23692e-02
I0208 18:14:42.202634 22542570456896 run_lib.py:146] step: 54000, eval_loss: 2.86539e-02
I0208 18:14:59.782594 22542570456896 run_lib.py:133] step: 54050, training_loss: 2.99950e-02
I0208 18:15:17.255523 22542570456896 run_lib.py:133] step: 54100, training_loss: 3.04946e-02
I0208 18:15:17.408803 22542570456896 run_lib.py:146] step: 54100, eval_loss: 2.77063e-02
I0208 18:15:34.864373 22542570456896 run_lib.py:133] step: 54150, training_loss: 2.76760e-02
I0208 18:15:52.322134 22542570456896 run_lib.py:133] step: 54200, training_loss: 2.70633e-02
I0208 18:15:52.477564 22542570456896 run_lib.py:146] step: 54200, eval_loss: 3.40304e-02
I0208 18:16:10.100929 22542570456896 run_lib.py:133] step: 54250, training_loss: 3.07214e-02
I0208 18:16:27.536722 22542570456896 run_lib.py:133] step: 54300, training_loss: 2.60704e-02
I0208 18:16:27.695286 22542570456896 run_lib.py:146] step: 54300, eval_loss: 3.71427e-02
I0208 18:16:45.267945 22542570456896 run_lib.py:133] step: 54350, training_loss: 2.73559e-02
I0208 18:17:02.684119 22542570456896 run_lib.py:133] step: 54400, training_loss: 3.27594e-02
I0208 18:17:02.852296 22542570456896 run_lib.py:146] step: 54400, eval_loss: 3.03760e-02
I0208 18:17:20.530271 22542570456896 run_lib.py:133] step: 54450, training_loss: 3.58154e-02
I0208 18:17:37.968051 22542570456896 run_lib.py:133] step: 54500, training_loss: 2.90781e-02
I0208 18:17:38.123689 22542570456896 run_lib.py:146] step: 54500, eval_loss: 3.48697e-02
I0208 18:17:55.548514 22542570456896 run_lib.py:133] step: 54550, training_loss: 3.81505e-02
I0208 18:18:13.125256 22542570456896 run_lib.py:133] step: 54600, training_loss: 2.81704e-02
I0208 18:18:13.283160 22542570456896 run_lib.py:146] step: 54600, eval_loss: 2.91373e-02
I0208 18:18:30.739514 22542570456896 run_lib.py:133] step: 54650, training_loss: 3.03585e-02
I0208 18:18:48.321887 22542570456896 run_lib.py:133] step: 54700, training_loss: 2.52296e-02
I0208 18:18:48.475566 22542570456896 run_lib.py:146] step: 54700, eval_loss: 3.32625e-02
I0208 18:19:05.925151 22542570456896 run_lib.py:133] step: 54750, training_loss: 2.48309e-02
I0208 18:19:23.338252 22542570456896 run_lib.py:133] step: 54800, training_loss: 2.87045e-02
I0208 18:19:23.497224 22542570456896 run_lib.py:146] step: 54800, eval_loss: 2.61832e-02
I0208 18:19:41.116205 22542570456896 run_lib.py:133] step: 54850, training_loss: 2.30534e-02
I0208 18:19:58.504587 22542570456896 run_lib.py:133] step: 54900, training_loss: 3.09088e-02
I0208 18:19:58.669314 22542570456896 run_lib.py:146] step: 54900, eval_loss: 2.90615e-02
I0208 18:20:16.102059 22542570456896 run_lib.py:133] step: 54950, training_loss: 2.90790e-02
I0208 18:20:33.596405 22542570456896 run_lib.py:133] step: 55000, training_loss: 2.80498e-02
I0208 18:20:33.754277 22542570456896 run_lib.py:146] step: 55000, eval_loss: 3.41175e-02
I0208 18:20:51.466355 22542570456896 run_lib.py:133] step: 55050, training_loss: 2.53864e-02
I0208 18:21:08.879518 22542570456896 run_lib.py:133] step: 55100, training_loss: 2.12096e-02
I0208 18:21:09.033105 22542570456896 run_lib.py:146] step: 55100, eval_loss: 3.00993e-02
I0208 18:21:26.489497 22542570456896 run_lib.py:133] step: 55150, training_loss: 3.45223e-02
I0208 18:21:43.957550 22542570456896 run_lib.py:133] step: 55200, training_loss: 3.63452e-02
I0208 18:21:44.110462 22542570456896 run_lib.py:146] step: 55200, eval_loss: 3.74369e-02
I0208 18:22:01.594172 22542570456896 run_lib.py:133] step: 55250, training_loss: 3.32865e-02
I0208 18:22:19.027178 22542570456896 run_lib.py:133] step: 55300, training_loss: 3.23351e-02
I0208 18:22:19.185343 22542570456896 run_lib.py:146] step: 55300, eval_loss: 3.15217e-02
I0208 18:22:36.761670 22542570456896 run_lib.py:133] step: 55350, training_loss: 2.56858e-02
I0208 18:22:54.249317 22542570456896 run_lib.py:133] step: 55400, training_loss: 2.68189e-02
I0208 18:22:54.404286 22542570456896 run_lib.py:146] step: 55400, eval_loss: 2.34164e-02
I0208 18:23:11.863822 22542570456896 run_lib.py:133] step: 55450, training_loss: 2.65561e-02
I0208 18:23:29.320362 22542570456896 run_lib.py:133] step: 55500, training_loss: 3.48829e-02
I0208 18:23:29.486544 22542570456896 run_lib.py:146] step: 55500, eval_loss: 2.90295e-02
I0208 18:23:47.074132 22542570456896 run_lib.py:133] step: 55550, training_loss: 2.75867e-02
I0208 18:24:04.525050 22542570456896 run_lib.py:133] step: 55600, training_loss: 3.35325e-02
I0208 18:24:04.675042 22542570456896 run_lib.py:146] step: 55600, eval_loss: 3.38956e-02
I0208 18:24:22.331553 22542570456896 run_lib.py:133] step: 55650, training_loss: 2.48681e-02
I0208 18:24:39.750346 22542570456896 run_lib.py:133] step: 55700, training_loss: 2.57044e-02
I0208 18:24:39.911380 22542570456896 run_lib.py:146] step: 55700, eval_loss: 2.54708e-02
I0208 18:24:57.441082 22542570456896 run_lib.py:133] step: 55750, training_loss: 3.15971e-02
I0208 18:25:14.839937 22542570456896 run_lib.py:133] step: 55800, training_loss: 2.69340e-02
I0208 18:25:15.019410 22542570456896 run_lib.py:146] step: 55800, eval_loss: 2.92201e-02
I0208 18:25:32.683922 22542570456896 run_lib.py:133] step: 55850, training_loss: 2.71903e-02
I0208 18:25:50.108088 22542570456896 run_lib.py:133] step: 55900, training_loss: 3.97790e-02
I0208 18:25:50.264568 22542570456896 run_lib.py:146] step: 55900, eval_loss: 2.42641e-02
I0208 18:26:07.688820 22542570456896 run_lib.py:133] step: 55950, training_loss: 2.99892e-02
I0208 18:26:25.239367 22542570456896 run_lib.py:133] step: 56000, training_loss: 2.12923e-02
I0208 18:26:25.393965 22542570456896 run_lib.py:146] step: 56000, eval_loss: 4.20373e-02
I0208 18:26:42.803589 22542570456896 run_lib.py:133] step: 56050, training_loss: 2.79932e-02
I0208 18:27:00.269752 22542570456896 run_lib.py:133] step: 56100, training_loss: 3.05892e-02
I0208 18:27:00.422569 22542570456896 run_lib.py:146] step: 56100, eval_loss: 3.05182e-02
I0208 18:27:18.051706 22542570456896 run_lib.py:133] step: 56150, training_loss: 2.85157e-02
I0208 18:27:35.650653 22542570456896 run_lib.py:133] step: 56200, training_loss: 2.64086e-02
I0208 18:27:35.806521 22542570456896 run_lib.py:146] step: 56200, eval_loss: 2.87048e-02
I0208 18:27:53.185229 22542570456896 run_lib.py:133] step: 56250, training_loss: 2.87999e-02
I0208 18:28:10.568326 22542570456896 run_lib.py:133] step: 56300, training_loss: 3.07238e-02
I0208 18:28:10.724541 22542570456896 run_lib.py:146] step: 56300, eval_loss: 2.65697e-02
I0208 18:28:28.168319 22542570456896 run_lib.py:133] step: 56350, training_loss: 2.58276e-02
I0208 18:28:45.763723 22542570456896 run_lib.py:133] step: 56400, training_loss: 2.75592e-02
I0208 18:28:45.920576 22542570456896 run_lib.py:146] step: 56400, eval_loss: 3.22144e-02
I0208 18:29:03.338593 22542570456896 run_lib.py:133] step: 56450, training_loss: 2.43021e-02
I0208 18:29:20.719416 22542570456896 run_lib.py:133] step: 56500, training_loss: 2.73884e-02
I0208 18:29:20.875312 22542570456896 run_lib.py:146] step: 56500, eval_loss: 2.67610e-02
I0208 18:29:38.291935 22542570456896 run_lib.py:133] step: 56550, training_loss: 2.99682e-02
I0208 18:29:55.897909 22542570456896 run_lib.py:133] step: 56600, training_loss: 2.87417e-02
I0208 18:29:56.050698 22542570456896 run_lib.py:146] step: 56600, eval_loss: 2.34210e-02
I0208 18:30:13.509852 22542570456896 run_lib.py:133] step: 56650, training_loss: 2.71550e-02
I0208 18:30:31.007675 22542570456896 run_lib.py:133] step: 56700, training_loss: 3.57507e-02
I0208 18:30:31.169238 22542570456896 run_lib.py:146] step: 56700, eval_loss: 3.26382e-02
I0208 18:30:48.571560 22542570456896 run_lib.py:133] step: 56750, training_loss: 2.52922e-02
I0208 18:31:06.014258 22542570456896 run_lib.py:133] step: 56800, training_loss: 2.90783e-02
I0208 18:31:06.170473 22542570456896 run_lib.py:146] step: 56800, eval_loss: 2.75910e-02
I0208 18:31:23.773732 22542570456896 run_lib.py:133] step: 56850, training_loss: 2.27867e-02
I0208 18:31:41.233618 22542570456896 run_lib.py:133] step: 56900, training_loss: 3.16076e-02
I0208 18:31:41.402287 22542570456896 run_lib.py:146] step: 56900, eval_loss: 3.07816e-02
I0208 18:31:58.876456 22542570456896 run_lib.py:133] step: 56950, training_loss: 3.24662e-02
I0208 18:32:16.374137 22542570456896 run_lib.py:133] step: 57000, training_loss: 2.97877e-02
I0208 18:32:16.528086 22542570456896 run_lib.py:146] step: 57000, eval_loss: 2.69382e-02
I0208 18:32:34.126174 22542570456896 run_lib.py:133] step: 57050, training_loss: 2.85655e-02
I0208 18:32:51.523634 22542570456896 run_lib.py:133] step: 57100, training_loss: 3.20758e-02
I0208 18:32:51.675422 22542570456896 run_lib.py:146] step: 57100, eval_loss: 3.05449e-02
I0208 18:33:09.225836 22542570456896 run_lib.py:133] step: 57150, training_loss: 3.13842e-02
I0208 18:33:26.694394 22542570456896 run_lib.py:133] step: 57200, training_loss: 2.65685e-02
I0208 18:33:26.869400 22542570456896 run_lib.py:146] step: 57200, eval_loss: 2.57190e-02
I0208 18:33:44.474925 22542570456896 run_lib.py:133] step: 57250, training_loss: 3.33476e-02
I0208 18:34:01.899900 22542570456896 run_lib.py:133] step: 57300, training_loss: 2.29880e-02
I0208 18:34:02.055618 22542570456896 run_lib.py:146] step: 57300, eval_loss: 2.78464e-02
I0208 18:34:19.460825 22542570456896 run_lib.py:133] step: 57350, training_loss: 3.05482e-02
I0208 18:34:37.009241 22542570456896 run_lib.py:133] step: 57400, training_loss: 3.60542e-02
I0208 18:34:37.164462 22542570456896 run_lib.py:146] step: 57400, eval_loss: 2.74988e-02
I0208 18:34:54.593034 22542570456896 run_lib.py:133] step: 57450, training_loss: 3.06069e-02
I0208 18:35:12.262151 22542570456896 run_lib.py:133] step: 57500, training_loss: 2.32956e-02
I0208 18:35:12.415443 22542570456896 run_lib.py:146] step: 57500, eval_loss: 4.01128e-02
I0208 18:35:29.853708 22542570456896 run_lib.py:133] step: 57550, training_loss: 3.39962e-02
I0208 18:35:47.268413 22542570456896 run_lib.py:133] step: 57600, training_loss: 3.53576e-02
I0208 18:35:47.423284 22542570456896 run_lib.py:146] step: 57600, eval_loss: 2.53335e-02
I0208 18:36:05.010407 22542570456896 run_lib.py:133] step: 57650, training_loss: 2.56691e-02
I0208 18:36:22.432342 22542570456896 run_lib.py:133] step: 57700, training_loss: 2.57649e-02
I0208 18:36:22.596531 22542570456896 run_lib.py:146] step: 57700, eval_loss: 3.11257e-02
I0208 18:36:40.032611 22542570456896 run_lib.py:133] step: 57750, training_loss: 2.84220e-02
I0208 18:36:57.602033 22542570456896 run_lib.py:133] step: 57800, training_loss: 3.50582e-02
I0208 18:36:57.768342 22542570456896 run_lib.py:146] step: 57800, eval_loss: 2.43545e-02
I0208 18:37:15.220089 22542570456896 run_lib.py:133] step: 57850, training_loss: 2.74775e-02
I0208 18:37:32.661516 22542570456896 run_lib.py:133] step: 57900, training_loss: 3.20717e-02
I0208 18:37:32.817495 22542570456896 run_lib.py:146] step: 57900, eval_loss: 2.50064e-02
I0208 18:37:50.362501 22542570456896 run_lib.py:133] step: 57950, training_loss: 3.06457e-02
I0208 18:38:07.792520 22542570456896 run_lib.py:133] step: 58000, training_loss: 2.97726e-02
I0208 18:38:07.951241 22542570456896 run_lib.py:146] step: 58000, eval_loss: 2.84865e-02
I0208 18:38:25.355656 22542570456896 run_lib.py:133] step: 58050, training_loss: 2.93745e-02
I0208 18:38:42.768970 22542570456896 run_lib.py:133] step: 58100, training_loss: 2.61518e-02
I0208 18:38:42.941879 22542570456896 run_lib.py:146] step: 58100, eval_loss: 3.08736e-02
I0208 18:39:00.568318 22542570456896 run_lib.py:133] step: 58150, training_loss: 3.55112e-02
I0208 18:39:18.110927 22542570456896 run_lib.py:133] step: 58200, training_loss: 3.25231e-02
I0208 18:39:18.280284 22542570456896 run_lib.py:146] step: 58200, eval_loss: 2.24151e-02
I0208 18:39:35.662519 22542570456896 run_lib.py:133] step: 58250, training_loss: 2.46453e-02
I0208 18:39:53.088688 22542570456896 run_lib.py:133] step: 58300, training_loss: 3.30315e-02
I0208 18:39:53.244439 22542570456896 run_lib.py:146] step: 58300, eval_loss: 2.50686e-02
I0208 18:40:10.796583 22542570456896 run_lib.py:133] step: 58350, training_loss: 2.77066e-02
I0208 18:40:28.265101 22542570456896 run_lib.py:133] step: 58400, training_loss: 3.07551e-02
I0208 18:40:28.420452 22542570456896 run_lib.py:146] step: 58400, eval_loss: 2.72936e-02
I0208 18:40:46.020363 22542570456896 run_lib.py:133] step: 58450, training_loss: 2.24383e-02
I0208 18:41:03.453451 22542570456896 run_lib.py:133] step: 58500, training_loss: 2.69860e-02
I0208 18:41:03.611017 22542570456896 run_lib.py:146] step: 58500, eval_loss: 3.17491e-02
I0208 18:41:21.211691 22542570456896 run_lib.py:133] step: 58550, training_loss: 2.66141e-02
I0208 18:41:38.670009 22542570456896 run_lib.py:133] step: 58600, training_loss: 3.02220e-02
I0208 18:41:38.828577 22542570456896 run_lib.py:146] step: 58600, eval_loss: 2.95557e-02
I0208 18:41:56.368236 22542570456896 run_lib.py:133] step: 58650, training_loss: 2.97210e-02
I0208 18:42:13.829372 22542570456896 run_lib.py:133] step: 58700, training_loss: 3.09269e-02
I0208 18:42:13.996264 22542570456896 run_lib.py:146] step: 58700, eval_loss: 2.97149e-02
I0208 18:42:31.445058 22542570456896 run_lib.py:133] step: 58750, training_loss: 3.08886e-02
I0208 18:42:49.065991 22542570456896 run_lib.py:133] step: 58800, training_loss: 3.40599e-02
I0208 18:42:49.225346 22542570456896 run_lib.py:146] step: 58800, eval_loss: 3.10813e-02
I0208 18:43:06.657455 22542570456896 run_lib.py:133] step: 58850, training_loss: 3.54624e-02
I0208 18:43:24.071936 22542570456896 run_lib.py:133] step: 58900, training_loss: 2.48370e-02
I0208 18:43:24.227066 22542570456896 run_lib.py:146] step: 58900, eval_loss: 2.98802e-02
I0208 18:43:41.815992 22542570456896 run_lib.py:133] step: 58950, training_loss: 2.55435e-02
I0208 18:43:59.272017 22542570456896 run_lib.py:133] step: 59000, training_loss: 2.64350e-02
I0208 18:43:59.430613 22542570456896 run_lib.py:146] step: 59000, eval_loss: 2.68906e-02
I0208 18:44:17.050863 22542570456896 run_lib.py:133] step: 59050, training_loss: 2.80085e-02
I0208 18:44:34.506089 22542570456896 run_lib.py:133] step: 59100, training_loss: 2.31710e-02
I0208 18:44:34.664247 22542570456896 run_lib.py:146] step: 59100, eval_loss: 3.14140e-02
I0208 18:44:52.064730 22542570456896 run_lib.py:133] step: 59150, training_loss: 2.71656e-02
I0208 18:45:09.541904 22542570456896 run_lib.py:133] step: 59200, training_loss: 3.22164e-02
I0208 18:45:09.695787 22542570456896 run_lib.py:146] step: 59200, eval_loss: 3.08228e-02
I0208 18:45:27.079595 22542570456896 run_lib.py:133] step: 59250, training_loss: 2.81799e-02
I0208 18:45:44.449321 22542570456896 run_lib.py:133] step: 59300, training_loss: 2.85028e-02
I0208 18:45:44.607640 22542570456896 run_lib.py:146] step: 59300, eval_loss: 2.21438e-02
I0208 18:46:02.005257 22542570456896 run_lib.py:133] step: 59350, training_loss: 3.05583e-02
I0208 18:46:19.605643 22542570456896 run_lib.py:133] step: 59400, training_loss: 3.33552e-02
I0208 18:46:19.758270 22542570456896 run_lib.py:146] step: 59400, eval_loss: 2.33487e-02
I0208 18:46:37.178788 22542570456896 run_lib.py:133] step: 59450, training_loss: 3.29562e-02
I0208 18:46:54.668685 22542570456896 run_lib.py:133] step: 59500, training_loss: 2.77675e-02
I0208 18:46:54.823641 22542570456896 run_lib.py:146] step: 59500, eval_loss: 2.44908e-02
I0208 18:47:12.298947 22542570456896 run_lib.py:133] step: 59550, training_loss: 3.05560e-02
I0208 18:47:29.770202 22542570456896 run_lib.py:133] step: 59600, training_loss: 2.69196e-02
I0208 18:47:29.930424 22542570456896 run_lib.py:146] step: 59600, eval_loss: 2.79251e-02
I0208 18:47:47.526789 22542570456896 run_lib.py:133] step: 59650, training_loss: 2.53731e-02
I0208 18:48:05.003355 22542570456896 run_lib.py:133] step: 59700, training_loss: 2.57071e-02
I0208 18:48:05.159312 22542570456896 run_lib.py:146] step: 59700, eval_loss: 2.64200e-02
I0208 18:48:22.626200 22542570456896 run_lib.py:133] step: 59750, training_loss: 2.89455e-02
I0208 18:48:40.033746 22542570456896 run_lib.py:133] step: 59800, training_loss: 2.76504e-02
I0208 18:48:40.194339 22542570456896 run_lib.py:146] step: 59800, eval_loss: 3.50242e-02
I0208 18:48:57.811583 22542570456896 run_lib.py:133] step: 59850, training_loss: 2.32238e-02
I0208 18:49:15.278756 22542570456896 run_lib.py:133] step: 59900, training_loss: 2.67063e-02
I0208 18:49:15.432839 22542570456896 run_lib.py:146] step: 59900, eval_loss: 3.53800e-02
I0208 18:49:33.049140 22542570456896 run_lib.py:133] step: 59950, training_loss: 3.00901e-02
I0208 18:49:50.469067 22542570456896 run_lib.py:133] step: 60000, training_loss: 3.62954e-02
I0208 18:49:51.168140 22542570456896 run_lib.py:146] step: 60000, eval_loss: 2.97753e-02
I0208 18:50:11.348218 22542570456896 run_lib.py:133] step: 60050, training_loss: 2.91256e-02
I0208 18:50:28.770195 22542570456896 run_lib.py:133] step: 60100, training_loss: 2.76772e-02
I0208 18:50:28.941638 22542570456896 run_lib.py:146] step: 60100, eval_loss: 3.08609e-02
I0208 18:50:46.514381 22542570456896 run_lib.py:133] step: 60150, training_loss: 3.81318e-02
I0208 18:51:03.980051 22542570456896 run_lib.py:133] step: 60200, training_loss: 2.59973e-02
I0208 18:51:04.136615 22542570456896 run_lib.py:146] step: 60200, eval_loss: 3.16776e-02
I0208 18:51:21.588563 22542570456896 run_lib.py:133] step: 60250, training_loss: 2.87107e-02
I0208 18:51:39.013362 22542570456896 run_lib.py:133] step: 60300, training_loss: 3.34189e-02
I0208 18:51:39.168368 22542570456896 run_lib.py:146] step: 60300, eval_loss: 2.56854e-02
I0208 18:51:56.749839 22542570456896 run_lib.py:133] step: 60350, training_loss: 3.08652e-02
I0208 18:52:14.309723 22542570456896 run_lib.py:133] step: 60400, training_loss: 3.24400e-02
I0208 18:52:14.472161 22542570456896 run_lib.py:146] step: 60400, eval_loss: 3.13203e-02
I0208 18:52:31.935242 22542570456896 run_lib.py:133] step: 60450, training_loss: 2.79493e-02
I0208 18:52:49.346158 22542570456896 run_lib.py:133] step: 60500, training_loss: 2.80099e-02
I0208 18:52:49.510284 22542570456896 run_lib.py:146] step: 60500, eval_loss: 2.69344e-02
I0208 18:53:07.036256 22542570456896 run_lib.py:133] step: 60550, training_loss: 2.69310e-02
I0208 18:53:24.460854 22542570456896 run_lib.py:133] step: 60600, training_loss: 2.59921e-02
I0208 18:53:24.626282 22542570456896 run_lib.py:146] step: 60600, eval_loss: 3.28923e-02
I0208 18:53:42.240586 22542570456896 run_lib.py:133] step: 60650, training_loss: 2.76630e-02
I0208 18:53:59.691008 22542570456896 run_lib.py:133] step: 60700, training_loss: 2.45724e-02
I0208 18:53:59.846459 22542570456896 run_lib.py:146] step: 60700, eval_loss: 3.14894e-02
I0208 18:54:17.437901 22542570456896 run_lib.py:133] step: 60750, training_loss: 3.22484e-02
I0208 18:54:34.850250 22542570456896 run_lib.py:133] step: 60800, training_loss: 2.33537e-02
I0208 18:54:35.006638 22542570456896 run_lib.py:146] step: 60800, eval_loss: 3.38578e-02
I0208 18:54:52.447869 22542570456896 run_lib.py:133] step: 60850, training_loss: 2.65032e-02
I0208 18:55:10.057719 22542570456896 run_lib.py:133] step: 60900, training_loss: 3.32306e-02
I0208 18:55:10.211588 22542570456896 run_lib.py:146] step: 60900, eval_loss: 2.64163e-02
I0208 18:55:27.690208 22542570456896 run_lib.py:133] step: 60950, training_loss: 2.62427e-02
I0208 18:55:45.294376 22542570456896 run_lib.py:133] step: 61000, training_loss: 2.99783e-02
I0208 18:55:45.447866 22542570456896 run_lib.py:146] step: 61000, eval_loss: 3.83025e-02
I0208 18:56:02.852924 22542570456896 run_lib.py:133] step: 61050, training_loss: 2.22554e-02
I0208 18:56:20.285464 22542570456896 run_lib.py:133] step: 61100, training_loss: 2.75067e-02
I0208 18:56:20.444742 22542570456896 run_lib.py:146] step: 61100, eval_loss: 3.33805e-02
I0208 18:56:38.019851 22542570456896 run_lib.py:133] step: 61150, training_loss: 3.82535e-02
I0208 18:56:55.478523 22542570456896 run_lib.py:133] step: 61200, training_loss: 3.59092e-02
I0208 18:56:55.634350 22542570456896 run_lib.py:146] step: 61200, eval_loss: 2.70731e-02
I0208 18:57:13.056407 22542570456896 run_lib.py:133] step: 61250, training_loss: 3.19220e-02
I0208 18:57:30.686512 22542570456896 run_lib.py:133] step: 61300, training_loss: 3.29990e-02
I0208 18:57:30.841298 22542570456896 run_lib.py:146] step: 61300, eval_loss: 3.33584e-02
I0208 18:57:48.269553 22542570456896 run_lib.py:133] step: 61350, training_loss: 2.31025e-02
I0208 18:58:05.693904 22542570456896 run_lib.py:133] step: 61400, training_loss: 3.05476e-02
I0208 18:58:05.991333 22542570456896 run_lib.py:146] step: 61400, eval_loss: 3.40130e-02
I0208 18:58:23.410582 22542570456896 run_lib.py:133] step: 61450, training_loss: 2.55570e-02
I0208 18:58:40.831565 22542570456896 run_lib.py:133] step: 61500, training_loss: 2.23567e-02
I0208 18:58:41.000398 22542570456896 run_lib.py:146] step: 61500, eval_loss: 2.84952e-02
I0208 18:58:58.505450 22542570456896 run_lib.py:133] step: 61550, training_loss: 2.22524e-02
I0208 18:59:15.973528 22542570456896 run_lib.py:133] step: 61600, training_loss: 3.53526e-02
I0208 18:59:16.130463 22542570456896 run_lib.py:146] step: 61600, eval_loss: 3.15735e-02
I0208 18:59:33.725067 22542570456896 run_lib.py:133] step: 61650, training_loss: 2.63956e-02
I0208 18:59:51.209412 22542570456896 run_lib.py:133] step: 61700, training_loss: 2.86283e-02
I0208 18:59:51.372470 22542570456896 run_lib.py:146] step: 61700, eval_loss: 3.23980e-02
I0208 19:00:08.807690 22542570456896 run_lib.py:133] step: 61750, training_loss: 3.61901e-02
I0208 19:00:26.261790 22542570456896 run_lib.py:133] step: 61800, training_loss: 3.23018e-02
I0208 19:00:26.417675 22542570456896 run_lib.py:146] step: 61800, eval_loss: 2.72602e-02
I0208 19:00:44.064758 22542570456896 run_lib.py:133] step: 61850, training_loss: 3.37457e-02
I0208 19:01:01.576482 22542570456896 run_lib.py:133] step: 61900, training_loss: 2.98324e-02
I0208 19:01:01.729390 22542570456896 run_lib.py:146] step: 61900, eval_loss: 3.17307e-02
I0208 19:01:19.143340 22542570456896 run_lib.py:133] step: 61950, training_loss: 2.75066e-02
I0208 19:01:36.554244 22542570456896 run_lib.py:133] step: 62000, training_loss: 3.12470e-02
I0208 19:01:36.713530 22542570456896 run_lib.py:146] step: 62000, eval_loss: 3.26576e-02
I0208 19:01:54.306150 22542570456896 run_lib.py:133] step: 62050, training_loss: 3.05194e-02
I0208 19:02:11.781392 22542570456896 run_lib.py:133] step: 62100, training_loss: 2.51434e-02
I0208 19:02:11.938635 22542570456896 run_lib.py:146] step: 62100, eval_loss: 3.07865e-02
I0208 19:02:29.535658 22542570456896 run_lib.py:133] step: 62150, training_loss: 3.46706e-02
I0208 19:02:46.965116 22542570456896 run_lib.py:133] step: 62200, training_loss: 2.59452e-02
I0208 19:02:47.121967 22542570456896 run_lib.py:146] step: 62200, eval_loss: 2.63038e-02
I0208 19:03:04.687238 22542570456896 run_lib.py:133] step: 62250, training_loss: 3.24039e-02
I0208 19:03:22.173918 22542570456896 run_lib.py:133] step: 62300, training_loss: 2.47455e-02
I0208 19:03:22.331629 22542570456896 run_lib.py:146] step: 62300, eval_loss: 3.32397e-02
I0208 19:03:39.805504 22542570456896 run_lib.py:133] step: 62350, training_loss: 2.57502e-02
I0208 19:03:57.436598 22542570456896 run_lib.py:133] step: 62400, training_loss: 2.49452e-02
I0208 19:03:57.591495 22542570456896 run_lib.py:146] step: 62400, eval_loss: 2.24661e-02
I0208 19:04:15.007437 22542570456896 run_lib.py:133] step: 62450, training_loss: 2.82103e-02
I0208 19:04:32.571050 22542570456896 run_lib.py:133] step: 62500, training_loss: 3.63363e-02
I0208 19:04:32.729487 22542570456896 run_lib.py:146] step: 62500, eval_loss: 2.60783e-02
I0208 19:04:50.208966 22542570456896 run_lib.py:133] step: 62550, training_loss: 3.15585e-02
I0208 19:05:07.681493 22542570456896 run_lib.py:133] step: 62600, training_loss: 2.95489e-02
I0208 19:05:07.837553 22542570456896 run_lib.py:146] step: 62600, eval_loss: 2.63387e-02
I0208 19:05:25.464891 22542570456896 run_lib.py:133] step: 62650, training_loss: 3.44580e-02
I0208 19:05:42.876029 22542570456896 run_lib.py:133] step: 62700, training_loss: 2.66700e-02
I0208 19:05:43.034004 22542570456896 run_lib.py:146] step: 62700, eval_loss: 3.13505e-02
I0208 19:06:00.432854 22542570456896 run_lib.py:133] step: 62750, training_loss: 2.80603e-02
I0208 19:06:17.868441 22542570456896 run_lib.py:133] step: 62800, training_loss: 3.26663e-02
I0208 19:06:18.019464 22542570456896 run_lib.py:146] step: 62800, eval_loss: 3.17748e-02
I0208 19:06:35.634994 22542570456896 run_lib.py:133] step: 62850, training_loss: 2.87491e-02
I0208 19:06:53.068662 22542570456896 run_lib.py:133] step: 62900, training_loss: 2.72671e-02
I0208 19:06:53.234793 22542570456896 run_lib.py:146] step: 62900, eval_loss: 3.76411e-02
I0208 19:07:10.761916 22542570456896 run_lib.py:133] step: 62950, training_loss: 2.74606e-02
I0208 19:07:28.200281 22542570456896 run_lib.py:133] step: 63000, training_loss: 3.08034e-02
I0208 19:07:28.357752 22542570456896 run_lib.py:146] step: 63000, eval_loss: 2.95931e-02
I0208 19:07:45.786417 22542570456896 run_lib.py:133] step: 63050, training_loss: 3.35824e-02
I0208 19:08:03.213432 22542570456896 run_lib.py:133] step: 63100, training_loss: 3.68180e-02
I0208 19:08:03.376713 22542570456896 run_lib.py:146] step: 63100, eval_loss: 2.37082e-02
I0208 19:08:20.979611 22542570456896 run_lib.py:133] step: 63150, training_loss: 3.07255e-02
I0208 19:08:38.550709 22542570456896 run_lib.py:133] step: 63200, training_loss: 2.63693e-02
I0208 19:08:38.706690 22542570456896 run_lib.py:146] step: 63200, eval_loss: 3.41469e-02
I0208 19:08:56.139514 22542570456896 run_lib.py:133] step: 63250, training_loss: 2.16482e-02
I0208 19:09:13.546090 22542570456896 run_lib.py:133] step: 63300, training_loss: 3.20217e-02
I0208 19:09:13.696610 22542570456896 run_lib.py:146] step: 63300, eval_loss: 2.46415e-02
I0208 19:09:31.259735 22542570456896 run_lib.py:133] step: 63350, training_loss: 3.54140e-02
I0208 19:09:48.731362 22542570456896 run_lib.py:133] step: 63400, training_loss: 2.53314e-02
I0208 19:09:48.899083 22542570456896 run_lib.py:146] step: 63400, eval_loss: 2.72657e-02
I0208 19:10:06.520889 22542570456896 run_lib.py:133] step: 63450, training_loss: 2.60562e-02
I0208 19:10:23.992640 22542570456896 run_lib.py:133] step: 63500, training_loss: 2.78810e-02
I0208 19:10:24.148507 22542570456896 run_lib.py:146] step: 63500, eval_loss: 2.67023e-02
I0208 19:10:41.742480 22542570456896 run_lib.py:133] step: 63550, training_loss: 3.09374e-02
I0208 19:10:59.162129 22542570456896 run_lib.py:133] step: 63600, training_loss: 2.96038e-02
I0208 19:10:59.317224 22542570456896 run_lib.py:146] step: 63600, eval_loss: 2.33455e-02
I0208 19:11:16.892287 22542570456896 run_lib.py:133] step: 63650, training_loss: 3.03462e-02
I0208 19:11:34.321998 22542570456896 run_lib.py:133] step: 63700, training_loss: 3.09018e-02
I0208 19:11:34.473536 22542570456896 run_lib.py:146] step: 63700, eval_loss: 2.36482e-02
I0208 19:11:51.963599 22542570456896 run_lib.py:133] step: 63750, training_loss: 2.94811e-02
I0208 19:12:09.575375 22542570456896 run_lib.py:133] step: 63800, training_loss: 3.41110e-02
I0208 19:12:09.735878 22542570456896 run_lib.py:146] step: 63800, eval_loss: 2.50653e-02
I0208 19:12:27.133461 22542570456896 run_lib.py:133] step: 63850, training_loss: 3.89533e-02
I0208 19:12:44.535896 22542570456896 run_lib.py:133] step: 63900, training_loss: 3.39032e-02
I0208 19:12:44.694225 22542570456896 run_lib.py:146] step: 63900, eval_loss: 3.15974e-02
I0208 19:13:02.223526 22542570456896 run_lib.py:133] step: 63950, training_loss: 2.91699e-02
I0208 19:13:19.852869 22542570456896 run_lib.py:133] step: 64000, training_loss: 2.88975e-02
I0208 19:13:20.013574 22542570456896 run_lib.py:146] step: 64000, eval_loss: 2.39751e-02
I0208 19:13:37.479789 22542570456896 run_lib.py:133] step: 64050, training_loss: 3.18078e-02
I0208 19:13:54.906590 22542570456896 run_lib.py:133] step: 64100, training_loss: 2.51189e-02
I0208 19:13:55.062114 22542570456896 run_lib.py:146] step: 64100, eval_loss: 2.45061e-02
I0208 19:14:12.478673 22542570456896 run_lib.py:133] step: 64150, training_loss: 2.47274e-02
I0208 19:14:30.093809 22542570456896 run_lib.py:133] step: 64200, training_loss: 2.95767e-02
I0208 19:14:30.245109 22542570456896 run_lib.py:146] step: 64200, eval_loss: 2.72096e-02
I0208 19:14:47.663039 22542570456896 run_lib.py:133] step: 64250, training_loss: 2.54353e-02
I0208 19:15:05.115189 22542570456896 run_lib.py:133] step: 64300, training_loss: 2.31747e-02
I0208 19:15:05.282627 22542570456896 run_lib.py:146] step: 64300, eval_loss: 3.36094e-02
I0208 19:15:22.696877 22542570456896 run_lib.py:133] step: 64350, training_loss: 3.01103e-02
I0208 19:15:40.341993 22542570456896 run_lib.py:133] step: 64400, training_loss: 2.16030e-02
I0208 19:15:40.500559 22542570456896 run_lib.py:146] step: 64400, eval_loss: 3.03227e-02
I0208 19:15:57.912814 22542570456896 run_lib.py:133] step: 64450, training_loss: 2.97687e-02
I0208 19:16:15.373929 22542570456896 run_lib.py:133] step: 64500, training_loss: 2.96293e-02
I0208 19:16:15.547350 22542570456896 run_lib.py:146] step: 64500, eval_loss: 2.67988e-02
I0208 19:16:32.970588 22542570456896 run_lib.py:133] step: 64550, training_loss: 2.31637e-02
I0208 19:16:50.448327 22542570456896 run_lib.py:133] step: 64600, training_loss: 3.01165e-02
I0208 19:16:50.611967 22542570456896 run_lib.py:146] step: 64600, eval_loss: 2.59926e-02
I0208 19:17:08.243424 22542570456896 run_lib.py:133] step: 64650, training_loss: 2.73445e-02
I0208 19:17:25.757310 22542570456896 run_lib.py:133] step: 64700, training_loss: 3.15543e-02
I0208 19:17:25.911314 22542570456896 run_lib.py:146] step: 64700, eval_loss: 3.21085e-02
I0208 19:17:43.321600 22542570456896 run_lib.py:133] step: 64750, training_loss: 2.20153e-02
I0208 19:18:00.734274 22542570456896 run_lib.py:133] step: 64800, training_loss: 2.89598e-02
I0208 19:18:00.911323 22542570456896 run_lib.py:146] step: 64800, eval_loss: 2.01793e-02
I0208 19:18:18.569289 22542570456896 run_lib.py:133] step: 64850, training_loss: 2.75576e-02
I0208 19:18:35.993767 22542570456896 run_lib.py:133] step: 64900, training_loss: 2.98560e-02
I0208 19:18:36.151503 22542570456896 run_lib.py:146] step: 64900, eval_loss: 3.58146e-02
I0208 19:18:53.716983 22542570456896 run_lib.py:133] step: 64950, training_loss: 3.57939e-02
I0208 19:19:11.125257 22542570456896 run_lib.py:133] step: 65000, training_loss: 2.79282e-02
I0208 19:19:11.281350 22542570456896 run_lib.py:146] step: 65000, eval_loss: 2.41778e-02
I0208 19:19:28.863715 22542570456896 run_lib.py:133] step: 65050, training_loss: 3.08267e-02
I0208 19:19:46.337864 22542570456896 run_lib.py:133] step: 65100, training_loss: 2.80159e-02
I0208 19:19:46.499800 22542570456896 run_lib.py:146] step: 65100, eval_loss: 3.22815e-02
I0208 19:20:03.960599 22542570456896 run_lib.py:133] step: 65150, training_loss: 3.17813e-02
I0208 19:20:21.579590 22542570456896 run_lib.py:133] step: 65200, training_loss: 2.62165e-02
I0208 19:20:21.736369 22542570456896 run_lib.py:146] step: 65200, eval_loss: 2.96499e-02
I0208 19:20:39.173730 22542570456896 run_lib.py:133] step: 65250, training_loss: 2.87271e-02
I0208 19:20:56.730841 22542570456896 run_lib.py:133] step: 65300, training_loss: 2.85602e-02
I0208 19:20:56.888124 22542570456896 run_lib.py:146] step: 65300, eval_loss: 3.12919e-02
I0208 19:21:14.316796 22542570456896 run_lib.py:133] step: 65350, training_loss: 3.34062e-02
I0208 19:21:31.810689 22542570456896 run_lib.py:133] step: 65400, training_loss: 3.36320e-02
I0208 19:21:31.968318 22542570456896 run_lib.py:146] step: 65400, eval_loss: 2.47401e-02
I0208 19:21:49.556754 22542570456896 run_lib.py:133] step: 65450, training_loss: 2.82145e-02
I0208 19:22:06.950272 22542570456896 run_lib.py:133] step: 65500, training_loss: 2.61990e-02
I0208 19:22:07.106492 22542570456896 run_lib.py:146] step: 65500, eval_loss: 3.04552e-02
I0208 19:22:24.530340 22542570456896 run_lib.py:133] step: 65550, training_loss: 2.56393e-02
I0208 19:22:42.093540 22542570456896 run_lib.py:133] step: 65600, training_loss: 3.31753e-02
I0208 19:22:42.247489 22542570456896 run_lib.py:146] step: 65600, eval_loss: 3.28467e-02
I0208 19:22:59.686032 22542570456896 run_lib.py:133] step: 65650, training_loss: 2.94407e-02
I0208 19:23:17.132509 22542570456896 run_lib.py:133] step: 65700, training_loss: 2.99489e-02
I0208 19:23:17.291573 22542570456896 run_lib.py:146] step: 65700, eval_loss: 2.55234e-02
I0208 19:23:34.820536 22542570456896 run_lib.py:133] step: 65750, training_loss: 3.24652e-02
I0208 19:23:52.291620 22542570456896 run_lib.py:133] step: 65800, training_loss: 2.87235e-02
I0208 19:23:52.451494 22542570456896 run_lib.py:146] step: 65800, eval_loss: 3.86934e-02
I0208 19:24:09.858167 22542570456896 run_lib.py:133] step: 65850, training_loss: 3.48894e-02
I0208 19:24:27.258952 22542570456896 run_lib.py:133] step: 65900, training_loss: 3.10669e-02
I0208 19:24:27.429229 22542570456896 run_lib.py:146] step: 65900, eval_loss: 2.61891e-02
I0208 19:24:45.023877 22542570456896 run_lib.py:133] step: 65950, training_loss: 3.32556e-02
I0208 19:25:02.576106 22542570456896 run_lib.py:133] step: 66000, training_loss: 3.25764e-02
I0208 19:25:02.736216 22542570456896 run_lib.py:146] step: 66000, eval_loss: 2.85940e-02
I0208 19:25:20.177385 22542570456896 run_lib.py:133] step: 66050, training_loss: 2.82597e-02
I0208 19:25:37.612100 22542570456896 run_lib.py:133] step: 66100, training_loss: 3.08401e-02
I0208 19:25:37.767258 22542570456896 run_lib.py:146] step: 66100, eval_loss: 2.91251e-02
I0208 19:25:55.328515 22542570456896 run_lib.py:133] step: 66150, training_loss: 2.20057e-02
I0208 19:26:12.769896 22542570456896 run_lib.py:133] step: 66200, training_loss: 2.92245e-02
I0208 19:26:12.939529 22542570456896 run_lib.py:146] step: 66200, eval_loss: 2.21185e-02
I0208 19:26:30.563349 22542570456896 run_lib.py:133] step: 66250, training_loss: 2.57067e-02
I0208 19:26:48.031734 22542570456896 run_lib.py:133] step: 66300, training_loss: 2.56719e-02
I0208 19:26:48.192323 22542570456896 run_lib.py:146] step: 66300, eval_loss: 3.55814e-02
I0208 19:27:05.801435 22542570456896 run_lib.py:133] step: 66350, training_loss: 2.56720e-02
I0208 19:27:23.212812 22542570456896 run_lib.py:133] step: 66400, training_loss: 3.45223e-02
I0208 19:27:23.368350 22542570456896 run_lib.py:146] step: 66400, eval_loss: 3.26357e-02
I0208 19:27:40.927323 22542570456896 run_lib.py:133] step: 66450, training_loss: 2.81846e-02
I0208 19:27:58.396373 22542570456896 run_lib.py:133] step: 66500, training_loss: 2.99311e-02
I0208 19:27:58.553704 22542570456896 run_lib.py:146] step: 66500, eval_loss: 2.66746e-02
I0208 19:28:16.022030 22542570456896 run_lib.py:133] step: 66550, training_loss: 2.96648e-02
I0208 19:28:33.674509 22542570456896 run_lib.py:133] step: 66600, training_loss: 2.79401e-02
I0208 19:28:33.831343 22542570456896 run_lib.py:146] step: 66600, eval_loss: 2.66959e-02
I0208 19:28:51.304181 22542570456896 run_lib.py:133] step: 66650, training_loss: 2.70460e-02
I0208 19:29:08.742097 22542570456896 run_lib.py:133] step: 66700, training_loss: 2.56898e-02
I0208 19:29:08.898448 22542570456896 run_lib.py:146] step: 66700, eval_loss: 3.17619e-02
I0208 19:29:26.481091 22542570456896 run_lib.py:133] step: 66750, training_loss: 2.81474e-02
I0208 19:29:43.955963 22542570456896 run_lib.py:133] step: 66800, training_loss: 3.12724e-02
I0208 19:29:44.119220 22542570456896 run_lib.py:146] step: 66800, eval_loss: 2.56664e-02
I0208 19:30:01.794145 22542570456896 run_lib.py:133] step: 66850, training_loss: 3.14423e-02
I0208 19:30:19.236052 22542570456896 run_lib.py:133] step: 66900, training_loss: 3.10825e-02
I0208 19:30:19.393421 22542570456896 run_lib.py:146] step: 66900, eval_loss: 2.76239e-02
I0208 19:30:36.832818 22542570456896 run_lib.py:133] step: 66950, training_loss: 2.87578e-02
I0208 19:30:54.399053 22542570456896 run_lib.py:133] step: 67000, training_loss: 2.84998e-02
I0208 19:30:54.556368 22542570456896 run_lib.py:146] step: 67000, eval_loss: 2.84909e-02
I0208 19:31:11.987103 22542570456896 run_lib.py:133] step: 67050, training_loss: 3.60449e-02
I0208 19:31:29.435328 22542570456896 run_lib.py:133] step: 67100, training_loss: 3.04440e-02
I0208 19:31:29.589990 22542570456896 run_lib.py:146] step: 67100, eval_loss: 2.59449e-02
I0208 19:31:47.068657 22542570456896 run_lib.py:133] step: 67150, training_loss: 2.30194e-02
I0208 19:32:04.708114 22542570456896 run_lib.py:133] step: 67200, training_loss: 3.28204e-02
I0208 19:32:04.867524 22542570456896 run_lib.py:146] step: 67200, eval_loss: 2.73036e-02
I0208 19:32:22.268628 22542570456896 run_lib.py:133] step: 67250, training_loss: 2.75903e-02
I0208 19:32:39.768770 22542570456896 run_lib.py:133] step: 67300, training_loss: 3.14788e-02
I0208 19:32:39.941649 22542570456896 run_lib.py:146] step: 67300, eval_loss: 3.47926e-02
I0208 19:32:57.419411 22542570456896 run_lib.py:133] step: 67350, training_loss: 2.31478e-02
I0208 19:33:14.837569 22542570456896 run_lib.py:133] step: 67400, training_loss: 3.46763e-02
I0208 19:33:14.998112 22542570456896 run_lib.py:146] step: 67400, eval_loss: 3.06275e-02
I0208 19:33:32.586702 22542570456896 run_lib.py:133] step: 67450, training_loss: 2.30721e-02
I0208 19:33:50.048250 22542570456896 run_lib.py:133] step: 67500, training_loss: 2.82780e-02
I0208 19:33:50.202065 22542570456896 run_lib.py:146] step: 67500, eval_loss: 3.80622e-02
I0208 19:34:07.672325 22542570456896 run_lib.py:133] step: 67550, training_loss: 2.68564e-02
I0208 19:34:25.165362 22542570456896 run_lib.py:133] step: 67600, training_loss: 2.59334e-02
I0208 19:34:25.322497 22542570456896 run_lib.py:146] step: 67600, eval_loss: 4.14884e-02
I0208 19:34:42.967607 22542570456896 run_lib.py:133] step: 67650, training_loss: 2.26474e-02
I0208 19:35:00.415039 22542570456896 run_lib.py:133] step: 67700, training_loss: 3.44918e-02
I0208 19:35:00.571437 22542570456896 run_lib.py:146] step: 67700, eval_loss: 2.61938e-02
I0208 19:35:18.133436 22542570456896 run_lib.py:133] step: 67750, training_loss: 3.08684e-02
I0208 19:35:35.595211 22542570456896 run_lib.py:133] step: 67800, training_loss: 3.53709e-02
I0208 19:35:35.750306 22542570456896 run_lib.py:146] step: 67800, eval_loss: 2.98912e-02
I0208 19:35:53.313740 22542570456896 run_lib.py:133] step: 67850, training_loss: 2.71210e-02
I0208 19:36:10.855878 22542570456896 run_lib.py:133] step: 67900, training_loss: 2.34809e-02
I0208 19:36:11.014167 22542570456896 run_lib.py:146] step: 67900, eval_loss: 2.27336e-02
I0208 19:36:28.462995 22542570456896 run_lib.py:133] step: 67950, training_loss: 3.82295e-02
I0208 19:36:46.100560 22542570456896 run_lib.py:133] step: 68000, training_loss: 2.93570e-02
I0208 19:36:46.253375 22542570456896 run_lib.py:146] step: 68000, eval_loss: 3.17730e-02
I0208 19:37:03.669210 22542570456896 run_lib.py:133] step: 68050, training_loss: 2.20313e-02
I0208 19:37:21.225172 22542570456896 run_lib.py:133] step: 68100, training_loss: 3.51390e-02
I0208 19:37:21.392536 22542570456896 run_lib.py:146] step: 68100, eval_loss: 3.23989e-02
I0208 19:37:38.868948 22542570456896 run_lib.py:133] step: 68150, training_loss: 3.52411e-02
I0208 19:37:56.341154 22542570456896 run_lib.py:133] step: 68200, training_loss: 2.47993e-02
I0208 19:37:56.501439 22542570456896 run_lib.py:146] step: 68200, eval_loss: 2.80346e-02
I0208 19:38:14.108569 22542570456896 run_lib.py:133] step: 68250, training_loss: 3.19938e-02
I0208 19:38:31.548085 22542570456896 run_lib.py:133] step: 68300, training_loss: 2.91820e-02
I0208 19:38:31.704346 22542570456896 run_lib.py:146] step: 68300, eval_loss: 2.73538e-02
I0208 19:38:49.134433 22542570456896 run_lib.py:133] step: 68350, training_loss: 2.29957e-02
I0208 19:39:06.707553 22542570456896 run_lib.py:133] step: 68400, training_loss: 2.30380e-02
I0208 19:39:06.869209 22542570456896 run_lib.py:146] step: 68400, eval_loss: 2.10526e-02
I0208 19:39:24.348701 22542570456896 run_lib.py:133] step: 68450, training_loss: 2.65804e-02
I0208 19:39:41.758898 22542570456896 run_lib.py:133] step: 68500, training_loss: 3.42659e-02
I0208 19:39:42.096349 22542570456896 run_lib.py:146] step: 68500, eval_loss: 2.64444e-02
I0208 19:39:59.540139 22542570456896 run_lib.py:133] step: 68550, training_loss: 2.61998e-02
I0208 19:40:16.975595 22542570456896 run_lib.py:133] step: 68600, training_loss: 2.63054e-02
I0208 19:40:17.129381 22542570456896 run_lib.py:146] step: 68600, eval_loss: 2.70124e-02
I0208 19:40:34.565885 22542570456896 run_lib.py:133] step: 68650, training_loss: 2.55949e-02
I0208 19:40:52.044207 22542570456896 run_lib.py:133] step: 68700, training_loss: 2.34100e-02
I0208 19:40:52.205199 22542570456896 run_lib.py:146] step: 68700, eval_loss: 2.24553e-02
I0208 19:41:09.810864 22542570456896 run_lib.py:133] step: 68750, training_loss: 3.39405e-02
I0208 19:41:27.294372 22542570456896 run_lib.py:133] step: 68800, training_loss: 3.01746e-02
I0208 19:41:27.453266 22542570456896 run_lib.py:146] step: 68800, eval_loss: 2.66922e-02
I0208 19:41:44.865199 22542570456896 run_lib.py:133] step: 68850, training_loss: 2.81491e-02
I0208 19:42:02.313276 22542570456896 run_lib.py:133] step: 68900, training_loss: 3.08510e-02
I0208 19:42:02.464472 22542570456896 run_lib.py:146] step: 68900, eval_loss: 3.47222e-02
I0208 19:42:20.061797 22542570456896 run_lib.py:133] step: 68950, training_loss: 2.68547e-02
I0208 19:42:37.600913 22542570456896 run_lib.py:133] step: 69000, training_loss: 2.97819e-02
I0208 19:42:37.757472 22542570456896 run_lib.py:146] step: 69000, eval_loss: 2.37277e-02
I0208 19:42:55.209685 22542570456896 run_lib.py:133] step: 69050, training_loss: 2.23423e-02
I0208 19:43:12.679670 22542570456896 run_lib.py:133] step: 69100, training_loss: 2.66500e-02
I0208 19:43:12.847504 22542570456896 run_lib.py:146] step: 69100, eval_loss: 2.58774e-02
I0208 19:43:30.386480 22542570456896 run_lib.py:133] step: 69150, training_loss: 3.10496e-02
I0208 19:43:47.808346 22542570456896 run_lib.py:133] step: 69200, training_loss: 3.35037e-02
I0208 19:43:47.979119 22542570456896 run_lib.py:146] step: 69200, eval_loss: 1.97422e-02
I0208 19:44:05.644769 22542570456896 run_lib.py:133] step: 69250, training_loss: 3.02285e-02
I0208 19:44:23.114329 22542570456896 run_lib.py:133] step: 69300, training_loss: 3.33260e-02
I0208 19:44:23.270187 22542570456896 run_lib.py:146] step: 69300, eval_loss: 3.38689e-02
I0208 19:44:40.844046 22542570456896 run_lib.py:133] step: 69350, training_loss: 2.47690e-02
I0208 19:44:58.246091 22542570456896 run_lib.py:133] step: 69400, training_loss: 3.07311e-02
I0208 19:44:58.399140 22542570456896 run_lib.py:146] step: 69400, eval_loss: 2.77157e-02
I0208 19:45:15.827847 22542570456896 run_lib.py:133] step: 69450, training_loss: 3.42525e-02
I0208 19:45:33.488190 22542570456896 run_lib.py:133] step: 69500, training_loss: 3.10418e-02
I0208 19:45:33.647537 22542570456896 run_lib.py:146] step: 69500, eval_loss: 2.53678e-02
I0208 19:45:51.091526 22542570456896 run_lib.py:133] step: 69550, training_loss: 2.91651e-02
I0208 19:46:08.727134 22542570456896 run_lib.py:133] step: 69600, training_loss: 3.11936e-02
I0208 19:46:08.891555 22542570456896 run_lib.py:146] step: 69600, eval_loss: 3.62847e-02
I0208 19:46:26.306802 22542570456896 run_lib.py:133] step: 69650, training_loss: 3.05100e-02
I0208 19:46:43.733704 22542570456896 run_lib.py:133] step: 69700, training_loss: 2.67047e-02
I0208 19:46:43.889346 22542570456896 run_lib.py:146] step: 69700, eval_loss: 2.61014e-02
I0208 19:47:01.473779 22542570456896 run_lib.py:133] step: 69750, training_loss: 3.36745e-02
I0208 19:47:18.919226 22542570456896 run_lib.py:133] step: 69800, training_loss: 2.80184e-02
I0208 19:47:19.076836 22542570456896 run_lib.py:146] step: 69800, eval_loss: 2.76619e-02
I0208 19:47:36.520427 22542570456896 run_lib.py:133] step: 69850, training_loss: 2.89149e-02
I0208 19:47:53.939615 22542570456896 run_lib.py:133] step: 69900, training_loss: 2.31239e-02
I0208 19:47:54.095327 22542570456896 run_lib.py:146] step: 69900, eval_loss: 2.42763e-02
I0208 19:48:11.693456 22542570456896 run_lib.py:133] step: 69950, training_loss: 2.54608e-02
I0208 19:48:29.143322 22542570456896 run_lib.py:133] step: 70000, training_loss: 2.70584e-02
I0208 19:48:29.858411 22542570456896 run_lib.py:146] step: 70000, eval_loss: 3.39806e-02
I0208 19:48:50.121306 22542570456896 run_lib.py:133] step: 70050, training_loss: 2.59420e-02
I0208 19:49:07.591465 22542570456896 run_lib.py:133] step: 70100, training_loss: 3.25214e-02
I0208 19:49:07.753433 22542570456896 run_lib.py:146] step: 70100, eval_loss: 2.88725e-02
I0208 19:49:25.324131 22542570456896 run_lib.py:133] step: 70150, training_loss: 2.92983e-02
I0208 19:49:42.745827 22542570456896 run_lib.py:133] step: 70200, training_loss: 3.68868e-02
I0208 19:49:42.912376 22542570456896 run_lib.py:146] step: 70200, eval_loss: 3.60226e-02
I0208 19:50:00.315302 22542570456896 run_lib.py:133] step: 70250, training_loss: 2.99240e-02
I0208 19:50:17.890334 22542570456896 run_lib.py:133] step: 70300, training_loss: 2.72009e-02
I0208 19:50:18.059336 22542570456896 run_lib.py:146] step: 70300, eval_loss: 3.28765e-02
I0208 19:50:35.493815 22542570456896 run_lib.py:133] step: 70350, training_loss: 2.86376e-02
I0208 19:50:52.926225 22542570456896 run_lib.py:133] step: 70400, training_loss: 3.27551e-02
I0208 19:50:53.082542 22542570456896 run_lib.py:146] step: 70400, eval_loss: 2.64753e-02
I0208 19:51:10.523174 22542570456896 run_lib.py:133] step: 70450, training_loss: 2.40471e-02
I0208 19:51:28.142730 22542570456896 run_lib.py:133] step: 70500, training_loss: 2.79399e-02
I0208 19:51:28.295397 22542570456896 run_lib.py:146] step: 70500, eval_loss: 2.58795e-02
I0208 19:51:45.689632 22542570456896 run_lib.py:133] step: 70550, training_loss: 3.04701e-02
I0208 19:52:03.201348 22542570456896 run_lib.py:133] step: 70600, training_loss: 3.78385e-02
I0208 19:52:03.384399 22542570456896 run_lib.py:146] step: 70600, eval_loss: 2.97341e-02
I0208 19:52:20.857147 22542570456896 run_lib.py:133] step: 70650, training_loss: 2.37499e-02
I0208 19:52:38.299074 22542570456896 run_lib.py:133] step: 70700, training_loss: 2.71249e-02
I0208 19:52:38.457527 22542570456896 run_lib.py:146] step: 70700, eval_loss: 3.07528e-02
I0208 19:52:56.045544 22542570456896 run_lib.py:133] step: 70750, training_loss: 3.04131e-02
I0208 19:53:13.504421 22542570456896 run_lib.py:133] step: 70800, training_loss: 2.34048e-02
I0208 19:53:13.661202 22542570456896 run_lib.py:146] step: 70800, eval_loss: 3.18856e-02
I0208 19:53:31.076180 22542570456896 run_lib.py:133] step: 70850, training_loss: 2.81225e-02
I0208 19:53:48.498376 22542570456896 run_lib.py:133] step: 70900, training_loss: 2.66682e-02
I0208 19:53:48.652869 22542570456896 run_lib.py:146] step: 70900, eval_loss: 2.76997e-02
I0208 19:54:06.217432 22542570456896 run_lib.py:133] step: 70950, training_loss: 2.64277e-02
I0208 19:54:23.541598 22542570456896 run_lib.py:133] step: 71000, training_loss: 3.28926e-02
I0208 19:54:23.695243 22542570456896 run_lib.py:146] step: 71000, eval_loss: 3.45142e-02
I0208 19:54:41.155375 22542570456896 run_lib.py:133] step: 71050, training_loss: 3.68433e-02
I0208 19:54:58.623929 22542570456896 run_lib.py:133] step: 71100, training_loss: 2.75220e-02
I0208 19:54:58.792458 22542570456896 run_lib.py:146] step: 71100, eval_loss: 2.67166e-02
I0208 19:55:16.397040 22542570456896 run_lib.py:133] step: 71150, training_loss: 2.41740e-02
I0208 19:55:33.878128 22542570456896 run_lib.py:133] step: 71200, training_loss: 2.22481e-02
I0208 19:55:34.036652 22542570456896 run_lib.py:146] step: 71200, eval_loss: 2.78373e-02
I0208 19:55:51.509059 22542570456896 run_lib.py:133] step: 71250, training_loss: 2.80719e-02
I0208 19:56:09.093413 22542570456896 run_lib.py:133] step: 71300, training_loss: 2.53792e-02
I0208 19:56:09.250455 22542570456896 run_lib.py:146] step: 71300, eval_loss: 2.72314e-02
I0208 19:56:26.727309 22542570456896 run_lib.py:133] step: 71350, training_loss: 3.00936e-02
I0208 19:56:44.266783 22542570456896 run_lib.py:133] step: 71400, training_loss: 2.39959e-02
I0208 19:56:44.419110 22542570456896 run_lib.py:146] step: 71400, eval_loss: 3.17064e-02
I0208 19:57:01.863027 22542570456896 run_lib.py:133] step: 71450, training_loss: 2.59034e-02
I0208 19:57:19.309674 22542570456896 run_lib.py:133] step: 71500, training_loss: 2.98052e-02
I0208 19:57:19.478662 22542570456896 run_lib.py:146] step: 71500, eval_loss: 3.26095e-02
I0208 19:57:37.095031 22542570456896 run_lib.py:133] step: 71550, training_loss: 2.16546e-02
I0208 19:57:54.529520 22542570456896 run_lib.py:133] step: 71600, training_loss: 3.62845e-02
I0208 19:57:54.688478 22542570456896 run_lib.py:146] step: 71600, eval_loss: 2.53008e-02
I0208 19:58:12.122949 22542570456896 run_lib.py:133] step: 71650, training_loss: 3.17259e-02
I0208 19:58:29.563453 22542570456896 run_lib.py:133] step: 71700, training_loss: 3.53800e-02
I0208 19:58:29.731376 22542570456896 run_lib.py:146] step: 71700, eval_loss: 2.50789e-02
I0208 19:58:47.353671 22542570456896 run_lib.py:133] step: 71750, training_loss: 2.47904e-02
I0208 19:59:04.813366 22542570456896 run_lib.py:133] step: 71800, training_loss: 2.43206e-02
I0208 19:59:04.970231 22542570456896 run_lib.py:146] step: 71800, eval_loss: 2.84831e-02
I0208 19:59:22.537079 22542570456896 run_lib.py:133] step: 71850, training_loss: 2.48857e-02
I0208 19:59:39.972197 22542570456896 run_lib.py:133] step: 71900, training_loss: 2.77098e-02
I0208 19:59:40.124419 22542570456896 run_lib.py:146] step: 71900, eval_loss: 2.65715e-02
I0208 19:59:57.548150 22542570456896 run_lib.py:133] step: 71950, training_loss: 2.69206e-02
I0208 20:00:14.967232 22542570456896 run_lib.py:133] step: 72000, training_loss: 3.01338e-02
I0208 20:00:15.137459 22542570456896 run_lib.py:146] step: 72000, eval_loss: 2.63621e-02
I0208 20:00:32.780039 22542570456896 run_lib.py:133] step: 72050, training_loss: 2.35563e-02
I0208 20:00:50.296575 22542570456896 run_lib.py:133] step: 72100, training_loss: 2.06620e-02
I0208 20:00:50.455458 22542570456896 run_lib.py:146] step: 72100, eval_loss: 3.64480e-02
I0208 20:01:07.888314 22542570456896 run_lib.py:133] step: 72150, training_loss: 2.43346e-02
I0208 20:01:25.270515 22542570456896 run_lib.py:133] step: 72200, training_loss: 2.95387e-02
I0208 20:01:25.429584 22542570456896 run_lib.py:146] step: 72200, eval_loss: 3.33670e-02
I0208 20:01:42.975322 22542570456896 run_lib.py:133] step: 72250, training_loss: 3.50845e-02
I0208 20:02:00.424311 22542570456896 run_lib.py:133] step: 72300, training_loss: 3.12103e-02
I0208 20:02:00.580540 22542570456896 run_lib.py:146] step: 72300, eval_loss: 2.70620e-02
I0208 20:02:18.198112 22542570456896 run_lib.py:133] step: 72350, training_loss: 2.27250e-02
I0208 20:02:35.588144 22542570456896 run_lib.py:133] step: 72400, training_loss: 3.26158e-02
I0208 20:02:35.740417 22542570456896 run_lib.py:146] step: 72400, eval_loss: 2.62538e-02
I0208 20:02:53.349434 22542570456896 run_lib.py:133] step: 72450, training_loss: 2.48297e-02
I0208 20:03:10.778762 22542570456896 run_lib.py:133] step: 72500, training_loss: 3.65550e-02
I0208 20:03:10.938452 22542570456896 run_lib.py:146] step: 72500, eval_loss: 2.79804e-02
I0208 20:03:28.563553 22542570456896 run_lib.py:133] step: 72550, training_loss: 3.04159e-02
I0208 20:03:46.063831 22542570456896 run_lib.py:133] step: 72600, training_loss: 3.12895e-02
I0208 20:03:46.221527 22542570456896 run_lib.py:146] step: 72600, eval_loss: 3.14407e-02
I0208 20:04:03.640441 22542570456896 run_lib.py:133] step: 72650, training_loss: 2.55574e-02
I0208 20:04:21.248545 22542570456896 run_lib.py:133] step: 72700, training_loss: 3.01578e-02
I0208 20:04:21.405526 22542570456896 run_lib.py:146] step: 72700, eval_loss: 2.72594e-02
I0208 20:04:38.793637 22542570456896 run_lib.py:133] step: 72750, training_loss: 3.31721e-02
I0208 20:04:56.227383 22542570456896 run_lib.py:133] step: 72800, training_loss: 2.91312e-02
I0208 20:04:56.382026 22542570456896 run_lib.py:146] step: 72800, eval_loss: 2.44676e-02
I0208 20:05:14.055049 22542570456896 run_lib.py:133] step: 72850, training_loss: 2.86627e-02
I0208 20:05:31.640245 22542570456896 run_lib.py:133] step: 72900, training_loss: 2.65962e-02
I0208 20:05:31.795273 22542570456896 run_lib.py:146] step: 72900, eval_loss: 3.28344e-02
I0208 20:05:49.207861 22542570456896 run_lib.py:133] step: 72950, training_loss: 3.34010e-02
I0208 20:06:06.656216 22542570456896 run_lib.py:133] step: 73000, training_loss: 3.22815e-02
I0208 20:06:06.817187 22542570456896 run_lib.py:146] step: 73000, eval_loss: 3.51907e-02
I0208 20:06:24.243022 22542570456896 run_lib.py:133] step: 73050, training_loss: 3.01797e-02
I0208 20:06:41.837184 22542570456896 run_lib.py:133] step: 73100, training_loss: 3.37475e-02
I0208 20:06:42.001890 22542570456896 run_lib.py:146] step: 73100, eval_loss: 2.60625e-02
I0208 20:06:59.469882 22542570456896 run_lib.py:133] step: 73150, training_loss: 2.80449e-02
I0208 20:07:16.947335 22542570456896 run_lib.py:133] step: 73200, training_loss: 3.91206e-02
I0208 20:07:17.112483 22542570456896 run_lib.py:146] step: 73200, eval_loss: 3.20728e-02
I0208 20:07:34.563569 22542570456896 run_lib.py:133] step: 73250, training_loss: 3.39435e-02
I0208 20:07:52.143437 22542570456896 run_lib.py:133] step: 73300, training_loss: 3.32928e-02
I0208 20:07:52.296430 22542570456896 run_lib.py:146] step: 73300, eval_loss: 3.06686e-02
I0208 20:08:09.709997 22542570456896 run_lib.py:133] step: 73350, training_loss: 2.69786e-02
I0208 20:08:27.242374 22542570456896 run_lib.py:133] step: 73400, training_loss: 3.43777e-02
I0208 20:08:27.413614 22542570456896 run_lib.py:146] step: 73400, eval_loss: 2.53370e-02
I0208 20:08:44.839769 22542570456896 run_lib.py:133] step: 73450, training_loss: 3.25837e-02
I0208 20:09:02.315636 22542570456896 run_lib.py:133] step: 73500, training_loss: 2.78663e-02
I0208 20:09:02.474342 22542570456896 run_lib.py:146] step: 73500, eval_loss: 4.22955e-02
I0208 20:09:20.086907 22542570456896 run_lib.py:133] step: 73550, training_loss: 2.69377e-02
I0208 20:09:37.594175 22542570456896 run_lib.py:133] step: 73600, training_loss: 3.39192e-02
I0208 20:09:37.758583 22542570456896 run_lib.py:146] step: 73600, eval_loss: 2.84365e-02
I0208 20:09:55.171423 22542570456896 run_lib.py:133] step: 73650, training_loss: 2.74463e-02
I0208 20:10:12.643452 22542570456896 run_lib.py:133] step: 73700, training_loss: 3.14516e-02
I0208 20:10:12.797548 22542570456896 run_lib.py:146] step: 73700, eval_loss: 2.54005e-02
I0208 20:10:30.409553 22542570456896 run_lib.py:133] step: 73750, training_loss: 2.64213e-02
I0208 20:10:47.833825 22542570456896 run_lib.py:133] step: 73800, training_loss: 2.74222e-02
I0208 20:10:47.996180 22542570456896 run_lib.py:146] step: 73800, eval_loss: 2.95533e-02
I0208 20:11:05.535018 22542570456896 run_lib.py:133] step: 73850, training_loss: 2.82600e-02
I0208 20:11:22.949258 22542570456896 run_lib.py:133] step: 73900, training_loss: 2.99224e-02
I0208 20:11:23.108194 22542570456896 run_lib.py:146] step: 73900, eval_loss: 3.17674e-02
I0208 20:11:41.310681 22542570456896 run_lib.py:133] step: 73950, training_loss: 2.50552e-02
I0208 20:11:58.816398 22542570456896 run_lib.py:133] step: 74000, training_loss: 2.69844e-02
I0208 20:11:58.976301 22542570456896 run_lib.py:146] step: 74000, eval_loss: 2.83496e-02
I0208 20:12:16.381808 22542570456896 run_lib.py:133] step: 74050, training_loss: 2.71318e-02
I0208 20:12:33.952841 22542570456896 run_lib.py:133] step: 74100, training_loss: 2.77723e-02
I0208 20:12:34.109427 22542570456896 run_lib.py:146] step: 74100, eval_loss: 2.52341e-02
I0208 20:12:51.547886 22542570456896 run_lib.py:133] step: 74150, training_loss: 3.07898e-02
I0208 20:13:09.114353 22542570456896 run_lib.py:133] step: 74200, training_loss: 2.70312e-02
I0208 20:13:09.270681 22542570456896 run_lib.py:146] step: 74200, eval_loss: 2.68681e-02
I0208 20:13:26.764951 22542570456896 run_lib.py:133] step: 74250, training_loss: 3.17703e-02
I0208 20:13:44.166684 22542570456896 run_lib.py:133] step: 74300, training_loss: 2.79708e-02
I0208 20:13:44.319361 22542570456896 run_lib.py:146] step: 74300, eval_loss: 3.11085e-02
I0208 20:14:01.942630 22542570456896 run_lib.py:133] step: 74350, training_loss: 2.49359e-02
I0208 20:14:19.361969 22542570456896 run_lib.py:133] step: 74400, training_loss: 2.85685e-02
I0208 20:14:19.529238 22542570456896 run_lib.py:146] step: 74400, eval_loss: 2.27831e-02
I0208 20:14:36.964429 22542570456896 run_lib.py:133] step: 74450, training_loss: 3.99800e-02
I0208 20:14:54.518403 22542570456896 run_lib.py:133] step: 74500, training_loss: 3.25792e-02
I0208 20:14:54.688025 22542570456896 run_lib.py:146] step: 74500, eval_loss: 3.33331e-02
I0208 20:15:12.156897 22542570456896 run_lib.py:133] step: 74550, training_loss: 3.51206e-02
I0208 20:15:29.628013 22542570456896 run_lib.py:133] step: 74600, training_loss: 2.66788e-02
I0208 20:15:29.784269 22542570456896 run_lib.py:146] step: 74600, eval_loss: 3.32743e-02
I0208 20:15:47.296395 22542570456896 run_lib.py:133] step: 74650, training_loss: 3.49661e-02
I0208 20:16:04.730098 22542570456896 run_lib.py:133] step: 74700, training_loss: 2.83036e-02
I0208 20:16:04.884082 22542570456896 run_lib.py:146] step: 74700, eval_loss: 2.84906e-02
I0208 20:16:22.287137 22542570456896 run_lib.py:133] step: 74750, training_loss: 2.22629e-02
I0208 20:16:39.744658 22542570456896 run_lib.py:133] step: 74800, training_loss: 3.18672e-02
I0208 20:16:39.911513 22542570456896 run_lib.py:146] step: 74800, eval_loss: 2.73381e-02
I0208 20:16:57.557794 22542570456896 run_lib.py:133] step: 74850, training_loss: 4.09548e-02
I0208 20:17:15.134274 22542570456896 run_lib.py:133] step: 74900, training_loss: 2.99687e-02
I0208 20:17:15.294387 22542570456896 run_lib.py:146] step: 74900, eval_loss: 2.96283e-02
I0208 20:17:32.718466 22542570456896 run_lib.py:133] step: 74950, training_loss: 2.89404e-02
I0208 20:17:50.163207 22542570456896 run_lib.py:133] step: 75000, training_loss: 2.81517e-02
I0208 20:17:50.324364 22542570456896 run_lib.py:146] step: 75000, eval_loss: 3.20781e-02
I0208 20:18:07.865081 22542570456896 run_lib.py:133] step: 75050, training_loss: 2.83444e-02
I0208 20:18:25.322022 22542570456896 run_lib.py:133] step: 75100, training_loss: 2.99200e-02
I0208 20:18:25.478430 22542570456896 run_lib.py:146] step: 75100, eval_loss: 2.68358e-02
I0208 20:18:43.114862 22542570456896 run_lib.py:133] step: 75150, training_loss: 2.57201e-02
I0208 20:19:00.505409 22542570456896 run_lib.py:133] step: 75200, training_loss: 2.62931e-02
I0208 20:19:00.659838 22542570456896 run_lib.py:146] step: 75200, eval_loss: 2.72720e-02
I0208 20:19:18.220601 22542570456896 run_lib.py:133] step: 75250, training_loss: 2.69451e-02
I0208 20:19:35.645937 22542570456896 run_lib.py:133] step: 75300, training_loss: 2.52775e-02
I0208 20:19:35.802680 22542570456896 run_lib.py:146] step: 75300, eval_loss: 2.91498e-02
I0208 20:19:53.467948 22542570456896 run_lib.py:133] step: 75350, training_loss: 3.13927e-02
I0208 20:20:10.915082 22542570456896 run_lib.py:133] step: 75400, training_loss: 2.59569e-02
I0208 20:20:11.070944 22542570456896 run_lib.py:146] step: 75400, eval_loss: 2.00661e-02
I0208 20:20:28.468062 22542570456896 run_lib.py:133] step: 75450, training_loss: 3.11453e-02
I0208 20:20:46.098181 22542570456896 run_lib.py:133] step: 75500, training_loss: 2.74299e-02
I0208 20:20:46.254345 22542570456896 run_lib.py:146] step: 75500, eval_loss: 2.96954e-02
I0208 20:21:03.674341 22542570456896 run_lib.py:133] step: 75550, training_loss: 3.56267e-02
I0208 20:21:21.162742 22542570456896 run_lib.py:133] step: 75600, training_loss: 3.63403e-02
I0208 20:21:21.320508 22542570456896 run_lib.py:146] step: 75600, eval_loss: 2.96232e-02
I0208 20:21:38.924997 22542570456896 run_lib.py:133] step: 75650, training_loss: 2.82109e-02
I0208 20:21:56.391391 22542570456896 run_lib.py:133] step: 75700, training_loss: 2.59671e-02
I0208 20:21:56.551408 22542570456896 run_lib.py:146] step: 75700, eval_loss: 2.94659e-02
I0208 20:22:14.156660 22542570456896 run_lib.py:133] step: 75750, training_loss: 3.52896e-02
I0208 20:22:31.627994 22542570456896 run_lib.py:133] step: 75800, training_loss: 2.77739e-02
I0208 20:22:31.785359 22542570456896 run_lib.py:146] step: 75800, eval_loss: 2.96437e-02
I0208 20:22:49.234910 22542570456896 run_lib.py:133] step: 75850, training_loss: 2.61280e-02
I0208 20:23:06.869244 22542570456896 run_lib.py:133] step: 75900, training_loss: 2.95805e-02
I0208 20:23:07.029998 22542570456896 run_lib.py:146] step: 75900, eval_loss: 2.96293e-02
I0208 20:23:24.476246 22542570456896 run_lib.py:133] step: 75950, training_loss: 2.42734e-02
I0208 20:23:41.879702 22542570456896 run_lib.py:133] step: 76000, training_loss: 2.34531e-02
I0208 20:23:42.036790 22542570456896 run_lib.py:146] step: 76000, eval_loss: 2.51775e-02
I0208 20:23:59.466753 22542570456896 run_lib.py:133] step: 76050, training_loss: 3.07791e-02
I0208 20:24:17.032105 22542570456896 run_lib.py:133] step: 76100, training_loss: 2.79426e-02
I0208 20:24:17.188236 22542570456896 run_lib.py:146] step: 76100, eval_loss: 3.02516e-02
I0208 20:24:34.646765 22542570456896 run_lib.py:133] step: 76150, training_loss: 2.84240e-02
I0208 20:24:52.183338 22542570456896 run_lib.py:133] step: 76200, training_loss: 2.30486e-02
I0208 20:24:52.345659 22542570456896 run_lib.py:146] step: 76200, eval_loss: 3.31983e-02
I0208 20:25:09.813056 22542570456896 run_lib.py:133] step: 76250, training_loss: 2.70788e-02
I0208 20:25:27.259717 22542570456896 run_lib.py:133] step: 76300, training_loss: 2.32161e-02
I0208 20:25:27.420673 22542570456896 run_lib.py:146] step: 76300, eval_loss: 2.97622e-02
I0208 20:25:45.045192 22542570456896 run_lib.py:133] step: 76350, training_loss: 2.40664e-02
I0208 20:26:02.521409 22542570456896 run_lib.py:133] step: 76400, training_loss: 2.68212e-02
I0208 20:26:02.690129 22542570456896 run_lib.py:146] step: 76400, eval_loss: 3.98110e-02
I0208 20:26:20.137330 22542570456896 run_lib.py:133] step: 76450, training_loss: 2.61008e-02
I0208 20:26:37.603304 22542570456896 run_lib.py:133] step: 76500, training_loss: 2.91085e-02
I0208 20:26:37.762206 22542570456896 run_lib.py:146] step: 76500, eval_loss: 2.53571e-02
I0208 20:26:55.410039 22542570456896 run_lib.py:133] step: 76550, training_loss: 2.71535e-02
I0208 20:27:12.806506 22542570456896 run_lib.py:133] step: 76600, training_loss: 2.80450e-02
I0208 20:27:12.959495 22542570456896 run_lib.py:146] step: 76600, eval_loss: 2.79804e-02
I0208 20:27:30.520655 22542570456896 run_lib.py:133] step: 76650, training_loss: 2.67637e-02
I0208 20:27:47.980065 22542570456896 run_lib.py:133] step: 76700, training_loss: 2.76321e-02
I0208 20:27:48.144649 22542570456896 run_lib.py:146] step: 76700, eval_loss: 3.23030e-02
I0208 20:28:05.808242 22542570456896 run_lib.py:133] step: 76750, training_loss: 2.16290e-02
I0208 20:28:23.233130 22542570456896 run_lib.py:133] step: 76800, training_loss: 2.76179e-02
I0208 20:28:23.397527 22542570456896 run_lib.py:146] step: 76800, eval_loss: 2.94179e-02
I0208 20:28:40.779183 22542570456896 run_lib.py:133] step: 76850, training_loss: 2.93505e-02
I0208 20:28:58.331803 22542570456896 run_lib.py:133] step: 76900, training_loss: 2.76733e-02
I0208 20:28:58.496387 22542570456896 run_lib.py:146] step: 76900, eval_loss: 2.80337e-02
I0208 20:29:15.961909 22542570456896 run_lib.py:133] step: 76950, training_loss: 2.87640e-02
I0208 20:29:33.580197 22542570456896 run_lib.py:133] step: 77000, training_loss: 3.03234e-02
I0208 20:29:33.737582 22542570456896 run_lib.py:146] step: 77000, eval_loss: 2.87513e-02
I0208 20:29:51.179178 22542570456896 run_lib.py:133] step: 77050, training_loss: 3.30764e-02
I0208 20:30:08.611056 22542570456896 run_lib.py:133] step: 77100, training_loss: 2.83829e-02
I0208 20:30:08.765330 22542570456896 run_lib.py:146] step: 77100, eval_loss: 3.69583e-02
I0208 20:30:26.349756 22542570456896 run_lib.py:133] step: 77150, training_loss: 2.52034e-02
I0208 20:30:43.816583 22542570456896 run_lib.py:133] step: 77200, training_loss: 3.41399e-02
I0208 20:30:43.985513 22542570456896 run_lib.py:146] step: 77200, eval_loss: 3.44659e-02
I0208 20:31:01.490467 22542570456896 run_lib.py:133] step: 77250, training_loss: 2.80636e-02
I0208 20:31:19.115997 22542570456896 run_lib.py:133] step: 77300, training_loss: 3.68455e-02
I0208 20:31:19.275574 22542570456896 run_lib.py:146] step: 77300, eval_loss: 3.12568e-02
I0208 20:31:36.760189 22542570456896 run_lib.py:133] step: 77350, training_loss: 3.17864e-02
I0208 20:31:54.209746 22542570456896 run_lib.py:133] step: 77400, training_loss: 2.98196e-02
I0208 20:31:54.521288 22542570456896 run_lib.py:146] step: 77400, eval_loss: 2.60893e-02
I0208 20:32:11.953828 22542570456896 run_lib.py:133] step: 77450, training_loss: 2.93350e-02
I0208 20:32:29.440021 22542570456896 run_lib.py:133] step: 77500, training_loss: 2.83182e-02
I0208 20:32:29.596649 22542570456896 run_lib.py:146] step: 77500, eval_loss: 1.95849e-02
I0208 20:32:47.066569 22542570456896 run_lib.py:133] step: 77550, training_loss: 2.64782e-02
I0208 20:33:04.478063 22542570456896 run_lib.py:133] step: 77600, training_loss: 3.64718e-02
I0208 20:33:04.631385 22542570456896 run_lib.py:146] step: 77600, eval_loss: 2.69014e-02
I0208 20:33:22.231404 22542570456896 run_lib.py:133] step: 77650, training_loss: 3.08087e-02
I0208 20:33:39.743208 22542570456896 run_lib.py:133] step: 77700, training_loss: 2.93691e-02
I0208 20:33:39.915418 22542570456896 run_lib.py:146] step: 77700, eval_loss: 2.89026e-02
I0208 20:33:57.383545 22542570456896 run_lib.py:133] step: 77750, training_loss: 2.98422e-02
I0208 20:34:14.808331 22542570456896 run_lib.py:133] step: 77800, training_loss: 2.95825e-02
I0208 20:34:14.969391 22542570456896 run_lib.py:146] step: 77800, eval_loss: 2.98082e-02
I0208 20:34:32.551935 22542570456896 run_lib.py:133] step: 77850, training_loss: 3.07381e-02
I0208 20:34:50.045220 22542570456896 run_lib.py:133] step: 77900, training_loss: 3.67269e-02
I0208 20:34:50.205420 22542570456896 run_lib.py:146] step: 77900, eval_loss: 2.98325e-02
I0208 20:35:07.604774 22542570456896 run_lib.py:133] step: 77950, training_loss: 2.49325e-02
I0208 20:35:25.046986 22542570456896 run_lib.py:133] step: 78000, training_loss: 3.24128e-02
I0208 20:35:25.209695 22542570456896 run_lib.py:146] step: 78000, eval_loss: 3.29846e-02
I0208 20:35:42.885219 22542570456896 run_lib.py:133] step: 78050, training_loss: 2.62938e-02
I0208 20:36:00.348460 22542570456896 run_lib.py:133] step: 78100, training_loss: 3.91454e-02
I0208 20:36:00.502288 22542570456896 run_lib.py:146] step: 78100, eval_loss: 3.60208e-02
I0208 20:36:18.023527 22542570456896 run_lib.py:133] step: 78150, training_loss: 2.74780e-02
I0208 20:36:35.442544 22542570456896 run_lib.py:133] step: 78200, training_loss: 3.57468e-02
I0208 20:36:35.603578 22542570456896 run_lib.py:146] step: 78200, eval_loss: 2.71860e-02
I0208 20:36:53.167789 22542570456896 run_lib.py:133] step: 78250, training_loss: 3.64233e-02
I0208 20:37:10.604208 22542570456896 run_lib.py:133] step: 78300, training_loss: 2.62237e-02
I0208 20:37:10.776395 22542570456896 run_lib.py:146] step: 78300, eval_loss: 2.31439e-02
I0208 20:37:28.224256 22542570456896 run_lib.py:133] step: 78350, training_loss: 2.90738e-02
I0208 20:37:45.887981 22542570456896 run_lib.py:133] step: 78400, training_loss: 2.86499e-02
I0208 20:37:46.045103 22542570456896 run_lib.py:146] step: 78400, eval_loss: 3.03494e-02
I0208 20:38:03.509961 22542570456896 run_lib.py:133] step: 78450, training_loss: 3.26621e-02
I0208 20:38:21.124503 22542570456896 run_lib.py:133] step: 78500, training_loss: 2.94237e-02
I0208 20:38:21.277388 22542570456896 run_lib.py:146] step: 78500, eval_loss: 2.63396e-02
I0208 20:38:38.715259 22542570456896 run_lib.py:133] step: 78550, training_loss: 2.31605e-02
I0208 20:38:56.126932 22542570456896 run_lib.py:133] step: 78600, training_loss: 3.11476e-02
I0208 20:38:56.299566 22542570456896 run_lib.py:146] step: 78600, eval_loss: 3.18072e-02
I0208 20:39:13.964394 22542570456896 run_lib.py:133] step: 78650, training_loss: 3.43811e-02
I0208 20:39:31.439968 22542570456896 run_lib.py:133] step: 78700, training_loss: 2.72386e-02
I0208 20:39:31.600324 22542570456896 run_lib.py:146] step: 78700, eval_loss: 3.33997e-02
I0208 20:39:49.038703 22542570456896 run_lib.py:133] step: 78750, training_loss: 3.16009e-02
I0208 20:40:06.433815 22542570456896 run_lib.py:133] step: 78800, training_loss: 3.47464e-02
I0208 20:40:06.590371 22542570456896 run_lib.py:146] step: 78800, eval_loss: 2.74042e-02
I0208 20:40:24.170232 22542570456896 run_lib.py:133] step: 78850, training_loss: 2.90151e-02
I0208 20:40:41.621516 22542570456896 run_lib.py:133] step: 78900, training_loss: 2.50887e-02
I0208 20:40:41.778598 22542570456896 run_lib.py:146] step: 78900, eval_loss: 2.58318e-02
I0208 20:40:59.316422 22542570456896 run_lib.py:133] step: 78950, training_loss: 2.60157e-02
I0208 20:41:16.767148 22542570456896 run_lib.py:133] step: 79000, training_loss: 2.95386e-02
I0208 20:41:16.920270 22542570456896 run_lib.py:146] step: 79000, eval_loss: 1.83603e-02
I0208 20:41:34.319512 22542570456896 run_lib.py:133] step: 79050, training_loss: 2.89011e-02
I0208 20:41:51.754140 22542570456896 run_lib.py:133] step: 79100, training_loss: 2.61598e-02
I0208 20:41:51.911340 22542570456896 run_lib.py:146] step: 79100, eval_loss: 2.77736e-02
I0208 20:42:09.481393 22542570456896 run_lib.py:133] step: 79150, training_loss: 2.42927e-02
I0208 20:42:26.996632 22542570456896 run_lib.py:133] step: 79200, training_loss: 3.40257e-02
I0208 20:42:27.175644 22542570456896 run_lib.py:146] step: 79200, eval_loss: 2.94124e-02
I0208 20:42:44.633075 22542570456896 run_lib.py:133] step: 79250, training_loss: 3.43688e-02
I0208 20:43:02.082005 22542570456896 run_lib.py:133] step: 79300, training_loss: 3.18010e-02
I0208 20:43:02.240532 22542570456896 run_lib.py:146] step: 79300, eval_loss: 3.21946e-02
I0208 20:43:19.814272 22542570456896 run_lib.py:133] step: 79350, training_loss: 3.55084e-02
I0208 20:43:37.240924 22542570456896 run_lib.py:133] step: 79400, training_loss: 2.40029e-02
I0208 20:43:37.397317 22542570456896 run_lib.py:146] step: 79400, eval_loss: 3.27283e-02
I0208 20:43:54.981677 22542570456896 run_lib.py:133] step: 79450, training_loss: 2.78730e-02
I0208 20:44:12.430236 22542570456896 run_lib.py:133] step: 79500, training_loss: 2.52254e-02
I0208 20:44:12.584709 22542570456896 run_lib.py:146] step: 79500, eval_loss: 3.00548e-02
I0208 20:44:30.256636 22542570456896 run_lib.py:133] step: 79550, training_loss: 2.89411e-02
I0208 20:44:47.700356 22542570456896 run_lib.py:133] step: 79600, training_loss: 3.37629e-02
I0208 20:44:47.865576 22542570456896 run_lib.py:146] step: 79600, eval_loss: 2.77167e-02
I0208 20:45:05.424386 22542570456896 run_lib.py:133] step: 79650, training_loss: 2.63284e-02
I0208 20:45:22.824225 22542570456896 run_lib.py:133] step: 79700, training_loss: 2.76842e-02
I0208 20:45:22.984261 22542570456896 run_lib.py:146] step: 79700, eval_loss: 2.66781e-02
I0208 20:45:40.445662 22542570456896 run_lib.py:133] step: 79750, training_loss: 3.84539e-02
I0208 20:45:58.062476 22542570456896 run_lib.py:133] step: 79800, training_loss: 2.61662e-02
I0208 20:45:58.220129 22542570456896 run_lib.py:146] step: 79800, eval_loss: 3.04608e-02
I0208 20:46:15.655348 22542570456896 run_lib.py:133] step: 79850, training_loss: 2.28446e-02
I0208 20:46:33.084864 22542570456896 run_lib.py:133] step: 79900, training_loss: 2.41553e-02
I0208 20:46:33.242144 22542570456896 run_lib.py:146] step: 79900, eval_loss: 3.28286e-02
I0208 20:46:50.809502 22542570456896 run_lib.py:133] step: 79950, training_loss: 2.73631e-02
I0208 20:47:08.368076 22542570456896 run_lib.py:133] step: 80000, training_loss: 2.12902e-02
I0208 20:47:09.087439 22542570456896 run_lib.py:146] step: 80000, eval_loss: 2.79580e-02
I0208 20:47:29.205897 22542570456896 run_lib.py:133] step: 80050, training_loss: 2.99594e-02
I0208 20:47:46.694837 22542570456896 run_lib.py:133] step: 80100, training_loss: 3.06410e-02
I0208 20:47:46.855658 22542570456896 run_lib.py:146] step: 80100, eval_loss: 3.46944e-02
I0208 20:48:04.301776 22542570456896 run_lib.py:133] step: 80150, training_loss: 3.70853e-02
I0208 20:48:21.758076 22542570456896 run_lib.py:133] step: 80200, training_loss: 3.43113e-02
I0208 20:48:21.916646 22542570456896 run_lib.py:146] step: 80200, eval_loss: 3.21752e-02
I0208 20:48:39.510177 22542570456896 run_lib.py:133] step: 80250, training_loss: 2.90520e-02
I0208 20:48:56.985154 22542570456896 run_lib.py:133] step: 80300, training_loss: 2.73137e-02
I0208 20:48:57.156603 22542570456896 run_lib.py:146] step: 80300, eval_loss: 3.08704e-02
I0208 20:49:14.580262 22542570456896 run_lib.py:133] step: 80350, training_loss: 2.13159e-02
I0208 20:49:32.005522 22542570456896 run_lib.py:133] step: 80400, training_loss: 2.49592e-02
I0208 20:49:32.162188 22542570456896 run_lib.py:146] step: 80400, eval_loss: 3.32564e-02
I0208 20:49:49.774955 22542570456896 run_lib.py:133] step: 80450, training_loss: 2.44926e-02
I0208 20:50:07.217025 22542570456896 run_lib.py:133] step: 80500, training_loss: 3.01058e-02
I0208 20:50:07.369291 22542570456896 run_lib.py:146] step: 80500, eval_loss: 2.99341e-02
I0208 20:50:25.002774 22542570456896 run_lib.py:133] step: 80550, training_loss: 2.59837e-02
I0208 20:50:42.428157 22542570456896 run_lib.py:133] step: 80600, training_loss: 2.52782e-02
I0208 20:50:42.596744 22542570456896 run_lib.py:146] step: 80600, eval_loss: 2.62990e-02
I0208 20:51:00.266967 22542570456896 run_lib.py:133] step: 80650, training_loss: 2.79151e-02
I0208 20:51:17.690471 22542570456896 run_lib.py:133] step: 80700, training_loss: 3.40943e-02
I0208 20:51:17.849429 22542570456896 run_lib.py:146] step: 80700, eval_loss: 3.44164e-02
I0208 20:51:35.245949 22542570456896 run_lib.py:133] step: 80750, training_loss: 2.90913e-02
I0208 20:51:52.823510 22542570456896 run_lib.py:133] step: 80800, training_loss: 3.78762e-02
I0208 20:51:52.980369 22542570456896 run_lib.py:146] step: 80800, eval_loss: 2.97844e-02
I0208 20:52:10.413134 22542570456896 run_lib.py:133] step: 80850, training_loss: 3.03207e-02
I0208 20:52:27.972580 22542570456896 run_lib.py:133] step: 80900, training_loss: 2.70289e-02
I0208 20:52:28.129521 22542570456896 run_lib.py:146] step: 80900, eval_loss: 3.02519e-02
I0208 20:52:45.598631 22542570456896 run_lib.py:133] step: 80950, training_loss: 2.89006e-02
I0208 20:53:03.051792 22542570456896 run_lib.py:133] step: 81000, training_loss: 3.25361e-02
I0208 20:53:03.201921 22542570456896 run_lib.py:146] step: 81000, eval_loss: 2.70152e-02
I0208 20:53:20.817782 22542570456896 run_lib.py:133] step: 81050, training_loss: 3.16575e-02
I0208 20:53:38.289978 22542570456896 run_lib.py:133] step: 81100, training_loss: 3.15274e-02
I0208 20:53:38.450748 22542570456896 run_lib.py:146] step: 81100, eval_loss: 2.89451e-02
I0208 20:53:55.857520 22542570456896 run_lib.py:133] step: 81150, training_loss: 3.14043e-02
I0208 20:54:13.541310 22542570456896 run_lib.py:133] step: 81200, training_loss: 3.30935e-02
I0208 20:54:13.698348 22542570456896 run_lib.py:146] step: 81200, eval_loss: 3.08328e-02
I0208 20:54:31.113936 22542570456896 run_lib.py:133] step: 81250, training_loss: 2.69150e-02
I0208 20:54:48.597956 22542570456896 run_lib.py:133] step: 81300, training_loss: 2.82987e-02
I0208 20:54:48.751009 22542570456896 run_lib.py:146] step: 81300, eval_loss: 2.79996e-02
I0208 20:55:06.213202 22542570456896 run_lib.py:133] step: 81350, training_loss: 3.32877e-02
I0208 20:55:23.643030 22542570456896 run_lib.py:133] step: 81400, training_loss: 3.02398e-02
I0208 20:55:23.797347 22542570456896 run_lib.py:146] step: 81400, eval_loss: 3.31745e-02
I0208 20:55:41.269186 22542570456896 run_lib.py:133] step: 81450, training_loss: 3.06964e-02
I0208 20:55:58.722423 22542570456896 run_lib.py:133] step: 81500, training_loss: 2.67219e-02
I0208 20:55:58.880598 22542570456896 run_lib.py:146] step: 81500, eval_loss: 2.52011e-02
I0208 20:56:16.516303 22542570456896 run_lib.py:133] step: 81550, training_loss: 3.48135e-02
I0208 20:56:34.033477 22542570456896 run_lib.py:133] step: 81600, training_loss: 2.06238e-02
I0208 20:56:34.191686 22542570456896 run_lib.py:146] step: 81600, eval_loss: 3.17175e-02
I0208 20:56:51.589102 22542570456896 run_lib.py:133] step: 81650, training_loss: 3.27647e-02
I0208 20:57:09.068007 22542570456896 run_lib.py:133] step: 81700, training_loss: 2.64922e-02
I0208 20:57:09.233700 22542570456896 run_lib.py:146] step: 81700, eval_loss: 2.84712e-02
I0208 20:57:26.846239 22542570456896 run_lib.py:133] step: 81750, training_loss: 2.95723e-02
I0208 20:57:44.265184 22542570456896 run_lib.py:133] step: 81800, training_loss: 2.97606e-02
I0208 20:57:44.422496 22542570456896 run_lib.py:146] step: 81800, eval_loss: 2.66435e-02
I0208 20:58:02.240380 22542570456896 run_lib.py:133] step: 81850, training_loss: 2.86811e-02
I0208 20:58:19.652056 22542570456896 run_lib.py:133] step: 81900, training_loss: 3.08131e-02
I0208 20:58:19.804272 22542570456896 run_lib.py:146] step: 81900, eval_loss: 2.67284e-02
I0208 20:58:37.373368 22542570456896 run_lib.py:133] step: 81950, training_loss: 3.10937e-02
I0208 20:58:54.896014 22542570456896 run_lib.py:133] step: 82000, training_loss: 3.03996e-02
I0208 20:58:55.067639 22542570456896 run_lib.py:146] step: 82000, eval_loss: 3.20200e-02
I0208 20:59:12.655487 22542570456896 run_lib.py:133] step: 82050, training_loss: 3.38029e-02
I0208 20:59:30.092766 22542570456896 run_lib.py:133] step: 82100, training_loss: 3.12919e-02
I0208 20:59:30.256676 22542570456896 run_lib.py:146] step: 82100, eval_loss: 3.30953e-02
I0208 20:59:47.713346 22542570456896 run_lib.py:133] step: 82150, training_loss: 2.58448e-02
I0208 21:00:05.304400 22542570456896 run_lib.py:133] step: 82200, training_loss: 2.38109e-02
I0208 21:00:05.473319 22542570456896 run_lib.py:146] step: 82200, eval_loss: 3.17321e-02
I0208 21:00:22.907239 22542570456896 run_lib.py:133] step: 82250, training_loss: 2.61116e-02
I0208 21:00:40.365366 22542570456896 run_lib.py:133] step: 82300, training_loss: 3.30278e-02
I0208 21:00:40.521560 22542570456896 run_lib.py:146] step: 82300, eval_loss: 3.57886e-02
I0208 21:00:58.130224 22542570456896 run_lib.py:133] step: 82350, training_loss: 2.83417e-02
I0208 21:01:15.573510 22542570456896 run_lib.py:133] step: 82400, training_loss: 2.39099e-02
I0208 21:01:15.734424 22542570456896 run_lib.py:146] step: 82400, eval_loss: 3.04953e-02
I0208 21:01:33.298619 22542570456896 run_lib.py:133] step: 82450, training_loss: 3.09952e-02
I0208 21:01:50.743079 22542570456896 run_lib.py:133] step: 82500, training_loss: 2.92421e-02
I0208 21:01:50.921709 22542570456896 run_lib.py:146] step: 82500, eval_loss: 3.24373e-02
I0208 21:02:08.372196 22542570456896 run_lib.py:133] step: 82550, training_loss: 3.26851e-02
I0208 21:02:25.948701 22542570456896 run_lib.py:133] step: 82600, training_loss: 2.29644e-02
I0208 21:02:26.106379 22542570456896 run_lib.py:146] step: 82600, eval_loss: 2.76124e-02
I0208 21:02:43.409370 22542570456896 run_lib.py:133] step: 82650, training_loss: 3.34129e-02
I0208 21:03:00.703960 22542570456896 run_lib.py:133] step: 82700, training_loss: 3.12203e-02
I0208 21:03:00.858922 22542570456896 run_lib.py:146] step: 82700, eval_loss: 2.51355e-02
I0208 21:03:18.171431 22542570456896 run_lib.py:133] step: 82750, training_loss: 3.44906e-02
I0208 21:03:35.831912 22542570456896 run_lib.py:133] step: 82800, training_loss: 3.05916e-02
I0208 21:03:35.988601 22542570456896 run_lib.py:146] step: 82800, eval_loss: 2.08213e-02
I0208 21:03:53.433967 22542570456896 run_lib.py:133] step: 82850, training_loss: 2.35786e-02
I0208 21:04:10.970353 22542570456896 run_lib.py:133] step: 82900, training_loss: 3.94544e-02
I0208 21:04:11.122278 22542570456896 run_lib.py:146] step: 82900, eval_loss: 2.96951e-02
I0208 21:04:28.537313 22542570456896 run_lib.py:133] step: 82950, training_loss: 2.40643e-02
I0208 21:04:45.965609 22542570456896 run_lib.py:133] step: 83000, training_loss: 3.49585e-02
I0208 21:04:46.142397 22542570456896 run_lib.py:146] step: 83000, eval_loss: 3.61839e-02
I0208 21:05:03.760550 22542570456896 run_lib.py:133] step: 83050, training_loss: 3.18826e-02
I0208 21:05:21.325205 22542570456896 run_lib.py:133] step: 83100, training_loss: 2.16664e-02
I0208 21:05:21.481571 22542570456896 run_lib.py:146] step: 83100, eval_loss: 2.59045e-02
I0208 21:05:38.921116 22542570456896 run_lib.py:133] step: 83150, training_loss: 2.78373e-02
I0208 21:05:56.385711 22542570456896 run_lib.py:133] step: 83200, training_loss: 3.12987e-02
I0208 21:05:56.541374 22542570456896 run_lib.py:146] step: 83200, eval_loss: 2.57804e-02
I0208 21:06:14.101737 22542570456896 run_lib.py:133] step: 83250, training_loss: 2.80069e-02
I0208 21:06:31.599613 22542570456896 run_lib.py:133] step: 83300, training_loss: 2.57042e-02
I0208 21:06:31.755200 22542570456896 run_lib.py:146] step: 83300, eval_loss: 3.51266e-02
I0208 21:06:49.366040 22542570456896 run_lib.py:133] step: 83350, training_loss: 3.50347e-02
I0208 21:07:06.807425 22542570456896 run_lib.py:133] step: 83400, training_loss: 3.15665e-02
I0208 21:07:06.960331 22542570456896 run_lib.py:146] step: 83400, eval_loss: 2.84726e-02
I0208 21:07:24.555247 22542570456896 run_lib.py:133] step: 83450, training_loss: 3.13855e-02
I0208 21:07:41.992053 22542570456896 run_lib.py:133] step: 83500, training_loss: 2.84857e-02
I0208 21:07:42.147461 22542570456896 run_lib.py:146] step: 83500, eval_loss: 2.66777e-02
I0208 21:07:59.589676 22542570456896 run_lib.py:133] step: 83550, training_loss: 3.49919e-02
I0208 21:08:17.249649 22542570456896 run_lib.py:133] step: 83600, training_loss: 2.47460e-02
I0208 21:08:17.406474 22542570456896 run_lib.py:146] step: 83600, eval_loss: 2.81703e-02
I0208 21:08:34.837285 22542570456896 run_lib.py:133] step: 83650, training_loss: 3.39036e-02
I0208 21:08:52.446690 22542570456896 run_lib.py:133] step: 83700, training_loss: 2.86125e-02
I0208 21:08:52.604026 22542570456896 run_lib.py:146] step: 83700, eval_loss: 3.06702e-02
I0208 21:09:10.035228 22542570456896 run_lib.py:133] step: 83750, training_loss: 2.37748e-02
I0208 21:09:27.509754 22542570456896 run_lib.py:133] step: 83800, training_loss: 3.44627e-02
I0208 21:09:27.664522 22542570456896 run_lib.py:146] step: 83800, eval_loss: 2.56176e-02
I0208 21:09:45.348566 22542570456896 run_lib.py:133] step: 83850, training_loss: 2.91364e-02
I0208 21:10:02.770035 22542570456896 run_lib.py:133] step: 83900, training_loss: 3.33918e-02
I0208 21:10:02.927319 22542570456896 run_lib.py:146] step: 83900, eval_loss: 2.92373e-02
I0208 21:10:20.346573 22542570456896 run_lib.py:133] step: 83950, training_loss: 2.74429e-02
I0208 21:10:37.907546 22542570456896 run_lib.py:133] step: 84000, training_loss: 2.86180e-02
I0208 21:10:38.066492 22542570456896 run_lib.py:146] step: 84000, eval_loss: 3.02486e-02
I0208 21:10:55.502649 22542570456896 run_lib.py:133] step: 84050, training_loss: 2.76896e-02
I0208 21:11:12.958875 22542570456896 run_lib.py:133] step: 84100, training_loss: 2.71249e-02
I0208 21:11:13.292461 22542570456896 run_lib.py:146] step: 84100, eval_loss: 3.28378e-02
I0208 21:11:30.735732 22542570456896 run_lib.py:133] step: 84150, training_loss: 2.76718e-02
I0208 21:11:48.156546 22542570456896 run_lib.py:133] step: 84200, training_loss: 3.12018e-02
I0208 21:11:48.320363 22542570456896 run_lib.py:146] step: 84200, eval_loss: 3.45569e-02
I0208 21:12:05.742251 22542570456896 run_lib.py:133] step: 84250, training_loss: 3.34816e-02
I0208 21:12:23.196284 22542570456896 run_lib.py:133] step: 84300, training_loss: 3.10948e-02
I0208 21:12:23.347712 22542570456896 run_lib.py:146] step: 84300, eval_loss: 2.65490e-02
I0208 21:12:40.946390 22542570456896 run_lib.py:133] step: 84350, training_loss: 3.80426e-02
I0208 21:12:58.486279 22542570456896 run_lib.py:133] step: 84400, training_loss: 2.76049e-02
I0208 21:12:58.656488 22542570456896 run_lib.py:146] step: 84400, eval_loss: 2.62230e-02
I0208 21:13:16.121660 22542570456896 run_lib.py:133] step: 84450, training_loss: 3.35808e-02
I0208 21:13:33.541801 22542570456896 run_lib.py:133] step: 84500, training_loss: 3.34511e-02
I0208 21:13:33.700529 22542570456896 run_lib.py:146] step: 84500, eval_loss: 2.21782e-02
I0208 21:13:51.286482 22542570456896 run_lib.py:133] step: 84550, training_loss: 2.92329e-02
I0208 21:14:08.806630 22542570456896 run_lib.py:133] step: 84600, training_loss: 2.49364e-02
I0208 21:14:08.963052 22542570456896 run_lib.py:146] step: 84600, eval_loss: 2.52983e-02
I0208 21:14:26.385393 22542570456896 run_lib.py:133] step: 84650, training_loss: 3.12494e-02
I0208 21:14:43.819783 22542570456896 run_lib.py:133] step: 84700, training_loss: 2.95008e-02
I0208 21:14:43.976557 22542570456896 run_lib.py:146] step: 84700, eval_loss: 2.18250e-02
I0208 21:15:01.600808 22542570456896 run_lib.py:133] step: 84750, training_loss: 3.09074e-02
I0208 21:15:19.006942 22542570456896 run_lib.py:133] step: 84800, training_loss: 3.19662e-02
I0208 21:15:19.160351 22542570456896 run_lib.py:146] step: 84800, eval_loss: 2.94464e-02
I0208 21:15:36.700492 22542570456896 run_lib.py:133] step: 84850, training_loss: 2.58753e-02
I0208 21:15:54.088096 22542570456896 run_lib.py:133] step: 84900, training_loss: 2.70067e-02
I0208 21:15:54.266360 22542570456896 run_lib.py:146] step: 84900, eval_loss: 3.27599e-02
I0208 21:16:11.878235 22542570456896 run_lib.py:133] step: 84950, training_loss: 2.81479e-02
I0208 21:16:29.341383 22542570456896 run_lib.py:133] step: 85000, training_loss: 2.84532e-02
I0208 21:16:29.500367 22542570456896 run_lib.py:146] step: 85000, eval_loss: 2.73258e-02
I0208 21:16:46.935484 22542570456896 run_lib.py:133] step: 85050, training_loss: 2.25556e-02
I0208 21:17:04.521179 22542570456896 run_lib.py:133] step: 85100, training_loss: 2.34844e-02
I0208 21:17:04.675396 22542570456896 run_lib.py:146] step: 85100, eval_loss: 2.71272e-02
I0208 21:17:22.137121 22542570456896 run_lib.py:133] step: 85150, training_loss: 3.01706e-02
I0208 21:17:39.690303 22542570456896 run_lib.py:133] step: 85200, training_loss: 3.63482e-02
I0208 21:17:39.846685 22542570456896 run_lib.py:146] step: 85200, eval_loss: 2.95900e-02
I0208 21:17:57.307734 22542570456896 run_lib.py:133] step: 85250, training_loss: 2.68025e-02
I0208 21:18:14.723667 22542570456896 run_lib.py:133] step: 85300, training_loss: 3.09653e-02
I0208 21:18:14.877261 22542570456896 run_lib.py:146] step: 85300, eval_loss: 2.46974e-02
I0208 21:18:32.478971 22542570456896 run_lib.py:133] step: 85350, training_loss: 2.61949e-02
I0208 21:18:49.908390 22542570456896 run_lib.py:133] step: 85400, training_loss: 2.56396e-02
I0208 21:18:50.068219 22542570456896 run_lib.py:146] step: 85400, eval_loss: 2.63187e-02
I0208 21:19:07.487995 22542570456896 run_lib.py:133] step: 85450, training_loss: 3.52545e-02
I0208 21:19:24.911175 22542570456896 run_lib.py:133] step: 85500, training_loss: 2.89206e-02
I0208 21:19:25.080254 22542570456896 run_lib.py:146] step: 85500, eval_loss: 2.61754e-02
I0208 21:19:42.746843 22542570456896 run_lib.py:133] step: 85550, training_loss: 2.62681e-02
I0208 21:20:00.187419 22542570456896 run_lib.py:133] step: 85600, training_loss: 3.44825e-02
I0208 21:20:00.347663 22542570456896 run_lib.py:146] step: 85600, eval_loss: 2.58383e-02
I0208 21:20:17.868009 22542570456896 run_lib.py:133] step: 85650, training_loss: 3.18534e-02
I0208 21:20:35.294416 22542570456896 run_lib.py:133] step: 85700, training_loss: 2.74489e-02
I0208 21:20:35.449852 22542570456896 run_lib.py:146] step: 85700, eval_loss: 2.77479e-02
I0208 21:20:52.854406 22542570456896 run_lib.py:133] step: 85750, training_loss: 2.66214e-02
I0208 21:21:10.297983 22542570456896 run_lib.py:133] step: 85800, training_loss: 2.62917e-02
I0208 21:21:10.469120 22542570456896 run_lib.py:146] step: 85800, eval_loss: 3.34720e-02
I0208 21:21:28.090931 22542570456896 run_lib.py:133] step: 85850, training_loss: 2.24634e-02
I0208 21:21:45.664976 22542570456896 run_lib.py:133] step: 85900, training_loss: 2.82621e-02
I0208 21:21:45.826429 22542570456896 run_lib.py:146] step: 85900, eval_loss: 2.38092e-02
I0208 21:22:03.232735 22542570456896 run_lib.py:133] step: 85950, training_loss: 3.29490e-02
I0208 21:22:20.656139 22542570456896 run_lib.py:133] step: 86000, training_loss: 2.81623e-02
I0208 21:22:20.814297 22542570456896 run_lib.py:146] step: 86000, eval_loss: 2.70917e-02
I0208 21:22:38.368587 22542570456896 run_lib.py:133] step: 86050, training_loss: 2.78666e-02
I0208 21:22:55.880568 22542570456896 run_lib.py:133] step: 86100, training_loss: 3.07227e-02
I0208 21:22:56.036672 22542570456896 run_lib.py:146] step: 86100, eval_loss: 2.48650e-02
I0208 21:23:13.624474 22542570456896 run_lib.py:133] step: 86150, training_loss: 2.63507e-02
I0208 21:23:31.036371 22542570456896 run_lib.py:133] step: 86200, training_loss: 2.36107e-02
I0208 21:23:31.194997 22542570456896 run_lib.py:146] step: 86200, eval_loss: 2.35389e-02
I0208 21:23:48.783363 22542570456896 run_lib.py:133] step: 86250, training_loss: 3.00947e-02
I0208 21:24:06.244156 22542570456896 run_lib.py:133] step: 86300, training_loss: 3.24178e-02
I0208 21:24:06.401168 22542570456896 run_lib.py:146] step: 86300, eval_loss: 3.07948e-02
I0208 21:24:23.994731 22542570456896 run_lib.py:133] step: 86350, training_loss: 2.93268e-02
I0208 21:24:41.507243 22542570456896 run_lib.py:133] step: 86400, training_loss: 3.04251e-02
I0208 21:24:41.668315 22542570456896 run_lib.py:146] step: 86400, eval_loss: 2.64242e-02
I0208 21:24:59.068539 22542570456896 run_lib.py:133] step: 86450, training_loss: 2.65360e-02
I0208 21:25:16.676033 22542570456896 run_lib.py:133] step: 86500, training_loss: 3.15077e-02
I0208 21:25:16.831506 22542570456896 run_lib.py:146] step: 86500, eval_loss: 2.61371e-02
I0208 21:25:34.234776 22542570456896 run_lib.py:133] step: 86550, training_loss: 2.83087e-02
I0208 21:25:51.665604 22542570456896 run_lib.py:133] step: 86600, training_loss: 3.12309e-02
I0208 21:25:51.822345 22542570456896 run_lib.py:146] step: 86600, eval_loss: 3.46649e-02
I0208 21:26:09.438439 22542570456896 run_lib.py:133] step: 86650, training_loss: 2.50782e-02
I0208 21:26:27.122966 22542570456896 run_lib.py:133] step: 86700, training_loss: 2.64395e-02
I0208 21:26:27.282535 22542570456896 run_lib.py:146] step: 86700, eval_loss: 2.76076e-02
I0208 21:26:44.730731 22542570456896 run_lib.py:133] step: 86750, training_loss: 3.02047e-02
I0208 21:27:02.134549 22542570456896 run_lib.py:133] step: 86800, training_loss: 3.03640e-02
I0208 21:27:02.295651 22542570456896 run_lib.py:146] step: 86800, eval_loss: 2.62321e-02
I0208 21:27:19.752914 22542570456896 run_lib.py:133] step: 86850, training_loss: 3.42154e-02
I0208 21:27:37.314139 22542570456896 run_lib.py:133] step: 86900, training_loss: 2.67147e-02
I0208 21:27:37.480240 22542570456896 run_lib.py:146] step: 86900, eval_loss: 2.74103e-02
I0208 21:27:54.905816 22542570456896 run_lib.py:133] step: 86950, training_loss: 3.45615e-02
I0208 21:28:12.325334 22542570456896 run_lib.py:133] step: 87000, training_loss: 2.89732e-02
I0208 21:28:12.483084 22542570456896 run_lib.py:146] step: 87000, eval_loss: 2.28280e-02
I0208 21:28:29.886924 22542570456896 run_lib.py:133] step: 87050, training_loss: 3.22132e-02
I0208 21:28:47.515492 22542570456896 run_lib.py:133] step: 87100, training_loss: 3.05093e-02
I0208 21:28:47.669103 22542570456896 run_lib.py:146] step: 87100, eval_loss: 2.21184e-02
I0208 21:29:05.059579 22542570456896 run_lib.py:133] step: 87150, training_loss: 3.35500e-02
I0208 21:29:22.577441 22542570456896 run_lib.py:133] step: 87200, training_loss: 3.32940e-02
I0208 21:29:22.735548 22542570456896 run_lib.py:146] step: 87200, eval_loss: 3.60389e-02
I0208 21:29:40.208784 22542570456896 run_lib.py:133] step: 87250, training_loss: 3.69622e-02
I0208 21:29:57.685104 22542570456896 run_lib.py:133] step: 87300, training_loss: 2.90485e-02
I0208 21:29:57.844358 22542570456896 run_lib.py:146] step: 87300, eval_loss: 2.48654e-02
I0208 21:30:15.403858 22542570456896 run_lib.py:133] step: 87350, training_loss: 2.68160e-02
I0208 21:30:32.878888 22542570456896 run_lib.py:133] step: 87400, training_loss: 2.61268e-02
I0208 21:30:33.035310 22542570456896 run_lib.py:146] step: 87400, eval_loss: 3.28099e-02
I0208 21:30:50.448996 22542570456896 run_lib.py:133] step: 87450, training_loss: 3.13147e-02
I0208 21:31:07.883554 22542570456896 run_lib.py:133] step: 87500, training_loss: 2.87414e-02
I0208 21:31:08.041537 22542570456896 run_lib.py:146] step: 87500, eval_loss: 3.23236e-02
I0208 21:31:25.665065 22542570456896 run_lib.py:133] step: 87550, training_loss: 2.95409e-02
I0208 21:31:43.140264 22542570456896 run_lib.py:133] step: 87600, training_loss: 2.92130e-02
I0208 21:31:43.293372 22542570456896 run_lib.py:146] step: 87600, eval_loss: 2.13920e-02
I0208 21:32:00.893216 22542570456896 run_lib.py:133] step: 87650, training_loss: 2.15376e-02
I0208 21:32:18.349362 22542570456896 run_lib.py:133] step: 87700, training_loss: 3.29840e-02
I0208 21:32:18.506255 22542570456896 run_lib.py:146] step: 87700, eval_loss: 3.15605e-02
I0208 21:32:36.050221 22542570456896 run_lib.py:133] step: 87750, training_loss: 3.20983e-02
I0208 21:32:53.508265 22542570456896 run_lib.py:133] step: 87800, training_loss: 3.06996e-02
I0208 21:32:53.684187 22542570456896 run_lib.py:146] step: 87800, eval_loss: 2.44203e-02
I0208 21:33:11.172732 22542570456896 run_lib.py:133] step: 87850, training_loss: 2.53798e-02
I0208 21:33:28.778070 22542570456896 run_lib.py:133] step: 87900, training_loss: 2.36232e-02
I0208 21:33:28.932430 22542570456896 run_lib.py:146] step: 87900, eval_loss: 3.09097e-02
I0208 21:33:46.334961 22542570456896 run_lib.py:133] step: 87950, training_loss: 2.62960e-02
I0208 21:34:03.894015 22542570456896 run_lib.py:133] step: 88000, training_loss: 3.08176e-02
I0208 21:34:04.052828 22542570456896 run_lib.py:146] step: 88000, eval_loss: 2.68317e-02
I0208 21:34:21.536259 22542570456896 run_lib.py:133] step: 88050, training_loss: 2.94164e-02
I0208 21:34:38.987796 22542570456896 run_lib.py:133] step: 88100, training_loss: 2.75684e-02
I0208 21:34:39.142822 22542570456896 run_lib.py:146] step: 88100, eval_loss: 2.18779e-02
I0208 21:34:56.760637 22542570456896 run_lib.py:133] step: 88150, training_loss: 2.49182e-02
I0208 21:35:14.203372 22542570456896 run_lib.py:133] step: 88200, training_loss: 3.20773e-02
I0208 21:35:14.361707 22542570456896 run_lib.py:146] step: 88200, eval_loss: 2.93718e-02
I0208 21:35:31.766934 22542570456896 run_lib.py:133] step: 88250, training_loss: 2.69138e-02
I0208 21:35:49.319142 22542570456896 run_lib.py:133] step: 88300, training_loss: 3.08203e-02
I0208 21:35:49.477327 22542570456896 run_lib.py:146] step: 88300, eval_loss: 3.07364e-02
I0208 21:36:06.902653 22542570456896 run_lib.py:133] step: 88350, training_loss: 2.71717e-02
I0208 21:36:24.343535 22542570456896 run_lib.py:133] step: 88400, training_loss: 3.10728e-02
I0208 21:36:24.498043 22542570456896 run_lib.py:146] step: 88400, eval_loss: 2.29273e-02
I0208 21:36:42.017558 22542570456896 run_lib.py:133] step: 88450, training_loss: 3.07654e-02
I0208 21:36:59.462833 22542570456896 run_lib.py:133] step: 88500, training_loss: 3.05165e-02
I0208 21:36:59.617550 22542570456896 run_lib.py:146] step: 88500, eval_loss: 2.27834e-02
I0208 21:37:16.996455 22542570456896 run_lib.py:133] step: 88550, training_loss: 2.71375e-02
I0208 21:37:34.443202 22542570456896 run_lib.py:133] step: 88600, training_loss: 3.05871e-02
I0208 21:37:34.594302 22542570456896 run_lib.py:146] step: 88600, eval_loss: 2.36274e-02
I0208 21:37:52.229439 22542570456896 run_lib.py:133] step: 88650, training_loss: 3.65426e-02
I0208 21:38:09.789474 22542570456896 run_lib.py:133] step: 88700, training_loss: 3.00593e-02
I0208 21:38:09.950609 22542570456896 run_lib.py:146] step: 88700, eval_loss: 3.39317e-02
I0208 21:38:27.354536 22542570456896 run_lib.py:133] step: 88750, training_loss: 3.16339e-02
I0208 21:38:44.749235 22542570456896 run_lib.py:133] step: 88800, training_loss: 3.07559e-02
I0208 21:38:44.911339 22542570456896 run_lib.py:146] step: 88800, eval_loss: 1.99640e-02
I0208 21:39:02.480656 22542570456896 run_lib.py:133] step: 88850, training_loss: 2.52886e-02
I0208 21:39:19.964457 22542570456896 run_lib.py:133] step: 88900, training_loss: 2.71960e-02
I0208 21:39:20.123168 22542570456896 run_lib.py:146] step: 88900, eval_loss: 2.59640e-02
I0208 21:39:37.736023 22542570456896 run_lib.py:133] step: 88950, training_loss: 3.58077e-02
I0208 21:39:55.171071 22542570456896 run_lib.py:133] step: 89000, training_loss: 2.45906e-02
I0208 21:39:55.324130 22542570456896 run_lib.py:146] step: 89000, eval_loss: 3.07402e-02
I0208 21:40:12.930335 22542570456896 run_lib.py:133] step: 89050, training_loss: 2.53035e-02
I0208 21:40:30.365982 22542570456896 run_lib.py:133] step: 89100, training_loss: 2.93022e-02
I0208 21:40:30.529455 22542570456896 run_lib.py:146] step: 89100, eval_loss: 2.48895e-02
I0208 21:40:48.070176 22542570456896 run_lib.py:133] step: 89150, training_loss: 2.49593e-02
I0208 21:41:05.504909 22542570456896 run_lib.py:133] step: 89200, training_loss: 2.63690e-02
I0208 21:41:05.675073 22542570456896 run_lib.py:146] step: 89200, eval_loss: 2.97908e-02
I0208 21:41:23.189538 22542570456896 run_lib.py:133] step: 89250, training_loss: 2.40579e-02
I0208 21:41:40.772602 22542570456896 run_lib.py:133] step: 89300, training_loss: 3.41542e-02
I0208 21:41:40.929366 22542570456896 run_lib.py:146] step: 89300, eval_loss: 3.49666e-02
I0208 21:41:58.338705 22542570456896 run_lib.py:133] step: 89350, training_loss: 3.59236e-02
I0208 21:42:15.760749 22542570456896 run_lib.py:133] step: 89400, training_loss: 2.45275e-02
I0208 21:42:15.917273 22542570456896 run_lib.py:146] step: 89400, eval_loss: 2.82106e-02
I0208 21:42:33.516792 22542570456896 run_lib.py:133] step: 89450, training_loss: 3.65351e-02
I0208 21:42:50.993885 22542570456896 run_lib.py:133] step: 89500, training_loss: 3.10274e-02
I0208 21:42:51.156550 22542570456896 run_lib.py:146] step: 89500, eval_loss: 3.14254e-02
I0208 21:43:08.809945 22542570456896 run_lib.py:133] step: 89550, training_loss: 2.58183e-02
I0208 21:43:26.281781 22542570456896 run_lib.py:133] step: 89600, training_loss: 3.19145e-02
I0208 21:43:26.437422 22542570456896 run_lib.py:146] step: 89600, eval_loss: 3.28711e-02
I0208 21:43:43.864650 22542570456896 run_lib.py:133] step: 89650, training_loss: 2.32916e-02
I0208 21:44:01.445254 22542570456896 run_lib.py:133] step: 89700, training_loss: 2.95462e-02
I0208 21:44:01.606409 22542570456896 run_lib.py:146] step: 89700, eval_loss: 3.04772e-02
I0208 21:44:19.012165 22542570456896 run_lib.py:133] step: 89750, training_loss: 2.87998e-02
I0208 21:44:36.439046 22542570456896 run_lib.py:133] step: 89800, training_loss: 3.56574e-02
I0208 21:44:36.596514 22542570456896 run_lib.py:146] step: 89800, eval_loss: 3.21655e-02
I0208 21:44:54.050588 22542570456896 run_lib.py:133] step: 89850, training_loss: 2.44915e-02
I0208 21:45:11.640306 22542570456896 run_lib.py:133] step: 89900, training_loss: 2.34207e-02
I0208 21:45:11.795266 22542570456896 run_lib.py:146] step: 89900, eval_loss: 1.91543e-02
I0208 21:45:29.200083 22542570456896 run_lib.py:133] step: 89950, training_loss: 2.90354e-02
I0208 21:45:46.707464 22542570456896 run_lib.py:133] step: 90000, training_loss: 2.96495e-02
I0208 21:45:47.405305 22542570456896 run_lib.py:146] step: 90000, eval_loss: 3.07465e-02
I0208 21:46:07.460229 22542570456896 run_lib.py:133] step: 90050, training_loss: 2.44442e-02
I0208 21:46:24.885734 22542570456896 run_lib.py:133] step: 90100, training_loss: 3.10095e-02
I0208 21:46:25.042600 22542570456896 run_lib.py:146] step: 90100, eval_loss: 2.64563e-02
I0208 21:46:42.696023 22542570456896 run_lib.py:133] step: 90150, training_loss: 2.65362e-02
I0208 21:47:00.144049 22542570456896 run_lib.py:133] step: 90200, training_loss: 3.44037e-02
I0208 21:47:00.303532 22542570456896 run_lib.py:146] step: 90200, eval_loss: 2.41155e-02
I0208 21:47:17.776293 22542570456896 run_lib.py:133] step: 90250, training_loss: 3.11482e-02
I0208 21:47:35.195794 22542570456896 run_lib.py:133] step: 90300, training_loss: 3.00959e-02
I0208 21:47:35.362284 22542570456896 run_lib.py:146] step: 90300, eval_loss: 2.87100e-02
I0208 21:47:52.797364 22542570456896 run_lib.py:133] step: 90350, training_loss: 2.88737e-02
I0208 21:48:10.266851 22542570456896 run_lib.py:133] step: 90400, training_loss: 2.61495e-02
I0208 21:48:10.432115 22542570456896 run_lib.py:146] step: 90400, eval_loss: 2.53791e-02
I0208 21:48:28.046865 22542570456896 run_lib.py:133] step: 90450, training_loss: 3.12125e-02
I0208 21:48:45.524665 22542570456896 run_lib.py:133] step: 90500, training_loss: 2.74524e-02
I0208 21:48:45.686423 22542570456896 run_lib.py:146] step: 90500, eval_loss: 2.78501e-02
I0208 21:49:03.144235 22542570456896 run_lib.py:133] step: 90550, training_loss: 3.43017e-02
I0208 21:49:20.595925 22542570456896 run_lib.py:133] step: 90600, training_loss: 2.44917e-02
I0208 21:49:20.770394 22542570456896 run_lib.py:146] step: 90600, eval_loss: 3.10297e-02
I0208 21:49:38.388376 22542570456896 run_lib.py:133] step: 90650, training_loss: 3.23871e-02
I0208 21:49:55.834300 22542570456896 run_lib.py:133] step: 90700, training_loss: 2.75775e-02
I0208 21:49:55.993557 22542570456896 run_lib.py:146] step: 90700, eval_loss: 3.34283e-02
I0208 21:50:13.572908 22542570456896 run_lib.py:133] step: 90750, training_loss: 2.79194e-02
I0208 21:50:30.998383 22542570456896 run_lib.py:133] step: 90800, training_loss: 2.87949e-02
I0208 21:50:31.163228 22542570456896 run_lib.py:146] step: 90800, eval_loss: 2.76235e-02
I0208 21:50:48.719764 22542570456896 run_lib.py:133] step: 90850, training_loss: 2.53234e-02
I0208 21:51:06.135793 22542570456896 run_lib.py:133] step: 90900, training_loss: 2.80783e-02
I0208 21:51:06.297759 22542570456896 run_lib.py:146] step: 90900, eval_loss: 2.95375e-02
I0208 21:51:23.758177 22542570456896 run_lib.py:133] step: 90950, training_loss: 3.30803e-02
I0208 21:51:41.405967 22542570456896 run_lib.py:133] step: 91000, training_loss: 2.66498e-02
I0208 21:51:41.558481 22542570456896 run_lib.py:146] step: 91000, eval_loss: 3.14721e-02
I0208 21:51:59.000249 22542570456896 run_lib.py:133] step: 91050, training_loss: 2.93192e-02
I0208 21:52:16.570307 22542570456896 run_lib.py:133] step: 91100, training_loss: 3.07202e-02
I0208 21:52:16.727379 22542570456896 run_lib.py:146] step: 91100, eval_loss: 2.22203e-02
I0208 21:52:34.126306 22542570456896 run_lib.py:133] step: 91150, training_loss: 2.48727e-02
I0208 21:52:51.579077 22542570456896 run_lib.py:133] step: 91200, training_loss: 2.72242e-02
I0208 21:52:51.751464 22542570456896 run_lib.py:146] step: 91200, eval_loss: 2.79363e-02
I0208 21:53:09.392256 22542570456896 run_lib.py:133] step: 91250, training_loss: 2.82665e-02
I0208 21:53:26.812466 22542570456896 run_lib.py:133] step: 91300, training_loss: 2.84263e-02
I0208 21:53:26.969504 22542570456896 run_lib.py:146] step: 91300, eval_loss: 3.33172e-02
I0208 21:53:44.383703 22542570456896 run_lib.py:133] step: 91350, training_loss: 2.85464e-02
I0208 21:54:01.956838 22542570456896 run_lib.py:133] step: 91400, training_loss: 2.80674e-02
I0208 21:54:02.112263 22542570456896 run_lib.py:146] step: 91400, eval_loss: 2.61940e-02
I0208 21:54:19.544556 22542570456896 run_lib.py:133] step: 91450, training_loss: 3.51817e-02
I0208 21:54:36.986153 22542570456896 run_lib.py:133] step: 91500, training_loss: 2.52157e-02
I0208 21:54:37.287232 22542570456896 run_lib.py:146] step: 91500, eval_loss: 3.79290e-02
I0208 21:54:54.762708 22542570456896 run_lib.py:133] step: 91550, training_loss: 3.86215e-02
I0208 21:55:12.240333 22542570456896 run_lib.py:133] step: 91600, training_loss: 3.05162e-02
I0208 21:55:12.407357 22542570456896 run_lib.py:146] step: 91600, eval_loss: 2.56450e-02
I0208 21:55:29.817101 22542570456896 run_lib.py:133] step: 91650, training_loss: 2.61197e-02
I0208 21:55:47.237740 22542570456896 run_lib.py:133] step: 91700, training_loss: 2.66334e-02
I0208 21:55:47.397687 22542570456896 run_lib.py:146] step: 91700, eval_loss: 2.52769e-02
I0208 21:56:05.046759 22542570456896 run_lib.py:133] step: 91750, training_loss: 3.82980e-02
I0208 21:56:22.610189 22542570456896 run_lib.py:133] step: 91800, training_loss: 3.11542e-02
I0208 21:56:22.768276 22542570456896 run_lib.py:146] step: 91800, eval_loss: 2.44353e-02
I0208 21:56:40.243199 22542570456896 run_lib.py:133] step: 91850, training_loss: 2.70104e-02
I0208 21:56:57.677875 22542570456896 run_lib.py:133] step: 91900, training_loss: 2.57066e-02
I0208 21:56:57.836177 22542570456896 run_lib.py:146] step: 91900, eval_loss: 2.86409e-02
I0208 21:57:15.425858 22542570456896 run_lib.py:133] step: 91950, training_loss: 2.90839e-02
I0208 21:57:32.916202 22542570456896 run_lib.py:133] step: 92000, training_loss: 2.87282e-02
I0208 21:57:33.072825 22542570456896 run_lib.py:146] step: 92000, eval_loss: 2.57717e-02
I0208 21:57:50.594028 22542570456896 run_lib.py:133] step: 92050, training_loss: 2.90850e-02
I0208 21:58:08.050202 22542570456896 run_lib.py:133] step: 92100, training_loss: 2.63204e-02
I0208 21:58:08.209306 22542570456896 run_lib.py:146] step: 92100, eval_loss: 3.46822e-02
I0208 21:58:25.819729 22542570456896 run_lib.py:133] step: 92150, training_loss: 2.82513e-02
I0208 21:58:43.239038 22542570456896 run_lib.py:133] step: 92200, training_loss: 3.01834e-02
I0208 21:58:43.396345 22542570456896 run_lib.py:146] step: 92200, eval_loss: 3.34266e-02
I0208 21:59:00.984464 22542570456896 run_lib.py:133] step: 92250, training_loss: 3.27165e-02
I0208 21:59:18.422025 22542570456896 run_lib.py:133] step: 92300, training_loss: 2.70573e-02
I0208 21:59:18.579512 22542570456896 run_lib.py:146] step: 92300, eval_loss: 2.32365e-02
I0208 21:59:36.240257 22542570456896 run_lib.py:133] step: 92350, training_loss: 2.85938e-02
I0208 21:59:53.659589 22542570456896 run_lib.py:133] step: 92400, training_loss: 2.48912e-02
I0208 21:59:53.816432 22542570456896 run_lib.py:146] step: 92400, eval_loss: 2.96615e-02
I0208 22:00:11.203225 22542570456896 run_lib.py:133] step: 92450, training_loss: 3.57486e-02
I0208 22:00:28.748718 22542570456896 run_lib.py:133] step: 92500, training_loss: 2.78935e-02
I0208 22:00:28.908454 22542570456896 run_lib.py:146] step: 92500, eval_loss: 2.47910e-02
I0208 22:00:46.301763 22542570456896 run_lib.py:133] step: 92550, training_loss: 2.86585e-02
I0208 22:01:03.885314 22542570456896 run_lib.py:133] step: 92600, training_loss: 2.89651e-02
I0208 22:01:04.061402 22542570456896 run_lib.py:146] step: 92600, eval_loss: 3.21248e-02
I0208 22:01:21.482957 22542570456896 run_lib.py:133] step: 92650, training_loss: 2.32302e-02
I0208 22:01:38.891162 22542570456896 run_lib.py:133] step: 92700, training_loss: 3.17079e-02
I0208 22:01:39.047650 22542570456896 run_lib.py:146] step: 92700, eval_loss: 2.45073e-02
I0208 22:01:56.658406 22542570456896 run_lib.py:133] step: 92750, training_loss: 3.18251e-02
I0208 22:02:14.034390 22542570456896 run_lib.py:133] step: 92800, training_loss: 2.70617e-02
I0208 22:02:14.190311 22542570456896 run_lib.py:146] step: 92800, eval_loss: 3.37118e-02
I0208 22:02:31.593306 22542570456896 run_lib.py:133] step: 92850, training_loss: 3.50436e-02
I0208 22:02:49.049901 22542570456896 run_lib.py:133] step: 92900, training_loss: 3.43009e-02
I0208 22:02:49.204628 22542570456896 run_lib.py:146] step: 92900, eval_loss: 2.86502e-02
I0208 22:03:06.883857 22542570456896 run_lib.py:133] step: 92950, training_loss: 2.77733e-02
I0208 22:03:24.356367 22542570456896 run_lib.py:133] step: 93000, training_loss: 3.20316e-02
I0208 22:03:24.520483 22542570456896 run_lib.py:146] step: 93000, eval_loss: 2.74485e-02
I0208 22:03:41.980770 22542570456896 run_lib.py:133] step: 93050, training_loss: 2.43984e-02
I0208 22:03:59.402376 22542570456896 run_lib.py:133] step: 93100, training_loss: 3.00849e-02
I0208 22:03:59.578482 22542570456896 run_lib.py:146] step: 93100, eval_loss: 2.83915e-02
I0208 22:04:17.080210 22542570456896 run_lib.py:133] step: 93150, training_loss: 3.14019e-02
I0208 22:04:34.509165 22542570456896 run_lib.py:133] step: 93200, training_loss: 2.27231e-02
I0208 22:04:34.666540 22542570456896 run_lib.py:146] step: 93200, eval_loss: 3.09155e-02
I0208 22:04:52.266120 22542570456896 run_lib.py:133] step: 93250, training_loss: 3.27055e-02
I0208 22:05:09.727692 22542570456896 run_lib.py:133] step: 93300, training_loss: 3.09875e-02
I0208 22:05:09.883339 22542570456896 run_lib.py:146] step: 93300, eval_loss: 2.75035e-02
I0208 22:05:27.308161 22542570456896 run_lib.py:133] step: 93350, training_loss: 3.40248e-02
I0208 22:05:44.776026 22542570456896 run_lib.py:133] step: 93400, training_loss: 2.11492e-02
I0208 22:05:44.939490 22542570456896 run_lib.py:146] step: 93400, eval_loss: 3.81404e-02
I0208 22:06:02.615383 22542570456896 run_lib.py:133] step: 93450, training_loss: 2.82878e-02
I0208 22:06:20.034600 22542570456896 run_lib.py:133] step: 93500, training_loss: 2.88321e-02
I0208 22:06:20.193243 22542570456896 run_lib.py:146] step: 93500, eval_loss: 2.73517e-02
I0208 22:06:37.783804 22542570456896 run_lib.py:133] step: 93550, training_loss: 2.79556e-02
I0208 22:06:55.202171 22542570456896 run_lib.py:133] step: 93600, training_loss: 2.87170e-02
I0208 22:06:55.359634 22542570456896 run_lib.py:146] step: 93600, eval_loss: 2.70589e-02
I0208 22:07:12.956191 22542570456896 run_lib.py:133] step: 93650, training_loss: 3.46278e-02
I0208 22:07:30.449749 22542570456896 run_lib.py:133] step: 93700, training_loss: 3.17259e-02
I0208 22:07:30.606146 22542570456896 run_lib.py:146] step: 93700, eval_loss: 2.62901e-02
I0208 22:07:48.229571 22542570456896 run_lib.py:133] step: 93750, training_loss: 3.02734e-02
I0208 22:08:05.645799 22542570456896 run_lib.py:133] step: 93800, training_loss: 3.41756e-02
I0208 22:08:05.800047 22542570456896 run_lib.py:146] step: 93800, eval_loss: 2.70239e-02
I0208 22:08:23.181199 22542570456896 run_lib.py:133] step: 93850, training_loss: 3.08645e-02
I0208 22:08:40.721770 22542570456896 run_lib.py:133] step: 93900, training_loss: 3.22719e-02
I0208 22:08:40.882651 22542570456896 run_lib.py:146] step: 93900, eval_loss: 2.77455e-02
I0208 22:08:58.415887 22542570456896 run_lib.py:133] step: 93950, training_loss: 3.06903e-02
I0208 22:09:15.853088 22542570456896 run_lib.py:133] step: 94000, training_loss: 2.75630e-02
I0208 22:09:16.012302 22542570456896 run_lib.py:146] step: 94000, eval_loss: 2.40575e-02
I0208 22:09:33.598077 22542570456896 run_lib.py:133] step: 94050, training_loss: 2.94248e-02
I0208 22:09:51.180732 22542570456896 run_lib.py:133] step: 94100, training_loss: 2.68768e-02
I0208 22:09:51.335032 22542570456896 run_lib.py:146] step: 94100, eval_loss: 2.49033e-02
I0208 22:10:08.743975 22542570456896 run_lib.py:133] step: 94150, training_loss: 3.47416e-02
I0208 22:10:26.144868 22542570456896 run_lib.py:133] step: 94200, training_loss: 2.87628e-02
I0208 22:10:26.303701 22542570456896 run_lib.py:146] step: 94200, eval_loss: 2.78860e-02
I0208 22:10:43.765886 22542570456896 run_lib.py:133] step: 94250, training_loss: 2.76596e-02
I0208 22:11:01.407276 22542570456896 run_lib.py:133] step: 94300, training_loss: 2.52491e-02
I0208 22:11:01.560234 22542570456896 run_lib.py:146] step: 94300, eval_loss: 2.22535e-02
I0208 22:11:18.868356 22542570456896 run_lib.py:133] step: 94350, training_loss: 2.96584e-02
I0208 22:11:36.196931 22542570456896 run_lib.py:133] step: 94400, training_loss: 3.17257e-02
I0208 22:11:36.351042 22542570456896 run_lib.py:146] step: 94400, eval_loss: 3.42258e-02
I0208 22:11:53.699900 22542570456896 run_lib.py:133] step: 94450, training_loss: 2.18237e-02
I0208 22:12:11.224421 22542570456896 run_lib.py:133] step: 94500, training_loss: 2.54660e-02
I0208 22:12:11.389442 22542570456896 run_lib.py:146] step: 94500, eval_loss: 3.14065e-02
I0208 22:12:28.801918 22542570456896 run_lib.py:133] step: 94550, training_loss: 3.03464e-02
I0208 22:12:46.329050 22542570456896 run_lib.py:133] step: 94600, training_loss: 2.60007e-02
I0208 22:12:46.485392 22542570456896 run_lib.py:146] step: 94600, eval_loss: 2.83520e-02
I0208 22:13:03.924649 22542570456896 run_lib.py:133] step: 94650, training_loss: 2.51734e-02
I0208 22:13:21.354698 22542570456896 run_lib.py:133] step: 94700, training_loss: 3.11133e-02
I0208 22:13:21.512560 22542570456896 run_lib.py:146] step: 94700, eval_loss: 2.96883e-02
I0208 22:13:39.101302 22542570456896 run_lib.py:133] step: 94750, training_loss: 2.99622e-02
I0208 22:13:56.613514 22542570456896 run_lib.py:133] step: 94800, training_loss: 3.04200e-02
I0208 22:13:56.766492 22542570456896 run_lib.py:146] step: 94800, eval_loss: 3.54387e-02
I0208 22:14:14.177124 22542570456896 run_lib.py:133] step: 94850, training_loss: 2.82448e-02
I0208 22:14:31.592813 22542570456896 run_lib.py:133] step: 94900, training_loss: 2.68507e-02
I0208 22:14:31.750593 22542570456896 run_lib.py:146] step: 94900, eval_loss: 2.81365e-02
I0208 22:14:49.314295 22542570456896 run_lib.py:133] step: 94950, training_loss: 3.60211e-02
I0208 22:15:06.768494 22542570456896 run_lib.py:133] step: 95000, training_loss: 2.61228e-02
I0208 22:15:06.954587 22542570456896 run_lib.py:146] step: 95000, eval_loss: 3.29824e-02
I0208 22:15:24.612978 22542570456896 run_lib.py:133] step: 95050, training_loss: 3.62274e-02
I0208 22:15:42.061244 22542570456896 run_lib.py:133] step: 95100, training_loss: 2.89210e-02
I0208 22:15:42.217586 22542570456896 run_lib.py:146] step: 95100, eval_loss: 2.33118e-02
I0208 22:15:59.839584 22542570456896 run_lib.py:133] step: 95150, training_loss: 2.73126e-02
I0208 22:16:17.271609 22542570456896 run_lib.py:133] step: 95200, training_loss: 2.75186e-02
I0208 22:16:17.429341 22542570456896 run_lib.py:146] step: 95200, eval_loss: 3.38593e-02
I0208 22:16:34.868658 22542570456896 run_lib.py:133] step: 95250, training_loss: 2.80030e-02
I0208 22:16:52.520352 22542570456896 run_lib.py:133] step: 95300, training_loss: 2.58643e-02
I0208 22:16:52.677576 22542570456896 run_lib.py:146] step: 95300, eval_loss: 2.54349e-02
I0208 22:17:10.160367 22542570456896 run_lib.py:133] step: 95350, training_loss: 2.90249e-02
I0208 22:17:27.767595 22542570456896 run_lib.py:133] step: 95400, training_loss: 2.44290e-02
I0208 22:17:27.928650 22542570456896 run_lib.py:146] step: 95400, eval_loss: 3.09390e-02
I0208 22:17:45.287971 22542570456896 run_lib.py:133] step: 95450, training_loss: 3.04165e-02
I0208 22:18:02.693931 22542570456896 run_lib.py:133] step: 95500, training_loss: 2.86018e-02
I0208 22:18:02.857351 22542570456896 run_lib.py:146] step: 95500, eval_loss: 3.08571e-02
I0208 22:18:20.424923 22542570456896 run_lib.py:133] step: 95550, training_loss: 2.71335e-02
I0208 22:18:37.907603 22542570456896 run_lib.py:133] step: 95600, training_loss: 3.05015e-02
I0208 22:18:38.064755 22542570456896 run_lib.py:146] step: 95600, eval_loss: 2.86787e-02
I0208 22:18:55.490020 22542570456896 run_lib.py:133] step: 95650, training_loss: 3.18416e-02
I0208 22:19:13.134369 22542570456896 run_lib.py:133] step: 95700, training_loss: 2.16432e-02
I0208 22:19:13.288074 22542570456896 run_lib.py:146] step: 95700, eval_loss: 3.28897e-02
I0208 22:19:30.676755 22542570456896 run_lib.py:133] step: 95750, training_loss: 2.73274e-02
I0208 22:19:48.088664 22542570456896 run_lib.py:133] step: 95800, training_loss: 2.55960e-02
I0208 22:19:48.258084 22542570456896 run_lib.py:146] step: 95800, eval_loss: 2.74279e-02
I0208 22:20:05.813502 22542570456896 run_lib.py:133] step: 95850, training_loss: 2.17778e-02
I0208 22:20:23.268636 22542570456896 run_lib.py:133] step: 95900, training_loss: 3.08527e-02
I0208 22:20:23.428392 22542570456896 run_lib.py:146] step: 95900, eval_loss: 2.61833e-02
I0208 22:20:40.838450 22542570456896 run_lib.py:133] step: 95950, training_loss: 3.11754e-02
I0208 22:20:58.247723 22542570456896 run_lib.py:133] step: 96000, training_loss: 3.50917e-02
I0208 22:20:58.413269 22542570456896 run_lib.py:146] step: 96000, eval_loss: 2.53153e-02
I0208 22:21:15.993805 22542570456896 run_lib.py:133] step: 96050, training_loss: 2.32603e-02
I0208 22:21:33.540927 22542570456896 run_lib.py:133] step: 96100, training_loss: 3.14633e-02
I0208 22:21:33.698666 22542570456896 run_lib.py:146] step: 96100, eval_loss: 2.81461e-02
I0208 22:21:51.179705 22542570456896 run_lib.py:133] step: 96150, training_loss: 2.47318e-02
I0208 22:22:08.575348 22542570456896 run_lib.py:133] step: 96200, training_loss: 2.92937e-02
I0208 22:22:08.729085 22542570456896 run_lib.py:146] step: 96200, eval_loss: 2.40828e-02
I0208 22:22:26.350025 22542570456896 run_lib.py:133] step: 96250, training_loss: 2.84531e-02
I0208 22:22:43.802021 22542570456896 run_lib.py:133] step: 96300, training_loss: 2.75608e-02
I0208 22:22:43.958518 22542570456896 run_lib.py:146] step: 96300, eval_loss: 2.81744e-02
I0208 22:23:01.581759 22542570456896 run_lib.py:133] step: 96350, training_loss: 3.36844e-02
I0208 22:23:19.018655 22542570456896 run_lib.py:133] step: 96400, training_loss: 3.06542e-02
I0208 22:23:19.178452 22542570456896 run_lib.py:146] step: 96400, eval_loss: 2.59323e-02
I0208 22:23:36.785582 22542570456896 run_lib.py:133] step: 96450, training_loss: 2.74995e-02
I0208 22:23:54.172287 22542570456896 run_lib.py:133] step: 96500, training_loss: 2.63990e-02
I0208 22:23:54.328347 22542570456896 run_lib.py:146] step: 96500, eval_loss: 3.38543e-02
I0208 22:24:11.903980 22542570456896 run_lib.py:133] step: 96550, training_loss: 2.50922e-02
I0208 22:24:29.342314 22542570456896 run_lib.py:133] step: 96600, training_loss: 3.33354e-02
I0208 22:24:29.499182 22542570456896 run_lib.py:146] step: 96600, eval_loss: 2.63087e-02
I0208 22:24:46.979874 22542570456896 run_lib.py:133] step: 96650, training_loss: 2.82854e-02
I0208 22:25:04.563011 22542570456896 run_lib.py:133] step: 96700, training_loss: 3.12432e-02
I0208 22:25:04.716192 22542570456896 run_lib.py:146] step: 96700, eval_loss: 2.84683e-02
I0208 22:25:22.114034 22542570456896 run_lib.py:133] step: 96750, training_loss: 3.37566e-02
I0208 22:25:39.553459 22542570456896 run_lib.py:133] step: 96800, training_loss: 2.25912e-02
I0208 22:25:39.710341 22542570456896 run_lib.py:146] step: 96800, eval_loss: 3.41104e-02
I0208 22:25:57.362030 22542570456896 run_lib.py:133] step: 96850, training_loss: 2.87583e-02
I0208 22:26:14.836461 22542570456896 run_lib.py:133] step: 96900, training_loss: 2.70980e-02
I0208 22:26:14.996365 22542570456896 run_lib.py:146] step: 96900, eval_loss: 2.83336e-02
I0208 22:26:32.636857 22542570456896 run_lib.py:133] step: 96950, training_loss: 3.31599e-02
I0208 22:26:50.059926 22542570456896 run_lib.py:133] step: 97000, training_loss: 2.71376e-02
I0208 22:26:50.216055 22542570456896 run_lib.py:146] step: 97000, eval_loss: 3.08652e-02
I0208 22:27:07.648278 22542570456896 run_lib.py:133] step: 97050, training_loss: 3.14135e-02
I0208 22:27:25.242500 22542570456896 run_lib.py:133] step: 97100, training_loss: 3.00077e-02
I0208 22:27:25.399738 22542570456896 run_lib.py:146] step: 97100, eval_loss: 2.56867e-02
I0208 22:27:42.859665 22542570456896 run_lib.py:133] step: 97150, training_loss: 3.29542e-02
I0208 22:28:00.283078 22542570456896 run_lib.py:133] step: 97200, training_loss: 2.37864e-02
I0208 22:28:00.437358 22542570456896 run_lib.py:146] step: 97200, eval_loss: 2.44145e-02
I0208 22:28:17.852901 22542570456896 run_lib.py:133] step: 97250, training_loss: 2.75841e-02
I0208 22:28:35.466768 22542570456896 run_lib.py:133] step: 97300, training_loss: 2.69162e-02
I0208 22:28:35.635522 22542570456896 run_lib.py:146] step: 97300, eval_loss: 2.88075e-02
I0208 22:28:53.059939 22542570456896 run_lib.py:133] step: 97350, training_loss: 2.93528e-02
I0208 22:29:10.526831 22542570456896 run_lib.py:133] step: 97400, training_loss: 3.01654e-02
I0208 22:29:10.694286 22542570456896 run_lib.py:146] step: 97400, eval_loss: 2.76661e-02
I0208 22:29:28.141576 22542570456896 run_lib.py:133] step: 97450, training_loss: 2.28793e-02
I0208 22:29:45.551450 22542570456896 run_lib.py:133] step: 97500, training_loss: 3.05749e-02
I0208 22:29:45.708904 22542570456896 run_lib.py:146] step: 97500, eval_loss: 2.74117e-02
I0208 22:30:03.330919 22542570456896 run_lib.py:133] step: 97550, training_loss: 3.04283e-02
I0208 22:30:20.796350 22542570456896 run_lib.py:133] step: 97600, training_loss: 2.73850e-02
I0208 22:30:20.954135 22542570456896 run_lib.py:146] step: 97600, eval_loss: 2.77898e-02
I0208 22:30:38.380896 22542570456896 run_lib.py:133] step: 97650, training_loss: 2.66044e-02
I0208 22:30:55.811836 22542570456896 run_lib.py:133] step: 97700, training_loss: 3.11214e-02
I0208 22:30:55.981515 22542570456896 run_lib.py:146] step: 97700, eval_loss: 2.88696e-02
I0208 22:31:13.695009 22542570456896 run_lib.py:133] step: 97750, training_loss: 3.04761e-02
I0208 22:31:31.144775 22542570456896 run_lib.py:133] step: 97800, training_loss: 2.62852e-02
I0208 22:31:31.301543 22542570456896 run_lib.py:146] step: 97800, eval_loss: 2.76305e-02
I0208 22:31:48.870479 22542570456896 run_lib.py:133] step: 97850, training_loss: 2.91772e-02
I0208 22:32:06.296688 22542570456896 run_lib.py:133] step: 97900, training_loss: 2.52294e-02
I0208 22:32:06.453154 22542570456896 run_lib.py:146] step: 97900, eval_loss: 2.90902e-02
I0208 22:32:24.007819 22542570456896 run_lib.py:133] step: 97950, training_loss: 2.70595e-02
I0208 22:32:41.492746 22542570456896 run_lib.py:133] step: 98000, training_loss: 2.76912e-02
I0208 22:32:41.650853 22542570456896 run_lib.py:146] step: 98000, eval_loss: 3.34763e-02
I0208 22:32:59.126330 22542570456896 run_lib.py:133] step: 98050, training_loss: 2.77559e-02
I0208 22:33:16.714861 22542570456896 run_lib.py:133] step: 98100, training_loss: 2.45685e-02
I0208 22:33:16.868401 22542570456896 run_lib.py:146] step: 98100, eval_loss: 3.04929e-02
I0208 22:33:34.292139 22542570456896 run_lib.py:133] step: 98150, training_loss: 2.20299e-02
I0208 22:33:51.864843 22542570456896 run_lib.py:133] step: 98200, training_loss: 3.07467e-02
I0208 22:33:52.018369 22542570456896 run_lib.py:146] step: 98200, eval_loss: 2.60848e-02
I0208 22:34:09.428885 22542570456896 run_lib.py:133] step: 98250, training_loss: 2.94914e-02
I0208 22:34:26.898761 22542570456896 run_lib.py:133] step: 98300, training_loss: 2.94075e-02
I0208 22:34:27.060298 22542570456896 run_lib.py:146] step: 98300, eval_loss: 3.32473e-02
I0208 22:34:44.663180 22542570456896 run_lib.py:133] step: 98350, training_loss: 2.89611e-02
I0208 22:35:02.083894 22542570456896 run_lib.py:133] step: 98400, training_loss: 2.87866e-02
I0208 22:35:02.247891 22542570456896 run_lib.py:146] step: 98400, eval_loss: 2.50973e-02
I0208 22:35:19.639178 22542570456896 run_lib.py:133] step: 98450, training_loss: 2.81528e-02
I0208 22:35:37.160873 22542570456896 run_lib.py:133] step: 98500, training_loss: 2.53739e-02
I0208 22:35:37.312043 22542570456896 run_lib.py:146] step: 98500, eval_loss: 3.22703e-02
I0208 22:35:54.726378 22542570456896 run_lib.py:133] step: 98550, training_loss: 3.35028e-02
I0208 22:36:12.232971 22542570456896 run_lib.py:133] step: 98600, training_loss: 3.23317e-02
I0208 22:36:12.572330 22542570456896 run_lib.py:146] step: 98600, eval_loss: 2.45590e-02
I0208 22:36:30.004699 22542570456896 run_lib.py:133] step: 98650, training_loss: 2.62448e-02
I0208 22:36:47.444856 22542570456896 run_lib.py:133] step: 98700, training_loss: 3.28496e-02
I0208 22:36:47.599125 22542570456896 run_lib.py:146] step: 98700, eval_loss: 3.25237e-02
I0208 22:37:05.045176 22542570456896 run_lib.py:133] step: 98750, training_loss: 2.80987e-02
I0208 22:37:22.467993 22542570456896 run_lib.py:133] step: 98800, training_loss: 2.55853e-02
I0208 22:37:22.635366 22542570456896 run_lib.py:146] step: 98800, eval_loss: 2.89328e-02
I0208 22:37:40.216069 22542570456896 run_lib.py:133] step: 98850, training_loss: 2.58238e-02
I0208 22:37:57.812018 22542570456896 run_lib.py:133] step: 98900, training_loss: 2.89188e-02
I0208 22:37:57.968965 22542570456896 run_lib.py:146] step: 98900, eval_loss: 2.82847e-02
I0208 22:38:15.420142 22542570456896 run_lib.py:133] step: 98950, training_loss: 2.22681e-02
I0208 22:38:32.828475 22542570456896 run_lib.py:133] step: 99000, training_loss: 2.80216e-02
I0208 22:38:32.985269 22542570456896 run_lib.py:146] step: 99000, eval_loss: 3.23228e-02
I0208 22:38:50.564485 22542570456896 run_lib.py:133] step: 99050, training_loss: 3.21812e-02
I0208 22:39:08.071012 22542570456896 run_lib.py:133] step: 99100, training_loss: 3.20758e-02
I0208 22:39:08.226669 22542570456896 run_lib.py:146] step: 99100, eval_loss: 3.43401e-02
I0208 22:39:25.736807 22542570456896 run_lib.py:133] step: 99150, training_loss: 2.96627e-02
I0208 22:39:43.210064 22542570456896 run_lib.py:133] step: 99200, training_loss: 2.54575e-02
I0208 22:39:43.369280 22542570456896 run_lib.py:146] step: 99200, eval_loss: 2.24813e-02
I0208 22:40:00.964489 22542570456896 run_lib.py:133] step: 99250, training_loss: 3.43451e-02
I0208 22:40:18.379544 22542570456896 run_lib.py:133] step: 99300, training_loss: 2.32239e-02
I0208 22:40:18.535510 22542570456896 run_lib.py:146] step: 99300, eval_loss: 2.68311e-02
I0208 22:40:36.117394 22542570456896 run_lib.py:133] step: 99350, training_loss: 2.61877e-02
I0208 22:40:53.606414 22542570456896 run_lib.py:133] step: 99400, training_loss: 3.13355e-02
I0208 22:40:53.764083 22542570456896 run_lib.py:146] step: 99400, eval_loss: 2.92298e-02
I0208 22:41:11.408766 22542570456896 run_lib.py:133] step: 99450, training_loss: 2.44444e-02
I0208 22:41:28.821488 22542570456896 run_lib.py:133] step: 99500, training_loss: 3.29599e-02
I0208 22:41:28.974103 22542570456896 run_lib.py:146] step: 99500, eval_loss: 2.85850e-02
I0208 22:41:46.416770 22542570456896 run_lib.py:133] step: 99550, training_loss: 3.05045e-02
I0208 22:42:04.000125 22542570456896 run_lib.py:133] step: 99600, training_loss: 2.68741e-02
I0208 22:42:04.155377 22542570456896 run_lib.py:146] step: 99600, eval_loss: 3.13526e-02
I0208 22:42:21.584027 22542570456896 run_lib.py:133] step: 99650, training_loss: 2.32024e-02
I0208 22:42:39.236966 22542570456896 run_lib.py:133] step: 99700, training_loss: 3.24934e-02
I0208 22:42:39.403258 22542570456896 run_lib.py:146] step: 99700, eval_loss: 2.84722e-02
I0208 22:42:56.809388 22542570456896 run_lib.py:133] step: 99750, training_loss: 2.99844e-02
I0208 22:43:14.249579 22542570456896 run_lib.py:133] step: 99800, training_loss: 3.21850e-02
I0208 22:43:14.406367 22542570456896 run_lib.py:146] step: 99800, eval_loss: 3.21468e-02
I0208 22:43:32.010882 22542570456896 run_lib.py:133] step: 99850, training_loss: 2.66584e-02
I0208 22:43:49.425606 22542570456896 run_lib.py:133] step: 99900, training_loss: 2.59189e-02
I0208 22:43:49.581361 22542570456896 run_lib.py:146] step: 99900, eval_loss: 3.00836e-02
I0208 22:44:07.043102 22542570456896 run_lib.py:133] step: 99950, training_loss: 2.65375e-02
I0208 22:44:24.501715 22542570456896 run_lib.py:133] step: 100000, training_loss: 3.02116e-02
I0208 22:44:25.213411 22542570456896 run_lib.py:146] step: 100000, eval_loss: 2.22917e-02
I0208 22:44:45.466351 22542570456896 run_lib.py:133] step: 100050, training_loss: 2.50331e-02
I0208 22:45:03.015789 22542570456896 run_lib.py:133] step: 100100, training_loss: 3.15841e-02
I0208 22:45:03.166495 22542570456896 run_lib.py:146] step: 100100, eval_loss: 3.24684e-02
I0208 22:45:20.579161 22542570456896 run_lib.py:133] step: 100150, training_loss: 2.37824e-02
I0208 22:45:38.006025 22542570456896 run_lib.py:133] step: 100200, training_loss: 3.54697e-02
I0208 22:45:38.164312 22542570456896 run_lib.py:146] step: 100200, eval_loss: 3.14687e-02
I0208 22:45:55.749566 22542570456896 run_lib.py:133] step: 100250, training_loss: 2.84287e-02
I0208 22:46:13.205314 22542570456896 run_lib.py:133] step: 100300, training_loss: 3.10695e-02
I0208 22:46:13.365261 22542570456896 run_lib.py:146] step: 100300, eval_loss: 2.55966e-02
I0208 22:46:30.792642 22542570456896 run_lib.py:133] step: 100350, training_loss: 2.38820e-02
I0208 22:46:48.214618 22542570456896 run_lib.py:133] step: 100400, training_loss: 2.87029e-02
I0208 22:46:48.371070 22542570456896 run_lib.py:146] step: 100400, eval_loss: 3.50185e-02
I0208 22:47:06.005263 22542570456896 run_lib.py:133] step: 100450, training_loss: 3.14522e-02
I0208 22:47:23.505064 22542570456896 run_lib.py:133] step: 100500, training_loss: 3.30709e-02
I0208 22:47:23.656749 22542570456896 run_lib.py:146] step: 100500, eval_loss: 2.92088e-02
I0208 22:47:41.189204 22542570456896 run_lib.py:133] step: 100550, training_loss: 2.71387e-02
I0208 22:47:58.566566 22542570456896 run_lib.py:133] step: 100600, training_loss: 2.61283e-02
I0208 22:47:58.720272 22542570456896 run_lib.py:146] step: 100600, eval_loss: 3.02325e-02
I0208 22:48:16.137780 22542570456896 run_lib.py:133] step: 100650, training_loss: 3.04396e-02
I0208 22:48:33.572881 22542570456896 run_lib.py:133] step: 100700, training_loss: 2.63714e-02
I0208 22:48:33.733519 22542570456896 run_lib.py:146] step: 100700, eval_loss: 2.51083e-02
I0208 22:48:51.319863 22542570456896 run_lib.py:133] step: 100750, training_loss: 2.59419e-02
I0208 22:49:08.871466 22542570456896 run_lib.py:133] step: 100800, training_loss: 2.97053e-02
I0208 22:49:09.029695 22542570456896 run_lib.py:146] step: 100800, eval_loss: 2.66008e-02
I0208 22:49:26.499520 22542570456896 run_lib.py:133] step: 100850, training_loss: 3.08678e-02
I0208 22:49:43.925658 22542570456896 run_lib.py:133] step: 100900, training_loss: 2.65667e-02
I0208 22:49:44.082662 22542570456896 run_lib.py:146] step: 100900, eval_loss: 2.43005e-02
I0208 22:50:01.698992 22542570456896 run_lib.py:133] step: 100950, training_loss: 2.82655e-02
I0208 22:50:19.120696 22542570456896 run_lib.py:133] step: 101000, training_loss: 3.36534e-02
I0208 22:50:19.273474 22542570456896 run_lib.py:146] step: 101000, eval_loss: 3.57060e-02
I0208 22:50:36.843657 22542570456896 run_lib.py:133] step: 101050, training_loss: 3.11769e-02
I0208 22:50:54.304505 22542570456896 run_lib.py:133] step: 101100, training_loss: 2.83133e-02
I0208 22:50:54.478387 22542570456896 run_lib.py:146] step: 101100, eval_loss: 3.15873e-02
I0208 22:51:12.101974 22542570456896 run_lib.py:133] step: 101150, training_loss: 3.39182e-02
I0208 22:51:29.534805 22542570456896 run_lib.py:133] step: 101200, training_loss: 3.17489e-02
I0208 22:51:29.698597 22542570456896 run_lib.py:146] step: 101200, eval_loss: 3.03797e-02
I0208 22:51:47.227459 22542570456896 run_lib.py:133] step: 101250, training_loss: 3.20952e-02
I0208 22:52:04.661774 22542570456896 run_lib.py:133] step: 101300, training_loss: 2.77560e-02
I0208 22:52:04.828326 22542570456896 run_lib.py:146] step: 101300, eval_loss: 2.84616e-02
I0208 22:52:22.295194 22542570456896 run_lib.py:133] step: 101350, training_loss: 3.72580e-02
I0208 22:52:39.905280 22542570456896 run_lib.py:133] step: 101400, training_loss: 3.16424e-02
I0208 22:52:40.061514 22542570456896 run_lib.py:146] step: 101400, eval_loss: 3.07044e-02
I0208 22:52:57.454320 22542570456896 run_lib.py:133] step: 101450, training_loss: 3.36447e-02
I0208 22:53:14.866147 22542570456896 run_lib.py:133] step: 101500, training_loss: 2.63689e-02
I0208 22:53:15.017314 22542570456896 run_lib.py:146] step: 101500, eval_loss: 2.40590e-02
I0208 22:53:32.560390 22542570456896 run_lib.py:133] step: 101550, training_loss: 3.39755e-02
I0208 22:53:49.959606 22542570456896 run_lib.py:133] step: 101600, training_loss: 2.30936e-02
I0208 22:53:50.128512 22542570456896 run_lib.py:146] step: 101600, eval_loss: 3.06491e-02
I0208 22:54:07.759228 22542570456896 run_lib.py:133] step: 101650, training_loss: 2.69783e-02
I0208 22:54:25.202128 22542570456896 run_lib.py:133] step: 101700, training_loss: 3.69416e-02
I0208 22:54:25.369457 22542570456896 run_lib.py:146] step: 101700, eval_loss: 3.20307e-02
I0208 22:54:42.794826 22542570456896 run_lib.py:133] step: 101750, training_loss: 3.13275e-02
I0208 22:55:00.386486 22542570456896 run_lib.py:133] step: 101800, training_loss: 2.93003e-02
I0208 22:55:00.543333 22542570456896 run_lib.py:146] step: 101800, eval_loss: 2.59120e-02
I0208 22:55:17.988557 22542570456896 run_lib.py:133] step: 101850, training_loss: 3.27979e-02
I0208 22:55:35.413794 22542570456896 run_lib.py:133] step: 101900, training_loss: 2.81774e-02
I0208 22:55:35.570487 22542570456896 run_lib.py:146] step: 101900, eval_loss: 2.72992e-02
I0208 22:55:53.076195 22542570456896 run_lib.py:133] step: 101950, training_loss: 2.55129e-02
I0208 22:56:10.722783 22542570456896 run_lib.py:133] step: 102000, training_loss: 2.91241e-02
I0208 22:56:10.877366 22542570456896 run_lib.py:146] step: 102000, eval_loss: 2.80233e-02
I0208 22:56:28.281549 22542570456896 run_lib.py:133] step: 102050, training_loss: 2.87585e-02
I0208 22:56:45.776351 22542570456896 run_lib.py:133] step: 102100, training_loss: 2.84360e-02
I0208 22:56:45.933671 22542570456896 run_lib.py:146] step: 102100, eval_loss: 3.11974e-02
I0208 22:57:03.360663 22542570456896 run_lib.py:133] step: 102150, training_loss: 3.32122e-02
I0208 22:57:20.849336 22542570456896 run_lib.py:133] step: 102200, training_loss: 2.19306e-02
I0208 22:57:21.006236 22542570456896 run_lib.py:146] step: 102200, eval_loss: 3.31413e-02
I0208 22:57:38.586141 22542570456896 run_lib.py:133] step: 102250, training_loss: 2.28936e-02
I0208 22:57:56.097288 22542570456896 run_lib.py:133] step: 102300, training_loss: 3.39183e-02
I0208 22:57:56.254359 22542570456896 run_lib.py:146] step: 102300, eval_loss: 2.91207e-02
I0208 22:58:13.742984 22542570456896 run_lib.py:133] step: 102350, training_loss: 2.96078e-02
I0208 22:58:31.107132 22542570456896 run_lib.py:133] step: 102400, training_loss: 2.36149e-02
I0208 22:58:31.268330 22542570456896 run_lib.py:146] step: 102400, eval_loss: 2.77364e-02
I0208 22:58:48.858496 22542570456896 run_lib.py:133] step: 102450, training_loss: 2.69003e-02
I0208 22:59:06.285242 22542570456896 run_lib.py:133] step: 102500, training_loss: 3.29669e-02
I0208 22:59:06.442718 22542570456896 run_lib.py:146] step: 102500, eval_loss: 2.68120e-02
I0208 22:59:24.074058 22542570456896 run_lib.py:133] step: 102550, training_loss: 2.96063e-02
I0208 22:59:41.489701 22542570456896 run_lib.py:133] step: 102600, training_loss: 2.89757e-02
I0208 22:59:41.651566 22542570456896 run_lib.py:146] step: 102600, eval_loss: 2.47012e-02
I0208 22:59:59.199527 22542570456896 run_lib.py:133] step: 102650, training_loss: 3.39018e-02
I0208 23:00:16.668148 22542570456896 run_lib.py:133] step: 102700, training_loss: 3.23642e-02
I0208 23:00:16.843134 22542570456896 run_lib.py:146] step: 102700, eval_loss: 2.76925e-02
I0208 23:00:34.273695 22542570456896 run_lib.py:133] step: 102750, training_loss: 3.09848e-02
I0208 23:00:51.904840 22542570456896 run_lib.py:133] step: 102800, training_loss: 2.57713e-02
I0208 23:00:52.061109 22542570456896 run_lib.py:146] step: 102800, eval_loss: 2.68767e-02
I0208 23:01:09.510753 22542570456896 run_lib.py:133] step: 102850, training_loss: 2.34731e-02
I0208 23:01:27.082305 22542570456896 run_lib.py:133] step: 102900, training_loss: 3.07738e-02
I0208 23:01:27.234496 22542570456896 run_lib.py:146] step: 102900, eval_loss: 3.15469e-02
I0208 23:01:44.640817 22542570456896 run_lib.py:133] step: 102950, training_loss: 3.00451e-02
I0208 23:02:02.037362 22542570456896 run_lib.py:133] step: 103000, training_loss: 3.09618e-02
I0208 23:02:02.206450 22542570456896 run_lib.py:146] step: 103000, eval_loss: 1.92895e-02
I0208 23:02:19.813586 22542570456896 run_lib.py:133] step: 103050, training_loss: 2.50196e-02
I0208 23:02:37.267304 22542570456896 run_lib.py:133] step: 103100, training_loss: 3.10526e-02
I0208 23:02:37.427480 22542570456896 run_lib.py:146] step: 103100, eval_loss: 3.13289e-02
I0208 23:02:54.866524 22542570456896 run_lib.py:133] step: 103150, training_loss: 3.51838e-02
I0208 23:03:12.431831 22542570456896 run_lib.py:133] step: 103200, training_loss: 2.75782e-02
I0208 23:03:12.588394 22542570456896 run_lib.py:146] step: 103200, eval_loss: 3.14172e-02
I0208 23:03:30.052610 22542570456896 run_lib.py:133] step: 103250, training_loss: 3.80870e-02
I0208 23:03:47.524200 22542570456896 run_lib.py:133] step: 103300, training_loss: 3.04492e-02
I0208 23:03:47.870524 22542570456896 run_lib.py:146] step: 103300, eval_loss: 2.91217e-02
I0208 23:04:05.288304 22542570456896 run_lib.py:133] step: 103350, training_loss: 3.21514e-02
I0208 23:04:22.713589 22542570456896 run_lib.py:133] step: 103400, training_loss: 2.80859e-02
I0208 23:04:22.867254 22542570456896 run_lib.py:146] step: 103400, eval_loss: 2.70661e-02
I0208 23:04:40.287674 22542570456896 run_lib.py:133] step: 103450, training_loss: 2.71414e-02
I0208 23:04:57.708780 22542570456896 run_lib.py:133] step: 103500, training_loss: 3.45947e-02
I0208 23:04:57.865509 22542570456896 run_lib.py:146] step: 103500, eval_loss: 3.68989e-02
I0208 23:05:15.474082 22542570456896 run_lib.py:133] step: 103550, training_loss: 2.13166e-02
I0208 23:05:33.038867 22542570456896 run_lib.py:133] step: 103600, training_loss: 2.80749e-02
I0208 23:05:33.197213 22542570456896 run_lib.py:146] step: 103600, eval_loss: 2.69136e-02
I0208 23:05:50.627554 22542570456896 run_lib.py:133] step: 103650, training_loss: 3.37577e-02
I0208 23:06:08.044265 22542570456896 run_lib.py:133] step: 103700, training_loss: 3.18165e-02
I0208 23:06:08.198322 22542570456896 run_lib.py:146] step: 103700, eval_loss: 2.81170e-02
I0208 23:06:25.786017 22542570456896 run_lib.py:133] step: 103750, training_loss: 3.55747e-02
I0208 23:06:43.301706 22542570456896 run_lib.py:133] step: 103800, training_loss: 3.45009e-02
I0208 23:06:43.457127 22542570456896 run_lib.py:146] step: 103800, eval_loss: 3.32148e-02
I0208 23:07:00.916058 22542570456896 run_lib.py:133] step: 103850, training_loss: 2.58116e-02
I0208 23:07:18.325636 22542570456896 run_lib.py:133] step: 103900, training_loss: 2.24430e-02
I0208 23:07:18.479560 22542570456896 run_lib.py:146] step: 103900, eval_loss: 2.68477e-02
I0208 23:07:36.095741 22542570456896 run_lib.py:133] step: 103950, training_loss: 3.26658e-02
I0208 23:07:53.525611 22542570456896 run_lib.py:133] step: 104000, training_loss: 2.41502e-02
I0208 23:07:53.693328 22542570456896 run_lib.py:146] step: 104000, eval_loss: 2.86744e-02
I0208 23:08:11.232348 22542570456896 run_lib.py:133] step: 104050, training_loss: 2.35938e-02
I0208 23:08:28.644683 22542570456896 run_lib.py:133] step: 104100, training_loss: 2.85833e-02
I0208 23:08:28.825017 22542570456896 run_lib.py:146] step: 104100, eval_loss: 3.54813e-02
I0208 23:08:46.518810 22542570456896 run_lib.py:133] step: 104150, training_loss: 2.96241e-02
I0208 23:09:03.949169 22542570456896 run_lib.py:133] step: 104200, training_loss: 3.38384e-02
I0208 23:09:04.106188 22542570456896 run_lib.py:146] step: 104200, eval_loss: 2.17932e-02
I0208 23:09:21.525225 22542570456896 run_lib.py:133] step: 104250, training_loss: 2.30963e-02
I0208 23:09:39.095541 22542570456896 run_lib.py:133] step: 104300, training_loss: 3.16025e-02
I0208 23:09:39.251049 22542570456896 run_lib.py:146] step: 104300, eval_loss: 2.86186e-02
I0208 23:09:56.652466 22542570456896 run_lib.py:133] step: 104350, training_loss: 2.79025e-02
I0208 23:10:14.259248 22542570456896 run_lib.py:133] step: 104400, training_loss: 2.75290e-02
I0208 23:10:14.423544 22542570456896 run_lib.py:146] step: 104400, eval_loss: 2.68165e-02
I0208 23:10:31.878481 22542570456896 run_lib.py:133] step: 104450, training_loss: 2.78244e-02
I0208 23:10:49.319715 22542570456896 run_lib.py:133] step: 104500, training_loss: 3.30114e-02
I0208 23:10:49.479179 22542570456896 run_lib.py:146] step: 104500, eval_loss: 3.85266e-02
I0208 23:11:07.086234 22542570456896 run_lib.py:133] step: 104550, training_loss: 3.00637e-02
I0208 23:11:24.477283 22542570456896 run_lib.py:133] step: 104600, training_loss: 2.59039e-02
I0208 23:11:24.633284 22542570456896 run_lib.py:146] step: 104600, eval_loss: 2.79614e-02
I0208 23:11:42.100935 22542570456896 run_lib.py:133] step: 104650, training_loss: 2.59604e-02
I0208 23:11:59.609363 22542570456896 run_lib.py:133] step: 104700, training_loss: 3.80683e-02
I0208 23:11:59.765997 22542570456896 run_lib.py:146] step: 104700, eval_loss: 2.45407e-02
I0208 23:12:17.404057 22542570456896 run_lib.py:133] step: 104750, training_loss: 3.19312e-02
I0208 23:12:34.866378 22542570456896 run_lib.py:133] step: 104800, training_loss: 2.83294e-02
I0208 23:12:35.020357 22542570456896 run_lib.py:146] step: 104800, eval_loss: 2.98641e-02
I0208 23:12:52.490357 22542570456896 run_lib.py:133] step: 104850, training_loss: 3.67976e-02
I0208 23:13:09.914460 22542570456896 run_lib.py:133] step: 104900, training_loss: 2.68117e-02
I0208 23:13:10.070334 22542570456896 run_lib.py:146] step: 104900, eval_loss: 3.50683e-02
I0208 23:13:27.484190 22542570456896 run_lib.py:133] step: 104950, training_loss: 3.03156e-02
I0208 23:13:44.953640 22542570456896 run_lib.py:133] step: 105000, training_loss: 2.93463e-02
I0208 23:13:45.109329 22542570456896 run_lib.py:146] step: 105000, eval_loss: 2.70875e-02
I0208 23:14:02.734704 22542570456896 run_lib.py:133] step: 105050, training_loss: 2.78648e-02
I0208 23:14:20.246271 22542570456896 run_lib.py:133] step: 105100, training_loss: 2.31747e-02
I0208 23:14:20.407423 22542570456896 run_lib.py:146] step: 105100, eval_loss: 2.85727e-02
I0208 23:14:37.838296 22542570456896 run_lib.py:133] step: 105150, training_loss: 3.29924e-02
I0208 23:14:55.291126 22542570456896 run_lib.py:133] step: 105200, training_loss: 2.93890e-02
I0208 23:14:55.456521 22542570456896 run_lib.py:146] step: 105200, eval_loss: 2.68063e-02
I0208 23:15:13.170051 22542570456896 run_lib.py:133] step: 105250, training_loss: 2.67504e-02
I0208 23:15:30.598631 22542570456896 run_lib.py:133] step: 105300, training_loss: 2.73353e-02
I0208 23:15:30.750692 22542570456896 run_lib.py:146] step: 105300, eval_loss: 3.30340e-02
I0208 23:15:48.345523 22542570456896 run_lib.py:133] step: 105350, training_loss: 2.34618e-02
I0208 23:16:05.807807 22542570456896 run_lib.py:133] step: 105400, training_loss: 2.61838e-02
I0208 23:16:05.964390 22542570456896 run_lib.py:146] step: 105400, eval_loss: 2.52211e-02
I0208 23:16:23.538331 22542570456896 run_lib.py:133] step: 105450, training_loss: 3.22268e-02
I0208 23:16:41.012288 22542570456896 run_lib.py:133] step: 105500, training_loss: 2.81670e-02
I0208 23:16:41.194443 22542570456896 run_lib.py:146] step: 105500, eval_loss: 3.33228e-02
I0208 23:16:58.834349 22542570456896 run_lib.py:133] step: 105550, training_loss: 2.72053e-02
I0208 23:17:16.285710 22542570456896 run_lib.py:133] step: 105600, training_loss: 2.71940e-02
I0208 23:17:16.442633 22542570456896 run_lib.py:146] step: 105600, eval_loss: 3.06938e-02
I0208 23:17:33.919935 22542570456896 run_lib.py:133] step: 105650, training_loss: 2.80529e-02
I0208 23:17:51.468021 22542570456896 run_lib.py:133] step: 105700, training_loss: 2.36926e-02
I0208 23:17:51.628326 22542570456896 run_lib.py:146] step: 105700, eval_loss: 2.68966e-02
I0208 23:18:09.014020 22542570456896 run_lib.py:133] step: 105750, training_loss: 4.02485e-02
I0208 23:18:26.489189 22542570456896 run_lib.py:133] step: 105800, training_loss: 2.69902e-02
I0208 23:18:26.644447 22542570456896 run_lib.py:146] step: 105800, eval_loss: 2.88896e-02
I0208 23:18:44.291834 22542570456896 run_lib.py:133] step: 105850, training_loss: 2.69945e-02
I0208 23:19:01.883402 22542570456896 run_lib.py:133] step: 105900, training_loss: 2.48043e-02
I0208 23:19:02.038931 22542570456896 run_lib.py:146] step: 105900, eval_loss: 3.72398e-02
I0208 23:19:19.430386 22542570456896 run_lib.py:133] step: 105950, training_loss: 3.05016e-02
I0208 23:19:36.830087 22542570456896 run_lib.py:133] step: 106000, training_loss: 2.67427e-02
I0208 23:19:36.986531 22542570456896 run_lib.py:146] step: 106000, eval_loss: 2.91586e-02
I0208 23:19:54.445154 22542570456896 run_lib.py:133] step: 106050, training_loss: 2.30367e-02
I0208 23:20:12.036126 22542570456896 run_lib.py:133] step: 106100, training_loss: 3.25214e-02
I0208 23:20:12.192028 22542570456896 run_lib.py:146] step: 106100, eval_loss: 3.22665e-02
I0208 23:20:29.564189 22542570456896 run_lib.py:133] step: 106150, training_loss: 3.32714e-02
I0208 23:20:46.871929 22542570456896 run_lib.py:133] step: 106200, training_loss: 3.39629e-02
I0208 23:20:47.026031 22542570456896 run_lib.py:146] step: 106200, eval_loss: 3.13761e-02
I0208 23:21:04.462750 22542570456896 run_lib.py:133] step: 106250, training_loss: 2.13195e-02
I0208 23:21:22.085964 22542570456896 run_lib.py:133] step: 106300, training_loss: 3.11169e-02
I0208 23:21:22.246410 22542570456896 run_lib.py:146] step: 106300, eval_loss: 3.09179e-02
I0208 23:21:39.712331 22542570456896 run_lib.py:133] step: 106350, training_loss: 3.98216e-02
I0208 23:21:57.254455 22542570456896 run_lib.py:133] step: 106400, training_loss: 1.99761e-02
I0208 23:21:57.414404 22542570456896 run_lib.py:146] step: 106400, eval_loss: 2.98260e-02
I0208 23:22:14.828226 22542570456896 run_lib.py:133] step: 106450, training_loss: 2.50781e-02
I0208 23:22:32.232796 22542570456896 run_lib.py:133] step: 106500, training_loss: 3.14503e-02
I0208 23:22:32.389482 22542570456896 run_lib.py:146] step: 106500, eval_loss: 2.50235e-02
I0208 23:22:49.939690 22542570456896 run_lib.py:133] step: 106550, training_loss: 2.63644e-02
I0208 23:23:07.523027 22542570456896 run_lib.py:133] step: 106600, training_loss: 3.21496e-02
I0208 23:23:07.683708 22542570456896 run_lib.py:146] step: 106600, eval_loss: 2.75434e-02
I0208 23:23:25.156500 22542570456896 run_lib.py:133] step: 106650, training_loss: 3.25347e-02
I0208 23:23:42.586654 22542570456896 run_lib.py:133] step: 106700, training_loss: 2.62245e-02
I0208 23:23:42.739287 22542570456896 run_lib.py:146] step: 106700, eval_loss: 2.87596e-02
I0208 23:24:00.344848 22542570456896 run_lib.py:133] step: 106750, training_loss: 3.66023e-02
I0208 23:24:17.760659 22542570456896 run_lib.py:133] step: 106800, training_loss: 3.19528e-02
I0208 23:24:17.917216 22542570456896 run_lib.py:146] step: 106800, eval_loss: 2.20892e-02
I0208 23:24:35.465933 22542570456896 run_lib.py:133] step: 106850, training_loss: 2.43727e-02
I0208 23:24:52.926323 22542570456896 run_lib.py:133] step: 106900, training_loss: 2.64788e-02
I0208 23:24:53.102325 22542570456896 run_lib.py:146] step: 106900, eval_loss: 3.36356e-02
I0208 23:25:10.718731 22542570456896 run_lib.py:133] step: 106950, training_loss: 3.00941e-02
I0208 23:25:28.168776 22542570456896 run_lib.py:133] step: 107000, training_loss: 3.23121e-02
I0208 23:25:28.326688 22542570456896 run_lib.py:146] step: 107000, eval_loss: 2.64537e-02
I0208 23:25:45.731763 22542570456896 run_lib.py:133] step: 107050, training_loss: 3.62871e-02
I0208 23:26:03.318233 22542570456896 run_lib.py:133] step: 107100, training_loss: 2.50875e-02
I0208 23:26:03.476414 22542570456896 run_lib.py:146] step: 107100, eval_loss: 2.74570e-02
I0208 23:26:20.897488 22542570456896 run_lib.py:133] step: 107150, training_loss: 2.52582e-02
I0208 23:26:38.538438 22542570456896 run_lib.py:133] step: 107200, training_loss: 2.50612e-02
I0208 23:26:38.694424 22542570456896 run_lib.py:146] step: 107200, eval_loss: 3.16855e-02
I0208 23:26:56.094491 22542570456896 run_lib.py:133] step: 107250, training_loss: 2.81328e-02
I0208 23:27:13.565456 22542570456896 run_lib.py:133] step: 107300, training_loss: 2.84397e-02
I0208 23:27:13.721375 22542570456896 run_lib.py:146] step: 107300, eval_loss: 2.66480e-02
I0208 23:27:31.325008 22542570456896 run_lib.py:133] step: 107350, training_loss: 2.87857e-02
I0208 23:27:48.731695 22542570456896 run_lib.py:133] step: 107400, training_loss: 2.33375e-02
I0208 23:27:48.891661 22542570456896 run_lib.py:146] step: 107400, eval_loss: 2.72339e-02
I0208 23:28:06.375196 22542570456896 run_lib.py:133] step: 107450, training_loss: 2.69622e-02
I0208 23:28:24.023370 22542570456896 run_lib.py:133] step: 107500, training_loss: 2.48062e-02
I0208 23:28:24.179510 22542570456896 run_lib.py:146] step: 107500, eval_loss: 2.68058e-02
I0208 23:28:41.589926 22542570456896 run_lib.py:133] step: 107550, training_loss: 3.06564e-02
I0208 23:28:59.010220 22542570456896 run_lib.py:133] step: 107600, training_loss: 2.59693e-02
I0208 23:28:59.166152 22542570456896 run_lib.py:146] step: 107600, eval_loss: 2.68580e-02
I0208 23:29:16.670852 22542570456896 run_lib.py:133] step: 107650, training_loss: 3.64075e-02
I0208 23:29:34.125801 22542570456896 run_lib.py:133] step: 107700, training_loss: 2.29406e-02
I0208 23:29:34.287402 22542570456896 run_lib.py:146] step: 107700, eval_loss: 2.62118e-02
I0208 23:29:51.803005 22542570456896 run_lib.py:133] step: 107750, training_loss: 2.81100e-02
I0208 23:30:09.225945 22542570456896 run_lib.py:133] step: 107800, training_loss: 3.08458e-02
I0208 23:30:09.385300 22542570456896 run_lib.py:146] step: 107800, eval_loss: 2.60917e-02
I0208 23:30:26.947832 22542570456896 run_lib.py:133] step: 107850, training_loss: 2.58031e-02
I0208 23:30:44.455279 22542570456896 run_lib.py:133] step: 107900, training_loss: 3.27584e-02
I0208 23:30:44.614590 22542570456896 run_lib.py:146] step: 107900, eval_loss: 3.25475e-02
I0208 23:31:02.057912 22542570456896 run_lib.py:133] step: 107950, training_loss: 3.16015e-02
I0208 23:31:19.561876 22542570456896 run_lib.py:133] step: 108000, training_loss: 3.29338e-02
I0208 23:31:19.719256 22542570456896 run_lib.py:146] step: 108000, eval_loss: 2.85372e-02
I0208 23:31:37.361651 22542570456896 run_lib.py:133] step: 108050, training_loss: 2.94924e-02
I0208 23:31:54.795663 22542570456896 run_lib.py:133] step: 108100, training_loss: 2.52640e-02
I0208 23:31:54.955046 22542570456896 run_lib.py:146] step: 108100, eval_loss: 2.52625e-02
I0208 23:32:12.573464 22542570456896 run_lib.py:133] step: 108150, training_loss: 2.76053e-02
I0208 23:32:30.021874 22542570456896 run_lib.py:133] step: 108200, training_loss: 2.96919e-02
I0208 23:32:30.176248 22542570456896 run_lib.py:146] step: 108200, eval_loss: 2.99379e-02
I0208 23:32:47.785485 22542570456896 run_lib.py:133] step: 108250, training_loss: 3.17431e-02
I0208 23:33:05.244813 22542570456896 run_lib.py:133] step: 108300, training_loss: 2.45329e-02
I0208 23:33:05.416098 22542570456896 run_lib.py:146] step: 108300, eval_loss: 2.46802e-02
I0208 23:33:23.020833 22542570456896 run_lib.py:133] step: 108350, training_loss: 2.31844e-02
I0208 23:33:40.484019 22542570456896 run_lib.py:133] step: 108400, training_loss: 3.20172e-02
I0208 23:33:40.641411 22542570456896 run_lib.py:146] step: 108400, eval_loss: 3.59040e-02
I0208 23:33:58.092722 22542570456896 run_lib.py:133] step: 108450, training_loss: 2.42741e-02
I0208 23:34:15.641252 22542570456896 run_lib.py:133] step: 108500, training_loss: 2.83624e-02
I0208 23:34:15.797391 22542570456896 run_lib.py:146] step: 108500, eval_loss: 2.38620e-02
I0208 23:34:33.261140 22542570456896 run_lib.py:133] step: 108550, training_loss: 2.93142e-02
I0208 23:34:50.754184 22542570456896 run_lib.py:133] step: 108600, training_loss: 2.74733e-02
I0208 23:34:50.911141 22542570456896 run_lib.py:146] step: 108600, eval_loss: 2.23405e-02
I0208 23:35:08.555632 22542570456896 run_lib.py:133] step: 108650, training_loss: 3.27100e-02
I0208 23:35:25.999036 22542570456896 run_lib.py:133] step: 108700, training_loss: 3.73131e-02
I0208 23:35:26.160292 22542570456896 run_lib.py:146] step: 108700, eval_loss: 2.56354e-02
I0208 23:35:43.705374 22542570456896 run_lib.py:133] step: 108750, training_loss: 2.61069e-02
I0208 23:36:01.168962 22542570456896 run_lib.py:133] step: 108800, training_loss: 2.57780e-02
I0208 23:36:01.327923 22542570456896 run_lib.py:146] step: 108800, eval_loss: 2.71315e-02
I0208 23:36:18.756535 22542570456896 run_lib.py:133] step: 108850, training_loss: 2.92802e-02
I0208 23:36:36.388006 22542570456896 run_lib.py:133] step: 108900, training_loss: 3.00470e-02
I0208 23:36:36.545568 22542570456896 run_lib.py:146] step: 108900, eval_loss: 2.20517e-02
I0208 23:36:54.006353 22542570456896 run_lib.py:133] step: 108950, training_loss: 2.67741e-02
I0208 23:37:11.419661 22542570456896 run_lib.py:133] step: 109000, training_loss: 2.71592e-02
I0208 23:37:11.580279 22542570456896 run_lib.py:146] step: 109000, eval_loss: 2.86520e-02
I0208 23:37:28.972633 22542570456896 run_lib.py:133] step: 109050, training_loss: 2.55874e-02
I0208 23:37:46.596527 22542570456896 run_lib.py:133] step: 109100, training_loss: 3.00184e-02
I0208 23:37:46.750427 22542570456896 run_lib.py:146] step: 109100, eval_loss: 3.73822e-02
I0208 23:38:04.249605 22542570456896 run_lib.py:133] step: 109150, training_loss: 3.16516e-02
I0208 23:38:21.784830 22542570456896 run_lib.py:133] step: 109200, training_loss: 2.73388e-02
I0208 23:38:21.941559 22542570456896 run_lib.py:146] step: 109200, eval_loss: 3.23164e-02
I0208 23:38:39.343315 22542570456896 run_lib.py:133] step: 109250, training_loss: 2.27826e-02
I0208 23:38:56.786533 22542570456896 run_lib.py:133] step: 109300, training_loss: 2.36301e-02
I0208 23:38:56.941989 22542570456896 run_lib.py:146] step: 109300, eval_loss: 4.03645e-02
I0208 23:39:14.500250 22542570456896 run_lib.py:133] step: 109350, training_loss: 3.43939e-02
I0208 23:39:32.036981 22542570456896 run_lib.py:133] step: 109400, training_loss: 3.03617e-02
I0208 23:39:32.201043 22542570456896 run_lib.py:146] step: 109400, eval_loss: 2.74333e-02
I0208 23:39:49.677733 22542570456896 run_lib.py:133] step: 109450, training_loss: 2.49147e-02
I0208 23:40:07.101820 22542570456896 run_lib.py:133] step: 109500, training_loss: 3.77967e-02
I0208 23:40:07.258074 22542570456896 run_lib.py:146] step: 109500, eval_loss: 2.33754e-02
I0208 23:40:24.918577 22542570456896 run_lib.py:133] step: 109550, training_loss: 2.64194e-02
I0208 23:40:42.308712 22542570456896 run_lib.py:133] step: 109600, training_loss: 2.78900e-02
I0208 23:40:42.463438 22542570456896 run_lib.py:146] step: 109600, eval_loss: 2.18363e-02
I0208 23:41:00.035746 22542570456896 run_lib.py:133] step: 109650, training_loss: 2.13324e-02
I0208 23:41:17.505290 22542570456896 run_lib.py:133] step: 109700, training_loss: 2.76158e-02
I0208 23:41:17.683325 22542570456896 run_lib.py:146] step: 109700, eval_loss: 2.58513e-02
I0208 23:41:35.316601 22542570456896 run_lib.py:133] step: 109750, training_loss: 2.51338e-02
I0208 23:41:52.765525 22542570456896 run_lib.py:133] step: 109800, training_loss: 3.79807e-02
I0208 23:41:52.922618 22542570456896 run_lib.py:146] step: 109800, eval_loss: 3.17274e-02
I0208 23:42:10.318909 22542570456896 run_lib.py:133] step: 109850, training_loss: 3.66672e-02
I0208 23:42:27.881075 22542570456896 run_lib.py:133] step: 109900, training_loss: 3.50276e-02
I0208 23:42:28.037323 22542570456896 run_lib.py:146] step: 109900, eval_loss: 2.50131e-02
I0208 23:42:45.461750 22542570456896 run_lib.py:133] step: 109950, training_loss: 2.50673e-02
I0208 23:43:03.070453 22542570456896 run_lib.py:133] step: 110000, training_loss: 2.45844e-02
I0208 23:43:03.781871 22542570456896 run_lib.py:146] step: 110000, eval_loss: 2.58312e-02
I0208 23:43:23.998379 22542570456896 run_lib.py:133] step: 110050, training_loss: 3.15685e-02
I0208 23:43:41.407572 22542570456896 run_lib.py:133] step: 110100, training_loss: 3.16077e-02
I0208 23:43:41.565378 22542570456896 run_lib.py:146] step: 110100, eval_loss: 3.02219e-02
I0208 23:43:59.003014 22542570456896 run_lib.py:133] step: 110150, training_loss: 3.02703e-02
I0208 23:44:16.439345 22542570456896 run_lib.py:133] step: 110200, training_loss: 2.66543e-02
I0208 23:44:16.608184 22542570456896 run_lib.py:146] step: 110200, eval_loss: 2.83053e-02
I0208 23:44:34.206381 22542570456896 run_lib.py:133] step: 110250, training_loss: 2.56059e-02
I0208 23:44:51.764018 22542570456896 run_lib.py:133] step: 110300, training_loss: 2.95898e-02
I0208 23:44:51.922594 22542570456896 run_lib.py:146] step: 110300, eval_loss: 2.52308e-02
I0208 23:45:09.350784 22542570456896 run_lib.py:133] step: 110350, training_loss: 2.32005e-02
I0208 23:45:26.767164 22542570456896 run_lib.py:133] step: 110400, training_loss: 3.56513e-02
I0208 23:45:26.923268 22542570456896 run_lib.py:146] step: 110400, eval_loss: 3.14669e-02
I0208 23:45:44.492593 22542570456896 run_lib.py:133] step: 110450, training_loss: 2.74670e-02
I0208 23:46:01.954249 22542570456896 run_lib.py:133] step: 110500, training_loss: 2.55903e-02
I0208 23:46:02.111633 22542570456896 run_lib.py:146] step: 110500, eval_loss: 3.33891e-02
I0208 23:46:19.725779 22542570456896 run_lib.py:133] step: 110550, training_loss: 2.76646e-02
I0208 23:46:37.156702 22542570456896 run_lib.py:133] step: 110600, training_loss: 2.77728e-02
I0208 23:46:37.305464 22542570456896 run_lib.py:146] step: 110600, eval_loss: 2.81297e-02
I0208 23:46:54.870191 22542570456896 run_lib.py:133] step: 110650, training_loss: 3.28162e-02
I0208 23:47:12.274969 22542570456896 run_lib.py:133] step: 110700, training_loss: 3.38757e-02
I0208 23:47:12.445158 22542570456896 run_lib.py:146] step: 110700, eval_loss: 3.01418e-02
I0208 23:47:30.071935 22542570456896 run_lib.py:133] step: 110750, training_loss: 3.66117e-02
I0208 23:47:47.549275 22542570456896 run_lib.py:133] step: 110800, training_loss: 2.46707e-02
I0208 23:47:47.710576 22542570456896 run_lib.py:146] step: 110800, eval_loss: 2.84974e-02
I0208 23:48:05.114676 22542570456896 run_lib.py:133] step: 110850, training_loss: 3.09944e-02
I0208 23:48:22.726280 22542570456896 run_lib.py:133] step: 110900, training_loss: 2.80143e-02
I0208 23:48:22.881598 22542570456896 run_lib.py:146] step: 110900, eval_loss: 2.26564e-02
I0208 23:48:40.284044 22542570456896 run_lib.py:133] step: 110950, training_loss: 2.11263e-02
I0208 23:48:57.764281 22542570456896 run_lib.py:133] step: 111000, training_loss: 3.13660e-02
I0208 23:48:57.922549 22542570456896 run_lib.py:146] step: 111000, eval_loss: 2.45399e-02
I0208 23:49:15.509244 22542570456896 run_lib.py:133] step: 111050, training_loss: 2.36670e-02
I0208 23:49:33.113407 22542570456896 run_lib.py:133] step: 111100, training_loss: 3.20776e-02
I0208 23:49:33.266343 22542570456896 run_lib.py:146] step: 111100, eval_loss: 2.48237e-02
I0208 23:49:50.697597 22542570456896 run_lib.py:133] step: 111150, training_loss: 2.83003e-02
I0208 23:50:08.143580 22542570456896 run_lib.py:133] step: 111200, training_loss: 2.55773e-02
I0208 23:50:08.303505 22542570456896 run_lib.py:146] step: 111200, eval_loss: 2.89885e-02
I0208 23:50:25.700641 22542570456896 run_lib.py:133] step: 111250, training_loss: 3.33366e-02
I0208 23:50:43.283020 22542570456896 run_lib.py:133] step: 111300, training_loss: 2.93958e-02
I0208 23:50:43.456362 22542570456896 run_lib.py:146] step: 111300, eval_loss: 2.67507e-02
I0208 23:51:00.910566 22542570456896 run_lib.py:133] step: 111350, training_loss: 2.69679e-02
I0208 23:51:18.369120 22542570456896 run_lib.py:133] step: 111400, training_loss: 2.38764e-02
I0208 23:51:18.526151 22542570456896 run_lib.py:146] step: 111400, eval_loss: 2.78919e-02
I0208 23:51:35.956351 22542570456896 run_lib.py:133] step: 111450, training_loss: 3.02339e-02
I0208 23:51:53.580185 22542570456896 run_lib.py:133] step: 111500, training_loss: 2.60722e-02
I0208 23:51:53.733120 22542570456896 run_lib.py:146] step: 111500, eval_loss: 2.24209e-02
I0208 23:52:11.130561 22542570456896 run_lib.py:133] step: 111550, training_loss: 3.17915e-02
I0208 23:52:28.629507 22542570456896 run_lib.py:133] step: 111600, training_loss: 2.40403e-02
I0208 23:52:28.799575 22542570456896 run_lib.py:146] step: 111600, eval_loss: 1.98346e-02
I0208 23:52:46.308659 22542570456896 run_lib.py:133] step: 111650, training_loss: 2.95770e-02
I0208 23:53:03.782488 22542570456896 run_lib.py:133] step: 111700, training_loss: 3.20337e-02
I0208 23:53:03.941556 22542570456896 run_lib.py:146] step: 111700, eval_loss: 2.76664e-02
I0208 23:53:21.537433 22542570456896 run_lib.py:133] step: 111750, training_loss: 3.10550e-02
I0208 23:53:39.011491 22542570456896 run_lib.py:133] step: 111800, training_loss: 2.95650e-02
I0208 23:53:39.168353 22542570456896 run_lib.py:146] step: 111800, eval_loss: 2.72044e-02
I0208 23:53:56.615956 22542570456896 run_lib.py:133] step: 111850, training_loss: 2.68896e-02
I0208 23:54:14.078554 22542570456896 run_lib.py:133] step: 111900, training_loss: 2.94127e-02
I0208 23:54:14.235522 22542570456896 run_lib.py:146] step: 111900, eval_loss: 2.75738e-02
I0208 23:54:31.876729 22542570456896 run_lib.py:133] step: 111950, training_loss: 2.66582e-02
I0208 23:54:49.324098 22542570456896 run_lib.py:133] step: 112000, training_loss: 3.07478e-02
I0208 23:54:49.477468 22542570456896 run_lib.py:146] step: 112000, eval_loss: 2.29621e-02
I0208 23:55:07.066318 22542570456896 run_lib.py:133] step: 112050, training_loss: 2.57118e-02
I0208 23:55:24.527691 22542570456896 run_lib.py:133] step: 112100, training_loss: 2.16800e-02
I0208 23:55:24.684331 22542570456896 run_lib.py:146] step: 112100, eval_loss: 3.02488e-02
I0208 23:55:42.231377 22542570456896 run_lib.py:133] step: 112150, training_loss: 2.89874e-02
I0208 23:55:59.692501 22542570456896 run_lib.py:133] step: 112200, training_loss: 3.09913e-02
I0208 23:55:59.872138 22542570456896 run_lib.py:146] step: 112200, eval_loss: 2.76231e-02
I0208 23:56:17.354342 22542570456896 run_lib.py:133] step: 112250, training_loss: 2.79309e-02
I0208 23:56:34.969364 22542570456896 run_lib.py:133] step: 112300, training_loss: 2.95046e-02
I0208 23:56:35.125484 22542570456896 run_lib.py:146] step: 112300, eval_loss: 2.49958e-02
I0208 23:56:52.567408 22542570456896 run_lib.py:133] step: 112350, training_loss: 3.66425e-02
I0208 23:57:10.146936 22542570456896 run_lib.py:133] step: 112400, training_loss: 1.98964e-02
I0208 23:57:10.310317 22542570456896 run_lib.py:146] step: 112400, eval_loss: 2.61541e-02
I0208 23:57:27.697176 22542570456896 run_lib.py:133] step: 112450, training_loss: 3.16073e-02
I0208 23:57:45.184583 22542570456896 run_lib.py:133] step: 112500, training_loss: 3.40778e-02
I0208 23:57:45.335746 22542570456896 run_lib.py:146] step: 112500, eval_loss: 3.09621e-02
I0208 23:58:03.034808 22542570456896 run_lib.py:133] step: 112550, training_loss: 2.74829e-02
I0208 23:58:20.491921 22542570456896 run_lib.py:133] step: 112600, training_loss: 3.39113e-02
I0208 23:58:20.648633 22542570456896 run_lib.py:146] step: 112600, eval_loss: 2.77012e-02
I0208 23:58:38.047479 22542570456896 run_lib.py:133] step: 112650, training_loss: 2.43405e-02
I0208 23:58:55.614596 22542570456896 run_lib.py:133] step: 112700, training_loss: 2.81458e-02
I0208 23:58:55.777588 22542570456896 run_lib.py:146] step: 112700, eval_loss: 2.65524e-02
I0208 23:59:13.204029 22542570456896 run_lib.py:133] step: 112750, training_loss: 2.84720e-02
I0208 23:59:30.670801 22542570456896 run_lib.py:133] step: 112800, training_loss: 2.81413e-02
I0208 23:59:30.828162 22542570456896 run_lib.py:146] step: 112800, eval_loss: 2.68725e-02
I0208 23:59:48.382431 22542570456896 run_lib.py:133] step: 112850, training_loss: 2.74039e-02
I0209 00:00:05.806921 22542570456896 run_lib.py:133] step: 112900, training_loss: 2.43627e-02
I0209 00:00:05.964758 22542570456896 run_lib.py:146] step: 112900, eval_loss: 3.17618e-02
I0209 00:00:23.440082 22542570456896 run_lib.py:133] step: 112950, training_loss: 2.54315e-02
I0209 00:00:40.879173 22542570456896 run_lib.py:133] step: 113000, training_loss: 2.97983e-02
I0209 00:00:41.034644 22542570456896 run_lib.py:146] step: 113000, eval_loss: 2.93277e-02
I0209 00:00:58.712042 22542570456896 run_lib.py:133] step: 113050, training_loss: 3.48354e-02
I0209 00:01:16.225758 22542570456896 run_lib.py:133] step: 113100, training_loss: 3.08076e-02
I0209 00:01:16.384478 22542570456896 run_lib.py:146] step: 113100, eval_loss: 2.97133e-02
I0209 00:01:33.825664 22542570456896 run_lib.py:133] step: 113150, training_loss: 3.31834e-02
I0209 00:01:51.255010 22542570456896 run_lib.py:133] step: 113200, training_loss: 2.77022e-02
I0209 00:01:51.411425 22542570456896 run_lib.py:146] step: 113200, eval_loss: 2.54113e-02
I0209 00:02:09.006060 22542570456896 run_lib.py:133] step: 113250, training_loss: 3.30013e-02
I0209 00:02:26.434995 22542570456896 run_lib.py:133] step: 113300, training_loss: 3.25285e-02
I0209 00:02:26.592164 22542570456896 run_lib.py:146] step: 113300, eval_loss: 3.76224e-02
I0209 00:02:44.197899 22542570456896 run_lib.py:133] step: 113350, training_loss: 2.84922e-02
I0209 00:03:01.618277 22542570456896 run_lib.py:133] step: 113400, training_loss: 2.78262e-02
I0209 00:03:01.770986 22542570456896 run_lib.py:146] step: 113400, eval_loss: 3.21410e-02
I0209 00:03:19.397528 22542570456896 run_lib.py:133] step: 113450, training_loss: 3.19330e-02
I0209 00:03:36.832369 22542570456896 run_lib.py:133] step: 113500, training_loss: 2.69567e-02
I0209 00:03:36.996009 22542570456896 run_lib.py:146] step: 113500, eval_loss: 2.20575e-02
I0209 00:03:54.550130 22542570456896 run_lib.py:133] step: 113550, training_loss: 2.94142e-02
I0209 00:04:11.992508 22542570456896 run_lib.py:133] step: 113600, training_loss: 2.55415e-02
I0209 00:04:12.168331 22542570456896 run_lib.py:146] step: 113600, eval_loss: 2.87829e-02
I0209 00:04:29.662413 22542570456896 run_lib.py:133] step: 113650, training_loss: 3.31135e-02
I0209 00:04:47.315830 22542570456896 run_lib.py:133] step: 113700, training_loss: 2.72813e-02
I0209 00:04:47.473550 22542570456896 run_lib.py:146] step: 113700, eval_loss: 2.33295e-02
I0209 00:05:04.856192 22542570456896 run_lib.py:133] step: 113750, training_loss: 2.79220e-02
I0209 00:05:22.234438 22542570456896 run_lib.py:133] step: 113800, training_loss: 2.91121e-02
I0209 00:05:22.391172 22542570456896 run_lib.py:146] step: 113800, eval_loss: 2.71208e-02
I0209 00:05:39.957943 22542570456896 run_lib.py:133] step: 113850, training_loss: 2.98600e-02
I0209 00:05:57.391133 22542570456896 run_lib.py:133] step: 113900, training_loss: 2.81908e-02
I0209 00:05:57.546592 22542570456896 run_lib.py:146] step: 113900, eval_loss: 2.94768e-02
I0209 00:06:15.170883 22542570456896 run_lib.py:133] step: 113950, training_loss: 3.48067e-02
I0209 00:06:32.568597 22542570456896 run_lib.py:133] step: 114000, training_loss: 3.08362e-02
I0209 00:06:32.721572 22542570456896 run_lib.py:146] step: 114000, eval_loss: 2.91776e-02
I0209 00:06:50.173344 22542570456896 run_lib.py:133] step: 114050, training_loss: 3.39099e-02
I0209 00:07:07.795582 22542570456896 run_lib.py:133] step: 114100, training_loss: 2.62115e-02
I0209 00:07:07.954679 22542570456896 run_lib.py:146] step: 114100, eval_loss: 2.91974e-02
I0209 00:07:25.394598 22542570456896 run_lib.py:133] step: 114150, training_loss: 2.87036e-02
I0209 00:07:42.868194 22542570456896 run_lib.py:133] step: 114200, training_loss: 3.39166e-02
I0209 00:07:43.026592 22542570456896 run_lib.py:146] step: 114200, eval_loss: 2.67745e-02
I0209 00:08:00.445669 22542570456896 run_lib.py:133] step: 114250, training_loss: 2.77880e-02
I0209 00:08:18.053401 22542570456896 run_lib.py:133] step: 114300, training_loss: 2.38684e-02
I0209 00:08:18.209408 22542570456896 run_lib.py:146] step: 114300, eval_loss: 3.60321e-02
I0209 00:08:35.588940 22542570456896 run_lib.py:133] step: 114350, training_loss: 2.58828e-02
I0209 00:08:53.059595 22542570456896 run_lib.py:133] step: 114400, training_loss: 2.08326e-02
I0209 00:08:53.220329 22542570456896 run_lib.py:146] step: 114400, eval_loss: 2.63750e-02
I0209 00:09:10.617210 22542570456896 run_lib.py:133] step: 114450, training_loss: 2.93645e-02
I0209 00:09:28.068932 22542570456896 run_lib.py:133] step: 114500, training_loss: 3.36492e-02
I0209 00:09:28.249244 22542570456896 run_lib.py:146] step: 114500, eval_loss: 2.95780e-02
I0209 00:09:45.941032 22542570456896 run_lib.py:133] step: 114550, training_loss: 2.78936e-02
I0209 00:10:03.443657 22542570456896 run_lib.py:133] step: 114600, training_loss: 2.75975e-02
I0209 00:10:03.599415 22542570456896 run_lib.py:146] step: 114600, eval_loss: 2.72392e-02
I0209 00:10:21.003357 22542570456896 run_lib.py:133] step: 114650, training_loss: 2.99308e-02
I0209 00:10:38.394485 22542570456896 run_lib.py:133] step: 114700, training_loss: 2.68171e-02
I0209 00:10:38.550462 22542570456896 run_lib.py:146] step: 114700, eval_loss: 2.99305e-02
I0209 00:10:56.121323 22542570456896 run_lib.py:133] step: 114750, training_loss: 2.90624e-02
I0209 00:11:13.565554 22542570456896 run_lib.py:133] step: 114800, training_loss: 3.32253e-02
I0209 00:11:13.721579 22542570456896 run_lib.py:146] step: 114800, eval_loss: 3.08483e-02
I0209 00:11:31.336486 22542570456896 run_lib.py:133] step: 114850, training_loss: 2.63714e-02
I0209 00:11:48.787303 22542570456896 run_lib.py:133] step: 114900, training_loss: 2.34754e-02
I0209 00:11:48.941709 22542570456896 run_lib.py:146] step: 114900, eval_loss: 3.21254e-02
I0209 00:12:06.514912 22542570456896 run_lib.py:133] step: 114950, training_loss: 3.31272e-02
I0209 00:12:23.941180 22542570456896 run_lib.py:133] step: 115000, training_loss: 4.44426e-02
I0209 00:12:24.125411 22542570456896 run_lib.py:146] step: 115000, eval_loss: 2.72608e-02
I0209 00:12:41.590428 22542570456896 run_lib.py:133] step: 115050, training_loss: 3.52426e-02
I0209 00:12:59.229474 22542570456896 run_lib.py:133] step: 115100, training_loss: 3.68329e-02
I0209 00:12:59.386816 22542570456896 run_lib.py:146] step: 115100, eval_loss: 2.23599e-02
I0209 00:13:16.822284 22542570456896 run_lib.py:133] step: 115150, training_loss: 2.79056e-02
I0209 00:13:34.363721 22542570456896 run_lib.py:133] step: 115200, training_loss: 3.46505e-02
I0209 00:13:34.520100 22542570456896 run_lib.py:146] step: 115200, eval_loss: 2.88871e-02
I0209 00:13:51.917125 22542570456896 run_lib.py:133] step: 115250, training_loss: 3.20359e-02
I0209 00:14:09.347829 22542570456896 run_lib.py:133] step: 115300, training_loss: 2.71421e-02
I0209 00:14:09.498846 22542570456896 run_lib.py:146] step: 115300, eval_loss: 2.80530e-02
I0209 00:14:27.141998 22542570456896 run_lib.py:133] step: 115350, training_loss: 3.12671e-02
I0209 00:14:44.559874 22542570456896 run_lib.py:133] step: 115400, training_loss: 2.23335e-02
I0209 00:14:44.715935 22542570456896 run_lib.py:146] step: 115400, eval_loss: 2.43648e-02
I0209 00:15:02.102509 22542570456896 run_lib.py:133] step: 115450, training_loss: 3.16624e-02
I0209 00:15:19.701348 22542570456896 run_lib.py:133] step: 115500, training_loss: 2.28401e-02
I0209 00:15:19.862270 22542570456896 run_lib.py:146] step: 115500, eval_loss: 2.55779e-02
I0209 00:15:37.237711 22542570456896 run_lib.py:133] step: 115550, training_loss: 2.84098e-02
I0209 00:15:54.666391 22542570456896 run_lib.py:133] step: 115600, training_loss: 3.13421e-02
I0209 00:15:54.984522 22542570456896 run_lib.py:146] step: 115600, eval_loss: 2.92535e-02
I0209 00:16:12.425398 22542570456896 run_lib.py:133] step: 115650, training_loss: 3.45091e-02
I0209 00:16:29.892704 22542570456896 run_lib.py:133] step: 115700, training_loss: 2.83335e-02
I0209 00:16:30.047740 22542570456896 run_lib.py:146] step: 115700, eval_loss: 2.54365e-02
I0209 00:16:47.456069 22542570456896 run_lib.py:133] step: 115750, training_loss: 2.73642e-02
I0209 00:17:04.882068 22542570456896 run_lib.py:133] step: 115800, training_loss: 2.85800e-02
I0209 00:17:05.034247 22542570456896 run_lib.py:146] step: 115800, eval_loss: 2.56925e-02
I0209 00:17:22.605449 22542570456896 run_lib.py:133] step: 115850, training_loss: 2.80476e-02
I0209 00:17:40.083577 22542570456896 run_lib.py:133] step: 115900, training_loss: 2.66632e-02
I0209 00:17:40.253505 22542570456896 run_lib.py:146] step: 115900, eval_loss: 2.41503e-02
I0209 00:17:57.710132 22542570456896 run_lib.py:133] step: 115950, training_loss: 3.21684e-02
I0209 00:18:15.173565 22542570456896 run_lib.py:133] step: 116000, training_loss: 2.42356e-02
I0209 00:18:15.341428 22542570456896 run_lib.py:146] step: 116000, eval_loss: 3.19578e-02
I0209 00:18:32.916178 22542570456896 run_lib.py:133] step: 116050, training_loss: 3.52804e-02
I0209 00:18:50.364140 22542570456896 run_lib.py:133] step: 116100, training_loss: 2.82463e-02
I0209 00:18:50.520251 22542570456896 run_lib.py:146] step: 116100, eval_loss: 2.78755e-02
I0209 00:19:07.976366 22542570456896 run_lib.py:133] step: 116150, training_loss: 2.54943e-02
I0209 00:19:25.441568 22542570456896 run_lib.py:133] step: 116200, training_loss: 3.05834e-02
I0209 00:19:25.594676 22542570456896 run_lib.py:146] step: 116200, eval_loss: 2.71078e-02
I0209 00:19:43.203838 22542570456896 run_lib.py:133] step: 116250, training_loss: 2.72021e-02
I0209 00:20:00.606231 22542570456896 run_lib.py:133] step: 116300, training_loss: 2.96420e-02
I0209 00:20:00.759408 22542570456896 run_lib.py:146] step: 116300, eval_loss: 3.19589e-02
I0209 00:20:18.316842 22542570456896 run_lib.py:133] step: 116350, training_loss: 2.70598e-02
I0209 00:20:35.755249 22542570456896 run_lib.py:133] step: 116400, training_loss: 3.26132e-02
I0209 00:20:35.923386 22542570456896 run_lib.py:146] step: 116400, eval_loss: 3.23196e-02
I0209 00:20:53.556632 22542570456896 run_lib.py:133] step: 116450, training_loss: 2.37900e-02
I0209 00:21:10.971935 22542570456896 run_lib.py:133] step: 116500, training_loss: 2.98428e-02
I0209 00:21:11.131263 22542570456896 run_lib.py:146] step: 116500, eval_loss: 2.59138e-02
I0209 00:21:28.564103 22542570456896 run_lib.py:133] step: 116550, training_loss: 3.01181e-02
I0209 00:21:46.158273 22542570456896 run_lib.py:133] step: 116600, training_loss: 2.48826e-02
I0209 00:21:46.323066 22542570456896 run_lib.py:146] step: 116600, eval_loss: 2.33051e-02
I0209 00:22:03.772169 22542570456896 run_lib.py:133] step: 116650, training_loss: 2.69918e-02
I0209 00:22:21.409143 22542570456896 run_lib.py:133] step: 116700, training_loss: 3.16639e-02
I0209 00:22:21.562962 22542570456896 run_lib.py:146] step: 116700, eval_loss: 2.80754e-02
I0209 00:22:39.002303 22542570456896 run_lib.py:133] step: 116750, training_loss: 2.58804e-02
I0209 00:22:56.419202 22542570456896 run_lib.py:133] step: 116800, training_loss: 3.07816e-02
I0209 00:22:56.577290 22542570456896 run_lib.py:146] step: 116800, eval_loss: 2.20067e-02
I0209 00:23:14.154380 22542570456896 run_lib.py:133] step: 116850, training_loss: 2.84197e-02
I0209 00:23:31.609179 22542570456896 run_lib.py:133] step: 116900, training_loss: 2.46123e-02
I0209 00:23:31.769479 22542570456896 run_lib.py:146] step: 116900, eval_loss: 2.76548e-02
I0209 00:23:49.190490 22542570456896 run_lib.py:133] step: 116950, training_loss: 3.13090e-02
I0209 00:24:06.614598 22542570456896 run_lib.py:133] step: 117000, training_loss: 3.28559e-02
I0209 00:24:06.779411 22542570456896 run_lib.py:146] step: 117000, eval_loss: 2.98607e-02
I0209 00:24:24.378512 22542570456896 run_lib.py:133] step: 117050, training_loss: 2.62852e-02
I0209 00:24:41.793428 22542570456896 run_lib.py:133] step: 117100, training_loss: 2.81949e-02
I0209 00:24:41.954908 22542570456896 run_lib.py:146] step: 117100, eval_loss: 2.28278e-02
I0209 00:24:59.449724 22542570456896 run_lib.py:133] step: 117150, training_loss: 3.95391e-02
I0209 00:25:16.850679 22542570456896 run_lib.py:133] step: 117200, training_loss: 3.37969e-02
I0209 00:25:17.014140 22542570456896 run_lib.py:146] step: 117200, eval_loss: 2.46031e-02
I0209 00:25:34.478944 22542570456896 run_lib.py:133] step: 117250, training_loss: 2.76687e-02
I0209 00:25:51.900322 22542570456896 run_lib.py:133] step: 117300, training_loss: 2.81771e-02
I0209 00:25:52.057578 22542570456896 run_lib.py:146] step: 117300, eval_loss: 3.82935e-02
I0209 00:26:09.653709 22542570456896 run_lib.py:133] step: 117350, training_loss: 2.84209e-02
I0209 00:26:27.114027 22542570456896 run_lib.py:133] step: 117400, training_loss: 2.63090e-02
I0209 00:26:27.273533 22542570456896 run_lib.py:146] step: 117400, eval_loss: 2.20120e-02
I0209 00:26:44.686287 22542570456896 run_lib.py:133] step: 117450, training_loss: 2.67893e-02
I0209 00:27:02.101347 22542570456896 run_lib.py:133] step: 117500, training_loss: 2.60849e-02
I0209 00:27:02.277398 22542570456896 run_lib.py:146] step: 117500, eval_loss: 2.23263e-02
I0209 00:27:19.888068 22542570456896 run_lib.py:133] step: 117550, training_loss: 3.12274e-02
I0209 00:27:37.311199 22542570456896 run_lib.py:133] step: 117600, training_loss: 2.50117e-02
I0209 00:27:37.467136 22542570456896 run_lib.py:146] step: 117600, eval_loss: 3.52596e-02
I0209 00:27:55.059262 22542570456896 run_lib.py:133] step: 117650, training_loss: 2.80808e-02
I0209 00:28:12.460601 22542570456896 run_lib.py:133] step: 117700, training_loss: 3.19289e-02
I0209 00:28:12.612312 22542570456896 run_lib.py:146] step: 117700, eval_loss: 3.29987e-02
I0209 00:28:30.187936 22542570456896 run_lib.py:133] step: 117750, training_loss: 2.35822e-02
I0209 00:28:47.652955 22542570456896 run_lib.py:133] step: 117800, training_loss: 2.82547e-02
I0209 00:28:47.822491 22542570456896 run_lib.py:146] step: 117800, eval_loss: 2.60169e-02
I0209 00:29:05.468032 22542570456896 run_lib.py:133] step: 117850, training_loss: 2.15635e-02
I0209 00:29:22.870389 22542570456896 run_lib.py:133] step: 117900, training_loss: 3.06180e-02
I0209 00:29:23.028356 22542570456896 run_lib.py:146] step: 117900, eval_loss: 2.83874e-02
I0209 00:29:40.403038 22542570456896 run_lib.py:133] step: 117950, training_loss: 2.33758e-02
I0209 00:29:57.978049 22542570456896 run_lib.py:133] step: 118000, training_loss: 2.89510e-02
I0209 00:29:58.135363 22542570456896 run_lib.py:146] step: 118000, eval_loss: 3.21959e-02
I0209 00:30:15.558904 22542570456896 run_lib.py:133] step: 118050, training_loss: 2.57044e-02
I0209 00:30:33.042845 22542570456896 run_lib.py:133] step: 118100, training_loss: 3.26184e-02
I0209 00:30:33.199610 22542570456896 run_lib.py:146] step: 118100, eval_loss: 2.57046e-02
I0209 00:30:50.839904 22542570456896 run_lib.py:133] step: 118150, training_loss: 3.04943e-02
I0209 00:31:08.402877 22542570456896 run_lib.py:133] step: 118200, training_loss: 2.72011e-02
I0209 00:31:08.556339 22542570456896 run_lib.py:146] step: 118200, eval_loss: 2.71748e-02
I0209 00:31:25.948524 22542570456896 run_lib.py:133] step: 118250, training_loss: 2.30310e-02
I0209 00:31:43.408173 22542570456896 run_lib.py:133] step: 118300, training_loss: 2.34110e-02
I0209 00:31:43.572838 22542570456896 run_lib.py:146] step: 118300, eval_loss: 3.05333e-02
I0209 00:32:01.047750 22542570456896 run_lib.py:133] step: 118350, training_loss: 2.87529e-02
I0209 00:32:18.715360 22542570456896 run_lib.py:133] step: 118400, training_loss: 3.01520e-02
I0209 00:32:18.877316 22542570456896 run_lib.py:146] step: 118400, eval_loss: 2.70065e-02
I0209 00:32:36.287700 22542570456896 run_lib.py:133] step: 118450, training_loss: 2.44890e-02
I0209 00:32:53.699666 22542570456896 run_lib.py:133] step: 118500, training_loss: 3.26327e-02
I0209 00:32:53.856794 22542570456896 run_lib.py:146] step: 118500, eval_loss: 2.83236e-02
I0209 00:33:11.269228 22542570456896 run_lib.py:133] step: 118550, training_loss: 2.99662e-02
I0209 00:33:28.850405 22542570456896 run_lib.py:133] step: 118600, training_loss: 2.67349e-02
I0209 00:33:29.004964 22542570456896 run_lib.py:146] step: 118600, eval_loss: 3.22724e-02
I0209 00:33:46.470390 22542570456896 run_lib.py:133] step: 118650, training_loss: 3.45131e-02
I0209 00:34:03.990585 22542570456896 run_lib.py:133] step: 118700, training_loss: 2.65372e-02
I0209 00:34:04.144389 22542570456896 run_lib.py:146] step: 118700, eval_loss: 2.88029e-02
I0209 00:34:21.608473 22542570456896 run_lib.py:133] step: 118750, training_loss: 2.75931e-02
I0209 00:34:39.002533 22542570456896 run_lib.py:133] step: 118800, training_loss: 2.63911e-02
I0209 00:34:39.164712 22542570456896 run_lib.py:146] step: 118800, eval_loss: 2.98998e-02
I0209 00:34:56.702119 22542570456896 run_lib.py:133] step: 118850, training_loss: 2.93273e-02
I0209 00:35:14.208204 22542570456896 run_lib.py:133] step: 118900, training_loss: 3.46473e-02
I0209 00:35:14.378277 22542570456896 run_lib.py:146] step: 118900, eval_loss: 2.84169e-02
I0209 00:35:31.824331 22542570456896 run_lib.py:133] step: 118950, training_loss: 2.75620e-02
I0209 00:35:49.223567 22542570456896 run_lib.py:133] step: 119000, training_loss: 2.99526e-02
I0209 00:35:49.380807 22542570456896 run_lib.py:146] step: 119000, eval_loss: 2.90690e-02
I0209 00:36:06.974875 22542570456896 run_lib.py:133] step: 119050, training_loss: 3.05660e-02
I0209 00:36:24.417757 22542570456896 run_lib.py:133] step: 119100, training_loss: 3.11396e-02
I0209 00:36:24.571338 22542570456896 run_lib.py:146] step: 119100, eval_loss: 3.05348e-02
I0209 00:36:42.136251 22542570456896 run_lib.py:133] step: 119150, training_loss: 2.31377e-02
I0209 00:36:59.598844 22542570456896 run_lib.py:133] step: 119200, training_loss: 2.84428e-02
I0209 00:36:59.776288 22542570456896 run_lib.py:146] step: 119200, eval_loss: 3.82268e-02
I0209 00:37:17.387969 22542570456896 run_lib.py:133] step: 119250, training_loss: 3.39020e-02
I0209 00:37:34.842461 22542570456896 run_lib.py:133] step: 119300, training_loss: 2.70239e-02
I0209 00:37:35.003373 22542570456896 run_lib.py:146] step: 119300, eval_loss: 3.36782e-02
I0209 00:37:52.431270 22542570456896 run_lib.py:133] step: 119350, training_loss: 2.19873e-02
I0209 00:38:09.965094 22542570456896 run_lib.py:133] step: 119400, training_loss: 2.86258e-02
I0209 00:38:10.129360 22542570456896 run_lib.py:146] step: 119400, eval_loss: 2.72819e-02
I0209 00:38:27.567163 22542570456896 run_lib.py:133] step: 119450, training_loss: 2.51053e-02
I0209 00:38:45.186336 22542570456896 run_lib.py:133] step: 119500, training_loss: 2.41258e-02
I0209 00:38:45.339643 22542570456896 run_lib.py:146] step: 119500, eval_loss: 2.75507e-02
I0209 00:39:02.763139 22542570456896 run_lib.py:133] step: 119550, training_loss: 3.35089e-02
I0209 00:39:20.208033 22542570456896 run_lib.py:133] step: 119600, training_loss: 3.00673e-02
I0209 00:39:20.362382 22542570456896 run_lib.py:146] step: 119600, eval_loss: 2.79080e-02
I0209 00:39:37.925973 22542570456896 run_lib.py:133] step: 119650, training_loss: 2.82760e-02
I0209 00:39:55.318269 22542570456896 run_lib.py:133] step: 119700, training_loss: 2.66847e-02
I0209 00:39:55.475455 22542570456896 run_lib.py:146] step: 119700, eval_loss: 2.89109e-02
I0209 00:40:12.912198 22542570456896 run_lib.py:133] step: 119750, training_loss: 2.55821e-02
I0209 00:40:30.584756 22542570456896 run_lib.py:133] step: 119800, training_loss: 3.27322e-02
I0209 00:40:30.741393 22542570456896 run_lib.py:146] step: 119800, eval_loss: 2.53644e-02
I0209 00:40:48.169954 22542570456896 run_lib.py:133] step: 119850, training_loss: 2.80842e-02
I0209 00:41:05.620513 22542570456896 run_lib.py:133] step: 119900, training_loss: 2.93816e-02
I0209 00:41:05.777294 22542570456896 run_lib.py:146] step: 119900, eval_loss: 2.46374e-02
I0209 00:41:23.268354 22542570456896 run_lib.py:133] step: 119950, training_loss: 3.15473e-02
I0209 00:41:40.686147 22542570456896 run_lib.py:133] step: 120000, training_loss: 2.31050e-02
I0209 00:41:41.421283 22542570456896 run_lib.py:146] step: 120000, eval_loss: 2.66282e-02
I0209 00:42:01.508473 22542570456896 run_lib.py:133] step: 120050, training_loss: 2.80048e-02
I0209 00:42:18.989343 22542570456896 run_lib.py:133] step: 120100, training_loss: 2.51754e-02
I0209 00:42:19.146278 22542570456896 run_lib.py:146] step: 120100, eval_loss: 2.55672e-02
I0209 00:42:36.750084 22542570456896 run_lib.py:133] step: 120150, training_loss: 3.80233e-02
I0209 00:42:54.152908 22542570456896 run_lib.py:133] step: 120200, training_loss: 3.31357e-02
I0209 00:42:54.312385 22542570456896 run_lib.py:146] step: 120200, eval_loss: 3.36150e-02
I0209 00:43:11.776973 22542570456896 run_lib.py:133] step: 120250, training_loss: 2.82338e-02
I0209 00:43:29.184794 22542570456896 run_lib.py:133] step: 120300, training_loss: 3.15285e-02
I0209 00:43:29.362288 22542570456896 run_lib.py:146] step: 120300, eval_loss: 2.88053e-02
I0209 00:43:46.812095 22542570456896 run_lib.py:133] step: 120350, training_loss: 2.61642e-02
I0209 00:44:04.233814 22542570456896 run_lib.py:133] step: 120400, training_loss: 2.77460e-02
I0209 00:44:04.398581 22542570456896 run_lib.py:146] step: 120400, eval_loss: 2.50119e-02
I0209 00:44:21.983321 22542570456896 run_lib.py:133] step: 120450, training_loss: 3.05745e-02
I0209 00:44:39.493799 22542570456896 run_lib.py:133] step: 120500, training_loss: 2.73703e-02
I0209 00:44:39.658772 22542570456896 run_lib.py:146] step: 120500, eval_loss: 3.28533e-02
I0209 00:44:57.062968 22542570456896 run_lib.py:133] step: 120550, training_loss: 2.69985e-02
I0209 00:45:14.513598 22542570456896 run_lib.py:133] step: 120600, training_loss: 3.10533e-02
I0209 00:45:14.665852 22542570456896 run_lib.py:146] step: 120600, eval_loss: 2.92479e-02
I0209 00:45:32.297475 22542570456896 run_lib.py:133] step: 120650, training_loss: 3.46166e-02
I0209 00:45:49.711469 22542570456896 run_lib.py:133] step: 120700, training_loss: 2.98692e-02
I0209 00:45:49.867780 22542570456896 run_lib.py:146] step: 120700, eval_loss: 2.48682e-02
I0209 00:46:07.420604 22542570456896 run_lib.py:133] step: 120750, training_loss: 2.86266e-02
I0209 00:46:24.824631 22542570456896 run_lib.py:133] step: 120800, training_loss: 2.57929e-02
I0209 00:46:24.981578 22542570456896 run_lib.py:146] step: 120800, eval_loss: 2.81628e-02
I0209 00:46:42.565762 22542570456896 run_lib.py:133] step: 120850, training_loss: 3.13963e-02
I0209 00:47:00.037805 22542570456896 run_lib.py:133] step: 120900, training_loss: 2.90058e-02
I0209 00:47:00.201515 22542570456896 run_lib.py:146] step: 120900, eval_loss: 3.41003e-02
I0209 00:47:17.828045 22542570456896 run_lib.py:133] step: 120950, training_loss: 2.54805e-02
I0209 00:47:35.229873 22542570456896 run_lib.py:133] step: 121000, training_loss: 2.57148e-02
I0209 00:47:35.385156 22542570456896 run_lib.py:146] step: 121000, eval_loss: 2.60189e-02
I0209 00:47:52.786310 22542570456896 run_lib.py:133] step: 121050, training_loss: 3.05554e-02
I0209 00:48:10.342399 22542570456896 run_lib.py:133] step: 121100, training_loss: 2.25246e-02
I0209 00:48:10.498553 22542570456896 run_lib.py:146] step: 121100, eval_loss: 2.94416e-02
I0209 00:48:27.921978 22542570456896 run_lib.py:133] step: 121150, training_loss: 2.69252e-02
I0209 00:48:45.349356 22542570456896 run_lib.py:133] step: 121200, training_loss: 2.58478e-02
I0209 00:48:45.505553 22542570456896 run_lib.py:146] step: 121200, eval_loss: 2.41603e-02
I0209 00:49:03.145372 22542570456896 run_lib.py:133] step: 121250, training_loss: 3.09799e-02
I0209 00:49:20.610357 22542570456896 run_lib.py:133] step: 121300, training_loss: 2.42423e-02
I0209 00:49:20.769646 22542570456896 run_lib.py:146] step: 121300, eval_loss: 2.28775e-02
I0209 00:49:38.349858 22542570456896 run_lib.py:133] step: 121350, training_loss: 3.38181e-02
I0209 00:49:55.759854 22542570456896 run_lib.py:133] step: 121400, training_loss: 2.63727e-02
I0209 00:49:55.916073 22542570456896 run_lib.py:146] step: 121400, eval_loss: 3.00413e-02
I0209 00:50:13.375560 22542570456896 run_lib.py:133] step: 121450, training_loss: 2.82735e-02
I0209 00:50:31.043570 22542570456896 run_lib.py:133] step: 121500, training_loss: 2.98060e-02
I0209 00:50:31.199084 22542570456896 run_lib.py:146] step: 121500, eval_loss: 2.28573e-02
I0209 00:50:48.619327 22542570456896 run_lib.py:133] step: 121550, training_loss: 3.16216e-02
I0209 00:51:06.023909 22542570456896 run_lib.py:133] step: 121600, training_loss: 2.85626e-02
I0209 00:51:06.177351 22542570456896 run_lib.py:146] step: 121600, eval_loss: 3.06671e-02
I0209 00:51:23.620221 22542570456896 run_lib.py:133] step: 121650, training_loss: 3.48842e-02
I0209 00:51:41.204414 22542570456896 run_lib.py:133] step: 121700, training_loss: 3.01773e-02
I0209 00:51:41.378035 22542570456896 run_lib.py:146] step: 121700, eval_loss: 2.56064e-02
I0209 00:51:58.822024 22542570456896 run_lib.py:133] step: 121750, training_loss: 3.37500e-02
I0209 00:52:16.370092 22542570456896 run_lib.py:133] step: 121800, training_loss: 2.74718e-02
I0209 00:52:16.535287 22542570456896 run_lib.py:146] step: 121800, eval_loss: 2.42146e-02
I0209 00:52:33.926519 22542570456896 run_lib.py:133] step: 121850, training_loss: 2.99907e-02
I0209 00:52:51.377180 22542570456896 run_lib.py:133] step: 121900, training_loss: 3.02350e-02
I0209 00:52:51.534378 22542570456896 run_lib.py:146] step: 121900, eval_loss: 2.81369e-02
I0209 00:53:09.087980 22542570456896 run_lib.py:133] step: 121950, training_loss: 3.34352e-02
I0209 00:53:26.625736 22542570456896 run_lib.py:133] step: 122000, training_loss: 3.38775e-02
I0209 00:53:26.789869 22542570456896 run_lib.py:146] step: 122000, eval_loss: 3.24145e-02
I0209 00:53:44.255487 22542570456896 run_lib.py:133] step: 122050, training_loss: 3.02726e-02
I0209 00:54:01.655304 22542570456896 run_lib.py:133] step: 122100, training_loss: 3.01035e-02
I0209 00:54:01.811221 22542570456896 run_lib.py:146] step: 122100, eval_loss: 2.52909e-02
I0209 00:54:19.383685 22542570456896 run_lib.py:133] step: 122150, training_loss: 2.92457e-02
I0209 00:54:36.809548 22542570456896 run_lib.py:133] step: 122200, training_loss: 2.78003e-02
I0209 00:54:36.968534 22542570456896 run_lib.py:146] step: 122200, eval_loss: 2.71326e-02
I0209 00:54:54.597952 22542570456896 run_lib.py:133] step: 122250, training_loss: 3.00772e-02
I0209 00:55:12.067724 22542570456896 run_lib.py:133] step: 122300, training_loss: 2.53552e-02
I0209 00:55:12.232534 22542570456896 run_lib.py:146] step: 122300, eval_loss: 2.68283e-02
I0209 00:55:29.845546 22542570456896 run_lib.py:133] step: 122350, training_loss: 2.98901e-02
I0209 00:55:47.238775 22542570456896 run_lib.py:133] step: 122400, training_loss: 2.63854e-02
I0209 00:55:47.392859 22542570456896 run_lib.py:146] step: 122400, eval_loss: 2.93111e-02
I0209 00:56:04.797282 22542570456896 run_lib.py:133] step: 122450, training_loss: 3.31969e-02
I0209 00:56:22.388848 22542570456896 run_lib.py:133] step: 122500, training_loss: 3.09852e-02
I0209 00:56:22.551873 22542570456896 run_lib.py:146] step: 122500, eval_loss: 2.17762e-02
I0209 00:56:40.032128 22542570456896 run_lib.py:133] step: 122550, training_loss: 2.78121e-02
I0209 00:56:57.692611 22542570456896 run_lib.py:133] step: 122600, training_loss: 2.78610e-02
I0209 00:56:57.855612 22542570456896 run_lib.py:146] step: 122600, eval_loss: 3.11025e-02
I0209 00:57:15.293886 22542570456896 run_lib.py:133] step: 122650, training_loss: 3.43825e-02
I0209 00:57:32.744763 22542570456896 run_lib.py:133] step: 122700, training_loss: 2.71052e-02
I0209 00:57:32.911608 22542570456896 run_lib.py:146] step: 122700, eval_loss: 2.83477e-02
I0209 00:57:50.462476 22542570456896 run_lib.py:133] step: 122750, training_loss: 2.78917e-02
I0209 00:58:07.926362 22542570456896 run_lib.py:133] step: 122800, training_loss: 3.04149e-02
I0209 00:58:08.093026 22542570456896 run_lib.py:146] step: 122800, eval_loss: 2.83526e-02
I0209 00:58:25.570986 22542570456896 run_lib.py:133] step: 122850, training_loss: 2.99891e-02
I0209 00:58:43.171954 22542570456896 run_lib.py:133] step: 122900, training_loss: 2.83782e-02
I0209 00:58:43.333156 22542570456896 run_lib.py:146] step: 122900, eval_loss: 2.84677e-02
I0209 00:59:00.782395 22542570456896 run_lib.py:133] step: 122950, training_loss: 3.60920e-02
I0209 00:59:18.224111 22542570456896 run_lib.py:133] step: 123000, training_loss: 2.86050e-02
I0209 00:59:18.524337 22542570456896 run_lib.py:146] step: 123000, eval_loss: 3.35675e-02
I0209 00:59:35.925692 22542570456896 run_lib.py:133] step: 123050, training_loss: 2.05798e-02
I0209 00:59:53.346781 22542570456896 run_lib.py:133] step: 123100, training_loss: 2.48177e-02
I0209 00:59:53.516175 22542570456896 run_lib.py:146] step: 123100, eval_loss: 2.88093e-02
I0209 01:00:10.953326 22542570456896 run_lib.py:133] step: 123150, training_loss: 3.02752e-02
I0209 01:00:28.396852 22542570456896 run_lib.py:133] step: 123200, training_loss: 2.40875e-02
I0209 01:00:28.556591 22542570456896 run_lib.py:146] step: 123200, eval_loss: 2.75189e-02
I0209 01:00:46.159087 22542570456896 run_lib.py:133] step: 123250, training_loss: 3.20458e-02
I0209 01:01:03.621599 22542570456896 run_lib.py:133] step: 123300, training_loss: 3.52113e-02
I0209 01:01:03.777407 22542570456896 run_lib.py:146] step: 123300, eval_loss: 3.12553e-02
I0209 01:01:21.185100 22542570456896 run_lib.py:133] step: 123350, training_loss: 3.51647e-02
I0209 01:01:38.650845 22542570456896 run_lib.py:133] step: 123400, training_loss: 2.49645e-02
I0209 01:01:38.809661 22542570456896 run_lib.py:146] step: 123400, eval_loss: 3.14099e-02
I0209 01:01:56.443405 22542570456896 run_lib.py:133] step: 123450, training_loss: 2.65337e-02
I0209 01:02:13.890946 22542570456896 run_lib.py:133] step: 123500, training_loss: 2.40985e-02
I0209 01:02:14.048384 22542570456896 run_lib.py:146] step: 123500, eval_loss: 2.88971e-02
I0209 01:02:31.448530 22542570456896 run_lib.py:133] step: 123550, training_loss: 2.95261e-02
I0209 01:02:48.860683 22542570456896 run_lib.py:133] step: 123600, training_loss: 2.44221e-02
I0209 01:02:49.019479 22542570456896 run_lib.py:146] step: 123600, eval_loss: 2.88972e-02
I0209 01:03:06.581108 22542570456896 run_lib.py:133] step: 123650, training_loss: 2.84663e-02
I0209 01:03:24.061237 22542570456896 run_lib.py:133] step: 123700, training_loss: 2.58383e-02
I0209 01:03:24.218479 22542570456896 run_lib.py:146] step: 123700, eval_loss: 2.73374e-02
I0209 01:03:41.868608 22542570456896 run_lib.py:133] step: 123750, training_loss: 2.89488e-02
I0209 01:03:59.329305 22542570456896 run_lib.py:133] step: 123800, training_loss: 2.54587e-02
I0209 01:03:59.494302 22542570456896 run_lib.py:146] step: 123800, eval_loss: 3.23689e-02
I0209 01:04:17.092738 22542570456896 run_lib.py:133] step: 123850, training_loss: 2.47576e-02
I0209 01:04:34.503317 22542570456896 run_lib.py:133] step: 123900, training_loss: 2.68001e-02
I0209 01:04:34.656320 22542570456896 run_lib.py:146] step: 123900, eval_loss: 2.49485e-02
I0209 01:04:52.113846 22542570456896 run_lib.py:133] step: 123950, training_loss: 3.50818e-02
I0209 01:05:09.778547 22542570456896 run_lib.py:133] step: 124000, training_loss: 2.85639e-02
I0209 01:05:09.935563 22542570456896 run_lib.py:146] step: 124000, eval_loss: 3.01466e-02
I0209 01:05:27.380769 22542570456896 run_lib.py:133] step: 124050, training_loss: 2.32574e-02
I0209 01:05:44.961609 22542570456896 run_lib.py:133] step: 124100, training_loss: 2.91511e-02
I0209 01:05:45.119712 22542570456896 run_lib.py:146] step: 124100, eval_loss: 2.59558e-02
I0209 01:06:02.516127 22542570456896 run_lib.py:133] step: 124150, training_loss: 3.34903e-02
I0209 01:06:19.923032 22542570456896 run_lib.py:133] step: 124200, training_loss: 2.86539e-02
I0209 01:06:20.091299 22542570456896 run_lib.py:146] step: 124200, eval_loss: 2.85836e-02
I0209 01:06:37.672062 22542570456896 run_lib.py:133] step: 124250, training_loss: 3.57123e-02
I0209 01:06:55.088157 22542570456896 run_lib.py:133] step: 124300, training_loss: 2.80842e-02
I0209 01:06:55.242706 22542570456896 run_lib.py:146] step: 124300, eval_loss: 2.85037e-02
I0209 01:07:12.684533 22542570456896 run_lib.py:133] step: 124350, training_loss: 2.38094e-02
I0209 01:07:30.095372 22542570456896 run_lib.py:133] step: 124400, training_loss: 2.51878e-02
I0209 01:07:30.246311 22542570456896 run_lib.py:146] step: 124400, eval_loss: 2.53245e-02
I0209 01:07:47.851619 22542570456896 run_lib.py:133] step: 124450, training_loss: 3.56571e-02
I0209 01:08:05.280234 22542570456896 run_lib.py:133] step: 124500, training_loss: 2.49975e-02
I0209 01:08:05.452089 22542570456896 run_lib.py:146] step: 124500, eval_loss: 3.11100e-02
I0209 01:08:22.971438 22542570456896 run_lib.py:133] step: 124550, training_loss: 3.65321e-02
I0209 01:08:40.415786 22542570456896 run_lib.py:133] step: 124600, training_loss: 2.75243e-02
I0209 01:08:40.574528 22542570456896 run_lib.py:146] step: 124600, eval_loss: 3.06733e-02
I0209 01:08:57.946698 22542570456896 run_lib.py:133] step: 124650, training_loss: 2.19425e-02
I0209 01:09:15.326994 22542570456896 run_lib.py:133] step: 124700, training_loss: 2.55408e-02
I0209 01:09:15.484374 22542570456896 run_lib.py:146] step: 124700, eval_loss: 2.88656e-02
I0209 01:09:33.124040 22542570456896 run_lib.py:133] step: 124750, training_loss: 2.43076e-02
I0209 01:09:50.683106 22542570456896 run_lib.py:133] step: 124800, training_loss: 2.99967e-02
I0209 01:09:50.841859 22542570456896 run_lib.py:146] step: 124800, eval_loss: 2.42306e-02
I0209 01:10:08.345686 22542570456896 run_lib.py:133] step: 124850, training_loss: 2.51492e-02
I0209 01:10:25.764099 22542570456896 run_lib.py:133] step: 124900, training_loss: 3.37593e-02
I0209 01:10:25.916293 22542570456896 run_lib.py:146] step: 124900, eval_loss: 3.38321e-02
I0209 01:10:43.506572 22542570456896 run_lib.py:133] step: 124950, training_loss: 3.29374e-02
I0209 01:11:00.922150 22542570456896 run_lib.py:133] step: 125000, training_loss: 2.65901e-02
I0209 01:11:01.077534 22542570456896 run_lib.py:146] step: 125000, eval_loss: 2.80833e-02
I0209 01:11:18.644587 22542570456896 run_lib.py:133] step: 125050, training_loss: 2.56640e-02
I0209 01:11:36.129965 22542570456896 run_lib.py:133] step: 125100, training_loss: 2.99560e-02
I0209 01:11:36.300512 22542570456896 run_lib.py:146] step: 125100, eval_loss: 2.33684e-02
I0209 01:11:53.900249 22542570456896 run_lib.py:133] step: 125150, training_loss: 2.69731e-02
I0209 01:12:11.360586 22542570456896 run_lib.py:133] step: 125200, training_loss: 2.98726e-02
I0209 01:12:11.515017 22542570456896 run_lib.py:146] step: 125200, eval_loss: 2.85098e-02
I0209 01:12:29.066842 22542570456896 run_lib.py:133] step: 125250, training_loss: 3.07820e-02
I0209 01:12:46.510531 22542570456896 run_lib.py:133] step: 125300, training_loss: 2.96603e-02
I0209 01:12:46.664246 22542570456896 run_lib.py:146] step: 125300, eval_loss: 3.18835e-02
I0209 01:13:04.163912 22542570456896 run_lib.py:133] step: 125350, training_loss: 2.58739e-02
I0209 01:13:21.777890 22542570456896 run_lib.py:133] step: 125400, training_loss: 2.35358e-02
I0209 01:13:21.931343 22542570456896 run_lib.py:146] step: 125400, eval_loss: 2.75177e-02
I0209 01:13:39.359808 22542570456896 run_lib.py:133] step: 125450, training_loss: 2.86990e-02
I0209 01:13:56.818740 22542570456896 run_lib.py:133] step: 125500, training_loss: 2.09058e-02
I0209 01:13:56.977592 22542570456896 run_lib.py:146] step: 125500, eval_loss: 3.01127e-02
I0209 01:14:14.597799 22542570456896 run_lib.py:133] step: 125550, training_loss: 3.40661e-02
I0209 01:14:32.227526 22542570456896 run_lib.py:133] step: 125600, training_loss: 2.49981e-02
I0209 01:14:32.384490 22542570456896 run_lib.py:146] step: 125600, eval_loss: 3.78806e-02
I0209 01:14:49.831244 22542570456896 run_lib.py:133] step: 125650, training_loss: 2.99735e-02
I0209 01:15:07.287093 22542570456896 run_lib.py:133] step: 125700, training_loss: 2.90041e-02
I0209 01:15:07.442075 22542570456896 run_lib.py:146] step: 125700, eval_loss: 2.81008e-02
I0209 01:15:24.863589 22542570456896 run_lib.py:133] step: 125750, training_loss: 3.07312e-02
I0209 01:15:42.491374 22542570456896 run_lib.py:133] step: 125800, training_loss: 2.69967e-02
I0209 01:15:42.642239 22542570456896 run_lib.py:146] step: 125800, eval_loss: 2.47836e-02
I0209 01:16:00.087250 22542570456896 run_lib.py:133] step: 125850, training_loss: 2.59347e-02
I0209 01:16:17.546580 22542570456896 run_lib.py:133] step: 125900, training_loss: 2.70394e-02
I0209 01:16:17.713105 22542570456896 run_lib.py:146] step: 125900, eval_loss: 3.49147e-02
I0209 01:16:35.201480 22542570456896 run_lib.py:133] step: 125950, training_loss: 3.15103e-02
I0209 01:16:52.823719 22542570456896 run_lib.py:133] step: 126000, training_loss: 2.96345e-02
I0209 01:16:52.983587 22542570456896 run_lib.py:146] step: 126000, eval_loss: 3.54014e-02
I0209 01:17:10.442667 22542570456896 run_lib.py:133] step: 126050, training_loss: 2.79755e-02
I0209 01:17:27.900875 22542570456896 run_lib.py:133] step: 126100, training_loss: 3.28571e-02
I0209 01:17:28.066248 22542570456896 run_lib.py:146] step: 126100, eval_loss: 3.00867e-02
I0209 01:17:45.551620 22542570456896 run_lib.py:133] step: 126150, training_loss: 2.76262e-02
I0209 01:18:02.998489 22542570456896 run_lib.py:133] step: 126200, training_loss: 2.55711e-02
I0209 01:18:03.154600 22542570456896 run_lib.py:146] step: 126200, eval_loss: 2.55707e-02
I0209 01:18:20.774888 22542570456896 run_lib.py:133] step: 126250, training_loss: 3.04207e-02
I0209 01:18:38.254064 22542570456896 run_lib.py:133] step: 126300, training_loss: 2.28328e-02
I0209 01:18:38.406490 22542570456896 run_lib.py:146] step: 126300, eval_loss: 3.35094e-02
I0209 01:18:55.828990 22542570456896 run_lib.py:133] step: 126350, training_loss: 2.87455e-02
I0209 01:19:13.258913 22542570456896 run_lib.py:133] step: 126400, training_loss: 2.23128e-02
I0209 01:19:13.429586 22542570456896 run_lib.py:146] step: 126400, eval_loss: 3.13226e-02
I0209 01:19:31.038516 22542570456896 run_lib.py:133] step: 126450, training_loss: 2.37686e-02
I0209 01:19:48.517428 22542570456896 run_lib.py:133] step: 126500, training_loss: 3.03027e-02
I0209 01:19:48.676354 22542570456896 run_lib.py:146] step: 126500, eval_loss: 3.41227e-02
I0209 01:20:06.309563 22542570456896 run_lib.py:133] step: 126550, training_loss: 3.68967e-02
I0209 01:20:23.741297 22542570456896 run_lib.py:133] step: 126600, training_loss: 3.46756e-02
I0209 01:20:23.897380 22542570456896 run_lib.py:146] step: 126600, eval_loss: 2.83945e-02
I0209 01:20:41.463743 22542570456896 run_lib.py:133] step: 126650, training_loss: 3.30295e-02
I0209 01:20:58.909248 22542570456896 run_lib.py:133] step: 126700, training_loss: 3.08217e-02
I0209 01:20:59.065577 22542570456896 run_lib.py:146] step: 126700, eval_loss: 2.86821e-02
I0209 01:21:16.530559 22542570456896 run_lib.py:133] step: 126750, training_loss: 2.81701e-02
I0209 01:21:34.171252 22542570456896 run_lib.py:133] step: 126800, training_loss: 2.74287e-02
I0209 01:21:34.325389 22542570456896 run_lib.py:146] step: 126800, eval_loss: 2.88756e-02
I0209 01:21:51.758880 22542570456896 run_lib.py:133] step: 126850, training_loss: 2.37498e-02
I0209 01:22:09.385434 22542570456896 run_lib.py:133] step: 126900, training_loss: 3.35938e-02
I0209 01:22:09.549587 22542570456896 run_lib.py:146] step: 126900, eval_loss: 2.76752e-02
I0209 01:22:26.968601 22542570456896 run_lib.py:133] step: 126950, training_loss: 3.34753e-02
I0209 01:22:44.410361 22542570456896 run_lib.py:133] step: 127000, training_loss: 2.88008e-02
I0209 01:22:44.578413 22542570456896 run_lib.py:146] step: 127000, eval_loss: 2.91640e-02
I0209 01:23:02.204698 22542570456896 run_lib.py:133] step: 127050, training_loss: 2.78903e-02
I0209 01:23:19.658140 22542570456896 run_lib.py:133] step: 127100, training_loss: 3.05968e-02
I0209 01:23:19.811957 22542570456896 run_lib.py:146] step: 127100, eval_loss: 3.19778e-02
I0209 01:23:37.273817 22542570456896 run_lib.py:133] step: 127150, training_loss: 2.42383e-02
I0209 01:23:54.851732 22542570456896 run_lib.py:133] step: 127200, training_loss: 2.70652e-02
I0209 01:23:55.005329 22542570456896 run_lib.py:146] step: 127200, eval_loss: 3.70800e-02
I0209 01:24:12.436695 22542570456896 run_lib.py:133] step: 127250, training_loss: 3.34774e-02
I0209 01:24:29.873907 22542570456896 run_lib.py:133] step: 127300, training_loss: 2.59958e-02
I0209 01:24:30.036563 22542570456896 run_lib.py:146] step: 127300, eval_loss: 2.65281e-02
I0209 01:24:47.592978 22542570456896 run_lib.py:133] step: 127350, training_loss: 3.32906e-02
I0209 01:25:05.003306 22542570456896 run_lib.py:133] step: 127400, training_loss: 3.11360e-02
I0209 01:25:05.161194 22542570456896 run_lib.py:146] step: 127400, eval_loss: 2.30522e-02
I0209 01:25:22.577031 22542570456896 run_lib.py:133] step: 127450, training_loss: 2.75519e-02
I0209 01:25:39.980171 22542570456896 run_lib.py:133] step: 127500, training_loss: 3.09092e-02
I0209 01:25:40.135396 22542570456896 run_lib.py:146] step: 127500, eval_loss: 2.65118e-02
I0209 01:25:57.735495 22542570456896 run_lib.py:133] step: 127550, training_loss: 2.68630e-02
I0209 01:26:15.238486 22542570456896 run_lib.py:133] step: 127600, training_loss: 2.79384e-02
I0209 01:26:15.404135 22542570456896 run_lib.py:146] step: 127600, eval_loss: 2.96317e-02
I0209 01:26:32.860679 22542570456896 run_lib.py:133] step: 127650, training_loss: 2.94398e-02
I0209 01:26:50.305997 22542570456896 run_lib.py:133] step: 127700, training_loss: 2.63059e-02
I0209 01:26:50.457548 22542570456896 run_lib.py:146] step: 127700, eval_loss: 2.75890e-02
I0209 01:27:08.021500 22542570456896 run_lib.py:133] step: 127750, training_loss: 2.73515e-02
I0209 01:27:25.444290 22542570456896 run_lib.py:133] step: 127800, training_loss: 2.75686e-02
I0209 01:27:25.599992 22542570456896 run_lib.py:146] step: 127800, eval_loss: 2.09300e-02
I0209 01:27:43.180111 22542570456896 run_lib.py:133] step: 127850, training_loss: 3.25474e-02
I0209 01:28:00.653116 22542570456896 run_lib.py:133] step: 127900, training_loss: 2.49755e-02
I0209 01:28:00.825338 22542570456896 run_lib.py:146] step: 127900, eval_loss: 2.79797e-02
I0209 01:28:18.402853 22542570456896 run_lib.py:133] step: 127950, training_loss: 3.62185e-02
I0209 01:28:35.807366 22542570456896 run_lib.py:133] step: 128000, training_loss: 3.03881e-02
I0209 01:28:35.962526 22542570456896 run_lib.py:146] step: 128000, eval_loss: 3.59441e-02
I0209 01:28:53.516184 22542570456896 run_lib.py:133] step: 128050, training_loss: 2.98256e-02
I0209 01:29:10.927665 22542570456896 run_lib.py:133] step: 128100, training_loss: 2.97650e-02
I0209 01:29:11.083367 22542570456896 run_lib.py:146] step: 128100, eval_loss: 3.50392e-02
I0209 01:29:28.493436 22542570456896 run_lib.py:133] step: 128150, training_loss: 2.74873e-02
I0209 01:29:46.072358 22542570456896 run_lib.py:133] step: 128200, training_loss: 2.44936e-02
I0209 01:29:46.223203 22542570456896 run_lib.py:146] step: 128200, eval_loss: 2.78528e-02
I0209 01:30:03.654760 22542570456896 run_lib.py:133] step: 128250, training_loss: 3.05724e-02
I0209 01:30:21.111093 22542570456896 run_lib.py:133] step: 128300, training_loss: 2.36803e-02
I0209 01:30:21.267039 22542570456896 run_lib.py:146] step: 128300, eval_loss: 2.78916e-02
I0209 01:30:38.877374 22542570456896 run_lib.py:133] step: 128350, training_loss: 2.98654e-02
I0209 01:30:56.303821 22542570456896 run_lib.py:133] step: 128400, training_loss: 2.82585e-02
I0209 01:30:56.462318 22542570456896 run_lib.py:146] step: 128400, eval_loss: 2.94771e-02
I0209 01:31:14.024206 22542570456896 run_lib.py:133] step: 128450, training_loss: 2.86089e-02
I0209 01:31:31.477105 22542570456896 run_lib.py:133] step: 128500, training_loss: 2.45453e-02
I0209 01:31:31.637575 22542570456896 run_lib.py:146] step: 128500, eval_loss: 2.59409e-02
I0209 01:31:49.069321 22542570456896 run_lib.py:133] step: 128550, training_loss: 3.02238e-02
I0209 01:32:06.651416 22542570456896 run_lib.py:133] step: 128600, training_loss: 3.45410e-02
I0209 01:32:06.808311 22542570456896 run_lib.py:146] step: 128600, eval_loss: 3.11244e-02
I0209 01:32:24.211142 22542570456896 run_lib.py:133] step: 128650, training_loss: 2.68277e-02
I0209 01:32:41.631905 22542570456896 run_lib.py:133] step: 128700, training_loss: 3.34342e-02
I0209 01:32:41.789514 22542570456896 run_lib.py:146] step: 128700, eval_loss: 2.60897e-02
I0209 01:32:59.258689 22542570456896 run_lib.py:133] step: 128750, training_loss: 3.24422e-02
I0209 01:33:16.839050 22542570456896 run_lib.py:133] step: 128800, training_loss: 2.87057e-02
I0209 01:33:16.997378 22542570456896 run_lib.py:146] step: 128800, eval_loss: 2.79098e-02
I0209 01:33:34.387598 22542570456896 run_lib.py:133] step: 128850, training_loss: 3.50536e-02
I0209 01:33:51.875720 22542570456896 run_lib.py:133] step: 128900, training_loss: 3.29339e-02
I0209 01:33:52.033430 22542570456896 run_lib.py:146] step: 128900, eval_loss: 3.22628e-02
I0209 01:34:09.447217 22542570456896 run_lib.py:133] step: 128950, training_loss: 3.02187e-02
I0209 01:34:26.937470 22542570456896 run_lib.py:133] step: 129000, training_loss: 3.13077e-02
I0209 01:34:27.094129 22542570456896 run_lib.py:146] step: 129000, eval_loss: 2.59253e-02
I0209 01:34:44.752720 22542570456896 run_lib.py:133] step: 129050, training_loss: 2.81475e-02
I0209 01:35:02.285234 22542570456896 run_lib.py:133] step: 129100, training_loss: 2.88848e-02
I0209 01:35:02.439238 22542570456896 run_lib.py:146] step: 129100, eval_loss: 2.63804e-02
I0209 01:35:19.853995 22542570456896 run_lib.py:133] step: 129150, training_loss: 2.59887e-02
I0209 01:35:37.314651 22542570456896 run_lib.py:133] step: 129200, training_loss: 2.70065e-02
I0209 01:35:37.472412 22542570456896 run_lib.py:146] step: 129200, eval_loss: 2.39683e-02
I0209 01:35:55.083423 22542570456896 run_lib.py:133] step: 129250, training_loss: 3.40654e-02
I0209 01:36:12.530406 22542570456896 run_lib.py:133] step: 129300, training_loss: 2.61330e-02
I0209 01:36:12.687333 22542570456896 run_lib.py:146] step: 129300, eval_loss: 3.54502e-02
I0209 01:36:30.298112 22542570456896 run_lib.py:133] step: 129350, training_loss: 2.88618e-02
I0209 01:36:47.696301 22542570456896 run_lib.py:133] step: 129400, training_loss: 2.51298e-02
I0209 01:36:47.852474 22542570456896 run_lib.py:146] step: 129400, eval_loss: 2.41771e-02
I0209 01:37:05.451693 22542570456896 run_lib.py:133] step: 129450, training_loss: 2.27014e-02
I0209 01:37:22.855729 22542570456896 run_lib.py:133] step: 129500, training_loss: 3.49550e-02
I0209 01:37:23.020521 22542570456896 run_lib.py:146] step: 129500, eval_loss: 2.80229e-02
I0209 01:37:40.395886 22542570456896 run_lib.py:133] step: 129550, training_loss: 3.31321e-02
I0209 01:37:57.949463 22542570456896 run_lib.py:133] step: 129600, training_loss: 2.79256e-02
I0209 01:37:58.103197 22542570456896 run_lib.py:146] step: 129600, eval_loss: 2.34607e-02
I0209 01:38:15.489903 22542570456896 run_lib.py:133] step: 129650, training_loss: 2.97939e-02
I0209 01:38:33.034066 22542570456896 run_lib.py:133] step: 129700, training_loss: 2.73901e-02
I0209 01:38:33.189265 22542570456896 run_lib.py:146] step: 129700, eval_loss: 2.77538e-02
I0209 01:38:50.564908 22542570456896 run_lib.py:133] step: 129750, training_loss: 3.36738e-02
I0209 01:39:07.988301 22542570456896 run_lib.py:133] step: 129800, training_loss: 2.57183e-02
I0209 01:39:08.149700 22542570456896 run_lib.py:146] step: 129800, eval_loss: 3.11605e-02
I0209 01:39:25.823315 22542570456896 run_lib.py:133] step: 129850, training_loss: 2.71400e-02
I0209 01:39:43.274824 22542570456896 run_lib.py:133] step: 129900, training_loss: 2.64575e-02
I0209 01:39:43.429760 22542570456896 run_lib.py:146] step: 129900, eval_loss: 2.46557e-02
I0209 01:40:00.857604 22542570456896 run_lib.py:133] step: 129950, training_loss: 2.76981e-02
I0209 01:40:18.482183 22542570456896 run_lib.py:133] step: 130000, training_loss: 2.65103e-02
I0209 01:40:19.245350 22542570456896 run_lib.py:146] step: 130000, eval_loss: 2.62444e-02
I0209 01:40:39.305596 22542570456896 run_lib.py:133] step: 130050, training_loss: 3.57306e-02
I0209 01:40:56.774811 22542570456896 run_lib.py:133] step: 130100, training_loss: 3.06889e-02
I0209 01:40:56.931636 22542570456896 run_lib.py:146] step: 130100, eval_loss: 3.71067e-02
I0209 01:41:14.547245 22542570456896 run_lib.py:133] step: 130150, training_loss: 2.54709e-02
I0209 01:41:31.957506 22542570456896 run_lib.py:133] step: 130200, training_loss: 2.89463e-02
I0209 01:41:32.109385 22542570456896 run_lib.py:146] step: 130200, eval_loss: 3.12196e-02
I0209 01:41:49.518195 22542570456896 run_lib.py:133] step: 130250, training_loss: 2.40640e-02
I0209 01:42:06.936276 22542570456896 run_lib.py:133] step: 130300, training_loss: 2.81879e-02
I0209 01:42:07.099783 22542570456896 run_lib.py:146] step: 130300, eval_loss: 2.66795e-02
I0209 01:42:24.638309 22542570456896 run_lib.py:133] step: 130350, training_loss: 2.65072e-02
I0209 01:42:42.099786 22542570456896 run_lib.py:133] step: 130400, training_loss: 1.99854e-02
I0209 01:42:42.258254 22542570456896 run_lib.py:146] step: 130400, eval_loss: 2.87446e-02
I0209 01:42:59.789336 22542570456896 run_lib.py:133] step: 130450, training_loss: 3.01021e-02
I0209 01:43:17.223888 22542570456896 run_lib.py:133] step: 130500, training_loss: 2.85361e-02
I0209 01:43:17.381176 22542570456896 run_lib.py:146] step: 130500, eval_loss: 3.04710e-02
I0209 01:43:34.790392 22542570456896 run_lib.py:133] step: 130550, training_loss: 2.77055e-02
I0209 01:43:52.168929 22542570456896 run_lib.py:133] step: 130600, training_loss: 2.69290e-02
I0209 01:43:52.322407 22542570456896 run_lib.py:146] step: 130600, eval_loss: 3.41644e-02
I0209 01:44:09.880222 22542570456896 run_lib.py:133] step: 130650, training_loss: 2.44101e-02
I0209 01:44:27.427371 22542570456896 run_lib.py:133] step: 130700, training_loss: 2.20948e-02
I0209 01:44:27.585481 22542570456896 run_lib.py:146] step: 130700, eval_loss: 2.77873e-02
I0209 01:44:45.009840 22542570456896 run_lib.py:133] step: 130750, training_loss: 2.88954e-02
I0209 01:45:02.461854 22542570456896 run_lib.py:133] step: 130800, training_loss: 2.94763e-02
I0209 01:45:02.621591 22542570456896 run_lib.py:146] step: 130800, eval_loss: 3.08480e-02
I0209 01:45:20.168278 22542570456896 run_lib.py:133] step: 130850, training_loss: 3.45888e-02
I0209 01:45:37.604070 22542570456896 run_lib.py:133] step: 130900, training_loss: 3.42791e-02
I0209 01:45:37.768328 22542570456896 run_lib.py:146] step: 130900, eval_loss: 3.36618e-02
I0209 01:45:55.325016 22542570456896 run_lib.py:133] step: 130950, training_loss: 3.27535e-02
I0209 01:46:12.761974 22542570456896 run_lib.py:133] step: 131000, training_loss: 2.27556e-02
I0209 01:46:12.918885 22542570456896 run_lib.py:146] step: 131000, eval_loss: 3.64752e-02
I0209 01:46:30.537662 22542570456896 run_lib.py:133] step: 131050, training_loss: 2.83218e-02
I0209 01:46:47.969399 22542570456896 run_lib.py:133] step: 131100, training_loss: 3.15722e-02
I0209 01:46:48.120466 22542570456896 run_lib.py:146] step: 131100, eval_loss: 2.87754e-02
I0209 01:47:05.715243 22542570456896 run_lib.py:133] step: 131150, training_loss: 2.89468e-02
I0209 01:47:23.127219 22542570456896 run_lib.py:133] step: 131200, training_loss: 4.00190e-02
I0209 01:47:23.294513 22542570456896 run_lib.py:146] step: 131200, eval_loss: 3.11302e-02
I0209 01:47:40.782673 22542570456896 run_lib.py:133] step: 131250, training_loss: 2.79320e-02
I0209 01:47:58.422681 22542570456896 run_lib.py:133] step: 131300, training_loss: 2.51652e-02
I0209 01:47:58.581288 22542570456896 run_lib.py:146] step: 131300, eval_loss: 2.42311e-02
I0209 01:48:15.976702 22542570456896 run_lib.py:133] step: 131350, training_loss: 3.13054e-02
I0209 01:48:33.412720 22542570456896 run_lib.py:133] step: 131400, training_loss: 2.71791e-02
I0209 01:48:33.567483 22542570456896 run_lib.py:146] step: 131400, eval_loss: 3.13962e-02
I0209 01:48:51.144053 22542570456896 run_lib.py:133] step: 131450, training_loss: 2.98712e-02
I0209 01:49:08.677227 22542570456896 run_lib.py:133] step: 131500, training_loss: 2.52718e-02
I0209 01:49:08.839567 22542570456896 run_lib.py:146] step: 131500, eval_loss: 2.45042e-02
I0209 01:49:26.307405 22542570456896 run_lib.py:133] step: 131550, training_loss: 2.74883e-02
I0209 01:49:43.769086 22542570456896 run_lib.py:133] step: 131600, training_loss: 2.92552e-02
I0209 01:49:43.920633 22542570456896 run_lib.py:146] step: 131600, eval_loss: 2.90226e-02
I0209 01:50:01.314438 22542570456896 run_lib.py:133] step: 131650, training_loss: 2.73753e-02
I0209 01:50:18.953479 22542570456896 run_lib.py:133] step: 131700, training_loss: 3.51143e-02
I0209 01:50:19.107318 22542570456896 run_lib.py:146] step: 131700, eval_loss: 2.39180e-02
I0209 01:50:36.485604 22542570456896 run_lib.py:133] step: 131750, training_loss: 3.66754e-02
I0209 01:50:53.981929 22542570456896 run_lib.py:133] step: 131800, training_loss: 3.18995e-02
I0209 01:50:54.159486 22542570456896 run_lib.py:146] step: 131800, eval_loss: 2.33738e-02
I0209 01:51:11.560547 22542570456896 run_lib.py:133] step: 131850, training_loss: 2.96103e-02
I0209 01:51:29.166085 22542570456896 run_lib.py:133] step: 131900, training_loss: 2.94501e-02
I0209 01:51:29.322388 22542570456896 run_lib.py:146] step: 131900, eval_loss: 2.92091e-02
I0209 01:51:46.756879 22542570456896 run_lib.py:133] step: 131950, training_loss: 2.79387e-02
I0209 01:52:04.251144 22542570456896 run_lib.py:133] step: 132000, training_loss: 2.40528e-02
I0209 01:52:04.405340 22542570456896 run_lib.py:146] step: 132000, eval_loss: 2.81855e-02
I0209 01:52:21.811838 22542570456896 run_lib.py:133] step: 132050, training_loss: 3.22546e-02
I0209 01:52:39.245463 22542570456896 run_lib.py:133] step: 132100, training_loss: 2.80909e-02
I0209 01:52:39.400514 22542570456896 run_lib.py:146] step: 132100, eval_loss: 3.12926e-02
I0209 01:52:57.010178 22542570456896 run_lib.py:133] step: 132150, training_loss: 3.23359e-02
I0209 01:53:14.505786 22542570456896 run_lib.py:133] step: 132200, training_loss: 3.50734e-02
I0209 01:53:14.663634 22542570456896 run_lib.py:146] step: 132200, eval_loss: 2.72533e-02
I0209 01:53:32.045772 22542570456896 run_lib.py:133] step: 132250, training_loss: 2.72780e-02
I0209 01:53:49.438583 22542570456896 run_lib.py:133] step: 132300, training_loss: 3.23717e-02
I0209 01:53:49.603594 22542570456896 run_lib.py:146] step: 132300, eval_loss: 2.95900e-02
I0209 01:54:07.217191 22542570456896 run_lib.py:133] step: 132350, training_loss: 2.93570e-02
I0209 01:54:24.690915 22542570456896 run_lib.py:133] step: 132400, training_loss: 3.47556e-02
I0209 01:54:24.844956 22542570456896 run_lib.py:146] step: 132400, eval_loss: 2.44397e-02
I0209 01:54:42.437288 22542570456896 run_lib.py:133] step: 132450, training_loss: 2.89986e-02
I0209 01:54:59.825917 22542570456896 run_lib.py:133] step: 132500, training_loss: 2.99196e-02
I0209 01:54:59.983330 22542570456896 run_lib.py:146] step: 132500, eval_loss: 3.71404e-02
I0209 01:55:17.519463 22542570456896 run_lib.py:133] step: 132550, training_loss: 3.31903e-02
I0209 01:55:35.004439 22542570456896 run_lib.py:133] step: 132600, training_loss: 2.73159e-02
I0209 01:55:35.165611 22542570456896 run_lib.py:146] step: 132600, eval_loss: 2.47673e-02
I0209 01:55:52.650479 22542570456896 run_lib.py:133] step: 132650, training_loss: 3.78514e-02
I0209 01:56:10.302151 22542570456896 run_lib.py:133] step: 132700, training_loss: 3.11062e-02
I0209 01:56:10.463381 22542570456896 run_lib.py:146] step: 132700, eval_loss: 3.46540e-02
I0209 01:56:27.893242 22542570456896 run_lib.py:133] step: 132750, training_loss: 3.23330e-02
I0209 01:56:45.443191 22542570456896 run_lib.py:133] step: 132800, training_loss: 2.55108e-02
I0209 01:56:45.600299 22542570456896 run_lib.py:146] step: 132800, eval_loss: 2.60057e-02
I0209 01:57:03.071154 22542570456896 run_lib.py:133] step: 132850, training_loss: 3.00531e-02
I0209 01:57:20.536499 22542570456896 run_lib.py:133] step: 132900, training_loss: 2.81551e-02
I0209 01:57:20.692159 22542570456896 run_lib.py:146] step: 132900, eval_loss: 2.94221e-02
I0209 01:57:38.303534 22542570456896 run_lib.py:133] step: 132950, training_loss: 2.34585e-02
I0209 01:57:55.757264 22542570456896 run_lib.py:133] step: 133000, training_loss: 2.61056e-02
I0209 01:57:55.917115 22542570456896 run_lib.py:146] step: 133000, eval_loss: 2.55117e-02
I0209 01:58:13.300884 22542570456896 run_lib.py:133] step: 133050, training_loss: 2.98524e-02
I0209 01:58:30.912692 22542570456896 run_lib.py:133] step: 133100, training_loss: 2.46225e-02
I0209 01:58:31.067409 22542570456896 run_lib.py:146] step: 133100, eval_loss: 2.45219e-02
I0209 01:58:48.488972 22542570456896 run_lib.py:133] step: 133150, training_loss: 2.64420e-02
I0209 01:59:05.959155 22542570456896 run_lib.py:133] step: 133200, training_loss: 2.65813e-02
I0209 01:59:06.127343 22542570456896 run_lib.py:146] step: 133200, eval_loss: 2.83898e-02
I0209 01:59:23.668696 22542570456896 run_lib.py:133] step: 133250, training_loss: 2.71077e-02
I0209 01:59:41.090739 22542570456896 run_lib.py:133] step: 133300, training_loss: 3.24574e-02
I0209 01:59:41.246429 22542570456896 run_lib.py:146] step: 133300, eval_loss: 2.81108e-02
I0209 01:59:58.632669 22542570456896 run_lib.py:133] step: 133350, training_loss: 3.14690e-02
I0209 02:00:16.083731 22542570456896 run_lib.py:133] step: 133400, training_loss: 2.81616e-02
I0209 02:00:16.238422 22542570456896 run_lib.py:146] step: 133400, eval_loss: 2.78884e-02
I0209 02:00:33.776107 22542570456896 run_lib.py:133] step: 133450, training_loss: 3.22312e-02
I0209 02:00:51.314958 22542570456896 run_lib.py:133] step: 133500, training_loss: 2.11941e-02
I0209 02:00:51.472742 22542570456896 run_lib.py:146] step: 133500, eval_loss: 2.76070e-02
I0209 02:01:08.897327 22542570456896 run_lib.py:133] step: 133550, training_loss: 3.00696e-02
I0209 02:01:26.345631 22542570456896 run_lib.py:133] step: 133600, training_loss: 3.63966e-02
I0209 02:01:26.502406 22542570456896 run_lib.py:146] step: 133600, eval_loss: 2.24747e-02
I0209 02:01:44.068600 22542570456896 run_lib.py:133] step: 133650, training_loss: 3.44842e-02
I0209 02:02:01.470226 22542570456896 run_lib.py:133] step: 133700, training_loss: 2.55194e-02
I0209 02:02:01.635376 22542570456896 run_lib.py:146] step: 133700, eval_loss: 3.11773e-02
I0209 02:02:19.252368 22542570456896 run_lib.py:133] step: 133750, training_loss: 2.66721e-02
I0209 02:02:36.684821 22542570456896 run_lib.py:133] step: 133800, training_loss: 3.45977e-02
I0209 02:02:36.841078 22542570456896 run_lib.py:146] step: 133800, eval_loss: 2.21154e-02
I0209 02:02:54.421727 22542570456896 run_lib.py:133] step: 133850, training_loss: 2.88584e-02
I0209 02:03:11.841735 22542570456896 run_lib.py:133] step: 133900, training_loss: 2.97109e-02
I0209 02:03:12.004295 22542570456896 run_lib.py:146] step: 133900, eval_loss: 3.06350e-02
I0209 02:03:29.608398 22542570456896 run_lib.py:133] step: 133950, training_loss: 2.64815e-02
I0209 02:03:47.022835 22542570456896 run_lib.py:133] step: 134000, training_loss: 2.70657e-02
I0209 02:03:47.176617 22542570456896 run_lib.py:146] step: 134000, eval_loss: 2.39877e-02
I0209 02:04:04.630394 22542570456896 run_lib.py:133] step: 134050, training_loss: 2.73597e-02
I0209 02:04:22.237501 22542570456896 run_lib.py:133] step: 134100, training_loss: 2.90417e-02
I0209 02:04:22.396626 22542570456896 run_lib.py:146] step: 134100, eval_loss: 2.61243e-02
I0209 02:04:39.813829 22542570456896 run_lib.py:133] step: 134150, training_loss: 2.67753e-02
I0209 02:04:57.224767 22542570456896 run_lib.py:133] step: 134200, training_loss: 3.85662e-02
I0209 02:04:57.382937 22542570456896 run_lib.py:146] step: 134200, eval_loss: 2.96305e-02
I0209 02:05:14.970058 22542570456896 run_lib.py:133] step: 134250, training_loss: 2.91770e-02
I0209 02:05:32.426234 22542570456896 run_lib.py:133] step: 134300, training_loss: 3.39861e-02
I0209 02:05:32.589665 22542570456896 run_lib.py:146] step: 134300, eval_loss: 3.27269e-02
I0209 02:05:50.213660 22542570456896 run_lib.py:133] step: 134350, training_loss: 3.16204e-02
I0209 02:06:07.585631 22542570456896 run_lib.py:133] step: 134400, training_loss: 3.45716e-02
I0209 02:06:07.737053 22542570456896 run_lib.py:146] step: 134400, eval_loss: 3.14187e-02
I0209 02:06:25.115741 22542570456896 run_lib.py:133] step: 134450, training_loss: 3.34387e-02
I0209 02:06:42.713074 22542570456896 run_lib.py:133] step: 134500, training_loss: 2.54005e-02
I0209 02:06:42.867488 22542570456896 run_lib.py:146] step: 134500, eval_loss: 2.36392e-02
I0209 02:07:00.392286 22542570456896 run_lib.py:133] step: 134550, training_loss: 2.64489e-02
I0209 02:07:17.809637 22542570456896 run_lib.py:133] step: 134600, training_loss: 2.75206e-02
I0209 02:07:17.974168 22542570456896 run_lib.py:146] step: 134600, eval_loss: 2.45863e-02
I0209 02:07:35.357513 22542570456896 run_lib.py:133] step: 134650, training_loss: 2.85448e-02
I0209 02:07:52.900412 22542570456896 run_lib.py:133] step: 134700, training_loss: 3.44770e-02
I0209 02:07:53.056247 22542570456896 run_lib.py:146] step: 134700, eval_loss: 2.44385e-02
I0209 02:08:10.469363 22542570456896 run_lib.py:133] step: 134750, training_loss: 2.38685e-02
I0209 02:08:27.954540 22542570456896 run_lib.py:133] step: 134800, training_loss: 3.00966e-02
I0209 02:08:28.110775 22542570456896 run_lib.py:146] step: 134800, eval_loss: 3.19903e-02
I0209 02:08:45.556977 22542570456896 run_lib.py:133] step: 134850, training_loss: 3.68902e-02
I0209 02:09:02.985532 22542570456896 run_lib.py:133] step: 134900, training_loss: 2.94590e-02
I0209 02:09:03.137393 22542570456896 run_lib.py:146] step: 134900, eval_loss: 2.49538e-02
I0209 02:09:20.685352 22542570456896 run_lib.py:133] step: 134950, training_loss: 2.43373e-02
I0209 02:09:38.173012 22542570456896 run_lib.py:133] step: 135000, training_loss: 2.39055e-02
I0209 02:09:38.329301 22542570456896 run_lib.py:146] step: 135000, eval_loss: 3.57215e-02
I0209 02:09:55.768111 22542570456896 run_lib.py:133] step: 135050, training_loss: 2.93422e-02
I0209 02:10:13.247342 22542570456896 run_lib.py:133] step: 135100, training_loss: 2.93066e-02
I0209 02:10:13.406238 22542570456896 run_lib.py:146] step: 135100, eval_loss: 2.71742e-02
I0209 02:10:30.998649 22542570456896 run_lib.py:133] step: 135150, training_loss: 2.71963e-02
I0209 02:10:48.392074 22542570456896 run_lib.py:133] step: 135200, training_loss: 3.20968e-02
I0209 02:10:48.547190 22542570456896 run_lib.py:146] step: 135200, eval_loss: 2.80914e-02
I0209 02:11:06.113324 22542570456896 run_lib.py:133] step: 135250, training_loss: 3.54901e-02
I0209 02:11:23.474061 22542570456896 run_lib.py:133] step: 135300, training_loss: 2.67622e-02
I0209 02:11:23.628469 22542570456896 run_lib.py:146] step: 135300, eval_loss: 2.44377e-02
I0209 02:11:41.215474 22542570456896 run_lib.py:133] step: 135350, training_loss: 2.77371e-02
I0209 02:11:58.665916 22542570456896 run_lib.py:133] step: 135400, training_loss: 3.86045e-02
I0209 02:11:58.819520 22542570456896 run_lib.py:146] step: 135400, eval_loss: 2.63887e-02
I0209 02:12:16.256268 22542570456896 run_lib.py:133] step: 135450, training_loss: 3.03093e-02
I0209 02:12:33.906231 22542570456896 run_lib.py:133] step: 135500, training_loss: 2.46006e-02
I0209 02:12:34.062220 22542570456896 run_lib.py:146] step: 135500, eval_loss: 3.15942e-02
I0209 02:12:51.518496 22542570456896 run_lib.py:133] step: 135550, training_loss: 2.59946e-02
I0209 02:13:09.101537 22542570456896 run_lib.py:133] step: 135600, training_loss: 3.90885e-02
I0209 02:13:09.264660 22542570456896 run_lib.py:146] step: 135600, eval_loss: 2.85193e-02
I0209 02:13:26.682346 22542570456896 run_lib.py:133] step: 135650, training_loss: 3.54996e-02
I0209 02:13:44.179579 22542570456896 run_lib.py:133] step: 135700, training_loss: 3.65111e-02
I0209 02:13:44.344560 22542570456896 run_lib.py:146] step: 135700, eval_loss: 3.00905e-02
I0209 02:14:01.948599 22542570456896 run_lib.py:133] step: 135750, training_loss: 3.05871e-02
I0209 02:14:19.364971 22542570456896 run_lib.py:133] step: 135800, training_loss: 2.95665e-02
I0209 02:14:19.521485 22542570456896 run_lib.py:146] step: 135800, eval_loss: 2.09263e-02
I0209 02:14:36.922381 22542570456896 run_lib.py:133] step: 135850, training_loss: 2.43982e-02
I0209 02:14:54.488289 22542570456896 run_lib.py:133] step: 135900, training_loss: 3.29036e-02
I0209 02:14:54.640601 22542570456896 run_lib.py:146] step: 135900, eval_loss: 2.38976e-02
I0209 02:15:12.128040 22542570456896 run_lib.py:133] step: 135950, training_loss: 2.57104e-02
I0209 02:15:29.584572 22542570456896 run_lib.py:133] step: 136000, training_loss: 2.49589e-02
I0209 02:15:29.934272 22542570456896 run_lib.py:146] step: 136000, eval_loss: 2.87452e-02
I0209 02:15:47.333436 22542570456896 run_lib.py:133] step: 136050, training_loss: 3.10332e-02
I0209 02:16:04.757074 22542570456896 run_lib.py:133] step: 136100, training_loss: 2.67512e-02
I0209 02:16:04.917462 22542570456896 run_lib.py:146] step: 136100, eval_loss: 2.16184e-02
I0209 02:16:22.363119 22542570456896 run_lib.py:133] step: 136150, training_loss: 3.02402e-02
I0209 02:16:39.782234 22542570456896 run_lib.py:133] step: 136200, training_loss: 2.98775e-02
I0209 02:16:39.954062 22542570456896 run_lib.py:146] step: 136200, eval_loss: 3.02217e-02
I0209 02:16:57.565687 22542570456896 run_lib.py:133] step: 136250, training_loss: 2.12835e-02
I0209 02:17:15.119852 22542570456896 run_lib.py:133] step: 136300, training_loss: 3.55583e-02
I0209 02:17:15.272118 22542570456896 run_lib.py:146] step: 136300, eval_loss: 2.79936e-02
I0209 02:17:32.692728 22542570456896 run_lib.py:133] step: 136350, training_loss: 2.47359e-02
I0209 02:17:50.101286 22542570456896 run_lib.py:133] step: 136400, training_loss: 2.34702e-02
I0209 02:17:50.265403 22542570456896 run_lib.py:146] step: 136400, eval_loss: 3.51489e-02
I0209 02:18:07.793023 22542570456896 run_lib.py:133] step: 136450, training_loss: 2.74073e-02
I0209 02:18:25.270893 22542570456896 run_lib.py:133] step: 136500, training_loss: 2.82886e-02
I0209 02:18:25.447290 22542570456896 run_lib.py:146] step: 136500, eval_loss: 2.70420e-02
I0209 02:18:42.901758 22542570456896 run_lib.py:133] step: 136550, training_loss: 2.90678e-02
I0209 02:19:00.402083 22542570456896 run_lib.py:133] step: 136600, training_loss: 3.02494e-02
I0209 02:19:00.557602 22542570456896 run_lib.py:146] step: 136600, eval_loss: 3.13139e-02
I0209 02:19:18.143791 22542570456896 run_lib.py:133] step: 136650, training_loss: 3.04006e-02
I0209 02:19:35.564935 22542570456896 run_lib.py:133] step: 136700, training_loss: 2.92810e-02
I0209 02:19:35.720347 22542570456896 run_lib.py:146] step: 136700, eval_loss: 2.29445e-02
I0209 02:19:53.256636 22542570456896 run_lib.py:133] step: 136750, training_loss: 3.75229e-02
I0209 02:20:10.731384 22542570456896 run_lib.py:133] step: 136800, training_loss: 2.87830e-02
I0209 02:20:10.884668 22542570456896 run_lib.py:146] step: 136800, eval_loss: 2.95217e-02
I0209 02:20:28.542867 22542570456896 run_lib.py:133] step: 136850, training_loss: 2.55353e-02
I0209 02:20:45.954057 22542570456896 run_lib.py:133] step: 136900, training_loss: 2.42737e-02
I0209 02:20:46.109462 22542570456896 run_lib.py:146] step: 136900, eval_loss: 2.93143e-02
I0209 02:21:03.523261 22542570456896 run_lib.py:133] step: 136950, training_loss: 2.54511e-02
I0209 02:21:21.113352 22542570456896 run_lib.py:133] step: 137000, training_loss: 3.09674e-02
I0209 02:21:21.271557 22542570456896 run_lib.py:146] step: 137000, eval_loss: 2.80548e-02
I0209 02:21:38.687032 22542570456896 run_lib.py:133] step: 137050, training_loss: 2.30876e-02
I0209 02:21:56.283330 22542570456896 run_lib.py:133] step: 137100, training_loss: 1.99031e-02
I0209 02:21:56.437540 22542570456896 run_lib.py:146] step: 137100, eval_loss: 2.52254e-02
I0209 02:22:13.816948 22542570456896 run_lib.py:133] step: 137150, training_loss: 3.01059e-02
I0209 02:22:31.240345 22542570456896 run_lib.py:133] step: 137200, training_loss: 3.17623e-02
I0209 02:22:31.396260 22542570456896 run_lib.py:146] step: 137200, eval_loss: 3.05874e-02
I0209 02:22:48.999924 22542570456896 run_lib.py:133] step: 137250, training_loss: 2.09289e-02
I0209 02:23:06.431187 22542570456896 run_lib.py:133] step: 137300, training_loss: 2.84231e-02
I0209 02:23:06.583348 22542570456896 run_lib.py:146] step: 137300, eval_loss: 2.71052e-02
I0209 02:23:24.048495 22542570456896 run_lib.py:133] step: 137350, training_loss: 2.62213e-02
I0209 02:23:41.475256 22542570456896 run_lib.py:133] step: 137400, training_loss: 2.50571e-02
I0209 02:23:41.631262 22542570456896 run_lib.py:146] step: 137400, eval_loss: 3.15287e-02
I0209 02:23:59.271201 22542570456896 run_lib.py:133] step: 137450, training_loss: 3.21626e-02
I0209 02:24:16.666058 22542570456896 run_lib.py:133] step: 137500, training_loss: 2.59774e-02
I0209 02:24:16.825559 22542570456896 run_lib.py:146] step: 137500, eval_loss: 2.24808e-02
I0209 02:24:34.289547 22542570456896 run_lib.py:133] step: 137550, training_loss: 3.10835e-02
I0209 02:24:51.685686 22542570456896 run_lib.py:133] step: 137600, training_loss: 2.67643e-02
I0209 02:24:51.852148 22542570456896 run_lib.py:146] step: 137600, eval_loss: 2.97685e-02
I0209 02:25:09.290225 22542570456896 run_lib.py:133] step: 137650, training_loss: 3.52944e-02
I0209 02:25:26.768147 22542570456896 run_lib.py:133] step: 137700, training_loss: 2.72615e-02
I0209 02:25:26.923055 22542570456896 run_lib.py:146] step: 137700, eval_loss: 2.59141e-02
I0209 02:25:44.503911 22542570456896 run_lib.py:133] step: 137750, training_loss: 2.88613e-02
I0209 02:26:01.978975 22542570456896 run_lib.py:133] step: 137800, training_loss: 2.33682e-02
I0209 02:26:02.131355 22542570456896 run_lib.py:146] step: 137800, eval_loss: 2.54423e-02
I0209 02:26:19.526908 22542570456896 run_lib.py:133] step: 137850, training_loss: 3.50699e-02
I0209 02:26:36.943782 22542570456896 run_lib.py:133] step: 137900, training_loss: 2.32044e-02
I0209 02:26:37.118371 22542570456896 run_lib.py:146] step: 137900, eval_loss: 2.55873e-02
I0209 02:26:54.697581 22542570456896 run_lib.py:133] step: 137950, training_loss: 3.50525e-02
I0209 02:27:12.126774 22542570456896 run_lib.py:133] step: 138000, training_loss: 2.41957e-02
I0209 02:27:12.282509 22542570456896 run_lib.py:146] step: 138000, eval_loss: 2.62888e-02
I0209 02:27:29.883888 22542570456896 run_lib.py:133] step: 138050, training_loss: 2.82825e-02
I0209 02:27:47.297264 22542570456896 run_lib.py:133] step: 138100, training_loss: 2.89799e-02
I0209 02:27:47.454069 22542570456896 run_lib.py:146] step: 138100, eval_loss: 2.19842e-02
I0209 02:28:04.992590 22542570456896 run_lib.py:133] step: 138150, training_loss: 3.35652e-02
I0209 02:28:22.389839 22542570456896 run_lib.py:133] step: 138200, training_loss: 3.03455e-02
I0209 02:28:22.551475 22542570456896 run_lib.py:146] step: 138200, eval_loss: 2.58918e-02
I0209 02:28:40.234616 22542570456896 run_lib.py:133] step: 138250, training_loss: 3.03230e-02
I0209 02:28:57.631543 22542570456896 run_lib.py:133] step: 138300, training_loss: 2.79144e-02
I0209 02:28:57.786301 22542570456896 run_lib.py:146] step: 138300, eval_loss: 2.59258e-02
I0209 02:29:15.167981 22542570456896 run_lib.py:133] step: 138350, training_loss: 2.49225e-02
I0209 02:29:32.755556 22542570456896 run_lib.py:133] step: 138400, training_loss: 3.06571e-02
I0209 02:29:32.913417 22542570456896 run_lib.py:146] step: 138400, eval_loss: 2.92854e-02
I0209 02:29:50.362523 22542570456896 run_lib.py:133] step: 138450, training_loss: 3.10271e-02
I0209 02:30:07.828733 22542570456896 run_lib.py:133] step: 138500, training_loss: 3.47586e-02
I0209 02:30:07.985523 22542570456896 run_lib.py:146] step: 138500, eval_loss: 2.79099e-02
I0209 02:30:25.533097 22542570456896 run_lib.py:133] step: 138550, training_loss: 3.26544e-02
I0209 02:30:43.136834 22542570456896 run_lib.py:133] step: 138600, training_loss: 3.56422e-02
I0209 02:30:43.299773 22542570456896 run_lib.py:146] step: 138600, eval_loss: 2.79100e-02
I0209 02:31:00.730546 22542570456896 run_lib.py:133] step: 138650, training_loss: 2.26686e-02
I0209 02:31:18.142948 22542570456896 run_lib.py:133] step: 138700, training_loss: 2.53163e-02
I0209 02:31:18.300185 22542570456896 run_lib.py:146] step: 138700, eval_loss: 2.80843e-02
I0209 02:31:35.701704 22542570456896 run_lib.py:133] step: 138750, training_loss: 2.67808e-02
I0209 02:31:53.319345 22542570456896 run_lib.py:133] step: 138800, training_loss: 2.95399e-02
I0209 02:31:53.490633 22542570456896 run_lib.py:146] step: 138800, eval_loss: 2.22517e-02
I0209 02:32:10.919571 22542570456896 run_lib.py:133] step: 138850, training_loss: 2.85972e-02
I0209 02:32:28.350803 22542570456896 run_lib.py:133] step: 138900, training_loss: 3.87759e-02
I0209 02:32:28.508574 22542570456896 run_lib.py:146] step: 138900, eval_loss: 3.09949e-02
I0209 02:32:45.912322 22542570456896 run_lib.py:133] step: 138950, training_loss: 3.06301e-02
I0209 02:33:03.510678 22542570456896 run_lib.py:133] step: 139000, training_loss: 3.51059e-02
I0209 02:33:03.666435 22542570456896 run_lib.py:146] step: 139000, eval_loss: 2.65173e-02
I0209 02:33:21.082200 22542570456896 run_lib.py:133] step: 139050, training_loss: 3.20720e-02
I0209 02:33:38.604249 22542570456896 run_lib.py:133] step: 139100, training_loss: 2.93433e-02
I0209 02:33:38.760573 22542570456896 run_lib.py:146] step: 139100, eval_loss: 2.47846e-02
I0209 02:33:56.215937 22542570456896 run_lib.py:133] step: 139150, training_loss: 3.13914e-02
I0209 02:34:13.647342 22542570456896 run_lib.py:133] step: 139200, training_loss: 2.18318e-02
I0209 02:34:13.799355 22542570456896 run_lib.py:146] step: 139200, eval_loss: 2.56011e-02
I0209 02:34:31.377088 22542570456896 run_lib.py:133] step: 139250, training_loss: 3.11044e-02
I0209 02:34:48.838567 22542570456896 run_lib.py:133] step: 139300, training_loss: 3.48235e-02
I0209 02:34:49.005358 22542570456896 run_lib.py:146] step: 139300, eval_loss: 2.97948e-02
I0209 02:35:06.449900 22542570456896 run_lib.py:133] step: 139350, training_loss: 3.16365e-02
I0209 02:35:23.915492 22542570456896 run_lib.py:133] step: 139400, training_loss: 2.58473e-02
I0209 02:35:24.072416 22542570456896 run_lib.py:146] step: 139400, eval_loss: 3.06756e-02
I0209 02:35:41.656674 22542570456896 run_lib.py:133] step: 139450, training_loss: 2.31154e-02
I0209 02:35:59.061329 22542570456896 run_lib.py:133] step: 139500, training_loss: 3.17101e-02
I0209 02:35:59.216473 22542570456896 run_lib.py:146] step: 139500, eval_loss: 3.43160e-02
I0209 02:36:16.783793 22542570456896 run_lib.py:133] step: 139550, training_loss: 2.61877e-02
I0209 02:36:34.228850 22542570456896 run_lib.py:133] step: 139600, training_loss: 2.45349e-02
I0209 02:36:34.383497 22542570456896 run_lib.py:146] step: 139600, eval_loss: 3.39060e-02
I0209 02:36:52.061136 22542570456896 run_lib.py:133] step: 139650, training_loss: 2.91910e-02
I0209 02:37:09.426105 22542570456896 run_lib.py:133] step: 139700, training_loss: 2.08437e-02
I0209 02:37:09.576210 22542570456896 run_lib.py:146] step: 139700, eval_loss: 2.75530e-02
I0209 02:37:26.950349 22542570456896 run_lib.py:133] step: 139750, training_loss: 2.52800e-02
I0209 02:37:44.517051 22542570456896 run_lib.py:133] step: 139800, training_loss: 2.46723e-02
I0209 02:37:44.682523 22542570456896 run_lib.py:146] step: 139800, eval_loss: 3.33647e-02
I0209 02:38:02.103835 22542570456896 run_lib.py:133] step: 139850, training_loss: 2.70275e-02
I0209 02:38:19.692119 22542570456896 run_lib.py:133] step: 139900, training_loss: 2.70871e-02
I0209 02:38:19.846529 22542570456896 run_lib.py:146] step: 139900, eval_loss: 2.70647e-02
I0209 02:38:37.299805 22542570456896 run_lib.py:133] step: 139950, training_loss: 3.11346e-02
I0209 02:38:54.748722 22542570456896 run_lib.py:133] step: 140000, training_loss: 3.69442e-02
I0209 02:38:55.469915 22542570456896 run_lib.py:146] step: 140000, eval_loss: 2.47737e-02
I0209 02:39:15.510831 22542570456896 run_lib.py:133] step: 140050, training_loss: 2.53991e-02
I0209 02:39:33.110941 22542570456896 run_lib.py:133] step: 140100, training_loss: 3.05938e-02
I0209 02:39:33.262455 22542570456896 run_lib.py:146] step: 140100, eval_loss: 2.81716e-02
I0209 02:39:50.703119 22542570456896 run_lib.py:133] step: 140150, training_loss: 2.95564e-02
I0209 02:40:08.331543 22542570456896 run_lib.py:133] step: 140200, training_loss: 2.51361e-02
I0209 02:40:08.484478 22542570456896 run_lib.py:146] step: 140200, eval_loss: 2.63388e-02
I0209 02:40:25.951616 22542570456896 run_lib.py:133] step: 140250, training_loss: 2.23369e-02
I0209 02:40:43.422577 22542570456896 run_lib.py:133] step: 140300, training_loss: 3.08499e-02
I0209 02:40:43.576835 22542570456896 run_lib.py:146] step: 140300, eval_loss: 3.37656e-02
I0209 02:41:01.121630 22542570456896 run_lib.py:133] step: 140350, training_loss: 3.01890e-02
I0209 02:41:18.602568 22542570456896 run_lib.py:133] step: 140400, training_loss: 2.74338e-02
I0209 02:41:18.779476 22542570456896 run_lib.py:146] step: 140400, eval_loss: 2.93406e-02
I0209 02:41:36.366146 22542570456896 run_lib.py:133] step: 140450, training_loss: 2.29329e-02
I0209 02:41:53.836445 22542570456896 run_lib.py:133] step: 140500, training_loss: 2.85047e-02
I0209 02:41:53.992529 22542570456896 run_lib.py:146] step: 140500, eval_loss: 2.82632e-02
I0209 02:42:11.437027 22542570456896 run_lib.py:133] step: 140550, training_loss: 2.78080e-02
I0209 02:42:29.038600 22542570456896 run_lib.py:133] step: 140600, training_loss: 2.46916e-02
I0209 02:42:29.192674 22542570456896 run_lib.py:146] step: 140600, eval_loss: 2.31733e-02
I0209 02:42:46.598488 22542570456896 run_lib.py:133] step: 140650, training_loss: 3.28029e-02
I0209 02:43:04.055151 22542570456896 run_lib.py:133] step: 140700, training_loss: 3.13344e-02
I0209 02:43:04.210579 22542570456896 run_lib.py:146] step: 140700, eval_loss: 2.56020e-02
I0209 02:43:21.628218 22542570456896 run_lib.py:133] step: 140750, training_loss: 3.49958e-02
I0209 02:43:39.248693 22542570456896 run_lib.py:133] step: 140800, training_loss: 2.53774e-02
I0209 02:43:39.407124 22542570456896 run_lib.py:146] step: 140800, eval_loss: 2.87215e-02
I0209 02:43:56.778472 22542570456896 run_lib.py:133] step: 140850, training_loss: 3.25229e-02
I0209 02:44:14.226518 22542570456896 run_lib.py:133] step: 140900, training_loss: 3.14082e-02
I0209 02:44:14.384340 22542570456896 run_lib.py:146] step: 140900, eval_loss: 2.71650e-02
I0209 02:44:31.830674 22542570456896 run_lib.py:133] step: 140950, training_loss: 2.63670e-02
I0209 02:44:49.278525 22542570456896 run_lib.py:133] step: 141000, training_loss: 2.59706e-02
I0209 02:44:49.432170 22542570456896 run_lib.py:146] step: 141000, eval_loss: 2.82731e-02
I0209 02:45:07.048137 22542570456896 run_lib.py:133] step: 141050, training_loss: 3.36284e-02
I0209 02:45:24.489381 22542570456896 run_lib.py:133] step: 141100, training_loss: 3.19659e-02
I0209 02:45:24.644003 22542570456896 run_lib.py:146] step: 141100, eval_loss: 2.50112e-02
I0209 02:45:42.050837 22542570456896 run_lib.py:133] step: 141150, training_loss: 2.04923e-02
I0209 02:45:59.488141 22542570456896 run_lib.py:133] step: 141200, training_loss: 2.32125e-02
I0209 02:45:59.651548 22542570456896 run_lib.py:146] step: 141200, eval_loss: 2.70327e-02
I0209 02:46:17.317475 22542570456896 run_lib.py:133] step: 141250, training_loss: 2.96750e-02
I0209 02:46:34.805118 22542570456896 run_lib.py:133] step: 141300, training_loss: 3.28603e-02
I0209 02:46:34.962223 22542570456896 run_lib.py:146] step: 141300, eval_loss: 2.75980e-02
I0209 02:46:52.479858 22542570456896 run_lib.py:133] step: 141350, training_loss: 3.04225e-02
I0209 02:47:09.821713 22542570456896 run_lib.py:133] step: 141400, training_loss: 2.49991e-02
I0209 02:47:09.979232 22542570456896 run_lib.py:146] step: 141400, eval_loss: 3.01042e-02
I0209 02:47:27.466279 22542570456896 run_lib.py:133] step: 141450, training_loss: 2.80564e-02
I0209 02:47:44.933257 22542570456896 run_lib.py:133] step: 141500, training_loss: 2.53743e-02
I0209 02:47:45.089951 22542570456896 run_lib.py:146] step: 141500, eval_loss: 3.41565e-02
I0209 02:48:02.556156 22542570456896 run_lib.py:133] step: 141550, training_loss: 2.71881e-02
I0209 02:48:20.163398 22542570456896 run_lib.py:133] step: 141600, training_loss: 2.59739e-02
I0209 02:48:20.316089 22542570456896 run_lib.py:146] step: 141600, eval_loss: 3.66910e-02
I0209 02:48:37.727980 22542570456896 run_lib.py:133] step: 141650, training_loss: 2.84017e-02
I0209 02:48:55.316079 22542570456896 run_lib.py:133] step: 141700, training_loss: 2.84252e-02
I0209 02:48:55.474642 22542570456896 run_lib.py:146] step: 141700, eval_loss: 2.72265e-02
I0209 02:49:12.916828 22542570456896 run_lib.py:133] step: 141750, training_loss: 3.07997e-02
I0209 02:49:30.404021 22542570456896 run_lib.py:133] step: 141800, training_loss: 2.87009e-02
I0209 02:49:30.563444 22542570456896 run_lib.py:146] step: 141800, eval_loss: 2.66094e-02
I0209 02:49:48.140265 22542570456896 run_lib.py:133] step: 141850, training_loss: 3.16369e-02
I0209 02:50:05.546911 22542570456896 run_lib.py:133] step: 141900, training_loss: 3.17847e-02
I0209 02:50:05.703341 22542570456896 run_lib.py:146] step: 141900, eval_loss: 3.21387e-02
I0209 02:50:23.131443 22542570456896 run_lib.py:133] step: 141950, training_loss: 2.91377e-02
I0209 02:50:40.713978 22542570456896 run_lib.py:133] step: 142000, training_loss: 3.19846e-02
I0209 02:50:40.877322 22542570456896 run_lib.py:146] step: 142000, eval_loss: 3.08857e-02
I0209 02:50:58.342414 22542570456896 run_lib.py:133] step: 142050, training_loss: 3.12179e-02
I0209 02:51:15.806591 22542570456896 run_lib.py:133] step: 142100, training_loss: 2.92245e-02
I0209 02:51:15.959639 22542570456896 run_lib.py:146] step: 142100, eval_loss: 2.47694e-02
I0209 02:51:33.514814 22542570456896 run_lib.py:133] step: 142150, training_loss: 3.04023e-02
I0209 02:51:50.932751 22542570456896 run_lib.py:133] step: 142200, training_loss: 2.89954e-02
I0209 02:51:51.087450 22542570456896 run_lib.py:146] step: 142200, eval_loss: 2.52615e-02
I0209 02:52:08.465264 22542570456896 run_lib.py:133] step: 142250, training_loss: 3.17181e-02
I0209 02:52:25.905773 22542570456896 run_lib.py:133] step: 142300, training_loss: 3.11071e-02
I0209 02:52:26.082261 22542570456896 run_lib.py:146] step: 142300, eval_loss: 2.71802e-02
I0209 02:52:43.692375 22542570456896 run_lib.py:133] step: 142350, training_loss: 2.36067e-02
I0209 02:53:01.213428 22542570456896 run_lib.py:133] step: 142400, training_loss: 3.08516e-02
I0209 02:53:01.369639 22542570456896 run_lib.py:146] step: 142400, eval_loss: 2.85711e-02
I0209 02:53:18.794847 22542570456896 run_lib.py:133] step: 142450, training_loss: 3.15059e-02
I0209 02:53:36.182907 22542570456896 run_lib.py:133] step: 142500, training_loss: 2.84206e-02
I0209 02:53:36.337147 22542570456896 run_lib.py:146] step: 142500, eval_loss: 2.68287e-02
I0209 02:53:53.914033 22542570456896 run_lib.py:133] step: 142550, training_loss: 2.95283e-02
I0209 02:54:11.380288 22542570456896 run_lib.py:133] step: 142600, training_loss: 2.91545e-02
I0209 02:54:11.535620 22542570456896 run_lib.py:146] step: 142600, eval_loss: 3.40348e-02
I0209 02:54:29.127167 22542570456896 run_lib.py:133] step: 142650, training_loss: 2.73891e-02
I0209 02:54:46.563241 22542570456896 run_lib.py:133] step: 142700, training_loss: 2.90262e-02
I0209 02:54:46.731470 22542570456896 run_lib.py:146] step: 142700, eval_loss: 3.22175e-02
I0209 02:55:04.316380 22542570456896 run_lib.py:133] step: 142750, training_loss: 2.70279e-02
I0209 02:55:21.721190 22542570456896 run_lib.py:133] step: 142800, training_loss: 2.78228e-02
I0209 02:55:21.877738 22542570456896 run_lib.py:146] step: 142800, eval_loss: 2.64088e-02
I0209 02:55:39.430965 22542570456896 run_lib.py:133] step: 142850, training_loss: 2.93834e-02
I0209 02:55:56.910242 22542570456896 run_lib.py:133] step: 142900, training_loss: 2.84584e-02
I0209 02:55:57.066214 22542570456896 run_lib.py:146] step: 142900, eval_loss: 2.91247e-02
I0209 02:56:14.541507 22542570456896 run_lib.py:133] step: 142950, training_loss: 2.30274e-02
I0209 02:56:32.125148 22542570456896 run_lib.py:133] step: 143000, training_loss: 3.39323e-02
I0209 02:56:32.275427 22542570456896 run_lib.py:146] step: 143000, eval_loss: 2.74815e-02
I0209 02:56:49.667055 22542570456896 run_lib.py:133] step: 143050, training_loss: 3.14502e-02
I0209 02:57:07.110652 22542570456896 run_lib.py:133] step: 143100, training_loss: 2.87496e-02
I0209 02:57:07.267548 22542570456896 run_lib.py:146] step: 143100, eval_loss: 2.54668e-02
I0209 02:57:24.932438 22542570456896 run_lib.py:133] step: 143150, training_loss: 3.51017e-02
I0209 02:57:42.333577 22542570456896 run_lib.py:133] step: 143200, training_loss: 4.35913e-02
I0209 02:57:42.492369 22542570456896 run_lib.py:146] step: 143200, eval_loss: 3.71488e-02
I0209 02:58:00.071388 22542570456896 run_lib.py:133] step: 143250, training_loss: 2.74379e-02
I0209 02:58:17.467319 22542570456896 run_lib.py:133] step: 143300, training_loss: 3.53778e-02
I0209 02:58:17.625357 22542570456896 run_lib.py:146] step: 143300, eval_loss: 2.33340e-02
I0209 02:58:35.102113 22542570456896 run_lib.py:133] step: 143350, training_loss: 2.49021e-02
I0209 02:58:52.717274 22542570456896 run_lib.py:133] step: 143400, training_loss: 2.44340e-02
I0209 02:58:52.874870 22542570456896 run_lib.py:146] step: 143400, eval_loss: 2.53077e-02
I0209 02:59:10.315181 22542570456896 run_lib.py:133] step: 143450, training_loss: 3.05551e-02
I0209 02:59:27.815847 22542570456896 run_lib.py:133] step: 143500, training_loss: 2.75615e-02
I0209 02:59:27.973442 22542570456896 run_lib.py:146] step: 143500, eval_loss: 2.16612e-02
I0209 02:59:45.427220 22542570456896 run_lib.py:133] step: 143550, training_loss: 2.70141e-02
I0209 03:00:02.999935 22542570456896 run_lib.py:133] step: 143600, training_loss: 2.97080e-02
I0209 03:00:03.155425 22542570456896 run_lib.py:146] step: 143600, eval_loss: 2.86072e-02
I0209 03:00:20.609827 22542570456896 run_lib.py:133] step: 143650, training_loss: 3.11647e-02
I0209 03:00:38.157455 22542570456896 run_lib.py:133] step: 143700, training_loss: 2.51494e-02
I0209 03:00:38.316538 22542570456896 run_lib.py:146] step: 143700, eval_loss: 2.54186e-02
I0209 03:00:55.775581 22542570456896 run_lib.py:133] step: 143750, training_loss: 2.70212e-02
I0209 03:01:13.199607 22542570456896 run_lib.py:133] step: 143800, training_loss: 3.27639e-02
I0209 03:01:13.356374 22542570456896 run_lib.py:146] step: 143800, eval_loss: 2.59032e-02
I0209 03:01:30.924237 22542570456896 run_lib.py:133] step: 143850, training_loss: 2.65654e-02
I0209 03:01:48.434955 22542570456896 run_lib.py:133] step: 143900, training_loss: 2.95920e-02
I0209 03:01:48.590197 22542570456896 run_lib.py:146] step: 143900, eval_loss: 3.07811e-02
I0209 03:02:06.086821 22542570456896 run_lib.py:133] step: 143950, training_loss: 2.83024e-02
I0209 03:02:23.528839 22542570456896 run_lib.py:133] step: 144000, training_loss: 2.27848e-02
I0209 03:02:23.681642 22542570456896 run_lib.py:146] step: 144000, eval_loss: 2.39909e-02
I0209 03:02:41.297687 22542570456896 run_lib.py:133] step: 144050, training_loss: 2.77990e-02
I0209 03:02:58.770688 22542570456896 run_lib.py:133] step: 144100, training_loss: 3.37102e-02
I0209 03:02:58.924615 22542570456896 run_lib.py:146] step: 144100, eval_loss: 2.54669e-02
I0209 03:03:16.534771 22542570456896 run_lib.py:133] step: 144150, training_loss: 3.24314e-02
I0209 03:03:33.946676 22542570456896 run_lib.py:133] step: 144200, training_loss: 2.95875e-02
I0209 03:03:34.119417 22542570456896 run_lib.py:146] step: 144200, eval_loss: 3.26142e-02
I0209 03:03:51.758395 22542570456896 run_lib.py:133] step: 144250, training_loss: 2.89630e-02
I0209 03:04:09.243383 22542570456896 run_lib.py:133] step: 144300, training_loss: 2.56725e-02
I0209 03:04:09.398750 22542570456896 run_lib.py:146] step: 144300, eval_loss: 3.36756e-02
I0209 03:04:26.867872 22542570456896 run_lib.py:133] step: 144350, training_loss: 2.77650e-02
I0209 03:04:44.469122 22542570456896 run_lib.py:133] step: 144400, training_loss: 2.47232e-02
I0209 03:04:44.626395 22542570456896 run_lib.py:146] step: 144400, eval_loss: 2.56053e-02
I0209 03:05:02.088052 22542570456896 run_lib.py:133] step: 144450, training_loss: 2.93427e-02
I0209 03:05:19.668129 22542570456896 run_lib.py:133] step: 144500, training_loss: 3.22518e-02
I0209 03:05:19.819444 22542570456896 run_lib.py:146] step: 144500, eval_loss: 3.05585e-02
I0209 03:05:37.271687 22542570456896 run_lib.py:133] step: 144550, training_loss: 2.49286e-02
I0209 03:05:54.727362 22542570456896 run_lib.py:133] step: 144600, training_loss: 2.96346e-02
I0209 03:05:54.886315 22542570456896 run_lib.py:146] step: 144600, eval_loss: 2.80592e-02
I0209 03:06:12.489359 22542570456896 run_lib.py:133] step: 144650, training_loss: 3.17834e-02
I0209 03:06:29.941165 22542570456896 run_lib.py:133] step: 144700, training_loss: 2.28213e-02
I0209 03:06:30.104455 22542570456896 run_lib.py:146] step: 144700, eval_loss: 2.76050e-02
I0209 03:06:47.518404 22542570456896 run_lib.py:133] step: 144750, training_loss: 3.46453e-02
I0209 03:07:05.082813 22542570456896 run_lib.py:133] step: 144800, training_loss: 3.42146e-02
I0209 03:07:05.252520 22542570456896 run_lib.py:146] step: 144800, eval_loss: 2.97473e-02
I0209 03:07:22.764988 22542570456896 run_lib.py:133] step: 144850, training_loss: 2.61199e-02
I0209 03:07:40.233775 22542570456896 run_lib.py:133] step: 144900, training_loss: 2.71766e-02
I0209 03:07:40.577011 22542570456896 run_lib.py:146] step: 144900, eval_loss: 2.54058e-02
I0209 03:07:57.999134 22542570456896 run_lib.py:133] step: 144950, training_loss: 2.96936e-02
I0209 03:08:15.441822 22542570456896 run_lib.py:133] step: 145000, training_loss: 2.96689e-02
I0209 03:08:15.596505 22542570456896 run_lib.py:146] step: 145000, eval_loss: 2.97071e-02
I0209 03:08:33.010210 22542570456896 run_lib.py:133] step: 145050, training_loss: 2.62679e-02
I0209 03:08:50.471507 22542570456896 run_lib.py:133] step: 145100, training_loss: 3.09209e-02
I0209 03:08:50.643300 22542570456896 run_lib.py:146] step: 145100, eval_loss: 2.59313e-02
I0209 03:09:08.277014 22542570456896 run_lib.py:133] step: 145150, training_loss: 3.46223e-02
I0209 03:09:25.792271 22542570456896 run_lib.py:133] step: 145200, training_loss: 3.53717e-02
I0209 03:09:25.944951 22542570456896 run_lib.py:146] step: 145200, eval_loss: 2.58317e-02
I0209 03:09:43.387951 22542570456896 run_lib.py:133] step: 145250, training_loss: 2.58926e-02
I0209 03:10:00.810049 22542570456896 run_lib.py:133] step: 145300, training_loss: 3.17019e-02
I0209 03:10:00.974506 22542570456896 run_lib.py:146] step: 145300, eval_loss: 3.30727e-02
I0209 03:10:18.553834 22542570456896 run_lib.py:133] step: 145350, training_loss: 2.62221e-02
I0209 03:10:36.084455 22542570456896 run_lib.py:133] step: 145400, training_loss: 3.26292e-02
I0209 03:10:36.238797 22542570456896 run_lib.py:146] step: 145400, eval_loss: 2.62261e-02
I0209 03:10:53.686808 22542570456896 run_lib.py:133] step: 145450, training_loss: 2.56635e-02
I0209 03:11:11.123071 22542570456896 run_lib.py:133] step: 145500, training_loss: 2.58130e-02
I0209 03:11:11.278392 22542570456896 run_lib.py:146] step: 145500, eval_loss: 2.43643e-02
I0209 03:11:28.859640 22542570456896 run_lib.py:133] step: 145550, training_loss: 2.22593e-02
I0209 03:11:46.356346 22542570456896 run_lib.py:133] step: 145600, training_loss: 2.91816e-02
I0209 03:11:46.532286 22542570456896 run_lib.py:146] step: 145600, eval_loss: 3.68891e-02
I0209 03:12:04.156856 22542570456896 run_lib.py:133] step: 145650, training_loss: 2.90563e-02
I0209 03:12:21.608840 22542570456896 run_lib.py:133] step: 145700, training_loss: 2.27765e-02
I0209 03:12:21.766558 22542570456896 run_lib.py:146] step: 145700, eval_loss: 3.07742e-02
I0209 03:12:39.375178 22542570456896 run_lib.py:133] step: 145750, training_loss: 2.62038e-02
I0209 03:12:56.809325 22542570456896 run_lib.py:133] step: 145800, training_loss: 3.10600e-02
I0209 03:12:56.961404 22542570456896 run_lib.py:146] step: 145800, eval_loss: 3.02095e-02
I0209 03:13:14.369330 22542570456896 run_lib.py:133] step: 145850, training_loss: 2.25907e-02
I0209 03:13:31.967824 22542570456896 run_lib.py:133] step: 145900, training_loss: 2.85471e-02
I0209 03:13:32.121562 22542570456896 run_lib.py:146] step: 145900, eval_loss: 3.34731e-02
I0209 03:13:49.578240 22542570456896 run_lib.py:133] step: 145950, training_loss: 2.50571e-02
I0209 03:14:07.168365 22542570456896 run_lib.py:133] step: 146000, training_loss: 3.56182e-02
I0209 03:14:07.327318 22542570456896 run_lib.py:146] step: 146000, eval_loss: 3.17483e-02
I0209 03:14:24.773926 22542570456896 run_lib.py:133] step: 146050, training_loss: 3.12774e-02
I0209 03:14:42.208793 22542570456896 run_lib.py:133] step: 146100, training_loss: 2.19250e-02
I0209 03:14:42.373604 22542570456896 run_lib.py:146] step: 146100, eval_loss: 3.10553e-02
I0209 03:14:59.948709 22542570456896 run_lib.py:133] step: 146150, training_loss: 3.20731e-02
I0209 03:15:17.423247 22542570456896 run_lib.py:133] step: 146200, training_loss: 2.08605e-02
I0209 03:15:17.580236 22542570456896 run_lib.py:146] step: 146200, eval_loss: 3.07179e-02
I0209 03:15:34.999210 22542570456896 run_lib.py:133] step: 146250, training_loss: 2.57387e-02
I0209 03:15:52.418092 22542570456896 run_lib.py:133] step: 146300, training_loss: 3.79330e-02
I0209 03:15:52.573295 22542570456896 run_lib.py:146] step: 146300, eval_loss: 3.21258e-02
I0209 03:16:10.167234 22542570456896 run_lib.py:133] step: 146350, training_loss: 2.40258e-02
I0209 03:16:27.590346 22542570456896 run_lib.py:133] step: 146400, training_loss: 2.68940e-02
I0209 03:16:27.745515 22542570456896 run_lib.py:146] step: 146400, eval_loss: 2.73927e-02
I0209 03:16:45.296182 22542570456896 run_lib.py:133] step: 146450, training_loss: 2.83065e-02
I0209 03:17:02.749492 22542570456896 run_lib.py:133] step: 146500, training_loss: 2.66722e-02
I0209 03:17:02.911494 22542570456896 run_lib.py:146] step: 146500, eval_loss: 3.05181e-02
I0209 03:17:20.335279 22542570456896 run_lib.py:133] step: 146550, training_loss: 2.59466e-02
I0209 03:17:37.730533 22542570456896 run_lib.py:133] step: 146600, training_loss: 3.01539e-02
I0209 03:17:37.888314 22542570456896 run_lib.py:146] step: 146600, eval_loss: 2.78308e-02
I0209 03:17:55.492331 22542570456896 run_lib.py:133] step: 146650, training_loss: 2.59496e-02
I0209 03:18:13.010460 22542570456896 run_lib.py:133] step: 146700, training_loss: 3.33766e-02
I0209 03:18:13.166401 22542570456896 run_lib.py:146] step: 146700, eval_loss: 2.82839e-02
I0209 03:18:30.552249 22542570456896 run_lib.py:133] step: 146750, training_loss: 2.76343e-02
I0209 03:18:48.041967 22542570456896 run_lib.py:133] step: 146800, training_loss: 2.40409e-02
I0209 03:18:48.197133 22542570456896 run_lib.py:146] step: 146800, eval_loss: 3.16357e-02
I0209 03:19:05.851610 22542570456896 run_lib.py:133] step: 146850, training_loss: 2.22500e-02
I0209 03:19:23.304537 22542570456896 run_lib.py:133] step: 146900, training_loss: 2.62154e-02
I0209 03:19:23.457258 22542570456896 run_lib.py:146] step: 146900, eval_loss: 2.77132e-02
I0209 03:19:40.994151 22542570456896 run_lib.py:133] step: 146950, training_loss: 3.40184e-02
I0209 03:19:58.404967 22542570456896 run_lib.py:133] step: 147000, training_loss: 3.09574e-02
I0209 03:19:58.587424 22542570456896 run_lib.py:146] step: 147000, eval_loss: 2.40193e-02
I0209 03:20:16.247424 22542570456896 run_lib.py:133] step: 147050, training_loss: 2.67064e-02
I0209 03:20:33.674584 22542570456896 run_lib.py:133] step: 147100, training_loss: 2.55410e-02
I0209 03:20:33.836234 22542570456896 run_lib.py:146] step: 147100, eval_loss: 2.34227e-02
I0209 03:20:51.424118 22542570456896 run_lib.py:133] step: 147150, training_loss: 3.45839e-02
I0209 03:21:08.836010 22542570456896 run_lib.py:133] step: 147200, training_loss: 2.72906e-02
I0209 03:21:08.987825 22542570456896 run_lib.py:146] step: 147200, eval_loss: 3.28756e-02
I0209 03:21:26.418309 22542570456896 run_lib.py:133] step: 147250, training_loss: 2.56643e-02
I0209 03:21:44.009790 22542570456896 run_lib.py:133] step: 147300, training_loss: 2.88475e-02
I0209 03:21:44.163611 22542570456896 run_lib.py:146] step: 147300, eval_loss: 2.73255e-02
I0209 03:22:01.612696 22542570456896 run_lib.py:133] step: 147350, training_loss: 2.49531e-02
I0209 03:22:18.994710 22542570456896 run_lib.py:133] step: 147400, training_loss: 2.48401e-02
I0209 03:22:19.150374 22542570456896 run_lib.py:146] step: 147400, eval_loss: 2.90047e-02
I0209 03:22:36.763482 22542570456896 run_lib.py:133] step: 147450, training_loss: 2.37362e-02
I0209 03:22:54.314127 22542570456896 run_lib.py:133] step: 147500, training_loss: 2.79981e-02
I0209 03:22:54.472440 22542570456896 run_lib.py:146] step: 147500, eval_loss: 2.06448e-02
I0209 03:23:11.879400 22542570456896 run_lib.py:133] step: 147550, training_loss: 2.43173e-02
I0209 03:23:29.330333 22542570456896 run_lib.py:133] step: 147600, training_loss: 2.39961e-02
I0209 03:23:29.486631 22542570456896 run_lib.py:146] step: 147600, eval_loss: 2.98946e-02
I0209 03:23:46.892868 22542570456896 run_lib.py:133] step: 147650, training_loss: 2.39676e-02
I0209 03:24:04.466123 22542570456896 run_lib.py:133] step: 147700, training_loss: 3.37069e-02
I0209 03:24:04.623314 22542570456896 run_lib.py:146] step: 147700, eval_loss: 3.07388e-02
I0209 03:24:22.006646 22542570456896 run_lib.py:133] step: 147750, training_loss: 2.31833e-02
I0209 03:24:39.431984 22542570456896 run_lib.py:133] step: 147800, training_loss: 2.30306e-02
I0209 03:24:39.583323 22542570456896 run_lib.py:146] step: 147800, eval_loss: 3.35589e-02
I0209 03:24:57.028211 22542570456896 run_lib.py:133] step: 147850, training_loss: 2.26258e-02
I0209 03:25:14.677271 22542570456896 run_lib.py:133] step: 147900, training_loss: 2.51816e-02
I0209 03:25:14.833164 22542570456896 run_lib.py:146] step: 147900, eval_loss: 3.01282e-02
I0209 03:25:32.227291 22542570456896 run_lib.py:133] step: 147950, training_loss: 2.90340e-02
I0209 03:25:49.708850 22542570456896 run_lib.py:133] step: 148000, training_loss: 3.00786e-02
I0209 03:25:49.863638 22542570456896 run_lib.py:146] step: 148000, eval_loss: 2.57994e-02
I0209 03:26:07.267585 22542570456896 run_lib.py:133] step: 148050, training_loss: 2.43460e-02
I0209 03:26:24.706716 22542570456896 run_lib.py:133] step: 148100, training_loss: 2.61155e-02
I0209 03:26:24.865406 22542570456896 run_lib.py:146] step: 148100, eval_loss: 2.38496e-02
I0209 03:26:42.428828 22542570456896 run_lib.py:133] step: 148150, training_loss: 3.59645e-02
I0209 03:26:59.967875 22542570456896 run_lib.py:133] step: 148200, training_loss: 2.16777e-02
I0209 03:27:00.130560 22542570456896 run_lib.py:146] step: 148200, eval_loss: 3.05542e-02
I0209 03:27:17.548384 22542570456896 run_lib.py:133] step: 148250, training_loss: 3.06322e-02
I0209 03:27:34.960630 22542570456896 run_lib.py:133] step: 148300, training_loss: 2.57357e-02
I0209 03:27:35.111539 22542570456896 run_lib.py:146] step: 148300, eval_loss: 2.91503e-02
I0209 03:27:52.693975 22542570456896 run_lib.py:133] step: 148350, training_loss: 2.52928e-02
I0209 03:28:10.171521 22542570456896 run_lib.py:133] step: 148400, training_loss: 2.63788e-02
I0209 03:28:10.348343 22542570456896 run_lib.py:146] step: 148400, eval_loss: 3.11148e-02
I0209 03:28:27.973036 22542570456896 run_lib.py:133] step: 148450, training_loss: 2.70467e-02
I0209 03:28:45.387344 22542570456896 run_lib.py:133] step: 148500, training_loss: 2.62367e-02
I0209 03:28:45.546652 22542570456896 run_lib.py:146] step: 148500, eval_loss: 2.52227e-02
I0209 03:29:03.114666 22542570456896 run_lib.py:133] step: 148550, training_loss: 2.62114e-02
I0209 03:29:20.511361 22542570456896 run_lib.py:133] step: 148600, training_loss: 2.38265e-02
I0209 03:29:20.667064 22542570456896 run_lib.py:146] step: 148600, eval_loss: 3.07750e-02
I0209 03:29:38.115066 22542570456896 run_lib.py:133] step: 148650, training_loss: 2.72021e-02
I0209 03:29:55.750687 22542570456896 run_lib.py:133] step: 148700, training_loss: 2.51368e-02
I0209 03:29:55.911168 22542570456896 run_lib.py:146] step: 148700, eval_loss: 2.71425e-02
I0209 03:30:13.367489 22542570456896 run_lib.py:133] step: 148750, training_loss: 2.93328e-02
I0209 03:30:30.957453 22542570456896 run_lib.py:133] step: 148800, training_loss: 3.10131e-02
I0209 03:30:31.111353 22542570456896 run_lib.py:146] step: 148800, eval_loss: 3.23109e-02
I0209 03:30:48.525741 22542570456896 run_lib.py:133] step: 148850, training_loss: 3.51605e-02
I0209 03:31:05.975659 22542570456896 run_lib.py:133] step: 148900, training_loss: 2.66862e-02
I0209 03:31:06.134299 22542570456896 run_lib.py:146] step: 148900, eval_loss: 2.21453e-02
I0209 03:31:23.729461 22542570456896 run_lib.py:133] step: 148950, training_loss: 2.38293e-02
I0209 03:31:41.227900 22542570456896 run_lib.py:133] step: 149000, training_loss: 2.36808e-02
I0209 03:31:41.385201 22542570456896 run_lib.py:146] step: 149000, eval_loss: 1.93312e-02
I0209 03:31:58.826317 22542570456896 run_lib.py:133] step: 149050, training_loss: 2.87846e-02
I0209 03:32:16.441783 22542570456896 run_lib.py:133] step: 149100, training_loss: 2.87121e-02
I0209 03:32:16.598251 22542570456896 run_lib.py:146] step: 149100, eval_loss: 2.40502e-02
I0209 03:32:34.008966 22542570456896 run_lib.py:133] step: 149150, training_loss: 2.68918e-02
I0209 03:32:51.438041 22542570456896 run_lib.py:133] step: 149200, training_loss: 3.32607e-02
I0209 03:32:51.591611 22542570456896 run_lib.py:146] step: 149200, eval_loss: 2.79925e-02
I0209 03:33:09.141422 22542570456896 run_lib.py:133] step: 149250, training_loss: 2.24506e-02
I0209 03:33:26.601730 22542570456896 run_lib.py:133] step: 149300, training_loss: 3.04054e-02
I0209 03:33:26.758747 22542570456896 run_lib.py:146] step: 149300, eval_loss: 3.29817e-02
I0209 03:33:44.201722 22542570456896 run_lib.py:133] step: 149350, training_loss: 3.51552e-02
I0209 03:34:01.631138 22542570456896 run_lib.py:133] step: 149400, training_loss: 3.28509e-02
I0209 03:34:01.789529 22542570456896 run_lib.py:146] step: 149400, eval_loss: 3.63063e-02
I0209 03:34:19.364531 22542570456896 run_lib.py:133] step: 149450, training_loss: 3.67717e-02
I0209 03:34:36.838252 22542570456896 run_lib.py:133] step: 149500, training_loss: 2.51508e-02
I0209 03:34:37.004252 22542570456896 run_lib.py:146] step: 149500, eval_loss: 3.27896e-02
I0209 03:34:54.451275 22542570456896 run_lib.py:133] step: 149550, training_loss: 2.68987e-02
I0209 03:35:11.931328 22542570456896 run_lib.py:133] step: 149600, training_loss: 3.02194e-02
I0209 03:35:12.094110 22542570456896 run_lib.py:146] step: 149600, eval_loss: 3.18589e-02
I0209 03:35:29.723632 22542570456896 run_lib.py:133] step: 149650, training_loss: 3.44111e-02
I0209 03:35:47.144118 22542570456896 run_lib.py:133] step: 149700, training_loss: 3.03143e-02
I0209 03:35:47.303266 22542570456896 run_lib.py:146] step: 149700, eval_loss: 3.51273e-02
I0209 03:36:04.897974 22542570456896 run_lib.py:133] step: 149750, training_loss: 2.55044e-02
I0209 03:36:22.351128 22542570456896 run_lib.py:133] step: 149800, training_loss: 3.10125e-02
I0209 03:36:22.521348 22542570456896 run_lib.py:146] step: 149800, eval_loss: 2.54966e-02
I0209 03:36:40.157546 22542570456896 run_lib.py:133] step: 149850, training_loss: 3.45254e-02
I0209 03:36:57.615190 22542570456896 run_lib.py:133] step: 149900, training_loss: 2.70564e-02
I0209 03:36:57.772281 22542570456896 run_lib.py:146] step: 149900, eval_loss: 3.08204e-02
I0209 03:37:15.368228 22542570456896 run_lib.py:133] step: 149950, training_loss: 2.58047e-02
I0209 03:37:32.805926 22542570456896 run_lib.py:133] step: 150000, training_loss: 2.92506e-02
I0209 03:37:33.503957 22542570456896 run_lib.py:146] step: 150000, eval_loss: 2.35086e-02
I0209 03:37:53.888524 22542570456896 run_lib.py:133] step: 150050, training_loss: 2.76008e-02
I0209 03:38:11.528725 22542570456896 run_lib.py:133] step: 150100, training_loss: 3.49492e-02
I0209 03:38:11.685141 22542570456896 run_lib.py:146] step: 150100, eval_loss: 3.02410e-02
I0209 03:38:29.111374 22542570456896 run_lib.py:133] step: 150150, training_loss: 2.84268e-02
I0209 03:38:46.648205 22542570456896 run_lib.py:133] step: 150200, training_loss: 2.81495e-02
I0209 03:38:46.800436 22542570456896 run_lib.py:146] step: 150200, eval_loss: 3.25339e-02
I0209 03:39:04.203734 22542570456896 run_lib.py:133] step: 150250, training_loss: 2.60899e-02
I0209 03:39:21.618152 22542570456896 run_lib.py:133] step: 150300, training_loss: 3.51343e-02
I0209 03:39:21.771244 22542570456896 run_lib.py:146] step: 150300, eval_loss: 2.75155e-02
I0209 03:39:39.357522 22542570456896 run_lib.py:133] step: 150350, training_loss: 2.99089e-02
I0209 03:39:56.858620 22542570456896 run_lib.py:133] step: 150400, training_loss: 3.24053e-02
I0209 03:39:57.025906 22542570456896 run_lib.py:146] step: 150400, eval_loss: 2.52982e-02
I0209 03:40:14.461265 22542570456896 run_lib.py:133] step: 150450, training_loss: 3.16301e-02
I0209 03:40:31.914945 22542570456896 run_lib.py:133] step: 150500, training_loss: 2.76867e-02
I0209 03:40:32.071625 22542570456896 run_lib.py:146] step: 150500, eval_loss: 2.70703e-02
I0209 03:40:49.667979 22542570456896 run_lib.py:133] step: 150550, training_loss: 3.23171e-02
I0209 03:41:07.094978 22542570456896 run_lib.py:133] step: 150600, training_loss: 3.53303e-02
I0209 03:41:07.263536 22542570456896 run_lib.py:146] step: 150600, eval_loss: 2.93025e-02
I0209 03:41:24.857315 22542570456896 run_lib.py:133] step: 150650, training_loss: 3.37910e-02
I0209 03:41:42.303012 22542570456896 run_lib.py:133] step: 150700, training_loss: 2.52100e-02
I0209 03:41:42.455525 22542570456896 run_lib.py:146] step: 150700, eval_loss: 2.77570e-02
I0209 03:42:00.126366 22542570456896 run_lib.py:133] step: 150750, training_loss: 2.64531e-02
I0209 03:42:17.526742 22542570456896 run_lib.py:133] step: 150800, training_loss: 3.14615e-02
I0209 03:42:17.681061 22542570456896 run_lib.py:146] step: 150800, eval_loss: 3.18215e-02
I0209 03:42:35.118819 22542570456896 run_lib.py:133] step: 150850, training_loss: 2.26147e-02
I0209 03:42:52.709029 22542570456896 run_lib.py:133] step: 150900, training_loss: 3.03729e-02
I0209 03:42:52.886404 22542570456896 run_lib.py:146] step: 150900, eval_loss: 3.06152e-02
I0209 03:43:10.384605 22542570456896 run_lib.py:133] step: 150950, training_loss: 3.12452e-02
I0209 03:43:27.981516 22542570456896 run_lib.py:133] step: 151000, training_loss: 3.27156e-02
I0209 03:43:28.136464 22542570456896 run_lib.py:146] step: 151000, eval_loss: 2.94289e-02
I0209 03:43:45.560299 22542570456896 run_lib.py:133] step: 151050, training_loss: 3.05379e-02
I0209 03:44:02.979643 22542570456896 run_lib.py:133] step: 151100, training_loss: 3.22074e-02
I0209 03:44:03.133376 22542570456896 run_lib.py:146] step: 151100, eval_loss: 3.37091e-02
I0209 03:44:20.746790 22542570456896 run_lib.py:133] step: 151150, training_loss: 3.42842e-02
I0209 03:44:38.221099 22542570456896 run_lib.py:133] step: 151200, training_loss: 2.99934e-02
I0209 03:44:38.384365 22542570456896 run_lib.py:146] step: 151200, eval_loss: 2.58090e-02
I0209 03:44:55.821716 22542570456896 run_lib.py:133] step: 151250, training_loss: 2.62061e-02
I0209 03:45:13.464338 22542570456896 run_lib.py:133] step: 151300, training_loss: 2.75941e-02
I0209 03:45:13.620385 22542570456896 run_lib.py:146] step: 151300, eval_loss: 3.26829e-02
I0209 03:45:31.062758 22542570456896 run_lib.py:133] step: 151350, training_loss: 2.59602e-02
I0209 03:45:48.480940 22542570456896 run_lib.py:133] step: 151400, training_loss: 2.05877e-02
I0209 03:45:48.643478 22542570456896 run_lib.py:146] step: 151400, eval_loss: 2.43286e-02
I0209 03:46:06.174640 22542570456896 run_lib.py:133] step: 151450, training_loss: 3.16952e-02
I0209 03:46:23.631997 22542570456896 run_lib.py:133] step: 151500, training_loss: 2.69241e-02
I0209 03:46:23.790393 22542570456896 run_lib.py:146] step: 151500, eval_loss: 3.04591e-02
I0209 03:46:41.260026 22542570456896 run_lib.py:133] step: 151550, training_loss: 2.62172e-02
I0209 03:46:58.655308 22542570456896 run_lib.py:133] step: 151600, training_loss: 3.20426e-02
I0209 03:46:58.810052 22542570456896 run_lib.py:146] step: 151600, eval_loss: 2.79623e-02
I0209 03:47:16.415969 22542570456896 run_lib.py:133] step: 151650, training_loss: 2.89177e-02
I0209 03:47:33.940163 22542570456896 run_lib.py:133] step: 151700, training_loss: 2.86833e-02
I0209 03:47:34.102592 22542570456896 run_lib.py:146] step: 151700, eval_loss: 3.46874e-02
I0209 03:47:51.606136 22542570456896 run_lib.py:133] step: 151750, training_loss: 2.73048e-02
I0209 03:48:09.032214 22542570456896 run_lib.py:133] step: 151800, training_loss: 3.22543e-02
I0209 03:48:09.190277 22542570456896 run_lib.py:146] step: 151800, eval_loss: 2.58110e-02
I0209 03:48:26.765442 22542570456896 run_lib.py:133] step: 151850, training_loss: 2.50828e-02
I0209 03:48:44.200512 22542570456896 run_lib.py:133] step: 151900, training_loss: 2.82838e-02
I0209 03:48:44.355350 22542570456896 run_lib.py:146] step: 151900, eval_loss: 2.68778e-02
I0209 03:49:01.936535 22542570456896 run_lib.py:133] step: 151950, training_loss: 3.00725e-02
I0209 03:49:19.348276 22542570456896 run_lib.py:133] step: 152000, training_loss: 2.27060e-02
I0209 03:49:19.521128 22542570456896 run_lib.py:146] step: 152000, eval_loss: 1.95586e-02
I0209 03:49:37.123570 22542570456896 run_lib.py:133] step: 152050, training_loss: 2.54062e-02
I0209 03:49:54.567779 22542570456896 run_lib.py:133] step: 152100, training_loss: 2.98521e-02
I0209 03:49:54.718559 22542570456896 run_lib.py:146] step: 152100, eval_loss: 3.40501e-02
I0209 03:50:12.339927 22542570456896 run_lib.py:133] step: 152150, training_loss: 2.74564e-02
I0209 03:50:29.749328 22542570456896 run_lib.py:133] step: 152200, training_loss: 3.27193e-02
I0209 03:50:29.905340 22542570456896 run_lib.py:146] step: 152200, eval_loss: 2.96714e-02
I0209 03:50:47.285186 22542570456896 run_lib.py:133] step: 152250, training_loss: 2.45855e-02
I0209 03:51:04.831377 22542570456896 run_lib.py:133] step: 152300, training_loss: 2.91795e-02
I0209 03:51:05.007386 22542570456896 run_lib.py:146] step: 152300, eval_loss: 2.68208e-02
I0209 03:51:22.473082 22542570456896 run_lib.py:133] step: 152350, training_loss: 2.39330e-02
I0209 03:51:39.884992 22542570456896 run_lib.py:133] step: 152400, training_loss: 2.70337e-02
I0209 03:51:40.041693 22542570456896 run_lib.py:146] step: 152400, eval_loss: 3.44092e-02
I0209 03:51:57.643746 22542570456896 run_lib.py:133] step: 152450, training_loss: 2.46314e-02
I0209 03:52:15.066854 22542570456896 run_lib.py:133] step: 152500, training_loss: 2.88683e-02
I0209 03:52:15.223434 22542570456896 run_lib.py:146] step: 152500, eval_loss: 2.26299e-02
I0209 03:52:32.801432 22542570456896 run_lib.py:133] step: 152550, training_loss: 3.38181e-02
I0209 03:52:50.264961 22542570456896 run_lib.py:133] step: 152600, training_loss: 3.03648e-02
I0209 03:52:50.419682 22542570456896 run_lib.py:146] step: 152600, eval_loss: 2.70442e-02
I0209 03:53:07.886696 22542570456896 run_lib.py:133] step: 152650, training_loss: 2.98638e-02
I0209 03:53:25.495871 22542570456896 run_lib.py:133] step: 152700, training_loss: 3.14646e-02
I0209 03:53:25.660437 22542570456896 run_lib.py:146] step: 152700, eval_loss: 3.09695e-02
I0209 03:53:43.067666 22542570456896 run_lib.py:133] step: 152750, training_loss: 2.95746e-02
I0209 03:54:00.486649 22542570456896 run_lib.py:133] step: 152800, training_loss: 2.48190e-02
I0209 03:54:00.641680 22542570456896 run_lib.py:146] step: 152800, eval_loss: 2.79100e-02
I0209 03:54:18.053456 22542570456896 run_lib.py:133] step: 152850, training_loss: 2.66734e-02
I0209 03:54:35.689162 22542570456896 run_lib.py:133] step: 152900, training_loss: 2.74686e-02
I0209 03:54:35.849159 22542570456896 run_lib.py:146] step: 152900, eval_loss: 2.26775e-02
I0209 03:54:53.262169 22542570456896 run_lib.py:133] step: 152950, training_loss: 2.97117e-02
I0209 03:55:10.752728 22542570456896 run_lib.py:133] step: 153000, training_loss: 2.55726e-02
I0209 03:55:10.911321 22542570456896 run_lib.py:146] step: 153000, eval_loss: 2.91309e-02
I0209 03:55:28.309733 22542570456896 run_lib.py:133] step: 153050, training_loss: 2.99738e-02
I0209 03:55:45.719515 22542570456896 run_lib.py:133] step: 153100, training_loss: 2.10805e-02
I0209 03:55:45.870317 22542570456896 run_lib.py:146] step: 153100, eval_loss: 2.68243e-02
I0209 03:56:03.360652 22542570456896 run_lib.py:133] step: 153150, training_loss: 2.78726e-02
I0209 03:56:20.860482 22542570456896 run_lib.py:133] step: 153200, training_loss: 2.44563e-02
I0209 03:56:21.029306 22542570456896 run_lib.py:146] step: 153200, eval_loss: 2.44520e-02
I0209 03:56:38.506485 22542570456896 run_lib.py:133] step: 153250, training_loss: 2.76948e-02
I0209 03:56:55.966047 22542570456896 run_lib.py:133] step: 153300, training_loss: 2.58719e-02
I0209 03:56:56.123631 22542570456896 run_lib.py:146] step: 153300, eval_loss: 3.08346e-02
I0209 03:57:13.711356 22542570456896 run_lib.py:133] step: 153350, training_loss: 3.41700e-02
I0209 03:57:31.157695 22542570456896 run_lib.py:133] step: 153400, training_loss: 2.84301e-02
I0209 03:57:31.328267 22542570456896 run_lib.py:146] step: 153400, eval_loss: 2.73417e-02
I0209 03:57:48.942169 22542570456896 run_lib.py:133] step: 153450, training_loss: 2.95288e-02
I0209 03:58:06.432754 22542570456896 run_lib.py:133] step: 153500, training_loss: 3.00326e-02
I0209 03:58:06.584141 22542570456896 run_lib.py:146] step: 153500, eval_loss: 3.46673e-02
I0209 03:58:24.220773 22542570456896 run_lib.py:133] step: 153550, training_loss: 2.40428e-02
I0209 03:58:41.665217 22542570456896 run_lib.py:133] step: 153600, training_loss: 2.71645e-02
I0209 03:58:41.817627 22542570456896 run_lib.py:146] step: 153600, eval_loss: 2.64739e-02
I0209 03:58:59.225017 22542570456896 run_lib.py:133] step: 153650, training_loss: 2.92323e-02
I0209 03:59:16.869426 22542570456896 run_lib.py:133] step: 153700, training_loss: 2.29442e-02
I0209 03:59:17.055344 22542570456896 run_lib.py:146] step: 153700, eval_loss: 2.50701e-02
I0209 03:59:34.515116 22542570456896 run_lib.py:133] step: 153750, training_loss: 2.43014e-02
I0209 03:59:52.118460 22542570456896 run_lib.py:133] step: 153800, training_loss: 2.41446e-02
I0209 03:59:52.275564 22542570456896 run_lib.py:146] step: 153800, eval_loss: 3.54028e-02
I0209 04:00:09.686375 22542570456896 run_lib.py:133] step: 153850, training_loss: 2.96421e-02
I0209 04:00:27.142949 22542570456896 run_lib.py:133] step: 153900, training_loss: 3.23852e-02
I0209 04:00:27.301506 22542570456896 run_lib.py:146] step: 153900, eval_loss: 3.94035e-02
I0209 04:00:44.956712 22542570456896 run_lib.py:133] step: 153950, training_loss: 3.12627e-02
I0209 04:01:02.435916 22542570456896 run_lib.py:133] step: 154000, training_loss: 3.22602e-02
I0209 04:01:02.587164 22542570456896 run_lib.py:146] step: 154000, eval_loss: 2.55892e-02
I0209 04:01:20.024724 22542570456896 run_lib.py:133] step: 154050, training_loss: 3.30817e-02
I0209 04:01:37.663033 22542570456896 run_lib.py:133] step: 154100, training_loss: 2.91285e-02
I0209 04:01:37.818402 22542570456896 run_lib.py:146] step: 154100, eval_loss: 2.93163e-02
I0209 04:01:55.300964 22542570456896 run_lib.py:133] step: 154150, training_loss: 2.32980e-02
I0209 04:02:12.780726 22542570456896 run_lib.py:133] step: 154200, training_loss: 3.43106e-02
I0209 04:02:13.090790 22542570456896 run_lib.py:146] step: 154200, eval_loss: 3.22400e-02
I0209 04:02:30.544393 22542570456896 run_lib.py:133] step: 154250, training_loss: 2.96624e-02
I0209 04:02:48.002953 22542570456896 run_lib.py:133] step: 154300, training_loss: 2.74148e-02
I0209 04:02:48.161428 22542570456896 run_lib.py:146] step: 154300, eval_loss: 3.41863e-02
I0209 04:03:05.581738 22542570456896 run_lib.py:133] step: 154350, training_loss: 2.69747e-02
I0209 04:03:23.035702 22542570456896 run_lib.py:133] step: 154400, training_loss: 3.52605e-02
I0209 04:03:23.190930 22542570456896 run_lib.py:146] step: 154400, eval_loss: 2.62965e-02
I0209 04:03:40.794342 22542570456896 run_lib.py:133] step: 154450, training_loss: 3.02445e-02
I0209 04:03:58.321854 22542570456896 run_lib.py:133] step: 154500, training_loss: 2.84304e-02
I0209 04:03:58.476525 22542570456896 run_lib.py:146] step: 154500, eval_loss: 2.33155e-02
I0209 04:04:15.936161 22542570456896 run_lib.py:133] step: 154550, training_loss: 3.06354e-02
I0209 04:04:33.389743 22542570456896 run_lib.py:133] step: 154600, training_loss: 2.79881e-02
I0209 04:04:33.546344 22542570456896 run_lib.py:146] step: 154600, eval_loss: 3.07191e-02
I0209 04:04:51.171369 22542570456896 run_lib.py:133] step: 154650, training_loss: 2.44420e-02
I0209 04:05:08.641302 22542570456896 run_lib.py:133] step: 154700, training_loss: 2.60816e-02
I0209 04:05:08.800345 22542570456896 run_lib.py:146] step: 154700, eval_loss: 2.57895e-02
I0209 04:05:26.233966 22542570456896 run_lib.py:133] step: 154750, training_loss: 2.90156e-02
I0209 04:05:43.673984 22542570456896 run_lib.py:133] step: 154800, training_loss: 2.66595e-02
I0209 04:05:43.838614 22542570456896 run_lib.py:146] step: 154800, eval_loss: 3.24614e-02
I0209 04:06:01.474042 22542570456896 run_lib.py:133] step: 154850, training_loss: 2.53803e-02
I0209 04:06:18.904063 22542570456896 run_lib.py:133] step: 154900, training_loss: 2.77848e-02
I0209 04:06:19.059453 22542570456896 run_lib.py:146] step: 154900, eval_loss: 3.21520e-02
I0209 04:06:36.621282 22542570456896 run_lib.py:133] step: 154950, training_loss: 2.89321e-02
I0209 04:06:54.069664 22542570456896 run_lib.py:133] step: 155000, training_loss: 2.67155e-02
I0209 04:06:54.232676 22542570456896 run_lib.py:146] step: 155000, eval_loss: 3.15985e-02
I0209 04:07:11.917347 22542570456896 run_lib.py:133] step: 155050, training_loss: 2.45488e-02
I0209 04:07:29.320420 22542570456896 run_lib.py:133] step: 155100, training_loss: 2.97503e-02
I0209 04:07:29.478425 22542570456896 run_lib.py:146] step: 155100, eval_loss: 2.72435e-02
I0209 04:07:46.884924 22542570456896 run_lib.py:133] step: 155150, training_loss: 2.60323e-02
I0209 04:08:04.465979 22542570456896 run_lib.py:133] step: 155200, training_loss: 2.74363e-02
I0209 04:08:04.621478 22542570456896 run_lib.py:146] step: 155200, eval_loss: 3.14222e-02
I0209 04:08:22.102427 22542570456896 run_lib.py:133] step: 155250, training_loss: 3.40602e-02
I0209 04:08:39.740391 22542570456896 run_lib.py:133] step: 155300, training_loss: 3.37452e-02
I0209 04:08:39.894438 22542570456896 run_lib.py:146] step: 155300, eval_loss: 3.05099e-02
I0209 04:08:57.346556 22542570456896 run_lib.py:133] step: 155350, training_loss: 2.83653e-02
I0209 04:09:14.748721 22542570456896 run_lib.py:133] step: 155400, training_loss: 3.20749e-02
I0209 04:09:14.899137 22542570456896 run_lib.py:146] step: 155400, eval_loss: 3.16556e-02
I0209 04:09:32.509256 22542570456896 run_lib.py:133] step: 155450, training_loss: 2.27711e-02
I0209 04:09:49.941959 22542570456896 run_lib.py:133] step: 155500, training_loss: 3.26082e-02
I0209 04:09:50.095607 22542570456896 run_lib.py:146] step: 155500, eval_loss: 2.55549e-02
I0209 04:10:07.565232 22542570456896 run_lib.py:133] step: 155550, training_loss: 2.68142e-02
I0209 04:10:24.992513 22542570456896 run_lib.py:133] step: 155600, training_loss: 3.01526e-02
I0209 04:10:25.149793 22542570456896 run_lib.py:146] step: 155600, eval_loss: 3.39828e-02
I0209 04:10:42.763061 22542570456896 run_lib.py:133] step: 155650, training_loss: 3.14703e-02
I0209 04:11:00.182408 22542570456896 run_lib.py:133] step: 155700, training_loss: 2.67819e-02
I0209 04:11:00.337433 22542570456896 run_lib.py:146] step: 155700, eval_loss: 2.75354e-02
I0209 04:11:17.853518 22542570456896 run_lib.py:133] step: 155750, training_loss: 3.34086e-02
I0209 04:11:35.263508 22542570456896 run_lib.py:133] step: 155800, training_loss: 4.06542e-02
I0209 04:11:35.425464 22542570456896 run_lib.py:146] step: 155800, eval_loss: 2.62117e-02
I0209 04:11:52.876868 22542570456896 run_lib.py:133] step: 155850, training_loss: 3.45626e-02
I0209 04:12:10.333483 22542570456896 run_lib.py:133] step: 155900, training_loss: 3.03855e-02
I0209 04:12:10.497586 22542570456896 run_lib.py:146] step: 155900, eval_loss: 3.42434e-02
I0209 04:12:28.131375 22542570456896 run_lib.py:133] step: 155950, training_loss: 2.55469e-02
I0209 04:12:45.624247 22542570456896 run_lib.py:133] step: 156000, training_loss: 2.79797e-02
I0209 04:12:45.778398 22542570456896 run_lib.py:146] step: 156000, eval_loss: 3.37986e-02
I0209 04:13:03.177345 22542570456896 run_lib.py:133] step: 156050, training_loss: 3.43740e-02
I0209 04:13:20.584961 22542570456896 run_lib.py:133] step: 156100, training_loss: 2.78721e-02
I0209 04:13:20.749373 22542570456896 run_lib.py:146] step: 156100, eval_loss: 3.00483e-02
I0209 04:13:38.363023 22542570456896 run_lib.py:133] step: 156150, training_loss: 2.65599e-02
I0209 04:13:55.829597 22542570456896 run_lib.py:133] step: 156200, training_loss: 3.22447e-02
I0209 04:13:55.985633 22542570456896 run_lib.py:146] step: 156200, eval_loss: 2.75170e-02
I0209 04:14:13.613756 22542570456896 run_lib.py:133] step: 156250, training_loss: 2.74815e-02
I0209 04:14:31.029871 22542570456896 run_lib.py:133] step: 156300, training_loss: 2.40425e-02
I0209 04:14:31.185395 22542570456896 run_lib.py:146] step: 156300, eval_loss: 3.56187e-02
I0209 04:14:48.752596 22542570456896 run_lib.py:133] step: 156350, training_loss: 2.62213e-02
I0209 04:15:06.176556 22542570456896 run_lib.py:133] step: 156400, training_loss: 2.76066e-02
I0209 04:15:06.330443 22542570456896 run_lib.py:146] step: 156400, eval_loss: 2.55646e-02
I0209 04:15:24.013899 22542570456896 run_lib.py:133] step: 156450, training_loss: 2.56093e-02
I0209 04:15:41.440942 22542570456896 run_lib.py:133] step: 156500, training_loss: 3.19184e-02
I0209 04:15:41.595332 22542570456896 run_lib.py:146] step: 156500, eval_loss: 3.32399e-02
I0209 04:15:59.015489 22542570456896 run_lib.py:133] step: 156550, training_loss: 2.31055e-02
I0209 04:16:16.586115 22542570456896 run_lib.py:133] step: 156600, training_loss: 2.90375e-02
I0209 04:16:16.743635 22542570456896 run_lib.py:146] step: 156600, eval_loss: 2.57772e-02
I0209 04:16:34.194094 22542570456896 run_lib.py:133] step: 156650, training_loss: 3.01472e-02
I0209 04:16:51.670434 22542570456896 run_lib.py:133] step: 156700, training_loss: 2.27266e-02
I0209 04:16:51.833580 22542570456896 run_lib.py:146] step: 156700, eval_loss: 3.00508e-02
I0209 04:17:09.430507 22542570456896 run_lib.py:133] step: 156750, training_loss: 2.71304e-02
I0209 04:17:27.008484 22542570456896 run_lib.py:133] step: 156800, training_loss: 2.31884e-02
I0209 04:17:27.162328 22542570456896 run_lib.py:146] step: 156800, eval_loss: 3.16440e-02
I0209 04:17:44.582183 22542570456896 run_lib.py:133] step: 156850, training_loss: 2.69679e-02
I0209 04:18:02.011834 22542570456896 run_lib.py:133] step: 156900, training_loss: 2.78318e-02
I0209 04:18:02.165346 22542570456896 run_lib.py:146] step: 156900, eval_loss: 3.14634e-02
I0209 04:18:19.578641 22542570456896 run_lib.py:133] step: 156950, training_loss: 3.40549e-02
I0209 04:18:37.212543 22542570456896 run_lib.py:133] step: 157000, training_loss: 3.30073e-02
I0209 04:18:37.373406 22542570456896 run_lib.py:146] step: 157000, eval_loss: 2.74177e-02
I0209 04:18:54.771757 22542570456896 run_lib.py:133] step: 157050, training_loss: 2.35715e-02
I0209 04:19:12.160610 22542570456896 run_lib.py:133] step: 157100, training_loss: 2.78336e-02
I0209 04:19:12.316254 22542570456896 run_lib.py:146] step: 157100, eval_loss: 3.03989e-02
I0209 04:19:29.764986 22542570456896 run_lib.py:133] step: 157150, training_loss: 3.21016e-02
I0209 04:19:47.372599 22542570456896 run_lib.py:133] step: 157200, training_loss: 1.88910e-02
I0209 04:19:47.541517 22542570456896 run_lib.py:146] step: 157200, eval_loss: 2.88388e-02
I0209 04:20:05.030441 22542570456896 run_lib.py:133] step: 157250, training_loss: 2.41129e-02
I0209 04:20:22.553793 22542570456896 run_lib.py:133] step: 157300, training_loss: 3.10352e-02
I0209 04:20:22.711148 22542570456896 run_lib.py:146] step: 157300, eval_loss: 2.46462e-02
I0209 04:20:40.169325 22542570456896 run_lib.py:133] step: 157350, training_loss: 2.91677e-02
I0209 04:20:57.623390 22542570456896 run_lib.py:133] step: 157400, training_loss: 2.40107e-02
I0209 04:20:57.776394 22542570456896 run_lib.py:146] step: 157400, eval_loss: 2.50718e-02
I0209 04:21:15.337333 22542570456896 run_lib.py:133] step: 157450, training_loss: 2.27671e-02
I0209 04:21:32.826606 22542570456896 run_lib.py:133] step: 157500, training_loss: 3.07592e-02
I0209 04:21:33.002453 22542570456896 run_lib.py:146] step: 157500, eval_loss: 2.48445e-02
I0209 04:21:50.463176 22542570456896 run_lib.py:133] step: 157550, training_loss: 2.69971e-02
I0209 04:22:07.930195 22542570456896 run_lib.py:133] step: 157600, training_loss: 2.53204e-02
I0209 04:22:08.085738 22542570456896 run_lib.py:146] step: 157600, eval_loss: 2.71553e-02
I0209 04:22:25.656780 22542570456896 run_lib.py:133] step: 157650, training_loss: 2.66902e-02
I0209 04:22:43.034649 22542570456896 run_lib.py:133] step: 157700, training_loss: 2.98969e-02
I0209 04:22:43.189579 22542570456896 run_lib.py:146] step: 157700, eval_loss: 3.73994e-02
I0209 04:23:00.716167 22542570456896 run_lib.py:133] step: 157750, training_loss: 2.83199e-02
I0209 04:23:18.218461 22542570456896 run_lib.py:133] step: 157800, training_loss: 3.33554e-02
I0209 04:23:18.372083 22542570456896 run_lib.py:146] step: 157800, eval_loss: 2.74969e-02
I0209 04:23:35.947632 22542570456896 run_lib.py:133] step: 157850, training_loss: 2.54410e-02
I0209 04:23:53.388798 22542570456896 run_lib.py:133] step: 157900, training_loss: 2.73722e-02
I0209 04:23:53.549345 22542570456896 run_lib.py:146] step: 157900, eval_loss: 2.87505e-02
I0209 04:24:10.997096 22542570456896 run_lib.py:133] step: 157950, training_loss: 2.45622e-02
I0209 04:24:28.566878 22542570456896 run_lib.py:133] step: 158000, training_loss: 3.12212e-02
I0209 04:24:28.725696 22542570456896 run_lib.py:146] step: 158000, eval_loss: 2.54846e-02
I0209 04:24:46.187125 22542570456896 run_lib.py:133] step: 158050, training_loss: 3.14118e-02
I0209 04:25:03.822674 22542570456896 run_lib.py:133] step: 158100, training_loss: 3.38943e-02
I0209 04:25:03.978538 22542570456896 run_lib.py:146] step: 158100, eval_loss: 2.59094e-02
I0209 04:25:21.412797 22542570456896 run_lib.py:133] step: 158150, training_loss: 3.09411e-02
I0209 04:25:38.817486 22542570456896 run_lib.py:133] step: 158200, training_loss: 3.38324e-02
I0209 04:25:38.976062 22542570456896 run_lib.py:146] step: 158200, eval_loss: 2.83622e-02
I0209 04:25:56.527584 22542570456896 run_lib.py:133] step: 158250, training_loss: 2.97061e-02
I0209 04:26:13.999071 22542570456896 run_lib.py:133] step: 158300, training_loss: 2.56722e-02
I0209 04:26:14.159217 22542570456896 run_lib.py:146] step: 158300, eval_loss: 2.99594e-02
I0209 04:26:31.663879 22542570456896 run_lib.py:133] step: 158350, training_loss: 2.44974e-02
I0209 04:26:49.261015 22542570456896 run_lib.py:133] step: 158400, training_loss: 3.01736e-02
I0209 04:26:49.418388 22542570456896 run_lib.py:146] step: 158400, eval_loss: 2.68257e-02
I0209 04:27:06.808494 22542570456896 run_lib.py:133] step: 158450, training_loss: 2.82316e-02
I0209 04:27:24.258855 22542570456896 run_lib.py:133] step: 158500, training_loss: 2.45640e-02
I0209 04:27:24.416699 22542570456896 run_lib.py:146] step: 158500, eval_loss: 2.49345e-02
I0209 04:27:41.912058 22542570456896 run_lib.py:133] step: 158550, training_loss: 3.36782e-02
I0209 04:27:59.400536 22542570456896 run_lib.py:133] step: 158600, training_loss: 2.77456e-02
I0209 04:27:59.557015 22542570456896 run_lib.py:146] step: 158600, eval_loss: 2.86777e-02
I0209 04:28:16.988468 22542570456896 run_lib.py:133] step: 158650, training_loss: 3.83030e-02
I0209 04:28:34.406097 22542570456896 run_lib.py:133] step: 158700, training_loss: 2.81935e-02
I0209 04:28:34.561239 22542570456896 run_lib.py:146] step: 158700, eval_loss: 2.93780e-02
I0209 04:28:52.167580 22542570456896 run_lib.py:133] step: 158750, training_loss: 2.93294e-02
I0209 04:29:09.667310 22542570456896 run_lib.py:133] step: 158800, training_loss: 3.11683e-02
I0209 04:29:09.819228 22542570456896 run_lib.py:146] step: 158800, eval_loss: 3.28027e-02
I0209 04:29:27.246072 22542570456896 run_lib.py:133] step: 158850, training_loss: 3.49970e-02
I0209 04:29:44.690316 22542570456896 run_lib.py:133] step: 158900, training_loss: 2.92138e-02
I0209 04:29:44.857304 22542570456896 run_lib.py:146] step: 158900, eval_loss: 2.73913e-02
I0209 04:30:02.482840 22542570456896 run_lib.py:133] step: 158950, training_loss: 2.48345e-02
I0209 04:30:19.903429 22542570456896 run_lib.py:133] step: 159000, training_loss: 2.89073e-02
I0209 04:30:20.060475 22542570456896 run_lib.py:146] step: 159000, eval_loss: 3.06882e-02
I0209 04:30:37.633425 22542570456896 run_lib.py:133] step: 159050, training_loss: 3.69745e-02
I0209 04:30:55.043280 22542570456896 run_lib.py:133] step: 159100, training_loss: 3.52979e-02
I0209 04:30:55.199414 22542570456896 run_lib.py:146] step: 159100, eval_loss: 3.01032e-02
I0209 04:31:12.786673 22542570456896 run_lib.py:133] step: 159150, training_loss: 3.32769e-02
I0209 04:31:30.273202 22542570456896 run_lib.py:133] step: 159200, training_loss: 2.60945e-02
I0209 04:31:30.435852 22542570456896 run_lib.py:146] step: 159200, eval_loss: 2.52448e-02
I0209 04:31:48.074536 22542570456896 run_lib.py:133] step: 159250, training_loss: 3.05920e-02
I0209 04:32:05.489200 22542570456896 run_lib.py:133] step: 159300, training_loss: 3.11691e-02
I0209 04:32:05.651322 22542570456896 run_lib.py:146] step: 159300, eval_loss: 2.94378e-02
I0209 04:32:23.078867 22542570456896 run_lib.py:133] step: 159350, training_loss: 2.60922e-02
I0209 04:32:40.643206 22542570456896 run_lib.py:133] step: 159400, training_loss: 2.40501e-02
I0209 04:32:40.809459 22542570456896 run_lib.py:146] step: 159400, eval_loss: 2.94542e-02
I0209 04:32:58.229650 22542570456896 run_lib.py:133] step: 159450, training_loss: 2.71112e-02
I0209 04:33:15.693706 22542570456896 run_lib.py:133] step: 159500, training_loss: 2.06580e-02
I0209 04:33:15.849539 22542570456896 run_lib.py:146] step: 159500, eval_loss: 3.75285e-02
I0209 04:33:33.486453 22542570456896 run_lib.py:133] step: 159550, training_loss: 2.73152e-02
I0209 04:33:50.892904 22542570456896 run_lib.py:133] step: 159600, training_loss: 2.43045e-02
I0209 04:33:51.049477 22542570456896 run_lib.py:146] step: 159600, eval_loss: 3.76946e-02
I0209 04:34:08.600876 22542570456896 run_lib.py:133] step: 159650, training_loss: 2.93496e-02
I0209 04:34:26.000076 22542570456896 run_lib.py:133] step: 159700, training_loss: 2.97554e-02
I0209 04:34:26.158490 22542570456896 run_lib.py:146] step: 159700, eval_loss: 2.48620e-02
I0209 04:34:43.633659 22542570456896 run_lib.py:133] step: 159750, training_loss: 2.50972e-02
I0209 04:35:01.237240 22542570456896 run_lib.py:133] step: 159800, training_loss: 3.53369e-02
I0209 04:35:01.396984 22542570456896 run_lib.py:146] step: 159800, eval_loss: 2.92186e-02
I0209 04:35:18.832459 22542570456896 run_lib.py:133] step: 159850, training_loss: 3.09123e-02
I0209 04:35:36.261437 22542570456896 run_lib.py:133] step: 159900, training_loss: 3.16424e-02
I0209 04:35:36.419571 22542570456896 run_lib.py:146] step: 159900, eval_loss: 2.70312e-02
I0209 04:35:53.861584 22542570456896 run_lib.py:133] step: 159950, training_loss: 2.79089e-02
I0209 04:36:11.411236 22542570456896 run_lib.py:133] step: 160000, training_loss: 3.15976e-02
I0209 04:36:12.230218 22542570456896 run_lib.py:146] step: 160000, eval_loss: 2.60856e-02
I0209 04:36:32.280759 22542570456896 run_lib.py:133] step: 160050, training_loss: 2.62063e-02
I0209 04:36:49.901192 22542570456896 run_lib.py:133] step: 160100, training_loss: 3.08826e-02
I0209 04:36:50.057299 22542570456896 run_lib.py:146] step: 160100, eval_loss: 2.92098e-02
I0209 04:37:07.462754 22542570456896 run_lib.py:133] step: 160150, training_loss: 3.08901e-02
I0209 04:37:24.893282 22542570456896 run_lib.py:133] step: 160200, training_loss: 2.80065e-02
I0209 04:37:25.046304 22542570456896 run_lib.py:146] step: 160200, eval_loss: 3.18477e-02
I0209 04:37:42.476590 22542570456896 run_lib.py:133] step: 160250, training_loss: 4.04242e-02
I0209 04:38:00.055196 22542570456896 run_lib.py:133] step: 160300, training_loss: 2.46676e-02
I0209 04:38:00.216444 22542570456896 run_lib.py:146] step: 160300, eval_loss: 3.11566e-02
I0209 04:38:17.781415 22542570456896 run_lib.py:133] step: 160350, training_loss: 2.56361e-02
I0209 04:38:35.234135 22542570456896 run_lib.py:133] step: 160400, training_loss: 2.54423e-02
I0209 04:38:35.391551 22542570456896 run_lib.py:146] step: 160400, eval_loss: 3.08011e-02
I0209 04:38:52.779454 22542570456896 run_lib.py:133] step: 160450, training_loss: 2.97591e-02
I0209 04:39:10.169888 22542570456896 run_lib.py:133] step: 160500, training_loss: 2.58059e-02
I0209 04:39:10.325376 22542570456896 run_lib.py:146] step: 160500, eval_loss: 2.61209e-02
I0209 04:39:27.906848 22542570456896 run_lib.py:133] step: 160550, training_loss: 2.74409e-02
I0209 04:39:45.468822 22542570456896 run_lib.py:133] step: 160600, training_loss: 3.30522e-02
I0209 04:39:45.632027 22542570456896 run_lib.py:146] step: 160600, eval_loss: 2.87957e-02
I0209 04:40:03.121648 22542570456896 run_lib.py:133] step: 160650, training_loss: 2.84117e-02
I0209 04:40:20.548775 22542570456896 run_lib.py:133] step: 160700, training_loss: 2.70463e-02
I0209 04:40:20.701165 22542570456896 run_lib.py:146] step: 160700, eval_loss: 3.16070e-02
I0209 04:40:38.252407 22542570456896 run_lib.py:133] step: 160750, training_loss: 3.50352e-02
I0209 04:40:55.692778 22542570456896 run_lib.py:133] step: 160800, training_loss: 3.37702e-02
I0209 04:40:55.852693 22542570456896 run_lib.py:146] step: 160800, eval_loss: 3.00958e-02
I0209 04:41:13.462864 22542570456896 run_lib.py:133] step: 160850, training_loss: 2.66833e-02
I0209 04:41:30.932931 22542570456896 run_lib.py:133] step: 160900, training_loss: 3.17905e-02
I0209 04:41:31.091212 22542570456896 run_lib.py:146] step: 160900, eval_loss: 2.74551e-02
I0209 04:41:48.690590 22542570456896 run_lib.py:133] step: 160950, training_loss: 3.51819e-02
I0209 04:42:06.123350 22542570456896 run_lib.py:133] step: 161000, training_loss: 2.11234e-02
I0209 04:42:06.279395 22542570456896 run_lib.py:146] step: 161000, eval_loss: 2.66028e-02
I0209 04:42:23.690759 22542570456896 run_lib.py:133] step: 161050, training_loss: 2.65781e-02
I0209 04:42:41.300460 22542570456896 run_lib.py:133] step: 161100, training_loss: 2.98353e-02
I0209 04:42:41.464291 22542570456896 run_lib.py:146] step: 161100, eval_loss: 2.48419e-02
I0209 04:42:58.906266 22542570456896 run_lib.py:133] step: 161150, training_loss: 2.27054e-02
I0209 04:43:16.503479 22542570456896 run_lib.py:133] step: 161200, training_loss: 2.71237e-02
I0209 04:43:16.654503 22542570456896 run_lib.py:146] step: 161200, eval_loss: 3.66136e-02
I0209 04:43:34.066235 22542570456896 run_lib.py:133] step: 161250, training_loss: 2.35171e-02
I0209 04:43:51.536487 22542570456896 run_lib.py:133] step: 161300, training_loss: 2.62878e-02
I0209 04:43:51.692341 22542570456896 run_lib.py:146] step: 161300, eval_loss: 2.84546e-02
I0209 04:44:09.225726 22542570456896 run_lib.py:133] step: 161350, training_loss: 2.96718e-02
I0209 04:44:26.711863 22542570456896 run_lib.py:133] step: 161400, training_loss: 3.59794e-02
I0209 04:44:26.889216 22542570456896 run_lib.py:146] step: 161400, eval_loss: 2.77486e-02
I0209 04:44:44.331081 22542570456896 run_lib.py:133] step: 161450, training_loss: 3.48246e-02
I0209 04:45:01.938500 22542570456896 run_lib.py:133] step: 161500, training_loss: 3.02077e-02
I0209 04:45:02.093535 22542570456896 run_lib.py:146] step: 161500, eval_loss: 2.61780e-02
I0209 04:45:19.503581 22542570456896 run_lib.py:133] step: 161550, training_loss: 2.35522e-02
I0209 04:45:36.950288 22542570456896 run_lib.py:133] step: 161600, training_loss: 2.92449e-02
I0209 04:45:37.251255 22542570456896 run_lib.py:146] step: 161600, eval_loss: 2.79036e-02
I0209 04:45:54.672425 22542570456896 run_lib.py:133] step: 161650, training_loss: 2.73810e-02
I0209 04:46:12.143361 22542570456896 run_lib.py:133] step: 161700, training_loss: 3.23114e-02
I0209 04:46:12.304369 22542570456896 run_lib.py:146] step: 161700, eval_loss: 2.06555e-02
I0209 04:46:29.763718 22542570456896 run_lib.py:133] step: 161750, training_loss: 3.23896e-02
I0209 04:46:47.157587 22542570456896 run_lib.py:133] step: 161800, training_loss: 2.63666e-02
I0209 04:46:47.313241 22542570456896 run_lib.py:146] step: 161800, eval_loss: 2.61739e-02
I0209 04:47:04.891883 22542570456896 run_lib.py:133] step: 161850, training_loss: 3.49270e-02
I0209 04:47:22.377050 22542570456896 run_lib.py:133] step: 161900, training_loss: 2.30193e-02
I0209 04:47:22.539323 22542570456896 run_lib.py:146] step: 161900, eval_loss: 2.11781e-02
I0209 04:47:39.953004 22542570456896 run_lib.py:133] step: 161950, training_loss: 3.00048e-02
I0209 04:47:57.394196 22542570456896 run_lib.py:133] step: 162000, training_loss: 3.17063e-02
I0209 04:47:57.550135 22542570456896 run_lib.py:146] step: 162000, eval_loss: 3.03869e-02
I0209 04:48:15.159308 22542570456896 run_lib.py:133] step: 162050, training_loss: 2.46985e-02
I0209 04:48:32.658985 22542570456896 run_lib.py:133] step: 162100, training_loss: 2.30222e-02
I0209 04:48:32.812916 22542570456896 run_lib.py:146] step: 162100, eval_loss: 3.75976e-02
I0209 04:48:50.239855 22542570456896 run_lib.py:133] step: 162150, training_loss: 3.73800e-02
I0209 04:49:07.648629 22542570456896 run_lib.py:133] step: 162200, training_loss: 2.54529e-02
I0209 04:49:07.800486 22542570456896 run_lib.py:146] step: 162200, eval_loss: 2.50140e-02
I0209 04:49:25.390769 22542570456896 run_lib.py:133] step: 162250, training_loss: 2.88993e-02
I0209 04:49:42.878891 22542570456896 run_lib.py:133] step: 162300, training_loss: 2.34578e-02
I0209 04:49:43.039467 22542570456896 run_lib.py:146] step: 162300, eval_loss: 3.26718e-02
I0209 04:50:00.620695 22542570456896 run_lib.py:133] step: 162350, training_loss: 3.07016e-02
I0209 04:50:18.030610 22542570456896 run_lib.py:133] step: 162400, training_loss: 2.84247e-02
I0209 04:50:18.186555 22542570456896 run_lib.py:146] step: 162400, eval_loss: 3.21668e-02
I0209 04:50:35.767570 22542570456896 run_lib.py:133] step: 162450, training_loss: 2.80914e-02
I0209 04:50:53.188940 22542570456896 run_lib.py:133] step: 162500, training_loss: 3.31969e-02
I0209 04:50:53.344137 22542570456896 run_lib.py:146] step: 162500, eval_loss: 2.57379e-02
I0209 04:51:10.792292 22542570456896 run_lib.py:133] step: 162550, training_loss: 3.17412e-02
I0209 04:51:28.460078 22542570456896 run_lib.py:133] step: 162600, training_loss: 2.76581e-02
I0209 04:51:28.611076 22542570456896 run_lib.py:146] step: 162600, eval_loss: 2.68818e-02
I0209 04:51:46.001777 22542570456896 run_lib.py:133] step: 162650, training_loss: 2.95395e-02
I0209 04:52:03.576408 22542570456896 run_lib.py:133] step: 162700, training_loss: 2.74802e-02
I0209 04:52:03.736354 22542570456896 run_lib.py:146] step: 162700, eval_loss: 2.77392e-02
I0209 04:52:21.208969 22542570456896 run_lib.py:133] step: 162750, training_loss: 2.94214e-02
I0209 04:52:38.679001 22542570456896 run_lib.py:133] step: 162800, training_loss: 2.73619e-02
I0209 04:52:38.862283 22542570456896 run_lib.py:146] step: 162800, eval_loss: 2.29649e-02
I0209 04:52:56.532357 22542570456896 run_lib.py:133] step: 162850, training_loss: 3.14211e-02
I0209 04:53:13.942042 22542570456896 run_lib.py:133] step: 162900, training_loss: 3.00744e-02
I0209 04:53:14.097528 22542570456896 run_lib.py:146] step: 162900, eval_loss: 2.86402e-02
I0209 04:53:31.524593 22542570456896 run_lib.py:133] step: 162950, training_loss: 2.52402e-02
I0209 04:53:48.915969 22542570456896 run_lib.py:133] step: 163000, training_loss: 2.59599e-02
I0209 04:53:49.070395 22542570456896 run_lib.py:146] step: 163000, eval_loss: 3.24096e-02
I0209 04:54:06.654577 22542570456896 run_lib.py:133] step: 163050, training_loss: 3.05453e-02
I0209 04:54:24.113215 22542570456896 run_lib.py:133] step: 163100, training_loss: 3.13515e-02
I0209 04:54:24.276434 22542570456896 run_lib.py:146] step: 163100, eval_loss: 2.90674e-02
I0209 04:54:41.825692 22542570456896 run_lib.py:133] step: 163150, training_loss: 3.01265e-02
I0209 04:54:59.220125 22542570456896 run_lib.py:133] step: 163200, training_loss: 2.83799e-02
I0209 04:54:59.375432 22542570456896 run_lib.py:146] step: 163200, eval_loss: 3.79669e-02
I0209 04:55:16.794188 22542570456896 run_lib.py:133] step: 163250, training_loss: 3.10701e-02
I0209 04:55:34.200282 22542570456896 run_lib.py:133] step: 163300, training_loss: 3.08316e-02
I0209 04:55:34.358608 22542570456896 run_lib.py:146] step: 163300, eval_loss: 2.99234e-02
I0209 04:55:51.931016 22542570456896 run_lib.py:133] step: 163350, training_loss: 2.87923e-02
I0209 04:56:09.408974 22542570456896 run_lib.py:133] step: 163400, training_loss: 2.68192e-02
I0209 04:56:09.564570 22542570456896 run_lib.py:146] step: 163400, eval_loss: 2.26443e-02
I0209 04:56:27.015982 22542570456896 run_lib.py:133] step: 163450, training_loss: 2.99701e-02
I0209 04:56:44.396174 22542570456896 run_lib.py:133] step: 163500, training_loss: 2.93270e-02
I0209 04:56:44.551353 22542570456896 run_lib.py:146] step: 163500, eval_loss: 3.50590e-02
I0209 04:57:02.126820 22542570456896 run_lib.py:133] step: 163550, training_loss: 2.52625e-02
I0209 04:57:19.533858 22542570456896 run_lib.py:133] step: 163600, training_loss: 2.25889e-02
I0209 04:57:19.685340 22542570456896 run_lib.py:146] step: 163600, eval_loss: 2.52222e-02
I0209 04:57:37.269596 22542570456896 run_lib.py:133] step: 163650, training_loss: 2.62302e-02
I0209 04:57:54.724746 22542570456896 run_lib.py:133] step: 163700, training_loss: 2.93682e-02
I0209 04:57:54.896409 22542570456896 run_lib.py:146] step: 163700, eval_loss: 2.95272e-02
I0209 04:58:12.514564 22542570456896 run_lib.py:133] step: 163750, training_loss: 2.78916e-02
I0209 04:58:29.931288 22542570456896 run_lib.py:133] step: 163800, training_loss: 3.28180e-02
I0209 04:58:30.086519 22542570456896 run_lib.py:146] step: 163800, eval_loss: 3.19687e-02
I0209 04:58:47.627971 22542570456896 run_lib.py:133] step: 163850, training_loss: 2.74432e-02
I0209 04:59:05.048976 22542570456896 run_lib.py:133] step: 163900, training_loss: 2.77953e-02
I0209 04:59:05.205179 22542570456896 run_lib.py:146] step: 163900, eval_loss: 3.27172e-02
I0209 04:59:22.655092 22542570456896 run_lib.py:133] step: 163950, training_loss: 2.87813e-02
I0209 04:59:40.261134 22542570456896 run_lib.py:133] step: 164000, training_loss: 3.11046e-02
I0209 04:59:40.423324 22542570456896 run_lib.py:146] step: 164000, eval_loss: 3.43374e-02
I0209 04:59:57.809022 22542570456896 run_lib.py:133] step: 164050, training_loss: 3.18317e-02
I0209 05:00:15.212294 22542570456896 run_lib.py:133] step: 164100, training_loss: 2.44232e-02
I0209 05:00:15.372260 22542570456896 run_lib.py:146] step: 164100, eval_loss: 3.09628e-02
I0209 05:00:32.898884 22542570456896 run_lib.py:133] step: 164150, training_loss: 2.71635e-02
I0209 05:00:50.436400 22542570456896 run_lib.py:133] step: 164200, training_loss: 3.12984e-02
I0209 05:00:50.620326 22542570456896 run_lib.py:146] step: 164200, eval_loss: 3.68429e-02
I0209 05:01:08.117799 22542570456896 run_lib.py:133] step: 164250, training_loss: 2.18884e-02
I0209 05:01:25.570722 22542570456896 run_lib.py:133] step: 164300, training_loss: 3.16319e-02
I0209 05:01:25.726493 22542570456896 run_lib.py:146] step: 164300, eval_loss: 3.03480e-02
I0209 05:01:43.192099 22542570456896 run_lib.py:133] step: 164350, training_loss: 2.73355e-02
I0209 05:02:00.775898 22542570456896 run_lib.py:133] step: 164400, training_loss: 4.33270e-02
I0209 05:02:00.939114 22542570456896 run_lib.py:146] step: 164400, eval_loss: 2.67110e-02
I0209 05:02:18.362431 22542570456896 run_lib.py:133] step: 164450, training_loss: 3.13585e-02
I0209 05:02:35.832503 22542570456896 run_lib.py:133] step: 164500, training_loss: 2.54649e-02
I0209 05:02:35.985527 22542570456896 run_lib.py:146] step: 164500, eval_loss: 2.83653e-02
I0209 05:02:53.445541 22542570456896 run_lib.py:133] step: 164550, training_loss: 3.14309e-02
I0209 05:03:11.069383 22542570456896 run_lib.py:133] step: 164600, training_loss: 3.08121e-02
I0209 05:03:11.225303 22542570456896 run_lib.py:146] step: 164600, eval_loss: 2.28326e-02
I0209 05:03:28.628417 22542570456896 run_lib.py:133] step: 164650, training_loss: 2.76941e-02
I0209 05:03:46.070176 22542570456896 run_lib.py:133] step: 164700, training_loss: 2.70717e-02
I0209 05:03:46.234442 22542570456896 run_lib.py:146] step: 164700, eval_loss: 2.90430e-02
I0209 05:04:03.638382 22542570456896 run_lib.py:133] step: 164750, training_loss: 2.72834e-02
I0209 05:04:21.083144 22542570456896 run_lib.py:133] step: 164800, training_loss: 3.21995e-02
I0209 05:04:21.236656 22542570456896 run_lib.py:146] step: 164800, eval_loss: 3.05455e-02
I0209 05:04:38.808617 22542570456896 run_lib.py:133] step: 164850, training_loss: 3.46571e-02
I0209 05:04:56.199272 22542570456896 run_lib.py:133] step: 164900, training_loss: 3.81993e-02
I0209 05:04:56.353229 22542570456896 run_lib.py:146] step: 164900, eval_loss: 3.21285e-02
I0209 05:05:13.683175 22542570456896 run_lib.py:133] step: 164950, training_loss: 3.05385e-02
I0209 05:05:31.115708 22542570456896 run_lib.py:133] step: 165000, training_loss: 2.91681e-02
I0209 05:05:31.268169 22542570456896 run_lib.py:146] step: 165000, eval_loss: 2.47898e-02
I0209 05:05:48.890373 22542570456896 run_lib.py:133] step: 165050, training_loss: 2.85380e-02
I0209 05:06:06.345308 22542570456896 run_lib.py:133] step: 165100, training_loss: 2.97539e-02
I0209 05:06:06.508534 22542570456896 run_lib.py:146] step: 165100, eval_loss: 2.95203e-02
I0209 05:06:24.128733 22542570456896 run_lib.py:133] step: 165150, training_loss: 2.94813e-02
I0209 05:06:41.558547 22542570456896 run_lib.py:133] step: 165200, training_loss: 3.57605e-02
I0209 05:06:41.717600 22542570456896 run_lib.py:146] step: 165200, eval_loss: 3.00398e-02
I0209 05:06:59.310191 22542570456896 run_lib.py:133] step: 165250, training_loss: 3.05101e-02
I0209 05:07:16.748210 22542570456896 run_lib.py:133] step: 165300, training_loss: 3.30634e-02
I0209 05:07:16.918380 22542570456896 run_lib.py:146] step: 165300, eval_loss: 2.69214e-02
I0209 05:07:34.348669 22542570456896 run_lib.py:133] step: 165350, training_loss: 3.10051e-02
I0209 05:07:52.026739 22542570456896 run_lib.py:133] step: 165400, training_loss: 2.28219e-02
I0209 05:07:52.181737 22542570456896 run_lib.py:146] step: 165400, eval_loss: 2.96756e-02
I0209 05:08:09.671779 22542570456896 run_lib.py:133] step: 165450, training_loss: 3.21788e-02
I0209 05:08:27.246498 22542570456896 run_lib.py:133] step: 165500, training_loss: 3.10759e-02
I0209 05:08:27.399409 22542570456896 run_lib.py:146] step: 165500, eval_loss: 2.64310e-02
I0209 05:08:44.810591 22542570456896 run_lib.py:133] step: 165550, training_loss: 2.54027e-02
I0209 05:09:02.273217 22542570456896 run_lib.py:133] step: 165600, training_loss: 3.16429e-02
I0209 05:09:02.449313 22542570456896 run_lib.py:146] step: 165600, eval_loss: 2.94325e-02
I0209 05:09:20.113012 22542570456896 run_lib.py:133] step: 165650, training_loss: 3.34786e-02
I0209 05:09:37.542252 22542570456896 run_lib.py:133] step: 165700, training_loss: 2.09617e-02
I0209 05:09:37.702308 22542570456896 run_lib.py:146] step: 165700, eval_loss: 2.57882e-02
I0209 05:09:55.144009 22542570456896 run_lib.py:133] step: 165750, training_loss: 3.13984e-02
I0209 05:10:12.717800 22542570456896 run_lib.py:133] step: 165800, training_loss: 2.78296e-02
I0209 05:10:12.874055 22542570456896 run_lib.py:146] step: 165800, eval_loss: 2.29399e-02
I0209 05:10:30.313033 22542570456896 run_lib.py:133] step: 165850, training_loss: 2.84213e-02
I0209 05:10:47.803454 22542570456896 run_lib.py:133] step: 165900, training_loss: 2.91474e-02
I0209 05:10:47.957226 22542570456896 run_lib.py:146] step: 165900, eval_loss: 3.10082e-02
I0209 05:11:05.505023 22542570456896 run_lib.py:133] step: 165950, training_loss: 2.36465e-02
I0209 05:11:22.952866 22542570456896 run_lib.py:133] step: 166000, training_loss: 2.52116e-02
I0209 05:11:23.105379 22542570456896 run_lib.py:146] step: 166000, eval_loss: 3.03304e-02
I0209 05:11:40.509646 22542570456896 run_lib.py:133] step: 166050, training_loss: 2.57932e-02
I0209 05:11:57.899850 22542570456896 run_lib.py:133] step: 166100, training_loss: 3.19472e-02
I0209 05:11:58.058579 22542570456896 run_lib.py:146] step: 166100, eval_loss: 2.73167e-02
I0209 05:12:15.650558 22542570456896 run_lib.py:133] step: 166150, training_loss: 3.07598e-02
I0209 05:12:33.189399 22542570456896 run_lib.py:133] step: 166200, training_loss: 3.56225e-02
I0209 05:12:33.344772 22542570456896 run_lib.py:146] step: 166200, eval_loss: 2.67755e-02
I0209 05:12:50.816022 22542570456896 run_lib.py:133] step: 166250, training_loss: 2.77472e-02
I0209 05:13:08.248336 22542570456896 run_lib.py:133] step: 166300, training_loss: 3.01663e-02
I0209 05:13:08.400839 22542570456896 run_lib.py:146] step: 166300, eval_loss: 3.21305e-02
I0209 05:13:26.044970 22542570456896 run_lib.py:133] step: 166350, training_loss: 3.07603e-02
I0209 05:13:43.477349 22542570456896 run_lib.py:133] step: 166400, training_loss: 2.87047e-02
I0209 05:13:43.628402 22542570456896 run_lib.py:146] step: 166400, eval_loss: 3.58673e-02
I0209 05:14:01.194086 22542570456896 run_lib.py:133] step: 166450, training_loss: 2.53097e-02
I0209 05:14:18.643233 22542570456896 run_lib.py:133] step: 166500, training_loss: 2.98996e-02
I0209 05:14:18.809535 22542570456896 run_lib.py:146] step: 166500, eval_loss: 2.49675e-02
I0209 05:14:36.477163 22542570456896 run_lib.py:133] step: 166550, training_loss: 3.05610e-02
I0209 05:14:53.907343 22542570456896 run_lib.py:133] step: 166600, training_loss: 3.47366e-02
I0209 05:14:54.064999 22542570456896 run_lib.py:146] step: 166600, eval_loss: 3.21637e-02
I0209 05:15:11.614567 22542570456896 run_lib.py:133] step: 166650, training_loss: 2.89038e-02
I0209 05:15:29.027908 22542570456896 run_lib.py:133] step: 166700, training_loss: 3.62200e-02
I0209 05:15:29.192405 22542570456896 run_lib.py:146] step: 166700, eval_loss: 2.70774e-02
I0209 05:15:46.652982 22542570456896 run_lib.py:133] step: 166750, training_loss: 2.80824e-02
I0209 05:16:04.247837 22542570456896 run_lib.py:133] step: 166800, training_loss: 2.77951e-02
I0209 05:16:04.404746 22542570456896 run_lib.py:146] step: 166800, eval_loss: 2.80628e-02
I0209 05:16:21.858659 22542570456896 run_lib.py:133] step: 166850, training_loss: 2.81065e-02
I0209 05:16:39.290428 22542570456896 run_lib.py:133] step: 166900, training_loss: 2.50381e-02
I0209 05:16:39.445075 22542570456896 run_lib.py:146] step: 166900, eval_loss: 3.12805e-02
I0209 05:16:57.048122 22542570456896 run_lib.py:133] step: 166950, training_loss: 2.37525e-02
I0209 05:17:14.506344 22542570456896 run_lib.py:133] step: 167000, training_loss: 2.86714e-02
I0209 05:17:14.676523 22542570456896 run_lib.py:146] step: 167000, eval_loss: 2.34146e-02
I0209 05:17:32.290280 22542570456896 run_lib.py:133] step: 167050, training_loss: 2.69524e-02
I0209 05:17:49.735518 22542570456896 run_lib.py:133] step: 167100, training_loss: 2.19400e-02
I0209 05:17:49.892340 22542570456896 run_lib.py:146] step: 167100, eval_loss: 2.85428e-02
I0209 05:18:07.321668 22542570456896 run_lib.py:133] step: 167150, training_loss: 2.80020e-02
I0209 05:18:24.955099 22542570456896 run_lib.py:133] step: 167200, training_loss: 2.60035e-02
I0209 05:18:25.111406 22542570456896 run_lib.py:146] step: 167200, eval_loss: 2.89078e-02
I0209 05:18:42.513585 22542570456896 run_lib.py:133] step: 167250, training_loss: 2.73913e-02
I0209 05:18:59.960987 22542570456896 run_lib.py:133] step: 167300, training_loss: 2.35571e-02
I0209 05:19:00.116630 22542570456896 run_lib.py:146] step: 167300, eval_loss: 3.13576e-02
I0209 05:19:17.580406 22542570456896 run_lib.py:133] step: 167350, training_loss: 1.75582e-02
I0209 05:19:35.173534 22542570456896 run_lib.py:133] step: 167400, training_loss: 2.92927e-02
I0209 05:19:35.331362 22542570456896 run_lib.py:146] step: 167400, eval_loss: 2.58250e-02
I0209 05:19:52.768598 22542570456896 run_lib.py:133] step: 167450, training_loss: 3.65415e-02
I0209 05:20:10.282295 22542570456896 run_lib.py:133] step: 167500, training_loss: 2.66309e-02
I0209 05:20:10.438031 22542570456896 run_lib.py:146] step: 167500, eval_loss: 2.95647e-02
I0209 05:20:27.905706 22542570456896 run_lib.py:133] step: 167550, training_loss: 2.78551e-02
I0209 05:20:45.341385 22542570456896 run_lib.py:133] step: 167600, training_loss: 3.59788e-02
I0209 05:20:45.501566 22542570456896 run_lib.py:146] step: 167600, eval_loss: 2.32626e-02
I0209 05:21:03.134674 22542570456896 run_lib.py:133] step: 167650, training_loss: 2.29061e-02
I0209 05:21:20.602402 22542570456896 run_lib.py:133] step: 167700, training_loss: 2.54592e-02
I0209 05:21:20.758225 22542570456896 run_lib.py:146] step: 167700, eval_loss: 2.86376e-02
I0209 05:21:38.200162 22542570456896 run_lib.py:133] step: 167750, training_loss: 2.57685e-02
I0209 05:21:55.620889 22542570456896 run_lib.py:133] step: 167800, training_loss: 2.75289e-02
I0209 05:21:55.781195 22542570456896 run_lib.py:146] step: 167800, eval_loss: 2.56203e-02
I0209 05:22:13.433725 22542570456896 run_lib.py:133] step: 167850, training_loss: 2.82038e-02
I0209 05:22:30.845960 22542570456896 run_lib.py:133] step: 167900, training_loss: 1.86785e-02
I0209 05:22:30.999283 22542570456896 run_lib.py:146] step: 167900, eval_loss: 3.14775e-02
I0209 05:22:48.598647 22542570456896 run_lib.py:133] step: 167950, training_loss: 2.69997e-02
I0209 05:23:06.011447 22542570456896 run_lib.py:133] step: 168000, training_loss: 2.62557e-02
I0209 05:23:06.174617 22542570456896 run_lib.py:146] step: 168000, eval_loss: 2.93779e-02
I0209 05:23:23.716774 22542570456896 run_lib.py:133] step: 168050, training_loss: 2.59055e-02
I0209 05:23:41.113439 22542570456896 run_lib.py:133] step: 168100, training_loss: 3.59672e-02
I0209 05:23:41.282295 22542570456896 run_lib.py:146] step: 168100, eval_loss: 2.07778e-02
I0209 05:23:58.737815 22542570456896 run_lib.py:133] step: 168150, training_loss: 2.86867e-02
I0209 05:24:16.371110 22542570456896 run_lib.py:133] step: 168200, training_loss: 2.87338e-02
I0209 05:24:16.528680 22542570456896 run_lib.py:146] step: 168200, eval_loss: 2.38576e-02
I0209 05:24:33.995796 22542570456896 run_lib.py:133] step: 168250, training_loss: 2.75198e-02
I0209 05:24:51.531875 22542570456896 run_lib.py:133] step: 168300, training_loss: 2.16537e-02
I0209 05:24:51.683362 22542570456896 run_lib.py:146] step: 168300, eval_loss: 3.57372e-02
I0209 05:25:09.085421 22542570456896 run_lib.py:133] step: 168350, training_loss: 2.41898e-02
I0209 05:25:26.526427 22542570456896 run_lib.py:133] step: 168400, training_loss: 2.86269e-02
I0209 05:25:26.695553 22542570456896 run_lib.py:146] step: 168400, eval_loss: 3.59380e-02
I0209 05:25:44.362261 22542570456896 run_lib.py:133] step: 168450, training_loss: 2.87818e-02
I0209 05:26:01.806726 22542570456896 run_lib.py:133] step: 168500, training_loss: 3.01877e-02
I0209 05:26:01.964302 22542570456896 run_lib.py:146] step: 168500, eval_loss: 2.27122e-02
I0209 05:26:19.382368 22542570456896 run_lib.py:133] step: 168550, training_loss: 2.87930e-02
I0209 05:26:36.919363 22542570456896 run_lib.py:133] step: 168600, training_loss: 2.86539e-02
I0209 05:26:37.074231 22542570456896 run_lib.py:146] step: 168600, eval_loss: 2.60753e-02
I0209 05:26:54.487967 22542570456896 run_lib.py:133] step: 168650, training_loss: 3.37214e-02
I0209 05:27:11.978569 22542570456896 run_lib.py:133] step: 168700, training_loss: 2.88021e-02
I0209 05:27:12.319495 22542570456896 run_lib.py:146] step: 168700, eval_loss: 2.47159e-02
I0209 05:27:29.790122 22542570456896 run_lib.py:133] step: 168750, training_loss: 2.54723e-02
I0209 05:27:47.172948 22542570456896 run_lib.py:133] step: 168800, training_loss: 3.32593e-02
I0209 05:27:47.326502 22542570456896 run_lib.py:146] step: 168800, eval_loss: 3.28690e-02
I0209 05:28:04.718003 22542570456896 run_lib.py:133] step: 168850, training_loss: 3.44826e-02
I0209 05:28:22.143246 22542570456896 run_lib.py:133] step: 168900, training_loss: 2.49401e-02
I0209 05:28:22.298335 22542570456896 run_lib.py:146] step: 168900, eval_loss: 3.37153e-02
I0209 05:28:39.886722 22542570456896 run_lib.py:133] step: 168950, training_loss: 3.01285e-02
I0209 05:28:57.461858 22542570456896 run_lib.py:133] step: 169000, training_loss: 2.27092e-02
I0209 05:28:57.622371 22542570456896 run_lib.py:146] step: 169000, eval_loss: 2.89025e-02
I0209 05:29:15.032248 22542570456896 run_lib.py:133] step: 169050, training_loss: 3.27122e-02
I0209 05:29:32.466190 22542570456896 run_lib.py:133] step: 169100, training_loss: 2.87185e-02
I0209 05:29:32.627434 22542570456896 run_lib.py:146] step: 169100, eval_loss: 3.00309e-02
I0209 05:29:50.245992 22542570456896 run_lib.py:133] step: 169150, training_loss: 3.42051e-02
I0209 05:30:07.712179 22542570456896 run_lib.py:133] step: 169200, training_loss: 3.08375e-02
I0209 05:30:07.879354 22542570456896 run_lib.py:146] step: 169200, eval_loss: 2.74791e-02
I0209 05:30:25.328501 22542570456896 run_lib.py:133] step: 169250, training_loss: 2.73594e-02
I0209 05:30:42.823560 22542570456896 run_lib.py:133] step: 169300, training_loss: 3.30470e-02
I0209 05:30:42.977664 22542570456896 run_lib.py:146] step: 169300, eval_loss: 2.80594e-02
I0209 05:31:00.646461 22542570456896 run_lib.py:133] step: 169350, training_loss: 3.30675e-02
I0209 05:31:18.116779 22542570456896 run_lib.py:133] step: 169400, training_loss: 2.45904e-02
I0209 05:31:18.274543 22542570456896 run_lib.py:146] step: 169400, eval_loss: 2.91268e-02
I0209 05:31:35.846764 22542570456896 run_lib.py:133] step: 169450, training_loss: 2.98076e-02
I0209 05:31:53.299985 22542570456896 run_lib.py:133] step: 169500, training_loss: 2.66742e-02
I0209 05:31:53.468350 22542570456896 run_lib.py:146] step: 169500, eval_loss: 2.24241e-02
I0209 05:32:11.097979 22542570456896 run_lib.py:133] step: 169550, training_loss: 3.04998e-02
I0209 05:32:28.558781 22542570456896 run_lib.py:133] step: 169600, training_loss: 2.53957e-02
I0209 05:32:28.714786 22542570456896 run_lib.py:146] step: 169600, eval_loss: 2.91994e-02
I0209 05:32:46.135071 22542570456896 run_lib.py:133] step: 169650, training_loss: 2.99824e-02
I0209 05:33:03.688704 22542570456896 run_lib.py:133] step: 169700, training_loss: 2.74647e-02
I0209 05:33:03.841435 22542570456896 run_lib.py:146] step: 169700, eval_loss: 2.64149e-02
I0209 05:33:21.247362 22542570456896 run_lib.py:133] step: 169750, training_loss: 3.26826e-02
I0209 05:33:38.856696 22542570456896 run_lib.py:133] step: 169800, training_loss: 3.69481e-02
I0209 05:33:39.015582 22542570456896 run_lib.py:146] step: 169800, eval_loss: 3.11532e-02
I0209 05:33:56.463732 22542570456896 run_lib.py:133] step: 169850, training_loss: 2.75729e-02
I0209 05:34:13.913960 22542570456896 run_lib.py:133] step: 169900, training_loss: 2.23519e-02
I0209 05:34:14.073489 22542570456896 run_lib.py:146] step: 169900, eval_loss: 2.43182e-02
I0209 05:34:31.637402 22542570456896 run_lib.py:133] step: 169950, training_loss: 2.37417e-02
I0209 05:34:49.068811 22542570456896 run_lib.py:133] step: 170000, training_loss: 3.44202e-02
I0209 05:34:49.805105 22542570456896 run_lib.py:146] step: 170000, eval_loss: 2.30771e-02
I0209 05:35:10.084692 22542570456896 run_lib.py:133] step: 170050, training_loss: 2.86054e-02
I0209 05:35:27.671074 22542570456896 run_lib.py:133] step: 170100, training_loss: 2.92913e-02
I0209 05:35:27.830695 22542570456896 run_lib.py:146] step: 170100, eval_loss: 2.53862e-02
I0209 05:35:45.257257 22542570456896 run_lib.py:133] step: 170150, training_loss: 2.69228e-02
I0209 05:36:02.713871 22542570456896 run_lib.py:133] step: 170200, training_loss: 3.36149e-02
I0209 05:36:02.869406 22542570456896 run_lib.py:146] step: 170200, eval_loss: 3.40453e-02
I0209 05:36:20.398495 22542570456896 run_lib.py:133] step: 170250, training_loss: 2.77325e-02
I0209 05:36:37.985275 22542570456896 run_lib.py:133] step: 170300, training_loss: 3.17203e-02
I0209 05:36:38.138651 22542570456896 run_lib.py:146] step: 170300, eval_loss: 3.22444e-02
I0209 05:36:55.611233 22542570456896 run_lib.py:133] step: 170350, training_loss: 3.07200e-02
I0209 05:37:13.053962 22542570456896 run_lib.py:133] step: 170400, training_loss: 3.05362e-02
I0209 05:37:13.210349 22542570456896 run_lib.py:146] step: 170400, eval_loss: 2.79546e-02
I0209 05:37:30.815327 22542570456896 run_lib.py:133] step: 170450, training_loss: 2.68080e-02
I0209 05:37:48.242365 22542570456896 run_lib.py:133] step: 170500, training_loss: 2.46501e-02
I0209 05:37:48.400716 22542570456896 run_lib.py:146] step: 170500, eval_loss: 3.18120e-02
I0209 05:38:05.946331 22542570456896 run_lib.py:133] step: 170550, training_loss: 2.57639e-02
I0209 05:38:23.419259 22542570456896 run_lib.py:133] step: 170600, training_loss: 2.51796e-02
I0209 05:38:23.575304 22542570456896 run_lib.py:146] step: 170600, eval_loss: 2.58935e-02
I0209 05:38:41.162688 22542570456896 run_lib.py:133] step: 170650, training_loss: 3.10574e-02
I0209 05:38:58.559177 22542570456896 run_lib.py:133] step: 170700, training_loss: 2.84815e-02
I0209 05:38:58.718169 22542570456896 run_lib.py:146] step: 170700, eval_loss: 2.93134e-02
I0209 05:39:16.142803 22542570456896 run_lib.py:133] step: 170750, training_loss: 2.61071e-02
I0209 05:39:33.692277 22542570456896 run_lib.py:133] step: 170800, training_loss: 2.64317e-02
I0209 05:39:33.844414 22542570456896 run_lib.py:146] step: 170800, eval_loss: 2.18531e-02
I0209 05:39:51.255764 22542570456896 run_lib.py:133] step: 170850, training_loss: 2.55755e-02
I0209 05:40:08.862922 22542570456896 run_lib.py:133] step: 170900, training_loss: 2.89768e-02
I0209 05:40:09.040381 22542570456896 run_lib.py:146] step: 170900, eval_loss: 2.20249e-02
I0209 05:40:26.489557 22542570456896 run_lib.py:133] step: 170950, training_loss: 3.31013e-02
I0209 05:40:43.933144 22542570456896 run_lib.py:133] step: 171000, training_loss: 3.33312e-02
I0209 05:40:44.096922 22542570456896 run_lib.py:146] step: 171000, eval_loss: 3.64932e-02
I0209 05:41:01.725981 22542570456896 run_lib.py:133] step: 171050, training_loss: 3.02146e-02
I0209 05:41:19.136011 22542570456896 run_lib.py:133] step: 171100, training_loss: 2.30535e-02
I0209 05:41:19.293396 22542570456896 run_lib.py:146] step: 171100, eval_loss: 3.13352e-02
I0209 05:41:36.696349 22542570456896 run_lib.py:133] step: 171150, training_loss: 2.92106e-02
I0209 05:41:54.166050 22542570456896 run_lib.py:133] step: 171200, training_loss: 2.52540e-02
I0209 05:41:54.327095 22542570456896 run_lib.py:146] step: 171200, eval_loss: 2.92987e-02
I0209 05:42:12.001859 22542570456896 run_lib.py:133] step: 171250, training_loss: 2.81161e-02
I0209 05:42:29.373219 22542570456896 run_lib.py:133] step: 171300, training_loss: 3.38744e-02
I0209 05:42:29.528432 22542570456896 run_lib.py:146] step: 171300, eval_loss: 2.64154e-02
I0209 05:42:46.997689 22542570456896 run_lib.py:133] step: 171350, training_loss: 2.88566e-02
I0209 05:43:04.401916 22542570456896 run_lib.py:133] step: 171400, training_loss: 2.83649e-02
I0209 05:43:04.566681 22542570456896 run_lib.py:146] step: 171400, eval_loss: 2.62756e-02
I0209 05:43:22.059867 22542570456896 run_lib.py:133] step: 171450, training_loss: 2.95187e-02
I0209 05:43:39.490924 22542570456896 run_lib.py:133] step: 171500, training_loss: 3.57937e-02
I0209 05:43:39.649519 22542570456896 run_lib.py:146] step: 171500, eval_loss: 3.02224e-02
I0209 05:43:57.237361 22542570456896 run_lib.py:133] step: 171550, training_loss: 2.38091e-02
I0209 05:44:14.714044 22542570456896 run_lib.py:133] step: 171600, training_loss: 2.08645e-02
I0209 05:44:14.868182 22542570456896 run_lib.py:146] step: 171600, eval_loss: 2.68826e-02
I0209 05:44:32.283159 22542570456896 run_lib.py:133] step: 171650, training_loss: 3.35520e-02
I0209 05:44:49.693442 22542570456896 run_lib.py:133] step: 171700, training_loss: 2.68264e-02
I0209 05:44:49.850316 22542570456896 run_lib.py:146] step: 171700, eval_loss: 3.53245e-02
I0209 05:45:07.461569 22542570456896 run_lib.py:133] step: 171750, training_loss: 2.76136e-02
I0209 05:45:24.853794 22542570456896 run_lib.py:133] step: 171800, training_loss: 2.60655e-02
I0209 05:45:25.007241 22542570456896 run_lib.py:146] step: 171800, eval_loss: 3.04168e-02
I0209 05:45:42.590444 22542570456896 run_lib.py:133] step: 171850, training_loss: 2.74042e-02
I0209 05:46:00.024210 22542570456896 run_lib.py:133] step: 171900, training_loss: 3.51498e-02
I0209 05:46:00.184053 22542570456896 run_lib.py:146] step: 171900, eval_loss: 1.68322e-02
I0209 05:46:17.749009 22542570456896 run_lib.py:133] step: 171950, training_loss: 1.98005e-02
I0209 05:46:35.279312 22542570456896 run_lib.py:133] step: 172000, training_loss: 2.94081e-02
I0209 05:46:35.435533 22542570456896 run_lib.py:146] step: 172000, eval_loss: 3.19539e-02
I0209 05:46:53.077307 22542570456896 run_lib.py:133] step: 172050, training_loss: 3.34112e-02
I0209 05:47:10.490286 22542570456896 run_lib.py:133] step: 172100, training_loss: 3.20348e-02
I0209 05:47:10.642431 22542570456896 run_lib.py:146] step: 172100, eval_loss: 2.55103e-02
I0209 05:47:28.101446 22542570456896 run_lib.py:133] step: 172150, training_loss: 2.34822e-02
I0209 05:47:45.694369 22542570456896 run_lib.py:133] step: 172200, training_loss: 2.31416e-02
I0209 05:47:45.849437 22542570456896 run_lib.py:146] step: 172200, eval_loss: 3.59984e-02
I0209 05:48:03.300461 22542570456896 run_lib.py:133] step: 172250, training_loss: 2.81707e-02
I0209 05:48:20.754586 22542570456896 run_lib.py:133] step: 172300, training_loss: 3.19457e-02
I0209 05:48:20.925127 22542570456896 run_lib.py:146] step: 172300, eval_loss: 3.34432e-02
I0209 05:48:38.556181 22542570456896 run_lib.py:133] step: 172350, training_loss: 3.59991e-02
I0209 05:48:56.126323 22542570456896 run_lib.py:133] step: 172400, training_loss: 2.95844e-02
I0209 05:48:56.285491 22542570456896 run_lib.py:146] step: 172400, eval_loss: 2.67694e-02
I0209 05:49:13.712342 22542570456896 run_lib.py:133] step: 172450, training_loss: 2.96463e-02
I0209 05:49:31.142844 22542570456896 run_lib.py:133] step: 172500, training_loss: 2.29006e-02
I0209 05:49:31.308441 22542570456896 run_lib.py:146] step: 172500, eval_loss: 2.90111e-02
I0209 05:49:48.766968 22542570456896 run_lib.py:133] step: 172550, training_loss: 2.87400e-02
I0209 05:50:06.404652 22542570456896 run_lib.py:133] step: 172600, training_loss: 2.67599e-02
I0209 05:50:06.564869 22542570456896 run_lib.py:146] step: 172600, eval_loss: 2.57959e-02
I0209 05:50:24.005066 22542570456896 run_lib.py:133] step: 172650, training_loss: 2.65308e-02
I0209 05:50:41.427160 22542570456896 run_lib.py:133] step: 172700, training_loss: 3.07036e-02
I0209 05:50:41.580879 22542570456896 run_lib.py:146] step: 172700, eval_loss: 2.58794e-02
I0209 05:50:59.026709 22542570456896 run_lib.py:133] step: 172750, training_loss: 3.23229e-02
I0209 05:51:16.591650 22542570456896 run_lib.py:133] step: 172800, training_loss: 2.67310e-02
I0209 05:51:16.771850 22542570456896 run_lib.py:146] step: 172800, eval_loss: 2.97069e-02
I0209 05:51:34.258990 22542570456896 run_lib.py:133] step: 172850, training_loss: 2.77468e-02
I0209 05:51:51.796036 22542570456896 run_lib.py:133] step: 172900, training_loss: 2.51502e-02
I0209 05:51:51.954599 22542570456896 run_lib.py:146] step: 172900, eval_loss: 2.99056e-02
I0209 05:52:09.336535 22542570456896 run_lib.py:133] step: 172950, training_loss: 2.55914e-02
I0209 05:52:26.769908 22542570456896 run_lib.py:133] step: 173000, training_loss: 2.64526e-02
I0209 05:52:26.926151 22542570456896 run_lib.py:146] step: 173000, eval_loss: 3.13151e-02
I0209 05:52:44.504395 22542570456896 run_lib.py:133] step: 173050, training_loss: 2.97866e-02
I0209 05:53:02.036025 22542570456896 run_lib.py:133] step: 173100, training_loss: 2.87935e-02
I0209 05:53:02.197177 22542570456896 run_lib.py:146] step: 173100, eval_loss: 2.49183e-02
I0209 05:53:19.627653 22542570456896 run_lib.py:133] step: 173150, training_loss: 3.12335e-02
I0209 05:53:37.102089 22542570456896 run_lib.py:133] step: 173200, training_loss: 3.09949e-02
I0209 05:53:37.257449 22542570456896 run_lib.py:146] step: 173200, eval_loss: 3.40076e-02
I0209 05:53:54.826453 22542570456896 run_lib.py:133] step: 173250, training_loss: 2.86153e-02
I0209 05:54:12.245815 22542570456896 run_lib.py:133] step: 173300, training_loss: 3.83584e-02
I0209 05:54:12.407748 22542570456896 run_lib.py:146] step: 173300, eval_loss: 2.99594e-02
I0209 05:54:30.008667 22542570456896 run_lib.py:133] step: 173350, training_loss: 2.34310e-02
I0209 05:54:47.521736 22542570456896 run_lib.py:133] step: 173400, training_loss: 2.70987e-02
I0209 05:54:47.679501 22542570456896 run_lib.py:146] step: 173400, eval_loss: 2.53690e-02
I0209 05:55:05.256246 22542570456896 run_lib.py:133] step: 173450, training_loss: 3.14788e-02
I0209 05:55:22.637525 22542570456896 run_lib.py:133] step: 173500, training_loss: 2.93943e-02
I0209 05:55:22.796086 22542570456896 run_lib.py:146] step: 173500, eval_loss: 3.23313e-02
I0209 05:55:40.170732 22542570456896 run_lib.py:133] step: 173550, training_loss: 2.91512e-02
I0209 05:55:57.716493 22542570456896 run_lib.py:133] step: 173600, training_loss: 2.97213e-02
I0209 05:55:57.874374 22542570456896 run_lib.py:146] step: 173600, eval_loss: 2.36463e-02
I0209 05:56:15.295603 22542570456896 run_lib.py:133] step: 173650, training_loss: 3.20799e-02
I0209 05:56:32.908450 22542570456896 run_lib.py:133] step: 173700, training_loss: 2.60701e-02
I0209 05:56:33.083570 22542570456896 run_lib.py:146] step: 173700, eval_loss: 2.64467e-02
I0209 05:56:50.535855 22542570456896 run_lib.py:133] step: 173750, training_loss: 2.40597e-02
I0209 05:57:07.948732 22542570456896 run_lib.py:133] step: 173800, training_loss: 2.27415e-02
I0209 05:57:08.107704 22542570456896 run_lib.py:146] step: 173800, eval_loss: 2.49552e-02
I0209 05:57:25.690334 22542570456896 run_lib.py:133] step: 173850, training_loss: 3.27454e-02
I0209 05:57:43.085386 22542570456896 run_lib.py:133] step: 173900, training_loss: 2.51007e-02
I0209 05:57:43.241463 22542570456896 run_lib.py:146] step: 173900, eval_loss: 3.14789e-02
I0209 05:58:00.686272 22542570456896 run_lib.py:133] step: 173950, training_loss: 2.41699e-02
I0209 05:58:18.363264 22542570456896 run_lib.py:133] step: 174000, training_loss: 2.37743e-02
I0209 05:58:18.519571 22542570456896 run_lib.py:146] step: 174000, eval_loss: 2.28104e-02
I0209 05:58:35.950372 22542570456896 run_lib.py:133] step: 174050, training_loss: 2.42928e-02
I0209 05:58:53.330615 22542570456896 run_lib.py:133] step: 174100, training_loss: 2.18500e-02
I0209 05:58:53.482444 22542570456896 run_lib.py:146] step: 174100, eval_loss: 3.23519e-02
I0209 05:59:10.935762 22542570456896 run_lib.py:133] step: 174150, training_loss: 3.17307e-02
I0209 05:59:28.354432 22542570456896 run_lib.py:133] step: 174200, training_loss: 3.13944e-02
I0209 05:59:28.510598 22542570456896 run_lib.py:146] step: 174200, eval_loss: 2.77733e-02
I0209 05:59:45.979168 22542570456896 run_lib.py:133] step: 174250, training_loss: 2.81857e-02
I0209 06:00:03.420291 22542570456896 run_lib.py:133] step: 174300, training_loss: 2.34934e-02
I0209 06:00:03.578391 22542570456896 run_lib.py:146] step: 174300, eval_loss: 2.70419e-02
I0209 06:00:21.174766 22542570456896 run_lib.py:133] step: 174350, training_loss: 2.91726e-02
I0209 06:00:38.671472 22542570456896 run_lib.py:133] step: 174400, training_loss: 2.34349e-02
I0209 06:00:38.828133 22542570456896 run_lib.py:146] step: 174400, eval_loss: 2.68124e-02
I0209 06:00:56.275915 22542570456896 run_lib.py:133] step: 174450, training_loss: 2.02193e-02
I0209 06:01:13.679881 22542570456896 run_lib.py:133] step: 174500, training_loss: 2.46346e-02
I0209 06:01:13.832357 22542570456896 run_lib.py:146] step: 174500, eval_loss: 3.07522e-02
I0209 06:01:31.381861 22542570456896 run_lib.py:133] step: 174550, training_loss: 2.87771e-02
I0209 06:01:48.836370 22542570456896 run_lib.py:133] step: 174600, training_loss: 2.36523e-02
I0209 06:01:48.992567 22542570456896 run_lib.py:146] step: 174600, eval_loss: 2.62885e-02
I0209 06:02:06.591981 22542570456896 run_lib.py:133] step: 174650, training_loss: 2.67172e-02
I0209 06:02:23.998505 22542570456896 run_lib.py:133] step: 174700, training_loss: 2.99265e-02
I0209 06:02:24.156638 22542570456896 run_lib.py:146] step: 174700, eval_loss: 3.31451e-02
I0209 06:02:41.709959 22542570456896 run_lib.py:133] step: 174750, training_loss: 2.99522e-02
I0209 06:02:59.139466 22542570456896 run_lib.py:133] step: 174800, training_loss: 2.35429e-02
I0209 06:02:59.294660 22542570456896 run_lib.py:146] step: 174800, eval_loss: 3.03045e-02
I0209 06:03:16.877086 22542570456896 run_lib.py:133] step: 174850, training_loss: 2.87835e-02
I0209 06:03:34.312720 22542570456896 run_lib.py:133] step: 174900, training_loss: 2.61913e-02
I0209 06:03:34.468190 22542570456896 run_lib.py:146] step: 174900, eval_loss: 3.25039e-02
I0209 06:03:51.917167 22542570456896 run_lib.py:133] step: 174950, training_loss: 2.61530e-02
I0209 06:04:09.535378 22542570456896 run_lib.py:133] step: 175000, training_loss: 2.65889e-02
I0209 06:04:09.687457 22542570456896 run_lib.py:146] step: 175000, eval_loss: 3.35288e-02
I0209 06:04:27.079760 22542570456896 run_lib.py:133] step: 175050, training_loss: 2.72411e-02
I0209 06:04:44.543210 22542570456896 run_lib.py:133] step: 175100, training_loss: 2.45259e-02
I0209 06:04:44.706673 22542570456896 run_lib.py:146] step: 175100, eval_loss: 2.71932e-02
I0209 06:05:02.317505 22542570456896 run_lib.py:133] step: 175150, training_loss: 2.76609e-02
I0209 06:05:19.778094 22542570456896 run_lib.py:133] step: 175200, training_loss: 2.78707e-02
I0209 06:05:19.936231 22542570456896 run_lib.py:146] step: 175200, eval_loss: 3.05496e-02
I0209 06:05:37.537297 22542570456896 run_lib.py:133] step: 175250, training_loss: 2.18944e-02
I0209 06:05:54.967699 22542570456896 run_lib.py:133] step: 175300, training_loss: 3.05600e-02
I0209 06:05:55.124146 22542570456896 run_lib.py:146] step: 175300, eval_loss: 2.92780e-02
I0209 06:06:12.546471 22542570456896 run_lib.py:133] step: 175350, training_loss: 2.99364e-02
I0209 06:06:30.144666 22542570456896 run_lib.py:133] step: 175400, training_loss: 2.85585e-02
I0209 06:06:30.304592 22542570456896 run_lib.py:146] step: 175400, eval_loss: 2.85334e-02
I0209 06:06:47.757940 22542570456896 run_lib.py:133] step: 175450, training_loss: 2.96097e-02
I0209 06:07:05.184141 22542570456896 run_lib.py:133] step: 175500, training_loss: 2.58712e-02
I0209 06:07:05.333906 22542570456896 run_lib.py:146] step: 175500, eval_loss: 2.74724e-02
I0209 06:07:22.786057 22542570456896 run_lib.py:133] step: 175550, training_loss: 2.93450e-02
I0209 06:07:40.465316 22542570456896 run_lib.py:133] step: 175600, training_loss: 2.30354e-02
I0209 06:07:40.622318 22542570456896 run_lib.py:146] step: 175600, eval_loss: 2.69781e-02
I0209 06:07:58.020421 22542570456896 run_lib.py:133] step: 175650, training_loss: 3.08730e-02
I0209 06:08:15.514749 22542570456896 run_lib.py:133] step: 175700, training_loss: 2.50620e-02
I0209 06:08:15.690341 22542570456896 run_lib.py:146] step: 175700, eval_loss: 3.05387e-02
I0209 06:08:33.167604 22542570456896 run_lib.py:133] step: 175750, training_loss: 2.39435e-02
I0209 06:08:50.576705 22542570456896 run_lib.py:133] step: 175800, training_loss: 2.70332e-02
I0209 06:08:50.737298 22542570456896 run_lib.py:146] step: 175800, eval_loss: 3.66252e-02
I0209 06:09:08.361999 22542570456896 run_lib.py:133] step: 175850, training_loss: 3.06831e-02
I0209 06:09:25.857149 22542570456896 run_lib.py:133] step: 175900, training_loss: 2.60627e-02
I0209 06:09:26.011252 22542570456896 run_lib.py:146] step: 175900, eval_loss: 2.56182e-02
I0209 06:09:43.463809 22542570456896 run_lib.py:133] step: 175950, training_loss: 2.85588e-02
I0209 06:10:00.970380 22542570456896 run_lib.py:133] step: 176000, training_loss: 2.75002e-02
I0209 06:10:01.126285 22542570456896 run_lib.py:146] step: 176000, eval_loss: 2.98267e-02
I0209 06:10:18.779860 22542570456896 run_lib.py:133] step: 176050, training_loss: 3.05314e-02
I0209 06:10:36.233590 22542570456896 run_lib.py:133] step: 176100, training_loss: 2.32651e-02
I0209 06:10:36.391405 22542570456896 run_lib.py:146] step: 176100, eval_loss: 2.60223e-02
I0209 06:10:53.962216 22542570456896 run_lib.py:133] step: 176150, training_loss: 2.76367e-02
I0209 06:11:11.365123 22542570456896 run_lib.py:133] step: 176200, training_loss: 2.95485e-02
I0209 06:11:11.519006 22542570456896 run_lib.py:146] step: 176200, eval_loss: 3.11071e-02
I0209 06:11:29.095218 22542570456896 run_lib.py:133] step: 176250, training_loss: 4.02236e-02
I0209 06:11:46.590720 22542570456896 run_lib.py:133] step: 176300, training_loss: 3.05253e-02
I0209 06:11:46.746805 22542570456896 run_lib.py:146] step: 176300, eval_loss: 3.22775e-02
I0209 06:12:04.168035 22542570456896 run_lib.py:133] step: 176350, training_loss: 2.79128e-02
I0209 06:12:21.736510 22542570456896 run_lib.py:133] step: 176400, training_loss: 3.25660e-02
I0209 06:12:21.889938 22542570456896 run_lib.py:146] step: 176400, eval_loss: 2.65568e-02
I0209 06:12:39.303509 22542570456896 run_lib.py:133] step: 176450, training_loss: 3.53182e-02
I0209 06:12:56.835797 22542570456896 run_lib.py:133] step: 176500, training_loss: 2.92117e-02
I0209 06:12:56.988314 22542570456896 run_lib.py:146] step: 176500, eval_loss: 3.26429e-02
I0209 06:13:14.420098 22542570456896 run_lib.py:133] step: 176550, training_loss: 2.61187e-02
I0209 06:13:31.837048 22542570456896 run_lib.py:133] step: 176600, training_loss: 2.82510e-02
I0209 06:13:32.014269 22542570456896 run_lib.py:146] step: 176600, eval_loss: 2.77402e-02
I0209 06:13:49.571529 22542570456896 run_lib.py:133] step: 176650, training_loss: 3.71344e-02
I0209 06:14:06.940993 22542570456896 run_lib.py:133] step: 176700, training_loss: 3.15976e-02
I0209 06:14:07.096539 22542570456896 run_lib.py:146] step: 176700, eval_loss: 2.89325e-02
I0209 06:14:24.554292 22542570456896 run_lib.py:133] step: 176750, training_loss: 2.70712e-02
I0209 06:14:42.133303 22542570456896 run_lib.py:133] step: 176800, training_loss: 2.80654e-02
I0209 06:14:42.289293 22542570456896 run_lib.py:146] step: 176800, eval_loss: 3.03067e-02
I0209 06:14:59.724953 22542570456896 run_lib.py:133] step: 176850, training_loss: 3.66398e-02
I0209 06:15:17.180899 22542570456896 run_lib.py:133] step: 176900, training_loss: 3.39973e-02
I0209 06:15:17.524985 22542570456896 run_lib.py:146] step: 176900, eval_loss: 2.97650e-02
I0209 06:15:34.991045 22542570456896 run_lib.py:133] step: 176950, training_loss: 2.22277e-02
I0209 06:15:52.436800 22542570456896 run_lib.py:133] step: 177000, training_loss: 2.57378e-02
I0209 06:15:52.592556 22542570456896 run_lib.py:146] step: 177000, eval_loss: 2.78554e-02
I0209 06:16:09.992446 22542570456896 run_lib.py:133] step: 177050, training_loss: 2.64478e-02
I0209 06:16:27.375608 22542570456896 run_lib.py:133] step: 177100, training_loss: 2.79148e-02
I0209 06:16:27.532436 22542570456896 run_lib.py:146] step: 177100, eval_loss: 3.14972e-02
I0209 06:16:45.140060 22542570456896 run_lib.py:133] step: 177150, training_loss: 3.04513e-02
I0209 06:17:02.716794 22542570456896 run_lib.py:133] step: 177200, training_loss: 2.66387e-02
I0209 06:17:02.872559 22542570456896 run_lib.py:146] step: 177200, eval_loss: 3.38287e-02
I0209 06:17:20.297610 22542570456896 run_lib.py:133] step: 177250, training_loss: 3.27933e-02
I0209 06:17:37.730056 22542570456896 run_lib.py:133] step: 177300, training_loss: 2.31180e-02
I0209 06:17:37.886323 22542570456896 run_lib.py:146] step: 177300, eval_loss: 3.11632e-02
I0209 06:17:55.446690 22542570456896 run_lib.py:133] step: 177350, training_loss: 3.31432e-02
I0209 06:18:12.972038 22542570456896 run_lib.py:133] step: 177400, training_loss: 3.06030e-02
I0209 06:18:13.124601 22542570456896 run_lib.py:146] step: 177400, eval_loss: 3.22728e-02
I0209 06:18:30.616252 22542570456896 run_lib.py:133] step: 177450, training_loss: 2.61757e-02
I0209 06:18:48.037934 22542570456896 run_lib.py:133] step: 177500, training_loss: 2.47339e-02
I0209 06:18:48.193449 22542570456896 run_lib.py:146] step: 177500, eval_loss: 2.95725e-02
I0209 06:19:05.812637 22542570456896 run_lib.py:133] step: 177550, training_loss: 2.64635e-02
I0209 06:19:23.234116 22542570456896 run_lib.py:133] step: 177600, training_loss: 2.91242e-02
I0209 06:19:23.392529 22542570456896 run_lib.py:146] step: 177600, eval_loss: 2.51258e-02
I0209 06:19:40.998341 22542570456896 run_lib.py:133] step: 177650, training_loss: 3.10355e-02
I0209 06:19:58.473711 22542570456896 run_lib.py:133] step: 177700, training_loss: 3.02352e-02
I0209 06:19:58.628229 22542570456896 run_lib.py:146] step: 177700, eval_loss: 3.09442e-02
I0209 06:20:16.241748 22542570456896 run_lib.py:133] step: 177750, training_loss: 3.05169e-02
I0209 06:20:33.653418 22542570456896 run_lib.py:133] step: 177800, training_loss: 3.03577e-02
I0209 06:20:33.809349 22542570456896 run_lib.py:146] step: 177800, eval_loss: 3.20748e-02
I0209 06:20:51.256994 22542570456896 run_lib.py:133] step: 177850, training_loss: 2.58131e-02
I0209 06:21:08.838038 22542570456896 run_lib.py:133] step: 177900, training_loss: 2.55818e-02
I0209 06:21:08.989300 22542570456896 run_lib.py:146] step: 177900, eval_loss: 2.89754e-02
I0209 06:21:26.394458 22542570456896 run_lib.py:133] step: 177950, training_loss: 1.85489e-02
I0209 06:21:43.939268 22542570456896 run_lib.py:133] step: 178000, training_loss: 3.49353e-02
I0209 06:21:44.113187 22542570456896 run_lib.py:146] step: 178000, eval_loss: 2.83064e-02
I0209 06:22:01.569546 22542570456896 run_lib.py:133] step: 178050, training_loss: 2.57501e-02
I0209 06:22:19.022192 22542570456896 run_lib.py:133] step: 178100, training_loss: 2.46992e-02
I0209 06:22:19.181534 22542570456896 run_lib.py:146] step: 178100, eval_loss: 2.54089e-02
I0209 06:22:36.751287 22542570456896 run_lib.py:133] step: 178150, training_loss: 2.38011e-02
I0209 06:22:54.140195 22542570456896 run_lib.py:133] step: 178200, training_loss: 3.32280e-02
I0209 06:22:54.295040 22542570456896 run_lib.py:146] step: 178200, eval_loss: 3.35198e-02
I0209 06:23:11.719563 22542570456896 run_lib.py:133] step: 178250, training_loss: 2.80898e-02
I0209 06:23:29.143438 22542570456896 run_lib.py:133] step: 178300, training_loss: 2.50869e-02
I0209 06:23:29.298130 22542570456896 run_lib.py:146] step: 178300, eval_loss: 3.04899e-02
I0209 06:23:46.928542 22542570456896 run_lib.py:133] step: 178350, training_loss: 2.50943e-02
I0209 06:24:04.345852 22542570456896 run_lib.py:133] step: 178400, training_loss: 2.86066e-02
I0209 06:24:04.498474 22542570456896 run_lib.py:146] step: 178400, eval_loss: 2.32897e-02
I0209 06:24:22.019716 22542570456896 run_lib.py:133] step: 178450, training_loss: 2.52126e-02
I0209 06:24:39.462517 22542570456896 run_lib.py:133] step: 178500, training_loss: 3.42536e-02
I0209 06:24:39.621569 22542570456896 run_lib.py:146] step: 178500, eval_loss: 3.13712e-02
I0209 06:24:57.029038 22542570456896 run_lib.py:133] step: 178550, training_loss: 2.98269e-02
I0209 06:25:14.473655 22542570456896 run_lib.py:133] step: 178600, training_loss: 2.18608e-02
I0209 06:25:14.637869 22542570456896 run_lib.py:146] step: 178600, eval_loss: 3.17839e-02
I0209 06:25:32.236555 22542570456896 run_lib.py:133] step: 178650, training_loss: 2.93251e-02
I0209 06:25:49.726172 22542570456896 run_lib.py:133] step: 178700, training_loss: 3.51800e-02
I0209 06:25:49.883628 22542570456896 run_lib.py:146] step: 178700, eval_loss: 2.75046e-02
I0209 06:26:07.301817 22542570456896 run_lib.py:133] step: 178750, training_loss: 3.33435e-02
I0209 06:26:24.718945 22542570456896 run_lib.py:133] step: 178800, training_loss: 2.97115e-02
I0209 06:26:24.870208 22542570456896 run_lib.py:146] step: 178800, eval_loss: 2.56773e-02
I0209 06:26:42.442825 22542570456896 run_lib.py:133] step: 178850, training_loss: 2.56961e-02
I0209 06:26:59.936421 22542570456896 run_lib.py:133] step: 178900, training_loss: 2.75664e-02
I0209 06:27:00.104701 22542570456896 run_lib.py:146] step: 178900, eval_loss: 2.88368e-02
I0209 06:27:17.774955 22542570456896 run_lib.py:133] step: 178950, training_loss: 2.91607e-02
I0209 06:27:35.208272 22542570456896 run_lib.py:133] step: 179000, training_loss: 2.95594e-02
I0209 06:27:35.365648 22542570456896 run_lib.py:146] step: 179000, eval_loss: 3.14844e-02
I0209 06:27:52.894926 22542570456896 run_lib.py:133] step: 179050, training_loss: 2.22274e-02
I0209 06:28:10.316802 22542570456896 run_lib.py:133] step: 179100, training_loss: 2.53508e-02
I0209 06:28:10.483287 22542570456896 run_lib.py:146] step: 179100, eval_loss: 2.99395e-02
I0209 06:28:28.062871 22542570456896 run_lib.py:133] step: 179150, training_loss: 3.06053e-02
I0209 06:28:45.557336 22542570456896 run_lib.py:133] step: 179200, training_loss: 2.45089e-02
I0209 06:28:45.721624 22542570456896 run_lib.py:146] step: 179200, eval_loss: 2.90127e-02
I0209 06:29:03.183184 22542570456896 run_lib.py:133] step: 179250, training_loss: 3.04008e-02
I0209 06:29:20.766212 22542570456896 run_lib.py:133] step: 179300, training_loss: 2.90572e-02
I0209 06:29:20.922367 22542570456896 run_lib.py:146] step: 179300, eval_loss: 2.97226e-02
I0209 06:29:38.320490 22542570456896 run_lib.py:133] step: 179350, training_loss: 3.20131e-02
I0209 06:29:55.714980 22542570456896 run_lib.py:133] step: 179400, training_loss: 2.57740e-02
I0209 06:29:55.883191 22542570456896 run_lib.py:146] step: 179400, eval_loss: 2.69056e-02
I0209 06:30:13.529433 22542570456896 run_lib.py:133] step: 179450, training_loss: 3.21949e-02
I0209 06:30:31.127180 22542570456896 run_lib.py:133] step: 179500, training_loss: 3.46569e-02
I0209 06:30:31.293355 22542570456896 run_lib.py:146] step: 179500, eval_loss: 1.99818e-02
I0209 06:30:48.689883 22542570456896 run_lib.py:133] step: 179550, training_loss: 3.02955e-02
I0209 06:31:06.072146 22542570456896 run_lib.py:133] step: 179600, training_loss: 2.65084e-02
I0209 06:31:06.227359 22542570456896 run_lib.py:146] step: 179600, eval_loss: 3.03590e-02
I0209 06:31:23.637393 22542570456896 run_lib.py:133] step: 179650, training_loss: 2.89358e-02
I0209 06:31:41.220000 22542570456896 run_lib.py:133] step: 179700, training_loss: 2.15324e-02
I0209 06:31:41.373627 22542570456896 run_lib.py:146] step: 179700, eval_loss: 3.05889e-02
I0209 06:31:58.854208 22542570456896 run_lib.py:133] step: 179750, training_loss: 2.37395e-02
I0209 06:32:16.259053 22542570456896 run_lib.py:133] step: 179800, training_loss: 2.20530e-02
I0209 06:32:16.410532 22542570456896 run_lib.py:146] step: 179800, eval_loss: 2.69451e-02
I0209 06:32:33.858375 22542570456896 run_lib.py:133] step: 179850, training_loss: 3.26807e-02
I0209 06:32:51.472594 22542570456896 run_lib.py:133] step: 179900, training_loss: 3.15599e-02
I0209 06:32:51.632821 22542570456896 run_lib.py:146] step: 179900, eval_loss: 2.96111e-02
I0209 06:33:09.046780 22542570456896 run_lib.py:133] step: 179950, training_loss: 2.76972e-02
I0209 06:33:26.528300 22542570456896 run_lib.py:133] step: 180000, training_loss: 2.63172e-02
I0209 06:33:27.239914 22542570456896 run_lib.py:146] step: 180000, eval_loss: 3.70604e-02
I0209 06:33:47.419286 22542570456896 run_lib.py:133] step: 180050, training_loss: 2.71037e-02
I0209 06:34:04.836526 22542570456896 run_lib.py:133] step: 180100, training_loss: 2.51655e-02
I0209 06:34:04.992585 22542570456896 run_lib.py:146] step: 180100, eval_loss: 3.34091e-02
I0209 06:34:22.419943 22542570456896 run_lib.py:133] step: 180150, training_loss: 2.80751e-02
I0209 06:34:39.995225 22542570456896 run_lib.py:133] step: 180200, training_loss: 2.54043e-02
I0209 06:34:40.153660 22542570456896 run_lib.py:146] step: 180200, eval_loss: 2.94697e-02
I0209 06:34:57.587880 22542570456896 run_lib.py:133] step: 180250, training_loss: 2.77792e-02
I0209 06:35:15.158270 22542570456896 run_lib.py:133] step: 180300, training_loss: 2.38698e-02
I0209 06:35:15.312668 22542570456896 run_lib.py:146] step: 180300, eval_loss: 2.75172e-02
I0209 06:35:32.761896 22542570456896 run_lib.py:133] step: 180350, training_loss: 2.61668e-02
I0209 06:35:50.224640 22542570456896 run_lib.py:133] step: 180400, training_loss: 2.97748e-02
I0209 06:35:50.380887 22542570456896 run_lib.py:146] step: 180400, eval_loss: 3.13327e-02
I0209 06:36:07.968531 22542570456896 run_lib.py:133] step: 180450, training_loss: 3.60605e-02
I0209 06:36:25.453771 22542570456896 run_lib.py:133] step: 180500, training_loss: 2.56162e-02
I0209 06:36:25.628613 22542570456896 run_lib.py:146] step: 180500, eval_loss: 3.55055e-02
I0209 06:36:43.073281 22542570456896 run_lib.py:133] step: 180550, training_loss: 2.15395e-02
I0209 06:37:00.508191 22542570456896 run_lib.py:133] step: 180600, training_loss: 2.56664e-02
I0209 06:37:00.664744 22542570456896 run_lib.py:146] step: 180600, eval_loss: 3.84773e-02
I0209 06:37:18.276328 22542570456896 run_lib.py:133] step: 180650, training_loss: 2.73493e-02
I0209 06:37:35.666160 22542570456896 run_lib.py:133] step: 180700, training_loss: 2.33579e-02
I0209 06:37:35.821051 22542570456896 run_lib.py:146] step: 180700, eval_loss: 2.88317e-02
I0209 06:37:53.351379 22542570456896 run_lib.py:133] step: 180750, training_loss: 2.48300e-02
I0209 06:38:10.774368 22542570456896 run_lib.py:133] step: 180800, training_loss: 2.27798e-02
I0209 06:38:10.936285 22542570456896 run_lib.py:146] step: 180800, eval_loss: 2.46182e-02
I0209 06:38:28.579319 22542570456896 run_lib.py:133] step: 180850, training_loss: 2.44092e-02
I0209 06:38:45.994866 22542570456896 run_lib.py:133] step: 180900, training_loss: 2.55571e-02
I0209 06:38:46.147413 22542570456896 run_lib.py:146] step: 180900, eval_loss: 2.47393e-02
I0209 06:39:03.565471 22542570456896 run_lib.py:133] step: 180950, training_loss: 1.87079e-02
I0209 06:39:21.175261 22542570456896 run_lib.py:133] step: 181000, training_loss: 2.70198e-02
I0209 06:39:21.333639 22542570456896 run_lib.py:146] step: 181000, eval_loss: 2.71166e-02
I0209 06:39:38.766304 22542570456896 run_lib.py:133] step: 181050, training_loss: 2.87107e-02
I0209 06:39:56.329073 22542570456896 run_lib.py:133] step: 181100, training_loss: 3.35741e-02
I0209 06:39:56.498360 22542570456896 run_lib.py:146] step: 181100, eval_loss: 3.32847e-02
I0209 06:40:13.952031 22542570456896 run_lib.py:133] step: 181150, training_loss: 2.86479e-02
I0209 06:40:31.415755 22542570456896 run_lib.py:133] step: 181200, training_loss: 2.71082e-02
I0209 06:40:31.572511 22542570456896 run_lib.py:146] step: 181200, eval_loss: 2.46657e-02
I0209 06:40:49.189002 22542570456896 run_lib.py:133] step: 181250, training_loss: 2.63338e-02
I0209 06:41:06.611667 22542570456896 run_lib.py:133] step: 181300, training_loss: 2.73072e-02
I0209 06:41:06.763639 22542570456896 run_lib.py:146] step: 181300, eval_loss: 3.54423e-02
I0209 06:41:24.188508 22542570456896 run_lib.py:133] step: 181350, training_loss: 2.62726e-02
I0209 06:41:41.759922 22542570456896 run_lib.py:133] step: 181400, training_loss: 3.27660e-02
I0209 06:41:41.934372 22542570456896 run_lib.py:146] step: 181400, eval_loss: 3.49231e-02
I0209 06:41:59.424295 22542570456896 run_lib.py:133] step: 181450, training_loss: 2.53333e-02
I0209 06:42:16.863706 22542570456896 run_lib.py:133] step: 181500, training_loss: 2.24871e-02
I0209 06:42:17.018307 22542570456896 run_lib.py:146] step: 181500, eval_loss: 2.69652e-02
I0209 06:42:34.558526 22542570456896 run_lib.py:133] step: 181550, training_loss: 3.01608e-02
I0209 06:42:52.036711 22542570456896 run_lib.py:133] step: 181600, training_loss: 2.74063e-02
I0209 06:42:52.193546 22542570456896 run_lib.py:146] step: 181600, eval_loss: 2.81445e-02
I0209 06:43:09.619302 22542570456896 run_lib.py:133] step: 181650, training_loss: 2.96260e-02
I0209 06:43:27.043813 22542570456896 run_lib.py:133] step: 181700, training_loss: 3.09100e-02
I0209 06:43:27.201483 22542570456896 run_lib.py:146] step: 181700, eval_loss: 2.10929e-02
I0209 06:43:44.815011 22542570456896 run_lib.py:133] step: 181750, training_loss: 3.20269e-02
I0209 06:44:02.373010 22542570456896 run_lib.py:133] step: 181800, training_loss: 2.71797e-02
I0209 06:44:02.527325 22542570456896 run_lib.py:146] step: 181800, eval_loss: 3.23744e-02
I0209 06:44:19.963063 22542570456896 run_lib.py:133] step: 181850, training_loss: 3.30576e-02
I0209 06:44:37.393134 22542570456896 run_lib.py:133] step: 181900, training_loss: 3.02433e-02
I0209 06:44:37.551694 22542570456896 run_lib.py:146] step: 181900, eval_loss: 2.98692e-02
I0209 06:44:55.088629 22542570456896 run_lib.py:133] step: 181950, training_loss: 2.54586e-02
I0209 06:45:12.537722 22542570456896 run_lib.py:133] step: 182000, training_loss: 2.92861e-02
I0209 06:45:12.708606 22542570456896 run_lib.py:146] step: 182000, eval_loss: 2.41455e-02
I0209 06:45:30.340792 22542570456896 run_lib.py:133] step: 182050, training_loss: 3.52760e-02
I0209 06:45:47.791171 22542570456896 run_lib.py:133] step: 182100, training_loss: 2.95184e-02
I0209 06:45:47.954766 22542570456896 run_lib.py:146] step: 182100, eval_loss: 2.52479e-02
I0209 06:46:05.583203 22542570456896 run_lib.py:133] step: 182150, training_loss: 3.00513e-02
I0209 06:46:23.006672 22542570456896 run_lib.py:133] step: 182200, training_loss: 2.58504e-02
I0209 06:46:23.159117 22542570456896 run_lib.py:146] step: 182200, eval_loss: 3.47679e-02
I0209 06:46:40.718507 22542570456896 run_lib.py:133] step: 182250, training_loss: 3.41413e-02
I0209 06:46:58.201516 22542570456896 run_lib.py:133] step: 182300, training_loss: 3.24415e-02
I0209 06:46:58.368506 22542570456896 run_lib.py:146] step: 182300, eval_loss: 3.05769e-02
I0209 06:47:15.822105 22542570456896 run_lib.py:133] step: 182350, training_loss: 2.90204e-02
I0209 06:47:33.506680 22542570456896 run_lib.py:133] step: 182400, training_loss: 2.96042e-02
I0209 06:47:33.662573 22542570456896 run_lib.py:146] step: 182400, eval_loss: 2.53450e-02
I0209 06:47:51.092919 22542570456896 run_lib.py:133] step: 182450, training_loss: 2.44702e-02
I0209 06:48:08.505361 22542570456896 run_lib.py:133] step: 182500, training_loss: 2.14044e-02
I0209 06:48:08.661545 22542570456896 run_lib.py:146] step: 182500, eval_loss: 2.72961e-02
I0209 06:48:26.208683 22542570456896 run_lib.py:133] step: 182550, training_loss: 3.05489e-02
I0209 06:48:43.734226 22542570456896 run_lib.py:133] step: 182600, training_loss: 1.78251e-02
I0209 06:48:43.889505 22542570456896 run_lib.py:146] step: 182600, eval_loss: 2.33675e-02
I0209 06:49:01.524191 22542570456896 run_lib.py:133] step: 182650, training_loss: 3.03624e-02
I0209 06:49:18.949956 22542570456896 run_lib.py:133] step: 182700, training_loss: 2.34884e-02
I0209 06:49:19.103394 22542570456896 run_lib.py:146] step: 182700, eval_loss: 2.99455e-02
I0209 06:49:36.547246 22542570456896 run_lib.py:133] step: 182750, training_loss: 2.65892e-02
I0209 06:49:54.134629 22542570456896 run_lib.py:133] step: 182800, training_loss: 2.60889e-02
I0209 06:49:54.304620 22542570456896 run_lib.py:146] step: 182800, eval_loss: 2.81766e-02
I0209 06:50:11.765734 22542570456896 run_lib.py:133] step: 182850, training_loss: 2.87872e-02
I0209 06:50:29.210558 22542570456896 run_lib.py:133] step: 182900, training_loss: 2.38956e-02
I0209 06:50:29.370562 22542570456896 run_lib.py:146] step: 182900, eval_loss: 2.75962e-02
I0209 06:50:46.778011 22542570456896 run_lib.py:133] step: 182950, training_loss: 2.54823e-02
I0209 06:51:04.368545 22542570456896 run_lib.py:133] step: 183000, training_loss: 2.77273e-02
I0209 06:51:04.524087 22542570456896 run_lib.py:146] step: 183000, eval_loss: 3.51670e-02
I0209 06:51:21.933641 22542570456896 run_lib.py:133] step: 183050, training_loss: 2.93373e-02
I0209 06:51:39.449436 22542570456896 run_lib.py:133] step: 183100, training_loss: 2.85041e-02
I0209 06:51:39.606614 22542570456896 run_lib.py:146] step: 183100, eval_loss: 2.73949e-02
I0209 06:51:57.113833 22542570456896 run_lib.py:133] step: 183150, training_loss: 3.18741e-02
I0209 06:52:14.533268 22542570456896 run_lib.py:133] step: 183200, training_loss: 3.20963e-02
I0209 06:52:14.688297 22542570456896 run_lib.py:146] step: 183200, eval_loss: 2.73043e-02
I0209 06:52:32.274414 22542570456896 run_lib.py:133] step: 183250, training_loss: 2.64208e-02
I0209 06:52:49.758910 22542570456896 run_lib.py:133] step: 183300, training_loss: 2.85749e-02
I0209 06:52:49.917708 22542570456896 run_lib.py:146] step: 183300, eval_loss: 2.98995e-02
I0209 06:53:07.302690 22542570456896 run_lib.py:133] step: 183350, training_loss: 2.91922e-02
I0209 06:53:24.732858 22542570456896 run_lib.py:133] step: 183400, training_loss: 2.83452e-02
I0209 06:53:24.899235 22542570456896 run_lib.py:146] step: 183400, eval_loss: 2.56308e-02
I0209 06:53:42.527741 22542570456896 run_lib.py:133] step: 183450, training_loss: 2.36225e-02
I0209 06:53:59.995939 22542570456896 run_lib.py:133] step: 183500, training_loss: 2.94799e-02
I0209 06:54:00.160492 22542570456896 run_lib.py:146] step: 183500, eval_loss: 2.53073e-02
I0209 06:54:17.761589 22542570456896 run_lib.py:133] step: 183550, training_loss: 2.94825e-02
I0209 06:54:35.195972 22542570456896 run_lib.py:133] step: 183600, training_loss: 2.36043e-02
I0209 06:54:35.348162 22542570456896 run_lib.py:146] step: 183600, eval_loss: 3.32839e-02
I0209 06:54:52.938417 22542570456896 run_lib.py:133] step: 183650, training_loss: 2.47380e-02
I0209 06:55:10.392603 22542570456896 run_lib.py:133] step: 183700, training_loss: 2.75237e-02
I0209 06:55:10.553541 22542570456896 run_lib.py:146] step: 183700, eval_loss: 2.97173e-02
I0209 06:55:28.047334 22542570456896 run_lib.py:133] step: 183750, training_loss: 2.89349e-02
I0209 06:55:45.709382 22542570456896 run_lib.py:133] step: 183800, training_loss: 2.11901e-02
I0209 06:55:45.876190 22542570456896 run_lib.py:146] step: 183800, eval_loss: 2.59589e-02
I0209 06:56:03.310254 22542570456896 run_lib.py:133] step: 183850, training_loss: 2.56817e-02
I0209 06:56:20.891419 22542570456896 run_lib.py:133] step: 183900, training_loss: 2.25136e-02
I0209 06:56:21.057146 22542570456896 run_lib.py:146] step: 183900, eval_loss: 3.11767e-02
I0209 06:56:38.522950 22542570456896 run_lib.py:133] step: 183950, training_loss: 3.19137e-02
I0209 06:56:55.997349 22542570456896 run_lib.py:133] step: 184000, training_loss: 2.17740e-02
I0209 06:56:56.153732 22542570456896 run_lib.py:146] step: 184000, eval_loss: 2.37255e-02
I0209 06:57:13.769358 22542570456896 run_lib.py:133] step: 184050, training_loss: 2.87901e-02
I0209 06:57:31.188156 22542570456896 run_lib.py:133] step: 184100, training_loss: 2.95883e-02
I0209 06:57:31.340331 22542570456896 run_lib.py:146] step: 184100, eval_loss: 2.45357e-02
I0209 06:57:48.762151 22542570456896 run_lib.py:133] step: 184150, training_loss: 2.06001e-02
I0209 06:58:06.338711 22542570456896 run_lib.py:133] step: 184200, training_loss: 3.08183e-02
I0209 06:58:06.509662 22542570456896 run_lib.py:146] step: 184200, eval_loss: 3.08580e-02
I0209 06:58:23.994391 22542570456896 run_lib.py:133] step: 184250, training_loss: 3.21216e-02
I0209 06:58:41.497867 22542570456896 run_lib.py:133] step: 184300, training_loss: 2.84110e-02
I0209 06:58:41.849358 22542570456896 run_lib.py:146] step: 184300, eval_loss: 2.55963e-02
I0209 06:58:59.281253 22542570456896 run_lib.py:133] step: 184350, training_loss: 3.30707e-02
I0209 06:59:16.703511 22542570456896 run_lib.py:133] step: 184400, training_loss: 2.35934e-02
I0209 06:59:16.859328 22542570456896 run_lib.py:146] step: 184400, eval_loss: 3.15640e-02
I0209 06:59:34.276576 22542570456896 run_lib.py:133] step: 184450, training_loss: 2.25914e-02
I0209 06:59:51.738504 22542570456896 run_lib.py:133] step: 184500, training_loss: 2.95476e-02
I0209 06:59:51.895708 22542570456896 run_lib.py:146] step: 184500, eval_loss: 3.04368e-02
I0209 07:00:09.564967 22542570456896 run_lib.py:133] step: 184550, training_loss: 2.56577e-02
I0209 07:00:27.028003 22542570456896 run_lib.py:133] step: 184600, training_loss: 3.20277e-02
I0209 07:00:27.178433 22542570456896 run_lib.py:146] step: 184600, eval_loss: 3.13836e-02
I0209 07:00:44.585101 22542570456896 run_lib.py:133] step: 184650, training_loss: 3.20352e-02
I0209 07:01:02.045780 22542570456896 run_lib.py:133] step: 184700, training_loss: 3.88514e-02
I0209 07:01:02.209931 22542570456896 run_lib.py:146] step: 184700, eval_loss: 3.46048e-02
I0209 07:01:19.779385 22542570456896 run_lib.py:133] step: 184750, training_loss: 2.49392e-02
I0209 07:01:37.381454 22542570456896 run_lib.py:133] step: 184800, training_loss: 2.78142e-02
I0209 07:01:37.548194 22542570456896 run_lib.py:146] step: 184800, eval_loss: 2.69023e-02
I0209 07:01:54.989377 22542570456896 run_lib.py:133] step: 184850, training_loss: 2.84124e-02
I0209 07:02:12.392094 22542570456896 run_lib.py:133] step: 184900, training_loss: 3.14450e-02
I0209 07:02:12.547563 22542570456896 run_lib.py:146] step: 184900, eval_loss: 2.68802e-02
I0209 07:02:30.102591 22542570456896 run_lib.py:133] step: 184950, training_loss: 2.74527e-02
I0209 07:02:47.511575 22542570456896 run_lib.py:133] step: 185000, training_loss: 2.65802e-02
I0209 07:02:47.666423 22542570456896 run_lib.py:146] step: 185000, eval_loss: 2.76187e-02
I0209 07:03:05.257652 22542570456896 run_lib.py:133] step: 185050, training_loss: 2.49805e-02
I0209 07:03:22.718484 22542570456896 run_lib.py:133] step: 185100, training_loss: 2.67319e-02
I0209 07:03:22.873519 22542570456896 run_lib.py:146] step: 185100, eval_loss: 2.01414e-02
I0209 07:03:40.570043 22542570456896 run_lib.py:133] step: 185150, training_loss: 2.76281e-02
I0209 07:03:58.020328 22542570456896 run_lib.py:133] step: 185200, training_loss: 2.65326e-02
I0209 07:03:58.179205 22542570456896 run_lib.py:146] step: 185200, eval_loss: 2.54203e-02
I0209 07:04:15.603727 22542570456896 run_lib.py:133] step: 185250, training_loss: 2.74392e-02
I0209 07:04:33.157843 22542570456896 run_lib.py:133] step: 185300, training_loss: 2.42224e-02
I0209 07:04:33.313452 22542570456896 run_lib.py:146] step: 185300, eval_loss: 3.43519e-02
I0209 07:04:50.756998 22542570456896 run_lib.py:133] step: 185350, training_loss: 2.38734e-02
I0209 07:05:08.409543 22542570456896 run_lib.py:133] step: 185400, training_loss: 2.82500e-02
I0209 07:05:08.567181 22542570456896 run_lib.py:146] step: 185400, eval_loss: 2.70807e-02
I0209 07:05:26.025251 22542570456896 run_lib.py:133] step: 185450, training_loss: 2.78086e-02
I0209 07:05:43.478567 22542570456896 run_lib.py:133] step: 185500, training_loss: 2.69700e-02
I0209 07:05:43.632075 22542570456896 run_lib.py:146] step: 185500, eval_loss: 3.55138e-02
I0209 07:06:01.258243 22542570456896 run_lib.py:133] step: 185550, training_loss: 3.04475e-02
I0209 07:06:18.695930 22542570456896 run_lib.py:133] step: 185600, training_loss: 2.90318e-02
I0209 07:06:18.850639 22542570456896 run_lib.py:146] step: 185600, eval_loss: 3.10002e-02
I0209 07:06:36.318086 22542570456896 run_lib.py:133] step: 185650, training_loss: 2.88038e-02
I0209 07:06:53.803292 22542570456896 run_lib.py:133] step: 185700, training_loss: 2.98972e-02
I0209 07:06:53.963403 22542570456896 run_lib.py:146] step: 185700, eval_loss: 2.13785e-02
I0209 07:07:11.554872 22542570456896 run_lib.py:133] step: 185750, training_loss: 3.09400e-02
I0209 07:07:28.984668 22542570456896 run_lib.py:133] step: 185800, training_loss: 2.63875e-02
I0209 07:07:29.145408 22542570456896 run_lib.py:146] step: 185800, eval_loss: 3.52234e-02
I0209 07:07:46.671073 22542570456896 run_lib.py:133] step: 185850, training_loss: 2.92557e-02
I0209 07:08:04.157218 22542570456896 run_lib.py:133] step: 185900, training_loss: 3.38415e-02
I0209 07:08:04.317684 22542570456896 run_lib.py:146] step: 185900, eval_loss: 2.79189e-02
I0209 07:08:21.824272 22542570456896 run_lib.py:133] step: 185950, training_loss: 2.38510e-02
I0209 07:08:39.222447 22542570456896 run_lib.py:133] step: 186000, training_loss: 3.03766e-02
I0209 07:08:39.374420 22542570456896 run_lib.py:146] step: 186000, eval_loss: 2.70759e-02
I0209 07:08:56.968952 22542570456896 run_lib.py:133] step: 186050, training_loss: 3.56915e-02
I0209 07:09:14.444957 22542570456896 run_lib.py:133] step: 186100, training_loss: 2.86367e-02
I0209 07:09:14.597678 22542570456896 run_lib.py:146] step: 186100, eval_loss: 2.95086e-02
I0209 07:09:32.005519 22542570456896 run_lib.py:133] step: 186150, training_loss: 3.14170e-02
I0209 07:09:49.457612 22542570456896 run_lib.py:133] step: 186200, training_loss: 2.46398e-02
I0209 07:09:49.621484 22542570456896 run_lib.py:146] step: 186200, eval_loss: 3.19457e-02
I0209 07:10:07.277522 22542570456896 run_lib.py:133] step: 186250, training_loss: 3.15490e-02
I0209 07:10:24.742678 22542570456896 run_lib.py:133] step: 186300, training_loss: 2.73725e-02
I0209 07:10:24.898699 22542570456896 run_lib.py:146] step: 186300, eval_loss: 2.96115e-02
I0209 07:10:42.483800 22542570456896 run_lib.py:133] step: 186350, training_loss: 2.58135e-02
I0209 07:10:59.899097 22542570456896 run_lib.py:133] step: 186400, training_loss: 2.13484e-02
I0209 07:11:00.052405 22542570456896 run_lib.py:146] step: 186400, eval_loss: 2.89918e-02
I0209 07:11:17.599298 22542570456896 run_lib.py:133] step: 186450, training_loss: 2.75161e-02
I0209 07:11:35.025080 22542570456896 run_lib.py:133] step: 186500, training_loss: 2.91714e-02
I0209 07:11:35.190521 22542570456896 run_lib.py:146] step: 186500, eval_loss: 2.17158e-02
I0209 07:11:52.838537 22542570456896 run_lib.py:133] step: 186550, training_loss: 2.56764e-02
I0209 07:12:10.243727 22542570456896 run_lib.py:133] step: 186600, training_loss: 3.04156e-02
I0209 07:12:10.398307 22542570456896 run_lib.py:146] step: 186600, eval_loss: 3.41953e-02
I0209 07:12:27.815996 22542570456896 run_lib.py:133] step: 186650, training_loss: 2.80819e-02
I0209 07:12:45.390192 22542570456896 run_lib.py:133] step: 186700, training_loss: 3.08457e-02
I0209 07:12:45.556656 22542570456896 run_lib.py:146] step: 186700, eval_loss: 2.91146e-02
I0209 07:13:03.002126 22542570456896 run_lib.py:133] step: 186750, training_loss: 2.83198e-02
I0209 07:13:20.462660 22542570456896 run_lib.py:133] step: 186800, training_loss: 3.21124e-02
I0209 07:13:20.622098 22542570456896 run_lib.py:146] step: 186800, eval_loss: 3.50409e-02
I0209 07:13:38.247455 22542570456896 run_lib.py:133] step: 186850, training_loss: 3.28894e-02
I0209 07:13:55.884400 22542570456896 run_lib.py:133] step: 186900, training_loss: 3.27257e-02
I0209 07:13:56.039381 22542570456896 run_lib.py:146] step: 186900, eval_loss: 3.03687e-02
I0209 07:14:13.448045 22542570456896 run_lib.py:133] step: 186950, training_loss: 2.60919e-02
I0209 07:14:30.906874 22542570456896 run_lib.py:133] step: 187000, training_loss: 2.12936e-02
I0209 07:14:31.059142 22542570456896 run_lib.py:146] step: 187000, eval_loss: 2.47097e-02
I0209 07:14:48.468778 22542570456896 run_lib.py:133] step: 187050, training_loss: 2.07322e-02
I0209 07:15:06.039966 22542570456896 run_lib.py:133] step: 187100, training_loss: 2.96648e-02
I0209 07:15:06.213333 22542570456896 run_lib.py:146] step: 187100, eval_loss: 2.78483e-02
I0209 07:15:23.621398 22542570456896 run_lib.py:133] step: 187150, training_loss: 2.07605e-02
I0209 07:15:41.033037 22542570456896 run_lib.py:133] step: 187200, training_loss: 3.15376e-02
I0209 07:15:41.189549 22542570456896 run_lib.py:146] step: 187200, eval_loss: 2.51057e-02
I0209 07:15:58.616463 22542570456896 run_lib.py:133] step: 187250, training_loss: 2.30000e-02
I0209 07:16:16.205750 22542570456896 run_lib.py:133] step: 187300, training_loss: 2.07140e-02
I0209 07:16:16.359491 22542570456896 run_lib.py:146] step: 187300, eval_loss: 2.93784e-02
I0209 07:16:33.808464 22542570456896 run_lib.py:133] step: 187350, training_loss: 2.89633e-02
I0209 07:16:51.311596 22542570456896 run_lib.py:133] step: 187400, training_loss: 2.79416e-02
I0209 07:16:51.464956 22542570456896 run_lib.py:146] step: 187400, eval_loss: 3.15105e-02
I0209 07:17:08.969014 22542570456896 run_lib.py:133] step: 187450, training_loss: 2.76646e-02
I0209 07:17:26.392585 22542570456896 run_lib.py:133] step: 187500, training_loss: 2.51670e-02
I0209 07:17:26.552085 22542570456896 run_lib.py:146] step: 187500, eval_loss: 2.50849e-02
I0209 07:17:44.139641 22542570456896 run_lib.py:133] step: 187550, training_loss: 2.46773e-02
I0209 07:18:01.668656 22542570456896 run_lib.py:133] step: 187600, training_loss: 2.94750e-02
I0209 07:18:01.828552 22542570456896 run_lib.py:146] step: 187600, eval_loss: 3.54307e-02
I0209 07:18:19.262383 22542570456896 run_lib.py:133] step: 187650, training_loss: 2.65860e-02
I0209 07:18:36.722307 22542570456896 run_lib.py:133] step: 187700, training_loss: 1.87709e-02
I0209 07:18:36.883551 22542570456896 run_lib.py:146] step: 187700, eval_loss: 3.20013e-02
I0209 07:18:54.512961 22542570456896 run_lib.py:133] step: 187750, training_loss: 3.48700e-02
I0209 07:19:11.968343 22542570456896 run_lib.py:133] step: 187800, training_loss: 2.77679e-02
I0209 07:19:12.123293 22542570456896 run_lib.py:146] step: 187800, eval_loss: 2.69452e-02
I0209 07:19:29.713246 22542570456896 run_lib.py:133] step: 187850, training_loss: 2.65396e-02
I0209 07:19:47.156771 22542570456896 run_lib.py:133] step: 187900, training_loss: 2.39286e-02
I0209 07:19:47.307388 22542570456896 run_lib.py:146] step: 187900, eval_loss: 2.67799e-02
I0209 07:20:04.850214 22542570456896 run_lib.py:133] step: 187950, training_loss: 3.62007e-02
I0209 07:20:22.312566 22542570456896 run_lib.py:133] step: 188000, training_loss: 2.35535e-02
I0209 07:20:22.482620 22542570456896 run_lib.py:146] step: 188000, eval_loss: 2.63289e-02
I0209 07:20:39.947027 22542570456896 run_lib.py:133] step: 188050, training_loss: 2.78904e-02
I0209 07:20:57.555991 22542570456896 run_lib.py:133] step: 188100, training_loss: 3.32979e-02
I0209 07:20:57.714670 22542570456896 run_lib.py:146] step: 188100, eval_loss: 2.64674e-02
I0209 07:21:15.120793 22542570456896 run_lib.py:133] step: 188150, training_loss: 3.42507e-02
I0209 07:21:32.661237 22542570456896 run_lib.py:133] step: 188200, training_loss: 3.07262e-02
I0209 07:21:32.816427 22542570456896 run_lib.py:146] step: 188200, eval_loss: 3.43585e-02
I0209 07:21:50.230543 22542570456896 run_lib.py:133] step: 188250, training_loss: 3.11912e-02
I0209 07:22:07.640704 22542570456896 run_lib.py:133] step: 188300, training_loss: 2.40227e-02
I0209 07:22:07.795521 22542570456896 run_lib.py:146] step: 188300, eval_loss: 3.10303e-02
I0209 07:22:25.375255 22542570456896 run_lib.py:133] step: 188350, training_loss: 3.20042e-02
I0209 07:22:42.719020 22542570456896 run_lib.py:133] step: 188400, training_loss: 2.86904e-02
I0209 07:22:42.871264 22542570456896 run_lib.py:146] step: 188400, eval_loss: 3.25841e-02
I0209 07:23:00.178719 22542570456896 run_lib.py:133] step: 188450, training_loss: 2.69147e-02
I0209 07:23:17.796442 22542570456896 run_lib.py:133] step: 188500, training_loss: 2.80625e-02
I0209 07:23:17.954688 22542570456896 run_lib.py:146] step: 188500, eval_loss: 4.03589e-02
I0209 07:23:35.373393 22542570456896 run_lib.py:133] step: 188550, training_loss: 2.75909e-02
I0209 07:23:52.852232 22542570456896 run_lib.py:133] step: 188600, training_loss: 2.99079e-02
I0209 07:23:53.008533 22542570456896 run_lib.py:146] step: 188600, eval_loss: 2.41660e-02
I0209 07:24:10.594103 22542570456896 run_lib.py:133] step: 188650, training_loss: 3.11039e-02
I0209 07:24:28.005144 22542570456896 run_lib.py:133] step: 188700, training_loss: 2.69581e-02
I0209 07:24:28.164017 22542570456896 run_lib.py:146] step: 188700, eval_loss: 2.78174e-02
I0209 07:24:45.597454 22542570456896 run_lib.py:133] step: 188750, training_loss: 3.34980e-02
I0209 07:25:03.034936 22542570456896 run_lib.py:133] step: 188800, training_loss: 3.71282e-02
I0209 07:25:03.189319 22542570456896 run_lib.py:146] step: 188800, eval_loss: 3.30835e-02
I0209 07:25:20.775810 22542570456896 run_lib.py:133] step: 188850, training_loss: 2.05922e-02
I0209 07:25:38.365593 22542570456896 run_lib.py:133] step: 188900, training_loss: 2.68141e-02
I0209 07:25:38.522589 22542570456896 run_lib.py:146] step: 188900, eval_loss: 2.69767e-02
I0209 07:25:55.966686 22542570456896 run_lib.py:133] step: 188950, training_loss: 2.68173e-02
I0209 07:26:13.403579 22542570456896 run_lib.py:133] step: 189000, training_loss: 3.14332e-02
I0209 07:26:13.566548 22542570456896 run_lib.py:146] step: 189000, eval_loss: 3.03008e-02
I0209 07:26:31.143859 22542570456896 run_lib.py:133] step: 189050, training_loss: 3.47735e-02
I0209 07:26:48.562918 22542570456896 run_lib.py:133] step: 189100, training_loss: 2.96700e-02
I0209 07:26:48.740285 22542570456896 run_lib.py:146] step: 189100, eval_loss: 3.09837e-02
I0209 07:27:06.350230 22542570456896 run_lib.py:133] step: 189150, training_loss: 2.50119e-02
I0209 07:27:23.822812 22542570456896 run_lib.py:133] step: 189200, training_loss: 3.16826e-02
I0209 07:27:23.978153 22542570456896 run_lib.py:146] step: 189200, eval_loss: 3.17039e-02
I0209 07:27:41.598204 22542570456896 run_lib.py:133] step: 189250, training_loss: 2.40240e-02
I0209 07:27:59.018651 22542570456896 run_lib.py:133] step: 189300, training_loss: 2.57249e-02
I0209 07:27:59.170419 22542570456896 run_lib.py:146] step: 189300, eval_loss: 2.81894e-02
I0209 07:28:16.762700 22542570456896 run_lib.py:133] step: 189350, training_loss: 2.38883e-02
I0209 07:28:34.228543 22542570456896 run_lib.py:133] step: 189400, training_loss: 2.26631e-02
I0209 07:28:34.404695 22542570456896 run_lib.py:146] step: 189400, eval_loss: 3.38121e-02
I0209 07:28:51.873007 22542570456896 run_lib.py:133] step: 189450, training_loss: 3.16337e-02
I0209 07:29:09.484812 22542570456896 run_lib.py:133] step: 189500, training_loss: 2.66250e-02
I0209 07:29:09.643293 22542570456896 run_lib.py:146] step: 189500, eval_loss: 2.63292e-02
I0209 07:29:27.040856 22542570456896 run_lib.py:133] step: 189550, training_loss: 2.78352e-02
I0209 07:29:44.482555 22542570456896 run_lib.py:133] step: 189600, training_loss: 2.65822e-02
I0209 07:29:44.643496 22542570456896 run_lib.py:146] step: 189600, eval_loss: 3.85478e-02
I0209 07:30:02.225714 22542570456896 run_lib.py:133] step: 189650, training_loss: 2.68211e-02
I0209 07:30:19.714750 22542570456896 run_lib.py:133] step: 189700, training_loss: 2.64109e-02
I0209 07:30:19.871609 22542570456896 run_lib.py:146] step: 189700, eval_loss: 3.10250e-02
I0209 07:30:37.491399 22542570456896 run_lib.py:133] step: 189750, training_loss: 2.77303e-02
I0209 07:30:54.919275 22542570456896 run_lib.py:133] step: 189800, training_loss: 3.81649e-02
I0209 07:30:55.071318 22542570456896 run_lib.py:146] step: 189800, eval_loss: 3.54052e-02
I0209 07:31:12.535634 22542570456896 run_lib.py:133] step: 189850, training_loss: 2.83391e-02
I0209 07:31:30.114176 22542570456896 run_lib.py:133] step: 189900, training_loss: 2.98714e-02
I0209 07:31:30.291443 22542570456896 run_lib.py:146] step: 189900, eval_loss: 3.15579e-02
I0209 07:31:47.764022 22542570456896 run_lib.py:133] step: 189950, training_loss: 2.32091e-02
I0209 07:32:05.228557 22542570456896 run_lib.py:133] step: 190000, training_loss: 2.49294e-02
I0209 07:32:05.930842 22542570456896 run_lib.py:146] step: 190000, eval_loss: 2.40386e-02
I0209 07:32:25.996146 22542570456896 run_lib.py:133] step: 190050, training_loss: 2.47099e-02
I0209 07:32:43.420551 22542570456896 run_lib.py:133] step: 190100, training_loss: 2.09702e-02
I0209 07:32:43.581664 22542570456896 run_lib.py:146] step: 190100, eval_loss: 2.54576e-02
I0209 07:33:01.214011 22542570456896 run_lib.py:133] step: 190150, training_loss: 2.56479e-02
I0209 07:33:18.693887 22542570456896 run_lib.py:133] step: 190200, training_loss: 2.79282e-02
I0209 07:33:18.849068 22542570456896 run_lib.py:146] step: 190200, eval_loss: 2.64127e-02
I0209 07:33:36.355996 22542570456896 run_lib.py:133] step: 190250, training_loss: 3.16998e-02
I0209 07:33:53.771338 22542570456896 run_lib.py:133] step: 190300, training_loss: 2.69861e-02
I0209 07:33:53.925289 22542570456896 run_lib.py:146] step: 190300, eval_loss: 2.79443e-02
I0209 07:34:11.390655 22542570456896 run_lib.py:133] step: 190350, training_loss: 3.14763e-02
I0209 07:34:28.837088 22542570456896 run_lib.py:133] step: 190400, training_loss: 2.44076e-02
I0209 07:34:28.990368 22542570456896 run_lib.py:146] step: 190400, eval_loss: 3.36436e-02
I0209 07:34:46.591409 22542570456896 run_lib.py:133] step: 190450, training_loss: 2.75771e-02
I0209 07:35:04.101342 22542570456896 run_lib.py:133] step: 190500, training_loss: 2.76930e-02
I0209 07:35:04.279403 22542570456896 run_lib.py:146] step: 190500, eval_loss: 2.85472e-02
I0209 07:35:21.739857 22542570456896 run_lib.py:133] step: 190550, training_loss: 2.56079e-02
I0209 07:35:39.202101 22542570456896 run_lib.py:133] step: 190600, training_loss: 2.51936e-02
I0209 07:35:39.358620 22542570456896 run_lib.py:146] step: 190600, eval_loss: 3.22474e-02
I0209 07:35:56.962891 22542570456896 run_lib.py:133] step: 190650, training_loss: 3.51946e-02
I0209 07:36:14.408064 22542570456896 run_lib.py:133] step: 190700, training_loss: 2.10106e-02
I0209 07:36:14.563587 22542570456896 run_lib.py:146] step: 190700, eval_loss: 2.87002e-02
I0209 07:36:32.099303 22542570456896 run_lib.py:133] step: 190750, training_loss: 3.00421e-02
I0209 07:36:49.580149 22542570456896 run_lib.py:133] step: 190800, training_loss: 2.57530e-02
I0209 07:36:49.735786 22542570456896 run_lib.py:146] step: 190800, eval_loss: 2.70883e-02
I0209 07:37:07.424879 22542570456896 run_lib.py:133] step: 190850, training_loss: 2.37042e-02
I0209 07:37:24.853081 22542570456896 run_lib.py:133] step: 190900, training_loss: 3.40781e-02
I0209 07:37:25.009501 22542570456896 run_lib.py:146] step: 190900, eval_loss: 3.38149e-02
I0209 07:37:42.570840 22542570456896 run_lib.py:133] step: 190950, training_loss: 2.96565e-02
I0209 07:38:00.015325 22542570456896 run_lib.py:133] step: 191000, training_loss: 1.94408e-02
I0209 07:38:00.178555 22542570456896 run_lib.py:146] step: 191000, eval_loss: 3.23100e-02
I0209 07:38:17.562066 22542570456896 run_lib.py:133] step: 191050, training_loss: 2.15253e-02
I0209 07:38:35.128946 22542570456896 run_lib.py:133] step: 191100, training_loss: 2.75139e-02
I0209 07:38:35.298340 22542570456896 run_lib.py:146] step: 191100, eval_loss: 2.97820e-02
I0209 07:38:52.727459 22542570456896 run_lib.py:133] step: 191150, training_loss: 2.18231e-02
I0209 07:39:10.200654 22542570456896 run_lib.py:133] step: 191200, training_loss: 2.25155e-02
I0209 07:39:10.356585 22542570456896 run_lib.py:146] step: 191200, eval_loss: 2.65686e-02
I0209 07:39:27.969338 22542570456896 run_lib.py:133] step: 191250, training_loss: 3.14036e-02
I0209 07:39:45.517073 22542570456896 run_lib.py:133] step: 191300, training_loss: 2.50443e-02
I0209 07:39:45.668280 22542570456896 run_lib.py:146] step: 191300, eval_loss: 2.46901e-02
I0209 07:40:03.076982 22542570456896 run_lib.py:133] step: 191350, training_loss: 2.32742e-02
I0209 07:40:20.514986 22542570456896 run_lib.py:133] step: 191400, training_loss: 2.65354e-02
I0209 07:40:20.680473 22542570456896 run_lib.py:146] step: 191400, eval_loss: 3.17405e-02
I0209 07:40:38.156218 22542570456896 run_lib.py:133] step: 191450, training_loss: 3.25459e-02
I0209 07:40:55.821528 22542570456896 run_lib.py:133] step: 191500, training_loss: 3.02493e-02
I0209 07:40:55.985249 22542570456896 run_lib.py:146] step: 191500, eval_loss: 2.41598e-02
I0209 07:41:13.400382 22542570456896 run_lib.py:133] step: 191550, training_loss: 2.57356e-02
I0209 07:41:30.829705 22542570456896 run_lib.py:133] step: 191600, training_loss: 4.00523e-02
I0209 07:41:30.989361 22542570456896 run_lib.py:146] step: 191600, eval_loss: 2.80848e-02
I0209 07:41:48.407687 22542570456896 run_lib.py:133] step: 191650, training_loss: 3.53960e-02
I0209 07:42:05.980637 22542570456896 run_lib.py:133] step: 191700, training_loss: 3.02118e-02
I0209 07:42:06.132711 22542570456896 run_lib.py:146] step: 191700, eval_loss: 3.09908e-02
I0209 07:42:23.581570 22542570456896 run_lib.py:133] step: 191750, training_loss: 3.39096e-02
I0209 07:42:41.111204 22542570456896 run_lib.py:133] step: 191800, training_loss: 3.13846e-02
I0209 07:42:41.263386 22542570456896 run_lib.py:146] step: 191800, eval_loss: 2.97786e-02
I0209 07:42:58.693505 22542570456896 run_lib.py:133] step: 191850, training_loss: 2.34629e-02
I0209 07:43:16.128855 22542570456896 run_lib.py:133] step: 191900, training_loss: 2.92051e-02
I0209 07:43:16.287833 22542570456896 run_lib.py:146] step: 191900, eval_loss: 2.46757e-02
I0209 07:43:33.860594 22542570456896 run_lib.py:133] step: 191950, training_loss: 2.90382e-02
I0209 07:43:51.333159 22542570456896 run_lib.py:133] step: 192000, training_loss: 2.47693e-02
I0209 07:43:51.500332 22542570456896 run_lib.py:146] step: 192000, eval_loss: 3.33083e-02
I0209 07:44:08.969383 22542570456896 run_lib.py:133] step: 192050, training_loss: 3.46890e-02
I0209 07:44:26.424701 22542570456896 run_lib.py:133] step: 192100, training_loss: 2.67892e-02
I0209 07:44:26.582272 22542570456896 run_lib.py:146] step: 192100, eval_loss: 2.48254e-02
I0209 07:44:44.201052 22542570456896 run_lib.py:133] step: 192150, training_loss: 2.70711e-02
I0209 07:45:01.591803 22542570456896 run_lib.py:133] step: 192200, training_loss: 3.21324e-02
I0209 07:45:01.743180 22542570456896 run_lib.py:146] step: 192200, eval_loss: 1.98498e-02
I0209 07:45:19.320674 22542570456896 run_lib.py:133] step: 192250, training_loss: 2.21363e-02
I0209 07:45:36.751131 22542570456896 run_lib.py:133] step: 192300, training_loss: 2.40564e-02
I0209 07:45:36.920643 22542570456896 run_lib.py:146] step: 192300, eval_loss: 3.14710e-02
I0209 07:45:54.610748 22542570456896 run_lib.py:133] step: 192350, training_loss: 2.60148e-02
I0209 07:46:12.036375 22542570456896 run_lib.py:133] step: 192400, training_loss: 2.42561e-02
I0209 07:46:12.194404 22542570456896 run_lib.py:146] step: 192400, eval_loss: 2.59584e-02
I0209 07:46:29.622185 22542570456896 run_lib.py:133] step: 192450, training_loss: 3.02775e-02
I0209 07:46:47.210407 22542570456896 run_lib.py:133] step: 192500, training_loss: 2.44163e-02
I0209 07:46:47.366465 22542570456896 run_lib.py:146] step: 192500, eval_loss: 3.10060e-02
I0209 07:47:04.807082 22542570456896 run_lib.py:133] step: 192550, training_loss: 3.01186e-02
I0209 07:47:22.384257 22542570456896 run_lib.py:133] step: 192600, training_loss: 3.05969e-02
I0209 07:47:22.541525 22542570456896 run_lib.py:146] step: 192600, eval_loss: 2.72497e-02
I0209 07:47:39.984236 22542570456896 run_lib.py:133] step: 192650, training_loss: 2.74617e-02
I0209 07:47:57.387274 22542570456896 run_lib.py:133] step: 192700, training_loss: 2.66123e-02
I0209 07:47:57.538388 22542570456896 run_lib.py:146] step: 192700, eval_loss: 2.44764e-02
I0209 07:48:15.184478 22542570456896 run_lib.py:133] step: 192750, training_loss: 2.52992e-02
I0209 07:48:32.610560 22542570456896 run_lib.py:133] step: 192800, training_loss: 2.58883e-02
I0209 07:48:32.765413 22542570456896 run_lib.py:146] step: 192800, eval_loss: 3.43287e-02
I0209 07:48:50.184286 22542570456896 run_lib.py:133] step: 192850, training_loss: 2.81749e-02
I0209 07:49:07.766084 22542570456896 run_lib.py:133] step: 192900, training_loss: 2.96655e-02
I0209 07:49:07.949926 22542570456896 run_lib.py:146] step: 192900, eval_loss: 2.69619e-02
I0209 07:49:25.449462 22542570456896 run_lib.py:133] step: 192950, training_loss: 2.45575e-02
I0209 07:49:42.879867 22542570456896 run_lib.py:133] step: 193000, training_loss: 2.33453e-02
I0209 07:49:43.036657 22542570456896 run_lib.py:146] step: 193000, eval_loss: 2.07910e-02
I0209 07:50:00.606092 22542570456896 run_lib.py:133] step: 193050, training_loss: 2.14299e-02
I0209 07:50:18.031015 22542570456896 run_lib.py:133] step: 193100, training_loss: 2.71420e-02
I0209 07:50:18.185492 22542570456896 run_lib.py:146] step: 193100, eval_loss: 2.60626e-02
I0209 07:50:35.601275 22542570456896 run_lib.py:133] step: 193150, training_loss: 2.63707e-02
I0209 07:50:53.003185 22542570456896 run_lib.py:133] step: 193200, training_loss: 2.06503e-02
I0209 07:50:53.167580 22542570456896 run_lib.py:146] step: 193200, eval_loss: 2.77984e-02
I0209 07:51:10.790751 22542570456896 run_lib.py:133] step: 193250, training_loss: 2.80697e-02
I0209 07:51:28.317914 22542570456896 run_lib.py:133] step: 193300, training_loss: 3.34398e-02
I0209 07:51:28.476456 22542570456896 run_lib.py:146] step: 193300, eval_loss: 3.11208e-02
I0209 07:51:45.904893 22542570456896 run_lib.py:133] step: 193350, training_loss: 3.31643e-02
I0209 07:52:03.293056 22542570456896 run_lib.py:133] step: 193400, training_loss: 2.76565e-02
I0209 07:52:03.456538 22542570456896 run_lib.py:146] step: 193400, eval_loss: 2.79106e-02
I0209 07:52:21.013612 22542570456896 run_lib.py:133] step: 193450, training_loss: 2.01308e-02
I0209 07:52:38.440985 22542570456896 run_lib.py:133] step: 193500, training_loss: 2.62886e-02
I0209 07:52:38.596288 22542570456896 run_lib.py:146] step: 193500, eval_loss: 2.48438e-02
I0209 07:52:56.185657 22542570456896 run_lib.py:133] step: 193550, training_loss: 2.95132e-02
I0209 07:53:13.592541 22542570456896 run_lib.py:133] step: 193600, training_loss: 3.34310e-02
I0209 07:53:13.747364 22542570456896 run_lib.py:146] step: 193600, eval_loss: 2.32699e-02
I0209 07:53:31.344236 22542570456896 run_lib.py:133] step: 193650, training_loss: 3.15479e-02
I0209 07:53:48.808978 22542570456896 run_lib.py:133] step: 193700, training_loss: 2.71766e-02
I0209 07:53:48.957412 22542570456896 run_lib.py:146] step: 193700, eval_loss: 2.75241e-02
I0209 07:54:06.516100 22542570456896 run_lib.py:133] step: 193750, training_loss: 2.91243e-02
I0209 07:54:23.957594 22542570456896 run_lib.py:133] step: 193800, training_loss: 3.06997e-02
I0209 07:54:24.134337 22542570456896 run_lib.py:146] step: 193800, eval_loss: 2.26891e-02
I0209 07:54:41.598030 22542570456896 run_lib.py:133] step: 193850, training_loss: 2.95010e-02
I0209 07:54:59.246950 22542570456896 run_lib.py:133] step: 193900, training_loss: 2.46233e-02
I0209 07:54:59.401425 22542570456896 run_lib.py:146] step: 193900, eval_loss: 2.59195e-02
I0209 07:55:16.816899 22542570456896 run_lib.py:133] step: 193950, training_loss: 3.30502e-02
I0209 07:55:34.248542 22542570456896 run_lib.py:133] step: 194000, training_loss: 2.47282e-02
I0209 07:55:34.404525 22542570456896 run_lib.py:146] step: 194000, eval_loss: 2.51800e-02
I0209 07:55:51.960602 22542570456896 run_lib.py:133] step: 194050, training_loss: 2.89978e-02
I0209 07:56:09.436337 22542570456896 run_lib.py:133] step: 194100, training_loss: 2.94265e-02
I0209 07:56:09.590944 22542570456896 run_lib.py:146] step: 194100, eval_loss: 2.99912e-02
I0209 07:56:27.165398 22542570456896 run_lib.py:133] step: 194150, training_loss: 3.60841e-02
I0209 07:56:44.600378 22542570456896 run_lib.py:133] step: 194200, training_loss: 2.14784e-02
I0209 07:56:44.754387 22542570456896 run_lib.py:146] step: 194200, eval_loss: 2.73829e-02
I0209 07:57:02.134451 22542570456896 run_lib.py:133] step: 194250, training_loss: 2.81127e-02
I0209 07:57:19.722603 22542570456896 run_lib.py:133] step: 194300, training_loss: 2.47899e-02
I0209 07:57:19.880584 22542570456896 run_lib.py:146] step: 194300, eval_loss: 2.63386e-02
I0209 07:57:37.325602 22542570456896 run_lib.py:133] step: 194350, training_loss: 2.44810e-02
I0209 07:57:54.762437 22542570456896 run_lib.py:133] step: 194400, training_loss: 3.06091e-02
I0209 07:57:54.918665 22542570456896 run_lib.py:146] step: 194400, eval_loss: 3.56370e-02
I0209 07:58:12.332784 22542570456896 run_lib.py:133] step: 194450, training_loss: 2.94471e-02
I0209 07:58:29.906090 22542570456896 run_lib.py:133] step: 194500, training_loss: 2.78422e-02
I0209 07:58:30.069630 22542570456896 run_lib.py:146] step: 194500, eval_loss: 2.75017e-02
I0209 07:58:47.493757 22542570456896 run_lib.py:133] step: 194550, training_loss: 2.60550e-02
I0209 07:59:04.951178 22542570456896 run_lib.py:133] step: 194600, training_loss: 2.53074e-02
I0209 07:59:05.102995 22542570456896 run_lib.py:146] step: 194600, eval_loss: 2.59974e-02
I0209 07:59:22.509569 22542570456896 run_lib.py:133] step: 194650, training_loss: 2.72362e-02
I0209 07:59:39.961044 22542570456896 run_lib.py:133] step: 194700, training_loss: 2.67453e-02
I0209 07:59:40.123524 22542570456896 run_lib.py:146] step: 194700, eval_loss: 3.27453e-02
I0209 07:59:57.709769 22542570456896 run_lib.py:133] step: 194750, training_loss: 2.50465e-02
I0209 08:00:15.220771 22542570456896 run_lib.py:133] step: 194800, training_loss: 2.17510e-02
I0209 08:00:15.379757 22542570456896 run_lib.py:146] step: 194800, eval_loss: 2.87431e-02
I0209 08:00:32.800635 22542570456896 run_lib.py:133] step: 194850, training_loss: 2.23369e-02
I0209 08:00:50.218475 22542570456896 run_lib.py:133] step: 194900, training_loss: 3.91361e-02
I0209 08:00:50.382460 22542570456896 run_lib.py:146] step: 194900, eval_loss: 2.68293e-02
I0209 08:01:07.968106 22542570456896 run_lib.py:133] step: 194950, training_loss: 2.65841e-02
I0209 08:01:25.421880 22542570456896 run_lib.py:133] step: 195000, training_loss: 2.85939e-02
I0209 08:01:25.579512 22542570456896 run_lib.py:146] step: 195000, eval_loss: 2.79727e-02
I0209 08:01:43.208292 22542570456896 run_lib.py:133] step: 195050, training_loss: 2.80267e-02
I0209 08:02:00.648739 22542570456896 run_lib.py:133] step: 195100, training_loss: 2.72634e-02
I0209 08:02:00.800376 22542570456896 run_lib.py:146] step: 195100, eval_loss: 2.05451e-02
I0209 08:02:18.350169 22542570456896 run_lib.py:133] step: 195150, training_loss: 3.32528e-02
I0209 08:02:35.778358 22542570456896 run_lib.py:133] step: 195200, training_loss: 2.74756e-02
I0209 08:02:35.954607 22542570456896 run_lib.py:146] step: 195200, eval_loss: 2.43946e-02
I0209 08:02:53.448831 22542570456896 run_lib.py:133] step: 195250, training_loss: 2.66662e-02
I0209 08:03:11.078301 22542570456896 run_lib.py:133] step: 195300, training_loss: 3.29145e-02
I0209 08:03:11.239531 22542570456896 run_lib.py:146] step: 195300, eval_loss: 3.16566e-02
I0209 08:03:28.658783 22542570456896 run_lib.py:133] step: 195350, training_loss: 2.85556e-02
I0209 08:03:46.199018 22542570456896 run_lib.py:133] step: 195400, training_loss: 3.23316e-02
I0209 08:03:46.354023 22542570456896 run_lib.py:146] step: 195400, eval_loss: 3.44163e-02
I0209 08:04:03.757278 22542570456896 run_lib.py:133] step: 195450, training_loss: 2.63818e-02
I0209 08:04:21.200878 22542570456896 run_lib.py:133] step: 195500, training_loss: 2.46316e-02
I0209 08:04:21.355588 22542570456896 run_lib.py:146] step: 195500, eval_loss: 2.31884e-02
I0209 08:04:38.976273 22542570456896 run_lib.py:133] step: 195550, training_loss: 3.24220e-02
I0209 08:04:56.425713 22542570456896 run_lib.py:133] step: 195600, training_loss: 2.17516e-02
I0209 08:04:56.578464 22542570456896 run_lib.py:146] step: 195600, eval_loss: 3.24870e-02
I0209 08:05:14.005957 22542570456896 run_lib.py:133] step: 195650, training_loss: 3.06616e-02
I0209 08:05:31.615672 22542570456896 run_lib.py:133] step: 195700, training_loss: 2.35341e-02
I0209 08:05:31.773777 22542570456896 run_lib.py:146] step: 195700, eval_loss: 3.43221e-02
I0209 08:05:49.175696 22542570456896 run_lib.py:133] step: 195750, training_loss: 2.81636e-02
I0209 08:06:06.593688 22542570456896 run_lib.py:133] step: 195800, training_loss: 3.06591e-02
I0209 08:06:06.911350 22542570456896 run_lib.py:146] step: 195800, eval_loss: 3.42345e-02
I0209 08:06:24.366023 22542570456896 run_lib.py:133] step: 195850, training_loss: 2.33393e-02
I0209 08:06:41.831978 22542570456896 run_lib.py:133] step: 195900, training_loss: 2.36217e-02
I0209 08:06:41.988541 22542570456896 run_lib.py:146] step: 195900, eval_loss: 2.43470e-02
I0209 08:06:59.396783 22542570456896 run_lib.py:133] step: 195950, training_loss: 2.69451e-02
I0209 08:07:16.759421 22542570456896 run_lib.py:133] step: 196000, training_loss: 3.02849e-02
I0209 08:07:16.911042 22542570456896 run_lib.py:146] step: 196000, eval_loss: 2.30283e-02
I0209 08:07:34.472359 22542570456896 run_lib.py:133] step: 196050, training_loss: 2.31484e-02
I0209 08:07:51.947955 22542570456896 run_lib.py:133] step: 196100, training_loss: 2.58354e-02
I0209 08:07:52.108396 22542570456896 run_lib.py:146] step: 196100, eval_loss: 3.02325e-02
I0209 08:08:09.585613 22542570456896 run_lib.py:133] step: 196150, training_loss: 2.84234e-02
I0209 08:08:27.044652 22542570456896 run_lib.py:133] step: 196200, training_loss: 3.65144e-02
I0209 08:08:27.203200 22542570456896 run_lib.py:146] step: 196200, eval_loss: 2.96661e-02
I0209 08:08:44.798986 22542570456896 run_lib.py:133] step: 196250, training_loss: 1.87256e-02
I0209 08:09:02.257677 22542570456896 run_lib.py:133] step: 196300, training_loss: 2.76510e-02
I0209 08:09:02.413457 22542570456896 run_lib.py:146] step: 196300, eval_loss: 2.96782e-02
I0209 08:09:19.837044 22542570456896 run_lib.py:133] step: 196350, training_loss: 3.02234e-02
I0209 08:09:37.339436 22542570456896 run_lib.py:133] step: 196400, training_loss: 2.37130e-02
I0209 08:09:37.497274 22542570456896 run_lib.py:146] step: 196400, eval_loss: 2.81054e-02
I0209 08:09:55.118548 22542570456896 run_lib.py:133] step: 196450, training_loss: 3.00221e-02
I0209 08:10:12.550992 22542570456896 run_lib.py:133] step: 196500, training_loss: 3.02411e-02
I0209 08:10:12.703356 22542570456896 run_lib.py:146] step: 196500, eval_loss: 2.69358e-02
I0209 08:10:30.261570 22542570456896 run_lib.py:133] step: 196550, training_loss: 3.01699e-02
I0209 08:10:47.670017 22542570456896 run_lib.py:133] step: 196600, training_loss: 3.17587e-02
I0209 08:10:47.825249 22542570456896 run_lib.py:146] step: 196600, eval_loss: 2.37713e-02
I0209 08:11:05.395307 22542570456896 run_lib.py:133] step: 196650, training_loss: 3.58848e-02
I0209 08:11:22.835940 22542570456896 run_lib.py:133] step: 196700, training_loss: 2.70988e-02
I0209 08:11:23.007252 22542570456896 run_lib.py:146] step: 196700, eval_loss: 3.11219e-02
I0209 08:11:40.419052 22542570456896 run_lib.py:133] step: 196750, training_loss: 2.46780e-02
I0209 08:11:58.062005 22542570456896 run_lib.py:133] step: 196800, training_loss: 2.45468e-02
I0209 08:11:58.218608 22542570456896 run_lib.py:146] step: 196800, eval_loss: 2.82282e-02
I0209 08:12:15.638700 22542570456896 run_lib.py:133] step: 196850, training_loss: 3.41521e-02
I0209 08:12:33.189692 22542570456896 run_lib.py:133] step: 196900, training_loss: 3.44134e-02
I0209 08:12:33.352117 22542570456896 run_lib.py:146] step: 196900, eval_loss: 3.05150e-02
I0209 08:12:50.768218 22542570456896 run_lib.py:133] step: 196950, training_loss: 2.39057e-02
I0209 08:13:08.203108 22542570456896 run_lib.py:133] step: 197000, training_loss: 2.89612e-02
I0209 08:13:08.356549 22542570456896 run_lib.py:146] step: 197000, eval_loss: 3.27654e-02
I0209 08:13:25.974904 22542570456896 run_lib.py:133] step: 197050, training_loss: 3.18635e-02
I0209 08:13:43.391282 22542570456896 run_lib.py:133] step: 197100, training_loss: 2.60647e-02
I0209 08:13:43.546303 22542570456896 run_lib.py:146] step: 197100, eval_loss: 2.85002e-02
I0209 08:14:00.937696 22542570456896 run_lib.py:133] step: 197150, training_loss: 3.68352e-02
I0209 08:14:18.351225 22542570456896 run_lib.py:133] step: 197200, training_loss: 2.91442e-02
I0209 08:14:18.516343 22542570456896 run_lib.py:146] step: 197200, eval_loss: 3.04458e-02
I0209 08:14:36.142434 22542570456896 run_lib.py:133] step: 197250, training_loss: 2.79114e-02
I0209 08:14:53.571718 22542570456896 run_lib.py:133] step: 197300, training_loss: 3.22101e-02
I0209 08:14:53.728839 22542570456896 run_lib.py:146] step: 197300, eval_loss: 2.93379e-02
I0209 08:15:11.270266 22542570456896 run_lib.py:133] step: 197350, training_loss: 2.77099e-02
I0209 08:15:28.659296 22542570456896 run_lib.py:133] step: 197400, training_loss: 3.44288e-02
I0209 08:15:28.822334 22542570456896 run_lib.py:146] step: 197400, eval_loss: 2.32948e-02
I0209 08:15:46.254297 22542570456896 run_lib.py:133] step: 197450, training_loss: 2.69386e-02
I0209 08:16:03.714555 22542570456896 run_lib.py:133] step: 197500, training_loss: 2.77707e-02
I0209 08:16:03.871536 22542570456896 run_lib.py:146] step: 197500, eval_loss: 2.44007e-02
I0209 08:16:21.459657 22542570456896 run_lib.py:133] step: 197550, training_loss: 2.40020e-02
I0209 08:16:39.013852 22542570456896 run_lib.py:133] step: 197600, training_loss: 3.26975e-02
I0209 08:16:39.172185 22542570456896 run_lib.py:146] step: 197600, eval_loss: 1.94362e-02
I0209 08:16:56.574644 22542570456896 run_lib.py:133] step: 197650, training_loss: 2.01120e-02
I0209 08:17:13.967384 22542570456896 run_lib.py:133] step: 197700, training_loss: 2.56021e-02
I0209 08:17:14.123387 22542570456896 run_lib.py:146] step: 197700, eval_loss: 3.22447e-02
I0209 08:17:31.658972 22542570456896 run_lib.py:133] step: 197750, training_loss: 2.44337e-02
I0209 08:17:49.101803 22542570456896 run_lib.py:133] step: 197800, training_loss: 2.84920e-02
I0209 08:17:49.259355 22542570456896 run_lib.py:146] step: 197800, eval_loss: 2.57819e-02
I0209 08:18:06.903324 22542570456896 run_lib.py:133] step: 197850, training_loss: 2.50327e-02
I0209 08:18:24.336978 22542570456896 run_lib.py:133] step: 197900, training_loss: 3.01922e-02
I0209 08:18:24.488161 22542570456896 run_lib.py:146] step: 197900, eval_loss: 2.84307e-02
I0209 08:18:42.077522 22542570456896 run_lib.py:133] step: 197950, training_loss: 2.89972e-02
I0209 08:18:59.512704 22542570456896 run_lib.py:133] step: 198000, training_loss: 2.75048e-02
I0209 08:18:59.671378 22542570456896 run_lib.py:146] step: 198000, eval_loss: 3.27558e-02
I0209 08:19:17.205566 22542570456896 run_lib.py:133] step: 198050, training_loss: 2.54557e-02
I0209 08:19:34.663938 22542570456896 run_lib.py:133] step: 198100, training_loss: 2.55155e-02
I0209 08:19:34.841306 22542570456896 run_lib.py:146] step: 198100, eval_loss: 2.77292e-02
I0209 08:19:52.306884 22542570456896 run_lib.py:133] step: 198150, training_loss: 2.96179e-02
I0209 08:20:09.940207 22542570456896 run_lib.py:133] step: 198200, training_loss: 2.75183e-02
I0209 08:20:10.095053 22542570456896 run_lib.py:146] step: 198200, eval_loss: 2.90799e-02
I0209 08:20:27.518175 22542570456896 run_lib.py:133] step: 198250, training_loss: 3.21393e-02
I0209 08:20:44.922638 22542570456896 run_lib.py:133] step: 198300, training_loss: 3.06589e-02
I0209 08:20:45.077355 22542570456896 run_lib.py:146] step: 198300, eval_loss: 2.07880e-02
I0209 08:21:02.605229 22542570456896 run_lib.py:133] step: 198350, training_loss: 3.25446e-02
I0209 08:21:20.250834 22542570456896 run_lib.py:133] step: 198400, training_loss: 3.29792e-02
I0209 08:21:20.405609 22542570456896 run_lib.py:146] step: 198400, eval_loss: 3.23058e-02
I0209 08:21:37.885236 22542570456896 run_lib.py:133] step: 198450, training_loss: 2.87158e-02
I0209 08:21:55.281162 22542570456896 run_lib.py:133] step: 198500, training_loss: 3.30998e-02
I0209 08:21:55.444389 22542570456896 run_lib.py:146] step: 198500, eval_loss: 2.33815e-02
I0209 08:22:12.823273 22542570456896 run_lib.py:133] step: 198550, training_loss: 2.54424e-02
I0209 08:22:30.459764 22542570456896 run_lib.py:133] step: 198600, training_loss: 2.97600e-02
I0209 08:22:30.617527 22542570456896 run_lib.py:146] step: 198600, eval_loss: 3.11379e-02
I0209 08:22:48.067728 22542570456896 run_lib.py:133] step: 198650, training_loss: 2.60480e-02
I0209 08:23:05.554472 22542570456896 run_lib.py:133] step: 198700, training_loss: 2.48342e-02
I0209 08:23:05.706743 22542570456896 run_lib.py:146] step: 198700, eval_loss: 2.24408e-02
I0209 08:23:23.128369 22542570456896 run_lib.py:133] step: 198750, training_loss: 3.05250e-02
I0209 08:23:40.787395 22542570456896 run_lib.py:133] step: 198800, training_loss: 2.07852e-02
I0209 08:23:40.941569 22542570456896 run_lib.py:146] step: 198800, eval_loss: 2.77269e-02
I0209 08:23:58.345149 22542570456896 run_lib.py:133] step: 198850, training_loss: 2.72250e-02
I0209 08:24:15.825377 22542570456896 run_lib.py:133] step: 198900, training_loss: 3.26851e-02
I0209 08:24:15.979260 22542570456896 run_lib.py:146] step: 198900, eval_loss: 3.15687e-02
I0209 08:24:33.396367 22542570456896 run_lib.py:133] step: 198950, training_loss: 2.63733e-02
I0209 08:24:50.855107 22542570456896 run_lib.py:133] step: 199000, training_loss: 2.94784e-02
I0209 08:24:51.024303 22542570456896 run_lib.py:146] step: 199000, eval_loss: 3.46268e-02
I0209 08:25:08.639066 22542570456896 run_lib.py:133] step: 199050, training_loss: 2.32092e-02
I0209 08:25:26.143200 22542570456896 run_lib.py:133] step: 199100, training_loss: 3.53986e-02
I0209 08:25:26.300705 22542570456896 run_lib.py:146] step: 199100, eval_loss: 2.55060e-02
I0209 08:25:43.729352 22542570456896 run_lib.py:133] step: 199150, training_loss: 2.64228e-02
I0209 08:26:01.139552 22542570456896 run_lib.py:133] step: 199200, training_loss: 3.01395e-02
I0209 08:26:01.295100 22542570456896 run_lib.py:146] step: 199200, eval_loss: 3.26953e-02
I0209 08:26:18.817268 22542570456896 run_lib.py:133] step: 199250, training_loss: 3.29416e-02
I0209 08:26:36.321073 22542570456896 run_lib.py:133] step: 199300, training_loss: 2.08808e-02
I0209 08:26:36.476558 22542570456896 run_lib.py:146] step: 199300, eval_loss: 2.81428e-02
I0209 08:26:54.136131 22542570456896 run_lib.py:133] step: 199350, training_loss: 3.09066e-02
I0209 08:27:11.534091 22542570456896 run_lib.py:133] step: 199400, training_loss: 2.47406e-02
I0209 08:27:11.687318 22542570456896 run_lib.py:146] step: 199400, eval_loss: 2.59425e-02
I0209 08:27:29.219883 22542570456896 run_lib.py:133] step: 199450, training_loss: 3.10841e-02
I0209 08:27:46.616474 22542570456896 run_lib.py:133] step: 199500, training_loss: 3.05260e-02
I0209 08:27:46.779570 22542570456896 run_lib.py:146] step: 199500, eval_loss: 3.23613e-02
I0209 08:28:04.222577 22542570456896 run_lib.py:133] step: 199550, training_loss: 2.98343e-02
I0209 08:28:21.825533 22542570456896 run_lib.py:133] step: 199600, training_loss: 2.82068e-02
I0209 08:28:21.987550 22542570456896 run_lib.py:146] step: 199600, eval_loss: 3.03142e-02
I0209 08:28:39.408658 22542570456896 run_lib.py:133] step: 199650, training_loss: 2.93232e-02
I0209 08:28:57.001601 22542570456896 run_lib.py:133] step: 199700, training_loss: 2.64484e-02
I0209 08:28:57.157140 22542570456896 run_lib.py:146] step: 199700, eval_loss: 3.55435e-02
I0209 08:29:14.550147 22542570456896 run_lib.py:133] step: 199750, training_loss: 2.55474e-02
I0209 08:29:31.978758 22542570456896 run_lib.py:133] step: 199800, training_loss: 2.91587e-02
I0209 08:29:32.129093 22542570456896 run_lib.py:146] step: 199800, eval_loss: 2.96731e-02
I0209 08:29:49.737210 22542570456896 run_lib.py:133] step: 199850, training_loss: 2.79383e-02
I0209 08:30:07.220106 22542570456896 run_lib.py:133] step: 199900, training_loss: 3.13774e-02
I0209 08:30:07.382577 22542570456896 run_lib.py:146] step: 199900, eval_loss: 2.71045e-02
I0209 08:30:24.838237 22542570456896 run_lib.py:133] step: 199950, training_loss: 3.00909e-02
I0209 08:30:42.462753 22542570456896 run_lib.py:133] step: 200000, training_loss: 2.44922e-02
I0209 08:30:43.179432 22542570456896 run_lib.py:146] step: 200000, eval_loss: 2.90544e-02
I0209 08:31:03.250191 22542570456896 run_lib.py:133] step: 200050, training_loss: 2.63434e-02
I0209 08:31:20.687715 22542570456896 run_lib.py:133] step: 200100, training_loss: 2.13452e-02
I0209 08:31:20.865193 22542570456896 run_lib.py:146] step: 200100, eval_loss: 2.77928e-02
I0209 08:31:38.246463 22542570456896 run_lib.py:133] step: 200150, training_loss: 2.98827e-02
I0209 08:31:55.764061 22542570456896 run_lib.py:133] step: 200200, training_loss: 3.01243e-02
I0209 08:31:55.919518 22542570456896 run_lib.py:146] step: 200200, eval_loss: 3.16327e-02
I0209 08:32:13.312123 22542570456896 run_lib.py:133] step: 200250, training_loss: 3.16105e-02
I0209 08:32:30.729836 22542570456896 run_lib.py:133] step: 200300, training_loss: 3.21650e-02
I0209 08:32:30.885384 22542570456896 run_lib.py:146] step: 200300, eval_loss: 2.43674e-02
I0209 08:32:48.448120 22542570456896 run_lib.py:133] step: 200350, training_loss: 3.30412e-02
I0209 08:33:05.886697 22542570456896 run_lib.py:133] step: 200400, training_loss: 3.13290e-02
I0209 08:33:06.050445 22542570456896 run_lib.py:146] step: 200400, eval_loss: 3.49141e-02
I0209 08:33:23.649430 22542570456896 run_lib.py:133] step: 200450, training_loss: 2.60591e-02
I0209 08:33:41.078025 22542570456896 run_lib.py:133] step: 200500, training_loss: 3.74914e-02
I0209 08:33:41.233252 22542570456896 run_lib.py:146] step: 200500, eval_loss: 2.58391e-02
I0209 08:33:58.647351 22542570456896 run_lib.py:133] step: 200550, training_loss: 2.96563e-02
I0209 08:34:16.114227 22542570456896 run_lib.py:133] step: 200600, training_loss: 3.00617e-02
I0209 08:34:16.269740 22542570456896 run_lib.py:146] step: 200600, eval_loss: 2.78328e-02
I0209 08:34:33.863729 22542570456896 run_lib.py:133] step: 200650, training_loss: 3.48856e-02
I0209 08:34:51.462747 22542570456896 run_lib.py:133] step: 200700, training_loss: 3.51212e-02
I0209 08:34:51.618947 22542570456896 run_lib.py:146] step: 200700, eval_loss: 2.98449e-02
I0209 08:35:09.097493 22542570456896 run_lib.py:133] step: 200750, training_loss: 3.36856e-02
I0209 08:35:26.512552 22542570456896 run_lib.py:133] step: 200800, training_loss: 3.41669e-02
I0209 08:35:26.666579 22542570456896 run_lib.py:146] step: 200800, eval_loss: 3.11889e-02
I0209 08:35:44.258288 22542570456896 run_lib.py:133] step: 200850, training_loss: 2.64163e-02
I0209 08:36:01.675221 22542570456896 run_lib.py:133] step: 200900, training_loss: 3.20871e-02
I0209 08:36:01.828453 22542570456896 run_lib.py:146] step: 200900, eval_loss: 2.83964e-02
I0209 08:36:19.414243 22542570456896 run_lib.py:133] step: 200950, training_loss: 2.94107e-02
I0209 08:36:36.866070 22542570456896 run_lib.py:133] step: 201000, training_loss: 3.11212e-02
I0209 08:36:37.025339 22542570456896 run_lib.py:146] step: 201000, eval_loss: 3.15036e-02
I0209 08:36:54.644009 22542570456896 run_lib.py:133] step: 201050, training_loss: 2.36892e-02
I0209 08:37:12.036690 22542570456896 run_lib.py:133] step: 201100, training_loss: 2.51364e-02
I0209 08:37:12.199431 22542570456896 run_lib.py:146] step: 201100, eval_loss: 2.78193e-02
I0209 08:37:29.827753 22542570456896 run_lib.py:133] step: 201150, training_loss: 2.14063e-02
I0209 08:37:47.261815 22542570456896 run_lib.py:133] step: 201200, training_loss: 2.66560e-02
I0209 08:37:47.431152 22542570456896 run_lib.py:146] step: 201200, eval_loss: 3.01457e-02
I0209 08:38:04.917456 22542570456896 run_lib.py:133] step: 201250, training_loss: 3.07590e-02
I0209 08:38:22.539872 22542570456896 run_lib.py:133] step: 201300, training_loss: 3.83070e-02
I0209 08:38:22.691679 22542570456896 run_lib.py:146] step: 201300, eval_loss: 3.54800e-02
I0209 08:38:40.145301 22542570456896 run_lib.py:133] step: 201350, training_loss: 3.53832e-02
I0209 08:38:57.596269 22542570456896 run_lib.py:133] step: 201400, training_loss: 2.56903e-02
I0209 08:38:57.760465 22542570456896 run_lib.py:146] step: 201400, eval_loss: 2.32663e-02
I0209 08:39:15.374833 22542570456896 run_lib.py:133] step: 201450, training_loss: 2.90762e-02
I0209 08:39:32.786108 22542570456896 run_lib.py:133] step: 201500, training_loss: 2.35557e-02
I0209 08:39:32.963353 22542570456896 run_lib.py:146] step: 201500, eval_loss: 2.94744e-02
I0209 08:39:50.603995 22542570456896 run_lib.py:133] step: 201550, training_loss: 2.35091e-02
I0209 08:40:08.043139 22542570456896 run_lib.py:133] step: 201600, training_loss: 2.66362e-02
I0209 08:40:08.197061 22542570456896 run_lib.py:146] step: 201600, eval_loss: 2.41777e-02
I0209 08:40:25.613828 22542570456896 run_lib.py:133] step: 201650, training_loss: 2.79568e-02
I0209 08:40:43.214008 22542570456896 run_lib.py:133] step: 201700, training_loss: 2.50372e-02
I0209 08:40:43.370404 22542570456896 run_lib.py:146] step: 201700, eval_loss: 2.55302e-02
I0209 08:41:00.820782 22542570456896 run_lib.py:133] step: 201750, training_loss: 2.60040e-02
I0209 08:41:18.248535 22542570456896 run_lib.py:133] step: 201800, training_loss: 2.81874e-02
I0209 08:41:18.400766 22542570456896 run_lib.py:146] step: 201800, eval_loss: 2.85275e-02
I0209 08:41:35.859735 22542570456896 run_lib.py:133] step: 201850, training_loss: 2.27920e-02
I0209 08:41:53.473569 22542570456896 run_lib.py:133] step: 201900, training_loss: 2.92339e-02
I0209 08:41:53.640476 22542570456896 run_lib.py:146] step: 201900, eval_loss: 2.35913e-02
I0209 08:42:11.074182 22542570456896 run_lib.py:133] step: 201950, training_loss: 2.94950e-02
I0209 08:42:28.565489 22542570456896 run_lib.py:133] step: 202000, training_loss: 2.97720e-02
I0209 08:42:28.723618 22542570456896 run_lib.py:146] step: 202000, eval_loss: 3.60502e-02
I0209 08:42:46.125899 22542570456896 run_lib.py:133] step: 202050, training_loss: 2.59840e-02
I0209 08:43:03.544118 22542570456896 run_lib.py:133] step: 202100, training_loss: 2.71916e-02
I0209 08:43:03.718151 22542570456896 run_lib.py:146] step: 202100, eval_loss: 3.55812e-02
I0209 08:43:21.345802 22542570456896 run_lib.py:133] step: 202150, training_loss: 2.53157e-02
I0209 08:43:38.877528 22542570456896 run_lib.py:133] step: 202200, training_loss: 2.95830e-02
I0209 08:43:39.029756 22542570456896 run_lib.py:146] step: 202200, eval_loss: 2.87014e-02
I0209 08:43:56.511045 22542570456896 run_lib.py:133] step: 202250, training_loss: 2.66734e-02
I0209 08:44:13.919986 22542570456896 run_lib.py:133] step: 202300, training_loss: 2.48644e-02
I0209 08:44:14.072339 22542570456896 run_lib.py:146] step: 202300, eval_loss: 3.34100e-02
I0209 08:44:31.608668 22542570456896 run_lib.py:133] step: 202350, training_loss: 2.55018e-02
I0209 08:44:49.030693 22542570456896 run_lib.py:133] step: 202400, training_loss: 2.60521e-02
I0209 08:44:49.215279 22542570456896 run_lib.py:146] step: 202400, eval_loss: 3.32684e-02
I0209 08:45:06.834785 22542570456896 run_lib.py:133] step: 202450, training_loss: 2.30039e-02
I0209 08:45:24.330572 22542570456896 run_lib.py:133] step: 202500, training_loss: 3.01986e-02
I0209 08:45:24.497428 22542570456896 run_lib.py:146] step: 202500, eval_loss: 3.01489e-02
I0209 08:45:42.101888 22542570456896 run_lib.py:133] step: 202550, training_loss: 2.84258e-02
I0209 08:45:59.505102 22542570456896 run_lib.py:133] step: 202600, training_loss: 2.55694e-02
I0209 08:45:59.662128 22542570456896 run_lib.py:146] step: 202600, eval_loss: 2.62304e-02
I0209 08:46:17.101458 22542570456896 run_lib.py:133] step: 202650, training_loss: 2.87763e-02
I0209 08:46:34.747307 22542570456896 run_lib.py:133] step: 202700, training_loss: 3.22666e-02
I0209 08:46:34.904157 22542570456896 run_lib.py:146] step: 202700, eval_loss: 2.89330e-02
I0209 08:46:52.361365 22542570456896 run_lib.py:133] step: 202750, training_loss: 3.19170e-02
I0209 08:47:09.966018 22542570456896 run_lib.py:133] step: 202800, training_loss: 3.39197e-02
I0209 08:47:10.131387 22542570456896 run_lib.py:146] step: 202800, eval_loss: 3.14038e-02
I0209 08:47:27.566914 22542570456896 run_lib.py:133] step: 202850, training_loss: 2.97791e-02
I0209 08:47:45.033304 22542570456896 run_lib.py:133] step: 202900, training_loss: 2.49270e-02
I0209 08:47:45.191521 22542570456896 run_lib.py:146] step: 202900, eval_loss: 3.42895e-02
I0209 08:48:02.780575 22542570456896 run_lib.py:133] step: 202950, training_loss: 2.46023e-02
I0209 08:48:20.269612 22542570456896 run_lib.py:133] step: 203000, training_loss: 2.18747e-02
I0209 08:48:20.426786 22542570456896 run_lib.py:146] step: 203000, eval_loss: 2.51922e-02
I0209 08:48:37.870837 22542570456896 run_lib.py:133] step: 203050, training_loss: 3.31240e-02
I0209 08:48:55.493013 22542570456896 run_lib.py:133] step: 203100, training_loss: 2.56594e-02
I0209 08:48:55.648813 22542570456896 run_lib.py:146] step: 203100, eval_loss: 2.98610e-02
I0209 08:49:13.066512 22542570456896 run_lib.py:133] step: 203150, training_loss: 3.69050e-02
I0209 08:49:30.461903 22542570456896 run_lib.py:133] step: 203200, training_loss: 3.09891e-02
I0209 08:49:30.763775 22542570456896 run_lib.py:146] step: 203200, eval_loss: 2.67803e-02
I0209 08:49:48.245770 22542570456896 run_lib.py:133] step: 203250, training_loss: 3.22271e-02
I0209 08:50:05.705986 22542570456896 run_lib.py:133] step: 203300, training_loss: 2.18370e-02
I0209 08:50:05.861585 22542570456896 run_lib.py:146] step: 203300, eval_loss: 2.78684e-02
I0209 08:50:23.259454 22542570456896 run_lib.py:133] step: 203350, training_loss: 2.48673e-02
I0209 08:50:40.698755 22542570456896 run_lib.py:133] step: 203400, training_loss: 2.69768e-02
I0209 08:50:40.856753 22542570456896 run_lib.py:146] step: 203400, eval_loss: 2.13050e-02
I0209 08:50:58.488477 22542570456896 run_lib.py:133] step: 203450, training_loss: 3.41082e-02
I0209 08:51:16.007273 22542570456896 run_lib.py:133] step: 203500, training_loss: 2.28713e-02
I0209 08:51:16.176427 22542570456896 run_lib.py:146] step: 203500, eval_loss: 3.14013e-02
I0209 08:51:33.601900 22542570456896 run_lib.py:133] step: 203550, training_loss: 2.35645e-02
I0209 08:51:51.032045 22542570456896 run_lib.py:133] step: 203600, training_loss: 3.03698e-02
I0209 08:51:51.188637 22542570456896 run_lib.py:146] step: 203600, eval_loss: 3.02064e-02
I0209 08:52:08.783500 22542570456896 run_lib.py:133] step: 203650, training_loss: 3.50129e-02
I0209 08:52:26.294471 22542570456896 run_lib.py:133] step: 203700, training_loss: 2.23984e-02
I0209 08:52:26.441036 22542570456896 run_lib.py:146] step: 203700, eval_loss: 2.42856e-02
I0209 08:52:43.835409 22542570456896 run_lib.py:133] step: 203750, training_loss: 3.04918e-02
I0209 08:53:01.323214 22542570456896 run_lib.py:133] step: 203800, training_loss: 1.92904e-02
I0209 08:53:01.493595 22542570456896 run_lib.py:146] step: 203800, eval_loss: 2.99798e-02
I0209 08:53:19.142860 22542570456896 run_lib.py:133] step: 203850, training_loss: 2.85889e-02
I0209 08:53:36.605691 22542570456896 run_lib.py:133] step: 203900, training_loss: 2.82165e-02
I0209 08:53:36.768454 22542570456896 run_lib.py:146] step: 203900, eval_loss: 2.46717e-02
I0209 08:53:54.308682 22542570456896 run_lib.py:133] step: 203950, training_loss: 2.37703e-02
I0209 08:54:11.683904 22542570456896 run_lib.py:133] step: 204000, training_loss: 2.79794e-02
I0209 08:54:11.840392 22542570456896 run_lib.py:146] step: 204000, eval_loss: 3.45208e-02
I0209 08:54:29.413993 22542570456896 run_lib.py:133] step: 204050, training_loss: 3.35433e-02
I0209 08:54:46.883519 22542570456896 run_lib.py:133] step: 204100, training_loss: 2.80650e-02
I0209 08:54:47.039547 22542570456896 run_lib.py:146] step: 204100, eval_loss: 2.63577e-02
I0209 08:55:04.519225 22542570456896 run_lib.py:133] step: 204150, training_loss: 2.84480e-02
I0209 08:55:22.109998 22542570456896 run_lib.py:133] step: 204200, training_loss: 3.02227e-02
I0209 08:55:22.262421 22542570456896 run_lib.py:146] step: 204200, eval_loss: 2.41579e-02
I0209 08:55:39.650307 22542570456896 run_lib.py:133] step: 204250, training_loss: 2.62546e-02
I0209 08:55:57.200577 22542570456896 run_lib.py:133] step: 204300, training_loss: 3.49359e-02
I0209 08:55:57.359772 22542570456896 run_lib.py:146] step: 204300, eval_loss: 3.83288e-02
I0209 08:56:14.767126 22542570456896 run_lib.py:133] step: 204350, training_loss: 2.47014e-02
I0209 08:56:32.228883 22542570456896 run_lib.py:133] step: 204400, training_loss: 2.74221e-02
I0209 08:56:32.387320 22542570456896 run_lib.py:146] step: 204400, eval_loss: 3.15642e-02
I0209 08:56:50.015458 22542570456896 run_lib.py:133] step: 204450, training_loss: 2.90816e-02
I0209 08:57:07.489480 22542570456896 run_lib.py:133] step: 204500, training_loss: 3.23341e-02
I0209 08:57:07.646104 22542570456896 run_lib.py:146] step: 204500, eval_loss: 2.78323e-02
I0209 08:57:25.047492 22542570456896 run_lib.py:133] step: 204550, training_loss: 3.01434e-02
I0209 08:57:42.447510 22542570456896 run_lib.py:133] step: 204600, training_loss: 2.68130e-02
I0209 08:57:42.600462 22542570456896 run_lib.py:146] step: 204600, eval_loss: 2.47089e-02
I0209 08:58:00.186127 22542570456896 run_lib.py:133] step: 204650, training_loss: 2.25723e-02
I0209 08:58:17.632932 22542570456896 run_lib.py:133] step: 204700, training_loss: 3.14220e-02
I0209 08:58:17.790565 22542570456896 run_lib.py:146] step: 204700, eval_loss: 3.48165e-02
I0209 08:58:35.360307 22542570456896 run_lib.py:133] step: 204750, training_loss: 2.99517e-02
I0209 08:58:52.791668 22542570456896 run_lib.py:133] step: 204800, training_loss: 2.26106e-02
I0209 08:58:52.955455 22542570456896 run_lib.py:146] step: 204800, eval_loss: 3.41302e-02
I0209 08:59:10.371160 22542570456896 run_lib.py:133] step: 204850, training_loss: 2.69086e-02
I0209 08:59:27.781899 22542570456896 run_lib.py:133] step: 204900, training_loss: 2.90827e-02
I0209 08:59:27.937379 22542570456896 run_lib.py:146] step: 204900, eval_loss: 2.66623e-02
I0209 08:59:45.534795 22542570456896 run_lib.py:133] step: 204950, training_loss: 3.14025e-02
I0209 09:00:03.086149 22542570456896 run_lib.py:133] step: 205000, training_loss: 3.44109e-02
I0209 09:00:03.242919 22542570456896 run_lib.py:146] step: 205000, eval_loss: 2.97072e-02
I0209 09:00:20.737874 22542570456896 run_lib.py:133] step: 205050, training_loss: 2.94542e-02
I0209 09:00:38.112003 22542570456896 run_lib.py:133] step: 205100, training_loss: 2.79890e-02
I0209 09:00:38.265384 22542570456896 run_lib.py:146] step: 205100, eval_loss: 3.15082e-02
I0209 09:00:55.852137 22542570456896 run_lib.py:133] step: 205150, training_loss: 2.60612e-02
I0209 09:01:13.277656 22542570456896 run_lib.py:133] step: 205200, training_loss: 2.90097e-02
I0209 09:01:13.433371 22542570456896 run_lib.py:146] step: 205200, eval_loss: 3.77811e-02
I0209 09:01:30.967717 22542570456896 run_lib.py:133] step: 205250, training_loss: 2.83082e-02
I0209 09:01:48.457125 22542570456896 run_lib.py:133] step: 205300, training_loss: 3.25777e-02
I0209 09:01:48.623364 22542570456896 run_lib.py:146] step: 205300, eval_loss: 2.58057e-02
I0209 09:02:06.211881 22542570456896 run_lib.py:133] step: 205350, training_loss: 3.13859e-02
I0209 09:02:23.633133 22542570456896 run_lib.py:133] step: 205400, training_loss: 2.24717e-02
I0209 09:02:23.788763 22542570456896 run_lib.py:146] step: 205400, eval_loss: 3.18927e-02
I0209 09:02:41.361665 22542570456896 run_lib.py:133] step: 205450, training_loss: 3.25793e-02
I0209 09:02:58.768535 22542570456896 run_lib.py:133] step: 205500, training_loss: 2.64951e-02
I0209 09:02:58.923015 22542570456896 run_lib.py:146] step: 205500, eval_loss: 2.59213e-02
I0209 09:03:16.386350 22542570456896 run_lib.py:133] step: 205550, training_loss: 2.45048e-02
I0209 09:03:33.964827 22542570456896 run_lib.py:133] step: 205600, training_loss: 2.73679e-02
I0209 09:03:34.119632 22542570456896 run_lib.py:146] step: 205600, eval_loss: 3.12318e-02
I0209 09:03:51.604254 22542570456896 run_lib.py:133] step: 205650, training_loss: 3.04314e-02
I0209 09:04:09.027589 22542570456896 run_lib.py:133] step: 205700, training_loss: 3.00005e-02
I0209 09:04:09.183760 22542570456896 run_lib.py:146] step: 205700, eval_loss: 2.19804e-02
I0209 09:04:26.757997 22542570456896 run_lib.py:133] step: 205750, training_loss: 3.06890e-02
I0209 09:04:44.294637 22542570456896 run_lib.py:133] step: 205800, training_loss: 2.58032e-02
I0209 09:04:44.453580 22542570456896 run_lib.py:146] step: 205800, eval_loss: 2.80677e-02
I0209 09:05:01.935658 22542570456896 run_lib.py:133] step: 205850, training_loss: 2.81688e-02
I0209 09:05:19.366644 22542570456896 run_lib.py:133] step: 205900, training_loss: 3.54903e-02
I0209 09:05:19.531545 22542570456896 run_lib.py:146] step: 205900, eval_loss: 2.52572e-02
I0209 09:05:37.004526 22542570456896 run_lib.py:133] step: 205950, training_loss: 2.67078e-02
I0209 09:05:54.622058 22542570456896 run_lib.py:133] step: 206000, training_loss: 2.99983e-02
I0209 09:05:54.777058 22542570456896 run_lib.py:146] step: 206000, eval_loss: 2.63509e-02
I0209 09:06:12.166805 22542570456896 run_lib.py:133] step: 206050, training_loss: 2.81813e-02
I0209 09:06:29.558904 22542570456896 run_lib.py:133] step: 206100, training_loss: 2.34130e-02
I0209 09:06:29.713739 22542570456896 run_lib.py:146] step: 206100, eval_loss: 2.87510e-02
I0209 09:06:47.277205 22542570456896 run_lib.py:133] step: 206150, training_loss: 2.58207e-02
I0209 09:07:04.910232 22542570456896 run_lib.py:133] step: 206200, training_loss: 2.66567e-02
I0209 09:07:05.066426 22542570456896 run_lib.py:146] step: 206200, eval_loss: 2.59161e-02
I0209 09:07:22.477789 22542570456896 run_lib.py:133] step: 206250, training_loss: 3.08040e-02
I0209 09:07:39.934031 22542570456896 run_lib.py:133] step: 206300, training_loss: 2.92524e-02
I0209 09:07:40.090584 22542570456896 run_lib.py:146] step: 206300, eval_loss: 2.53956e-02
I0209 09:07:57.489926 22542570456896 run_lib.py:133] step: 206350, training_loss: 2.67916e-02
I0209 09:08:14.875651 22542570456896 run_lib.py:133] step: 206400, training_loss: 2.94576e-02
I0209 09:08:15.039457 22542570456896 run_lib.py:146] step: 206400, eval_loss: 3.62341e-02
I0209 09:08:32.608282 22542570456896 run_lib.py:133] step: 206450, training_loss: 2.74357e-02
I0209 09:08:50.157488 22542570456896 run_lib.py:133] step: 206500, training_loss: 3.35010e-02
I0209 09:08:50.310117 22542570456896 run_lib.py:146] step: 206500, eval_loss: 2.88449e-02
I0209 09:09:07.742999 22542570456896 run_lib.py:133] step: 206550, training_loss: 2.91013e-02
I0209 09:09:25.178445 22542570456896 run_lib.py:133] step: 206600, training_loss: 3.03281e-02
I0209 09:09:25.332365 22542570456896 run_lib.py:146] step: 206600, eval_loss: 2.50565e-02
I0209 09:09:42.879765 22542570456896 run_lib.py:133] step: 206650, training_loss: 2.89136e-02
I0209 09:10:00.288991 22542570456896 run_lib.py:133] step: 206700, training_loss: 3.09778e-02
I0209 09:10:00.471428 22542570456896 run_lib.py:146] step: 206700, eval_loss: 2.55934e-02
I0209 09:10:18.094806 22542570456896 run_lib.py:133] step: 206750, training_loss: 2.60265e-02
I0209 09:10:35.524581 22542570456896 run_lib.py:133] step: 206800, training_loss: 3.36624e-02
I0209 09:10:35.689376 22542570456896 run_lib.py:146] step: 206800, eval_loss: 3.38388e-02
I0209 09:10:53.259424 22542570456896 run_lib.py:133] step: 206850, training_loss: 3.09809e-02
I0209 09:11:10.668196 22542570456896 run_lib.py:133] step: 206900, training_loss: 2.78307e-02
I0209 09:11:10.823082 22542570456896 run_lib.py:146] step: 206900, eval_loss: 3.08417e-02
I0209 09:11:28.222224 22542570456896 run_lib.py:133] step: 206950, training_loss: 3.13037e-02
I0209 09:11:45.838180 22542570456896 run_lib.py:133] step: 207000, training_loss: 2.50158e-02
I0209 09:11:45.991338 22542570456896 run_lib.py:146] step: 207000, eval_loss: 3.24777e-02
I0209 09:12:03.464240 22542570456896 run_lib.py:133] step: 207050, training_loss: 3.04378e-02
I0209 09:12:21.069755 22542570456896 run_lib.py:133] step: 207100, training_loss: 2.33078e-02
I0209 09:12:21.226378 22542570456896 run_lib.py:146] step: 207100, eval_loss: 2.90276e-02
I0209 09:12:38.659927 22542570456896 run_lib.py:133] step: 207150, training_loss: 2.42377e-02
I0209 09:12:56.120971 22542570456896 run_lib.py:133] step: 207200, training_loss: 3.28589e-02
I0209 09:12:56.278697 22542570456896 run_lib.py:146] step: 207200, eval_loss: 2.53912e-02
I0209 09:13:13.830273 22542570456896 run_lib.py:133] step: 207250, training_loss: 3.14894e-02
I0209 09:13:31.283936 22542570456896 run_lib.py:133] step: 207300, training_loss: 3.46045e-02
I0209 09:13:31.440366 22542570456896 run_lib.py:146] step: 207300, eval_loss: 3.62964e-02
I0209 09:13:48.863964 22542570456896 run_lib.py:133] step: 207350, training_loss: 3.62337e-02
I0209 09:14:06.489131 22542570456896 run_lib.py:133] step: 207400, training_loss: 2.54025e-02
I0209 09:14:06.647407 22542570456896 run_lib.py:146] step: 207400, eval_loss: 3.33760e-02
I0209 09:14:24.056226 22542570456896 run_lib.py:133] step: 207450, training_loss: 3.29516e-02
I0209 09:14:41.463978 22542570456896 run_lib.py:133] step: 207500, training_loss: 3.11805e-02
I0209 09:14:41.615449 22542570456896 run_lib.py:146] step: 207500, eval_loss: 2.78144e-02
I0209 09:14:59.097317 22542570456896 run_lib.py:133] step: 207550, training_loss: 3.38723e-02
I0209 09:15:16.571670 22542570456896 run_lib.py:133] step: 207600, training_loss: 3.35794e-02
I0209 09:15:16.742661 22542570456896 run_lib.py:146] step: 207600, eval_loss: 3.12980e-02
I0209 09:15:34.205732 22542570456896 run_lib.py:133] step: 207650, training_loss: 2.99471e-02
I0209 09:15:51.651558 22542570456896 run_lib.py:133] step: 207700, training_loss: 2.76686e-02
I0209 09:15:51.816494 22542570456896 run_lib.py:146] step: 207700, eval_loss: 3.08314e-02
I0209 09:16:09.396279 22542570456896 run_lib.py:133] step: 207750, training_loss: 2.32289e-02
I0209 09:16:26.883967 22542570456896 run_lib.py:133] step: 207800, training_loss: 2.78694e-02
I0209 09:16:27.040235 22542570456896 run_lib.py:146] step: 207800, eval_loss: 3.00027e-02
I0209 09:16:44.470924 22542570456896 run_lib.py:133] step: 207850, training_loss: 2.49059e-02
I0209 09:17:01.967025 22542570456896 run_lib.py:133] step: 207900, training_loss: 3.05996e-02
I0209 09:17:02.129679 22542570456896 run_lib.py:146] step: 207900, eval_loss: 3.23889e-02
I0209 09:17:19.797227 22542570456896 run_lib.py:133] step: 207950, training_loss: 3.19169e-02
I0209 09:17:37.214979 22542570456896 run_lib.py:133] step: 208000, training_loss: 2.86824e-02
I0209 09:17:37.367343 22542570456896 run_lib.py:146] step: 208000, eval_loss: 2.93950e-02
I0209 09:17:54.943529 22542570456896 run_lib.py:133] step: 208050, training_loss: 2.49902e-02
I0209 09:18:12.345916 22542570456896 run_lib.py:133] step: 208100, training_loss: 3.06736e-02
I0209 09:18:12.505637 22542570456896 run_lib.py:146] step: 208100, eval_loss: 3.35208e-02
I0209 09:18:30.069827 22542570456896 run_lib.py:133] step: 208150, training_loss: 2.52307e-02
I0209 09:18:47.566036 22542570456896 run_lib.py:133] step: 208200, training_loss: 3.03684e-02
I0209 09:18:47.724612 22542570456896 run_lib.py:146] step: 208200, eval_loss: 2.67673e-02
I0209 09:19:05.342542 22542570456896 run_lib.py:133] step: 208250, training_loss: 2.95391e-02
I0209 09:19:22.802246 22542570456896 run_lib.py:133] step: 208300, training_loss: 2.78009e-02
I0209 09:19:22.966440 22542570456896 run_lib.py:146] step: 208300, eval_loss: 2.53117e-02
I0209 09:19:40.383954 22542570456896 run_lib.py:133] step: 208350, training_loss: 2.93563e-02
I0209 09:19:57.929278 22542570456896 run_lib.py:133] step: 208400, training_loss: 3.05451e-02
I0209 09:19:58.081411 22542570456896 run_lib.py:146] step: 208400, eval_loss: 3.07670e-02
I0209 09:20:15.467015 22542570456896 run_lib.py:133] step: 208450, training_loss: 2.75382e-02
I0209 09:20:32.907558 22542570456896 run_lib.py:133] step: 208500, training_loss: 3.03481e-02
I0209 09:20:33.070612 22542570456896 run_lib.py:146] step: 208500, eval_loss: 3.04205e-02
I0209 09:20:50.748151 22542570456896 run_lib.py:133] step: 208550, training_loss: 3.48497e-02
I0209 09:21:08.182491 22542570456896 run_lib.py:133] step: 208600, training_loss: 1.87548e-02
I0209 09:21:08.340138 22542570456896 run_lib.py:146] step: 208600, eval_loss: 2.52036e-02
I0209 09:21:25.902217 22542570456896 run_lib.py:133] step: 208650, training_loss: 3.89107e-02
I0209 09:21:43.306839 22542570456896 run_lib.py:133] step: 208700, training_loss: 3.27198e-02
I0209 09:21:43.462344 22542570456896 run_lib.py:146] step: 208700, eval_loss: 3.09748e-02
I0209 09:22:00.889746 22542570456896 run_lib.py:133] step: 208750, training_loss: 2.96940e-02
I0209 09:22:18.489470 22542570456896 run_lib.py:133] step: 208800, training_loss: 3.77668e-02
I0209 09:22:18.648990 22542570456896 run_lib.py:146] step: 208800, eval_loss: 3.03155e-02
I0209 09:22:36.116939 22542570456896 run_lib.py:133] step: 208850, training_loss: 3.34083e-02
I0209 09:22:53.520989 22542570456896 run_lib.py:133] step: 208900, training_loss: 2.85591e-02
I0209 09:22:53.672561 22542570456896 run_lib.py:146] step: 208900, eval_loss: 3.69716e-02
I0209 09:23:11.101743 22542570456896 run_lib.py:133] step: 208950, training_loss: 3.07738e-02
I0209 09:23:28.724527 22542570456896 run_lib.py:133] step: 209000, training_loss: 3.05701e-02
I0209 09:23:28.875686 22542570456896 run_lib.py:146] step: 209000, eval_loss: 3.18361e-02
I0209 09:23:46.282147 22542570456896 run_lib.py:133] step: 209050, training_loss: 3.31244e-02
I0209 09:24:03.770151 22542570456896 run_lib.py:133] step: 209100, training_loss: 2.63299e-02
I0209 09:24:03.946894 22542570456896 run_lib.py:146] step: 209100, eval_loss: 3.75337e-02
I0209 09:24:21.421071 22542570456896 run_lib.py:133] step: 209150, training_loss: 3.23673e-02
I0209 09:24:38.839575 22542570456896 run_lib.py:133] step: 209200, training_loss: 2.70492e-02
I0209 09:24:38.996580 22542570456896 run_lib.py:146] step: 209200, eval_loss: 3.03957e-02
I0209 09:24:56.591889 22542570456896 run_lib.py:133] step: 209250, training_loss: 2.68031e-02
I0209 09:25:14.038542 22542570456896 run_lib.py:133] step: 209300, training_loss: 2.57421e-02
I0209 09:25:14.192397 22542570456896 run_lib.py:146] step: 209300, eval_loss: 2.40554e-02
I0209 09:25:31.653339 22542570456896 run_lib.py:133] step: 209350, training_loss: 2.81625e-02
I0209 09:25:49.114404 22542570456896 run_lib.py:133] step: 209400, training_loss: 3.01834e-02
I0209 09:25:49.270666 22542570456896 run_lib.py:146] step: 209400, eval_loss: 3.57430e-02
I0209 09:26:06.911705 22542570456896 run_lib.py:133] step: 209450, training_loss: 2.96298e-02
I0209 09:26:24.314337 22542570456896 run_lib.py:133] step: 209500, training_loss: 2.71207e-02
I0209 09:26:24.469050 22542570456896 run_lib.py:146] step: 209500, eval_loss: 2.97848e-02
I0209 09:26:42.037473 22542570456896 run_lib.py:133] step: 209550, training_loss: 3.07973e-02
I0209 09:26:59.422884 22542570456896 run_lib.py:133] step: 209600, training_loss: 2.47863e-02
I0209 09:26:59.579080 22542570456896 run_lib.py:146] step: 209600, eval_loss: 2.66316e-02
I0209 09:27:17.122563 22542570456896 run_lib.py:133] step: 209650, training_loss: 3.18135e-02
I0209 09:27:34.558738 22542570456896 run_lib.py:133] step: 209700, training_loss: 3.21977e-02
I0209 09:27:34.716487 22542570456896 run_lib.py:146] step: 209700, eval_loss: 2.70111e-02
I0209 09:27:52.225946 22542570456896 run_lib.py:133] step: 209750, training_loss: 3.01538e-02
I0209 09:28:09.864534 22542570456896 run_lib.py:133] step: 209800, training_loss: 2.64710e-02
I0209 09:28:10.019362 22542570456896 run_lib.py:146] step: 209800, eval_loss: 2.17979e-02
I0209 09:28:27.468421 22542570456896 run_lib.py:133] step: 209850, training_loss: 2.60672e-02
I0209 09:28:45.020448 22542570456896 run_lib.py:133] step: 209900, training_loss: 3.14598e-02
I0209 09:28:45.172438 22542570456896 run_lib.py:146] step: 209900, eval_loss: 2.97138e-02
I0209 09:29:02.560696 22542570456896 run_lib.py:133] step: 209950, training_loss: 3.04788e-02
I0209 09:29:19.948524 22542570456896 run_lib.py:133] step: 210000, training_loss: 2.54510e-02
I0209 09:29:20.666273 22542570456896 run_lib.py:146] step: 210000, eval_loss: 2.71364e-02
I0209 09:29:40.958905 22542570456896 run_lib.py:133] step: 210050, training_loss: 3.14731e-02
I0209 09:29:58.402824 22542570456896 run_lib.py:133] step: 210100, training_loss: 2.17562e-02
I0209 09:29:58.560196 22542570456896 run_lib.py:146] step: 210100, eval_loss: 3.00116e-02
I0209 09:30:16.156050 22542570456896 run_lib.py:133] step: 210150, training_loss: 2.85796e-02
I0209 09:30:33.549885 22542570456896 run_lib.py:133] step: 210200, training_loss: 3.58709e-02
I0209 09:30:33.713427 22542570456896 run_lib.py:146] step: 210200, eval_loss: 2.67145e-02
I0209 09:30:51.129782 22542570456896 run_lib.py:133] step: 210250, training_loss: 3.84014e-02
I0209 09:31:08.816684 22542570456896 run_lib.py:133] step: 210300, training_loss: 3.17253e-02
I0209 09:31:08.972548 22542570456896 run_lib.py:146] step: 210300, eval_loss: 2.50364e-02
I0209 09:31:26.428471 22542570456896 run_lib.py:133] step: 210350, training_loss: 2.57662e-02
I0209 09:31:43.970255 22542570456896 run_lib.py:133] step: 210400, training_loss: 2.87407e-02
I0209 09:31:44.121331 22542570456896 run_lib.py:146] step: 210400, eval_loss: 3.07916e-02
I0209 09:32:01.511404 22542570456896 run_lib.py:133] step: 210450, training_loss: 3.17871e-02
I0209 09:32:18.950141 22542570456896 run_lib.py:133] step: 210500, training_loss: 2.55375e-02
I0209 09:32:19.108448 22542570456896 run_lib.py:146] step: 210500, eval_loss: 2.70643e-02
I0209 09:32:36.572749 22542570456896 run_lib.py:133] step: 210550, training_loss: 2.55281e-02
I0209 09:32:54.168351 22542570456896 run_lib.py:133] step: 210600, training_loss: 3.27860e-02
I0209 09:32:54.352305 22542570456896 run_lib.py:146] step: 210600, eval_loss: 2.32553e-02
I0209 09:33:11.801998 22542570456896 run_lib.py:133] step: 210650, training_loss: 2.51102e-02
I0209 09:33:29.275923 22542570456896 run_lib.py:133] step: 210700, training_loss: 2.34934e-02
I0209 09:33:29.431548 22542570456896 run_lib.py:146] step: 210700, eval_loss: 2.29075e-02
I0209 09:33:47.043823 22542570456896 run_lib.py:133] step: 210750, training_loss: 2.54662e-02
I0209 09:34:04.439079 22542570456896 run_lib.py:133] step: 210800, training_loss: 3.40910e-02
I0209 09:34:04.593218 22542570456896 run_lib.py:146] step: 210800, eval_loss: 2.89969e-02
I0209 09:34:22.088136 22542570456896 run_lib.py:133] step: 210850, training_loss: 2.83774e-02
I0209 09:34:39.586678 22542570456896 run_lib.py:133] step: 210900, training_loss: 2.61673e-02
I0209 09:34:39.743550 22542570456896 run_lib.py:146] step: 210900, eval_loss: 2.39131e-02
I0209 09:34:57.260532 22542570456896 run_lib.py:133] step: 210950, training_loss: 2.20809e-02
I0209 09:35:14.675431 22542570456896 run_lib.py:133] step: 211000, training_loss: 3.08610e-02
I0209 09:35:14.839515 22542570456896 run_lib.py:146] step: 211000, eval_loss: 3.36634e-02
I0209 09:35:32.450071 22542570456896 run_lib.py:133] step: 211050, training_loss: 2.67796e-02
I0209 09:35:49.924967 22542570456896 run_lib.py:133] step: 211100, training_loss: 3.36076e-02
I0209 09:35:50.101631 22542570456896 run_lib.py:146] step: 211100, eval_loss: 2.80836e-02
I0209 09:36:07.560818 22542570456896 run_lib.py:133] step: 211150, training_loss: 2.67293e-02
I0209 09:36:24.984262 22542570456896 run_lib.py:133] step: 211200, training_loss: 3.21477e-02
I0209 09:36:25.142122 22542570456896 run_lib.py:146] step: 211200, eval_loss: 2.34159e-02
I0209 09:36:42.762927 22542570456896 run_lib.py:133] step: 211250, training_loss: 2.98661e-02
I0209 09:37:00.205223 22542570456896 run_lib.py:133] step: 211300, training_loss: 3.25418e-02
I0209 09:37:00.360294 22542570456896 run_lib.py:146] step: 211300, eval_loss: 2.81310e-02
I0209 09:37:17.901855 22542570456896 run_lib.py:133] step: 211350, training_loss: 2.36699e-02
I0209 09:37:35.357290 22542570456896 run_lib.py:133] step: 211400, training_loss: 1.97610e-02
I0209 09:37:35.511538 22542570456896 run_lib.py:146] step: 211400, eval_loss: 2.92039e-02
I0209 09:37:53.174674 22542570456896 run_lib.py:133] step: 211450, training_loss: 3.40224e-02
I0209 09:38:10.613430 22542570456896 run_lib.py:133] step: 211500, training_loss: 2.99908e-02
I0209 09:38:10.775459 22542570456896 run_lib.py:146] step: 211500, eval_loss: 2.73841e-02
I0209 09:38:28.355555 22542570456896 run_lib.py:133] step: 211550, training_loss: 2.88556e-02
I0209 09:38:45.736069 22542570456896 run_lib.py:133] step: 211600, training_loss: 2.50269e-02
I0209 09:38:45.891414 22542570456896 run_lib.py:146] step: 211600, eval_loss: 3.14266e-02
I0209 09:39:03.316073 22542570456896 run_lib.py:133] step: 211650, training_loss: 3.01292e-02
I0209 09:39:20.944973 22542570456896 run_lib.py:133] step: 211700, training_loss: 3.57291e-02
I0209 09:39:21.101092 22542570456896 run_lib.py:146] step: 211700, eval_loss: 2.59323e-02
I0209 09:39:38.543383 22542570456896 run_lib.py:133] step: 211750, training_loss: 2.74321e-02
I0209 09:39:55.929807 22542570456896 run_lib.py:133] step: 211800, training_loss: 3.32159e-02
I0209 09:39:56.083102 22542570456896 run_lib.py:146] step: 211800, eval_loss: 2.55952e-02
I0209 09:40:13.643201 22542570456896 run_lib.py:133] step: 211850, training_loss: 3.13433e-02
I0209 09:40:31.009055 22542570456896 run_lib.py:133] step: 211900, training_loss: 2.90872e-02
I0209 09:40:31.163216 22542570456896 run_lib.py:146] step: 211900, eval_loss: 3.23928e-02
I0209 09:40:48.622303 22542570456896 run_lib.py:133] step: 211950, training_loss: 3.19023e-02
I0209 09:41:06.039194 22542570456896 run_lib.py:133] step: 212000, training_loss: 2.39264e-02
I0209 09:41:06.212185 22542570456896 run_lib.py:146] step: 212000, eval_loss: 2.82147e-02
I0209 09:41:23.648597 22542570456896 run_lib.py:133] step: 212050, training_loss: 2.66632e-02
I0209 09:41:41.255963 22542570456896 run_lib.py:133] step: 212100, training_loss: 2.68579e-02
I0209 09:41:41.412562 22542570456896 run_lib.py:146] step: 212100, eval_loss: 2.54816e-02
I0209 09:41:58.843487 22542570456896 run_lib.py:133] step: 212150, training_loss: 2.73144e-02
I0209 09:42:16.260545 22542570456896 run_lib.py:133] step: 212200, training_loss: 3.13571e-02
I0209 09:42:16.419125 22542570456896 run_lib.py:146] step: 212200, eval_loss: 2.99861e-02
I0209 09:42:33.879472 22542570456896 run_lib.py:133] step: 212250, training_loss: 3.17259e-02
I0209 09:42:51.518383 22542570456896 run_lib.py:133] step: 212300, training_loss: 2.50735e-02
I0209 09:42:51.671537 22542570456896 run_lib.py:146] step: 212300, eval_loss: 2.85334e-02
I0209 09:43:09.121519 22542570456896 run_lib.py:133] step: 212350, training_loss: 2.58054e-02
I0209 09:43:26.670884 22542570456896 run_lib.py:133] step: 212400, training_loss: 2.43532e-02
I0209 09:43:26.826377 22542570456896 run_lib.py:146] step: 212400, eval_loss: 3.32529e-02
I0209 09:43:44.223377 22542570456896 run_lib.py:133] step: 212450, training_loss: 2.32327e-02
I0209 09:44:01.661375 22542570456896 run_lib.py:133] step: 212500, training_loss: 2.94526e-02
I0209 09:44:01.819563 22542570456896 run_lib.py:146] step: 212500, eval_loss: 2.54096e-02
I0209 09:44:19.368254 22542570456896 run_lib.py:133] step: 212550, training_loss: 2.16639e-02
I0209 09:44:36.884677 22542570456896 run_lib.py:133] step: 212600, training_loss: 2.16180e-02
I0209 09:44:37.041605 22542570456896 run_lib.py:146] step: 212600, eval_loss: 2.72427e-02
I0209 09:44:54.476264 22542570456896 run_lib.py:133] step: 212650, training_loss: 2.98806e-02
I0209 09:45:11.929829 22542570456896 run_lib.py:133] step: 212700, training_loss: 2.91040e-02
I0209 09:45:12.085443 22542570456896 run_lib.py:146] step: 212700, eval_loss: 2.74614e-02
I0209 09:45:29.666039 22542570456896 run_lib.py:133] step: 212750, training_loss: 3.45643e-02
I0209 09:45:47.113780 22542570456896 run_lib.py:133] step: 212800, training_loss: 2.88962e-02
I0209 09:45:47.265503 22542570456896 run_lib.py:146] step: 212800, eval_loss: 2.58796e-02
I0209 09:46:04.860457 22542570456896 run_lib.py:133] step: 212850, training_loss: 3.14249e-02
I0209 09:46:22.290246 22542570456896 run_lib.py:133] step: 212900, training_loss: 2.50450e-02
I0209 09:46:22.460368 22542570456896 run_lib.py:146] step: 212900, eval_loss: 3.32669e-02
I0209 09:46:40.067984 22542570456896 run_lib.py:133] step: 212950, training_loss: 3.66693e-02
I0209 09:46:57.491384 22542570456896 run_lib.py:133] step: 213000, training_loss: 3.01223e-02
I0209 09:46:57.646291 22542570456896 run_lib.py:146] step: 213000, eval_loss: 3.11250e-02
I0209 09:47:15.114360 22542570456896 run_lib.py:133] step: 213050, training_loss: 2.39339e-02
I0209 09:47:32.649572 22542570456896 run_lib.py:133] step: 213100, training_loss: 3.20426e-02
I0209 09:47:32.804395 22542570456896 run_lib.py:146] step: 213100, eval_loss: 2.87062e-02
I0209 09:47:50.255723 22542570456896 run_lib.py:133] step: 213150, training_loss: 2.36756e-02
I0209 09:48:07.903176 22542570456896 run_lib.py:133] step: 213200, training_loss: 2.45722e-02
I0209 09:48:08.057583 22542570456896 run_lib.py:146] step: 213200, eval_loss: 3.02034e-02
I0209 09:48:25.527271 22542570456896 run_lib.py:133] step: 213250, training_loss: 3.16176e-02
I0209 09:48:42.968975 22542570456896 run_lib.py:133] step: 213300, training_loss: 2.73400e-02
I0209 09:48:43.127315 22542570456896 run_lib.py:146] step: 213300, eval_loss: 2.72394e-02
I0209 09:49:00.765830 22542570456896 run_lib.py:133] step: 213350, training_loss: 2.38454e-02
I0209 09:49:18.156816 22542570456896 run_lib.py:133] step: 213400, training_loss: 3.46910e-02
I0209 09:49:18.323575 22542570456896 run_lib.py:146] step: 213400, eval_loss: 2.48371e-02
I0209 09:49:35.762604 22542570456896 run_lib.py:133] step: 213450, training_loss: 3.03134e-02
I0209 09:49:53.398012 22542570456896 run_lib.py:133] step: 213500, training_loss: 2.35104e-02
I0209 09:49:53.551726 22542570456896 run_lib.py:146] step: 213500, eval_loss: 2.84017e-02
I0209 09:50:10.919463 22542570456896 run_lib.py:133] step: 213550, training_loss: 2.89771e-02
I0209 09:50:28.349182 22542570456896 run_lib.py:133] step: 213600, training_loss: 2.71459e-02
I0209 09:50:28.679391 22542570456896 run_lib.py:146] step: 213600, eval_loss: 3.06701e-02
I0209 09:50:46.128233 22542570456896 run_lib.py:133] step: 213650, training_loss: 3.05716e-02
I0209 09:51:03.539531 22542570456896 run_lib.py:133] step: 213700, training_loss: 2.39127e-02
I0209 09:51:03.690298 22542570456896 run_lib.py:146] step: 213700, eval_loss: 2.66495e-02
I0209 09:51:21.141754 22542570456896 run_lib.py:133] step: 213750, training_loss: 3.50539e-02
I0209 09:51:38.585969 22542570456896 run_lib.py:133] step: 213800, training_loss: 2.15402e-02
I0209 09:51:38.750567 22542570456896 run_lib.py:146] step: 213800, eval_loss: 3.14895e-02
I0209 09:51:56.378122 22542570456896 run_lib.py:133] step: 213850, training_loss: 3.38129e-02
I0209 09:52:13.867987 22542570456896 run_lib.py:133] step: 213900, training_loss: 2.39049e-02
I0209 09:52:14.025544 22542570456896 run_lib.py:146] step: 213900, eval_loss: 2.98276e-02
I0209 09:52:31.487515 22542570456896 run_lib.py:133] step: 213950, training_loss: 2.99001e-02
I0209 09:52:48.923489 22542570456896 run_lib.py:133] step: 214000, training_loss: 2.69155e-02
I0209 09:52:49.091344 22542570456896 run_lib.py:146] step: 214000, eval_loss: 3.13233e-02
I0209 09:53:06.712783 22542570456896 run_lib.py:133] step: 214050, training_loss: 2.54871e-02
I0209 09:53:24.218458 22542570456896 run_lib.py:133] step: 214100, training_loss: 2.82898e-02
I0209 09:53:24.378132 22542570456896 run_lib.py:146] step: 214100, eval_loss: 2.51454e-02
I0209 09:53:41.800957 22542570456896 run_lib.py:133] step: 214150, training_loss: 2.43971e-02
I0209 09:53:59.225115 22542570456896 run_lib.py:133] step: 214200, training_loss: 3.68223e-02
I0209 09:53:59.385337 22542570456896 run_lib.py:146] step: 214200, eval_loss: 2.84923e-02
I0209 09:54:16.944276 22542570456896 run_lib.py:133] step: 214250, training_loss: 2.90810e-02
I0209 09:54:34.367451 22542570456896 run_lib.py:133] step: 214300, training_loss: 2.99639e-02
I0209 09:54:34.540002 22542570456896 run_lib.py:146] step: 214300, eval_loss: 3.35558e-02
I0209 09:54:52.162309 22542570456896 run_lib.py:133] step: 214350, training_loss: 3.30848e-02
I0209 09:55:09.592659 22542570456896 run_lib.py:133] step: 214400, training_loss: 3.24563e-02
I0209 09:55:09.750320 22542570456896 run_lib.py:146] step: 214400, eval_loss: 3.12335e-02
I0209 09:55:27.323597 22542570456896 run_lib.py:133] step: 214450, training_loss: 3.34685e-02
I0209 09:55:44.743669 22542570456896 run_lib.py:133] step: 214500, training_loss: 3.00703e-02
I0209 09:55:44.909894 22542570456896 run_lib.py:146] step: 214500, eval_loss: 2.44555e-02
I0209 09:56:02.314055 22542570456896 run_lib.py:133] step: 214550, training_loss: 2.41799e-02
I0209 09:56:19.871977 22542570456896 run_lib.py:133] step: 214600, training_loss: 2.61406e-02
I0209 09:56:20.026536 22542570456896 run_lib.py:146] step: 214600, eval_loss: 3.12854e-02
I0209 09:56:37.484805 22542570456896 run_lib.py:133] step: 214650, training_loss: 2.48362e-02
I0209 09:56:55.069737 22542570456896 run_lib.py:133] step: 214700, training_loss: 2.55484e-02
I0209 09:56:55.220355 22542570456896 run_lib.py:146] step: 214700, eval_loss: 2.70031e-02
I0209 09:57:12.645570 22542570456896 run_lib.py:133] step: 214750, training_loss: 2.56930e-02
I0209 09:57:30.057950 22542570456896 run_lib.py:133] step: 214800, training_loss: 2.90459e-02
I0209 09:57:30.217548 22542570456896 run_lib.py:146] step: 214800, eval_loss: 3.11869e-02
I0209 09:57:47.753821 22542570456896 run_lib.py:133] step: 214850, training_loss: 2.36438e-02
I0209 09:58:05.155893 22542570456896 run_lib.py:133] step: 214900, training_loss: 2.61267e-02
I0209 09:58:05.331176 22542570456896 run_lib.py:146] step: 214900, eval_loss: 2.55718e-02
I0209 09:58:22.771305 22542570456896 run_lib.py:133] step: 214950, training_loss: 3.19616e-02
I0209 09:58:40.231374 22542570456896 run_lib.py:133] step: 215000, training_loss: 3.20138e-02
I0209 09:58:40.390119 22542570456896 run_lib.py:146] step: 215000, eval_loss: 3.17110e-02
I0209 09:58:57.961827 22542570456896 run_lib.py:133] step: 215050, training_loss: 2.57318e-02
I0209 09:59:15.388408 22542570456896 run_lib.py:133] step: 215100, training_loss: 2.76611e-02
I0209 09:59:15.542129 22542570456896 run_lib.py:146] step: 215100, eval_loss: 2.51037e-02
I0209 09:59:33.023899 22542570456896 run_lib.py:133] step: 215150, training_loss: 3.10718e-02
I0209 09:59:50.502465 22542570456896 run_lib.py:133] step: 215200, training_loss: 2.48550e-02
I0209 09:59:50.659089 22542570456896 run_lib.py:146] step: 215200, eval_loss: 2.99078e-02
I0209 10:00:08.144073 22542570456896 run_lib.py:133] step: 215250, training_loss: 3.28522e-02
I0209 10:00:25.604559 22542570456896 run_lib.py:133] step: 215300, training_loss: 2.84580e-02
I0209 10:00:25.771726 22542570456896 run_lib.py:146] step: 215300, eval_loss: 2.81357e-02
I0209 10:00:43.335772 22542570456896 run_lib.py:133] step: 215350, training_loss: 2.31970e-02
I0209 10:01:00.865881 22542570456896 run_lib.py:133] step: 215400, training_loss: 2.86377e-02
I0209 10:01:01.022197 22542570456896 run_lib.py:146] step: 215400, eval_loss: 2.88137e-02
I0209 10:01:18.469190 22542570456896 run_lib.py:133] step: 215450, training_loss: 2.80244e-02
I0209 10:01:35.905842 22542570456896 run_lib.py:133] step: 215500, training_loss: 2.65410e-02
I0209 10:01:36.062928 22542570456896 run_lib.py:146] step: 215500, eval_loss: 2.81542e-02
I0209 10:01:53.669575 22542570456896 run_lib.py:133] step: 215550, training_loss: 2.47650e-02
I0209 10:02:11.098561 22542570456896 run_lib.py:133] step: 215600, training_loss: 3.36411e-02
I0209 10:02:11.249106 22542570456896 run_lib.py:146] step: 215600, eval_loss: 2.70637e-02
I0209 10:02:28.837147 22542570456896 run_lib.py:133] step: 215650, training_loss: 3.00329e-02
I0209 10:02:46.280154 22542570456896 run_lib.py:133] step: 215700, training_loss: 2.75175e-02
I0209 10:02:46.440977 22542570456896 run_lib.py:146] step: 215700, eval_loss: 2.91672e-02
I0209 10:03:04.031155 22542570456896 run_lib.py:133] step: 215750, training_loss: 2.83616e-02
I0209 10:03:21.506332 22542570456896 run_lib.py:133] step: 215800, training_loss: 3.96610e-02
I0209 10:03:21.683341 22542570456896 run_lib.py:146] step: 215800, eval_loss: 2.64510e-02
I0209 10:03:39.306321 22542570456896 run_lib.py:133] step: 215850, training_loss: 2.90394e-02
I0209 10:03:56.718861 22542570456896 run_lib.py:133] step: 215900, training_loss: 2.38625e-02
I0209 10:03:56.875500 22542570456896 run_lib.py:146] step: 215900, eval_loss: 3.00215e-02
I0209 10:04:14.331464 22542570456896 run_lib.py:133] step: 215950, training_loss: 3.18807e-02
I0209 10:04:31.922676 22542570456896 run_lib.py:133] step: 216000, training_loss: 2.57554e-02
I0209 10:04:32.078181 22542570456896 run_lib.py:146] step: 216000, eval_loss: 3.03093e-02
I0209 10:04:49.490297 22542570456896 run_lib.py:133] step: 216050, training_loss: 2.73834e-02
I0209 10:05:06.934527 22542570456896 run_lib.py:133] step: 216100, training_loss: 3.40795e-02
I0209 10:05:07.091457 22542570456896 run_lib.py:146] step: 216100, eval_loss: 2.34259e-02
I0209 10:05:24.752747 22542570456896 run_lib.py:133] step: 216150, training_loss: 2.51553e-02
I0209 10:05:42.363198 22542570456896 run_lib.py:133] step: 216200, training_loss: 3.69042e-02
I0209 10:05:42.527103 22542570456896 run_lib.py:146] step: 216200, eval_loss: 2.94886e-02
I0209 10:05:59.951751 22542570456896 run_lib.py:133] step: 216250, training_loss: 2.77283e-02
I0209 10:06:17.379990 22542570456896 run_lib.py:133] step: 216300, training_loss: 2.70940e-02
I0209 10:06:17.536475 22542570456896 run_lib.py:146] step: 216300, eval_loss: 2.45332e-02
I0209 10:06:34.971469 22542570456896 run_lib.py:133] step: 216350, training_loss: 3.41800e-02
I0209 10:06:52.619223 22542570456896 run_lib.py:133] step: 216400, training_loss: 2.92012e-02
I0209 10:06:52.777738 22542570456896 run_lib.py:146] step: 216400, eval_loss: 3.31026e-02
I0209 10:07:10.179528 22542570456896 run_lib.py:133] step: 216450, training_loss: 3.89197e-02
I0209 10:07:27.630821 22542570456896 run_lib.py:133] step: 216500, training_loss: 2.54053e-02
I0209 10:07:27.785312 22542570456896 run_lib.py:146] step: 216500, eval_loss: 3.25053e-02
I0209 10:07:45.192382 22542570456896 run_lib.py:133] step: 216550, training_loss: 3.09594e-02
I0209 10:08:02.808105 22542570456896 run_lib.py:133] step: 216600, training_loss: 3.03623e-02
I0209 10:08:02.961539 22542570456896 run_lib.py:146] step: 216600, eval_loss: 2.67360e-02
I0209 10:08:20.406399 22542570456896 run_lib.py:133] step: 216650, training_loss: 2.97534e-02
I0209 10:08:37.892734 22542570456896 run_lib.py:133] step: 216700, training_loss: 2.75583e-02
I0209 10:08:38.050590 22542570456896 run_lib.py:146] step: 216700, eval_loss: 2.45353e-02
I0209 10:08:55.427742 22542570456896 run_lib.py:133] step: 216750, training_loss: 2.48825e-02
I0209 10:09:12.857921 22542570456896 run_lib.py:133] step: 216800, training_loss: 2.19178e-02
I0209 10:09:13.022544 22542570456896 run_lib.py:146] step: 216800, eval_loss: 2.65915e-02
I0209 10:09:30.649351 22542570456896 run_lib.py:133] step: 216850, training_loss: 2.90459e-02
I0209 10:09:48.113597 22542570456896 run_lib.py:133] step: 216900, training_loss: 3.18412e-02
I0209 10:09:48.278843 22542570456896 run_lib.py:146] step: 216900, eval_loss: 3.21188e-02
I0209 10:10:05.731557 22542570456896 run_lib.py:133] step: 216950, training_loss: 3.17271e-02
I0209 10:10:23.135521 22542570456896 run_lib.py:133] step: 217000, training_loss: 2.44756e-02
I0209 10:10:23.294253 22542570456896 run_lib.py:146] step: 217000, eval_loss: 3.44471e-02
I0209 10:10:40.904441 22542570456896 run_lib.py:133] step: 217050, training_loss: 2.93274e-02
I0209 10:10:58.303597 22542570456896 run_lib.py:133] step: 217100, training_loss: 2.02816e-02
I0209 10:10:58.457374 22542570456896 run_lib.py:146] step: 217100, eval_loss: 3.12997e-02
I0209 10:11:16.004394 22542570456896 run_lib.py:133] step: 217150, training_loss: 2.11675e-02
I0209 10:11:33.429124 22542570456896 run_lib.py:133] step: 217200, training_loss: 2.87152e-02
I0209 10:11:33.587434 22542570456896 run_lib.py:146] step: 217200, eval_loss: 3.28232e-02
I0209 10:11:51.180158 22542570456896 run_lib.py:133] step: 217250, training_loss: 3.39892e-02
I0209 10:12:08.681490 22542570456896 run_lib.py:133] step: 217300, training_loss: 2.83942e-02
I0209 10:12:08.837470 22542570456896 run_lib.py:146] step: 217300, eval_loss: 2.51787e-02
I0209 10:12:26.245187 22542570456896 run_lib.py:133] step: 217350, training_loss: 2.71898e-02
I0209 10:12:43.814166 22542570456896 run_lib.py:133] step: 217400, training_loss: 2.93732e-02
I0209 10:12:43.978638 22542570456896 run_lib.py:146] step: 217400, eval_loss: 3.30584e-02
I0209 10:13:01.394032 22542570456896 run_lib.py:133] step: 217450, training_loss: 2.28436e-02
I0209 10:13:18.962867 22542570456896 run_lib.py:133] step: 217500, training_loss: 2.62688e-02
I0209 10:13:19.114921 22542570456896 run_lib.py:146] step: 217500, eval_loss: 2.87566e-02
I0209 10:13:36.548072 22542570456896 run_lib.py:133] step: 217550, training_loss: 2.75716e-02
I0209 10:13:54.000868 22542570456896 run_lib.py:133] step: 217600, training_loss: 2.59243e-02
I0209 10:13:54.168659 22542570456896 run_lib.py:146] step: 217600, eval_loss: 2.80737e-02
I0209 10:14:11.769649 22542570456896 run_lib.py:133] step: 217650, training_loss: 2.43469e-02
I0209 10:14:29.213063 22542570456896 run_lib.py:133] step: 217700, training_loss: 2.87726e-02
I0209 10:14:29.372365 22542570456896 run_lib.py:146] step: 217700, eval_loss: 2.74212e-02
I0209 10:14:46.774131 22542570456896 run_lib.py:133] step: 217750, training_loss: 2.72114e-02
I0209 10:15:04.314486 22542570456896 run_lib.py:133] step: 217800, training_loss: 2.84760e-02
I0209 10:15:04.483232 22542570456896 run_lib.py:146] step: 217800, eval_loss: 3.81599e-02
I0209 10:15:21.909100 22542570456896 run_lib.py:133] step: 217850, training_loss: 2.89848e-02
I0209 10:15:39.364585 22542570456896 run_lib.py:133] step: 217900, training_loss: 2.76078e-02
I0209 10:15:39.519513 22542570456896 run_lib.py:146] step: 217900, eval_loss: 2.65219e-02
I0209 10:15:57.071539 22542570456896 run_lib.py:133] step: 217950, training_loss: 2.55528e-02
I0209 10:16:14.476418 22542570456896 run_lib.py:133] step: 218000, training_loss: 3.54264e-02
I0209 10:16:14.627365 22542570456896 run_lib.py:146] step: 218000, eval_loss: 2.96241e-02
I0209 10:16:32.009436 22542570456896 run_lib.py:133] step: 218050, training_loss: 2.95824e-02
I0209 10:16:49.441895 22542570456896 run_lib.py:133] step: 218100, training_loss: 2.23583e-02
I0209 10:16:49.607574 22542570456896 run_lib.py:146] step: 218100, eval_loss: 2.95420e-02
I0209 10:17:07.200347 22542570456896 run_lib.py:133] step: 218150, training_loss: 2.60285e-02
I0209 10:17:24.692112 22542570456896 run_lib.py:133] step: 218200, training_loss: 2.65047e-02
I0209 10:17:24.857403 22542570456896 run_lib.py:146] step: 218200, eval_loss: 3.01479e-02
I0209 10:17:42.234308 22542570456896 run_lib.py:133] step: 218250, training_loss: 2.37778e-02
I0209 10:17:59.628461 22542570456896 run_lib.py:133] step: 218300, training_loss: 2.82597e-02
I0209 10:17:59.784404 22542570456896 run_lib.py:146] step: 218300, eval_loss: 3.26700e-02
I0209 10:18:17.325896 22542570456896 run_lib.py:133] step: 218350, training_loss: 2.42978e-02
I0209 10:18:34.720880 22542570456896 run_lib.py:133] step: 218400, training_loss: 2.86569e-02
I0209 10:18:34.878664 22542570456896 run_lib.py:146] step: 218400, eval_loss: 3.20077e-02
I0209 10:18:52.467541 22542570456896 run_lib.py:133] step: 218450, training_loss: 3.45544e-02
I0209 10:19:09.865489 22542570456896 run_lib.py:133] step: 218500, training_loss: 2.84059e-02
I0209 10:19:10.019317 22542570456896 run_lib.py:146] step: 218500, eval_loss: 2.90115e-02
I0209 10:19:27.652780 22542570456896 run_lib.py:133] step: 218550, training_loss: 2.52736e-02
I0209 10:19:45.096074 22542570456896 run_lib.py:133] step: 218600, training_loss: 2.89475e-02
I0209 10:19:45.256986 22542570456896 run_lib.py:146] step: 218600, eval_loss: 2.40290e-02
I0209 10:20:02.793000 22542570456896 run_lib.py:133] step: 218650, training_loss: 2.79120e-02
I0209 10:20:20.217319 22542570456896 run_lib.py:133] step: 218700, training_loss: 2.59309e-02
I0209 10:20:20.386338 22542570456896 run_lib.py:146] step: 218700, eval_loss: 3.15630e-02
I0209 10:20:37.852765 22542570456896 run_lib.py:133] step: 218750, training_loss: 2.65500e-02
I0209 10:20:55.479341 22542570456896 run_lib.py:133] step: 218800, training_loss: 2.91851e-02
I0209 10:20:55.635859 22542570456896 run_lib.py:146] step: 218800, eval_loss: 3.75983e-02
I0209 10:21:13.063487 22542570456896 run_lib.py:133] step: 218850, training_loss: 2.76696e-02
I0209 10:21:30.476116 22542570456896 run_lib.py:133] step: 218900, training_loss: 2.75179e-02
I0209 10:21:30.628032 22542570456896 run_lib.py:146] step: 218900, eval_loss: 3.03831e-02
I0209 10:21:48.198915 22542570456896 run_lib.py:133] step: 218950, training_loss: 2.37476e-02
I0209 10:22:05.649091 22542570456896 run_lib.py:133] step: 219000, training_loss: 2.58606e-02
I0209 10:22:05.811133 22542570456896 run_lib.py:146] step: 219000, eval_loss: 2.63616e-02
I0209 10:22:23.431596 22542570456896 run_lib.py:133] step: 219050, training_loss: 2.79115e-02
I0209 10:22:40.870934 22542570456896 run_lib.py:133] step: 219100, training_loss: 3.18765e-02
I0209 10:22:41.030281 22542570456896 run_lib.py:146] step: 219100, eval_loss: 3.10061e-02
I0209 10:22:58.435276 22542570456896 run_lib.py:133] step: 219150, training_loss: 2.59360e-02
I0209 10:23:15.998498 22542570456896 run_lib.py:133] step: 219200, training_loss: 2.61160e-02
I0209 10:23:16.154295 22542570456896 run_lib.py:146] step: 219200, eval_loss: 3.37710e-02
I0209 10:23:33.585724 22542570456896 run_lib.py:133] step: 219250, training_loss: 4.13682e-02
I0209 10:23:51.090420 22542570456896 run_lib.py:133] step: 219300, training_loss: 2.31731e-02
I0209 10:23:51.245632 22542570456896 run_lib.py:146] step: 219300, eval_loss: 2.54827e-02
I0209 10:24:08.668022 22542570456896 run_lib.py:133] step: 219350, training_loss: 3.16419e-02
I0209 10:24:26.299659 22542570456896 run_lib.py:133] step: 219400, training_loss: 2.48410e-02
I0209 10:24:26.450987 22542570456896 run_lib.py:146] step: 219400, eval_loss: 2.98505e-02
I0209 10:24:43.876605 22542570456896 run_lib.py:133] step: 219450, training_loss: 2.53654e-02
I0209 10:25:01.355572 22542570456896 run_lib.py:133] step: 219500, training_loss: 2.79461e-02
I0209 10:25:01.510436 22542570456896 run_lib.py:146] step: 219500, eval_loss: 3.22958e-02
I0209 10:25:18.927312 22542570456896 run_lib.py:133] step: 219550, training_loss: 2.71773e-02
I0209 10:25:36.339607 22542570456896 run_lib.py:133] step: 219600, training_loss: 2.55838e-02
I0209 10:25:36.516276 22542570456896 run_lib.py:146] step: 219600, eval_loss: 2.93323e-02
I0209 10:25:54.135832 22542570456896 run_lib.py:133] step: 219650, training_loss: 3.43148e-02
I0209 10:26:11.709215 22542570456896 run_lib.py:133] step: 219700, training_loss: 3.45975e-02
I0209 10:26:11.865627 22542570456896 run_lib.py:146] step: 219700, eval_loss: 2.52242e-02
I0209 10:26:29.328238 22542570456896 run_lib.py:133] step: 219750, training_loss: 2.47843e-02
I0209 10:26:46.766740 22542570456896 run_lib.py:133] step: 219800, training_loss: 3.03197e-02
I0209 10:26:46.922427 22542570456896 run_lib.py:146] step: 219800, eval_loss: 3.24045e-02
I0209 10:27:04.481694 22542570456896 run_lib.py:133] step: 219850, training_loss: 2.76911e-02
I0209 10:27:22.025808 22542570456896 run_lib.py:133] step: 219900, training_loss: 2.47064e-02
I0209 10:27:22.180536 22542570456896 run_lib.py:146] step: 219900, eval_loss: 2.72255e-02
I0209 10:27:39.793897 22542570456896 run_lib.py:133] step: 219950, training_loss: 3.19581e-02
I0209 10:27:57.237930 22542570456896 run_lib.py:133] step: 220000, training_loss: 3.21532e-02
I0209 10:27:57.937238 22542570456896 run_lib.py:146] step: 220000, eval_loss: 2.24518e-02
I0209 10:28:18.241770 22542570456896 run_lib.py:133] step: 220050, training_loss: 2.92180e-02
I0209 10:28:35.651118 22542570456896 run_lib.py:133] step: 220100, training_loss: 3.09245e-02
I0209 10:28:35.820364 22542570456896 run_lib.py:146] step: 220100, eval_loss: 2.55412e-02
I0209 10:28:53.309870 22542570456896 run_lib.py:133] step: 220150, training_loss: 2.69796e-02
I0209 10:29:10.742711 22542570456896 run_lib.py:133] step: 220200, training_loss: 2.36434e-02
I0209 10:29:10.899394 22542570456896 run_lib.py:146] step: 220200, eval_loss: 2.60601e-02
I0209 10:29:28.315280 22542570456896 run_lib.py:133] step: 220250, training_loss: 3.10179e-02
I0209 10:29:45.742421 22542570456896 run_lib.py:133] step: 220300, training_loss: 2.81054e-02
I0209 10:29:45.899327 22542570456896 run_lib.py:146] step: 220300, eval_loss: 2.89226e-02
I0209 10:30:03.483092 22542570456896 run_lib.py:133] step: 220350, training_loss: 3.12781e-02
I0209 10:30:20.904445 22542570456896 run_lib.py:133] step: 220400, training_loss: 3.21909e-02
I0209 10:30:21.056438 22542570456896 run_lib.py:146] step: 220400, eval_loss: 2.64257e-02
I0209 10:30:38.514408 22542570456896 run_lib.py:133] step: 220450, training_loss: 3.02768e-02
I0209 10:30:56.033015 22542570456896 run_lib.py:133] step: 220500, training_loss: 2.41685e-02
I0209 10:30:56.203500 22542570456896 run_lib.py:146] step: 220500, eval_loss: 3.47325e-02
I0209 10:31:13.816278 22542570456896 run_lib.py:133] step: 220550, training_loss: 2.62527e-02
I0209 10:31:31.263483 22542570456896 run_lib.py:133] step: 220600, training_loss: 3.65965e-02
I0209 10:31:31.421593 22542570456896 run_lib.py:146] step: 220600, eval_loss: 2.75891e-02
I0209 10:31:48.949053 22542570456896 run_lib.py:133] step: 220650, training_loss: 3.29718e-02
I0209 10:32:06.373612 22542570456896 run_lib.py:133] step: 220700, training_loss: 2.64016e-02
I0209 10:32:06.546421 22542570456896 run_lib.py:146] step: 220700, eval_loss: 2.34707e-02
I0209 10:32:24.162366 22542570456896 run_lib.py:133] step: 220750, training_loss: 3.00210e-02
I0209 10:32:41.610244 22542570456896 run_lib.py:133] step: 220800, training_loss: 3.59528e-02
I0209 10:32:41.766816 22542570456896 run_lib.py:146] step: 220800, eval_loss: 3.35471e-02
I0209 10:32:59.217364 22542570456896 run_lib.py:133] step: 220850, training_loss: 3.03831e-02
I0209 10:33:16.825910 22542570456896 run_lib.py:133] step: 220900, training_loss: 3.09320e-02
I0209 10:33:16.976308 22542570456896 run_lib.py:146] step: 220900, eval_loss: 2.81934e-02
I0209 10:33:34.383942 22542570456896 run_lib.py:133] step: 220950, training_loss: 2.80988e-02
I0209 10:33:51.976927 22542570456896 run_lib.py:133] step: 221000, training_loss: 2.37505e-02
I0209 10:33:52.147465 22542570456896 run_lib.py:146] step: 221000, eval_loss: 3.27150e-02
I0209 10:34:09.588697 22542570456896 run_lib.py:133] step: 221050, training_loss: 2.52498e-02
I0209 10:34:27.079877 22542570456896 run_lib.py:133] step: 221100, training_loss: 3.56384e-02
I0209 10:34:27.240387 22542570456896 run_lib.py:146] step: 221100, eval_loss: 3.24903e-02
I0209 10:34:44.829347 22542570456896 run_lib.py:133] step: 221150, training_loss: 2.65180e-02
I0209 10:35:02.230948 22542570456896 run_lib.py:133] step: 221200, training_loss: 2.97447e-02
I0209 10:35:02.383827 22542570456896 run_lib.py:146] step: 221200, eval_loss: 2.53520e-02
I0209 10:35:19.850797 22542570456896 run_lib.py:133] step: 221250, training_loss: 2.59425e-02
I0209 10:35:37.397453 22542570456896 run_lib.py:133] step: 221300, training_loss: 2.86731e-02
I0209 10:35:37.552617 22542570456896 run_lib.py:146] step: 221300, eval_loss: 3.15634e-02
I0209 10:35:55.048106 22542570456896 run_lib.py:133] step: 221350, training_loss: 3.07410e-02
I0209 10:36:12.435696 22542570456896 run_lib.py:133] step: 221400, training_loss: 2.83805e-02
I0209 10:36:12.770095 22542570456896 run_lib.py:146] step: 221400, eval_loss: 2.80416e-02
I0209 10:36:30.209183 22542570456896 run_lib.py:133] step: 221450, training_loss: 2.94148e-02
I0209 10:36:47.616003 22542570456896 run_lib.py:133] step: 221500, training_loss: 2.48442e-02
I0209 10:36:47.771237 22542570456896 run_lib.py:146] step: 221500, eval_loss: 2.38348e-02
I0209 10:37:05.211424 22542570456896 run_lib.py:133] step: 221550, training_loss: 2.42786e-02
I0209 10:37:22.695108 22542570456896 run_lib.py:133] step: 221600, training_loss: 2.56896e-02
I0209 10:37:22.852495 22542570456896 run_lib.py:146] step: 221600, eval_loss: 2.96758e-02
I0209 10:37:40.440765 22542570456896 run_lib.py:133] step: 221650, training_loss: 2.82178e-02
I0209 10:37:57.909865 22542570456896 run_lib.py:133] step: 221700, training_loss: 2.52931e-02
I0209 10:37:58.064428 22542570456896 run_lib.py:146] step: 221700, eval_loss: 2.93040e-02
I0209 10:38:15.512304 22542570456896 run_lib.py:133] step: 221750, training_loss: 2.72213e-02
I0209 10:38:32.945677 22542570456896 run_lib.py:133] step: 221800, training_loss: 3.50177e-02
I0209 10:38:33.106359 22542570456896 run_lib.py:146] step: 221800, eval_loss: 2.73073e-02
I0209 10:38:50.751145 22542570456896 run_lib.py:133] step: 221850, training_loss: 2.71823e-02
I0209 10:39:08.274178 22542570456896 run_lib.py:133] step: 221900, training_loss: 2.76804e-02
I0209 10:39:08.429611 22542570456896 run_lib.py:146] step: 221900, eval_loss: 3.06749e-02
I0209 10:39:25.840169 22542570456896 run_lib.py:133] step: 221950, training_loss: 2.62912e-02
I0209 10:39:43.272509 22542570456896 run_lib.py:133] step: 222000, training_loss: 3.38287e-02
I0209 10:39:43.432195 22542570456896 run_lib.py:146] step: 222000, eval_loss: 2.98327e-02
I0209 10:40:00.990787 22542570456896 run_lib.py:133] step: 222050, training_loss: 3.12866e-02
I0209 10:40:18.407935 22542570456896 run_lib.py:133] step: 222100, training_loss: 2.66570e-02
I0209 10:40:18.575183 22542570456896 run_lib.py:146] step: 222100, eval_loss: 2.94061e-02
I0209 10:40:36.164858 22542570456896 run_lib.py:133] step: 222150, training_loss: 3.15111e-02
I0209 10:40:53.594537 22542570456896 run_lib.py:133] step: 222200, training_loss: 2.13983e-02
I0209 10:40:53.749391 22542570456896 run_lib.py:146] step: 222200, eval_loss: 2.64291e-02
I0209 10:41:11.367220 22542570456896 run_lib.py:133] step: 222250, training_loss: 2.75530e-02
I0209 10:41:28.761983 22542570456896 run_lib.py:133] step: 222300, training_loss: 2.18588e-02
I0209 10:41:28.916140 22542570456896 run_lib.py:146] step: 222300, eval_loss: 2.64868e-02
I0209 10:41:46.309009 22542570456896 run_lib.py:133] step: 222350, training_loss: 2.62589e-02
I0209 10:42:03.836346 22542570456896 run_lib.py:133] step: 222400, training_loss: 3.57189e-02
I0209 10:42:04.001518 22542570456896 run_lib.py:146] step: 222400, eval_loss: 2.78668e-02
I0209 10:42:21.513167 22542570456896 run_lib.py:133] step: 222450, training_loss: 2.93565e-02
I0209 10:42:39.115309 22542570456896 run_lib.py:133] step: 222500, training_loss: 2.93935e-02
I0209 10:42:39.274428 22542570456896 run_lib.py:146] step: 222500, eval_loss: 2.43776e-02
I0209 10:42:56.673707 22542570456896 run_lib.py:133] step: 222550, training_loss: 2.52624e-02
I0209 10:43:14.032649 22542570456896 run_lib.py:133] step: 222600, training_loss: 2.54799e-02
I0209 10:43:14.187336 22542570456896 run_lib.py:146] step: 222600, eval_loss: 2.53330e-02
I0209 10:43:31.758912 22542570456896 run_lib.py:133] step: 222650, training_loss: 2.46578e-02
I0209 10:43:49.156630 22542570456896 run_lib.py:133] step: 222700, training_loss: 2.09500e-02
I0209 10:43:49.324285 22542570456896 run_lib.py:146] step: 222700, eval_loss: 3.50602e-02
I0209 10:44:06.768057 22542570456896 run_lib.py:133] step: 222750, training_loss: 3.24408e-02
I0209 10:44:24.167493 22542570456896 run_lib.py:133] step: 222800, training_loss: 2.41147e-02
I0209 10:44:24.319587 22542570456896 run_lib.py:146] step: 222800, eval_loss: 2.66201e-02
I0209 10:44:41.976638 22542570456896 run_lib.py:133] step: 222850, training_loss: 2.69450e-02
I0209 10:44:59.394764 22542570456896 run_lib.py:133] step: 222900, training_loss: 2.80656e-02
I0209 10:44:59.550295 22542570456896 run_lib.py:146] step: 222900, eval_loss: 2.93976e-02
I0209 10:45:17.005959 22542570456896 run_lib.py:133] step: 222950, training_loss: 3.10692e-02
I0209 10:45:34.411962 22542570456896 run_lib.py:133] step: 223000, training_loss: 3.39157e-02
I0209 10:45:34.586345 22542570456896 run_lib.py:146] step: 223000, eval_loss: 3.38267e-02
I0209 10:45:52.047409 22542570456896 run_lib.py:133] step: 223050, training_loss: 3.41347e-02
I0209 10:46:09.464253 22542570456896 run_lib.py:133] step: 223100, training_loss: 3.33553e-02
I0209 10:46:09.619613 22542570456896 run_lib.py:146] step: 223100, eval_loss: 2.63478e-02
I0209 10:46:27.237539 22542570456896 run_lib.py:133] step: 223150, training_loss: 3.26090e-02
I0209 10:46:44.718304 22542570456896 run_lib.py:133] step: 223200, training_loss: 2.83202e-02
I0209 10:46:44.881400 22542570456896 run_lib.py:146] step: 223200, eval_loss: 2.28019e-02
I0209 10:47:02.349575 22542570456896 run_lib.py:133] step: 223250, training_loss: 2.87580e-02
I0209 10:47:19.792824 22542570456896 run_lib.py:133] step: 223300, training_loss: 2.57054e-02
I0209 10:47:19.947363 22542570456896 run_lib.py:146] step: 223300, eval_loss: 3.20400e-02
I0209 10:47:37.612037 22542570456896 run_lib.py:133] step: 223350, training_loss: 2.70169e-02
I0209 10:47:55.037544 22542570456896 run_lib.py:133] step: 223400, training_loss: 2.77867e-02
I0209 10:47:55.194280 22542570456896 run_lib.py:146] step: 223400, eval_loss: 2.79469e-02
I0209 10:48:12.789997 22542570456896 run_lib.py:133] step: 223450, training_loss: 2.64377e-02
I0209 10:48:30.216289 22542570456896 run_lib.py:133] step: 223500, training_loss: 2.12327e-02
I0209 10:48:30.374651 22542570456896 run_lib.py:146] step: 223500, eval_loss: 2.86437e-02
I0209 10:48:47.937593 22542570456896 run_lib.py:133] step: 223550, training_loss: 2.66005e-02
I0209 10:49:05.332312 22542570456896 run_lib.py:133] step: 223600, training_loss: 3.14630e-02
I0209 10:49:05.488093 22542570456896 run_lib.py:146] step: 223600, eval_loss: 2.71952e-02
I0209 10:49:23.024358 22542570456896 run_lib.py:133] step: 223650, training_loss: 2.50390e-02
I0209 10:49:40.336788 22542570456896 run_lib.py:133] step: 223700, training_loss: 3.28323e-02
I0209 10:49:40.490979 22542570456896 run_lib.py:146] step: 223700, eval_loss: 2.74133e-02
I0209 10:49:57.867298 22542570456896 run_lib.py:133] step: 223750, training_loss: 2.17868e-02
I0209 10:50:15.469141 22542570456896 run_lib.py:133] step: 223800, training_loss: 2.27744e-02
I0209 10:50:15.621371 22542570456896 run_lib.py:146] step: 223800, eval_loss: 3.00517e-02
I0209 10:50:33.066536 22542570456896 run_lib.py:133] step: 223850, training_loss: 2.36684e-02
I0209 10:50:50.507144 22542570456896 run_lib.py:133] step: 223900, training_loss: 2.80014e-02
I0209 10:50:50.685545 22542570456896 run_lib.py:146] step: 223900, eval_loss: 3.16547e-02
I0209 10:51:08.348758 22542570456896 run_lib.py:133] step: 223950, training_loss: 3.08035e-02
I0209 10:51:26.006312 22542570456896 run_lib.py:133] step: 224000, training_loss: 2.81756e-02
I0209 10:51:26.162536 22542570456896 run_lib.py:146] step: 224000, eval_loss: 3.22977e-02
I0209 10:51:43.589590 22542570456896 run_lib.py:133] step: 224050, training_loss: 3.20014e-02
I0209 10:52:01.043359 22542570456896 run_lib.py:133] step: 224100, training_loss: 2.33830e-02
I0209 10:52:01.198109 22542570456896 run_lib.py:146] step: 224100, eval_loss: 2.88176e-02
I0209 10:52:18.597412 22542570456896 run_lib.py:133] step: 224150, training_loss: 2.77255e-02
I0209 10:52:36.260711 22542570456896 run_lib.py:133] step: 224200, training_loss: 3.45150e-02
I0209 10:52:36.414220 22542570456896 run_lib.py:146] step: 224200, eval_loss: 2.60173e-02
I0209 10:52:53.864028 22542570456896 run_lib.py:133] step: 224250, training_loss: 2.58121e-02
I0209 10:53:11.264891 22542570456896 run_lib.py:133] step: 224300, training_loss: 3.36927e-02
I0209 10:53:11.417669 22542570456896 run_lib.py:146] step: 224300, eval_loss: 2.50523e-02
I0209 10:53:28.851296 22542570456896 run_lib.py:133] step: 224350, training_loss: 2.57522e-02
I0209 10:53:46.463432 22542570456896 run_lib.py:133] step: 224400, training_loss: 2.56346e-02
I0209 10:53:46.631498 22542570456896 run_lib.py:146] step: 224400, eval_loss: 3.13717e-02
I0209 10:54:04.079847 22542570456896 run_lib.py:133] step: 224450, training_loss: 2.85406e-02
I0209 10:54:21.599300 22542570456896 run_lib.py:133] step: 224500, training_loss: 2.69298e-02
I0209 10:54:21.755615 22542570456896 run_lib.py:146] step: 224500, eval_loss: 3.34694e-02
I0209 10:54:39.185992 22542570456896 run_lib.py:133] step: 224550, training_loss: 2.99981e-02
I0209 10:54:56.606690 22542570456896 run_lib.py:133] step: 224600, training_loss: 2.45630e-02
I0209 10:54:56.763373 22542570456896 run_lib.py:146] step: 224600, eval_loss: 2.60686e-02
I0209 10:55:14.350762 22542570456896 run_lib.py:133] step: 224650, training_loss: 2.58996e-02
I0209 10:55:31.810469 22542570456896 run_lib.py:133] step: 224700, training_loss: 2.50237e-02
I0209 10:55:31.963568 22542570456896 run_lib.py:146] step: 224700, eval_loss: 3.09929e-02
I0209 10:55:49.441541 22542570456896 run_lib.py:133] step: 224750, training_loss: 3.09657e-02
I0209 10:56:06.912750 22542570456896 run_lib.py:133] step: 224800, training_loss: 2.41105e-02
I0209 10:56:07.078353 22542570456896 run_lib.py:146] step: 224800, eval_loss: 2.56318e-02
I0209 10:56:24.678279 22542570456896 run_lib.py:133] step: 224850, training_loss: 2.64327e-02
I0209 10:56:42.120477 22542570456896 run_lib.py:133] step: 224900, training_loss: 2.72719e-02
I0209 10:56:42.278712 22542570456896 run_lib.py:146] step: 224900, eval_loss: 2.97453e-02
I0209 10:56:59.814094 22542570456896 run_lib.py:133] step: 224950, training_loss: 2.97764e-02
I0209 10:57:17.284336 22542570456896 run_lib.py:133] step: 225000, training_loss: 2.26863e-02
I0209 10:57:17.461358 22542570456896 run_lib.py:146] step: 225000, eval_loss: 2.94085e-02
I0209 10:57:35.078587 22542570456896 run_lib.py:133] step: 225050, training_loss: 2.47804e-02
I0209 10:57:52.511365 22542570456896 run_lib.py:133] step: 225100, training_loss: 2.94174e-02
I0209 10:57:52.667647 22542570456896 run_lib.py:146] step: 225100, eval_loss: 2.51803e-02
I0209 10:58:10.113864 22542570456896 run_lib.py:133] step: 225150, training_loss: 2.06032e-02
I0209 10:58:27.709655 22542570456896 run_lib.py:133] step: 225200, training_loss: 2.78002e-02
I0209 10:58:27.862451 22542570456896 run_lib.py:146] step: 225200, eval_loss: 3.43139e-02
I0209 10:58:45.287212 22542570456896 run_lib.py:133] step: 225250, training_loss: 3.02652e-02
I0209 10:59:02.821186 22542570456896 run_lib.py:133] step: 225300, training_loss: 2.24871e-02
I0209 10:59:02.995378 22542570456896 run_lib.py:146] step: 225300, eval_loss: 2.25050e-02
I0209 10:59:20.490848 22542570456896 run_lib.py:133] step: 225350, training_loss: 2.47862e-02
I0209 10:59:37.909376 22542570456896 run_lib.py:133] step: 225400, training_loss: 2.22501e-02
I0209 10:59:38.066286 22542570456896 run_lib.py:146] step: 225400, eval_loss: 2.42982e-02
I0209 10:59:55.707827 22542570456896 run_lib.py:133] step: 225450, training_loss: 2.40302e-02
I0209 11:00:13.129078 22542570456896 run_lib.py:133] step: 225500, training_loss: 2.72558e-02
I0209 11:00:13.285598 22542570456896 run_lib.py:146] step: 225500, eval_loss: 2.42665e-02
I0209 11:00:30.710830 22542570456896 run_lib.py:133] step: 225550, training_loss: 2.40973e-02
I0209 11:00:48.274998 22542570456896 run_lib.py:133] step: 225600, training_loss: 2.63732e-02
I0209 11:00:48.435188 22542570456896 run_lib.py:146] step: 225600, eval_loss: 2.59721e-02
I0209 11:01:05.905700 22542570456896 run_lib.py:133] step: 225650, training_loss: 3.21958e-02
I0209 11:01:23.368409 22542570456896 run_lib.py:133] step: 225700, training_loss: 2.46867e-02
I0209 11:01:23.520658 22542570456896 run_lib.py:146] step: 225700, eval_loss: 2.63130e-02
I0209 11:01:41.043998 22542570456896 run_lib.py:133] step: 225750, training_loss: 2.91306e-02
I0209 11:01:58.474690 22542570456896 run_lib.py:133] step: 225800, training_loss: 2.61583e-02
I0209 11:01:58.632702 22542570456896 run_lib.py:146] step: 225800, eval_loss: 2.67333e-02
I0209 11:02:16.018534 22542570456896 run_lib.py:133] step: 225850, training_loss: 2.51112e-02
I0209 11:02:33.474143 22542570456896 run_lib.py:133] step: 225900, training_loss: 2.78143e-02
I0209 11:02:33.634688 22542570456896 run_lib.py:146] step: 225900, eval_loss: 2.97041e-02
I0209 11:02:51.272053 22542570456896 run_lib.py:133] step: 225950, training_loss: 2.89625e-02
I0209 11:03:08.734364 22542570456896 run_lib.py:133] step: 226000, training_loss: 3.18466e-02
I0209 11:03:08.893168 22542570456896 run_lib.py:146] step: 226000, eval_loss: 2.93586e-02
I0209 11:03:26.308925 22542570456896 run_lib.py:133] step: 226050, training_loss: 3.36255e-02
I0209 11:03:43.717727 22542570456896 run_lib.py:133] step: 226100, training_loss: 3.99789e-02
I0209 11:03:43.868293 22542570456896 run_lib.py:146] step: 226100, eval_loss: 2.79963e-02
I0209 11:04:01.463292 22542570456896 run_lib.py:133] step: 226150, training_loss: 2.55034e-02
I0209 11:04:18.917906 22542570456896 run_lib.py:133] step: 226200, training_loss: 2.99288e-02
I0209 11:04:19.088688 22542570456896 run_lib.py:146] step: 226200, eval_loss: 2.83316e-02
I0209 11:04:36.720795 22542570456896 run_lib.py:133] step: 226250, training_loss: 3.32514e-02
I0209 11:04:54.175810 22542570456896 run_lib.py:133] step: 226300, training_loss: 2.83088e-02
I0209 11:04:54.341457 22542570456896 run_lib.py:146] step: 226300, eval_loss: 2.51305e-02
I0209 11:05:11.937070 22542570456896 run_lib.py:133] step: 226350, training_loss: 3.09981e-02
I0209 11:05:29.347576 22542570456896 run_lib.py:133] step: 226400, training_loss: 2.46716e-02
I0209 11:05:29.503218 22542570456896 run_lib.py:146] step: 226400, eval_loss: 2.17824e-02
I0209 11:05:47.114306 22542570456896 run_lib.py:133] step: 226450, training_loss: 3.12489e-02
I0209 11:06:04.573849 22542570456896 run_lib.py:133] step: 226500, training_loss: 2.39274e-02
I0209 11:06:04.736628 22542570456896 run_lib.py:146] step: 226500, eval_loss: 2.62555e-02
I0209 11:06:22.191222 22542570456896 run_lib.py:133] step: 226550, training_loss: 2.81297e-02
I0209 11:06:39.755356 22542570456896 run_lib.py:133] step: 226600, training_loss: 3.33594e-02
I0209 11:06:39.911372 22542570456896 run_lib.py:146] step: 226600, eval_loss: 2.64560e-02
I0209 11:06:57.318785 22542570456896 run_lib.py:133] step: 226650, training_loss: 3.01030e-02
I0209 11:07:14.749964 22542570456896 run_lib.py:133] step: 226700, training_loss: 3.11897e-02
I0209 11:07:14.911651 22542570456896 run_lib.py:146] step: 226700, eval_loss: 2.77498e-02
I0209 11:07:32.548740 22542570456896 run_lib.py:133] step: 226750, training_loss: 2.75889e-02
I0209 11:07:50.006649 22542570456896 run_lib.py:133] step: 226800, training_loss: 2.44332e-02
I0209 11:07:50.166370 22542570456896 run_lib.py:146] step: 226800, eval_loss: 3.54599e-02
I0209 11:08:07.811594 22542570456896 run_lib.py:133] step: 226850, training_loss: 2.81278e-02
I0209 11:08:25.229499 22542570456896 run_lib.py:133] step: 226900, training_loss: 2.67835e-02
I0209 11:08:25.384404 22542570456896 run_lib.py:146] step: 226900, eval_loss: 3.11504e-02
I0209 11:08:42.826458 22542570456896 run_lib.py:133] step: 226950, training_loss: 3.04090e-02
I0209 11:09:00.384584 22542570456896 run_lib.py:133] step: 227000, training_loss: 2.52138e-02
I0209 11:09:00.539297 22542570456896 run_lib.py:146] step: 227000, eval_loss: 2.66878e-02
I0209 11:09:18.024446 22542570456896 run_lib.py:133] step: 227050, training_loss: 2.75899e-02
I0209 11:09:35.506164 22542570456896 run_lib.py:133] step: 227100, training_loss: 2.66339e-02
I0209 11:09:35.661558 22542570456896 run_lib.py:146] step: 227100, eval_loss: 2.73752e-02
I0209 11:09:53.117110 22542570456896 run_lib.py:133] step: 227150, training_loss: 2.71079e-02
I0209 11:10:10.762514 22542570456896 run_lib.py:133] step: 227200, training_loss: 2.25670e-02
I0209 11:10:10.920776 22542570456896 run_lib.py:146] step: 227200, eval_loss: 2.80464e-02
I0209 11:10:28.315334 22542570456896 run_lib.py:133] step: 227250, training_loss: 2.89641e-02
I0209 11:10:45.792562 22542570456896 run_lib.py:133] step: 227300, training_loss: 2.65686e-02
I0209 11:10:45.960370 22542570456896 run_lib.py:146] step: 227300, eval_loss: 2.43446e-02
I0209 11:11:03.438043 22542570456896 run_lib.py:133] step: 227350, training_loss: 2.41357e-02
I0209 11:11:20.907599 22542570456896 run_lib.py:133] step: 227400, training_loss: 2.14319e-02
I0209 11:11:21.065371 22542570456896 run_lib.py:146] step: 227400, eval_loss: 2.75235e-02
I0209 11:11:38.680263 22542570456896 run_lib.py:133] step: 227450, training_loss: 2.34113e-02
I0209 11:11:56.203927 22542570456896 run_lib.py:133] step: 227500, training_loss: 3.18970e-02
I0209 11:11:56.358279 22542570456896 run_lib.py:146] step: 227500, eval_loss: 2.95168e-02
I0209 11:12:13.803282 22542570456896 run_lib.py:133] step: 227550, training_loss: 2.59070e-02
I0209 11:12:31.252536 22542570456896 run_lib.py:133] step: 227600, training_loss: 2.46846e-02
I0209 11:12:31.416957 22542570456896 run_lib.py:146] step: 227600, eval_loss: 2.48764e-02
I0209 11:12:49.038741 22542570456896 run_lib.py:133] step: 227650, training_loss: 2.68171e-02
I0209 11:13:06.504961 22542570456896 run_lib.py:133] step: 227700, training_loss: 2.64171e-02
I0209 11:13:06.671531 22542570456896 run_lib.py:146] step: 227700, eval_loss: 2.96265e-02
I0209 11:13:24.249274 22542570456896 run_lib.py:133] step: 227750, training_loss: 3.22075e-02
I0209 11:13:41.674908 22542570456896 run_lib.py:133] step: 227800, training_loss: 3.20080e-02
I0209 11:13:41.831374 22542570456896 run_lib.py:146] step: 227800, eval_loss: 2.87024e-02
I0209 11:13:59.389476 22542570456896 run_lib.py:133] step: 227850, training_loss: 3.20726e-02
I0209 11:14:16.827674 22542570456896 run_lib.py:133] step: 227900, training_loss: 3.17441e-02
I0209 11:14:16.984448 22542570456896 run_lib.py:146] step: 227900, eval_loss: 2.49080e-02
I0209 11:14:34.439112 22542570456896 run_lib.py:133] step: 227950, training_loss: 2.63190e-02
I0209 11:14:52.093275 22542570456896 run_lib.py:133] step: 228000, training_loss: 2.49628e-02
I0209 11:14:52.243496 22542570456896 run_lib.py:146] step: 228000, eval_loss: 3.28100e-02
I0209 11:15:09.643073 22542570456896 run_lib.py:133] step: 228050, training_loss: 2.32551e-02
I0209 11:15:27.209554 22542570456896 run_lib.py:133] step: 228100, training_loss: 2.93489e-02
I0209 11:15:27.364491 22542570456896 run_lib.py:146] step: 228100, eval_loss: 2.05334e-02
I0209 11:15:44.764451 22542570456896 run_lib.py:133] step: 228150, training_loss: 3.29674e-02
I0209 11:16:02.180258 22542570456896 run_lib.py:133] step: 228200, training_loss: 2.35722e-02
I0209 11:16:02.357359 22542570456896 run_lib.py:146] step: 228200, eval_loss: 2.96158e-02
I0209 11:16:19.984291 22542570456896 run_lib.py:133] step: 228250, training_loss: 2.22929e-02
I0209 11:16:37.451256 22542570456896 run_lib.py:133] step: 228300, training_loss: 2.81053e-02
I0209 11:16:37.616664 22542570456896 run_lib.py:146] step: 228300, eval_loss: 2.72031e-02
I0209 11:16:55.026662 22542570456896 run_lib.py:133] step: 228350, training_loss: 3.06929e-02
I0209 11:17:12.625616 22542570456896 run_lib.py:133] step: 228400, training_loss: 3.32145e-02
I0209 11:17:12.781183 22542570456896 run_lib.py:146] step: 228400, eval_loss: 3.60040e-02
I0209 11:17:30.247404 22542570456896 run_lib.py:133] step: 228450, training_loss: 3.13308e-02
I0209 11:17:47.670822 22542570456896 run_lib.py:133] step: 228500, training_loss: 3.05906e-02
I0209 11:17:47.977611 22542570456896 run_lib.py:146] step: 228500, eval_loss: 3.23156e-02
I0209 11:18:05.457946 22542570456896 run_lib.py:133] step: 228550, training_loss: 2.47629e-02
I0209 11:18:22.902704 22542570456896 run_lib.py:133] step: 228600, training_loss: 3.14811e-02
I0209 11:18:23.058674 22542570456896 run_lib.py:146] step: 228600, eval_loss: 3.39821e-02
I0209 11:18:40.506359 22542570456896 run_lib.py:133] step: 228650, training_loss: 2.75221e-02
I0209 11:18:57.944132 22542570456896 run_lib.py:133] step: 228700, training_loss: 2.27824e-02
I0209 11:18:58.103165 22542570456896 run_lib.py:146] step: 228700, eval_loss: 2.83854e-02
I0209 11:19:15.683574 22542570456896 run_lib.py:133] step: 228750, training_loss: 2.94144e-02
I0209 11:19:33.174887 22542570456896 run_lib.py:133] step: 228800, training_loss: 2.95963e-02
I0209 11:19:33.340740 22542570456896 run_lib.py:146] step: 228800, eval_loss: 2.38208e-02
I0209 11:19:50.789249 22542570456896 run_lib.py:133] step: 228850, training_loss: 3.00039e-02
I0209 11:20:08.260205 22542570456896 run_lib.py:133] step: 228900, training_loss: 2.97390e-02
I0209 11:20:08.414689 22542570456896 run_lib.py:146] step: 228900, eval_loss: 2.52568e-02
I0209 11:20:26.022170 22542570456896 run_lib.py:133] step: 228950, training_loss: 3.01970e-02
I0209 11:20:43.513251 22542570456896 run_lib.py:133] step: 229000, training_loss: 2.67678e-02
I0209 11:20:43.666367 22542570456896 run_lib.py:146] step: 229000, eval_loss: 3.21514e-02
I0209 11:21:01.101927 22542570456896 run_lib.py:133] step: 229050, training_loss: 3.04477e-02
I0209 11:21:18.551824 22542570456896 run_lib.py:133] step: 229100, training_loss: 3.18635e-02
I0209 11:21:18.727411 22542570456896 run_lib.py:146] step: 229100, eval_loss: 2.79189e-02
I0209 11:21:36.353500 22542570456896 run_lib.py:133] step: 229150, training_loss: 2.60765e-02
I0209 11:21:53.834138 22542570456896 run_lib.py:133] step: 229200, training_loss: 2.47011e-02
I0209 11:21:53.989421 22542570456896 run_lib.py:146] step: 229200, eval_loss: 3.27773e-02
I0209 11:22:11.610752 22542570456896 run_lib.py:133] step: 229250, training_loss: 2.49838e-02
I0209 11:22:29.063413 22542570456896 run_lib.py:133] step: 229300, training_loss: 2.95692e-02
I0209 11:22:29.215721 22542570456896 run_lib.py:146] step: 229300, eval_loss: 2.04941e-02
I0209 11:22:46.798919 22542570456896 run_lib.py:133] step: 229350, training_loss: 3.13366e-02
I0209 11:23:04.276190 22542570456896 run_lib.py:133] step: 229400, training_loss: 2.68819e-02
I0209 11:23:04.429201 22542570456896 run_lib.py:146] step: 229400, eval_loss: 2.33170e-02
I0209 11:23:21.941925 22542570456896 run_lib.py:133] step: 229450, training_loss: 3.49509e-02
I0209 11:23:39.572024 22542570456896 run_lib.py:133] step: 229500, training_loss: 2.16661e-02
I0209 11:23:39.726790 22542570456896 run_lib.py:146] step: 229500, eval_loss: 2.66760e-02
I0209 11:23:57.158044 22542570456896 run_lib.py:133] step: 229550, training_loss: 2.47814e-02
I0209 11:24:14.760055 22542570456896 run_lib.py:133] step: 229600, training_loss: 3.76800e-02
I0209 11:24:14.918619 22542570456896 run_lib.py:146] step: 229600, eval_loss: 2.53693e-02
I0209 11:24:32.384503 22542570456896 run_lib.py:133] step: 229650, training_loss: 2.91891e-02
I0209 11:24:49.826816 22542570456896 run_lib.py:133] step: 229700, training_loss: 4.39736e-02
I0209 11:24:49.995048 22542570456896 run_lib.py:146] step: 229700, eval_loss: 2.89013e-02
I0209 11:25:07.628243 22542570456896 run_lib.py:133] step: 229750, training_loss: 3.12415e-02
I0209 11:25:25.115003 22542570456896 run_lib.py:133] step: 229800, training_loss: 3.04067e-02
I0209 11:25:25.271739 22542570456896 run_lib.py:146] step: 229800, eval_loss: 3.71617e-02
I0209 11:25:42.773699 22542570456896 run_lib.py:133] step: 229850, training_loss: 2.95323e-02
I0209 11:26:00.232179 22542570456896 run_lib.py:133] step: 229900, training_loss: 2.65656e-02
I0209 11:26:00.382611 22542570456896 run_lib.py:146] step: 229900, eval_loss: 3.01108e-02
I0209 11:26:17.987506 22542570456896 run_lib.py:133] step: 229950, training_loss: 3.06040e-02
I0209 11:26:35.456362 22542570456896 run_lib.py:133] step: 230000, training_loss: 3.73062e-02
I0209 11:26:36.412558 22542570456896 run_lib.py:146] step: 230000, eval_loss: 2.90719e-02
I0209 11:26:56.854115 22542570456896 run_lib.py:133] step: 230050, training_loss: 2.70330e-02
I0209 11:27:14.293977 22542570456896 run_lib.py:133] step: 230100, training_loss: 2.98761e-02
I0209 11:27:14.453046 22542570456896 run_lib.py:146] step: 230100, eval_loss: 2.61597e-02
I0209 11:27:32.065514 22542570456896 run_lib.py:133] step: 230150, training_loss: 2.86045e-02
I0209 11:27:49.514609 22542570456896 run_lib.py:133] step: 230200, training_loss: 2.49363e-02
I0209 11:27:49.673681 22542570456896 run_lib.py:146] step: 230200, eval_loss: 2.11910e-02
I0209 11:28:07.122261 22542570456896 run_lib.py:133] step: 230250, training_loss: 2.60575e-02
I0209 11:28:24.687191 22542570456896 run_lib.py:133] step: 230300, training_loss: 3.31448e-02
I0209 11:28:24.859560 22542570456896 run_lib.py:146] step: 230300, eval_loss: 2.51938e-02
I0209 11:28:42.335936 22542570456896 run_lib.py:133] step: 230350, training_loss: 3.09679e-02
I0209 11:28:59.782005 22542570456896 run_lib.py:133] step: 230400, training_loss: 3.12204e-02
I0209 11:28:59.937636 22542570456896 run_lib.py:146] step: 230400, eval_loss: 3.02218e-02
I0209 11:29:17.431972 22542570456896 run_lib.py:133] step: 230450, training_loss: 2.87272e-02
I0209 11:29:35.077644 22542570456896 run_lib.py:133] step: 230500, training_loss: 3.08983e-02
I0209 11:29:35.230461 22542570456896 run_lib.py:146] step: 230500, eval_loss: 2.77834e-02
I0209 11:29:52.665763 22542570456896 run_lib.py:133] step: 230550, training_loss: 3.21490e-02
I0209 11:30:10.185316 22542570456896 run_lib.py:133] step: 230600, training_loss: 2.53622e-02
I0209 11:30:10.351397 22542570456896 run_lib.py:146] step: 230600, eval_loss: 2.53351e-02
I0209 11:30:27.839619 22542570456896 run_lib.py:133] step: 230650, training_loss: 3.52867e-02
I0209 11:30:45.279720 22542570456896 run_lib.py:133] step: 230700, training_loss: 3.11954e-02
I0209 11:30:45.440432 22542570456896 run_lib.py:146] step: 230700, eval_loss: 2.65432e-02
I0209 11:31:03.069732 22542570456896 run_lib.py:133] step: 230750, training_loss: 2.63748e-02
I0209 11:31:20.586980 22542570456896 run_lib.py:133] step: 230800, training_loss: 2.88417e-02
I0209 11:31:20.745634 22542570456896 run_lib.py:146] step: 230800, eval_loss: 2.90290e-02
I0209 11:31:38.218110 22542570456896 run_lib.py:133] step: 230850, training_loss: 2.87796e-02
I0209 11:31:55.654449 22542570456896 run_lib.py:133] step: 230900, training_loss: 2.48832e-02
I0209 11:31:55.809199 22542570456896 run_lib.py:146] step: 230900, eval_loss: 2.89797e-02
I0209 11:32:13.480154 22542570456896 run_lib.py:133] step: 230950, training_loss: 2.45717e-02
I0209 11:32:30.971461 22542570456896 run_lib.py:133] step: 231000, training_loss: 3.22642e-02
I0209 11:32:31.126375 22542570456896 run_lib.py:146] step: 231000, eval_loss: 2.59529e-02
I0209 11:32:48.737873 22542570456896 run_lib.py:133] step: 231050, training_loss: 3.12215e-02
I0209 11:33:06.175251 22542570456896 run_lib.py:133] step: 231100, training_loss: 2.15228e-02
I0209 11:33:06.334440 22542570456896 run_lib.py:146] step: 231100, eval_loss: 2.69969e-02
I0209 11:33:23.906672 22542570456896 run_lib.py:133] step: 231150, training_loss: 2.38729e-02
I0209 11:33:41.353998 22542570456896 run_lib.py:133] step: 231200, training_loss: 3.34011e-02
I0209 11:33:41.525527 22542570456896 run_lib.py:146] step: 231200, eval_loss: 3.02468e-02
I0209 11:33:59.067139 22542570456896 run_lib.py:133] step: 231250, training_loss: 2.46923e-02
I0209 11:34:16.799259 22542570456896 run_lib.py:133] step: 231300, training_loss: 2.97371e-02
I0209 11:34:16.955726 22542570456896 run_lib.py:146] step: 231300, eval_loss: 3.40420e-02
I0209 11:34:34.377248 22542570456896 run_lib.py:133] step: 231350, training_loss: 3.19012e-02
I0209 11:34:51.933729 22542570456896 run_lib.py:133] step: 231400, training_loss: 3.10865e-02
I0209 11:34:52.085117 22542570456896 run_lib.py:146] step: 231400, eval_loss: 2.96166e-02
I0209 11:35:09.517311 22542570456896 run_lib.py:133] step: 231450, training_loss: 3.38396e-02
I0209 11:35:26.921169 22542570456896 run_lib.py:133] step: 231500, training_loss: 2.78919e-02
I0209 11:35:27.100399 22542570456896 run_lib.py:146] step: 231500, eval_loss: 2.72824e-02
I0209 11:35:44.748291 22542570456896 run_lib.py:133] step: 231550, training_loss: 3.10406e-02
I0209 11:36:02.239928 22542570456896 run_lib.py:133] step: 231600, training_loss: 2.67711e-02
I0209 11:36:02.399348 22542570456896 run_lib.py:146] step: 231600, eval_loss: 3.49116e-02
I0209 11:36:19.810093 22542570456896 run_lib.py:133] step: 231650, training_loss: 2.69468e-02
I0209 11:36:37.242511 22542570456896 run_lib.py:133] step: 231700, training_loss: 2.63441e-02
I0209 11:36:37.399361 22542570456896 run_lib.py:146] step: 231700, eval_loss: 3.79932e-02
I0209 11:36:54.982954 22542570456896 run_lib.py:133] step: 231750, training_loss: 2.87521e-02
I0209 11:37:12.502233 22542570456896 run_lib.py:133] step: 231800, training_loss: 3.03875e-02
I0209 11:37:12.666356 22542570456896 run_lib.py:146] step: 231800, eval_loss: 2.32465e-02
I0209 11:37:30.209646 22542570456896 run_lib.py:133] step: 231850, training_loss: 2.68625e-02
I0209 11:37:47.659363 22542570456896 run_lib.py:133] step: 231900, training_loss: 2.37676e-02
I0209 11:37:47.812602 22542570456896 run_lib.py:146] step: 231900, eval_loss: 2.84474e-02
I0209 11:38:05.232302 22542570456896 run_lib.py:133] step: 231950, training_loss: 3.06649e-02
I0209 11:38:22.676978 22542570456896 run_lib.py:133] step: 232000, training_loss: 2.69848e-02
I0209 11:38:22.841618 22542570456896 run_lib.py:146] step: 232000, eval_loss: 2.80633e-02
I0209 11:38:40.437473 22542570456896 run_lib.py:133] step: 232050, training_loss: 2.73922e-02
I0209 11:38:57.997734 22542570456896 run_lib.py:133] step: 232100, training_loss: 2.84918e-02
I0209 11:38:58.160438 22542570456896 run_lib.py:146] step: 232100, eval_loss: 3.08477e-02
I0209 11:39:15.596750 22542570456896 run_lib.py:133] step: 232150, training_loss: 2.48054e-02
I0209 11:39:33.082629 22542570456896 run_lib.py:133] step: 232200, training_loss: 3.18954e-02
I0209 11:39:33.239188 22542570456896 run_lib.py:146] step: 232200, eval_loss: 2.98750e-02
I0209 11:39:50.873187 22542570456896 run_lib.py:133] step: 232250, training_loss: 2.79255e-02
I0209 11:40:08.301081 22542570456896 run_lib.py:133] step: 232300, training_loss: 2.24355e-02
I0209 11:40:08.455452 22542570456896 run_lib.py:146] step: 232300, eval_loss: 3.02520e-02
I0209 11:40:26.018388 22542570456896 run_lib.py:133] step: 232350, training_loss: 2.97542e-02
I0209 11:40:43.509264 22542570456896 run_lib.py:133] step: 232400, training_loss: 2.67486e-02
I0209 11:40:43.663682 22542570456896 run_lib.py:146] step: 232400, eval_loss: 3.16122e-02
I0209 11:41:01.280325 22542570456896 run_lib.py:133] step: 232450, training_loss: 3.32023e-02
I0209 11:41:18.710840 22542570456896 run_lib.py:133] step: 232500, training_loss: 3.37833e-02
I0209 11:41:18.877607 22542570456896 run_lib.py:146] step: 232500, eval_loss: 3.65198e-02
I0209 11:41:36.431972 22542570456896 run_lib.py:133] step: 232550, training_loss: 2.75038e-02
I0209 11:41:53.884591 22542570456896 run_lib.py:133] step: 232600, training_loss: 3.38904e-02
I0209 11:41:54.040308 22542570456896 run_lib.py:146] step: 232600, eval_loss: 3.42231e-02
I0209 11:42:11.453094 22542570456896 run_lib.py:133] step: 232650, training_loss: 2.77918e-02
I0209 11:42:29.131308 22542570456896 run_lib.py:133] step: 232700, training_loss: 2.67218e-02
I0209 11:42:29.287724 22542570456896 run_lib.py:146] step: 232700, eval_loss: 2.62798e-02
I0209 11:42:46.746092 22542570456896 run_lib.py:133] step: 232750, training_loss: 2.66389e-02
I0209 11:43:04.188176 22542570456896 run_lib.py:133] step: 232800, training_loss: 3.13347e-02
I0209 11:43:04.341526 22542570456896 run_lib.py:146] step: 232800, eval_loss: 3.67655e-02
I0209 11:43:21.987286 22542570456896 run_lib.py:133] step: 232850, training_loss: 2.33544e-02
I0209 11:43:39.557014 22542570456896 run_lib.py:133] step: 232900, training_loss: 2.42676e-02
I0209 11:43:39.711371 22542570456896 run_lib.py:146] step: 232900, eval_loss: 2.39554e-02
I0209 11:43:57.179913 22542570456896 run_lib.py:133] step: 232950, training_loss: 2.07819e-02
I0209 11:44:14.653096 22542570456896 run_lib.py:133] step: 233000, training_loss: 2.99222e-02
I0209 11:44:14.812401 22542570456896 run_lib.py:146] step: 233000, eval_loss: 2.46589e-02
I0209 11:44:32.230841 22542570456896 run_lib.py:133] step: 233050, training_loss: 2.45606e-02
I0209 11:44:49.856713 22542570456896 run_lib.py:133] step: 233100, training_loss: 2.96324e-02
I0209 11:44:50.012486 22542570456896 run_lib.py:146] step: 233100, eval_loss: 3.02442e-02
I0209 11:45:07.465874 22542570456896 run_lib.py:133] step: 233150, training_loss: 2.77206e-02
I0209 11:45:24.937009 22542570456896 run_lib.py:133] step: 233200, training_loss: 2.77064e-02
I0209 11:45:25.103065 22542570456896 run_lib.py:146] step: 233200, eval_loss: 2.97063e-02
I0209 11:45:42.600072 22542570456896 run_lib.py:133] step: 233250, training_loss: 2.97312e-02
I0209 11:46:00.212463 22542570456896 run_lib.py:133] step: 233300, training_loss: 2.71120e-02
I0209 11:46:00.364516 22542570456896 run_lib.py:146] step: 233300, eval_loss: 3.82420e-02
I0209 11:46:17.785186 22542570456896 run_lib.py:133] step: 233350, training_loss: 2.61229e-02
I0209 11:46:35.300881 22542570456896 run_lib.py:133] step: 233400, training_loss: 2.85858e-02
I0209 11:46:35.456419 22542570456896 run_lib.py:146] step: 233400, eval_loss: 3.03477e-02
I0209 11:46:52.872274 22542570456896 run_lib.py:133] step: 233450, training_loss: 2.95884e-02
I0209 11:47:10.312237 22542570456896 run_lib.py:133] step: 233500, training_loss: 2.84428e-02
I0209 11:47:10.489446 22542570456896 run_lib.py:146] step: 233500, eval_loss: 2.98127e-02
I0209 11:47:28.138971 22542570456896 run_lib.py:133] step: 233550, training_loss: 2.62573e-02
I0209 11:47:45.674932 22542570456896 run_lib.py:133] step: 233600, training_loss: 2.93905e-02
I0209 11:47:45.831582 22542570456896 run_lib.py:146] step: 233600, eval_loss: 3.18235e-02
I0209 11:48:03.254773 22542570456896 run_lib.py:133] step: 233650, training_loss: 2.43691e-02
I0209 11:48:20.651855 22542570456896 run_lib.py:133] step: 233700, training_loss: 2.49679e-02
I0209 11:48:20.806322 22542570456896 run_lib.py:146] step: 233700, eval_loss: 3.31568e-02
I0209 11:48:38.382446 22542570456896 run_lib.py:133] step: 233750, training_loss: 2.81454e-02
I0209 11:48:55.802045 22542570456896 run_lib.py:133] step: 233800, training_loss: 3.12217e-02
I0209 11:48:55.957852 22542570456896 run_lib.py:146] step: 233800, eval_loss: 2.57060e-02
I0209 11:49:13.614135 22542570456896 run_lib.py:133] step: 233850, training_loss: 2.76766e-02
I0209 11:49:31.056215 22542570456896 run_lib.py:133] step: 233900, training_loss: 2.68967e-02
I0209 11:49:31.212213 22542570456896 run_lib.py:146] step: 233900, eval_loss: 2.99952e-02
I0209 11:49:48.836869 22542570456896 run_lib.py:133] step: 233950, training_loss: 3.06232e-02
I0209 11:50:06.256033 22542570456896 run_lib.py:133] step: 234000, training_loss: 2.21242e-02
I0209 11:50:06.423776 22542570456896 run_lib.py:146] step: 234000, eval_loss: 2.93813e-02
I0209 11:50:23.871179 22542570456896 run_lib.py:133] step: 234050, training_loss: 3.21620e-02
I0209 11:50:41.504040 22542570456896 run_lib.py:133] step: 234100, training_loss: 2.02972e-02
I0209 11:50:41.659881 22542570456896 run_lib.py:146] step: 234100, eval_loss: 3.27406e-02
I0209 11:50:59.118763 22542570456896 run_lib.py:133] step: 234150, training_loss: 3.15559e-02
I0209 11:51:16.730752 22542570456896 run_lib.py:133] step: 234200, training_loss: 3.20136e-02
I0209 11:51:16.886422 22542570456896 run_lib.py:146] step: 234200, eval_loss: 2.43400e-02
I0209 11:51:34.317486 22542570456896 run_lib.py:133] step: 234250, training_loss: 2.99269e-02
I0209 11:51:51.778272 22542570456896 run_lib.py:133] step: 234300, training_loss: 2.84938e-02
I0209 11:51:51.931438 22542570456896 run_lib.py:146] step: 234300, eval_loss: 2.31400e-02
I0209 11:52:09.511843 22542570456896 run_lib.py:133] step: 234350, training_loss: 2.97875e-02
I0209 11:52:26.994746 22542570456896 run_lib.py:133] step: 234400, training_loss: 2.66114e-02
I0209 11:52:27.171065 22542570456896 run_lib.py:146] step: 234400, eval_loss: 2.55716e-02
I0209 11:52:44.639679 22542570456896 run_lib.py:133] step: 234450, training_loss: 2.79072e-02
I0209 11:53:02.262315 22542570456896 run_lib.py:133] step: 234500, training_loss: 3.04204e-02
I0209 11:53:02.418456 22542570456896 run_lib.py:146] step: 234500, eval_loss: 2.97829e-02
I0209 11:53:19.861210 22542570456896 run_lib.py:133] step: 234550, training_loss: 2.41905e-02
I0209 11:53:37.316419 22542570456896 run_lib.py:133] step: 234600, training_loss: 3.15297e-02
I0209 11:53:37.481238 22542570456896 run_lib.py:146] step: 234600, eval_loss: 2.58710e-02
I0209 11:53:55.011664 22542570456896 run_lib.py:133] step: 234650, training_loss: 3.43924e-02
I0209 11:54:12.488507 22542570456896 run_lib.py:133] step: 234700, training_loss: 2.96589e-02
I0209 11:54:12.641150 22542570456896 run_lib.py:146] step: 234700, eval_loss: 2.77153e-02
I0209 11:54:30.081984 22542570456896 run_lib.py:133] step: 234750, training_loss: 2.49152e-02
I0209 11:54:47.491919 22542570456896 run_lib.py:133] step: 234800, training_loss: 2.43046e-02
I0209 11:54:47.647409 22542570456896 run_lib.py:146] step: 234800, eval_loss: 2.90005e-02
I0209 11:55:05.234424 22542570456896 run_lib.py:133] step: 234850, training_loss: 2.53969e-02
I0209 11:55:22.733080 22542570456896 run_lib.py:133] step: 234900, training_loss: 3.50211e-02
I0209 11:55:22.911412 22542570456896 run_lib.py:146] step: 234900, eval_loss: 2.85396e-02
I0209 11:55:40.463602 22542570456896 run_lib.py:133] step: 234950, training_loss: 2.36267e-02
I0209 11:55:57.929545 22542570456896 run_lib.py:133] step: 235000, training_loss: 3.05641e-02
I0209 11:55:58.095216 22542570456896 run_lib.py:146] step: 235000, eval_loss: 2.93858e-02
I0209 11:56:15.716041 22542570456896 run_lib.py:133] step: 235050, training_loss: 2.62570e-02
I0209 11:56:33.157728 22542570456896 run_lib.py:133] step: 235100, training_loss: 3.10990e-02
I0209 11:56:33.321380 22542570456896 run_lib.py:146] step: 235100, eval_loss: 2.76683e-02
I0209 11:56:50.937862 22542570456896 run_lib.py:133] step: 235150, training_loss: 3.06427e-02
I0209 11:57:08.388044 22542570456896 run_lib.py:133] step: 235200, training_loss: 3.22697e-02
I0209 11:57:08.541678 22542570456896 run_lib.py:146] step: 235200, eval_loss: 2.73362e-02
I0209 11:57:26.220764 22542570456896 run_lib.py:133] step: 235250, training_loss: 3.59366e-02
I0209 11:57:43.652300 22542570456896 run_lib.py:133] step: 235300, training_loss: 2.64837e-02
I0209 11:57:43.808284 22542570456896 run_lib.py:146] step: 235300, eval_loss: 3.31862e-02
I0209 11:58:01.346592 22542570456896 run_lib.py:133] step: 235350, training_loss: 2.75702e-02
I0209 11:58:18.708981 22542570456896 run_lib.py:133] step: 235400, training_loss: 3.04017e-02
I0209 11:58:18.866525 22542570456896 run_lib.py:146] step: 235400, eval_loss: 2.90897e-02
I0209 11:58:36.221346 22542570456896 run_lib.py:133] step: 235450, training_loss: 2.78607e-02
I0209 11:58:53.711238 22542570456896 run_lib.py:133] step: 235500, training_loss: 2.97484e-02
I0209 11:58:53.882435 22542570456896 run_lib.py:146] step: 235500, eval_loss: 2.40310e-02
I0209 11:59:11.394194 22542570456896 run_lib.py:133] step: 235550, training_loss: 2.54573e-02
I0209 11:59:28.839771 22542570456896 run_lib.py:133] step: 235600, training_loss: 3.06489e-02
I0209 11:59:29.002806 22542570456896 run_lib.py:146] step: 235600, eval_loss: 2.79618e-02
I0209 11:59:46.710001 22542570456896 run_lib.py:133] step: 235650, training_loss: 2.69642e-02
I0209 12:00:04.176737 22542570456896 run_lib.py:133] step: 235700, training_loss: 2.55329e-02
I0209 12:00:04.329365 22542570456896 run_lib.py:146] step: 235700, eval_loss: 2.52426e-02
I0209 12:00:21.899783 22542570456896 run_lib.py:133] step: 235750, training_loss: 2.02250e-02
I0209 12:00:39.359071 22542570456896 run_lib.py:133] step: 235800, training_loss: 2.56011e-02
I0209 12:00:39.535340 22542570456896 run_lib.py:146] step: 235800, eval_loss: 2.92473e-02
I0209 12:00:56.995104 22542570456896 run_lib.py:133] step: 235850, training_loss: 2.86805e-02
I0209 12:01:14.678910 22542570456896 run_lib.py:133] step: 235900, training_loss: 2.48044e-02
I0209 12:01:14.837441 22542570456896 run_lib.py:146] step: 235900, eval_loss: 2.53501e-02
I0209 12:01:32.271238 22542570456896 run_lib.py:133] step: 235950, training_loss: 3.18046e-02
I0209 12:01:49.693619 22542570456896 run_lib.py:133] step: 236000, training_loss: 2.51287e-02
I0209 12:01:49.850171 22542570456896 run_lib.py:146] step: 236000, eval_loss: 2.28621e-02
I0209 12:02:07.286212 22542570456896 run_lib.py:133] step: 236050, training_loss: 2.57624e-02
I0209 12:02:24.950479 22542570456896 run_lib.py:133] step: 236100, training_loss: 3.78420e-02
I0209 12:02:25.106117 22542570456896 run_lib.py:146] step: 236100, eval_loss: 3.57662e-02
I0209 12:02:42.563235 22542570456896 run_lib.py:133] step: 236150, training_loss: 3.21676e-02
I0209 12:03:00.128619 22542570456896 run_lib.py:133] step: 236200, training_loss: 2.77376e-02
I0209 12:03:00.281596 22542570456896 run_lib.py:146] step: 236200, eval_loss: 3.26201e-02
I0209 12:03:17.694028 22542570456896 run_lib.py:133] step: 236250, training_loss: 2.44164e-02
I0209 12:03:35.141643 22542570456896 run_lib.py:133] step: 236300, training_loss: 2.86750e-02
I0209 12:03:35.301690 22542570456896 run_lib.py:146] step: 236300, eval_loss: 2.67219e-02
I0209 12:03:52.865627 22542570456896 run_lib.py:133] step: 236350, training_loss: 2.81974e-02
I0209 12:04:10.404671 22542570456896 run_lib.py:133] step: 236400, training_loss: 3.38581e-02
I0209 12:04:10.561325 22542570456896 run_lib.py:146] step: 236400, eval_loss: 3.56418e-02
I0209 12:04:28.037814 22542570456896 run_lib.py:133] step: 236450, training_loss: 3.25415e-02
I0209 12:04:45.507837 22542570456896 run_lib.py:133] step: 236500, training_loss: 3.18401e-02
I0209 12:04:45.663044 22542570456896 run_lib.py:146] step: 236500, eval_loss: 2.39065e-02
I0209 12:05:03.325578 22542570456896 run_lib.py:133] step: 236550, training_loss: 3.06814e-02
I0209 12:05:20.749919 22542570456896 run_lib.py:133] step: 236600, training_loss: 2.51362e-02
I0209 12:05:20.899077 22542570456896 run_lib.py:146] step: 236600, eval_loss: 2.96141e-02
I0209 12:05:38.481372 22542570456896 run_lib.py:133] step: 236650, training_loss: 2.17424e-02
I0209 12:05:55.985362 22542570456896 run_lib.py:133] step: 236700, training_loss: 2.80612e-02
I0209 12:05:56.149559 22542570456896 run_lib.py:146] step: 236700, eval_loss: 3.04684e-02
I0209 12:06:13.813055 22542570456896 run_lib.py:133] step: 236750, training_loss: 2.83668e-02
I0209 12:06:31.248849 22542570456896 run_lib.py:133] step: 236800, training_loss: 2.73029e-02
I0209 12:06:31.407778 22542570456896 run_lib.py:146] step: 236800, eval_loss: 2.62538e-02
I0209 12:06:48.834114 22542570456896 run_lib.py:133] step: 236850, training_loss: 3.14335e-02
I0209 12:07:06.386527 22542570456896 run_lib.py:133] step: 236900, training_loss: 3.29900e-02
I0209 12:07:06.542266 22542570456896 run_lib.py:146] step: 236900, eval_loss: 2.68513e-02
I0209 12:07:23.961100 22542570456896 run_lib.py:133] step: 236950, training_loss: 2.53479e-02
I0209 12:07:41.558938 22542570456896 run_lib.py:133] step: 237000, training_loss: 2.48593e-02
I0209 12:07:41.719731 22542570456896 run_lib.py:146] step: 237000, eval_loss: 3.49049e-02
I0209 12:07:59.191299 22542570456896 run_lib.py:133] step: 237050, training_loss: 3.19285e-02
I0209 12:08:16.674374 22542570456896 run_lib.py:133] step: 237100, training_loss: 2.59093e-02
I0209 12:08:16.826349 22542570456896 run_lib.py:146] step: 237100, eval_loss: 2.43619e-02
I0209 12:08:34.450860 22542570456896 run_lib.py:133] step: 237150, training_loss: 2.67244e-02
I0209 12:08:51.862164 22542570456896 run_lib.py:133] step: 237200, training_loss: 2.75536e-02
I0209 12:08:52.018659 22542570456896 run_lib.py:146] step: 237200, eval_loss: 2.80930e-02
I0209 12:09:09.461687 22542570456896 run_lib.py:133] step: 237250, training_loss: 2.71576e-02
I0209 12:09:27.113874 22542570456896 run_lib.py:133] step: 237300, training_loss: 3.41576e-02
I0209 12:09:27.274375 22542570456896 run_lib.py:146] step: 237300, eval_loss: 3.47650e-02
I0209 12:09:44.715740 22542570456896 run_lib.py:133] step: 237350, training_loss: 2.05612e-02
I0209 12:10:02.161391 22542570456896 run_lib.py:133] step: 237400, training_loss: 3.73242e-02
I0209 12:10:02.499354 22542570456896 run_lib.py:146] step: 237400, eval_loss: 3.64905e-02
I0209 12:10:19.958513 22542570456896 run_lib.py:133] step: 237450, training_loss: 2.54055e-02
I0209 12:10:37.390139 22542570456896 run_lib.py:133] step: 237500, training_loss: 2.65117e-02
I0209 12:10:37.544458 22542570456896 run_lib.py:146] step: 237500, eval_loss: 2.93342e-02
I0209 12:10:55.000095 22542570456896 run_lib.py:133] step: 237550, training_loss: 3.32547e-02
I0209 12:11:12.493261 22542570456896 run_lib.py:133] step: 237600, training_loss: 3.53294e-02
I0209 12:11:12.648649 22542570456896 run_lib.py:146] step: 237600, eval_loss: 2.67489e-02
I0209 12:11:30.279047 22542570456896 run_lib.py:133] step: 237650, training_loss: 2.98955e-02
I0209 12:11:47.839455 22542570456896 run_lib.py:133] step: 237700, training_loss: 2.41225e-02
I0209 12:11:47.998656 22542570456896 run_lib.py:146] step: 237700, eval_loss: 2.26441e-02
I0209 12:12:05.428216 22542570456896 run_lib.py:133] step: 237750, training_loss: 3.11499e-02
I0209 12:12:22.867578 22542570456896 run_lib.py:133] step: 237800, training_loss: 2.91622e-02
I0209 12:12:23.040515 22542570456896 run_lib.py:146] step: 237800, eval_loss: 2.31637e-02
I0209 12:12:40.682962 22542570456896 run_lib.py:133] step: 237850, training_loss: 2.56119e-02
I0209 12:12:58.274528 22542570456896 run_lib.py:133] step: 237900, training_loss: 3.25497e-02
I0209 12:12:58.433712 22542570456896 run_lib.py:146] step: 237900, eval_loss: 3.27216e-02
I0209 12:13:15.875724 22542570456896 run_lib.py:133] step: 237950, training_loss: 2.83084e-02
I0209 12:13:33.299686 22542570456896 run_lib.py:133] step: 238000, training_loss: 2.29602e-02
I0209 12:13:33.453329 22542570456896 run_lib.py:146] step: 238000, eval_loss: 3.18958e-02
I0209 12:13:51.028773 22542570456896 run_lib.py:133] step: 238050, training_loss: 2.83215e-02
I0209 12:14:08.462959 22542570456896 run_lib.py:133] step: 238100, training_loss: 2.56411e-02
I0209 12:14:08.622611 22542570456896 run_lib.py:146] step: 238100, eval_loss: 3.67689e-02
I0209 12:14:26.261303 22542570456896 run_lib.py:133] step: 238150, training_loss: 3.25190e-02
I0209 12:14:43.758357 22542570456896 run_lib.py:133] step: 238200, training_loss: 2.53341e-02
I0209 12:14:43.917370 22542570456896 run_lib.py:146] step: 238200, eval_loss: 3.14927e-02
I0209 12:15:01.538785 22542570456896 run_lib.py:133] step: 238250, training_loss: 2.81519e-02
I0209 12:15:18.963384 22542570456896 run_lib.py:133] step: 238300, training_loss: 2.31037e-02
I0209 12:15:19.119453 22542570456896 run_lib.py:146] step: 238300, eval_loss: 2.84769e-02
I0209 12:15:36.581747 22542570456896 run_lib.py:133] step: 238350, training_loss: 2.78869e-02
I0209 12:15:54.228032 22542570456896 run_lib.py:133] step: 238400, training_loss: 2.54446e-02
I0209 12:15:54.385297 22542570456896 run_lib.py:146] step: 238400, eval_loss: 2.32282e-02
I0209 12:16:11.896808 22542570456896 run_lib.py:133] step: 238450, training_loss: 2.69962e-02
I0209 12:16:29.481111 22542570456896 run_lib.py:133] step: 238500, training_loss: 2.67351e-02
I0209 12:16:29.633457 22542570456896 run_lib.py:146] step: 238500, eval_loss: 2.31425e-02
I0209 12:16:47.079823 22542570456896 run_lib.py:133] step: 238550, training_loss: 2.78134e-02
I0209 12:17:04.535012 22542570456896 run_lib.py:133] step: 238600, training_loss: 3.03341e-02
I0209 12:17:04.692417 22542570456896 run_lib.py:146] step: 238600, eval_loss: 2.92292e-02
I0209 12:17:22.275522 22542570456896 run_lib.py:133] step: 238650, training_loss: 3.72208e-02
I0209 12:17:39.707933 22542570456896 run_lib.py:133] step: 238700, training_loss: 2.48078e-02
I0209 12:17:39.884360 22542570456896 run_lib.py:146] step: 238700, eval_loss: 2.30366e-02
I0209 12:17:57.395936 22542570456896 run_lib.py:133] step: 238750, training_loss: 2.97484e-02
I0209 12:18:14.879579 22542570456896 run_lib.py:133] step: 238800, training_loss: 2.97973e-02
I0209 12:18:15.040646 22542570456896 run_lib.py:146] step: 238800, eval_loss: 2.51421e-02
I0209 12:18:32.650499 22542570456896 run_lib.py:133] step: 238850, training_loss: 3.05420e-02
I0209 12:18:50.076654 22542570456896 run_lib.py:133] step: 238900, training_loss: 2.80192e-02
I0209 12:18:50.232407 22542570456896 run_lib.py:146] step: 238900, eval_loss: 2.83495e-02
I0209 12:19:07.743825 22542570456896 run_lib.py:133] step: 238950, training_loss: 2.83297e-02
I0209 12:19:25.186247 22542570456896 run_lib.py:133] step: 239000, training_loss: 3.04887e-02
I0209 12:19:25.336958 22542570456896 run_lib.py:146] step: 239000, eval_loss: 2.68342e-02
I0209 12:19:42.896421 22542570456896 run_lib.py:133] step: 239050, training_loss: 2.31809e-02
I0209 12:20:00.306273 22542570456896 run_lib.py:133] step: 239100, training_loss: 3.51669e-02
I0209 12:20:00.462353 22542570456896 run_lib.py:146] step: 239100, eval_loss: 2.54551e-02
I0209 12:20:18.024465 22542570456896 run_lib.py:133] step: 239150, training_loss: 3.35898e-02
I0209 12:20:35.507942 22542570456896 run_lib.py:133] step: 239200, training_loss: 2.82214e-02
I0209 12:20:35.666577 22542570456896 run_lib.py:146] step: 239200, eval_loss: 2.69395e-02
I0209 12:20:53.099736 22542570456896 run_lib.py:133] step: 239250, training_loss: 3.56860e-02
I0209 12:21:10.558485 22542570456896 run_lib.py:133] step: 239300, training_loss: 2.47321e-02
I0209 12:21:10.714398 22542570456896 run_lib.py:146] step: 239300, eval_loss: 3.06234e-02
I0209 12:21:28.334474 22542570456896 run_lib.py:133] step: 239350, training_loss: 2.77648e-02
I0209 12:21:45.769473 22542570456896 run_lib.py:133] step: 239400, training_loss: 2.53391e-02
I0209 12:21:45.923420 22542570456896 run_lib.py:146] step: 239400, eval_loss: 3.18217e-02
I0209 12:22:03.494488 22542570456896 run_lib.py:133] step: 239450, training_loss: 3.66843e-02
I0209 12:22:20.922000 22542570456896 run_lib.py:133] step: 239500, training_loss: 2.77948e-02
I0209 12:22:21.072706 22542570456896 run_lib.py:146] step: 239500, eval_loss: 2.74107e-02
I0209 12:22:38.667326 22542570456896 run_lib.py:133] step: 239550, training_loss: 2.79693e-02
I0209 12:22:56.138664 22542570456896 run_lib.py:133] step: 239600, training_loss: 2.78292e-02
I0209 12:22:56.315389 22542570456896 run_lib.py:146] step: 239600, eval_loss: 2.46542e-02
I0209 12:23:14.011069 22542570456896 run_lib.py:133] step: 239650, training_loss: 3.17684e-02
I0209 12:23:31.518907 22542570456896 run_lib.py:133] step: 239700, training_loss: 2.93194e-02
I0209 12:23:31.674927 22542570456896 run_lib.py:146] step: 239700, eval_loss: 2.83653e-02
I0209 12:23:49.124321 22542570456896 run_lib.py:133] step: 239750, training_loss: 2.80706e-02
I0209 12:24:06.696628 22542570456896 run_lib.py:133] step: 239800, training_loss: 2.22186e-02
I0209 12:24:06.852227 22542570456896 run_lib.py:146] step: 239800, eval_loss: 3.05088e-02
I0209 12:24:24.303158 22542570456896 run_lib.py:133] step: 239850, training_loss: 2.34706e-02
I0209 12:24:41.811237 22542570456896 run_lib.py:133] step: 239900, training_loss: 3.69993e-02
I0209 12:24:41.967092 22542570456896 run_lib.py:146] step: 239900, eval_loss: 2.31837e-02
I0209 12:24:59.657640 22542570456896 run_lib.py:133] step: 239950, training_loss: 3.05785e-02
I0209 12:25:17.227806 22542570456896 run_lib.py:133] step: 240000, training_loss: 2.70711e-02
I0209 12:25:17.989214 22542570456896 run_lib.py:146] step: 240000, eval_loss: 2.93876e-02
I0209 12:25:38.232511 22542570456896 run_lib.py:133] step: 240050, training_loss: 3.38032e-02
I0209 12:25:55.731955 22542570456896 run_lib.py:133] step: 240100, training_loss: 2.78660e-02
I0209 12:25:55.899571 22542570456896 run_lib.py:146] step: 240100, eval_loss: 2.97617e-02
I0209 12:26:13.406511 22542570456896 run_lib.py:133] step: 240150, training_loss: 3.57416e-02
I0209 12:26:30.904885 22542570456896 run_lib.py:133] step: 240200, training_loss: 3.09388e-02
I0209 12:26:31.066405 22542570456896 run_lib.py:146] step: 240200, eval_loss: 2.30765e-02
I0209 12:26:48.672721 22542570456896 run_lib.py:133] step: 240250, training_loss: 2.39706e-02
I0209 12:27:06.194286 22542570456896 run_lib.py:133] step: 240300, training_loss: 3.23978e-02
I0209 12:27:06.350427 22542570456896 run_lib.py:146] step: 240300, eval_loss: 2.74957e-02
I0209 12:27:23.789859 22542570456896 run_lib.py:133] step: 240350, training_loss: 3.23857e-02
I0209 12:27:41.221348 22542570456896 run_lib.py:133] step: 240400, training_loss: 2.46381e-02
I0209 12:27:41.376577 22542570456896 run_lib.py:146] step: 240400, eval_loss: 2.32599e-02
I0209 12:27:58.990712 22542570456896 run_lib.py:133] step: 240450, training_loss: 2.84722e-02
I0209 12:28:16.440345 22542570456896 run_lib.py:133] step: 240500, training_loss: 3.08640e-02
I0209 12:28:16.592347 22542570456896 run_lib.py:146] step: 240500, eval_loss: 3.22950e-02
I0209 12:28:34.211277 22542570456896 run_lib.py:133] step: 240550, training_loss: 2.53866e-02
I0209 12:28:51.676977 22542570456896 run_lib.py:133] step: 240600, training_loss: 3.55589e-02
I0209 12:28:51.838409 22542570456896 run_lib.py:146] step: 240600, eval_loss: 3.12093e-02
I0209 12:29:09.414116 22542570456896 run_lib.py:133] step: 240650, training_loss: 2.92353e-02
I0209 12:29:26.841838 22542570456896 run_lib.py:133] step: 240700, training_loss: 2.96111e-02
I0209 12:29:27.009899 22542570456896 run_lib.py:146] step: 240700, eval_loss: 3.07021e-02
I0209 12:29:44.513747 22542570456896 run_lib.py:133] step: 240750, training_loss: 2.56046e-02
I0209 12:30:02.232934 22542570456896 run_lib.py:133] step: 240800, training_loss: 2.91028e-02
I0209 12:30:02.389659 22542570456896 run_lib.py:146] step: 240800, eval_loss: 3.17174e-02
I0209 12:30:19.860841 22542570456896 run_lib.py:133] step: 240850, training_loss: 2.65698e-02
I0209 12:30:37.436425 22542570456896 run_lib.py:133] step: 240900, training_loss: 2.49570e-02
I0209 12:30:37.591166 22542570456896 run_lib.py:146] step: 240900, eval_loss: 2.64511e-02
I0209 12:30:55.024091 22542570456896 run_lib.py:133] step: 240950, training_loss: 2.88173e-02
I0209 12:31:12.527054 22542570456896 run_lib.py:133] step: 241000, training_loss: 2.36589e-02
I0209 12:31:12.683753 22542570456896 run_lib.py:146] step: 241000, eval_loss: 2.75694e-02
I0209 12:31:30.362868 22542570456896 run_lib.py:133] step: 241050, training_loss: 3.04634e-02
I0209 12:31:47.830990 22542570456896 run_lib.py:133] step: 241100, training_loss: 2.77777e-02
I0209 12:31:47.988487 22542570456896 run_lib.py:146] step: 241100, eval_loss: 2.71109e-02
I0209 12:32:05.407257 22542570456896 run_lib.py:133] step: 241150, training_loss: 3.13912e-02
I0209 12:32:23.008125 22542570456896 run_lib.py:133] step: 241200, training_loss: 2.68837e-02
I0209 12:32:23.164698 22542570456896 run_lib.py:146] step: 241200, eval_loss: 2.31897e-02
I0209 12:32:40.585325 22542570456896 run_lib.py:133] step: 241250, training_loss: 2.69755e-02
I0209 12:32:58.081152 22542570456896 run_lib.py:133] step: 241300, training_loss: 2.37950e-02
I0209 12:32:58.237439 22542570456896 run_lib.py:146] step: 241300, eval_loss: 2.57817e-02
I0209 12:33:15.759127 22542570456896 run_lib.py:133] step: 241350, training_loss: 2.35620e-02
I0209 12:33:33.187628 22542570456896 run_lib.py:133] step: 241400, training_loss: 2.97046e-02
I0209 12:33:33.345196 22542570456896 run_lib.py:146] step: 241400, eval_loss: 2.30184e-02
I0209 12:33:50.811218 22542570456896 run_lib.py:133] step: 241450, training_loss: 2.74209e-02
I0209 12:34:08.268271 22542570456896 run_lib.py:133] step: 241500, training_loss: 2.66211e-02
I0209 12:34:08.422400 22542570456896 run_lib.py:146] step: 241500, eval_loss: 3.26145e-02
I0209 12:34:25.997191 22542570456896 run_lib.py:133] step: 241550, training_loss: 2.37969e-02
I0209 12:34:43.551895 22542570456896 run_lib.py:133] step: 241600, training_loss: 3.54391e-02
I0209 12:34:43.716468 22542570456896 run_lib.py:146] step: 241600, eval_loss: 3.23676e-02
I0209 12:35:01.156543 22542570456896 run_lib.py:133] step: 241650, training_loss: 2.62250e-02
I0209 12:35:18.633359 22542570456896 run_lib.py:133] step: 241700, training_loss: 2.64208e-02
I0209 12:35:18.797652 22542570456896 run_lib.py:146] step: 241700, eval_loss: 2.69036e-02
I0209 12:35:36.418254 22542570456896 run_lib.py:133] step: 241750, training_loss: 2.37108e-02
I0209 12:35:53.879429 22542570456896 run_lib.py:133] step: 241800, training_loss: 2.70258e-02
I0209 12:35:54.051647 22542570456896 run_lib.py:146] step: 241800, eval_loss: 3.22141e-02
I0209 12:36:11.679648 22542570456896 run_lib.py:133] step: 241850, training_loss: 2.76152e-02
I0209 12:36:29.130398 22542570456896 run_lib.py:133] step: 241900, training_loss: 2.43455e-02
I0209 12:36:29.282578 22542570456896 run_lib.py:146] step: 241900, eval_loss: 3.60649e-02
I0209 12:36:46.934501 22542570456896 run_lib.py:133] step: 241950, training_loss: 2.65023e-02
I0209 12:37:04.366671 22542570456896 run_lib.py:133] step: 242000, training_loss: 3.90331e-02
I0209 12:37:04.530182 22542570456896 run_lib.py:146] step: 242000, eval_loss: 2.91003e-02
I0209 12:37:22.074246 22542570456896 run_lib.py:133] step: 242050, training_loss: 2.50037e-02
I0209 12:37:39.511941 22542570456896 run_lib.py:133] step: 242100, training_loss: 2.44049e-02
I0209 12:37:39.687095 22542570456896 run_lib.py:146] step: 242100, eval_loss: 2.77794e-02
I0209 12:37:57.207005 22542570456896 run_lib.py:133] step: 242150, training_loss: 2.76803e-02
I0209 12:38:14.848340 22542570456896 run_lib.py:133] step: 242200, training_loss: 2.77625e-02
I0209 12:38:15.004583 22542570456896 run_lib.py:146] step: 242200, eval_loss: 3.17856e-02
I0209 12:38:32.447507 22542570456896 run_lib.py:133] step: 242250, training_loss: 1.86729e-02
I0209 12:38:49.865435 22542570456896 run_lib.py:133] step: 242300, training_loss: 2.77131e-02
I0209 12:38:50.021445 22542570456896 run_lib.py:146] step: 242300, eval_loss: 2.60561e-02
I0209 12:39:07.641965 22542570456896 run_lib.py:133] step: 242350, training_loss: 2.77214e-02
I0209 12:39:25.126781 22542570456896 run_lib.py:133] step: 242400, training_loss: 2.84705e-02
I0209 12:39:25.280672 22542570456896 run_lib.py:146] step: 242400, eval_loss: 3.65642e-02
I0209 12:39:42.917978 22542570456896 run_lib.py:133] step: 242450, training_loss: 2.63823e-02
I0209 12:40:00.325663 22542570456896 run_lib.py:133] step: 242500, training_loss: 3.13042e-02
I0209 12:40:00.486451 22542570456896 run_lib.py:146] step: 242500, eval_loss: 2.64165e-02
I0209 12:40:17.940232 22542570456896 run_lib.py:133] step: 242550, training_loss: 2.92164e-02
I0209 12:40:35.574990 22542570456896 run_lib.py:133] step: 242600, training_loss: 3.27516e-02
I0209 12:40:35.736620 22542570456896 run_lib.py:146] step: 242600, eval_loss: 2.90137e-02
I0209 12:40:53.220390 22542570456896 run_lib.py:133] step: 242650, training_loss: 3.42936e-02
I0209 12:41:10.698328 22542570456896 run_lib.py:133] step: 242700, training_loss: 2.96258e-02
I0209 12:41:10.855702 22542570456896 run_lib.py:146] step: 242700, eval_loss: 2.97844e-02
I0209 12:41:28.333786 22542570456896 run_lib.py:133] step: 242750, training_loss: 2.85378e-02
I0209 12:41:45.962350 22542570456896 run_lib.py:133] step: 242800, training_loss: 2.42765e-02
I0209 12:41:46.118447 22542570456896 run_lib.py:146] step: 242800, eval_loss: 2.78713e-02
I0209 12:42:03.554182 22542570456896 run_lib.py:133] step: 242850, training_loss: 3.00249e-02
I0209 12:42:21.047398 22542570456896 run_lib.py:133] step: 242900, training_loss: 2.84146e-02
I0209 12:42:21.198555 22542570456896 run_lib.py:146] step: 242900, eval_loss: 3.60213e-02
I0209 12:42:38.719367 22542570456896 run_lib.py:133] step: 242950, training_loss: 2.83033e-02
I0209 12:42:56.205697 22542570456896 run_lib.py:133] step: 243000, training_loss: 2.62482e-02
I0209 12:42:56.365504 22542570456896 run_lib.py:146] step: 243000, eval_loss: 3.13881e-02
I0209 12:43:13.995177 22542570456896 run_lib.py:133] step: 243050, training_loss: 3.08046e-02
I0209 12:43:31.555774 22542570456896 run_lib.py:133] step: 243100, training_loss: 2.73201e-02
I0209 12:43:31.711415 22542570456896 run_lib.py:146] step: 243100, eval_loss: 2.84982e-02
I0209 12:43:49.171444 22542570456896 run_lib.py:133] step: 243150, training_loss: 2.79939e-02
I0209 12:44:06.572858 22542570456896 run_lib.py:133] step: 243200, training_loss: 2.16808e-02
I0209 12:44:06.727562 22542570456896 run_lib.py:146] step: 243200, eval_loss: 2.77810e-02
I0209 12:44:24.300317 22542570456896 run_lib.py:133] step: 243250, training_loss: 2.92067e-02
I0209 12:44:41.793236 22542570456896 run_lib.py:133] step: 243300, training_loss: 3.22308e-02
I0209 12:44:41.954172 22542570456896 run_lib.py:146] step: 243300, eval_loss: 2.42638e-02
I0209 12:44:59.651883 22542570456896 run_lib.py:133] step: 243350, training_loss: 3.54473e-02
I0209 12:45:17.113327 22542570456896 run_lib.py:133] step: 243400, training_loss: 2.87325e-02
I0209 12:45:17.268405 22542570456896 run_lib.py:146] step: 243400, eval_loss: 2.80545e-02
I0209 12:45:34.840992 22542570456896 run_lib.py:133] step: 243450, training_loss: 3.25205e-02
I0209 12:45:52.249196 22542570456896 run_lib.py:133] step: 243500, training_loss: 2.77517e-02
I0209 12:45:52.416978 22542570456896 run_lib.py:146] step: 243500, eval_loss: 2.65005e-02
I0209 12:46:09.860584 22542570456896 run_lib.py:133] step: 243550, training_loss: 2.14459e-02
I0209 12:46:27.521538 22542570456896 run_lib.py:133] step: 243600, training_loss: 2.98121e-02
I0209 12:46:27.679619 22542570456896 run_lib.py:146] step: 243600, eval_loss: 3.41119e-02
I0209 12:46:45.138766 22542570456896 run_lib.py:133] step: 243650, training_loss: 2.42391e-02
I0209 12:47:02.754643 22542570456896 run_lib.py:133] step: 243700, training_loss: 2.78630e-02
I0209 12:47:02.911572 22542570456896 run_lib.py:146] step: 243700, eval_loss: 2.89118e-02
I0209 12:47:20.348527 22542570456896 run_lib.py:133] step: 243750, training_loss: 2.24321e-02
I0209 12:47:37.801041 22542570456896 run_lib.py:133] step: 243800, training_loss: 2.12428e-02
I0209 12:47:37.956432 22542570456896 run_lib.py:146] step: 243800, eval_loss: 2.53344e-02
I0209 12:47:55.612618 22542570456896 run_lib.py:133] step: 243850, training_loss: 3.38530e-02
I0209 12:48:13.066074 22542570456896 run_lib.py:133] step: 243900, training_loss: 2.59520e-02
I0209 12:48:13.221402 22542570456896 run_lib.py:146] step: 243900, eval_loss: 3.15377e-02
I0209 12:48:30.643055 22542570456896 run_lib.py:133] step: 243950, training_loss: 2.54887e-02
I0209 12:48:48.283134 22542570456896 run_lib.py:133] step: 244000, training_loss: 2.53085e-02
I0209 12:48:48.444608 22542570456896 run_lib.py:146] step: 244000, eval_loss: 3.46298e-02
I0209 12:49:05.868886 22542570456896 run_lib.py:133] step: 244050, training_loss: 3.64919e-02
I0209 12:49:23.400290 22542570456896 run_lib.py:133] step: 244100, training_loss: 2.88510e-02
I0209 12:49:23.721363 22542570456896 run_lib.py:146] step: 244100, eval_loss: 2.56133e-02
I0209 12:49:41.225544 22542570456896 run_lib.py:133] step: 244150, training_loss: 3.18679e-02
I0209 12:49:58.690915 22542570456896 run_lib.py:133] step: 244200, training_loss: 2.96074e-02
I0209 12:49:58.845505 22542570456896 run_lib.py:146] step: 244200, eval_loss: 2.63704e-02
I0209 12:50:16.306905 22542570456896 run_lib.py:133] step: 244250, training_loss: 2.18361e-02
I0209 12:50:33.753164 22542570456896 run_lib.py:133] step: 244300, training_loss: 3.18909e-02
I0209 12:50:33.911382 22542570456896 run_lib.py:146] step: 244300, eval_loss: 2.76249e-02
I0209 12:50:51.531211 22542570456896 run_lib.py:133] step: 244350, training_loss: 3.73794e-02
I0209 12:51:09.073856 22542570456896 run_lib.py:133] step: 244400, training_loss: 2.99622e-02
I0209 12:51:09.244732 22542570456896 run_lib.py:146] step: 244400, eval_loss: 1.94791e-02
I0209 12:51:26.753648 22542570456896 run_lib.py:133] step: 244450, training_loss: 2.75441e-02
I0209 12:51:44.236223 22542570456896 run_lib.py:133] step: 244500, training_loss: 3.04940e-02
I0209 12:51:44.394628 22542570456896 run_lib.py:146] step: 244500, eval_loss: 3.00800e-02
I0209 12:52:02.005249 22542570456896 run_lib.py:133] step: 244550, training_loss: 3.28299e-02
I0209 12:52:19.531361 22542570456896 run_lib.py:133] step: 244600, training_loss: 2.55156e-02
I0209 12:52:19.688187 22542570456896 run_lib.py:146] step: 244600, eval_loss: 3.07745e-02
I0209 12:52:37.142542 22542570456896 run_lib.py:133] step: 244650, training_loss: 2.92918e-02
I0209 12:52:54.669323 22542570456896 run_lib.py:133] step: 244700, training_loss: 2.32093e-02
I0209 12:52:54.823598 22542570456896 run_lib.py:146] step: 244700, eval_loss: 2.91973e-02
I0209 12:53:12.434602 22542570456896 run_lib.py:133] step: 244750, training_loss: 3.14843e-02
I0209 12:53:29.866045 22542570456896 run_lib.py:133] step: 244800, training_loss: 2.98793e-02
I0209 12:53:30.019414 22542570456896 run_lib.py:146] step: 244800, eval_loss: 2.26815e-02
I0209 12:53:47.561810 22542570456896 run_lib.py:133] step: 244850, training_loss: 2.42218e-02
I0209 12:54:05.021265 22542570456896 run_lib.py:133] step: 244900, training_loss: 2.58445e-02
I0209 12:54:05.180659 22542570456896 run_lib.py:146] step: 244900, eval_loss: 2.82352e-02
I0209 12:54:22.759144 22542570456896 run_lib.py:133] step: 244950, training_loss: 2.99357e-02
I0209 12:54:40.237467 22542570456896 run_lib.py:133] step: 245000, training_loss: 2.38991e-02
I0209 12:54:40.393737 22542570456896 run_lib.py:146] step: 245000, eval_loss: 3.09682e-02
I0209 12:54:57.826297 22542570456896 run_lib.py:133] step: 245050, training_loss: 2.72923e-02
I0209 12:55:15.433985 22542570456896 run_lib.py:133] step: 245100, training_loss: 3.29379e-02
I0209 12:55:15.590586 22542570456896 run_lib.py:146] step: 245100, eval_loss: 3.17329e-02
I0209 12:55:33.060260 22542570456896 run_lib.py:133] step: 245150, training_loss: 2.55307e-02
I0209 12:55:50.641921 22542570456896 run_lib.py:133] step: 245200, training_loss: 2.95410e-02
I0209 12:55:50.794167 22542570456896 run_lib.py:146] step: 245200, eval_loss: 2.51122e-02
I0209 12:56:08.233718 22542570456896 run_lib.py:133] step: 245250, training_loss: 3.49287e-02
I0209 12:56:25.710435 22542570456896 run_lib.py:133] step: 245300, training_loss: 2.59029e-02
I0209 12:56:25.872570 22542570456896 run_lib.py:146] step: 245300, eval_loss: 3.01092e-02
I0209 12:56:43.549337 22542570456896 run_lib.py:133] step: 245350, training_loss: 2.54064e-02
I0209 12:57:01.010739 22542570456896 run_lib.py:133] step: 245400, training_loss: 3.17602e-02
I0209 12:57:01.172599 22542570456896 run_lib.py:146] step: 245400, eval_loss: 2.53345e-02
I0209 12:57:18.595746 22542570456896 run_lib.py:133] step: 245450, training_loss: 2.61489e-02
I0209 12:57:36.034505 22542570456896 run_lib.py:133] step: 245500, training_loss: 2.49153e-02
I0209 12:57:36.204301 22542570456896 run_lib.py:146] step: 245500, eval_loss: 3.27260e-02
I0209 12:57:53.818444 22542570456896 run_lib.py:133] step: 245550, training_loss: 3.00758e-02
I0209 12:58:11.280220 22542570456896 run_lib.py:133] step: 245600, training_loss: 2.53046e-02
I0209 12:58:11.437938 22542570456896 run_lib.py:146] step: 245600, eval_loss: 2.76668e-02
I0209 12:58:29.017754 22542570456896 run_lib.py:133] step: 245650, training_loss: 2.36561e-02
I0209 12:58:46.456500 22542570456896 run_lib.py:133] step: 245700, training_loss: 2.96653e-02
I0209 12:58:46.620515 22542570456896 run_lib.py:146] step: 245700, eval_loss: 3.08903e-02
I0209 12:59:04.041701 22542570456896 run_lib.py:133] step: 245750, training_loss: 2.43833e-02
I0209 12:59:21.463368 22542570456896 run_lib.py:133] step: 245800, training_loss: 3.14016e-02
I0209 12:59:21.637538 22542570456896 run_lib.py:146] step: 245800, eval_loss: 2.03697e-02
I0209 12:59:39.258715 22542570456896 run_lib.py:133] step: 245850, training_loss: 3.14131e-02
I0209 12:59:56.840029 22542570456896 run_lib.py:133] step: 245900, training_loss: 3.38586e-02
I0209 12:59:56.998379 22542570456896 run_lib.py:146] step: 245900, eval_loss: 2.79358e-02
I0209 13:00:14.440142 22542570456896 run_lib.py:133] step: 245950, training_loss: 2.70630e-02
I0209 13:00:31.833355 22542570456896 run_lib.py:133] step: 246000, training_loss: 2.69014e-02
I0209 13:00:31.990638 22542570456896 run_lib.py:146] step: 246000, eval_loss: 2.93150e-02
I0209 13:00:49.595810 22542570456896 run_lib.py:133] step: 246050, training_loss: 3.25717e-02
I0209 13:01:07.081387 22542570456896 run_lib.py:133] step: 246100, training_loss: 3.47540e-02
I0209 13:01:07.237138 22542570456896 run_lib.py:146] step: 246100, eval_loss: 2.28689e-02
I0209 13:01:24.863148 22542570456896 run_lib.py:133] step: 246150, training_loss: 2.89678e-02
I0209 13:01:42.312117 22542570456896 run_lib.py:133] step: 246200, training_loss: 2.74245e-02
I0209 13:01:42.464372 22542570456896 run_lib.py:146] step: 246200, eval_loss: 2.54973e-02
I0209 13:02:00.114273 22542570456896 run_lib.py:133] step: 246250, training_loss: 2.86731e-02
I0209 13:02:17.529964 22542570456896 run_lib.py:133] step: 246300, training_loss: 2.56322e-02
I0209 13:02:17.686349 22542570456896 run_lib.py:146] step: 246300, eval_loss: 2.67776e-02
I0209 13:02:35.269516 22542570456896 run_lib.py:133] step: 246350, training_loss: 2.98103e-02
I0209 13:02:52.764359 22542570456896 run_lib.py:133] step: 246400, training_loss: 2.60508e-02
I0209 13:02:52.923364 22542570456896 run_lib.py:146] step: 246400, eval_loss: 2.27158e-02
I0209 13:03:10.378444 22542570456896 run_lib.py:133] step: 246450, training_loss: 3.23908e-02
I0209 13:03:27.999487 22542570456896 run_lib.py:133] step: 246500, training_loss: 2.86453e-02
I0209 13:03:28.155475 22542570456896 run_lib.py:146] step: 246500, eval_loss: 3.60911e-02
I0209 13:03:45.575388 22542570456896 run_lib.py:133] step: 246550, training_loss: 2.15126e-02
I0209 13:04:03.011517 22542570456896 run_lib.py:133] step: 246600, training_loss: 2.81023e-02
I0209 13:04:03.166508 22542570456896 run_lib.py:146] step: 246600, eval_loss: 2.85253e-02
I0209 13:04:20.755322 22542570456896 run_lib.py:133] step: 246650, training_loss: 2.38653e-02
I0209 13:04:38.432229 22542570456896 run_lib.py:133] step: 246700, training_loss: 3.09619e-02
I0209 13:04:38.587641 22542570456896 run_lib.py:146] step: 246700, eval_loss: 2.85273e-02
I0209 13:04:56.068513 22542570456896 run_lib.py:133] step: 246750, training_loss: 2.89087e-02
I0209 13:05:13.538269 22542570456896 run_lib.py:133] step: 246800, training_loss: 3.06009e-02
I0209 13:05:13.696719 22542570456896 run_lib.py:146] step: 246800, eval_loss: 2.91871e-02
I0209 13:05:31.140913 22542570456896 run_lib.py:133] step: 246850, training_loss: 2.65418e-02
I0209 13:05:48.710011 22542570456896 run_lib.py:133] step: 246900, training_loss: 3.37273e-02
I0209 13:05:48.866666 22542570456896 run_lib.py:146] step: 246900, eval_loss: 2.92748e-02
I0209 13:06:06.346524 22542570456896 run_lib.py:133] step: 246950, training_loss: 2.57186e-02
I0209 13:06:23.833602 22542570456896 run_lib.py:133] step: 247000, training_loss: 2.79343e-02
I0209 13:06:23.990407 22542570456896 run_lib.py:146] step: 247000, eval_loss: 3.21245e-02
I0209 13:06:41.438643 22542570456896 run_lib.py:133] step: 247050, training_loss: 2.88281e-02
I0209 13:06:58.996332 22542570456896 run_lib.py:133] step: 247100, training_loss: 2.37698e-02
I0209 13:06:59.153325 22542570456896 run_lib.py:146] step: 247100, eval_loss: 3.34289e-02
I0209 13:07:16.504997 22542570456896 run_lib.py:133] step: 247150, training_loss: 2.88649e-02
I0209 13:07:33.975544 22542570456896 run_lib.py:133] step: 247200, training_loss: 2.99294e-02
I0209 13:07:34.133598 22542570456896 run_lib.py:146] step: 247200, eval_loss: 3.23417e-02
I0209 13:07:51.642514 22542570456896 run_lib.py:133] step: 247250, training_loss: 3.13401e-02
I0209 13:08:09.097175 22542570456896 run_lib.py:133] step: 247300, training_loss: 3.20165e-02
I0209 13:08:09.255381 22542570456896 run_lib.py:146] step: 247300, eval_loss: 3.33404e-02
I0209 13:08:26.870549 22542570456896 run_lib.py:133] step: 247350, training_loss: 3.17755e-02
I0209 13:08:44.359254 22542570456896 run_lib.py:133] step: 247400, training_loss: 2.62635e-02
I0209 13:08:44.515514 22542570456896 run_lib.py:146] step: 247400, eval_loss: 3.15761e-02
I0209 13:09:01.984868 22542570456896 run_lib.py:133] step: 247450, training_loss: 2.90520e-02
I0209 13:09:19.415446 22542570456896 run_lib.py:133] step: 247500, training_loss: 2.61450e-02
I0209 13:09:19.581346 22542570456896 run_lib.py:146] step: 247500, eval_loss: 2.57819e-02
I0209 13:09:37.211041 22542570456896 run_lib.py:133] step: 247550, training_loss: 2.97514e-02
I0209 13:09:54.692900 22542570456896 run_lib.py:133] step: 247600, training_loss: 2.55914e-02
I0209 13:09:54.845671 22542570456896 run_lib.py:146] step: 247600, eval_loss: 2.40097e-02
I0209 13:10:12.505551 22542570456896 run_lib.py:133] step: 247650, training_loss: 3.36071e-02
I0209 13:10:29.951197 22542570456896 run_lib.py:133] step: 247700, training_loss: 2.82098e-02
I0209 13:10:30.106432 22542570456896 run_lib.py:146] step: 247700, eval_loss: 3.30384e-02
I0209 13:10:47.695277 22542570456896 run_lib.py:133] step: 247750, training_loss: 3.11544e-02
I0209 13:11:05.174157 22542570456896 run_lib.py:133] step: 247800, training_loss: 2.46033e-02
I0209 13:11:05.351525 22542570456896 run_lib.py:146] step: 247800, eval_loss: 2.62019e-02
I0209 13:11:22.861370 22542570456896 run_lib.py:133] step: 247850, training_loss: 2.37252e-02
I0209 13:11:40.514831 22542570456896 run_lib.py:133] step: 247900, training_loss: 2.57659e-02
I0209 13:11:40.671655 22542570456896 run_lib.py:146] step: 247900, eval_loss: 2.85932e-02
I0209 13:11:58.128793 22542570456896 run_lib.py:133] step: 247950, training_loss: 2.30527e-02
I0209 13:12:15.713306 22542570456896 run_lib.py:133] step: 248000, training_loss: 2.62270e-02
I0209 13:12:15.867337 22542570456896 run_lib.py:146] step: 248000, eval_loss: 3.30182e-02
I0209 13:12:33.300443 22542570456896 run_lib.py:133] step: 248050, training_loss: 3.16868e-02
I0209 13:12:50.752089 22542570456896 run_lib.py:133] step: 248100, training_loss: 2.39798e-02
I0209 13:12:50.908185 22542570456896 run_lib.py:146] step: 248100, eval_loss: 2.79749e-02
I0209 13:13:08.564192 22542570456896 run_lib.py:133] step: 248150, training_loss: 2.87052e-02
I0209 13:13:26.026605 22542570456896 run_lib.py:133] step: 248200, training_loss: 2.79890e-02
I0209 13:13:26.183564 22542570456896 run_lib.py:146] step: 248200, eval_loss: 2.50610e-02
I0209 13:13:43.626913 22542570456896 run_lib.py:133] step: 248250, training_loss: 2.79834e-02
I0209 13:14:01.208979 22542570456896 run_lib.py:133] step: 248300, training_loss: 2.64924e-02
I0209 13:14:01.375756 22542570456896 run_lib.py:146] step: 248300, eval_loss: 3.81271e-02
I0209 13:14:18.870734 22542570456896 run_lib.py:133] step: 248350, training_loss: 2.66517e-02
I0209 13:14:36.407162 22542570456896 run_lib.py:133] step: 248400, training_loss: 2.49540e-02
I0209 13:14:36.563148 22542570456896 run_lib.py:146] step: 248400, eval_loss: 2.60840e-02
I0209 13:14:54.089938 22542570456896 run_lib.py:133] step: 248450, training_loss: 2.78614e-02
I0209 13:15:11.557785 22542570456896 run_lib.py:133] step: 248500, training_loss: 3.08573e-02
I0209 13:15:11.708961 22542570456896 run_lib.py:146] step: 248500, eval_loss: 2.71885e-02
I0209 13:15:29.166447 22542570456896 run_lib.py:133] step: 248550, training_loss: 2.33959e-02
I0209 13:15:46.611274 22542570456896 run_lib.py:133] step: 248600, training_loss: 2.59479e-02
I0209 13:15:46.763993 22542570456896 run_lib.py:146] step: 248600, eval_loss: 3.74285e-02
I0209 13:16:04.373076 22542570456896 run_lib.py:133] step: 248650, training_loss: 3.03287e-02
I0209 13:16:21.916204 22542570456896 run_lib.py:133] step: 248700, training_loss: 2.19575e-02
I0209 13:16:22.076391 22542570456896 run_lib.py:146] step: 248700, eval_loss: 2.99245e-02
I0209 13:16:39.548511 22542570456896 run_lib.py:133] step: 248750, training_loss: 2.16693e-02
I0209 13:16:57.005074 22542570456896 run_lib.py:133] step: 248800, training_loss: 2.85544e-02
I0209 13:16:57.162597 22542570456896 run_lib.py:146] step: 248800, eval_loss: 2.68256e-02
I0209 13:17:14.777071 22542570456896 run_lib.py:133] step: 248850, training_loss: 2.54275e-02
I0209 13:17:32.201442 22542570456896 run_lib.py:133] step: 248900, training_loss: 2.69821e-02
I0209 13:17:32.374222 22542570456896 run_lib.py:146] step: 248900, eval_loss: 3.26216e-02
I0209 13:17:49.977661 22542570456896 run_lib.py:133] step: 248950, training_loss: 2.73816e-02
I0209 13:18:07.465293 22542570456896 run_lib.py:133] step: 249000, training_loss: 3.43470e-02
I0209 13:18:07.627202 22542570456896 run_lib.py:146] step: 249000, eval_loss: 3.03215e-02
I0209 13:18:25.274461 22542570456896 run_lib.py:133] step: 249050, training_loss: 2.99643e-02
I0209 13:18:42.719882 22542570456896 run_lib.py:133] step: 249100, training_loss: 2.51926e-02
I0209 13:18:42.873543 22542570456896 run_lib.py:146] step: 249100, eval_loss: 3.69079e-02
I0209 13:19:00.444662 22542570456896 run_lib.py:133] step: 249150, training_loss: 2.81501e-02
I0209 13:19:17.879384 22542570456896 run_lib.py:133] step: 249200, training_loss: 2.73717e-02
I0209 13:19:18.039479 22542570456896 run_lib.py:146] step: 249200, eval_loss: 2.70661e-02
I0209 13:19:35.521266 22542570456896 run_lib.py:133] step: 249250, training_loss: 3.31357e-02
I0209 13:19:53.144134 22542570456896 run_lib.py:133] step: 249300, training_loss: 3.67941e-02
I0209 13:19:53.309433 22542570456896 run_lib.py:146] step: 249300, eval_loss: 3.18177e-02
I0209 13:20:10.726271 22542570456896 run_lib.py:133] step: 249350, training_loss: 2.96770e-02
I0209 13:20:28.159198 22542570456896 run_lib.py:133] step: 249400, training_loss: 3.03356e-02
I0209 13:20:28.310228 22542570456896 run_lib.py:146] step: 249400, eval_loss: 2.71797e-02
I0209 13:20:45.928533 22542570456896 run_lib.py:133] step: 249450, training_loss: 2.78710e-02
I0209 13:21:03.344545 22542570456896 run_lib.py:133] step: 249500, training_loss: 2.81530e-02
I0209 13:21:03.499715 22542570456896 run_lib.py:146] step: 249500, eval_loss: 2.01670e-02
I0209 13:21:21.103049 22542570456896 run_lib.py:133] step: 249550, training_loss: 2.55232e-02
I0209 13:21:38.614343 22542570456896 run_lib.py:133] step: 249600, training_loss: 3.34596e-02
I0209 13:21:38.770696 22542570456896 run_lib.py:146] step: 249600, eval_loss: 2.59655e-02
I0209 13:21:56.203955 22542570456896 run_lib.py:133] step: 249650, training_loss: 1.72883e-02
I0209 13:22:13.853150 22542570456896 run_lib.py:133] step: 249700, training_loss: 2.52299e-02
I0209 13:22:14.019391 22542570456896 run_lib.py:146] step: 249700, eval_loss: 2.73282e-02
I0209 13:22:31.462815 22542570456896 run_lib.py:133] step: 249750, training_loss: 2.70335e-02
I0209 13:22:48.925438 22542570456896 run_lib.py:133] step: 249800, training_loss: 2.98941e-02
I0209 13:22:49.082506 22542570456896 run_lib.py:146] step: 249800, eval_loss: 3.39264e-02
I0209 13:23:06.566285 22542570456896 run_lib.py:133] step: 249850, training_loss: 2.75122e-02
I0209 13:23:24.233804 22542570456896 run_lib.py:133] step: 249900, training_loss: 2.65291e-02
I0209 13:23:24.388607 22542570456896 run_lib.py:146] step: 249900, eval_loss: 3.33680e-02
I0209 13:23:41.839993 22542570456896 run_lib.py:133] step: 249950, training_loss: 2.51746e-02
I0209 13:23:59.371364 22542570456896 run_lib.py:133] step: 250000, training_loss: 2.89892e-02
I0209 13:24:00.132797 22542570456896 run_lib.py:146] step: 250000, eval_loss: 2.57991e-02
I0209 13:24:20.212470 22542570456896 run_lib.py:133] step: 250050, training_loss: 2.84281e-02
I0209 13:24:37.662496 22542570456896 run_lib.py:133] step: 250100, training_loss: 2.73864e-02
I0209 13:24:37.819701 22542570456896 run_lib.py:146] step: 250100, eval_loss: 2.37266e-02
I0209 13:24:55.505598 22542570456896 run_lib.py:133] step: 250150, training_loss: 2.50160e-02
I0209 13:25:12.947981 22542570456896 run_lib.py:133] step: 250200, training_loss: 2.48607e-02
I0209 13:25:13.109594 22542570456896 run_lib.py:146] step: 250200, eval_loss: 3.19615e-02
I0209 13:25:30.622353 22542570456896 run_lib.py:133] step: 250250, training_loss: 2.80451e-02
I0209 13:25:48.039800 22542570456896 run_lib.py:133] step: 250300, training_loss: 3.27106e-02
I0209 13:25:48.203382 22542570456896 run_lib.py:146] step: 250300, eval_loss: 2.66916e-02
I0209 13:26:05.674983 22542570456896 run_lib.py:133] step: 250350, training_loss: 2.60344e-02
I0209 13:26:23.163369 22542570456896 run_lib.py:133] step: 250400, training_loss: 3.29473e-02
I0209 13:26:23.326299 22542570456896 run_lib.py:146] step: 250400, eval_loss: 2.80178e-02
I0209 13:26:40.976364 22542570456896 run_lib.py:133] step: 250450, training_loss: 3.18690e-02
I0209 13:26:58.491326 22542570456896 run_lib.py:133] step: 250500, training_loss: 2.34339e-02
I0209 13:26:58.643418 22542570456896 run_lib.py:146] step: 250500, eval_loss: 2.65632e-02
I0209 13:27:16.099741 22542570456896 run_lib.py:133] step: 250550, training_loss: 2.78946e-02
I0209 13:27:33.551447 22542570456896 run_lib.py:133] step: 250600, training_loss: 2.89782e-02
I0209 13:27:33.712500 22542570456896 run_lib.py:146] step: 250600, eval_loss: 3.23578e-02
I0209 13:27:51.261688 22542570456896 run_lib.py:133] step: 250650, training_loss: 3.36278e-02
I0209 13:28:08.730046 22542570456896 run_lib.py:133] step: 250700, training_loss: 2.51346e-02
I0209 13:28:08.900020 22542570456896 run_lib.py:146] step: 250700, eval_loss: 2.88914e-02
I0209 13:28:26.564616 22542570456896 run_lib.py:133] step: 250750, training_loss: 3.21994e-02
I0209 13:28:44.007534 22542570456896 run_lib.py:133] step: 250800, training_loss: 3.15252e-02
I0209 13:28:44.163681 22542570456896 run_lib.py:146] step: 250800, eval_loss: 2.24643e-02
I0209 13:29:01.754171 22542570456896 run_lib.py:133] step: 250850, training_loss: 3.13437e-02
I0209 13:29:19.175403 22542570456896 run_lib.py:133] step: 250900, training_loss: 2.72330e-02
I0209 13:29:19.330392 22542570456896 run_lib.py:146] step: 250900, eval_loss: 2.58691e-02
I0209 13:29:36.791448 22542570456896 run_lib.py:133] step: 250950, training_loss: 2.93489e-02
I0209 13:29:54.435455 22542570456896 run_lib.py:133] step: 251000, training_loss: 2.91417e-02
I0209 13:29:54.590617 22542570456896 run_lib.py:146] step: 251000, eval_loss: 2.76991e-02
I0209 13:30:12.092988 22542570456896 run_lib.py:133] step: 251050, training_loss: 2.92378e-02
I0209 13:30:29.712260 22542570456896 run_lib.py:133] step: 251100, training_loss: 2.85704e-02
I0209 13:30:29.868425 22542570456896 run_lib.py:146] step: 251100, eval_loss: 2.87878e-02
I0209 13:30:47.300925 22542570456896 run_lib.py:133] step: 251150, training_loss: 2.66391e-02
I0209 13:31:04.731430 22542570456896 run_lib.py:133] step: 251200, training_loss: 2.66768e-02
I0209 13:31:04.891646 22542570456896 run_lib.py:146] step: 251200, eval_loss: 3.57175e-02
I0209 13:31:22.521010 22542570456896 run_lib.py:133] step: 251250, training_loss: 3.07832e-02
I0209 13:31:40.023141 22542570456896 run_lib.py:133] step: 251300, training_loss: 2.24204e-02
I0209 13:31:40.179632 22542570456896 run_lib.py:146] step: 251300, eval_loss: 3.08412e-02
I0209 13:31:57.642106 22542570456896 run_lib.py:133] step: 251350, training_loss: 2.56053e-02
I0209 13:32:15.249615 22542570456896 run_lib.py:133] step: 251400, training_loss: 2.85331e-02
I0209 13:32:15.405371 22542570456896 run_lib.py:146] step: 251400, eval_loss: 2.55526e-02
I0209 13:32:32.853174 22542570456896 run_lib.py:133] step: 251450, training_loss: 2.41578e-02
I0209 13:32:50.333034 22542570456896 run_lib.py:133] step: 251500, training_loss: 2.94076e-02
I0209 13:32:50.638592 22542570456896 run_lib.py:146] step: 251500, eval_loss: 2.58023e-02
I0209 13:33:08.158534 22542570456896 run_lib.py:133] step: 251550, training_loss: 2.79753e-02
I0209 13:33:25.612655 22542570456896 run_lib.py:133] step: 251600, training_loss: 2.64849e-02
I0209 13:33:25.773361 22542570456896 run_lib.py:146] step: 251600, eval_loss: 3.07153e-02
I0209 13:33:43.203555 22542570456896 run_lib.py:133] step: 251650, training_loss: 3.00156e-02
I0209 13:34:00.661892 22542570456896 run_lib.py:133] step: 251700, training_loss: 2.61642e-02
I0209 13:34:00.825663 22542570456896 run_lib.py:146] step: 251700, eval_loss: 2.91170e-02
I0209 13:34:18.450591 22542570456896 run_lib.py:133] step: 251750, training_loss: 2.99521e-02
I0209 13:34:35.923818 22542570456896 run_lib.py:133] step: 251800, training_loss: 2.36131e-02
I0209 13:34:36.086100 22542570456896 run_lib.py:146] step: 251800, eval_loss: 2.84312e-02
I0209 13:34:53.538737 22542570456896 run_lib.py:133] step: 251850, training_loss: 2.50680e-02
I0209 13:35:10.996834 22542570456896 run_lib.py:133] step: 251900, training_loss: 2.72549e-02
I0209 13:35:11.151085 22542570456896 run_lib.py:146] step: 251900, eval_loss: 2.93628e-02
I0209 13:35:28.772583 22542570456896 run_lib.py:133] step: 251950, training_loss: 3.15284e-02
I0209 13:35:46.245208 22542570456896 run_lib.py:133] step: 252000, training_loss: 2.34243e-02
I0209 13:35:46.396153 22542570456896 run_lib.py:146] step: 252000, eval_loss: 2.65942e-02
I0209 13:36:03.761022 22542570456896 run_lib.py:133] step: 252050, training_loss: 3.21734e-02
I0209 13:36:21.161576 22542570456896 run_lib.py:133] step: 252100, training_loss: 3.22658e-02
I0209 13:36:21.328473 22542570456896 run_lib.py:146] step: 252100, eval_loss: 2.56150e-02
I0209 13:36:38.953978 22542570456896 run_lib.py:133] step: 252150, training_loss: 2.97930e-02
I0209 13:36:56.389153 22542570456896 run_lib.py:133] step: 252200, training_loss: 3.26107e-02
I0209 13:36:56.549617 22542570456896 run_lib.py:146] step: 252200, eval_loss: 2.62434e-02
I0209 13:37:14.170325 22542570456896 run_lib.py:133] step: 252250, training_loss: 3.04342e-02
I0209 13:37:31.590055 22542570456896 run_lib.py:133] step: 252300, training_loss: 2.27365e-02
I0209 13:37:31.746644 22542570456896 run_lib.py:146] step: 252300, eval_loss: 3.18499e-02
I0209 13:37:49.350204 22542570456896 run_lib.py:133] step: 252350, training_loss: 3.05429e-02
I0209 13:38:06.830792 22542570456896 run_lib.py:133] step: 252400, training_loss: 2.74803e-02
I0209 13:38:06.988113 22542570456896 run_lib.py:146] step: 252400, eval_loss: 3.35677e-02
I0209 13:38:24.466482 22542570456896 run_lib.py:133] step: 252450, training_loss: 2.50388e-02
I0209 13:38:42.114588 22542570456896 run_lib.py:133] step: 252500, training_loss: 2.62744e-02
I0209 13:38:42.273458 22542570456896 run_lib.py:146] step: 252500, eval_loss: 3.45975e-02
I0209 13:38:59.710719 22542570456896 run_lib.py:133] step: 252550, training_loss: 2.90992e-02
I0209 13:39:17.257836 22542570456896 run_lib.py:133] step: 252600, training_loss: 3.28851e-02
I0209 13:39:17.415620 22542570456896 run_lib.py:146] step: 252600, eval_loss: 2.63711e-02
I0209 13:39:34.823805 22542570456896 run_lib.py:133] step: 252650, training_loss: 2.59747e-02
I0209 13:39:52.310277 22542570456896 run_lib.py:133] step: 252700, training_loss: 2.67708e-02
I0209 13:39:52.474607 22542570456896 run_lib.py:146] step: 252700, eval_loss: 3.05413e-02
I0209 13:40:10.079985 22542570456896 run_lib.py:133] step: 252750, training_loss: 2.35049e-02
I0209 13:40:27.488711 22542570456896 run_lib.py:133] step: 252800, training_loss: 2.60504e-02
I0209 13:40:27.643425 22542570456896 run_lib.py:146] step: 252800, eval_loss: 3.30375e-02
I0209 13:40:45.076477 22542570456896 run_lib.py:133] step: 252850, training_loss: 2.57263e-02
I0209 13:41:02.532597 22542570456896 run_lib.py:133] step: 252900, training_loss: 2.50892e-02
I0209 13:41:02.685366 22542570456896 run_lib.py:146] step: 252900, eval_loss: 3.57541e-02
I0209 13:41:20.332206 22542570456896 run_lib.py:133] step: 252950, training_loss: 2.83672e-02
I0209 13:41:37.790113 22542570456896 run_lib.py:133] step: 253000, training_loss: 3.44725e-02
I0209 13:41:37.957578 22542570456896 run_lib.py:146] step: 253000, eval_loss: 2.71019e-02
I0209 13:41:55.531257 22542570456896 run_lib.py:133] step: 253050, training_loss: 2.86020e-02
I0209 13:42:12.989883 22542570456896 run_lib.py:133] step: 253100, training_loss: 3.17378e-02
I0209 13:42:13.147597 22542570456896 run_lib.py:146] step: 253100, eval_loss: 2.29973e-02
I0209 13:42:30.558106 22542570456896 run_lib.py:133] step: 253150, training_loss: 2.87985e-02
I0209 13:42:47.996597 22542570456896 run_lib.py:133] step: 253200, training_loss: 2.85767e-02
I0209 13:42:48.160385 22542570456896 run_lib.py:146] step: 253200, eval_loss: 2.74680e-02
I0209 13:43:05.732439 22542570456896 run_lib.py:133] step: 253250, training_loss: 3.11487e-02
I0209 13:43:23.321131 22542570456896 run_lib.py:133] step: 253300, training_loss: 2.68703e-02
I0209 13:43:23.479685 22542570456896 run_lib.py:146] step: 253300, eval_loss: 2.66594e-02
I0209 13:43:40.920292 22542570456896 run_lib.py:133] step: 253350, training_loss: 2.79887e-02
I0209 13:43:58.387941 22542570456896 run_lib.py:133] step: 253400, training_loss: 3.21612e-02
I0209 13:43:58.547883 22542570456896 run_lib.py:146] step: 253400, eval_loss: 3.65796e-02
I0209 13:44:16.137278 22542570456896 run_lib.py:133] step: 253450, training_loss: 3.05228e-02
I0209 13:44:33.585375 22542570456896 run_lib.py:133] step: 253500, training_loss: 3.08617e-02
I0209 13:44:33.762362 22542570456896 run_lib.py:146] step: 253500, eval_loss: 2.53153e-02
I0209 13:44:51.410377 22542570456896 run_lib.py:133] step: 253550, training_loss: 2.64183e-02
I0209 13:45:08.855228 22542570456896 run_lib.py:133] step: 253600, training_loss: 2.50421e-02
I0209 13:45:09.013237 22542570456896 run_lib.py:146] step: 253600, eval_loss: 2.69240e-02
I0209 13:45:26.598176 22542570456896 run_lib.py:133] step: 253650, training_loss: 3.11714e-02
I0209 13:45:44.041541 22542570456896 run_lib.py:133] step: 253700, training_loss: 2.45605e-02
I0209 13:45:44.197181 22542570456896 run_lib.py:146] step: 253700, eval_loss: 3.94944e-02
I0209 13:46:01.797323 22542570456896 run_lib.py:133] step: 253750, training_loss: 2.61906e-02
I0209 13:46:19.248234 22542570456896 run_lib.py:133] step: 253800, training_loss: 3.55121e-02
I0209 13:46:19.404294 22542570456896 run_lib.py:146] step: 253800, eval_loss: 2.88244e-02
I0209 13:46:36.901543 22542570456896 run_lib.py:133] step: 253850, training_loss: 3.26063e-02
I0209 13:46:54.519898 22542570456896 run_lib.py:133] step: 253900, training_loss: 3.68011e-02
I0209 13:46:54.669620 22542570456896 run_lib.py:146] step: 253900, eval_loss: 3.65548e-02
I0209 13:47:12.087524 22542570456896 run_lib.py:133] step: 253950, training_loss: 3.09520e-02
I0209 13:47:29.535720 22542570456896 run_lib.py:133] step: 254000, training_loss: 2.42521e-02
I0209 13:47:29.693592 22542570456896 run_lib.py:146] step: 254000, eval_loss: 2.49681e-02
I0209 13:47:47.260999 22542570456896 run_lib.py:133] step: 254050, training_loss: 2.64503e-02
I0209 13:48:04.918900 22542570456896 run_lib.py:133] step: 254100, training_loss: 2.60587e-02
I0209 13:48:05.076640 22542570456896 run_lib.py:146] step: 254100, eval_loss: 2.95932e-02
I0209 13:48:22.530866 22542570456896 run_lib.py:133] step: 254150, training_loss: 2.44995e-02
I0209 13:48:39.955539 22542570456896 run_lib.py:133] step: 254200, training_loss: 3.45862e-02
I0209 13:48:40.112534 22542570456896 run_lib.py:146] step: 254200, eval_loss: 3.01750e-02
I0209 13:48:57.539817 22542570456896 run_lib.py:133] step: 254250, training_loss: 2.84029e-02
I0209 13:49:15.176739 22542570456896 run_lib.py:133] step: 254300, training_loss: 2.77844e-02
I0209 13:49:15.328437 22542570456896 run_lib.py:146] step: 254300, eval_loss: 3.18789e-02
I0209 13:49:32.757827 22542570456896 run_lib.py:133] step: 254350, training_loss: 2.96229e-02
I0209 13:49:50.194154 22542570456896 run_lib.py:133] step: 254400, training_loss: 3.07110e-02
I0209 13:49:50.363547 22542570456896 run_lib.py:146] step: 254400, eval_loss: 2.82610e-02
I0209 13:50:07.836741 22542570456896 run_lib.py:133] step: 254450, training_loss: 3.05305e-02
I0209 13:50:25.462225 22542570456896 run_lib.py:133] step: 254500, training_loss: 2.93968e-02
I0209 13:50:25.621722 22542570456896 run_lib.py:146] step: 254500, eval_loss: 3.18973e-02
I0209 13:50:43.033158 22542570456896 run_lib.py:133] step: 254550, training_loss: 2.71142e-02
I0209 13:51:00.505897 22542570456896 run_lib.py:133] step: 254600, training_loss: 3.35178e-02
I0209 13:51:00.661445 22542570456896 run_lib.py:146] step: 254600, eval_loss: 2.76765e-02
I0209 13:51:18.115468 22542570456896 run_lib.py:133] step: 254650, training_loss: 2.84391e-02
I0209 13:51:35.578677 22542570456896 run_lib.py:133] step: 254700, training_loss: 3.37294e-02
I0209 13:51:35.734574 22542570456896 run_lib.py:146] step: 254700, eval_loss: 3.04156e-02
I0209 13:51:53.344057 22542570456896 run_lib.py:133] step: 254750, training_loss: 2.24535e-02
I0209 13:52:10.820798 22542570456896 run_lib.py:133] step: 254800, training_loss: 2.87224e-02
I0209 13:52:10.973421 22542570456896 run_lib.py:146] step: 254800, eval_loss: 3.14238e-02
I0209 13:52:28.401257 22542570456896 run_lib.py:133] step: 254850, training_loss: 2.98259e-02
I0209 13:52:45.823046 22542570456896 run_lib.py:133] step: 254900, training_loss: 3.51865e-02
I0209 13:52:45.990683 22542570456896 run_lib.py:146] step: 254900, eval_loss: 2.45563e-02
I0209 13:53:03.651610 22542570456896 run_lib.py:133] step: 254950, training_loss: 2.96145e-02
I0209 13:53:21.118828 22542570456896 run_lib.py:133] step: 255000, training_loss: 3.30190e-02
I0209 13:53:21.277585 22542570456896 run_lib.py:146] step: 255000, eval_loss: 2.79205e-02
I0209 13:53:38.891845 22542570456896 run_lib.py:133] step: 255050, training_loss: 3.12971e-02
I0209 13:53:56.300850 22542570456896 run_lib.py:133] step: 255100, training_loss: 2.32029e-02
I0209 13:53:56.456349 22542570456896 run_lib.py:146] step: 255100, eval_loss: 3.10244e-02
I0209 13:54:14.073395 22542570456896 run_lib.py:133] step: 255150, training_loss: 3.25189e-02
I0209 13:54:31.498344 22542570456896 run_lib.py:133] step: 255200, training_loss: 2.28282e-02
I0209 13:54:31.661599 22542570456896 run_lib.py:146] step: 255200, eval_loss: 3.42032e-02
I0209 13:54:49.241499 22542570456896 run_lib.py:133] step: 255250, training_loss: 2.97275e-02
I0209 13:55:06.815001 22542570456896 run_lib.py:133] step: 255300, training_loss: 2.36928e-02
I0209 13:55:06.967389 22542570456896 run_lib.py:146] step: 255300, eval_loss: 2.79140e-02
I0209 13:55:24.384674 22542570456896 run_lib.py:133] step: 255350, training_loss: 2.71848e-02
I0209 13:55:41.959715 22542570456896 run_lib.py:133] step: 255400, training_loss: 2.62706e-02
I0209 13:55:42.117548 22542570456896 run_lib.py:146] step: 255400, eval_loss: 3.45990e-02
I0209 13:55:59.533746 22542570456896 run_lib.py:133] step: 255450, training_loss: 2.66148e-02
I0209 13:56:16.952702 22542570456896 run_lib.py:133] step: 255500, training_loss: 3.38233e-02
I0209 13:56:17.121348 22542570456896 run_lib.py:146] step: 255500, eval_loss: 2.66246e-02
I0209 13:56:34.763823 22542570456896 run_lib.py:133] step: 255550, training_loss: 2.42849e-02
I0209 13:56:52.211556 22542570456896 run_lib.py:133] step: 255600, training_loss: 2.56908e-02
I0209 13:56:52.375695 22542570456896 run_lib.py:146] step: 255600, eval_loss: 3.18900e-02
I0209 13:57:09.804494 22542570456896 run_lib.py:133] step: 255650, training_loss: 2.61131e-02
I0209 13:57:27.397141 22542570456896 run_lib.py:133] step: 255700, training_loss: 2.63486e-02
I0209 13:57:27.557443 22542570456896 run_lib.py:146] step: 255700, eval_loss: 2.73703e-02
I0209 13:57:44.983679 22542570456896 run_lib.py:133] step: 255750, training_loss: 2.65117e-02
I0209 13:58:02.437340 22542570456896 run_lib.py:133] step: 255800, training_loss: 2.80086e-02
I0209 13:58:02.602243 22542570456896 run_lib.py:146] step: 255800, eval_loss: 2.81913e-02
I0209 13:58:20.164228 22542570456896 run_lib.py:133] step: 255850, training_loss: 3.11833e-02
I0209 13:58:37.610615 22542570456896 run_lib.py:133] step: 255900, training_loss: 2.54322e-02
I0209 13:58:37.768693 22542570456896 run_lib.py:146] step: 255900, eval_loss: 3.19505e-02
I0209 13:58:55.204200 22542570456896 run_lib.py:133] step: 255950, training_loss: 2.15200e-02
I0209 13:59:12.620546 22542570456896 run_lib.py:133] step: 256000, training_loss: 2.70291e-02
I0209 13:59:12.781507 22542570456896 run_lib.py:146] step: 256000, eval_loss: 3.06737e-02
I0209 13:59:30.364361 22542570456896 run_lib.py:133] step: 256050, training_loss: 2.65097e-02
I0209 13:59:47.903176 22542570456896 run_lib.py:133] step: 256100, training_loss: 2.29786e-02
I0209 13:59:48.058850 22542570456896 run_lib.py:146] step: 256100, eval_loss: 3.50734e-02
I0209 14:00:05.518808 22542570456896 run_lib.py:133] step: 256150, training_loss: 3.09516e-02
I0209 14:00:22.916673 22542570456896 run_lib.py:133] step: 256200, training_loss: 3.06032e-02
I0209 14:00:23.069164 22542570456896 run_lib.py:146] step: 256200, eval_loss: 3.07953e-02
I0209 14:00:40.665608 22542570456896 run_lib.py:133] step: 256250, training_loss: 2.69351e-02
I0209 14:00:58.119998 22542570456896 run_lib.py:133] step: 256300, training_loss: 3.49895e-02
I0209 14:00:58.287601 22542570456896 run_lib.py:146] step: 256300, eval_loss: 2.34827e-02
I0209 14:01:15.915058 22542570456896 run_lib.py:133] step: 256350, training_loss: 2.75261e-02
I0209 14:01:33.384455 22542570456896 run_lib.py:133] step: 256400, training_loss: 3.14211e-02
I0209 14:01:33.552297 22542570456896 run_lib.py:146] step: 256400, eval_loss: 2.85507e-02
I0209 14:01:51.173262 22542570456896 run_lib.py:133] step: 256450, training_loss: 2.45365e-02
I0209 14:02:08.591400 22542570456896 run_lib.py:133] step: 256500, training_loss: 2.69941e-02
I0209 14:02:08.754803 22542570456896 run_lib.py:146] step: 256500, eval_loss: 3.04013e-02
I0209 14:02:26.365026 22542570456896 run_lib.py:133] step: 256550, training_loss: 2.32916e-02
I0209 14:02:43.859702 22542570456896 run_lib.py:133] step: 256600, training_loss: 3.09708e-02
I0209 14:02:44.014534 22542570456896 run_lib.py:146] step: 256600, eval_loss: 3.12148e-02
I0209 14:03:01.486302 22542570456896 run_lib.py:133] step: 256650, training_loss: 3.64101e-02
I0209 14:03:19.079399 22542570456896 run_lib.py:133] step: 256700, training_loss: 2.82829e-02
I0209 14:03:19.237407 22542570456896 run_lib.py:146] step: 256700, eval_loss: 2.49684e-02
I0209 14:03:36.689366 22542570456896 run_lib.py:133] step: 256750, training_loss: 2.25860e-02
I0209 14:03:54.115061 22542570456896 run_lib.py:133] step: 256800, training_loss: 3.02571e-02
I0209 14:03:54.275420 22542570456896 run_lib.py:146] step: 256800, eval_loss: 2.68466e-02
I0209 14:04:11.859388 22542570456896 run_lib.py:133] step: 256850, training_loss: 2.52942e-02
I0209 14:04:29.326533 22542570456896 run_lib.py:133] step: 256900, training_loss: 2.56444e-02
I0209 14:04:29.486427 22542570456896 run_lib.py:146] step: 256900, eval_loss: 3.04548e-02
I0209 14:04:47.081819 22542570456896 run_lib.py:133] step: 256950, training_loss: 3.02609e-02
I0209 14:05:04.491761 22542570456896 run_lib.py:133] step: 257000, training_loss: 2.56108e-02
I0209 14:05:04.647105 22542570456896 run_lib.py:146] step: 257000, eval_loss: 2.54131e-02
I0209 14:05:22.101047 22542570456896 run_lib.py:133] step: 257050, training_loss: 2.62127e-02
I0209 14:05:39.664982 22542570456896 run_lib.py:133] step: 257100, training_loss: 2.70354e-02
I0209 14:05:39.820475 22542570456896 run_lib.py:146] step: 257100, eval_loss: 3.35548e-02
I0209 14:05:57.272010 22542570456896 run_lib.py:133] step: 257150, training_loss: 2.47452e-02
I0209 14:06:14.733757 22542570456896 run_lib.py:133] step: 257200, training_loss: 2.65244e-02
I0209 14:06:14.885687 22542570456896 run_lib.py:146] step: 257200, eval_loss: 3.20334e-02
I0209 14:06:32.311032 22542570456896 run_lib.py:133] step: 257250, training_loss: 2.59328e-02
I0209 14:06:49.934498 22542570456896 run_lib.py:133] step: 257300, training_loss: 2.52314e-02
I0209 14:06:50.098701 22542570456896 run_lib.py:146] step: 257300, eval_loss: 2.58247e-02
I0209 14:07:07.552308 22542570456896 run_lib.py:133] step: 257350, training_loss: 2.72861e-02
I0209 14:07:25.033494 22542570456896 run_lib.py:133] step: 257400, training_loss: 3.73880e-02
I0209 14:07:25.206338 22542570456896 run_lib.py:146] step: 257400, eval_loss: 2.84729e-02
I0209 14:07:42.673222 22542570456896 run_lib.py:133] step: 257450, training_loss: 2.21978e-02
I0209 14:08:00.113475 22542570456896 run_lib.py:133] step: 257500, training_loss: 2.79687e-02
I0209 14:08:00.272599 22542570456896 run_lib.py:146] step: 257500, eval_loss: 2.34244e-02
I0209 14:08:17.907472 22542570456896 run_lib.py:133] step: 257550, training_loss: 3.30822e-02
I0209 14:08:35.405572 22542570456896 run_lib.py:133] step: 257600, training_loss: 2.87700e-02
I0209 14:08:35.558137 22542570456896 run_lib.py:146] step: 257600, eval_loss: 3.06856e-02
I0209 14:08:52.993307 22542570456896 run_lib.py:133] step: 257650, training_loss: 2.77086e-02
I0209 14:09:10.413164 22542570456896 run_lib.py:133] step: 257700, training_loss: 3.06535e-02
I0209 14:09:10.572440 22542570456896 run_lib.py:146] step: 257700, eval_loss: 2.97814e-02
I0209 14:09:28.236838 22542570456896 run_lib.py:133] step: 257750, training_loss: 3.03179e-02
I0209 14:09:45.679627 22542570456896 run_lib.py:133] step: 257800, training_loss: 3.09601e-02
I0209 14:09:45.836840 22542570456896 run_lib.py:146] step: 257800, eval_loss: 3.02998e-02
I0209 14:10:03.435494 22542570456896 run_lib.py:133] step: 257850, training_loss: 2.58231e-02
I0209 14:10:20.852425 22542570456896 run_lib.py:133] step: 257900, training_loss: 2.56155e-02
I0209 14:10:21.007344 22542570456896 run_lib.py:146] step: 257900, eval_loss: 2.76412e-02
I0209 14:10:38.611578 22542570456896 run_lib.py:133] step: 257950, training_loss: 2.40194e-02
I0209 14:10:56.114043 22542570456896 run_lib.py:133] step: 258000, training_loss: 2.95760e-02
I0209 14:10:56.274258 22542570456896 run_lib.py:146] step: 258000, eval_loss: 2.91193e-02
I0209 14:11:13.723025 22542570456896 run_lib.py:133] step: 258050, training_loss: 2.78848e-02
I0209 14:11:31.342462 22542570456896 run_lib.py:133] step: 258100, training_loss: 2.75960e-02
I0209 14:11:31.496454 22542570456896 run_lib.py:146] step: 258100, eval_loss: 3.00940e-02
I0209 14:11:48.959820 22542570456896 run_lib.py:133] step: 258150, training_loss: 3.51947e-02
I0209 14:12:06.525178 22542570456896 run_lib.py:133] step: 258200, training_loss: 3.15013e-02
I0209 14:12:06.681390 22542570456896 run_lib.py:146] step: 258200, eval_loss: 2.33143e-02
I0209 14:12:24.127822 22542570456896 run_lib.py:133] step: 258250, training_loss: 3.10453e-02
I0209 14:12:41.605310 22542570456896 run_lib.py:133] step: 258300, training_loss: 3.02177e-02
I0209 14:12:41.765465 22542570456896 run_lib.py:146] step: 258300, eval_loss: 3.33040e-02
I0209 14:12:59.437002 22542570456896 run_lib.py:133] step: 258350, training_loss: 3.29407e-02
I0209 14:13:16.888662 22542570456896 run_lib.py:133] step: 258400, training_loss: 2.71527e-02
I0209 14:13:17.044544 22542570456896 run_lib.py:146] step: 258400, eval_loss: 3.40418e-02
I0209 14:13:34.521399 22542570456896 run_lib.py:133] step: 258450, training_loss: 3.16020e-02
I0209 14:13:52.052800 22542570456896 run_lib.py:133] step: 258500, training_loss: 3.03598e-02
I0209 14:13:52.212321 22542570456896 run_lib.py:146] step: 258500, eval_loss: 2.45001e-02
I0209 14:14:09.680773 22542570456896 run_lib.py:133] step: 258550, training_loss: 2.72913e-02
I0209 14:14:27.170365 22542570456896 run_lib.py:133] step: 258600, training_loss: 2.55221e-02
I0209 14:14:27.519290 22542570456896 run_lib.py:146] step: 258600, eval_loss: 2.90369e-02
I0209 14:14:44.967441 22542570456896 run_lib.py:133] step: 258650, training_loss: 3.54694e-02
I0209 14:15:02.417853 22542570456896 run_lib.py:133] step: 258700, training_loss: 3.26891e-02
I0209 14:15:02.573186 22542570456896 run_lib.py:146] step: 258700, eval_loss: 3.07477e-02
I0209 14:15:20.015938 22542570456896 run_lib.py:133] step: 258750, training_loss: 2.95394e-02
I0209 14:15:37.439419 22542570456896 run_lib.py:133] step: 258800, training_loss: 2.95096e-02
I0209 14:15:37.618241 22542570456896 run_lib.py:146] step: 258800, eval_loss: 2.58956e-02
I0209 14:15:55.157702 22542570456896 run_lib.py:133] step: 258850, training_loss: 2.67375e-02
I0209 14:16:12.645662 22542570456896 run_lib.py:133] step: 258900, training_loss: 2.96406e-02
I0209 14:16:12.805460 22542570456896 run_lib.py:146] step: 258900, eval_loss: 3.43235e-02
I0209 14:16:30.169537 22542570456896 run_lib.py:133] step: 258950, training_loss: 3.19029e-02
I0209 14:16:47.613590 22542570456896 run_lib.py:133] step: 259000, training_loss: 2.84482e-02
I0209 14:16:47.768413 22542570456896 run_lib.py:146] step: 259000, eval_loss: 3.01562e-02
I0209 14:17:05.333620 22542570456896 run_lib.py:133] step: 259050, training_loss: 3.18236e-02
I0209 14:17:22.831258 22542570456896 run_lib.py:133] step: 259100, training_loss: 2.14956e-02
I0209 14:17:22.987591 22542570456896 run_lib.py:146] step: 259100, eval_loss: 2.91603e-02
I0209 14:17:40.539729 22542570456896 run_lib.py:133] step: 259150, training_loss: 3.05551e-02
I0209 14:17:57.952379 22542570456896 run_lib.py:133] step: 259200, training_loss: 3.08609e-02
I0209 14:17:58.119369 22542570456896 run_lib.py:146] step: 259200, eval_loss: 2.68531e-02
I0209 14:18:15.721904 22542570456896 run_lib.py:133] step: 259250, training_loss: 2.66278e-02
I0209 14:18:33.163298 22542570456896 run_lib.py:133] step: 259300, training_loss: 2.00474e-02
I0209 14:18:33.319400 22542570456896 run_lib.py:146] step: 259300, eval_loss: 2.91171e-02
I0209 14:18:50.915930 22542570456896 run_lib.py:133] step: 259350, training_loss: 2.50419e-02
I0209 14:19:08.341637 22542570456896 run_lib.py:133] step: 259400, training_loss: 2.92113e-02
I0209 14:19:08.497101 22542570456896 run_lib.py:146] step: 259400, eval_loss: 2.77824e-02
I0209 14:19:26.142437 22542570456896 run_lib.py:133] step: 259450, training_loss: 2.87679e-02
I0209 14:19:43.603342 22542570456896 run_lib.py:133] step: 259500, training_loss: 3.04796e-02
I0209 14:19:43.756526 22542570456896 run_lib.py:146] step: 259500, eval_loss: 2.86060e-02
I0209 14:20:01.206922 22542570456896 run_lib.py:133] step: 259550, training_loss: 2.74977e-02
I0209 14:20:18.783575 22542570456896 run_lib.py:133] step: 259600, training_loss: 1.89625e-02
I0209 14:20:18.938897 22542570456896 run_lib.py:146] step: 259600, eval_loss: 2.69003e-02
I0209 14:20:36.384291 22542570456896 run_lib.py:133] step: 259650, training_loss: 2.95992e-02
I0209 14:20:54.004916 22542570456896 run_lib.py:133] step: 259700, training_loss: 2.73493e-02
I0209 14:20:54.181948 22542570456896 run_lib.py:146] step: 259700, eval_loss: 2.87906e-02
I0209 14:21:11.688732 22542570456896 run_lib.py:133] step: 259750, training_loss: 2.37554e-02
I0209 14:21:29.116577 22542570456896 run_lib.py:133] step: 259800, training_loss: 2.49460e-02
I0209 14:21:29.277543 22542570456896 run_lib.py:146] step: 259800, eval_loss: 3.50179e-02
I0209 14:21:46.879056 22542570456896 run_lib.py:133] step: 259850, training_loss: 3.20727e-02
I0209 14:22:04.314988 22542570456896 run_lib.py:133] step: 259900, training_loss: 2.76357e-02
I0209 14:22:04.476435 22542570456896 run_lib.py:146] step: 259900, eval_loss: 2.75239e-02
I0209 14:22:21.915193 22542570456896 run_lib.py:133] step: 259950, training_loss: 2.97261e-02
I0209 14:22:39.374671 22542570456896 run_lib.py:133] step: 260000, training_loss: 2.70440e-02
I0209 14:22:40.142701 22542570456896 run_lib.py:146] step: 260000, eval_loss: 3.34161e-02
I0209 14:23:00.446171 22542570456896 run_lib.py:133] step: 260050, training_loss: 2.67863e-02
I0209 14:23:18.006243 22542570456896 run_lib.py:133] step: 260100, training_loss: 2.64256e-02
I0209 14:23:18.161354 22542570456896 run_lib.py:146] step: 260100, eval_loss: 2.95946e-02
I0209 14:23:35.603198 22542570456896 run_lib.py:133] step: 260150, training_loss: 2.63859e-02
I0209 14:23:53.036768 22542570456896 run_lib.py:133] step: 260200, training_loss: 2.91448e-02
I0209 14:23:53.207443 22542570456896 run_lib.py:146] step: 260200, eval_loss: 2.11973e-02
I0209 14:24:10.884524 22542570456896 run_lib.py:133] step: 260250, training_loss: 2.41474e-02
I0209 14:24:28.330274 22542570456896 run_lib.py:133] step: 260300, training_loss: 3.09152e-02
I0209 14:24:28.488468 22542570456896 run_lib.py:146] step: 260300, eval_loss: 3.55366e-02
I0209 14:24:45.920245 22542570456896 run_lib.py:133] step: 260350, training_loss: 2.57965e-02
I0209 14:25:03.347884 22542570456896 run_lib.py:133] step: 260400, training_loss: 2.54997e-02
I0209 14:25:03.509667 22542570456896 run_lib.py:146] step: 260400, eval_loss: 3.07766e-02
I0209 14:25:21.134285 22542570456896 run_lib.py:133] step: 260450, training_loss: 2.83837e-02
I0209 14:25:38.568378 22542570456896 run_lib.py:133] step: 260500, training_loss: 3.80100e-02
I0209 14:25:38.723625 22542570456896 run_lib.py:146] step: 260500, eval_loss: 2.81883e-02
I0209 14:25:56.298533 22542570456896 run_lib.py:133] step: 260550, training_loss: 2.86407e-02
I0209 14:26:13.782715 22542570456896 run_lib.py:133] step: 260600, training_loss: 2.75156e-02
I0209 14:26:13.935440 22542570456896 run_lib.py:146] step: 260600, eval_loss: 2.85168e-02
I0209 14:26:31.356249 22542570456896 run_lib.py:133] step: 260650, training_loss: 2.87667e-02
I0209 14:26:48.811110 22542570456896 run_lib.py:133] step: 260700, training_loss: 3.22124e-02
I0209 14:26:48.976511 22542570456896 run_lib.py:146] step: 260700, eval_loss: 2.79893e-02
I0209 14:27:06.574148 22542570456896 run_lib.py:133] step: 260750, training_loss: 2.57594e-02
I0209 14:27:24.075134 22542570456896 run_lib.py:133] step: 260800, training_loss: 3.01379e-02
I0209 14:27:24.247489 22542570456896 run_lib.py:146] step: 260800, eval_loss: 2.61017e-02
I0209 14:27:41.719764 22542570456896 run_lib.py:133] step: 260850, training_loss: 2.65499e-02
I0209 14:27:59.202119 22542570456896 run_lib.py:133] step: 260900, training_loss: 2.82609e-02
I0209 14:27:59.357139 22542570456896 run_lib.py:146] step: 260900, eval_loss: 2.75773e-02
I0209 14:28:16.956785 22542570456896 run_lib.py:133] step: 260950, training_loss: 2.92411e-02
I0209 14:28:34.391240 22542570456896 run_lib.py:133] step: 261000, training_loss: 2.47231e-02
I0209 14:28:34.544183 22542570456896 run_lib.py:146] step: 261000, eval_loss: 2.67810e-02
I0209 14:28:52.136702 22542570456896 run_lib.py:133] step: 261050, training_loss: 2.78861e-02
I0209 14:29:09.556578 22542570456896 run_lib.py:133] step: 261100, training_loss: 3.20362e-02
I0209 14:29:09.718560 22542570456896 run_lib.py:146] step: 261100, eval_loss: 2.51351e-02
I0209 14:29:27.337728 22542570456896 run_lib.py:133] step: 261150, training_loss: 2.33424e-02
I0209 14:29:44.823188 22542570456896 run_lib.py:133] step: 261200, training_loss: 3.40446e-02
I0209 14:29:44.989390 22542570456896 run_lib.py:146] step: 261200, eval_loss: 2.79241e-02
I0209 14:30:02.592822 22542570456896 run_lib.py:133] step: 261250, training_loss: 3.04513e-02
I0209 14:30:20.057965 22542570456896 run_lib.py:133] step: 261300, training_loss: 3.00337e-02
I0209 14:30:20.213374 22542570456896 run_lib.py:146] step: 261300, eval_loss: 2.70992e-02
I0209 14:30:37.665845 22542570456896 run_lib.py:133] step: 261350, training_loss: 3.51844e-02
I0209 14:30:55.246348 22542570456896 run_lib.py:133] step: 261400, training_loss: 2.62006e-02
I0209 14:30:55.408412 22542570456896 run_lib.py:146] step: 261400, eval_loss: 2.63867e-02
I0209 14:31:12.912656 22542570456896 run_lib.py:133] step: 261450, training_loss: 3.41032e-02
I0209 14:31:30.404219 22542570456896 run_lib.py:133] step: 261500, training_loss: 2.40885e-02
I0209 14:31:30.556533 22542570456896 run_lib.py:146] step: 261500, eval_loss: 2.66697e-02
I0209 14:31:48.168487 22542570456896 run_lib.py:133] step: 261550, training_loss: 2.51708e-02
I0209 14:32:05.609584 22542570456896 run_lib.py:133] step: 261600, training_loss: 2.16625e-02
I0209 14:32:05.764545 22542570456896 run_lib.py:146] step: 261600, eval_loss: 2.93750e-02
I0209 14:32:23.304510 22542570456896 run_lib.py:133] step: 261650, training_loss: 2.77237e-02
I0209 14:32:40.738321 22542570456896 run_lib.py:133] step: 261700, training_loss: 2.80673e-02
I0209 14:32:40.914481 22542570456896 run_lib.py:146] step: 261700, eval_loss: 3.06526e-02
I0209 14:32:58.399378 22542570456896 run_lib.py:133] step: 261750, training_loss: 2.30645e-02
I0209 14:33:16.020040 22542570456896 run_lib.py:133] step: 261800, training_loss: 2.49070e-02
I0209 14:33:16.176620 22542570456896 run_lib.py:146] step: 261800, eval_loss: 2.34770e-02
I0209 14:33:33.610122 22542570456896 run_lib.py:133] step: 261850, training_loss: 3.02292e-02
I0209 14:33:51.081259 22542570456896 run_lib.py:133] step: 261900, training_loss: 2.61430e-02
I0209 14:33:51.242235 22542570456896 run_lib.py:146] step: 261900, eval_loss: 3.55565e-02
I0209 14:34:08.696408 22542570456896 run_lib.py:133] step: 261950, training_loss: 2.62224e-02
I0209 14:34:26.281769 22542570456896 run_lib.py:133] step: 262000, training_loss: 2.68972e-02
I0209 14:34:26.437751 22542570456896 run_lib.py:146] step: 262000, eval_loss: 2.65275e-02
I0209 14:34:43.919848 22542570456896 run_lib.py:133] step: 262050, training_loss: 2.62951e-02
I0209 14:35:01.477749 22542570456896 run_lib.py:133] step: 262100, training_loss: 2.33602e-02
I0209 14:35:01.635039 22542570456896 run_lib.py:146] step: 262100, eval_loss: 2.56097e-02
I0209 14:35:19.055802 22542570456896 run_lib.py:133] step: 262150, training_loss: 2.86807e-02
I0209 14:35:36.510646 22542570456896 run_lib.py:133] step: 262200, training_loss: 3.11290e-02
I0209 14:35:36.665564 22542570456896 run_lib.py:146] step: 262200, eval_loss: 3.54560e-02
I0209 14:35:54.229208 22542570456896 run_lib.py:133] step: 262250, training_loss: 3.40405e-02
I0209 14:36:11.764967 22542570456896 run_lib.py:133] step: 262300, training_loss: 2.59594e-02
I0209 14:36:11.918946 22542570456896 run_lib.py:146] step: 262300, eval_loss: 2.31552e-02
I0209 14:36:29.358717 22542570456896 run_lib.py:133] step: 262350, training_loss: 3.01616e-02
I0209 14:36:46.838232 22542570456896 run_lib.py:133] step: 262400, training_loss: 2.11906e-02
I0209 14:36:46.993340 22542570456896 run_lib.py:146] step: 262400, eval_loss: 3.27493e-02
I0209 14:37:04.628797 22542570456896 run_lib.py:133] step: 262450, training_loss: 2.10005e-02
I0209 14:37:22.080774 22542570456896 run_lib.py:133] step: 262500, training_loss: 3.34059e-02
I0209 14:37:22.241322 22542570456896 run_lib.py:146] step: 262500, eval_loss: 2.43472e-02
I0209 14:37:39.878329 22542570456896 run_lib.py:133] step: 262550, training_loss: 2.91854e-02
I0209 14:37:57.299477 22542570456896 run_lib.py:133] step: 262600, training_loss: 2.92164e-02
I0209 14:37:57.477451 22542570456896 run_lib.py:146] step: 262600, eval_loss: 2.51310e-02
I0209 14:38:15.218226 22542570456896 run_lib.py:133] step: 262650, training_loss: 3.30511e-02
I0209 14:38:32.675373 22542570456896 run_lib.py:133] step: 262700, training_loss: 2.90942e-02
I0209 14:38:32.837169 22542570456896 run_lib.py:146] step: 262700, eval_loss: 2.82586e-02
I0209 14:38:50.280408 22542570456896 run_lib.py:133] step: 262750, training_loss: 3.10297e-02
I0209 14:39:07.841337 22542570456896 run_lib.py:133] step: 262800, training_loss: 2.85295e-02
I0209 14:39:07.996678 22542570456896 run_lib.py:146] step: 262800, eval_loss: 3.00586e-02
I0209 14:39:25.455677 22542570456896 run_lib.py:133] step: 262850, training_loss: 2.94315e-02
I0209 14:39:43.062194 22542570456896 run_lib.py:133] step: 262900, training_loss: 3.83665e-02
I0209 14:39:43.223883 22542570456896 run_lib.py:146] step: 262900, eval_loss: 2.76380e-02
I0209 14:40:00.681001 22542570456896 run_lib.py:133] step: 262950, training_loss: 3.23266e-02
I0209 14:40:18.098212 22542570456896 run_lib.py:133] step: 263000, training_loss: 2.35558e-02
I0209 14:40:18.253222 22542570456896 run_lib.py:146] step: 263000, eval_loss: 2.46090e-02
I0209 14:40:35.892823 22542570456896 run_lib.py:133] step: 263050, training_loss: 2.91125e-02
I0209 14:40:53.354822 22542570456896 run_lib.py:133] step: 263100, training_loss: 3.17532e-02
I0209 14:40:53.511710 22542570456896 run_lib.py:146] step: 263100, eval_loss: 2.70019e-02
I0209 14:41:10.927448 22542570456896 run_lib.py:133] step: 263150, training_loss: 2.26368e-02
I0209 14:41:28.574215 22542570456896 run_lib.py:133] step: 263200, training_loss: 3.03465e-02
I0209 14:41:28.731632 22542570456896 run_lib.py:146] step: 263200, eval_loss: 2.60481e-02
I0209 14:41:46.219212 22542570456896 run_lib.py:133] step: 263250, training_loss: 3.62321e-02
I0209 14:42:03.631852 22542570456896 run_lib.py:133] step: 263300, training_loss: 2.73569e-02
I0209 14:42:03.981251 22542570456896 run_lib.py:146] step: 263300, eval_loss: 2.67402e-02
I0209 14:42:21.408397 22542570456896 run_lib.py:133] step: 263350, training_loss: 2.80195e-02
I0209 14:42:38.898487 22542570456896 run_lib.py:133] step: 263400, training_loss: 3.30309e-02
I0209 14:42:39.053659 22542570456896 run_lib.py:146] step: 263400, eval_loss: 4.81174e-02
I0209 14:42:56.562695 22542570456896 run_lib.py:133] step: 263450, training_loss: 3.14273e-02
I0209 14:43:13.973435 22542570456896 run_lib.py:133] step: 263500, training_loss: 2.84816e-02
I0209 14:43:14.130429 22542570456896 run_lib.py:146] step: 263500, eval_loss: 2.75247e-02
I0209 14:43:31.757834 22542570456896 run_lib.py:133] step: 263550, training_loss: 2.97970e-02
I0209 14:43:49.291726 22542570456896 run_lib.py:133] step: 263600, training_loss: 2.62515e-02
I0209 14:43:49.449588 22542570456896 run_lib.py:146] step: 263600, eval_loss: 2.78400e-02
I0209 14:44:06.866171 22542570456896 run_lib.py:133] step: 263650, training_loss: 2.56062e-02
I0209 14:44:24.364778 22542570456896 run_lib.py:133] step: 263700, training_loss: 2.87482e-02
I0209 14:44:24.523576 22542570456896 run_lib.py:146] step: 263700, eval_loss: 2.57412e-02
I0209 14:44:42.132881 22542570456896 run_lib.py:133] step: 263750, training_loss: 2.61934e-02
I0209 14:44:59.690913 22542570456896 run_lib.py:133] step: 263800, training_loss: 2.82126e-02
I0209 14:44:59.847639 22542570456896 run_lib.py:146] step: 263800, eval_loss: 2.90630e-02
I0209 14:45:17.310655 22542570456896 run_lib.py:133] step: 263850, training_loss: 2.57206e-02
I0209 14:45:34.792965 22542570456896 run_lib.py:133] step: 263900, training_loss: 2.17837e-02
I0209 14:45:34.942929 22542570456896 run_lib.py:146] step: 263900, eval_loss: 3.58235e-02
I0209 14:45:52.509235 22542570456896 run_lib.py:133] step: 263950, training_loss: 3.14439e-02
I0209 14:46:09.928006 22542570456896 run_lib.py:133] step: 264000, training_loss: 2.34174e-02
I0209 14:46:10.103362 22542570456896 run_lib.py:146] step: 264000, eval_loss: 4.03020e-02
I0209 14:46:27.806450 22542570456896 run_lib.py:133] step: 264050, training_loss: 2.44116e-02
I0209 14:46:45.270539 22542570456896 run_lib.py:133] step: 264100, training_loss: 2.99337e-02
I0209 14:46:45.429352 22542570456896 run_lib.py:146] step: 264100, eval_loss: 2.73426e-02
I0209 14:47:03.012650 22542570456896 run_lib.py:133] step: 264150, training_loss: 2.80390e-02
I0209 14:47:20.420237 22542570456896 run_lib.py:133] step: 264200, training_loss: 2.85007e-02
I0209 14:47:20.576200 22542570456896 run_lib.py:146] step: 264200, eval_loss: 3.17078e-02
I0209 14:47:38.052022 22542570456896 run_lib.py:133] step: 264250, training_loss: 2.49560e-02
I0209 14:47:55.682586 22542570456896 run_lib.py:133] step: 264300, training_loss: 2.61507e-02
I0209 14:47:55.838175 22542570456896 run_lib.py:146] step: 264300, eval_loss: 2.42153e-02
I0209 14:48:13.297375 22542570456896 run_lib.py:133] step: 264350, training_loss: 2.79928e-02
I0209 14:48:30.915237 22542570456896 run_lib.py:133] step: 264400, training_loss: 2.38742e-02
I0209 14:48:31.072411 22542570456896 run_lib.py:146] step: 264400, eval_loss: 2.34028e-02
I0209 14:48:48.484442 22542570456896 run_lib.py:133] step: 264450, training_loss: 2.73761e-02
I0209 14:49:05.931742 22542570456896 run_lib.py:133] step: 264500, training_loss: 3.04609e-02
I0209 14:49:06.089629 22542570456896 run_lib.py:146] step: 264500, eval_loss: 2.92042e-02
I0209 14:49:23.711914 22542570456896 run_lib.py:133] step: 264550, training_loss: 1.98896e-02
I0209 14:49:41.203725 22542570456896 run_lib.py:133] step: 264600, training_loss: 2.85600e-02
I0209 14:49:41.360587 22542570456896 run_lib.py:146] step: 264600, eval_loss: 2.04529e-02
I0209 14:49:58.784708 22542570456896 run_lib.py:133] step: 264650, training_loss: 2.23583e-02
I0209 14:50:16.187196 22542570456896 run_lib.py:133] step: 264700, training_loss: 3.60095e-02
I0209 14:50:16.343592 22542570456896 run_lib.py:146] step: 264700, eval_loss: 3.12450e-02
I0209 14:50:33.974767 22542570456896 run_lib.py:133] step: 264750, training_loss: 2.38884e-02
I0209 14:50:51.465864 22542570456896 run_lib.py:133] step: 264800, training_loss: 2.74786e-02
I0209 14:50:51.619240 22542570456896 run_lib.py:146] step: 264800, eval_loss: 1.89103e-02
I0209 14:51:09.175431 22542570456896 run_lib.py:133] step: 264850, training_loss: 2.83924e-02
I0209 14:51:26.606059 22542570456896 run_lib.py:133] step: 264900, training_loss: 3.19894e-02
I0209 14:51:26.763725 22542570456896 run_lib.py:146] step: 264900, eval_loss: 3.71525e-02
I0209 14:51:44.222181 22542570456896 run_lib.py:133] step: 264950, training_loss: 2.27620e-02
I0209 14:52:01.700680 22542570456896 run_lib.py:133] step: 265000, training_loss: 3.13658e-02
I0209 14:52:01.859654 22542570456896 run_lib.py:146] step: 265000, eval_loss: 2.64100e-02
I0209 14:52:19.466207 22542570456896 run_lib.py:133] step: 265050, training_loss: 2.71372e-02
I0209 14:52:36.950848 22542570456896 run_lib.py:133] step: 265100, training_loss: 2.60825e-02
I0209 14:52:37.107101 22542570456896 run_lib.py:146] step: 265100, eval_loss: 2.68060e-02
I0209 14:52:54.571043 22542570456896 run_lib.py:133] step: 265150, training_loss: 2.77236e-02
I0209 14:53:12.053983 22542570456896 run_lib.py:133] step: 265200, training_loss: 2.54300e-02
I0209 14:53:12.213454 22542570456896 run_lib.py:146] step: 265200, eval_loss: 2.66957e-02
I0209 14:53:29.879297 22542570456896 run_lib.py:133] step: 265250, training_loss: 2.91590e-02
I0209 14:53:47.285594 22542570456896 run_lib.py:133] step: 265300, training_loss: 2.68427e-02
I0209 14:53:47.440333 22542570456896 run_lib.py:146] step: 265300, eval_loss: 2.67715e-02
I0209 14:54:04.992289 22542570456896 run_lib.py:133] step: 265350, training_loss: 2.77736e-02
I0209 14:54:22.408462 22542570456896 run_lib.py:133] step: 265400, training_loss: 3.26202e-02
I0209 14:54:22.579699 22542570456896 run_lib.py:146] step: 265400, eval_loss: 3.03372e-02
I0209 14:54:40.220231 22542570456896 run_lib.py:133] step: 265450, training_loss: 2.77462e-02
I0209 14:54:57.691800 22542570456896 run_lib.py:133] step: 265500, training_loss: 2.16380e-02
I0209 14:54:57.852364 22542570456896 run_lib.py:146] step: 265500, eval_loss: 2.67616e-02
I0209 14:55:15.388132 22542570456896 run_lib.py:133] step: 265550, training_loss: 3.05155e-02
I0209 14:55:32.796707 22542570456896 run_lib.py:133] step: 265600, training_loss: 2.69596e-02
I0209 14:55:32.954364 22542570456896 run_lib.py:146] step: 265600, eval_loss: 2.49437e-02
I0209 14:55:50.376887 22542570456896 run_lib.py:133] step: 265650, training_loss: 3.13371e-02
I0209 14:56:07.915611 22542570456896 run_lib.py:133] step: 265700, training_loss: 2.98600e-02
I0209 14:56:08.081277 22542570456896 run_lib.py:146] step: 265700, eval_loss: 2.78932e-02
I0209 14:56:25.560966 22542570456896 run_lib.py:133] step: 265750, training_loss: 2.80129e-02
I0209 14:56:43.000374 22542570456896 run_lib.py:133] step: 265800, training_loss: 2.15898e-02
I0209 14:56:43.153385 22542570456896 run_lib.py:146] step: 265800, eval_loss: 2.60480e-02
I0209 14:57:00.760377 22542570456896 run_lib.py:133] step: 265850, training_loss: 2.93912e-02
I0209 14:57:18.370295 22542570456896 run_lib.py:133] step: 265900, training_loss: 2.56562e-02
I0209 14:57:18.529742 22542570456896 run_lib.py:146] step: 265900, eval_loss: 2.33718e-02
I0209 14:57:35.938463 22542570456896 run_lib.py:133] step: 265950, training_loss: 2.73388e-02
I0209 14:57:53.379286 22542570456896 run_lib.py:133] step: 266000, training_loss: 2.94428e-02
I0209 14:57:53.547346 22542570456896 run_lib.py:146] step: 266000, eval_loss: 2.54519e-02
I0209 14:58:11.023604 22542570456896 run_lib.py:133] step: 266050, training_loss: 3.41820e-02
I0209 14:58:28.683139 22542570456896 run_lib.py:133] step: 266100, training_loss: 2.54403e-02
I0209 14:58:28.838214 22542570456896 run_lib.py:146] step: 266100, eval_loss: 2.42308e-02
I0209 14:58:46.341277 22542570456896 run_lib.py:133] step: 266150, training_loss: 2.89281e-02
I0209 14:59:03.855722 22542570456896 run_lib.py:133] step: 266200, training_loss: 2.78971e-02
I0209 14:59:04.008151 22542570456896 run_lib.py:146] step: 266200, eval_loss: 3.04573e-02
I0209 14:59:21.450376 22542570456896 run_lib.py:133] step: 266250, training_loss: 2.13118e-02
I0209 14:59:39.089505 22542570456896 run_lib.py:133] step: 266300, training_loss: 3.06926e-02
I0209 14:59:39.254859 22542570456896 run_lib.py:146] step: 266300, eval_loss: 3.64142e-02
I0209 14:59:56.734422 22542570456896 run_lib.py:133] step: 266350, training_loss: 2.68783e-02
I0209 15:00:14.321310 22542570456896 run_lib.py:133] step: 266400, training_loss: 2.84272e-02
I0209 15:00:14.479257 22542570456896 run_lib.py:146] step: 266400, eval_loss: 3.29948e-02
I0209 15:00:31.910312 22542570456896 run_lib.py:133] step: 266450, training_loss: 3.08786e-02
I0209 15:00:49.354678 22542570456896 run_lib.py:133] step: 266500, training_loss: 2.47336e-02
I0209 15:00:49.511371 22542570456896 run_lib.py:146] step: 266500, eval_loss: 3.03069e-02
I0209 15:01:07.114287 22542570456896 run_lib.py:133] step: 266550, training_loss: 2.94830e-02
I0209 15:01:24.679238 22542570456896 run_lib.py:133] step: 266600, training_loss: 2.37361e-02
I0209 15:01:24.836880 22542570456896 run_lib.py:146] step: 266600, eval_loss: 4.33141e-02
I0209 15:01:42.293444 22542570456896 run_lib.py:133] step: 266650, training_loss: 3.16273e-02
I0209 15:01:59.716987 22542570456896 run_lib.py:133] step: 266700, training_loss: 2.78499e-02
I0209 15:01:59.869315 22542570456896 run_lib.py:146] step: 266700, eval_loss: 2.97657e-02
I0209 15:02:17.503597 22542570456896 run_lib.py:133] step: 266750, training_loss: 2.32885e-02
I0209 15:02:34.944069 22542570456896 run_lib.py:133] step: 266800, training_loss: 3.29074e-02
I0209 15:02:35.105011 22542570456896 run_lib.py:146] step: 266800, eval_loss: 3.02223e-02
I0209 15:02:52.704648 22542570456896 run_lib.py:133] step: 266850, training_loss: 3.01373e-02
I0209 15:03:10.205133 22542570456896 run_lib.py:133] step: 266900, training_loss: 2.72636e-02
I0209 15:03:10.364575 22542570456896 run_lib.py:146] step: 266900, eval_loss: 2.70970e-02
I0209 15:03:27.985162 22542570456896 run_lib.py:133] step: 266950, training_loss: 2.90386e-02
I0209 15:03:45.401172 22542570456896 run_lib.py:133] step: 267000, training_loss: 2.75305e-02
I0209 15:03:45.557413 22542570456896 run_lib.py:146] step: 267000, eval_loss: 2.30816e-02
I0209 15:04:02.992785 22542570456896 run_lib.py:133] step: 267050, training_loss: 3.39868e-02
I0209 15:04:20.553842 22542570456896 run_lib.py:133] step: 267100, training_loss: 2.91765e-02
I0209 15:04:20.708122 22542570456896 run_lib.py:146] step: 267100, eval_loss: 3.49579e-02
I0209 15:04:38.159438 22542570456896 run_lib.py:133] step: 267150, training_loss: 3.34104e-02
I0209 15:04:55.822314 22542570456896 run_lib.py:133] step: 267200, training_loss: 2.44022e-02
I0209 15:04:55.976580 22542570456896 run_lib.py:146] step: 267200, eval_loss: 2.79683e-02
I0209 15:05:13.443404 22542570456896 run_lib.py:133] step: 267250, training_loss: 2.70318e-02
I0209 15:05:30.901081 22542570456896 run_lib.py:133] step: 267300, training_loss: 2.89230e-02
I0209 15:05:31.057340 22542570456896 run_lib.py:146] step: 267300, eval_loss: 2.19081e-02
I0209 15:05:48.655381 22542570456896 run_lib.py:133] step: 267350, training_loss: 2.96927e-02
I0209 15:06:06.122120 22542570456896 run_lib.py:133] step: 267400, training_loss: 2.61448e-02
I0209 15:06:06.303332 22542570456896 run_lib.py:146] step: 267400, eval_loss: 2.71843e-02
I0209 15:06:23.761084 22542570456896 run_lib.py:133] step: 267450, training_loss: 2.77655e-02
I0209 15:06:41.384720 22542570456896 run_lib.py:133] step: 267500, training_loss: 2.68186e-02
I0209 15:06:41.541598 22542570456896 run_lib.py:146] step: 267500, eval_loss: 3.01957e-02
I0209 15:06:58.998686 22542570456896 run_lib.py:133] step: 267550, training_loss: 3.09614e-02
I0209 15:07:16.403690 22542570456896 run_lib.py:133] step: 267600, training_loss: 2.65342e-02
I0209 15:07:16.559302 22542570456896 run_lib.py:146] step: 267600, eval_loss: 2.72865e-02
I0209 15:07:34.031352 22542570456896 run_lib.py:133] step: 267650, training_loss: 2.48346e-02
I0209 15:07:51.442614 22542570456896 run_lib.py:133] step: 267700, training_loss: 2.70960e-02
I0209 15:07:51.597676 22542570456896 run_lib.py:146] step: 267700, eval_loss: 2.32138e-02
I0209 15:08:09.096221 22542570456896 run_lib.py:133] step: 267750, training_loss: 2.73905e-02
I0209 15:08:26.505977 22542570456896 run_lib.py:133] step: 267800, training_loss: 3.27788e-02
I0209 15:08:26.669400 22542570456896 run_lib.py:146] step: 267800, eval_loss: 3.29700e-02
I0209 15:08:44.280431 22542570456896 run_lib.py:133] step: 267850, training_loss: 2.75782e-02
I0209 15:09:01.777531 22542570456896 run_lib.py:133] step: 267900, training_loss: 3.20578e-02
I0209 15:09:01.933562 22542570456896 run_lib.py:146] step: 267900, eval_loss: 2.58056e-02
I0209 15:09:19.392964 22542570456896 run_lib.py:133] step: 267950, training_loss: 3.00250e-02
I0209 15:09:36.876325 22542570456896 run_lib.py:133] step: 268000, training_loss: 3.08263e-02
I0209 15:09:37.033208 22542570456896 run_lib.py:146] step: 268000, eval_loss: 2.35236e-02
I0209 15:09:54.672972 22542570456896 run_lib.py:133] step: 268050, training_loss: 3.11090e-02
I0209 15:10:12.088453 22542570456896 run_lib.py:133] step: 268100, training_loss: 3.16681e-02
I0209 15:10:12.241127 22542570456896 run_lib.py:146] step: 268100, eval_loss: 2.99393e-02
I0209 15:10:29.822122 22542570456896 run_lib.py:133] step: 268150, training_loss: 2.16581e-02
I0209 15:10:47.324889 22542570456896 run_lib.py:133] step: 268200, training_loss: 2.91986e-02
I0209 15:10:47.478343 22542570456896 run_lib.py:146] step: 268200, eval_loss: 3.07188e-02
I0209 15:11:05.050150 22542570456896 run_lib.py:133] step: 268250, training_loss: 2.51522e-02
I0209 15:11:22.516279 22542570456896 run_lib.py:133] step: 268300, training_loss: 3.44923e-02
I0209 15:11:22.696463 22542570456896 run_lib.py:146] step: 268300, eval_loss: 2.75062e-02
I0209 15:11:40.367154 22542570456896 run_lib.py:133] step: 268350, training_loss: 2.73185e-02
I0209 15:11:57.789562 22542570456896 run_lib.py:133] step: 268400, training_loss: 2.62917e-02
I0209 15:11:57.955514 22542570456896 run_lib.py:146] step: 268400, eval_loss: 2.30883e-02
I0209 15:12:15.377673 22542570456896 run_lib.py:133] step: 268450, training_loss: 2.59984e-02
I0209 15:12:32.917009 22542570456896 run_lib.py:133] step: 268500, training_loss: 2.91638e-02
I0209 15:12:33.071676 22542570456896 run_lib.py:146] step: 268500, eval_loss: 2.48504e-02
I0209 15:12:50.494424 22542570456896 run_lib.py:133] step: 268550, training_loss: 3.33846e-02
I0209 15:13:07.975723 22542570456896 run_lib.py:133] step: 268600, training_loss: 2.42983e-02
I0209 15:13:08.130264 22542570456896 run_lib.py:146] step: 268600, eval_loss: 3.23753e-02
I0209 15:13:25.778908 22542570456896 run_lib.py:133] step: 268650, training_loss: 2.83647e-02
I0209 15:13:43.208998 22542570456896 run_lib.py:133] step: 268700, training_loss: 3.03595e-02
I0209 15:13:43.365416 22542570456896 run_lib.py:146] step: 268700, eval_loss: 2.25042e-02
I0209 15:14:00.935006 22542570456896 run_lib.py:133] step: 268750, training_loss: 2.76304e-02
I0209 15:14:18.359686 22542570456896 run_lib.py:133] step: 268800, training_loss: 3.02266e-02
I0209 15:14:18.518568 22542570456896 run_lib.py:146] step: 268800, eval_loss: 2.40778e-02
I0209 15:14:35.961803 22542570456896 run_lib.py:133] step: 268850, training_loss: 2.28205e-02
I0209 15:14:53.582786 22542570456896 run_lib.py:133] step: 268900, training_loss: 2.04367e-02
I0209 15:14:53.738466 22542570456896 run_lib.py:146] step: 268900, eval_loss: 3.04496e-02
I0209 15:15:11.162040 22542570456896 run_lib.py:133] step: 268950, training_loss: 2.43453e-02
I0209 15:15:28.595469 22542570456896 run_lib.py:133] step: 269000, training_loss: 2.72350e-02
I0209 15:15:28.751376 22542570456896 run_lib.py:146] step: 269000, eval_loss: 2.76289e-02
I0209 15:15:46.206949 22542570456896 run_lib.py:133] step: 269050, training_loss: 3.34248e-02
I0209 15:16:03.812678 22542570456896 run_lib.py:133] step: 269100, training_loss: 2.81827e-02
I0209 15:16:03.964424 22542570456896 run_lib.py:146] step: 269100, eval_loss: 3.26398e-02
I0209 15:16:21.394044 22542570456896 run_lib.py:133] step: 269150, training_loss: 2.69073e-02
I0209 15:16:38.908560 22542570456896 run_lib.py:133] step: 269200, training_loss: 3.10345e-02
I0209 15:16:39.077651 22542570456896 run_lib.py:146] step: 269200, eval_loss: 2.38505e-02
I0209 15:16:56.544676 22542570456896 run_lib.py:133] step: 269250, training_loss: 2.56810e-02
I0209 15:17:14.028236 22542570456896 run_lib.py:133] step: 269300, training_loss: 3.34444e-02
I0209 15:17:14.186644 22542570456896 run_lib.py:146] step: 269300, eval_loss: 3.66049e-02
I0209 15:17:31.794577 22542570456896 run_lib.py:133] step: 269350, training_loss: 3.15064e-02
I0209 15:17:49.289764 22542570456896 run_lib.py:133] step: 269400, training_loss: 2.82082e-02
I0209 15:17:49.444181 22542570456896 run_lib.py:146] step: 269400, eval_loss: 2.47469e-02
I0209 15:18:06.827773 22542570456896 run_lib.py:133] step: 269450, training_loss: 3.38549e-02
I0209 15:18:24.323375 22542570456896 run_lib.py:133] step: 269500, training_loss: 2.34452e-02
I0209 15:18:24.487913 22542570456896 run_lib.py:146] step: 269500, eval_loss: 2.78513e-02
I0209 15:18:42.139233 22542570456896 run_lib.py:133] step: 269550, training_loss: 2.80323e-02
I0209 15:18:59.558531 22542570456896 run_lib.py:133] step: 269600, training_loss: 2.44042e-02
I0209 15:18:59.711321 22542570456896 run_lib.py:146] step: 269600, eval_loss: 2.76591e-02
I0209 15:19:17.277302 22542570456896 run_lib.py:133] step: 269650, training_loss: 2.82475e-02
I0209 15:19:34.778016 22542570456896 run_lib.py:133] step: 269700, training_loss: 2.53471e-02
I0209 15:19:34.941979 22542570456896 run_lib.py:146] step: 269700, eval_loss: 3.79987e-02
I0209 15:19:52.528290 22542570456896 run_lib.py:133] step: 269750, training_loss: 2.76888e-02
I0209 15:20:10.021381 22542570456896 run_lib.py:133] step: 269800, training_loss: 2.61788e-02
I0209 15:20:10.181540 22542570456896 run_lib.py:146] step: 269800, eval_loss: 2.45743e-02
I0209 15:20:27.589665 22542570456896 run_lib.py:133] step: 269850, training_loss: 3.47195e-02
I0209 15:20:45.193933 22542570456896 run_lib.py:133] step: 269900, training_loss: 2.48801e-02
I0209 15:20:45.350311 22542570456896 run_lib.py:146] step: 269900, eval_loss: 3.16142e-02
I0209 15:21:02.779564 22542570456896 run_lib.py:133] step: 269950, training_loss: 2.99231e-02
I0209 15:21:20.337636 22542570456896 run_lib.py:133] step: 270000, training_loss: 2.67419e-02
I0209 15:21:21.075052 22542570456896 run_lib.py:146] step: 270000, eval_loss: 2.17156e-02
I0209 15:21:41.226423 22542570456896 run_lib.py:133] step: 270050, training_loss: 2.97854e-02
I0209 15:21:58.679370 22542570456896 run_lib.py:133] step: 270100, training_loss: 3.62321e-02
I0209 15:21:58.841142 22542570456896 run_lib.py:146] step: 270100, eval_loss: 2.63278e-02
I0209 15:22:16.254635 22542570456896 run_lib.py:133] step: 270150, training_loss: 2.76729e-02
I0209 15:22:33.723448 22542570456896 run_lib.py:133] step: 270200, training_loss: 2.90556e-02
I0209 15:22:33.889352 22542570456896 run_lib.py:146] step: 270200, eval_loss: 2.88142e-02
I0209 15:22:51.466662 22542570456896 run_lib.py:133] step: 270250, training_loss: 2.51028e-02
I0209 15:23:08.956904 22542570456896 run_lib.py:133] step: 270300, training_loss: 2.63317e-02
I0209 15:23:09.137463 22542570456896 run_lib.py:146] step: 270300, eval_loss: 3.01208e-02
I0209 15:23:26.604461 22542570456896 run_lib.py:133] step: 270350, training_loss: 3.30997e-02
I0209 15:23:44.089468 22542570456896 run_lib.py:133] step: 270400, training_loss: 2.40305e-02
I0209 15:23:44.246387 22542570456896 run_lib.py:146] step: 270400, eval_loss: 2.70488e-02
I0209 15:24:01.859515 22542570456896 run_lib.py:133] step: 270450, training_loss: 2.66226e-02
I0209 15:24:19.252754 22542570456896 run_lib.py:133] step: 270500, training_loss: 2.00819e-02
I0209 15:24:19.405028 22542570456896 run_lib.py:146] step: 270500, eval_loss: 3.51439e-02
I0209 15:24:36.944831 22542570456896 run_lib.py:133] step: 270550, training_loss: 3.08746e-02
I0209 15:24:54.366873 22542570456896 run_lib.py:133] step: 270600, training_loss: 3.01668e-02
I0209 15:24:54.521476 22542570456896 run_lib.py:146] step: 270600, eval_loss: 2.76137e-02
I0209 15:25:12.125728 22542570456896 run_lib.py:133] step: 270650, training_loss: 2.55459e-02
I0209 15:25:29.509459 22542570456896 run_lib.py:133] step: 270700, training_loss: 2.13304e-02
I0209 15:25:29.666245 22542570456896 run_lib.py:146] step: 270700, eval_loss: 3.09987e-02
I0209 15:25:47.238753 22542570456896 run_lib.py:133] step: 270750, training_loss: 2.77906e-02
I0209 15:26:04.648000 22542570456896 run_lib.py:133] step: 270800, training_loss: 2.60422e-02
I0209 15:26:04.806810 22542570456896 run_lib.py:146] step: 270800, eval_loss: 2.96022e-02
I0209 15:26:22.267695 22542570456896 run_lib.py:133] step: 270850, training_loss: 2.93354e-02
I0209 15:26:39.927717 22542570456896 run_lib.py:133] step: 270900, training_loss: 2.63154e-02
I0209 15:26:40.091107 22542570456896 run_lib.py:146] step: 270900, eval_loss: 3.80162e-02
I0209 15:26:57.527910 22542570456896 run_lib.py:133] step: 270950, training_loss: 3.38344e-02
I0209 15:27:14.958038 22542570456896 run_lib.py:133] step: 271000, training_loss: 2.93159e-02
I0209 15:27:15.113416 22542570456896 run_lib.py:146] step: 271000, eval_loss: 2.60624e-02
I0209 15:27:32.753115 22542570456896 run_lib.py:133] step: 271050, training_loss: 3.25415e-02
I0209 15:27:50.330650 22542570456896 run_lib.py:133] step: 271100, training_loss: 2.56895e-02
I0209 15:27:50.485543 22542570456896 run_lib.py:146] step: 271100, eval_loss: 4.28566e-02
I0209 15:28:07.955717 22542570456896 run_lib.py:133] step: 271150, training_loss: 3.05052e-02
I0209 15:28:25.406256 22542570456896 run_lib.py:133] step: 271200, training_loss: 1.93517e-02
I0209 15:28:25.565310 22542570456896 run_lib.py:146] step: 271200, eval_loss: 2.32075e-02
I0209 15:28:42.982620 22542570456896 run_lib.py:133] step: 271250, training_loss: 2.93655e-02
I0209 15:29:00.601357 22542570456896 run_lib.py:133] step: 271300, training_loss: 3.77081e-02
I0209 15:29:00.761842 22542570456896 run_lib.py:146] step: 271300, eval_loss: 2.76424e-02
I0209 15:29:18.201591 22542570456896 run_lib.py:133] step: 271350, training_loss: 2.50123e-02
I0209 15:29:35.607331 22542570456896 run_lib.py:133] step: 271400, training_loss: 2.43453e-02
I0209 15:29:35.767150 22542570456896 run_lib.py:146] step: 271400, eval_loss: 2.78417e-02
I0209 15:29:53.246903 22542570456896 run_lib.py:133] step: 271450, training_loss: 3.31965e-02
I0209 15:30:10.877917 22542570456896 run_lib.py:133] step: 271500, training_loss: 2.49178e-02
I0209 15:30:11.031563 22542570456896 run_lib.py:146] step: 271500, eval_loss: 3.31617e-02
I0209 15:30:28.450876 22542570456896 run_lib.py:133] step: 271550, training_loss: 2.84557e-02
I0209 15:30:45.941954 22542570456896 run_lib.py:133] step: 271600, training_loss: 3.48345e-02
I0209 15:30:46.096420 22542570456896 run_lib.py:146] step: 271600, eval_loss: 2.70279e-02
I0209 15:31:03.528415 22542570456896 run_lib.py:133] step: 271650, training_loss: 3.33557e-02
I0209 15:31:20.984733 22542570456896 run_lib.py:133] step: 271700, training_loss: 2.97993e-02
I0209 15:31:21.158552 22542570456896 run_lib.py:146] step: 271700, eval_loss: 2.61508e-02
I0209 15:31:38.856165 22542570456896 run_lib.py:133] step: 271750, training_loss: 2.77364e-02
I0209 15:31:56.362405 22542570456896 run_lib.py:133] step: 271800, training_loss: 3.20668e-02
I0209 15:31:56.519666 22542570456896 run_lib.py:146] step: 271800, eval_loss: 3.62111e-02
I0209 15:32:13.985705 22542570456896 run_lib.py:133] step: 271850, training_loss: 2.60477e-02
I0209 15:32:31.411669 22542570456896 run_lib.py:133] step: 271900, training_loss: 2.94154e-02
I0209 15:32:31.567482 22542570456896 run_lib.py:146] step: 271900, eval_loss: 3.33847e-02
I0209 15:32:49.121785 22542570456896 run_lib.py:133] step: 271950, training_loss: 2.06368e-02
I0209 15:33:06.593165 22542570456896 run_lib.py:133] step: 272000, training_loss: 2.72025e-02
I0209 15:33:06.746563 22542570456896 run_lib.py:146] step: 272000, eval_loss: 2.46923e-02
I0209 15:33:24.395236 22542570456896 run_lib.py:133] step: 272050, training_loss: 2.86734e-02
I0209 15:33:41.809273 22542570456896 run_lib.py:133] step: 272100, training_loss: 2.45011e-02
I0209 15:33:41.965373 22542570456896 run_lib.py:146] step: 272100, eval_loss: 3.13167e-02
I0209 15:33:59.545670 22542570456896 run_lib.py:133] step: 272150, training_loss: 2.63154e-02
I0209 15:34:16.948199 22542570456896 run_lib.py:133] step: 272200, training_loss: 2.86584e-02
I0209 15:34:17.105479 22542570456896 run_lib.py:146] step: 272200, eval_loss: 3.33447e-02
I0209 15:34:34.556855 22542570456896 run_lib.py:133] step: 272250, training_loss: 2.91123e-02
I0209 15:34:52.178326 22542570456896 run_lib.py:133] step: 272300, training_loss: 3.17424e-02
I0209 15:34:52.334638 22542570456896 run_lib.py:146] step: 272300, eval_loss: 2.93500e-02
I0209 15:35:09.775756 22542570456896 run_lib.py:133] step: 272350, training_loss: 3.00252e-02
I0209 15:35:27.408495 22542570456896 run_lib.py:133] step: 272400, training_loss: 2.38977e-02
I0209 15:35:27.569388 22542570456896 run_lib.py:146] step: 272400, eval_loss: 3.36950e-02
I0209 15:35:45.011783 22542570456896 run_lib.py:133] step: 272450, training_loss: 2.71566e-02
I0209 15:36:02.467448 22542570456896 run_lib.py:133] step: 272500, training_loss: 2.74256e-02
I0209 15:36:02.624346 22542570456896 run_lib.py:146] step: 272500, eval_loss: 2.75737e-02
I0209 15:36:20.219783 22542570456896 run_lib.py:133] step: 272550, training_loss: 3.44903e-02
I0209 15:36:37.716480 22542570456896 run_lib.py:133] step: 272600, training_loss: 2.75734e-02
I0209 15:36:37.886472 22542570456896 run_lib.py:146] step: 272600, eval_loss: 3.31641e-02
I0209 15:36:55.368757 22542570456896 run_lib.py:133] step: 272650, training_loss: 2.33649e-02
I0209 15:37:13.011391 22542570456896 run_lib.py:133] step: 272700, training_loss: 2.99885e-02
I0209 15:37:13.173579 22542570456896 run_lib.py:146] step: 272700, eval_loss: 3.07407e-02
I0209 15:37:30.664561 22542570456896 run_lib.py:133] step: 272750, training_loss: 2.51906e-02
I0209 15:37:48.095089 22542570456896 run_lib.py:133] step: 272800, training_loss: 2.41871e-02
I0209 15:37:48.249186 22542570456896 run_lib.py:146] step: 272800, eval_loss: 2.56643e-02
I0209 15:38:05.763305 22542570456896 run_lib.py:133] step: 272850, training_loss: 3.07540e-02
I0209 15:38:23.237538 22542570456896 run_lib.py:133] step: 272900, training_loss: 3.07919e-02
I0209 15:38:23.392547 22542570456896 run_lib.py:146] step: 272900, eval_loss: 2.67756e-02
I0209 15:38:40.840385 22542570456896 run_lib.py:133] step: 272950, training_loss: 3.14697e-02
I0209 15:38:58.237798 22542570456896 run_lib.py:133] step: 273000, training_loss: 2.50924e-02
I0209 15:38:58.391321 22542570456896 run_lib.py:146] step: 273000, eval_loss: 2.96747e-02
I0209 15:39:16.007083 22542570456896 run_lib.py:133] step: 273050, training_loss: 3.29507e-02
I0209 15:39:33.483954 22542570456896 run_lib.py:133] step: 273100, training_loss: 2.48322e-02
I0209 15:39:33.643451 22542570456896 run_lib.py:146] step: 273100, eval_loss: 2.91247e-02
I0209 15:39:51.091837 22542570456896 run_lib.py:133] step: 273150, training_loss: 3.04658e-02
I0209 15:40:08.598305 22542570456896 run_lib.py:133] step: 273200, training_loss: 2.22623e-02
I0209 15:40:08.758337 22542570456896 run_lib.py:146] step: 273200, eval_loss: 3.08681e-02
I0209 15:40:26.333134 22542570456896 run_lib.py:133] step: 273250, training_loss: 2.53733e-02
I0209 15:40:43.720933 22542570456896 run_lib.py:133] step: 273300, training_loss: 2.98576e-02
I0209 15:40:43.876026 22542570456896 run_lib.py:146] step: 273300, eval_loss: 2.10679e-02
I0209 15:41:01.410611 22542570456896 run_lib.py:133] step: 273350, training_loss: 2.58791e-02
I0209 15:41:18.850896 22542570456896 run_lib.py:133] step: 273400, training_loss: 2.58929e-02
I0209 15:41:19.003169 22542570456896 run_lib.py:146] step: 273400, eval_loss: 3.90789e-02
I0209 15:41:36.586482 22542570456896 run_lib.py:133] step: 273450, training_loss: 3.00666e-02
I0209 15:41:54.034834 22542570456896 run_lib.py:133] step: 273500, training_loss: 2.61382e-02
I0209 15:41:54.194581 22542570456896 run_lib.py:146] step: 273500, eval_loss: 3.02685e-02
I0209 15:42:11.808586 22542570456896 run_lib.py:133] step: 273550, training_loss: 2.19095e-02
I0209 15:42:29.241371 22542570456896 run_lib.py:133] step: 273600, training_loss: 2.94292e-02
I0209 15:42:29.400428 22542570456896 run_lib.py:146] step: 273600, eval_loss: 2.97211e-02
I0209 15:42:46.846494 22542570456896 run_lib.py:133] step: 273650, training_loss: 2.49919e-02
I0209 15:43:04.385243 22542570456896 run_lib.py:133] step: 273700, training_loss: 2.50837e-02
I0209 15:43:04.553281 22542570456896 run_lib.py:146] step: 273700, eval_loss: 3.61655e-02
I0209 15:43:21.996861 22542570456896 run_lib.py:133] step: 273750, training_loss: 2.61731e-02
I0209 15:43:39.491485 22542570456896 run_lib.py:133] step: 273800, training_loss: 2.54591e-02
I0209 15:43:39.647605 22542570456896 run_lib.py:146] step: 273800, eval_loss: 2.30418e-02
I0209 15:43:57.303052 22542570456896 run_lib.py:133] step: 273850, training_loss: 2.95607e-02
I0209 15:44:14.720771 22542570456896 run_lib.py:133] step: 273900, training_loss: 3.03882e-02
I0209 15:44:14.872320 22542570456896 run_lib.py:146] step: 273900, eval_loss: 1.91615e-02
I0209 15:44:32.442209 22542570456896 run_lib.py:133] step: 273950, training_loss: 3.17448e-02
I0209 15:44:49.899802 22542570456896 run_lib.py:133] step: 274000, training_loss: 2.96899e-02
I0209 15:44:50.064558 22542570456896 run_lib.py:146] step: 274000, eval_loss: 2.58465e-02
I0209 15:45:07.535695 22542570456896 run_lib.py:133] step: 274050, training_loss: 2.36010e-02
I0209 15:45:25.196487 22542570456896 run_lib.py:133] step: 274100, training_loss: 3.18518e-02
I0209 15:45:25.354491 22542570456896 run_lib.py:146] step: 274100, eval_loss: 2.10046e-02
I0209 15:45:42.799501 22542570456896 run_lib.py:133] step: 274150, training_loss: 2.86187e-02
I0209 15:46:00.226457 22542570456896 run_lib.py:133] step: 274200, training_loss: 2.64177e-02
I0209 15:46:00.387410 22542570456896 run_lib.py:146] step: 274200, eval_loss: 3.00846e-02
I0209 15:46:17.796159 22542570456896 run_lib.py:133] step: 274250, training_loss: 3.90242e-02
I0209 15:46:35.377574 22542570456896 run_lib.py:133] step: 274300, training_loss: 3.70302e-02
I0209 15:46:35.536610 22542570456896 run_lib.py:146] step: 274300, eval_loss: 2.43215e-02
I0209 15:46:52.986852 22542570456896 run_lib.py:133] step: 274350, training_loss: 2.14347e-02
I0209 15:47:10.545472 22542570456896 run_lib.py:133] step: 274400, training_loss: 2.49787e-02
I0209 15:47:10.696319 22542570456896 run_lib.py:146] step: 274400, eval_loss: 2.90830e-02
I0209 15:47:28.114652 22542570456896 run_lib.py:133] step: 274450, training_loss: 3.14447e-02
I0209 15:47:45.557517 22542570456896 run_lib.py:133] step: 274500, training_loss: 3.43998e-02
I0209 15:47:45.713120 22542570456896 run_lib.py:146] step: 274500, eval_loss: 2.90453e-02
I0209 15:48:03.285658 22542570456896 run_lib.py:133] step: 274550, training_loss: 2.80157e-02
I0209 15:48:20.817041 22542570456896 run_lib.py:133] step: 274600, training_loss: 3.74570e-02
I0209 15:48:20.983409 22542570456896 run_lib.py:146] step: 274600, eval_loss: 2.61132e-02
I0209 15:48:38.413128 22542570456896 run_lib.py:133] step: 274650, training_loss: 2.28527e-02
I0209 15:48:55.862431 22542570456896 run_lib.py:133] step: 274700, training_loss: 2.67522e-02
I0209 15:48:56.017589 22542570456896 run_lib.py:146] step: 274700, eval_loss: 2.81502e-02
I0209 15:49:13.672550 22542570456896 run_lib.py:133] step: 274750, training_loss: 3.03009e-02
I0209 15:49:31.101905 22542570456896 run_lib.py:133] step: 274800, training_loss: 2.91198e-02
I0209 15:49:31.255394 22542570456896 run_lib.py:146] step: 274800, eval_loss: 2.40371e-02
I0209 15:49:48.881154 22542570456896 run_lib.py:133] step: 274850, training_loss: 2.63101e-02
I0209 15:50:06.318267 22542570456896 run_lib.py:133] step: 274900, training_loss: 3.14490e-02
I0209 15:50:06.474660 22542570456896 run_lib.py:146] step: 274900, eval_loss: 2.77486e-02
I0209 15:50:24.114227 22542570456896 run_lib.py:133] step: 274950, training_loss: 3.21516e-02
I0209 15:50:41.576820 22542570456896 run_lib.py:133] step: 275000, training_loss: 2.54284e-02
I0209 15:50:41.736817 22542570456896 run_lib.py:146] step: 275000, eval_loss: 3.57255e-02
I0209 15:50:59.140629 22542570456896 run_lib.py:133] step: 275050, training_loss: 2.68728e-02
I0209 15:51:16.678186 22542570456896 run_lib.py:133] step: 275100, training_loss: 3.21291e-02
I0209 15:51:16.842369 22542570456896 run_lib.py:146] step: 275100, eval_loss: 3.04457e-02
I0209 15:51:34.334391 22542570456896 run_lib.py:133] step: 275150, training_loss: 2.91479e-02
I0209 15:51:51.995430 22542570456896 run_lib.py:133] step: 275200, training_loss: 2.47754e-02
I0209 15:51:52.148262 22542570456896 run_lib.py:146] step: 275200, eval_loss: 2.54439e-02
I0209 15:52:09.585063 22542570456896 run_lib.py:133] step: 275250, training_loss: 2.33244e-02
I0209 15:52:27.012130 22542570456896 run_lib.py:133] step: 275300, training_loss: 2.61869e-02
I0209 15:52:27.164424 22542570456896 run_lib.py:146] step: 275300, eval_loss: 3.19689e-02
I0209 15:52:44.734997 22542570456896 run_lib.py:133] step: 275350, training_loss: 2.82873e-02
I0209 15:53:02.180829 22542570456896 run_lib.py:133] step: 275400, training_loss: 2.72368e-02
I0209 15:53:02.348608 22542570456896 run_lib.py:146] step: 275400, eval_loss: 2.30400e-02
I0209 15:53:19.831288 22542570456896 run_lib.py:133] step: 275450, training_loss: 2.51547e-02
I0209 15:53:37.467133 22542570456896 run_lib.py:133] step: 275500, training_loss: 2.42783e-02
I0209 15:53:37.626338 22542570456896 run_lib.py:146] step: 275500, eval_loss: 2.55404e-02
I0209 15:53:55.064540 22542570456896 run_lib.py:133] step: 275550, training_loss: 2.87203e-02
I0209 15:54:12.492084 22542570456896 run_lib.py:133] step: 275600, training_loss: 3.02751e-02
I0209 15:54:12.797349 22542570456896 run_lib.py:146] step: 275600, eval_loss: 2.61572e-02
I0209 15:54:30.218456 22542570456896 run_lib.py:133] step: 275650, training_loss: 4.01000e-02
I0209 15:54:47.744068 22542570456896 run_lib.py:133] step: 275700, training_loss: 2.46747e-02
I0209 15:54:47.897540 22542570456896 run_lib.py:146] step: 275700, eval_loss: 3.13390e-02
I0209 15:55:05.352175 22542570456896 run_lib.py:133] step: 275750, training_loss: 2.73975e-02
I0209 15:55:22.784493 22542570456896 run_lib.py:133] step: 275800, training_loss: 2.29320e-02
I0209 15:55:22.937394 22542570456896 run_lib.py:146] step: 275800, eval_loss: 2.93713e-02
I0209 15:55:40.526255 22542570456896 run_lib.py:133] step: 275850, training_loss: 2.85916e-02
I0209 15:55:58.008804 22542570456896 run_lib.py:133] step: 275900, training_loss: 2.45557e-02
I0209 15:55:58.170546 22542570456896 run_lib.py:146] step: 275900, eval_loss: 2.47669e-02
I0209 15:56:15.667562 22542570456896 run_lib.py:133] step: 275950, training_loss: 3.10770e-02
I0209 15:56:33.118162 22542570456896 run_lib.py:133] step: 276000, training_loss: 3.17302e-02
I0209 15:56:33.277359 22542570456896 run_lib.py:146] step: 276000, eval_loss: 3.03570e-02
I0209 15:56:50.882212 22542570456896 run_lib.py:133] step: 276050, training_loss: 2.53669e-02
I0209 15:57:08.358190 22542570456896 run_lib.py:133] step: 276100, training_loss: 2.84403e-02
I0209 15:57:08.514390 22542570456896 run_lib.py:146] step: 276100, eval_loss: 2.89912e-02
I0209 15:57:25.926862 22542570456896 run_lib.py:133] step: 276150, training_loss: 2.56472e-02
I0209 15:57:43.325923 22542570456896 run_lib.py:133] step: 276200, training_loss: 2.64540e-02
I0209 15:57:43.489326 22542570456896 run_lib.py:146] step: 276200, eval_loss: 3.05883e-02
I0209 15:58:01.110507 22542570456896 run_lib.py:133] step: 276250, training_loss: 2.63287e-02
I0209 15:58:18.559904 22542570456896 run_lib.py:133] step: 276300, training_loss: 3.18112e-02
I0209 15:58:18.719638 22542570456896 run_lib.py:146] step: 276300, eval_loss: 3.26247e-02
I0209 15:58:36.375729 22542570456896 run_lib.py:133] step: 276350, training_loss: 2.91704e-02
I0209 15:58:53.810486 22542570456896 run_lib.py:133] step: 276400, training_loss: 2.56672e-02
I0209 15:58:53.969661 22542570456896 run_lib.py:146] step: 276400, eval_loss: 2.94812e-02
I0209 15:59:11.502374 22542570456896 run_lib.py:133] step: 276450, training_loss: 3.62969e-02
I0209 15:59:28.914414 22542570456896 run_lib.py:133] step: 276500, training_loss: 2.58666e-02
I0209 15:59:29.089350 22542570456896 run_lib.py:146] step: 276500, eval_loss: 3.07489e-02
I0209 15:59:46.601893 22542570456896 run_lib.py:133] step: 276550, training_loss: 2.64332e-02
I0209 16:00:04.188697 22542570456896 run_lib.py:133] step: 276600, training_loss: 2.98443e-02
I0209 16:00:04.349187 22542570456896 run_lib.py:146] step: 276600, eval_loss: 3.15517e-02
I0209 16:00:21.812262 22542570456896 run_lib.py:133] step: 276650, training_loss: 2.55564e-02
I0209 16:00:39.361968 22542570456896 run_lib.py:133] step: 276700, training_loss: 2.88096e-02
I0209 16:00:39.512431 22542570456896 run_lib.py:146] step: 276700, eval_loss: 2.52049e-02
I0209 16:00:56.960663 22542570456896 run_lib.py:133] step: 276750, training_loss: 2.65560e-02
I0209 16:01:14.435039 22542570456896 run_lib.py:133] step: 276800, training_loss: 2.70988e-02
I0209 16:01:14.592291 22542570456896 run_lib.py:146] step: 276800, eval_loss: 3.10764e-02
I0209 16:01:32.236448 22542570456896 run_lib.py:133] step: 276850, training_loss: 2.36455e-02
I0209 16:01:49.676779 22542570456896 run_lib.py:133] step: 276900, training_loss: 2.69160e-02
I0209 16:01:49.835248 22542570456896 run_lib.py:146] step: 276900, eval_loss: 2.60479e-02
I0209 16:02:07.231614 22542570456896 run_lib.py:133] step: 276950, training_loss: 3.21991e-02
I0209 16:02:24.625012 22542570456896 run_lib.py:133] step: 277000, training_loss: 2.95293e-02
I0209 16:02:24.782204 22542570456896 run_lib.py:146] step: 277000, eval_loss: 2.27107e-02
I0209 16:02:42.363777 22542570456896 run_lib.py:133] step: 277050, training_loss: 2.91623e-02
I0209 16:02:59.867266 22542570456896 run_lib.py:133] step: 277100, training_loss: 2.73099e-02
I0209 16:03:00.024145 22542570456896 run_lib.py:146] step: 277100, eval_loss: 3.18430e-02
I0209 16:03:17.563341 22542570456896 run_lib.py:133] step: 277150, training_loss: 3.07253e-02
I0209 16:03:34.958530 22542570456896 run_lib.py:133] step: 277200, training_loss: 3.14139e-02
I0209 16:03:35.114573 22542570456896 run_lib.py:146] step: 277200, eval_loss: 2.57178e-02
I0209 16:03:52.517124 22542570456896 run_lib.py:133] step: 277250, training_loss: 3.66381e-02
I0209 16:04:09.935915 22542570456896 run_lib.py:133] step: 277300, training_loss: 3.29587e-02
I0209 16:04:10.087729 22542570456896 run_lib.py:146] step: 277300, eval_loss: 3.58688e-02
I0209 16:04:27.632687 22542570456896 run_lib.py:133] step: 277350, training_loss: 3.30826e-02
I0209 16:04:45.173381 22542570456896 run_lib.py:133] step: 277400, training_loss: 2.60860e-02
I0209 16:04:45.348578 22542570456896 run_lib.py:146] step: 277400, eval_loss: 2.75437e-02
I0209 16:05:02.762146 22542570456896 run_lib.py:133] step: 277450, training_loss: 2.50040e-02
I0209 16:05:20.185574 22542570456896 run_lib.py:133] step: 277500, training_loss: 3.05723e-02
I0209 16:05:20.336756 22542570456896 run_lib.py:146] step: 277500, eval_loss: 2.92094e-02
I0209 16:05:37.934820 22542570456896 run_lib.py:133] step: 277550, training_loss: 3.08396e-02
I0209 16:05:55.356403 22542570456896 run_lib.py:133] step: 277600, training_loss: 2.80334e-02
I0209 16:05:55.518931 22542570456896 run_lib.py:146] step: 277600, eval_loss: 3.88018e-02
I0209 16:06:13.134096 22542570456896 run_lib.py:133] step: 277650, training_loss: 2.52077e-02
I0209 16:06:30.593008 22542570456896 run_lib.py:133] step: 277700, training_loss: 2.62863e-02
I0209 16:06:30.747695 22542570456896 run_lib.py:146] step: 277700, eval_loss: 2.24771e-02
I0209 16:06:48.345571 22542570456896 run_lib.py:133] step: 277750, training_loss: 2.64641e-02
I0209 16:07:05.746777 22542570456896 run_lib.py:133] step: 277800, training_loss: 2.83413e-02
I0209 16:07:05.899272 22542570456896 run_lib.py:146] step: 277800, eval_loss: 2.18748e-02
I0209 16:07:23.449752 22542570456896 run_lib.py:133] step: 277850, training_loss: 1.80350e-02
I0209 16:07:40.916366 22542570456896 run_lib.py:133] step: 277900, training_loss: 2.40737e-02
I0209 16:07:41.090509 22542570456896 run_lib.py:146] step: 277900, eval_loss: 3.08323e-02
I0209 16:07:58.534722 22542570456896 run_lib.py:133] step: 277950, training_loss: 2.42057e-02
I0209 16:08:16.127736 22542570456896 run_lib.py:133] step: 278000, training_loss: 2.84303e-02
I0209 16:08:16.284654 22542570456896 run_lib.py:146] step: 278000, eval_loss: 2.31097e-02
I0209 16:08:33.693256 22542570456896 run_lib.py:133] step: 278050, training_loss: 2.16522e-02
I0209 16:08:51.075087 22542570456896 run_lib.py:133] step: 278100, training_loss: 2.86476e-02
I0209 16:08:51.225713 22542570456896 run_lib.py:146] step: 278100, eval_loss: 3.29184e-02
I0209 16:09:08.785317 22542570456896 run_lib.py:133] step: 278150, training_loss: 2.54774e-02
I0209 16:09:26.422741 22542570456896 run_lib.py:133] step: 278200, training_loss: 3.05482e-02
I0209 16:09:26.577423 22542570456896 run_lib.py:146] step: 278200, eval_loss: 3.63489e-02
I0209 16:09:44.021853 22542570456896 run_lib.py:133] step: 278250, training_loss: 2.70992e-02
I0209 16:10:01.442549 22542570456896 run_lib.py:133] step: 278300, training_loss: 3.12661e-02
I0209 16:10:01.598595 22542570456896 run_lib.py:146] step: 278300, eval_loss: 2.40215e-02
I0209 16:10:19.001893 22542570456896 run_lib.py:133] step: 278350, training_loss: 2.97990e-02
I0209 16:10:36.571034 22542570456896 run_lib.py:133] step: 278400, training_loss: 2.92130e-02
I0209 16:10:36.726253 22542570456896 run_lib.py:146] step: 278400, eval_loss: 2.34850e-02
I0209 16:10:54.131616 22542570456896 run_lib.py:133] step: 278450, training_loss: 2.44160e-02
I0209 16:11:11.594586 22542570456896 run_lib.py:133] step: 278500, training_loss: 3.00537e-02
I0209 16:11:11.758090 22542570456896 run_lib.py:146] step: 278500, eval_loss: 2.34503e-02
I0209 16:11:29.165441 22542570456896 run_lib.py:133] step: 278550, training_loss: 2.40738e-02
I0209 16:11:46.726096 22542570456896 run_lib.py:133] step: 278600, training_loss: 2.57896e-02
I0209 16:11:46.879853 22542570456896 run_lib.py:146] step: 278600, eval_loss: 2.85150e-02
I0209 16:12:04.285578 22542570456896 run_lib.py:133] step: 278650, training_loss: 2.41571e-02
I0209 16:12:21.794780 22542570456896 run_lib.py:133] step: 278700, training_loss: 3.51958e-02
I0209 16:12:21.954980 22542570456896 run_lib.py:146] step: 278700, eval_loss: 2.63247e-02
I0209 16:12:39.415543 22542570456896 run_lib.py:133] step: 278750, training_loss: 3.00173e-02
I0209 16:12:56.867469 22542570456896 run_lib.py:133] step: 278800, training_loss: 2.84406e-02
I0209 16:12:57.027329 22542570456896 run_lib.py:146] step: 278800, eval_loss: 2.29138e-02
I0209 16:13:14.624639 22542570456896 run_lib.py:133] step: 278850, training_loss: 2.98501e-02
I0209 16:13:32.113935 22542570456896 run_lib.py:133] step: 278900, training_loss: 3.66056e-02
I0209 16:13:32.272437 22542570456896 run_lib.py:146] step: 278900, eval_loss: 2.37156e-02
I0209 16:13:49.693739 22542570456896 run_lib.py:133] step: 278950, training_loss: 3.26151e-02
I0209 16:14:07.114602 22542570456896 run_lib.py:133] step: 279000, training_loss: 3.21472e-02
I0209 16:14:07.281153 22542570456896 run_lib.py:146] step: 279000, eval_loss: 2.88921e-02
I0209 16:14:24.892717 22542570456896 run_lib.py:133] step: 279050, training_loss: 2.64932e-02
I0209 16:14:42.300460 22542570456896 run_lib.py:133] step: 279100, training_loss: 3.01113e-02
I0209 16:14:42.452222 22542570456896 run_lib.py:146] step: 279100, eval_loss: 2.90141e-02
I0209 16:15:00.059267 22542570456896 run_lib.py:133] step: 279150, training_loss: 3.49141e-02
I0209 16:15:17.478747 22542570456896 run_lib.py:133] step: 279200, training_loss: 2.83746e-02
I0209 16:15:17.636373 22542570456896 run_lib.py:146] step: 279200, eval_loss: 3.25137e-02
I0209 16:15:35.188658 22542570456896 run_lib.py:133] step: 279250, training_loss: 2.50870e-02
I0209 16:15:52.659404 22542570456896 run_lib.py:133] step: 279300, training_loss: 3.42314e-02
I0209 16:15:52.833352 22542570456896 run_lib.py:146] step: 279300, eval_loss: 2.79439e-02
I0209 16:16:10.306600 22542570456896 run_lib.py:133] step: 279350, training_loss: 2.26391e-02
I0209 16:16:27.902445 22542570456896 run_lib.py:133] step: 279400, training_loss: 2.55497e-02
I0209 16:16:28.057577 22542570456896 run_lib.py:146] step: 279400, eval_loss: 2.65660e-02
I0209 16:16:45.473246 22542570456896 run_lib.py:133] step: 279450, training_loss: 2.83951e-02
I0209 16:17:03.043301 22542570456896 run_lib.py:133] step: 279500, training_loss: 2.96839e-02
I0209 16:17:03.199376 22542570456896 run_lib.py:146] step: 279500, eval_loss: 2.74452e-02
I0209 16:17:20.626747 22542570456896 run_lib.py:133] step: 279550, training_loss: 2.48620e-02
I0209 16:17:38.073356 22542570456896 run_lib.py:133] step: 279600, training_loss: 3.35509e-02
I0209 16:17:38.228513 22542570456896 run_lib.py:146] step: 279600, eval_loss: 2.36434e-02
I0209 16:17:55.887237 22542570456896 run_lib.py:133] step: 279650, training_loss: 2.91590e-02
I0209 16:18:13.302873 22542570456896 run_lib.py:133] step: 279700, training_loss: 2.38695e-02
I0209 16:18:13.466487 22542570456896 run_lib.py:146] step: 279700, eval_loss: 2.53202e-02
I0209 16:18:30.878634 22542570456896 run_lib.py:133] step: 279750, training_loss: 3.28091e-02
I0209 16:18:48.434707 22542570456896 run_lib.py:133] step: 279800, training_loss: 3.67969e-02
I0209 16:18:48.592384 22542570456896 run_lib.py:146] step: 279800, eval_loss: 2.60561e-02
I0209 16:19:06.052439 22542570456896 run_lib.py:133] step: 279850, training_loss: 2.73042e-02
I0209 16:19:23.489103 22542570456896 run_lib.py:133] step: 279900, training_loss: 2.63884e-02
I0209 16:19:23.645552 22542570456896 run_lib.py:146] step: 279900, eval_loss: 2.35159e-02
I0209 16:19:41.168606 22542570456896 run_lib.py:133] step: 279950, training_loss: 2.65954e-02
I0209 16:19:58.599540 22542570456896 run_lib.py:133] step: 280000, training_loss: 2.68670e-02
I0209 16:19:59.297075 22542570456896 run_lib.py:146] step: 280000, eval_loss: 3.28212e-02
I0209 16:20:19.331299 22542570456896 run_lib.py:133] step: 280050, training_loss: 2.81722e-02
I0209 16:20:36.721139 22542570456896 run_lib.py:133] step: 280100, training_loss: 3.31955e-02
I0209 16:20:36.879257 22542570456896 run_lib.py:146] step: 280100, eval_loss: 2.64098e-02
I0209 16:20:54.463126 22542570456896 run_lib.py:133] step: 280150, training_loss: 2.80402e-02
I0209 16:21:11.902929 22542570456896 run_lib.py:133] step: 280200, training_loss: 2.94317e-02
I0209 16:21:12.057527 22542570456896 run_lib.py:146] step: 280200, eval_loss: 2.79880e-02
I0209 16:21:29.614883 22542570456896 run_lib.py:133] step: 280250, training_loss: 2.83712e-02
I0209 16:21:47.062101 22542570456896 run_lib.py:133] step: 280300, training_loss: 2.63624e-02
I0209 16:21:47.221198 22542570456896 run_lib.py:146] step: 280300, eval_loss: 3.07335e-02
I0209 16:22:04.596613 22542570456896 run_lib.py:133] step: 280350, training_loss: 2.92687e-02
I0209 16:22:21.978881 22542570456896 run_lib.py:133] step: 280400, training_loss: 2.73485e-02
I0209 16:22:22.146084 22542570456896 run_lib.py:146] step: 280400, eval_loss: 3.53515e-02
I0209 16:22:39.716995 22542570456896 run_lib.py:133] step: 280450, training_loss: 3.80381e-02
I0209 16:22:57.286148 22542570456896 run_lib.py:133] step: 280500, training_loss: 2.95135e-02
I0209 16:22:57.441796 22542570456896 run_lib.py:146] step: 280500, eval_loss: 2.57780e-02
I0209 16:23:14.877439 22542570456896 run_lib.py:133] step: 280550, training_loss: 3.19291e-02
I0209 16:23:32.271140 22542570456896 run_lib.py:133] step: 280600, training_loss: 1.88056e-02
I0209 16:23:32.423101 22542570456896 run_lib.py:146] step: 280600, eval_loss: 3.28171e-02
I0209 16:23:49.994606 22542570456896 run_lib.py:133] step: 280650, training_loss: 3.29106e-02
I0209 16:24:07.438021 22542570456896 run_lib.py:133] step: 280700, training_loss: 3.23365e-02
I0209 16:24:07.604531 22542570456896 run_lib.py:146] step: 280700, eval_loss: 2.22535e-02
I0209 16:24:25.222246 22542570456896 run_lib.py:133] step: 280750, training_loss: 3.59723e-02
I0209 16:24:42.716253 22542570456896 run_lib.py:133] step: 280800, training_loss: 2.66055e-02
I0209 16:24:42.875319 22542570456896 run_lib.py:146] step: 280800, eval_loss: 2.11306e-02
I0209 16:25:00.510428 22542570456896 run_lib.py:133] step: 280850, training_loss: 2.75603e-02
I0209 16:25:17.963160 22542570456896 run_lib.py:133] step: 280900, training_loss: 3.27623e-02
I0209 16:25:18.123013 22542570456896 run_lib.py:146] step: 280900, eval_loss: 2.35863e-02
I0209 16:25:35.716469 22542570456896 run_lib.py:133] step: 280950, training_loss: 2.33123e-02
I0209 16:25:53.158237 22542570456896 run_lib.py:133] step: 281000, training_loss: 3.58574e-02
I0209 16:25:53.319529 22542570456896 run_lib.py:146] step: 281000, eval_loss: 2.47852e-02
I0209 16:26:10.813427 22542570456896 run_lib.py:133] step: 281050, training_loss: 2.75360e-02
I0209 16:26:28.400922 22542570456896 run_lib.py:133] step: 281100, training_loss: 2.35886e-02
I0209 16:26:28.553368 22542570456896 run_lib.py:146] step: 281100, eval_loss: 3.25771e-02
I0209 16:26:45.954166 22542570456896 run_lib.py:133] step: 281150, training_loss: 3.12309e-02
I0209 16:27:03.363069 22542570456896 run_lib.py:133] step: 281200, training_loss: 2.79254e-02
I0209 16:27:03.516992 22542570456896 run_lib.py:146] step: 281200, eval_loss: 2.50213e-02
I0209 16:27:21.096005 22542570456896 run_lib.py:133] step: 281250, training_loss: 2.29208e-02
I0209 16:27:38.551160 22542570456896 run_lib.py:133] step: 281300, training_loss: 2.98407e-02
I0209 16:27:38.730346 22542570456896 run_lib.py:146] step: 281300, eval_loss: 2.55399e-02
I0209 16:27:56.342555 22542570456896 run_lib.py:133] step: 281350, training_loss: 3.51862e-02
I0209 16:28:13.811021 22542570456896 run_lib.py:133] step: 281400, training_loss: 2.68714e-02
I0209 16:28:13.974025 22542570456896 run_lib.py:146] step: 281400, eval_loss: 2.90113e-02
I0209 16:28:31.436081 22542570456896 run_lib.py:133] step: 281450, training_loss: 2.96848e-02
I0209 16:28:48.996810 22542570456896 run_lib.py:133] step: 281500, training_loss: 2.30207e-02
I0209 16:28:49.151319 22542570456896 run_lib.py:146] step: 281500, eval_loss: 2.85457e-02
I0209 16:29:06.571300 22542570456896 run_lib.py:133] step: 281550, training_loss: 2.38586e-02
I0209 16:29:24.060016 22542570456896 run_lib.py:133] step: 281600, training_loss: 2.06768e-02
I0209 16:29:24.215576 22542570456896 run_lib.py:146] step: 281600, eval_loss: 2.97376e-02
I0209 16:29:41.649811 22542570456896 run_lib.py:133] step: 281650, training_loss: 2.75988e-02
I0209 16:29:59.297894 22542570456896 run_lib.py:133] step: 281700, training_loss: 2.89507e-02
I0209 16:29:59.456415 22542570456896 run_lib.py:146] step: 281700, eval_loss: 2.84697e-02
I0209 16:30:16.857572 22542570456896 run_lib.py:133] step: 281750, training_loss: 2.88421e-02
I0209 16:30:34.336346 22542570456896 run_lib.py:133] step: 281800, training_loss: 2.85220e-02
I0209 16:30:34.492352 22542570456896 run_lib.py:146] step: 281800, eval_loss: 2.82848e-02
I0209 16:30:51.936309 22542570456896 run_lib.py:133] step: 281850, training_loss: 3.57040e-02
I0209 16:31:09.388530 22542570456896 run_lib.py:133] step: 281900, training_loss: 2.38217e-02
I0209 16:31:09.549223 22542570456896 run_lib.py:146] step: 281900, eval_loss: 2.38108e-02
I0209 16:31:27.157048 22542570456896 run_lib.py:133] step: 281950, training_loss: 3.55693e-02
I0209 16:31:44.679970 22542570456896 run_lib.py:133] step: 282000, training_loss: 3.13068e-02
I0209 16:31:44.834241 22542570456896 run_lib.py:146] step: 282000, eval_loss: 2.75314e-02
I0209 16:32:02.237585 22542570456896 run_lib.py:133] step: 282050, training_loss: 3.43179e-02
I0209 16:32:19.632726 22542570456896 run_lib.py:133] step: 282100, training_loss: 3.15912e-02
I0209 16:32:19.786844 22542570456896 run_lib.py:146] step: 282100, eval_loss: 2.83067e-02
I0209 16:32:37.340970 22542570456896 run_lib.py:133] step: 282150, training_loss: 2.48735e-02
I0209 16:32:54.820659 22542570456896 run_lib.py:133] step: 282200, training_loss: 3.06932e-02
I0209 16:32:54.995259 22542570456896 run_lib.py:146] step: 282200, eval_loss: 3.09283e-02
I0209 16:33:12.593768 22542570456896 run_lib.py:133] step: 282250, training_loss: 2.36939e-02
I0209 16:33:29.920433 22542570456896 run_lib.py:133] step: 282300, training_loss: 2.67092e-02
I0209 16:33:30.074127 22542570456896 run_lib.py:146] step: 282300, eval_loss: 3.05433e-02
I0209 16:33:47.507573 22542570456896 run_lib.py:133] step: 282350, training_loss: 2.88837e-02
I0209 16:34:04.802654 22542570456896 run_lib.py:133] step: 282400, training_loss: 2.26087e-02
I0209 16:34:04.970499 22542570456896 run_lib.py:146] step: 282400, eval_loss: 3.18335e-02
I0209 16:34:22.305114 22542570456896 run_lib.py:133] step: 282450, training_loss: 2.77897e-02
I0209 16:34:39.955120 22542570456896 run_lib.py:133] step: 282500, training_loss: 2.77138e-02
I0209 16:34:40.115682 22542570456896 run_lib.py:146] step: 282500, eval_loss: 2.86820e-02
I0209 16:34:57.537436 22542570456896 run_lib.py:133] step: 282550, training_loss: 3.03245e-02
I0209 16:35:15.136881 22542570456896 run_lib.py:133] step: 282600, training_loss: 2.61732e-02
I0209 16:35:15.293322 22542570456896 run_lib.py:146] step: 282600, eval_loss: 2.78222e-02
I0209 16:35:32.695447 22542570456896 run_lib.py:133] step: 282650, training_loss: 2.03432e-02
I0209 16:35:50.125230 22542570456896 run_lib.py:133] step: 282700, training_loss: 2.41950e-02
I0209 16:35:50.298278 22542570456896 run_lib.py:146] step: 282700, eval_loss: 2.82243e-02
I0209 16:36:07.892495 22542570456896 run_lib.py:133] step: 282750, training_loss: 2.54671e-02
I0209 16:36:25.343286 22542570456896 run_lib.py:133] step: 282800, training_loss: 2.75747e-02
I0209 16:36:25.501605 22542570456896 run_lib.py:146] step: 282800, eval_loss: 2.90967e-02
I0209 16:36:42.890778 22542570456896 run_lib.py:133] step: 282850, training_loss: 2.36653e-02
I0209 16:37:00.485728 22542570456896 run_lib.py:133] step: 282900, training_loss: 2.50224e-02
I0209 16:37:00.641470 22542570456896 run_lib.py:146] step: 282900, eval_loss: 2.55231e-02
I0209 16:37:18.071561 22542570456896 run_lib.py:133] step: 282950, training_loss: 3.46865e-02
I0209 16:37:35.571740 22542570456896 run_lib.py:133] step: 283000, training_loss: 2.81253e-02
I0209 16:37:35.872560 22542570456896 run_lib.py:146] step: 283000, eval_loss: 3.27915e-02
I0209 16:37:53.306372 22542570456896 run_lib.py:133] step: 283050, training_loss: 2.43437e-02
I0209 16:38:10.727560 22542570456896 run_lib.py:133] step: 283100, training_loss: 2.81159e-02
I0209 16:38:10.883193 22542570456896 run_lib.py:146] step: 283100, eval_loss: 2.80549e-02
I0209 16:38:28.365571 22542570456896 run_lib.py:133] step: 283150, training_loss: 2.67245e-02
I0209 16:38:45.807989 22542570456896 run_lib.py:133] step: 283200, training_loss: 3.41926e-02
I0209 16:38:45.974442 22542570456896 run_lib.py:146] step: 283200, eval_loss: 2.80458e-02
I0209 16:39:03.615725 22542570456896 run_lib.py:133] step: 283250, training_loss: 3.30826e-02
I0209 16:39:21.099170 22542570456896 run_lib.py:133] step: 283300, training_loss: 2.44172e-02
I0209 16:39:21.271723 22542570456896 run_lib.py:146] step: 283300, eval_loss: 2.95891e-02
I0209 16:39:38.691812 22542570456896 run_lib.py:133] step: 283350, training_loss: 3.14620e-02
I0209 16:39:56.162240 22542570456896 run_lib.py:133] step: 283400, training_loss: 2.54767e-02
I0209 16:39:56.317059 22542570456896 run_lib.py:146] step: 283400, eval_loss: 3.16449e-02
I0209 16:40:13.949110 22542570456896 run_lib.py:133] step: 283450, training_loss: 3.32751e-02
I0209 16:40:31.388289 22542570456896 run_lib.py:133] step: 283500, training_loss: 3.41647e-02
I0209 16:40:31.541298 22542570456896 run_lib.py:146] step: 283500, eval_loss: 3.13026e-02
I0209 16:40:48.956497 22542570456896 run_lib.py:133] step: 283550, training_loss: 2.20454e-02
I0209 16:41:06.420106 22542570456896 run_lib.py:133] step: 283600, training_loss: 2.97225e-02
I0209 16:41:06.596405 22542570456896 run_lib.py:146] step: 283600, eval_loss: 2.73053e-02
I0209 16:41:24.181946 22542570456896 run_lib.py:133] step: 283650, training_loss: 3.00652e-02
I0209 16:41:41.600389 22542570456896 run_lib.py:133] step: 283700, training_loss: 3.34479e-02
I0209 16:41:41.755523 22542570456896 run_lib.py:146] step: 283700, eval_loss: 2.91228e-02
I0209 16:41:59.320639 22542570456896 run_lib.py:133] step: 283750, training_loss: 2.67006e-02
I0209 16:42:16.731853 22542570456896 run_lib.py:133] step: 283800, training_loss: 3.00943e-02
I0209 16:42:16.891644 22542570456896 run_lib.py:146] step: 283800, eval_loss: 2.37671e-02
I0209 16:42:34.441439 22542570456896 run_lib.py:133] step: 283850, training_loss: 2.63067e-02
I0209 16:42:51.873311 22542570456896 run_lib.py:133] step: 283900, training_loss: 2.47167e-02
I0209 16:42:52.033332 22542570456896 run_lib.py:146] step: 283900, eval_loss: 3.69505e-02
I0209 16:43:09.486568 22542570456896 run_lib.py:133] step: 283950, training_loss: 2.58380e-02
I0209 16:43:27.044082 22542570456896 run_lib.py:133] step: 284000, training_loss: 2.48114e-02
I0209 16:43:27.198433 22542570456896 run_lib.py:146] step: 284000, eval_loss: 4.00668e-02
I0209 16:43:44.605647 22542570456896 run_lib.py:133] step: 284050, training_loss: 2.84370e-02
I0209 16:44:02.188881 22542570456896 run_lib.py:133] step: 284100, training_loss: 2.65361e-02
I0209 16:44:02.368882 22542570456896 run_lib.py:146] step: 284100, eval_loss: 3.16889e-02
I0209 16:44:19.842282 22542570456896 run_lib.py:133] step: 284150, training_loss: 2.90324e-02
I0209 16:44:37.244084 22542570456896 run_lib.py:133] step: 284200, training_loss: 2.57972e-02
I0209 16:44:37.401657 22542570456896 run_lib.py:146] step: 284200, eval_loss: 2.52516e-02
I0209 16:44:55.017747 22542570456896 run_lib.py:133] step: 284250, training_loss: 3.31105e-02
I0209 16:45:12.421027 22542570456896 run_lib.py:133] step: 284300, training_loss: 3.13814e-02
I0209 16:45:12.576257 22542570456896 run_lib.py:146] step: 284300, eval_loss: 2.86578e-02
I0209 16:45:30.039010 22542570456896 run_lib.py:133] step: 284350, training_loss: 3.17211e-02
I0209 16:45:47.520858 22542570456896 run_lib.py:133] step: 284400, training_loss: 2.36567e-02
I0209 16:45:47.681107 22542570456896 run_lib.py:146] step: 284400, eval_loss: 2.44937e-02
I0209 16:46:05.308476 22542570456896 run_lib.py:133] step: 284450, training_loss: 2.73007e-02
I0209 16:46:22.744144 22542570456896 run_lib.py:133] step: 284500, training_loss: 4.24389e-02
I0209 16:46:22.899195 22542570456896 run_lib.py:146] step: 284500, eval_loss: 3.15136e-02
I0209 16:46:40.385095 22542570456896 run_lib.py:133] step: 284550, training_loss: 2.75886e-02
I0209 16:46:57.774092 22542570456896 run_lib.py:133] step: 284600, training_loss: 3.21685e-02
I0209 16:46:57.933519 22542570456896 run_lib.py:146] step: 284600, eval_loss: 2.92146e-02
I0209 16:47:15.386820 22542570456896 run_lib.py:133] step: 284650, training_loss: 2.77322e-02
I0209 16:47:32.851388 22542570456896 run_lib.py:133] step: 284700, training_loss: 2.82235e-02
I0209 16:47:33.008668 22542570456896 run_lib.py:146] step: 284700, eval_loss: 2.32901e-02
I0209 16:47:50.640138 22542570456896 run_lib.py:133] step: 284750, training_loss: 3.28337e-02
I0209 16:48:08.097533 22542570456896 run_lib.py:133] step: 284800, training_loss: 2.77450e-02
I0209 16:48:08.257366 22542570456896 run_lib.py:146] step: 284800, eval_loss: 3.38434e-02
I0209 16:48:25.690111 22542570456896 run_lib.py:133] step: 284850, training_loss: 3.14476e-02
I0209 16:48:43.094940 22542570456896 run_lib.py:133] step: 284900, training_loss: 2.69876e-02
I0209 16:48:43.246243 22542570456896 run_lib.py:146] step: 284900, eval_loss: 2.87645e-02
I0209 16:49:00.821325 22542570456896 run_lib.py:133] step: 284950, training_loss: 2.56270e-02
I0209 16:49:18.230966 22542570456896 run_lib.py:133] step: 285000, training_loss: 3.32953e-02
I0209 16:49:18.398238 22542570456896 run_lib.py:146] step: 285000, eval_loss: 2.33108e-02
I0209 16:49:36.024207 22542570456896 run_lib.py:133] step: 285050, training_loss: 2.56447e-02
I0209 16:49:53.516058 22542570456896 run_lib.py:133] step: 285100, training_loss: 2.69659e-02
I0209 16:49:53.674546 22542570456896 run_lib.py:146] step: 285100, eval_loss: 2.75778e-02
I0209 16:50:11.261530 22542570456896 run_lib.py:133] step: 285150, training_loss: 2.51276e-02
I0209 16:50:28.653763 22542570456896 run_lib.py:133] step: 285200, training_loss: 3.01401e-02
I0209 16:50:28.808161 22542570456896 run_lib.py:146] step: 285200, eval_loss: 3.31344e-02
I0209 16:50:46.381120 22542570456896 run_lib.py:133] step: 285250, training_loss: 3.34182e-02
I0209 16:51:03.819777 22542570456896 run_lib.py:133] step: 285300, training_loss: 2.85025e-02
I0209 16:51:03.974535 22542570456896 run_lib.py:146] step: 285300, eval_loss: 3.05256e-02
I0209 16:51:21.444689 22542570456896 run_lib.py:133] step: 285350, training_loss: 2.31493e-02
I0209 16:51:39.028085 22542570456896 run_lib.py:133] step: 285400, training_loss: 2.95268e-02
I0209 16:51:39.188453 22542570456896 run_lib.py:146] step: 285400, eval_loss: 3.41310e-02
I0209 16:51:56.596713 22542570456896 run_lib.py:133] step: 285450, training_loss: 2.78531e-02
I0209 16:52:13.988146 22542570456896 run_lib.py:133] step: 285500, training_loss: 2.40984e-02
I0209 16:52:14.147614 22542570456896 run_lib.py:146] step: 285500, eval_loss: 3.22024e-02
I0209 16:52:31.756610 22542570456896 run_lib.py:133] step: 285550, training_loss: 2.72733e-02
I0209 16:52:49.421376 22542570456896 run_lib.py:133] step: 285600, training_loss: 2.06040e-02
I0209 16:52:49.577592 22542570456896 run_lib.py:146] step: 285600, eval_loss: 2.73229e-02
I0209 16:53:06.970898 22542570456896 run_lib.py:133] step: 285650, training_loss: 3.00693e-02
I0209 16:53:24.421841 22542570456896 run_lib.py:133] step: 285700, training_loss: 2.44667e-02
I0209 16:53:24.585182 22542570456896 run_lib.py:146] step: 285700, eval_loss: 2.82440e-02
I0209 16:53:41.999353 22542570456896 run_lib.py:133] step: 285750, training_loss: 2.84053e-02
I0209 16:53:59.546087 22542570456896 run_lib.py:133] step: 285800, training_loss: 2.91017e-02
I0209 16:53:59.699094 22542570456896 run_lib.py:146] step: 285800, eval_loss: 2.91018e-02
I0209 16:54:17.166238 22542570456896 run_lib.py:133] step: 285850, training_loss: 2.70685e-02
I0209 16:54:34.577584 22542570456896 run_lib.py:133] step: 285900, training_loss: 2.50078e-02
I0209 16:54:34.733517 22542570456896 run_lib.py:146] step: 285900, eval_loss: 2.81618e-02
I0209 16:54:52.127165 22542570456896 run_lib.py:133] step: 285950, training_loss: 3.17797e-02
I0209 16:55:09.747849 22542570456896 run_lib.py:133] step: 286000, training_loss: 3.04949e-02
I0209 16:55:09.912433 22542570456896 run_lib.py:146] step: 286000, eval_loss: 2.24429e-02
I0209 16:55:27.318069 22542570456896 run_lib.py:133] step: 286050, training_loss: 2.83935e-02
I0209 16:55:44.860324 22542570456896 run_lib.py:133] step: 286100, training_loss: 3.16410e-02
I0209 16:55:45.024568 22542570456896 run_lib.py:146] step: 286100, eval_loss: 2.89835e-02
I0209 16:56:02.462461 22542570456896 run_lib.py:133] step: 286150, training_loss: 3.15751e-02
I0209 16:56:19.875597 22542570456896 run_lib.py:133] step: 286200, training_loss: 2.53522e-02
I0209 16:56:20.033965 22542570456896 run_lib.py:146] step: 286200, eval_loss: 2.77023e-02
I0209 16:56:37.619415 22542570456896 run_lib.py:133] step: 286250, training_loss: 2.82201e-02
I0209 16:56:55.114506 22542570456896 run_lib.py:133] step: 286300, training_loss: 3.11554e-02
I0209 16:56:55.266401 22542570456896 run_lib.py:146] step: 286300, eval_loss: 2.68974e-02
I0209 16:57:12.652506 22542570456896 run_lib.py:133] step: 286350, training_loss: 2.87076e-02
I0209 16:57:30.102130 22542570456896 run_lib.py:133] step: 286400, training_loss: 1.92153e-02
I0209 16:57:30.271616 22542570456896 run_lib.py:146] step: 286400, eval_loss: 2.81237e-02
I0209 16:57:47.869128 22542570456896 run_lib.py:133] step: 286450, training_loss: 2.98665e-02
I0209 16:58:05.305856 22542570456896 run_lib.py:133] step: 286500, training_loss: 2.26201e-02
I0209 16:58:05.472377 22542570456896 run_lib.py:146] step: 286500, eval_loss: 2.33906e-02
I0209 16:58:22.995510 22542570456896 run_lib.py:133] step: 286550, training_loss: 3.11478e-02
I0209 16:58:40.359718 22542570456896 run_lib.py:133] step: 286600, training_loss: 2.38888e-02
I0209 16:58:40.515338 22542570456896 run_lib.py:146] step: 286600, eval_loss: 2.77814e-02
I0209 16:58:58.039845 22542570456896 run_lib.py:133] step: 286650, training_loss: 2.13555e-02
I0209 16:59:15.507406 22542570456896 run_lib.py:133] step: 286700, training_loss: 2.65201e-02
I0209 16:59:15.665661 22542570456896 run_lib.py:146] step: 286700, eval_loss: 2.72428e-02
I0209 16:59:33.089177 22542570456896 run_lib.py:133] step: 286750, training_loss: 2.47379e-02
I0209 16:59:50.678154 22542570456896 run_lib.py:133] step: 286800, training_loss: 2.99803e-02
I0209 16:59:50.836418 22542570456896 run_lib.py:146] step: 286800, eval_loss: 2.60773e-02
I0209 17:00:08.226735 22542570456896 run_lib.py:133] step: 286850, training_loss: 2.39192e-02
I0209 17:00:25.765078 22542570456896 run_lib.py:133] step: 286900, training_loss: 2.89743e-02
I0209 17:00:25.920930 22542570456896 run_lib.py:146] step: 286900, eval_loss: 3.37774e-02
I0209 17:00:43.368823 22542570456896 run_lib.py:133] step: 286950, training_loss: 2.50127e-02
I0209 17:01:00.813057 22542570456896 run_lib.py:133] step: 287000, training_loss: 3.19419e-02
I0209 17:01:00.968274 22542570456896 run_lib.py:146] step: 287000, eval_loss: 3.21347e-02
I0209 17:01:18.563904 22542570456896 run_lib.py:133] step: 287050, training_loss: 3.00838e-02
I0209 17:01:36.001432 22542570456896 run_lib.py:133] step: 287100, training_loss: 3.38668e-02
I0209 17:01:36.157567 22542570456896 run_lib.py:146] step: 287100, eval_loss: 2.48415e-02
I0209 17:01:53.593493 22542570456896 run_lib.py:133] step: 287150, training_loss: 2.50836e-02
I0209 17:02:11.184843 22542570456896 run_lib.py:133] step: 287200, training_loss: 3.46831e-02
I0209 17:02:11.346313 22542570456896 run_lib.py:146] step: 287200, eval_loss: 2.66843e-02
I0209 17:02:28.797668 22542570456896 run_lib.py:133] step: 287250, training_loss: 3.31486e-02
I0209 17:02:46.268332 22542570456896 run_lib.py:133] step: 287300, training_loss: 2.72823e-02
I0209 17:02:46.422510 22542570456896 run_lib.py:146] step: 287300, eval_loss: 2.38590e-02
I0209 17:03:03.955252 22542570456896 run_lib.py:133] step: 287350, training_loss: 2.88173e-02
I0209 17:03:21.392512 22542570456896 run_lib.py:133] step: 287400, training_loss: 2.67778e-02
I0209 17:03:21.558558 22542570456896 run_lib.py:146] step: 287400, eval_loss: 2.37748e-02
I0209 17:03:38.984806 22542570456896 run_lib.py:133] step: 287450, training_loss: 2.49257e-02
I0209 17:03:56.377439 22542570456896 run_lib.py:133] step: 287500, training_loss: 3.29911e-02
I0209 17:03:56.555350 22542570456896 run_lib.py:146] step: 287500, eval_loss: 3.04757e-02
I0209 17:04:14.173293 22542570456896 run_lib.py:133] step: 287550, training_loss: 2.74204e-02
I0209 17:04:31.746138 22542570456896 run_lib.py:133] step: 287600, training_loss: 2.85613e-02
I0209 17:04:31.899064 22542570456896 run_lib.py:146] step: 287600, eval_loss: 2.80609e-02
I0209 17:04:49.305977 22542570456896 run_lib.py:133] step: 287650, training_loss: 2.15161e-02
I0209 17:05:06.723534 22542570456896 run_lib.py:133] step: 287700, training_loss: 1.49578e-02
I0209 17:05:06.871597 22542570456896 run_lib.py:146] step: 287700, eval_loss: 3.04174e-02
I0209 17:05:24.391914 22542570456896 run_lib.py:133] step: 287750, training_loss: 2.67761e-02
I0209 17:05:41.809762 22542570456896 run_lib.py:133] step: 287800, training_loss: 3.03101e-02
I0209 17:05:41.977517 22542570456896 run_lib.py:146] step: 287800, eval_loss: 2.50482e-02
I0209 17:05:59.598480 22542570456896 run_lib.py:133] step: 287850, training_loss: 2.56387e-02
I0209 17:06:17.002349 22542570456896 run_lib.py:133] step: 287900, training_loss: 2.79597e-02
I0209 17:06:17.160417 22542570456896 run_lib.py:146] step: 287900, eval_loss: 2.82935e-02
I0209 17:06:34.771536 22542570456896 run_lib.py:133] step: 287950, training_loss: 2.67124e-02
I0209 17:06:52.162259 22542570456896 run_lib.py:133] step: 288000, training_loss: 2.82501e-02
I0209 17:06:52.317943 22542570456896 run_lib.py:146] step: 288000, eval_loss: 3.00090e-02
I0209 17:07:09.864135 22542570456896 run_lib.py:133] step: 288050, training_loss: 2.81198e-02
I0209 17:07:27.327816 22542570456896 run_lib.py:133] step: 288100, training_loss: 3.16072e-02
I0209 17:07:27.484717 22542570456896 run_lib.py:146] step: 288100, eval_loss: 3.02651e-02
I0209 17:07:44.926412 22542570456896 run_lib.py:133] step: 288150, training_loss: 2.81712e-02
I0209 17:08:02.505374 22542570456896 run_lib.py:133] step: 288200, training_loss: 3.35372e-02
I0209 17:08:02.657389 22542570456896 run_lib.py:146] step: 288200, eval_loss: 3.07243e-02
I0209 17:08:20.067888 22542570456896 run_lib.py:133] step: 288250, training_loss: 2.91177e-02
I0209 17:08:37.538763 22542570456896 run_lib.py:133] step: 288300, training_loss: 2.75355e-02
I0209 17:08:37.704539 22542570456896 run_lib.py:146] step: 288300, eval_loss: 2.74389e-02
I0209 17:08:55.272177 22542570456896 run_lib.py:133] step: 288350, training_loss: 2.55740e-02
I0209 17:09:12.755008 22542570456896 run_lib.py:133] step: 288400, training_loss: 3.00314e-02
I0209 17:09:12.914405 22542570456896 run_lib.py:146] step: 288400, eval_loss: 2.95791e-02
I0209 17:09:30.536148 22542570456896 run_lib.py:133] step: 288450, training_loss: 2.69328e-02
I0209 17:09:47.943777 22542570456896 run_lib.py:133] step: 288500, training_loss: 2.92451e-02
I0209 17:09:48.098269 22542570456896 run_lib.py:146] step: 288500, eval_loss: 2.22086e-02
I0209 17:10:05.509964 22542570456896 run_lib.py:133] step: 288550, training_loss: 2.41280e-02
I0209 17:10:23.108283 22542570456896 run_lib.py:133] step: 288600, training_loss: 3.05649e-02
I0209 17:10:23.270236 22542570456896 run_lib.py:146] step: 288600, eval_loss: 2.47355e-02
I0209 17:10:40.775773 22542570456896 run_lib.py:133] step: 288650, training_loss: 2.57892e-02
I0209 17:10:58.187682 22542570456896 run_lib.py:133] step: 288700, training_loss: 2.41751e-02
I0209 17:10:58.342719 22542570456896 run_lib.py:146] step: 288700, eval_loss: 2.28155e-02
I0209 17:11:15.758465 22542570456896 run_lib.py:133] step: 288750, training_loss: 3.10078e-02
I0209 17:11:33.360654 22542570456896 run_lib.py:133] step: 288800, training_loss: 3.03893e-02
I0209 17:11:33.519572 22542570456896 run_lib.py:146] step: 288800, eval_loss: 2.91287e-02
I0209 17:11:50.896957 22542570456896 run_lib.py:133] step: 288850, training_loss: 2.48941e-02
I0209 17:12:08.391045 22542570456896 run_lib.py:133] step: 288900, training_loss: 3.05858e-02
I0209 17:12:08.565352 22542570456896 run_lib.py:146] step: 288900, eval_loss: 2.89293e-02
I0209 17:12:26.011573 22542570456896 run_lib.py:133] step: 288950, training_loss: 2.74626e-02
I0209 17:12:43.436218 22542570456896 run_lib.py:133] step: 289000, training_loss: 2.83307e-02
I0209 17:12:43.591249 22542570456896 run_lib.py:146] step: 289000, eval_loss: 2.88572e-02
I0209 17:13:01.204906 22542570456896 run_lib.py:133] step: 289050, training_loss: 3.39894e-02
I0209 17:13:18.685621 22542570456896 run_lib.py:133] step: 289100, training_loss: 2.80693e-02
I0209 17:13:18.843026 22542570456896 run_lib.py:146] step: 289100, eval_loss: 2.96002e-02
I0209 17:13:36.236628 22542570456896 run_lib.py:133] step: 289150, training_loss: 2.53258e-02
I0209 17:13:53.725202 22542570456896 run_lib.py:133] step: 289200, training_loss: 3.40180e-02
I0209 17:13:53.887642 22542570456896 run_lib.py:146] step: 289200, eval_loss: 2.82273e-02
I0209 17:14:11.556317 22542570456896 run_lib.py:133] step: 289250, training_loss: 2.84525e-02
I0209 17:14:28.959278 22542570456896 run_lib.py:133] step: 289300, training_loss: 3.04134e-02
I0209 17:14:29.118411 22542570456896 run_lib.py:146] step: 289300, eval_loss: 2.65769e-02
I0209 17:14:46.688132 22542570456896 run_lib.py:133] step: 289350, training_loss: 2.74096e-02
I0209 17:15:04.113799 22542570456896 run_lib.py:133] step: 289400, training_loss: 2.60952e-02
I0209 17:15:04.268446 22542570456896 run_lib.py:146] step: 289400, eval_loss: 3.49344e-02
I0209 17:15:21.852874 22542570456896 run_lib.py:133] step: 289450, training_loss: 2.49086e-02
I0209 17:15:39.306051 22542570456896 run_lib.py:133] step: 289500, training_loss: 2.74333e-02
I0209 17:15:39.463077 22542570456896 run_lib.py:146] step: 289500, eval_loss: 2.75411e-02
I0209 17:15:56.935660 22542570456896 run_lib.py:133] step: 289550, training_loss: 3.31326e-02
I0209 17:16:14.587417 22542570456896 run_lib.py:133] step: 289600, training_loss: 2.77832e-02
I0209 17:16:14.747023 22542570456896 run_lib.py:146] step: 289600, eval_loss: 2.95262e-02
I0209 17:16:32.170588 22542570456896 run_lib.py:133] step: 289650, training_loss: 2.68899e-02
I0209 17:16:49.759534 22542570456896 run_lib.py:133] step: 289700, training_loss: 2.76110e-02
I0209 17:16:49.915426 22542570456896 run_lib.py:146] step: 289700, eval_loss: 2.97600e-02
I0209 17:17:07.385374 22542570456896 run_lib.py:133] step: 289750, training_loss: 2.85536e-02
I0209 17:17:24.802008 22542570456896 run_lib.py:133] step: 289800, training_loss: 2.88102e-02
I0209 17:17:24.975338 22542570456896 run_lib.py:146] step: 289800, eval_loss: 2.67821e-02
I0209 17:17:42.630651 22542570456896 run_lib.py:133] step: 289850, training_loss: 3.11759e-02
I0209 17:18:00.055089 22542570456896 run_lib.py:133] step: 289900, training_loss: 1.93967e-02
I0209 17:18:00.211634 22542570456896 run_lib.py:146] step: 289900, eval_loss: 3.15368e-02
I0209 17:18:17.655909 22542570456896 run_lib.py:133] step: 289950, training_loss: 2.05136e-02
I0209 17:18:35.227303 22542570456896 run_lib.py:133] step: 290000, training_loss: 3.18349e-02
I0209 17:18:35.932992 22542570456896 run_lib.py:146] step: 290000, eval_loss: 3.23169e-02
I0209 17:18:55.927095 22542570456896 run_lib.py:133] step: 290050, training_loss: 2.48824e-02
I0209 17:19:13.350324 22542570456896 run_lib.py:133] step: 290100, training_loss: 2.72837e-02
I0209 17:19:13.507704 22542570456896 run_lib.py:146] step: 290100, eval_loss: 3.05405e-02
I0209 17:19:31.127409 22542570456896 run_lib.py:133] step: 290150, training_loss: 3.00614e-02
I0209 17:19:48.550310 22542570456896 run_lib.py:133] step: 290200, training_loss: 3.10014e-02
I0209 17:19:48.700702 22542570456896 run_lib.py:146] step: 290200, eval_loss: 3.02082e-02
I0209 17:20:06.126478 22542570456896 run_lib.py:133] step: 290250, training_loss: 3.24110e-02
I0209 17:20:23.528708 22542570456896 run_lib.py:133] step: 290300, training_loss: 3.48981e-02
I0209 17:20:23.688319 22542570456896 run_lib.py:146] step: 290300, eval_loss: 2.11288e-02
I0209 17:20:41.261578 22542570456896 run_lib.py:133] step: 290350, training_loss: 2.49636e-02
I0209 17:20:58.756241 22542570456896 run_lib.py:133] step: 290400, training_loss: 3.34865e-02
I0209 17:20:58.912310 22542570456896 run_lib.py:146] step: 290400, eval_loss: 3.14118e-02
I0209 17:21:16.433220 22542570456896 run_lib.py:133] step: 290450, training_loss: 3.04925e-02
I0209 17:21:33.815746 22542570456896 run_lib.py:133] step: 290500, training_loss: 3.13692e-02
I0209 17:21:33.971405 22542570456896 run_lib.py:146] step: 290500, eval_loss: 2.81869e-02
I0209 17:21:51.417869 22542570456896 run_lib.py:133] step: 290550, training_loss: 2.52603e-02
I0209 17:22:08.886967 22542570456896 run_lib.py:133] step: 290600, training_loss: 2.36224e-02
I0209 17:22:09.040713 22542570456896 run_lib.py:146] step: 290600, eval_loss: 2.94410e-02
I0209 17:22:26.597775 22542570456896 run_lib.py:133] step: 290650, training_loss: 3.10444e-02
I0209 17:22:44.125327 22542570456896 run_lib.py:133] step: 290700, training_loss: 3.20192e-02
I0209 17:22:44.281609 22542570456896 run_lib.py:146] step: 290700, eval_loss: 2.99613e-02
I0209 17:23:01.697980 22542570456896 run_lib.py:133] step: 290750, training_loss: 2.80942e-02
I0209 17:23:19.174090 22542570456896 run_lib.py:133] step: 290800, training_loss: 3.04645e-02
I0209 17:23:19.332695 22542570456896 run_lib.py:146] step: 290800, eval_loss: 2.45982e-02
I0209 17:23:36.902408 22542570456896 run_lib.py:133] step: 290850, training_loss: 2.71415e-02
I0209 17:23:54.312530 22542570456896 run_lib.py:133] step: 290900, training_loss: 2.60918e-02
I0209 17:23:54.464365 22542570456896 run_lib.py:146] step: 290900, eval_loss: 2.82900e-02
I0209 17:24:12.022288 22542570456896 run_lib.py:133] step: 290950, training_loss: 3.61406e-02
I0209 17:24:29.509955 22542570456896 run_lib.py:133] step: 291000, training_loss: 2.19377e-02
I0209 17:24:29.666579 22542570456896 run_lib.py:146] step: 291000, eval_loss: 3.14373e-02
I0209 17:24:47.303416 22542570456896 run_lib.py:133] step: 291050, training_loss: 2.77232e-02
I0209 17:25:04.695181 22542570456896 run_lib.py:133] step: 291100, training_loss: 2.91922e-02
I0209 17:25:04.847208 22542570456896 run_lib.py:146] step: 291100, eval_loss: 2.92314e-02
I0209 17:25:22.431946 22542570456896 run_lib.py:133] step: 291150, training_loss: 2.98010e-02
I0209 17:25:39.852925 22542570456896 run_lib.py:133] step: 291200, training_loss: 2.70915e-02
I0209 17:25:40.016663 22542570456896 run_lib.py:146] step: 291200, eval_loss: 2.77759e-02
I0209 17:25:57.519047 22542570456896 run_lib.py:133] step: 291250, training_loss: 2.92466e-02
I0209 17:26:15.120418 22542570456896 run_lib.py:133] step: 291300, training_loss: 3.01847e-02
I0209 17:26:15.289217 22542570456896 run_lib.py:146] step: 291300, eval_loss: 2.36393e-02
I0209 17:26:32.712500 22542570456896 run_lib.py:133] step: 291350, training_loss: 2.91289e-02
I0209 17:26:50.143093 22542570456896 run_lib.py:133] step: 291400, training_loss: 3.10108e-02
I0209 17:26:50.298376 22542570456896 run_lib.py:146] step: 291400, eval_loss: 2.76680e-02
I0209 17:27:07.881473 22542570456896 run_lib.py:133] step: 291450, training_loss: 2.12539e-02
I0209 17:27:25.457466 22542570456896 run_lib.py:133] step: 291500, training_loss: 2.52946e-02
I0209 17:27:25.608633 22542570456896 run_lib.py:146] step: 291500, eval_loss: 2.69743e-02
I0209 17:27:43.009636 22542570456896 run_lib.py:133] step: 291550, training_loss: 2.64604e-02
I0209 17:28:00.473910 22542570456896 run_lib.py:133] step: 291600, training_loss: 3.13914e-02
I0209 17:28:00.628526 22542570456896 run_lib.py:146] step: 291600, eval_loss: 2.57674e-02
I0209 17:28:18.062349 22542570456896 run_lib.py:133] step: 291650, training_loss: 2.17200e-02
I0209 17:28:35.665524 22542570456896 run_lib.py:133] step: 291700, training_loss: 2.68181e-02
I0209 17:28:35.829363 22542570456896 run_lib.py:146] step: 291700, eval_loss: 2.06944e-02
I0209 17:28:53.238294 22542570456896 run_lib.py:133] step: 291750, training_loss: 2.73716e-02
I0209 17:29:10.668071 22542570456896 run_lib.py:133] step: 291800, training_loss: 3.36649e-02
I0209 17:29:10.844334 22542570456896 run_lib.py:146] step: 291800, eval_loss: 2.89518e-02
I0209 17:29:28.310188 22542570456896 run_lib.py:133] step: 291850, training_loss: 2.76530e-02
I0209 17:29:45.934103 22542570456896 run_lib.py:133] step: 291900, training_loss: 3.20091e-02
I0209 17:29:46.090661 22542570456896 run_lib.py:146] step: 291900, eval_loss: 2.81961e-02
I0209 17:30:03.523228 22542570456896 run_lib.py:133] step: 291950, training_loss: 2.91774e-02
I0209 17:30:20.982011 22542570456896 run_lib.py:133] step: 292000, training_loss: 3.26702e-02
I0209 17:30:21.136127 22542570456896 run_lib.py:146] step: 292000, eval_loss: 2.34789e-02
I0209 17:30:38.549546 22542570456896 run_lib.py:133] step: 292050, training_loss: 2.82091e-02
I0209 17:30:55.986166 22542570456896 run_lib.py:133] step: 292100, training_loss: 2.69466e-02
I0209 17:30:56.140504 22542570456896 run_lib.py:146] step: 292100, eval_loss: 2.74925e-02
I0209 17:31:13.818977 22542570456896 run_lib.py:133] step: 292150, training_loss: 3.06955e-02
I0209 17:31:31.288450 22542570456896 run_lib.py:133] step: 292200, training_loss: 2.90584e-02
I0209 17:31:31.446266 22542570456896 run_lib.py:146] step: 292200, eval_loss: 2.63792e-02
I0209 17:31:48.873631 22542570456896 run_lib.py:133] step: 292250, training_loss: 2.83001e-02
I0209 17:32:06.264024 22542570456896 run_lib.py:133] step: 292300, training_loss: 2.42257e-02
I0209 17:32:06.419515 22542570456896 run_lib.py:146] step: 292300, eval_loss: 2.67100e-02
I0209 17:32:24.024254 22542570456896 run_lib.py:133] step: 292350, training_loss: 2.27911e-02
I0209 17:32:41.512196 22542570456896 run_lib.py:133] step: 292400, training_loss: 3.58603e-02
I0209 17:32:41.669916 22542570456896 run_lib.py:146] step: 292400, eval_loss: 2.67060e-02
I0209 17:32:59.278985 22542570456896 run_lib.py:133] step: 292450, training_loss: 3.31563e-02
I0209 17:33:16.703920 22542570456896 run_lib.py:133] step: 292500, training_loss: 3.14929e-02
I0209 17:33:16.858082 22542570456896 run_lib.py:146] step: 292500, eval_loss: 2.94589e-02
I0209 17:33:34.472185 22542570456896 run_lib.py:133] step: 292550, training_loss: 3.10513e-02
I0209 17:33:51.896072 22542570456896 run_lib.py:133] step: 292600, training_loss: 3.02157e-02
I0209 17:33:52.057565 22542570456896 run_lib.py:146] step: 292600, eval_loss: 2.56199e-02
I0209 17:34:09.515539 22542570456896 run_lib.py:133] step: 292650, training_loss: 2.20827e-02
I0209 17:34:27.139691 22542570456896 run_lib.py:133] step: 292700, training_loss: 3.04754e-02
I0209 17:34:27.297221 22542570456896 run_lib.py:146] step: 292700, eval_loss: 2.73986e-02
I0209 17:34:44.728842 22542570456896 run_lib.py:133] step: 292750, training_loss: 2.52005e-02
I0209 17:35:02.250161 22542570456896 run_lib.py:133] step: 292800, training_loss: 2.56473e-02
I0209 17:35:02.406288 22542570456896 run_lib.py:146] step: 292800, eval_loss: 2.76903e-02
I0209 17:35:19.854589 22542570456896 run_lib.py:133] step: 292850, training_loss: 2.90337e-02
I0209 17:35:37.297399 22542570456896 run_lib.py:133] step: 292900, training_loss: 3.57619e-02
I0209 17:35:37.454566 22542570456896 run_lib.py:146] step: 292900, eval_loss: 2.76633e-02
I0209 17:35:55.073954 22542570456896 run_lib.py:133] step: 292950, training_loss: 2.63427e-02
I0209 17:36:12.528005 22542570456896 run_lib.py:133] step: 293000, training_loss: 2.38601e-02
I0209 17:36:12.680093 22542570456896 run_lib.py:146] step: 293000, eval_loss: 2.89837e-02
I0209 17:36:30.097321 22542570456896 run_lib.py:133] step: 293050, training_loss: 2.78268e-02
I0209 17:36:47.700696 22542570456896 run_lib.py:133] step: 293100, training_loss: 3.03135e-02
I0209 17:36:47.852450 22542570456896 run_lib.py:146] step: 293100, eval_loss: 2.84477e-02
I0209 17:37:05.267134 22542570456896 run_lib.py:133] step: 293150, training_loss: 2.44491e-02
I0209 17:37:22.728333 22542570456896 run_lib.py:133] step: 293200, training_loss: 3.21384e-02
I0209 17:37:22.894779 22542570456896 run_lib.py:146] step: 293200, eval_loss: 3.10394e-02
I0209 17:37:40.444065 22542570456896 run_lib.py:133] step: 293250, training_loss: 2.81101e-02
I0209 17:37:57.905188 22542570456896 run_lib.py:133] step: 293300, training_loss: 2.84076e-02
I0209 17:37:58.061636 22542570456896 run_lib.py:146] step: 293300, eval_loss: 2.47031e-02
I0209 17:38:15.531635 22542570456896 run_lib.py:133] step: 293350, training_loss: 2.71454e-02
I0209 17:38:32.903895 22542570456896 run_lib.py:133] step: 293400, training_loss: 2.71829e-02
I0209 17:38:33.056015 22542570456896 run_lib.py:146] step: 293400, eval_loss: 2.69758e-02
I0209 17:38:50.677512 22542570456896 run_lib.py:133] step: 293450, training_loss: 2.96920e-02
I0209 17:39:08.172366 22542570456896 run_lib.py:133] step: 293500, training_loss: 3.52892e-02
I0209 17:39:08.323907 22542570456896 run_lib.py:146] step: 293500, eval_loss: 3.00878e-02
I0209 17:39:25.788336 22542570456896 run_lib.py:133] step: 293550, training_loss: 2.33405e-02
I0209 17:39:43.215276 22542570456896 run_lib.py:133] step: 293600, training_loss: 3.40300e-02
I0209 17:39:43.370440 22542570456896 run_lib.py:146] step: 293600, eval_loss: 3.37899e-02
I0209 17:40:00.965691 22542570456896 run_lib.py:133] step: 293650, training_loss: 2.85228e-02
I0209 17:40:18.349294 22542570456896 run_lib.py:133] step: 293700, training_loss: 2.84489e-02
I0209 17:40:18.516556 22542570456896 run_lib.py:146] step: 293700, eval_loss: 2.63685e-02
I0209 17:40:36.137933 22542570456896 run_lib.py:133] step: 293750, training_loss: 3.18217e-02
I0209 17:40:53.573302 22542570456896 run_lib.py:133] step: 293800, training_loss: 2.84626e-02
I0209 17:40:53.730169 22542570456896 run_lib.py:146] step: 293800, eval_loss: 2.23010e-02
I0209 17:41:11.314326 22542570456896 run_lib.py:133] step: 293850, training_loss: 2.39718e-02
I0209 17:41:28.701753 22542570456896 run_lib.py:133] step: 293900, training_loss: 3.03276e-02
I0209 17:41:28.857418 22542570456896 run_lib.py:146] step: 293900, eval_loss: 2.40454e-02
I0209 17:41:46.421237 22542570456896 run_lib.py:133] step: 293950, training_loss: 3.93545e-02
I0209 17:42:03.814109 22542570456896 run_lib.py:133] step: 294000, training_loss: 3.19422e-02
I0209 17:42:03.966427 22542570456896 run_lib.py:146] step: 294000, eval_loss: 2.55738e-02
I0209 17:42:21.329534 22542570456896 run_lib.py:133] step: 294050, training_loss: 3.12984e-02
I0209 17:42:38.786856 22542570456896 run_lib.py:133] step: 294100, training_loss: 4.10838e-02
I0209 17:42:38.941401 22542570456896 run_lib.py:146] step: 294100, eval_loss: 2.42776e-02
I0209 17:42:56.237402 22542570456896 run_lib.py:133] step: 294150, training_loss: 3.13099e-02
I0209 17:43:13.618844 22542570456896 run_lib.py:133] step: 294200, training_loss: 3.11273e-02
I0209 17:43:13.772317 22542570456896 run_lib.py:146] step: 294200, eval_loss: 3.00543e-02
I0209 17:43:31.392038 22542570456896 run_lib.py:133] step: 294250, training_loss: 3.01258e-02
I0209 17:43:48.913956 22542570456896 run_lib.py:133] step: 294300, training_loss: 2.56088e-02
I0209 17:43:49.079344 22542570456896 run_lib.py:146] step: 294300, eval_loss: 2.27925e-02
I0209 17:44:06.679825 22542570456896 run_lib.py:133] step: 294350, training_loss: 1.92775e-02
I0209 17:44:24.111270 22542570456896 run_lib.py:133] step: 294400, training_loss: 2.37181e-02
I0209 17:44:24.263990 22542570456896 run_lib.py:146] step: 294400, eval_loss: 2.31433e-02
I0209 17:44:41.693149 22542570456896 run_lib.py:133] step: 294450, training_loss: 3.08904e-02
I0209 17:44:59.305676 22542570456896 run_lib.py:133] step: 294500, training_loss: 2.39028e-02
I0209 17:44:59.459323 22542570456896 run_lib.py:146] step: 294500, eval_loss: 2.84855e-02
I0209 17:45:16.898378 22542570456896 run_lib.py:133] step: 294550, training_loss: 3.04050e-02
I0209 17:45:34.354205 22542570456896 run_lib.py:133] step: 294600, training_loss: 3.18713e-02
I0209 17:45:34.532371 22542570456896 run_lib.py:146] step: 294600, eval_loss: 2.99618e-02
I0209 17:45:51.966718 22542570456896 run_lib.py:133] step: 294650, training_loss: 3.58648e-02
I0209 17:46:09.604102 22542570456896 run_lib.py:133] step: 294700, training_loss: 2.48992e-02
I0209 17:46:09.760532 22542570456896 run_lib.py:146] step: 294700, eval_loss: 2.74748e-02
I0209 17:46:27.165254 22542570456896 run_lib.py:133] step: 294750, training_loss: 2.77215e-02
I0209 17:46:44.636609 22542570456896 run_lib.py:133] step: 294800, training_loss: 2.85258e-02
I0209 17:46:44.792664 22542570456896 run_lib.py:146] step: 294800, eval_loss: 3.27795e-02
I0209 17:47:02.175254 22542570456896 run_lib.py:133] step: 294850, training_loss: 3.01016e-02
I0209 17:47:19.671668 22542570456896 run_lib.py:133] step: 294900, training_loss: 4.01896e-02
I0209 17:47:19.834607 22542570456896 run_lib.py:146] step: 294900, eval_loss: 2.74493e-02
I0209 17:47:37.443348 22542570456896 run_lib.py:133] step: 294950, training_loss: 2.13742e-02
I0209 17:47:54.924889 22542570456896 run_lib.py:133] step: 295000, training_loss: 2.47368e-02
I0209 17:47:55.081384 22542570456896 run_lib.py:146] step: 295000, eval_loss: 2.97385e-02
I0209 17:48:12.468702 22542570456896 run_lib.py:133] step: 295050, training_loss: 2.69670e-02
I0209 17:48:29.888147 22542570456896 run_lib.py:133] step: 295100, training_loss: 2.83022e-02
I0209 17:48:30.052023 22542570456896 run_lib.py:146] step: 295100, eval_loss: 2.56717e-02
I0209 17:48:47.647414 22542570456896 run_lib.py:133] step: 295150, training_loss: 2.51156e-02
I0209 17:49:05.127768 22542570456896 run_lib.py:133] step: 295200, training_loss: 2.91560e-02
I0209 17:49:05.284569 22542570456896 run_lib.py:146] step: 295200, eval_loss: 2.87224e-02
I0209 17:49:22.905631 22542570456896 run_lib.py:133] step: 295250, training_loss: 2.84401e-02
I0209 17:49:40.296124 22542570456896 run_lib.py:133] step: 295300, training_loss: 3.51203e-02
I0209 17:49:40.451272 22542570456896 run_lib.py:146] step: 295300, eval_loss: 2.69627e-02
I0209 17:49:57.977939 22542570456896 run_lib.py:133] step: 295350, training_loss: 2.65202e-02
I0209 17:50:15.389765 22542570456896 run_lib.py:133] step: 295400, training_loss: 2.97073e-02
I0209 17:50:15.543582 22542570456896 run_lib.py:146] step: 295400, eval_loss: 2.72737e-02
I0209 17:50:32.988430 22542570456896 run_lib.py:133] step: 295450, training_loss: 2.66709e-02
I0209 17:50:50.579900 22542570456896 run_lib.py:133] step: 295500, training_loss: 3.06273e-02
I0209 17:50:50.734370 22542570456896 run_lib.py:146] step: 295500, eval_loss: 2.90361e-02
I0209 17:51:08.152225 22542570456896 run_lib.py:133] step: 295550, training_loss: 3.94636e-02
I0209 17:51:25.722372 22542570456896 run_lib.py:133] step: 295600, training_loss: 2.82304e-02
I0209 17:51:25.879663 22542570456896 run_lib.py:146] step: 295600, eval_loss: 3.53848e-02
I0209 17:51:43.265328 22542570456896 run_lib.py:133] step: 295650, training_loss: 2.33159e-02
I0209 17:52:00.715243 22542570456896 run_lib.py:133] step: 295700, training_loss: 2.28523e-02
I0209 17:52:00.871975 22542570456896 run_lib.py:146] step: 295700, eval_loss: 3.32182e-02
I0209 17:52:18.470410 22542570456896 run_lib.py:133] step: 295750, training_loss: 3.17713e-02
I0209 17:52:35.902491 22542570456896 run_lib.py:133] step: 295800, training_loss: 3.05613e-02
I0209 17:52:36.057399 22542570456896 run_lib.py:146] step: 295800, eval_loss: 3.36992e-02
I0209 17:52:53.472203 22542570456896 run_lib.py:133] step: 295850, training_loss: 2.63053e-02
I0209 17:53:11.084206 22542570456896 run_lib.py:133] step: 295900, training_loss: 2.80495e-02
I0209 17:53:11.235368 22542570456896 run_lib.py:146] step: 295900, eval_loss: 2.97691e-02
I0209 17:53:28.662462 22542570456896 run_lib.py:133] step: 295950, training_loss: 3.07819e-02
I0209 17:53:46.137282 22542570456896 run_lib.py:133] step: 296000, training_loss: 3.05483e-02
I0209 17:53:46.503356 22542570456896 run_lib.py:146] step: 296000, eval_loss: 2.06963e-02
I0209 17:54:03.974810 22542570456896 run_lib.py:133] step: 296050, training_loss: 3.50962e-02
I0209 17:54:21.425383 22542570456896 run_lib.py:133] step: 296100, training_loss: 3.37824e-02
I0209 17:54:21.578710 22542570456896 run_lib.py:146] step: 296100, eval_loss: 2.90624e-02
I0209 17:54:39.025589 22542570456896 run_lib.py:133] step: 296150, training_loss: 2.98080e-02
I0209 17:54:56.468026 22542570456896 run_lib.py:133] step: 296200, training_loss: 3.52637e-02
I0209 17:54:56.623503 22542570456896 run_lib.py:146] step: 296200, eval_loss: 2.84934e-02
I0209 17:55:14.244352 22542570456896 run_lib.py:133] step: 296250, training_loss: 2.34344e-02
I0209 17:55:31.773937 22542570456896 run_lib.py:133] step: 296300, training_loss: 2.92999e-02
I0209 17:55:31.926245 22542570456896 run_lib.py:146] step: 296300, eval_loss: 2.66620e-02
I0209 17:55:49.328205 22542570456896 run_lib.py:133] step: 296350, training_loss: 2.14775e-02
I0209 17:56:06.754593 22542570456896 run_lib.py:133] step: 296400, training_loss: 2.84872e-02
I0209 17:56:06.911379 22542570456896 run_lib.py:146] step: 296400, eval_loss: 2.55678e-02
I0209 17:56:24.516064 22542570456896 run_lib.py:133] step: 296450, training_loss: 2.38477e-02
I0209 17:56:42.025566 22542570456896 run_lib.py:133] step: 296500, training_loss: 3.31068e-02
I0209 17:56:42.204332 22542570456896 run_lib.py:146] step: 296500, eval_loss: 2.96382e-02
I0209 17:56:59.653884 22542570456896 run_lib.py:133] step: 296550, training_loss: 3.02383e-02
I0209 17:57:17.075643 22542570456896 run_lib.py:133] step: 296600, training_loss: 3.28020e-02
I0209 17:57:17.231188 22542570456896 run_lib.py:146] step: 296600, eval_loss: 2.37749e-02
I0209 17:57:34.829674 22542570456896 run_lib.py:133] step: 296650, training_loss: 2.32260e-02
I0209 17:57:52.199337 22542570456896 run_lib.py:133] step: 296700, training_loss: 2.24263e-02
I0209 17:57:52.353176 22542570456896 run_lib.py:146] step: 296700, eval_loss: 2.69138e-02
I0209 17:58:09.906019 22542570456896 run_lib.py:133] step: 296750, training_loss: 3.33385e-02
I0209 17:58:27.312034 22542570456896 run_lib.py:133] step: 296800, training_loss: 2.39830e-02
I0209 17:58:27.464613 22542570456896 run_lib.py:146] step: 296800, eval_loss: 3.16570e-02
I0209 17:58:45.139655 22542570456896 run_lib.py:133] step: 296850, training_loss: 2.45176e-02
I0209 17:59:02.532611 22542570456896 run_lib.py:133] step: 296900, training_loss: 2.98412e-02
I0209 17:59:02.687541 22542570456896 run_lib.py:146] step: 296900, eval_loss: 2.71613e-02
I0209 17:59:20.116218 22542570456896 run_lib.py:133] step: 296950, training_loss: 2.13597e-02
I0209 17:59:37.686484 22542570456896 run_lib.py:133] step: 297000, training_loss: 2.75546e-02
I0209 17:59:37.849626 22542570456896 run_lib.py:146] step: 297000, eval_loss: 2.35282e-02
I0209 17:59:55.260661 22542570456896 run_lib.py:133] step: 297050, training_loss: 3.57583e-02
I0209 18:00:12.855457 22542570456896 run_lib.py:133] step: 297100, training_loss: 3.11949e-02
I0209 18:00:13.011477 22542570456896 run_lib.py:146] step: 297100, eval_loss: 2.88978e-02
I0209 18:00:30.449894 22542570456896 run_lib.py:133] step: 297150, training_loss: 2.66823e-02
I0209 18:00:47.856919 22542570456896 run_lib.py:133] step: 297200, training_loss: 2.30189e-02
I0209 18:00:48.012331 22542570456896 run_lib.py:146] step: 297200, eval_loss: 2.40849e-02
I0209 18:01:05.613743 22542570456896 run_lib.py:133] step: 297250, training_loss: 3.30139e-02
I0209 18:01:23.031016 22542570456896 run_lib.py:133] step: 297300, training_loss: 2.35908e-02
I0209 18:01:23.183309 22542570456896 run_lib.py:146] step: 297300, eval_loss: 2.80162e-02
I0209 18:01:40.606365 22542570456896 run_lib.py:133] step: 297350, training_loss: 2.84315e-02
I0209 18:01:58.040869 22542570456896 run_lib.py:133] step: 297400, training_loss: 2.75957e-02
I0209 18:01:58.208365 22542570456896 run_lib.py:146] step: 297400, eval_loss: 2.67606e-02
I0209 18:02:15.866795 22542570456896 run_lib.py:133] step: 297450, training_loss: 3.13111e-02
I0209 18:02:33.280982 22542570456896 run_lib.py:133] step: 297500, training_loss: 2.74634e-02
I0209 18:02:33.438592 22542570456896 run_lib.py:146] step: 297500, eval_loss: 2.80637e-02
I0209 18:02:50.901210 22542570456896 run_lib.py:133] step: 297550, training_loss: 3.12706e-02
I0209 18:03:08.278362 22542570456896 run_lib.py:133] step: 297600, training_loss: 2.30637e-02
I0209 18:03:08.442136 22542570456896 run_lib.py:146] step: 297600, eval_loss: 2.72135e-02
I0209 18:03:25.879539 22542570456896 run_lib.py:133] step: 297650, training_loss: 2.74423e-02
I0209 18:03:43.315936 22542570456896 run_lib.py:133] step: 297700, training_loss: 2.94454e-02
I0209 18:03:43.474106 22542570456896 run_lib.py:146] step: 297700, eval_loss: 3.10656e-02
I0209 18:04:01.130745 22542570456896 run_lib.py:133] step: 297750, training_loss: 2.88376e-02
I0209 18:04:18.631578 22542570456896 run_lib.py:133] step: 297800, training_loss: 2.86840e-02
I0209 18:04:18.782347 22542570456896 run_lib.py:146] step: 297800, eval_loss: 2.68345e-02
I0209 18:04:36.183424 22542570456896 run_lib.py:133] step: 297850, training_loss: 2.67787e-02
I0209 18:04:53.589887 22542570456896 run_lib.py:133] step: 297900, training_loss: 2.19605e-02
I0209 18:04:53.765078 22542570456896 run_lib.py:146] step: 297900, eval_loss: 3.13177e-02
I0209 18:05:11.353773 22542570456896 run_lib.py:133] step: 297950, training_loss: 2.74019e-02
I0209 18:05:28.814209 22542570456896 run_lib.py:133] step: 298000, training_loss: 2.24642e-02
I0209 18:05:28.970540 22542570456896 run_lib.py:146] step: 298000, eval_loss: 3.06425e-02
I0209 18:05:46.591164 22542570456896 run_lib.py:133] step: 298050, training_loss: 2.83044e-02
I0209 18:06:04.044246 22542570456896 run_lib.py:133] step: 298100, training_loss: 3.20020e-02
I0209 18:06:04.199257 22542570456896 run_lib.py:146] step: 298100, eval_loss: 2.89330e-02
I0209 18:06:21.742259 22542570456896 run_lib.py:133] step: 298150, training_loss: 2.64479e-02
I0209 18:06:39.210804 22542570456896 run_lib.py:133] step: 298200, training_loss: 3.10171e-02
I0209 18:06:39.365175 22542570456896 run_lib.py:146] step: 298200, eval_loss: 3.02154e-02
I0209 18:06:56.959613 22542570456896 run_lib.py:133] step: 298250, training_loss: 2.91642e-02
I0209 18:07:14.335276 22542570456896 run_lib.py:133] step: 298300, training_loss: 2.84545e-02
I0209 18:07:14.490302 22542570456896 run_lib.py:146] step: 298300, eval_loss: 3.03112e-02
I0209 18:07:31.913007 22542570456896 run_lib.py:133] step: 298350, training_loss: 1.88127e-02
I0209 18:07:49.504092 22542570456896 run_lib.py:133] step: 298400, training_loss: 2.65136e-02
I0209 18:07:49.663594 22542570456896 run_lib.py:146] step: 298400, eval_loss: 2.55336e-02
I0209 18:08:07.070551 22542570456896 run_lib.py:133] step: 298450, training_loss: 3.39061e-02
I0209 18:08:24.523394 22542570456896 run_lib.py:133] step: 298500, training_loss: 2.73222e-02
I0209 18:08:24.679587 22542570456896 run_lib.py:146] step: 298500, eval_loss: 3.26689e-02
I0209 18:08:42.288080 22542570456896 run_lib.py:133] step: 298550, training_loss: 2.35483e-02
I0209 18:08:59.907684 22542570456896 run_lib.py:133] step: 298600, training_loss: 2.30056e-02
I0209 18:09:00.062299 22542570456896 run_lib.py:146] step: 298600, eval_loss: 2.68118e-02
I0209 18:09:17.503992 22542570456896 run_lib.py:133] step: 298650, training_loss: 3.32586e-02
I0209 18:09:34.904317 22542570456896 run_lib.py:133] step: 298700, training_loss: 3.12540e-02
I0209 18:09:35.063337 22542570456896 run_lib.py:146] step: 298700, eval_loss: 2.98440e-02
I0209 18:09:52.469103 22542570456896 run_lib.py:133] step: 298750, training_loss: 2.98960e-02
I0209 18:10:10.101749 22542570456896 run_lib.py:133] step: 298800, training_loss: 2.89142e-02
I0209 18:10:10.272166 22542570456896 run_lib.py:146] step: 298800, eval_loss: 3.18434e-02
I0209 18:10:27.712012 22542570456896 run_lib.py:133] step: 298850, training_loss: 3.02745e-02
I0209 18:10:45.115938 22542570456896 run_lib.py:133] step: 298900, training_loss: 2.49906e-02
I0209 18:10:45.274497 22542570456896 run_lib.py:146] step: 298900, eval_loss: 2.65847e-02
I0209 18:11:02.708228 22542570456896 run_lib.py:133] step: 298950, training_loss: 2.97696e-02
I0209 18:11:20.309386 22542570456896 run_lib.py:133] step: 299000, training_loss: 2.48557e-02
I0209 18:11:20.464275 22542570456896 run_lib.py:146] step: 299000, eval_loss: 2.81363e-02
I0209 18:11:37.868353 22542570456896 run_lib.py:133] step: 299050, training_loss: 2.55062e-02
I0209 18:11:55.376796 22542570456896 run_lib.py:133] step: 299100, training_loss: 2.77776e-02
I0209 18:11:55.532616 22542570456896 run_lib.py:146] step: 299100, eval_loss: 3.11011e-02
I0209 18:12:12.962376 22542570456896 run_lib.py:133] step: 299150, training_loss: 3.13409e-02
I0209 18:12:30.371002 22542570456896 run_lib.py:133] step: 299200, training_loss: 3.46097e-02
I0209 18:12:30.523445 22542570456896 run_lib.py:146] step: 299200, eval_loss: 2.98244e-02
I0209 18:12:48.125914 22542570456896 run_lib.py:133] step: 299250, training_loss: 2.97280e-02
I0209 18:13:05.630317 22542570456896 run_lib.py:133] step: 299300, training_loss: 2.92929e-02
I0209 18:13:05.793507 22542570456896 run_lib.py:146] step: 299300, eval_loss: 3.25077e-02
I0209 18:13:23.222046 22542570456896 run_lib.py:133] step: 299350, training_loss: 2.20835e-02
I0209 18:13:40.717933 22542570456896 run_lib.py:133] step: 299400, training_loss: 3.32830e-02
I0209 18:13:40.874520 22542570456896 run_lib.py:146] step: 299400, eval_loss: 2.67560e-02
I0209 18:13:58.467471 22542570456896 run_lib.py:133] step: 299450, training_loss: 2.52017e-02
I0209 18:14:15.891440 22542570456896 run_lib.py:133] step: 299500, training_loss: 2.29773e-02
I0209 18:14:16.056526 22542570456896 run_lib.py:146] step: 299500, eval_loss: 2.65728e-02
I0209 18:14:33.634461 22542570456896 run_lib.py:133] step: 299550, training_loss: 3.46796e-02
I0209 18:14:51.080570 22542570456896 run_lib.py:133] step: 299600, training_loss: 4.14080e-02
I0209 18:14:51.235486 22542570456896 run_lib.py:146] step: 299600, eval_loss: 3.05110e-02
I0209 18:15:08.925919 22542570456896 run_lib.py:133] step: 299650, training_loss: 3.02300e-02
I0209 18:15:26.349396 22542570456896 run_lib.py:133] step: 299700, training_loss: 2.67973e-02
I0209 18:15:26.502449 22542570456896 run_lib.py:146] step: 299700, eval_loss: 2.70377e-02
I0209 18:15:43.915727 22542570456896 run_lib.py:133] step: 299750, training_loss: 3.44931e-02
I0209 18:16:01.483498 22542570456896 run_lib.py:133] step: 299800, training_loss: 2.41435e-02
I0209 18:16:01.644557 22542570456896 run_lib.py:146] step: 299800, eval_loss: 2.47450e-02
I0209 18:16:19.062565 22542570456896 run_lib.py:133] step: 299850, training_loss: 3.11352e-02
I0209 18:16:36.601283 22542570456896 run_lib.py:133] step: 299900, training_loss: 2.88307e-02
I0209 18:16:36.772215 22542570456896 run_lib.py:146] step: 299900, eval_loss: 2.40983e-02
I0209 18:16:54.204200 22542570456896 run_lib.py:133] step: 299950, training_loss: 3.01916e-02
I0209 18:17:11.673012 22542570456896 run_lib.py:133] step: 300000, training_loss: 2.84761e-02
I0209 18:17:12.371868 22542570456896 run_lib.py:146] step: 300000, eval_loss: 3.12248e-02
I0209 18:17:32.407305 22542570456896 run_lib.py:133] step: 300050, training_loss: 2.48802e-02
I0209 18:17:50.023050 22542570456896 run_lib.py:133] step: 300100, training_loss: 3.60631e-02
I0209 18:17:50.179375 22542570456896 run_lib.py:146] step: 300100, eval_loss: 3.69533e-02
I0209 18:18:07.592521 22542570456896 run_lib.py:133] step: 300150, training_loss: 2.81857e-02
I0209 18:18:25.216341 22542570456896 run_lib.py:133] step: 300200, training_loss: 2.82985e-02
I0209 18:18:25.370479 22542570456896 run_lib.py:146] step: 300200, eval_loss: 2.57809e-02
I0209 18:18:42.836528 22542570456896 run_lib.py:133] step: 300250, training_loss: 3.34849e-02
I0209 18:19:00.250790 22542570456896 run_lib.py:133] step: 300300, training_loss: 2.41947e-02
I0209 18:19:00.407390 22542570456896 run_lib.py:146] step: 300300, eval_loss: 2.75400e-02
I0209 18:19:18.007169 22542570456896 run_lib.py:133] step: 300350, training_loss: 2.79216e-02
I0209 18:19:35.431237 22542570456896 run_lib.py:133] step: 300400, training_loss: 2.67521e-02
I0209 18:19:35.593657 22542570456896 run_lib.py:146] step: 300400, eval_loss: 3.21027e-02
I0209 18:19:53.140127 22542570456896 run_lib.py:133] step: 300450, training_loss: 2.88702e-02
I0209 18:20:10.614277 22542570456896 run_lib.py:133] step: 300500, training_loss: 3.34348e-02
I0209 18:20:10.778393 22542570456896 run_lib.py:146] step: 300500, eval_loss: 2.20850e-02
I0209 18:20:28.230013 22542570456896 run_lib.py:133] step: 300550, training_loss: 2.95289e-02
I0209 18:20:45.816174 22542570456896 run_lib.py:133] step: 300600, training_loss: 2.55520e-02
I0209 18:20:45.970564 22542570456896 run_lib.py:146] step: 300600, eval_loss: 3.15418e-02
I0209 18:21:03.349335 22542570456896 run_lib.py:133] step: 300650, training_loss: 2.95663e-02
I0209 18:21:20.738857 22542570456896 run_lib.py:133] step: 300700, training_loss: 2.43537e-02
I0209 18:21:20.890922 22542570456896 run_lib.py:146] step: 300700, eval_loss: 2.97315e-02
I0209 18:21:38.336304 22542570456896 run_lib.py:133] step: 300750, training_loss: 2.62511e-02
I0209 18:21:55.964107 22542570456896 run_lib.py:133] step: 300800, training_loss: 2.39784e-02
I0209 18:21:56.137304 22542570456896 run_lib.py:146] step: 300800, eval_loss: 3.09719e-02
I0209 18:22:13.557521 22542570456896 run_lib.py:133] step: 300850, training_loss: 2.06338e-02
I0209 18:22:31.071923 22542570456896 run_lib.py:133] step: 300900, training_loss: 2.71976e-02
I0209 18:22:31.230510 22542570456896 run_lib.py:146] step: 300900, eval_loss: 3.51341e-02
I0209 18:22:48.693196 22542570456896 run_lib.py:133] step: 300950, training_loss: 3.46130e-02
I0209 18:23:06.099872 22542570456896 run_lib.py:133] step: 301000, training_loss: 3.06323e-02
I0209 18:23:06.265193 22542570456896 run_lib.py:146] step: 301000, eval_loss: 3.54477e-02
I0209 18:23:23.854206 22542570456896 run_lib.py:133] step: 301050, training_loss: 2.97293e-02
I0209 18:23:41.406596 22542570456896 run_lib.py:133] step: 301100, training_loss: 2.68338e-02
I0209 18:23:41.561140 22542570456896 run_lib.py:146] step: 301100, eval_loss: 3.13901e-02
I0209 18:23:58.999974 22542570456896 run_lib.py:133] step: 301150, training_loss: 2.58366e-02
I0209 18:24:16.421935 22542570456896 run_lib.py:133] step: 301200, training_loss: 3.10170e-02
I0209 18:24:16.575290 22542570456896 run_lib.py:146] step: 301200, eval_loss: 3.14283e-02
I0209 18:24:34.134945 22542570456896 run_lib.py:133] step: 301250, training_loss: 2.56818e-02
I0209 18:24:51.520582 22542570456896 run_lib.py:133] step: 301300, training_loss: 2.43659e-02
I0209 18:24:51.695300 22542570456896 run_lib.py:146] step: 301300, eval_loss: 2.46787e-02
I0209 18:25:09.298572 22542570456896 run_lib.py:133] step: 301350, training_loss: 3.39762e-02
I0209 18:25:26.691818 22542570456896 run_lib.py:133] step: 301400, training_loss: 2.55873e-02
I0209 18:25:26.846590 22542570456896 run_lib.py:146] step: 301400, eval_loss: 3.11586e-02
I0209 18:25:44.485075 22542570456896 run_lib.py:133] step: 301450, training_loss: 2.66859e-02
I0209 18:26:01.851600 22542570456896 run_lib.py:133] step: 301500, training_loss: 3.21980e-02
I0209 18:26:02.013585 22542570456896 run_lib.py:146] step: 301500, eval_loss: 2.45321e-02
I0209 18:26:19.437280 22542570456896 run_lib.py:133] step: 301550, training_loss: 2.38395e-02
I0209 18:26:37.036659 22542570456896 run_lib.py:133] step: 301600, training_loss: 2.26256e-02
I0209 18:26:37.197131 22542570456896 run_lib.py:146] step: 301600, eval_loss: 2.72270e-02
I0209 18:26:54.623448 22542570456896 run_lib.py:133] step: 301650, training_loss: 2.82123e-02
I0209 18:27:12.217745 22542570456896 run_lib.py:133] step: 301700, training_loss: 2.72382e-02
I0209 18:27:12.373413 22542570456896 run_lib.py:146] step: 301700, eval_loss: 3.05995e-02
I0209 18:27:29.762502 22542570456896 run_lib.py:133] step: 301750, training_loss: 2.67783e-02
I0209 18:27:47.175766 22542570456896 run_lib.py:133] step: 301800, training_loss: 3.24934e-02
I0209 18:27:47.335574 22542570456896 run_lib.py:146] step: 301800, eval_loss: 3.22340e-02
I0209 18:28:04.907754 22542570456896 run_lib.py:133] step: 301850, training_loss: 2.60430e-02
I0209 18:28:22.368301 22542570456896 run_lib.py:133] step: 301900, training_loss: 2.71754e-02
I0209 18:28:22.524543 22542570456896 run_lib.py:146] step: 301900, eval_loss: 3.77029e-02
I0209 18:28:39.978864 22542570456896 run_lib.py:133] step: 301950, training_loss: 2.49172e-02
I0209 18:28:57.616925 22542570456896 run_lib.py:133] step: 302000, training_loss: 3.04213e-02
I0209 18:28:57.770569 22542570456896 run_lib.py:146] step: 302000, eval_loss: 2.67609e-02
I0209 18:29:15.213662 22542570456896 run_lib.py:133] step: 302050, training_loss: 2.52617e-02
I0209 18:29:32.626100 22542570456896 run_lib.py:133] step: 302100, training_loss: 2.51937e-02
I0209 18:29:32.777410 22542570456896 run_lib.py:146] step: 302100, eval_loss: 2.99932e-02
I0209 18:29:50.279188 22542570456896 run_lib.py:133] step: 302150, training_loss: 2.64407e-02
I0209 18:30:07.738021 22542570456896 run_lib.py:133] step: 302200, training_loss: 3.58088e-02
I0209 18:30:07.899456 22542570456896 run_lib.py:146] step: 302200, eval_loss: 2.78947e-02
I0209 18:30:25.343514 22542570456896 run_lib.py:133] step: 302250, training_loss: 3.24876e-02
I0209 18:30:42.780194 22542570456896 run_lib.py:133] step: 302300, training_loss: 3.79971e-02
I0209 18:30:42.941788 22542570456896 run_lib.py:146] step: 302300, eval_loss: 2.82462e-02
I0209 18:31:00.530767 22542570456896 run_lib.py:133] step: 302350, training_loss: 2.97380e-02
I0209 18:31:17.989306 22542570456896 run_lib.py:133] step: 302400, training_loss: 2.67514e-02
I0209 18:31:18.160330 22542570456896 run_lib.py:146] step: 302400, eval_loss: 3.10995e-02
I0209 18:31:35.567417 22542570456896 run_lib.py:133] step: 302450, training_loss: 3.25454e-02
I0209 18:31:53.001930 22542570456896 run_lib.py:133] step: 302500, training_loss: 2.71011e-02
I0209 18:31:53.159592 22542570456896 run_lib.py:146] step: 302500, eval_loss: 3.04837e-02
I0209 18:32:10.763209 22542570456896 run_lib.py:133] step: 302550, training_loss: 2.65785e-02
I0209 18:32:28.214416 22542570456896 run_lib.py:133] step: 302600, training_loss: 2.34354e-02
I0209 18:32:28.364647 22542570456896 run_lib.py:146] step: 302600, eval_loss: 2.34544e-02
I0209 18:32:45.930996 22542570456896 run_lib.py:133] step: 302650, training_loss: 2.85056e-02
I0209 18:33:03.387688 22542570456896 run_lib.py:133] step: 302700, training_loss: 2.65964e-02
I0209 18:33:03.565324 22542570456896 run_lib.py:146] step: 302700, eval_loss: 3.30196e-02
I0209 18:33:21.143439 22542570456896 run_lib.py:133] step: 302750, training_loss: 2.74746e-02
I0209 18:33:38.601202 22542570456896 run_lib.py:133] step: 302800, training_loss: 2.99214e-02
I0209 18:33:38.753397 22542570456896 run_lib.py:146] step: 302800, eval_loss: 3.30666e-02
I0209 18:33:56.314321 22542570456896 run_lib.py:133] step: 302850, training_loss: 2.92130e-02
I0209 18:34:13.760654 22542570456896 run_lib.py:133] step: 302900, training_loss: 2.26911e-02
I0209 18:34:13.916103 22542570456896 run_lib.py:146] step: 302900, eval_loss: 2.84912e-02
I0209 18:34:31.319319 22542570456896 run_lib.py:133] step: 302950, training_loss: 2.37687e-02
I0209 18:34:48.903898 22542570456896 run_lib.py:133] step: 303000, training_loss: 2.40864e-02
I0209 18:34:49.063043 22542570456896 run_lib.py:146] step: 303000, eval_loss: 3.12138e-02
I0209 18:35:06.564585 22542570456896 run_lib.py:133] step: 303050, training_loss: 2.65910e-02
I0209 18:35:23.974689 22542570456896 run_lib.py:133] step: 303100, training_loss: 2.91853e-02
I0209 18:35:24.128332 22542570456896 run_lib.py:146] step: 303100, eval_loss: 2.72142e-02
I0209 18:35:41.735454 22542570456896 run_lib.py:133] step: 303150, training_loss: 2.93276e-02
I0209 18:35:59.157835 22542570456896 run_lib.py:133] step: 303200, training_loss: 2.77931e-02
I0209 18:35:59.325637 22542570456896 run_lib.py:146] step: 303200, eval_loss: 3.32037e-02
I0209 18:36:16.926717 22542570456896 run_lib.py:133] step: 303250, training_loss: 2.63810e-02
I0209 18:36:34.415932 22542570456896 run_lib.py:133] step: 303300, training_loss: 2.71351e-02
I0209 18:36:34.571520 22542570456896 run_lib.py:146] step: 303300, eval_loss: 2.94473e-02
I0209 18:36:51.983469 22542570456896 run_lib.py:133] step: 303350, training_loss: 2.91053e-02
I0209 18:37:09.572818 22542570456896 run_lib.py:133] step: 303400, training_loss: 2.49784e-02
I0209 18:37:09.731606 22542570456896 run_lib.py:146] step: 303400, eval_loss: 3.71081e-02
I0209 18:37:27.156247 22542570456896 run_lib.py:133] step: 303450, training_loss: 2.78853e-02
I0209 18:37:44.551850 22542570456896 run_lib.py:133] step: 303500, training_loss: 2.63161e-02
I0209 18:37:44.703607 22542570456896 run_lib.py:146] step: 303500, eval_loss: 3.16182e-02
I0209 18:38:02.076494 22542570456896 run_lib.py:133] step: 303550, training_loss: 2.67710e-02
I0209 18:38:19.716931 22542570456896 run_lib.py:133] step: 303600, training_loss: 2.69347e-02
I0209 18:38:19.888575 22542570456896 run_lib.py:146] step: 303600, eval_loss: 3.20436e-02
I0209 18:38:37.328040 22542570456896 run_lib.py:133] step: 303650, training_loss: 2.53386e-02
I0209 18:38:54.851488 22542570456896 run_lib.py:133] step: 303700, training_loss: 2.07779e-02
I0209 18:38:55.008880 22542570456896 run_lib.py:146] step: 303700, eval_loss: 2.99519e-02
I0209 18:39:12.434915 22542570456896 run_lib.py:133] step: 303750, training_loss: 3.16244e-02
I0209 18:39:29.855899 22542570456896 run_lib.py:133] step: 303800, training_loss: 2.70356e-02
I0209 18:39:30.011453 22542570456896 run_lib.py:146] step: 303800, eval_loss: 2.45950e-02
I0209 18:39:47.560114 22542570456896 run_lib.py:133] step: 303850, training_loss: 3.10977e-02
I0209 18:40:05.116322 22542570456896 run_lib.py:133] step: 303900, training_loss: 3.09346e-02
I0209 18:40:05.273653 22542570456896 run_lib.py:146] step: 303900, eval_loss: 2.75169e-02
I0209 18:40:22.729243 22542570456896 run_lib.py:133] step: 303950, training_loss: 2.58573e-02
I0209 18:40:40.124801 22542570456896 run_lib.py:133] step: 304000, training_loss: 3.16633e-02
I0209 18:40:40.276432 22542570456896 run_lib.py:146] step: 304000, eval_loss: 3.59039e-02
I0209 18:40:57.848584 22542570456896 run_lib.py:133] step: 304050, training_loss: 2.32989e-02
I0209 18:41:15.233095 22542570456896 run_lib.py:133] step: 304100, training_loss: 2.97897e-02
I0209 18:41:15.403549 22542570456896 run_lib.py:146] step: 304100, eval_loss: 3.23454e-02
I0209 18:41:33.007268 22542570456896 run_lib.py:133] step: 304150, training_loss: 2.61857e-02
I0209 18:41:50.436772 22542570456896 run_lib.py:133] step: 304200, training_loss: 2.64751e-02
I0209 18:41:50.594986 22542570456896 run_lib.py:146] step: 304200, eval_loss: 2.87239e-02
I0209 18:42:08.172369 22542570456896 run_lib.py:133] step: 304250, training_loss: 3.02846e-02
I0209 18:42:25.621493 22542570456896 run_lib.py:133] step: 304300, training_loss: 3.97379e-02
I0209 18:42:25.782361 22542570456896 run_lib.py:146] step: 304300, eval_loss: 3.31457e-02
I0209 18:42:43.216216 22542570456896 run_lib.py:133] step: 304350, training_loss: 3.93164e-02
I0209 18:43:00.812496 22542570456896 run_lib.py:133] step: 304400, training_loss: 3.43442e-02
I0209 18:43:00.969603 22542570456896 run_lib.py:146] step: 304400, eval_loss: 2.36698e-02
I0209 18:43:18.493956 22542570456896 run_lib.py:133] step: 304450, training_loss: 3.79190e-02
I0209 18:43:36.101183 22542570456896 run_lib.py:133] step: 304500, training_loss: 3.03187e-02
I0209 18:43:36.254324 22542570456896 run_lib.py:146] step: 304500, eval_loss: 3.18414e-02
I0209 18:43:53.671849 22542570456896 run_lib.py:133] step: 304550, training_loss: 2.66847e-02
I0209 18:44:11.096034 22542570456896 run_lib.py:133] step: 304600, training_loss: 3.61105e-02
I0209 18:44:11.254678 22542570456896 run_lib.py:146] step: 304600, eval_loss: 2.79569e-02
I0209 18:44:28.839439 22542570456896 run_lib.py:133] step: 304650, training_loss: 2.46217e-02
I0209 18:44:46.306807 22542570456896 run_lib.py:133] step: 304700, training_loss: 2.85943e-02
I0209 18:44:46.462348 22542570456896 run_lib.py:146] step: 304700, eval_loss: 2.57562e-02
I0209 18:45:03.894864 22542570456896 run_lib.py:133] step: 304750, training_loss: 1.89576e-02
I0209 18:45:21.491743 22542570456896 run_lib.py:133] step: 304800, training_loss: 2.67367e-02
I0209 18:45:21.648134 22542570456896 run_lib.py:146] step: 304800, eval_loss: 2.72209e-02
I0209 18:45:39.091852 22542570456896 run_lib.py:133] step: 304850, training_loss: 2.71018e-02
I0209 18:45:56.483986 22542570456896 run_lib.py:133] step: 304900, training_loss: 2.45095e-02
I0209 18:45:56.784089 22542570456896 run_lib.py:146] step: 304900, eval_loss: 3.00811e-02
I0209 18:46:14.221027 22542570456896 run_lib.py:133] step: 304950, training_loss: 3.60429e-02
I0209 18:46:31.690970 22542570456896 run_lib.py:133] step: 305000, training_loss: 2.70695e-02
I0209 18:46:31.844554 22542570456896 run_lib.py:146] step: 305000, eval_loss: 3.92128e-02
I0209 18:46:49.272542 22542570456896 run_lib.py:133] step: 305050, training_loss: 3.13736e-02
I0209 18:47:06.664974 22542570456896 run_lib.py:133] step: 305100, training_loss: 2.35215e-02
I0209 18:47:06.821614 22542570456896 run_lib.py:146] step: 305100, eval_loss: 2.37509e-02
I0209 18:47:24.417760 22542570456896 run_lib.py:133] step: 305150, training_loss: 3.05945e-02
I0209 18:47:41.880500 22542570456896 run_lib.py:133] step: 305200, training_loss: 2.61467e-02
I0209 18:47:42.039343 22542570456896 run_lib.py:146] step: 305200, eval_loss: 3.21365e-02
I0209 18:47:59.519142 22542570456896 run_lib.py:133] step: 305250, training_loss: 2.92014e-02
I0209 18:48:16.924332 22542570456896 run_lib.py:133] step: 305300, training_loss: 3.17078e-02
I0209 18:48:17.079621 22542570456896 run_lib.py:146] step: 305300, eval_loss: 3.20302e-02
I0209 18:48:34.666337 22542570456896 run_lib.py:133] step: 305350, training_loss: 2.61435e-02
I0209 18:48:52.153401 22542570456896 run_lib.py:133] step: 305400, training_loss: 3.00330e-02
I0209 18:48:52.304103 22542570456896 run_lib.py:146] step: 305400, eval_loss: 2.59466e-02
I0209 18:49:09.766855 22542570456896 run_lib.py:133] step: 305450, training_loss: 2.77331e-02
I0209 18:49:27.216875 22542570456896 run_lib.py:133] step: 305500, training_loss: 2.89700e-02
I0209 18:49:27.386643 22542570456896 run_lib.py:146] step: 305500, eval_loss: 2.71851e-02
I0209 18:49:44.994915 22542570456896 run_lib.py:133] step: 305550, training_loss: 2.31427e-02
I0209 18:50:02.445028 22542570456896 run_lib.py:133] step: 305600, training_loss: 2.88775e-02
I0209 18:50:02.601220 22542570456896 run_lib.py:146] step: 305600, eval_loss: 2.59293e-02
I0209 18:50:20.163574 22542570456896 run_lib.py:133] step: 305650, training_loss: 2.17789e-02
I0209 18:50:37.546613 22542570456896 run_lib.py:133] step: 305700, training_loss: 2.34185e-02
I0209 18:50:37.704950 22542570456896 run_lib.py:146] step: 305700, eval_loss: 3.31668e-02
I0209 18:50:55.214986 22542570456896 run_lib.py:133] step: 305750, training_loss: 2.72053e-02
I0209 18:51:12.595381 22542570456896 run_lib.py:133] step: 305800, training_loss: 3.00099e-02
I0209 18:51:12.749515 22542570456896 run_lib.py:146] step: 305800, eval_loss: 2.78209e-02
I0209 18:51:30.119153 22542570456896 run_lib.py:133] step: 305850, training_loss: 2.15725e-02
I0209 18:51:47.613546 22542570456896 run_lib.py:133] step: 305900, training_loss: 2.14014e-02
I0209 18:51:47.765213 22542570456896 run_lib.py:146] step: 305900, eval_loss: 2.66872e-02
I0209 18:52:05.200642 22542570456896 run_lib.py:133] step: 305950, training_loss: 3.51935e-02
I0209 18:52:22.780124 22542570456896 run_lib.py:133] step: 306000, training_loss: 3.33239e-02
I0209 18:52:22.941833 22542570456896 run_lib.py:146] step: 306000, eval_loss: 3.05143e-02
I0209 18:52:40.396760 22542570456896 run_lib.py:133] step: 306050, training_loss: 3.30079e-02
I0209 18:52:57.840403 22542570456896 run_lib.py:133] step: 306100, training_loss: 2.43156e-02
I0209 18:52:57.998333 22542570456896 run_lib.py:146] step: 306100, eval_loss: 2.90561e-02
I0209 18:53:15.556717 22542570456896 run_lib.py:133] step: 306150, training_loss: 2.14740e-02
I0209 18:53:32.973553 22542570456896 run_lib.py:133] step: 306200, training_loss: 2.77807e-02
I0209 18:53:33.129104 22542570456896 run_lib.py:146] step: 306200, eval_loss: 2.76480e-02
I0209 18:53:50.579872 22542570456896 run_lib.py:133] step: 306250, training_loss: 2.41586e-02
I0209 18:54:08.021288 22542570456896 run_lib.py:133] step: 306300, training_loss: 2.65560e-02
I0209 18:54:08.182610 22542570456896 run_lib.py:146] step: 306300, eval_loss: 2.82624e-02
I0209 18:54:25.777298 22542570456896 run_lib.py:133] step: 306350, training_loss: 2.70217e-02
I0209 18:54:43.198348 22542570456896 run_lib.py:133] step: 306400, training_loss: 3.50384e-02
I0209 18:54:43.351391 22542570456896 run_lib.py:146] step: 306400, eval_loss: 2.81826e-02
I0209 18:55:00.864705 22542570456896 run_lib.py:133] step: 306450, training_loss: 2.20418e-02
I0209 18:55:18.262269 22542570456896 run_lib.py:133] step: 306500, training_loss: 2.36418e-02
I0209 18:55:18.420696 22542570456896 run_lib.py:146] step: 306500, eval_loss: 2.99813e-02
I0209 18:55:35.822145 22542570456896 run_lib.py:133] step: 306550, training_loss: 2.58931e-02
I0209 18:55:53.321698 22542570456896 run_lib.py:133] step: 306600, training_loss: 2.39558e-02
I0209 18:55:53.481611 22542570456896 run_lib.py:146] step: 306600, eval_loss: 2.65337e-02
I0209 18:56:11.059563 22542570456896 run_lib.py:133] step: 306650, training_loss: 2.76328e-02
I0209 18:56:28.550857 22542570456896 run_lib.py:133] step: 306700, training_loss: 2.29873e-02
I0209 18:56:28.707711 22542570456896 run_lib.py:146] step: 306700, eval_loss: 2.95607e-02
I0209 18:56:46.127269 22542570456896 run_lib.py:133] step: 306750, training_loss: 2.13161e-02
I0209 18:57:03.533269 22542570456896 run_lib.py:133] step: 306800, training_loss: 2.93021e-02
I0209 18:57:03.685041 22542570456896 run_lib.py:146] step: 306800, eval_loss: 2.46571e-02
I0209 18:57:21.212450 22542570456896 run_lib.py:133] step: 306850, training_loss: 2.76908e-02
I0209 18:57:38.676910 22542570456896 run_lib.py:133] step: 306900, training_loss: 2.15775e-02
I0209 18:57:38.839486 22542570456896 run_lib.py:146] step: 306900, eval_loss: 2.89252e-02
I0209 18:57:56.427153 22542570456896 run_lib.py:133] step: 306950, training_loss: 2.37009e-02
I0209 18:58:13.857786 22542570456896 run_lib.py:133] step: 307000, training_loss: 2.92928e-02
I0209 18:58:14.016625 22542570456896 run_lib.py:146] step: 307000, eval_loss: 2.93713e-02
I0209 18:58:31.560213 22542570456896 run_lib.py:133] step: 307050, training_loss: 2.53704e-02
I0209 18:58:48.962430 22542570456896 run_lib.py:133] step: 307100, training_loss: 2.49665e-02
I0209 18:58:49.117401 22542570456896 run_lib.py:146] step: 307100, eval_loss: 2.92763e-02
I0209 18:59:06.675650 22542570456896 run_lib.py:133] step: 307150, training_loss: 2.49043e-02
I0209 18:59:24.156675 22542570456896 run_lib.py:133] step: 307200, training_loss: 4.20041e-02
I0209 18:59:24.311820 22542570456896 run_lib.py:146] step: 307200, eval_loss: 3.00332e-02
I0209 18:59:41.757902 22542570456896 run_lib.py:133] step: 307250, training_loss: 3.06404e-02
I0209 18:59:59.360866 22542570456896 run_lib.py:133] step: 307300, training_loss: 2.42678e-02
I0209 18:59:59.512410 22542570456896 run_lib.py:146] step: 307300, eval_loss: 2.89324e-02
I0209 19:00:16.922572 22542570456896 run_lib.py:133] step: 307350, training_loss: 3.69455e-02
I0209 19:00:34.368751 22542570456896 run_lib.py:133] step: 307400, training_loss: 2.53869e-02
I0209 19:00:34.540556 22542570456896 run_lib.py:146] step: 307400, eval_loss: 2.47301e-02
I0209 19:00:52.185041 22542570456896 run_lib.py:133] step: 307450, training_loss: 2.28976e-02
I0209 19:01:09.835819 22542570456896 run_lib.py:133] step: 307500, training_loss: 2.89400e-02
I0209 19:01:09.991858 22542570456896 run_lib.py:146] step: 307500, eval_loss: 3.30891e-02
I0209 19:01:27.404829 22542570456896 run_lib.py:133] step: 307550, training_loss: 2.74721e-02
I0209 19:01:44.817728 22542570456896 run_lib.py:133] step: 307600, training_loss: 2.56430e-02
I0209 19:01:44.974401 22542570456896 run_lib.py:146] step: 307600, eval_loss: 3.38741e-02
I0209 19:02:02.443783 22542570456896 run_lib.py:133] step: 307650, training_loss: 2.85372e-02
I0209 19:02:20.030638 22542570456896 run_lib.py:133] step: 307700, training_loss: 2.16979e-02
I0209 19:02:20.190262 22542570456896 run_lib.py:146] step: 307700, eval_loss: 3.19603e-02
I0209 19:02:37.618256 22542570456896 run_lib.py:133] step: 307750, training_loss: 2.90047e-02
I0209 19:02:55.086979 22542570456896 run_lib.py:133] step: 307800, training_loss: 2.05978e-02
I0209 19:02:55.245490 22542570456896 run_lib.py:146] step: 307800, eval_loss: 3.23490e-02
I0209 19:03:12.684137 22542570456896 run_lib.py:133] step: 307850, training_loss: 2.77923e-02
I0209 19:03:30.307349 22542570456896 run_lib.py:133] step: 307900, training_loss: 2.92275e-02
I0209 19:03:30.463223 22542570456896 run_lib.py:146] step: 307900, eval_loss: 2.77800e-02
I0209 19:03:47.885151 22542570456896 run_lib.py:133] step: 307950, training_loss: 2.66072e-02
I0209 19:04:05.412246 22542570456896 run_lib.py:133] step: 308000, training_loss: 2.57125e-02
I0209 19:04:05.587274 22542570456896 run_lib.py:146] step: 308000, eval_loss: 3.94389e-02
I0209 19:04:23.058104 22542570456896 run_lib.py:133] step: 308050, training_loss: 2.99236e-02
I0209 19:04:40.462304 22542570456896 run_lib.py:133] step: 308100, training_loss: 2.55864e-02
I0209 19:04:40.621648 22542570456896 run_lib.py:146] step: 308100, eval_loss: 3.17480e-02
I0209 19:04:58.202446 22542570456896 run_lib.py:133] step: 308150, training_loss: 2.62827e-02
I0209 19:05:15.682183 22542570456896 run_lib.py:133] step: 308200, training_loss: 2.28257e-02
I0209 19:05:15.840372 22542570456896 run_lib.py:146] step: 308200, eval_loss: 3.27832e-02
I0209 19:05:33.270685 22542570456896 run_lib.py:133] step: 308250, training_loss: 3.16966e-02
I0209 19:05:50.693468 22542570456896 run_lib.py:133] step: 308300, training_loss: 2.21921e-02
I0209 19:05:50.848531 22542570456896 run_lib.py:146] step: 308300, eval_loss: 2.58816e-02
I0209 19:06:08.442769 22542570456896 run_lib.py:133] step: 308350, training_loss: 3.27309e-02
I0209 19:06:25.882303 22542570456896 run_lib.py:133] step: 308400, training_loss: 2.54479e-02
I0209 19:06:26.041328 22542570456896 run_lib.py:146] step: 308400, eval_loss: 2.74255e-02
I0209 19:06:43.618977 22542570456896 run_lib.py:133] step: 308450, training_loss: 2.47944e-02
I0209 19:07:01.041661 22542570456896 run_lib.py:133] step: 308500, training_loss: 3.43504e-02
I0209 19:07:01.196872 22542570456896 run_lib.py:146] step: 308500, eval_loss: 2.76937e-02
I0209 19:07:18.768229 22542570456896 run_lib.py:133] step: 308550, training_loss: 2.94846e-02
I0209 19:07:36.259046 22542570456896 run_lib.py:133] step: 308600, training_loss: 2.49892e-02
I0209 19:07:36.417174 22542570456896 run_lib.py:146] step: 308600, eval_loss: 2.27545e-02
I0209 19:07:53.839080 22542570456896 run_lib.py:133] step: 308650, training_loss: 3.10198e-02
I0209 19:08:11.431159 22542570456896 run_lib.py:133] step: 308700, training_loss: 2.67645e-02
I0209 19:08:11.589067 22542570456896 run_lib.py:146] step: 308700, eval_loss: 2.47535e-02
I0209 19:08:29.019524 22542570456896 run_lib.py:133] step: 308750, training_loss: 2.63611e-02
I0209 19:08:46.601719 22542570456896 run_lib.py:133] step: 308800, training_loss: 3.03848e-02
I0209 19:08:46.756308 22542570456896 run_lib.py:146] step: 308800, eval_loss: 2.95070e-02
I0209 19:09:04.155473 22542570456896 run_lib.py:133] step: 308850, training_loss: 3.74034e-02
I0209 19:09:21.637384 22542570456896 run_lib.py:133] step: 308900, training_loss: 2.18402e-02
I0209 19:09:21.811310 22542570456896 run_lib.py:146] step: 308900, eval_loss: 3.50798e-02
I0209 19:09:39.468658 22542570456896 run_lib.py:133] step: 308950, training_loss: 3.09664e-02
I0209 19:09:56.859506 22542570456896 run_lib.py:133] step: 309000, training_loss: 2.07176e-02
I0209 19:09:57.016678 22542570456896 run_lib.py:146] step: 309000, eval_loss: 2.23132e-02
I0209 19:10:14.427139 22542570456896 run_lib.py:133] step: 309050, training_loss: 2.22221e-02
I0209 19:10:31.973199 22542570456896 run_lib.py:133] step: 309100, training_loss: 2.85288e-02
I0209 19:10:32.128368 22542570456896 run_lib.py:146] step: 309100, eval_loss: 2.50107e-02
I0209 19:10:49.568376 22542570456896 run_lib.py:133] step: 309150, training_loss: 2.48790e-02
I0209 19:11:06.998661 22542570456896 run_lib.py:133] step: 309200, training_loss: 2.67857e-02
I0209 19:11:07.158574 22542570456896 run_lib.py:146] step: 309200, eval_loss: 2.40153e-02
I0209 19:11:24.683092 22542570456896 run_lib.py:133] step: 309250, training_loss: 3.34010e-02
I0209 19:11:42.134915 22542570456896 run_lib.py:133] step: 309300, training_loss: 2.76311e-02
I0209 19:11:42.295341 22542570456896 run_lib.py:146] step: 309300, eval_loss: 3.46336e-02
I0209 19:11:59.710825 22542570456896 run_lib.py:133] step: 309350, training_loss: 3.22895e-02
I0209 19:12:17.093176 22542570456896 run_lib.py:133] step: 309400, training_loss: 2.72407e-02
I0209 19:12:17.278347 22542570456896 run_lib.py:146] step: 309400, eval_loss: 2.48575e-02
I0209 19:12:34.886128 22542570456896 run_lib.py:133] step: 309450, training_loss: 2.93530e-02
I0209 19:12:52.467759 22542570456896 run_lib.py:133] step: 309500, training_loss: 3.24849e-02
I0209 19:12:52.624550 22542570456896 run_lib.py:146] step: 309500, eval_loss: 3.05327e-02
I0209 19:13:10.089721 22542570456896 run_lib.py:133] step: 309550, training_loss: 2.76186e-02
I0209 19:13:27.511406 22542570456896 run_lib.py:133] step: 309600, training_loss: 2.74230e-02
I0209 19:13:27.665340 22542570456896 run_lib.py:146] step: 309600, eval_loss: 2.57574e-02
I0209 19:13:45.218618 22542570456896 run_lib.py:133] step: 309650, training_loss: 3.10359e-02
I0209 19:14:02.665818 22542570456896 run_lib.py:133] step: 309700, training_loss: 2.23274e-02
I0209 19:14:02.820762 22542570456896 run_lib.py:146] step: 309700, eval_loss: 2.84565e-02
I0209 19:14:20.524558 22542570456896 run_lib.py:133] step: 309750, training_loss: 2.67268e-02
I0209 19:14:37.951066 22542570456896 run_lib.py:133] step: 309800, training_loss: 2.45414e-02
I0209 19:14:38.113279 22542570456896 run_lib.py:146] step: 309800, eval_loss: 3.20983e-02
I0209 19:14:55.645916 22542570456896 run_lib.py:133] step: 309850, training_loss: 3.06062e-02
I0209 19:15:13.052079 22542570456896 run_lib.py:133] step: 309900, training_loss: 2.60601e-02
I0209 19:15:13.209537 22542570456896 run_lib.py:146] step: 309900, eval_loss: 3.27643e-02
I0209 19:15:30.817822 22542570456896 run_lib.py:133] step: 309950, training_loss: 3.17616e-02
I0209 19:15:48.256987 22542570456896 run_lib.py:133] step: 310000, training_loss: 2.62348e-02
I0209 19:15:48.961477 22542570456896 run_lib.py:146] step: 310000, eval_loss: 2.42788e-02
I0209 19:16:09.034813 22542570456896 run_lib.py:133] step: 310050, training_loss: 2.48483e-02
I0209 19:16:26.615300 22542570456896 run_lib.py:133] step: 310100, training_loss: 3.11286e-02
I0209 19:16:26.771123 22542570456896 run_lib.py:146] step: 310100, eval_loss: 2.74566e-02
I0209 19:16:44.252157 22542570456896 run_lib.py:133] step: 310150, training_loss: 3.14841e-02
I0209 19:17:01.729168 22542570456896 run_lib.py:133] step: 310200, training_loss: 2.28086e-02
I0209 19:17:01.881084 22542570456896 run_lib.py:146] step: 310200, eval_loss: 2.81093e-02
I0209 19:17:19.266337 22542570456896 run_lib.py:133] step: 310250, training_loss: 2.48485e-02
I0209 19:17:36.746768 22542570456896 run_lib.py:133] step: 310300, training_loss: 2.44518e-02
I0209 19:17:36.912566 22542570456896 run_lib.py:146] step: 310300, eval_loss: 2.73993e-02
I0209 19:17:54.584439 22542570456896 run_lib.py:133] step: 310350, training_loss: 2.26428e-02
I0209 19:18:12.069656 22542570456896 run_lib.py:133] step: 310400, training_loss: 2.57058e-02
I0209 19:18:12.226661 22542570456896 run_lib.py:146] step: 310400, eval_loss: 3.57243e-02
I0209 19:18:29.616434 22542570456896 run_lib.py:133] step: 310450, training_loss: 2.90633e-02
I0209 19:18:46.996402 22542570456896 run_lib.py:133] step: 310500, training_loss: 2.08470e-02
I0209 19:18:47.156415 22542570456896 run_lib.py:146] step: 310500, eval_loss: 3.28634e-02
I0209 19:19:04.723089 22542570456896 run_lib.py:133] step: 310550, training_loss: 2.61069e-02
I0209 19:19:22.180105 22542570456896 run_lib.py:133] step: 310600, training_loss: 3.24572e-02
I0209 19:19:22.344380 22542570456896 run_lib.py:146] step: 310600, eval_loss: 2.86242e-02
I0209 19:19:39.958019 22542570456896 run_lib.py:133] step: 310650, training_loss: 2.67718e-02
I0209 19:19:57.393465 22542570456896 run_lib.py:133] step: 310700, training_loss: 3.24955e-02
I0209 19:19:57.545286 22542570456896 run_lib.py:146] step: 310700, eval_loss: 3.04586e-02
I0209 19:20:15.086265 22542570456896 run_lib.py:133] step: 310750, training_loss: 3.62889e-02
I0209 19:20:32.555761 22542570456896 run_lib.py:133] step: 310800, training_loss: 2.75819e-02
I0209 19:20:32.731255 22542570456896 run_lib.py:146] step: 310800, eval_loss: 3.85541e-02
I0209 19:20:50.159560 22542570456896 run_lib.py:133] step: 310850, training_loss: 2.47334e-02
I0209 19:21:07.787160 22542570456896 run_lib.py:133] step: 310900, training_loss: 1.96717e-02
I0209 19:21:07.953397 22542570456896 run_lib.py:146] step: 310900, eval_loss: 2.12434e-02
I0209 19:21:25.379264 22542570456896 run_lib.py:133] step: 310950, training_loss: 2.74767e-02
I0209 19:21:42.913249 22542570456896 run_lib.py:133] step: 311000, training_loss: 2.85045e-02
I0209 19:21:43.068356 22542570456896 run_lib.py:146] step: 311000, eval_loss: 2.57607e-02
I0209 19:22:00.474849 22542570456896 run_lib.py:133] step: 311050, training_loss: 3.28736e-02
I0209 19:22:17.945574 22542570456896 run_lib.py:133] step: 311100, training_loss: 2.57249e-02
I0209 19:22:18.101594 22542570456896 run_lib.py:146] step: 311100, eval_loss: 3.31429e-02
I0209 19:22:35.731155 22542570456896 run_lib.py:133] step: 311150, training_loss: 2.53310e-02
I0209 19:22:53.242273 22542570456896 run_lib.py:133] step: 311200, training_loss: 2.58653e-02
I0209 19:22:53.396327 22542570456896 run_lib.py:146] step: 311200, eval_loss: 3.00811e-02
I0209 19:23:10.776136 22542570456896 run_lib.py:133] step: 311250, training_loss: 3.03609e-02
I0209 19:23:28.369150 22542570456896 run_lib.py:133] step: 311300, training_loss: 2.29422e-02
I0209 19:23:28.539853 22542570456896 run_lib.py:146] step: 311300, eval_loss: 2.74410e-02
I0209 19:23:46.015266 22542570456896 run_lib.py:133] step: 311350, training_loss: 2.68948e-02
I0209 19:24:03.481654 22542570456896 run_lib.py:133] step: 311400, training_loss: 2.90307e-02
I0209 19:24:03.637334 22542570456896 run_lib.py:146] step: 311400, eval_loss: 3.12487e-02
I0209 19:24:21.133133 22542570456896 run_lib.py:133] step: 311450, training_loss: 2.59865e-02
I0209 19:24:38.601771 22542570456896 run_lib.py:133] step: 311500, training_loss: 3.10681e-02
I0209 19:24:38.756413 22542570456896 run_lib.py:146] step: 311500, eval_loss: 3.72750e-02
I0209 19:24:56.193075 22542570456896 run_lib.py:133] step: 311550, training_loss: 2.61584e-02
I0209 19:25:13.654001 22542570456896 run_lib.py:133] step: 311600, training_loss: 3.10603e-02
I0209 19:25:13.808482 22542570456896 run_lib.py:146] step: 311600, eval_loss: 2.92017e-02
I0209 19:25:31.389431 22542570456896 run_lib.py:133] step: 311650, training_loss: 2.37568e-02
I0209 19:25:48.950704 22542570456896 run_lib.py:133] step: 311700, training_loss: 2.84332e-02
I0209 19:25:49.108153 22542570456896 run_lib.py:146] step: 311700, eval_loss: 2.50964e-02
I0209 19:26:06.528520 22542570456896 run_lib.py:133] step: 311750, training_loss: 2.39894e-02
I0209 19:26:23.952795 22542570456896 run_lib.py:133] step: 311800, training_loss: 2.51262e-02
I0209 19:26:24.120645 22542570456896 run_lib.py:146] step: 311800, eval_loss: 2.97829e-02
I0209 19:26:41.663995 22542570456896 run_lib.py:133] step: 311850, training_loss: 3.51630e-02
I0209 19:26:59.100454 22542570456896 run_lib.py:133] step: 311900, training_loss: 2.90370e-02
I0209 19:26:59.267699 22542570456896 run_lib.py:146] step: 311900, eval_loss: 2.45491e-02
I0209 19:27:16.884723 22542570456896 run_lib.py:133] step: 311950, training_loss: 2.59353e-02
I0209 19:27:34.269143 22542570456896 run_lib.py:133] step: 312000, training_loss: 2.59393e-02
I0209 19:27:34.425067 22542570456896 run_lib.py:146] step: 312000, eval_loss: 2.66927e-02
I0209 19:27:52.028706 22542570456896 run_lib.py:133] step: 312050, training_loss: 2.64602e-02
I0209 19:28:09.435384 22542570456896 run_lib.py:133] step: 312100, training_loss: 3.23380e-02
I0209 19:28:09.593428 22542570456896 run_lib.py:146] step: 312100, eval_loss: 2.72357e-02
I0209 19:28:27.175846 22542570456896 run_lib.py:133] step: 312150, training_loss: 3.47358e-02
I0209 19:28:44.657121 22542570456896 run_lib.py:133] step: 312200, training_loss: 2.36212e-02
I0209 19:28:44.819654 22542570456896 run_lib.py:146] step: 312200, eval_loss: 2.63730e-02
I0209 19:29:02.280952 22542570456896 run_lib.py:133] step: 312250, training_loss: 2.72995e-02
I0209 19:29:19.923886 22542570456896 run_lib.py:133] step: 312300, training_loss: 3.03833e-02
I0209 19:29:20.090378 22542570456896 run_lib.py:146] step: 312300, eval_loss: 3.24507e-02
I0209 19:29:37.475702 22542570456896 run_lib.py:133] step: 312350, training_loss: 2.19863e-02
I0209 19:29:54.911381 22542570456896 run_lib.py:133] step: 312400, training_loss: 2.90552e-02
I0209 19:29:55.080404 22542570456896 run_lib.py:146] step: 312400, eval_loss: 2.09998e-02
I0209 19:30:12.725847 22542570456896 run_lib.py:133] step: 312450, training_loss: 2.69599e-02
I0209 19:30:30.254465 22542570456896 run_lib.py:133] step: 312500, training_loss: 2.45337e-02
I0209 19:30:30.411225 22542570456896 run_lib.py:146] step: 312500, eval_loss: 3.71824e-02
I0209 19:30:48.034052 22542570456896 run_lib.py:133] step: 312550, training_loss: 2.33705e-02
I0209 19:31:05.419589 22542570456896 run_lib.py:133] step: 312600, training_loss: 2.59112e-02
I0209 19:31:05.573364 22542570456896 run_lib.py:146] step: 312600, eval_loss: 3.07384e-02
I0209 19:31:22.994345 22542570456896 run_lib.py:133] step: 312650, training_loss: 2.39818e-02
I0209 19:31:40.562404 22542570456896 run_lib.py:133] step: 312700, training_loss: 2.93880e-02
I0209 19:31:40.731619 22542570456896 run_lib.py:146] step: 312700, eval_loss: 2.52049e-02
I0209 19:31:58.225060 22542570456896 run_lib.py:133] step: 312750, training_loss: 2.87763e-02
I0209 19:32:15.667816 22542570456896 run_lib.py:133] step: 312800, training_loss: 3.52960e-02
I0209 19:32:15.833327 22542570456896 run_lib.py:146] step: 312800, eval_loss: 3.09713e-02
I0209 19:32:33.263293 22542570456896 run_lib.py:133] step: 312850, training_loss: 2.90788e-02
I0209 19:32:50.843698 22542570456896 run_lib.py:133] step: 312900, training_loss: 2.58515e-02
I0209 19:32:50.999429 22542570456896 run_lib.py:146] step: 312900, eval_loss: 3.69220e-02
I0209 19:33:08.423337 22542570456896 run_lib.py:133] step: 312950, training_loss: 2.41656e-02
I0209 19:33:25.938756 22542570456896 run_lib.py:133] step: 313000, training_loss: 2.72732e-02
I0209 19:33:26.093666 22542570456896 run_lib.py:146] step: 313000, eval_loss: 2.49734e-02
I0209 19:33:43.625864 22542570456896 run_lib.py:133] step: 313050, training_loss: 2.57876e-02
I0209 19:34:01.002631 22542570456896 run_lib.py:133] step: 313100, training_loss: 2.28276e-02
I0209 19:34:01.155839 22542570456896 run_lib.py:146] step: 313100, eval_loss: 2.65471e-02
I0209 19:34:18.764250 22542570456896 run_lib.py:133] step: 313150, training_loss: 2.84845e-02
I0209 19:34:36.251802 22542570456896 run_lib.py:133] step: 313200, training_loss: 3.26907e-02
I0209 19:34:36.410606 22542570456896 run_lib.py:146] step: 313200, eval_loss: 2.97119e-02
I0209 19:34:53.851269 22542570456896 run_lib.py:133] step: 313250, training_loss: 2.73513e-02
I0209 19:35:11.294261 22542570456896 run_lib.py:133] step: 313300, training_loss: 3.51438e-02
I0209 19:35:11.453318 22542570456896 run_lib.py:146] step: 313300, eval_loss: 3.33624e-02
I0209 19:35:29.052334 22542570456896 run_lib.py:133] step: 313350, training_loss: 2.92543e-02
I0209 19:35:46.470561 22542570456896 run_lib.py:133] step: 313400, training_loss: 3.04631e-02
I0209 19:35:46.626206 22542570456896 run_lib.py:146] step: 313400, eval_loss: 3.63520e-02
I0209 19:36:04.260097 22542570456896 run_lib.py:133] step: 313450, training_loss: 2.36058e-02
I0209 19:36:21.680490 22542570456896 run_lib.py:133] step: 313500, training_loss: 2.35961e-02
I0209 19:36:21.834126 22542570456896 run_lib.py:146] step: 313500, eval_loss: 2.85096e-02
I0209 19:36:39.397918 22542570456896 run_lib.py:133] step: 313550, training_loss: 3.11618e-02
I0209 19:36:56.827792 22542570456896 run_lib.py:133] step: 313600, training_loss: 2.31879e-02
I0209 19:36:56.984625 22542570456896 run_lib.py:146] step: 313600, eval_loss: 3.21763e-02
I0209 19:37:14.466731 22542570456896 run_lib.py:133] step: 313650, training_loss: 2.72466e-02
I0209 19:37:32.077440 22542570456896 run_lib.py:133] step: 313700, training_loss: 3.09518e-02
I0209 19:37:32.241509 22542570456896 run_lib.py:146] step: 313700, eval_loss: 2.74634e-02
I0209 19:37:49.664882 22542570456896 run_lib.py:133] step: 313750, training_loss: 2.56731e-02
I0209 19:38:07.224819 22542570456896 run_lib.py:133] step: 313800, training_loss: 3.60555e-02
I0209 19:38:07.380960 22542570456896 run_lib.py:146] step: 313800, eval_loss: 2.72459e-02
I0209 19:38:24.839650 22542570456896 run_lib.py:133] step: 313850, training_loss: 2.72375e-02
I0209 19:38:42.312831 22542570456896 run_lib.py:133] step: 313900, training_loss: 2.99731e-02
I0209 19:38:42.469804 22542570456896 run_lib.py:146] step: 313900, eval_loss: 2.65310e-02
I0209 19:39:00.086800 22542570456896 run_lib.py:133] step: 313950, training_loss: 2.55336e-02
I0209 19:39:17.538229 22542570456896 run_lib.py:133] step: 314000, training_loss: 1.92685e-02
I0209 19:39:17.690448 22542570456896 run_lib.py:146] step: 314000, eval_loss: 2.88377e-02
I0209 19:39:35.134909 22542570456896 run_lib.py:133] step: 314050, training_loss: 3.87060e-02
I0209 19:39:52.811191 22542570456896 run_lib.py:133] step: 314100, training_loss: 2.74787e-02
I0209 19:39:52.975497 22542570456896 run_lib.py:146] step: 314100, eval_loss: 3.03988e-02
I0209 19:40:10.449502 22542570456896 run_lib.py:133] step: 314150, training_loss: 3.22654e-02
I0209 19:40:27.852053 22542570456896 run_lib.py:133] step: 314200, training_loss: 3.65874e-02
I0209 19:40:28.196241 22542570456896 run_lib.py:146] step: 314200, eval_loss: 3.31225e-02
I0209 19:40:45.626244 22542570456896 run_lib.py:133] step: 314250, training_loss: 3.31119e-02
I0209 19:41:03.044031 22542570456896 run_lib.py:133] step: 314300, training_loss: 3.37518e-02
I0209 19:41:03.198499 22542570456896 run_lib.py:146] step: 314300, eval_loss: 2.83645e-02
I0209 19:41:20.609528 22542570456896 run_lib.py:133] step: 314350, training_loss: 2.78417e-02
I0209 19:41:38.052251 22542570456896 run_lib.py:133] step: 314400, training_loss: 2.84251e-02
I0209 19:41:38.207579 22542570456896 run_lib.py:146] step: 314400, eval_loss: 2.17142e-02
I0209 19:41:55.862938 22542570456896 run_lib.py:133] step: 314450, training_loss: 3.04736e-02
I0209 19:42:13.395308 22542570456896 run_lib.py:133] step: 314500, training_loss: 2.23859e-02
I0209 19:42:13.544560 22542570456896 run_lib.py:146] step: 314500, eval_loss: 3.17783e-02
I0209 19:42:30.957824 22542570456896 run_lib.py:133] step: 314550, training_loss: 2.77177e-02
I0209 19:42:48.393080 22542570456896 run_lib.py:133] step: 314600, training_loss: 2.49749e-02
I0209 19:42:48.548459 22542570456896 run_lib.py:146] step: 314600, eval_loss: 3.59583e-02
I0209 19:43:06.141165 22542570456896 run_lib.py:133] step: 314650, training_loss: 2.57853e-02
I0209 19:43:23.714343 22542570456896 run_lib.py:133] step: 314700, training_loss: 2.53272e-02
I0209 19:43:23.873328 22542570456896 run_lib.py:146] step: 314700, eval_loss: 2.32322e-02
I0209 19:43:41.278565 22542570456896 run_lib.py:133] step: 314750, training_loss: 2.03371e-02
I0209 19:43:58.698788 22542570456896 run_lib.py:133] step: 314800, training_loss: 3.13649e-02
I0209 19:43:58.854070 22542570456896 run_lib.py:146] step: 314800, eval_loss: 3.26492e-02
I0209 19:44:16.451733 22542570456896 run_lib.py:133] step: 314850, training_loss: 2.81864e-02
I0209 19:44:33.868412 22542570456896 run_lib.py:133] step: 314900, training_loss: 2.35141e-02
I0209 19:44:34.023443 22542570456896 run_lib.py:146] step: 314900, eval_loss: 3.01028e-02
I0209 19:44:51.649460 22542570456896 run_lib.py:133] step: 314950, training_loss: 2.86267e-02
I0209 19:45:09.141802 22542570456896 run_lib.py:133] step: 315000, training_loss: 2.18859e-02
I0209 19:45:09.296401 22542570456896 run_lib.py:146] step: 315000, eval_loss: 2.78847e-02
I0209 19:45:26.910883 22542570456896 run_lib.py:133] step: 315050, training_loss: 2.70768e-02
I0209 19:45:44.368372 22542570456896 run_lib.py:133] step: 315100, training_loss: 2.44660e-02
I0209 19:45:44.525820 22542570456896 run_lib.py:146] step: 315100, eval_loss: 2.58572e-02
I0209 19:46:01.924541 22542570456896 run_lib.py:133] step: 315150, training_loss: 2.28180e-02
I0209 19:46:19.520077 22542570456896 run_lib.py:133] step: 315200, training_loss: 2.79823e-02
I0209 19:46:19.677143 22542570456896 run_lib.py:146] step: 315200, eval_loss: 2.67052e-02
I0209 19:46:37.123880 22542570456896 run_lib.py:133] step: 315250, training_loss: 2.61482e-02
I0209 19:46:54.753541 22542570456896 run_lib.py:133] step: 315300, training_loss: 2.68381e-02
I0209 19:46:54.912131 22542570456896 run_lib.py:146] step: 315300, eval_loss: 2.68336e-02
I0209 19:47:12.338416 22542570456896 run_lib.py:133] step: 315350, training_loss: 2.85028e-02
I0209 19:47:29.732765 22542570456896 run_lib.py:133] step: 315400, training_loss: 3.28631e-02
I0209 19:47:29.883338 22542570456896 run_lib.py:146] step: 315400, eval_loss: 2.42718e-02
I0209 19:47:47.438190 22542570456896 run_lib.py:133] step: 315450, training_loss: 3.10077e-02
I0209 19:48:04.904710 22542570456896 run_lib.py:133] step: 315500, training_loss: 2.72619e-02
I0209 19:48:05.060523 22542570456896 run_lib.py:146] step: 315500, eval_loss: 3.14537e-02
I0209 19:48:22.577780 22542570456896 run_lib.py:133] step: 315550, training_loss: 2.11677e-02
I0209 19:48:40.046696 22542570456896 run_lib.py:133] step: 315600, training_loss: 2.77485e-02
I0209 19:48:40.205971 22542570456896 run_lib.py:146] step: 315600, eval_loss: 2.63044e-02
I0209 19:48:57.828262 22542570456896 run_lib.py:133] step: 315650, training_loss: 2.48423e-02
I0209 19:49:15.241124 22542570456896 run_lib.py:133] step: 315700, training_loss: 2.77443e-02
I0209 19:49:15.396397 22542570456896 run_lib.py:146] step: 315700, eval_loss: 3.79967e-02
I0209 19:49:32.868106 22542570456896 run_lib.py:133] step: 315750, training_loss: 2.79929e-02
I0209 19:49:50.303761 22542570456896 run_lib.py:133] step: 315800, training_loss: 2.89848e-02
I0209 19:49:50.463328 22542570456896 run_lib.py:146] step: 315800, eval_loss: 2.53322e-02
I0209 19:50:07.901095 22542570456896 run_lib.py:133] step: 315850, training_loss: 3.06220e-02
I0209 19:50:25.341511 22542570456896 run_lib.py:133] step: 315900, training_loss: 2.76424e-02
I0209 19:50:25.492726 22542570456896 run_lib.py:146] step: 315900, eval_loss: 2.39615e-02
I0209 19:50:43.102977 22542570456896 run_lib.py:133] step: 315950, training_loss: 3.39347e-02
I0209 19:51:00.623914 22542570456896 run_lib.py:133] step: 316000, training_loss: 2.72994e-02
I0209 19:51:00.779315 22542570456896 run_lib.py:146] step: 316000, eval_loss: 2.88908e-02
I0209 19:51:18.195152 22542570456896 run_lib.py:133] step: 316050, training_loss: 3.10259e-02
I0209 19:51:35.622813 22542570456896 run_lib.py:133] step: 316100, training_loss: 3.31286e-02
I0209 19:51:35.791409 22542570456896 run_lib.py:146] step: 316100, eval_loss: 2.93505e-02
I0209 19:51:53.425937 22542570456896 run_lib.py:133] step: 316150, training_loss: 2.34827e-02
I0209 19:52:10.882884 22542570456896 run_lib.py:133] step: 316200, training_loss: 2.67254e-02
I0209 19:52:11.042566 22542570456896 run_lib.py:146] step: 316200, eval_loss: 2.80665e-02
I0209 19:52:28.671708 22542570456896 run_lib.py:133] step: 316250, training_loss: 3.23690e-02
I0209 19:52:46.101673 22542570456896 run_lib.py:133] step: 316300, training_loss: 2.17879e-02
I0209 19:52:46.257457 22542570456896 run_lib.py:146] step: 316300, eval_loss: 2.50334e-02
I0209 19:53:03.830746 22542570456896 run_lib.py:133] step: 316350, training_loss: 2.31403e-02
I0209 19:53:21.287455 22542570456896 run_lib.py:133] step: 316400, training_loss: 3.63732e-02
I0209 19:53:21.441495 22542570456896 run_lib.py:146] step: 316400, eval_loss: 2.90431e-02
I0209 19:53:39.092026 22542570456896 run_lib.py:133] step: 316450, training_loss: 2.50869e-02
I0209 19:53:56.489198 22542570456896 run_lib.py:133] step: 316500, training_loss: 2.85180e-02
I0209 19:53:56.644320 22542570456896 run_lib.py:146] step: 316500, eval_loss: 2.63257e-02
I0209 19:54:14.076717 22542570456896 run_lib.py:133] step: 316550, training_loss: 2.85607e-02
I0209 19:54:31.656941 22542570456896 run_lib.py:133] step: 316600, training_loss: 2.67440e-02
I0209 19:54:31.814675 22542570456896 run_lib.py:146] step: 316600, eval_loss: 2.79278e-02
I0209 19:54:49.220516 22542570456896 run_lib.py:133] step: 316650, training_loss: 3.17598e-02
I0209 19:55:06.634446 22542570456896 run_lib.py:133] step: 316700, training_loss: 2.98217e-02
I0209 19:55:06.792355 22542570456896 run_lib.py:146] step: 316700, eval_loss: 2.74411e-02
I0209 19:55:24.435223 22542570456896 run_lib.py:133] step: 316750, training_loss: 2.28238e-02
I0209 19:55:42.018215 22542570456896 run_lib.py:133] step: 316800, training_loss: 2.89288e-02
I0209 19:55:42.173041 22542570456896 run_lib.py:146] step: 316800, eval_loss: 2.46971e-02
I0209 19:55:59.605182 22542570456896 run_lib.py:133] step: 316850, training_loss: 2.31312e-02
I0209 19:56:17.027123 22542570456896 run_lib.py:133] step: 316900, training_loss: 2.24352e-02
I0209 19:56:17.174629 22542570456896 run_lib.py:146] step: 316900, eval_loss: 2.62047e-02
I0209 19:56:34.617660 22542570456896 run_lib.py:133] step: 316950, training_loss: 2.70683e-02
I0209 19:56:52.215390 22542570456896 run_lib.py:133] step: 317000, training_loss: 2.74139e-02
I0209 19:56:52.399434 22542570456896 run_lib.py:146] step: 317000, eval_loss: 3.19672e-02
I0209 19:57:09.873591 22542570456896 run_lib.py:133] step: 317050, training_loss: 3.06668e-02
I0209 19:57:27.336738 22542570456896 run_lib.py:133] step: 317100, training_loss: 2.74216e-02
I0209 19:57:27.492523 22542570456896 run_lib.py:146] step: 317100, eval_loss: 2.58201e-02
I0209 19:57:44.938480 22542570456896 run_lib.py:133] step: 317150, training_loss: 2.87845e-02
I0209 19:58:02.547040 22542570456896 run_lib.py:133] step: 317200, training_loss: 3.11244e-02
I0209 19:58:02.721953 22542570456896 run_lib.py:146] step: 317200, eval_loss: 2.72464e-02
I0209 19:58:20.169883 22542570456896 run_lib.py:133] step: 317250, training_loss: 2.90912e-02
I0209 19:58:37.702604 22542570456896 run_lib.py:133] step: 317300, training_loss: 1.95731e-02
I0209 19:58:37.854489 22542570456896 run_lib.py:146] step: 317300, eval_loss: 3.72242e-02
I0209 19:58:55.294295 22542570456896 run_lib.py:133] step: 317350, training_loss: 2.97196e-02
I0209 19:59:12.702480 22542570456896 run_lib.py:133] step: 317400, training_loss: 2.96339e-02
I0209 19:59:12.856461 22542570456896 run_lib.py:146] step: 317400, eval_loss: 2.06290e-02
I0209 19:59:30.396424 22542570456896 run_lib.py:133] step: 317450, training_loss: 2.61405e-02
I0209 19:59:47.765059 22542570456896 run_lib.py:133] step: 317500, training_loss: 2.35866e-02
I0209 19:59:47.940164 22542570456896 run_lib.py:146] step: 317500, eval_loss: 2.95371e-02
I0209 20:00:05.320385 22542570456896 run_lib.py:133] step: 317550, training_loss: 2.59973e-02
I0209 20:00:22.628169 22542570456896 run_lib.py:133] step: 317600, training_loss: 3.22966e-02
I0209 20:00:22.782367 22542570456896 run_lib.py:146] step: 317600, eval_loss: 3.08400e-02
I0209 20:00:40.289606 22542570456896 run_lib.py:133] step: 317650, training_loss: 2.70447e-02
I0209 20:00:57.695949 22542570456896 run_lib.py:133] step: 317700, training_loss: 2.79103e-02
I0209 20:00:57.852546 22542570456896 run_lib.py:146] step: 317700, eval_loss: 3.46500e-02
I0209 20:01:15.401756 22542570456896 run_lib.py:133] step: 317750, training_loss: 2.73796e-02
I0209 20:01:32.851757 22542570456896 run_lib.py:133] step: 317800, training_loss: 2.27674e-02
I0209 20:01:33.005140 22542570456896 run_lib.py:146] step: 317800, eval_loss: 2.32485e-02
I0209 20:01:50.682796 22542570456896 run_lib.py:133] step: 317850, training_loss: 3.39609e-02
I0209 20:02:08.115732 22542570456896 run_lib.py:133] step: 317900, training_loss: 2.64466e-02
I0209 20:02:08.276318 22542570456896 run_lib.py:146] step: 317900, eval_loss: 3.06664e-02
I0209 20:02:25.688901 22542570456896 run_lib.py:133] step: 317950, training_loss: 2.62968e-02
I0209 20:02:43.227835 22542570456896 run_lib.py:133] step: 318000, training_loss: 3.05438e-02
I0209 20:02:43.386676 22542570456896 run_lib.py:146] step: 318000, eval_loss: 2.18526e-02
I0209 20:03:00.837897 22542570456896 run_lib.py:133] step: 318050, training_loss: 2.88438e-02
I0209 20:03:18.423881 22542570456896 run_lib.py:133] step: 318100, training_loss: 2.57705e-02
I0209 20:03:18.580598 22542570456896 run_lib.py:146] step: 318100, eval_loss: 2.55776e-02
I0209 20:03:36.025898 22542570456896 run_lib.py:133] step: 318150, training_loss: 3.34812e-02
I0209 20:03:53.426587 22542570456896 run_lib.py:133] step: 318200, training_loss: 2.26275e-02
I0209 20:03:53.582336 22542570456896 run_lib.py:146] step: 318200, eval_loss: 3.50326e-02
I0209 20:04:11.208108 22542570456896 run_lib.py:133] step: 318250, training_loss: 3.80960e-02
I0209 20:04:28.647104 22542570456896 run_lib.py:133] step: 318300, training_loss: 2.42798e-02
I0209 20:04:28.805340 22542570456896 run_lib.py:146] step: 318300, eval_loss: 2.73821e-02
I0209 20:04:46.229370 22542570456896 run_lib.py:133] step: 318350, training_loss: 2.69028e-02
I0209 20:05:03.828469 22542570456896 run_lib.py:133] step: 318400, training_loss: 3.87124e-02
I0209 20:05:03.998585 22542570456896 run_lib.py:146] step: 318400, eval_loss: 3.40285e-02
I0209 20:05:21.419703 22542570456896 run_lib.py:133] step: 318450, training_loss: 2.67561e-02
I0209 20:05:38.858093 22542570456896 run_lib.py:133] step: 318500, training_loss: 2.47833e-02
I0209 20:05:39.017571 22542570456896 run_lib.py:146] step: 318500, eval_loss: 2.51138e-02
I0209 20:05:56.508400 22542570456896 run_lib.py:133] step: 318550, training_loss: 3.61675e-02
I0209 20:06:13.919860 22542570456896 run_lib.py:133] step: 318600, training_loss: 2.19852e-02
I0209 20:06:14.077021 22542570456896 run_lib.py:146] step: 318600, eval_loss: 3.17986e-02
I0209 20:06:31.468846 22542570456896 run_lib.py:133] step: 318650, training_loss: 2.80540e-02
I0209 20:06:48.923161 22542570456896 run_lib.py:133] step: 318700, training_loss: 2.54263e-02
I0209 20:06:49.080643 22542570456896 run_lib.py:146] step: 318700, eval_loss: 2.58633e-02
I0209 20:07:06.734648 22542570456896 run_lib.py:133] step: 318750, training_loss: 2.46902e-02
I0209 20:07:24.186403 22542570456896 run_lib.py:133] step: 318800, training_loss: 2.71323e-02
I0209 20:07:24.346388 22542570456896 run_lib.py:146] step: 318800, eval_loss: 2.56766e-02
I0209 20:07:41.775329 22542570456896 run_lib.py:133] step: 318850, training_loss: 2.72850e-02
I0209 20:07:59.227420 22542570456896 run_lib.py:133] step: 318900, training_loss: 2.72036e-02
I0209 20:07:59.400374 22542570456896 run_lib.py:146] step: 318900, eval_loss: 2.57691e-02
I0209 20:08:17.000399 22542570456896 run_lib.py:133] step: 318950, training_loss: 2.39009e-02
I0209 20:08:34.463480 22542570456896 run_lib.py:133] step: 319000, training_loss: 2.43852e-02
I0209 20:08:34.619618 22542570456896 run_lib.py:146] step: 319000, eval_loss: 2.87163e-02
I0209 20:08:52.231026 22542570456896 run_lib.py:133] step: 319050, training_loss: 2.85579e-02
I0209 20:09:09.649800 22542570456896 run_lib.py:133] step: 319100, training_loss: 2.34168e-02
I0209 20:09:09.804405 22542570456896 run_lib.py:146] step: 319100, eval_loss: 2.84981e-02
I0209 20:09:27.353731 22542570456896 run_lib.py:133] step: 319150, training_loss: 2.82819e-02
I0209 20:09:44.814528 22542570456896 run_lib.py:133] step: 319200, training_loss: 2.60746e-02
I0209 20:09:44.968241 22542570456896 run_lib.py:146] step: 319200, eval_loss: 3.42288e-02
I0209 20:10:02.611170 22542570456896 run_lib.py:133] step: 319250, training_loss: 2.38304e-02
I0209 20:10:20.056429 22542570456896 run_lib.py:133] step: 319300, training_loss: 2.47831e-02
I0209 20:10:20.211511 22542570456896 run_lib.py:146] step: 319300, eval_loss: 3.19102e-02
I0209 20:10:37.634387 22542570456896 run_lib.py:133] step: 319350, training_loss: 2.83777e-02
I0209 20:10:55.202962 22542570456896 run_lib.py:133] step: 319400, training_loss: 3.07542e-02
I0209 20:10:55.361636 22542570456896 run_lib.py:146] step: 319400, eval_loss: 2.77974e-02
I0209 20:11:12.771128 22542570456896 run_lib.py:133] step: 319450, training_loss: 2.59766e-02
I0209 20:11:30.230464 22542570456896 run_lib.py:133] step: 319500, training_loss: 2.66623e-02
I0209 20:11:30.386595 22542570456896 run_lib.py:146] step: 319500, eval_loss: 3.69801e-02
I0209 20:11:47.987898 22542570456896 run_lib.py:133] step: 319550, training_loss: 2.76385e-02
I0209 20:12:05.463148 22542570456896 run_lib.py:133] step: 319600, training_loss: 2.32666e-02
I0209 20:12:05.619470 22542570456896 run_lib.py:146] step: 319600, eval_loss: 3.50855e-02
I0209 20:12:23.199870 22542570456896 run_lib.py:133] step: 319650, training_loss: 2.87077e-02
I0209 20:12:40.612782 22542570456896 run_lib.py:133] step: 319700, training_loss: 3.33589e-02
I0209 20:12:40.764492 22542570456896 run_lib.py:146] step: 319700, eval_loss: 2.53346e-02
I0209 20:12:58.175942 22542570456896 run_lib.py:133] step: 319750, training_loss: 2.74611e-02
I0209 20:13:15.796277 22542570456896 run_lib.py:133] step: 319800, training_loss: 3.30933e-02
I0209 20:13:15.973262 22542570456896 run_lib.py:146] step: 319800, eval_loss: 3.37698e-02
I0209 20:13:33.446320 22542570456896 run_lib.py:133] step: 319850, training_loss: 3.06351e-02
I0209 20:13:50.961480 22542570456896 run_lib.py:133] step: 319900, training_loss: 2.78159e-02
I0209 20:13:51.119834 22542570456896 run_lib.py:146] step: 319900, eval_loss: 2.97932e-02
I0209 20:14:08.522924 22542570456896 run_lib.py:133] step: 319950, training_loss: 2.40017e-02
I0209 20:14:26.097422 22542570456896 run_lib.py:133] step: 320000, training_loss: 3.06816e-02
I0209 20:14:26.820158 22542570456896 run_lib.py:146] step: 320000, eval_loss: 3.20481e-02
I0209 20:14:47.091994 22542570456896 run_lib.py:133] step: 320050, training_loss: 3.08651e-02
I0209 20:15:04.758107 22542570456896 run_lib.py:133] step: 320100, training_loss: 2.96500e-02
I0209 20:15:04.916613 22542570456896 run_lib.py:146] step: 320100, eval_loss: 2.61748e-02
I0209 20:15:22.322306 22542570456896 run_lib.py:133] step: 320150, training_loss: 3.01902e-02
I0209 20:15:39.730757 22542570456896 run_lib.py:133] step: 320200, training_loss: 2.80457e-02
I0209 20:15:39.886392 22542570456896 run_lib.py:146] step: 320200, eval_loss: 2.47119e-02
I0209 20:15:57.312392 22542570456896 run_lib.py:133] step: 320250, training_loss: 3.14968e-02
I0209 20:16:14.966174 22542570456896 run_lib.py:133] step: 320300, training_loss: 2.79018e-02
I0209 20:16:15.120254 22542570456896 run_lib.py:146] step: 320300, eval_loss: 3.17471e-02
I0209 20:16:32.694238 22542570456896 run_lib.py:133] step: 320350, training_loss: 2.48760e-02
I0209 20:16:50.114468 22542570456896 run_lib.py:133] step: 320400, training_loss: 3.52463e-02
I0209 20:16:50.271486 22542570456896 run_lib.py:146] step: 320400, eval_loss: 3.06057e-02
I0209 20:17:07.683901 22542570456896 run_lib.py:133] step: 320450, training_loss: 2.87288e-02
I0209 20:17:25.167753 22542570456896 run_lib.py:133] step: 320500, training_loss: 2.94327e-02
I0209 20:17:25.322222 22542570456896 run_lib.py:146] step: 320500, eval_loss: 2.79190e-02
I0209 20:17:42.894271 22542570456896 run_lib.py:133] step: 320550, training_loss: 3.20147e-02
I0209 20:18:00.417874 22542570456896 run_lib.py:133] step: 320600, training_loss: 3.05522e-02
I0209 20:18:00.583993 22542570456896 run_lib.py:146] step: 320600, eval_loss: 3.35159e-02
I0209 20:18:18.001394 22542570456896 run_lib.py:133] step: 320650, training_loss: 2.89044e-02
I0209 20:18:35.397545 22542570456896 run_lib.py:133] step: 320700, training_loss: 2.32896e-02
I0209 20:18:35.554066 22542570456896 run_lib.py:146] step: 320700, eval_loss: 3.27315e-02
I0209 20:18:53.159348 22542570456896 run_lib.py:133] step: 320750, training_loss: 3.12860e-02
I0209 20:19:10.577993 22542570456896 run_lib.py:133] step: 320800, training_loss: 3.50231e-02
I0209 20:19:10.740339 22542570456896 run_lib.py:146] step: 320800, eval_loss: 3.26521e-02
I0209 20:19:28.321987 22542570456896 run_lib.py:133] step: 320850, training_loss: 2.93762e-02
I0209 20:19:45.797145 22542570456896 run_lib.py:133] step: 320900, training_loss: 3.22241e-02
I0209 20:19:45.957458 22542570456896 run_lib.py:146] step: 320900, eval_loss: 2.76070e-02
I0209 20:20:03.554035 22542570456896 run_lib.py:133] step: 320950, training_loss: 2.90504e-02
I0209 20:20:20.942534 22542570456896 run_lib.py:133] step: 321000, training_loss: 2.79120e-02
I0209 20:20:21.097487 22542570456896 run_lib.py:146] step: 321000, eval_loss: 4.13366e-02
I0209 20:20:38.512788 22542570456896 run_lib.py:133] step: 321050, training_loss: 2.63280e-02
I0209 20:20:56.101515 22542570456896 run_lib.py:133] step: 321100, training_loss: 2.87356e-02
I0209 20:20:56.263533 22542570456896 run_lib.py:146] step: 321100, eval_loss: 3.22797e-02
I0209 20:21:13.725239 22542570456896 run_lib.py:133] step: 321150, training_loss: 2.60268e-02
I0209 20:21:31.331331 22542570456896 run_lib.py:133] step: 321200, training_loss: 2.34296e-02
I0209 20:21:31.482324 22542570456896 run_lib.py:146] step: 321200, eval_loss: 2.47076e-02
I0209 20:21:48.904378 22542570456896 run_lib.py:133] step: 321250, training_loss: 2.58738e-02
I0209 20:22:06.372787 22542570456896 run_lib.py:133] step: 321300, training_loss: 2.61073e-02
I0209 20:22:06.527438 22542570456896 run_lib.py:146] step: 321300, eval_loss: 2.65171e-02
I0209 20:22:24.066949 22542570456896 run_lib.py:133] step: 321350, training_loss: 2.92737e-02
I0209 20:22:41.534615 22542570456896 run_lib.py:133] step: 321400, training_loss: 2.36030e-02
I0209 20:22:41.715732 22542570456896 run_lib.py:146] step: 321400, eval_loss: 2.75893e-02
I0209 20:22:59.179045 22542570456896 run_lib.py:133] step: 321450, training_loss: 3.12983e-02
I0209 20:23:16.771712 22542570456896 run_lib.py:133] step: 321500, training_loss: 2.61273e-02
I0209 20:23:16.936351 22542570456896 run_lib.py:146] step: 321500, eval_loss: 2.82428e-02
I0209 20:23:34.378533 22542570456896 run_lib.py:133] step: 321550, training_loss: 3.18360e-02
I0209 20:23:51.787696 22542570456896 run_lib.py:133] step: 321600, training_loss: 2.41180e-02
I0209 20:23:52.097305 22542570456896 run_lib.py:146] step: 321600, eval_loss: 3.76132e-02
I0209 20:24:09.538599 22542570456896 run_lib.py:133] step: 321650, training_loss: 2.28628e-02
I0209 20:24:26.998105 22542570456896 run_lib.py:133] step: 321700, training_loss: 3.46596e-02
I0209 20:24:27.153572 22542570456896 run_lib.py:146] step: 321700, eval_loss: 2.83031e-02
I0209 20:24:44.585507 22542570456896 run_lib.py:133] step: 321750, training_loss: 2.61148e-02
I0209 20:25:02.021002 22542570456896 run_lib.py:133] step: 321800, training_loss: 3.33046e-02
I0209 20:25:02.174346 22542570456896 run_lib.py:146] step: 321800, eval_loss: 3.24889e-02
I0209 20:25:19.761458 22542570456896 run_lib.py:133] step: 321850, training_loss: 2.66615e-02
I0209 20:25:37.223528 22542570456896 run_lib.py:133] step: 321900, training_loss: 3.47122e-02
I0209 20:25:37.379544 22542570456896 run_lib.py:146] step: 321900, eval_loss: 2.64447e-02
I0209 20:25:54.819067 22542570456896 run_lib.py:133] step: 321950, training_loss: 2.91160e-02
I0209 20:26:12.255214 22542570456896 run_lib.py:133] step: 322000, training_loss: 2.47220e-02
I0209 20:26:12.416090 22542570456896 run_lib.py:146] step: 322000, eval_loss: 2.93574e-02
I0209 20:26:30.096486 22542570456896 run_lib.py:133] step: 322050, training_loss: 2.24983e-02
I0209 20:26:47.570690 22542570456896 run_lib.py:133] step: 322100, training_loss: 3.01002e-02
I0209 20:26:47.726329 22542570456896 run_lib.py:146] step: 322100, eval_loss: 3.04360e-02
I0209 20:27:05.131169 22542570456896 run_lib.py:133] step: 322150, training_loss: 2.85825e-02
I0209 20:27:22.569394 22542570456896 run_lib.py:133] step: 322200, training_loss: 2.06694e-02
I0209 20:27:22.722602 22542570456896 run_lib.py:146] step: 322200, eval_loss: 2.64653e-02
I0209 20:27:40.411376 22542570456896 run_lib.py:133] step: 322250, training_loss: 3.67459e-02
I0209 20:27:57.854869 22542570456896 run_lib.py:133] step: 322300, training_loss: 2.65569e-02
I0209 20:27:58.014434 22542570456896 run_lib.py:146] step: 322300, eval_loss: 3.23877e-02
I0209 20:28:15.583637 22542570456896 run_lib.py:133] step: 322350, training_loss: 2.44501e-02
I0209 20:28:33.012582 22542570456896 run_lib.py:133] step: 322400, training_loss: 3.33702e-02
I0209 20:28:33.170813 22542570456896 run_lib.py:146] step: 322400, eval_loss: 3.18974e-02
I0209 20:28:50.780279 22542570456896 run_lib.py:133] step: 322450, training_loss: 2.48841e-02
I0209 20:29:08.247011 22542570456896 run_lib.py:133] step: 322500, training_loss: 2.89479e-02
I0209 20:29:08.403048 22542570456896 run_lib.py:146] step: 322500, eval_loss: 3.22654e-02
I0209 20:29:25.876898 22542570456896 run_lib.py:133] step: 322550, training_loss: 2.59782e-02
I0209 20:29:43.491902 22542570456896 run_lib.py:133] step: 322600, training_loss: 2.92778e-02
I0209 20:29:43.644129 22542570456896 run_lib.py:146] step: 322600, eval_loss: 2.62769e-02
I0209 20:30:01.048635 22542570456896 run_lib.py:133] step: 322650, training_loss: 2.71834e-02
I0209 20:30:18.605041 22542570456896 run_lib.py:133] step: 322700, training_loss: 2.66218e-02
I0209 20:30:18.762560 22542570456896 run_lib.py:146] step: 322700, eval_loss: 3.15290e-02
I0209 20:30:36.202532 22542570456896 run_lib.py:133] step: 322750, training_loss: 2.36704e-02
I0209 20:30:53.676181 22542570456896 run_lib.py:133] step: 322800, training_loss: 2.19030e-02
I0209 20:30:53.835270 22542570456896 run_lib.py:146] step: 322800, eval_loss: 3.17500e-02
I0209 20:31:11.504716 22542570456896 run_lib.py:133] step: 322850, training_loss: 2.53111e-02
I0209 20:31:28.939876 22542570456896 run_lib.py:133] step: 322900, training_loss: 2.28712e-02
I0209 20:31:29.092651 22542570456896 run_lib.py:146] step: 322900, eval_loss: 3.30259e-02
I0209 20:31:46.516450 22542570456896 run_lib.py:133] step: 322950, training_loss: 2.19663e-02
I0209 20:32:03.945465 22542570456896 run_lib.py:133] step: 323000, training_loss: 3.53284e-02
I0209 20:32:04.101696 22542570456896 run_lib.py:146] step: 323000, eval_loss: 2.20959e-02
I0209 20:32:21.661159 22542570456896 run_lib.py:133] step: 323050, training_loss: 3.06539e-02
I0209 20:32:39.114569 22542570456896 run_lib.py:133] step: 323100, training_loss: 2.33776e-02
I0209 20:32:39.269451 22542570456896 run_lib.py:146] step: 323100, eval_loss: 3.24294e-02
I0209 20:32:56.813979 22542570456896 run_lib.py:133] step: 323150, training_loss: 3.69368e-02
I0209 20:33:14.278459 22542570456896 run_lib.py:133] step: 323200, training_loss: 2.81606e-02
I0209 20:33:14.433467 22542570456896 run_lib.py:146] step: 323200, eval_loss: 2.46124e-02
I0209 20:33:31.823931 22542570456896 run_lib.py:133] step: 323250, training_loss: 2.60122e-02
I0209 20:33:49.259596 22542570456896 run_lib.py:133] step: 323300, training_loss: 2.85957e-02
I0209 20:33:49.418606 22542570456896 run_lib.py:146] step: 323300, eval_loss: 2.88362e-02
I0209 20:34:07.008105 22542570456896 run_lib.py:133] step: 323350, training_loss: 2.98962e-02
I0209 20:34:24.553569 22542570456896 run_lib.py:133] step: 323400, training_loss: 3.27416e-02
I0209 20:34:24.709508 22542570456896 run_lib.py:146] step: 323400, eval_loss: 3.17999e-02
I0209 20:34:42.139721 22542570456896 run_lib.py:133] step: 323450, training_loss: 2.63914e-02
I0209 20:34:59.561617 22542570456896 run_lib.py:133] step: 323500, training_loss: 3.08063e-02
I0209 20:34:59.716327 22542570456896 run_lib.py:146] step: 323500, eval_loss: 3.10337e-02
I0209 20:35:17.274179 22542570456896 run_lib.py:133] step: 323550, training_loss: 3.61633e-02
I0209 20:35:34.701500 22542570456896 run_lib.py:133] step: 323600, training_loss: 2.67226e-02
I0209 20:35:34.855747 22542570456896 run_lib.py:146] step: 323600, eval_loss: 2.37226e-02
I0209 20:35:52.478668 22542570456896 run_lib.py:133] step: 323650, training_loss: 2.67635e-02
I0209 20:36:09.879957 22542570456896 run_lib.py:133] step: 323700, training_loss: 2.94939e-02
I0209 20:36:10.036303 22542570456896 run_lib.py:146] step: 323700, eval_loss: 2.35737e-02
I0209 20:36:27.638474 22542570456896 run_lib.py:133] step: 323750, training_loss: 2.64412e-02
I0209 20:36:45.059899 22542570456896 run_lib.py:133] step: 323800, training_loss: 2.29278e-02
I0209 20:36:45.215448 22542570456896 run_lib.py:146] step: 323800, eval_loss: 2.66896e-02
I0209 20:37:02.808795 22542570456896 run_lib.py:133] step: 323850, training_loss: 2.89526e-02
I0209 20:37:20.283720 22542570456896 run_lib.py:133] step: 323900, training_loss: 3.00851e-02
I0209 20:37:20.444811 22542570456896 run_lib.py:146] step: 323900, eval_loss: 2.81713e-02
I0209 20:37:37.902903 22542570456896 run_lib.py:133] step: 323950, training_loss: 2.13975e-02
I0209 20:37:55.548248 22542570456896 run_lib.py:133] step: 324000, training_loss: 2.53102e-02
I0209 20:37:55.702019 22542570456896 run_lib.py:146] step: 324000, eval_loss: 2.93075e-02
I0209 20:38:13.137829 22542570456896 run_lib.py:133] step: 324050, training_loss: 2.75011e-02
I0209 20:38:30.534184 22542570456896 run_lib.py:133] step: 324100, training_loss: 3.12468e-02
I0209 20:38:30.685318 22542570456896 run_lib.py:146] step: 324100, eval_loss: 2.54596e-02
I0209 20:38:48.291233 22542570456896 run_lib.py:133] step: 324150, training_loss: 2.41647e-02
I0209 20:39:05.907416 22542570456896 run_lib.py:133] step: 324200, training_loss: 3.03581e-02
I0209 20:39:06.071367 22542570456896 run_lib.py:146] step: 324200, eval_loss: 3.40477e-02
I0209 20:39:23.502516 22542570456896 run_lib.py:133] step: 324250, training_loss: 3.33531e-02
I0209 20:39:40.896661 22542570456896 run_lib.py:133] step: 324300, training_loss: 2.20436e-02
I0209 20:39:41.052368 22542570456896 run_lib.py:146] step: 324300, eval_loss: 3.15214e-02
I0209 20:39:58.473311 22542570456896 run_lib.py:133] step: 324350, training_loss: 2.99956e-02
I0209 20:40:16.037940 22542570456896 run_lib.py:133] step: 324400, training_loss: 2.68419e-02
I0209 20:40:16.198164 22542570456896 run_lib.py:146] step: 324400, eval_loss: 2.38122e-02
I0209 20:40:33.635510 22542570456896 run_lib.py:133] step: 324450, training_loss: 2.76621e-02
I0209 20:40:51.050147 22542570456896 run_lib.py:133] step: 324500, training_loss: 2.93061e-02
I0209 20:40:51.206681 22542570456896 run_lib.py:146] step: 324500, eval_loss: 2.78564e-02
I0209 20:41:08.642181 22542570456896 run_lib.py:133] step: 324550, training_loss: 3.42424e-02
I0209 20:41:26.276018 22542570456896 run_lib.py:133] step: 324600, training_loss: 2.84516e-02
I0209 20:41:26.431339 22542570456896 run_lib.py:146] step: 324600, eval_loss: 3.62286e-02
I0209 20:41:43.847313 22542570456896 run_lib.py:133] step: 324650, training_loss: 2.59996e-02
I0209 20:42:01.326862 22542570456896 run_lib.py:133] step: 324700, training_loss: 2.57809e-02
I0209 20:42:01.502261 22542570456896 run_lib.py:146] step: 324700, eval_loss: 2.66048e-02
I0209 20:42:18.951566 22542570456896 run_lib.py:133] step: 324750, training_loss: 2.69947e-02
I0209 20:42:36.394525 22542570456896 run_lib.py:133] step: 324800, training_loss: 2.76888e-02
I0209 20:42:36.558587 22542570456896 run_lib.py:146] step: 324800, eval_loss: 2.91422e-02
I0209 20:42:54.165369 22542570456896 run_lib.py:133] step: 324850, training_loss: 3.05894e-02
I0209 20:43:11.651112 22542570456896 run_lib.py:133] step: 324900, training_loss: 3.32952e-02
I0209 20:43:11.804337 22542570456896 run_lib.py:146] step: 324900, eval_loss: 2.83707e-02
I0209 20:43:29.219446 22542570456896 run_lib.py:133] step: 324950, training_loss: 2.25567e-02
I0209 20:43:46.711208 22542570456896 run_lib.py:133] step: 325000, training_loss: 3.40546e-02
I0209 20:43:46.865503 22542570456896 run_lib.py:146] step: 325000, eval_loss: 2.73010e-02
I0209 20:44:04.499395 22542570456896 run_lib.py:133] step: 325050, training_loss: 2.82320e-02
I0209 20:44:21.922587 22542570456896 run_lib.py:133] step: 325100, training_loss: 2.53440e-02
I0209 20:44:22.077312 22542570456896 run_lib.py:146] step: 325100, eval_loss: 2.76935e-02
I0209 20:44:39.654355 22542570456896 run_lib.py:133] step: 325150, training_loss: 2.72207e-02
I0209 20:44:57.118556 22542570456896 run_lib.py:133] step: 325200, training_loss: 2.17293e-02
I0209 20:44:57.275567 22542570456896 run_lib.py:146] step: 325200, eval_loss: 3.04369e-02
I0209 20:45:14.836185 22542570456896 run_lib.py:133] step: 325250, training_loss: 2.28781e-02
I0209 20:45:32.294585 22542570456896 run_lib.py:133] step: 325300, training_loss: 2.46990e-02
I0209 20:45:32.451493 22542570456896 run_lib.py:146] step: 325300, eval_loss: 2.14476e-02
I0209 20:45:49.915178 22542570456896 run_lib.py:133] step: 325350, training_loss: 3.06141e-02
I0209 20:46:07.539009 22542570456896 run_lib.py:133] step: 325400, training_loss: 3.42432e-02
I0209 20:46:07.696401 22542570456896 run_lib.py:146] step: 325400, eval_loss: 3.13497e-02
I0209 20:46:25.130423 22542570456896 run_lib.py:133] step: 325450, training_loss: 2.98205e-02
I0209 20:46:42.689792 22542570456896 run_lib.py:133] step: 325500, training_loss: 2.81656e-02
I0209 20:46:42.842431 22542570456896 run_lib.py:146] step: 325500, eval_loss: 2.51998e-02
I0209 20:47:00.250454 22542570456896 run_lib.py:133] step: 325550, training_loss: 2.57743e-02
I0209 20:47:17.706036 22542570456896 run_lib.py:133] step: 325600, training_loss: 3.49364e-02
I0209 20:47:17.881288 22542570456896 run_lib.py:146] step: 325600, eval_loss: 2.83913e-02
I0209 20:47:35.519463 22542570456896 run_lib.py:133] step: 325650, training_loss: 3.07114e-02
I0209 20:47:52.937702 22542570456896 run_lib.py:133] step: 325700, training_loss: 2.67988e-02
I0209 20:47:53.102428 22542570456896 run_lib.py:146] step: 325700, eval_loss: 2.49701e-02
I0209 20:48:10.505079 22542570456896 run_lib.py:133] step: 325750, training_loss: 2.84944e-02
I0209 20:48:28.070402 22542570456896 run_lib.py:133] step: 325800, training_loss: 2.88375e-02
I0209 20:48:28.225367 22542570456896 run_lib.py:146] step: 325800, eval_loss: 3.17044e-02
I0209 20:48:45.646227 22542570456896 run_lib.py:133] step: 325850, training_loss: 2.36898e-02
I0209 20:49:03.113892 22542570456896 run_lib.py:133] step: 325900, training_loss: 2.88086e-02
I0209 20:49:03.268138 22542570456896 run_lib.py:146] step: 325900, eval_loss: 3.79042e-02
I0209 20:49:20.820246 22542570456896 run_lib.py:133] step: 325950, training_loss: 2.69804e-02
I0209 20:49:38.237640 22542570456896 run_lib.py:133] step: 326000, training_loss: 2.37350e-02
I0209 20:49:38.390897 22542570456896 run_lib.py:146] step: 326000, eval_loss: 2.56732e-02
I0209 20:49:55.778701 22542570456896 run_lib.py:133] step: 326050, training_loss: 2.93555e-02
I0209 20:50:13.267812 22542570456896 run_lib.py:133] step: 326100, training_loss: 2.78911e-02
I0209 20:50:13.435056 22542570456896 run_lib.py:146] step: 326100, eval_loss: 3.16569e-02
I0209 20:50:31.025445 22542570456896 run_lib.py:133] step: 326150, training_loss: 2.39323e-02
I0209 20:50:48.560365 22542570456896 run_lib.py:133] step: 326200, training_loss: 2.94794e-02
I0209 20:50:48.713698 22542570456896 run_lib.py:146] step: 326200, eval_loss: 2.43647e-02
I0209 20:51:06.101247 22542570456896 run_lib.py:133] step: 326250, training_loss: 2.94337e-02
I0209 20:51:23.477991 22542570456896 run_lib.py:133] step: 326300, training_loss: 2.54783e-02
I0209 20:51:23.634550 22542570456896 run_lib.py:146] step: 326300, eval_loss: 2.75351e-02
I0209 20:51:41.206869 22542570456896 run_lib.py:133] step: 326350, training_loss: 2.64880e-02
I0209 20:51:58.678782 22542570456896 run_lib.py:133] step: 326400, training_loss: 2.18302e-02
I0209 20:51:58.841259 22542570456896 run_lib.py:146] step: 326400, eval_loss: 2.89540e-02
I0209 20:52:16.475837 22542570456896 run_lib.py:133] step: 326450, training_loss: 2.52546e-02
I0209 20:52:33.864301 22542570456896 run_lib.py:133] step: 326500, training_loss: 2.86776e-02
I0209 20:52:34.019279 22542570456896 run_lib.py:146] step: 326500, eval_loss: 3.00710e-02
I0209 20:52:51.610500 22542570456896 run_lib.py:133] step: 326550, training_loss: 2.84517e-02
I0209 20:53:09.016819 22542570456896 run_lib.py:133] step: 326600, training_loss: 2.60860e-02
I0209 20:53:09.171571 22542570456896 run_lib.py:146] step: 326600, eval_loss: 2.65604e-02
I0209 20:53:26.743343 22542570456896 run_lib.py:133] step: 326650, training_loss: 2.43597e-02
I0209 20:53:44.212789 22542570456896 run_lib.py:133] step: 326700, training_loss: 2.57211e-02
I0209 20:53:44.368837 22542570456896 run_lib.py:146] step: 326700, eval_loss: 2.49216e-02
I0209 20:54:01.843716 22542570456896 run_lib.py:133] step: 326750, training_loss: 2.50247e-02
I0209 20:54:19.430459 22542570456896 run_lib.py:133] step: 326800, training_loss: 2.54652e-02
I0209 20:54:19.586381 22542570456896 run_lib.py:146] step: 326800, eval_loss: 3.14054e-02
I0209 20:54:37.062571 22542570456896 run_lib.py:133] step: 326850, training_loss: 2.15941e-02
I0209 20:54:54.420951 22542570456896 run_lib.py:133] step: 326900, training_loss: 2.82839e-02
I0209 20:54:54.574442 22542570456896 run_lib.py:146] step: 326900, eval_loss: 2.98499e-02
I0209 20:55:12.128820 22542570456896 run_lib.py:133] step: 326950, training_loss: 2.91800e-02
I0209 20:55:29.565427 22542570456896 run_lib.py:133] step: 327000, training_loss: 2.22973e-02
I0209 20:55:29.734513 22542570456896 run_lib.py:146] step: 327000, eval_loss: 2.62870e-02
I0209 20:55:47.364148 22542570456896 run_lib.py:133] step: 327050, training_loss: 3.11546e-02
I0209 20:56:04.835797 22542570456896 run_lib.py:133] step: 327100, training_loss: 3.07441e-02
I0209 20:56:05.000430 22542570456896 run_lib.py:146] step: 327100, eval_loss: 2.60141e-02
I0209 20:56:22.407673 22542570456896 run_lib.py:133] step: 327150, training_loss: 2.72105e-02
I0209 20:56:39.962531 22542570456896 run_lib.py:133] step: 327200, training_loss: 3.24780e-02
I0209 20:56:40.118391 22542570456896 run_lib.py:146] step: 327200, eval_loss: 2.89823e-02
I0209 20:56:57.502890 22542570456896 run_lib.py:133] step: 327250, training_loss: 2.73423e-02
I0209 20:57:14.970875 22542570456896 run_lib.py:133] step: 327300, training_loss: 3.04784e-02
I0209 20:57:15.126515 22542570456896 run_lib.py:146] step: 327300, eval_loss: 2.41528e-02
I0209 20:57:32.597995 22542570456896 run_lib.py:133] step: 327350, training_loss: 2.81532e-02
I0209 20:57:50.219083 22542570456896 run_lib.py:133] step: 327400, training_loss: 2.48978e-02
I0209 20:57:50.371348 22542570456896 run_lib.py:146] step: 327400, eval_loss: 2.38283e-02
I0209 20:58:07.761581 22542570456896 run_lib.py:133] step: 327450, training_loss: 2.29967e-02
I0209 20:58:25.254302 22542570456896 run_lib.py:133] step: 327500, training_loss: 3.03969e-02
I0209 20:58:25.424188 22542570456896 run_lib.py:146] step: 327500, eval_loss: 2.27389e-02
I0209 20:58:42.875766 22542570456896 run_lib.py:133] step: 327550, training_loss: 2.55255e-02
I0209 20:59:00.311864 22542570456896 run_lib.py:133] step: 327600, training_loss: 2.28102e-02
I0209 20:59:00.467318 22542570456896 run_lib.py:146] step: 327600, eval_loss: 3.51155e-02
I0209 20:59:18.051038 22542570456896 run_lib.py:133] step: 327650, training_loss: 3.19480e-02
I0209 20:59:35.545689 22542570456896 run_lib.py:133] step: 327700, training_loss: 3.08487e-02
I0209 20:59:35.699559 22542570456896 run_lib.py:146] step: 327700, eval_loss: 2.98244e-02
I0209 20:59:53.097817 22542570456896 run_lib.py:133] step: 327750, training_loss: 2.18740e-02
I0209 21:00:10.539370 22542570456896 run_lib.py:133] step: 327800, training_loss: 3.33788e-02
I0209 21:00:10.705192 22542570456896 run_lib.py:146] step: 327800, eval_loss: 3.29800e-02
I0209 21:00:28.304149 22542570456896 run_lib.py:133] step: 327850, training_loss: 2.79984e-02
I0209 21:00:45.759293 22542570456896 run_lib.py:133] step: 327900, training_loss: 2.51497e-02
I0209 21:00:45.913341 22542570456896 run_lib.py:146] step: 327900, eval_loss: 3.34200e-02
I0209 21:01:03.462492 22542570456896 run_lib.py:133] step: 327950, training_loss: 2.49624e-02
I0209 21:01:20.864251 22542570456896 run_lib.py:133] step: 328000, training_loss: 3.25853e-02
I0209 21:01:21.023521 22542570456896 run_lib.py:146] step: 328000, eval_loss: 3.16345e-02
I0209 21:01:38.568734 22542570456896 run_lib.py:133] step: 328050, training_loss: 2.55128e-02
I0209 21:01:55.958387 22542570456896 run_lib.py:133] step: 328100, training_loss: 2.76364e-02
I0209 21:01:56.124480 22542570456896 run_lib.py:146] step: 328100, eval_loss: 2.55310e-02
I0209 21:02:13.607312 22542570456896 run_lib.py:133] step: 328150, training_loss: 2.62495e-02
I0209 21:02:31.236014 22542570456896 run_lib.py:133] step: 328200, training_loss: 3.15203e-02
I0209 21:02:31.400641 22542570456896 run_lib.py:146] step: 328200, eval_loss: 2.93438e-02
I0209 21:02:48.807189 22542570456896 run_lib.py:133] step: 328250, training_loss: 2.53966e-02
I0209 21:03:06.367765 22542570456896 run_lib.py:133] step: 328300, training_loss: 3.41964e-02
I0209 21:03:06.527404 22542570456896 run_lib.py:146] step: 328300, eval_loss: 3.22170e-02
I0209 21:03:23.913550 22542570456896 run_lib.py:133] step: 328350, training_loss: 2.65051e-02
I0209 21:03:41.302198 22542570456896 run_lib.py:133] step: 328400, training_loss: 2.62823e-02
I0209 21:03:41.475552 22542570456896 run_lib.py:146] step: 328400, eval_loss: 2.97233e-02
I0209 21:03:59.120329 22542570456896 run_lib.py:133] step: 328450, training_loss: 2.77223e-02
I0209 21:04:16.559179 22542570456896 run_lib.py:133] step: 328500, training_loss: 2.27983e-02
I0209 21:04:16.717546 22542570456896 run_lib.py:146] step: 328500, eval_loss: 2.76713e-02
I0209 21:04:34.122195 22542570456896 run_lib.py:133] step: 328550, training_loss: 2.52823e-02
I0209 21:04:51.679182 22542570456896 run_lib.py:133] step: 328600, training_loss: 2.80331e-02
I0209 21:04:51.835278 22542570456896 run_lib.py:146] step: 328600, eval_loss: 2.68523e-02
I0209 21:05:09.228715 22542570456896 run_lib.py:133] step: 328650, training_loss: 2.80186e-02
I0209 21:05:26.751556 22542570456896 run_lib.py:133] step: 328700, training_loss: 3.43716e-02
I0209 21:05:27.105362 22542570456896 run_lib.py:146] step: 328700, eval_loss: 2.98170e-02
I0209 21:05:44.570146 22542570456896 run_lib.py:133] step: 328750, training_loss: 2.57739e-02
I0209 21:06:01.989616 22542570456896 run_lib.py:133] step: 328800, training_loss: 2.49114e-02
I0209 21:06:02.138395 22542570456896 run_lib.py:146] step: 328800, eval_loss: 2.60517e-02
I0209 21:06:19.572178 22542570456896 run_lib.py:133] step: 328850, training_loss: 3.10156e-02
I0209 21:06:37.002525 22542570456896 run_lib.py:133] step: 328900, training_loss: 2.76094e-02
I0209 21:06:37.170517 22542570456896 run_lib.py:146] step: 328900, eval_loss: 3.11842e-02
I0209 21:06:54.776422 22542570456896 run_lib.py:133] step: 328950, training_loss: 3.35638e-02
I0209 21:07:12.324384 22542570456896 run_lib.py:133] step: 329000, training_loss: 2.63088e-02
I0209 21:07:12.482312 22542570456896 run_lib.py:146] step: 329000, eval_loss: 3.31882e-02
I0209 21:07:29.891028 22542570456896 run_lib.py:133] step: 329050, training_loss: 2.35371e-02
I0209 21:07:47.327604 22542570456896 run_lib.py:133] step: 329100, training_loss: 3.06938e-02
I0209 21:07:47.484316 22542570456896 run_lib.py:146] step: 329100, eval_loss: 2.76619e-02
I0209 21:08:05.060041 22542570456896 run_lib.py:133] step: 329150, training_loss: 2.50756e-02
I0209 21:08:22.575002 22542570456896 run_lib.py:133] step: 329200, training_loss: 2.35212e-02
I0209 21:08:22.730396 22542570456896 run_lib.py:146] step: 329200, eval_loss: 2.68970e-02
I0209 21:08:40.120709 22542570456896 run_lib.py:133] step: 329250, training_loss: 2.60026e-02
I0209 21:08:57.399227 22542570456896 run_lib.py:133] step: 329300, training_loss: 3.18088e-02
I0209 21:08:57.549178 22542570456896 run_lib.py:146] step: 329300, eval_loss: 3.23038e-02
I0209 21:09:15.076595 22542570456896 run_lib.py:133] step: 329350, training_loss: 3.16144e-02
I0209 21:09:32.485940 22542570456896 run_lib.py:133] step: 329400, training_loss: 2.71620e-02
I0209 21:09:32.645561 22542570456896 run_lib.py:146] step: 329400, eval_loss: 2.80037e-02
I0209 21:09:50.226433 22542570456896 run_lib.py:133] step: 329450, training_loss: 3.19582e-02
I0209 21:10:07.677119 22542570456896 run_lib.py:133] step: 329500, training_loss: 2.66198e-02
I0209 21:10:07.844413 22542570456896 run_lib.py:146] step: 329500, eval_loss: 2.80104e-02
I0209 21:10:25.426024 22542570456896 run_lib.py:133] step: 329550, training_loss: 3.02964e-02
I0209 21:10:42.828966 22542570456896 run_lib.py:133] step: 329600, training_loss: 2.46333e-02
I0209 21:10:42.983886 22542570456896 run_lib.py:146] step: 329600, eval_loss: 2.43157e-02
I0209 21:11:00.463462 22542570456896 run_lib.py:133] step: 329650, training_loss: 2.68134e-02
I0209 21:11:18.032431 22542570456896 run_lib.py:133] step: 329700, training_loss: 3.29048e-02
I0209 21:11:18.187453 22542570456896 run_lib.py:146] step: 329700, eval_loss: 2.16201e-02
I0209 21:11:35.654645 22542570456896 run_lib.py:133] step: 329750, training_loss: 3.21097e-02
I0209 21:11:53.268311 22542570456896 run_lib.py:133] step: 329800, training_loss: 2.83506e-02
I0209 21:11:53.426642 22542570456896 run_lib.py:146] step: 329800, eval_loss: 3.33263e-02
I0209 21:12:10.872069 22542570456896 run_lib.py:133] step: 329850, training_loss: 2.89277e-02
I0209 21:12:28.343422 22542570456896 run_lib.py:133] step: 329900, training_loss: 3.00929e-02
I0209 21:12:28.502604 22542570456896 run_lib.py:146] step: 329900, eval_loss: 3.06450e-02
I0209 21:12:46.079115 22542570456896 run_lib.py:133] step: 329950, training_loss: 2.81758e-02
I0209 21:13:03.521161 22542570456896 run_lib.py:133] step: 330000, training_loss: 2.23044e-02
I0209 21:13:04.282163 22542570456896 run_lib.py:146] step: 330000, eval_loss: 2.51898e-02
I0209 21:13:24.754417 22542570456896 run_lib.py:133] step: 330050, training_loss: 3.25604e-02
I0209 21:13:42.268219 22542570456896 run_lib.py:133] step: 330100, training_loss: 2.71202e-02
I0209 21:13:42.421784 22542570456896 run_lib.py:146] step: 330100, eval_loss: 3.39840e-02
I0209 21:13:59.810447 22542570456896 run_lib.py:133] step: 330150, training_loss: 2.51331e-02
I0209 21:14:17.228606 22542570456896 run_lib.py:133] step: 330200, training_loss: 2.62856e-02
I0209 21:14:17.387714 22542570456896 run_lib.py:146] step: 330200, eval_loss: 3.40891e-02
