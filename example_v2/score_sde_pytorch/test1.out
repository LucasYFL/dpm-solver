WARNING:tensorflow:From /home/yifulu/.conda/envs/qq/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W0207 22:07:37.881910 23092487714304 utils.py:10] No checkpoint found at experiments/checkpoints-meta/checkpoint.pth. Returned the same state as input
W0207 22:07:37.927544 23092487714304 xla_bridge.py:135] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0207 22:07:37.930135 23092487714304 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0207 22:07:37.934802 23092487714304 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0207 22:07:37.934920 23092487714304 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0207 22:07:37.935056 23092487714304 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0207 22:07:37.935153 23092487714304 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0207 22:07:38.130399 23092487714304 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0207 22:07:38.130626 23092487714304 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0207 22:07:38.130751 23092487714304 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0207 22:07:38.130831 23092487714304 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0207 22:07:38.299834 23092487714304 run_lib.py:123] Starting training loop at step 0.
I0207 22:08:01.600339 23092487714304 run_lib.py:133] step: 0, training_loss: 9.97581e-01
I0207 22:08:03.094717 23092487714304 run_lib.py:146] step: 0, eval_loss: 1.00025e+00
I0207 22:08:18.158922 23092487714304 run_lib.py:133] step: 50, training_loss: 9.88888e-01
I0207 22:08:33.234939 23092487714304 run_lib.py:133] step: 100, training_loss: 9.54511e-01
I0207 22:08:33.348606 23092487714304 run_lib.py:146] step: 100, eval_loss: 9.70902e-01
I0207 22:08:48.434579 23092487714304 run_lib.py:133] step: 150, training_loss: 8.88050e-01
I0207 22:09:03.578455 23092487714304 run_lib.py:133] step: 200, training_loss: 8.09841e-01
I0207 22:09:03.689531 23092487714304 run_lib.py:146] step: 200, eval_loss: 8.36648e-01
I0207 22:09:18.792037 23092487714304 run_lib.py:133] step: 250, training_loss: 7.07413e-01
I0207 22:09:33.912260 23092487714304 run_lib.py:133] step: 300, training_loss: 5.96190e-01
I0207 22:09:34.025680 23092487714304 run_lib.py:146] step: 300, eval_loss: 6.58306e-01
I0207 22:09:48.323689 23092487714304 run_lib.py:133] step: 350, training_loss: 4.88185e-01
I0207 22:10:02.444340 23092487714304 run_lib.py:133] step: 400, training_loss: 3.79308e-01
I0207 22:10:02.555163 23092487714304 run_lib.py:146] step: 400, eval_loss: 4.51251e-01
I0207 22:10:16.819172 23092487714304 run_lib.py:133] step: 450, training_loss: 2.67981e-01
I0207 22:10:31.120321 23092487714304 run_lib.py:133] step: 500, training_loss: 1.67298e-01
I0207 22:10:31.234884 23092487714304 run_lib.py:146] step: 500, eval_loss: 2.47806e-01
I0207 22:10:45.398618 23092487714304 run_lib.py:133] step: 550, training_loss: 1.21943e-01
I0207 22:10:59.563510 23092487714304 run_lib.py:133] step: 600, training_loss: 6.93368e-02
I0207 22:10:59.674046 23092487714304 run_lib.py:146] step: 600, eval_loss: 1.06815e-01
I0207 22:11:13.835373 23092487714304 run_lib.py:133] step: 650, training_loss: 4.54875e-02
I0207 22:11:28.011554 23092487714304 run_lib.py:133] step: 700, training_loss: 4.86160e-02
I0207 22:11:28.124079 23092487714304 run_lib.py:146] step: 700, eval_loss: 4.85614e-02
I0207 22:11:42.274226 23092487714304 run_lib.py:133] step: 750, training_loss: 3.26283e-02
I0207 22:11:56.406612 23092487714304 run_lib.py:133] step: 800, training_loss: 5.54812e-02
I0207 22:11:56.515794 23092487714304 run_lib.py:146] step: 800, eval_loss: 5.36676e-02
I0207 22:12:10.654470 23092487714304 run_lib.py:133] step: 850, training_loss: 3.25729e-02
I0207 22:12:24.802831 23092487714304 run_lib.py:133] step: 900, training_loss: 2.70075e-02
I0207 22:12:24.913148 23092487714304 run_lib.py:146] step: 900, eval_loss: 3.18949e-02
I0207 22:12:39.049869 23092487714304 run_lib.py:133] step: 950, training_loss: 4.22334e-02
I0207 22:12:53.189085 23092487714304 run_lib.py:133] step: 1000, training_loss: 4.22759e-02
I0207 22:12:53.297820 23092487714304 run_lib.py:146] step: 1000, eval_loss: 2.60479e-02
I0207 22:13:07.436189 23092487714304 run_lib.py:133] step: 1050, training_loss: 6.51477e-02
I0207 22:13:21.613201 23092487714304 run_lib.py:133] step: 1100, training_loss: 3.98954e-02
I0207 22:13:21.724077 23092487714304 run_lib.py:146] step: 1100, eval_loss: 3.26774e-02
I0207 22:13:35.872390 23092487714304 run_lib.py:133] step: 1150, training_loss: 2.76783e-02
I0207 22:13:50.014441 23092487714304 run_lib.py:133] step: 1200, training_loss: 4.11218e-02
I0207 22:13:50.123417 23092487714304 run_lib.py:146] step: 1200, eval_loss: 4.32353e-02
I0207 22:14:04.267036 23092487714304 run_lib.py:133] step: 1250, training_loss: 3.55719e-02
I0207 22:14:18.421169 23092487714304 run_lib.py:133] step: 1300, training_loss: 5.72567e-02
I0207 22:14:18.530604 23092487714304 run_lib.py:146] step: 1300, eval_loss: 3.11478e-02
I0207 22:14:32.681300 23092487714304 run_lib.py:133] step: 1350, training_loss: 3.69887e-02
I0207 22:14:46.839749 23092487714304 run_lib.py:133] step: 1400, training_loss: 4.22468e-02
I0207 22:14:46.949152 23092487714304 run_lib.py:146] step: 1400, eval_loss: 4.00244e-02
I0207 22:15:01.101341 23092487714304 run_lib.py:133] step: 1450, training_loss: 5.71558e-02
I0207 22:15:15.254819 23092487714304 run_lib.py:133] step: 1500, training_loss: 2.84390e-02
I0207 22:15:15.364418 23092487714304 run_lib.py:146] step: 1500, eval_loss: 3.86072e-02
I0207 22:15:29.514468 23092487714304 run_lib.py:133] step: 1550, training_loss: 3.13204e-02
I0207 22:15:43.664688 23092487714304 run_lib.py:133] step: 1600, training_loss: 3.81309e-02
I0207 22:15:43.775086 23092487714304 run_lib.py:146] step: 1600, eval_loss: 3.42413e-02
I0207 22:15:57.914074 23092487714304 run_lib.py:133] step: 1650, training_loss: 3.35435e-02
I0207 22:16:12.060648 23092487714304 run_lib.py:133] step: 1700, training_loss: 4.64633e-02
I0207 22:16:12.171367 23092487714304 run_lib.py:146] step: 1700, eval_loss: 4.54968e-02
I0207 22:16:26.323135 23092487714304 run_lib.py:133] step: 1750, training_loss: 4.40836e-02
I0207 22:16:40.471637 23092487714304 run_lib.py:133] step: 1800, training_loss: 3.27866e-02
I0207 22:16:40.580608 23092487714304 run_lib.py:146] step: 1800, eval_loss: 3.78880e-02
I0207 22:16:54.750256 23092487714304 run_lib.py:133] step: 1850, training_loss: 4.20926e-02
I0207 22:17:08.902446 23092487714304 run_lib.py:133] step: 1900, training_loss: 2.42364e-02
I0207 22:17:09.012414 23092487714304 run_lib.py:146] step: 1900, eval_loss: 3.85306e-02
I0207 22:17:23.151960 23092487714304 run_lib.py:133] step: 1950, training_loss: 6.28761e-02
I0207 22:17:37.297308 23092487714304 run_lib.py:133] step: 2000, training_loss: 4.53412e-02
I0207 22:17:37.405760 23092487714304 run_lib.py:146] step: 2000, eval_loss: 2.29335e-02
I0207 22:17:51.545886 23092487714304 run_lib.py:133] step: 2050, training_loss: 3.31304e-02
I0207 22:18:05.683908 23092487714304 run_lib.py:133] step: 2100, training_loss: 4.19462e-02
I0207 22:18:05.793202 23092487714304 run_lib.py:146] step: 2100, eval_loss: 4.95104e-02
I0207 22:18:19.963543 23092487714304 run_lib.py:133] step: 2150, training_loss: 2.92475e-02
I0207 22:18:34.123661 23092487714304 run_lib.py:133] step: 2200, training_loss: 3.72465e-02
I0207 22:18:34.233585 23092487714304 run_lib.py:146] step: 2200, eval_loss: 4.00459e-02
I0207 22:18:48.399316 23092487714304 run_lib.py:133] step: 2250, training_loss: 3.37843e-02
I0207 22:19:02.550785 23092487714304 run_lib.py:133] step: 2300, training_loss: 3.72777e-02
I0207 22:19:02.661173 23092487714304 run_lib.py:146] step: 2300, eval_loss: 2.66054e-02
I0207 22:19:16.802058 23092487714304 run_lib.py:133] step: 2350, training_loss: 3.44756e-02
I0207 22:19:30.935107 23092487714304 run_lib.py:133] step: 2400, training_loss: 2.51662e-02
I0207 22:19:31.043567 23092487714304 run_lib.py:146] step: 2400, eval_loss: 2.70286e-02
I0207 22:19:45.187035 23092487714304 run_lib.py:133] step: 2450, training_loss: 4.84534e-02
I0207 22:19:59.329733 23092487714304 run_lib.py:133] step: 2500, training_loss: 3.34668e-02
I0207 22:19:59.439562 23092487714304 run_lib.py:146] step: 2500, eval_loss: 3.75829e-02
I0207 22:20:13.579157 23092487714304 run_lib.py:133] step: 2550, training_loss: 4.34811e-02
I0207 22:20:27.713084 23092487714304 run_lib.py:133] step: 2600, training_loss: 4.85107e-02
I0207 22:20:27.821675 23092487714304 run_lib.py:146] step: 2600, eval_loss: 4.33846e-02
I0207 22:20:41.951516 23092487714304 run_lib.py:133] step: 2650, training_loss: 4.27818e-02
I0207 22:20:56.079130 23092487714304 run_lib.py:133] step: 2700, training_loss: 3.19993e-02
I0207 22:20:56.186748 23092487714304 run_lib.py:146] step: 2700, eval_loss: 3.08723e-02
I0207 22:21:10.277209 23092487714304 run_lib.py:133] step: 2750, training_loss: 4.08412e-02
I0207 22:21:24.393775 23092487714304 run_lib.py:133] step: 2800, training_loss: 4.25416e-02
I0207 22:21:24.504401 23092487714304 run_lib.py:146] step: 2800, eval_loss: 3.40244e-02
I0207 22:21:38.652400 23092487714304 run_lib.py:133] step: 2850, training_loss: 2.96609e-02
I0207 22:21:52.795984 23092487714304 run_lib.py:133] step: 2900, training_loss: 3.71896e-02
I0207 22:21:52.905379 23092487714304 run_lib.py:146] step: 2900, eval_loss: 3.15908e-02
I0207 22:22:07.055450 23092487714304 run_lib.py:133] step: 2950, training_loss: 3.34284e-02
I0207 22:22:21.203899 23092487714304 run_lib.py:133] step: 3000, training_loss: 5.03673e-02
I0207 22:22:21.313373 23092487714304 run_lib.py:146] step: 3000, eval_loss: 3.45701e-02
I0207 22:22:35.458206 23092487714304 run_lib.py:133] step: 3050, training_loss: 4.10450e-02
I0207 22:22:49.609134 23092487714304 run_lib.py:133] step: 3100, training_loss: 4.82759e-02
I0207 22:22:49.719231 23092487714304 run_lib.py:146] step: 3100, eval_loss: 2.88281e-02
I0207 22:23:03.882524 23092487714304 run_lib.py:133] step: 3150, training_loss: 2.91906e-02
I0207 22:23:18.038344 23092487714304 run_lib.py:133] step: 3200, training_loss: 4.26954e-02
I0207 22:23:18.148106 23092487714304 run_lib.py:146] step: 3200, eval_loss: 2.89561e-02
I0207 22:23:32.293604 23092487714304 run_lib.py:133] step: 3250, training_loss: 5.30740e-02
I0207 22:23:46.434715 23092487714304 run_lib.py:133] step: 3300, training_loss: 4.65750e-02
I0207 22:23:46.544048 23092487714304 run_lib.py:146] step: 3300, eval_loss: 3.60460e-02
I0207 22:24:00.691182 23092487714304 run_lib.py:133] step: 3350, training_loss: 3.89685e-02
I0207 22:24:14.837966 23092487714304 run_lib.py:133] step: 3400, training_loss: 3.17951e-02
I0207 22:24:14.947052 23092487714304 run_lib.py:146] step: 3400, eval_loss: 2.50915e-02
I0207 22:24:29.106235 23092487714304 run_lib.py:133] step: 3450, training_loss: 2.88880e-02
I0207 22:24:43.254340 23092487714304 run_lib.py:133] step: 3500, training_loss: 5.09689e-02
I0207 22:24:43.364482 23092487714304 run_lib.py:146] step: 3500, eval_loss: 3.33975e-02
I0207 22:24:57.516399 23092487714304 run_lib.py:133] step: 3550, training_loss: 4.73260e-02
I0207 22:25:11.665702 23092487714304 run_lib.py:133] step: 3600, training_loss: 4.78201e-02
I0207 22:25:11.774681 23092487714304 run_lib.py:146] step: 3600, eval_loss: 2.84672e-02
I0207 22:25:25.912827 23092487714304 run_lib.py:133] step: 3650, training_loss: 4.07068e-02
I0207 22:25:40.050377 23092487714304 run_lib.py:133] step: 3700, training_loss: 2.34497e-02
I0207 22:25:40.159077 23092487714304 run_lib.py:146] step: 3700, eval_loss: 4.59329e-02
I0207 22:25:54.300401 23092487714304 run_lib.py:133] step: 3750, training_loss: 3.18340e-02
I0207 22:26:08.459511 23092487714304 run_lib.py:133] step: 3800, training_loss: 3.05773e-02
I0207 22:26:08.569716 23092487714304 run_lib.py:146] step: 3800, eval_loss: 2.60659e-02
I0207 22:26:22.721066 23092487714304 run_lib.py:133] step: 3850, training_loss: 3.76676e-02
I0207 22:26:36.855167 23092487714304 run_lib.py:133] step: 3900, training_loss: 4.30199e-02
I0207 22:26:36.964725 23092487714304 run_lib.py:146] step: 3900, eval_loss: 3.34021e-02
I0207 22:26:51.107274 23092487714304 run_lib.py:133] step: 3950, training_loss: 3.45887e-02
I0207 22:27:05.253647 23092487714304 run_lib.py:133] step: 4000, training_loss: 3.59163e-02
I0207 22:27:05.362641 23092487714304 run_lib.py:146] step: 4000, eval_loss: 2.85845e-02
I0207 22:27:19.496477 23092487714304 run_lib.py:133] step: 4050, training_loss: 2.85872e-02
I0207 22:27:33.633654 23092487714304 run_lib.py:133] step: 4100, training_loss: 2.97888e-02
I0207 22:27:33.742503 23092487714304 run_lib.py:146] step: 4100, eval_loss: 3.39169e-02
I0207 22:27:47.871765 23092487714304 run_lib.py:133] step: 4150, training_loss: 4.33953e-02
I0207 22:28:01.999905 23092487714304 run_lib.py:133] step: 4200, training_loss: 3.02881e-02
I0207 22:28:02.109859 23092487714304 run_lib.py:146] step: 4200, eval_loss: 3.64849e-02
I0207 22:28:16.253607 23092487714304 run_lib.py:133] step: 4250, training_loss: 2.95515e-02
I0207 22:28:30.380932 23092487714304 run_lib.py:133] step: 4300, training_loss: 3.41332e-02
I0207 22:28:30.489996 23092487714304 run_lib.py:146] step: 4300, eval_loss: 3.43953e-02
I0207 22:28:44.618664 23092487714304 run_lib.py:133] step: 4350, training_loss: 4.63695e-02
I0207 22:28:58.748193 23092487714304 run_lib.py:133] step: 4400, training_loss: 3.39851e-02
I0207 22:28:58.857032 23092487714304 run_lib.py:146] step: 4400, eval_loss: 3.31312e-02
I0207 22:29:12.975160 23092487714304 run_lib.py:133] step: 4450, training_loss: 2.62172e-02
I0207 22:29:27.126180 23092487714304 run_lib.py:133] step: 4500, training_loss: 4.13068e-02
I0207 22:29:27.235797 23092487714304 run_lib.py:146] step: 4500, eval_loss: 3.64675e-02
I0207 22:29:41.397797 23092487714304 run_lib.py:133] step: 4550, training_loss: 3.15165e-02
I0207 22:29:55.555551 23092487714304 run_lib.py:133] step: 4600, training_loss: 3.23976e-02
I0207 22:29:55.665061 23092487714304 run_lib.py:146] step: 4600, eval_loss: 3.83472e-02
I0207 22:30:09.811394 23092487714304 run_lib.py:133] step: 4650, training_loss: 3.24840e-02
I0207 22:30:23.947827 23092487714304 run_lib.py:133] step: 4700, training_loss: 3.10193e-02
I0207 22:30:24.056808 23092487714304 run_lib.py:146] step: 4700, eval_loss: 3.08966e-02
I0207 22:30:38.196151 23092487714304 run_lib.py:133] step: 4750, training_loss: 2.91679e-02
I0207 22:30:52.351259 23092487714304 run_lib.py:133] step: 4800, training_loss: 3.45366e-02
I0207 22:30:52.461180 23092487714304 run_lib.py:146] step: 4800, eval_loss: 3.20538e-02
I0207 22:31:06.631961 23092487714304 run_lib.py:133] step: 4850, training_loss: 2.82642e-02
I0207 22:31:20.790963 23092487714304 run_lib.py:133] step: 4900, training_loss: 2.31219e-02
I0207 22:31:20.900526 23092487714304 run_lib.py:146] step: 4900, eval_loss: 3.98567e-02
I0207 22:31:35.051776 23092487714304 run_lib.py:133] step: 4950, training_loss: 3.06290e-02
I0207 22:31:49.206332 23092487714304 run_lib.py:133] step: 5000, training_loss: 2.62490e-02
I0207 22:31:49.315738 23092487714304 run_lib.py:146] step: 5000, eval_loss: 4.10756e-02
I0207 22:32:03.458524 23092487714304 run_lib.py:133] step: 5050, training_loss: 2.87445e-02
