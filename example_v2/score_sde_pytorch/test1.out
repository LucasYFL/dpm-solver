WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

W0208 12:57:49.051929 22542570456896 utils.py:10] No checkpoint found at experiments/dpm/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0208 12:57:49.054075 22542570456896 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0208 12:57:49.054291 22542570456896 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0208 12:57:49.054371 22542570456896 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0208 12:57:49.055144 22542570456896 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0208 12:57:49.055267 22542570456896 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0208 12:57:49.055354 22542570456896 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0208 12:57:49.058266 22542570456896 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0208 12:57:49.062551 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0208 12:57:49.062675 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0208 12:57:49.062807 22542570456896 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0208 12:57:49.062909 22542570456896 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0208 12:57:49.229959 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0208 12:57:49.230218 22542570456896 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0208 12:57:49.230372 22542570456896 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0208 12:57:49.230468 22542570456896 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0208 12:57:49.341570 22542570456896 run_lib.py:123] Starting training loop at step 0.
I0208 12:57:58.372729 22542570456896 run_lib.py:133] step: 0, training_loss: 9.99617e-01
I0208 12:57:59.899679 22542570456896 run_lib.py:146] step: 0, eval_loss: 1.00356e+00
I0208 12:58:19.537102 22542570456896 run_lib.py:133] step: 50, training_loss: 9.92776e-01
I0208 12:58:38.938248 22542570456896 run_lib.py:133] step: 100, training_loss: 9.55566e-01
I0208 12:58:39.093762 22542570456896 run_lib.py:146] step: 100, eval_loss: 9.65793e-01
I0208 12:58:58.558991 22542570456896 run_lib.py:133] step: 150, training_loss: 8.91180e-01
I0208 12:59:16.228488 22542570456896 run_lib.py:133] step: 200, training_loss: 8.04884e-01
I0208 12:59:16.387307 22542570456896 run_lib.py:146] step: 200, eval_loss: 8.38131e-01
I0208 12:59:33.777011 22542570456896 run_lib.py:133] step: 250, training_loss: 7.06697e-01
I0208 12:59:51.331310 22542570456896 run_lib.py:133] step: 300, training_loss: 5.98116e-01
I0208 12:59:51.488079 22542570456896 run_lib.py:146] step: 300, eval_loss: 6.57949e-01
I0208 13:00:08.948299 22542570456896 run_lib.py:133] step: 350, training_loss: 4.88462e-01
I0208 13:00:26.366629 22542570456896 run_lib.py:133] step: 400, training_loss: 3.71722e-01
I0208 13:00:26.524862 22542570456896 run_lib.py:146] step: 400, eval_loss: 4.50303e-01
I0208 13:00:43.903513 22542570456896 run_lib.py:133] step: 450, training_loss: 2.64188e-01
I0208 13:01:01.391698 22542570456896 run_lib.py:133] step: 500, training_loss: 1.73977e-01
I0208 13:01:01.562173 22542570456896 run_lib.py:146] step: 500, eval_loss: 2.48400e-01
I0208 13:01:18.987039 22542570456896 run_lib.py:133] step: 550, training_loss: 1.09633e-01
I0208 13:01:36.299633 22542570456896 run_lib.py:133] step: 600, training_loss: 5.60537e-02
I0208 13:01:36.457871 22542570456896 run_lib.py:146] step: 600, eval_loss: 1.13022e-01
I0208 13:01:53.967114 22542570456896 run_lib.py:133] step: 650, training_loss: 4.61361e-02
I0208 13:02:11.397075 22542570456896 run_lib.py:133] step: 700, training_loss: 5.47449e-02
I0208 13:02:11.552112 22542570456896 run_lib.py:146] step: 700, eval_loss: 4.14143e-02
I0208 13:02:29.079758 22542570456896 run_lib.py:133] step: 750, training_loss: 4.22573e-02
I0208 13:02:46.556979 22542570456896 run_lib.py:133] step: 800, training_loss: 3.94412e-02
I0208 13:02:46.725491 22542570456896 run_lib.py:146] step: 800, eval_loss: 4.49249e-02
I0208 13:03:04.194205 22542570456896 run_lib.py:133] step: 850, training_loss: 3.91286e-02
I0208 13:03:21.683692 22542570456896 run_lib.py:133] step: 900, training_loss: 4.07929e-02
I0208 13:03:21.849570 22542570456896 run_lib.py:146] step: 900, eval_loss: 3.33471e-02
I0208 13:03:39.449281 22542570456896 run_lib.py:133] step: 950, training_loss: 3.50711e-02
I0208 13:03:56.913946 22542570456896 run_lib.py:133] step: 1000, training_loss: 3.46980e-02
I0208 13:03:57.070210 22542570456896 run_lib.py:146] step: 1000, eval_loss: 3.63577e-02
I0208 13:04:14.493350 22542570456896 run_lib.py:133] step: 1050, training_loss: 3.75380e-02
I0208 13:04:31.960293 22542570456896 run_lib.py:133] step: 1100, training_loss: 3.82094e-02
I0208 13:04:32.119498 22542570456896 run_lib.py:146] step: 1100, eval_loss: 3.16897e-02
I0208 13:04:49.784672 22542570456896 run_lib.py:133] step: 1150, training_loss: 4.94681e-02
I0208 13:05:07.214823 22542570456896 run_lib.py:133] step: 1200, training_loss: 3.50922e-02
I0208 13:05:07.368219 22542570456896 run_lib.py:146] step: 1200, eval_loss: 3.50499e-02
I0208 13:05:24.918386 22542570456896 run_lib.py:133] step: 1250, training_loss: 3.22535e-02
I0208 13:05:42.338188 22542570456896 run_lib.py:133] step: 1300, training_loss: 2.82136e-02
I0208 13:05:42.503532 22542570456896 run_lib.py:146] step: 1300, eval_loss: 3.34172e-02
I0208 13:06:00.166349 22542570456896 run_lib.py:133] step: 1350, training_loss: 4.07605e-02
I0208 13:06:17.595434 22542570456896 run_lib.py:133] step: 1400, training_loss: 3.03951e-02
I0208 13:06:17.754232 22542570456896 run_lib.py:146] step: 1400, eval_loss: 3.39308e-02
I0208 13:06:35.324366 22542570456896 run_lib.py:133] step: 1450, training_loss: 4.13633e-02
I0208 13:06:52.716661 22542570456896 run_lib.py:133] step: 1500, training_loss: 3.70187e-02
I0208 13:06:52.881244 22542570456896 run_lib.py:146] step: 1500, eval_loss: 3.05767e-02
I0208 13:07:10.336620 22542570456896 run_lib.py:133] step: 1550, training_loss: 3.77755e-02
I0208 13:07:27.897181 22542570456896 run_lib.py:133] step: 1600, training_loss: 3.65964e-02
I0208 13:07:28.055762 22542570456896 run_lib.py:146] step: 1600, eval_loss: 3.54764e-02
I0208 13:07:45.534567 22542570456896 run_lib.py:133] step: 1650, training_loss: 2.76487e-02
I0208 13:08:02.969487 22542570456896 run_lib.py:133] step: 1700, training_loss: 2.67881e-02
I0208 13:08:03.122982 22542570456896 run_lib.py:146] step: 1700, eval_loss: 3.29160e-02
I0208 13:08:20.732806 22542570456896 run_lib.py:133] step: 1750, training_loss: 3.36325e-02
I0208 13:08:38.140561 22542570456896 run_lib.py:133] step: 1800, training_loss: 3.81225e-02
I0208 13:08:38.305242 22542570456896 run_lib.py:146] step: 1800, eval_loss: 3.29462e-02
I0208 13:08:55.863643 22542570456896 run_lib.py:133] step: 1850, training_loss: 3.18390e-02
I0208 13:09:13.273253 22542570456896 run_lib.py:133] step: 1900, training_loss: 3.01034e-02
I0208 13:09:13.447312 22542570456896 run_lib.py:146] step: 1900, eval_loss: 4.49623e-02
I0208 13:09:30.915045 22542570456896 run_lib.py:133] step: 1950, training_loss: 4.33371e-02
I0208 13:09:48.522432 22542570456896 run_lib.py:133] step: 2000, training_loss: 3.34198e-02
I0208 13:09:48.679039 22542570456896 run_lib.py:146] step: 2000, eval_loss: 3.14717e-02
I0208 13:10:06.083464 22542570456896 run_lib.py:133] step: 2050, training_loss: 3.02608e-02
I0208 13:10:23.510876 22542570456896 run_lib.py:133] step: 2100, training_loss: 4.13079e-02
I0208 13:10:23.667245 22542570456896 run_lib.py:146] step: 2100, eval_loss: 4.24564e-02
I0208 13:10:41.079616 22542570456896 run_lib.py:133] step: 2150, training_loss: 3.42374e-02
I0208 13:10:58.639108 22542570456896 run_lib.py:133] step: 2200, training_loss: 3.98412e-02
I0208 13:10:58.796617 22542570456896 run_lib.py:146] step: 2200, eval_loss: 2.82924e-02
I0208 13:11:16.253496 22542570456896 run_lib.py:133] step: 2250, training_loss: 3.08876e-02
I0208 13:11:33.776957 22542570456896 run_lib.py:133] step: 2300, training_loss: 3.93552e-02
I0208 13:11:33.942337 22542570456896 run_lib.py:146] step: 2300, eval_loss: 3.64078e-02
I0208 13:11:51.347778 22542570456896 run_lib.py:133] step: 2350, training_loss: 3.59119e-02
I0208 13:12:08.748673 22542570456896 run_lib.py:133] step: 2400, training_loss: 3.01577e-02
I0208 13:12:08.911223 22542570456896 run_lib.py:146] step: 2400, eval_loss: 3.47637e-02
I0208 13:12:26.447584 22542570456896 run_lib.py:133] step: 2450, training_loss: 4.22560e-02
I0208 13:12:44.010932 22542570456896 run_lib.py:133] step: 2500, training_loss: 3.19840e-02
I0208 13:12:44.172200 22542570456896 run_lib.py:146] step: 2500, eval_loss: 2.26466e-02
I0208 13:13:01.599204 22542570456896 run_lib.py:133] step: 2550, training_loss: 3.41390e-02
I0208 13:13:19.009538 22542570456896 run_lib.py:133] step: 2600, training_loss: 3.95318e-02
I0208 13:13:19.162729 22542570456896 run_lib.py:146] step: 2600, eval_loss: 3.91480e-02
I0208 13:13:36.726851 22542570456896 run_lib.py:133] step: 2650, training_loss: 3.99377e-02
I0208 13:13:54.157723 22542570456896 run_lib.py:133] step: 2700, training_loss: 3.97581e-02
I0208 13:13:54.312315 22542570456896 run_lib.py:146] step: 2700, eval_loss: 2.80752e-02
I0208 13:14:11.898476 22542570456896 run_lib.py:133] step: 2750, training_loss: 2.85208e-02
I0208 13:14:29.350039 22542570456896 run_lib.py:133] step: 2800, training_loss: 3.04474e-02
I0208 13:14:29.508445 22542570456896 run_lib.py:146] step: 2800, eval_loss: 3.88222e-02
I0208 13:14:47.144168 22542570456896 run_lib.py:133] step: 2850, training_loss: 3.12158e-02
I0208 13:15:04.564088 22542570456896 run_lib.py:133] step: 2900, training_loss: 3.54186e-02
I0208 13:15:04.728364 22542570456896 run_lib.py:146] step: 2900, eval_loss: 3.19420e-02
I0208 13:15:22.114368 22542570456896 run_lib.py:133] step: 2950, training_loss: 3.57419e-02
I0208 13:15:39.682236 22542570456896 run_lib.py:133] step: 3000, training_loss: 4.10163e-02
I0208 13:15:39.838385 22542570456896 run_lib.py:146] step: 3000, eval_loss: 3.77177e-02
I0208 13:15:57.223060 22542570456896 run_lib.py:133] step: 3050, training_loss: 3.10344e-02
I0208 13:16:14.871049 22542570456896 run_lib.py:133] step: 3100, training_loss: 3.69532e-02
I0208 13:16:15.025430 22542570456896 run_lib.py:146] step: 3100, eval_loss: 3.34579e-02
I0208 13:16:32.456033 22542570456896 run_lib.py:133] step: 3150, training_loss: 3.26781e-02
I0208 13:16:49.870999 22542570456896 run_lib.py:133] step: 3200, training_loss: 3.80814e-02
I0208 13:16:50.027373 22542570456896 run_lib.py:146] step: 3200, eval_loss: 2.64472e-02
I0208 13:17:07.635648 22542570456896 run_lib.py:133] step: 3250, training_loss: 3.52367e-02
I0208 13:17:25.067038 22542570456896 run_lib.py:133] step: 3300, training_loss: 2.88069e-02
I0208 13:17:25.231459 22542570456896 run_lib.py:146] step: 3300, eval_loss: 3.50736e-02
I0208 13:17:42.692201 22542570456896 run_lib.py:133] step: 3350, training_loss: 2.50768e-02
I0208 13:18:00.335011 22542570456896 run_lib.py:133] step: 3400, training_loss: 3.29472e-02
I0208 13:18:00.492619 22542570456896 run_lib.py:146] step: 3400, eval_loss: 2.72077e-02
I0208 13:18:17.921135 22542570456896 run_lib.py:133] step: 3450, training_loss: 3.16122e-02
I0208 13:18:35.595440 22542570456896 run_lib.py:133] step: 3500, training_loss: 3.58662e-02
I0208 13:18:35.749331 22542570456896 run_lib.py:146] step: 3500, eval_loss: 2.52649e-02
I0208 13:18:53.209066 22542570456896 run_lib.py:133] step: 3550, training_loss: 3.76826e-02
I0208 13:19:10.597953 22542570456896 run_lib.py:133] step: 3600, training_loss: 3.14983e-02
I0208 13:19:10.752468 22542570456896 run_lib.py:146] step: 3600, eval_loss: 2.77968e-02
I0208 13:19:28.243014 22542570456896 run_lib.py:133] step: 3650, training_loss: 3.88927e-02
I0208 13:19:45.686424 22542570456896 run_lib.py:133] step: 3700, training_loss: 3.65355e-02
I0208 13:19:45.849291 22542570456896 run_lib.py:146] step: 3700, eval_loss: 3.42024e-02
I0208 13:20:03.419656 22542570456896 run_lib.py:133] step: 3750, training_loss: 4.10317e-02
I0208 13:20:20.866056 22542570456896 run_lib.py:133] step: 3800, training_loss: 3.17061e-02
I0208 13:20:21.030226 22542570456896 run_lib.py:146] step: 3800, eval_loss: 2.82481e-02
I0208 13:20:38.477299 22542570456896 run_lib.py:133] step: 3850, training_loss: 3.48026e-02
I0208 13:20:55.893840 22542570456896 run_lib.py:133] step: 3900, training_loss: 2.55296e-02
I0208 13:20:56.049342 22542570456896 run_lib.py:146] step: 3900, eval_loss: 3.10320e-02
I0208 13:21:13.604808 22542570456896 run_lib.py:133] step: 3950, training_loss: 3.33867e-02
I0208 13:21:31.141149 22542570456896 run_lib.py:133] step: 4000, training_loss: 3.29413e-02
I0208 13:21:31.295506 22542570456896 run_lib.py:146] step: 4000, eval_loss: 3.07754e-02
I0208 13:21:48.738983 22542570456896 run_lib.py:133] step: 4050, training_loss: 2.26354e-02
I0208 13:22:06.224093 22542570456896 run_lib.py:133] step: 4100, training_loss: 4.07965e-02
I0208 13:22:06.379302 22542570456896 run_lib.py:146] step: 4100, eval_loss: 3.57607e-02
I0208 13:22:23.923791 22542570456896 run_lib.py:133] step: 4150, training_loss: 4.31621e-02
I0208 13:22:41.343120 22542570456896 run_lib.py:133] step: 4200, training_loss: 3.62458e-02
I0208 13:22:41.517695 22542570456896 run_lib.py:146] step: 4200, eval_loss: 3.11306e-02
I0208 13:22:59.185637 22542570456896 run_lib.py:133] step: 4250, training_loss: 3.29133e-02
I0208 13:23:16.640021 22542570456896 run_lib.py:133] step: 4300, training_loss: 3.01792e-02
I0208 13:23:16.797367 22542570456896 run_lib.py:146] step: 4300, eval_loss: 2.88109e-02
I0208 13:23:34.340394 22542570456896 run_lib.py:133] step: 4350, training_loss: 3.55693e-02
I0208 13:23:51.717256 22542570456896 run_lib.py:133] step: 4400, training_loss: 2.74521e-02
I0208 13:23:51.874022 22542570456896 run_lib.py:146] step: 4400, eval_loss: 3.20779e-02
I0208 13:24:09.279072 22542570456896 run_lib.py:133] step: 4450, training_loss: 3.42202e-02
I0208 13:24:26.879693 22542570456896 run_lib.py:133] step: 4500, training_loss: 3.52170e-02
I0208 13:24:27.034202 22542570456896 run_lib.py:146] step: 4500, eval_loss: 3.36948e-02
I0208 13:24:44.487220 22542570456896 run_lib.py:133] step: 4550, training_loss: 3.24702e-02
I0208 13:25:02.064263 22542570456896 run_lib.py:133] step: 4600, training_loss: 3.00201e-02
I0208 13:25:02.219147 22542570456896 run_lib.py:146] step: 4600, eval_loss: 3.54778e-02
I0208 13:25:19.594413 22542570456896 run_lib.py:133] step: 4650, training_loss: 3.38483e-02
I0208 13:25:36.991977 22542570456896 run_lib.py:133] step: 4700, training_loss: 3.26926e-02
I0208 13:25:37.156564 22542570456896 run_lib.py:146] step: 4700, eval_loss: 2.80781e-02
I0208 13:25:54.715699 22542570456896 run_lib.py:133] step: 4750, training_loss: 2.91616e-02
I0208 13:26:12.201862 22542570456896 run_lib.py:133] step: 4800, training_loss: 3.10817e-02
I0208 13:26:12.359416 22542570456896 run_lib.py:146] step: 4800, eval_loss: 3.03321e-02
I0208 13:26:29.818228 22542570456896 run_lib.py:133] step: 4850, training_loss: 2.64526e-02
I0208 13:26:47.240868 22542570456896 run_lib.py:133] step: 4900, training_loss: 3.54936e-02
I0208 13:26:47.396249 22542570456896 run_lib.py:146] step: 4900, eval_loss: 2.97258e-02
I0208 13:27:04.969464 22542570456896 run_lib.py:133] step: 4950, training_loss: 3.81405e-02
I0208 13:27:22.373175 22542570456896 run_lib.py:133] step: 5000, training_loss: 3.60393e-02
I0208 13:27:22.525258 22542570456896 run_lib.py:146] step: 5000, eval_loss: 2.85652e-02
I0208 13:27:39.978454 22542570456896 run_lib.py:133] step: 5050, training_loss: 3.28199e-02
I0208 13:27:57.416970 22542570456896 run_lib.py:133] step: 5100, training_loss: 3.13515e-02
I0208 13:27:57.593783 22542570456896 run_lib.py:146] step: 5100, eval_loss: 2.86784e-02
I0208 13:28:15.020037 22542570456896 run_lib.py:133] step: 5150, training_loss: 2.73356e-02
I0208 13:28:32.452074 22542570456896 run_lib.py:133] step: 5200, training_loss: 3.23691e-02
I0208 13:28:32.609184 22542570456896 run_lib.py:146] step: 5200, eval_loss: 2.89899e-02
I0208 13:28:50.173048 22542570456896 run_lib.py:133] step: 5250, training_loss: 3.61048e-02
I0208 13:29:07.606858 22542570456896 run_lib.py:133] step: 5300, training_loss: 3.33456e-02
I0208 13:29:07.764225 22542570456896 run_lib.py:146] step: 5300, eval_loss: 3.11784e-02
I0208 13:29:25.157505 22542570456896 run_lib.py:133] step: 5350, training_loss: 2.53605e-02
I0208 13:29:42.612750 22542570456896 run_lib.py:133] step: 5400, training_loss: 2.57011e-02
I0208 13:29:42.767970 22542570456896 run_lib.py:146] step: 5400, eval_loss: 2.21273e-02
I0208 13:30:00.377259 22542570456896 run_lib.py:133] step: 5450, training_loss: 3.60500e-02
I0208 13:30:17.826808 22542570456896 run_lib.py:133] step: 5500, training_loss: 3.46252e-02
I0208 13:30:17.980221 22542570456896 run_lib.py:146] step: 5500, eval_loss: 2.69132e-02
I0208 13:30:35.375690 22542570456896 run_lib.py:133] step: 5550, training_loss: 3.54329e-02
I0208 13:30:52.789595 22542570456896 run_lib.py:133] step: 5600, training_loss: 3.31962e-02
I0208 13:30:52.964477 22542570456896 run_lib.py:146] step: 5600, eval_loss: 3.29102e-02
I0208 13:31:10.604553 22542570456896 run_lib.py:133] step: 5650, training_loss: 3.46920e-02
I0208 13:31:27.999405 22542570456896 run_lib.py:133] step: 5700, training_loss: 3.53055e-02
I0208 13:31:28.162155 22542570456896 run_lib.py:146] step: 5700, eval_loss: 3.40798e-02
I0208 13:31:45.749531 22542570456896 run_lib.py:133] step: 5750, training_loss: 3.39605e-02
I0208 13:32:03.134221 22542570456896 run_lib.py:133] step: 5800, training_loss: 2.34529e-02
I0208 13:32:03.308394 22542570456896 run_lib.py:146] step: 5800, eval_loss: 3.37768e-02
I0208 13:32:20.922359 22542570456896 run_lib.py:133] step: 5850, training_loss: 2.97209e-02
I0208 13:32:38.361783 22542570456896 run_lib.py:133] step: 5900, training_loss: 3.20832e-02
I0208 13:32:38.524022 22542570456896 run_lib.py:146] step: 5900, eval_loss: 3.12477e-02
I0208 13:32:56.020266 22542570456896 run_lib.py:133] step: 5950, training_loss: 3.65802e-02
I0208 13:33:13.625683 22542570456896 run_lib.py:133] step: 6000, training_loss: 3.73492e-02
I0208 13:33:13.779205 22542570456896 run_lib.py:146] step: 6000, eval_loss: 4.01488e-02
I0208 13:33:31.200269 22542570456896 run_lib.py:133] step: 6050, training_loss: 2.59098e-02
I0208 13:33:48.733793 22542570456896 run_lib.py:133] step: 6100, training_loss: 3.19268e-02
I0208 13:33:48.893480 22542570456896 run_lib.py:146] step: 6100, eval_loss: 2.91445e-02
I0208 13:34:06.309448 22542570456896 run_lib.py:133] step: 6150, training_loss: 2.99506e-02
I0208 13:34:23.708058 22542570456896 run_lib.py:133] step: 6200, training_loss: 2.76210e-02
I0208 13:34:23.879609 22542570456896 run_lib.py:146] step: 6200, eval_loss: 3.04969e-02
I0208 13:34:41.491349 22542570456896 run_lib.py:133] step: 6250, training_loss: 3.43946e-02
I0208 13:34:58.898868 22542570456896 run_lib.py:133] step: 6300, training_loss: 3.33616e-02
I0208 13:34:59.055687 22542570456896 run_lib.py:146] step: 6300, eval_loss: 3.62013e-02
I0208 13:35:16.477236 22542570456896 run_lib.py:133] step: 6350, training_loss: 3.29453e-02
I0208 13:35:33.865691 22542570456896 run_lib.py:133] step: 6400, training_loss: 3.14581e-02
I0208 13:35:34.016999 22542570456896 run_lib.py:146] step: 6400, eval_loss: 3.11512e-02
I0208 13:35:51.605192 22542570456896 run_lib.py:133] step: 6450, training_loss: 3.06851e-02
I0208 13:36:09.001200 22542570456896 run_lib.py:133] step: 6500, training_loss: 3.26933e-02
I0208 13:36:09.168507 22542570456896 run_lib.py:146] step: 6500, eval_loss: 3.34358e-02
I0208 13:36:26.718175 22542570456896 run_lib.py:133] step: 6550, training_loss: 3.21237e-02
I0208 13:36:44.190343 22542570456896 run_lib.py:133] step: 6600, training_loss: 2.78481e-02
I0208 13:36:44.348396 22542570456896 run_lib.py:146] step: 6600, eval_loss: 3.16449e-02
I0208 13:37:01.759959 22542570456896 run_lib.py:133] step: 6650, training_loss: 2.92570e-02
I0208 13:37:19.180212 22542570456896 run_lib.py:133] step: 6700, training_loss: 3.28249e-02
I0208 13:37:19.337272 22542570456896 run_lib.py:146] step: 6700, eval_loss: 3.44428e-02
I0208 13:37:36.907314 22542570456896 run_lib.py:133] step: 6750, training_loss: 3.96872e-02
I0208 13:37:54.487422 22542570456896 run_lib.py:133] step: 6800, training_loss: 2.69548e-02
I0208 13:37:54.641952 22542570456896 run_lib.py:146] step: 6800, eval_loss: 3.26312e-02
I0208 13:38:12.079152 22542570456896 run_lib.py:133] step: 6850, training_loss: 3.34300e-02
I0208 13:38:29.482551 22542570456896 run_lib.py:133] step: 6900, training_loss: 2.95054e-02
I0208 13:38:29.635201 22542570456896 run_lib.py:146] step: 6900, eval_loss: 3.12587e-02
I0208 13:38:47.182066 22542570456896 run_lib.py:133] step: 6950, training_loss: 3.61652e-02
I0208 13:39:04.648566 22542570456896 run_lib.py:133] step: 7000, training_loss: 3.12189e-02
I0208 13:39:04.804872 22542570456896 run_lib.py:146] step: 7000, eval_loss: 3.49476e-02
I0208 13:39:22.211568 22542570456896 run_lib.py:133] step: 7050, training_loss: 2.89630e-02
I0208 13:39:39.648669 22542570456896 run_lib.py:133] step: 7100, training_loss: 3.61654e-02
I0208 13:39:39.833417 22542570456896 run_lib.py:146] step: 7100, eval_loss: 2.36666e-02
I0208 13:39:57.432019 22542570456896 run_lib.py:133] step: 7150, training_loss: 3.03866e-02
I0208 13:40:14.839995 22542570456896 run_lib.py:133] step: 7200, training_loss: 3.15748e-02
I0208 13:40:15.008587 22542570456896 run_lib.py:146] step: 7200, eval_loss: 3.35053e-02
I0208 13:40:32.572407 22542570456896 run_lib.py:133] step: 7250, training_loss: 2.96672e-02
I0208 13:40:49.982546 22542570456896 run_lib.py:133] step: 7300, training_loss: 3.27004e-02
I0208 13:40:50.145236 22542570456896 run_lib.py:146] step: 7300, eval_loss: 3.26762e-02
I0208 13:41:07.701758 22542570456896 run_lib.py:133] step: 7350, training_loss: 3.08722e-02
I0208 13:41:25.186023 22542570456896 run_lib.py:133] step: 7400, training_loss: 2.53504e-02
I0208 13:41:25.345372 22542570456896 run_lib.py:146] step: 7400, eval_loss: 2.45102e-02
I0208 13:41:42.758274 22542570456896 run_lib.py:133] step: 7450, training_loss: 2.81144e-02
I0208 13:42:00.369444 22542570456896 run_lib.py:133] step: 7500, training_loss: 3.27259e-02
I0208 13:42:00.529189 22542570456896 run_lib.py:146] step: 7500, eval_loss: 3.49899e-02
I0208 13:42:17.911922 22542570456896 run_lib.py:133] step: 7550, training_loss: 2.62285e-02
I0208 13:42:35.559620 22542570456896 run_lib.py:133] step: 7600, training_loss: 2.53161e-02
I0208 13:42:35.836466 22542570456896 run_lib.py:146] step: 7600, eval_loss: 3.30554e-02
I0208 13:42:53.234280 22542570456896 run_lib.py:133] step: 7650, training_loss: 3.41126e-02
I0208 13:43:10.756670 22542570456896 run_lib.py:133] step: 7700, training_loss: 2.66350e-02
I0208 13:43:11.003000 22542570456896 run_lib.py:146] step: 7700, eval_loss: 2.44821e-02
I0208 13:43:28.624886 22542570456896 run_lib.py:133] step: 7750, training_loss: 3.07566e-02
I0208 13:43:46.157135 22542570456896 run_lib.py:133] step: 7800, training_loss: 2.77503e-02
I0208 13:43:46.328003 22542570456896 run_lib.py:146] step: 7800, eval_loss: 3.84743e-02
I0208 13:44:03.729784 22542570456896 run_lib.py:133] step: 7850, training_loss: 3.17989e-02
I0208 13:44:21.197762 22542570456896 run_lib.py:133] step: 7900, training_loss: 2.94013e-02
I0208 13:44:21.363230 22542570456896 run_lib.py:146] step: 7900, eval_loss: 2.54226e-02
I0208 13:44:38.896822 22542570456896 run_lib.py:133] step: 7950, training_loss: 2.92197e-02
I0208 13:44:56.304429 22542570456896 run_lib.py:133] step: 8000, training_loss: 3.07970e-02
I0208 13:44:56.480673 22542570456896 run_lib.py:146] step: 8000, eval_loss: 4.09069e-02
I0208 13:45:14.027127 22542570456896 run_lib.py:133] step: 8050, training_loss: 3.26012e-02
I0208 13:45:31.440092 22542570456896 run_lib.py:133] step: 8100, training_loss: 3.36076e-02
I0208 13:45:31.600584 22542570456896 run_lib.py:146] step: 8100, eval_loss: 4.04855e-02
I0208 13:45:49.039038 22542570456896 run_lib.py:133] step: 8150, training_loss: 3.34328e-02
I0208 13:46:06.447143 22542570456896 run_lib.py:133] step: 8200, training_loss: 2.92599e-02
I0208 13:46:06.603398 22542570456896 run_lib.py:146] step: 8200, eval_loss: 3.26038e-02
I0208 13:46:24.185692 22542570456896 run_lib.py:133] step: 8250, training_loss: 3.47455e-02
I0208 13:46:41.724233 22542570456896 run_lib.py:133] step: 8300, training_loss: 2.89106e-02
I0208 13:46:41.878544 22542570456896 run_lib.py:146] step: 8300, eval_loss: 3.83376e-02
I0208 13:46:59.357692 22542570456896 run_lib.py:133] step: 8350, training_loss: 3.27945e-02
I0208 13:47:16.825547 22542570456896 run_lib.py:133] step: 8400, training_loss: 3.31539e-02
I0208 13:47:16.980220 22542570456896 run_lib.py:146] step: 8400, eval_loss: 4.47119e-02
I0208 13:47:34.569833 22542570456896 run_lib.py:133] step: 8450, training_loss: 3.04540e-02
I0208 13:47:52.028419 22542570456896 run_lib.py:133] step: 8500, training_loss: 3.08564e-02
I0208 13:47:52.185405 22542570456896 run_lib.py:146] step: 8500, eval_loss: 2.40625e-02
I0208 13:48:09.616097 22542570456896 run_lib.py:133] step: 8550, training_loss: 3.54900e-02
I0208 13:48:27.046509 22542570456896 run_lib.py:133] step: 8600, training_loss: 2.60878e-02
I0208 13:48:27.212117 22542570456896 run_lib.py:146] step: 8600, eval_loss: 2.98933e-02
I0208 13:48:44.829791 22542570456896 run_lib.py:133] step: 8650, training_loss: 3.34715e-02
I0208 13:49:02.245119 22542570456896 run_lib.py:133] step: 8700, training_loss: 2.92800e-02
I0208 13:49:02.400744 22542570456896 run_lib.py:146] step: 8700, eval_loss: 3.53009e-02
I0208 13:49:19.972478 22542570456896 run_lib.py:133] step: 8750, training_loss: 2.67259e-02
I0208 13:49:37.413902 22542570456896 run_lib.py:133] step: 8800, training_loss: 3.52225e-02
I0208 13:49:37.567061 22542570456896 run_lib.py:146] step: 8800, eval_loss: 3.28940e-02
I0208 13:49:55.127035 22542570456896 run_lib.py:133] step: 8850, training_loss: 3.11929e-02
I0208 13:50:12.545140 22542570456896 run_lib.py:133] step: 8900, training_loss: 3.01345e-02
I0208 13:50:12.722601 22542570456896 run_lib.py:146] step: 8900, eval_loss: 3.25204e-02
I0208 13:50:30.224162 22542570456896 run_lib.py:133] step: 8950, training_loss: 3.02247e-02
I0208 13:50:47.849345 22542570456896 run_lib.py:133] step: 9000, training_loss: 2.93759e-02
I0208 13:50:48.007301 22542570456896 run_lib.py:146] step: 9000, eval_loss: 2.96383e-02
I0208 13:51:05.388063 22542570456896 run_lib.py:133] step: 9050, training_loss: 2.89024e-02
I0208 13:51:22.907227 22542570456896 run_lib.py:133] step: 9100, training_loss: 3.23621e-02
I0208 13:51:23.064299 22542570456896 run_lib.py:146] step: 9100, eval_loss: 2.99409e-02
I0208 13:51:40.525188 22542570456896 run_lib.py:133] step: 9150, training_loss: 3.06498e-02
I0208 13:51:57.972560 22542570456896 run_lib.py:133] step: 9200, training_loss: 2.67334e-02
I0208 13:51:58.129621 22542570456896 run_lib.py:146] step: 9200, eval_loss: 3.10768e-02
I0208 13:52:15.731081 22542570456896 run_lib.py:133] step: 9250, training_loss: 2.78171e-02
I0208 13:52:33.137525 22542570456896 run_lib.py:133] step: 9300, training_loss: 3.75257e-02
I0208 13:52:33.291289 22542570456896 run_lib.py:146] step: 9300, eval_loss: 2.68031e-02
I0208 13:52:50.711079 22542570456896 run_lib.py:133] step: 9350, training_loss: 3.10844e-02
I0208 13:53:08.114182 22542570456896 run_lib.py:133] step: 9400, training_loss: 3.01952e-02
I0208 13:53:08.290280 22542570456896 run_lib.py:146] step: 9400, eval_loss: 3.13975e-02
I0208 13:53:25.885421 22542570456896 run_lib.py:133] step: 9450, training_loss: 2.96739e-02
I0208 13:53:43.312634 22542570456896 run_lib.py:133] step: 9500, training_loss: 2.45620e-02
I0208 13:53:43.470445 22542570456896 run_lib.py:146] step: 9500, eval_loss: 2.51559e-02
I0208 13:54:00.975235 22542570456896 run_lib.py:133] step: 9550, training_loss: 2.76278e-02
I0208 13:54:18.371012 22542570456896 run_lib.py:133] step: 9600, training_loss: 2.55430e-02
I0208 13:54:18.526610 22542570456896 run_lib.py:146] step: 9600, eval_loss: 3.57851e-02
I0208 13:54:35.917399 22542570456896 run_lib.py:133] step: 9650, training_loss: 3.76539e-02
I0208 13:54:53.319003 22542570456896 run_lib.py:133] step: 9700, training_loss: 2.65544e-02
I0208 13:54:53.472067 22542570456896 run_lib.py:146] step: 9700, eval_loss: 3.18732e-02
I0208 13:55:11.118451 22542570456896 run_lib.py:133] step: 9750, training_loss: 3.49816e-02
I0208 13:55:28.592976 22542570456896 run_lib.py:133] step: 9800, training_loss: 2.74391e-02
I0208 13:55:28.745413 22542570456896 run_lib.py:146] step: 9800, eval_loss: 3.35227e-02
I0208 13:55:46.162519 22542570456896 run_lib.py:133] step: 9850, training_loss: 2.92220e-02
I0208 13:56:03.571376 22542570456896 run_lib.py:133] step: 9900, training_loss: 3.31555e-02
I0208 13:56:03.731545 22542570456896 run_lib.py:146] step: 9900, eval_loss: 3.36733e-02
I0208 13:56:21.299154 22542570456896 run_lib.py:133] step: 9950, training_loss: 3.49846e-02
I0208 13:56:38.791041 22542570456896 run_lib.py:133] step: 10000, training_loss: 3.22687e-02
I0208 13:56:39.497126 22542570456896 run_lib.py:146] step: 10000, eval_loss: 2.86938e-02
I0208 13:56:59.798640 22542570456896 run_lib.py:133] step: 10050, training_loss: 2.43569e-02
I0208 13:57:17.324590 22542570456896 run_lib.py:133] step: 10100, training_loss: 2.90191e-02
I0208 13:57:17.480411 22542570456896 run_lib.py:146] step: 10100, eval_loss: 3.72240e-02
I0208 13:57:34.929587 22542570456896 run_lib.py:133] step: 10150, training_loss: 2.64977e-02
I0208 13:57:52.324878 22542570456896 run_lib.py:133] step: 10200, training_loss: 2.61430e-02
I0208 13:57:52.479192 22542570456896 run_lib.py:146] step: 10200, eval_loss: 3.25585e-02
I0208 13:58:10.029817 22542570456896 run_lib.py:133] step: 10250, training_loss: 3.94023e-02
I0208 13:58:27.559586 22542570456896 run_lib.py:133] step: 10300, training_loss: 2.44286e-02
I0208 13:58:27.715469 22542570456896 run_lib.py:146] step: 10300, eval_loss: 2.40043e-02
I0208 13:58:45.185108 22542570456896 run_lib.py:133] step: 10350, training_loss: 3.00542e-02
I0208 13:59:02.620399 22542570456896 run_lib.py:133] step: 10400, training_loss: 2.49375e-02
I0208 13:59:02.780410 22542570456896 run_lib.py:146] step: 10400, eval_loss: 2.22272e-02
I0208 13:59:20.339932 22542570456896 run_lib.py:133] step: 10450, training_loss: 2.62616e-02
I0208 13:59:37.740677 22542570456896 run_lib.py:133] step: 10500, training_loss: 2.36932e-02
I0208 13:59:37.899362 22542570456896 run_lib.py:146] step: 10500, eval_loss: 2.58576e-02
I0208 13:59:55.467419 22542570456896 run_lib.py:133] step: 10550, training_loss: 3.77989e-02
I0208 14:00:12.927830 22542570456896 run_lib.py:133] step: 10600, training_loss: 3.27630e-02
I0208 14:00:13.085002 22542570456896 run_lib.py:146] step: 10600, eval_loss: 3.20933e-02
I0208 14:00:30.701526 22542570456896 run_lib.py:133] step: 10650, training_loss: 3.47279e-02
I0208 14:00:48.113591 22542570456896 run_lib.py:133] step: 10700, training_loss: 3.58897e-02
I0208 14:00:48.270151 22542570456896 run_lib.py:146] step: 10700, eval_loss: 2.91011e-02
I0208 14:01:05.679464 22542570456896 run_lib.py:133] step: 10750, training_loss: 3.71283e-02
I0208 14:01:23.212565 22542570456896 run_lib.py:133] step: 10800, training_loss: 2.99958e-02
I0208 14:01:23.365320 22542570456896 run_lib.py:146] step: 10800, eval_loss: 4.04702e-02
I0208 14:01:40.783337 22542570456896 run_lib.py:133] step: 10850, training_loss: 2.53280e-02
I0208 14:01:58.379098 22542570456896 run_lib.py:133] step: 10900, training_loss: 3.27758e-02
I0208 14:01:58.558383 22542570456896 run_lib.py:146] step: 10900, eval_loss: 2.34370e-02
I0208 14:02:15.975598 22542570456896 run_lib.py:133] step: 10950, training_loss: 4.28506e-02
I0208 14:02:33.377599 22542570456896 run_lib.py:133] step: 11000, training_loss: 2.41933e-02
I0208 14:02:33.534702 22542570456896 run_lib.py:146] step: 11000, eval_loss: 2.90779e-02
I0208 14:02:51.120250 22542570456896 run_lib.py:133] step: 11050, training_loss: 4.12094e-02
I0208 14:03:08.504608 22542570456896 run_lib.py:133] step: 11100, training_loss: 3.38224e-02
I0208 14:03:08.661295 22542570456896 run_lib.py:146] step: 11100, eval_loss: 3.02975e-02
I0208 14:03:26.082429 22542570456896 run_lib.py:133] step: 11150, training_loss: 3.17088e-02
I0208 14:03:43.650990 22542570456896 run_lib.py:133] step: 11200, training_loss: 2.84823e-02
I0208 14:03:43.814751 22542570456896 run_lib.py:146] step: 11200, eval_loss: 2.78683e-02
I0208 14:04:01.290605 22542570456896 run_lib.py:133] step: 11250, training_loss: 3.81375e-02
I0208 14:04:18.709565 22542570456896 run_lib.py:133] step: 11300, training_loss: 3.51475e-02
I0208 14:04:19.051234 22542570456896 run_lib.py:146] step: 11300, eval_loss: 2.83638e-02
I0208 14:04:36.487147 22542570456896 run_lib.py:133] step: 11350, training_loss: 3.09887e-02
I0208 14:04:53.900105 22542570456896 run_lib.py:133] step: 11400, training_loss: 3.30331e-02
I0208 14:04:54.062279 22542570456896 run_lib.py:146] step: 11400, eval_loss: 3.71419e-02
I0208 14:05:11.505064 22542570456896 run_lib.py:133] step: 11450, training_loss: 3.37941e-02
I0208 14:05:28.958444 22542570456896 run_lib.py:133] step: 11500, training_loss: 3.12617e-02
I0208 14:05:29.112688 22542570456896 run_lib.py:146] step: 11500, eval_loss: 3.21876e-02
I0208 14:05:46.689342 22542570456896 run_lib.py:133] step: 11550, training_loss: 3.20689e-02
I0208 14:06:04.174138 22542570456896 run_lib.py:133] step: 11600, training_loss: 3.12447e-02
I0208 14:06:04.329322 22542570456896 run_lib.py:146] step: 11600, eval_loss: 3.06488e-02
I0208 14:06:21.732556 22542570456896 run_lib.py:133] step: 11650, training_loss: 2.44972e-02
I0208 14:06:39.140600 22542570456896 run_lib.py:133] step: 11700, training_loss: 2.81961e-02
I0208 14:06:39.293069 22542570456896 run_lib.py:146] step: 11700, eval_loss: 3.37917e-02
I0208 14:06:56.850605 22542570456896 run_lib.py:133] step: 11750, training_loss: 2.96830e-02
I0208 14:07:14.322237 22542570456896 run_lib.py:133] step: 11800, training_loss: 2.75883e-02
I0208 14:07:14.491398 22542570456896 run_lib.py:146] step: 11800, eval_loss: 3.39290e-02
I0208 14:07:31.961257 22542570456896 run_lib.py:133] step: 11850, training_loss: 2.70437e-02
I0208 14:07:49.451993 22542570456896 run_lib.py:133] step: 11900, training_loss: 3.02390e-02
I0208 14:07:49.611310 22542570456896 run_lib.py:146] step: 11900, eval_loss: 2.41927e-02
I0208 14:08:07.200340 22542570456896 run_lib.py:133] step: 11950, training_loss: 3.31081e-02
I0208 14:08:24.611760 22542570456896 run_lib.py:133] step: 12000, training_loss: 3.43115e-02
I0208 14:08:24.767236 22542570456896 run_lib.py:146] step: 12000, eval_loss: 2.77179e-02
I0208 14:08:42.351166 22542570456896 run_lib.py:133] step: 12050, training_loss: 3.52546e-02
I0208 14:08:59.820209 22542570456896 run_lib.py:133] step: 12100, training_loss: 3.17901e-02
I0208 14:08:59.976555 22542570456896 run_lib.py:146] step: 12100, eval_loss: 3.06790e-02
I0208 14:09:17.599086 22542570456896 run_lib.py:133] step: 12150, training_loss: 2.91365e-02
I0208 14:09:35.025677 22542570456896 run_lib.py:133] step: 12200, training_loss: 3.14265e-02
I0208 14:09:35.177548 22542570456896 run_lib.py:146] step: 12200, eval_loss: 2.38436e-02
I0208 14:09:52.545985 22542570456896 run_lib.py:133] step: 12250, training_loss: 3.05999e-02
I0208 14:10:10.061942 22542570456896 run_lib.py:133] step: 12300, training_loss: 3.72203e-02
I0208 14:10:10.223019 22542570456896 run_lib.py:146] step: 12300, eval_loss: 2.43292e-02
I0208 14:10:27.538540 22542570456896 run_lib.py:133] step: 12350, training_loss: 2.71455e-02
I0208 14:10:45.060457 22542570456896 run_lib.py:133] step: 12400, training_loss: 2.69520e-02
I0208 14:10:45.241535 22542570456896 run_lib.py:146] step: 12400, eval_loss: 2.70323e-02
I0208 14:11:02.760732 22542570456896 run_lib.py:133] step: 12450, training_loss: 3.26369e-02
I0208 14:11:20.270601 22542570456896 run_lib.py:133] step: 12500, training_loss: 3.65039e-02
I0208 14:11:20.426651 22542570456896 run_lib.py:146] step: 12500, eval_loss: 2.13397e-02
I0208 14:11:38.067261 22542570456896 run_lib.py:133] step: 12550, training_loss: 3.63785e-02
I0208 14:11:55.468219 22542570456896 run_lib.py:133] step: 12600, training_loss: 2.01502e-02
I0208 14:11:55.623292 22542570456896 run_lib.py:146] step: 12600, eval_loss: 3.48762e-02
I0208 14:12:13.038786 22542570456896 run_lib.py:133] step: 12650, training_loss: 2.49788e-02
I0208 14:12:30.529977 22542570456896 run_lib.py:133] step: 12700, training_loss: 3.21543e-02
I0208 14:12:30.686513 22542570456896 run_lib.py:146] step: 12700, eval_loss: 4.19556e-02
I0208 14:12:48.320716 22542570456896 run_lib.py:133] step: 12750, training_loss: 2.93885e-02
I0208 14:13:05.777095 22542570456896 run_lib.py:133] step: 12800, training_loss: 3.55026e-02
I0208 14:13:05.941010 22542570456896 run_lib.py:146] step: 12800, eval_loss: 2.69207e-02
I0208 14:13:23.433542 22542570456896 run_lib.py:133] step: 12850, training_loss: 3.22606e-02
I0208 14:13:40.840490 22542570456896 run_lib.py:133] step: 12900, training_loss: 2.81667e-02
I0208 14:13:41.005908 22542570456896 run_lib.py:146] step: 12900, eval_loss: 3.65190e-02
I0208 14:13:58.475327 22542570456896 run_lib.py:133] step: 12950, training_loss: 3.35986e-02
I0208 14:14:15.965260 22542570456896 run_lib.py:133] step: 13000, training_loss: 2.76537e-02
I0208 14:14:16.119027 22542570456896 run_lib.py:146] step: 13000, eval_loss: 3.24697e-02
I0208 14:14:33.746296 22542570456896 run_lib.py:133] step: 13050, training_loss: 2.60628e-02
I0208 14:14:51.254420 22542570456896 run_lib.py:133] step: 13100, training_loss: 4.02316e-02
I0208 14:14:51.407132 22542570456896 run_lib.py:146] step: 13100, eval_loss: 2.63517e-02
I0208 14:15:08.866364 22542570456896 run_lib.py:133] step: 13150, training_loss: 2.83346e-02
I0208 14:15:26.317278 22542570456896 run_lib.py:133] step: 13200, training_loss: 3.10723e-02
I0208 14:15:26.474512 22542570456896 run_lib.py:146] step: 13200, eval_loss: 3.05565e-02
I0208 14:15:44.017432 22542570456896 run_lib.py:133] step: 13250, training_loss: 3.34347e-02
I0208 14:16:01.442294 22542570456896 run_lib.py:133] step: 13300, training_loss: 4.28483e-02
I0208 14:16:01.620474 22542570456896 run_lib.py:146] step: 13300, eval_loss: 3.35879e-02
I0208 14:16:19.407383 22542570456896 run_lib.py:133] step: 13350, training_loss: 4.08657e-02
I0208 14:16:36.836561 22542570456896 run_lib.py:133] step: 13400, training_loss: 3.52982e-02
I0208 14:16:36.993526 22542570456896 run_lib.py:146] step: 13400, eval_loss: 3.27520e-02
I0208 14:16:54.562511 22542570456896 run_lib.py:133] step: 13450, training_loss: 3.75118e-02
I0208 14:17:11.957827 22542570456896 run_lib.py:133] step: 13500, training_loss: 3.16631e-02
I0208 14:17:12.117294 22542570456896 run_lib.py:146] step: 13500, eval_loss: 2.91284e-02
I0208 14:17:29.672259 22542570456896 run_lib.py:133] step: 13550, training_loss: 3.38247e-02
I0208 14:17:47.090903 22542570456896 run_lib.py:133] step: 13600, training_loss: 3.39529e-02
I0208 14:17:47.253367 22542570456896 run_lib.py:146] step: 13600, eval_loss: 2.94070e-02
I0208 14:18:04.713664 22542570456896 run_lib.py:133] step: 13650, training_loss: 3.02639e-02
I0208 14:18:22.309542 22542570456896 run_lib.py:133] step: 13700, training_loss: 3.33212e-02
I0208 14:18:22.469012 22542570456896 run_lib.py:146] step: 13700, eval_loss: 3.09083e-02
I0208 14:18:39.823935 22542570456896 run_lib.py:133] step: 13750, training_loss: 2.26463e-02
I0208 14:18:57.242756 22542570456896 run_lib.py:133] step: 13800, training_loss: 3.91858e-02
I0208 14:18:57.414345 22542570456896 run_lib.py:146] step: 13800, eval_loss: 3.23758e-02
I0208 14:19:15.011732 22542570456896 run_lib.py:133] step: 13850, training_loss: 2.56843e-02
I0208 14:19:32.603082 22542570456896 run_lib.py:133] step: 13900, training_loss: 3.06358e-02
I0208 14:19:32.759920 22542570456896 run_lib.py:146] step: 13900, eval_loss: 3.57236e-02
I0208 14:19:50.163797 22542570456896 run_lib.py:133] step: 13950, training_loss: 3.90008e-02
I0208 14:20:07.547825 22542570456896 run_lib.py:133] step: 14000, training_loss: 3.69225e-02
I0208 14:20:07.703114 22542570456896 run_lib.py:146] step: 14000, eval_loss: 2.52624e-02
I0208 14:20:25.147571 22542570456896 run_lib.py:133] step: 14050, training_loss: 2.97527e-02
I0208 14:20:42.725488 22542570456896 run_lib.py:133] step: 14100, training_loss: 3.52973e-02
I0208 14:20:42.878443 22542570456896 run_lib.py:146] step: 14100, eval_loss: 3.34558e-02
I0208 14:21:00.369294 22542570456896 run_lib.py:133] step: 14150, training_loss: 2.73236e-02
I0208 14:21:17.788271 22542570456896 run_lib.py:133] step: 14200, training_loss: 3.13222e-02
I0208 14:21:17.954335 22542570456896 run_lib.py:146] step: 14200, eval_loss: 3.58175e-02
I0208 14:21:35.403311 22542570456896 run_lib.py:133] step: 14250, training_loss: 3.77594e-02
I0208 14:21:53.028490 22542570456896 run_lib.py:133] step: 14300, training_loss: 2.12066e-02
I0208 14:21:53.189635 22542570456896 run_lib.py:146] step: 14300, eval_loss: 3.28859e-02
I0208 14:22:10.607668 22542570456896 run_lib.py:133] step: 14350, training_loss: 3.28019e-02
I0208 14:22:28.093068 22542570456896 run_lib.py:133] step: 14400, training_loss: 3.07779e-02
I0208 14:22:28.266974 22542570456896 run_lib.py:146] step: 14400, eval_loss: 2.94622e-02
I0208 14:22:45.730724 22542570456896 run_lib.py:133] step: 14450, training_loss: 2.51437e-02
I0208 14:23:03.168491 22542570456896 run_lib.py:133] step: 14500, training_loss: 3.54726e-02
I0208 14:23:03.324557 22542570456896 run_lib.py:146] step: 14500, eval_loss: 3.09188e-02
I0208 14:23:20.875433 22542570456896 run_lib.py:133] step: 14550, training_loss: 3.00924e-02
I0208 14:23:38.321089 22542570456896 run_lib.py:133] step: 14600, training_loss: 3.22528e-02
I0208 14:23:38.474386 22542570456896 run_lib.py:146] step: 14600, eval_loss: 2.99220e-02
I0208 14:23:55.899129 22542570456896 run_lib.py:133] step: 14650, training_loss: 2.74813e-02
I0208 14:24:13.326242 22542570456896 run_lib.py:133] step: 14700, training_loss: 3.71038e-02
I0208 14:24:13.502249 22542570456896 run_lib.py:146] step: 14700, eval_loss: 3.35433e-02
I0208 14:24:31.119125 22542570456896 run_lib.py:133] step: 14750, training_loss: 2.42023e-02
I0208 14:24:48.562332 22542570456896 run_lib.py:133] step: 14800, training_loss: 2.45747e-02
I0208 14:24:48.720472 22542570456896 run_lib.py:146] step: 14800, eval_loss: 3.25729e-02
I0208 14:25:06.292590 22542570456896 run_lib.py:133] step: 14850, training_loss: 2.46793e-02
I0208 14:25:23.717677 22542570456896 run_lib.py:133] step: 14900, training_loss: 3.15095e-02
I0208 14:25:23.874140 22542570456896 run_lib.py:146] step: 14900, eval_loss: 3.54498e-02
I0208 14:25:41.425536 22542570456896 run_lib.py:133] step: 14950, training_loss: 2.78515e-02
I0208 14:25:58.903043 22542570456896 run_lib.py:133] step: 15000, training_loss: 3.83848e-02
I0208 14:25:59.058187 22542570456896 run_lib.py:146] step: 15000, eval_loss: 3.02805e-02
I0208 14:26:16.486679 22542570456896 run_lib.py:133] step: 15050, training_loss: 3.23876e-02
I0208 14:26:34.127463 22542570456896 run_lib.py:133] step: 15100, training_loss: 2.87254e-02
I0208 14:26:34.283272 22542570456896 run_lib.py:146] step: 15100, eval_loss: 3.32504e-02
I0208 14:26:51.684887 22542570456896 run_lib.py:133] step: 15150, training_loss: 3.19303e-02
I0208 14:27:09.269105 22542570456896 run_lib.py:133] step: 15200, training_loss: 2.67277e-02
I0208 14:27:09.428321 22542570456896 run_lib.py:146] step: 15200, eval_loss: 3.28621e-02
I0208 14:27:26.863176 22542570456896 run_lib.py:133] step: 15250, training_loss: 2.89377e-02
I0208 14:27:44.317249 22542570456896 run_lib.py:133] step: 15300, training_loss: 3.11234e-02
I0208 14:27:44.477479 22542570456896 run_lib.py:146] step: 15300, eval_loss: 2.81577e-02
I0208 14:28:02.093913 22542570456896 run_lib.py:133] step: 15350, training_loss: 2.56104e-02
I0208 14:28:19.491342 22542570456896 run_lib.py:133] step: 15400, training_loss: 2.63345e-02
I0208 14:28:19.648338 22542570456896 run_lib.py:146] step: 15400, eval_loss: 2.81266e-02
I0208 14:28:37.113951 22542570456896 run_lib.py:133] step: 15450, training_loss: 3.22692e-02
I0208 14:28:54.662334 22542570456896 run_lib.py:133] step: 15500, training_loss: 2.52730e-02
I0208 14:28:54.821300 22542570456896 run_lib.py:146] step: 15500, eval_loss: 2.86669e-02
I0208 14:29:12.213780 22542570456896 run_lib.py:133] step: 15550, training_loss: 3.17823e-02
I0208 14:29:29.699277 22542570456896 run_lib.py:133] step: 15600, training_loss: 2.69346e-02
I0208 14:29:29.870408 22542570456896 run_lib.py:146] step: 15600, eval_loss: 2.94632e-02
I0208 14:29:47.388567 22542570456896 run_lib.py:133] step: 15650, training_loss: 3.12090e-02
I0208 14:30:04.819092 22542570456896 run_lib.py:133] step: 15700, training_loss: 3.21081e-02
I0208 14:30:04.984102 22542570456896 run_lib.py:146] step: 15700, eval_loss: 2.86198e-02
I0208 14:30:22.400697 22542570456896 run_lib.py:133] step: 15750, training_loss: 3.19448e-02
I0208 14:30:39.834120 22542570456896 run_lib.py:133] step: 15800, training_loss: 2.69554e-02
I0208 14:30:39.989950 22542570456896 run_lib.py:146] step: 15800, eval_loss: 2.53482e-02
I0208 14:30:57.558405 22542570456896 run_lib.py:133] step: 15850, training_loss: 2.64240e-02
I0208 14:31:15.118983 22542570456896 run_lib.py:133] step: 15900, training_loss: 2.60555e-02
I0208 14:31:15.278420 22542570456896 run_lib.py:146] step: 15900, eval_loss: 2.86537e-02
I0208 14:31:32.727107 22542570456896 run_lib.py:133] step: 15950, training_loss: 2.83805e-02
I0208 14:31:50.164811 22542570456896 run_lib.py:133] step: 16000, training_loss: 3.05199e-02
I0208 14:31:50.325451 22542570456896 run_lib.py:146] step: 16000, eval_loss: 2.52211e-02
I0208 14:32:07.924170 22542570456896 run_lib.py:133] step: 16050, training_loss: 2.79009e-02
I0208 14:32:25.347914 22542570456896 run_lib.py:133] step: 16100, training_loss: 2.73588e-02
I0208 14:32:25.509498 22542570456896 run_lib.py:146] step: 16100, eval_loss: 2.90429e-02
I0208 14:32:43.076442 22542570456896 run_lib.py:133] step: 16150, training_loss: 2.70981e-02
I0208 14:33:00.540895 22542570456896 run_lib.py:133] step: 16200, training_loss: 2.57011e-02
I0208 14:33:00.694576 22542570456896 run_lib.py:146] step: 16200, eval_loss: 2.95756e-02
I0208 14:33:18.308420 22542570456896 run_lib.py:133] step: 16250, training_loss: 2.66284e-02
I0208 14:33:35.698616 22542570456896 run_lib.py:133] step: 16300, training_loss: 2.72474e-02
I0208 14:33:35.852384 22542570456896 run_lib.py:146] step: 16300, eval_loss: 3.22435e-02
I0208 14:33:53.461414 22542570456896 run_lib.py:133] step: 16350, training_loss: 3.40837e-02
I0208 14:34:10.897519 22542570456896 run_lib.py:133] step: 16400, training_loss: 3.14499e-02
I0208 14:34:11.053368 22542570456896 run_lib.py:146] step: 16400, eval_loss: 2.73497e-02
I0208 14:34:28.571038 22542570456896 run_lib.py:133] step: 16450, training_loss: 2.66661e-02
I0208 14:34:46.145047 22542570456896 run_lib.py:133] step: 16500, training_loss: 2.40197e-02
I0208 14:34:46.301625 22542570456896 run_lib.py:146] step: 16500, eval_loss: 3.13323e-02
I0208 14:35:03.742470 22542570456896 run_lib.py:133] step: 16550, training_loss: 2.99441e-02
I0208 14:35:21.179688 22542570456896 run_lib.py:133] step: 16600, training_loss: 2.60736e-02
I0208 14:35:21.339221 22542570456896 run_lib.py:146] step: 16600, eval_loss: 3.46340e-02
I0208 14:35:38.912818 22542570456896 run_lib.py:133] step: 16650, training_loss: 3.16449e-02
I0208 14:35:56.402310 22542570456896 run_lib.py:133] step: 16700, training_loss: 2.71215e-02
I0208 14:35:56.570199 22542570456896 run_lib.py:146] step: 16700, eval_loss: 2.69985e-02
I0208 14:36:14.165566 22542570456896 run_lib.py:133] step: 16750, training_loss: 2.69226e-02
I0208 14:36:31.630542 22542570456896 run_lib.py:133] step: 16800, training_loss: 3.53165e-02
I0208 14:36:31.787058 22542570456896 run_lib.py:146] step: 16800, eval_loss: 2.73658e-02
I0208 14:36:49.225650 22542570456896 run_lib.py:133] step: 16850, training_loss: 2.66782e-02
I0208 14:37:06.814190 22542570456896 run_lib.py:133] step: 16900, training_loss: 2.73676e-02
I0208 14:37:06.976300 22542570456896 run_lib.py:146] step: 16900, eval_loss: 2.98581e-02
I0208 14:37:24.457853 22542570456896 run_lib.py:133] step: 16950, training_loss: 3.88254e-02
I0208 14:37:41.904790 22542570456896 run_lib.py:133] step: 17000, training_loss: 3.50996e-02
I0208 14:37:42.073597 22542570456896 run_lib.py:146] step: 17000, eval_loss: 3.85482e-02
I0208 14:37:59.479680 22542570456896 run_lib.py:133] step: 17050, training_loss: 3.29203e-02
I0208 14:38:17.081261 22542570456896 run_lib.py:133] step: 17100, training_loss: 3.23201e-02
I0208 14:38:17.238232 22542570456896 run_lib.py:146] step: 17100, eval_loss: 2.90560e-02
I0208 14:38:34.654736 22542570456896 run_lib.py:133] step: 17150, training_loss: 2.74685e-02
I0208 14:38:52.130476 22542570456896 run_lib.py:133] step: 17200, training_loss: 2.90764e-02
I0208 14:38:52.286154 22542570456896 run_lib.py:146] step: 17200, eval_loss: 2.99078e-02
I0208 14:39:09.744780 22542570456896 run_lib.py:133] step: 17250, training_loss: 4.06121e-02
I0208 14:39:27.250286 22542570456896 run_lib.py:133] step: 17300, training_loss: 3.25355e-02
I0208 14:39:27.405703 22542570456896 run_lib.py:146] step: 17300, eval_loss: 2.47348e-02
I0208 14:39:45.034650 22542570456896 run_lib.py:133] step: 17350, training_loss: 3.12071e-02
I0208 14:40:02.485638 22542570456896 run_lib.py:133] step: 17400, training_loss: 2.86027e-02
I0208 14:40:02.648258 22542570456896 run_lib.py:146] step: 17400, eval_loss: 2.89723e-02
I0208 14:40:20.035525 22542570456896 run_lib.py:133] step: 17450, training_loss: 2.86088e-02
I0208 14:40:37.448996 22542570456896 run_lib.py:133] step: 17500, training_loss: 2.90081e-02
I0208 14:40:37.604258 22542570456896 run_lib.py:146] step: 17500, eval_loss: 2.88418e-02
I0208 14:40:55.183156 22542570456896 run_lib.py:133] step: 17550, training_loss: 2.43179e-02
I0208 14:41:12.665339 22542570456896 run_lib.py:133] step: 17600, training_loss: 2.92142e-02
I0208 14:41:12.825278 22542570456896 run_lib.py:146] step: 17600, eval_loss: 2.53995e-02
I0208 14:41:30.394389 22542570456896 run_lib.py:133] step: 17650, training_loss: 2.67581e-02
I0208 14:41:47.819160 22542570456896 run_lib.py:133] step: 17700, training_loss: 2.59059e-02
I0208 14:41:47.974428 22542570456896 run_lib.py:146] step: 17700, eval_loss: 2.84121e-02
I0208 14:42:05.541352 22542570456896 run_lib.py:133] step: 17750, training_loss: 3.62900e-02
I0208 14:42:22.954724 22542570456896 run_lib.py:133] step: 17800, training_loss: 3.02285e-02
I0208 14:42:23.109220 22542570456896 run_lib.py:146] step: 17800, eval_loss: 2.46126e-02
I0208 14:42:40.524791 22542570456896 run_lib.py:133] step: 17850, training_loss: 2.71653e-02
I0208 14:42:58.124449 22542570456896 run_lib.py:133] step: 17900, training_loss: 2.85344e-02
I0208 14:42:58.280532 22542570456896 run_lib.py:146] step: 17900, eval_loss: 2.89805e-02
I0208 14:43:15.754556 22542570456896 run_lib.py:133] step: 17950, training_loss: 2.93169e-02
I0208 14:43:33.413235 22542570456896 run_lib.py:133] step: 18000, training_loss: 3.01075e-02
I0208 14:43:33.571470 22542570456896 run_lib.py:146] step: 18000, eval_loss: 3.27683e-02
I0208 14:43:51.002497 22542570456896 run_lib.py:133] step: 18050, training_loss: 2.76772e-02
I0208 14:44:08.398858 22542570456896 run_lib.py:133] step: 18100, training_loss: 2.88721e-02
I0208 14:44:08.558437 22542570456896 run_lib.py:146] step: 18100, eval_loss: 2.71650e-02
I0208 14:44:26.183932 22542570456896 run_lib.py:133] step: 18150, training_loss: 3.10713e-02
I0208 14:44:43.679739 22542570456896 run_lib.py:133] step: 18200, training_loss: 2.63865e-02
I0208 14:44:43.837858 22542570456896 run_lib.py:146] step: 18200, eval_loss: 2.95494e-02
I0208 14:45:01.281673 22542570456896 run_lib.py:133] step: 18250, training_loss: 2.88232e-02
I0208 14:45:18.906834 22542570456896 run_lib.py:133] step: 18300, training_loss: 3.76483e-02
I0208 14:45:19.064020 22542570456896 run_lib.py:146] step: 18300, eval_loss: 2.79591e-02
I0208 14:45:36.497758 22542570456896 run_lib.py:133] step: 18350, training_loss: 3.26061e-02
I0208 14:45:53.905387 22542570456896 run_lib.py:133] step: 18400, training_loss: 3.19789e-02
I0208 14:45:54.208306 22542570456896 run_lib.py:146] step: 18400, eval_loss: 3.30033e-02
I0208 14:46:11.653512 22542570456896 run_lib.py:133] step: 18450, training_loss: 3.34676e-02
I0208 14:46:29.081833 22542570456896 run_lib.py:133] step: 18500, training_loss: 3.08820e-02
I0208 14:46:29.241302 22542570456896 run_lib.py:146] step: 18500, eval_loss: 2.85794e-02
I0208 14:46:46.647192 22542570456896 run_lib.py:133] step: 18550, training_loss: 3.47864e-02
I0208 14:47:04.143026 22542570456896 run_lib.py:133] step: 18600, training_loss: 3.60387e-02
I0208 14:47:04.299208 22542570456896 run_lib.py:146] step: 18600, eval_loss: 2.90303e-02
I0208 14:47:21.894895 22542570456896 run_lib.py:133] step: 18650, training_loss: 3.13364e-02
I0208 14:47:39.364545 22542570456896 run_lib.py:133] step: 18700, training_loss: 3.35885e-02
I0208 14:47:39.521540 22542570456896 run_lib.py:146] step: 18700, eval_loss: 3.29761e-02
I0208 14:47:56.949718 22542570456896 run_lib.py:133] step: 18750, training_loss: 3.66579e-02
I0208 14:48:14.431817 22542570456896 run_lib.py:133] step: 18800, training_loss: 2.51735e-02
I0208 14:48:14.588503 22542570456896 run_lib.py:146] step: 18800, eval_loss: 3.01855e-02
I0208 14:48:32.209229 22542570456896 run_lib.py:133] step: 18850, training_loss: 3.42898e-02
I0208 14:48:49.702728 22542570456896 run_lib.py:133] step: 18900, training_loss: 2.87599e-02
I0208 14:48:49.858293 22542570456896 run_lib.py:146] step: 18900, eval_loss: 2.62201e-02
I0208 14:49:07.250303 22542570456896 run_lib.py:133] step: 18950, training_loss: 3.40575e-02
I0208 14:49:24.679229 22542570456896 run_lib.py:133] step: 19000, training_loss: 2.69562e-02
I0208 14:49:24.837476 22542570456896 run_lib.py:146] step: 19000, eval_loss: 2.31658e-02
I0208 14:49:42.411557 22542570456896 run_lib.py:133] step: 19050, training_loss: 3.11577e-02
I0208 14:49:59.889302 22542570456896 run_lib.py:133] step: 19100, training_loss: 3.47376e-02
I0208 14:50:00.046687 22542570456896 run_lib.py:146] step: 19100, eval_loss: 3.41338e-02
I0208 14:50:17.604304 22542570456896 run_lib.py:133] step: 19150, training_loss: 3.21504e-02
I0208 14:50:34.977063 22542570456896 run_lib.py:133] step: 19200, training_loss: 4.19304e-02
I0208 14:50:35.136209 22542570456896 run_lib.py:146] step: 19200, eval_loss: 2.87062e-02
I0208 14:50:52.704440 22542570456896 run_lib.py:133] step: 19250, training_loss: 2.89171e-02
I0208 14:51:10.165919 22542570456896 run_lib.py:133] step: 19300, training_loss: 3.94727e-02
I0208 14:51:10.322515 22542570456896 run_lib.py:146] step: 19300, eval_loss: 2.76162e-02
I0208 14:51:27.784974 22542570456896 run_lib.py:133] step: 19350, training_loss: 2.81229e-02
I0208 14:51:45.402323 22542570456896 run_lib.py:133] step: 19400, training_loss: 3.53197e-02
I0208 14:51:45.559260 22542570456896 run_lib.py:146] step: 19400, eval_loss: 3.73039e-02
I0208 14:52:02.993056 22542570456896 run_lib.py:133] step: 19450, training_loss: 3.84398e-02
I0208 14:52:20.564904 22542570456896 run_lib.py:133] step: 19500, training_loss: 3.14896e-02
I0208 14:52:20.729562 22542570456896 run_lib.py:146] step: 19500, eval_loss: 2.72153e-02
I0208 14:52:38.136605 22542570456896 run_lib.py:133] step: 19550, training_loss: 3.10057e-02
I0208 14:52:55.525135 22542570456896 run_lib.py:133] step: 19600, training_loss: 2.19136e-02
I0208 14:52:55.693208 22542570456896 run_lib.py:146] step: 19600, eval_loss: 2.48725e-02
I0208 14:53:13.304439 22542570456896 run_lib.py:133] step: 19650, training_loss: 3.33270e-02
I0208 14:53:30.774419 22542570456896 run_lib.py:133] step: 19700, training_loss: 4.10176e-02
I0208 14:53:30.929519 22542570456896 run_lib.py:146] step: 19700, eval_loss: 2.76305e-02
I0208 14:53:48.343066 22542570456896 run_lib.py:133] step: 19750, training_loss: 3.82360e-02
I0208 14:54:05.715503 22542570456896 run_lib.py:133] step: 19800, training_loss: 2.77532e-02
I0208 14:54:05.868291 22542570456896 run_lib.py:146] step: 19800, eval_loss: 3.19931e-02
I0208 14:54:23.462764 22542570456896 run_lib.py:133] step: 19850, training_loss: 3.44307e-02
I0208 14:54:40.924362 22542570456896 run_lib.py:133] step: 19900, training_loss: 2.81508e-02
I0208 14:54:41.095299 22542570456896 run_lib.py:146] step: 19900, eval_loss: 2.65018e-02
I0208 14:54:58.606074 22542570456896 run_lib.py:133] step: 19950, training_loss: 2.29535e-02
I0208 14:55:16.072585 22542570456896 run_lib.py:133] step: 20000, training_loss: 3.17412e-02
I0208 14:55:16.781097 22542570456896 run_lib.py:146] step: 20000, eval_loss: 3.33569e-02
I0208 14:55:36.820199 22542570456896 run_lib.py:133] step: 20050, training_loss: 2.67487e-02
I0208 14:55:54.243275 22542570456896 run_lib.py:133] step: 20100, training_loss: 3.37289e-02
I0208 14:55:54.401257 22542570456896 run_lib.py:146] step: 20100, eval_loss: 2.76236e-02
I0208 14:56:11.835749 22542570456896 run_lib.py:133] step: 20150, training_loss: 2.83945e-02
I0208 14:56:29.479246 22542570456896 run_lib.py:133] step: 20200, training_loss: 2.58672e-02
I0208 14:56:29.639707 22542570456896 run_lib.py:146] step: 20200, eval_loss: 2.46178e-02
I0208 14:56:47.203701 22542570456896 run_lib.py:133] step: 20250, training_loss: 2.86123e-02
I0208 14:57:04.644607 22542570456896 run_lib.py:133] step: 20300, training_loss: 2.96973e-02
I0208 14:57:04.797370 22542570456896 run_lib.py:146] step: 20300, eval_loss: 3.41751e-02
I0208 14:57:22.253644 22542570456896 run_lib.py:133] step: 20350, training_loss: 3.55689e-02
I0208 14:57:39.671220 22542570456896 run_lib.py:133] step: 20400, training_loss: 2.35698e-02
I0208 14:57:39.827647 22542570456896 run_lib.py:146] step: 20400, eval_loss: 2.84142e-02
I0208 14:57:57.377058 22542570456896 run_lib.py:133] step: 20450, training_loss: 3.34803e-02
I0208 14:58:15.009253 22542570456896 run_lib.py:133] step: 20500, training_loss: 2.61238e-02
I0208 14:58:15.187371 22542570456896 run_lib.py:146] step: 20500, eval_loss: 2.74789e-02
I0208 14:58:32.621160 22542570456896 run_lib.py:133] step: 20550, training_loss: 3.43181e-02
I0208 14:58:50.057782 22542570456896 run_lib.py:133] step: 20600, training_loss: 2.93475e-02
I0208 14:58:50.224941 22542570456896 run_lib.py:146] step: 20600, eval_loss: 3.67484e-02
I0208 14:59:07.887280 22542570456896 run_lib.py:133] step: 20650, training_loss: 3.27188e-02
I0208 14:59:25.284978 22542570456896 run_lib.py:133] step: 20700, training_loss: 4.11802e-02
I0208 14:59:25.440307 22542570456896 run_lib.py:146] step: 20700, eval_loss: 3.26685e-02
I0208 14:59:43.018196 22542570456896 run_lib.py:133] step: 20750, training_loss: 3.40268e-02
I0208 15:00:00.535236 22542570456896 run_lib.py:133] step: 20800, training_loss: 3.25908e-02
I0208 15:00:00.697563 22542570456896 run_lib.py:146] step: 20800, eval_loss: 3.17484e-02
I0208 15:00:18.358359 22542570456896 run_lib.py:133] step: 20850, training_loss: 3.61859e-02
I0208 15:00:35.778135 22542570456896 run_lib.py:133] step: 20900, training_loss: 2.67189e-02
I0208 15:00:35.935334 22542570456896 run_lib.py:146] step: 20900, eval_loss: 2.98860e-02
I0208 15:00:53.370235 22542570456896 run_lib.py:133] step: 20950, training_loss: 3.11092e-02
I0208 15:01:10.932182 22542570456896 run_lib.py:133] step: 21000, training_loss: 2.96413e-02
I0208 15:01:11.090538 22542570456896 run_lib.py:146] step: 21000, eval_loss: 4.15649e-02
I0208 15:01:28.547797 22542570456896 run_lib.py:133] step: 21050, training_loss: 2.61775e-02
I0208 15:01:46.168347 22542570456896 run_lib.py:133] step: 21100, training_loss: 2.66482e-02
I0208 15:01:46.325478 22542570456896 run_lib.py:146] step: 21100, eval_loss: 3.14856e-02
I0208 15:02:03.732431 22542570456896 run_lib.py:133] step: 21150, training_loss: 3.73829e-02
I0208 15:02:21.160886 22542570456896 run_lib.py:133] step: 21200, training_loss: 2.87297e-02
I0208 15:02:21.328341 22542570456896 run_lib.py:146] step: 21200, eval_loss: 3.75515e-02
I0208 15:02:38.998091 22542570456896 run_lib.py:133] step: 21250, training_loss: 3.27001e-02
I0208 15:02:56.415749 22542570456896 run_lib.py:133] step: 21300, training_loss: 3.07729e-02
I0208 15:02:56.568431 22542570456896 run_lib.py:146] step: 21300, eval_loss: 3.03469e-02
I0208 15:03:14.041925 22542570456896 run_lib.py:133] step: 21350, training_loss: 2.85500e-02
I0208 15:03:31.673182 22542570456896 run_lib.py:133] step: 21400, training_loss: 2.40182e-02
I0208 15:03:31.833335 22542570456896 run_lib.py:146] step: 21400, eval_loss: 2.71848e-02
I0208 15:03:49.281801 22542570456896 run_lib.py:133] step: 21450, training_loss: 2.91817e-02
I0208 15:04:06.696527 22542570456896 run_lib.py:133] step: 21500, training_loss: 3.48805e-02
I0208 15:04:06.853500 22542570456896 run_lib.py:146] step: 21500, eval_loss: 3.36534e-02
I0208 15:04:24.364349 22542570456896 run_lib.py:133] step: 21550, training_loss: 3.09599e-02
I0208 15:04:41.810951 22542570456896 run_lib.py:133] step: 21600, training_loss: 3.00013e-02
I0208 15:04:41.979482 22542570456896 run_lib.py:146] step: 21600, eval_loss: 3.19149e-02
I0208 15:04:59.475550 22542570456896 run_lib.py:133] step: 21650, training_loss: 2.85083e-02
I0208 15:05:16.905924 22542570456896 run_lib.py:133] step: 21700, training_loss: 2.78641e-02
I0208 15:05:17.067088 22542570456896 run_lib.py:146] step: 21700, eval_loss: 2.89446e-02
I0208 15:05:34.678727 22542570456896 run_lib.py:133] step: 21750, training_loss: 2.93841e-02
I0208 15:05:52.166871 22542570456896 run_lib.py:133] step: 21800, training_loss: 3.49881e-02
I0208 15:05:52.322346 22542570456896 run_lib.py:146] step: 21800, eval_loss: 2.57335e-02
I0208 15:06:09.777190 22542570456896 run_lib.py:133] step: 21850, training_loss: 3.19760e-02
I0208 15:06:27.183656 22542570456896 run_lib.py:133] step: 21900, training_loss: 2.40381e-02
I0208 15:06:27.344369 22542570456896 run_lib.py:146] step: 21900, eval_loss: 3.32018e-02
I0208 15:06:44.994444 22542570456896 run_lib.py:133] step: 21950, training_loss: 2.79527e-02
I0208 15:07:02.444988 22542570456896 run_lib.py:133] step: 22000, training_loss: 3.05590e-02
I0208 15:07:02.602528 22542570456896 run_lib.py:146] step: 22000, eval_loss: 2.93640e-02
I0208 15:07:20.231890 22542570456896 run_lib.py:133] step: 22050, training_loss: 3.78217e-02
I0208 15:07:37.630375 22542570456896 run_lib.py:133] step: 22100, training_loss: 2.87496e-02
I0208 15:07:37.788213 22542570456896 run_lib.py:146] step: 22100, eval_loss: 2.69246e-02
I0208 15:07:55.333519 22542570456896 run_lib.py:133] step: 22150, training_loss: 2.64020e-02
I0208 15:08:12.768229 22542570456896 run_lib.py:133] step: 22200, training_loss: 2.87239e-02
I0208 15:08:12.930654 22542570456896 run_lib.py:146] step: 22200, eval_loss: 2.99575e-02
I0208 15:08:30.620974 22542570456896 run_lib.py:133] step: 22250, training_loss: 2.80969e-02
I0208 15:08:48.054996 22542570456896 run_lib.py:133] step: 22300, training_loss: 3.44399e-02
I0208 15:08:48.211526 22542570456896 run_lib.py:146] step: 22300, eval_loss: 3.54922e-02
I0208 15:09:05.660373 22542570456896 run_lib.py:133] step: 22350, training_loss: 2.55160e-02
I0208 15:09:23.299304 22542570456896 run_lib.py:133] step: 22400, training_loss: 3.25475e-02
I0208 15:09:23.459535 22542570456896 run_lib.py:146] step: 22400, eval_loss: 2.61729e-02
I0208 15:09:40.897687 22542570456896 run_lib.py:133] step: 22450, training_loss: 3.08632e-02
I0208 15:09:58.305108 22542570456896 run_lib.py:133] step: 22500, training_loss: 2.80854e-02
I0208 15:09:58.476395 22542570456896 run_lib.py:146] step: 22500, eval_loss: 3.13394e-02
I0208 15:10:16.099847 22542570456896 run_lib.py:133] step: 22550, training_loss: 3.27927e-02
I0208 15:10:33.574985 22542570456896 run_lib.py:133] step: 22600, training_loss: 2.64550e-02
I0208 15:10:33.732605 22542570456896 run_lib.py:146] step: 22600, eval_loss: 2.86068e-02
I0208 15:10:51.390546 22542570456896 run_lib.py:133] step: 22650, training_loss: 3.34497e-02
I0208 15:11:08.808512 22542570456896 run_lib.py:133] step: 22700, training_loss: 3.06716e-02
I0208 15:11:08.961351 22542570456896 run_lib.py:146] step: 22700, eval_loss: 2.86433e-02
I0208 15:11:26.359092 22542570456896 run_lib.py:133] step: 22750, training_loss: 2.64146e-02
I0208 15:11:43.945339 22542570456896 run_lib.py:133] step: 22800, training_loss: 3.05198e-02
I0208 15:11:44.115686 22542570456896 run_lib.py:146] step: 22800, eval_loss: 3.22213e-02
I0208 15:12:01.565682 22542570456896 run_lib.py:133] step: 22850, training_loss: 2.62308e-02
I0208 15:12:19.007561 22542570456896 run_lib.py:133] step: 22900, training_loss: 2.74066e-02
I0208 15:12:19.166609 22542570456896 run_lib.py:146] step: 22900, eval_loss: 2.65923e-02
I0208 15:12:36.575726 22542570456896 run_lib.py:133] step: 22950, training_loss: 2.77460e-02
I0208 15:12:54.193972 22542570456896 run_lib.py:133] step: 23000, training_loss: 3.18382e-02
I0208 15:12:54.351042 22542570456896 run_lib.py:146] step: 23000, eval_loss: 3.47946e-02
I0208 15:13:11.830851 22542570456896 run_lib.py:133] step: 23050, training_loss: 2.89908e-02
I0208 15:13:29.362677 22542570456896 run_lib.py:133] step: 23100, training_loss: 2.99187e-02
I0208 15:13:29.521503 22542570456896 run_lib.py:146] step: 23100, eval_loss: 2.38550e-02
I0208 15:13:46.991707 22542570456896 run_lib.py:133] step: 23150, training_loss: 2.55428e-02
I0208 15:14:04.398742 22542570456896 run_lib.py:133] step: 23200, training_loss: 3.25621e-02
I0208 15:14:04.553294 22542570456896 run_lib.py:146] step: 23200, eval_loss: 3.17509e-02
I0208 15:14:22.144445 22542570456896 run_lib.py:133] step: 23250, training_loss: 3.16325e-02
I0208 15:14:39.629834 22542570456896 run_lib.py:133] step: 23300, training_loss: 3.04177e-02
I0208 15:14:39.789541 22542570456896 run_lib.py:146] step: 23300, eval_loss: 2.86807e-02
I0208 15:14:57.222242 22542570456896 run_lib.py:133] step: 23350, training_loss: 2.29302e-02
I0208 15:15:14.769896 22542570456896 run_lib.py:133] step: 23400, training_loss: 3.62737e-02
I0208 15:15:14.927586 22542570456896 run_lib.py:146] step: 23400, eval_loss: 2.42799e-02
I0208 15:15:32.530191 22542570456896 run_lib.py:133] step: 23450, training_loss: 2.85509e-02
I0208 15:15:49.937042 22542570456896 run_lib.py:133] step: 23500, training_loss: 3.27615e-02
I0208 15:15:50.093399 22542570456896 run_lib.py:146] step: 23500, eval_loss: 4.25690e-02
I0208 15:16:07.684115 22542570456896 run_lib.py:133] step: 23550, training_loss: 2.65970e-02
I0208 15:16:25.116090 22542570456896 run_lib.py:133] step: 23600, training_loss: 3.01419e-02
I0208 15:16:25.269039 22542570456896 run_lib.py:146] step: 23600, eval_loss: 4.18397e-02
I0208 15:16:42.880300 22542570456896 run_lib.py:133] step: 23650, training_loss: 3.39347e-02
I0208 15:17:00.353933 22542570456896 run_lib.py:133] step: 23700, training_loss: 2.55353e-02
I0208 15:17:00.520522 22542570456896 run_lib.py:146] step: 23700, eval_loss: 2.95883e-02
I0208 15:17:18.020594 22542570456896 run_lib.py:133] step: 23750, training_loss: 2.52186e-02
I0208 15:17:35.651408 22542570456896 run_lib.py:133] step: 23800, training_loss: 3.28343e-02
I0208 15:17:35.819567 22542570456896 run_lib.py:146] step: 23800, eval_loss: 2.97682e-02
I0208 15:17:53.284145 22542570456896 run_lib.py:133] step: 23850, training_loss: 3.31481e-02
I0208 15:18:10.839505 22542570456896 run_lib.py:133] step: 23900, training_loss: 2.50686e-02
I0208 15:18:10.997268 22542570456896 run_lib.py:146] step: 23900, eval_loss: 2.84796e-02
I0208 15:18:28.424161 22542570456896 run_lib.py:133] step: 23950, training_loss: 3.17597e-02
I0208 15:18:45.844187 22542570456896 run_lib.py:133] step: 24000, training_loss: 3.38765e-02
I0208 15:18:46.005275 22542570456896 run_lib.py:146] step: 24000, eval_loss: 2.32446e-02
I0208 15:19:03.522325 22542570456896 run_lib.py:133] step: 24050, training_loss: 2.86347e-02
I0208 15:19:20.846199 22542570456896 run_lib.py:133] step: 24100, training_loss: 3.57401e-02
I0208 15:19:20.998601 22542570456896 run_lib.py:146] step: 24100, eval_loss: 2.58084e-02
I0208 15:19:38.344011 22542570456896 run_lib.py:133] step: 24150, training_loss: 3.62711e-02
I0208 15:19:55.930014 22542570456896 run_lib.py:133] step: 24200, training_loss: 3.81337e-02
I0208 15:19:56.087695 22542570456896 run_lib.py:146] step: 24200, eval_loss: 2.49476e-02
I0208 15:20:13.581757 22542570456896 run_lib.py:133] step: 24250, training_loss: 2.81595e-02
I0208 15:20:31.065679 22542570456896 run_lib.py:133] step: 24300, training_loss: 2.88878e-02
I0208 15:20:31.413191 22542570456896 run_lib.py:146] step: 24300, eval_loss: 3.07184e-02
I0208 15:20:48.854454 22542570456896 run_lib.py:133] step: 24350, training_loss: 3.12762e-02
I0208 15:21:06.264923 22542570456896 run_lib.py:133] step: 24400, training_loss: 3.72920e-02
I0208 15:21:06.421310 22542570456896 run_lib.py:146] step: 24400, eval_loss: 2.48740e-02
I0208 15:21:23.863526 22542570456896 run_lib.py:133] step: 24450, training_loss: 3.22523e-02
I0208 15:21:41.272103 22542570456896 run_lib.py:133] step: 24500, training_loss: 3.21592e-02
I0208 15:21:41.434293 22542570456896 run_lib.py:146] step: 24500, eval_loss: 2.70245e-02
I0208 15:21:59.013743 22542570456896 run_lib.py:133] step: 24550, training_loss: 3.65507e-02
I0208 15:22:16.634487 22542570456896 run_lib.py:133] step: 24600, training_loss: 2.71023e-02
I0208 15:22:16.789632 22542570456896 run_lib.py:146] step: 24600, eval_loss: 2.71485e-02
I0208 15:22:34.246750 22542570456896 run_lib.py:133] step: 24650, training_loss: 3.95792e-02
I0208 15:22:51.695281 22542570456896 run_lib.py:133] step: 24700, training_loss: 3.36147e-02
I0208 15:22:51.853154 22542570456896 run_lib.py:146] step: 24700, eval_loss: 3.25803e-02
I0208 15:23:09.379296 22542570456896 run_lib.py:133] step: 24750, training_loss: 3.05943e-02
I0208 15:23:26.850593 22542570456896 run_lib.py:133] step: 24800, training_loss: 2.30418e-02
I0208 15:23:27.034862 22542570456896 run_lib.py:146] step: 24800, eval_loss: 3.19123e-02
I0208 15:23:44.526832 22542570456896 run_lib.py:133] step: 24850, training_loss: 2.63630e-02
I0208 15:24:01.989738 22542570456896 run_lib.py:133] step: 24900, training_loss: 2.35304e-02
I0208 15:24:02.146676 22542570456896 run_lib.py:146] step: 24900, eval_loss: 2.61400e-02
I0208 15:24:19.763949 22542570456896 run_lib.py:133] step: 24950, training_loss: 2.61456e-02
I0208 15:24:37.200756 22542570456896 run_lib.py:133] step: 25000, training_loss: 3.67059e-02
I0208 15:24:37.356312 22542570456896 run_lib.py:146] step: 25000, eval_loss: 2.27567e-02
I0208 15:24:54.913589 22542570456896 run_lib.py:133] step: 25050, training_loss: 3.28899e-02
I0208 15:25:12.377949 22542570456896 run_lib.py:133] step: 25100, training_loss: 2.94376e-02
I0208 15:25:12.541512 22542570456896 run_lib.py:146] step: 25100, eval_loss: 2.51337e-02
I0208 15:25:30.163776 22542570456896 run_lib.py:133] step: 25150, training_loss: 3.21594e-02
I0208 15:25:47.635005 22542570456896 run_lib.py:133] step: 25200, training_loss: 3.23395e-02
I0208 15:25:47.793507 22542570456896 run_lib.py:146] step: 25200, eval_loss: 3.00467e-02
I0208 15:26:05.202180 22542570456896 run_lib.py:133] step: 25250, training_loss: 3.44201e-02
I0208 15:26:22.810599 22542570456896 run_lib.py:133] step: 25300, training_loss: 3.06354e-02
I0208 15:26:22.966664 22542570456896 run_lib.py:146] step: 25300, eval_loss: 3.70064e-02
I0208 15:26:40.401133 22542570456896 run_lib.py:133] step: 25350, training_loss: 3.11030e-02
I0208 15:26:58.039640 22542570456896 run_lib.py:133] step: 25400, training_loss: 3.22902e-02
I0208 15:26:58.195204 22542570456896 run_lib.py:146] step: 25400, eval_loss: 3.01637e-02
I0208 15:27:15.660377 22542570456896 run_lib.py:133] step: 25450, training_loss: 2.69729e-02
I0208 15:27:33.079782 22542570456896 run_lib.py:133] step: 25500, training_loss: 3.00287e-02
I0208 15:27:33.233031 22542570456896 run_lib.py:146] step: 25500, eval_loss: 2.81802e-02
I0208 15:27:50.829901 22542570456896 run_lib.py:133] step: 25550, training_loss: 3.23730e-02
I0208 15:28:08.255593 22542570456896 run_lib.py:133] step: 25600, training_loss: 2.91895e-02
I0208 15:28:08.412600 22542570456896 run_lib.py:146] step: 25600, eval_loss: 3.01764e-02
I0208 15:28:25.898590 22542570456896 run_lib.py:133] step: 25650, training_loss: 2.15557e-02
I0208 15:28:43.369717 22542570456896 run_lib.py:133] step: 25700, training_loss: 3.03931e-02
I0208 15:28:43.529356 22542570456896 run_lib.py:146] step: 25700, eval_loss: 3.37248e-02
I0208 15:29:01.143617 22542570456896 run_lib.py:133] step: 25750, training_loss: 2.27053e-02
I0208 15:29:18.555466 22542570456896 run_lib.py:133] step: 25800, training_loss: 2.90135e-02
I0208 15:29:18.713415 22542570456896 run_lib.py:146] step: 25800, eval_loss: 3.04806e-02
I0208 15:29:36.202800 22542570456896 run_lib.py:133] step: 25850, training_loss: 2.16911e-02
I0208 15:29:53.663283 22542570456896 run_lib.py:133] step: 25900, training_loss: 3.29151e-02
I0208 15:29:53.826292 22542570456896 run_lib.py:146] step: 25900, eval_loss: 2.50791e-02
I0208 15:30:11.325109 22542570456896 run_lib.py:133] step: 25950, training_loss: 2.93009e-02
I0208 15:30:28.757193 22542570456896 run_lib.py:133] step: 26000, training_loss: 3.33437e-02
I0208 15:30:28.908782 22542570456896 run_lib.py:146] step: 26000, eval_loss: 2.81765e-02
I0208 15:30:46.511577 22542570456896 run_lib.py:133] step: 26050, training_loss: 2.59980e-02
I0208 15:31:04.004671 22542570456896 run_lib.py:133] step: 26100, training_loss: 3.15520e-02
I0208 15:31:04.160348 22542570456896 run_lib.py:146] step: 26100, eval_loss: 3.36560e-02
I0208 15:31:21.589295 22542570456896 run_lib.py:133] step: 26150, training_loss: 2.75444e-02
I0208 15:31:39.042655 22542570456896 run_lib.py:133] step: 26200, training_loss: 2.38535e-02
I0208 15:31:39.217290 22542570456896 run_lib.py:146] step: 26200, eval_loss: 3.04231e-02
I0208 15:31:56.843868 22542570456896 run_lib.py:133] step: 26250, training_loss: 2.96777e-02
I0208 15:32:14.259496 22542570456896 run_lib.py:133] step: 26300, training_loss: 3.08194e-02
I0208 15:32:14.415782 22542570456896 run_lib.py:146] step: 26300, eval_loss: 2.47012e-02
I0208 15:32:32.041315 22542570456896 run_lib.py:133] step: 26350, training_loss: 3.58800e-02
I0208 15:32:49.488315 22542570456896 run_lib.py:133] step: 26400, training_loss: 2.75130e-02
I0208 15:32:49.644306 22542570456896 run_lib.py:146] step: 26400, eval_loss: 2.66932e-02
I0208 15:33:07.204662 22542570456896 run_lib.py:133] step: 26450, training_loss: 3.27714e-02
I0208 15:33:24.648460 22542570456896 run_lib.py:133] step: 26500, training_loss: 3.24519e-02
I0208 15:33:24.811374 22542570456896 run_lib.py:146] step: 26500, eval_loss: 2.85256e-02
I0208 15:33:42.450710 22542570456896 run_lib.py:133] step: 26550, training_loss: 4.14745e-02
I0208 15:33:59.913675 22542570456896 run_lib.py:133] step: 26600, training_loss: 3.77560e-02
I0208 15:34:00.068625 22542570456896 run_lib.py:146] step: 26600, eval_loss: 2.81970e-02
I0208 15:34:17.475382 22542570456896 run_lib.py:133] step: 26650, training_loss: 3.04252e-02
I0208 15:34:35.055822 22542570456896 run_lib.py:133] step: 26700, training_loss: 2.31290e-02
I0208 15:34:35.219571 22542570456896 run_lib.py:146] step: 26700, eval_loss: 3.03143e-02
I0208 15:34:52.679010 22542570456896 run_lib.py:133] step: 26750, training_loss: 3.43619e-02
I0208 15:35:10.162100 22542570456896 run_lib.py:133] step: 26800, training_loss: 3.29544e-02
I0208 15:35:10.319168 22542570456896 run_lib.py:146] step: 26800, eval_loss: 2.57550e-02
I0208 15:35:27.956398 22542570456896 run_lib.py:133] step: 26850, training_loss: 2.75917e-02
I0208 15:35:45.518278 22542570456896 run_lib.py:133] step: 26900, training_loss: 2.93295e-02
I0208 15:35:45.675343 22542570456896 run_lib.py:146] step: 26900, eval_loss: 2.31050e-02
I0208 15:36:03.078613 22542570456896 run_lib.py:133] step: 26950, training_loss: 2.63123e-02
I0208 15:36:20.485157 22542570456896 run_lib.py:133] step: 27000, training_loss: 3.37976e-02
I0208 15:36:20.647501 22542570456896 run_lib.py:146] step: 27000, eval_loss: 3.07912e-02
I0208 15:36:38.168459 22542570456896 run_lib.py:133] step: 27050, training_loss: 3.36096e-02
I0208 15:36:55.796619 22542570456896 run_lib.py:133] step: 27100, training_loss: 2.62752e-02
I0208 15:36:55.956235 22542570456896 run_lib.py:146] step: 27100, eval_loss: 3.93643e-02
I0208 15:37:13.423443 22542570456896 run_lib.py:133] step: 27150, training_loss: 3.78290e-02
I0208 15:37:30.783390 22542570456896 run_lib.py:133] step: 27200, training_loss: 3.06904e-02
I0208 15:37:30.939313 22542570456896 run_lib.py:146] step: 27200, eval_loss: 2.93148e-02
I0208 15:37:48.353170 22542570456896 run_lib.py:133] step: 27250, training_loss: 3.25451e-02
I0208 15:38:06.006009 22542570456896 run_lib.py:133] step: 27300, training_loss: 2.86083e-02
I0208 15:38:06.162593 22542570456896 run_lib.py:146] step: 27300, eval_loss: 2.65244e-02
I0208 15:38:23.635888 22542570456896 run_lib.py:133] step: 27350, training_loss: 2.38395e-02
I0208 15:38:41.164707 22542570456896 run_lib.py:133] step: 27400, training_loss: 3.01688e-02
I0208 15:38:41.316084 22542570456896 run_lib.py:146] step: 27400, eval_loss: 3.14703e-02
I0208 15:38:58.740645 22542570456896 run_lib.py:133] step: 27450, training_loss: 2.77561e-02
I0208 15:39:16.197315 22542570456896 run_lib.py:133] step: 27500, training_loss: 2.82483e-02
I0208 15:39:16.353271 22542570456896 run_lib.py:146] step: 27500, eval_loss: 3.00174e-02
I0208 15:39:33.881214 22542570456896 run_lib.py:133] step: 27550, training_loss: 2.52098e-02
I0208 15:39:51.400464 22542570456896 run_lib.py:133] step: 27600, training_loss: 2.88691e-02
I0208 15:39:51.579200 22542570456896 run_lib.py:146] step: 27600, eval_loss: 2.64141e-02
I0208 15:40:09.038689 22542570456896 run_lib.py:133] step: 27650, training_loss: 2.55589e-02
I0208 15:40:26.494461 22542570456896 run_lib.py:133] step: 27700, training_loss: 2.88623e-02
I0208 15:40:26.651538 22542570456896 run_lib.py:146] step: 27700, eval_loss: 2.33608e-02
I0208 15:40:44.279932 22542570456896 run_lib.py:133] step: 27750, training_loss: 3.58486e-02
I0208 15:41:01.656949 22542570456896 run_lib.py:133] step: 27800, training_loss: 3.13493e-02
I0208 15:41:01.817280 22542570456896 run_lib.py:146] step: 27800, eval_loss: 2.88136e-02
I0208 15:41:19.375892 22542570456896 run_lib.py:133] step: 27850, training_loss: 3.13343e-02
I0208 15:41:36.863447 22542570456896 run_lib.py:133] step: 27900, training_loss: 2.12116e-02
I0208 15:41:37.022532 22542570456896 run_lib.py:146] step: 27900, eval_loss: 2.48081e-02
I0208 15:41:54.611753 22542570456896 run_lib.py:133] step: 27950, training_loss: 2.63777e-02
I0208 15:42:12.012966 22542570456896 run_lib.py:133] step: 28000, training_loss: 2.71649e-02
I0208 15:42:12.170334 22542570456896 run_lib.py:146] step: 28000, eval_loss: 3.58693e-02
I0208 15:42:29.602991 22542570456896 run_lib.py:133] step: 28050, training_loss: 2.99246e-02
I0208 15:42:47.234081 22542570456896 run_lib.py:133] step: 28100, training_loss: 2.88588e-02
I0208 15:42:47.394568 22542570456896 run_lib.py:146] step: 28100, eval_loss: 2.48011e-02
I0208 15:43:05.009779 22542570456896 run_lib.py:133] step: 28150, training_loss: 2.86612e-02
I0208 15:43:22.647291 22542570456896 run_lib.py:133] step: 28200, training_loss: 3.36608e-02
I0208 15:43:22.809554 22542570456896 run_lib.py:146] step: 28200, eval_loss: 3.12458e-02
I0208 15:43:40.219210 22542570456896 run_lib.py:133] step: 28250, training_loss: 2.51112e-02
I0208 15:43:57.637982 22542570456896 run_lib.py:133] step: 28300, training_loss: 3.78130e-02
I0208 15:43:57.793356 22542570456896 run_lib.py:146] step: 28300, eval_loss: 3.72979e-02
I0208 15:44:15.336166 22542570456896 run_lib.py:133] step: 28350, training_loss: 3.15875e-02
I0208 15:44:32.814666 22542570456896 run_lib.py:133] step: 28400, training_loss: 2.76687e-02
I0208 15:44:32.971596 22542570456896 run_lib.py:146] step: 28400, eval_loss: 3.25419e-02
I0208 15:44:50.450781 22542570456896 run_lib.py:133] step: 28450, training_loss: 2.96072e-02
I0208 15:45:08.074299 22542570456896 run_lib.py:133] step: 28500, training_loss: 3.61224e-02
I0208 15:45:08.230332 22542570456896 run_lib.py:146] step: 28500, eval_loss: 3.28382e-02
I0208 15:45:25.654981 22542570456896 run_lib.py:133] step: 28550, training_loss: 2.53117e-02
I0208 15:45:43.083636 22542570456896 run_lib.py:133] step: 28600, training_loss: 2.89165e-02
I0208 15:45:43.239461 22542570456896 run_lib.py:146] step: 28600, eval_loss: 3.09778e-02
I0208 15:46:00.734614 22542570456896 run_lib.py:133] step: 28650, training_loss: 2.44965e-02
I0208 15:46:18.226662 22542570456896 run_lib.py:133] step: 28700, training_loss: 2.62838e-02
I0208 15:46:18.398448 22542570456896 run_lib.py:146] step: 28700, eval_loss: 2.50832e-02
I0208 15:46:35.860347 22542570456896 run_lib.py:133] step: 28750, training_loss: 2.55960e-02
I0208 15:46:53.301670 22542570456896 run_lib.py:133] step: 28800, training_loss: 2.97785e-02
I0208 15:46:53.457064 22542570456896 run_lib.py:146] step: 28800, eval_loss: 2.85989e-02
I0208 15:47:11.069962 22542570456896 run_lib.py:133] step: 28850, training_loss: 2.69075e-02
I0208 15:47:28.625178 22542570456896 run_lib.py:133] step: 28900, training_loss: 3.55560e-02
I0208 15:47:28.782394 22542570456896 run_lib.py:146] step: 28900, eval_loss: 3.30081e-02
I0208 15:47:46.185022 22542570456896 run_lib.py:133] step: 28950, training_loss: 3.59485e-02
I0208 15:48:03.609763 22542570456896 run_lib.py:133] step: 29000, training_loss: 3.00317e-02
I0208 15:48:03.787219 22542570456896 run_lib.py:146] step: 29000, eval_loss: 3.49301e-02
I0208 15:48:21.408656 22542570456896 run_lib.py:133] step: 29050, training_loss: 3.00463e-02
I0208 15:48:38.890483 22542570456896 run_lib.py:133] step: 29100, training_loss: 2.69116e-02
I0208 15:48:39.046613 22542570456896 run_lib.py:146] step: 29100, eval_loss: 3.39207e-02
I0208 15:48:56.617225 22542570456896 run_lib.py:133] step: 29150, training_loss: 3.11703e-02
I0208 15:49:14.027994 22542570456896 run_lib.py:133] step: 29200, training_loss: 2.94404e-02
I0208 15:49:14.183998 22542570456896 run_lib.py:146] step: 29200, eval_loss: 2.76939e-02
I0208 15:49:31.750484 22542570456896 run_lib.py:133] step: 29250, training_loss: 2.77097e-02
I0208 15:49:49.227998 22542570456896 run_lib.py:133] step: 29300, training_loss: 2.85423e-02
I0208 15:49:49.390796 22542570456896 run_lib.py:146] step: 29300, eval_loss: 3.04406e-02
I0208 15:50:07.043895 22542570456896 run_lib.py:133] step: 29350, training_loss: 2.96219e-02
I0208 15:50:24.433889 22542570456896 run_lib.py:133] step: 29400, training_loss: 2.51166e-02
I0208 15:50:24.587450 22542570456896 run_lib.py:146] step: 29400, eval_loss: 3.06143e-02
I0208 15:50:42.015159 22542570456896 run_lib.py:133] step: 29450, training_loss: 2.90938e-02
I0208 15:50:59.563158 22542570456896 run_lib.py:133] step: 29500, training_loss: 2.98075e-02
I0208 15:50:59.722719 22542570456896 run_lib.py:146] step: 29500, eval_loss: 2.66095e-02
I0208 15:51:17.136347 22542570456896 run_lib.py:133] step: 29550, training_loss: 3.26202e-02
I0208 15:51:34.615474 22542570456896 run_lib.py:133] step: 29600, training_loss: 2.76220e-02
I0208 15:51:34.790295 22542570456896 run_lib.py:146] step: 29600, eval_loss: 2.96312e-02
I0208 15:51:52.409156 22542570456896 run_lib.py:133] step: 29650, training_loss: 2.60052e-02
I0208 15:52:09.852682 22542570456896 run_lib.py:133] step: 29700, training_loss: 3.37372e-02
I0208 15:52:10.008965 22542570456896 run_lib.py:146] step: 29700, eval_loss: 2.66346e-02
I0208 15:52:27.569638 22542570456896 run_lib.py:133] step: 29750, training_loss: 3.01749e-02
I0208 15:52:44.981097 22542570456896 run_lib.py:133] step: 29800, training_loss: 3.51526e-02
I0208 15:52:45.134452 22542570456896 run_lib.py:146] step: 29800, eval_loss: 3.00524e-02
I0208 15:53:02.565310 22542570456896 run_lib.py:133] step: 29850, training_loss: 2.94810e-02
I0208 15:53:20.164740 22542570456896 run_lib.py:133] step: 29900, training_loss: 2.82044e-02
I0208 15:53:20.334506 22542570456896 run_lib.py:146] step: 29900, eval_loss: 3.73063e-02
I0208 15:53:37.764287 22542570456896 run_lib.py:133] step: 29950, training_loss: 2.72480e-02
I0208 15:53:55.179445 22542570456896 run_lib.py:133] step: 30000, training_loss: 3.69629e-02
I0208 15:53:55.968434 22542570456896 run_lib.py:146] step: 30000, eval_loss: 2.90428e-02
I0208 15:54:16.001790 22542570456896 run_lib.py:133] step: 30050, training_loss: 3.03554e-02
I0208 15:54:33.380654 22542570456896 run_lib.py:133] step: 30100, training_loss: 3.38984e-02
I0208 15:54:33.540443 22542570456896 run_lib.py:146] step: 30100, eval_loss: 2.69935e-02
I0208 15:54:51.165360 22542570456896 run_lib.py:133] step: 30150, training_loss: 2.64793e-02
I0208 15:55:08.607359 22542570456896 run_lib.py:133] step: 30200, training_loss: 2.81392e-02
I0208 15:55:08.764172 22542570456896 run_lib.py:146] step: 30200, eval_loss: 2.64137e-02
I0208 15:55:26.325156 22542570456896 run_lib.py:133] step: 30250, training_loss: 3.20796e-02
I0208 15:55:43.747573 22542570456896 run_lib.py:133] step: 30300, training_loss: 3.30909e-02
I0208 15:55:43.910109 22542570456896 run_lib.py:146] step: 30300, eval_loss: 2.27115e-02
I0208 15:56:01.338766 22542570456896 run_lib.py:133] step: 30350, training_loss: 3.11313e-02
I0208 15:56:18.772870 22542570456896 run_lib.py:133] step: 30400, training_loss: 2.92023e-02
I0208 15:56:18.931409 22542570456896 run_lib.py:146] step: 30400, eval_loss: 4.31697e-02
I0208 15:56:36.553060 22542570456896 run_lib.py:133] step: 30450, training_loss: 2.70602e-02
I0208 15:56:54.048341 22542570456896 run_lib.py:133] step: 30500, training_loss: 3.07054e-02
I0208 15:56:54.207249 22542570456896 run_lib.py:146] step: 30500, eval_loss: 3.14841e-02
I0208 15:57:11.629749 22542570456896 run_lib.py:133] step: 30550, training_loss: 2.69203e-02
I0208 15:57:29.029175 22542570456896 run_lib.py:133] step: 30600, training_loss: 3.21366e-02
I0208 15:57:29.185319 22542570456896 run_lib.py:146] step: 30600, eval_loss: 2.56048e-02
I0208 15:57:46.726839 22542570456896 run_lib.py:133] step: 30650, training_loss: 2.70543e-02
I0208 15:58:04.205425 22542570456896 run_lib.py:133] step: 30700, training_loss: 2.64293e-02
I0208 15:58:04.363889 22542570456896 run_lib.py:146] step: 30700, eval_loss: 2.71918e-02
I0208 15:58:21.953655 22542570456896 run_lib.py:133] step: 30750, training_loss: 3.00420e-02
I0208 15:58:39.390931 22542570456896 run_lib.py:133] step: 30800, training_loss: 3.15536e-02
I0208 15:58:39.543095 22542570456896 run_lib.py:146] step: 30800, eval_loss: 3.15065e-02
I0208 15:58:57.113422 22542570456896 run_lib.py:133] step: 30850, training_loss: 2.97973e-02
I0208 15:59:14.545617 22542570456896 run_lib.py:133] step: 30900, training_loss: 2.53820e-02
I0208 15:59:14.709349 22542570456896 run_lib.py:146] step: 30900, eval_loss: 3.65838e-02
I0208 15:59:32.243344 22542570456896 run_lib.py:133] step: 30950, training_loss: 3.38389e-02
I0208 15:59:49.723092 22542570456896 run_lib.py:133] step: 31000, training_loss: 2.68383e-02
I0208 15:59:49.900017 22542570456896 run_lib.py:146] step: 31000, eval_loss: 3.24275e-02
I0208 16:00:07.389787 22542570456896 run_lib.py:133] step: 31050, training_loss: 3.18028e-02
I0208 16:00:24.964326 22542570456896 run_lib.py:133] step: 31100, training_loss: 2.55865e-02
I0208 16:00:25.120457 22542570456896 run_lib.py:146] step: 31100, eval_loss: 3.15488e-02
I0208 16:00:42.542945 22542570456896 run_lib.py:133] step: 31150, training_loss: 2.21920e-02
I0208 16:00:59.994242 22542570456896 run_lib.py:133] step: 31200, training_loss: 2.70051e-02
I0208 16:01:00.148234 22542570456896 run_lib.py:146] step: 31200, eval_loss: 2.62016e-02
I0208 16:01:17.772827 22542570456896 run_lib.py:133] step: 31250, training_loss: 2.81847e-02
I0208 16:01:35.436617 22542570456896 run_lib.py:133] step: 31300, training_loss: 3.76280e-02
I0208 16:01:35.593464 22542570456896 run_lib.py:146] step: 31300, eval_loss: 2.74812e-02
I0208 16:01:53.028430 22542570456896 run_lib.py:133] step: 31350, training_loss: 2.98136e-02
I0208 16:02:10.463107 22542570456896 run_lib.py:133] step: 31400, training_loss: 3.40660e-02
I0208 16:02:10.615579 22542570456896 run_lib.py:146] step: 31400, eval_loss: 2.61180e-02
I0208 16:02:28.046247 22542570456896 run_lib.py:133] step: 31450, training_loss: 2.80192e-02
I0208 16:02:45.607055 22542570456896 run_lib.py:133] step: 31500, training_loss: 4.06449e-02
I0208 16:02:45.767357 22542570456896 run_lib.py:146] step: 31500, eval_loss: 2.60821e-02
I0208 16:03:03.203248 22542570456896 run_lib.py:133] step: 31550, training_loss: 2.22002e-02
I0208 16:03:20.675278 22542570456896 run_lib.py:133] step: 31600, training_loss: 2.83209e-02
I0208 16:03:20.832598 22542570456896 run_lib.py:146] step: 31600, eval_loss: 3.13783e-02
I0208 16:03:38.272849 22542570456896 run_lib.py:133] step: 31650, training_loss: 3.86373e-02
I0208 16:03:55.833278 22542570456896 run_lib.py:133] step: 31700, training_loss: 3.67990e-02
I0208 16:03:55.988296 22542570456896 run_lib.py:146] step: 31700, eval_loss: 3.15545e-02
I0208 16:04:13.407996 22542570456896 run_lib.py:133] step: 31750, training_loss: 3.22890e-02
I0208 16:04:30.933374 22542570456896 run_lib.py:133] step: 31800, training_loss: 3.15190e-02
I0208 16:04:31.089525 22542570456896 run_lib.py:146] step: 31800, eval_loss: 3.03668e-02
I0208 16:04:48.496529 22542570456896 run_lib.py:133] step: 31850, training_loss: 3.05993e-02
I0208 16:05:05.908691 22542570456896 run_lib.py:133] step: 31900, training_loss: 2.80356e-02
I0208 16:05:06.077831 22542570456896 run_lib.py:146] step: 31900, eval_loss: 3.01968e-02
I0208 16:05:23.812052 22542570456896 run_lib.py:133] step: 31950, training_loss: 2.51655e-02
I0208 16:05:41.268343 22542570456896 run_lib.py:133] step: 32000, training_loss: 3.39533e-02
I0208 16:05:41.435088 22542570456896 run_lib.py:146] step: 32000, eval_loss: 2.69654e-02
I0208 16:05:58.865404 22542570456896 run_lib.py:133] step: 32050, training_loss: 2.18431e-02
I0208 16:06:16.342502 22542570456896 run_lib.py:133] step: 32100, training_loss: 3.19435e-02
I0208 16:06:16.498414 22542570456896 run_lib.py:146] step: 32100, eval_loss: 2.95402e-02
I0208 16:06:34.138972 22542570456896 run_lib.py:133] step: 32150, training_loss: 3.27887e-02
I0208 16:06:51.559368 22542570456896 run_lib.py:133] step: 32200, training_loss: 3.23066e-02
I0208 16:06:51.715075 22542570456896 run_lib.py:146] step: 32200, eval_loss: 3.11115e-02
I0208 16:07:09.275649 22542570456896 run_lib.py:133] step: 32250, training_loss: 3.13788e-02
I0208 16:07:26.692881 22542570456896 run_lib.py:133] step: 32300, training_loss: 2.72891e-02
I0208 16:07:26.845547 22542570456896 run_lib.py:146] step: 32300, eval_loss: 4.07027e-02
I0208 16:07:44.448988 22542570456896 run_lib.py:133] step: 32350, training_loss: 3.66457e-02
I0208 16:08:01.926106 22542570456896 run_lib.py:133] step: 32400, training_loss: 2.55456e-02
I0208 16:08:02.085220 22542570456896 run_lib.py:146] step: 32400, eval_loss: 2.94043e-02
I0208 16:08:19.466991 22542570456896 run_lib.py:133] step: 32450, training_loss: 2.98899e-02
I0208 16:08:37.060307 22542570456896 run_lib.py:133] step: 32500, training_loss: 2.16527e-02
I0208 16:08:37.217441 22542570456896 run_lib.py:146] step: 32500, eval_loss: 2.83951e-02
I0208 16:08:54.623354 22542570456896 run_lib.py:133] step: 32550, training_loss: 2.77461e-02
I0208 16:09:12.240973 22542570456896 run_lib.py:133] step: 32600, training_loss: 2.87732e-02
I0208 16:09:12.400204 22542570456896 run_lib.py:146] step: 32600, eval_loss: 2.89496e-02
I0208 16:09:29.875762 22542570456896 run_lib.py:133] step: 32650, training_loss: 2.31998e-02
I0208 16:09:47.314744 22542570456896 run_lib.py:133] step: 32700, training_loss: 2.80020e-02
I0208 16:09:47.475378 22542570456896 run_lib.py:146] step: 32700, eval_loss: 3.58286e-02
I0208 16:10:05.047100 22542570456896 run_lib.py:133] step: 32750, training_loss: 3.25443e-02
I0208 16:10:22.489609 22542570456896 run_lib.py:133] step: 32800, training_loss: 2.90439e-02
I0208 16:10:22.646653 22542570456896 run_lib.py:146] step: 32800, eval_loss: 2.87022e-02
I0208 16:10:40.071143 22542570456896 run_lib.py:133] step: 32850, training_loss: 2.53804e-02
I0208 16:10:57.647525 22542570456896 run_lib.py:133] step: 32900, training_loss: 3.39702e-02
I0208 16:10:57.821388 22542570456896 run_lib.py:146] step: 32900, eval_loss: 2.99263e-02
I0208 16:11:15.271112 22542570456896 run_lib.py:133] step: 32950, training_loss: 3.41039e-02
I0208 16:11:32.719780 22542570456896 run_lib.py:133] step: 33000, training_loss: 2.57200e-02
I0208 16:11:32.876631 22542570456896 run_lib.py:146] step: 33000, eval_loss: 3.10776e-02
I0208 16:11:50.405102 22542570456896 run_lib.py:133] step: 33050, training_loss: 3.55991e-02
I0208 16:12:07.829420 22542570456896 run_lib.py:133] step: 33100, training_loss: 2.82597e-02
I0208 16:12:07.984348 22542570456896 run_lib.py:146] step: 33100, eval_loss: 3.36682e-02
I0208 16:12:25.401561 22542570456896 run_lib.py:133] step: 33150, training_loss: 2.46755e-02
I0208 16:12:42.919434 22542570456896 run_lib.py:133] step: 33200, training_loss: 2.31147e-02
I0208 16:12:43.083226 22542570456896 run_lib.py:146] step: 33200, eval_loss: 3.16186e-02
I0208 16:13:00.763269 22542570456896 run_lib.py:133] step: 33250, training_loss: 4.02798e-02
I0208 16:13:18.281602 22542570456896 run_lib.py:133] step: 33300, training_loss: 2.94270e-02
I0208 16:13:18.440084 22542570456896 run_lib.py:146] step: 33300, eval_loss: 3.32293e-02
I0208 16:13:35.963616 22542570456896 run_lib.py:133] step: 33350, training_loss: 2.69882e-02
I0208 16:13:53.373895 22542570456896 run_lib.py:133] step: 33400, training_loss: 2.80346e-02
I0208 16:13:53.544348 22542570456896 run_lib.py:146] step: 33400, eval_loss: 3.18169e-02
I0208 16:14:11.222057 22542570456896 run_lib.py:133] step: 33450, training_loss: 3.02148e-02
I0208 16:14:28.636515 22542570456896 run_lib.py:133] step: 33500, training_loss: 3.18774e-02
I0208 16:14:28.793525 22542570456896 run_lib.py:146] step: 33500, eval_loss: 3.47729e-02
I0208 16:14:46.422998 22542570456896 run_lib.py:133] step: 33550, training_loss: 2.77405e-02
I0208 16:15:03.891064 22542570456896 run_lib.py:133] step: 33600, training_loss: 3.18676e-02
I0208 16:15:04.047347 22542570456896 run_lib.py:146] step: 33600, eval_loss: 2.65525e-02
I0208 16:15:21.581227 22542570456896 run_lib.py:133] step: 33650, training_loss: 3.89311e-02
I0208 16:15:39.085012 22542570456896 run_lib.py:133] step: 33700, training_loss: 2.46809e-02
I0208 16:15:39.240628 22542570456896 run_lib.py:146] step: 33700, eval_loss: 3.19422e-02
I0208 16:15:56.901383 22542570456896 run_lib.py:133] step: 33750, training_loss: 2.36064e-02
I0208 16:16:14.305170 22542570456896 run_lib.py:133] step: 33800, training_loss: 1.88582e-02
I0208 16:16:14.472051 22542570456896 run_lib.py:146] step: 33800, eval_loss: 2.83224e-02
I0208 16:16:31.892186 22542570456896 run_lib.py:133] step: 33850, training_loss: 3.20373e-02
I0208 16:16:49.439507 22542570456896 run_lib.py:133] step: 33900, training_loss: 3.04224e-02
I0208 16:16:49.595391 22542570456896 run_lib.py:146] step: 33900, eval_loss: 3.05668e-02
I0208 16:17:07.063930 22542570456896 run_lib.py:133] step: 33950, training_loss: 3.52502e-02
I0208 16:17:24.535673 22542570456896 run_lib.py:133] step: 34000, training_loss: 3.12602e-02
I0208 16:17:24.700725 22542570456896 run_lib.py:146] step: 34000, eval_loss: 3.45233e-02
I0208 16:17:42.340585 22542570456896 run_lib.py:133] step: 34050, training_loss: 2.97324e-02
I0208 16:17:59.755238 22542570456896 run_lib.py:133] step: 34100, training_loss: 3.00930e-02
I0208 16:17:59.913525 22542570456896 run_lib.py:146] step: 34100, eval_loss: 2.26070e-02
I0208 16:18:17.479418 22542570456896 run_lib.py:133] step: 34150, training_loss: 2.73851e-02
I0208 16:18:34.904406 22542570456896 run_lib.py:133] step: 34200, training_loss: 3.17385e-02
I0208 16:18:35.066496 22542570456896 run_lib.py:146] step: 34200, eval_loss: 2.74246e-02
I0208 16:18:52.544998 22542570456896 run_lib.py:133] step: 34250, training_loss: 3.28441e-02
I0208 16:19:10.138242 22542570456896 run_lib.py:133] step: 34300, training_loss: 3.47814e-02
I0208 16:19:10.303263 22542570456896 run_lib.py:146] step: 34300, eval_loss: 2.71983e-02
I0208 16:19:27.725840 22542570456896 run_lib.py:133] step: 34350, training_loss: 2.68201e-02
I0208 16:19:45.114259 22542570456896 run_lib.py:133] step: 34400, training_loss: 2.43146e-02
I0208 16:19:45.278211 22542570456896 run_lib.py:146] step: 34400, eval_loss: 3.07703e-02
I0208 16:20:02.709569 22542570456896 run_lib.py:133] step: 34450, training_loss: 2.77821e-02
I0208 16:20:20.280740 22542570456896 run_lib.py:133] step: 34500, training_loss: 2.96053e-02
I0208 16:20:20.438303 22542570456896 run_lib.py:146] step: 34500, eval_loss: 3.15290e-02
I0208 16:20:37.921934 22542570456896 run_lib.py:133] step: 34550, training_loss: 2.56486e-02
I0208 16:20:55.449046 22542570456896 run_lib.py:133] step: 34600, training_loss: 2.84427e-02
I0208 16:20:55.602066 22542570456896 run_lib.py:146] step: 34600, eval_loss: 3.43034e-02
I0208 16:21:13.033667 22542570456896 run_lib.py:133] step: 34650, training_loss: 4.03888e-02
I0208 16:21:30.445043 22542570456896 run_lib.py:133] step: 34700, training_loss: 3.29944e-02
I0208 16:21:30.601157 22542570456896 run_lib.py:146] step: 34700, eval_loss: 2.84120e-02
I0208 16:21:48.160177 22542570456896 run_lib.py:133] step: 34750, training_loss: 2.71703e-02
I0208 16:22:05.646664 22542570456896 run_lib.py:133] step: 34800, training_loss: 3.12255e-02
I0208 16:22:05.829439 22542570456896 run_lib.py:146] step: 34800, eval_loss: 2.88664e-02
I0208 16:22:23.271340 22542570456896 run_lib.py:133] step: 34850, training_loss: 3.02920e-02
I0208 16:22:40.723934 22542570456896 run_lib.py:133] step: 34900, training_loss: 2.68384e-02
I0208 16:22:40.880542 22542570456896 run_lib.py:146] step: 34900, eval_loss: 2.69233e-02
I0208 16:22:58.476676 22542570456896 run_lib.py:133] step: 34950, training_loss: 2.78817e-02
I0208 16:23:15.896564 22542570456896 run_lib.py:133] step: 35000, training_loss: 2.45968e-02
I0208 16:23:16.058388 22542570456896 run_lib.py:146] step: 35000, eval_loss: 2.33609e-02
I0208 16:23:33.648923 22542570456896 run_lib.py:133] step: 35050, training_loss: 2.83426e-02
I0208 16:23:51.113559 22542570456896 run_lib.py:133] step: 35100, training_loss: 2.78430e-02
I0208 16:23:51.268539 22542570456896 run_lib.py:146] step: 35100, eval_loss: 2.89564e-02
I0208 16:24:09.036950 22542570456896 run_lib.py:133] step: 35150, training_loss: 3.85954e-02
I0208 16:24:26.423041 22542570456896 run_lib.py:133] step: 35200, training_loss: 2.58806e-02
I0208 16:24:26.586141 22542570456896 run_lib.py:146] step: 35200, eval_loss: 3.37912e-02
I0208 16:24:43.978068 22542570456896 run_lib.py:133] step: 35250, training_loss: 3.61131e-02
I0208 16:25:01.560308 22542570456896 run_lib.py:133] step: 35300, training_loss: 2.55628e-02
I0208 16:25:01.718501 22542570456896 run_lib.py:146] step: 35300, eval_loss: 3.09666e-02
I0208 16:25:19.159715 22542570456896 run_lib.py:133] step: 35350, training_loss: 2.69287e-02
I0208 16:25:36.761675 22542570456896 run_lib.py:133] step: 35400, training_loss: 3.15709e-02
I0208 16:25:36.919093 22542570456896 run_lib.py:146] step: 35400, eval_loss: 3.04502e-02
I0208 16:25:54.420347 22542570456896 run_lib.py:133] step: 35450, training_loss: 2.61565e-02
I0208 16:26:11.848973 22542570456896 run_lib.py:133] step: 35500, training_loss: 2.94617e-02
I0208 16:26:12.012347 22542570456896 run_lib.py:146] step: 35500, eval_loss: 2.72353e-02
I0208 16:26:29.629169 22542570456896 run_lib.py:133] step: 35550, training_loss: 3.15015e-02
I0208 16:26:47.067112 22542570456896 run_lib.py:133] step: 35600, training_loss: 3.17842e-02
I0208 16:26:47.220429 22542570456896 run_lib.py:146] step: 35600, eval_loss: 3.05059e-02
I0208 16:27:04.684100 22542570456896 run_lib.py:133] step: 35650, training_loss: 2.78765e-02
I0208 16:27:22.285778 22542570456896 run_lib.py:133] step: 35700, training_loss: 3.17688e-02
I0208 16:27:22.446292 22542570456896 run_lib.py:146] step: 35700, eval_loss: 2.67462e-02
I0208 16:27:39.837220 22542570456896 run_lib.py:133] step: 35750, training_loss: 3.03490e-02
I0208 16:27:57.166247 22542570456896 run_lib.py:133] step: 35800, training_loss: 3.03251e-02
I0208 16:27:57.476161 22542570456896 run_lib.py:146] step: 35800, eval_loss: 3.25878e-02
I0208 16:28:14.804249 22542570456896 run_lib.py:133] step: 35850, training_loss: 3.75311e-02
I0208 16:28:32.206810 22542570456896 run_lib.py:133] step: 35900, training_loss: 3.24303e-02
I0208 16:28:32.363404 22542570456896 run_lib.py:146] step: 35900, eval_loss: 4.09873e-02
I0208 16:28:49.820829 22542570456896 run_lib.py:133] step: 35950, training_loss: 2.74300e-02
I0208 16:29:07.277395 22542570456896 run_lib.py:133] step: 36000, training_loss: 2.63936e-02
I0208 16:29:07.433142 22542570456896 run_lib.py:146] step: 36000, eval_loss: 2.93819e-02
I0208 16:29:25.082690 22542570456896 run_lib.py:133] step: 36050, training_loss: 3.29103e-02
I0208 16:29:42.619134 22542570456896 run_lib.py:133] step: 36100, training_loss: 2.84069e-02
I0208 16:29:42.774393 22542570456896 run_lib.py:146] step: 36100, eval_loss: 3.31621e-02
I0208 16:30:00.177641 22542570456896 run_lib.py:133] step: 36150, training_loss: 3.14998e-02
I0208 16:30:17.611908 22542570456896 run_lib.py:133] step: 36200, training_loss: 2.94461e-02
I0208 16:30:17.789322 22542570456896 run_lib.py:146] step: 36200, eval_loss: 3.30395e-02
I0208 16:30:35.434487 22542570456896 run_lib.py:133] step: 36250, training_loss: 2.67166e-02
I0208 16:30:52.990967 22542570456896 run_lib.py:133] step: 36300, training_loss: 2.67772e-02
I0208 16:30:53.149660 22542570456896 run_lib.py:146] step: 36300, eval_loss: 2.61815e-02
I0208 16:31:10.564549 22542570456896 run_lib.py:133] step: 36350, training_loss: 2.16845e-02
I0208 16:31:27.961660 22542570456896 run_lib.py:133] step: 36400, training_loss: 2.56429e-02
I0208 16:31:28.118627 22542570456896 run_lib.py:146] step: 36400, eval_loss: 2.55874e-02
I0208 16:31:45.735309 22542570456896 run_lib.py:133] step: 36450, training_loss: 2.52538e-02
I0208 16:32:03.256220 22542570456896 run_lib.py:133] step: 36500, training_loss: 2.74602e-02
I0208 16:32:03.418632 22542570456896 run_lib.py:146] step: 36500, eval_loss: 3.16839e-02
I0208 16:32:21.060078 22542570456896 run_lib.py:133] step: 36550, training_loss: 3.19846e-02
I0208 16:32:38.492347 22542570456896 run_lib.py:133] step: 36600, training_loss: 2.65042e-02
I0208 16:32:38.650298 22542570456896 run_lib.py:146] step: 36600, eval_loss: 3.10590e-02
I0208 16:32:56.221560 22542570456896 run_lib.py:133] step: 36650, training_loss: 3.00238e-02
I0208 16:33:13.664719 22542570456896 run_lib.py:133] step: 36700, training_loss: 3.37521e-02
I0208 16:33:13.833567 22542570456896 run_lib.py:146] step: 36700, eval_loss: 2.80549e-02
I0208 16:33:31.325002 22542570456896 run_lib.py:133] step: 36750, training_loss: 2.66333e-02
I0208 16:33:48.996488 22542570456896 run_lib.py:133] step: 36800, training_loss: 3.24082e-02
I0208 16:33:49.153461 22542570456896 run_lib.py:146] step: 36800, eval_loss: 2.87573e-02
I0208 16:34:06.578042 22542570456896 run_lib.py:133] step: 36850, training_loss: 2.62615e-02
I0208 16:34:24.166184 22542570456896 run_lib.py:133] step: 36900, training_loss: 3.10290e-02
I0208 16:34:24.323410 22542570456896 run_lib.py:146] step: 36900, eval_loss: 2.64751e-02
I0208 16:34:41.781663 22542570456896 run_lib.py:133] step: 36950, training_loss: 2.88766e-02
I0208 16:34:59.226670 22542570456896 run_lib.py:133] step: 37000, training_loss: 3.41818e-02
I0208 16:34:59.388528 22542570456896 run_lib.py:146] step: 37000, eval_loss: 3.07184e-02
I0208 16:35:17.077200 22542570456896 run_lib.py:133] step: 37050, training_loss: 3.51473e-02
I0208 16:35:34.532232 22542570456896 run_lib.py:133] step: 37100, training_loss: 3.30061e-02
I0208 16:35:34.689204 22542570456896 run_lib.py:146] step: 37100, eval_loss: 3.13581e-02
I0208 16:35:52.126556 22542570456896 run_lib.py:133] step: 37150, training_loss: 3.01707e-02
I0208 16:36:09.562406 22542570456896 run_lib.py:133] step: 37200, training_loss: 3.10642e-02
I0208 16:36:09.721655 22542570456896 run_lib.py:146] step: 37200, eval_loss: 3.10076e-02
I0208 16:36:27.341139 22542570456896 run_lib.py:133] step: 37250, training_loss: 3.10071e-02
I0208 16:36:44.892012 22542570456896 run_lib.py:133] step: 37300, training_loss: 2.45986e-02
I0208 16:36:45.049784 22542570456896 run_lib.py:146] step: 37300, eval_loss: 2.66389e-02
I0208 16:37:02.550286 22542570456896 run_lib.py:133] step: 37350, training_loss: 2.88821e-02
I0208 16:37:19.942745 22542570456896 run_lib.py:133] step: 37400, training_loss: 3.09645e-02
I0208 16:37:20.098300 22542570456896 run_lib.py:146] step: 37400, eval_loss: 2.89265e-02
I0208 16:37:37.523895 22542570456896 run_lib.py:133] step: 37450, training_loss: 2.43474e-02
I0208 16:37:54.978775 22542570456896 run_lib.py:133] step: 37500, training_loss: 3.57877e-02
I0208 16:37:55.135573 22542570456896 run_lib.py:146] step: 37500, eval_loss: 2.72256e-02
I0208 16:38:12.760110 22542570456896 run_lib.py:133] step: 37550, training_loss: 2.46660e-02
I0208 16:38:30.363881 22542570456896 run_lib.py:133] step: 37600, training_loss: 2.66112e-02
I0208 16:38:30.523324 22542570456896 run_lib.py:146] step: 37600, eval_loss: 2.80321e-02
I0208 16:38:47.965034 22542570456896 run_lib.py:133] step: 37650, training_loss: 2.79146e-02
I0208 16:39:05.385734 22542570456896 run_lib.py:133] step: 37700, training_loss: 2.86851e-02
I0208 16:39:05.544355 22542570456896 run_lib.py:146] step: 37700, eval_loss: 2.71915e-02
I0208 16:39:23.096288 22542570456896 run_lib.py:133] step: 37750, training_loss: 2.76004e-02
I0208 16:39:40.523864 22542570456896 run_lib.py:133] step: 37800, training_loss: 2.79942e-02
I0208 16:39:40.701965 22542570456896 run_lib.py:146] step: 37800, eval_loss: 2.30249e-02
I0208 16:39:58.322495 22542570456896 run_lib.py:133] step: 37850, training_loss: 3.03159e-02
I0208 16:40:15.752696 22542570456896 run_lib.py:133] step: 37900, training_loss: 2.75448e-02
I0208 16:40:15.911059 22542570456896 run_lib.py:146] step: 37900, eval_loss: 2.60213e-02
I0208 16:40:33.548581 22542570456896 run_lib.py:133] step: 37950, training_loss: 2.48004e-02
I0208 16:40:51.024707 22542570456896 run_lib.py:133] step: 38000, training_loss: 3.27516e-02
I0208 16:40:51.181348 22542570456896 run_lib.py:146] step: 38000, eval_loss: 2.96892e-02
I0208 16:41:08.753864 22542570456896 run_lib.py:133] step: 38050, training_loss: 3.07657e-02
I0208 16:41:26.173165 22542570456896 run_lib.py:133] step: 38100, training_loss: 2.54381e-02
I0208 16:41:26.332416 22542570456896 run_lib.py:146] step: 38100, eval_loss: 3.20838e-02
I0208 16:41:43.812755 22542570456896 run_lib.py:133] step: 38150, training_loss: 2.99205e-02
I0208 16:42:01.468004 22542570456896 run_lib.py:133] step: 38200, training_loss: 2.90476e-02
I0208 16:42:01.624583 22542570456896 run_lib.py:146] step: 38200, eval_loss: 2.64098e-02
I0208 16:42:19.029485 22542570456896 run_lib.py:133] step: 38250, training_loss: 3.69070e-02
I0208 16:42:36.421048 22542570456896 run_lib.py:133] step: 38300, training_loss: 2.50562e-02
I0208 16:42:36.577298 22542570456896 run_lib.py:146] step: 38300, eval_loss: 2.87401e-02
I0208 16:42:54.320781 22542570456896 run_lib.py:133] step: 38350, training_loss: 2.97515e-02
I0208 16:43:11.931005 22542570456896 run_lib.py:133] step: 38400, training_loss: 2.60726e-02
I0208 16:43:12.086491 22542570456896 run_lib.py:146] step: 38400, eval_loss: 3.39093e-02
I0208 16:43:29.553199 22542570456896 run_lib.py:133] step: 38450, training_loss: 3.35146e-02
I0208 16:43:46.953607 22542570456896 run_lib.py:133] step: 38500, training_loss: 3.16404e-02
I0208 16:43:47.110278 22542570456896 run_lib.py:146] step: 38500, eval_loss: 3.32581e-02
I0208 16:44:04.568000 22542570456896 run_lib.py:133] step: 38550, training_loss: 3.01536e-02
I0208 16:44:22.187649 22542570456896 run_lib.py:133] step: 38600, training_loss: 2.59673e-02
I0208 16:44:22.353678 22542570456896 run_lib.py:146] step: 38600, eval_loss: 2.80748e-02
I0208 16:44:39.805282 22542570456896 run_lib.py:133] step: 38650, training_loss: 2.87183e-02
I0208 16:44:57.266003 22542570456896 run_lib.py:133] step: 38700, training_loss: 3.38170e-02
I0208 16:44:57.426515 22542570456896 run_lib.py:146] step: 38700, eval_loss: 3.18936e-02
I0208 16:45:14.877817 22542570456896 run_lib.py:133] step: 38750, training_loss: 3.38319e-02
I0208 16:45:32.461354 22542570456896 run_lib.py:133] step: 38800, training_loss: 3.48308e-02
I0208 16:45:32.624971 22542570456896 run_lib.py:146] step: 38800, eval_loss: 3.25973e-02
I0208 16:45:50.037881 22542570456896 run_lib.py:133] step: 38850, training_loss: 2.77008e-02
I0208 16:46:07.534705 22542570456896 run_lib.py:133] step: 38900, training_loss: 2.86894e-02
I0208 16:46:07.689041 22542570456896 run_lib.py:146] step: 38900, eval_loss: 2.59260e-02
I0208 16:46:25.122026 22542570456896 run_lib.py:133] step: 38950, training_loss: 3.11588e-02
I0208 16:46:42.600297 22542570456896 run_lib.py:133] step: 39000, training_loss: 2.81229e-02
I0208 16:46:42.758173 22542570456896 run_lib.py:146] step: 39000, eval_loss: 2.64046e-02
I0208 16:47:00.371358 22542570456896 run_lib.py:133] step: 39050, training_loss: 3.16139e-02
I0208 16:47:17.878049 22542570456896 run_lib.py:133] step: 39100, training_loss: 2.96719e-02
I0208 16:47:18.043569 22542570456896 run_lib.py:146] step: 39100, eval_loss: 2.35598e-02
I0208 16:47:35.449219 22542570456896 run_lib.py:133] step: 39150, training_loss: 3.06643e-02
I0208 16:47:52.911768 22542570456896 run_lib.py:133] step: 39200, training_loss: 2.66350e-02
I0208 16:47:53.081026 22542570456896 run_lib.py:146] step: 39200, eval_loss: 2.69172e-02
I0208 16:48:10.755443 22542570456896 run_lib.py:133] step: 39250, training_loss: 2.88615e-02
I0208 16:48:28.159814 22542570456896 run_lib.py:133] step: 39300, training_loss: 3.10612e-02
I0208 16:48:28.321573 22542570456896 run_lib.py:146] step: 39300, eval_loss: 3.22122e-02
I0208 16:48:45.903346 22542570456896 run_lib.py:133] step: 39350, training_loss: 3.10476e-02
I0208 16:49:03.334398 22542570456896 run_lib.py:133] step: 39400, training_loss: 3.35001e-02
I0208 16:49:03.487435 22542570456896 run_lib.py:146] step: 39400, eval_loss: 2.60113e-02
I0208 16:49:21.056302 22542570456896 run_lib.py:133] step: 39450, training_loss: 2.56153e-02
I0208 16:49:38.504991 22542570456896 run_lib.py:133] step: 39500, training_loss: 2.95088e-02
I0208 16:49:38.682051 22542570456896 run_lib.py:146] step: 39500, eval_loss: 3.72024e-02
I0208 16:49:56.118844 22542570456896 run_lib.py:133] step: 39550, training_loss: 3.44678e-02
I0208 16:50:13.764827 22542570456896 run_lib.py:133] step: 39600, training_loss: 2.47818e-02
I0208 16:50:13.921569 22542570456896 run_lib.py:146] step: 39600, eval_loss: 2.41903e-02
I0208 16:50:31.397620 22542570456896 run_lib.py:133] step: 39650, training_loss: 3.59333e-02
I0208 16:50:48.964070 22542570456896 run_lib.py:133] step: 39700, training_loss: 3.55800e-02
I0208 16:50:49.118974 22542570456896 run_lib.py:146] step: 39700, eval_loss: 2.99552e-02
I0208 16:51:06.574047 22542570456896 run_lib.py:133] step: 39750, training_loss: 3.28545e-02
I0208 16:51:24.068078 22542570456896 run_lib.py:133] step: 39800, training_loss: 4.17244e-02
I0208 16:51:24.220074 22542570456896 run_lib.py:146] step: 39800, eval_loss: 2.48882e-02
I0208 16:51:41.852120 22542570456896 run_lib.py:133] step: 39850, training_loss: 3.27208e-02
I0208 16:51:59.283057 22542570456896 run_lib.py:133] step: 39900, training_loss: 2.71183e-02
I0208 16:51:59.439276 22542570456896 run_lib.py:146] step: 39900, eval_loss: 2.75771e-02
I0208 16:52:16.959222 22542570456896 run_lib.py:133] step: 39950, training_loss: 3.31806e-02
I0208 16:52:34.599280 22542570456896 run_lib.py:133] step: 40000, training_loss: 2.50828e-02
I0208 16:52:35.310563 22542570456896 run_lib.py:146] step: 40000, eval_loss: 2.57641e-02
I0208 16:52:55.446505 22542570456896 run_lib.py:133] step: 40050, training_loss: 4.19919e-02
I0208 16:53:12.870160 22542570456896 run_lib.py:133] step: 40100, training_loss: 2.38204e-02
I0208 16:53:13.029366 22542570456896 run_lib.py:146] step: 40100, eval_loss: 2.72055e-02
I0208 16:53:30.428514 22542570456896 run_lib.py:133] step: 40150, training_loss: 2.97810e-02
I0208 16:53:48.053797 22542570456896 run_lib.py:133] step: 40200, training_loss: 2.41753e-02
I0208 16:53:48.211287 22542570456896 run_lib.py:146] step: 40200, eval_loss: 3.00656e-02
I0208 16:54:05.653800 22542570456896 run_lib.py:133] step: 40250, training_loss: 3.18942e-02
I0208 16:54:23.157491 22542570456896 run_lib.py:133] step: 40300, training_loss: 2.98507e-02
I0208 16:54:23.320612 22542570456896 run_lib.py:146] step: 40300, eval_loss: 2.39418e-02
I0208 16:54:40.965727 22542570456896 run_lib.py:133] step: 40350, training_loss: 3.46053e-02
I0208 16:54:58.400089 22542570456896 run_lib.py:133] step: 40400, training_loss: 2.40869e-02
I0208 16:54:58.560306 22542570456896 run_lib.py:146] step: 40400, eval_loss: 2.88435e-02
I0208 16:55:16.023101 22542570456896 run_lib.py:133] step: 40450, training_loss: 3.19074e-02
I0208 16:55:33.484706 22542570456896 run_lib.py:133] step: 40500, training_loss: 2.48695e-02
I0208 16:55:33.643470 22542570456896 run_lib.py:146] step: 40500, eval_loss: 2.66782e-02
I0208 16:55:51.043853 22542570456896 run_lib.py:133] step: 40550, training_loss: 2.34221e-02
I0208 16:56:08.556847 22542570456896 run_lib.py:133] step: 40600, training_loss: 3.03133e-02
I0208 16:56:08.714474 22542570456896 run_lib.py:146] step: 40600, eval_loss: 3.24106e-02
I0208 16:56:26.322657 22542570456896 run_lib.py:133] step: 40650, training_loss: 2.60614e-02
I0208 16:56:43.817783 22542570456896 run_lib.py:133] step: 40700, training_loss: 3.04038e-02
I0208 16:56:43.975473 22542570456896 run_lib.py:146] step: 40700, eval_loss: 2.87890e-02
I0208 16:57:01.412226 22542570456896 run_lib.py:133] step: 40750, training_loss: 2.43040e-02
I0208 16:57:18.844310 22542570456896 run_lib.py:133] step: 40800, training_loss: 2.89797e-02
I0208 16:57:18.998553 22542570456896 run_lib.py:146] step: 40800, eval_loss: 2.74675e-02
I0208 16:57:36.660179 22542570456896 run_lib.py:133] step: 40850, training_loss: 3.27027e-02
I0208 16:57:54.143747 22542570456896 run_lib.py:133] step: 40900, training_loss: 2.63565e-02
I0208 16:57:54.299220 22542570456896 run_lib.py:146] step: 40900, eval_loss: 3.03629e-02
I0208 16:58:11.892245 22542570456896 run_lib.py:133] step: 40950, training_loss: 3.04783e-02
I0208 16:58:29.312394 22542570456896 run_lib.py:133] step: 41000, training_loss: 3.16707e-02
I0208 16:58:29.471597 22542570456896 run_lib.py:146] step: 41000, eval_loss: 2.66662e-02
I0208 16:58:47.049458 22542570456896 run_lib.py:133] step: 41050, training_loss: 2.85159e-02
I0208 16:59:04.477304 22542570456896 run_lib.py:133] step: 41100, training_loss: 3.31153e-02
I0208 16:59:04.647631 22542570456896 run_lib.py:146] step: 41100, eval_loss: 2.89071e-02
I0208 16:59:22.297124 22542570456896 run_lib.py:133] step: 41150, training_loss: 3.18463e-02
I0208 16:59:39.771406 22542570456896 run_lib.py:133] step: 41200, training_loss: 2.99476e-02
I0208 16:59:39.934104 22542570456896 run_lib.py:146] step: 41200, eval_loss: 3.17113e-02
I0208 16:59:57.356095 22542570456896 run_lib.py:133] step: 41250, training_loss: 2.75518e-02
I0208 17:00:14.903420 22542570456896 run_lib.py:133] step: 41300, training_loss: 2.75938e-02
I0208 17:00:15.062369 22542570456896 run_lib.py:146] step: 41300, eval_loss: 1.90765e-02
I0208 17:00:32.518205 22542570456896 run_lib.py:133] step: 41350, training_loss: 2.91506e-02
I0208 17:00:50.052546 22542570456896 run_lib.py:133] step: 41400, training_loss: 2.70594e-02
I0208 17:00:50.221409 22542570456896 run_lib.py:146] step: 41400, eval_loss: 3.09854e-02
I0208 17:01:07.863467 22542570456896 run_lib.py:133] step: 41450, training_loss: 3.59155e-02
I0208 17:01:25.283275 22542570456896 run_lib.py:133] step: 41500, training_loss: 2.50014e-02
I0208 17:01:25.444111 22542570456896 run_lib.py:146] step: 41500, eval_loss: 3.02400e-02
I0208 17:01:43.016997 22542570456896 run_lib.py:133] step: 41550, training_loss: 3.81668e-02
I0208 17:02:00.479963 22542570456896 run_lib.py:133] step: 41600, training_loss: 2.89392e-02
I0208 17:02:00.636247 22542570456896 run_lib.py:146] step: 41600, eval_loss: 3.38809e-02
I0208 17:02:18.112121 22542570456896 run_lib.py:133] step: 41650, training_loss: 3.65171e-02
I0208 17:02:35.760199 22542570456896 run_lib.py:133] step: 41700, training_loss: 3.47014e-02
I0208 17:02:35.918370 22542570456896 run_lib.py:146] step: 41700, eval_loss: 2.56765e-02
I0208 17:02:53.323478 22542570456896 run_lib.py:133] step: 41750, training_loss: 2.84710e-02
I0208 17:03:10.814797 22542570456896 run_lib.py:133] step: 41800, training_loss: 3.06120e-02
I0208 17:03:10.968282 22542570456896 run_lib.py:146] step: 41800, eval_loss: 2.58227e-02
I0208 17:03:28.397867 22542570456896 run_lib.py:133] step: 41850, training_loss: 3.11207e-02
I0208 17:03:45.980497 22542570456896 run_lib.py:133] step: 41900, training_loss: 2.55223e-02
I0208 17:03:46.147549 22542570456896 run_lib.py:146] step: 41900, eval_loss: 2.81813e-02
I0208 17:04:03.663670 22542570456896 run_lib.py:133] step: 41950, training_loss: 2.83861e-02
I0208 17:04:21.199325 22542570456896 run_lib.py:133] step: 42000, training_loss: 3.11207e-02
I0208 17:04:21.359288 22542570456896 run_lib.py:146] step: 42000, eval_loss: 3.76166e-02
I0208 17:04:38.773495 22542570456896 run_lib.py:133] step: 42050, training_loss: 2.84126e-02
I0208 17:04:56.211451 22542570456896 run_lib.py:133] step: 42100, training_loss: 2.63985e-02
I0208 17:04:56.370303 22542570456896 run_lib.py:146] step: 42100, eval_loss: 2.63633e-02
I0208 17:05:13.956011 22542570456896 run_lib.py:133] step: 42150, training_loss: 3.25384e-02
I0208 17:05:31.462954 22542570456896 run_lib.py:133] step: 42200, training_loss: 3.51325e-02
I0208 17:05:31.619983 22542570456896 run_lib.py:146] step: 42200, eval_loss: 2.71192e-02
I0208 17:05:49.090638 22542570456896 run_lib.py:133] step: 42250, training_loss: 2.98656e-02
I0208 17:06:06.502413 22542570456896 run_lib.py:133] step: 42300, training_loss: 2.94317e-02
I0208 17:06:06.654270 22542570456896 run_lib.py:146] step: 42300, eval_loss: 3.36016e-02
I0208 17:06:24.263322 22542570456896 run_lib.py:133] step: 42350, training_loss: 2.57821e-02
I0208 17:06:41.701551 22542570456896 run_lib.py:133] step: 42400, training_loss: 2.54708e-02
I0208 17:06:41.867146 22542570456896 run_lib.py:146] step: 42400, eval_loss: 2.82117e-02
I0208 17:06:59.417951 22542570456896 run_lib.py:133] step: 42450, training_loss: 2.99743e-02
I0208 17:07:16.858161 22542570456896 run_lib.py:133] step: 42500, training_loss: 2.74961e-02
I0208 17:07:17.039321 22542570456896 run_lib.py:146] step: 42500, eval_loss: 3.00989e-02
I0208 17:07:34.716150 22542570456896 run_lib.py:133] step: 42550, training_loss: 4.31569e-02
I0208 17:07:52.113448 22542570456896 run_lib.py:133] step: 42600, training_loss: 3.55114e-02
I0208 17:07:52.271776 22542570456896 run_lib.py:146] step: 42600, eval_loss: 3.26144e-02
I0208 17:08:09.707666 22542570456896 run_lib.py:133] step: 42650, training_loss: 2.81322e-02
I0208 17:08:27.261688 22542570456896 run_lib.py:133] step: 42700, training_loss: 2.43674e-02
I0208 17:08:27.413061 22542570456896 run_lib.py:146] step: 42700, eval_loss: 3.18016e-02
I0208 17:08:44.836642 22542570456896 run_lib.py:133] step: 42750, training_loss: 3.45147e-02
I0208 17:09:02.439785 22542570456896 run_lib.py:133] step: 42800, training_loss: 2.96813e-02
I0208 17:09:02.596618 22542570456896 run_lib.py:146] step: 42800, eval_loss: 3.09458e-02
I0208 17:09:20.032652 22542570456896 run_lib.py:133] step: 42850, training_loss: 3.24663e-02
I0208 17:09:37.462620 22542570456896 run_lib.py:133] step: 42900, training_loss: 2.75903e-02
I0208 17:09:37.621433 22542570456896 run_lib.py:146] step: 42900, eval_loss: 2.99566e-02
I0208 17:09:55.218096 22542570456896 run_lib.py:133] step: 42950, training_loss: 4.04319e-02
I0208 17:10:12.621772 22542570456896 run_lib.py:133] step: 43000, training_loss: 3.13511e-02
I0208 17:10:12.783399 22542570456896 run_lib.py:146] step: 43000, eval_loss: 2.98760e-02
I0208 17:10:30.214667 22542570456896 run_lib.py:133] step: 43050, training_loss: 2.62131e-02
I0208 17:10:47.838683 22542570456896 run_lib.py:133] step: 43100, training_loss: 3.32727e-02
I0208 17:10:47.997060 22542570456896 run_lib.py:146] step: 43100, eval_loss: 2.59190e-02
I0208 17:11:05.489740 22542570456896 run_lib.py:133] step: 43150, training_loss: 3.47019e-02
I0208 17:11:22.901072 22542570456896 run_lib.py:133] step: 43200, training_loss: 3.14023e-02
I0208 17:11:23.240273 22542570456896 run_lib.py:146] step: 43200, eval_loss: 2.94028e-02
I0208 17:11:40.642307 22542570456896 run_lib.py:133] step: 43250, training_loss: 3.77603e-02
I0208 17:11:58.095144 22542570456896 run_lib.py:133] step: 43300, training_loss: 3.61964e-02
I0208 17:11:58.249383 22542570456896 run_lib.py:146] step: 43300, eval_loss: 2.96445e-02
I0208 17:12:15.711454 22542570456896 run_lib.py:133] step: 43350, training_loss: 2.78316e-02
I0208 17:12:33.177862 22542570456896 run_lib.py:133] step: 43400, training_loss: 2.41855e-02
I0208 17:12:33.341994 22542570456896 run_lib.py:146] step: 43400, eval_loss: 2.64083e-02
I0208 17:12:50.964186 22542570456896 run_lib.py:133] step: 43450, training_loss: 3.28763e-02
I0208 17:13:08.448246 22542570456896 run_lib.py:133] step: 43500, training_loss: 3.03320e-02
I0208 17:13:08.603322 22542570456896 run_lib.py:146] step: 43500, eval_loss: 2.90155e-02
I0208 17:13:26.076036 22542570456896 run_lib.py:133] step: 43550, training_loss: 3.85944e-02
I0208 17:13:43.543791 22542570456896 run_lib.py:133] step: 43600, training_loss: 2.95241e-02
I0208 17:13:43.703344 22542570456896 run_lib.py:146] step: 43600, eval_loss: 2.87446e-02
I0208 17:14:01.303110 22542570456896 run_lib.py:133] step: 43650, training_loss: 2.70367e-02
I0208 17:14:18.860690 22542570456896 run_lib.py:133] step: 43700, training_loss: 2.44585e-02
I0208 17:14:19.012645 22542570456896 run_lib.py:146] step: 43700, eval_loss: 3.38043e-02
I0208 17:14:36.486046 22542570456896 run_lib.py:133] step: 43750, training_loss: 2.80832e-02
I0208 17:14:53.913547 22542570456896 run_lib.py:133] step: 43800, training_loss: 3.33671e-02
I0208 17:14:54.068329 22542570456896 run_lib.py:146] step: 43800, eval_loss: 2.76147e-02
I0208 17:15:11.639439 22542570456896 run_lib.py:133] step: 43850, training_loss: 2.88851e-02
I0208 17:15:29.057231 22542570456896 run_lib.py:133] step: 43900, training_loss: 2.94478e-02
I0208 17:15:29.233285 22542570456896 run_lib.py:146] step: 43900, eval_loss: 3.38876e-02
I0208 17:15:46.931677 22542570456896 run_lib.py:133] step: 43950, training_loss: 2.84083e-02
I0208 17:16:04.333140 22542570456896 run_lib.py:133] step: 44000, training_loss: 3.41026e-02
I0208 17:16:04.489594 22542570456896 run_lib.py:146] step: 44000, eval_loss: 3.34833e-02
I0208 17:16:22.071352 22542570456896 run_lib.py:133] step: 44050, training_loss: 3.10788e-02
I0208 17:16:39.548095 22542570456896 run_lib.py:133] step: 44100, training_loss: 3.16214e-02
I0208 17:16:39.703392 22542570456896 run_lib.py:146] step: 44100, eval_loss: 2.90407e-02
I0208 17:16:57.113740 22542570456896 run_lib.py:133] step: 44150, training_loss: 2.67526e-02
I0208 17:17:14.715145 22542570456896 run_lib.py:133] step: 44200, training_loss: 3.33334e-02
I0208 17:17:14.869420 22542570456896 run_lib.py:146] step: 44200, eval_loss: 3.00740e-02
I0208 17:17:32.312826 22542570456896 run_lib.py:133] step: 44250, training_loss: 3.37097e-02
I0208 17:17:49.974291 22542570456896 run_lib.py:133] step: 44300, training_loss: 3.48067e-02
I0208 17:17:50.133719 22542570456896 run_lib.py:146] step: 44300, eval_loss: 2.79139e-02
I0208 17:18:07.568910 22542570456896 run_lib.py:133] step: 44350, training_loss: 2.51654e-02
I0208 17:18:25.014587 22542570456896 run_lib.py:133] step: 44400, training_loss: 3.09027e-02
I0208 17:18:25.170564 22542570456896 run_lib.py:146] step: 44400, eval_loss: 2.60747e-02
I0208 17:18:42.799299 22542570456896 run_lib.py:133] step: 44450, training_loss: 2.79694e-02
I0208 17:19:00.277873 22542570456896 run_lib.py:133] step: 44500, training_loss: 2.38699e-02
I0208 17:19:00.433027 22542570456896 run_lib.py:146] step: 44500, eval_loss: 2.95341e-02
I0208 17:19:17.854962 22542570456896 run_lib.py:133] step: 44550, training_loss: 2.72961e-02
I0208 17:19:35.296925 22542570456896 run_lib.py:133] step: 44600, training_loss: 2.75579e-02
I0208 17:19:35.453120 22542570456896 run_lib.py:146] step: 44600, eval_loss: 3.34332e-02
I0208 17:19:53.056473 22542570456896 run_lib.py:133] step: 44650, training_loss: 3.02122e-02
I0208 17:20:10.566074 22542570456896 run_lib.py:133] step: 44700, training_loss: 2.29372e-02
I0208 17:20:10.721378 22542570456896 run_lib.py:146] step: 44700, eval_loss: 3.01151e-02
I0208 17:20:28.307997 22542570456896 run_lib.py:133] step: 44750, training_loss: 2.72794e-02
I0208 17:20:45.761955 22542570456896 run_lib.py:133] step: 44800, training_loss: 2.87206e-02
I0208 17:20:45.918896 22542570456896 run_lib.py:146] step: 44800, eval_loss: 2.77681e-02
I0208 17:21:03.322487 22542570456896 run_lib.py:133] step: 44850, training_loss: 2.65617e-02
I0208 17:21:20.731345 22542570456896 run_lib.py:133] step: 44900, training_loss: 2.96175e-02
I0208 17:21:20.891348 22542570456896 run_lib.py:146] step: 44900, eval_loss: 2.77934e-02
I0208 17:21:38.466940 22542570456896 run_lib.py:133] step: 44950, training_loss: 3.34636e-02
I0208 17:21:56.026406 22542570456896 run_lib.py:133] step: 45000, training_loss: 2.84653e-02
I0208 17:21:56.182806 22542570456896 run_lib.py:146] step: 45000, eval_loss: 3.74594e-02
I0208 17:22:13.594879 22542570456896 run_lib.py:133] step: 45050, training_loss: 2.68867e-02
I0208 17:22:31.019497 22542570456896 run_lib.py:133] step: 45100, training_loss: 2.73973e-02
I0208 17:22:31.170788 22542570456896 run_lib.py:146] step: 45100, eval_loss: 3.13760e-02
I0208 17:22:48.698335 22542570456896 run_lib.py:133] step: 45150, training_loss: 3.09371e-02
I0208 17:23:06.110844 22542570456896 run_lib.py:133] step: 45200, training_loss: 2.92430e-02
I0208 17:23:06.279493 22542570456896 run_lib.py:146] step: 45200, eval_loss: 3.31974e-02
I0208 17:23:23.866166 22542570456896 run_lib.py:133] step: 45250, training_loss: 2.52846e-02
I0208 17:23:41.308302 22542570456896 run_lib.py:133] step: 45300, training_loss: 2.87055e-02
I0208 17:23:41.465559 22542570456896 run_lib.py:146] step: 45300, eval_loss: 2.40147e-02
I0208 17:23:59.002206 22542570456896 run_lib.py:133] step: 45350, training_loss: 3.03884e-02
I0208 17:24:16.389815 22542570456896 run_lib.py:133] step: 45400, training_loss: 3.11761e-02
I0208 17:24:16.545396 22542570456896 run_lib.py:146] step: 45400, eval_loss: 2.90622e-02
I0208 17:24:34.114124 22542570456896 run_lib.py:133] step: 45450, training_loss: 2.42062e-02
I0208 17:24:51.569514 22542570456896 run_lib.py:133] step: 45500, training_loss: 2.49007e-02
I0208 17:24:51.724990 22542570456896 run_lib.py:146] step: 45500, eval_loss: 2.93469e-02
I0208 17:25:09.176088 22542570456896 run_lib.py:133] step: 45550, training_loss: 2.58579e-02
I0208 17:25:26.837875 22542570456896 run_lib.py:133] step: 45600, training_loss: 3.48467e-02
I0208 17:25:26.990375 22542570456896 run_lib.py:146] step: 45600, eval_loss: 2.71215e-02
I0208 17:25:44.413325 22542570456896 run_lib.py:133] step: 45650, training_loss: 3.08921e-02
I0208 17:26:01.859125 22542570456896 run_lib.py:133] step: 45700, training_loss: 2.64723e-02
I0208 17:26:02.014635 22542570456896 run_lib.py:146] step: 45700, eval_loss: 3.17240e-02
I0208 17:26:19.609426 22542570456896 run_lib.py:133] step: 45750, training_loss: 3.61209e-02
I0208 17:26:37.229267 22542570456896 run_lib.py:133] step: 45800, training_loss: 3.29135e-02
I0208 17:26:37.387396 22542570456896 run_lib.py:146] step: 45800, eval_loss: 2.88797e-02
I0208 17:26:54.853845 22542570456896 run_lib.py:133] step: 45850, training_loss: 3.34398e-02
I0208 17:27:12.269168 22542570456896 run_lib.py:133] step: 45900, training_loss: 2.97210e-02
I0208 17:27:12.425257 22542570456896 run_lib.py:146] step: 45900, eval_loss: 3.18934e-02
I0208 17:27:29.828619 22542570456896 run_lib.py:133] step: 45950, training_loss: 3.03051e-02
I0208 17:27:47.420789 22542570456896 run_lib.py:133] step: 46000, training_loss: 3.10176e-02
I0208 17:27:47.576658 22542570456896 run_lib.py:146] step: 46000, eval_loss: 3.13912e-02
I0208 17:28:05.086813 22542570456896 run_lib.py:133] step: 46050, training_loss: 2.61498e-02
I0208 17:28:22.523873 22542570456896 run_lib.py:133] step: 46100, training_loss: 3.07428e-02
I0208 17:28:22.675233 22542570456896 run_lib.py:146] step: 46100, eval_loss: 2.98076e-02
I0208 17:28:40.090673 22542570456896 run_lib.py:133] step: 46150, training_loss: 2.27485e-02
I0208 17:28:57.690773 22542570456896 run_lib.py:133] step: 46200, training_loss: 2.54132e-02
I0208 17:28:57.849690 22542570456896 run_lib.py:146] step: 46200, eval_loss: 3.12507e-02
I0208 17:29:15.259655 22542570456896 run_lib.py:133] step: 46250, training_loss: 2.80957e-02
I0208 17:29:32.767068 22542570456896 run_lib.py:133] step: 46300, training_loss: 2.78720e-02
I0208 17:29:32.923351 22542570456896 run_lib.py:146] step: 46300, eval_loss: 3.08742e-02
I0208 17:29:50.390786 22542570456896 run_lib.py:133] step: 46350, training_loss: 2.49342e-02
I0208 17:30:07.806283 22542570456896 run_lib.py:133] step: 46400, training_loss: 3.22748e-02
I0208 17:30:07.961677 22542570456896 run_lib.py:146] step: 46400, eval_loss: 2.03300e-02
I0208 17:30:25.591053 22542570456896 run_lib.py:133] step: 46450, training_loss: 2.81574e-02
I0208 17:30:43.064498 22542570456896 run_lib.py:133] step: 46500, training_loss: 2.89052e-02
I0208 17:30:43.220325 22542570456896 run_lib.py:146] step: 46500, eval_loss: 3.56074e-02
I0208 17:31:00.655958 22542570456896 run_lib.py:133] step: 46550, training_loss: 2.49252e-02
I0208 17:31:18.087431 22542570456896 run_lib.py:133] step: 46600, training_loss: 3.51526e-02
I0208 17:31:18.248527 22542570456896 run_lib.py:146] step: 46600, eval_loss: 2.51901e-02
I0208 17:31:35.898418 22542570456896 run_lib.py:133] step: 46650, training_loss: 2.77375e-02
I0208 17:31:53.333405 22542570456896 run_lib.py:133] step: 46700, training_loss: 3.34420e-02
I0208 17:31:53.491587 22542570456896 run_lib.py:146] step: 46700, eval_loss: 3.11838e-02
I0208 17:32:11.058498 22542570456896 run_lib.py:133] step: 46750, training_loss: 2.76105e-02
I0208 17:32:28.463129 22542570456896 run_lib.py:133] step: 46800, training_loss: 2.89143e-02
I0208 17:32:28.617220 22542570456896 run_lib.py:146] step: 46800, eval_loss: 2.92460e-02
I0208 17:32:46.267131 22542570456896 run_lib.py:133] step: 46850, training_loss: 2.86635e-02
I0208 17:33:03.699086 22542570456896 run_lib.py:133] step: 46900, training_loss: 2.69497e-02
I0208 17:33:03.862738 22542570456896 run_lib.py:146] step: 46900, eval_loss: 2.53747e-02
I0208 17:33:21.318303 22542570456896 run_lib.py:133] step: 46950, training_loss: 3.01007e-02
I0208 17:33:38.905222 22542570456896 run_lib.py:133] step: 47000, training_loss: 3.08248e-02
I0208 17:33:39.056025 22542570456896 run_lib.py:146] step: 47000, eval_loss: 3.87427e-02
I0208 17:33:56.505193 22542570456896 run_lib.py:133] step: 47050, training_loss: 3.08148e-02
I0208 17:34:14.071985 22542570456896 run_lib.py:133] step: 47100, training_loss: 2.80363e-02
I0208 17:34:14.227013 22542570456896 run_lib.py:146] step: 47100, eval_loss: 2.47700e-02
I0208 17:34:31.655262 22542570456896 run_lib.py:133] step: 47150, training_loss: 2.57831e-02
I0208 17:34:49.140455 22542570456896 run_lib.py:133] step: 47200, training_loss: 2.67699e-02
I0208 17:34:49.302172 22542570456896 run_lib.py:146] step: 47200, eval_loss: 2.43576e-02
I0208 17:35:06.929300 22542570456896 run_lib.py:133] step: 47250, training_loss: 2.38838e-02
I0208 17:35:24.317062 22542570456896 run_lib.py:133] step: 47300, training_loss: 3.05038e-02
I0208 17:35:24.472206 22542570456896 run_lib.py:146] step: 47300, eval_loss: 2.67556e-02
I0208 17:35:41.924493 22542570456896 run_lib.py:133] step: 47350, training_loss: 2.47002e-02
I0208 17:35:59.477525 22542570456896 run_lib.py:133] step: 47400, training_loss: 2.97697e-02
I0208 17:35:59.631243 22542570456896 run_lib.py:146] step: 47400, eval_loss: 3.34708e-02
I0208 17:36:17.011241 22542570456896 run_lib.py:133] step: 47450, training_loss: 3.28546e-02
I0208 17:36:34.423334 22542570456896 run_lib.py:133] step: 47500, training_loss: 2.90130e-02
I0208 17:36:34.582328 22542570456896 run_lib.py:146] step: 47500, eval_loss: 2.52703e-02
I0208 17:36:52.038621 22542570456896 run_lib.py:133] step: 47550, training_loss: 3.12648e-02
I0208 17:37:09.365106 22542570456896 run_lib.py:133] step: 47600, training_loss: 2.60415e-02
I0208 17:37:09.519154 22542570456896 run_lib.py:146] step: 47600, eval_loss: 3.07204e-02
I0208 17:37:26.979497 22542570456896 run_lib.py:133] step: 47650, training_loss: 2.93024e-02
I0208 17:37:44.384025 22542570456896 run_lib.py:133] step: 47700, training_loss: 2.56606e-02
I0208 17:37:44.540539 22542570456896 run_lib.py:146] step: 47700, eval_loss: 2.80024e-02
I0208 17:38:02.170558 22542570456896 run_lib.py:133] step: 47750, training_loss: 2.57085e-02
I0208 17:38:19.764006 22542570456896 run_lib.py:133] step: 47800, training_loss: 3.01638e-02
I0208 17:38:19.920794 22542570456896 run_lib.py:146] step: 47800, eval_loss: 2.68191e-02
I0208 17:38:37.360901 22542570456896 run_lib.py:133] step: 47850, training_loss: 3.42536e-02
I0208 17:38:54.769400 22542570456896 run_lib.py:133] step: 47900, training_loss: 2.75365e-02
I0208 17:38:54.922590 22542570456896 run_lib.py:146] step: 47900, eval_loss: 2.58667e-02
I0208 17:39:12.510171 22542570456896 run_lib.py:133] step: 47950, training_loss: 2.70361e-02
I0208 17:39:29.930177 22542570456896 run_lib.py:133] step: 48000, training_loss: 3.09124e-02
I0208 17:39:30.085580 22542570456896 run_lib.py:146] step: 48000, eval_loss: 3.08386e-02
I0208 17:39:47.743783 22542570456896 run_lib.py:133] step: 48050, training_loss: 2.67518e-02
I0208 17:40:05.178918 22542570456896 run_lib.py:133] step: 48100, training_loss: 2.31226e-02
I0208 17:40:05.344436 22542570456896 run_lib.py:146] step: 48100, eval_loss: 2.74100e-02
I0208 17:40:22.937631 22542570456896 run_lib.py:133] step: 48150, training_loss: 3.14418e-02
I0208 17:40:40.366016 22542570456896 run_lib.py:133] step: 48200, training_loss: 2.52691e-02
I0208 17:40:40.528316 22542570456896 run_lib.py:146] step: 48200, eval_loss: 2.85658e-02
I0208 17:40:58.123970 22542570456896 run_lib.py:133] step: 48250, training_loss: 3.58813e-02
I0208 17:41:15.593954 22542570456896 run_lib.py:133] step: 48300, training_loss: 2.91610e-02
I0208 17:41:15.750773 22542570456896 run_lib.py:146] step: 48300, eval_loss: 3.34875e-02
I0208 17:41:33.203547 22542570456896 run_lib.py:133] step: 48350, training_loss: 3.04895e-02
I0208 17:41:50.795773 22542570456896 run_lib.py:133] step: 48400, training_loss: 3.43253e-02
I0208 17:41:50.948804 22542570456896 run_lib.py:146] step: 48400, eval_loss: 3.24885e-02
I0208 17:42:08.360853 22542570456896 run_lib.py:133] step: 48450, training_loss: 3.28217e-02
I0208 17:42:25.815023 22542570456896 run_lib.py:133] step: 48500, training_loss: 3.26552e-02
I0208 17:42:25.968265 22542570456896 run_lib.py:146] step: 48500, eval_loss: 3.21279e-02
I0208 17:42:43.520394 22542570456896 run_lib.py:133] step: 48550, training_loss: 2.92748e-02
I0208 17:43:01.023553 22542570456896 run_lib.py:133] step: 48600, training_loss: 3.38901e-02
I0208 17:43:01.193417 22542570456896 run_lib.py:146] step: 48600, eval_loss: 2.40264e-02
I0208 17:43:18.833391 22542570456896 run_lib.py:133] step: 48650, training_loss: 3.22197e-02
I0208 17:43:36.295483 22542570456896 run_lib.py:133] step: 48700, training_loss: 3.13591e-02
I0208 17:43:36.450636 22542570456896 run_lib.py:146] step: 48700, eval_loss: 3.31431e-02
I0208 17:43:53.943301 22542570456896 run_lib.py:133] step: 48750, training_loss: 2.84291e-02
I0208 17:44:11.546002 22542570456896 run_lib.py:133] step: 48800, training_loss: 1.98342e-02
I0208 17:44:11.702469 22542570456896 run_lib.py:146] step: 48800, eval_loss: 2.94868e-02
I0208 17:44:29.143397 22542570456896 run_lib.py:133] step: 48850, training_loss: 3.49824e-02
I0208 17:44:46.572090 22542570456896 run_lib.py:133] step: 48900, training_loss: 2.20635e-02
I0208 17:44:46.725539 22542570456896 run_lib.py:146] step: 48900, eval_loss: 2.88502e-02
I0208 17:45:04.182826 22542570456896 run_lib.py:133] step: 48950, training_loss: 2.55903e-02
I0208 17:45:21.813131 22542570456896 run_lib.py:133] step: 49000, training_loss: 2.27682e-02
I0208 17:45:21.968294 22542570456896 run_lib.py:146] step: 49000, eval_loss: 3.07204e-02
I0208 17:45:39.381709 22542570456896 run_lib.py:133] step: 49050, training_loss: 3.54032e-02
I0208 17:45:56.865693 22542570456896 run_lib.py:133] step: 49100, training_loss: 2.68110e-02
I0208 17:45:57.022465 22542570456896 run_lib.py:146] step: 49100, eval_loss: 2.68699e-02
I0208 17:46:14.460345 22542570456896 run_lib.py:133] step: 49150, training_loss: 2.74176e-02
I0208 17:46:31.960985 22542570456896 run_lib.py:133] step: 49200, training_loss: 2.74103e-02
I0208 17:46:32.117590 22542570456896 run_lib.py:146] step: 49200, eval_loss: 2.51478e-02
I0208 17:46:49.701360 22542570456896 run_lib.py:133] step: 49250, training_loss: 2.99284e-02
I0208 17:47:07.170806 22542570456896 run_lib.py:133] step: 49300, training_loss: 3.34021e-02
I0208 17:47:07.326339 22542570456896 run_lib.py:146] step: 49300, eval_loss: 3.19841e-02
I0208 17:47:24.760856 22542570456896 run_lib.py:133] step: 49350, training_loss: 4.03519e-02
I0208 17:47:42.195429 22542570456896 run_lib.py:133] step: 49400, training_loss: 2.63034e-02
I0208 17:47:42.348285 22542570456896 run_lib.py:146] step: 49400, eval_loss: 2.72249e-02
I0208 17:47:59.924816 22542570456896 run_lib.py:133] step: 49450, training_loss: 3.54981e-02
I0208 17:48:17.354829 22542570456896 run_lib.py:133] step: 49500, training_loss: 2.27440e-02
I0208 17:48:17.513082 22542570456896 run_lib.py:146] step: 49500, eval_loss: 2.13791e-02
I0208 17:48:35.167250 22542570456896 run_lib.py:133] step: 49550, training_loss: 2.96058e-02
I0208 17:48:52.615273 22542570456896 run_lib.py:133] step: 49600, training_loss: 2.86733e-02
I0208 17:48:52.772686 22542570456896 run_lib.py:146] step: 49600, eval_loss: 2.70571e-02
I0208 17:49:10.340665 22542570456896 run_lib.py:133] step: 49650, training_loss: 3.35870e-02
I0208 17:49:27.765314 22542570456896 run_lib.py:133] step: 49700, training_loss: 3.77814e-02
I0208 17:49:27.929345 22542570456896 run_lib.py:146] step: 49700, eval_loss: 3.33887e-02
I0208 17:49:45.365710 22542570456896 run_lib.py:133] step: 49750, training_loss: 2.77246e-02
I0208 17:50:03.011980 22542570456896 run_lib.py:133] step: 49800, training_loss: 3.26495e-02
I0208 17:50:03.170880 22542570456896 run_lib.py:146] step: 49800, eval_loss: 2.68024e-02
I0208 17:50:20.616586 22542570456896 run_lib.py:133] step: 49850, training_loss: 3.58875e-02
I0208 17:50:38.197006 22542570456896 run_lib.py:133] step: 49900, training_loss: 3.38415e-02
I0208 17:50:38.349289 22542570456896 run_lib.py:146] step: 49900, eval_loss: 2.53869e-02
I0208 17:50:55.739139 22542570456896 run_lib.py:133] step: 49950, training_loss: 3.14566e-02
I0208 17:51:13.189382 22542570456896 run_lib.py:133] step: 50000, training_loss: 3.42302e-02
I0208 17:51:13.889360 22542570456896 run_lib.py:146] step: 50000, eval_loss: 3.24229e-02
I0208 17:51:34.114599 22542570456896 run_lib.py:133] step: 50050, training_loss: 2.63409e-02
I0208 17:51:51.560903 22542570456896 run_lib.py:133] step: 50100, training_loss: 3.33672e-02
I0208 17:51:51.719323 22542570456896 run_lib.py:146] step: 50100, eval_loss: 2.47980e-02
I0208 17:52:09.298969 22542570456896 run_lib.py:133] step: 50150, training_loss: 2.75073e-02
I0208 17:52:26.721089 22542570456896 run_lib.py:133] step: 50200, training_loss: 3.25637e-02
I0208 17:52:26.876516 22542570456896 run_lib.py:146] step: 50200, eval_loss: 3.33522e-02
I0208 17:52:44.290393 22542570456896 run_lib.py:133] step: 50250, training_loss: 3.66582e-02
I0208 17:53:01.876722 22542570456896 run_lib.py:133] step: 50300, training_loss: 2.65353e-02
I0208 17:53:02.044633 22542570456896 run_lib.py:146] step: 50300, eval_loss: 2.56051e-02
I0208 17:53:19.538950 22542570456896 run_lib.py:133] step: 50350, training_loss: 2.73638e-02
I0208 17:53:37.126010 22542570456896 run_lib.py:133] step: 50400, training_loss: 2.81934e-02
I0208 17:53:37.280506 22542570456896 run_lib.py:146] step: 50400, eval_loss: 2.87656e-02
I0208 17:53:54.697752 22542570456896 run_lib.py:133] step: 50450, training_loss: 2.80215e-02
I0208 17:54:12.162076 22542570456896 run_lib.py:133] step: 50500, training_loss: 2.85488e-02
I0208 17:54:12.315270 22542570456896 run_lib.py:146] step: 50500, eval_loss: 3.44634e-02
I0208 17:54:29.703267 22542570456896 run_lib.py:133] step: 50550, training_loss: 3.01271e-02
I0208 17:54:47.266091 22542570456896 run_lib.py:133] step: 50600, training_loss: 3.38812e-02
I0208 17:54:47.442769 22542570456896 run_lib.py:146] step: 50600, eval_loss: 3.28225e-02
I0208 17:55:04.909735 22542570456896 run_lib.py:133] step: 50650, training_loss: 2.56071e-02
I0208 17:55:22.333379 22542570456896 run_lib.py:133] step: 50700, training_loss: 2.83525e-02
I0208 17:55:22.495561 22542570456896 run_lib.py:146] step: 50700, eval_loss: 2.65558e-02
I0208 17:55:40.183372 22542570456896 run_lib.py:133] step: 50750, training_loss: 2.43955e-02
I0208 17:55:57.565485 22542570456896 run_lib.py:133] step: 50800, training_loss: 3.02184e-02
I0208 17:55:57.720338 22542570456896 run_lib.py:146] step: 50800, eval_loss: 2.84135e-02
I0208 17:56:15.199130 22542570456896 run_lib.py:133] step: 50850, training_loss: 2.74332e-02
I0208 17:56:32.636299 22542570456896 run_lib.py:133] step: 50900, training_loss: 2.49043e-02
I0208 17:56:32.787574 22542570456896 run_lib.py:146] step: 50900, eval_loss: 2.43883e-02
I0208 17:56:50.254237 22542570456896 run_lib.py:133] step: 50950, training_loss: 2.90863e-02
I0208 17:57:07.699380 22542570456896 run_lib.py:133] step: 51000, training_loss: 3.34553e-02
I0208 17:57:07.856509 22542570456896 run_lib.py:146] step: 51000, eval_loss: 3.23947e-02
I0208 17:57:25.449861 22542570456896 run_lib.py:133] step: 51050, training_loss: 3.21349e-02
I0208 17:57:42.967396 22542570456896 run_lib.py:133] step: 51100, training_loss: 2.47470e-02
I0208 17:57:43.126580 22542570456896 run_lib.py:146] step: 51100, eval_loss: 2.89580e-02
I0208 17:58:00.616133 22542570456896 run_lib.py:133] step: 51150, training_loss: 2.69340e-02
I0208 17:58:18.072450 22542570456896 run_lib.py:133] step: 51200, training_loss: 3.27900e-02
I0208 17:58:18.235127 22542570456896 run_lib.py:146] step: 51200, eval_loss: 3.40040e-02
I0208 17:58:35.832529 22542570456896 run_lib.py:133] step: 51250, training_loss: 3.05715e-02
I0208 17:58:53.212734 22542570456896 run_lib.py:133] step: 51300, training_loss: 2.59717e-02
I0208 17:58:53.363643 22542570456896 run_lib.py:146] step: 51300, eval_loss: 2.92950e-02
I0208 17:59:10.923257 22542570456896 run_lib.py:133] step: 51350, training_loss: 2.61428e-02
I0208 17:59:28.359359 22542570456896 run_lib.py:133] step: 51400, training_loss: 3.11946e-02
I0208 17:59:28.515428 22542570456896 run_lib.py:146] step: 51400, eval_loss: 2.48933e-02
I0208 17:59:46.191809 22542570456896 run_lib.py:133] step: 51450, training_loss: 2.93526e-02
I0208 18:00:03.609956 22542570456896 run_lib.py:133] step: 51500, training_loss: 2.83212e-02
I0208 18:00:03.768182 22542570456896 run_lib.py:146] step: 51500, eval_loss: 3.21382e-02
I0208 18:00:21.316020 22542570456896 run_lib.py:133] step: 51550, training_loss: 2.23110e-02
I0208 18:00:38.736060 22542570456896 run_lib.py:133] step: 51600, training_loss: 3.12841e-02
I0208 18:00:38.891199 22542570456896 run_lib.py:146] step: 51600, eval_loss: 2.62692e-02
I0208 18:00:56.287411 22542570456896 run_lib.py:133] step: 51650, training_loss: 3.54684e-02
I0208 18:01:13.853770 22542570456896 run_lib.py:133] step: 51700, training_loss: 3.15638e-02
I0208 18:01:14.014990 22542570456896 run_lib.py:146] step: 51700, eval_loss: 2.26804e-02
I0208 18:01:31.471837 22542570456896 run_lib.py:133] step: 51750, training_loss: 2.88974e-02
I0208 18:01:48.882467 22542570456896 run_lib.py:133] step: 51800, training_loss: 2.40199e-02
I0208 18:01:49.034077 22542570456896 run_lib.py:146] step: 51800, eval_loss: 2.36790e-02
I0208 18:02:06.651228 22542570456896 run_lib.py:133] step: 51850, training_loss: 3.44825e-02
I0208 18:02:24.032716 22542570456896 run_lib.py:133] step: 51900, training_loss: 3.03760e-02
I0208 18:02:24.191610 22542570456896 run_lib.py:146] step: 51900, eval_loss: 3.23420e-02
I0208 18:02:41.765975 22542570456896 run_lib.py:133] step: 51950, training_loss: 3.06760e-02
I0208 18:02:59.237340 22542570456896 run_lib.py:133] step: 52000, training_loss: 2.95831e-02
I0208 18:02:59.413265 22542570456896 run_lib.py:146] step: 52000, eval_loss: 2.61492e-02
I0208 18:03:16.863855 22542570456896 run_lib.py:133] step: 52050, training_loss: 3.36346e-02
I0208 18:03:34.489142 22542570456896 run_lib.py:133] step: 52100, training_loss: 3.13677e-02
I0208 18:03:34.641716 22542570456896 run_lib.py:146] step: 52100, eval_loss: 2.27817e-02
I0208 18:03:52.086771 22542570456896 run_lib.py:133] step: 52150, training_loss: 2.81913e-02
I0208 18:04:09.481855 22542570456896 run_lib.py:133] step: 52200, training_loss: 3.09640e-02
I0208 18:04:09.637381 22542570456896 run_lib.py:146] step: 52200, eval_loss: 2.53878e-02
I0208 18:04:27.064172 22542570456896 run_lib.py:133] step: 52250, training_loss: 2.85557e-02
I0208 18:04:44.650961 22542570456896 run_lib.py:133] step: 52300, training_loss: 2.72357e-02
I0208 18:04:44.804388 22542570456896 run_lib.py:146] step: 52300, eval_loss: 2.87527e-02
I0208 18:05:02.271550 22542570456896 run_lib.py:133] step: 52350, training_loss: 2.96847e-02
I0208 18:05:19.763574 22542570456896 run_lib.py:133] step: 52400, training_loss: 3.74106e-02
I0208 18:05:19.919234 22542570456896 run_lib.py:146] step: 52400, eval_loss: 3.07866e-02
I0208 18:05:37.325453 22542570456896 run_lib.py:133] step: 52450, training_loss: 2.71144e-02
I0208 18:05:54.732467 22542570456896 run_lib.py:133] step: 52500, training_loss: 2.38774e-02
I0208 18:05:54.889340 22542570456896 run_lib.py:146] step: 52500, eval_loss: 2.49183e-02
I0208 18:06:12.491820 22542570456896 run_lib.py:133] step: 52550, training_loss: 3.21541e-02
I0208 18:06:30.037252 22542570456896 run_lib.py:133] step: 52600, training_loss: 3.03349e-02
I0208 18:06:30.196617 22542570456896 run_lib.py:146] step: 52600, eval_loss: 2.50025e-02
I0208 18:06:47.630788 22542570456896 run_lib.py:133] step: 52650, training_loss: 2.43219e-02
I0208 18:07:05.044508 22542570456896 run_lib.py:133] step: 52700, training_loss: 2.87580e-02
I0208 18:07:05.205314 22542570456896 run_lib.py:146] step: 52700, eval_loss: 2.64252e-02
I0208 18:07:22.731927 22542570456896 run_lib.py:133] step: 52750, training_loss: 2.98973e-02
I0208 18:07:40.143466 22542570456896 run_lib.py:133] step: 52800, training_loss: 2.23065e-02
I0208 18:07:40.297161 22542570456896 run_lib.py:146] step: 52800, eval_loss: 2.68134e-02
I0208 18:07:57.904434 22542570456896 run_lib.py:133] step: 52850, training_loss: 4.05518e-02
I0208 18:08:15.352547 22542570456896 run_lib.py:133] step: 52900, training_loss: 3.45540e-02
I0208 18:08:15.508296 22542570456896 run_lib.py:146] step: 52900, eval_loss: 2.68467e-02
I0208 18:08:33.131231 22542570456896 run_lib.py:133] step: 52950, training_loss: 2.82269e-02
I0208 18:08:50.581690 22542570456896 run_lib.py:133] step: 53000, training_loss: 2.64808e-02
I0208 18:08:50.744679 22542570456896 run_lib.py:146] step: 53000, eval_loss: 2.96752e-02
I0208 18:09:08.156466 22542570456896 run_lib.py:133] step: 53050, training_loss: 2.64281e-02
I0208 18:09:25.772471 22542570456896 run_lib.py:133] step: 53100, training_loss: 3.15981e-02
I0208 18:09:25.936654 22542570456896 run_lib.py:146] step: 53100, eval_loss: 3.20590e-02
I0208 18:09:43.378008 22542570456896 run_lib.py:133] step: 53150, training_loss: 2.92777e-02
I0208 18:10:00.982745 22542570456896 run_lib.py:133] step: 53200, training_loss: 3.24371e-02
I0208 18:10:01.134358 22542570456896 run_lib.py:146] step: 53200, eval_loss: 3.30321e-02
I0208 18:10:18.531053 22542570456896 run_lib.py:133] step: 53250, training_loss: 3.61394e-02
I0208 18:10:35.980952 22542570456896 run_lib.py:133] step: 53300, training_loss: 2.65176e-02
I0208 18:10:36.133295 22542570456896 run_lib.py:146] step: 53300, eval_loss: 2.89178e-02
I0208 18:10:53.717789 22542570456896 run_lib.py:133] step: 53350, training_loss: 2.67994e-02
I0208 18:11:11.172338 22542570456896 run_lib.py:133] step: 53400, training_loss: 2.81466e-02
I0208 18:11:11.340283 22542570456896 run_lib.py:146] step: 53400, eval_loss: 2.15950e-02
I0208 18:11:28.784591 22542570456896 run_lib.py:133] step: 53450, training_loss: 3.49110e-02
I0208 18:11:46.399926 22542570456896 run_lib.py:133] step: 53500, training_loss: 2.63852e-02
I0208 18:11:46.555325 22542570456896 run_lib.py:146] step: 53500, eval_loss: 2.71520e-02
I0208 18:12:04.007263 22542570456896 run_lib.py:133] step: 53550, training_loss: 2.76123e-02
I0208 18:12:21.416086 22542570456896 run_lib.py:133] step: 53600, training_loss: 3.50152e-02
I0208 18:12:21.725024 22542570456896 run_lib.py:146] step: 53600, eval_loss: 2.76912e-02
I0208 18:12:39.204199 22542570456896 run_lib.py:133] step: 53650, training_loss: 3.44015e-02
I0208 18:12:56.656049 22542570456896 run_lib.py:133] step: 53700, training_loss: 2.90649e-02
I0208 18:12:56.807586 22542570456896 run_lib.py:146] step: 53700, eval_loss: 3.68298e-02
I0208 18:13:14.215740 22542570456896 run_lib.py:133] step: 53750, training_loss: 3.33383e-02
I0208 18:13:31.681077 22542570456896 run_lib.py:133] step: 53800, training_loss: 2.77345e-02
I0208 18:13:31.836450 22542570456896 run_lib.py:146] step: 53800, eval_loss: 2.17109e-02
I0208 18:13:49.389482 22542570456896 run_lib.py:133] step: 53850, training_loss: 2.46046e-02
I0208 18:14:06.909558 22542570456896 run_lib.py:133] step: 53900, training_loss: 2.73768e-02
I0208 18:14:07.085161 22542570456896 run_lib.py:146] step: 53900, eval_loss: 2.47656e-02
I0208 18:14:24.580199 22542570456896 run_lib.py:133] step: 53950, training_loss: 3.74156e-02
I0208 18:14:42.050364 22542570456896 run_lib.py:133] step: 54000, training_loss: 3.23692e-02
I0208 18:14:42.202634 22542570456896 run_lib.py:146] step: 54000, eval_loss: 2.86539e-02
I0208 18:14:59.782594 22542570456896 run_lib.py:133] step: 54050, training_loss: 2.99950e-02
I0208 18:15:17.255523 22542570456896 run_lib.py:133] step: 54100, training_loss: 3.04946e-02
I0208 18:15:17.408803 22542570456896 run_lib.py:146] step: 54100, eval_loss: 2.77063e-02
I0208 18:15:34.864373 22542570456896 run_lib.py:133] step: 54150, training_loss: 2.76760e-02
I0208 18:15:52.322134 22542570456896 run_lib.py:133] step: 54200, training_loss: 2.70633e-02
I0208 18:15:52.477564 22542570456896 run_lib.py:146] step: 54200, eval_loss: 3.40304e-02
I0208 18:16:10.100929 22542570456896 run_lib.py:133] step: 54250, training_loss: 3.07214e-02
I0208 18:16:27.536722 22542570456896 run_lib.py:133] step: 54300, training_loss: 2.60704e-02
I0208 18:16:27.695286 22542570456896 run_lib.py:146] step: 54300, eval_loss: 3.71427e-02
I0208 18:16:45.267945 22542570456896 run_lib.py:133] step: 54350, training_loss: 2.73559e-02
I0208 18:17:02.684119 22542570456896 run_lib.py:133] step: 54400, training_loss: 3.27594e-02
I0208 18:17:02.852296 22542570456896 run_lib.py:146] step: 54400, eval_loss: 3.03760e-02
I0208 18:17:20.530271 22542570456896 run_lib.py:133] step: 54450, training_loss: 3.58154e-02
I0208 18:17:37.968051 22542570456896 run_lib.py:133] step: 54500, training_loss: 2.90781e-02
I0208 18:17:38.123689 22542570456896 run_lib.py:146] step: 54500, eval_loss: 3.48697e-02
I0208 18:17:55.548514 22542570456896 run_lib.py:133] step: 54550, training_loss: 3.81505e-02
I0208 18:18:13.125256 22542570456896 run_lib.py:133] step: 54600, training_loss: 2.81704e-02
I0208 18:18:13.283160 22542570456896 run_lib.py:146] step: 54600, eval_loss: 2.91373e-02
I0208 18:18:30.739514 22542570456896 run_lib.py:133] step: 54650, training_loss: 3.03585e-02
I0208 18:18:48.321887 22542570456896 run_lib.py:133] step: 54700, training_loss: 2.52296e-02
I0208 18:18:48.475566 22542570456896 run_lib.py:146] step: 54700, eval_loss: 3.32625e-02
I0208 18:19:05.925151 22542570456896 run_lib.py:133] step: 54750, training_loss: 2.48309e-02
I0208 18:19:23.338252 22542570456896 run_lib.py:133] step: 54800, training_loss: 2.87045e-02
I0208 18:19:23.497224 22542570456896 run_lib.py:146] step: 54800, eval_loss: 2.61832e-02
I0208 18:19:41.116205 22542570456896 run_lib.py:133] step: 54850, training_loss: 2.30534e-02
I0208 18:19:58.504587 22542570456896 run_lib.py:133] step: 54900, training_loss: 3.09088e-02
I0208 18:19:58.669314 22542570456896 run_lib.py:146] step: 54900, eval_loss: 2.90615e-02
I0208 18:20:16.102059 22542570456896 run_lib.py:133] step: 54950, training_loss: 2.90790e-02
I0208 18:20:33.596405 22542570456896 run_lib.py:133] step: 55000, training_loss: 2.80498e-02
I0208 18:20:33.754277 22542570456896 run_lib.py:146] step: 55000, eval_loss: 3.41175e-02
I0208 18:20:51.466355 22542570456896 run_lib.py:133] step: 55050, training_loss: 2.53864e-02
I0208 18:21:08.879518 22542570456896 run_lib.py:133] step: 55100, training_loss: 2.12096e-02
I0208 18:21:09.033105 22542570456896 run_lib.py:146] step: 55100, eval_loss: 3.00993e-02
I0208 18:21:26.489497 22542570456896 run_lib.py:133] step: 55150, training_loss: 3.45223e-02
I0208 18:21:43.957550 22542570456896 run_lib.py:133] step: 55200, training_loss: 3.63452e-02
I0208 18:21:44.110462 22542570456896 run_lib.py:146] step: 55200, eval_loss: 3.74369e-02
I0208 18:22:01.594172 22542570456896 run_lib.py:133] step: 55250, training_loss: 3.32865e-02
I0208 18:22:19.027178 22542570456896 run_lib.py:133] step: 55300, training_loss: 3.23351e-02
I0208 18:22:19.185343 22542570456896 run_lib.py:146] step: 55300, eval_loss: 3.15217e-02
I0208 18:22:36.761670 22542570456896 run_lib.py:133] step: 55350, training_loss: 2.56858e-02
I0208 18:22:54.249317 22542570456896 run_lib.py:133] step: 55400, training_loss: 2.68189e-02
I0208 18:22:54.404286 22542570456896 run_lib.py:146] step: 55400, eval_loss: 2.34164e-02
I0208 18:23:11.863822 22542570456896 run_lib.py:133] step: 55450, training_loss: 2.65561e-02
I0208 18:23:29.320362 22542570456896 run_lib.py:133] step: 55500, training_loss: 3.48829e-02
I0208 18:23:29.486544 22542570456896 run_lib.py:146] step: 55500, eval_loss: 2.90295e-02
I0208 18:23:47.074132 22542570456896 run_lib.py:133] step: 55550, training_loss: 2.75867e-02
I0208 18:24:04.525050 22542570456896 run_lib.py:133] step: 55600, training_loss: 3.35325e-02
I0208 18:24:04.675042 22542570456896 run_lib.py:146] step: 55600, eval_loss: 3.38956e-02
I0208 18:24:22.331553 22542570456896 run_lib.py:133] step: 55650, training_loss: 2.48681e-02
I0208 18:24:39.750346 22542570456896 run_lib.py:133] step: 55700, training_loss: 2.57044e-02
I0208 18:24:39.911380 22542570456896 run_lib.py:146] step: 55700, eval_loss: 2.54708e-02
I0208 18:24:57.441082 22542570456896 run_lib.py:133] step: 55750, training_loss: 3.15971e-02
I0208 18:25:14.839937 22542570456896 run_lib.py:133] step: 55800, training_loss: 2.69340e-02
I0208 18:25:15.019410 22542570456896 run_lib.py:146] step: 55800, eval_loss: 2.92201e-02
I0208 18:25:32.683922 22542570456896 run_lib.py:133] step: 55850, training_loss: 2.71903e-02
I0208 18:25:50.108088 22542570456896 run_lib.py:133] step: 55900, training_loss: 3.97790e-02
I0208 18:25:50.264568 22542570456896 run_lib.py:146] step: 55900, eval_loss: 2.42641e-02
I0208 18:26:07.688820 22542570456896 run_lib.py:133] step: 55950, training_loss: 2.99892e-02
I0208 18:26:25.239367 22542570456896 run_lib.py:133] step: 56000, training_loss: 2.12923e-02
I0208 18:26:25.393965 22542570456896 run_lib.py:146] step: 56000, eval_loss: 4.20373e-02
I0208 18:26:42.803589 22542570456896 run_lib.py:133] step: 56050, training_loss: 2.79932e-02
I0208 18:27:00.269752 22542570456896 run_lib.py:133] step: 56100, training_loss: 3.05892e-02
I0208 18:27:00.422569 22542570456896 run_lib.py:146] step: 56100, eval_loss: 3.05182e-02
I0208 18:27:18.051706 22542570456896 run_lib.py:133] step: 56150, training_loss: 2.85157e-02
I0208 18:27:35.650653 22542570456896 run_lib.py:133] step: 56200, training_loss: 2.64086e-02
I0208 18:27:35.806521 22542570456896 run_lib.py:146] step: 56200, eval_loss: 2.87048e-02
I0208 18:27:53.185229 22542570456896 run_lib.py:133] step: 56250, training_loss: 2.87999e-02
I0208 18:28:10.568326 22542570456896 run_lib.py:133] step: 56300, training_loss: 3.07238e-02
I0208 18:28:10.724541 22542570456896 run_lib.py:146] step: 56300, eval_loss: 2.65697e-02
I0208 18:28:28.168319 22542570456896 run_lib.py:133] step: 56350, training_loss: 2.58276e-02
I0208 18:28:45.763723 22542570456896 run_lib.py:133] step: 56400, training_loss: 2.75592e-02
I0208 18:28:45.920576 22542570456896 run_lib.py:146] step: 56400, eval_loss: 3.22144e-02
I0208 18:29:03.338593 22542570456896 run_lib.py:133] step: 56450, training_loss: 2.43021e-02
I0208 18:29:20.719416 22542570456896 run_lib.py:133] step: 56500, training_loss: 2.73884e-02
I0208 18:29:20.875312 22542570456896 run_lib.py:146] step: 56500, eval_loss: 2.67610e-02
I0208 18:29:38.291935 22542570456896 run_lib.py:133] step: 56550, training_loss: 2.99682e-02
I0208 18:29:55.897909 22542570456896 run_lib.py:133] step: 56600, training_loss: 2.87417e-02
I0208 18:29:56.050698 22542570456896 run_lib.py:146] step: 56600, eval_loss: 2.34210e-02
I0208 18:30:13.509852 22542570456896 run_lib.py:133] step: 56650, training_loss: 2.71550e-02
I0208 18:30:31.007675 22542570456896 run_lib.py:133] step: 56700, training_loss: 3.57507e-02
I0208 18:30:31.169238 22542570456896 run_lib.py:146] step: 56700, eval_loss: 3.26382e-02
I0208 18:30:48.571560 22542570456896 run_lib.py:133] step: 56750, training_loss: 2.52922e-02
I0208 18:31:06.014258 22542570456896 run_lib.py:133] step: 56800, training_loss: 2.90783e-02
I0208 18:31:06.170473 22542570456896 run_lib.py:146] step: 56800, eval_loss: 2.75910e-02
I0208 18:31:23.773732 22542570456896 run_lib.py:133] step: 56850, training_loss: 2.27867e-02
I0208 18:31:41.233618 22542570456896 run_lib.py:133] step: 56900, training_loss: 3.16076e-02
I0208 18:31:41.402287 22542570456896 run_lib.py:146] step: 56900, eval_loss: 3.07816e-02
I0208 18:31:58.876456 22542570456896 run_lib.py:133] step: 56950, training_loss: 3.24662e-02
I0208 18:32:16.374137 22542570456896 run_lib.py:133] step: 57000, training_loss: 2.97877e-02
I0208 18:32:16.528086 22542570456896 run_lib.py:146] step: 57000, eval_loss: 2.69382e-02
I0208 18:32:34.126174 22542570456896 run_lib.py:133] step: 57050, training_loss: 2.85655e-02
I0208 18:32:51.523634 22542570456896 run_lib.py:133] step: 57100, training_loss: 3.20758e-02
I0208 18:32:51.675422 22542570456896 run_lib.py:146] step: 57100, eval_loss: 3.05449e-02
I0208 18:33:09.225836 22542570456896 run_lib.py:133] step: 57150, training_loss: 3.13842e-02
I0208 18:33:26.694394 22542570456896 run_lib.py:133] step: 57200, training_loss: 2.65685e-02
I0208 18:33:26.869400 22542570456896 run_lib.py:146] step: 57200, eval_loss: 2.57190e-02
I0208 18:33:44.474925 22542570456896 run_lib.py:133] step: 57250, training_loss: 3.33476e-02
I0208 18:34:01.899900 22542570456896 run_lib.py:133] step: 57300, training_loss: 2.29880e-02
I0208 18:34:02.055618 22542570456896 run_lib.py:146] step: 57300, eval_loss: 2.78464e-02
I0208 18:34:19.460825 22542570456896 run_lib.py:133] step: 57350, training_loss: 3.05482e-02
I0208 18:34:37.009241 22542570456896 run_lib.py:133] step: 57400, training_loss: 3.60542e-02
I0208 18:34:37.164462 22542570456896 run_lib.py:146] step: 57400, eval_loss: 2.74988e-02
I0208 18:34:54.593034 22542570456896 run_lib.py:133] step: 57450, training_loss: 3.06069e-02
I0208 18:35:12.262151 22542570456896 run_lib.py:133] step: 57500, training_loss: 2.32956e-02
I0208 18:35:12.415443 22542570456896 run_lib.py:146] step: 57500, eval_loss: 4.01128e-02
I0208 18:35:29.853708 22542570456896 run_lib.py:133] step: 57550, training_loss: 3.39962e-02
I0208 18:35:47.268413 22542570456896 run_lib.py:133] step: 57600, training_loss: 3.53576e-02
I0208 18:35:47.423284 22542570456896 run_lib.py:146] step: 57600, eval_loss: 2.53335e-02
I0208 18:36:05.010407 22542570456896 run_lib.py:133] step: 57650, training_loss: 2.56691e-02
I0208 18:36:22.432342 22542570456896 run_lib.py:133] step: 57700, training_loss: 2.57649e-02
I0208 18:36:22.596531 22542570456896 run_lib.py:146] step: 57700, eval_loss: 3.11257e-02
I0208 18:36:40.032611 22542570456896 run_lib.py:133] step: 57750, training_loss: 2.84220e-02
I0208 18:36:57.602033 22542570456896 run_lib.py:133] step: 57800, training_loss: 3.50582e-02
I0208 18:36:57.768342 22542570456896 run_lib.py:146] step: 57800, eval_loss: 2.43545e-02
I0208 18:37:15.220089 22542570456896 run_lib.py:133] step: 57850, training_loss: 2.74775e-02
I0208 18:37:32.661516 22542570456896 run_lib.py:133] step: 57900, training_loss: 3.20717e-02
I0208 18:37:32.817495 22542570456896 run_lib.py:146] step: 57900, eval_loss: 2.50064e-02
I0208 18:37:50.362501 22542570456896 run_lib.py:133] step: 57950, training_loss: 3.06457e-02
I0208 18:38:07.792520 22542570456896 run_lib.py:133] step: 58000, training_loss: 2.97726e-02
I0208 18:38:07.951241 22542570456896 run_lib.py:146] step: 58000, eval_loss: 2.84865e-02
I0208 18:38:25.355656 22542570456896 run_lib.py:133] step: 58050, training_loss: 2.93745e-02
I0208 18:38:42.768970 22542570456896 run_lib.py:133] step: 58100, training_loss: 2.61518e-02
I0208 18:38:42.941879 22542570456896 run_lib.py:146] step: 58100, eval_loss: 3.08736e-02
I0208 18:39:00.568318 22542570456896 run_lib.py:133] step: 58150, training_loss: 3.55112e-02
I0208 18:39:18.110927 22542570456896 run_lib.py:133] step: 58200, training_loss: 3.25231e-02
I0208 18:39:18.280284 22542570456896 run_lib.py:146] step: 58200, eval_loss: 2.24151e-02
I0208 18:39:35.662519 22542570456896 run_lib.py:133] step: 58250, training_loss: 2.46453e-02
I0208 18:39:53.088688 22542570456896 run_lib.py:133] step: 58300, training_loss: 3.30315e-02
I0208 18:39:53.244439 22542570456896 run_lib.py:146] step: 58300, eval_loss: 2.50686e-02
I0208 18:40:10.796583 22542570456896 run_lib.py:133] step: 58350, training_loss: 2.77066e-02
I0208 18:40:28.265101 22542570456896 run_lib.py:133] step: 58400, training_loss: 3.07551e-02
I0208 18:40:28.420452 22542570456896 run_lib.py:146] step: 58400, eval_loss: 2.72936e-02
I0208 18:40:46.020363 22542570456896 run_lib.py:133] step: 58450, training_loss: 2.24383e-02
I0208 18:41:03.453451 22542570456896 run_lib.py:133] step: 58500, training_loss: 2.69860e-02
I0208 18:41:03.611017 22542570456896 run_lib.py:146] step: 58500, eval_loss: 3.17491e-02
I0208 18:41:21.211691 22542570456896 run_lib.py:133] step: 58550, training_loss: 2.66141e-02
I0208 18:41:38.670009 22542570456896 run_lib.py:133] step: 58600, training_loss: 3.02220e-02
I0208 18:41:38.828577 22542570456896 run_lib.py:146] step: 58600, eval_loss: 2.95557e-02
I0208 18:41:56.368236 22542570456896 run_lib.py:133] step: 58650, training_loss: 2.97210e-02
I0208 18:42:13.829372 22542570456896 run_lib.py:133] step: 58700, training_loss: 3.09269e-02
I0208 18:42:13.996264 22542570456896 run_lib.py:146] step: 58700, eval_loss: 2.97149e-02
I0208 18:42:31.445058 22542570456896 run_lib.py:133] step: 58750, training_loss: 3.08886e-02
I0208 18:42:49.065991 22542570456896 run_lib.py:133] step: 58800, training_loss: 3.40599e-02
I0208 18:42:49.225346 22542570456896 run_lib.py:146] step: 58800, eval_loss: 3.10813e-02
I0208 18:43:06.657455 22542570456896 run_lib.py:133] step: 58850, training_loss: 3.54624e-02
I0208 18:43:24.071936 22542570456896 run_lib.py:133] step: 58900, training_loss: 2.48370e-02
I0208 18:43:24.227066 22542570456896 run_lib.py:146] step: 58900, eval_loss: 2.98802e-02
I0208 18:43:41.815992 22542570456896 run_lib.py:133] step: 58950, training_loss: 2.55435e-02
I0208 18:43:59.272017 22542570456896 run_lib.py:133] step: 59000, training_loss: 2.64350e-02
I0208 18:43:59.430613 22542570456896 run_lib.py:146] step: 59000, eval_loss: 2.68906e-02
I0208 18:44:17.050863 22542570456896 run_lib.py:133] step: 59050, training_loss: 2.80085e-02
I0208 18:44:34.506089 22542570456896 run_lib.py:133] step: 59100, training_loss: 2.31710e-02
I0208 18:44:34.664247 22542570456896 run_lib.py:146] step: 59100, eval_loss: 3.14140e-02
I0208 18:44:52.064730 22542570456896 run_lib.py:133] step: 59150, training_loss: 2.71656e-02
I0208 18:45:09.541904 22542570456896 run_lib.py:133] step: 59200, training_loss: 3.22164e-02
I0208 18:45:09.695787 22542570456896 run_lib.py:146] step: 59200, eval_loss: 3.08228e-02
I0208 18:45:27.079595 22542570456896 run_lib.py:133] step: 59250, training_loss: 2.81799e-02
I0208 18:45:44.449321 22542570456896 run_lib.py:133] step: 59300, training_loss: 2.85028e-02
I0208 18:45:44.607640 22542570456896 run_lib.py:146] step: 59300, eval_loss: 2.21438e-02
I0208 18:46:02.005257 22542570456896 run_lib.py:133] step: 59350, training_loss: 3.05583e-02
I0208 18:46:19.605643 22542570456896 run_lib.py:133] step: 59400, training_loss: 3.33552e-02
I0208 18:46:19.758270 22542570456896 run_lib.py:146] step: 59400, eval_loss: 2.33487e-02
I0208 18:46:37.178788 22542570456896 run_lib.py:133] step: 59450, training_loss: 3.29562e-02
I0208 18:46:54.668685 22542570456896 run_lib.py:133] step: 59500, training_loss: 2.77675e-02
I0208 18:46:54.823641 22542570456896 run_lib.py:146] step: 59500, eval_loss: 2.44908e-02
I0208 18:47:12.298947 22542570456896 run_lib.py:133] step: 59550, training_loss: 3.05560e-02
I0208 18:47:29.770202 22542570456896 run_lib.py:133] step: 59600, training_loss: 2.69196e-02
I0208 18:47:29.930424 22542570456896 run_lib.py:146] step: 59600, eval_loss: 2.79251e-02
I0208 18:47:47.526789 22542570456896 run_lib.py:133] step: 59650, training_loss: 2.53731e-02
I0208 18:48:05.003355 22542570456896 run_lib.py:133] step: 59700, training_loss: 2.57071e-02
I0208 18:48:05.159312 22542570456896 run_lib.py:146] step: 59700, eval_loss: 2.64200e-02
I0208 18:48:22.626200 22542570456896 run_lib.py:133] step: 59750, training_loss: 2.89455e-02
I0208 18:48:40.033746 22542570456896 run_lib.py:133] step: 59800, training_loss: 2.76504e-02
I0208 18:48:40.194339 22542570456896 run_lib.py:146] step: 59800, eval_loss: 3.50242e-02
I0208 18:48:57.811583 22542570456896 run_lib.py:133] step: 59850, training_loss: 2.32238e-02
I0208 18:49:15.278756 22542570456896 run_lib.py:133] step: 59900, training_loss: 2.67063e-02
I0208 18:49:15.432839 22542570456896 run_lib.py:146] step: 59900, eval_loss: 3.53800e-02
I0208 18:49:33.049140 22542570456896 run_lib.py:133] step: 59950, training_loss: 3.00901e-02
I0208 18:49:50.469067 22542570456896 run_lib.py:133] step: 60000, training_loss: 3.62954e-02
I0208 18:49:51.168140 22542570456896 run_lib.py:146] step: 60000, eval_loss: 2.97753e-02
I0208 18:50:11.348218 22542570456896 run_lib.py:133] step: 60050, training_loss: 2.91256e-02
I0208 18:50:28.770195 22542570456896 run_lib.py:133] step: 60100, training_loss: 2.76772e-02
I0208 18:50:28.941638 22542570456896 run_lib.py:146] step: 60100, eval_loss: 3.08609e-02
I0208 18:50:46.514381 22542570456896 run_lib.py:133] step: 60150, training_loss: 3.81318e-02
I0208 18:51:03.980051 22542570456896 run_lib.py:133] step: 60200, training_loss: 2.59973e-02
I0208 18:51:04.136615 22542570456896 run_lib.py:146] step: 60200, eval_loss: 3.16776e-02
I0208 18:51:21.588563 22542570456896 run_lib.py:133] step: 60250, training_loss: 2.87107e-02
I0208 18:51:39.013362 22542570456896 run_lib.py:133] step: 60300, training_loss: 3.34189e-02
I0208 18:51:39.168368 22542570456896 run_lib.py:146] step: 60300, eval_loss: 2.56854e-02
I0208 18:51:56.749839 22542570456896 run_lib.py:133] step: 60350, training_loss: 3.08652e-02
I0208 18:52:14.309723 22542570456896 run_lib.py:133] step: 60400, training_loss: 3.24400e-02
I0208 18:52:14.472161 22542570456896 run_lib.py:146] step: 60400, eval_loss: 3.13203e-02
I0208 18:52:31.935242 22542570456896 run_lib.py:133] step: 60450, training_loss: 2.79493e-02
I0208 18:52:49.346158 22542570456896 run_lib.py:133] step: 60500, training_loss: 2.80099e-02
I0208 18:52:49.510284 22542570456896 run_lib.py:146] step: 60500, eval_loss: 2.69344e-02
I0208 18:53:07.036256 22542570456896 run_lib.py:133] step: 60550, training_loss: 2.69310e-02
I0208 18:53:24.460854 22542570456896 run_lib.py:133] step: 60600, training_loss: 2.59921e-02
I0208 18:53:24.626282 22542570456896 run_lib.py:146] step: 60600, eval_loss: 3.28923e-02
I0208 18:53:42.240586 22542570456896 run_lib.py:133] step: 60650, training_loss: 2.76630e-02
I0208 18:53:59.691008 22542570456896 run_lib.py:133] step: 60700, training_loss: 2.45724e-02
I0208 18:53:59.846459 22542570456896 run_lib.py:146] step: 60700, eval_loss: 3.14894e-02
I0208 18:54:17.437901 22542570456896 run_lib.py:133] step: 60750, training_loss: 3.22484e-02
I0208 18:54:34.850250 22542570456896 run_lib.py:133] step: 60800, training_loss: 2.33537e-02
I0208 18:54:35.006638 22542570456896 run_lib.py:146] step: 60800, eval_loss: 3.38578e-02
I0208 18:54:52.447869 22542570456896 run_lib.py:133] step: 60850, training_loss: 2.65032e-02
I0208 18:55:10.057719 22542570456896 run_lib.py:133] step: 60900, training_loss: 3.32306e-02
I0208 18:55:10.211588 22542570456896 run_lib.py:146] step: 60900, eval_loss: 2.64163e-02
I0208 18:55:27.690208 22542570456896 run_lib.py:133] step: 60950, training_loss: 2.62427e-02
I0208 18:55:45.294376 22542570456896 run_lib.py:133] step: 61000, training_loss: 2.99783e-02
I0208 18:55:45.447866 22542570456896 run_lib.py:146] step: 61000, eval_loss: 3.83025e-02
I0208 18:56:02.852924 22542570456896 run_lib.py:133] step: 61050, training_loss: 2.22554e-02
I0208 18:56:20.285464 22542570456896 run_lib.py:133] step: 61100, training_loss: 2.75067e-02
I0208 18:56:20.444742 22542570456896 run_lib.py:146] step: 61100, eval_loss: 3.33805e-02
I0208 18:56:38.019851 22542570456896 run_lib.py:133] step: 61150, training_loss: 3.82535e-02
I0208 18:56:55.478523 22542570456896 run_lib.py:133] step: 61200, training_loss: 3.59092e-02
I0208 18:56:55.634350 22542570456896 run_lib.py:146] step: 61200, eval_loss: 2.70731e-02
I0208 18:57:13.056407 22542570456896 run_lib.py:133] step: 61250, training_loss: 3.19220e-02
I0208 18:57:30.686512 22542570456896 run_lib.py:133] step: 61300, training_loss: 3.29990e-02
I0208 18:57:30.841298 22542570456896 run_lib.py:146] step: 61300, eval_loss: 3.33584e-02
I0208 18:57:48.269553 22542570456896 run_lib.py:133] step: 61350, training_loss: 2.31025e-02
I0208 18:58:05.693904 22542570456896 run_lib.py:133] step: 61400, training_loss: 3.05476e-02
I0208 18:58:05.991333 22542570456896 run_lib.py:146] step: 61400, eval_loss: 3.40130e-02
I0208 18:58:23.410582 22542570456896 run_lib.py:133] step: 61450, training_loss: 2.55570e-02
I0208 18:58:40.831565 22542570456896 run_lib.py:133] step: 61500, training_loss: 2.23567e-02
I0208 18:58:41.000398 22542570456896 run_lib.py:146] step: 61500, eval_loss: 2.84952e-02
I0208 18:58:58.505450 22542570456896 run_lib.py:133] step: 61550, training_loss: 2.22524e-02
I0208 18:59:15.973528 22542570456896 run_lib.py:133] step: 61600, training_loss: 3.53526e-02
I0208 18:59:16.130463 22542570456896 run_lib.py:146] step: 61600, eval_loss: 3.15735e-02
I0208 18:59:33.725067 22542570456896 run_lib.py:133] step: 61650, training_loss: 2.63956e-02
I0208 18:59:51.209412 22542570456896 run_lib.py:133] step: 61700, training_loss: 2.86283e-02
I0208 18:59:51.372470 22542570456896 run_lib.py:146] step: 61700, eval_loss: 3.23980e-02
I0208 19:00:08.807690 22542570456896 run_lib.py:133] step: 61750, training_loss: 3.61901e-02
I0208 19:00:26.261790 22542570456896 run_lib.py:133] step: 61800, training_loss: 3.23018e-02
I0208 19:00:26.417675 22542570456896 run_lib.py:146] step: 61800, eval_loss: 2.72602e-02
I0208 19:00:44.064758 22542570456896 run_lib.py:133] step: 61850, training_loss: 3.37457e-02
I0208 19:01:01.576482 22542570456896 run_lib.py:133] step: 61900, training_loss: 2.98324e-02
I0208 19:01:01.729390 22542570456896 run_lib.py:146] step: 61900, eval_loss: 3.17307e-02
I0208 19:01:19.143340 22542570456896 run_lib.py:133] step: 61950, training_loss: 2.75066e-02
I0208 19:01:36.554244 22542570456896 run_lib.py:133] step: 62000, training_loss: 3.12470e-02
I0208 19:01:36.713530 22542570456896 run_lib.py:146] step: 62000, eval_loss: 3.26576e-02
I0208 19:01:54.306150 22542570456896 run_lib.py:133] step: 62050, training_loss: 3.05194e-02
I0208 19:02:11.781392 22542570456896 run_lib.py:133] step: 62100, training_loss: 2.51434e-02
I0208 19:02:11.938635 22542570456896 run_lib.py:146] step: 62100, eval_loss: 3.07865e-02
I0208 19:02:29.535658 22542570456896 run_lib.py:133] step: 62150, training_loss: 3.46706e-02
I0208 19:02:46.965116 22542570456896 run_lib.py:133] step: 62200, training_loss: 2.59452e-02
I0208 19:02:47.121967 22542570456896 run_lib.py:146] step: 62200, eval_loss: 2.63038e-02
I0208 19:03:04.687238 22542570456896 run_lib.py:133] step: 62250, training_loss: 3.24039e-02
I0208 19:03:22.173918 22542570456896 run_lib.py:133] step: 62300, training_loss: 2.47455e-02
I0208 19:03:22.331629 22542570456896 run_lib.py:146] step: 62300, eval_loss: 3.32397e-02
I0208 19:03:39.805504 22542570456896 run_lib.py:133] step: 62350, training_loss: 2.57502e-02
I0208 19:03:57.436598 22542570456896 run_lib.py:133] step: 62400, training_loss: 2.49452e-02
I0208 19:03:57.591495 22542570456896 run_lib.py:146] step: 62400, eval_loss: 2.24661e-02
I0208 19:04:15.007437 22542570456896 run_lib.py:133] step: 62450, training_loss: 2.82103e-02
I0208 19:04:32.571050 22542570456896 run_lib.py:133] step: 62500, training_loss: 3.63363e-02
I0208 19:04:32.729487 22542570456896 run_lib.py:146] step: 62500, eval_loss: 2.60783e-02
I0208 19:04:50.208966 22542570456896 run_lib.py:133] step: 62550, training_loss: 3.15585e-02
I0208 19:05:07.681493 22542570456896 run_lib.py:133] step: 62600, training_loss: 2.95489e-02
I0208 19:05:07.837553 22542570456896 run_lib.py:146] step: 62600, eval_loss: 2.63387e-02
I0208 19:05:25.464891 22542570456896 run_lib.py:133] step: 62650, training_loss: 3.44580e-02
I0208 19:05:42.876029 22542570456896 run_lib.py:133] step: 62700, training_loss: 2.66700e-02
I0208 19:05:43.034004 22542570456896 run_lib.py:146] step: 62700, eval_loss: 3.13505e-02
I0208 19:06:00.432854 22542570456896 run_lib.py:133] step: 62750, training_loss: 2.80603e-02
I0208 19:06:17.868441 22542570456896 run_lib.py:133] step: 62800, training_loss: 3.26663e-02
I0208 19:06:18.019464 22542570456896 run_lib.py:146] step: 62800, eval_loss: 3.17748e-02
I0208 19:06:35.634994 22542570456896 run_lib.py:133] step: 62850, training_loss: 2.87491e-02
I0208 19:06:53.068662 22542570456896 run_lib.py:133] step: 62900, training_loss: 2.72671e-02
I0208 19:06:53.234793 22542570456896 run_lib.py:146] step: 62900, eval_loss: 3.76411e-02
I0208 19:07:10.761916 22542570456896 run_lib.py:133] step: 62950, training_loss: 2.74606e-02
I0208 19:07:28.200281 22542570456896 run_lib.py:133] step: 63000, training_loss: 3.08034e-02
I0208 19:07:28.357752 22542570456896 run_lib.py:146] step: 63000, eval_loss: 2.95931e-02
I0208 19:07:45.786417 22542570456896 run_lib.py:133] step: 63050, training_loss: 3.35824e-02
I0208 19:08:03.213432 22542570456896 run_lib.py:133] step: 63100, training_loss: 3.68180e-02
I0208 19:08:03.376713 22542570456896 run_lib.py:146] step: 63100, eval_loss: 2.37082e-02
I0208 19:08:20.979611 22542570456896 run_lib.py:133] step: 63150, training_loss: 3.07255e-02
I0208 19:08:38.550709 22542570456896 run_lib.py:133] step: 63200, training_loss: 2.63693e-02
I0208 19:08:38.706690 22542570456896 run_lib.py:146] step: 63200, eval_loss: 3.41469e-02
I0208 19:08:56.139514 22542570456896 run_lib.py:133] step: 63250, training_loss: 2.16482e-02
I0208 19:09:13.546090 22542570456896 run_lib.py:133] step: 63300, training_loss: 3.20217e-02
I0208 19:09:13.696610 22542570456896 run_lib.py:146] step: 63300, eval_loss: 2.46415e-02
I0208 19:09:31.259735 22542570456896 run_lib.py:133] step: 63350, training_loss: 3.54140e-02
I0208 19:09:48.731362 22542570456896 run_lib.py:133] step: 63400, training_loss: 2.53314e-02
I0208 19:09:48.899083 22542570456896 run_lib.py:146] step: 63400, eval_loss: 2.72657e-02
I0208 19:10:06.520889 22542570456896 run_lib.py:133] step: 63450, training_loss: 2.60562e-02
I0208 19:10:23.992640 22542570456896 run_lib.py:133] step: 63500, training_loss: 2.78810e-02
I0208 19:10:24.148507 22542570456896 run_lib.py:146] step: 63500, eval_loss: 2.67023e-02
I0208 19:10:41.742480 22542570456896 run_lib.py:133] step: 63550, training_loss: 3.09374e-02
I0208 19:10:59.162129 22542570456896 run_lib.py:133] step: 63600, training_loss: 2.96038e-02
I0208 19:10:59.317224 22542570456896 run_lib.py:146] step: 63600, eval_loss: 2.33455e-02
I0208 19:11:16.892287 22542570456896 run_lib.py:133] step: 63650, training_loss: 3.03462e-02
I0208 19:11:34.321998 22542570456896 run_lib.py:133] step: 63700, training_loss: 3.09018e-02
I0208 19:11:34.473536 22542570456896 run_lib.py:146] step: 63700, eval_loss: 2.36482e-02
I0208 19:11:51.963599 22542570456896 run_lib.py:133] step: 63750, training_loss: 2.94811e-02
I0208 19:12:09.575375 22542570456896 run_lib.py:133] step: 63800, training_loss: 3.41110e-02
I0208 19:12:09.735878 22542570456896 run_lib.py:146] step: 63800, eval_loss: 2.50653e-02
I0208 19:12:27.133461 22542570456896 run_lib.py:133] step: 63850, training_loss: 3.89533e-02
I0208 19:12:44.535896 22542570456896 run_lib.py:133] step: 63900, training_loss: 3.39032e-02
I0208 19:12:44.694225 22542570456896 run_lib.py:146] step: 63900, eval_loss: 3.15974e-02
I0208 19:13:02.223526 22542570456896 run_lib.py:133] step: 63950, training_loss: 2.91699e-02
I0208 19:13:19.852869 22542570456896 run_lib.py:133] step: 64000, training_loss: 2.88975e-02
I0208 19:13:20.013574 22542570456896 run_lib.py:146] step: 64000, eval_loss: 2.39751e-02
I0208 19:13:37.479789 22542570456896 run_lib.py:133] step: 64050, training_loss: 3.18078e-02
I0208 19:13:54.906590 22542570456896 run_lib.py:133] step: 64100, training_loss: 2.51189e-02
I0208 19:13:55.062114 22542570456896 run_lib.py:146] step: 64100, eval_loss: 2.45061e-02
I0208 19:14:12.478673 22542570456896 run_lib.py:133] step: 64150, training_loss: 2.47274e-02
I0208 19:14:30.093809 22542570456896 run_lib.py:133] step: 64200, training_loss: 2.95767e-02
I0208 19:14:30.245109 22542570456896 run_lib.py:146] step: 64200, eval_loss: 2.72096e-02
I0208 19:14:47.663039 22542570456896 run_lib.py:133] step: 64250, training_loss: 2.54353e-02
I0208 19:15:05.115189 22542570456896 run_lib.py:133] step: 64300, training_loss: 2.31747e-02
I0208 19:15:05.282627 22542570456896 run_lib.py:146] step: 64300, eval_loss: 3.36094e-02
I0208 19:15:22.696877 22542570456896 run_lib.py:133] step: 64350, training_loss: 3.01103e-02
I0208 19:15:40.341993 22542570456896 run_lib.py:133] step: 64400, training_loss: 2.16030e-02
I0208 19:15:40.500559 22542570456896 run_lib.py:146] step: 64400, eval_loss: 3.03227e-02
I0208 19:15:57.912814 22542570456896 run_lib.py:133] step: 64450, training_loss: 2.97687e-02
I0208 19:16:15.373929 22542570456896 run_lib.py:133] step: 64500, training_loss: 2.96293e-02
I0208 19:16:15.547350 22542570456896 run_lib.py:146] step: 64500, eval_loss: 2.67988e-02
I0208 19:16:32.970588 22542570456896 run_lib.py:133] step: 64550, training_loss: 2.31637e-02
I0208 19:16:50.448327 22542570456896 run_lib.py:133] step: 64600, training_loss: 3.01165e-02
I0208 19:16:50.611967 22542570456896 run_lib.py:146] step: 64600, eval_loss: 2.59926e-02
I0208 19:17:08.243424 22542570456896 run_lib.py:133] step: 64650, training_loss: 2.73445e-02
I0208 19:17:25.757310 22542570456896 run_lib.py:133] step: 64700, training_loss: 3.15543e-02
I0208 19:17:25.911314 22542570456896 run_lib.py:146] step: 64700, eval_loss: 3.21085e-02
I0208 19:17:43.321600 22542570456896 run_lib.py:133] step: 64750, training_loss: 2.20153e-02
I0208 19:18:00.734274 22542570456896 run_lib.py:133] step: 64800, training_loss: 2.89598e-02
I0208 19:18:00.911323 22542570456896 run_lib.py:146] step: 64800, eval_loss: 2.01793e-02
I0208 19:18:18.569289 22542570456896 run_lib.py:133] step: 64850, training_loss: 2.75576e-02
I0208 19:18:35.993767 22542570456896 run_lib.py:133] step: 64900, training_loss: 2.98560e-02
I0208 19:18:36.151503 22542570456896 run_lib.py:146] step: 64900, eval_loss: 3.58146e-02
I0208 19:18:53.716983 22542570456896 run_lib.py:133] step: 64950, training_loss: 3.57939e-02
I0208 19:19:11.125257 22542570456896 run_lib.py:133] step: 65000, training_loss: 2.79282e-02
I0208 19:19:11.281350 22542570456896 run_lib.py:146] step: 65000, eval_loss: 2.41778e-02
I0208 19:19:28.863715 22542570456896 run_lib.py:133] step: 65050, training_loss: 3.08267e-02
I0208 19:19:46.337864 22542570456896 run_lib.py:133] step: 65100, training_loss: 2.80159e-02
I0208 19:19:46.499800 22542570456896 run_lib.py:146] step: 65100, eval_loss: 3.22815e-02
I0208 19:20:03.960599 22542570456896 run_lib.py:133] step: 65150, training_loss: 3.17813e-02
I0208 19:20:21.579590 22542570456896 run_lib.py:133] step: 65200, training_loss: 2.62165e-02
I0208 19:20:21.736369 22542570456896 run_lib.py:146] step: 65200, eval_loss: 2.96499e-02
I0208 19:20:39.173730 22542570456896 run_lib.py:133] step: 65250, training_loss: 2.87271e-02
I0208 19:20:56.730841 22542570456896 run_lib.py:133] step: 65300, training_loss: 2.85602e-02
I0208 19:20:56.888124 22542570456896 run_lib.py:146] step: 65300, eval_loss: 3.12919e-02
I0208 19:21:14.316796 22542570456896 run_lib.py:133] step: 65350, training_loss: 3.34062e-02
I0208 19:21:31.810689 22542570456896 run_lib.py:133] step: 65400, training_loss: 3.36320e-02
I0208 19:21:31.968318 22542570456896 run_lib.py:146] step: 65400, eval_loss: 2.47401e-02
I0208 19:21:49.556754 22542570456896 run_lib.py:133] step: 65450, training_loss: 2.82145e-02
I0208 19:22:06.950272 22542570456896 run_lib.py:133] step: 65500, training_loss: 2.61990e-02
I0208 19:22:07.106492 22542570456896 run_lib.py:146] step: 65500, eval_loss: 3.04552e-02
I0208 19:22:24.530340 22542570456896 run_lib.py:133] step: 65550, training_loss: 2.56393e-02
I0208 19:22:42.093540 22542570456896 run_lib.py:133] step: 65600, training_loss: 3.31753e-02
I0208 19:22:42.247489 22542570456896 run_lib.py:146] step: 65600, eval_loss: 3.28467e-02
I0208 19:22:59.686032 22542570456896 run_lib.py:133] step: 65650, training_loss: 2.94407e-02
I0208 19:23:17.132509 22542570456896 run_lib.py:133] step: 65700, training_loss: 2.99489e-02
I0208 19:23:17.291573 22542570456896 run_lib.py:146] step: 65700, eval_loss: 2.55234e-02
I0208 19:23:34.820536 22542570456896 run_lib.py:133] step: 65750, training_loss: 3.24652e-02
I0208 19:23:52.291620 22542570456896 run_lib.py:133] step: 65800, training_loss: 2.87235e-02
I0208 19:23:52.451494 22542570456896 run_lib.py:146] step: 65800, eval_loss: 3.86934e-02
I0208 19:24:09.858167 22542570456896 run_lib.py:133] step: 65850, training_loss: 3.48894e-02
I0208 19:24:27.258952 22542570456896 run_lib.py:133] step: 65900, training_loss: 3.10669e-02
I0208 19:24:27.429229 22542570456896 run_lib.py:146] step: 65900, eval_loss: 2.61891e-02
I0208 19:24:45.023877 22542570456896 run_lib.py:133] step: 65950, training_loss: 3.32556e-02
I0208 19:25:02.576106 22542570456896 run_lib.py:133] step: 66000, training_loss: 3.25764e-02
I0208 19:25:02.736216 22542570456896 run_lib.py:146] step: 66000, eval_loss: 2.85940e-02
I0208 19:25:20.177385 22542570456896 run_lib.py:133] step: 66050, training_loss: 2.82597e-02
I0208 19:25:37.612100 22542570456896 run_lib.py:133] step: 66100, training_loss: 3.08401e-02
I0208 19:25:37.767258 22542570456896 run_lib.py:146] step: 66100, eval_loss: 2.91251e-02
I0208 19:25:55.328515 22542570456896 run_lib.py:133] step: 66150, training_loss: 2.20057e-02
I0208 19:26:12.769896 22542570456896 run_lib.py:133] step: 66200, training_loss: 2.92245e-02
I0208 19:26:12.939529 22542570456896 run_lib.py:146] step: 66200, eval_loss: 2.21185e-02
I0208 19:26:30.563349 22542570456896 run_lib.py:133] step: 66250, training_loss: 2.57067e-02
I0208 19:26:48.031734 22542570456896 run_lib.py:133] step: 66300, training_loss: 2.56719e-02
I0208 19:26:48.192323 22542570456896 run_lib.py:146] step: 66300, eval_loss: 3.55814e-02
I0208 19:27:05.801435 22542570456896 run_lib.py:133] step: 66350, training_loss: 2.56720e-02
I0208 19:27:23.212812 22542570456896 run_lib.py:133] step: 66400, training_loss: 3.45223e-02
I0208 19:27:23.368350 22542570456896 run_lib.py:146] step: 66400, eval_loss: 3.26357e-02
I0208 19:27:40.927323 22542570456896 run_lib.py:133] step: 66450, training_loss: 2.81846e-02
I0208 19:27:58.396373 22542570456896 run_lib.py:133] step: 66500, training_loss: 2.99311e-02
I0208 19:27:58.553704 22542570456896 run_lib.py:146] step: 66500, eval_loss: 2.66746e-02
I0208 19:28:16.022030 22542570456896 run_lib.py:133] step: 66550, training_loss: 2.96648e-02
I0208 19:28:33.674509 22542570456896 run_lib.py:133] step: 66600, training_loss: 2.79401e-02
I0208 19:28:33.831343 22542570456896 run_lib.py:146] step: 66600, eval_loss: 2.66959e-02
I0208 19:28:51.304181 22542570456896 run_lib.py:133] step: 66650, training_loss: 2.70460e-02
I0208 19:29:08.742097 22542570456896 run_lib.py:133] step: 66700, training_loss: 2.56898e-02
I0208 19:29:08.898448 22542570456896 run_lib.py:146] step: 66700, eval_loss: 3.17619e-02
I0208 19:29:26.481091 22542570456896 run_lib.py:133] step: 66750, training_loss: 2.81474e-02
I0208 19:29:43.955963 22542570456896 run_lib.py:133] step: 66800, training_loss: 3.12724e-02
I0208 19:29:44.119220 22542570456896 run_lib.py:146] step: 66800, eval_loss: 2.56664e-02
I0208 19:30:01.794145 22542570456896 run_lib.py:133] step: 66850, training_loss: 3.14423e-02
I0208 19:30:19.236052 22542570456896 run_lib.py:133] step: 66900, training_loss: 3.10825e-02
I0208 19:30:19.393421 22542570456896 run_lib.py:146] step: 66900, eval_loss: 2.76239e-02
I0208 19:30:36.832818 22542570456896 run_lib.py:133] step: 66950, training_loss: 2.87578e-02
I0208 19:30:54.399053 22542570456896 run_lib.py:133] step: 67000, training_loss: 2.84998e-02
I0208 19:30:54.556368 22542570456896 run_lib.py:146] step: 67000, eval_loss: 2.84909e-02
I0208 19:31:11.987103 22542570456896 run_lib.py:133] step: 67050, training_loss: 3.60449e-02
I0208 19:31:29.435328 22542570456896 run_lib.py:133] step: 67100, training_loss: 3.04440e-02
I0208 19:31:29.589990 22542570456896 run_lib.py:146] step: 67100, eval_loss: 2.59449e-02
I0208 19:31:47.068657 22542570456896 run_lib.py:133] step: 67150, training_loss: 2.30194e-02
I0208 19:32:04.708114 22542570456896 run_lib.py:133] step: 67200, training_loss: 3.28204e-02
I0208 19:32:04.867524 22542570456896 run_lib.py:146] step: 67200, eval_loss: 2.73036e-02
I0208 19:32:22.268628 22542570456896 run_lib.py:133] step: 67250, training_loss: 2.75903e-02
I0208 19:32:39.768770 22542570456896 run_lib.py:133] step: 67300, training_loss: 3.14788e-02
I0208 19:32:39.941649 22542570456896 run_lib.py:146] step: 67300, eval_loss: 3.47926e-02
I0208 19:32:57.419411 22542570456896 run_lib.py:133] step: 67350, training_loss: 2.31478e-02
I0208 19:33:14.837569 22542570456896 run_lib.py:133] step: 67400, training_loss: 3.46763e-02
I0208 19:33:14.998112 22542570456896 run_lib.py:146] step: 67400, eval_loss: 3.06275e-02
I0208 19:33:32.586702 22542570456896 run_lib.py:133] step: 67450, training_loss: 2.30721e-02
I0208 19:33:50.048250 22542570456896 run_lib.py:133] step: 67500, training_loss: 2.82780e-02
I0208 19:33:50.202065 22542570456896 run_lib.py:146] step: 67500, eval_loss: 3.80622e-02
I0208 19:34:07.672325 22542570456896 run_lib.py:133] step: 67550, training_loss: 2.68564e-02
I0208 19:34:25.165362 22542570456896 run_lib.py:133] step: 67600, training_loss: 2.59334e-02
I0208 19:34:25.322497 22542570456896 run_lib.py:146] step: 67600, eval_loss: 4.14884e-02
I0208 19:34:42.967607 22542570456896 run_lib.py:133] step: 67650, training_loss: 2.26474e-02
I0208 19:35:00.415039 22542570456896 run_lib.py:133] step: 67700, training_loss: 3.44918e-02
I0208 19:35:00.571437 22542570456896 run_lib.py:146] step: 67700, eval_loss: 2.61938e-02
I0208 19:35:18.133436 22542570456896 run_lib.py:133] step: 67750, training_loss: 3.08684e-02
I0208 19:35:35.595211 22542570456896 run_lib.py:133] step: 67800, training_loss: 3.53709e-02
I0208 19:35:35.750306 22542570456896 run_lib.py:146] step: 67800, eval_loss: 2.98912e-02
I0208 19:35:53.313740 22542570456896 run_lib.py:133] step: 67850, training_loss: 2.71210e-02
I0208 19:36:10.855878 22542570456896 run_lib.py:133] step: 67900, training_loss: 2.34809e-02
I0208 19:36:11.014167 22542570456896 run_lib.py:146] step: 67900, eval_loss: 2.27336e-02
I0208 19:36:28.462995 22542570456896 run_lib.py:133] step: 67950, training_loss: 3.82295e-02
I0208 19:36:46.100560 22542570456896 run_lib.py:133] step: 68000, training_loss: 2.93570e-02
I0208 19:36:46.253375 22542570456896 run_lib.py:146] step: 68000, eval_loss: 3.17730e-02
I0208 19:37:03.669210 22542570456896 run_lib.py:133] step: 68050, training_loss: 2.20313e-02
I0208 19:37:21.225172 22542570456896 run_lib.py:133] step: 68100, training_loss: 3.51390e-02
I0208 19:37:21.392536 22542570456896 run_lib.py:146] step: 68100, eval_loss: 3.23989e-02
I0208 19:37:38.868948 22542570456896 run_lib.py:133] step: 68150, training_loss: 3.52411e-02
I0208 19:37:56.341154 22542570456896 run_lib.py:133] step: 68200, training_loss: 2.47993e-02
I0208 19:37:56.501439 22542570456896 run_lib.py:146] step: 68200, eval_loss: 2.80346e-02
I0208 19:38:14.108569 22542570456896 run_lib.py:133] step: 68250, training_loss: 3.19938e-02
I0208 19:38:31.548085 22542570456896 run_lib.py:133] step: 68300, training_loss: 2.91820e-02
I0208 19:38:31.704346 22542570456896 run_lib.py:146] step: 68300, eval_loss: 2.73538e-02
I0208 19:38:49.134433 22542570456896 run_lib.py:133] step: 68350, training_loss: 2.29957e-02
I0208 19:39:06.707553 22542570456896 run_lib.py:133] step: 68400, training_loss: 2.30380e-02
I0208 19:39:06.869209 22542570456896 run_lib.py:146] step: 68400, eval_loss: 2.10526e-02
I0208 19:39:24.348701 22542570456896 run_lib.py:133] step: 68450, training_loss: 2.65804e-02
I0208 19:39:41.758898 22542570456896 run_lib.py:133] step: 68500, training_loss: 3.42659e-02
I0208 19:39:42.096349 22542570456896 run_lib.py:146] step: 68500, eval_loss: 2.64444e-02
I0208 19:39:59.540139 22542570456896 run_lib.py:133] step: 68550, training_loss: 2.61998e-02
I0208 19:40:16.975595 22542570456896 run_lib.py:133] step: 68600, training_loss: 2.63054e-02
I0208 19:40:17.129381 22542570456896 run_lib.py:146] step: 68600, eval_loss: 2.70124e-02
I0208 19:40:34.565885 22542570456896 run_lib.py:133] step: 68650, training_loss: 2.55949e-02
I0208 19:40:52.044207 22542570456896 run_lib.py:133] step: 68700, training_loss: 2.34100e-02
I0208 19:40:52.205199 22542570456896 run_lib.py:146] step: 68700, eval_loss: 2.24553e-02
I0208 19:41:09.810864 22542570456896 run_lib.py:133] step: 68750, training_loss: 3.39405e-02
I0208 19:41:27.294372 22542570456896 run_lib.py:133] step: 68800, training_loss: 3.01746e-02
I0208 19:41:27.453266 22542570456896 run_lib.py:146] step: 68800, eval_loss: 2.66922e-02
I0208 19:41:44.865199 22542570456896 run_lib.py:133] step: 68850, training_loss: 2.81491e-02
I0208 19:42:02.313276 22542570456896 run_lib.py:133] step: 68900, training_loss: 3.08510e-02
I0208 19:42:02.464472 22542570456896 run_lib.py:146] step: 68900, eval_loss: 3.47222e-02
I0208 19:42:20.061797 22542570456896 run_lib.py:133] step: 68950, training_loss: 2.68547e-02
I0208 19:42:37.600913 22542570456896 run_lib.py:133] step: 69000, training_loss: 2.97819e-02
I0208 19:42:37.757472 22542570456896 run_lib.py:146] step: 69000, eval_loss: 2.37277e-02
I0208 19:42:55.209685 22542570456896 run_lib.py:133] step: 69050, training_loss: 2.23423e-02
I0208 19:43:12.679670 22542570456896 run_lib.py:133] step: 69100, training_loss: 2.66500e-02
I0208 19:43:12.847504 22542570456896 run_lib.py:146] step: 69100, eval_loss: 2.58774e-02
I0208 19:43:30.386480 22542570456896 run_lib.py:133] step: 69150, training_loss: 3.10496e-02
I0208 19:43:47.808346 22542570456896 run_lib.py:133] step: 69200, training_loss: 3.35037e-02
I0208 19:43:47.979119 22542570456896 run_lib.py:146] step: 69200, eval_loss: 1.97422e-02
I0208 19:44:05.644769 22542570456896 run_lib.py:133] step: 69250, training_loss: 3.02285e-02
I0208 19:44:23.114329 22542570456896 run_lib.py:133] step: 69300, training_loss: 3.33260e-02
I0208 19:44:23.270187 22542570456896 run_lib.py:146] step: 69300, eval_loss: 3.38689e-02
I0208 19:44:40.844046 22542570456896 run_lib.py:133] step: 69350, training_loss: 2.47690e-02
I0208 19:44:58.246091 22542570456896 run_lib.py:133] step: 69400, training_loss: 3.07311e-02
I0208 19:44:58.399140 22542570456896 run_lib.py:146] step: 69400, eval_loss: 2.77157e-02
I0208 19:45:15.827847 22542570456896 run_lib.py:133] step: 69450, training_loss: 3.42525e-02
I0208 19:45:33.488190 22542570456896 run_lib.py:133] step: 69500, training_loss: 3.10418e-02
I0208 19:45:33.647537 22542570456896 run_lib.py:146] step: 69500, eval_loss: 2.53678e-02
I0208 19:45:51.091526 22542570456896 run_lib.py:133] step: 69550, training_loss: 2.91651e-02
I0208 19:46:08.727134 22542570456896 run_lib.py:133] step: 69600, training_loss: 3.11936e-02
I0208 19:46:08.891555 22542570456896 run_lib.py:146] step: 69600, eval_loss: 3.62847e-02
I0208 19:46:26.306802 22542570456896 run_lib.py:133] step: 69650, training_loss: 3.05100e-02
I0208 19:46:43.733704 22542570456896 run_lib.py:133] step: 69700, training_loss: 2.67047e-02
I0208 19:46:43.889346 22542570456896 run_lib.py:146] step: 69700, eval_loss: 2.61014e-02
I0208 19:47:01.473779 22542570456896 run_lib.py:133] step: 69750, training_loss: 3.36745e-02
I0208 19:47:18.919226 22542570456896 run_lib.py:133] step: 69800, training_loss: 2.80184e-02
I0208 19:47:19.076836 22542570456896 run_lib.py:146] step: 69800, eval_loss: 2.76619e-02
I0208 19:47:36.520427 22542570456896 run_lib.py:133] step: 69850, training_loss: 2.89149e-02
I0208 19:47:53.939615 22542570456896 run_lib.py:133] step: 69900, training_loss: 2.31239e-02
I0208 19:47:54.095327 22542570456896 run_lib.py:146] step: 69900, eval_loss: 2.42763e-02
I0208 19:48:11.693456 22542570456896 run_lib.py:133] step: 69950, training_loss: 2.54608e-02
I0208 19:48:29.143322 22542570456896 run_lib.py:133] step: 70000, training_loss: 2.70584e-02
I0208 19:48:29.858411 22542570456896 run_lib.py:146] step: 70000, eval_loss: 3.39806e-02
I0208 19:48:50.121306 22542570456896 run_lib.py:133] step: 70050, training_loss: 2.59420e-02
I0208 19:49:07.591465 22542570456896 run_lib.py:133] step: 70100, training_loss: 3.25214e-02
I0208 19:49:07.753433 22542570456896 run_lib.py:146] step: 70100, eval_loss: 2.88725e-02
I0208 19:49:25.324131 22542570456896 run_lib.py:133] step: 70150, training_loss: 2.92983e-02
I0208 19:49:42.745827 22542570456896 run_lib.py:133] step: 70200, training_loss: 3.68868e-02
I0208 19:49:42.912376 22542570456896 run_lib.py:146] step: 70200, eval_loss: 3.60226e-02
I0208 19:50:00.315302 22542570456896 run_lib.py:133] step: 70250, training_loss: 2.99240e-02
I0208 19:50:17.890334 22542570456896 run_lib.py:133] step: 70300, training_loss: 2.72009e-02
I0208 19:50:18.059336 22542570456896 run_lib.py:146] step: 70300, eval_loss: 3.28765e-02
I0208 19:50:35.493815 22542570456896 run_lib.py:133] step: 70350, training_loss: 2.86376e-02
I0208 19:50:52.926225 22542570456896 run_lib.py:133] step: 70400, training_loss: 3.27551e-02
I0208 19:50:53.082542 22542570456896 run_lib.py:146] step: 70400, eval_loss: 2.64753e-02
I0208 19:51:10.523174 22542570456896 run_lib.py:133] step: 70450, training_loss: 2.40471e-02
I0208 19:51:28.142730 22542570456896 run_lib.py:133] step: 70500, training_loss: 2.79399e-02
I0208 19:51:28.295397 22542570456896 run_lib.py:146] step: 70500, eval_loss: 2.58795e-02
I0208 19:51:45.689632 22542570456896 run_lib.py:133] step: 70550, training_loss: 3.04701e-02
I0208 19:52:03.201348 22542570456896 run_lib.py:133] step: 70600, training_loss: 3.78385e-02
I0208 19:52:03.384399 22542570456896 run_lib.py:146] step: 70600, eval_loss: 2.97341e-02
I0208 19:52:20.857147 22542570456896 run_lib.py:133] step: 70650, training_loss: 2.37499e-02
I0208 19:52:38.299074 22542570456896 run_lib.py:133] step: 70700, training_loss: 2.71249e-02
I0208 19:52:38.457527 22542570456896 run_lib.py:146] step: 70700, eval_loss: 3.07528e-02
I0208 19:52:56.045544 22542570456896 run_lib.py:133] step: 70750, training_loss: 3.04131e-02
I0208 19:53:13.504421 22542570456896 run_lib.py:133] step: 70800, training_loss: 2.34048e-02
I0208 19:53:13.661202 22542570456896 run_lib.py:146] step: 70800, eval_loss: 3.18856e-02
I0208 19:53:31.076180 22542570456896 run_lib.py:133] step: 70850, training_loss: 2.81225e-02
I0208 19:53:48.498376 22542570456896 run_lib.py:133] step: 70900, training_loss: 2.66682e-02
I0208 19:53:48.652869 22542570456896 run_lib.py:146] step: 70900, eval_loss: 2.76997e-02
I0208 19:54:06.217432 22542570456896 run_lib.py:133] step: 70950, training_loss: 2.64277e-02
I0208 19:54:23.541598 22542570456896 run_lib.py:133] step: 71000, training_loss: 3.28926e-02
I0208 19:54:23.695243 22542570456896 run_lib.py:146] step: 71000, eval_loss: 3.45142e-02
I0208 19:54:41.155375 22542570456896 run_lib.py:133] step: 71050, training_loss: 3.68433e-02
I0208 19:54:58.623929 22542570456896 run_lib.py:133] step: 71100, training_loss: 2.75220e-02
I0208 19:54:58.792458 22542570456896 run_lib.py:146] step: 71100, eval_loss: 2.67166e-02
I0208 19:55:16.397040 22542570456896 run_lib.py:133] step: 71150, training_loss: 2.41740e-02
I0208 19:55:33.878128 22542570456896 run_lib.py:133] step: 71200, training_loss: 2.22481e-02
I0208 19:55:34.036652 22542570456896 run_lib.py:146] step: 71200, eval_loss: 2.78373e-02
I0208 19:55:51.509059 22542570456896 run_lib.py:133] step: 71250, training_loss: 2.80719e-02
I0208 19:56:09.093413 22542570456896 run_lib.py:133] step: 71300, training_loss: 2.53792e-02
I0208 19:56:09.250455 22542570456896 run_lib.py:146] step: 71300, eval_loss: 2.72314e-02
I0208 19:56:26.727309 22542570456896 run_lib.py:133] step: 71350, training_loss: 3.00936e-02
I0208 19:56:44.266783 22542570456896 run_lib.py:133] step: 71400, training_loss: 2.39959e-02
I0208 19:56:44.419110 22542570456896 run_lib.py:146] step: 71400, eval_loss: 3.17064e-02
I0208 19:57:01.863027 22542570456896 run_lib.py:133] step: 71450, training_loss: 2.59034e-02
I0208 19:57:19.309674 22542570456896 run_lib.py:133] step: 71500, training_loss: 2.98052e-02
I0208 19:57:19.478662 22542570456896 run_lib.py:146] step: 71500, eval_loss: 3.26095e-02
I0208 19:57:37.095031 22542570456896 run_lib.py:133] step: 71550, training_loss: 2.16546e-02
I0208 19:57:54.529520 22542570456896 run_lib.py:133] step: 71600, training_loss: 3.62845e-02
I0208 19:57:54.688478 22542570456896 run_lib.py:146] step: 71600, eval_loss: 2.53008e-02
I0208 19:58:12.122949 22542570456896 run_lib.py:133] step: 71650, training_loss: 3.17259e-02
I0208 19:58:29.563453 22542570456896 run_lib.py:133] step: 71700, training_loss: 3.53800e-02
I0208 19:58:29.731376 22542570456896 run_lib.py:146] step: 71700, eval_loss: 2.50789e-02
I0208 19:58:47.353671 22542570456896 run_lib.py:133] step: 71750, training_loss: 2.47904e-02
I0208 19:59:04.813366 22542570456896 run_lib.py:133] step: 71800, training_loss: 2.43206e-02
I0208 19:59:04.970231 22542570456896 run_lib.py:146] step: 71800, eval_loss: 2.84831e-02
I0208 19:59:22.537079 22542570456896 run_lib.py:133] step: 71850, training_loss: 2.48857e-02
I0208 19:59:39.972197 22542570456896 run_lib.py:133] step: 71900, training_loss: 2.77098e-02
I0208 19:59:40.124419 22542570456896 run_lib.py:146] step: 71900, eval_loss: 2.65715e-02
I0208 19:59:57.548150 22542570456896 run_lib.py:133] step: 71950, training_loss: 2.69206e-02
I0208 20:00:14.967232 22542570456896 run_lib.py:133] step: 72000, training_loss: 3.01338e-02
I0208 20:00:15.137459 22542570456896 run_lib.py:146] step: 72000, eval_loss: 2.63621e-02
I0208 20:00:32.780039 22542570456896 run_lib.py:133] step: 72050, training_loss: 2.35563e-02
I0208 20:00:50.296575 22542570456896 run_lib.py:133] step: 72100, training_loss: 2.06620e-02
I0208 20:00:50.455458 22542570456896 run_lib.py:146] step: 72100, eval_loss: 3.64480e-02
I0208 20:01:07.888314 22542570456896 run_lib.py:133] step: 72150, training_loss: 2.43346e-02
I0208 20:01:25.270515 22542570456896 run_lib.py:133] step: 72200, training_loss: 2.95387e-02
I0208 20:01:25.429584 22542570456896 run_lib.py:146] step: 72200, eval_loss: 3.33670e-02
I0208 20:01:42.975322 22542570456896 run_lib.py:133] step: 72250, training_loss: 3.50845e-02
I0208 20:02:00.424311 22542570456896 run_lib.py:133] step: 72300, training_loss: 3.12103e-02
I0208 20:02:00.580540 22542570456896 run_lib.py:146] step: 72300, eval_loss: 2.70620e-02
I0208 20:02:18.198112 22542570456896 run_lib.py:133] step: 72350, training_loss: 2.27250e-02
I0208 20:02:35.588144 22542570456896 run_lib.py:133] step: 72400, training_loss: 3.26158e-02
I0208 20:02:35.740417 22542570456896 run_lib.py:146] step: 72400, eval_loss: 2.62538e-02
I0208 20:02:53.349434 22542570456896 run_lib.py:133] step: 72450, training_loss: 2.48297e-02
I0208 20:03:10.778762 22542570456896 run_lib.py:133] step: 72500, training_loss: 3.65550e-02
I0208 20:03:10.938452 22542570456896 run_lib.py:146] step: 72500, eval_loss: 2.79804e-02
I0208 20:03:28.563553 22542570456896 run_lib.py:133] step: 72550, training_loss: 3.04159e-02
I0208 20:03:46.063831 22542570456896 run_lib.py:133] step: 72600, training_loss: 3.12895e-02
I0208 20:03:46.221527 22542570456896 run_lib.py:146] step: 72600, eval_loss: 3.14407e-02
I0208 20:04:03.640441 22542570456896 run_lib.py:133] step: 72650, training_loss: 2.55574e-02
I0208 20:04:21.248545 22542570456896 run_lib.py:133] step: 72700, training_loss: 3.01578e-02
I0208 20:04:21.405526 22542570456896 run_lib.py:146] step: 72700, eval_loss: 2.72594e-02
I0208 20:04:38.793637 22542570456896 run_lib.py:133] step: 72750, training_loss: 3.31721e-02
I0208 20:04:56.227383 22542570456896 run_lib.py:133] step: 72800, training_loss: 2.91312e-02
I0208 20:04:56.382026 22542570456896 run_lib.py:146] step: 72800, eval_loss: 2.44676e-02
I0208 20:05:14.055049 22542570456896 run_lib.py:133] step: 72850, training_loss: 2.86627e-02
I0208 20:05:31.640245 22542570456896 run_lib.py:133] step: 72900, training_loss: 2.65962e-02
I0208 20:05:31.795273 22542570456896 run_lib.py:146] step: 72900, eval_loss: 3.28344e-02
I0208 20:05:49.207861 22542570456896 run_lib.py:133] step: 72950, training_loss: 3.34010e-02
I0208 20:06:06.656216 22542570456896 run_lib.py:133] step: 73000, training_loss: 3.22815e-02
I0208 20:06:06.817187 22542570456896 run_lib.py:146] step: 73000, eval_loss: 3.51907e-02
I0208 20:06:24.243022 22542570456896 run_lib.py:133] step: 73050, training_loss: 3.01797e-02
I0208 20:06:41.837184 22542570456896 run_lib.py:133] step: 73100, training_loss: 3.37475e-02
I0208 20:06:42.001890 22542570456896 run_lib.py:146] step: 73100, eval_loss: 2.60625e-02
I0208 20:06:59.469882 22542570456896 run_lib.py:133] step: 73150, training_loss: 2.80449e-02
I0208 20:07:16.947335 22542570456896 run_lib.py:133] step: 73200, training_loss: 3.91206e-02
I0208 20:07:17.112483 22542570456896 run_lib.py:146] step: 73200, eval_loss: 3.20728e-02
I0208 20:07:34.563569 22542570456896 run_lib.py:133] step: 73250, training_loss: 3.39435e-02
I0208 20:07:52.143437 22542570456896 run_lib.py:133] step: 73300, training_loss: 3.32928e-02
I0208 20:07:52.296430 22542570456896 run_lib.py:146] step: 73300, eval_loss: 3.06686e-02
I0208 20:08:09.709997 22542570456896 run_lib.py:133] step: 73350, training_loss: 2.69786e-02
I0208 20:08:27.242374 22542570456896 run_lib.py:133] step: 73400, training_loss: 3.43777e-02
I0208 20:08:27.413614 22542570456896 run_lib.py:146] step: 73400, eval_loss: 2.53370e-02
I0208 20:08:44.839769 22542570456896 run_lib.py:133] step: 73450, training_loss: 3.25837e-02
I0208 20:09:02.315636 22542570456896 run_lib.py:133] step: 73500, training_loss: 2.78663e-02
I0208 20:09:02.474342 22542570456896 run_lib.py:146] step: 73500, eval_loss: 4.22955e-02
I0208 20:09:20.086907 22542570456896 run_lib.py:133] step: 73550, training_loss: 2.69377e-02
I0208 20:09:37.594175 22542570456896 run_lib.py:133] step: 73600, training_loss: 3.39192e-02
I0208 20:09:37.758583 22542570456896 run_lib.py:146] step: 73600, eval_loss: 2.84365e-02
I0208 20:09:55.171423 22542570456896 run_lib.py:133] step: 73650, training_loss: 2.74463e-02
I0208 20:10:12.643452 22542570456896 run_lib.py:133] step: 73700, training_loss: 3.14516e-02
I0208 20:10:12.797548 22542570456896 run_lib.py:146] step: 73700, eval_loss: 2.54005e-02
I0208 20:10:30.409553 22542570456896 run_lib.py:133] step: 73750, training_loss: 2.64213e-02
I0208 20:10:47.833825 22542570456896 run_lib.py:133] step: 73800, training_loss: 2.74222e-02
I0208 20:10:47.996180 22542570456896 run_lib.py:146] step: 73800, eval_loss: 2.95533e-02
I0208 20:11:05.535018 22542570456896 run_lib.py:133] step: 73850, training_loss: 2.82600e-02
I0208 20:11:22.949258 22542570456896 run_lib.py:133] step: 73900, training_loss: 2.99224e-02
I0208 20:11:23.108194 22542570456896 run_lib.py:146] step: 73900, eval_loss: 3.17674e-02
I0208 20:11:41.310681 22542570456896 run_lib.py:133] step: 73950, training_loss: 2.50552e-02
I0208 20:11:58.816398 22542570456896 run_lib.py:133] step: 74000, training_loss: 2.69844e-02
I0208 20:11:58.976301 22542570456896 run_lib.py:146] step: 74000, eval_loss: 2.83496e-02
I0208 20:12:16.381808 22542570456896 run_lib.py:133] step: 74050, training_loss: 2.71318e-02
I0208 20:12:33.952841 22542570456896 run_lib.py:133] step: 74100, training_loss: 2.77723e-02
I0208 20:12:34.109427 22542570456896 run_lib.py:146] step: 74100, eval_loss: 2.52341e-02
I0208 20:12:51.547886 22542570456896 run_lib.py:133] step: 74150, training_loss: 3.07898e-02
I0208 20:13:09.114353 22542570456896 run_lib.py:133] step: 74200, training_loss: 2.70312e-02
I0208 20:13:09.270681 22542570456896 run_lib.py:146] step: 74200, eval_loss: 2.68681e-02
I0208 20:13:26.764951 22542570456896 run_lib.py:133] step: 74250, training_loss: 3.17703e-02
I0208 20:13:44.166684 22542570456896 run_lib.py:133] step: 74300, training_loss: 2.79708e-02
I0208 20:13:44.319361 22542570456896 run_lib.py:146] step: 74300, eval_loss: 3.11085e-02
I0208 20:14:01.942630 22542570456896 run_lib.py:133] step: 74350, training_loss: 2.49359e-02
I0208 20:14:19.361969 22542570456896 run_lib.py:133] step: 74400, training_loss: 2.85685e-02
I0208 20:14:19.529238 22542570456896 run_lib.py:146] step: 74400, eval_loss: 2.27831e-02
I0208 20:14:36.964429 22542570456896 run_lib.py:133] step: 74450, training_loss: 3.99800e-02
I0208 20:14:54.518403 22542570456896 run_lib.py:133] step: 74500, training_loss: 3.25792e-02
I0208 20:14:54.688025 22542570456896 run_lib.py:146] step: 74500, eval_loss: 3.33331e-02
I0208 20:15:12.156897 22542570456896 run_lib.py:133] step: 74550, training_loss: 3.51206e-02
I0208 20:15:29.628013 22542570456896 run_lib.py:133] step: 74600, training_loss: 2.66788e-02
I0208 20:15:29.784269 22542570456896 run_lib.py:146] step: 74600, eval_loss: 3.32743e-02
I0208 20:15:47.296395 22542570456896 run_lib.py:133] step: 74650, training_loss: 3.49661e-02
I0208 20:16:04.730098 22542570456896 run_lib.py:133] step: 74700, training_loss: 2.83036e-02
I0208 20:16:04.884082 22542570456896 run_lib.py:146] step: 74700, eval_loss: 2.84906e-02
I0208 20:16:22.287137 22542570456896 run_lib.py:133] step: 74750, training_loss: 2.22629e-02
I0208 20:16:39.744658 22542570456896 run_lib.py:133] step: 74800, training_loss: 3.18672e-02
I0208 20:16:39.911513 22542570456896 run_lib.py:146] step: 74800, eval_loss: 2.73381e-02
I0208 20:16:57.557794 22542570456896 run_lib.py:133] step: 74850, training_loss: 4.09548e-02
I0208 20:17:15.134274 22542570456896 run_lib.py:133] step: 74900, training_loss: 2.99687e-02
I0208 20:17:15.294387 22542570456896 run_lib.py:146] step: 74900, eval_loss: 2.96283e-02
I0208 20:17:32.718466 22542570456896 run_lib.py:133] step: 74950, training_loss: 2.89404e-02
I0208 20:17:50.163207 22542570456896 run_lib.py:133] step: 75000, training_loss: 2.81517e-02
I0208 20:17:50.324364 22542570456896 run_lib.py:146] step: 75000, eval_loss: 3.20781e-02
I0208 20:18:07.865081 22542570456896 run_lib.py:133] step: 75050, training_loss: 2.83444e-02
I0208 20:18:25.322022 22542570456896 run_lib.py:133] step: 75100, training_loss: 2.99200e-02
I0208 20:18:25.478430 22542570456896 run_lib.py:146] step: 75100, eval_loss: 2.68358e-02
I0208 20:18:43.114862 22542570456896 run_lib.py:133] step: 75150, training_loss: 2.57201e-02
I0208 20:19:00.505409 22542570456896 run_lib.py:133] step: 75200, training_loss: 2.62931e-02
I0208 20:19:00.659838 22542570456896 run_lib.py:146] step: 75200, eval_loss: 2.72720e-02
I0208 20:19:18.220601 22542570456896 run_lib.py:133] step: 75250, training_loss: 2.69451e-02
I0208 20:19:35.645937 22542570456896 run_lib.py:133] step: 75300, training_loss: 2.52775e-02
I0208 20:19:35.802680 22542570456896 run_lib.py:146] step: 75300, eval_loss: 2.91498e-02
I0208 20:19:53.467948 22542570456896 run_lib.py:133] step: 75350, training_loss: 3.13927e-02
I0208 20:20:10.915082 22542570456896 run_lib.py:133] step: 75400, training_loss: 2.59569e-02
I0208 20:20:11.070944 22542570456896 run_lib.py:146] step: 75400, eval_loss: 2.00661e-02
I0208 20:20:28.468062 22542570456896 run_lib.py:133] step: 75450, training_loss: 3.11453e-02
I0208 20:20:46.098181 22542570456896 run_lib.py:133] step: 75500, training_loss: 2.74299e-02
I0208 20:20:46.254345 22542570456896 run_lib.py:146] step: 75500, eval_loss: 2.96954e-02
I0208 20:21:03.674341 22542570456896 run_lib.py:133] step: 75550, training_loss: 3.56267e-02
I0208 20:21:21.162742 22542570456896 run_lib.py:133] step: 75600, training_loss: 3.63403e-02
I0208 20:21:21.320508 22542570456896 run_lib.py:146] step: 75600, eval_loss: 2.96232e-02
I0208 20:21:38.924997 22542570456896 run_lib.py:133] step: 75650, training_loss: 2.82109e-02
I0208 20:21:56.391391 22542570456896 run_lib.py:133] step: 75700, training_loss: 2.59671e-02
I0208 20:21:56.551408 22542570456896 run_lib.py:146] step: 75700, eval_loss: 2.94659e-02
I0208 20:22:14.156660 22542570456896 run_lib.py:133] step: 75750, training_loss: 3.52896e-02
I0208 20:22:31.627994 22542570456896 run_lib.py:133] step: 75800, training_loss: 2.77739e-02
I0208 20:22:31.785359 22542570456896 run_lib.py:146] step: 75800, eval_loss: 2.96437e-02
I0208 20:22:49.234910 22542570456896 run_lib.py:133] step: 75850, training_loss: 2.61280e-02
I0208 20:23:06.869244 22542570456896 run_lib.py:133] step: 75900, training_loss: 2.95805e-02
I0208 20:23:07.029998 22542570456896 run_lib.py:146] step: 75900, eval_loss: 2.96293e-02
I0208 20:23:24.476246 22542570456896 run_lib.py:133] step: 75950, training_loss: 2.42734e-02
I0208 20:23:41.879702 22542570456896 run_lib.py:133] step: 76000, training_loss: 2.34531e-02
I0208 20:23:42.036790 22542570456896 run_lib.py:146] step: 76000, eval_loss: 2.51775e-02
I0208 20:23:59.466753 22542570456896 run_lib.py:133] step: 76050, training_loss: 3.07791e-02
I0208 20:24:17.032105 22542570456896 run_lib.py:133] step: 76100, training_loss: 2.79426e-02
I0208 20:24:17.188236 22542570456896 run_lib.py:146] step: 76100, eval_loss: 3.02516e-02
I0208 20:24:34.646765 22542570456896 run_lib.py:133] step: 76150, training_loss: 2.84240e-02
I0208 20:24:52.183338 22542570456896 run_lib.py:133] step: 76200, training_loss: 2.30486e-02
I0208 20:24:52.345659 22542570456896 run_lib.py:146] step: 76200, eval_loss: 3.31983e-02
I0208 20:25:09.813056 22542570456896 run_lib.py:133] step: 76250, training_loss: 2.70788e-02
I0208 20:25:27.259717 22542570456896 run_lib.py:133] step: 76300, training_loss: 2.32161e-02
I0208 20:25:27.420673 22542570456896 run_lib.py:146] step: 76300, eval_loss: 2.97622e-02
I0208 20:25:45.045192 22542570456896 run_lib.py:133] step: 76350, training_loss: 2.40664e-02
I0208 20:26:02.521409 22542570456896 run_lib.py:133] step: 76400, training_loss: 2.68212e-02
I0208 20:26:02.690129 22542570456896 run_lib.py:146] step: 76400, eval_loss: 3.98110e-02
I0208 20:26:20.137330 22542570456896 run_lib.py:133] step: 76450, training_loss: 2.61008e-02
I0208 20:26:37.603304 22542570456896 run_lib.py:133] step: 76500, training_loss: 2.91085e-02
I0208 20:26:37.762206 22542570456896 run_lib.py:146] step: 76500, eval_loss: 2.53571e-02
I0208 20:26:55.410039 22542570456896 run_lib.py:133] step: 76550, training_loss: 2.71535e-02
I0208 20:27:12.806506 22542570456896 run_lib.py:133] step: 76600, training_loss: 2.80450e-02
I0208 20:27:12.959495 22542570456896 run_lib.py:146] step: 76600, eval_loss: 2.79804e-02
I0208 20:27:30.520655 22542570456896 run_lib.py:133] step: 76650, training_loss: 2.67637e-02
I0208 20:27:47.980065 22542570456896 run_lib.py:133] step: 76700, training_loss: 2.76321e-02
I0208 20:27:48.144649 22542570456896 run_lib.py:146] step: 76700, eval_loss: 3.23030e-02
I0208 20:28:05.808242 22542570456896 run_lib.py:133] step: 76750, training_loss: 2.16290e-02
I0208 20:28:23.233130 22542570456896 run_lib.py:133] step: 76800, training_loss: 2.76179e-02
I0208 20:28:23.397527 22542570456896 run_lib.py:146] step: 76800, eval_loss: 2.94179e-02
I0208 20:28:40.779183 22542570456896 run_lib.py:133] step: 76850, training_loss: 2.93505e-02
I0208 20:28:58.331803 22542570456896 run_lib.py:133] step: 76900, training_loss: 2.76733e-02
I0208 20:28:58.496387 22542570456896 run_lib.py:146] step: 76900, eval_loss: 2.80337e-02
I0208 20:29:15.961909 22542570456896 run_lib.py:133] step: 76950, training_loss: 2.87640e-02
I0208 20:29:33.580197 22542570456896 run_lib.py:133] step: 77000, training_loss: 3.03234e-02
I0208 20:29:33.737582 22542570456896 run_lib.py:146] step: 77000, eval_loss: 2.87513e-02
I0208 20:29:51.179178 22542570456896 run_lib.py:133] step: 77050, training_loss: 3.30764e-02
I0208 20:30:08.611056 22542570456896 run_lib.py:133] step: 77100, training_loss: 2.83829e-02
I0208 20:30:08.765330 22542570456896 run_lib.py:146] step: 77100, eval_loss: 3.69583e-02
I0208 20:30:26.349756 22542570456896 run_lib.py:133] step: 77150, training_loss: 2.52034e-02
I0208 20:30:43.816583 22542570456896 run_lib.py:133] step: 77200, training_loss: 3.41399e-02
I0208 20:30:43.985513 22542570456896 run_lib.py:146] step: 77200, eval_loss: 3.44659e-02
I0208 20:31:01.490467 22542570456896 run_lib.py:133] step: 77250, training_loss: 2.80636e-02
I0208 20:31:19.115997 22542570456896 run_lib.py:133] step: 77300, training_loss: 3.68455e-02
I0208 20:31:19.275574 22542570456896 run_lib.py:146] step: 77300, eval_loss: 3.12568e-02
I0208 20:31:36.760189 22542570456896 run_lib.py:133] step: 77350, training_loss: 3.17864e-02
I0208 20:31:54.209746 22542570456896 run_lib.py:133] step: 77400, training_loss: 2.98196e-02
I0208 20:31:54.521288 22542570456896 run_lib.py:146] step: 77400, eval_loss: 2.60893e-02
I0208 20:32:11.953828 22542570456896 run_lib.py:133] step: 77450, training_loss: 2.93350e-02
I0208 20:32:29.440021 22542570456896 run_lib.py:133] step: 77500, training_loss: 2.83182e-02
I0208 20:32:29.596649 22542570456896 run_lib.py:146] step: 77500, eval_loss: 1.95849e-02
I0208 20:32:47.066569 22542570456896 run_lib.py:133] step: 77550, training_loss: 2.64782e-02
I0208 20:33:04.478063 22542570456896 run_lib.py:133] step: 77600, training_loss: 3.64718e-02
I0208 20:33:04.631385 22542570456896 run_lib.py:146] step: 77600, eval_loss: 2.69014e-02
I0208 20:33:22.231404 22542570456896 run_lib.py:133] step: 77650, training_loss: 3.08087e-02
I0208 20:33:39.743208 22542570456896 run_lib.py:133] step: 77700, training_loss: 2.93691e-02
I0208 20:33:39.915418 22542570456896 run_lib.py:146] step: 77700, eval_loss: 2.89026e-02
I0208 20:33:57.383545 22542570456896 run_lib.py:133] step: 77750, training_loss: 2.98422e-02
I0208 20:34:14.808331 22542570456896 run_lib.py:133] step: 77800, training_loss: 2.95825e-02
I0208 20:34:14.969391 22542570456896 run_lib.py:146] step: 77800, eval_loss: 2.98082e-02
I0208 20:34:32.551935 22542570456896 run_lib.py:133] step: 77850, training_loss: 3.07381e-02
I0208 20:34:50.045220 22542570456896 run_lib.py:133] step: 77900, training_loss: 3.67269e-02
I0208 20:34:50.205420 22542570456896 run_lib.py:146] step: 77900, eval_loss: 2.98325e-02
I0208 20:35:07.604774 22542570456896 run_lib.py:133] step: 77950, training_loss: 2.49325e-02
I0208 20:35:25.046986 22542570456896 run_lib.py:133] step: 78000, training_loss: 3.24128e-02
I0208 20:35:25.209695 22542570456896 run_lib.py:146] step: 78000, eval_loss: 3.29846e-02
I0208 20:35:42.885219 22542570456896 run_lib.py:133] step: 78050, training_loss: 2.62938e-02
I0208 20:36:00.348460 22542570456896 run_lib.py:133] step: 78100, training_loss: 3.91454e-02
I0208 20:36:00.502288 22542570456896 run_lib.py:146] step: 78100, eval_loss: 3.60208e-02
I0208 20:36:18.023527 22542570456896 run_lib.py:133] step: 78150, training_loss: 2.74780e-02
I0208 20:36:35.442544 22542570456896 run_lib.py:133] step: 78200, training_loss: 3.57468e-02
I0208 20:36:35.603578 22542570456896 run_lib.py:146] step: 78200, eval_loss: 2.71860e-02
I0208 20:36:53.167789 22542570456896 run_lib.py:133] step: 78250, training_loss: 3.64233e-02
I0208 20:37:10.604208 22542570456896 run_lib.py:133] step: 78300, training_loss: 2.62237e-02
I0208 20:37:10.776395 22542570456896 run_lib.py:146] step: 78300, eval_loss: 2.31439e-02
I0208 20:37:28.224256 22542570456896 run_lib.py:133] step: 78350, training_loss: 2.90738e-02
I0208 20:37:45.887981 22542570456896 run_lib.py:133] step: 78400, training_loss: 2.86499e-02
I0208 20:37:46.045103 22542570456896 run_lib.py:146] step: 78400, eval_loss: 3.03494e-02
I0208 20:38:03.509961 22542570456896 run_lib.py:133] step: 78450, training_loss: 3.26621e-02
I0208 20:38:21.124503 22542570456896 run_lib.py:133] step: 78500, training_loss: 2.94237e-02
I0208 20:38:21.277388 22542570456896 run_lib.py:146] step: 78500, eval_loss: 2.63396e-02
I0208 20:38:38.715259 22542570456896 run_lib.py:133] step: 78550, training_loss: 2.31605e-02
I0208 20:38:56.126932 22542570456896 run_lib.py:133] step: 78600, training_loss: 3.11476e-02
I0208 20:38:56.299566 22542570456896 run_lib.py:146] step: 78600, eval_loss: 3.18072e-02
I0208 20:39:13.964394 22542570456896 run_lib.py:133] step: 78650, training_loss: 3.43811e-02
I0208 20:39:31.439968 22542570456896 run_lib.py:133] step: 78700, training_loss: 2.72386e-02
I0208 20:39:31.600324 22542570456896 run_lib.py:146] step: 78700, eval_loss: 3.33997e-02
I0208 20:39:49.038703 22542570456896 run_lib.py:133] step: 78750, training_loss: 3.16009e-02
I0208 20:40:06.433815 22542570456896 run_lib.py:133] step: 78800, training_loss: 3.47464e-02
I0208 20:40:06.590371 22542570456896 run_lib.py:146] step: 78800, eval_loss: 2.74042e-02
I0208 20:40:24.170232 22542570456896 run_lib.py:133] step: 78850, training_loss: 2.90151e-02
I0208 20:40:41.621516 22542570456896 run_lib.py:133] step: 78900, training_loss: 2.50887e-02
I0208 20:40:41.778598 22542570456896 run_lib.py:146] step: 78900, eval_loss: 2.58318e-02
I0208 20:40:59.316422 22542570456896 run_lib.py:133] step: 78950, training_loss: 2.60157e-02
I0208 20:41:16.767148 22542570456896 run_lib.py:133] step: 79000, training_loss: 2.95386e-02
I0208 20:41:16.920270 22542570456896 run_lib.py:146] step: 79000, eval_loss: 1.83603e-02
I0208 20:41:34.319512 22542570456896 run_lib.py:133] step: 79050, training_loss: 2.89011e-02
I0208 20:41:51.754140 22542570456896 run_lib.py:133] step: 79100, training_loss: 2.61598e-02
I0208 20:41:51.911340 22542570456896 run_lib.py:146] step: 79100, eval_loss: 2.77736e-02
I0208 20:42:09.481393 22542570456896 run_lib.py:133] step: 79150, training_loss: 2.42927e-02
I0208 20:42:26.996632 22542570456896 run_lib.py:133] step: 79200, training_loss: 3.40257e-02
I0208 20:42:27.175644 22542570456896 run_lib.py:146] step: 79200, eval_loss: 2.94124e-02
I0208 20:42:44.633075 22542570456896 run_lib.py:133] step: 79250, training_loss: 3.43688e-02
I0208 20:43:02.082005 22542570456896 run_lib.py:133] step: 79300, training_loss: 3.18010e-02
I0208 20:43:02.240532 22542570456896 run_lib.py:146] step: 79300, eval_loss: 3.21946e-02
I0208 20:43:19.814272 22542570456896 run_lib.py:133] step: 79350, training_loss: 3.55084e-02
I0208 20:43:37.240924 22542570456896 run_lib.py:133] step: 79400, training_loss: 2.40029e-02
I0208 20:43:37.397317 22542570456896 run_lib.py:146] step: 79400, eval_loss: 3.27283e-02
I0208 20:43:54.981677 22542570456896 run_lib.py:133] step: 79450, training_loss: 2.78730e-02
I0208 20:44:12.430236 22542570456896 run_lib.py:133] step: 79500, training_loss: 2.52254e-02
I0208 20:44:12.584709 22542570456896 run_lib.py:146] step: 79500, eval_loss: 3.00548e-02
I0208 20:44:30.256636 22542570456896 run_lib.py:133] step: 79550, training_loss: 2.89411e-02
I0208 20:44:47.700356 22542570456896 run_lib.py:133] step: 79600, training_loss: 3.37629e-02
I0208 20:44:47.865576 22542570456896 run_lib.py:146] step: 79600, eval_loss: 2.77167e-02
I0208 20:45:05.424386 22542570456896 run_lib.py:133] step: 79650, training_loss: 2.63284e-02
I0208 20:45:22.824225 22542570456896 run_lib.py:133] step: 79700, training_loss: 2.76842e-02
I0208 20:45:22.984261 22542570456896 run_lib.py:146] step: 79700, eval_loss: 2.66781e-02
I0208 20:45:40.445662 22542570456896 run_lib.py:133] step: 79750, training_loss: 3.84539e-02
I0208 20:45:58.062476 22542570456896 run_lib.py:133] step: 79800, training_loss: 2.61662e-02
I0208 20:45:58.220129 22542570456896 run_lib.py:146] step: 79800, eval_loss: 3.04608e-02
I0208 20:46:15.655348 22542570456896 run_lib.py:133] step: 79850, training_loss: 2.28446e-02
I0208 20:46:33.084864 22542570456896 run_lib.py:133] step: 79900, training_loss: 2.41553e-02
I0208 20:46:33.242144 22542570456896 run_lib.py:146] step: 79900, eval_loss: 3.28286e-02
I0208 20:46:50.809502 22542570456896 run_lib.py:133] step: 79950, training_loss: 2.73631e-02
I0208 20:47:08.368076 22542570456896 run_lib.py:133] step: 80000, training_loss: 2.12902e-02
I0208 20:47:09.087439 22542570456896 run_lib.py:146] step: 80000, eval_loss: 2.79580e-02
I0208 20:47:29.205897 22542570456896 run_lib.py:133] step: 80050, training_loss: 2.99594e-02
I0208 20:47:46.694837 22542570456896 run_lib.py:133] step: 80100, training_loss: 3.06410e-02
I0208 20:47:46.855658 22542570456896 run_lib.py:146] step: 80100, eval_loss: 3.46944e-02
I0208 20:48:04.301776 22542570456896 run_lib.py:133] step: 80150, training_loss: 3.70853e-02
I0208 20:48:21.758076 22542570456896 run_lib.py:133] step: 80200, training_loss: 3.43113e-02
I0208 20:48:21.916646 22542570456896 run_lib.py:146] step: 80200, eval_loss: 3.21752e-02
I0208 20:48:39.510177 22542570456896 run_lib.py:133] step: 80250, training_loss: 2.90520e-02
I0208 20:48:56.985154 22542570456896 run_lib.py:133] step: 80300, training_loss: 2.73137e-02
I0208 20:48:57.156603 22542570456896 run_lib.py:146] step: 80300, eval_loss: 3.08704e-02
I0208 20:49:14.580262 22542570456896 run_lib.py:133] step: 80350, training_loss: 2.13159e-02
I0208 20:49:32.005522 22542570456896 run_lib.py:133] step: 80400, training_loss: 2.49592e-02
I0208 20:49:32.162188 22542570456896 run_lib.py:146] step: 80400, eval_loss: 3.32564e-02
I0208 20:49:49.774955 22542570456896 run_lib.py:133] step: 80450, training_loss: 2.44926e-02
I0208 20:50:07.217025 22542570456896 run_lib.py:133] step: 80500, training_loss: 3.01058e-02
I0208 20:50:07.369291 22542570456896 run_lib.py:146] step: 80500, eval_loss: 2.99341e-02
I0208 20:50:25.002774 22542570456896 run_lib.py:133] step: 80550, training_loss: 2.59837e-02
I0208 20:50:42.428157 22542570456896 run_lib.py:133] step: 80600, training_loss: 2.52782e-02
I0208 20:50:42.596744 22542570456896 run_lib.py:146] step: 80600, eval_loss: 2.62990e-02
I0208 20:51:00.266967 22542570456896 run_lib.py:133] step: 80650, training_loss: 2.79151e-02
I0208 20:51:17.690471 22542570456896 run_lib.py:133] step: 80700, training_loss: 3.40943e-02
I0208 20:51:17.849429 22542570456896 run_lib.py:146] step: 80700, eval_loss: 3.44164e-02
I0208 20:51:35.245949 22542570456896 run_lib.py:133] step: 80750, training_loss: 2.90913e-02
I0208 20:51:52.823510 22542570456896 run_lib.py:133] step: 80800, training_loss: 3.78762e-02
I0208 20:51:52.980369 22542570456896 run_lib.py:146] step: 80800, eval_loss: 2.97844e-02
I0208 20:52:10.413134 22542570456896 run_lib.py:133] step: 80850, training_loss: 3.03207e-02
I0208 20:52:27.972580 22542570456896 run_lib.py:133] step: 80900, training_loss: 2.70289e-02
I0208 20:52:28.129521 22542570456896 run_lib.py:146] step: 80900, eval_loss: 3.02519e-02
I0208 20:52:45.598631 22542570456896 run_lib.py:133] step: 80950, training_loss: 2.89006e-02
I0208 20:53:03.051792 22542570456896 run_lib.py:133] step: 81000, training_loss: 3.25361e-02
I0208 20:53:03.201921 22542570456896 run_lib.py:146] step: 81000, eval_loss: 2.70152e-02
I0208 20:53:20.817782 22542570456896 run_lib.py:133] step: 81050, training_loss: 3.16575e-02
I0208 20:53:38.289978 22542570456896 run_lib.py:133] step: 81100, training_loss: 3.15274e-02
I0208 20:53:38.450748 22542570456896 run_lib.py:146] step: 81100, eval_loss: 2.89451e-02
I0208 20:53:55.857520 22542570456896 run_lib.py:133] step: 81150, training_loss: 3.14043e-02
I0208 20:54:13.541310 22542570456896 run_lib.py:133] step: 81200, training_loss: 3.30935e-02
I0208 20:54:13.698348 22542570456896 run_lib.py:146] step: 81200, eval_loss: 3.08328e-02
I0208 20:54:31.113936 22542570456896 run_lib.py:133] step: 81250, training_loss: 2.69150e-02
I0208 20:54:48.597956 22542570456896 run_lib.py:133] step: 81300, training_loss: 2.82987e-02
I0208 20:54:48.751009 22542570456896 run_lib.py:146] step: 81300, eval_loss: 2.79996e-02
I0208 20:55:06.213202 22542570456896 run_lib.py:133] step: 81350, training_loss: 3.32877e-02
I0208 20:55:23.643030 22542570456896 run_lib.py:133] step: 81400, training_loss: 3.02398e-02
I0208 20:55:23.797347 22542570456896 run_lib.py:146] step: 81400, eval_loss: 3.31745e-02
I0208 20:55:41.269186 22542570456896 run_lib.py:133] step: 81450, training_loss: 3.06964e-02
I0208 20:55:58.722423 22542570456896 run_lib.py:133] step: 81500, training_loss: 2.67219e-02
I0208 20:55:58.880598 22542570456896 run_lib.py:146] step: 81500, eval_loss: 2.52011e-02
I0208 20:56:16.516303 22542570456896 run_lib.py:133] step: 81550, training_loss: 3.48135e-02
I0208 20:56:34.033477 22542570456896 run_lib.py:133] step: 81600, training_loss: 2.06238e-02
I0208 20:56:34.191686 22542570456896 run_lib.py:146] step: 81600, eval_loss: 3.17175e-02
I0208 20:56:51.589102 22542570456896 run_lib.py:133] step: 81650, training_loss: 3.27647e-02
I0208 20:57:09.068007 22542570456896 run_lib.py:133] step: 81700, training_loss: 2.64922e-02
I0208 20:57:09.233700 22542570456896 run_lib.py:146] step: 81700, eval_loss: 2.84712e-02
I0208 20:57:26.846239 22542570456896 run_lib.py:133] step: 81750, training_loss: 2.95723e-02
I0208 20:57:44.265184 22542570456896 run_lib.py:133] step: 81800, training_loss: 2.97606e-02
I0208 20:57:44.422496 22542570456896 run_lib.py:146] step: 81800, eval_loss: 2.66435e-02
I0208 20:58:02.240380 22542570456896 run_lib.py:133] step: 81850, training_loss: 2.86811e-02
I0208 20:58:19.652056 22542570456896 run_lib.py:133] step: 81900, training_loss: 3.08131e-02
I0208 20:58:19.804272 22542570456896 run_lib.py:146] step: 81900, eval_loss: 2.67284e-02
I0208 20:58:37.373368 22542570456896 run_lib.py:133] step: 81950, training_loss: 3.10937e-02
I0208 20:58:54.896014 22542570456896 run_lib.py:133] step: 82000, training_loss: 3.03996e-02
I0208 20:58:55.067639 22542570456896 run_lib.py:146] step: 82000, eval_loss: 3.20200e-02
I0208 20:59:12.655487 22542570456896 run_lib.py:133] step: 82050, training_loss: 3.38029e-02
I0208 20:59:30.092766 22542570456896 run_lib.py:133] step: 82100, training_loss: 3.12919e-02
I0208 20:59:30.256676 22542570456896 run_lib.py:146] step: 82100, eval_loss: 3.30953e-02
I0208 20:59:47.713346 22542570456896 run_lib.py:133] step: 82150, training_loss: 2.58448e-02
I0208 21:00:05.304400 22542570456896 run_lib.py:133] step: 82200, training_loss: 2.38109e-02
I0208 21:00:05.473319 22542570456896 run_lib.py:146] step: 82200, eval_loss: 3.17321e-02
I0208 21:00:22.907239 22542570456896 run_lib.py:133] step: 82250, training_loss: 2.61116e-02
I0208 21:00:40.365366 22542570456896 run_lib.py:133] step: 82300, training_loss: 3.30278e-02
I0208 21:00:40.521560 22542570456896 run_lib.py:146] step: 82300, eval_loss: 3.57886e-02
I0208 21:00:58.130224 22542570456896 run_lib.py:133] step: 82350, training_loss: 2.83417e-02
I0208 21:01:15.573510 22542570456896 run_lib.py:133] step: 82400, training_loss: 2.39099e-02
I0208 21:01:15.734424 22542570456896 run_lib.py:146] step: 82400, eval_loss: 3.04953e-02
I0208 21:01:33.298619 22542570456896 run_lib.py:133] step: 82450, training_loss: 3.09952e-02
I0208 21:01:50.743079 22542570456896 run_lib.py:133] step: 82500, training_loss: 2.92421e-02
I0208 21:01:50.921709 22542570456896 run_lib.py:146] step: 82500, eval_loss: 3.24373e-02
I0208 21:02:08.372196 22542570456896 run_lib.py:133] step: 82550, training_loss: 3.26851e-02
I0208 21:02:25.948701 22542570456896 run_lib.py:133] step: 82600, training_loss: 2.29644e-02
I0208 21:02:26.106379 22542570456896 run_lib.py:146] step: 82600, eval_loss: 2.76124e-02
I0208 21:02:43.409370 22542570456896 run_lib.py:133] step: 82650, training_loss: 3.34129e-02
I0208 21:03:00.703960 22542570456896 run_lib.py:133] step: 82700, training_loss: 3.12203e-02
I0208 21:03:00.858922 22542570456896 run_lib.py:146] step: 82700, eval_loss: 2.51355e-02
I0208 21:03:18.171431 22542570456896 run_lib.py:133] step: 82750, training_loss: 3.44906e-02
I0208 21:03:35.831912 22542570456896 run_lib.py:133] step: 82800, training_loss: 3.05916e-02
I0208 21:03:35.988601 22542570456896 run_lib.py:146] step: 82800, eval_loss: 2.08213e-02
I0208 21:03:53.433967 22542570456896 run_lib.py:133] step: 82850, training_loss: 2.35786e-02
I0208 21:04:10.970353 22542570456896 run_lib.py:133] step: 82900, training_loss: 3.94544e-02
I0208 21:04:11.122278 22542570456896 run_lib.py:146] step: 82900, eval_loss: 2.96951e-02
I0208 21:04:28.537313 22542570456896 run_lib.py:133] step: 82950, training_loss: 2.40643e-02
I0208 21:04:45.965609 22542570456896 run_lib.py:133] step: 83000, training_loss: 3.49585e-02
I0208 21:04:46.142397 22542570456896 run_lib.py:146] step: 83000, eval_loss: 3.61839e-02
I0208 21:05:03.760550 22542570456896 run_lib.py:133] step: 83050, training_loss: 3.18826e-02
I0208 21:05:21.325205 22542570456896 run_lib.py:133] step: 83100, training_loss: 2.16664e-02
I0208 21:05:21.481571 22542570456896 run_lib.py:146] step: 83100, eval_loss: 2.59045e-02
I0208 21:05:38.921116 22542570456896 run_lib.py:133] step: 83150, training_loss: 2.78373e-02
I0208 21:05:56.385711 22542570456896 run_lib.py:133] step: 83200, training_loss: 3.12987e-02
I0208 21:05:56.541374 22542570456896 run_lib.py:146] step: 83200, eval_loss: 2.57804e-02
I0208 21:06:14.101737 22542570456896 run_lib.py:133] step: 83250, training_loss: 2.80069e-02
I0208 21:06:31.599613 22542570456896 run_lib.py:133] step: 83300, training_loss: 2.57042e-02
I0208 21:06:31.755200 22542570456896 run_lib.py:146] step: 83300, eval_loss: 3.51266e-02
I0208 21:06:49.366040 22542570456896 run_lib.py:133] step: 83350, training_loss: 3.50347e-02
I0208 21:07:06.807425 22542570456896 run_lib.py:133] step: 83400, training_loss: 3.15665e-02
I0208 21:07:06.960331 22542570456896 run_lib.py:146] step: 83400, eval_loss: 2.84726e-02
I0208 21:07:24.555247 22542570456896 run_lib.py:133] step: 83450, training_loss: 3.13855e-02
I0208 21:07:41.992053 22542570456896 run_lib.py:133] step: 83500, training_loss: 2.84857e-02
I0208 21:07:42.147461 22542570456896 run_lib.py:146] step: 83500, eval_loss: 2.66777e-02
I0208 21:07:59.589676 22542570456896 run_lib.py:133] step: 83550, training_loss: 3.49919e-02
I0208 21:08:17.249649 22542570456896 run_lib.py:133] step: 83600, training_loss: 2.47460e-02
I0208 21:08:17.406474 22542570456896 run_lib.py:146] step: 83600, eval_loss: 2.81703e-02
I0208 21:08:34.837285 22542570456896 run_lib.py:133] step: 83650, training_loss: 3.39036e-02
I0208 21:08:52.446690 22542570456896 run_lib.py:133] step: 83700, training_loss: 2.86125e-02
I0208 21:08:52.604026 22542570456896 run_lib.py:146] step: 83700, eval_loss: 3.06702e-02
I0208 21:09:10.035228 22542570456896 run_lib.py:133] step: 83750, training_loss: 2.37748e-02
I0208 21:09:27.509754 22542570456896 run_lib.py:133] step: 83800, training_loss: 3.44627e-02
I0208 21:09:27.664522 22542570456896 run_lib.py:146] step: 83800, eval_loss: 2.56176e-02
I0208 21:09:45.348566 22542570456896 run_lib.py:133] step: 83850, training_loss: 2.91364e-02
I0208 21:10:02.770035 22542570456896 run_lib.py:133] step: 83900, training_loss: 3.33918e-02
I0208 21:10:02.927319 22542570456896 run_lib.py:146] step: 83900, eval_loss: 2.92373e-02
I0208 21:10:20.346573 22542570456896 run_lib.py:133] step: 83950, training_loss: 2.74429e-02
I0208 21:10:37.907546 22542570456896 run_lib.py:133] step: 84000, training_loss: 2.86180e-02
I0208 21:10:38.066492 22542570456896 run_lib.py:146] step: 84000, eval_loss: 3.02486e-02
I0208 21:10:55.502649 22542570456896 run_lib.py:133] step: 84050, training_loss: 2.76896e-02
I0208 21:11:12.958875 22542570456896 run_lib.py:133] step: 84100, training_loss: 2.71249e-02
I0208 21:11:13.292461 22542570456896 run_lib.py:146] step: 84100, eval_loss: 3.28378e-02
I0208 21:11:30.735732 22542570456896 run_lib.py:133] step: 84150, training_loss: 2.76718e-02
I0208 21:11:48.156546 22542570456896 run_lib.py:133] step: 84200, training_loss: 3.12018e-02
I0208 21:11:48.320363 22542570456896 run_lib.py:146] step: 84200, eval_loss: 3.45569e-02
I0208 21:12:05.742251 22542570456896 run_lib.py:133] step: 84250, training_loss: 3.34816e-02
I0208 21:12:23.196284 22542570456896 run_lib.py:133] step: 84300, training_loss: 3.10948e-02
I0208 21:12:23.347712 22542570456896 run_lib.py:146] step: 84300, eval_loss: 2.65490e-02
I0208 21:12:40.946390 22542570456896 run_lib.py:133] step: 84350, training_loss: 3.80426e-02
I0208 21:12:58.486279 22542570456896 run_lib.py:133] step: 84400, training_loss: 2.76049e-02
I0208 21:12:58.656488 22542570456896 run_lib.py:146] step: 84400, eval_loss: 2.62230e-02
I0208 21:13:16.121660 22542570456896 run_lib.py:133] step: 84450, training_loss: 3.35808e-02
I0208 21:13:33.541801 22542570456896 run_lib.py:133] step: 84500, training_loss: 3.34511e-02
I0208 21:13:33.700529 22542570456896 run_lib.py:146] step: 84500, eval_loss: 2.21782e-02
I0208 21:13:51.286482 22542570456896 run_lib.py:133] step: 84550, training_loss: 2.92329e-02
I0208 21:14:08.806630 22542570456896 run_lib.py:133] step: 84600, training_loss: 2.49364e-02
I0208 21:14:08.963052 22542570456896 run_lib.py:146] step: 84600, eval_loss: 2.52983e-02
I0208 21:14:26.385393 22542570456896 run_lib.py:133] step: 84650, training_loss: 3.12494e-02
I0208 21:14:43.819783 22542570456896 run_lib.py:133] step: 84700, training_loss: 2.95008e-02
I0208 21:14:43.976557 22542570456896 run_lib.py:146] step: 84700, eval_loss: 2.18250e-02
I0208 21:15:01.600808 22542570456896 run_lib.py:133] step: 84750, training_loss: 3.09074e-02
I0208 21:15:19.006942 22542570456896 run_lib.py:133] step: 84800, training_loss: 3.19662e-02
I0208 21:15:19.160351 22542570456896 run_lib.py:146] step: 84800, eval_loss: 2.94464e-02
I0208 21:15:36.700492 22542570456896 run_lib.py:133] step: 84850, training_loss: 2.58753e-02
I0208 21:15:54.088096 22542570456896 run_lib.py:133] step: 84900, training_loss: 2.70067e-02
I0208 21:15:54.266360 22542570456896 run_lib.py:146] step: 84900, eval_loss: 3.27599e-02
I0208 21:16:11.878235 22542570456896 run_lib.py:133] step: 84950, training_loss: 2.81479e-02
I0208 21:16:29.341383 22542570456896 run_lib.py:133] step: 85000, training_loss: 2.84532e-02
I0208 21:16:29.500367 22542570456896 run_lib.py:146] step: 85000, eval_loss: 2.73258e-02
I0208 21:16:46.935484 22542570456896 run_lib.py:133] step: 85050, training_loss: 2.25556e-02
I0208 21:17:04.521179 22542570456896 run_lib.py:133] step: 85100, training_loss: 2.34844e-02
I0208 21:17:04.675396 22542570456896 run_lib.py:146] step: 85100, eval_loss: 2.71272e-02
I0208 21:17:22.137121 22542570456896 run_lib.py:133] step: 85150, training_loss: 3.01706e-02
I0208 21:17:39.690303 22542570456896 run_lib.py:133] step: 85200, training_loss: 3.63482e-02
I0208 21:17:39.846685 22542570456896 run_lib.py:146] step: 85200, eval_loss: 2.95900e-02
I0208 21:17:57.307734 22542570456896 run_lib.py:133] step: 85250, training_loss: 2.68025e-02
I0208 21:18:14.723667 22542570456896 run_lib.py:133] step: 85300, training_loss: 3.09653e-02
I0208 21:18:14.877261 22542570456896 run_lib.py:146] step: 85300, eval_loss: 2.46974e-02
I0208 21:18:32.478971 22542570456896 run_lib.py:133] step: 85350, training_loss: 2.61949e-02
I0208 21:18:49.908390 22542570456896 run_lib.py:133] step: 85400, training_loss: 2.56396e-02
I0208 21:18:50.068219 22542570456896 run_lib.py:146] step: 85400, eval_loss: 2.63187e-02
I0208 21:19:07.487995 22542570456896 run_lib.py:133] step: 85450, training_loss: 3.52545e-02
I0208 21:19:24.911175 22542570456896 run_lib.py:133] step: 85500, training_loss: 2.89206e-02
I0208 21:19:25.080254 22542570456896 run_lib.py:146] step: 85500, eval_loss: 2.61754e-02
I0208 21:19:42.746843 22542570456896 run_lib.py:133] step: 85550, training_loss: 2.62681e-02
I0208 21:20:00.187419 22542570456896 run_lib.py:133] step: 85600, training_loss: 3.44825e-02
I0208 21:20:00.347663 22542570456896 run_lib.py:146] step: 85600, eval_loss: 2.58383e-02
I0208 21:20:17.868009 22542570456896 run_lib.py:133] step: 85650, training_loss: 3.18534e-02
I0208 21:20:35.294416 22542570456896 run_lib.py:133] step: 85700, training_loss: 2.74489e-02
I0208 21:20:35.449852 22542570456896 run_lib.py:146] step: 85700, eval_loss: 2.77479e-02
I0208 21:20:52.854406 22542570456896 run_lib.py:133] step: 85750, training_loss: 2.66214e-02
I0208 21:21:10.297983 22542570456896 run_lib.py:133] step: 85800, training_loss: 2.62917e-02
I0208 21:21:10.469120 22542570456896 run_lib.py:146] step: 85800, eval_loss: 3.34720e-02
I0208 21:21:28.090931 22542570456896 run_lib.py:133] step: 85850, training_loss: 2.24634e-02
I0208 21:21:45.664976 22542570456896 run_lib.py:133] step: 85900, training_loss: 2.82621e-02
I0208 21:21:45.826429 22542570456896 run_lib.py:146] step: 85900, eval_loss: 2.38092e-02
I0208 21:22:03.232735 22542570456896 run_lib.py:133] step: 85950, training_loss: 3.29490e-02
I0208 21:22:20.656139 22542570456896 run_lib.py:133] step: 86000, training_loss: 2.81623e-02
I0208 21:22:20.814297 22542570456896 run_lib.py:146] step: 86000, eval_loss: 2.70917e-02
I0208 21:22:38.368587 22542570456896 run_lib.py:133] step: 86050, training_loss: 2.78666e-02
I0208 21:22:55.880568 22542570456896 run_lib.py:133] step: 86100, training_loss: 3.07227e-02
I0208 21:22:56.036672 22542570456896 run_lib.py:146] step: 86100, eval_loss: 2.48650e-02
I0208 21:23:13.624474 22542570456896 run_lib.py:133] step: 86150, training_loss: 2.63507e-02
I0208 21:23:31.036371 22542570456896 run_lib.py:133] step: 86200, training_loss: 2.36107e-02
I0208 21:23:31.194997 22542570456896 run_lib.py:146] step: 86200, eval_loss: 2.35389e-02
I0208 21:23:48.783363 22542570456896 run_lib.py:133] step: 86250, training_loss: 3.00947e-02
I0208 21:24:06.244156 22542570456896 run_lib.py:133] step: 86300, training_loss: 3.24178e-02
I0208 21:24:06.401168 22542570456896 run_lib.py:146] step: 86300, eval_loss: 3.07948e-02
I0208 21:24:23.994731 22542570456896 run_lib.py:133] step: 86350, training_loss: 2.93268e-02
I0208 21:24:41.507243 22542570456896 run_lib.py:133] step: 86400, training_loss: 3.04251e-02
I0208 21:24:41.668315 22542570456896 run_lib.py:146] step: 86400, eval_loss: 2.64242e-02
I0208 21:24:59.068539 22542570456896 run_lib.py:133] step: 86450, training_loss: 2.65360e-02
I0208 21:25:16.676033 22542570456896 run_lib.py:133] step: 86500, training_loss: 3.15077e-02
I0208 21:25:16.831506 22542570456896 run_lib.py:146] step: 86500, eval_loss: 2.61371e-02
I0208 21:25:34.234776 22542570456896 run_lib.py:133] step: 86550, training_loss: 2.83087e-02
I0208 21:25:51.665604 22542570456896 run_lib.py:133] step: 86600, training_loss: 3.12309e-02
I0208 21:25:51.822345 22542570456896 run_lib.py:146] step: 86600, eval_loss: 3.46649e-02
I0208 21:26:09.438439 22542570456896 run_lib.py:133] step: 86650, training_loss: 2.50782e-02
I0208 21:26:27.122966 22542570456896 run_lib.py:133] step: 86700, training_loss: 2.64395e-02
I0208 21:26:27.282535 22542570456896 run_lib.py:146] step: 86700, eval_loss: 2.76076e-02
I0208 21:26:44.730731 22542570456896 run_lib.py:133] step: 86750, training_loss: 3.02047e-02
I0208 21:27:02.134549 22542570456896 run_lib.py:133] step: 86800, training_loss: 3.03640e-02
I0208 21:27:02.295651 22542570456896 run_lib.py:146] step: 86800, eval_loss: 2.62321e-02
I0208 21:27:19.752914 22542570456896 run_lib.py:133] step: 86850, training_loss: 3.42154e-02
I0208 21:27:37.314139 22542570456896 run_lib.py:133] step: 86900, training_loss: 2.67147e-02
I0208 21:27:37.480240 22542570456896 run_lib.py:146] step: 86900, eval_loss: 2.74103e-02
I0208 21:27:54.905816 22542570456896 run_lib.py:133] step: 86950, training_loss: 3.45615e-02
I0208 21:28:12.325334 22542570456896 run_lib.py:133] step: 87000, training_loss: 2.89732e-02
I0208 21:28:12.483084 22542570456896 run_lib.py:146] step: 87000, eval_loss: 2.28280e-02
I0208 21:28:29.886924 22542570456896 run_lib.py:133] step: 87050, training_loss: 3.22132e-02
I0208 21:28:47.515492 22542570456896 run_lib.py:133] step: 87100, training_loss: 3.05093e-02
I0208 21:28:47.669103 22542570456896 run_lib.py:146] step: 87100, eval_loss: 2.21184e-02
I0208 21:29:05.059579 22542570456896 run_lib.py:133] step: 87150, training_loss: 3.35500e-02
I0208 21:29:22.577441 22542570456896 run_lib.py:133] step: 87200, training_loss: 3.32940e-02
I0208 21:29:22.735548 22542570456896 run_lib.py:146] step: 87200, eval_loss: 3.60389e-02
I0208 21:29:40.208784 22542570456896 run_lib.py:133] step: 87250, training_loss: 3.69622e-02
I0208 21:29:57.685104 22542570456896 run_lib.py:133] step: 87300, training_loss: 2.90485e-02
I0208 21:29:57.844358 22542570456896 run_lib.py:146] step: 87300, eval_loss: 2.48654e-02
I0208 21:30:15.403858 22542570456896 run_lib.py:133] step: 87350, training_loss: 2.68160e-02
I0208 21:30:32.878888 22542570456896 run_lib.py:133] step: 87400, training_loss: 2.61268e-02
I0208 21:30:33.035310 22542570456896 run_lib.py:146] step: 87400, eval_loss: 3.28099e-02
I0208 21:30:50.448996 22542570456896 run_lib.py:133] step: 87450, training_loss: 3.13147e-02
I0208 21:31:07.883554 22542570456896 run_lib.py:133] step: 87500, training_loss: 2.87414e-02
I0208 21:31:08.041537 22542570456896 run_lib.py:146] step: 87500, eval_loss: 3.23236e-02
I0208 21:31:25.665065 22542570456896 run_lib.py:133] step: 87550, training_loss: 2.95409e-02
I0208 21:31:43.140264 22542570456896 run_lib.py:133] step: 87600, training_loss: 2.92130e-02
I0208 21:31:43.293372 22542570456896 run_lib.py:146] step: 87600, eval_loss: 2.13920e-02
I0208 21:32:00.893216 22542570456896 run_lib.py:133] step: 87650, training_loss: 2.15376e-02
I0208 21:32:18.349362 22542570456896 run_lib.py:133] step: 87700, training_loss: 3.29840e-02
I0208 21:32:18.506255 22542570456896 run_lib.py:146] step: 87700, eval_loss: 3.15605e-02
I0208 21:32:36.050221 22542570456896 run_lib.py:133] step: 87750, training_loss: 3.20983e-02
I0208 21:32:53.508265 22542570456896 run_lib.py:133] step: 87800, training_loss: 3.06996e-02
I0208 21:32:53.684187 22542570456896 run_lib.py:146] step: 87800, eval_loss: 2.44203e-02
I0208 21:33:11.172732 22542570456896 run_lib.py:133] step: 87850, training_loss: 2.53798e-02
I0208 21:33:28.778070 22542570456896 run_lib.py:133] step: 87900, training_loss: 2.36232e-02
I0208 21:33:28.932430 22542570456896 run_lib.py:146] step: 87900, eval_loss: 3.09097e-02
I0208 21:33:46.334961 22542570456896 run_lib.py:133] step: 87950, training_loss: 2.62960e-02
I0208 21:34:03.894015 22542570456896 run_lib.py:133] step: 88000, training_loss: 3.08176e-02
I0208 21:34:04.052828 22542570456896 run_lib.py:146] step: 88000, eval_loss: 2.68317e-02
I0208 21:34:21.536259 22542570456896 run_lib.py:133] step: 88050, training_loss: 2.94164e-02
I0208 21:34:38.987796 22542570456896 run_lib.py:133] step: 88100, training_loss: 2.75684e-02
I0208 21:34:39.142822 22542570456896 run_lib.py:146] step: 88100, eval_loss: 2.18779e-02
I0208 21:34:56.760637 22542570456896 run_lib.py:133] step: 88150, training_loss: 2.49182e-02
I0208 21:35:14.203372 22542570456896 run_lib.py:133] step: 88200, training_loss: 3.20773e-02
I0208 21:35:14.361707 22542570456896 run_lib.py:146] step: 88200, eval_loss: 2.93718e-02
I0208 21:35:31.766934 22542570456896 run_lib.py:133] step: 88250, training_loss: 2.69138e-02
I0208 21:35:49.319142 22542570456896 run_lib.py:133] step: 88300, training_loss: 3.08203e-02
I0208 21:35:49.477327 22542570456896 run_lib.py:146] step: 88300, eval_loss: 3.07364e-02
I0208 21:36:06.902653 22542570456896 run_lib.py:133] step: 88350, training_loss: 2.71717e-02
I0208 21:36:24.343535 22542570456896 run_lib.py:133] step: 88400, training_loss: 3.10728e-02
I0208 21:36:24.498043 22542570456896 run_lib.py:146] step: 88400, eval_loss: 2.29273e-02
I0208 21:36:42.017558 22542570456896 run_lib.py:133] step: 88450, training_loss: 3.07654e-02
I0208 21:36:59.462833 22542570456896 run_lib.py:133] step: 88500, training_loss: 3.05165e-02
I0208 21:36:59.617550 22542570456896 run_lib.py:146] step: 88500, eval_loss: 2.27834e-02
I0208 21:37:16.996455 22542570456896 run_lib.py:133] step: 88550, training_loss: 2.71375e-02
I0208 21:37:34.443202 22542570456896 run_lib.py:133] step: 88600, training_loss: 3.05871e-02
I0208 21:37:34.594302 22542570456896 run_lib.py:146] step: 88600, eval_loss: 2.36274e-02
I0208 21:37:52.229439 22542570456896 run_lib.py:133] step: 88650, training_loss: 3.65426e-02
I0208 21:38:09.789474 22542570456896 run_lib.py:133] step: 88700, training_loss: 3.00593e-02
I0208 21:38:09.950609 22542570456896 run_lib.py:146] step: 88700, eval_loss: 3.39317e-02
I0208 21:38:27.354536 22542570456896 run_lib.py:133] step: 88750, training_loss: 3.16339e-02
I0208 21:38:44.749235 22542570456896 run_lib.py:133] step: 88800, training_loss: 3.07559e-02
I0208 21:38:44.911339 22542570456896 run_lib.py:146] step: 88800, eval_loss: 1.99640e-02
I0208 21:39:02.480656 22542570456896 run_lib.py:133] step: 88850, training_loss: 2.52886e-02
I0208 21:39:19.964457 22542570456896 run_lib.py:133] step: 88900, training_loss: 2.71960e-02
I0208 21:39:20.123168 22542570456896 run_lib.py:146] step: 88900, eval_loss: 2.59640e-02
I0208 21:39:37.736023 22542570456896 run_lib.py:133] step: 88950, training_loss: 3.58077e-02
I0208 21:39:55.171071 22542570456896 run_lib.py:133] step: 89000, training_loss: 2.45906e-02
I0208 21:39:55.324130 22542570456896 run_lib.py:146] step: 89000, eval_loss: 3.07402e-02
I0208 21:40:12.930335 22542570456896 run_lib.py:133] step: 89050, training_loss: 2.53035e-02
I0208 21:40:30.365982 22542570456896 run_lib.py:133] step: 89100, training_loss: 2.93022e-02
I0208 21:40:30.529455 22542570456896 run_lib.py:146] step: 89100, eval_loss: 2.48895e-02
I0208 21:40:48.070176 22542570456896 run_lib.py:133] step: 89150, training_loss: 2.49593e-02
I0208 21:41:05.504909 22542570456896 run_lib.py:133] step: 89200, training_loss: 2.63690e-02
I0208 21:41:05.675073 22542570456896 run_lib.py:146] step: 89200, eval_loss: 2.97908e-02
I0208 21:41:23.189538 22542570456896 run_lib.py:133] step: 89250, training_loss: 2.40579e-02
I0208 21:41:40.772602 22542570456896 run_lib.py:133] step: 89300, training_loss: 3.41542e-02
I0208 21:41:40.929366 22542570456896 run_lib.py:146] step: 89300, eval_loss: 3.49666e-02
I0208 21:41:58.338705 22542570456896 run_lib.py:133] step: 89350, training_loss: 3.59236e-02
I0208 21:42:15.760749 22542570456896 run_lib.py:133] step: 89400, training_loss: 2.45275e-02
I0208 21:42:15.917273 22542570456896 run_lib.py:146] step: 89400, eval_loss: 2.82106e-02
I0208 21:42:33.516792 22542570456896 run_lib.py:133] step: 89450, training_loss: 3.65351e-02
I0208 21:42:50.993885 22542570456896 run_lib.py:133] step: 89500, training_loss: 3.10274e-02
I0208 21:42:51.156550 22542570456896 run_lib.py:146] step: 89500, eval_loss: 3.14254e-02
I0208 21:43:08.809945 22542570456896 run_lib.py:133] step: 89550, training_loss: 2.58183e-02
I0208 21:43:26.281781 22542570456896 run_lib.py:133] step: 89600, training_loss: 3.19145e-02
I0208 21:43:26.437422 22542570456896 run_lib.py:146] step: 89600, eval_loss: 3.28711e-02
I0208 21:43:43.864650 22542570456896 run_lib.py:133] step: 89650, training_loss: 2.32916e-02
I0208 21:44:01.445254 22542570456896 run_lib.py:133] step: 89700, training_loss: 2.95462e-02
I0208 21:44:01.606409 22542570456896 run_lib.py:146] step: 89700, eval_loss: 3.04772e-02
I0208 21:44:19.012165 22542570456896 run_lib.py:133] step: 89750, training_loss: 2.87998e-02
I0208 21:44:36.439046 22542570456896 run_lib.py:133] step: 89800, training_loss: 3.56574e-02
I0208 21:44:36.596514 22542570456896 run_lib.py:146] step: 89800, eval_loss: 3.21655e-02
I0208 21:44:54.050588 22542570456896 run_lib.py:133] step: 89850, training_loss: 2.44915e-02
I0208 21:45:11.640306 22542570456896 run_lib.py:133] step: 89900, training_loss: 2.34207e-02
I0208 21:45:11.795266 22542570456896 run_lib.py:146] step: 89900, eval_loss: 1.91543e-02
I0208 21:45:29.200083 22542570456896 run_lib.py:133] step: 89950, training_loss: 2.90354e-02
I0208 21:45:46.707464 22542570456896 run_lib.py:133] step: 90000, training_loss: 2.96495e-02
I0208 21:45:47.405305 22542570456896 run_lib.py:146] step: 90000, eval_loss: 3.07465e-02
I0208 21:46:07.460229 22542570456896 run_lib.py:133] step: 90050, training_loss: 2.44442e-02
I0208 21:46:24.885734 22542570456896 run_lib.py:133] step: 90100, training_loss: 3.10095e-02
I0208 21:46:25.042600 22542570456896 run_lib.py:146] step: 90100, eval_loss: 2.64563e-02
I0208 21:46:42.696023 22542570456896 run_lib.py:133] step: 90150, training_loss: 2.65362e-02
I0208 21:47:00.144049 22542570456896 run_lib.py:133] step: 90200, training_loss: 3.44037e-02
I0208 21:47:00.303532 22542570456896 run_lib.py:146] step: 90200, eval_loss: 2.41155e-02
I0208 21:47:17.776293 22542570456896 run_lib.py:133] step: 90250, training_loss: 3.11482e-02
I0208 21:47:35.195794 22542570456896 run_lib.py:133] step: 90300, training_loss: 3.00959e-02
I0208 21:47:35.362284 22542570456896 run_lib.py:146] step: 90300, eval_loss: 2.87100e-02
I0208 21:47:52.797364 22542570456896 run_lib.py:133] step: 90350, training_loss: 2.88737e-02
I0208 21:48:10.266851 22542570456896 run_lib.py:133] step: 90400, training_loss: 2.61495e-02
I0208 21:48:10.432115 22542570456896 run_lib.py:146] step: 90400, eval_loss: 2.53791e-02
I0208 21:48:28.046865 22542570456896 run_lib.py:133] step: 90450, training_loss: 3.12125e-02
I0208 21:48:45.524665 22542570456896 run_lib.py:133] step: 90500, training_loss: 2.74524e-02
I0208 21:48:45.686423 22542570456896 run_lib.py:146] step: 90500, eval_loss: 2.78501e-02
I0208 21:49:03.144235 22542570456896 run_lib.py:133] step: 90550, training_loss: 3.43017e-02
I0208 21:49:20.595925 22542570456896 run_lib.py:133] step: 90600, training_loss: 2.44917e-02
I0208 21:49:20.770394 22542570456896 run_lib.py:146] step: 90600, eval_loss: 3.10297e-02
I0208 21:49:38.388376 22542570456896 run_lib.py:133] step: 90650, training_loss: 3.23871e-02
I0208 21:49:55.834300 22542570456896 run_lib.py:133] step: 90700, training_loss: 2.75775e-02
I0208 21:49:55.993557 22542570456896 run_lib.py:146] step: 90700, eval_loss: 3.34283e-02
I0208 21:50:13.572908 22542570456896 run_lib.py:133] step: 90750, training_loss: 2.79194e-02
I0208 21:50:30.998383 22542570456896 run_lib.py:133] step: 90800, training_loss: 2.87949e-02
I0208 21:50:31.163228 22542570456896 run_lib.py:146] step: 90800, eval_loss: 2.76235e-02
I0208 21:50:48.719764 22542570456896 run_lib.py:133] step: 90850, training_loss: 2.53234e-02
I0208 21:51:06.135793 22542570456896 run_lib.py:133] step: 90900, training_loss: 2.80783e-02
I0208 21:51:06.297759 22542570456896 run_lib.py:146] step: 90900, eval_loss: 2.95375e-02
I0208 21:51:23.758177 22542570456896 run_lib.py:133] step: 90950, training_loss: 3.30803e-02
I0208 21:51:41.405967 22542570456896 run_lib.py:133] step: 91000, training_loss: 2.66498e-02
I0208 21:51:41.558481 22542570456896 run_lib.py:146] step: 91000, eval_loss: 3.14721e-02
I0208 21:51:59.000249 22542570456896 run_lib.py:133] step: 91050, training_loss: 2.93192e-02
I0208 21:52:16.570307 22542570456896 run_lib.py:133] step: 91100, training_loss: 3.07202e-02
I0208 21:52:16.727379 22542570456896 run_lib.py:146] step: 91100, eval_loss: 2.22203e-02
I0208 21:52:34.126306 22542570456896 run_lib.py:133] step: 91150, training_loss: 2.48727e-02
I0208 21:52:51.579077 22542570456896 run_lib.py:133] step: 91200, training_loss: 2.72242e-02
I0208 21:52:51.751464 22542570456896 run_lib.py:146] step: 91200, eval_loss: 2.79363e-02
I0208 21:53:09.392256 22542570456896 run_lib.py:133] step: 91250, training_loss: 2.82665e-02
I0208 21:53:26.812466 22542570456896 run_lib.py:133] step: 91300, training_loss: 2.84263e-02
I0208 21:53:26.969504 22542570456896 run_lib.py:146] step: 91300, eval_loss: 3.33172e-02
I0208 21:53:44.383703 22542570456896 run_lib.py:133] step: 91350, training_loss: 2.85464e-02
I0208 21:54:01.956838 22542570456896 run_lib.py:133] step: 91400, training_loss: 2.80674e-02
I0208 21:54:02.112263 22542570456896 run_lib.py:146] step: 91400, eval_loss: 2.61940e-02
I0208 21:54:19.544556 22542570456896 run_lib.py:133] step: 91450, training_loss: 3.51817e-02
I0208 21:54:36.986153 22542570456896 run_lib.py:133] step: 91500, training_loss: 2.52157e-02
I0208 21:54:37.287232 22542570456896 run_lib.py:146] step: 91500, eval_loss: 3.79290e-02
I0208 21:54:54.762708 22542570456896 run_lib.py:133] step: 91550, training_loss: 3.86215e-02
I0208 21:55:12.240333 22542570456896 run_lib.py:133] step: 91600, training_loss: 3.05162e-02
I0208 21:55:12.407357 22542570456896 run_lib.py:146] step: 91600, eval_loss: 2.56450e-02
I0208 21:55:29.817101 22542570456896 run_lib.py:133] step: 91650, training_loss: 2.61197e-02
I0208 21:55:47.237740 22542570456896 run_lib.py:133] step: 91700, training_loss: 2.66334e-02
I0208 21:55:47.397687 22542570456896 run_lib.py:146] step: 91700, eval_loss: 2.52769e-02
I0208 21:56:05.046759 22542570456896 run_lib.py:133] step: 91750, training_loss: 3.82980e-02
I0208 21:56:22.610189 22542570456896 run_lib.py:133] step: 91800, training_loss: 3.11542e-02
I0208 21:56:22.768276 22542570456896 run_lib.py:146] step: 91800, eval_loss: 2.44353e-02
I0208 21:56:40.243199 22542570456896 run_lib.py:133] step: 91850, training_loss: 2.70104e-02
I0208 21:56:57.677875 22542570456896 run_lib.py:133] step: 91900, training_loss: 2.57066e-02
I0208 21:56:57.836177 22542570456896 run_lib.py:146] step: 91900, eval_loss: 2.86409e-02
I0208 21:57:15.425858 22542570456896 run_lib.py:133] step: 91950, training_loss: 2.90839e-02
I0208 21:57:32.916202 22542570456896 run_lib.py:133] step: 92000, training_loss: 2.87282e-02
I0208 21:57:33.072825 22542570456896 run_lib.py:146] step: 92000, eval_loss: 2.57717e-02
I0208 21:57:50.594028 22542570456896 run_lib.py:133] step: 92050, training_loss: 2.90850e-02
I0208 21:58:08.050202 22542570456896 run_lib.py:133] step: 92100, training_loss: 2.63204e-02
I0208 21:58:08.209306 22542570456896 run_lib.py:146] step: 92100, eval_loss: 3.46822e-02
I0208 21:58:25.819729 22542570456896 run_lib.py:133] step: 92150, training_loss: 2.82513e-02
I0208 21:58:43.239038 22542570456896 run_lib.py:133] step: 92200, training_loss: 3.01834e-02
I0208 21:58:43.396345 22542570456896 run_lib.py:146] step: 92200, eval_loss: 3.34266e-02
I0208 21:59:00.984464 22542570456896 run_lib.py:133] step: 92250, training_loss: 3.27165e-02
I0208 21:59:18.422025 22542570456896 run_lib.py:133] step: 92300, training_loss: 2.70573e-02
I0208 21:59:18.579512 22542570456896 run_lib.py:146] step: 92300, eval_loss: 2.32365e-02
I0208 21:59:36.240257 22542570456896 run_lib.py:133] step: 92350, training_loss: 2.85938e-02
I0208 21:59:53.659589 22542570456896 run_lib.py:133] step: 92400, training_loss: 2.48912e-02
I0208 21:59:53.816432 22542570456896 run_lib.py:146] step: 92400, eval_loss: 2.96615e-02
I0208 22:00:11.203225 22542570456896 run_lib.py:133] step: 92450, training_loss: 3.57486e-02
I0208 22:00:28.748718 22542570456896 run_lib.py:133] step: 92500, training_loss: 2.78935e-02
I0208 22:00:28.908454 22542570456896 run_lib.py:146] step: 92500, eval_loss: 2.47910e-02
I0208 22:00:46.301763 22542570456896 run_lib.py:133] step: 92550, training_loss: 2.86585e-02
I0208 22:01:03.885314 22542570456896 run_lib.py:133] step: 92600, training_loss: 2.89651e-02
I0208 22:01:04.061402 22542570456896 run_lib.py:146] step: 92600, eval_loss: 3.21248e-02
I0208 22:01:21.482957 22542570456896 run_lib.py:133] step: 92650, training_loss: 2.32302e-02
I0208 22:01:38.891162 22542570456896 run_lib.py:133] step: 92700, training_loss: 3.17079e-02
I0208 22:01:39.047650 22542570456896 run_lib.py:146] step: 92700, eval_loss: 2.45073e-02
I0208 22:01:56.658406 22542570456896 run_lib.py:133] step: 92750, training_loss: 3.18251e-02
I0208 22:02:14.034390 22542570456896 run_lib.py:133] step: 92800, training_loss: 2.70617e-02
I0208 22:02:14.190311 22542570456896 run_lib.py:146] step: 92800, eval_loss: 3.37118e-02
I0208 22:02:31.593306 22542570456896 run_lib.py:133] step: 92850, training_loss: 3.50436e-02
I0208 22:02:49.049901 22542570456896 run_lib.py:133] step: 92900, training_loss: 3.43009e-02
I0208 22:02:49.204628 22542570456896 run_lib.py:146] step: 92900, eval_loss: 2.86502e-02
I0208 22:03:06.883857 22542570456896 run_lib.py:133] step: 92950, training_loss: 2.77733e-02
I0208 22:03:24.356367 22542570456896 run_lib.py:133] step: 93000, training_loss: 3.20316e-02
I0208 22:03:24.520483 22542570456896 run_lib.py:146] step: 93000, eval_loss: 2.74485e-02
I0208 22:03:41.980770 22542570456896 run_lib.py:133] step: 93050, training_loss: 2.43984e-02
I0208 22:03:59.402376 22542570456896 run_lib.py:133] step: 93100, training_loss: 3.00849e-02
I0208 22:03:59.578482 22542570456896 run_lib.py:146] step: 93100, eval_loss: 2.83915e-02
I0208 22:04:17.080210 22542570456896 run_lib.py:133] step: 93150, training_loss: 3.14019e-02
I0208 22:04:34.509165 22542570456896 run_lib.py:133] step: 93200, training_loss: 2.27231e-02
I0208 22:04:34.666540 22542570456896 run_lib.py:146] step: 93200, eval_loss: 3.09155e-02
I0208 22:04:52.266120 22542570456896 run_lib.py:133] step: 93250, training_loss: 3.27055e-02
I0208 22:05:09.727692 22542570456896 run_lib.py:133] step: 93300, training_loss: 3.09875e-02
I0208 22:05:09.883339 22542570456896 run_lib.py:146] step: 93300, eval_loss: 2.75035e-02
I0208 22:05:27.308161 22542570456896 run_lib.py:133] step: 93350, training_loss: 3.40248e-02
I0208 22:05:44.776026 22542570456896 run_lib.py:133] step: 93400, training_loss: 2.11492e-02
I0208 22:05:44.939490 22542570456896 run_lib.py:146] step: 93400, eval_loss: 3.81404e-02
I0208 22:06:02.615383 22542570456896 run_lib.py:133] step: 93450, training_loss: 2.82878e-02
I0208 22:06:20.034600 22542570456896 run_lib.py:133] step: 93500, training_loss: 2.88321e-02
I0208 22:06:20.193243 22542570456896 run_lib.py:146] step: 93500, eval_loss: 2.73517e-02
I0208 22:06:37.783804 22542570456896 run_lib.py:133] step: 93550, training_loss: 2.79556e-02
I0208 22:06:55.202171 22542570456896 run_lib.py:133] step: 93600, training_loss: 2.87170e-02
I0208 22:06:55.359634 22542570456896 run_lib.py:146] step: 93600, eval_loss: 2.70589e-02
I0208 22:07:12.956191 22542570456896 run_lib.py:133] step: 93650, training_loss: 3.46278e-02
I0208 22:07:30.449749 22542570456896 run_lib.py:133] step: 93700, training_loss: 3.17259e-02
I0208 22:07:30.606146 22542570456896 run_lib.py:146] step: 93700, eval_loss: 2.62901e-02
I0208 22:07:48.229571 22542570456896 run_lib.py:133] step: 93750, training_loss: 3.02734e-02
I0208 22:08:05.645799 22542570456896 run_lib.py:133] step: 93800, training_loss: 3.41756e-02
I0208 22:08:05.800047 22542570456896 run_lib.py:146] step: 93800, eval_loss: 2.70239e-02
I0208 22:08:23.181199 22542570456896 run_lib.py:133] step: 93850, training_loss: 3.08645e-02
I0208 22:08:40.721770 22542570456896 run_lib.py:133] step: 93900, training_loss: 3.22719e-02
I0208 22:08:40.882651 22542570456896 run_lib.py:146] step: 93900, eval_loss: 2.77455e-02
I0208 22:08:58.415887 22542570456896 run_lib.py:133] step: 93950, training_loss: 3.06903e-02
I0208 22:09:15.853088 22542570456896 run_lib.py:133] step: 94000, training_loss: 2.75630e-02
I0208 22:09:16.012302 22542570456896 run_lib.py:146] step: 94000, eval_loss: 2.40575e-02
I0208 22:09:33.598077 22542570456896 run_lib.py:133] step: 94050, training_loss: 2.94248e-02
I0208 22:09:51.180732 22542570456896 run_lib.py:133] step: 94100, training_loss: 2.68768e-02
I0208 22:09:51.335032 22542570456896 run_lib.py:146] step: 94100, eval_loss: 2.49033e-02
I0208 22:10:08.743975 22542570456896 run_lib.py:133] step: 94150, training_loss: 3.47416e-02
I0208 22:10:26.144868 22542570456896 run_lib.py:133] step: 94200, training_loss: 2.87628e-02
I0208 22:10:26.303701 22542570456896 run_lib.py:146] step: 94200, eval_loss: 2.78860e-02
I0208 22:10:43.765886 22542570456896 run_lib.py:133] step: 94250, training_loss: 2.76596e-02
I0208 22:11:01.407276 22542570456896 run_lib.py:133] step: 94300, training_loss: 2.52491e-02
I0208 22:11:01.560234 22542570456896 run_lib.py:146] step: 94300, eval_loss: 2.22535e-02
I0208 22:11:18.868356 22542570456896 run_lib.py:133] step: 94350, training_loss: 2.96584e-02
I0208 22:11:36.196931 22542570456896 run_lib.py:133] step: 94400, training_loss: 3.17257e-02
I0208 22:11:36.351042 22542570456896 run_lib.py:146] step: 94400, eval_loss: 3.42258e-02
I0208 22:11:53.699900 22542570456896 run_lib.py:133] step: 94450, training_loss: 2.18237e-02
I0208 22:12:11.224421 22542570456896 run_lib.py:133] step: 94500, training_loss: 2.54660e-02
I0208 22:12:11.389442 22542570456896 run_lib.py:146] step: 94500, eval_loss: 3.14065e-02
I0208 22:12:28.801918 22542570456896 run_lib.py:133] step: 94550, training_loss: 3.03464e-02
I0208 22:12:46.329050 22542570456896 run_lib.py:133] step: 94600, training_loss: 2.60007e-02
I0208 22:12:46.485392 22542570456896 run_lib.py:146] step: 94600, eval_loss: 2.83520e-02
I0208 22:13:03.924649 22542570456896 run_lib.py:133] step: 94650, training_loss: 2.51734e-02
I0208 22:13:21.354698 22542570456896 run_lib.py:133] step: 94700, training_loss: 3.11133e-02
I0208 22:13:21.512560 22542570456896 run_lib.py:146] step: 94700, eval_loss: 2.96883e-02
I0208 22:13:39.101302 22542570456896 run_lib.py:133] step: 94750, training_loss: 2.99622e-02
I0208 22:13:56.613514 22542570456896 run_lib.py:133] step: 94800, training_loss: 3.04200e-02
I0208 22:13:56.766492 22542570456896 run_lib.py:146] step: 94800, eval_loss: 3.54387e-02
I0208 22:14:14.177124 22542570456896 run_lib.py:133] step: 94850, training_loss: 2.82448e-02
I0208 22:14:31.592813 22542570456896 run_lib.py:133] step: 94900, training_loss: 2.68507e-02
I0208 22:14:31.750593 22542570456896 run_lib.py:146] step: 94900, eval_loss: 2.81365e-02
I0208 22:14:49.314295 22542570456896 run_lib.py:133] step: 94950, training_loss: 3.60211e-02
I0208 22:15:06.768494 22542570456896 run_lib.py:133] step: 95000, training_loss: 2.61228e-02
I0208 22:15:06.954587 22542570456896 run_lib.py:146] step: 95000, eval_loss: 3.29824e-02
I0208 22:15:24.612978 22542570456896 run_lib.py:133] step: 95050, training_loss: 3.62274e-02
I0208 22:15:42.061244 22542570456896 run_lib.py:133] step: 95100, training_loss: 2.89210e-02
I0208 22:15:42.217586 22542570456896 run_lib.py:146] step: 95100, eval_loss: 2.33118e-02
I0208 22:15:59.839584 22542570456896 run_lib.py:133] step: 95150, training_loss: 2.73126e-02
I0208 22:16:17.271609 22542570456896 run_lib.py:133] step: 95200, training_loss: 2.75186e-02
I0208 22:16:17.429341 22542570456896 run_lib.py:146] step: 95200, eval_loss: 3.38593e-02
I0208 22:16:34.868658 22542570456896 run_lib.py:133] step: 95250, training_loss: 2.80030e-02
I0208 22:16:52.520352 22542570456896 run_lib.py:133] step: 95300, training_loss: 2.58643e-02
I0208 22:16:52.677576 22542570456896 run_lib.py:146] step: 95300, eval_loss: 2.54349e-02
I0208 22:17:10.160367 22542570456896 run_lib.py:133] step: 95350, training_loss: 2.90249e-02
I0208 22:17:27.767595 22542570456896 run_lib.py:133] step: 95400, training_loss: 2.44290e-02
I0208 22:17:27.928650 22542570456896 run_lib.py:146] step: 95400, eval_loss: 3.09390e-02
I0208 22:17:45.287971 22542570456896 run_lib.py:133] step: 95450, training_loss: 3.04165e-02
I0208 22:18:02.693931 22542570456896 run_lib.py:133] step: 95500, training_loss: 2.86018e-02
I0208 22:18:02.857351 22542570456896 run_lib.py:146] step: 95500, eval_loss: 3.08571e-02
I0208 22:18:20.424923 22542570456896 run_lib.py:133] step: 95550, training_loss: 2.71335e-02
I0208 22:18:37.907603 22542570456896 run_lib.py:133] step: 95600, training_loss: 3.05015e-02
I0208 22:18:38.064755 22542570456896 run_lib.py:146] step: 95600, eval_loss: 2.86787e-02
I0208 22:18:55.490020 22542570456896 run_lib.py:133] step: 95650, training_loss: 3.18416e-02
I0208 22:19:13.134369 22542570456896 run_lib.py:133] step: 95700, training_loss: 2.16432e-02
I0208 22:19:13.288074 22542570456896 run_lib.py:146] step: 95700, eval_loss: 3.28897e-02
I0208 22:19:30.676755 22542570456896 run_lib.py:133] step: 95750, training_loss: 2.73274e-02
I0208 22:19:48.088664 22542570456896 run_lib.py:133] step: 95800, training_loss: 2.55960e-02
I0208 22:19:48.258084 22542570456896 run_lib.py:146] step: 95800, eval_loss: 2.74279e-02
I0208 22:20:05.813502 22542570456896 run_lib.py:133] step: 95850, training_loss: 2.17778e-02
I0208 22:20:23.268636 22542570456896 run_lib.py:133] step: 95900, training_loss: 3.08527e-02
I0208 22:20:23.428392 22542570456896 run_lib.py:146] step: 95900, eval_loss: 2.61833e-02
I0208 22:20:40.838450 22542570456896 run_lib.py:133] step: 95950, training_loss: 3.11754e-02
I0208 22:20:58.247723 22542570456896 run_lib.py:133] step: 96000, training_loss: 3.50917e-02
I0208 22:20:58.413269 22542570456896 run_lib.py:146] step: 96000, eval_loss: 2.53153e-02
I0208 22:21:15.993805 22542570456896 run_lib.py:133] step: 96050, training_loss: 2.32603e-02
I0208 22:21:33.540927 22542570456896 run_lib.py:133] step: 96100, training_loss: 3.14633e-02
I0208 22:21:33.698666 22542570456896 run_lib.py:146] step: 96100, eval_loss: 2.81461e-02
I0208 22:21:51.179705 22542570456896 run_lib.py:133] step: 96150, training_loss: 2.47318e-02
I0208 22:22:08.575348 22542570456896 run_lib.py:133] step: 96200, training_loss: 2.92937e-02
I0208 22:22:08.729085 22542570456896 run_lib.py:146] step: 96200, eval_loss: 2.40828e-02
I0208 22:22:26.350025 22542570456896 run_lib.py:133] step: 96250, training_loss: 2.84531e-02
I0208 22:22:43.802021 22542570456896 run_lib.py:133] step: 96300, training_loss: 2.75608e-02
I0208 22:22:43.958518 22542570456896 run_lib.py:146] step: 96300, eval_loss: 2.81744e-02
I0208 22:23:01.581759 22542570456896 run_lib.py:133] step: 96350, training_loss: 3.36844e-02
I0208 22:23:19.018655 22542570456896 run_lib.py:133] step: 96400, training_loss: 3.06542e-02
I0208 22:23:19.178452 22542570456896 run_lib.py:146] step: 96400, eval_loss: 2.59323e-02
I0208 22:23:36.785582 22542570456896 run_lib.py:133] step: 96450, training_loss: 2.74995e-02
I0208 22:23:54.172287 22542570456896 run_lib.py:133] step: 96500, training_loss: 2.63990e-02
I0208 22:23:54.328347 22542570456896 run_lib.py:146] step: 96500, eval_loss: 3.38543e-02
I0208 22:24:11.903980 22542570456896 run_lib.py:133] step: 96550, training_loss: 2.50922e-02
I0208 22:24:29.342314 22542570456896 run_lib.py:133] step: 96600, training_loss: 3.33354e-02
I0208 22:24:29.499182 22542570456896 run_lib.py:146] step: 96600, eval_loss: 2.63087e-02
I0208 22:24:46.979874 22542570456896 run_lib.py:133] step: 96650, training_loss: 2.82854e-02
I0208 22:25:04.563011 22542570456896 run_lib.py:133] step: 96700, training_loss: 3.12432e-02
I0208 22:25:04.716192 22542570456896 run_lib.py:146] step: 96700, eval_loss: 2.84683e-02
I0208 22:25:22.114034 22542570456896 run_lib.py:133] step: 96750, training_loss: 3.37566e-02
I0208 22:25:39.553459 22542570456896 run_lib.py:133] step: 96800, training_loss: 2.25912e-02
I0208 22:25:39.710341 22542570456896 run_lib.py:146] step: 96800, eval_loss: 3.41104e-02
I0208 22:25:57.362030 22542570456896 run_lib.py:133] step: 96850, training_loss: 2.87583e-02
I0208 22:26:14.836461 22542570456896 run_lib.py:133] step: 96900, training_loss: 2.70980e-02
I0208 22:26:14.996365 22542570456896 run_lib.py:146] step: 96900, eval_loss: 2.83336e-02
I0208 22:26:32.636857 22542570456896 run_lib.py:133] step: 96950, training_loss: 3.31599e-02
I0208 22:26:50.059926 22542570456896 run_lib.py:133] step: 97000, training_loss: 2.71376e-02
I0208 22:26:50.216055 22542570456896 run_lib.py:146] step: 97000, eval_loss: 3.08652e-02
I0208 22:27:07.648278 22542570456896 run_lib.py:133] step: 97050, training_loss: 3.14135e-02
I0208 22:27:25.242500 22542570456896 run_lib.py:133] step: 97100, training_loss: 3.00077e-02
I0208 22:27:25.399738 22542570456896 run_lib.py:146] step: 97100, eval_loss: 2.56867e-02
I0208 22:27:42.859665 22542570456896 run_lib.py:133] step: 97150, training_loss: 3.29542e-02
I0208 22:28:00.283078 22542570456896 run_lib.py:133] step: 97200, training_loss: 2.37864e-02
I0208 22:28:00.437358 22542570456896 run_lib.py:146] step: 97200, eval_loss: 2.44145e-02
I0208 22:28:17.852901 22542570456896 run_lib.py:133] step: 97250, training_loss: 2.75841e-02
I0208 22:28:35.466768 22542570456896 run_lib.py:133] step: 97300, training_loss: 2.69162e-02
I0208 22:28:35.635522 22542570456896 run_lib.py:146] step: 97300, eval_loss: 2.88075e-02
I0208 22:28:53.059939 22542570456896 run_lib.py:133] step: 97350, training_loss: 2.93528e-02
I0208 22:29:10.526831 22542570456896 run_lib.py:133] step: 97400, training_loss: 3.01654e-02
I0208 22:29:10.694286 22542570456896 run_lib.py:146] step: 97400, eval_loss: 2.76661e-02
I0208 22:29:28.141576 22542570456896 run_lib.py:133] step: 97450, training_loss: 2.28793e-02
I0208 22:29:45.551450 22542570456896 run_lib.py:133] step: 97500, training_loss: 3.05749e-02
I0208 22:29:45.708904 22542570456896 run_lib.py:146] step: 97500, eval_loss: 2.74117e-02
I0208 22:30:03.330919 22542570456896 run_lib.py:133] step: 97550, training_loss: 3.04283e-02
I0208 22:30:20.796350 22542570456896 run_lib.py:133] step: 97600, training_loss: 2.73850e-02
I0208 22:30:20.954135 22542570456896 run_lib.py:146] step: 97600, eval_loss: 2.77898e-02
I0208 22:30:38.380896 22542570456896 run_lib.py:133] step: 97650, training_loss: 2.66044e-02
I0208 22:30:55.811836 22542570456896 run_lib.py:133] step: 97700, training_loss: 3.11214e-02
I0208 22:30:55.981515 22542570456896 run_lib.py:146] step: 97700, eval_loss: 2.88696e-02
I0208 22:31:13.695009 22542570456896 run_lib.py:133] step: 97750, training_loss: 3.04761e-02
I0208 22:31:31.144775 22542570456896 run_lib.py:133] step: 97800, training_loss: 2.62852e-02
I0208 22:31:31.301543 22542570456896 run_lib.py:146] step: 97800, eval_loss: 2.76305e-02
I0208 22:31:48.870479 22542570456896 run_lib.py:133] step: 97850, training_loss: 2.91772e-02
I0208 22:32:06.296688 22542570456896 run_lib.py:133] step: 97900, training_loss: 2.52294e-02
I0208 22:32:06.453154 22542570456896 run_lib.py:146] step: 97900, eval_loss: 2.90902e-02
I0208 22:32:24.007819 22542570456896 run_lib.py:133] step: 97950, training_loss: 2.70595e-02
I0208 22:32:41.492746 22542570456896 run_lib.py:133] step: 98000, training_loss: 2.76912e-02
I0208 22:32:41.650853 22542570456896 run_lib.py:146] step: 98000, eval_loss: 3.34763e-02
I0208 22:32:59.126330 22542570456896 run_lib.py:133] step: 98050, training_loss: 2.77559e-02
I0208 22:33:16.714861 22542570456896 run_lib.py:133] step: 98100, training_loss: 2.45685e-02
I0208 22:33:16.868401 22542570456896 run_lib.py:146] step: 98100, eval_loss: 3.04929e-02
I0208 22:33:34.292139 22542570456896 run_lib.py:133] step: 98150, training_loss: 2.20299e-02
I0208 22:33:51.864843 22542570456896 run_lib.py:133] step: 98200, training_loss: 3.07467e-02
I0208 22:33:52.018369 22542570456896 run_lib.py:146] step: 98200, eval_loss: 2.60848e-02
I0208 22:34:09.428885 22542570456896 run_lib.py:133] step: 98250, training_loss: 2.94914e-02
I0208 22:34:26.898761 22542570456896 run_lib.py:133] step: 98300, training_loss: 2.94075e-02
I0208 22:34:27.060298 22542570456896 run_lib.py:146] step: 98300, eval_loss: 3.32473e-02
I0208 22:34:44.663180 22542570456896 run_lib.py:133] step: 98350, training_loss: 2.89611e-02
I0208 22:35:02.083894 22542570456896 run_lib.py:133] step: 98400, training_loss: 2.87866e-02
I0208 22:35:02.247891 22542570456896 run_lib.py:146] step: 98400, eval_loss: 2.50973e-02
I0208 22:35:19.639178 22542570456896 run_lib.py:133] step: 98450, training_loss: 2.81528e-02
I0208 22:35:37.160873 22542570456896 run_lib.py:133] step: 98500, training_loss: 2.53739e-02
I0208 22:35:37.312043 22542570456896 run_lib.py:146] step: 98500, eval_loss: 3.22703e-02
I0208 22:35:54.726378 22542570456896 run_lib.py:133] step: 98550, training_loss: 3.35028e-02
I0208 22:36:12.232971 22542570456896 run_lib.py:133] step: 98600, training_loss: 3.23317e-02
I0208 22:36:12.572330 22542570456896 run_lib.py:146] step: 98600, eval_loss: 2.45590e-02
I0208 22:36:30.004699 22542570456896 run_lib.py:133] step: 98650, training_loss: 2.62448e-02
I0208 22:36:47.444856 22542570456896 run_lib.py:133] step: 98700, training_loss: 3.28496e-02
I0208 22:36:47.599125 22542570456896 run_lib.py:146] step: 98700, eval_loss: 3.25237e-02
I0208 22:37:05.045176 22542570456896 run_lib.py:133] step: 98750, training_loss: 2.80987e-02
I0208 22:37:22.467993 22542570456896 run_lib.py:133] step: 98800, training_loss: 2.55853e-02
I0208 22:37:22.635366 22542570456896 run_lib.py:146] step: 98800, eval_loss: 2.89328e-02
I0208 22:37:40.216069 22542570456896 run_lib.py:133] step: 98850, training_loss: 2.58238e-02
I0208 22:37:57.812018 22542570456896 run_lib.py:133] step: 98900, training_loss: 2.89188e-02
I0208 22:37:57.968965 22542570456896 run_lib.py:146] step: 98900, eval_loss: 2.82847e-02
I0208 22:38:15.420142 22542570456896 run_lib.py:133] step: 98950, training_loss: 2.22681e-02
I0208 22:38:32.828475 22542570456896 run_lib.py:133] step: 99000, training_loss: 2.80216e-02
I0208 22:38:32.985269 22542570456896 run_lib.py:146] step: 99000, eval_loss: 3.23228e-02
I0208 22:38:50.564485 22542570456896 run_lib.py:133] step: 99050, training_loss: 3.21812e-02
I0208 22:39:08.071012 22542570456896 run_lib.py:133] step: 99100, training_loss: 3.20758e-02
I0208 22:39:08.226669 22542570456896 run_lib.py:146] step: 99100, eval_loss: 3.43401e-02
I0208 22:39:25.736807 22542570456896 run_lib.py:133] step: 99150, training_loss: 2.96627e-02
I0208 22:39:43.210064 22542570456896 run_lib.py:133] step: 99200, training_loss: 2.54575e-02
I0208 22:39:43.369280 22542570456896 run_lib.py:146] step: 99200, eval_loss: 2.24813e-02
I0208 22:40:00.964489 22542570456896 run_lib.py:133] step: 99250, training_loss: 3.43451e-02
I0208 22:40:18.379544 22542570456896 run_lib.py:133] step: 99300, training_loss: 2.32239e-02
I0208 22:40:18.535510 22542570456896 run_lib.py:146] step: 99300, eval_loss: 2.68311e-02
I0208 22:40:36.117394 22542570456896 run_lib.py:133] step: 99350, training_loss: 2.61877e-02
I0208 22:40:53.606414 22542570456896 run_lib.py:133] step: 99400, training_loss: 3.13355e-02
I0208 22:40:53.764083 22542570456896 run_lib.py:146] step: 99400, eval_loss: 2.92298e-02
I0208 22:41:11.408766 22542570456896 run_lib.py:133] step: 99450, training_loss: 2.44444e-02
I0208 22:41:28.821488 22542570456896 run_lib.py:133] step: 99500, training_loss: 3.29599e-02
I0208 22:41:28.974103 22542570456896 run_lib.py:146] step: 99500, eval_loss: 2.85850e-02
I0208 22:41:46.416770 22542570456896 run_lib.py:133] step: 99550, training_loss: 3.05045e-02
I0208 22:42:04.000125 22542570456896 run_lib.py:133] step: 99600, training_loss: 2.68741e-02
I0208 22:42:04.155377 22542570456896 run_lib.py:146] step: 99600, eval_loss: 3.13526e-02
I0208 22:42:21.584027 22542570456896 run_lib.py:133] step: 99650, training_loss: 2.32024e-02
I0208 22:42:39.236966 22542570456896 run_lib.py:133] step: 99700, training_loss: 3.24934e-02
I0208 22:42:39.403258 22542570456896 run_lib.py:146] step: 99700, eval_loss: 2.84722e-02
I0208 22:42:56.809388 22542570456896 run_lib.py:133] step: 99750, training_loss: 2.99844e-02
I0208 22:43:14.249579 22542570456896 run_lib.py:133] step: 99800, training_loss: 3.21850e-02
I0208 22:43:14.406367 22542570456896 run_lib.py:146] step: 99800, eval_loss: 3.21468e-02
I0208 22:43:32.010882 22542570456896 run_lib.py:133] step: 99850, training_loss: 2.66584e-02
I0208 22:43:49.425606 22542570456896 run_lib.py:133] step: 99900, training_loss: 2.59189e-02
I0208 22:43:49.581361 22542570456896 run_lib.py:146] step: 99900, eval_loss: 3.00836e-02
I0208 22:44:07.043102 22542570456896 run_lib.py:133] step: 99950, training_loss: 2.65375e-02
I0208 22:44:24.501715 22542570456896 run_lib.py:133] step: 100000, training_loss: 3.02116e-02
I0208 22:44:25.213411 22542570456896 run_lib.py:146] step: 100000, eval_loss: 2.22917e-02
I0208 22:44:45.466351 22542570456896 run_lib.py:133] step: 100050, training_loss: 2.50331e-02
I0208 22:45:03.015789 22542570456896 run_lib.py:133] step: 100100, training_loss: 3.15841e-02
I0208 22:45:03.166495 22542570456896 run_lib.py:146] step: 100100, eval_loss: 3.24684e-02
I0208 22:45:20.579161 22542570456896 run_lib.py:133] step: 100150, training_loss: 2.37824e-02
I0208 22:45:38.006025 22542570456896 run_lib.py:133] step: 100200, training_loss: 3.54697e-02
I0208 22:45:38.164312 22542570456896 run_lib.py:146] step: 100200, eval_loss: 3.14687e-02
I0208 22:45:55.749566 22542570456896 run_lib.py:133] step: 100250, training_loss: 2.84287e-02
I0208 22:46:13.205314 22542570456896 run_lib.py:133] step: 100300, training_loss: 3.10695e-02
I0208 22:46:13.365261 22542570456896 run_lib.py:146] step: 100300, eval_loss: 2.55966e-02
I0208 22:46:30.792642 22542570456896 run_lib.py:133] step: 100350, training_loss: 2.38820e-02
I0208 22:46:48.214618 22542570456896 run_lib.py:133] step: 100400, training_loss: 2.87029e-02
I0208 22:46:48.371070 22542570456896 run_lib.py:146] step: 100400, eval_loss: 3.50185e-02
I0208 22:47:06.005263 22542570456896 run_lib.py:133] step: 100450, training_loss: 3.14522e-02
I0208 22:47:23.505064 22542570456896 run_lib.py:133] step: 100500, training_loss: 3.30709e-02
I0208 22:47:23.656749 22542570456896 run_lib.py:146] step: 100500, eval_loss: 2.92088e-02
I0208 22:47:41.189204 22542570456896 run_lib.py:133] step: 100550, training_loss: 2.71387e-02
I0208 22:47:58.566566 22542570456896 run_lib.py:133] step: 100600, training_loss: 2.61283e-02
I0208 22:47:58.720272 22542570456896 run_lib.py:146] step: 100600, eval_loss: 3.02325e-02
I0208 22:48:16.137780 22542570456896 run_lib.py:133] step: 100650, training_loss: 3.04396e-02
I0208 22:48:33.572881 22542570456896 run_lib.py:133] step: 100700, training_loss: 2.63714e-02
I0208 22:48:33.733519 22542570456896 run_lib.py:146] step: 100700, eval_loss: 2.51083e-02
I0208 22:48:51.319863 22542570456896 run_lib.py:133] step: 100750, training_loss: 2.59419e-02
I0208 22:49:08.871466 22542570456896 run_lib.py:133] step: 100800, training_loss: 2.97053e-02
I0208 22:49:09.029695 22542570456896 run_lib.py:146] step: 100800, eval_loss: 2.66008e-02
I0208 22:49:26.499520 22542570456896 run_lib.py:133] step: 100850, training_loss: 3.08678e-02
I0208 22:49:43.925658 22542570456896 run_lib.py:133] step: 100900, training_loss: 2.65667e-02
I0208 22:49:44.082662 22542570456896 run_lib.py:146] step: 100900, eval_loss: 2.43005e-02
I0208 22:50:01.698992 22542570456896 run_lib.py:133] step: 100950, training_loss: 2.82655e-02
I0208 22:50:19.120696 22542570456896 run_lib.py:133] step: 101000, training_loss: 3.36534e-02
I0208 22:50:19.273474 22542570456896 run_lib.py:146] step: 101000, eval_loss: 3.57060e-02
I0208 22:50:36.843657 22542570456896 run_lib.py:133] step: 101050, training_loss: 3.11769e-02
I0208 22:50:54.304505 22542570456896 run_lib.py:133] step: 101100, training_loss: 2.83133e-02
I0208 22:50:54.478387 22542570456896 run_lib.py:146] step: 101100, eval_loss: 3.15873e-02
I0208 22:51:12.101974 22542570456896 run_lib.py:133] step: 101150, training_loss: 3.39182e-02
I0208 22:51:29.534805 22542570456896 run_lib.py:133] step: 101200, training_loss: 3.17489e-02
I0208 22:51:29.698597 22542570456896 run_lib.py:146] step: 101200, eval_loss: 3.03797e-02
I0208 22:51:47.227459 22542570456896 run_lib.py:133] step: 101250, training_loss: 3.20952e-02
I0208 22:52:04.661774 22542570456896 run_lib.py:133] step: 101300, training_loss: 2.77560e-02
I0208 22:52:04.828326 22542570456896 run_lib.py:146] step: 101300, eval_loss: 2.84616e-02
I0208 22:52:22.295194 22542570456896 run_lib.py:133] step: 101350, training_loss: 3.72580e-02
I0208 22:52:39.905280 22542570456896 run_lib.py:133] step: 101400, training_loss: 3.16424e-02
I0208 22:52:40.061514 22542570456896 run_lib.py:146] step: 101400, eval_loss: 3.07044e-02
I0208 22:52:57.454320 22542570456896 run_lib.py:133] step: 101450, training_loss: 3.36447e-02
I0208 22:53:14.866147 22542570456896 run_lib.py:133] step: 101500, training_loss: 2.63689e-02
I0208 22:53:15.017314 22542570456896 run_lib.py:146] step: 101500, eval_loss: 2.40590e-02
I0208 22:53:32.560390 22542570456896 run_lib.py:133] step: 101550, training_loss: 3.39755e-02
I0208 22:53:49.959606 22542570456896 run_lib.py:133] step: 101600, training_loss: 2.30936e-02
I0208 22:53:50.128512 22542570456896 run_lib.py:146] step: 101600, eval_loss: 3.06491e-02
I0208 22:54:07.759228 22542570456896 run_lib.py:133] step: 101650, training_loss: 2.69783e-02
I0208 22:54:25.202128 22542570456896 run_lib.py:133] step: 101700, training_loss: 3.69416e-02
I0208 22:54:25.369457 22542570456896 run_lib.py:146] step: 101700, eval_loss: 3.20307e-02
I0208 22:54:42.794826 22542570456896 run_lib.py:133] step: 101750, training_loss: 3.13275e-02
I0208 22:55:00.386486 22542570456896 run_lib.py:133] step: 101800, training_loss: 2.93003e-02
I0208 22:55:00.543333 22542570456896 run_lib.py:146] step: 101800, eval_loss: 2.59120e-02
I0208 22:55:17.988557 22542570456896 run_lib.py:133] step: 101850, training_loss: 3.27979e-02
I0208 22:55:35.413794 22542570456896 run_lib.py:133] step: 101900, training_loss: 2.81774e-02
I0208 22:55:35.570487 22542570456896 run_lib.py:146] step: 101900, eval_loss: 2.72992e-02
I0208 22:55:53.076195 22542570456896 run_lib.py:133] step: 101950, training_loss: 2.55129e-02
I0208 22:56:10.722783 22542570456896 run_lib.py:133] step: 102000, training_loss: 2.91241e-02
I0208 22:56:10.877366 22542570456896 run_lib.py:146] step: 102000, eval_loss: 2.80233e-02
I0208 22:56:28.281549 22542570456896 run_lib.py:133] step: 102050, training_loss: 2.87585e-02
I0208 22:56:45.776351 22542570456896 run_lib.py:133] step: 102100, training_loss: 2.84360e-02
I0208 22:56:45.933671 22542570456896 run_lib.py:146] step: 102100, eval_loss: 3.11974e-02
I0208 22:57:03.360663 22542570456896 run_lib.py:133] step: 102150, training_loss: 3.32122e-02
I0208 22:57:20.849336 22542570456896 run_lib.py:133] step: 102200, training_loss: 2.19306e-02
I0208 22:57:21.006236 22542570456896 run_lib.py:146] step: 102200, eval_loss: 3.31413e-02
I0208 22:57:38.586141 22542570456896 run_lib.py:133] step: 102250, training_loss: 2.28936e-02
I0208 22:57:56.097288 22542570456896 run_lib.py:133] step: 102300, training_loss: 3.39183e-02
I0208 22:57:56.254359 22542570456896 run_lib.py:146] step: 102300, eval_loss: 2.91207e-02
I0208 22:58:13.742984 22542570456896 run_lib.py:133] step: 102350, training_loss: 2.96078e-02
I0208 22:58:31.107132 22542570456896 run_lib.py:133] step: 102400, training_loss: 2.36149e-02
I0208 22:58:31.268330 22542570456896 run_lib.py:146] step: 102400, eval_loss: 2.77364e-02
I0208 22:58:48.858496 22542570456896 run_lib.py:133] step: 102450, training_loss: 2.69003e-02
I0208 22:59:06.285242 22542570456896 run_lib.py:133] step: 102500, training_loss: 3.29669e-02
I0208 22:59:06.442718 22542570456896 run_lib.py:146] step: 102500, eval_loss: 2.68120e-02
I0208 22:59:24.074058 22542570456896 run_lib.py:133] step: 102550, training_loss: 2.96063e-02
I0208 22:59:41.489701 22542570456896 run_lib.py:133] step: 102600, training_loss: 2.89757e-02
I0208 22:59:41.651566 22542570456896 run_lib.py:146] step: 102600, eval_loss: 2.47012e-02
I0208 22:59:59.199527 22542570456896 run_lib.py:133] step: 102650, training_loss: 3.39018e-02
I0208 23:00:16.668148 22542570456896 run_lib.py:133] step: 102700, training_loss: 3.23642e-02
I0208 23:00:16.843134 22542570456896 run_lib.py:146] step: 102700, eval_loss: 2.76925e-02
I0208 23:00:34.273695 22542570456896 run_lib.py:133] step: 102750, training_loss: 3.09848e-02
I0208 23:00:51.904840 22542570456896 run_lib.py:133] step: 102800, training_loss: 2.57713e-02
I0208 23:00:52.061109 22542570456896 run_lib.py:146] step: 102800, eval_loss: 2.68767e-02
I0208 23:01:09.510753 22542570456896 run_lib.py:133] step: 102850, training_loss: 2.34731e-02
I0208 23:01:27.082305 22542570456896 run_lib.py:133] step: 102900, training_loss: 3.07738e-02
I0208 23:01:27.234496 22542570456896 run_lib.py:146] step: 102900, eval_loss: 3.15469e-02
I0208 23:01:44.640817 22542570456896 run_lib.py:133] step: 102950, training_loss: 3.00451e-02
I0208 23:02:02.037362 22542570456896 run_lib.py:133] step: 103000, training_loss: 3.09618e-02
I0208 23:02:02.206450 22542570456896 run_lib.py:146] step: 103000, eval_loss: 1.92895e-02
I0208 23:02:19.813586 22542570456896 run_lib.py:133] step: 103050, training_loss: 2.50196e-02
I0208 23:02:37.267304 22542570456896 run_lib.py:133] step: 103100, training_loss: 3.10526e-02
I0208 23:02:37.427480 22542570456896 run_lib.py:146] step: 103100, eval_loss: 3.13289e-02
I0208 23:02:54.866524 22542570456896 run_lib.py:133] step: 103150, training_loss: 3.51838e-02
I0208 23:03:12.431831 22542570456896 run_lib.py:133] step: 103200, training_loss: 2.75782e-02
I0208 23:03:12.588394 22542570456896 run_lib.py:146] step: 103200, eval_loss: 3.14172e-02
I0208 23:03:30.052610 22542570456896 run_lib.py:133] step: 103250, training_loss: 3.80870e-02
I0208 23:03:47.524200 22542570456896 run_lib.py:133] step: 103300, training_loss: 3.04492e-02
I0208 23:03:47.870524 22542570456896 run_lib.py:146] step: 103300, eval_loss: 2.91217e-02
I0208 23:04:05.288304 22542570456896 run_lib.py:133] step: 103350, training_loss: 3.21514e-02
I0208 23:04:22.713589 22542570456896 run_lib.py:133] step: 103400, training_loss: 2.80859e-02
I0208 23:04:22.867254 22542570456896 run_lib.py:146] step: 103400, eval_loss: 2.70661e-02
I0208 23:04:40.287674 22542570456896 run_lib.py:133] step: 103450, training_loss: 2.71414e-02
I0208 23:04:57.708780 22542570456896 run_lib.py:133] step: 103500, training_loss: 3.45947e-02
I0208 23:04:57.865509 22542570456896 run_lib.py:146] step: 103500, eval_loss: 3.68989e-02
I0208 23:05:15.474082 22542570456896 run_lib.py:133] step: 103550, training_loss: 2.13166e-02
I0208 23:05:33.038867 22542570456896 run_lib.py:133] step: 103600, training_loss: 2.80749e-02
I0208 23:05:33.197213 22542570456896 run_lib.py:146] step: 103600, eval_loss: 2.69136e-02
I0208 23:05:50.627554 22542570456896 run_lib.py:133] step: 103650, training_loss: 3.37577e-02
I0208 23:06:08.044265 22542570456896 run_lib.py:133] step: 103700, training_loss: 3.18165e-02
I0208 23:06:08.198322 22542570456896 run_lib.py:146] step: 103700, eval_loss: 2.81170e-02
I0208 23:06:25.786017 22542570456896 run_lib.py:133] step: 103750, training_loss: 3.55747e-02
I0208 23:06:43.301706 22542570456896 run_lib.py:133] step: 103800, training_loss: 3.45009e-02
I0208 23:06:43.457127 22542570456896 run_lib.py:146] step: 103800, eval_loss: 3.32148e-02
I0208 23:07:00.916058 22542570456896 run_lib.py:133] step: 103850, training_loss: 2.58116e-02
I0208 23:07:18.325636 22542570456896 run_lib.py:133] step: 103900, training_loss: 2.24430e-02
I0208 23:07:18.479560 22542570456896 run_lib.py:146] step: 103900, eval_loss: 2.68477e-02
I0208 23:07:36.095741 22542570456896 run_lib.py:133] step: 103950, training_loss: 3.26658e-02
I0208 23:07:53.525611 22542570456896 run_lib.py:133] step: 104000, training_loss: 2.41502e-02
I0208 23:07:53.693328 22542570456896 run_lib.py:146] step: 104000, eval_loss: 2.86744e-02
I0208 23:08:11.232348 22542570456896 run_lib.py:133] step: 104050, training_loss: 2.35938e-02
I0208 23:08:28.644683 22542570456896 run_lib.py:133] step: 104100, training_loss: 2.85833e-02
I0208 23:08:28.825017 22542570456896 run_lib.py:146] step: 104100, eval_loss: 3.54813e-02
I0208 23:08:46.518810 22542570456896 run_lib.py:133] step: 104150, training_loss: 2.96241e-02
I0208 23:09:03.949169 22542570456896 run_lib.py:133] step: 104200, training_loss: 3.38384e-02
I0208 23:09:04.106188 22542570456896 run_lib.py:146] step: 104200, eval_loss: 2.17932e-02
I0208 23:09:21.525225 22542570456896 run_lib.py:133] step: 104250, training_loss: 2.30963e-02
I0208 23:09:39.095541 22542570456896 run_lib.py:133] step: 104300, training_loss: 3.16025e-02
I0208 23:09:39.251049 22542570456896 run_lib.py:146] step: 104300, eval_loss: 2.86186e-02
I0208 23:09:56.652466 22542570456896 run_lib.py:133] step: 104350, training_loss: 2.79025e-02
I0208 23:10:14.259248 22542570456896 run_lib.py:133] step: 104400, training_loss: 2.75290e-02
I0208 23:10:14.423544 22542570456896 run_lib.py:146] step: 104400, eval_loss: 2.68165e-02
I0208 23:10:31.878481 22542570456896 run_lib.py:133] step: 104450, training_loss: 2.78244e-02
I0208 23:10:49.319715 22542570456896 run_lib.py:133] step: 104500, training_loss: 3.30114e-02
I0208 23:10:49.479179 22542570456896 run_lib.py:146] step: 104500, eval_loss: 3.85266e-02
I0208 23:11:07.086234 22542570456896 run_lib.py:133] step: 104550, training_loss: 3.00637e-02
I0208 23:11:24.477283 22542570456896 run_lib.py:133] step: 104600, training_loss: 2.59039e-02
I0208 23:11:24.633284 22542570456896 run_lib.py:146] step: 104600, eval_loss: 2.79614e-02
I0208 23:11:42.100935 22542570456896 run_lib.py:133] step: 104650, training_loss: 2.59604e-02
I0208 23:11:59.609363 22542570456896 run_lib.py:133] step: 104700, training_loss: 3.80683e-02
I0208 23:11:59.765997 22542570456896 run_lib.py:146] step: 104700, eval_loss: 2.45407e-02
I0208 23:12:17.404057 22542570456896 run_lib.py:133] step: 104750, training_loss: 3.19312e-02
I0208 23:12:34.866378 22542570456896 run_lib.py:133] step: 104800, training_loss: 2.83294e-02
I0208 23:12:35.020357 22542570456896 run_lib.py:146] step: 104800, eval_loss: 2.98641e-02
I0208 23:12:52.490357 22542570456896 run_lib.py:133] step: 104850, training_loss: 3.67976e-02
I0208 23:13:09.914460 22542570456896 run_lib.py:133] step: 104900, training_loss: 2.68117e-02
I0208 23:13:10.070334 22542570456896 run_lib.py:146] step: 104900, eval_loss: 3.50683e-02
I0208 23:13:27.484190 22542570456896 run_lib.py:133] step: 104950, training_loss: 3.03156e-02
I0208 23:13:44.953640 22542570456896 run_lib.py:133] step: 105000, training_loss: 2.93463e-02
I0208 23:13:45.109329 22542570456896 run_lib.py:146] step: 105000, eval_loss: 2.70875e-02
I0208 23:14:02.734704 22542570456896 run_lib.py:133] step: 105050, training_loss: 2.78648e-02
I0208 23:14:20.246271 22542570456896 run_lib.py:133] step: 105100, training_loss: 2.31747e-02
I0208 23:14:20.407423 22542570456896 run_lib.py:146] step: 105100, eval_loss: 2.85727e-02
I0208 23:14:37.838296 22542570456896 run_lib.py:133] step: 105150, training_loss: 3.29924e-02
I0208 23:14:55.291126 22542570456896 run_lib.py:133] step: 105200, training_loss: 2.93890e-02
I0208 23:14:55.456521 22542570456896 run_lib.py:146] step: 105200, eval_loss: 2.68063e-02
I0208 23:15:13.170051 22542570456896 run_lib.py:133] step: 105250, training_loss: 2.67504e-02
I0208 23:15:30.598631 22542570456896 run_lib.py:133] step: 105300, training_loss: 2.73353e-02
I0208 23:15:30.750692 22542570456896 run_lib.py:146] step: 105300, eval_loss: 3.30340e-02
I0208 23:15:48.345523 22542570456896 run_lib.py:133] step: 105350, training_loss: 2.34618e-02
I0208 23:16:05.807807 22542570456896 run_lib.py:133] step: 105400, training_loss: 2.61838e-02
I0208 23:16:05.964390 22542570456896 run_lib.py:146] step: 105400, eval_loss: 2.52211e-02
I0208 23:16:23.538331 22542570456896 run_lib.py:133] step: 105450, training_loss: 3.22268e-02
I0208 23:16:41.012288 22542570456896 run_lib.py:133] step: 105500, training_loss: 2.81670e-02
I0208 23:16:41.194443 22542570456896 run_lib.py:146] step: 105500, eval_loss: 3.33228e-02
I0208 23:16:58.834349 22542570456896 run_lib.py:133] step: 105550, training_loss: 2.72053e-02
I0208 23:17:16.285710 22542570456896 run_lib.py:133] step: 105600, training_loss: 2.71940e-02
I0208 23:17:16.442633 22542570456896 run_lib.py:146] step: 105600, eval_loss: 3.06938e-02
I0208 23:17:33.919935 22542570456896 run_lib.py:133] step: 105650, training_loss: 2.80529e-02
I0208 23:17:51.468021 22542570456896 run_lib.py:133] step: 105700, training_loss: 2.36926e-02
I0208 23:17:51.628326 22542570456896 run_lib.py:146] step: 105700, eval_loss: 2.68966e-02
I0208 23:18:09.014020 22542570456896 run_lib.py:133] step: 105750, training_loss: 4.02485e-02
I0208 23:18:26.489189 22542570456896 run_lib.py:133] step: 105800, training_loss: 2.69902e-02
I0208 23:18:26.644447 22542570456896 run_lib.py:146] step: 105800, eval_loss: 2.88896e-02
I0208 23:18:44.291834 22542570456896 run_lib.py:133] step: 105850, training_loss: 2.69945e-02
I0208 23:19:01.883402 22542570456896 run_lib.py:133] step: 105900, training_loss: 2.48043e-02
I0208 23:19:02.038931 22542570456896 run_lib.py:146] step: 105900, eval_loss: 3.72398e-02
I0208 23:19:19.430386 22542570456896 run_lib.py:133] step: 105950, training_loss: 3.05016e-02
I0208 23:19:36.830087 22542570456896 run_lib.py:133] step: 106000, training_loss: 2.67427e-02
I0208 23:19:36.986531 22542570456896 run_lib.py:146] step: 106000, eval_loss: 2.91586e-02
I0208 23:19:54.445154 22542570456896 run_lib.py:133] step: 106050, training_loss: 2.30367e-02
I0208 23:20:12.036126 22542570456896 run_lib.py:133] step: 106100, training_loss: 3.25214e-02
I0208 23:20:12.192028 22542570456896 run_lib.py:146] step: 106100, eval_loss: 3.22665e-02
I0208 23:20:29.564189 22542570456896 run_lib.py:133] step: 106150, training_loss: 3.32714e-02
I0208 23:20:46.871929 22542570456896 run_lib.py:133] step: 106200, training_loss: 3.39629e-02
I0208 23:20:47.026031 22542570456896 run_lib.py:146] step: 106200, eval_loss: 3.13761e-02
I0208 23:21:04.462750 22542570456896 run_lib.py:133] step: 106250, training_loss: 2.13195e-02
I0208 23:21:22.085964 22542570456896 run_lib.py:133] step: 106300, training_loss: 3.11169e-02
I0208 23:21:22.246410 22542570456896 run_lib.py:146] step: 106300, eval_loss: 3.09179e-02
I0208 23:21:39.712331 22542570456896 run_lib.py:133] step: 106350, training_loss: 3.98216e-02
I0208 23:21:57.254455 22542570456896 run_lib.py:133] step: 106400, training_loss: 1.99761e-02
I0208 23:21:57.414404 22542570456896 run_lib.py:146] step: 106400, eval_loss: 2.98260e-02
I0208 23:22:14.828226 22542570456896 run_lib.py:133] step: 106450, training_loss: 2.50781e-02
I0208 23:22:32.232796 22542570456896 run_lib.py:133] step: 106500, training_loss: 3.14503e-02
I0208 23:22:32.389482 22542570456896 run_lib.py:146] step: 106500, eval_loss: 2.50235e-02
I0208 23:22:49.939690 22542570456896 run_lib.py:133] step: 106550, training_loss: 2.63644e-02
I0208 23:23:07.523027 22542570456896 run_lib.py:133] step: 106600, training_loss: 3.21496e-02
I0208 23:23:07.683708 22542570456896 run_lib.py:146] step: 106600, eval_loss: 2.75434e-02
I0208 23:23:25.156500 22542570456896 run_lib.py:133] step: 106650, training_loss: 3.25347e-02
I0208 23:23:42.586654 22542570456896 run_lib.py:133] step: 106700, training_loss: 2.62245e-02
I0208 23:23:42.739287 22542570456896 run_lib.py:146] step: 106700, eval_loss: 2.87596e-02
I0208 23:24:00.344848 22542570456896 run_lib.py:133] step: 106750, training_loss: 3.66023e-02
I0208 23:24:17.760659 22542570456896 run_lib.py:133] step: 106800, training_loss: 3.19528e-02
I0208 23:24:17.917216 22542570456896 run_lib.py:146] step: 106800, eval_loss: 2.20892e-02
I0208 23:24:35.465933 22542570456896 run_lib.py:133] step: 106850, training_loss: 2.43727e-02
I0208 23:24:52.926323 22542570456896 run_lib.py:133] step: 106900, training_loss: 2.64788e-02
I0208 23:24:53.102325 22542570456896 run_lib.py:146] step: 106900, eval_loss: 3.36356e-02
I0208 23:25:10.718731 22542570456896 run_lib.py:133] step: 106950, training_loss: 3.00941e-02
I0208 23:25:28.168776 22542570456896 run_lib.py:133] step: 107000, training_loss: 3.23121e-02
I0208 23:25:28.326688 22542570456896 run_lib.py:146] step: 107000, eval_loss: 2.64537e-02
I0208 23:25:45.731763 22542570456896 run_lib.py:133] step: 107050, training_loss: 3.62871e-02
I0208 23:26:03.318233 22542570456896 run_lib.py:133] step: 107100, training_loss: 2.50875e-02
I0208 23:26:03.476414 22542570456896 run_lib.py:146] step: 107100, eval_loss: 2.74570e-02
I0208 23:26:20.897488 22542570456896 run_lib.py:133] step: 107150, training_loss: 2.52582e-02
I0208 23:26:38.538438 22542570456896 run_lib.py:133] step: 107200, training_loss: 2.50612e-02
I0208 23:26:38.694424 22542570456896 run_lib.py:146] step: 107200, eval_loss: 3.16855e-02
I0208 23:26:56.094491 22542570456896 run_lib.py:133] step: 107250, training_loss: 2.81328e-02
I0208 23:27:13.565456 22542570456896 run_lib.py:133] step: 107300, training_loss: 2.84397e-02
I0208 23:27:13.721375 22542570456896 run_lib.py:146] step: 107300, eval_loss: 2.66480e-02
I0208 23:27:31.325008 22542570456896 run_lib.py:133] step: 107350, training_loss: 2.87857e-02
I0208 23:27:48.731695 22542570456896 run_lib.py:133] step: 107400, training_loss: 2.33375e-02
I0208 23:27:48.891661 22542570456896 run_lib.py:146] step: 107400, eval_loss: 2.72339e-02
I0208 23:28:06.375196 22542570456896 run_lib.py:133] step: 107450, training_loss: 2.69622e-02
I0208 23:28:24.023370 22542570456896 run_lib.py:133] step: 107500, training_loss: 2.48062e-02
I0208 23:28:24.179510 22542570456896 run_lib.py:146] step: 107500, eval_loss: 2.68058e-02
I0208 23:28:41.589926 22542570456896 run_lib.py:133] step: 107550, training_loss: 3.06564e-02
I0208 23:28:59.010220 22542570456896 run_lib.py:133] step: 107600, training_loss: 2.59693e-02
I0208 23:28:59.166152 22542570456896 run_lib.py:146] step: 107600, eval_loss: 2.68580e-02
I0208 23:29:16.670852 22542570456896 run_lib.py:133] step: 107650, training_loss: 3.64075e-02
I0208 23:29:34.125801 22542570456896 run_lib.py:133] step: 107700, training_loss: 2.29406e-02
I0208 23:29:34.287402 22542570456896 run_lib.py:146] step: 107700, eval_loss: 2.62118e-02
I0208 23:29:51.803005 22542570456896 run_lib.py:133] step: 107750, training_loss: 2.81100e-02
I0208 23:30:09.225945 22542570456896 run_lib.py:133] step: 107800, training_loss: 3.08458e-02
I0208 23:30:09.385300 22542570456896 run_lib.py:146] step: 107800, eval_loss: 2.60917e-02
I0208 23:30:26.947832 22542570456896 run_lib.py:133] step: 107850, training_loss: 2.58031e-02
I0208 23:30:44.455279 22542570456896 run_lib.py:133] step: 107900, training_loss: 3.27584e-02
I0208 23:30:44.614590 22542570456896 run_lib.py:146] step: 107900, eval_loss: 3.25475e-02
I0208 23:31:02.057912 22542570456896 run_lib.py:133] step: 107950, training_loss: 3.16015e-02
I0208 23:31:19.561876 22542570456896 run_lib.py:133] step: 108000, training_loss: 3.29338e-02
I0208 23:31:19.719256 22542570456896 run_lib.py:146] step: 108000, eval_loss: 2.85372e-02
I0208 23:31:37.361651 22542570456896 run_lib.py:133] step: 108050, training_loss: 2.94924e-02
I0208 23:31:54.795663 22542570456896 run_lib.py:133] step: 108100, training_loss: 2.52640e-02
I0208 23:31:54.955046 22542570456896 run_lib.py:146] step: 108100, eval_loss: 2.52625e-02
I0208 23:32:12.573464 22542570456896 run_lib.py:133] step: 108150, training_loss: 2.76053e-02
I0208 23:32:30.021874 22542570456896 run_lib.py:133] step: 108200, training_loss: 2.96919e-02
I0208 23:32:30.176248 22542570456896 run_lib.py:146] step: 108200, eval_loss: 2.99379e-02
I0208 23:32:47.785485 22542570456896 run_lib.py:133] step: 108250, training_loss: 3.17431e-02
I0208 23:33:05.244813 22542570456896 run_lib.py:133] step: 108300, training_loss: 2.45329e-02
I0208 23:33:05.416098 22542570456896 run_lib.py:146] step: 108300, eval_loss: 2.46802e-02
I0208 23:33:23.020833 22542570456896 run_lib.py:133] step: 108350, training_loss: 2.31844e-02
I0208 23:33:40.484019 22542570456896 run_lib.py:133] step: 108400, training_loss: 3.20172e-02
I0208 23:33:40.641411 22542570456896 run_lib.py:146] step: 108400, eval_loss: 3.59040e-02
I0208 23:33:58.092722 22542570456896 run_lib.py:133] step: 108450, training_loss: 2.42741e-02
I0208 23:34:15.641252 22542570456896 run_lib.py:133] step: 108500, training_loss: 2.83624e-02
I0208 23:34:15.797391 22542570456896 run_lib.py:146] step: 108500, eval_loss: 2.38620e-02
I0208 23:34:33.261140 22542570456896 run_lib.py:133] step: 108550, training_loss: 2.93142e-02
I0208 23:34:50.754184 22542570456896 run_lib.py:133] step: 108600, training_loss: 2.74733e-02
I0208 23:34:50.911141 22542570456896 run_lib.py:146] step: 108600, eval_loss: 2.23405e-02
I0208 23:35:08.555632 22542570456896 run_lib.py:133] step: 108650, training_loss: 3.27100e-02
I0208 23:35:25.999036 22542570456896 run_lib.py:133] step: 108700, training_loss: 3.73131e-02
I0208 23:35:26.160292 22542570456896 run_lib.py:146] step: 108700, eval_loss: 2.56354e-02
I0208 23:35:43.705374 22542570456896 run_lib.py:133] step: 108750, training_loss: 2.61069e-02
I0208 23:36:01.168962 22542570456896 run_lib.py:133] step: 108800, training_loss: 2.57780e-02
I0208 23:36:01.327923 22542570456896 run_lib.py:146] step: 108800, eval_loss: 2.71315e-02
I0208 23:36:18.756535 22542570456896 run_lib.py:133] step: 108850, training_loss: 2.92802e-02
I0208 23:36:36.388006 22542570456896 run_lib.py:133] step: 108900, training_loss: 3.00470e-02
I0208 23:36:36.545568 22542570456896 run_lib.py:146] step: 108900, eval_loss: 2.20517e-02
I0208 23:36:54.006353 22542570456896 run_lib.py:133] step: 108950, training_loss: 2.67741e-02
I0208 23:37:11.419661 22542570456896 run_lib.py:133] step: 109000, training_loss: 2.71592e-02
I0208 23:37:11.580279 22542570456896 run_lib.py:146] step: 109000, eval_loss: 2.86520e-02
I0208 23:37:28.972633 22542570456896 run_lib.py:133] step: 109050, training_loss: 2.55874e-02
I0208 23:37:46.596527 22542570456896 run_lib.py:133] step: 109100, training_loss: 3.00184e-02
I0208 23:37:46.750427 22542570456896 run_lib.py:146] step: 109100, eval_loss: 3.73822e-02
I0208 23:38:04.249605 22542570456896 run_lib.py:133] step: 109150, training_loss: 3.16516e-02
I0208 23:38:21.784830 22542570456896 run_lib.py:133] step: 109200, training_loss: 2.73388e-02
I0208 23:38:21.941559 22542570456896 run_lib.py:146] step: 109200, eval_loss: 3.23164e-02
I0208 23:38:39.343315 22542570456896 run_lib.py:133] step: 109250, training_loss: 2.27826e-02
I0208 23:38:56.786533 22542570456896 run_lib.py:133] step: 109300, training_loss: 2.36301e-02
I0208 23:38:56.941989 22542570456896 run_lib.py:146] step: 109300, eval_loss: 4.03645e-02
I0208 23:39:14.500250 22542570456896 run_lib.py:133] step: 109350, training_loss: 3.43939e-02
I0208 23:39:32.036981 22542570456896 run_lib.py:133] step: 109400, training_loss: 3.03617e-02
I0208 23:39:32.201043 22542570456896 run_lib.py:146] step: 109400, eval_loss: 2.74333e-02
I0208 23:39:49.677733 22542570456896 run_lib.py:133] step: 109450, training_loss: 2.49147e-02
I0208 23:40:07.101820 22542570456896 run_lib.py:133] step: 109500, training_loss: 3.77967e-02
I0208 23:40:07.258074 22542570456896 run_lib.py:146] step: 109500, eval_loss: 2.33754e-02
I0208 23:40:24.918577 22542570456896 run_lib.py:133] step: 109550, training_loss: 2.64194e-02
I0208 23:40:42.308712 22542570456896 run_lib.py:133] step: 109600, training_loss: 2.78900e-02
I0208 23:40:42.463438 22542570456896 run_lib.py:146] step: 109600, eval_loss: 2.18363e-02
I0208 23:41:00.035746 22542570456896 run_lib.py:133] step: 109650, training_loss: 2.13324e-02
I0208 23:41:17.505290 22542570456896 run_lib.py:133] step: 109700, training_loss: 2.76158e-02
I0208 23:41:17.683325 22542570456896 run_lib.py:146] step: 109700, eval_loss: 2.58513e-02
I0208 23:41:35.316601 22542570456896 run_lib.py:133] step: 109750, training_loss: 2.51338e-02
I0208 23:41:52.765525 22542570456896 run_lib.py:133] step: 109800, training_loss: 3.79807e-02
I0208 23:41:52.922618 22542570456896 run_lib.py:146] step: 109800, eval_loss: 3.17274e-02
I0208 23:42:10.318909 22542570456896 run_lib.py:133] step: 109850, training_loss: 3.66672e-02
I0208 23:42:27.881075 22542570456896 run_lib.py:133] step: 109900, training_loss: 3.50276e-02
I0208 23:42:28.037323 22542570456896 run_lib.py:146] step: 109900, eval_loss: 2.50131e-02
I0208 23:42:45.461750 22542570456896 run_lib.py:133] step: 109950, training_loss: 2.50673e-02
I0208 23:43:03.070453 22542570456896 run_lib.py:133] step: 110000, training_loss: 2.45844e-02
I0208 23:43:03.781871 22542570456896 run_lib.py:146] step: 110000, eval_loss: 2.58312e-02
I0208 23:43:23.998379 22542570456896 run_lib.py:133] step: 110050, training_loss: 3.15685e-02
I0208 23:43:41.407572 22542570456896 run_lib.py:133] step: 110100, training_loss: 3.16077e-02
I0208 23:43:41.565378 22542570456896 run_lib.py:146] step: 110100, eval_loss: 3.02219e-02
I0208 23:43:59.003014 22542570456896 run_lib.py:133] step: 110150, training_loss: 3.02703e-02
I0208 23:44:16.439345 22542570456896 run_lib.py:133] step: 110200, training_loss: 2.66543e-02
I0208 23:44:16.608184 22542570456896 run_lib.py:146] step: 110200, eval_loss: 2.83053e-02
I0208 23:44:34.206381 22542570456896 run_lib.py:133] step: 110250, training_loss: 2.56059e-02
I0208 23:44:51.764018 22542570456896 run_lib.py:133] step: 110300, training_loss: 2.95898e-02
I0208 23:44:51.922594 22542570456896 run_lib.py:146] step: 110300, eval_loss: 2.52308e-02
I0208 23:45:09.350784 22542570456896 run_lib.py:133] step: 110350, training_loss: 2.32005e-02
I0208 23:45:26.767164 22542570456896 run_lib.py:133] step: 110400, training_loss: 3.56513e-02
I0208 23:45:26.923268 22542570456896 run_lib.py:146] step: 110400, eval_loss: 3.14669e-02
I0208 23:45:44.492593 22542570456896 run_lib.py:133] step: 110450, training_loss: 2.74670e-02
I0208 23:46:01.954249 22542570456896 run_lib.py:133] step: 110500, training_loss: 2.55903e-02
I0208 23:46:02.111633 22542570456896 run_lib.py:146] step: 110500, eval_loss: 3.33891e-02
I0208 23:46:19.725779 22542570456896 run_lib.py:133] step: 110550, training_loss: 2.76646e-02
I0208 23:46:37.156702 22542570456896 run_lib.py:133] step: 110600, training_loss: 2.77728e-02
I0208 23:46:37.305464 22542570456896 run_lib.py:146] step: 110600, eval_loss: 2.81297e-02
I0208 23:46:54.870191 22542570456896 run_lib.py:133] step: 110650, training_loss: 3.28162e-02
I0208 23:47:12.274969 22542570456896 run_lib.py:133] step: 110700, training_loss: 3.38757e-02
I0208 23:47:12.445158 22542570456896 run_lib.py:146] step: 110700, eval_loss: 3.01418e-02
I0208 23:47:30.071935 22542570456896 run_lib.py:133] step: 110750, training_loss: 3.66117e-02
I0208 23:47:47.549275 22542570456896 run_lib.py:133] step: 110800, training_loss: 2.46707e-02
I0208 23:47:47.710576 22542570456896 run_lib.py:146] step: 110800, eval_loss: 2.84974e-02
I0208 23:48:05.114676 22542570456896 run_lib.py:133] step: 110850, training_loss: 3.09944e-02
I0208 23:48:22.726280 22542570456896 run_lib.py:133] step: 110900, training_loss: 2.80143e-02
I0208 23:48:22.881598 22542570456896 run_lib.py:146] step: 110900, eval_loss: 2.26564e-02
I0208 23:48:40.284044 22542570456896 run_lib.py:133] step: 110950, training_loss: 2.11263e-02
I0208 23:48:57.764281 22542570456896 run_lib.py:133] step: 111000, training_loss: 3.13660e-02
I0208 23:48:57.922549 22542570456896 run_lib.py:146] step: 111000, eval_loss: 2.45399e-02
I0208 23:49:15.509244 22542570456896 run_lib.py:133] step: 111050, training_loss: 2.36670e-02
I0208 23:49:33.113407 22542570456896 run_lib.py:133] step: 111100, training_loss: 3.20776e-02
I0208 23:49:33.266343 22542570456896 run_lib.py:146] step: 111100, eval_loss: 2.48237e-02
I0208 23:49:50.697597 22542570456896 run_lib.py:133] step: 111150, training_loss: 2.83003e-02
I0208 23:50:08.143580 22542570456896 run_lib.py:133] step: 111200, training_loss: 2.55773e-02
I0208 23:50:08.303505 22542570456896 run_lib.py:146] step: 111200, eval_loss: 2.89885e-02
I0208 23:50:25.700641 22542570456896 run_lib.py:133] step: 111250, training_loss: 3.33366e-02
I0208 23:50:43.283020 22542570456896 run_lib.py:133] step: 111300, training_loss: 2.93958e-02
I0208 23:50:43.456362 22542570456896 run_lib.py:146] step: 111300, eval_loss: 2.67507e-02
I0208 23:51:00.910566 22542570456896 run_lib.py:133] step: 111350, training_loss: 2.69679e-02
I0208 23:51:18.369120 22542570456896 run_lib.py:133] step: 111400, training_loss: 2.38764e-02
I0208 23:51:18.526151 22542570456896 run_lib.py:146] step: 111400, eval_loss: 2.78919e-02
I0208 23:51:35.956351 22542570456896 run_lib.py:133] step: 111450, training_loss: 3.02339e-02
I0208 23:51:53.580185 22542570456896 run_lib.py:133] step: 111500, training_loss: 2.60722e-02
I0208 23:51:53.733120 22542570456896 run_lib.py:146] step: 111500, eval_loss: 2.24209e-02
I0208 23:52:11.130561 22542570456896 run_lib.py:133] step: 111550, training_loss: 3.17915e-02
I0208 23:52:28.629507 22542570456896 run_lib.py:133] step: 111600, training_loss: 2.40403e-02
I0208 23:52:28.799575 22542570456896 run_lib.py:146] step: 111600, eval_loss: 1.98346e-02
I0208 23:52:46.308659 22542570456896 run_lib.py:133] step: 111650, training_loss: 2.95770e-02
I0208 23:53:03.782488 22542570456896 run_lib.py:133] step: 111700, training_loss: 3.20337e-02
I0208 23:53:03.941556 22542570456896 run_lib.py:146] step: 111700, eval_loss: 2.76664e-02
I0208 23:53:21.537433 22542570456896 run_lib.py:133] step: 111750, training_loss: 3.10550e-02
I0208 23:53:39.011491 22542570456896 run_lib.py:133] step: 111800, training_loss: 2.95650e-02
I0208 23:53:39.168353 22542570456896 run_lib.py:146] step: 111800, eval_loss: 2.72044e-02
I0208 23:53:56.615956 22542570456896 run_lib.py:133] step: 111850, training_loss: 2.68896e-02
I0208 23:54:14.078554 22542570456896 run_lib.py:133] step: 111900, training_loss: 2.94127e-02
I0208 23:54:14.235522 22542570456896 run_lib.py:146] step: 111900, eval_loss: 2.75738e-02
I0208 23:54:31.876729 22542570456896 run_lib.py:133] step: 111950, training_loss: 2.66582e-02
I0208 23:54:49.324098 22542570456896 run_lib.py:133] step: 112000, training_loss: 3.07478e-02
I0208 23:54:49.477468 22542570456896 run_lib.py:146] step: 112000, eval_loss: 2.29621e-02
I0208 23:55:07.066318 22542570456896 run_lib.py:133] step: 112050, training_loss: 2.57118e-02
I0208 23:55:24.527691 22542570456896 run_lib.py:133] step: 112100, training_loss: 2.16800e-02
I0208 23:55:24.684331 22542570456896 run_lib.py:146] step: 112100, eval_loss: 3.02488e-02
I0208 23:55:42.231377 22542570456896 run_lib.py:133] step: 112150, training_loss: 2.89874e-02
I0208 23:55:59.692501 22542570456896 run_lib.py:133] step: 112200, training_loss: 3.09913e-02
I0208 23:55:59.872138 22542570456896 run_lib.py:146] step: 112200, eval_loss: 2.76231e-02
I0208 23:56:17.354342 22542570456896 run_lib.py:133] step: 112250, training_loss: 2.79309e-02
I0208 23:56:34.969364 22542570456896 run_lib.py:133] step: 112300, training_loss: 2.95046e-02
I0208 23:56:35.125484 22542570456896 run_lib.py:146] step: 112300, eval_loss: 2.49958e-02
I0208 23:56:52.567408 22542570456896 run_lib.py:133] step: 112350, training_loss: 3.66425e-02
I0208 23:57:10.146936 22542570456896 run_lib.py:133] step: 112400, training_loss: 1.98964e-02
I0208 23:57:10.310317 22542570456896 run_lib.py:146] step: 112400, eval_loss: 2.61541e-02
I0208 23:57:27.697176 22542570456896 run_lib.py:133] step: 112450, training_loss: 3.16073e-02
I0208 23:57:45.184583 22542570456896 run_lib.py:133] step: 112500, training_loss: 3.40778e-02
I0208 23:57:45.335746 22542570456896 run_lib.py:146] step: 112500, eval_loss: 3.09621e-02
I0208 23:58:03.034808 22542570456896 run_lib.py:133] step: 112550, training_loss: 2.74829e-02
I0208 23:58:20.491921 22542570456896 run_lib.py:133] step: 112600, training_loss: 3.39113e-02
I0208 23:58:20.648633 22542570456896 run_lib.py:146] step: 112600, eval_loss: 2.77012e-02
I0208 23:58:38.047479 22542570456896 run_lib.py:133] step: 112650, training_loss: 2.43405e-02
I0208 23:58:55.614596 22542570456896 run_lib.py:133] step: 112700, training_loss: 2.81458e-02
I0208 23:58:55.777588 22542570456896 run_lib.py:146] step: 112700, eval_loss: 2.65524e-02
I0208 23:59:13.204029 22542570456896 run_lib.py:133] step: 112750, training_loss: 2.84720e-02
I0208 23:59:30.670801 22542570456896 run_lib.py:133] step: 112800, training_loss: 2.81413e-02
I0208 23:59:30.828162 22542570456896 run_lib.py:146] step: 112800, eval_loss: 2.68725e-02
I0208 23:59:48.382431 22542570456896 run_lib.py:133] step: 112850, training_loss: 2.74039e-02
I0209 00:00:05.806921 22542570456896 run_lib.py:133] step: 112900, training_loss: 2.43627e-02
I0209 00:00:05.964758 22542570456896 run_lib.py:146] step: 112900, eval_loss: 3.17618e-02
I0209 00:00:23.440082 22542570456896 run_lib.py:133] step: 112950, training_loss: 2.54315e-02
I0209 00:00:40.879173 22542570456896 run_lib.py:133] step: 113000, training_loss: 2.97983e-02
I0209 00:00:41.034644 22542570456896 run_lib.py:146] step: 113000, eval_loss: 2.93277e-02
I0209 00:00:58.712042 22542570456896 run_lib.py:133] step: 113050, training_loss: 3.48354e-02
I0209 00:01:16.225758 22542570456896 run_lib.py:133] step: 113100, training_loss: 3.08076e-02
I0209 00:01:16.384478 22542570456896 run_lib.py:146] step: 113100, eval_loss: 2.97133e-02
I0209 00:01:33.825664 22542570456896 run_lib.py:133] step: 113150, training_loss: 3.31834e-02
I0209 00:01:51.255010 22542570456896 run_lib.py:133] step: 113200, training_loss: 2.77022e-02
I0209 00:01:51.411425 22542570456896 run_lib.py:146] step: 113200, eval_loss: 2.54113e-02
I0209 00:02:09.006060 22542570456896 run_lib.py:133] step: 113250, training_loss: 3.30013e-02
I0209 00:02:26.434995 22542570456896 run_lib.py:133] step: 113300, training_loss: 3.25285e-02
I0209 00:02:26.592164 22542570456896 run_lib.py:146] step: 113300, eval_loss: 3.76224e-02
I0209 00:02:44.197899 22542570456896 run_lib.py:133] step: 113350, training_loss: 2.84922e-02
I0209 00:03:01.618277 22542570456896 run_lib.py:133] step: 113400, training_loss: 2.78262e-02
I0209 00:03:01.770986 22542570456896 run_lib.py:146] step: 113400, eval_loss: 3.21410e-02
I0209 00:03:19.397528 22542570456896 run_lib.py:133] step: 113450, training_loss: 3.19330e-02
I0209 00:03:36.832369 22542570456896 run_lib.py:133] step: 113500, training_loss: 2.69567e-02
I0209 00:03:36.996009 22542570456896 run_lib.py:146] step: 113500, eval_loss: 2.20575e-02
I0209 00:03:54.550130 22542570456896 run_lib.py:133] step: 113550, training_loss: 2.94142e-02
I0209 00:04:11.992508 22542570456896 run_lib.py:133] step: 113600, training_loss: 2.55415e-02
I0209 00:04:12.168331 22542570456896 run_lib.py:146] step: 113600, eval_loss: 2.87829e-02
I0209 00:04:29.662413 22542570456896 run_lib.py:133] step: 113650, training_loss: 3.31135e-02
I0209 00:04:47.315830 22542570456896 run_lib.py:133] step: 113700, training_loss: 2.72813e-02
I0209 00:04:47.473550 22542570456896 run_lib.py:146] step: 113700, eval_loss: 2.33295e-02
I0209 00:05:04.856192 22542570456896 run_lib.py:133] step: 113750, training_loss: 2.79220e-02
I0209 00:05:22.234438 22542570456896 run_lib.py:133] step: 113800, training_loss: 2.91121e-02
I0209 00:05:22.391172 22542570456896 run_lib.py:146] step: 113800, eval_loss: 2.71208e-02
I0209 00:05:39.957943 22542570456896 run_lib.py:133] step: 113850, training_loss: 2.98600e-02
I0209 00:05:57.391133 22542570456896 run_lib.py:133] step: 113900, training_loss: 2.81908e-02
I0209 00:05:57.546592 22542570456896 run_lib.py:146] step: 113900, eval_loss: 2.94768e-02
I0209 00:06:15.170883 22542570456896 run_lib.py:133] step: 113950, training_loss: 3.48067e-02
I0209 00:06:32.568597 22542570456896 run_lib.py:133] step: 114000, training_loss: 3.08362e-02
I0209 00:06:32.721572 22542570456896 run_lib.py:146] step: 114000, eval_loss: 2.91776e-02
I0209 00:06:50.173344 22542570456896 run_lib.py:133] step: 114050, training_loss: 3.39099e-02
I0209 00:07:07.795582 22542570456896 run_lib.py:133] step: 114100, training_loss: 2.62115e-02
I0209 00:07:07.954679 22542570456896 run_lib.py:146] step: 114100, eval_loss: 2.91974e-02
I0209 00:07:25.394598 22542570456896 run_lib.py:133] step: 114150, training_loss: 2.87036e-02
I0209 00:07:42.868194 22542570456896 run_lib.py:133] step: 114200, training_loss: 3.39166e-02
I0209 00:07:43.026592 22542570456896 run_lib.py:146] step: 114200, eval_loss: 2.67745e-02
I0209 00:08:00.445669 22542570456896 run_lib.py:133] step: 114250, training_loss: 2.77880e-02
I0209 00:08:18.053401 22542570456896 run_lib.py:133] step: 114300, training_loss: 2.38684e-02
I0209 00:08:18.209408 22542570456896 run_lib.py:146] step: 114300, eval_loss: 3.60321e-02
I0209 00:08:35.588940 22542570456896 run_lib.py:133] step: 114350, training_loss: 2.58828e-02
I0209 00:08:53.059595 22542570456896 run_lib.py:133] step: 114400, training_loss: 2.08326e-02
I0209 00:08:53.220329 22542570456896 run_lib.py:146] step: 114400, eval_loss: 2.63750e-02
I0209 00:09:10.617210 22542570456896 run_lib.py:133] step: 114450, training_loss: 2.93645e-02
I0209 00:09:28.068932 22542570456896 run_lib.py:133] step: 114500, training_loss: 3.36492e-02
I0209 00:09:28.249244 22542570456896 run_lib.py:146] step: 114500, eval_loss: 2.95780e-02
I0209 00:09:45.941032 22542570456896 run_lib.py:133] step: 114550, training_loss: 2.78936e-02
I0209 00:10:03.443657 22542570456896 run_lib.py:133] step: 114600, training_loss: 2.75975e-02
I0209 00:10:03.599415 22542570456896 run_lib.py:146] step: 114600, eval_loss: 2.72392e-02
I0209 00:10:21.003357 22542570456896 run_lib.py:133] step: 114650, training_loss: 2.99308e-02
I0209 00:10:38.394485 22542570456896 run_lib.py:133] step: 114700, training_loss: 2.68171e-02
I0209 00:10:38.550462 22542570456896 run_lib.py:146] step: 114700, eval_loss: 2.99305e-02
I0209 00:10:56.121323 22542570456896 run_lib.py:133] step: 114750, training_loss: 2.90624e-02
I0209 00:11:13.565554 22542570456896 run_lib.py:133] step: 114800, training_loss: 3.32253e-02
I0209 00:11:13.721579 22542570456896 run_lib.py:146] step: 114800, eval_loss: 3.08483e-02
I0209 00:11:31.336486 22542570456896 run_lib.py:133] step: 114850, training_loss: 2.63714e-02
I0209 00:11:48.787303 22542570456896 run_lib.py:133] step: 114900, training_loss: 2.34754e-02
I0209 00:11:48.941709 22542570456896 run_lib.py:146] step: 114900, eval_loss: 3.21254e-02
I0209 00:12:06.514912 22542570456896 run_lib.py:133] step: 114950, training_loss: 3.31272e-02
I0209 00:12:23.941180 22542570456896 run_lib.py:133] step: 115000, training_loss: 4.44426e-02
I0209 00:12:24.125411 22542570456896 run_lib.py:146] step: 115000, eval_loss: 2.72608e-02
I0209 00:12:41.590428 22542570456896 run_lib.py:133] step: 115050, training_loss: 3.52426e-02
I0209 00:12:59.229474 22542570456896 run_lib.py:133] step: 115100, training_loss: 3.68329e-02
I0209 00:12:59.386816 22542570456896 run_lib.py:146] step: 115100, eval_loss: 2.23599e-02
I0209 00:13:16.822284 22542570456896 run_lib.py:133] step: 115150, training_loss: 2.79056e-02
I0209 00:13:34.363721 22542570456896 run_lib.py:133] step: 115200, training_loss: 3.46505e-02
I0209 00:13:34.520100 22542570456896 run_lib.py:146] step: 115200, eval_loss: 2.88871e-02
I0209 00:13:51.917125 22542570456896 run_lib.py:133] step: 115250, training_loss: 3.20359e-02
I0209 00:14:09.347829 22542570456896 run_lib.py:133] step: 115300, training_loss: 2.71421e-02
I0209 00:14:09.498846 22542570456896 run_lib.py:146] step: 115300, eval_loss: 2.80530e-02
I0209 00:14:27.141998 22542570456896 run_lib.py:133] step: 115350, training_loss: 3.12671e-02
I0209 00:14:44.559874 22542570456896 run_lib.py:133] step: 115400, training_loss: 2.23335e-02
I0209 00:14:44.715935 22542570456896 run_lib.py:146] step: 115400, eval_loss: 2.43648e-02
I0209 00:15:02.102509 22542570456896 run_lib.py:133] step: 115450, training_loss: 3.16624e-02
I0209 00:15:19.701348 22542570456896 run_lib.py:133] step: 115500, training_loss: 2.28401e-02
I0209 00:15:19.862270 22542570456896 run_lib.py:146] step: 115500, eval_loss: 2.55779e-02
I0209 00:15:37.237711 22542570456896 run_lib.py:133] step: 115550, training_loss: 2.84098e-02
I0209 00:15:54.666391 22542570456896 run_lib.py:133] step: 115600, training_loss: 3.13421e-02
I0209 00:15:54.984522 22542570456896 run_lib.py:146] step: 115600, eval_loss: 2.92535e-02
I0209 00:16:12.425398 22542570456896 run_lib.py:133] step: 115650, training_loss: 3.45091e-02
I0209 00:16:29.892704 22542570456896 run_lib.py:133] step: 115700, training_loss: 2.83335e-02
I0209 00:16:30.047740 22542570456896 run_lib.py:146] step: 115700, eval_loss: 2.54365e-02
I0209 00:16:47.456069 22542570456896 run_lib.py:133] step: 115750, training_loss: 2.73642e-02
I0209 00:17:04.882068 22542570456896 run_lib.py:133] step: 115800, training_loss: 2.85800e-02
I0209 00:17:05.034247 22542570456896 run_lib.py:146] step: 115800, eval_loss: 2.56925e-02
I0209 00:17:22.605449 22542570456896 run_lib.py:133] step: 115850, training_loss: 2.80476e-02
I0209 00:17:40.083577 22542570456896 run_lib.py:133] step: 115900, training_loss: 2.66632e-02
I0209 00:17:40.253505 22542570456896 run_lib.py:146] step: 115900, eval_loss: 2.41503e-02
I0209 00:17:57.710132 22542570456896 run_lib.py:133] step: 115950, training_loss: 3.21684e-02
I0209 00:18:15.173565 22542570456896 run_lib.py:133] step: 116000, training_loss: 2.42356e-02
I0209 00:18:15.341428 22542570456896 run_lib.py:146] step: 116000, eval_loss: 3.19578e-02
I0209 00:18:32.916178 22542570456896 run_lib.py:133] step: 116050, training_loss: 3.52804e-02
I0209 00:18:50.364140 22542570456896 run_lib.py:133] step: 116100, training_loss: 2.82463e-02
I0209 00:18:50.520251 22542570456896 run_lib.py:146] step: 116100, eval_loss: 2.78755e-02
I0209 00:19:07.976366 22542570456896 run_lib.py:133] step: 116150, training_loss: 2.54943e-02
I0209 00:19:25.441568 22542570456896 run_lib.py:133] step: 116200, training_loss: 3.05834e-02
I0209 00:19:25.594676 22542570456896 run_lib.py:146] step: 116200, eval_loss: 2.71078e-02
I0209 00:19:43.203838 22542570456896 run_lib.py:133] step: 116250, training_loss: 2.72021e-02
I0209 00:20:00.606231 22542570456896 run_lib.py:133] step: 116300, training_loss: 2.96420e-02
I0209 00:20:00.759408 22542570456896 run_lib.py:146] step: 116300, eval_loss: 3.19589e-02
I0209 00:20:18.316842 22542570456896 run_lib.py:133] step: 116350, training_loss: 2.70598e-02
I0209 00:20:35.755249 22542570456896 run_lib.py:133] step: 116400, training_loss: 3.26132e-02
I0209 00:20:35.923386 22542570456896 run_lib.py:146] step: 116400, eval_loss: 3.23196e-02
I0209 00:20:53.556632 22542570456896 run_lib.py:133] step: 116450, training_loss: 2.37900e-02
I0209 00:21:10.971935 22542570456896 run_lib.py:133] step: 116500, training_loss: 2.98428e-02
I0209 00:21:11.131263 22542570456896 run_lib.py:146] step: 116500, eval_loss: 2.59138e-02
I0209 00:21:28.564103 22542570456896 run_lib.py:133] step: 116550, training_loss: 3.01181e-02
I0209 00:21:46.158273 22542570456896 run_lib.py:133] step: 116600, training_loss: 2.48826e-02
I0209 00:21:46.323066 22542570456896 run_lib.py:146] step: 116600, eval_loss: 2.33051e-02
I0209 00:22:03.772169 22542570456896 run_lib.py:133] step: 116650, training_loss: 2.69918e-02
I0209 00:22:21.409143 22542570456896 run_lib.py:133] step: 116700, training_loss: 3.16639e-02
I0209 00:22:21.562962 22542570456896 run_lib.py:146] step: 116700, eval_loss: 2.80754e-02
I0209 00:22:39.002303 22542570456896 run_lib.py:133] step: 116750, training_loss: 2.58804e-02
I0209 00:22:56.419202 22542570456896 run_lib.py:133] step: 116800, training_loss: 3.07816e-02
I0209 00:22:56.577290 22542570456896 run_lib.py:146] step: 116800, eval_loss: 2.20067e-02
I0209 00:23:14.154380 22542570456896 run_lib.py:133] step: 116850, training_loss: 2.84197e-02
I0209 00:23:31.609179 22542570456896 run_lib.py:133] step: 116900, training_loss: 2.46123e-02
I0209 00:23:31.769479 22542570456896 run_lib.py:146] step: 116900, eval_loss: 2.76548e-02
I0209 00:23:49.190490 22542570456896 run_lib.py:133] step: 116950, training_loss: 3.13090e-02
I0209 00:24:06.614598 22542570456896 run_lib.py:133] step: 117000, training_loss: 3.28559e-02
I0209 00:24:06.779411 22542570456896 run_lib.py:146] step: 117000, eval_loss: 2.98607e-02
I0209 00:24:24.378512 22542570456896 run_lib.py:133] step: 117050, training_loss: 2.62852e-02
I0209 00:24:41.793428 22542570456896 run_lib.py:133] step: 117100, training_loss: 2.81949e-02
I0209 00:24:41.954908 22542570456896 run_lib.py:146] step: 117100, eval_loss: 2.28278e-02
I0209 00:24:59.449724 22542570456896 run_lib.py:133] step: 117150, training_loss: 3.95391e-02
I0209 00:25:16.850679 22542570456896 run_lib.py:133] step: 117200, training_loss: 3.37969e-02
I0209 00:25:17.014140 22542570456896 run_lib.py:146] step: 117200, eval_loss: 2.46031e-02
I0209 00:25:34.478944 22542570456896 run_lib.py:133] step: 117250, training_loss: 2.76687e-02
I0209 00:25:51.900322 22542570456896 run_lib.py:133] step: 117300, training_loss: 2.81771e-02
I0209 00:25:52.057578 22542570456896 run_lib.py:146] step: 117300, eval_loss: 3.82935e-02
I0209 00:26:09.653709 22542570456896 run_lib.py:133] step: 117350, training_loss: 2.84209e-02
I0209 00:26:27.114027 22542570456896 run_lib.py:133] step: 117400, training_loss: 2.63090e-02
I0209 00:26:27.273533 22542570456896 run_lib.py:146] step: 117400, eval_loss: 2.20120e-02
I0209 00:26:44.686287 22542570456896 run_lib.py:133] step: 117450, training_loss: 2.67893e-02
I0209 00:27:02.101347 22542570456896 run_lib.py:133] step: 117500, training_loss: 2.60849e-02
I0209 00:27:02.277398 22542570456896 run_lib.py:146] step: 117500, eval_loss: 2.23263e-02
I0209 00:27:19.888068 22542570456896 run_lib.py:133] step: 117550, training_loss: 3.12274e-02
I0209 00:27:37.311199 22542570456896 run_lib.py:133] step: 117600, training_loss: 2.50117e-02
I0209 00:27:37.467136 22542570456896 run_lib.py:146] step: 117600, eval_loss: 3.52596e-02
I0209 00:27:55.059262 22542570456896 run_lib.py:133] step: 117650, training_loss: 2.80808e-02
I0209 00:28:12.460601 22542570456896 run_lib.py:133] step: 117700, training_loss: 3.19289e-02
I0209 00:28:12.612312 22542570456896 run_lib.py:146] step: 117700, eval_loss: 3.29987e-02
I0209 00:28:30.187936 22542570456896 run_lib.py:133] step: 117750, training_loss: 2.35822e-02
I0209 00:28:47.652955 22542570456896 run_lib.py:133] step: 117800, training_loss: 2.82547e-02
I0209 00:28:47.822491 22542570456896 run_lib.py:146] step: 117800, eval_loss: 2.60169e-02
I0209 00:29:05.468032 22542570456896 run_lib.py:133] step: 117850, training_loss: 2.15635e-02
I0209 00:29:22.870389 22542570456896 run_lib.py:133] step: 117900, training_loss: 3.06180e-02
I0209 00:29:23.028356 22542570456896 run_lib.py:146] step: 117900, eval_loss: 2.83874e-02
I0209 00:29:40.403038 22542570456896 run_lib.py:133] step: 117950, training_loss: 2.33758e-02
I0209 00:29:57.978049 22542570456896 run_lib.py:133] step: 118000, training_loss: 2.89510e-02
I0209 00:29:58.135363 22542570456896 run_lib.py:146] step: 118000, eval_loss: 3.21959e-02
I0209 00:30:15.558904 22542570456896 run_lib.py:133] step: 118050, training_loss: 2.57044e-02
I0209 00:30:33.042845 22542570456896 run_lib.py:133] step: 118100, training_loss: 3.26184e-02
I0209 00:30:33.199610 22542570456896 run_lib.py:146] step: 118100, eval_loss: 2.57046e-02
I0209 00:30:50.839904 22542570456896 run_lib.py:133] step: 118150, training_loss: 3.04943e-02
I0209 00:31:08.402877 22542570456896 run_lib.py:133] step: 118200, training_loss: 2.72011e-02
I0209 00:31:08.556339 22542570456896 run_lib.py:146] step: 118200, eval_loss: 2.71748e-02
I0209 00:31:25.948524 22542570456896 run_lib.py:133] step: 118250, training_loss: 2.30310e-02
I0209 00:31:43.408173 22542570456896 run_lib.py:133] step: 118300, training_loss: 2.34110e-02
I0209 00:31:43.572838 22542570456896 run_lib.py:146] step: 118300, eval_loss: 3.05333e-02
I0209 00:32:01.047750 22542570456896 run_lib.py:133] step: 118350, training_loss: 2.87529e-02
I0209 00:32:18.715360 22542570456896 run_lib.py:133] step: 118400, training_loss: 3.01520e-02
I0209 00:32:18.877316 22542570456896 run_lib.py:146] step: 118400, eval_loss: 2.70065e-02
I0209 00:32:36.287700 22542570456896 run_lib.py:133] step: 118450, training_loss: 2.44890e-02
I0209 00:32:53.699666 22542570456896 run_lib.py:133] step: 118500, training_loss: 3.26327e-02
I0209 00:32:53.856794 22542570456896 run_lib.py:146] step: 118500, eval_loss: 2.83236e-02
I0209 00:33:11.269228 22542570456896 run_lib.py:133] step: 118550, training_loss: 2.99662e-02
I0209 00:33:28.850405 22542570456896 run_lib.py:133] step: 118600, training_loss: 2.67349e-02
I0209 00:33:29.004964 22542570456896 run_lib.py:146] step: 118600, eval_loss: 3.22724e-02
I0209 00:33:46.470390 22542570456896 run_lib.py:133] step: 118650, training_loss: 3.45131e-02
I0209 00:34:03.990585 22542570456896 run_lib.py:133] step: 118700, training_loss: 2.65372e-02
I0209 00:34:04.144389 22542570456896 run_lib.py:146] step: 118700, eval_loss: 2.88029e-02
I0209 00:34:21.608473 22542570456896 run_lib.py:133] step: 118750, training_loss: 2.75931e-02
I0209 00:34:39.002533 22542570456896 run_lib.py:133] step: 118800, training_loss: 2.63911e-02
I0209 00:34:39.164712 22542570456896 run_lib.py:146] step: 118800, eval_loss: 2.98998e-02
I0209 00:34:56.702119 22542570456896 run_lib.py:133] step: 118850, training_loss: 2.93273e-02
I0209 00:35:14.208204 22542570456896 run_lib.py:133] step: 118900, training_loss: 3.46473e-02
I0209 00:35:14.378277 22542570456896 run_lib.py:146] step: 118900, eval_loss: 2.84169e-02
I0209 00:35:31.824331 22542570456896 run_lib.py:133] step: 118950, training_loss: 2.75620e-02
I0209 00:35:49.223567 22542570456896 run_lib.py:133] step: 119000, training_loss: 2.99526e-02
I0209 00:35:49.380807 22542570456896 run_lib.py:146] step: 119000, eval_loss: 2.90690e-02
I0209 00:36:06.974875 22542570456896 run_lib.py:133] step: 119050, training_loss: 3.05660e-02
I0209 00:36:24.417757 22542570456896 run_lib.py:133] step: 119100, training_loss: 3.11396e-02
I0209 00:36:24.571338 22542570456896 run_lib.py:146] step: 119100, eval_loss: 3.05348e-02
I0209 00:36:42.136251 22542570456896 run_lib.py:133] step: 119150, training_loss: 2.31377e-02
I0209 00:36:59.598844 22542570456896 run_lib.py:133] step: 119200, training_loss: 2.84428e-02
I0209 00:36:59.776288 22542570456896 run_lib.py:146] step: 119200, eval_loss: 3.82268e-02
I0209 00:37:17.387969 22542570456896 run_lib.py:133] step: 119250, training_loss: 3.39020e-02
I0209 00:37:34.842461 22542570456896 run_lib.py:133] step: 119300, training_loss: 2.70239e-02
I0209 00:37:35.003373 22542570456896 run_lib.py:146] step: 119300, eval_loss: 3.36782e-02
I0209 00:37:52.431270 22542570456896 run_lib.py:133] step: 119350, training_loss: 2.19873e-02
I0209 00:38:09.965094 22542570456896 run_lib.py:133] step: 119400, training_loss: 2.86258e-02
I0209 00:38:10.129360 22542570456896 run_lib.py:146] step: 119400, eval_loss: 2.72819e-02
I0209 00:38:27.567163 22542570456896 run_lib.py:133] step: 119450, training_loss: 2.51053e-02
I0209 00:38:45.186336 22542570456896 run_lib.py:133] step: 119500, training_loss: 2.41258e-02
I0209 00:38:45.339643 22542570456896 run_lib.py:146] step: 119500, eval_loss: 2.75507e-02
I0209 00:39:02.763139 22542570456896 run_lib.py:133] step: 119550, training_loss: 3.35089e-02
I0209 00:39:20.208033 22542570456896 run_lib.py:133] step: 119600, training_loss: 3.00673e-02
I0209 00:39:20.362382 22542570456896 run_lib.py:146] step: 119600, eval_loss: 2.79080e-02
I0209 00:39:37.925973 22542570456896 run_lib.py:133] step: 119650, training_loss: 2.82760e-02
I0209 00:39:55.318269 22542570456896 run_lib.py:133] step: 119700, training_loss: 2.66847e-02
I0209 00:39:55.475455 22542570456896 run_lib.py:146] step: 119700, eval_loss: 2.89109e-02
I0209 00:40:12.912198 22542570456896 run_lib.py:133] step: 119750, training_loss: 2.55821e-02
I0209 00:40:30.584756 22542570456896 run_lib.py:133] step: 119800, training_loss: 3.27322e-02
I0209 00:40:30.741393 22542570456896 run_lib.py:146] step: 119800, eval_loss: 2.53644e-02
I0209 00:40:48.169954 22542570456896 run_lib.py:133] step: 119850, training_loss: 2.80842e-02
I0209 00:41:05.620513 22542570456896 run_lib.py:133] step: 119900, training_loss: 2.93816e-02
I0209 00:41:05.777294 22542570456896 run_lib.py:146] step: 119900, eval_loss: 2.46374e-02
I0209 00:41:23.268354 22542570456896 run_lib.py:133] step: 119950, training_loss: 3.15473e-02
I0209 00:41:40.686147 22542570456896 run_lib.py:133] step: 120000, training_loss: 2.31050e-02
I0209 00:41:41.421283 22542570456896 run_lib.py:146] step: 120000, eval_loss: 2.66282e-02
I0209 00:42:01.508473 22542570456896 run_lib.py:133] step: 120050, training_loss: 2.80048e-02
I0209 00:42:18.989343 22542570456896 run_lib.py:133] step: 120100, training_loss: 2.51754e-02
I0209 00:42:19.146278 22542570456896 run_lib.py:146] step: 120100, eval_loss: 2.55672e-02
I0209 00:42:36.750084 22542570456896 run_lib.py:133] step: 120150, training_loss: 3.80233e-02
I0209 00:42:54.152908 22542570456896 run_lib.py:133] step: 120200, training_loss: 3.31357e-02
I0209 00:42:54.312385 22542570456896 run_lib.py:146] step: 120200, eval_loss: 3.36150e-02
I0209 00:43:11.776973 22542570456896 run_lib.py:133] step: 120250, training_loss: 2.82338e-02
I0209 00:43:29.184794 22542570456896 run_lib.py:133] step: 120300, training_loss: 3.15285e-02
I0209 00:43:29.362288 22542570456896 run_lib.py:146] step: 120300, eval_loss: 2.88053e-02
I0209 00:43:46.812095 22542570456896 run_lib.py:133] step: 120350, training_loss: 2.61642e-02
I0209 00:44:04.233814 22542570456896 run_lib.py:133] step: 120400, training_loss: 2.77460e-02
I0209 00:44:04.398581 22542570456896 run_lib.py:146] step: 120400, eval_loss: 2.50119e-02
I0209 00:44:21.983321 22542570456896 run_lib.py:133] step: 120450, training_loss: 3.05745e-02
I0209 00:44:39.493799 22542570456896 run_lib.py:133] step: 120500, training_loss: 2.73703e-02
I0209 00:44:39.658772 22542570456896 run_lib.py:146] step: 120500, eval_loss: 3.28533e-02
I0209 00:44:57.062968 22542570456896 run_lib.py:133] step: 120550, training_loss: 2.69985e-02
I0209 00:45:14.513598 22542570456896 run_lib.py:133] step: 120600, training_loss: 3.10533e-02
I0209 00:45:14.665852 22542570456896 run_lib.py:146] step: 120600, eval_loss: 2.92479e-02
I0209 00:45:32.297475 22542570456896 run_lib.py:133] step: 120650, training_loss: 3.46166e-02
I0209 00:45:49.711469 22542570456896 run_lib.py:133] step: 120700, training_loss: 2.98692e-02
I0209 00:45:49.867780 22542570456896 run_lib.py:146] step: 120700, eval_loss: 2.48682e-02
I0209 00:46:07.420604 22542570456896 run_lib.py:133] step: 120750, training_loss: 2.86266e-02
I0209 00:46:24.824631 22542570456896 run_lib.py:133] step: 120800, training_loss: 2.57929e-02
I0209 00:46:24.981578 22542570456896 run_lib.py:146] step: 120800, eval_loss: 2.81628e-02
I0209 00:46:42.565762 22542570456896 run_lib.py:133] step: 120850, training_loss: 3.13963e-02
I0209 00:47:00.037805 22542570456896 run_lib.py:133] step: 120900, training_loss: 2.90058e-02
I0209 00:47:00.201515 22542570456896 run_lib.py:146] step: 120900, eval_loss: 3.41003e-02
I0209 00:47:17.828045 22542570456896 run_lib.py:133] step: 120950, training_loss: 2.54805e-02
I0209 00:47:35.229873 22542570456896 run_lib.py:133] step: 121000, training_loss: 2.57148e-02
I0209 00:47:35.385156 22542570456896 run_lib.py:146] step: 121000, eval_loss: 2.60189e-02
I0209 00:47:52.786310 22542570456896 run_lib.py:133] step: 121050, training_loss: 3.05554e-02
I0209 00:48:10.342399 22542570456896 run_lib.py:133] step: 121100, training_loss: 2.25246e-02
I0209 00:48:10.498553 22542570456896 run_lib.py:146] step: 121100, eval_loss: 2.94416e-02
I0209 00:48:27.921978 22542570456896 run_lib.py:133] step: 121150, training_loss: 2.69252e-02
I0209 00:48:45.349356 22542570456896 run_lib.py:133] step: 121200, training_loss: 2.58478e-02
I0209 00:48:45.505553 22542570456896 run_lib.py:146] step: 121200, eval_loss: 2.41603e-02
I0209 00:49:03.145372 22542570456896 run_lib.py:133] step: 121250, training_loss: 3.09799e-02
I0209 00:49:20.610357 22542570456896 run_lib.py:133] step: 121300, training_loss: 2.42423e-02
I0209 00:49:20.769646 22542570456896 run_lib.py:146] step: 121300, eval_loss: 2.28775e-02
I0209 00:49:38.349858 22542570456896 run_lib.py:133] step: 121350, training_loss: 3.38181e-02
I0209 00:49:55.759854 22542570456896 run_lib.py:133] step: 121400, training_loss: 2.63727e-02
I0209 00:49:55.916073 22542570456896 run_lib.py:146] step: 121400, eval_loss: 3.00413e-02
I0209 00:50:13.375560 22542570456896 run_lib.py:133] step: 121450, training_loss: 2.82735e-02
I0209 00:50:31.043570 22542570456896 run_lib.py:133] step: 121500, training_loss: 2.98060e-02
I0209 00:50:31.199084 22542570456896 run_lib.py:146] step: 121500, eval_loss: 2.28573e-02
I0209 00:50:48.619327 22542570456896 run_lib.py:133] step: 121550, training_loss: 3.16216e-02
I0209 00:51:06.023909 22542570456896 run_lib.py:133] step: 121600, training_loss: 2.85626e-02
I0209 00:51:06.177351 22542570456896 run_lib.py:146] step: 121600, eval_loss: 3.06671e-02
I0209 00:51:23.620221 22542570456896 run_lib.py:133] step: 121650, training_loss: 3.48842e-02
I0209 00:51:41.204414 22542570456896 run_lib.py:133] step: 121700, training_loss: 3.01773e-02
I0209 00:51:41.378035 22542570456896 run_lib.py:146] step: 121700, eval_loss: 2.56064e-02
I0209 00:51:58.822024 22542570456896 run_lib.py:133] step: 121750, training_loss: 3.37500e-02
I0209 00:52:16.370092 22542570456896 run_lib.py:133] step: 121800, training_loss: 2.74718e-02
I0209 00:52:16.535287 22542570456896 run_lib.py:146] step: 121800, eval_loss: 2.42146e-02
I0209 00:52:33.926519 22542570456896 run_lib.py:133] step: 121850, training_loss: 2.99907e-02
I0209 00:52:51.377180 22542570456896 run_lib.py:133] step: 121900, training_loss: 3.02350e-02
I0209 00:52:51.534378 22542570456896 run_lib.py:146] step: 121900, eval_loss: 2.81369e-02
I0209 00:53:09.087980 22542570456896 run_lib.py:133] step: 121950, training_loss: 3.34352e-02
I0209 00:53:26.625736 22542570456896 run_lib.py:133] step: 122000, training_loss: 3.38775e-02
I0209 00:53:26.789869 22542570456896 run_lib.py:146] step: 122000, eval_loss: 3.24145e-02
I0209 00:53:44.255487 22542570456896 run_lib.py:133] step: 122050, training_loss: 3.02726e-02
I0209 00:54:01.655304 22542570456896 run_lib.py:133] step: 122100, training_loss: 3.01035e-02
I0209 00:54:01.811221 22542570456896 run_lib.py:146] step: 122100, eval_loss: 2.52909e-02
I0209 00:54:19.383685 22542570456896 run_lib.py:133] step: 122150, training_loss: 2.92457e-02
I0209 00:54:36.809548 22542570456896 run_lib.py:133] step: 122200, training_loss: 2.78003e-02
I0209 00:54:36.968534 22542570456896 run_lib.py:146] step: 122200, eval_loss: 2.71326e-02
I0209 00:54:54.597952 22542570456896 run_lib.py:133] step: 122250, training_loss: 3.00772e-02
I0209 00:55:12.067724 22542570456896 run_lib.py:133] step: 122300, training_loss: 2.53552e-02
I0209 00:55:12.232534 22542570456896 run_lib.py:146] step: 122300, eval_loss: 2.68283e-02
I0209 00:55:29.845546 22542570456896 run_lib.py:133] step: 122350, training_loss: 2.98901e-02
I0209 00:55:47.238775 22542570456896 run_lib.py:133] step: 122400, training_loss: 2.63854e-02
I0209 00:55:47.392859 22542570456896 run_lib.py:146] step: 122400, eval_loss: 2.93111e-02
I0209 00:56:04.797282 22542570456896 run_lib.py:133] step: 122450, training_loss: 3.31969e-02
I0209 00:56:22.388848 22542570456896 run_lib.py:133] step: 122500, training_loss: 3.09852e-02
I0209 00:56:22.551873 22542570456896 run_lib.py:146] step: 122500, eval_loss: 2.17762e-02
I0209 00:56:40.032128 22542570456896 run_lib.py:133] step: 122550, training_loss: 2.78121e-02
I0209 00:56:57.692611 22542570456896 run_lib.py:133] step: 122600, training_loss: 2.78610e-02
I0209 00:56:57.855612 22542570456896 run_lib.py:146] step: 122600, eval_loss: 3.11025e-02
I0209 00:57:15.293886 22542570456896 run_lib.py:133] step: 122650, training_loss: 3.43825e-02
I0209 00:57:32.744763 22542570456896 run_lib.py:133] step: 122700, training_loss: 2.71052e-02
I0209 00:57:32.911608 22542570456896 run_lib.py:146] step: 122700, eval_loss: 2.83477e-02
I0209 00:57:50.462476 22542570456896 run_lib.py:133] step: 122750, training_loss: 2.78917e-02
I0209 00:58:07.926362 22542570456896 run_lib.py:133] step: 122800, training_loss: 3.04149e-02
I0209 00:58:08.093026 22542570456896 run_lib.py:146] step: 122800, eval_loss: 2.83526e-02
I0209 00:58:25.570986 22542570456896 run_lib.py:133] step: 122850, training_loss: 2.99891e-02
I0209 00:58:43.171954 22542570456896 run_lib.py:133] step: 122900, training_loss: 2.83782e-02
I0209 00:58:43.333156 22542570456896 run_lib.py:146] step: 122900, eval_loss: 2.84677e-02
I0209 00:59:00.782395 22542570456896 run_lib.py:133] step: 122950, training_loss: 3.60920e-02
I0209 00:59:18.224111 22542570456896 run_lib.py:133] step: 123000, training_loss: 2.86050e-02
I0209 00:59:18.524337 22542570456896 run_lib.py:146] step: 123000, eval_loss: 3.35675e-02
I0209 00:59:35.925692 22542570456896 run_lib.py:133] step: 123050, training_loss: 2.05798e-02
I0209 00:59:53.346781 22542570456896 run_lib.py:133] step: 123100, training_loss: 2.48177e-02
I0209 00:59:53.516175 22542570456896 run_lib.py:146] step: 123100, eval_loss: 2.88093e-02
I0209 01:00:10.953326 22542570456896 run_lib.py:133] step: 123150, training_loss: 3.02752e-02
I0209 01:00:28.396852 22542570456896 run_lib.py:133] step: 123200, training_loss: 2.40875e-02
I0209 01:00:28.556591 22542570456896 run_lib.py:146] step: 123200, eval_loss: 2.75189e-02
I0209 01:00:46.159087 22542570456896 run_lib.py:133] step: 123250, training_loss: 3.20458e-02
I0209 01:01:03.621599 22542570456896 run_lib.py:133] step: 123300, training_loss: 3.52113e-02
I0209 01:01:03.777407 22542570456896 run_lib.py:146] step: 123300, eval_loss: 3.12553e-02
I0209 01:01:21.185100 22542570456896 run_lib.py:133] step: 123350, training_loss: 3.51647e-02
I0209 01:01:38.650845 22542570456896 run_lib.py:133] step: 123400, training_loss: 2.49645e-02
I0209 01:01:38.809661 22542570456896 run_lib.py:146] step: 123400, eval_loss: 3.14099e-02
I0209 01:01:56.443405 22542570456896 run_lib.py:133] step: 123450, training_loss: 2.65337e-02
I0209 01:02:13.890946 22542570456896 run_lib.py:133] step: 123500, training_loss: 2.40985e-02
I0209 01:02:14.048384 22542570456896 run_lib.py:146] step: 123500, eval_loss: 2.88971e-02
I0209 01:02:31.448530 22542570456896 run_lib.py:133] step: 123550, training_loss: 2.95261e-02
I0209 01:02:48.860683 22542570456896 run_lib.py:133] step: 123600, training_loss: 2.44221e-02
I0209 01:02:49.019479 22542570456896 run_lib.py:146] step: 123600, eval_loss: 2.88972e-02
I0209 01:03:06.581108 22542570456896 run_lib.py:133] step: 123650, training_loss: 2.84663e-02
I0209 01:03:24.061237 22542570456896 run_lib.py:133] step: 123700, training_loss: 2.58383e-02
I0209 01:03:24.218479 22542570456896 run_lib.py:146] step: 123700, eval_loss: 2.73374e-02
I0209 01:03:41.868608 22542570456896 run_lib.py:133] step: 123750, training_loss: 2.89488e-02
I0209 01:03:59.329305 22542570456896 run_lib.py:133] step: 123800, training_loss: 2.54587e-02
I0209 01:03:59.494302 22542570456896 run_lib.py:146] step: 123800, eval_loss: 3.23689e-02
I0209 01:04:17.092738 22542570456896 run_lib.py:133] step: 123850, training_loss: 2.47576e-02
I0209 01:04:34.503317 22542570456896 run_lib.py:133] step: 123900, training_loss: 2.68001e-02
I0209 01:04:34.656320 22542570456896 run_lib.py:146] step: 123900, eval_loss: 2.49485e-02
I0209 01:04:52.113846 22542570456896 run_lib.py:133] step: 123950, training_loss: 3.50818e-02
I0209 01:05:09.778547 22542570456896 run_lib.py:133] step: 124000, training_loss: 2.85639e-02
I0209 01:05:09.935563 22542570456896 run_lib.py:146] step: 124000, eval_loss: 3.01466e-02
I0209 01:05:27.380769 22542570456896 run_lib.py:133] step: 124050, training_loss: 2.32574e-02
I0209 01:05:44.961609 22542570456896 run_lib.py:133] step: 124100, training_loss: 2.91511e-02
I0209 01:05:45.119712 22542570456896 run_lib.py:146] step: 124100, eval_loss: 2.59558e-02
I0209 01:06:02.516127 22542570456896 run_lib.py:133] step: 124150, training_loss: 3.34903e-02
I0209 01:06:19.923032 22542570456896 run_lib.py:133] step: 124200, training_loss: 2.86539e-02
I0209 01:06:20.091299 22542570456896 run_lib.py:146] step: 124200, eval_loss: 2.85836e-02
I0209 01:06:37.672062 22542570456896 run_lib.py:133] step: 124250, training_loss: 3.57123e-02
I0209 01:06:55.088157 22542570456896 run_lib.py:133] step: 124300, training_loss: 2.80842e-02
I0209 01:06:55.242706 22542570456896 run_lib.py:146] step: 124300, eval_loss: 2.85037e-02
I0209 01:07:12.684533 22542570456896 run_lib.py:133] step: 124350, training_loss: 2.38094e-02
I0209 01:07:30.095372 22542570456896 run_lib.py:133] step: 124400, training_loss: 2.51878e-02
I0209 01:07:30.246311 22542570456896 run_lib.py:146] step: 124400, eval_loss: 2.53245e-02
I0209 01:07:47.851619 22542570456896 run_lib.py:133] step: 124450, training_loss: 3.56571e-02
I0209 01:08:05.280234 22542570456896 run_lib.py:133] step: 124500, training_loss: 2.49975e-02
I0209 01:08:05.452089 22542570456896 run_lib.py:146] step: 124500, eval_loss: 3.11100e-02
I0209 01:08:22.971438 22542570456896 run_lib.py:133] step: 124550, training_loss: 3.65321e-02
I0209 01:08:40.415786 22542570456896 run_lib.py:133] step: 124600, training_loss: 2.75243e-02
I0209 01:08:40.574528 22542570456896 run_lib.py:146] step: 124600, eval_loss: 3.06733e-02
I0209 01:08:57.946698 22542570456896 run_lib.py:133] step: 124650, training_loss: 2.19425e-02
I0209 01:09:15.326994 22542570456896 run_lib.py:133] step: 124700, training_loss: 2.55408e-02
I0209 01:09:15.484374 22542570456896 run_lib.py:146] step: 124700, eval_loss: 2.88656e-02
I0209 01:09:33.124040 22542570456896 run_lib.py:133] step: 124750, training_loss: 2.43076e-02
I0209 01:09:50.683106 22542570456896 run_lib.py:133] step: 124800, training_loss: 2.99967e-02
I0209 01:09:50.841859 22542570456896 run_lib.py:146] step: 124800, eval_loss: 2.42306e-02
I0209 01:10:08.345686 22542570456896 run_lib.py:133] step: 124850, training_loss: 2.51492e-02
I0209 01:10:25.764099 22542570456896 run_lib.py:133] step: 124900, training_loss: 3.37593e-02
I0209 01:10:25.916293 22542570456896 run_lib.py:146] step: 124900, eval_loss: 3.38321e-02
I0209 01:10:43.506572 22542570456896 run_lib.py:133] step: 124950, training_loss: 3.29374e-02
I0209 01:11:00.922150 22542570456896 run_lib.py:133] step: 125000, training_loss: 2.65901e-02
I0209 01:11:01.077534 22542570456896 run_lib.py:146] step: 125000, eval_loss: 2.80833e-02
I0209 01:11:18.644587 22542570456896 run_lib.py:133] step: 125050, training_loss: 2.56640e-02
I0209 01:11:36.129965 22542570456896 run_lib.py:133] step: 125100, training_loss: 2.99560e-02
I0209 01:11:36.300512 22542570456896 run_lib.py:146] step: 125100, eval_loss: 2.33684e-02
I0209 01:11:53.900249 22542570456896 run_lib.py:133] step: 125150, training_loss: 2.69731e-02
I0209 01:12:11.360586 22542570456896 run_lib.py:133] step: 125200, training_loss: 2.98726e-02
I0209 01:12:11.515017 22542570456896 run_lib.py:146] step: 125200, eval_loss: 2.85098e-02
I0209 01:12:29.066842 22542570456896 run_lib.py:133] step: 125250, training_loss: 3.07820e-02
I0209 01:12:46.510531 22542570456896 run_lib.py:133] step: 125300, training_loss: 2.96603e-02
I0209 01:12:46.664246 22542570456896 run_lib.py:146] step: 125300, eval_loss: 3.18835e-02
I0209 01:13:04.163912 22542570456896 run_lib.py:133] step: 125350, training_loss: 2.58739e-02
I0209 01:13:21.777890 22542570456896 run_lib.py:133] step: 125400, training_loss: 2.35358e-02
I0209 01:13:21.931343 22542570456896 run_lib.py:146] step: 125400, eval_loss: 2.75177e-02
I0209 01:13:39.359808 22542570456896 run_lib.py:133] step: 125450, training_loss: 2.86990e-02
I0209 01:13:56.818740 22542570456896 run_lib.py:133] step: 125500, training_loss: 2.09058e-02
I0209 01:13:56.977592 22542570456896 run_lib.py:146] step: 125500, eval_loss: 3.01127e-02
I0209 01:14:14.597799 22542570456896 run_lib.py:133] step: 125550, training_loss: 3.40661e-02
I0209 01:14:32.227526 22542570456896 run_lib.py:133] step: 125600, training_loss: 2.49981e-02
I0209 01:14:32.384490 22542570456896 run_lib.py:146] step: 125600, eval_loss: 3.78806e-02
I0209 01:14:49.831244 22542570456896 run_lib.py:133] step: 125650, training_loss: 2.99735e-02
I0209 01:15:07.287093 22542570456896 run_lib.py:133] step: 125700, training_loss: 2.90041e-02
I0209 01:15:07.442075 22542570456896 run_lib.py:146] step: 125700, eval_loss: 2.81008e-02
I0209 01:15:24.863589 22542570456896 run_lib.py:133] step: 125750, training_loss: 3.07312e-02
I0209 01:15:42.491374 22542570456896 run_lib.py:133] step: 125800, training_loss: 2.69967e-02
I0209 01:15:42.642239 22542570456896 run_lib.py:146] step: 125800, eval_loss: 2.47836e-02
I0209 01:16:00.087250 22542570456896 run_lib.py:133] step: 125850, training_loss: 2.59347e-02
I0209 01:16:17.546580 22542570456896 run_lib.py:133] step: 125900, training_loss: 2.70394e-02
I0209 01:16:17.713105 22542570456896 run_lib.py:146] step: 125900, eval_loss: 3.49147e-02
I0209 01:16:35.201480 22542570456896 run_lib.py:133] step: 125950, training_loss: 3.15103e-02
I0209 01:16:52.823719 22542570456896 run_lib.py:133] step: 126000, training_loss: 2.96345e-02
I0209 01:16:52.983587 22542570456896 run_lib.py:146] step: 126000, eval_loss: 3.54014e-02
I0209 01:17:10.442667 22542570456896 run_lib.py:133] step: 126050, training_loss: 2.79755e-02
I0209 01:17:27.900875 22542570456896 run_lib.py:133] step: 126100, training_loss: 3.28571e-02
I0209 01:17:28.066248 22542570456896 run_lib.py:146] step: 126100, eval_loss: 3.00867e-02
I0209 01:17:45.551620 22542570456896 run_lib.py:133] step: 126150, training_loss: 2.76262e-02
I0209 01:18:02.998489 22542570456896 run_lib.py:133] step: 126200, training_loss: 2.55711e-02
I0209 01:18:03.154600 22542570456896 run_lib.py:146] step: 126200, eval_loss: 2.55707e-02
I0209 01:18:20.774888 22542570456896 run_lib.py:133] step: 126250, training_loss: 3.04207e-02
I0209 01:18:38.254064 22542570456896 run_lib.py:133] step: 126300, training_loss: 2.28328e-02
I0209 01:18:38.406490 22542570456896 run_lib.py:146] step: 126300, eval_loss: 3.35094e-02
I0209 01:18:55.828990 22542570456896 run_lib.py:133] step: 126350, training_loss: 2.87455e-02
I0209 01:19:13.258913 22542570456896 run_lib.py:133] step: 126400, training_loss: 2.23128e-02
I0209 01:19:13.429586 22542570456896 run_lib.py:146] step: 126400, eval_loss: 3.13226e-02
I0209 01:19:31.038516 22542570456896 run_lib.py:133] step: 126450, training_loss: 2.37686e-02
I0209 01:19:48.517428 22542570456896 run_lib.py:133] step: 126500, training_loss: 3.03027e-02
I0209 01:19:48.676354 22542570456896 run_lib.py:146] step: 126500, eval_loss: 3.41227e-02
I0209 01:20:06.309563 22542570456896 run_lib.py:133] step: 126550, training_loss: 3.68967e-02
I0209 01:20:23.741297 22542570456896 run_lib.py:133] step: 126600, training_loss: 3.46756e-02
I0209 01:20:23.897380 22542570456896 run_lib.py:146] step: 126600, eval_loss: 2.83945e-02
I0209 01:20:41.463743 22542570456896 run_lib.py:133] step: 126650, training_loss: 3.30295e-02
I0209 01:20:58.909248 22542570456896 run_lib.py:133] step: 126700, training_loss: 3.08217e-02
I0209 01:20:59.065577 22542570456896 run_lib.py:146] step: 126700, eval_loss: 2.86821e-02
I0209 01:21:16.530559 22542570456896 run_lib.py:133] step: 126750, training_loss: 2.81701e-02
I0209 01:21:34.171252 22542570456896 run_lib.py:133] step: 126800, training_loss: 2.74287e-02
I0209 01:21:34.325389 22542570456896 run_lib.py:146] step: 126800, eval_loss: 2.88756e-02
I0209 01:21:51.758880 22542570456896 run_lib.py:133] step: 126850, training_loss: 2.37498e-02
I0209 01:22:09.385434 22542570456896 run_lib.py:133] step: 126900, training_loss: 3.35938e-02
I0209 01:22:09.549587 22542570456896 run_lib.py:146] step: 126900, eval_loss: 2.76752e-02
I0209 01:22:26.968601 22542570456896 run_lib.py:133] step: 126950, training_loss: 3.34753e-02
I0209 01:22:44.410361 22542570456896 run_lib.py:133] step: 127000, training_loss: 2.88008e-02
I0209 01:22:44.578413 22542570456896 run_lib.py:146] step: 127000, eval_loss: 2.91640e-02
I0209 01:23:02.204698 22542570456896 run_lib.py:133] step: 127050, training_loss: 2.78903e-02
I0209 01:23:19.658140 22542570456896 run_lib.py:133] step: 127100, training_loss: 3.05968e-02
I0209 01:23:19.811957 22542570456896 run_lib.py:146] step: 127100, eval_loss: 3.19778e-02
I0209 01:23:37.273817 22542570456896 run_lib.py:133] step: 127150, training_loss: 2.42383e-02
I0209 01:23:54.851732 22542570456896 run_lib.py:133] step: 127200, training_loss: 2.70652e-02
I0209 01:23:55.005329 22542570456896 run_lib.py:146] step: 127200, eval_loss: 3.70800e-02
I0209 01:24:12.436695 22542570456896 run_lib.py:133] step: 127250, training_loss: 3.34774e-02
I0209 01:24:29.873907 22542570456896 run_lib.py:133] step: 127300, training_loss: 2.59958e-02
I0209 01:24:30.036563 22542570456896 run_lib.py:146] step: 127300, eval_loss: 2.65281e-02
I0209 01:24:47.592978 22542570456896 run_lib.py:133] step: 127350, training_loss: 3.32906e-02
I0209 01:25:05.003306 22542570456896 run_lib.py:133] step: 127400, training_loss: 3.11360e-02
I0209 01:25:05.161194 22542570456896 run_lib.py:146] step: 127400, eval_loss: 2.30522e-02
I0209 01:25:22.577031 22542570456896 run_lib.py:133] step: 127450, training_loss: 2.75519e-02
I0209 01:25:39.980171 22542570456896 run_lib.py:133] step: 127500, training_loss: 3.09092e-02
I0209 01:25:40.135396 22542570456896 run_lib.py:146] step: 127500, eval_loss: 2.65118e-02
I0209 01:25:57.735495 22542570456896 run_lib.py:133] step: 127550, training_loss: 2.68630e-02
I0209 01:26:15.238486 22542570456896 run_lib.py:133] step: 127600, training_loss: 2.79384e-02
I0209 01:26:15.404135 22542570456896 run_lib.py:146] step: 127600, eval_loss: 2.96317e-02
I0209 01:26:32.860679 22542570456896 run_lib.py:133] step: 127650, training_loss: 2.94398e-02
I0209 01:26:50.305997 22542570456896 run_lib.py:133] step: 127700, training_loss: 2.63059e-02
I0209 01:26:50.457548 22542570456896 run_lib.py:146] step: 127700, eval_loss: 2.75890e-02
I0209 01:27:08.021500 22542570456896 run_lib.py:133] step: 127750, training_loss: 2.73515e-02
I0209 01:27:25.444290 22542570456896 run_lib.py:133] step: 127800, training_loss: 2.75686e-02
I0209 01:27:25.599992 22542570456896 run_lib.py:146] step: 127800, eval_loss: 2.09300e-02
I0209 01:27:43.180111 22542570456896 run_lib.py:133] step: 127850, training_loss: 3.25474e-02
I0209 01:28:00.653116 22542570456896 run_lib.py:133] step: 127900, training_loss: 2.49755e-02
I0209 01:28:00.825338 22542570456896 run_lib.py:146] step: 127900, eval_loss: 2.79797e-02
I0209 01:28:18.402853 22542570456896 run_lib.py:133] step: 127950, training_loss: 3.62185e-02
I0209 01:28:35.807366 22542570456896 run_lib.py:133] step: 128000, training_loss: 3.03881e-02
I0209 01:28:35.962526 22542570456896 run_lib.py:146] step: 128000, eval_loss: 3.59441e-02
I0209 01:28:53.516184 22542570456896 run_lib.py:133] step: 128050, training_loss: 2.98256e-02
I0209 01:29:10.927665 22542570456896 run_lib.py:133] step: 128100, training_loss: 2.97650e-02
I0209 01:29:11.083367 22542570456896 run_lib.py:146] step: 128100, eval_loss: 3.50392e-02
I0209 01:29:28.493436 22542570456896 run_lib.py:133] step: 128150, training_loss: 2.74873e-02
I0209 01:29:46.072358 22542570456896 run_lib.py:133] step: 128200, training_loss: 2.44936e-02
I0209 01:29:46.223203 22542570456896 run_lib.py:146] step: 128200, eval_loss: 2.78528e-02
I0209 01:30:03.654760 22542570456896 run_lib.py:133] step: 128250, training_loss: 3.05724e-02
I0209 01:30:21.111093 22542570456896 run_lib.py:133] step: 128300, training_loss: 2.36803e-02
I0209 01:30:21.267039 22542570456896 run_lib.py:146] step: 128300, eval_loss: 2.78916e-02
I0209 01:30:38.877374 22542570456896 run_lib.py:133] step: 128350, training_loss: 2.98654e-02
I0209 01:30:56.303821 22542570456896 run_lib.py:133] step: 128400, training_loss: 2.82585e-02
I0209 01:30:56.462318 22542570456896 run_lib.py:146] step: 128400, eval_loss: 2.94771e-02
I0209 01:31:14.024206 22542570456896 run_lib.py:133] step: 128450, training_loss: 2.86089e-02
I0209 01:31:31.477105 22542570456896 run_lib.py:133] step: 128500, training_loss: 2.45453e-02
I0209 01:31:31.637575 22542570456896 run_lib.py:146] step: 128500, eval_loss: 2.59409e-02
I0209 01:31:49.069321 22542570456896 run_lib.py:133] step: 128550, training_loss: 3.02238e-02
I0209 01:32:06.651416 22542570456896 run_lib.py:133] step: 128600, training_loss: 3.45410e-02
I0209 01:32:06.808311 22542570456896 run_lib.py:146] step: 128600, eval_loss: 3.11244e-02
I0209 01:32:24.211142 22542570456896 run_lib.py:133] step: 128650, training_loss: 2.68277e-02
I0209 01:32:41.631905 22542570456896 run_lib.py:133] step: 128700, training_loss: 3.34342e-02
I0209 01:32:41.789514 22542570456896 run_lib.py:146] step: 128700, eval_loss: 2.60897e-02
I0209 01:32:59.258689 22542570456896 run_lib.py:133] step: 128750, training_loss: 3.24422e-02
I0209 01:33:16.839050 22542570456896 run_lib.py:133] step: 128800, training_loss: 2.87057e-02
I0209 01:33:16.997378 22542570456896 run_lib.py:146] step: 128800, eval_loss: 2.79098e-02
I0209 01:33:34.387598 22542570456896 run_lib.py:133] step: 128850, training_loss: 3.50536e-02
I0209 01:33:51.875720 22542570456896 run_lib.py:133] step: 128900, training_loss: 3.29339e-02
I0209 01:33:52.033430 22542570456896 run_lib.py:146] step: 128900, eval_loss: 3.22628e-02
I0209 01:34:09.447217 22542570456896 run_lib.py:133] step: 128950, training_loss: 3.02187e-02
I0209 01:34:26.937470 22542570456896 run_lib.py:133] step: 129000, training_loss: 3.13077e-02
I0209 01:34:27.094129 22542570456896 run_lib.py:146] step: 129000, eval_loss: 2.59253e-02
I0209 01:34:44.752720 22542570456896 run_lib.py:133] step: 129050, training_loss: 2.81475e-02
I0209 01:35:02.285234 22542570456896 run_lib.py:133] step: 129100, training_loss: 2.88848e-02
I0209 01:35:02.439238 22542570456896 run_lib.py:146] step: 129100, eval_loss: 2.63804e-02
I0209 01:35:19.853995 22542570456896 run_lib.py:133] step: 129150, training_loss: 2.59887e-02
I0209 01:35:37.314651 22542570456896 run_lib.py:133] step: 129200, training_loss: 2.70065e-02
I0209 01:35:37.472412 22542570456896 run_lib.py:146] step: 129200, eval_loss: 2.39683e-02
I0209 01:35:55.083423 22542570456896 run_lib.py:133] step: 129250, training_loss: 3.40654e-02
I0209 01:36:12.530406 22542570456896 run_lib.py:133] step: 129300, training_loss: 2.61330e-02
I0209 01:36:12.687333 22542570456896 run_lib.py:146] step: 129300, eval_loss: 3.54502e-02
I0209 01:36:30.298112 22542570456896 run_lib.py:133] step: 129350, training_loss: 2.88618e-02
I0209 01:36:47.696301 22542570456896 run_lib.py:133] step: 129400, training_loss: 2.51298e-02
I0209 01:36:47.852474 22542570456896 run_lib.py:146] step: 129400, eval_loss: 2.41771e-02
I0209 01:37:05.451693 22542570456896 run_lib.py:133] step: 129450, training_loss: 2.27014e-02
I0209 01:37:22.855729 22542570456896 run_lib.py:133] step: 129500, training_loss: 3.49550e-02
I0209 01:37:23.020521 22542570456896 run_lib.py:146] step: 129500, eval_loss: 2.80229e-02
I0209 01:37:40.395886 22542570456896 run_lib.py:133] step: 129550, training_loss: 3.31321e-02
I0209 01:37:57.949463 22542570456896 run_lib.py:133] step: 129600, training_loss: 2.79256e-02
I0209 01:37:58.103197 22542570456896 run_lib.py:146] step: 129600, eval_loss: 2.34607e-02
I0209 01:38:15.489903 22542570456896 run_lib.py:133] step: 129650, training_loss: 2.97939e-02
I0209 01:38:33.034066 22542570456896 run_lib.py:133] step: 129700, training_loss: 2.73901e-02
I0209 01:38:33.189265 22542570456896 run_lib.py:146] step: 129700, eval_loss: 2.77538e-02
I0209 01:38:50.564908 22542570456896 run_lib.py:133] step: 129750, training_loss: 3.36738e-02
I0209 01:39:07.988301 22542570456896 run_lib.py:133] step: 129800, training_loss: 2.57183e-02
I0209 01:39:08.149700 22542570456896 run_lib.py:146] step: 129800, eval_loss: 3.11605e-02
I0209 01:39:25.823315 22542570456896 run_lib.py:133] step: 129850, training_loss: 2.71400e-02
I0209 01:39:43.274824 22542570456896 run_lib.py:133] step: 129900, training_loss: 2.64575e-02
I0209 01:39:43.429760 22542570456896 run_lib.py:146] step: 129900, eval_loss: 2.46557e-02
I0209 01:40:00.857604 22542570456896 run_lib.py:133] step: 129950, training_loss: 2.76981e-02
I0209 01:40:18.482183 22542570456896 run_lib.py:133] step: 130000, training_loss: 2.65103e-02
I0209 01:40:19.245350 22542570456896 run_lib.py:146] step: 130000, eval_loss: 2.62444e-02
I0209 01:40:39.305596 22542570456896 run_lib.py:133] step: 130050, training_loss: 3.57306e-02
I0209 01:40:56.774811 22542570456896 run_lib.py:133] step: 130100, training_loss: 3.06889e-02
I0209 01:40:56.931636 22542570456896 run_lib.py:146] step: 130100, eval_loss: 3.71067e-02
I0209 01:41:14.547245 22542570456896 run_lib.py:133] step: 130150, training_loss: 2.54709e-02
I0209 01:41:31.957506 22542570456896 run_lib.py:133] step: 130200, training_loss: 2.89463e-02
I0209 01:41:32.109385 22542570456896 run_lib.py:146] step: 130200, eval_loss: 3.12196e-02
I0209 01:41:49.518195 22542570456896 run_lib.py:133] step: 130250, training_loss: 2.40640e-02
I0209 01:42:06.936276 22542570456896 run_lib.py:133] step: 130300, training_loss: 2.81879e-02
I0209 01:42:07.099783 22542570456896 run_lib.py:146] step: 130300, eval_loss: 2.66795e-02
I0209 01:42:24.638309 22542570456896 run_lib.py:133] step: 130350, training_loss: 2.65072e-02
I0209 01:42:42.099786 22542570456896 run_lib.py:133] step: 130400, training_loss: 1.99854e-02
I0209 01:42:42.258254 22542570456896 run_lib.py:146] step: 130400, eval_loss: 2.87446e-02
I0209 01:42:59.789336 22542570456896 run_lib.py:133] step: 130450, training_loss: 3.01021e-02
I0209 01:43:17.223888 22542570456896 run_lib.py:133] step: 130500, training_loss: 2.85361e-02
I0209 01:43:17.381176 22542570456896 run_lib.py:146] step: 130500, eval_loss: 3.04710e-02
I0209 01:43:34.790392 22542570456896 run_lib.py:133] step: 130550, training_loss: 2.77055e-02
I0209 01:43:52.168929 22542570456896 run_lib.py:133] step: 130600, training_loss: 2.69290e-02
I0209 01:43:52.322407 22542570456896 run_lib.py:146] step: 130600, eval_loss: 3.41644e-02
I0209 01:44:09.880222 22542570456896 run_lib.py:133] step: 130650, training_loss: 2.44101e-02
I0209 01:44:27.427371 22542570456896 run_lib.py:133] step: 130700, training_loss: 2.20948e-02
I0209 01:44:27.585481 22542570456896 run_lib.py:146] step: 130700, eval_loss: 2.77873e-02
I0209 01:44:45.009840 22542570456896 run_lib.py:133] step: 130750, training_loss: 2.88954e-02
I0209 01:45:02.461854 22542570456896 run_lib.py:133] step: 130800, training_loss: 2.94763e-02
I0209 01:45:02.621591 22542570456896 run_lib.py:146] step: 130800, eval_loss: 3.08480e-02
I0209 01:45:20.168278 22542570456896 run_lib.py:133] step: 130850, training_loss: 3.45888e-02
I0209 01:45:37.604070 22542570456896 run_lib.py:133] step: 130900, training_loss: 3.42791e-02
I0209 01:45:37.768328 22542570456896 run_lib.py:146] step: 130900, eval_loss: 3.36618e-02
I0209 01:45:55.325016 22542570456896 run_lib.py:133] step: 130950, training_loss: 3.27535e-02
I0209 01:46:12.761974 22542570456896 run_lib.py:133] step: 131000, training_loss: 2.27556e-02
I0209 01:46:12.918885 22542570456896 run_lib.py:146] step: 131000, eval_loss: 3.64752e-02
I0209 01:46:30.537662 22542570456896 run_lib.py:133] step: 131050, training_loss: 2.83218e-02
I0209 01:46:47.969399 22542570456896 run_lib.py:133] step: 131100, training_loss: 3.15722e-02
I0209 01:46:48.120466 22542570456896 run_lib.py:146] step: 131100, eval_loss: 2.87754e-02
I0209 01:47:05.715243 22542570456896 run_lib.py:133] step: 131150, training_loss: 2.89468e-02
I0209 01:47:23.127219 22542570456896 run_lib.py:133] step: 131200, training_loss: 4.00190e-02
I0209 01:47:23.294513 22542570456896 run_lib.py:146] step: 131200, eval_loss: 3.11302e-02
I0209 01:47:40.782673 22542570456896 run_lib.py:133] step: 131250, training_loss: 2.79320e-02
I0209 01:47:58.422681 22542570456896 run_lib.py:133] step: 131300, training_loss: 2.51652e-02
I0209 01:47:58.581288 22542570456896 run_lib.py:146] step: 131300, eval_loss: 2.42311e-02
I0209 01:48:15.976702 22542570456896 run_lib.py:133] step: 131350, training_loss: 3.13054e-02
I0209 01:48:33.412720 22542570456896 run_lib.py:133] step: 131400, training_loss: 2.71791e-02
I0209 01:48:33.567483 22542570456896 run_lib.py:146] step: 131400, eval_loss: 3.13962e-02
I0209 01:48:51.144053 22542570456896 run_lib.py:133] step: 131450, training_loss: 2.98712e-02
I0209 01:49:08.677227 22542570456896 run_lib.py:133] step: 131500, training_loss: 2.52718e-02
I0209 01:49:08.839567 22542570456896 run_lib.py:146] step: 131500, eval_loss: 2.45042e-02
I0209 01:49:26.307405 22542570456896 run_lib.py:133] step: 131550, training_loss: 2.74883e-02
I0209 01:49:43.769086 22542570456896 run_lib.py:133] step: 131600, training_loss: 2.92552e-02
I0209 01:49:43.920633 22542570456896 run_lib.py:146] step: 131600, eval_loss: 2.90226e-02
I0209 01:50:01.314438 22542570456896 run_lib.py:133] step: 131650, training_loss: 2.73753e-02
I0209 01:50:18.953479 22542570456896 run_lib.py:133] step: 131700, training_loss: 3.51143e-02
I0209 01:50:19.107318 22542570456896 run_lib.py:146] step: 131700, eval_loss: 2.39180e-02
I0209 01:50:36.485604 22542570456896 run_lib.py:133] step: 131750, training_loss: 3.66754e-02
I0209 01:50:53.981929 22542570456896 run_lib.py:133] step: 131800, training_loss: 3.18995e-02
I0209 01:50:54.159486 22542570456896 run_lib.py:146] step: 131800, eval_loss: 2.33738e-02
I0209 01:51:11.560547 22542570456896 run_lib.py:133] step: 131850, training_loss: 2.96103e-02
I0209 01:51:29.166085 22542570456896 run_lib.py:133] step: 131900, training_loss: 2.94501e-02
I0209 01:51:29.322388 22542570456896 run_lib.py:146] step: 131900, eval_loss: 2.92091e-02
I0209 01:51:46.756879 22542570456896 run_lib.py:133] step: 131950, training_loss: 2.79387e-02
I0209 01:52:04.251144 22542570456896 run_lib.py:133] step: 132000, training_loss: 2.40528e-02
I0209 01:52:04.405340 22542570456896 run_lib.py:146] step: 132000, eval_loss: 2.81855e-02
I0209 01:52:21.811838 22542570456896 run_lib.py:133] step: 132050, training_loss: 3.22546e-02
I0209 01:52:39.245463 22542570456896 run_lib.py:133] step: 132100, training_loss: 2.80909e-02
I0209 01:52:39.400514 22542570456896 run_lib.py:146] step: 132100, eval_loss: 3.12926e-02
I0209 01:52:57.010178 22542570456896 run_lib.py:133] step: 132150, training_loss: 3.23359e-02
I0209 01:53:14.505786 22542570456896 run_lib.py:133] step: 132200, training_loss: 3.50734e-02
I0209 01:53:14.663634 22542570456896 run_lib.py:146] step: 132200, eval_loss: 2.72533e-02
I0209 01:53:32.045772 22542570456896 run_lib.py:133] step: 132250, training_loss: 2.72780e-02
I0209 01:53:49.438583 22542570456896 run_lib.py:133] step: 132300, training_loss: 3.23717e-02
I0209 01:53:49.603594 22542570456896 run_lib.py:146] step: 132300, eval_loss: 2.95900e-02
I0209 01:54:07.217191 22542570456896 run_lib.py:133] step: 132350, training_loss: 2.93570e-02
I0209 01:54:24.690915 22542570456896 run_lib.py:133] step: 132400, training_loss: 3.47556e-02
I0209 01:54:24.844956 22542570456896 run_lib.py:146] step: 132400, eval_loss: 2.44397e-02
I0209 01:54:42.437288 22542570456896 run_lib.py:133] step: 132450, training_loss: 2.89986e-02
I0209 01:54:59.825917 22542570456896 run_lib.py:133] step: 132500, training_loss: 2.99196e-02
I0209 01:54:59.983330 22542570456896 run_lib.py:146] step: 132500, eval_loss: 3.71404e-02
I0209 01:55:17.519463 22542570456896 run_lib.py:133] step: 132550, training_loss: 3.31903e-02
I0209 01:55:35.004439 22542570456896 run_lib.py:133] step: 132600, training_loss: 2.73159e-02
I0209 01:55:35.165611 22542570456896 run_lib.py:146] step: 132600, eval_loss: 2.47673e-02
I0209 01:55:52.650479 22542570456896 run_lib.py:133] step: 132650, training_loss: 3.78514e-02
I0209 01:56:10.302151 22542570456896 run_lib.py:133] step: 132700, training_loss: 3.11062e-02
I0209 01:56:10.463381 22542570456896 run_lib.py:146] step: 132700, eval_loss: 3.46540e-02
I0209 01:56:27.893242 22542570456896 run_lib.py:133] step: 132750, training_loss: 3.23330e-02
I0209 01:56:45.443191 22542570456896 run_lib.py:133] step: 132800, training_loss: 2.55108e-02
I0209 01:56:45.600299 22542570456896 run_lib.py:146] step: 132800, eval_loss: 2.60057e-02
I0209 01:57:03.071154 22542570456896 run_lib.py:133] step: 132850, training_loss: 3.00531e-02
I0209 01:57:20.536499 22542570456896 run_lib.py:133] step: 132900, training_loss: 2.81551e-02
I0209 01:57:20.692159 22542570456896 run_lib.py:146] step: 132900, eval_loss: 2.94221e-02
I0209 01:57:38.303534 22542570456896 run_lib.py:133] step: 132950, training_loss: 2.34585e-02
I0209 01:57:55.757264 22542570456896 run_lib.py:133] step: 133000, training_loss: 2.61056e-02
I0209 01:57:55.917115 22542570456896 run_lib.py:146] step: 133000, eval_loss: 2.55117e-02
I0209 01:58:13.300884 22542570456896 run_lib.py:133] step: 133050, training_loss: 2.98524e-02
I0209 01:58:30.912692 22542570456896 run_lib.py:133] step: 133100, training_loss: 2.46225e-02
I0209 01:58:31.067409 22542570456896 run_lib.py:146] step: 133100, eval_loss: 2.45219e-02
I0209 01:58:48.488972 22542570456896 run_lib.py:133] step: 133150, training_loss: 2.64420e-02
I0209 01:59:05.959155 22542570456896 run_lib.py:133] step: 133200, training_loss: 2.65813e-02
I0209 01:59:06.127343 22542570456896 run_lib.py:146] step: 133200, eval_loss: 2.83898e-02
I0209 01:59:23.668696 22542570456896 run_lib.py:133] step: 133250, training_loss: 2.71077e-02
I0209 01:59:41.090739 22542570456896 run_lib.py:133] step: 133300, training_loss: 3.24574e-02
I0209 01:59:41.246429 22542570456896 run_lib.py:146] step: 133300, eval_loss: 2.81108e-02
I0209 01:59:58.632669 22542570456896 run_lib.py:133] step: 133350, training_loss: 3.14690e-02
I0209 02:00:16.083731 22542570456896 run_lib.py:133] step: 133400, training_loss: 2.81616e-02
I0209 02:00:16.238422 22542570456896 run_lib.py:146] step: 133400, eval_loss: 2.78884e-02
I0209 02:00:33.776107 22542570456896 run_lib.py:133] step: 133450, training_loss: 3.22312e-02
I0209 02:00:51.314958 22542570456896 run_lib.py:133] step: 133500, training_loss: 2.11941e-02
I0209 02:00:51.472742 22542570456896 run_lib.py:146] step: 133500, eval_loss: 2.76070e-02
I0209 02:01:08.897327 22542570456896 run_lib.py:133] step: 133550, training_loss: 3.00696e-02
I0209 02:01:26.345631 22542570456896 run_lib.py:133] step: 133600, training_loss: 3.63966e-02
I0209 02:01:26.502406 22542570456896 run_lib.py:146] step: 133600, eval_loss: 2.24747e-02
I0209 02:01:44.068600 22542570456896 run_lib.py:133] step: 133650, training_loss: 3.44842e-02
I0209 02:02:01.470226 22542570456896 run_lib.py:133] step: 133700, training_loss: 2.55194e-02
I0209 02:02:01.635376 22542570456896 run_lib.py:146] step: 133700, eval_loss: 3.11773e-02
I0209 02:02:19.252368 22542570456896 run_lib.py:133] step: 133750, training_loss: 2.66721e-02
I0209 02:02:36.684821 22542570456896 run_lib.py:133] step: 133800, training_loss: 3.45977e-02
I0209 02:02:36.841078 22542570456896 run_lib.py:146] step: 133800, eval_loss: 2.21154e-02
I0209 02:02:54.421727 22542570456896 run_lib.py:133] step: 133850, training_loss: 2.88584e-02
I0209 02:03:11.841735 22542570456896 run_lib.py:133] step: 133900, training_loss: 2.97109e-02
I0209 02:03:12.004295 22542570456896 run_lib.py:146] step: 133900, eval_loss: 3.06350e-02
I0209 02:03:29.608398 22542570456896 run_lib.py:133] step: 133950, training_loss: 2.64815e-02
I0209 02:03:47.022835 22542570456896 run_lib.py:133] step: 134000, training_loss: 2.70657e-02
I0209 02:03:47.176617 22542570456896 run_lib.py:146] step: 134000, eval_loss: 2.39877e-02
I0209 02:04:04.630394 22542570456896 run_lib.py:133] step: 134050, training_loss: 2.73597e-02
I0209 02:04:22.237501 22542570456896 run_lib.py:133] step: 134100, training_loss: 2.90417e-02
I0209 02:04:22.396626 22542570456896 run_lib.py:146] step: 134100, eval_loss: 2.61243e-02
I0209 02:04:39.813829 22542570456896 run_lib.py:133] step: 134150, training_loss: 2.67753e-02
I0209 02:04:57.224767 22542570456896 run_lib.py:133] step: 134200, training_loss: 3.85662e-02
I0209 02:04:57.382937 22542570456896 run_lib.py:146] step: 134200, eval_loss: 2.96305e-02
I0209 02:05:14.970058 22542570456896 run_lib.py:133] step: 134250, training_loss: 2.91770e-02
I0209 02:05:32.426234 22542570456896 run_lib.py:133] step: 134300, training_loss: 3.39861e-02
I0209 02:05:32.589665 22542570456896 run_lib.py:146] step: 134300, eval_loss: 3.27269e-02
I0209 02:05:50.213660 22542570456896 run_lib.py:133] step: 134350, training_loss: 3.16204e-02
I0209 02:06:07.585631 22542570456896 run_lib.py:133] step: 134400, training_loss: 3.45716e-02
I0209 02:06:07.737053 22542570456896 run_lib.py:146] step: 134400, eval_loss: 3.14187e-02
I0209 02:06:25.115741 22542570456896 run_lib.py:133] step: 134450, training_loss: 3.34387e-02
I0209 02:06:42.713074 22542570456896 run_lib.py:133] step: 134500, training_loss: 2.54005e-02
I0209 02:06:42.867488 22542570456896 run_lib.py:146] step: 134500, eval_loss: 2.36392e-02
I0209 02:07:00.392286 22542570456896 run_lib.py:133] step: 134550, training_loss: 2.64489e-02
I0209 02:07:17.809637 22542570456896 run_lib.py:133] step: 134600, training_loss: 2.75206e-02
I0209 02:07:17.974168 22542570456896 run_lib.py:146] step: 134600, eval_loss: 2.45863e-02
I0209 02:07:35.357513 22542570456896 run_lib.py:133] step: 134650, training_loss: 2.85448e-02
I0209 02:07:52.900412 22542570456896 run_lib.py:133] step: 134700, training_loss: 3.44770e-02
I0209 02:07:53.056247 22542570456896 run_lib.py:146] step: 134700, eval_loss: 2.44385e-02
I0209 02:08:10.469363 22542570456896 run_lib.py:133] step: 134750, training_loss: 2.38685e-02
I0209 02:08:27.954540 22542570456896 run_lib.py:133] step: 134800, training_loss: 3.00966e-02
I0209 02:08:28.110775 22542570456896 run_lib.py:146] step: 134800, eval_loss: 3.19903e-02
I0209 02:08:45.556977 22542570456896 run_lib.py:133] step: 134850, training_loss: 3.68902e-02
I0209 02:09:02.985532 22542570456896 run_lib.py:133] step: 134900, training_loss: 2.94590e-02
I0209 02:09:03.137393 22542570456896 run_lib.py:146] step: 134900, eval_loss: 2.49538e-02
I0209 02:09:20.685352 22542570456896 run_lib.py:133] step: 134950, training_loss: 2.43373e-02
I0209 02:09:38.173012 22542570456896 run_lib.py:133] step: 135000, training_loss: 2.39055e-02
I0209 02:09:38.329301 22542570456896 run_lib.py:146] step: 135000, eval_loss: 3.57215e-02
I0209 02:09:55.768111 22542570456896 run_lib.py:133] step: 135050, training_loss: 2.93422e-02
I0209 02:10:13.247342 22542570456896 run_lib.py:133] step: 135100, training_loss: 2.93066e-02
I0209 02:10:13.406238 22542570456896 run_lib.py:146] step: 135100, eval_loss: 2.71742e-02
I0209 02:10:30.998649 22542570456896 run_lib.py:133] step: 135150, training_loss: 2.71963e-02
I0209 02:10:48.392074 22542570456896 run_lib.py:133] step: 135200, training_loss: 3.20968e-02
I0209 02:10:48.547190 22542570456896 run_lib.py:146] step: 135200, eval_loss: 2.80914e-02
I0209 02:11:06.113324 22542570456896 run_lib.py:133] step: 135250, training_loss: 3.54901e-02
I0209 02:11:23.474061 22542570456896 run_lib.py:133] step: 135300, training_loss: 2.67622e-02
I0209 02:11:23.628469 22542570456896 run_lib.py:146] step: 135300, eval_loss: 2.44377e-02
I0209 02:11:41.215474 22542570456896 run_lib.py:133] step: 135350, training_loss: 2.77371e-02
I0209 02:11:58.665916 22542570456896 run_lib.py:133] step: 135400, training_loss: 3.86045e-02
I0209 02:11:58.819520 22542570456896 run_lib.py:146] step: 135400, eval_loss: 2.63887e-02
I0209 02:12:16.256268 22542570456896 run_lib.py:133] step: 135450, training_loss: 3.03093e-02
I0209 02:12:33.906231 22542570456896 run_lib.py:133] step: 135500, training_loss: 2.46006e-02
I0209 02:12:34.062220 22542570456896 run_lib.py:146] step: 135500, eval_loss: 3.15942e-02
I0209 02:12:51.518496 22542570456896 run_lib.py:133] step: 135550, training_loss: 2.59946e-02
I0209 02:13:09.101537 22542570456896 run_lib.py:133] step: 135600, training_loss: 3.90885e-02
I0209 02:13:09.264660 22542570456896 run_lib.py:146] step: 135600, eval_loss: 2.85193e-02
I0209 02:13:26.682346 22542570456896 run_lib.py:133] step: 135650, training_loss: 3.54996e-02
I0209 02:13:44.179579 22542570456896 run_lib.py:133] step: 135700, training_loss: 3.65111e-02
I0209 02:13:44.344560 22542570456896 run_lib.py:146] step: 135700, eval_loss: 3.00905e-02
I0209 02:14:01.948599 22542570456896 run_lib.py:133] step: 135750, training_loss: 3.05871e-02
I0209 02:14:19.364971 22542570456896 run_lib.py:133] step: 135800, training_loss: 2.95665e-02
I0209 02:14:19.521485 22542570456896 run_lib.py:146] step: 135800, eval_loss: 2.09263e-02
I0209 02:14:36.922381 22542570456896 run_lib.py:133] step: 135850, training_loss: 2.43982e-02
I0209 02:14:54.488289 22542570456896 run_lib.py:133] step: 135900, training_loss: 3.29036e-02
I0209 02:14:54.640601 22542570456896 run_lib.py:146] step: 135900, eval_loss: 2.38976e-02
I0209 02:15:12.128040 22542570456896 run_lib.py:133] step: 135950, training_loss: 2.57104e-02
I0209 02:15:29.584572 22542570456896 run_lib.py:133] step: 136000, training_loss: 2.49589e-02
I0209 02:15:29.934272 22542570456896 run_lib.py:146] step: 136000, eval_loss: 2.87452e-02
I0209 02:15:47.333436 22542570456896 run_lib.py:133] step: 136050, training_loss: 3.10332e-02
I0209 02:16:04.757074 22542570456896 run_lib.py:133] step: 136100, training_loss: 2.67512e-02
I0209 02:16:04.917462 22542570456896 run_lib.py:146] step: 136100, eval_loss: 2.16184e-02
I0209 02:16:22.363119 22542570456896 run_lib.py:133] step: 136150, training_loss: 3.02402e-02
I0209 02:16:39.782234 22542570456896 run_lib.py:133] step: 136200, training_loss: 2.98775e-02
I0209 02:16:39.954062 22542570456896 run_lib.py:146] step: 136200, eval_loss: 3.02217e-02
I0209 02:16:57.565687 22542570456896 run_lib.py:133] step: 136250, training_loss: 2.12835e-02
I0209 02:17:15.119852 22542570456896 run_lib.py:133] step: 136300, training_loss: 3.55583e-02
I0209 02:17:15.272118 22542570456896 run_lib.py:146] step: 136300, eval_loss: 2.79936e-02
I0209 02:17:32.692728 22542570456896 run_lib.py:133] step: 136350, training_loss: 2.47359e-02
I0209 02:17:50.101286 22542570456896 run_lib.py:133] step: 136400, training_loss: 2.34702e-02
I0209 02:17:50.265403 22542570456896 run_lib.py:146] step: 136400, eval_loss: 3.51489e-02
I0209 02:18:07.793023 22542570456896 run_lib.py:133] step: 136450, training_loss: 2.74073e-02
I0209 02:18:25.270893 22542570456896 run_lib.py:133] step: 136500, training_loss: 2.82886e-02
I0209 02:18:25.447290 22542570456896 run_lib.py:146] step: 136500, eval_loss: 2.70420e-02
I0209 02:18:42.901758 22542570456896 run_lib.py:133] step: 136550, training_loss: 2.90678e-02
I0209 02:19:00.402083 22542570456896 run_lib.py:133] step: 136600, training_loss: 3.02494e-02
I0209 02:19:00.557602 22542570456896 run_lib.py:146] step: 136600, eval_loss: 3.13139e-02
I0209 02:19:18.143791 22542570456896 run_lib.py:133] step: 136650, training_loss: 3.04006e-02
I0209 02:19:35.564935 22542570456896 run_lib.py:133] step: 136700, training_loss: 2.92810e-02
I0209 02:19:35.720347 22542570456896 run_lib.py:146] step: 136700, eval_loss: 2.29445e-02
I0209 02:19:53.256636 22542570456896 run_lib.py:133] step: 136750, training_loss: 3.75229e-02
I0209 02:20:10.731384 22542570456896 run_lib.py:133] step: 136800, training_loss: 2.87830e-02
I0209 02:20:10.884668 22542570456896 run_lib.py:146] step: 136800, eval_loss: 2.95217e-02
I0209 02:20:28.542867 22542570456896 run_lib.py:133] step: 136850, training_loss: 2.55353e-02
I0209 02:20:45.954057 22542570456896 run_lib.py:133] step: 136900, training_loss: 2.42737e-02
I0209 02:20:46.109462 22542570456896 run_lib.py:146] step: 136900, eval_loss: 2.93143e-02
I0209 02:21:03.523261 22542570456896 run_lib.py:133] step: 136950, training_loss: 2.54511e-02
I0209 02:21:21.113352 22542570456896 run_lib.py:133] step: 137000, training_loss: 3.09674e-02
I0209 02:21:21.271557 22542570456896 run_lib.py:146] step: 137000, eval_loss: 2.80548e-02
I0209 02:21:38.687032 22542570456896 run_lib.py:133] step: 137050, training_loss: 2.30876e-02
I0209 02:21:56.283330 22542570456896 run_lib.py:133] step: 137100, training_loss: 1.99031e-02
I0209 02:21:56.437540 22542570456896 run_lib.py:146] step: 137100, eval_loss: 2.52254e-02
I0209 02:22:13.816948 22542570456896 run_lib.py:133] step: 137150, training_loss: 3.01059e-02
I0209 02:22:31.240345 22542570456896 run_lib.py:133] step: 137200, training_loss: 3.17623e-02
I0209 02:22:31.396260 22542570456896 run_lib.py:146] step: 137200, eval_loss: 3.05874e-02
I0209 02:22:48.999924 22542570456896 run_lib.py:133] step: 137250, training_loss: 2.09289e-02
I0209 02:23:06.431187 22542570456896 run_lib.py:133] step: 137300, training_loss: 2.84231e-02
I0209 02:23:06.583348 22542570456896 run_lib.py:146] step: 137300, eval_loss: 2.71052e-02
I0209 02:23:24.048495 22542570456896 run_lib.py:133] step: 137350, training_loss: 2.62213e-02
I0209 02:23:41.475256 22542570456896 run_lib.py:133] step: 137400, training_loss: 2.50571e-02
I0209 02:23:41.631262 22542570456896 run_lib.py:146] step: 137400, eval_loss: 3.15287e-02
I0209 02:23:59.271201 22542570456896 run_lib.py:133] step: 137450, training_loss: 3.21626e-02
I0209 02:24:16.666058 22542570456896 run_lib.py:133] step: 137500, training_loss: 2.59774e-02
I0209 02:24:16.825559 22542570456896 run_lib.py:146] step: 137500, eval_loss: 2.24808e-02
I0209 02:24:34.289547 22542570456896 run_lib.py:133] step: 137550, training_loss: 3.10835e-02
I0209 02:24:51.685686 22542570456896 run_lib.py:133] step: 137600, training_loss: 2.67643e-02
I0209 02:24:51.852148 22542570456896 run_lib.py:146] step: 137600, eval_loss: 2.97685e-02
I0209 02:25:09.290225 22542570456896 run_lib.py:133] step: 137650, training_loss: 3.52944e-02
I0209 02:25:26.768147 22542570456896 run_lib.py:133] step: 137700, training_loss: 2.72615e-02
I0209 02:25:26.923055 22542570456896 run_lib.py:146] step: 137700, eval_loss: 2.59141e-02
I0209 02:25:44.503911 22542570456896 run_lib.py:133] step: 137750, training_loss: 2.88613e-02
I0209 02:26:01.978975 22542570456896 run_lib.py:133] step: 137800, training_loss: 2.33682e-02
I0209 02:26:02.131355 22542570456896 run_lib.py:146] step: 137800, eval_loss: 2.54423e-02
I0209 02:26:19.526908 22542570456896 run_lib.py:133] step: 137850, training_loss: 3.50699e-02
I0209 02:26:36.943782 22542570456896 run_lib.py:133] step: 137900, training_loss: 2.32044e-02
I0209 02:26:37.118371 22542570456896 run_lib.py:146] step: 137900, eval_loss: 2.55873e-02
I0209 02:26:54.697581 22542570456896 run_lib.py:133] step: 137950, training_loss: 3.50525e-02
I0209 02:27:12.126774 22542570456896 run_lib.py:133] step: 138000, training_loss: 2.41957e-02
I0209 02:27:12.282509 22542570456896 run_lib.py:146] step: 138000, eval_loss: 2.62888e-02
I0209 02:27:29.883888 22542570456896 run_lib.py:133] step: 138050, training_loss: 2.82825e-02
I0209 02:27:47.297264 22542570456896 run_lib.py:133] step: 138100, training_loss: 2.89799e-02
I0209 02:27:47.454069 22542570456896 run_lib.py:146] step: 138100, eval_loss: 2.19842e-02
I0209 02:28:04.992590 22542570456896 run_lib.py:133] step: 138150, training_loss: 3.35652e-02
I0209 02:28:22.389839 22542570456896 run_lib.py:133] step: 138200, training_loss: 3.03455e-02
I0209 02:28:22.551475 22542570456896 run_lib.py:146] step: 138200, eval_loss: 2.58918e-02
I0209 02:28:40.234616 22542570456896 run_lib.py:133] step: 138250, training_loss: 3.03230e-02
I0209 02:28:57.631543 22542570456896 run_lib.py:133] step: 138300, training_loss: 2.79144e-02
I0209 02:28:57.786301 22542570456896 run_lib.py:146] step: 138300, eval_loss: 2.59258e-02
I0209 02:29:15.167981 22542570456896 run_lib.py:133] step: 138350, training_loss: 2.49225e-02
I0209 02:29:32.755556 22542570456896 run_lib.py:133] step: 138400, training_loss: 3.06571e-02
I0209 02:29:32.913417 22542570456896 run_lib.py:146] step: 138400, eval_loss: 2.92854e-02
I0209 02:29:50.362523 22542570456896 run_lib.py:133] step: 138450, training_loss: 3.10271e-02
I0209 02:30:07.828733 22542570456896 run_lib.py:133] step: 138500, training_loss: 3.47586e-02
I0209 02:30:07.985523 22542570456896 run_lib.py:146] step: 138500, eval_loss: 2.79099e-02
I0209 02:30:25.533097 22542570456896 run_lib.py:133] step: 138550, training_loss: 3.26544e-02
I0209 02:30:43.136834 22542570456896 run_lib.py:133] step: 138600, training_loss: 3.56422e-02
I0209 02:30:43.299773 22542570456896 run_lib.py:146] step: 138600, eval_loss: 2.79100e-02
I0209 02:31:00.730546 22542570456896 run_lib.py:133] step: 138650, training_loss: 2.26686e-02
I0209 02:31:18.142948 22542570456896 run_lib.py:133] step: 138700, training_loss: 2.53163e-02
I0209 02:31:18.300185 22542570456896 run_lib.py:146] step: 138700, eval_loss: 2.80843e-02
I0209 02:31:35.701704 22542570456896 run_lib.py:133] step: 138750, training_loss: 2.67808e-02
I0209 02:31:53.319345 22542570456896 run_lib.py:133] step: 138800, training_loss: 2.95399e-02
I0209 02:31:53.490633 22542570456896 run_lib.py:146] step: 138800, eval_loss: 2.22517e-02
I0209 02:32:10.919571 22542570456896 run_lib.py:133] step: 138850, training_loss: 2.85972e-02
I0209 02:32:28.350803 22542570456896 run_lib.py:133] step: 138900, training_loss: 3.87759e-02
I0209 02:32:28.508574 22542570456896 run_lib.py:146] step: 138900, eval_loss: 3.09949e-02
I0209 02:32:45.912322 22542570456896 run_lib.py:133] step: 138950, training_loss: 3.06301e-02
I0209 02:33:03.510678 22542570456896 run_lib.py:133] step: 139000, training_loss: 3.51059e-02
I0209 02:33:03.666435 22542570456896 run_lib.py:146] step: 139000, eval_loss: 2.65173e-02
I0209 02:33:21.082200 22542570456896 run_lib.py:133] step: 139050, training_loss: 3.20720e-02
I0209 02:33:38.604249 22542570456896 run_lib.py:133] step: 139100, training_loss: 2.93433e-02
I0209 02:33:38.760573 22542570456896 run_lib.py:146] step: 139100, eval_loss: 2.47846e-02
I0209 02:33:56.215937 22542570456896 run_lib.py:133] step: 139150, training_loss: 3.13914e-02
I0209 02:34:13.647342 22542570456896 run_lib.py:133] step: 139200, training_loss: 2.18318e-02
I0209 02:34:13.799355 22542570456896 run_lib.py:146] step: 139200, eval_loss: 2.56011e-02
I0209 02:34:31.377088 22542570456896 run_lib.py:133] step: 139250, training_loss: 3.11044e-02
I0209 02:34:48.838567 22542570456896 run_lib.py:133] step: 139300, training_loss: 3.48235e-02
I0209 02:34:49.005358 22542570456896 run_lib.py:146] step: 139300, eval_loss: 2.97948e-02
I0209 02:35:06.449900 22542570456896 run_lib.py:133] step: 139350, training_loss: 3.16365e-02
I0209 02:35:23.915492 22542570456896 run_lib.py:133] step: 139400, training_loss: 2.58473e-02
I0209 02:35:24.072416 22542570456896 run_lib.py:146] step: 139400, eval_loss: 3.06756e-02
I0209 02:35:41.656674 22542570456896 run_lib.py:133] step: 139450, training_loss: 2.31154e-02
I0209 02:35:59.061329 22542570456896 run_lib.py:133] step: 139500, training_loss: 3.17101e-02
I0209 02:35:59.216473 22542570456896 run_lib.py:146] step: 139500, eval_loss: 3.43160e-02
I0209 02:36:16.783793 22542570456896 run_lib.py:133] step: 139550, training_loss: 2.61877e-02
I0209 02:36:34.228850 22542570456896 run_lib.py:133] step: 139600, training_loss: 2.45349e-02
I0209 02:36:34.383497 22542570456896 run_lib.py:146] step: 139600, eval_loss: 3.39060e-02
I0209 02:36:52.061136 22542570456896 run_lib.py:133] step: 139650, training_loss: 2.91910e-02
I0209 02:37:09.426105 22542570456896 run_lib.py:133] step: 139700, training_loss: 2.08437e-02
I0209 02:37:09.576210 22542570456896 run_lib.py:146] step: 139700, eval_loss: 2.75530e-02
I0209 02:37:26.950349 22542570456896 run_lib.py:133] step: 139750, training_loss: 2.52800e-02
I0209 02:37:44.517051 22542570456896 run_lib.py:133] step: 139800, training_loss: 2.46723e-02
I0209 02:37:44.682523 22542570456896 run_lib.py:146] step: 139800, eval_loss: 3.33647e-02
I0209 02:38:02.103835 22542570456896 run_lib.py:133] step: 139850, training_loss: 2.70275e-02
I0209 02:38:19.692119 22542570456896 run_lib.py:133] step: 139900, training_loss: 2.70871e-02
I0209 02:38:19.846529 22542570456896 run_lib.py:146] step: 139900, eval_loss: 2.70647e-02
I0209 02:38:37.299805 22542570456896 run_lib.py:133] step: 139950, training_loss: 3.11346e-02
I0209 02:38:54.748722 22542570456896 run_lib.py:133] step: 140000, training_loss: 3.69442e-02
I0209 02:38:55.469915 22542570456896 run_lib.py:146] step: 140000, eval_loss: 2.47737e-02
I0209 02:39:15.510831 22542570456896 run_lib.py:133] step: 140050, training_loss: 2.53991e-02
I0209 02:39:33.110941 22542570456896 run_lib.py:133] step: 140100, training_loss: 3.05938e-02
I0209 02:39:33.262455 22542570456896 run_lib.py:146] step: 140100, eval_loss: 2.81716e-02
I0209 02:39:50.703119 22542570456896 run_lib.py:133] step: 140150, training_loss: 2.95564e-02
I0209 02:40:08.331543 22542570456896 run_lib.py:133] step: 140200, training_loss: 2.51361e-02
I0209 02:40:08.484478 22542570456896 run_lib.py:146] step: 140200, eval_loss: 2.63388e-02
I0209 02:40:25.951616 22542570456896 run_lib.py:133] step: 140250, training_loss: 2.23369e-02
I0209 02:40:43.422577 22542570456896 run_lib.py:133] step: 140300, training_loss: 3.08499e-02
I0209 02:40:43.576835 22542570456896 run_lib.py:146] step: 140300, eval_loss: 3.37656e-02
I0209 02:41:01.121630 22542570456896 run_lib.py:133] step: 140350, training_loss: 3.01890e-02
I0209 02:41:18.602568 22542570456896 run_lib.py:133] step: 140400, training_loss: 2.74338e-02
I0209 02:41:18.779476 22542570456896 run_lib.py:146] step: 140400, eval_loss: 2.93406e-02
I0209 02:41:36.366146 22542570456896 run_lib.py:133] step: 140450, training_loss: 2.29329e-02
I0209 02:41:53.836445 22542570456896 run_lib.py:133] step: 140500, training_loss: 2.85047e-02
I0209 02:41:53.992529 22542570456896 run_lib.py:146] step: 140500, eval_loss: 2.82632e-02
I0209 02:42:11.437027 22542570456896 run_lib.py:133] step: 140550, training_loss: 2.78080e-02
I0209 02:42:29.038600 22542570456896 run_lib.py:133] step: 140600, training_loss: 2.46916e-02
I0209 02:42:29.192674 22542570456896 run_lib.py:146] step: 140600, eval_loss: 2.31733e-02
I0209 02:42:46.598488 22542570456896 run_lib.py:133] step: 140650, training_loss: 3.28029e-02
I0209 02:43:04.055151 22542570456896 run_lib.py:133] step: 140700, training_loss: 3.13344e-02
I0209 02:43:04.210579 22542570456896 run_lib.py:146] step: 140700, eval_loss: 2.56020e-02
I0209 02:43:21.628218 22542570456896 run_lib.py:133] step: 140750, training_loss: 3.49958e-02
I0209 02:43:39.248693 22542570456896 run_lib.py:133] step: 140800, training_loss: 2.53774e-02
I0209 02:43:39.407124 22542570456896 run_lib.py:146] step: 140800, eval_loss: 2.87215e-02
I0209 02:43:56.778472 22542570456896 run_lib.py:133] step: 140850, training_loss: 3.25229e-02
I0209 02:44:14.226518 22542570456896 run_lib.py:133] step: 140900, training_loss: 3.14082e-02
I0209 02:44:14.384340 22542570456896 run_lib.py:146] step: 140900, eval_loss: 2.71650e-02
I0209 02:44:31.830674 22542570456896 run_lib.py:133] step: 140950, training_loss: 2.63670e-02
I0209 02:44:49.278525 22542570456896 run_lib.py:133] step: 141000, training_loss: 2.59706e-02
I0209 02:44:49.432170 22542570456896 run_lib.py:146] step: 141000, eval_loss: 2.82731e-02
I0209 02:45:07.048137 22542570456896 run_lib.py:133] step: 141050, training_loss: 3.36284e-02
I0209 02:45:24.489381 22542570456896 run_lib.py:133] step: 141100, training_loss: 3.19659e-02
I0209 02:45:24.644003 22542570456896 run_lib.py:146] step: 141100, eval_loss: 2.50112e-02
I0209 02:45:42.050837 22542570456896 run_lib.py:133] step: 141150, training_loss: 2.04923e-02
I0209 02:45:59.488141 22542570456896 run_lib.py:133] step: 141200, training_loss: 2.32125e-02
I0209 02:45:59.651548 22542570456896 run_lib.py:146] step: 141200, eval_loss: 2.70327e-02
I0209 02:46:17.317475 22542570456896 run_lib.py:133] step: 141250, training_loss: 2.96750e-02
I0209 02:46:34.805118 22542570456896 run_lib.py:133] step: 141300, training_loss: 3.28603e-02
I0209 02:46:34.962223 22542570456896 run_lib.py:146] step: 141300, eval_loss: 2.75980e-02
I0209 02:46:52.479858 22542570456896 run_lib.py:133] step: 141350, training_loss: 3.04225e-02
I0209 02:47:09.821713 22542570456896 run_lib.py:133] step: 141400, training_loss: 2.49991e-02
I0209 02:47:09.979232 22542570456896 run_lib.py:146] step: 141400, eval_loss: 3.01042e-02
I0209 02:47:27.466279 22542570456896 run_lib.py:133] step: 141450, training_loss: 2.80564e-02
I0209 02:47:44.933257 22542570456896 run_lib.py:133] step: 141500, training_loss: 2.53743e-02
I0209 02:47:45.089951 22542570456896 run_lib.py:146] step: 141500, eval_loss: 3.41565e-02
I0209 02:48:02.556156 22542570456896 run_lib.py:133] step: 141550, training_loss: 2.71881e-02
I0209 02:48:20.163398 22542570456896 run_lib.py:133] step: 141600, training_loss: 2.59739e-02
I0209 02:48:20.316089 22542570456896 run_lib.py:146] step: 141600, eval_loss: 3.66910e-02
I0209 02:48:37.727980 22542570456896 run_lib.py:133] step: 141650, training_loss: 2.84017e-02
I0209 02:48:55.316079 22542570456896 run_lib.py:133] step: 141700, training_loss: 2.84252e-02
I0209 02:48:55.474642 22542570456896 run_lib.py:146] step: 141700, eval_loss: 2.72265e-02
I0209 02:49:12.916828 22542570456896 run_lib.py:133] step: 141750, training_loss: 3.07997e-02
I0209 02:49:30.404021 22542570456896 run_lib.py:133] step: 141800, training_loss: 2.87009e-02
I0209 02:49:30.563444 22542570456896 run_lib.py:146] step: 141800, eval_loss: 2.66094e-02
I0209 02:49:48.140265 22542570456896 run_lib.py:133] step: 141850, training_loss: 3.16369e-02
I0209 02:50:05.546911 22542570456896 run_lib.py:133] step: 141900, training_loss: 3.17847e-02
I0209 02:50:05.703341 22542570456896 run_lib.py:146] step: 141900, eval_loss: 3.21387e-02
I0209 02:50:23.131443 22542570456896 run_lib.py:133] step: 141950, training_loss: 2.91377e-02
I0209 02:50:40.713978 22542570456896 run_lib.py:133] step: 142000, training_loss: 3.19846e-02
I0209 02:50:40.877322 22542570456896 run_lib.py:146] step: 142000, eval_loss: 3.08857e-02
I0209 02:50:58.342414 22542570456896 run_lib.py:133] step: 142050, training_loss: 3.12179e-02
I0209 02:51:15.806591 22542570456896 run_lib.py:133] step: 142100, training_loss: 2.92245e-02
I0209 02:51:15.959639 22542570456896 run_lib.py:146] step: 142100, eval_loss: 2.47694e-02
I0209 02:51:33.514814 22542570456896 run_lib.py:133] step: 142150, training_loss: 3.04023e-02
I0209 02:51:50.932751 22542570456896 run_lib.py:133] step: 142200, training_loss: 2.89954e-02
I0209 02:51:51.087450 22542570456896 run_lib.py:146] step: 142200, eval_loss: 2.52615e-02
I0209 02:52:08.465264 22542570456896 run_lib.py:133] step: 142250, training_loss: 3.17181e-02
I0209 02:52:25.905773 22542570456896 run_lib.py:133] step: 142300, training_loss: 3.11071e-02
I0209 02:52:26.082261 22542570456896 run_lib.py:146] step: 142300, eval_loss: 2.71802e-02
I0209 02:52:43.692375 22542570456896 run_lib.py:133] step: 142350, training_loss: 2.36067e-02
I0209 02:53:01.213428 22542570456896 run_lib.py:133] step: 142400, training_loss: 3.08516e-02
I0209 02:53:01.369639 22542570456896 run_lib.py:146] step: 142400, eval_loss: 2.85711e-02
I0209 02:53:18.794847 22542570456896 run_lib.py:133] step: 142450, training_loss: 3.15059e-02
I0209 02:53:36.182907 22542570456896 run_lib.py:133] step: 142500, training_loss: 2.84206e-02
I0209 02:53:36.337147 22542570456896 run_lib.py:146] step: 142500, eval_loss: 2.68287e-02
I0209 02:53:53.914033 22542570456896 run_lib.py:133] step: 142550, training_loss: 2.95283e-02
I0209 02:54:11.380288 22542570456896 run_lib.py:133] step: 142600, training_loss: 2.91545e-02
I0209 02:54:11.535620 22542570456896 run_lib.py:146] step: 142600, eval_loss: 3.40348e-02
I0209 02:54:29.127167 22542570456896 run_lib.py:133] step: 142650, training_loss: 2.73891e-02
I0209 02:54:46.563241 22542570456896 run_lib.py:133] step: 142700, training_loss: 2.90262e-02
I0209 02:54:46.731470 22542570456896 run_lib.py:146] step: 142700, eval_loss: 3.22175e-02
I0209 02:55:04.316380 22542570456896 run_lib.py:133] step: 142750, training_loss: 2.70279e-02
I0209 02:55:21.721190 22542570456896 run_lib.py:133] step: 142800, training_loss: 2.78228e-02
I0209 02:55:21.877738 22542570456896 run_lib.py:146] step: 142800, eval_loss: 2.64088e-02
I0209 02:55:39.430965 22542570456896 run_lib.py:133] step: 142850, training_loss: 2.93834e-02
I0209 02:55:56.910242 22542570456896 run_lib.py:133] step: 142900, training_loss: 2.84584e-02
I0209 02:55:57.066214 22542570456896 run_lib.py:146] step: 142900, eval_loss: 2.91247e-02
I0209 02:56:14.541507 22542570456896 run_lib.py:133] step: 142950, training_loss: 2.30274e-02
I0209 02:56:32.125148 22542570456896 run_lib.py:133] step: 143000, training_loss: 3.39323e-02
I0209 02:56:32.275427 22542570456896 run_lib.py:146] step: 143000, eval_loss: 2.74815e-02
I0209 02:56:49.667055 22542570456896 run_lib.py:133] step: 143050, training_loss: 3.14502e-02
I0209 02:57:07.110652 22542570456896 run_lib.py:133] step: 143100, training_loss: 2.87496e-02
I0209 02:57:07.267548 22542570456896 run_lib.py:146] step: 143100, eval_loss: 2.54668e-02
I0209 02:57:24.932438 22542570456896 run_lib.py:133] step: 143150, training_loss: 3.51017e-02
I0209 02:57:42.333577 22542570456896 run_lib.py:133] step: 143200, training_loss: 4.35913e-02
I0209 02:57:42.492369 22542570456896 run_lib.py:146] step: 143200, eval_loss: 3.71488e-02
I0209 02:58:00.071388 22542570456896 run_lib.py:133] step: 143250, training_loss: 2.74379e-02
I0209 02:58:17.467319 22542570456896 run_lib.py:133] step: 143300, training_loss: 3.53778e-02
I0209 02:58:17.625357 22542570456896 run_lib.py:146] step: 143300, eval_loss: 2.33340e-02
I0209 02:58:35.102113 22542570456896 run_lib.py:133] step: 143350, training_loss: 2.49021e-02
I0209 02:58:52.717274 22542570456896 run_lib.py:133] step: 143400, training_loss: 2.44340e-02
I0209 02:58:52.874870 22542570456896 run_lib.py:146] step: 143400, eval_loss: 2.53077e-02
I0209 02:59:10.315181 22542570456896 run_lib.py:133] step: 143450, training_loss: 3.05551e-02
I0209 02:59:27.815847 22542570456896 run_lib.py:133] step: 143500, training_loss: 2.75615e-02
I0209 02:59:27.973442 22542570456896 run_lib.py:146] step: 143500, eval_loss: 2.16612e-02
I0209 02:59:45.427220 22542570456896 run_lib.py:133] step: 143550, training_loss: 2.70141e-02
I0209 03:00:02.999935 22542570456896 run_lib.py:133] step: 143600, training_loss: 2.97080e-02
I0209 03:00:03.155425 22542570456896 run_lib.py:146] step: 143600, eval_loss: 2.86072e-02
I0209 03:00:20.609827 22542570456896 run_lib.py:133] step: 143650, training_loss: 3.11647e-02
I0209 03:00:38.157455 22542570456896 run_lib.py:133] step: 143700, training_loss: 2.51494e-02
I0209 03:00:38.316538 22542570456896 run_lib.py:146] step: 143700, eval_loss: 2.54186e-02
I0209 03:00:55.775581 22542570456896 run_lib.py:133] step: 143750, training_loss: 2.70212e-02
I0209 03:01:13.199607 22542570456896 run_lib.py:133] step: 143800, training_loss: 3.27639e-02
I0209 03:01:13.356374 22542570456896 run_lib.py:146] step: 143800, eval_loss: 2.59032e-02
I0209 03:01:30.924237 22542570456896 run_lib.py:133] step: 143850, training_loss: 2.65654e-02
I0209 03:01:48.434955 22542570456896 run_lib.py:133] step: 143900, training_loss: 2.95920e-02
I0209 03:01:48.590197 22542570456896 run_lib.py:146] step: 143900, eval_loss: 3.07811e-02
I0209 03:02:06.086821 22542570456896 run_lib.py:133] step: 143950, training_loss: 2.83024e-02
I0209 03:02:23.528839 22542570456896 run_lib.py:133] step: 144000, training_loss: 2.27848e-02
I0209 03:02:23.681642 22542570456896 run_lib.py:146] step: 144000, eval_loss: 2.39909e-02
I0209 03:02:41.297687 22542570456896 run_lib.py:133] step: 144050, training_loss: 2.77990e-02
I0209 03:02:58.770688 22542570456896 run_lib.py:133] step: 144100, training_loss: 3.37102e-02
I0209 03:02:58.924615 22542570456896 run_lib.py:146] step: 144100, eval_loss: 2.54669e-02
I0209 03:03:16.534771 22542570456896 run_lib.py:133] step: 144150, training_loss: 3.24314e-02
I0209 03:03:33.946676 22542570456896 run_lib.py:133] step: 144200, training_loss: 2.95875e-02
I0209 03:03:34.119417 22542570456896 run_lib.py:146] step: 144200, eval_loss: 3.26142e-02
I0209 03:03:51.758395 22542570456896 run_lib.py:133] step: 144250, training_loss: 2.89630e-02
I0209 03:04:09.243383 22542570456896 run_lib.py:133] step: 144300, training_loss: 2.56725e-02
I0209 03:04:09.398750 22542570456896 run_lib.py:146] step: 144300, eval_loss: 3.36756e-02
I0209 03:04:26.867872 22542570456896 run_lib.py:133] step: 144350, training_loss: 2.77650e-02
I0209 03:04:44.469122 22542570456896 run_lib.py:133] step: 144400, training_loss: 2.47232e-02
I0209 03:04:44.626395 22542570456896 run_lib.py:146] step: 144400, eval_loss: 2.56053e-02
I0209 03:05:02.088052 22542570456896 run_lib.py:133] step: 144450, training_loss: 2.93427e-02
I0209 03:05:19.668129 22542570456896 run_lib.py:133] step: 144500, training_loss: 3.22518e-02
I0209 03:05:19.819444 22542570456896 run_lib.py:146] step: 144500, eval_loss: 3.05585e-02
I0209 03:05:37.271687 22542570456896 run_lib.py:133] step: 144550, training_loss: 2.49286e-02
I0209 03:05:54.727362 22542570456896 run_lib.py:133] step: 144600, training_loss: 2.96346e-02
I0209 03:05:54.886315 22542570456896 run_lib.py:146] step: 144600, eval_loss: 2.80592e-02
I0209 03:06:12.489359 22542570456896 run_lib.py:133] step: 144650, training_loss: 3.17834e-02
I0209 03:06:29.941165 22542570456896 run_lib.py:133] step: 144700, training_loss: 2.28213e-02
I0209 03:06:30.104455 22542570456896 run_lib.py:146] step: 144700, eval_loss: 2.76050e-02
I0209 03:06:47.518404 22542570456896 run_lib.py:133] step: 144750, training_loss: 3.46453e-02
I0209 03:07:05.082813 22542570456896 run_lib.py:133] step: 144800, training_loss: 3.42146e-02
I0209 03:07:05.252520 22542570456896 run_lib.py:146] step: 144800, eval_loss: 2.97473e-02
I0209 03:07:22.764988 22542570456896 run_lib.py:133] step: 144850, training_loss: 2.61199e-02
I0209 03:07:40.233775 22542570456896 run_lib.py:133] step: 144900, training_loss: 2.71766e-02
I0209 03:07:40.577011 22542570456896 run_lib.py:146] step: 144900, eval_loss: 2.54058e-02
I0209 03:07:57.999134 22542570456896 run_lib.py:133] step: 144950, training_loss: 2.96936e-02
I0209 03:08:15.441822 22542570456896 run_lib.py:133] step: 145000, training_loss: 2.96689e-02
I0209 03:08:15.596505 22542570456896 run_lib.py:146] step: 145000, eval_loss: 2.97071e-02
I0209 03:08:33.010210 22542570456896 run_lib.py:133] step: 145050, training_loss: 2.62679e-02
I0209 03:08:50.471507 22542570456896 run_lib.py:133] step: 145100, training_loss: 3.09209e-02
I0209 03:08:50.643300 22542570456896 run_lib.py:146] step: 145100, eval_loss: 2.59313e-02
I0209 03:09:08.277014 22542570456896 run_lib.py:133] step: 145150, training_loss: 3.46223e-02
I0209 03:09:25.792271 22542570456896 run_lib.py:133] step: 145200, training_loss: 3.53717e-02
I0209 03:09:25.944951 22542570456896 run_lib.py:146] step: 145200, eval_loss: 2.58317e-02
I0209 03:09:43.387951 22542570456896 run_lib.py:133] step: 145250, training_loss: 2.58926e-02
I0209 03:10:00.810049 22542570456896 run_lib.py:133] step: 145300, training_loss: 3.17019e-02
I0209 03:10:00.974506 22542570456896 run_lib.py:146] step: 145300, eval_loss: 3.30727e-02
I0209 03:10:18.553834 22542570456896 run_lib.py:133] step: 145350, training_loss: 2.62221e-02
I0209 03:10:36.084455 22542570456896 run_lib.py:133] step: 145400, training_loss: 3.26292e-02
I0209 03:10:36.238797 22542570456896 run_lib.py:146] step: 145400, eval_loss: 2.62261e-02
I0209 03:10:53.686808 22542570456896 run_lib.py:133] step: 145450, training_loss: 2.56635e-02
I0209 03:11:11.123071 22542570456896 run_lib.py:133] step: 145500, training_loss: 2.58130e-02
I0209 03:11:11.278392 22542570456896 run_lib.py:146] step: 145500, eval_loss: 2.43643e-02
I0209 03:11:28.859640 22542570456896 run_lib.py:133] step: 145550, training_loss: 2.22593e-02
I0209 03:11:46.356346 22542570456896 run_lib.py:133] step: 145600, training_loss: 2.91816e-02
I0209 03:11:46.532286 22542570456896 run_lib.py:146] step: 145600, eval_loss: 3.68891e-02
I0209 03:12:04.156856 22542570456896 run_lib.py:133] step: 145650, training_loss: 2.90563e-02
I0209 03:12:21.608840 22542570456896 run_lib.py:133] step: 145700, training_loss: 2.27765e-02
I0209 03:12:21.766558 22542570456896 run_lib.py:146] step: 145700, eval_loss: 3.07742e-02
I0209 03:12:39.375178 22542570456896 run_lib.py:133] step: 145750, training_loss: 2.62038e-02
I0209 03:12:56.809325 22542570456896 run_lib.py:133] step: 145800, training_loss: 3.10600e-02
I0209 03:12:56.961404 22542570456896 run_lib.py:146] step: 145800, eval_loss: 3.02095e-02
I0209 03:13:14.369330 22542570456896 run_lib.py:133] step: 145850, training_loss: 2.25907e-02
I0209 03:13:31.967824 22542570456896 run_lib.py:133] step: 145900, training_loss: 2.85471e-02
I0209 03:13:32.121562 22542570456896 run_lib.py:146] step: 145900, eval_loss: 3.34731e-02
I0209 03:13:49.578240 22542570456896 run_lib.py:133] step: 145950, training_loss: 2.50571e-02
I0209 03:14:07.168365 22542570456896 run_lib.py:133] step: 146000, training_loss: 3.56182e-02
I0209 03:14:07.327318 22542570456896 run_lib.py:146] step: 146000, eval_loss: 3.17483e-02
I0209 03:14:24.773926 22542570456896 run_lib.py:133] step: 146050, training_loss: 3.12774e-02
I0209 03:14:42.208793 22542570456896 run_lib.py:133] step: 146100, training_loss: 2.19250e-02
I0209 03:14:42.373604 22542570456896 run_lib.py:146] step: 146100, eval_loss: 3.10553e-02
I0209 03:14:59.948709 22542570456896 run_lib.py:133] step: 146150, training_loss: 3.20731e-02
I0209 03:15:17.423247 22542570456896 run_lib.py:133] step: 146200, training_loss: 2.08605e-02
I0209 03:15:17.580236 22542570456896 run_lib.py:146] step: 146200, eval_loss: 3.07179e-02
I0209 03:15:34.999210 22542570456896 run_lib.py:133] step: 146250, training_loss: 2.57387e-02
I0209 03:15:52.418092 22542570456896 run_lib.py:133] step: 146300, training_loss: 3.79330e-02
I0209 03:15:52.573295 22542570456896 run_lib.py:146] step: 146300, eval_loss: 3.21258e-02
I0209 03:16:10.167234 22542570456896 run_lib.py:133] step: 146350, training_loss: 2.40258e-02
I0209 03:16:27.590346 22542570456896 run_lib.py:133] step: 146400, training_loss: 2.68940e-02
I0209 03:16:27.745515 22542570456896 run_lib.py:146] step: 146400, eval_loss: 2.73927e-02
I0209 03:16:45.296182 22542570456896 run_lib.py:133] step: 146450, training_loss: 2.83065e-02
I0209 03:17:02.749492 22542570456896 run_lib.py:133] step: 146500, training_loss: 2.66722e-02
I0209 03:17:02.911494 22542570456896 run_lib.py:146] step: 146500, eval_loss: 3.05181e-02
I0209 03:17:20.335279 22542570456896 run_lib.py:133] step: 146550, training_loss: 2.59466e-02
I0209 03:17:37.730533 22542570456896 run_lib.py:133] step: 146600, training_loss: 3.01539e-02
I0209 03:17:37.888314 22542570456896 run_lib.py:146] step: 146600, eval_loss: 2.78308e-02
I0209 03:17:55.492331 22542570456896 run_lib.py:133] step: 146650, training_loss: 2.59496e-02
I0209 03:18:13.010460 22542570456896 run_lib.py:133] step: 146700, training_loss: 3.33766e-02
I0209 03:18:13.166401 22542570456896 run_lib.py:146] step: 146700, eval_loss: 2.82839e-02
I0209 03:18:30.552249 22542570456896 run_lib.py:133] step: 146750, training_loss: 2.76343e-02
I0209 03:18:48.041967 22542570456896 run_lib.py:133] step: 146800, training_loss: 2.40409e-02
I0209 03:18:48.197133 22542570456896 run_lib.py:146] step: 146800, eval_loss: 3.16357e-02
I0209 03:19:05.851610 22542570456896 run_lib.py:133] step: 146850, training_loss: 2.22500e-02
I0209 03:19:23.304537 22542570456896 run_lib.py:133] step: 146900, training_loss: 2.62154e-02
I0209 03:19:23.457258 22542570456896 run_lib.py:146] step: 146900, eval_loss: 2.77132e-02
I0209 03:19:40.994151 22542570456896 run_lib.py:133] step: 146950, training_loss: 3.40184e-02
I0209 03:19:58.404967 22542570456896 run_lib.py:133] step: 147000, training_loss: 3.09574e-02
I0209 03:19:58.587424 22542570456896 run_lib.py:146] step: 147000, eval_loss: 2.40193e-02
I0209 03:20:16.247424 22542570456896 run_lib.py:133] step: 147050, training_loss: 2.67064e-02
I0209 03:20:33.674584 22542570456896 run_lib.py:133] step: 147100, training_loss: 2.55410e-02
I0209 03:20:33.836234 22542570456896 run_lib.py:146] step: 147100, eval_loss: 2.34227e-02
I0209 03:20:51.424118 22542570456896 run_lib.py:133] step: 147150, training_loss: 3.45839e-02
I0209 03:21:08.836010 22542570456896 run_lib.py:133] step: 147200, training_loss: 2.72906e-02
I0209 03:21:08.987825 22542570456896 run_lib.py:146] step: 147200, eval_loss: 3.28756e-02
I0209 03:21:26.418309 22542570456896 run_lib.py:133] step: 147250, training_loss: 2.56643e-02
I0209 03:21:44.009790 22542570456896 run_lib.py:133] step: 147300, training_loss: 2.88475e-02
I0209 03:21:44.163611 22542570456896 run_lib.py:146] step: 147300, eval_loss: 2.73255e-02
I0209 03:22:01.612696 22542570456896 run_lib.py:133] step: 147350, training_loss: 2.49531e-02
I0209 03:22:18.994710 22542570456896 run_lib.py:133] step: 147400, training_loss: 2.48401e-02
I0209 03:22:19.150374 22542570456896 run_lib.py:146] step: 147400, eval_loss: 2.90047e-02
I0209 03:22:36.763482 22542570456896 run_lib.py:133] step: 147450, training_loss: 2.37362e-02
I0209 03:22:54.314127 22542570456896 run_lib.py:133] step: 147500, training_loss: 2.79981e-02
I0209 03:22:54.472440 22542570456896 run_lib.py:146] step: 147500, eval_loss: 2.06448e-02
I0209 03:23:11.879400 22542570456896 run_lib.py:133] step: 147550, training_loss: 2.43173e-02
I0209 03:23:29.330333 22542570456896 run_lib.py:133] step: 147600, training_loss: 2.39961e-02
I0209 03:23:29.486631 22542570456896 run_lib.py:146] step: 147600, eval_loss: 2.98946e-02
I0209 03:23:46.892868 22542570456896 run_lib.py:133] step: 147650, training_loss: 2.39676e-02
I0209 03:24:04.466123 22542570456896 run_lib.py:133] step: 147700, training_loss: 3.37069e-02
I0209 03:24:04.623314 22542570456896 run_lib.py:146] step: 147700, eval_loss: 3.07388e-02
I0209 03:24:22.006646 22542570456896 run_lib.py:133] step: 147750, training_loss: 2.31833e-02
I0209 03:24:39.431984 22542570456896 run_lib.py:133] step: 147800, training_loss: 2.30306e-02
I0209 03:24:39.583323 22542570456896 run_lib.py:146] step: 147800, eval_loss: 3.35589e-02
I0209 03:24:57.028211 22542570456896 run_lib.py:133] step: 147850, training_loss: 2.26258e-02
I0209 03:25:14.677271 22542570456896 run_lib.py:133] step: 147900, training_loss: 2.51816e-02
I0209 03:25:14.833164 22542570456896 run_lib.py:146] step: 147900, eval_loss: 3.01282e-02
I0209 03:25:32.227291 22542570456896 run_lib.py:133] step: 147950, training_loss: 2.90340e-02
I0209 03:25:49.708850 22542570456896 run_lib.py:133] step: 148000, training_loss: 3.00786e-02
I0209 03:25:49.863638 22542570456896 run_lib.py:146] step: 148000, eval_loss: 2.57994e-02
I0209 03:26:07.267585 22542570456896 run_lib.py:133] step: 148050, training_loss: 2.43460e-02
I0209 03:26:24.706716 22542570456896 run_lib.py:133] step: 148100, training_loss: 2.61155e-02
I0209 03:26:24.865406 22542570456896 run_lib.py:146] step: 148100, eval_loss: 2.38496e-02
I0209 03:26:42.428828 22542570456896 run_lib.py:133] step: 148150, training_loss: 3.59645e-02
I0209 03:26:59.967875 22542570456896 run_lib.py:133] step: 148200, training_loss: 2.16777e-02
I0209 03:27:00.130560 22542570456896 run_lib.py:146] step: 148200, eval_loss: 3.05542e-02
I0209 03:27:17.548384 22542570456896 run_lib.py:133] step: 148250, training_loss: 3.06322e-02
I0209 03:27:34.960630 22542570456896 run_lib.py:133] step: 148300, training_loss: 2.57357e-02
I0209 03:27:35.111539 22542570456896 run_lib.py:146] step: 148300, eval_loss: 2.91503e-02
I0209 03:27:52.693975 22542570456896 run_lib.py:133] step: 148350, training_loss: 2.52928e-02
I0209 03:28:10.171521 22542570456896 run_lib.py:133] step: 148400, training_loss: 2.63788e-02
I0209 03:28:10.348343 22542570456896 run_lib.py:146] step: 148400, eval_loss: 3.11148e-02
I0209 03:28:27.973036 22542570456896 run_lib.py:133] step: 148450, training_loss: 2.70467e-02
I0209 03:28:45.387344 22542570456896 run_lib.py:133] step: 148500, training_loss: 2.62367e-02
I0209 03:28:45.546652 22542570456896 run_lib.py:146] step: 148500, eval_loss: 2.52227e-02
I0209 03:29:03.114666 22542570456896 run_lib.py:133] step: 148550, training_loss: 2.62114e-02
I0209 03:29:20.511361 22542570456896 run_lib.py:133] step: 148600, training_loss: 2.38265e-02
I0209 03:29:20.667064 22542570456896 run_lib.py:146] step: 148600, eval_loss: 3.07750e-02
I0209 03:29:38.115066 22542570456896 run_lib.py:133] step: 148650, training_loss: 2.72021e-02
I0209 03:29:55.750687 22542570456896 run_lib.py:133] step: 148700, training_loss: 2.51368e-02
I0209 03:29:55.911168 22542570456896 run_lib.py:146] step: 148700, eval_loss: 2.71425e-02
I0209 03:30:13.367489 22542570456896 run_lib.py:133] step: 148750, training_loss: 2.93328e-02
I0209 03:30:30.957453 22542570456896 run_lib.py:133] step: 148800, training_loss: 3.10131e-02
I0209 03:30:31.111353 22542570456896 run_lib.py:146] step: 148800, eval_loss: 3.23109e-02
I0209 03:30:48.525741 22542570456896 run_lib.py:133] step: 148850, training_loss: 3.51605e-02
I0209 03:31:05.975659 22542570456896 run_lib.py:133] step: 148900, training_loss: 2.66862e-02
I0209 03:31:06.134299 22542570456896 run_lib.py:146] step: 148900, eval_loss: 2.21453e-02
I0209 03:31:23.729461 22542570456896 run_lib.py:133] step: 148950, training_loss: 2.38293e-02
I0209 03:31:41.227900 22542570456896 run_lib.py:133] step: 149000, training_loss: 2.36808e-02
I0209 03:31:41.385201 22542570456896 run_lib.py:146] step: 149000, eval_loss: 1.93312e-02
I0209 03:31:58.826317 22542570456896 run_lib.py:133] step: 149050, training_loss: 2.87846e-02
I0209 03:32:16.441783 22542570456896 run_lib.py:133] step: 149100, training_loss: 2.87121e-02
I0209 03:32:16.598251 22542570456896 run_lib.py:146] step: 149100, eval_loss: 2.40502e-02
I0209 03:32:34.008966 22542570456896 run_lib.py:133] step: 149150, training_loss: 2.68918e-02
I0209 03:32:51.438041 22542570456896 run_lib.py:133] step: 149200, training_loss: 3.32607e-02
I0209 03:32:51.591611 22542570456896 run_lib.py:146] step: 149200, eval_loss: 2.79925e-02
I0209 03:33:09.141422 22542570456896 run_lib.py:133] step: 149250, training_loss: 2.24506e-02
I0209 03:33:26.601730 22542570456896 run_lib.py:133] step: 149300, training_loss: 3.04054e-02
I0209 03:33:26.758747 22542570456896 run_lib.py:146] step: 149300, eval_loss: 3.29817e-02
I0209 03:33:44.201722 22542570456896 run_lib.py:133] step: 149350, training_loss: 3.51552e-02
I0209 03:34:01.631138 22542570456896 run_lib.py:133] step: 149400, training_loss: 3.28509e-02
I0209 03:34:01.789529 22542570456896 run_lib.py:146] step: 149400, eval_loss: 3.63063e-02
I0209 03:34:19.364531 22542570456896 run_lib.py:133] step: 149450, training_loss: 3.67717e-02
I0209 03:34:36.838252 22542570456896 run_lib.py:133] step: 149500, training_loss: 2.51508e-02
I0209 03:34:37.004252 22542570456896 run_lib.py:146] step: 149500, eval_loss: 3.27896e-02
I0209 03:34:54.451275 22542570456896 run_lib.py:133] step: 149550, training_loss: 2.68987e-02
I0209 03:35:11.931328 22542570456896 run_lib.py:133] step: 149600, training_loss: 3.02194e-02
I0209 03:35:12.094110 22542570456896 run_lib.py:146] step: 149600, eval_loss: 3.18589e-02
I0209 03:35:29.723632 22542570456896 run_lib.py:133] step: 149650, training_loss: 3.44111e-02
I0209 03:35:47.144118 22542570456896 run_lib.py:133] step: 149700, training_loss: 3.03143e-02
I0209 03:35:47.303266 22542570456896 run_lib.py:146] step: 149700, eval_loss: 3.51273e-02
I0209 03:36:04.897974 22542570456896 run_lib.py:133] step: 149750, training_loss: 2.55044e-02
I0209 03:36:22.351128 22542570456896 run_lib.py:133] step: 149800, training_loss: 3.10125e-02
I0209 03:36:22.521348 22542570456896 run_lib.py:146] step: 149800, eval_loss: 2.54966e-02
I0209 03:36:40.157546 22542570456896 run_lib.py:133] step: 149850, training_loss: 3.45254e-02
I0209 03:36:57.615190 22542570456896 run_lib.py:133] step: 149900, training_loss: 2.70564e-02
I0209 03:36:57.772281 22542570456896 run_lib.py:146] step: 149900, eval_loss: 3.08204e-02
I0209 03:37:15.368228 22542570456896 run_lib.py:133] step: 149950, training_loss: 2.58047e-02
I0209 03:37:32.805926 22542570456896 run_lib.py:133] step: 150000, training_loss: 2.92506e-02
I0209 03:37:33.503957 22542570456896 run_lib.py:146] step: 150000, eval_loss: 2.35086e-02
I0209 03:37:53.888524 22542570456896 run_lib.py:133] step: 150050, training_loss: 2.76008e-02
I0209 03:38:11.528725 22542570456896 run_lib.py:133] step: 150100, training_loss: 3.49492e-02
I0209 03:38:11.685141 22542570456896 run_lib.py:146] step: 150100, eval_loss: 3.02410e-02
I0209 03:38:29.111374 22542570456896 run_lib.py:133] step: 150150, training_loss: 2.84268e-02
I0209 03:38:46.648205 22542570456896 run_lib.py:133] step: 150200, training_loss: 2.81495e-02
I0209 03:38:46.800436 22542570456896 run_lib.py:146] step: 150200, eval_loss: 3.25339e-02
I0209 03:39:04.203734 22542570456896 run_lib.py:133] step: 150250, training_loss: 2.60899e-02
I0209 03:39:21.618152 22542570456896 run_lib.py:133] step: 150300, training_loss: 3.51343e-02
I0209 03:39:21.771244 22542570456896 run_lib.py:146] step: 150300, eval_loss: 2.75155e-02
I0209 03:39:39.357522 22542570456896 run_lib.py:133] step: 150350, training_loss: 2.99089e-02
I0209 03:39:56.858620 22542570456896 run_lib.py:133] step: 150400, training_loss: 3.24053e-02
I0209 03:39:57.025906 22542570456896 run_lib.py:146] step: 150400, eval_loss: 2.52982e-02
I0209 03:40:14.461265 22542570456896 run_lib.py:133] step: 150450, training_loss: 3.16301e-02
I0209 03:40:31.914945 22542570456896 run_lib.py:133] step: 150500, training_loss: 2.76867e-02
I0209 03:40:32.071625 22542570456896 run_lib.py:146] step: 150500, eval_loss: 2.70703e-02
I0209 03:40:49.667979 22542570456896 run_lib.py:133] step: 150550, training_loss: 3.23171e-02
I0209 03:41:07.094978 22542570456896 run_lib.py:133] step: 150600, training_loss: 3.53303e-02
I0209 03:41:07.263536 22542570456896 run_lib.py:146] step: 150600, eval_loss: 2.93025e-02
I0209 03:41:24.857315 22542570456896 run_lib.py:133] step: 150650, training_loss: 3.37910e-02
I0209 03:41:42.303012 22542570456896 run_lib.py:133] step: 150700, training_loss: 2.52100e-02
I0209 03:41:42.455525 22542570456896 run_lib.py:146] step: 150700, eval_loss: 2.77570e-02
I0209 03:42:00.126366 22542570456896 run_lib.py:133] step: 150750, training_loss: 2.64531e-02
I0209 03:42:17.526742 22542570456896 run_lib.py:133] step: 150800, training_loss: 3.14615e-02
I0209 03:42:17.681061 22542570456896 run_lib.py:146] step: 150800, eval_loss: 3.18215e-02
I0209 03:42:35.118819 22542570456896 run_lib.py:133] step: 150850, training_loss: 2.26147e-02
I0209 03:42:52.709029 22542570456896 run_lib.py:133] step: 150900, training_loss: 3.03729e-02
I0209 03:42:52.886404 22542570456896 run_lib.py:146] step: 150900, eval_loss: 3.06152e-02
I0209 03:43:10.384605 22542570456896 run_lib.py:133] step: 150950, training_loss: 3.12452e-02
I0209 03:43:27.981516 22542570456896 run_lib.py:133] step: 151000, training_loss: 3.27156e-02
I0209 03:43:28.136464 22542570456896 run_lib.py:146] step: 151000, eval_loss: 2.94289e-02
I0209 03:43:45.560299 22542570456896 run_lib.py:133] step: 151050, training_loss: 3.05379e-02
I0209 03:44:02.979643 22542570456896 run_lib.py:133] step: 151100, training_loss: 3.22074e-02
I0209 03:44:03.133376 22542570456896 run_lib.py:146] step: 151100, eval_loss: 3.37091e-02
I0209 03:44:20.746790 22542570456896 run_lib.py:133] step: 151150, training_loss: 3.42842e-02
I0209 03:44:38.221099 22542570456896 run_lib.py:133] step: 151200, training_loss: 2.99934e-02
I0209 03:44:38.384365 22542570456896 run_lib.py:146] step: 151200, eval_loss: 2.58090e-02
I0209 03:44:55.821716 22542570456896 run_lib.py:133] step: 151250, training_loss: 2.62061e-02
I0209 03:45:13.464338 22542570456896 run_lib.py:133] step: 151300, training_loss: 2.75941e-02
I0209 03:45:13.620385 22542570456896 run_lib.py:146] step: 151300, eval_loss: 3.26829e-02
I0209 03:45:31.062758 22542570456896 run_lib.py:133] step: 151350, training_loss: 2.59602e-02
I0209 03:45:48.480940 22542570456896 run_lib.py:133] step: 151400, training_loss: 2.05877e-02
I0209 03:45:48.643478 22542570456896 run_lib.py:146] step: 151400, eval_loss: 2.43286e-02
I0209 03:46:06.174640 22542570456896 run_lib.py:133] step: 151450, training_loss: 3.16952e-02
I0209 03:46:23.631997 22542570456896 run_lib.py:133] step: 151500, training_loss: 2.69241e-02
I0209 03:46:23.790393 22542570456896 run_lib.py:146] step: 151500, eval_loss: 3.04591e-02
I0209 03:46:41.260026 22542570456896 run_lib.py:133] step: 151550, training_loss: 2.62172e-02
I0209 03:46:58.655308 22542570456896 run_lib.py:133] step: 151600, training_loss: 3.20426e-02
I0209 03:46:58.810052 22542570456896 run_lib.py:146] step: 151600, eval_loss: 2.79623e-02
I0209 03:47:16.415969 22542570456896 run_lib.py:133] step: 151650, training_loss: 2.89177e-02
I0209 03:47:33.940163 22542570456896 run_lib.py:133] step: 151700, training_loss: 2.86833e-02
I0209 03:47:34.102592 22542570456896 run_lib.py:146] step: 151700, eval_loss: 3.46874e-02
I0209 03:47:51.606136 22542570456896 run_lib.py:133] step: 151750, training_loss: 2.73048e-02
I0209 03:48:09.032214 22542570456896 run_lib.py:133] step: 151800, training_loss: 3.22543e-02
I0209 03:48:09.190277 22542570456896 run_lib.py:146] step: 151800, eval_loss: 2.58110e-02
I0209 03:48:26.765442 22542570456896 run_lib.py:133] step: 151850, training_loss: 2.50828e-02
I0209 03:48:44.200512 22542570456896 run_lib.py:133] step: 151900, training_loss: 2.82838e-02
I0209 03:48:44.355350 22542570456896 run_lib.py:146] step: 151900, eval_loss: 2.68778e-02
I0209 03:49:01.936535 22542570456896 run_lib.py:133] step: 151950, training_loss: 3.00725e-02
I0209 03:49:19.348276 22542570456896 run_lib.py:133] step: 152000, training_loss: 2.27060e-02
I0209 03:49:19.521128 22542570456896 run_lib.py:146] step: 152000, eval_loss: 1.95586e-02
I0209 03:49:37.123570 22542570456896 run_lib.py:133] step: 152050, training_loss: 2.54062e-02
I0209 03:49:54.567779 22542570456896 run_lib.py:133] step: 152100, training_loss: 2.98521e-02
I0209 03:49:54.718559 22542570456896 run_lib.py:146] step: 152100, eval_loss: 3.40501e-02
I0209 03:50:12.339927 22542570456896 run_lib.py:133] step: 152150, training_loss: 2.74564e-02
I0209 03:50:29.749328 22542570456896 run_lib.py:133] step: 152200, training_loss: 3.27193e-02
I0209 03:50:29.905340 22542570456896 run_lib.py:146] step: 152200, eval_loss: 2.96714e-02
I0209 03:50:47.285186 22542570456896 run_lib.py:133] step: 152250, training_loss: 2.45855e-02
I0209 03:51:04.831377 22542570456896 run_lib.py:133] step: 152300, training_loss: 2.91795e-02
I0209 03:51:05.007386 22542570456896 run_lib.py:146] step: 152300, eval_loss: 2.68208e-02
I0209 03:51:22.473082 22542570456896 run_lib.py:133] step: 152350, training_loss: 2.39330e-02
I0209 03:51:39.884992 22542570456896 run_lib.py:133] step: 152400, training_loss: 2.70337e-02
I0209 03:51:40.041693 22542570456896 run_lib.py:146] step: 152400, eval_loss: 3.44092e-02
I0209 03:51:57.643746 22542570456896 run_lib.py:133] step: 152450, training_loss: 2.46314e-02
I0209 03:52:15.066854 22542570456896 run_lib.py:133] step: 152500, training_loss: 2.88683e-02
I0209 03:52:15.223434 22542570456896 run_lib.py:146] step: 152500, eval_loss: 2.26299e-02
I0209 03:52:32.801432 22542570456896 run_lib.py:133] step: 152550, training_loss: 3.38181e-02
I0209 03:52:50.264961 22542570456896 run_lib.py:133] step: 152600, training_loss: 3.03648e-02
I0209 03:52:50.419682 22542570456896 run_lib.py:146] step: 152600, eval_loss: 2.70442e-02
I0209 03:53:07.886696 22542570456896 run_lib.py:133] step: 152650, training_loss: 2.98638e-02
I0209 03:53:25.495871 22542570456896 run_lib.py:133] step: 152700, training_loss: 3.14646e-02
I0209 03:53:25.660437 22542570456896 run_lib.py:146] step: 152700, eval_loss: 3.09695e-02
I0209 03:53:43.067666 22542570456896 run_lib.py:133] step: 152750, training_loss: 2.95746e-02
I0209 03:54:00.486649 22542570456896 run_lib.py:133] step: 152800, training_loss: 2.48190e-02
I0209 03:54:00.641680 22542570456896 run_lib.py:146] step: 152800, eval_loss: 2.79100e-02
I0209 03:54:18.053456 22542570456896 run_lib.py:133] step: 152850, training_loss: 2.66734e-02
I0209 03:54:35.689162 22542570456896 run_lib.py:133] step: 152900, training_loss: 2.74686e-02
I0209 03:54:35.849159 22542570456896 run_lib.py:146] step: 152900, eval_loss: 2.26775e-02
I0209 03:54:53.262169 22542570456896 run_lib.py:133] step: 152950, training_loss: 2.97117e-02
I0209 03:55:10.752728 22542570456896 run_lib.py:133] step: 153000, training_loss: 2.55726e-02
I0209 03:55:10.911321 22542570456896 run_lib.py:146] step: 153000, eval_loss: 2.91309e-02
I0209 03:55:28.309733 22542570456896 run_lib.py:133] step: 153050, training_loss: 2.99738e-02
I0209 03:55:45.719515 22542570456896 run_lib.py:133] step: 153100, training_loss: 2.10805e-02
I0209 03:55:45.870317 22542570456896 run_lib.py:146] step: 153100, eval_loss: 2.68243e-02
I0209 03:56:03.360652 22542570456896 run_lib.py:133] step: 153150, training_loss: 2.78726e-02
I0209 03:56:20.860482 22542570456896 run_lib.py:133] step: 153200, training_loss: 2.44563e-02
I0209 03:56:21.029306 22542570456896 run_lib.py:146] step: 153200, eval_loss: 2.44520e-02
I0209 03:56:38.506485 22542570456896 run_lib.py:133] step: 153250, training_loss: 2.76948e-02
I0209 03:56:55.966047 22542570456896 run_lib.py:133] step: 153300, training_loss: 2.58719e-02
I0209 03:56:56.123631 22542570456896 run_lib.py:146] step: 153300, eval_loss: 3.08346e-02
I0209 03:57:13.711356 22542570456896 run_lib.py:133] step: 153350, training_loss: 3.41700e-02
I0209 03:57:31.157695 22542570456896 run_lib.py:133] step: 153400, training_loss: 2.84301e-02
I0209 03:57:31.328267 22542570456896 run_lib.py:146] step: 153400, eval_loss: 2.73417e-02
I0209 03:57:48.942169 22542570456896 run_lib.py:133] step: 153450, training_loss: 2.95288e-02
I0209 03:58:06.432754 22542570456896 run_lib.py:133] step: 153500, training_loss: 3.00326e-02
I0209 03:58:06.584141 22542570456896 run_lib.py:146] step: 153500, eval_loss: 3.46673e-02
I0209 03:58:24.220773 22542570456896 run_lib.py:133] step: 153550, training_loss: 2.40428e-02
I0209 03:58:41.665217 22542570456896 run_lib.py:133] step: 153600, training_loss: 2.71645e-02
I0209 03:58:41.817627 22542570456896 run_lib.py:146] step: 153600, eval_loss: 2.64739e-02
I0209 03:58:59.225017 22542570456896 run_lib.py:133] step: 153650, training_loss: 2.92323e-02
I0209 03:59:16.869426 22542570456896 run_lib.py:133] step: 153700, training_loss: 2.29442e-02
I0209 03:59:17.055344 22542570456896 run_lib.py:146] step: 153700, eval_loss: 2.50701e-02
I0209 03:59:34.515116 22542570456896 run_lib.py:133] step: 153750, training_loss: 2.43014e-02
I0209 03:59:52.118460 22542570456896 run_lib.py:133] step: 153800, training_loss: 2.41446e-02
I0209 03:59:52.275564 22542570456896 run_lib.py:146] step: 153800, eval_loss: 3.54028e-02
I0209 04:00:09.686375 22542570456896 run_lib.py:133] step: 153850, training_loss: 2.96421e-02
I0209 04:00:27.142949 22542570456896 run_lib.py:133] step: 153900, training_loss: 3.23852e-02
I0209 04:00:27.301506 22542570456896 run_lib.py:146] step: 153900, eval_loss: 3.94035e-02
I0209 04:00:44.956712 22542570456896 run_lib.py:133] step: 153950, training_loss: 3.12627e-02
I0209 04:01:02.435916 22542570456896 run_lib.py:133] step: 154000, training_loss: 3.22602e-02
I0209 04:01:02.587164 22542570456896 run_lib.py:146] step: 154000, eval_loss: 2.55892e-02
I0209 04:01:20.024724 22542570456896 run_lib.py:133] step: 154050, training_loss: 3.30817e-02
I0209 04:01:37.663033 22542570456896 run_lib.py:133] step: 154100, training_loss: 2.91285e-02
I0209 04:01:37.818402 22542570456896 run_lib.py:146] step: 154100, eval_loss: 2.93163e-02
I0209 04:01:55.300964 22542570456896 run_lib.py:133] step: 154150, training_loss: 2.32980e-02
I0209 04:02:12.780726 22542570456896 run_lib.py:133] step: 154200, training_loss: 3.43106e-02
I0209 04:02:13.090790 22542570456896 run_lib.py:146] step: 154200, eval_loss: 3.22400e-02
I0209 04:02:30.544393 22542570456896 run_lib.py:133] step: 154250, training_loss: 2.96624e-02
I0209 04:02:48.002953 22542570456896 run_lib.py:133] step: 154300, training_loss: 2.74148e-02
I0209 04:02:48.161428 22542570456896 run_lib.py:146] step: 154300, eval_loss: 3.41863e-02
I0209 04:03:05.581738 22542570456896 run_lib.py:133] step: 154350, training_loss: 2.69747e-02
I0209 04:03:23.035702 22542570456896 run_lib.py:133] step: 154400, training_loss: 3.52605e-02
I0209 04:03:23.190930 22542570456896 run_lib.py:146] step: 154400, eval_loss: 2.62965e-02
I0209 04:03:40.794342 22542570456896 run_lib.py:133] step: 154450, training_loss: 3.02445e-02
I0209 04:03:58.321854 22542570456896 run_lib.py:133] step: 154500, training_loss: 2.84304e-02
I0209 04:03:58.476525 22542570456896 run_lib.py:146] step: 154500, eval_loss: 2.33155e-02
I0209 04:04:15.936161 22542570456896 run_lib.py:133] step: 154550, training_loss: 3.06354e-02
I0209 04:04:33.389743 22542570456896 run_lib.py:133] step: 154600, training_loss: 2.79881e-02
I0209 04:04:33.546344 22542570456896 run_lib.py:146] step: 154600, eval_loss: 3.07191e-02
I0209 04:04:51.171369 22542570456896 run_lib.py:133] step: 154650, training_loss: 2.44420e-02
I0209 04:05:08.641302 22542570456896 run_lib.py:133] step: 154700, training_loss: 2.60816e-02
I0209 04:05:08.800345 22542570456896 run_lib.py:146] step: 154700, eval_loss: 2.57895e-02
I0209 04:05:26.233966 22542570456896 run_lib.py:133] step: 154750, training_loss: 2.90156e-02
I0209 04:05:43.673984 22542570456896 run_lib.py:133] step: 154800, training_loss: 2.66595e-02
I0209 04:05:43.838614 22542570456896 run_lib.py:146] step: 154800, eval_loss: 3.24614e-02
I0209 04:06:01.474042 22542570456896 run_lib.py:133] step: 154850, training_loss: 2.53803e-02
I0209 04:06:18.904063 22542570456896 run_lib.py:133] step: 154900, training_loss: 2.77848e-02
I0209 04:06:19.059453 22542570456896 run_lib.py:146] step: 154900, eval_loss: 3.21520e-02
I0209 04:06:36.621282 22542570456896 run_lib.py:133] step: 154950, training_loss: 2.89321e-02
I0209 04:06:54.069664 22542570456896 run_lib.py:133] step: 155000, training_loss: 2.67155e-02
I0209 04:06:54.232676 22542570456896 run_lib.py:146] step: 155000, eval_loss: 3.15985e-02
I0209 04:07:11.917347 22542570456896 run_lib.py:133] step: 155050, training_loss: 2.45488e-02
I0209 04:07:29.320420 22542570456896 run_lib.py:133] step: 155100, training_loss: 2.97503e-02
I0209 04:07:29.478425 22542570456896 run_lib.py:146] step: 155100, eval_loss: 2.72435e-02
I0209 04:07:46.884924 22542570456896 run_lib.py:133] step: 155150, training_loss: 2.60323e-02
I0209 04:08:04.465979 22542570456896 run_lib.py:133] step: 155200, training_loss: 2.74363e-02
I0209 04:08:04.621478 22542570456896 run_lib.py:146] step: 155200, eval_loss: 3.14222e-02
I0209 04:08:22.102427 22542570456896 run_lib.py:133] step: 155250, training_loss: 3.40602e-02
I0209 04:08:39.740391 22542570456896 run_lib.py:133] step: 155300, training_loss: 3.37452e-02
I0209 04:08:39.894438 22542570456896 run_lib.py:146] step: 155300, eval_loss: 3.05099e-02
I0209 04:08:57.346556 22542570456896 run_lib.py:133] step: 155350, training_loss: 2.83653e-02
I0209 04:09:14.748721 22542570456896 run_lib.py:133] step: 155400, training_loss: 3.20749e-02
I0209 04:09:14.899137 22542570456896 run_lib.py:146] step: 155400, eval_loss: 3.16556e-02
I0209 04:09:32.509256 22542570456896 run_lib.py:133] step: 155450, training_loss: 2.27711e-02
I0209 04:09:49.941959 22542570456896 run_lib.py:133] step: 155500, training_loss: 3.26082e-02
I0209 04:09:50.095607 22542570456896 run_lib.py:146] step: 155500, eval_loss: 2.55549e-02
I0209 04:10:07.565232 22542570456896 run_lib.py:133] step: 155550, training_loss: 2.68142e-02
I0209 04:10:24.992513 22542570456896 run_lib.py:133] step: 155600, training_loss: 3.01526e-02
I0209 04:10:25.149793 22542570456896 run_lib.py:146] step: 155600, eval_loss: 3.39828e-02
I0209 04:10:42.763061 22542570456896 run_lib.py:133] step: 155650, training_loss: 3.14703e-02
I0209 04:11:00.182408 22542570456896 run_lib.py:133] step: 155700, training_loss: 2.67819e-02
I0209 04:11:00.337433 22542570456896 run_lib.py:146] step: 155700, eval_loss: 2.75354e-02
I0209 04:11:17.853518 22542570456896 run_lib.py:133] step: 155750, training_loss: 3.34086e-02
I0209 04:11:35.263508 22542570456896 run_lib.py:133] step: 155800, training_loss: 4.06542e-02
I0209 04:11:35.425464 22542570456896 run_lib.py:146] step: 155800, eval_loss: 2.62117e-02
I0209 04:11:52.876868 22542570456896 run_lib.py:133] step: 155850, training_loss: 3.45626e-02
I0209 04:12:10.333483 22542570456896 run_lib.py:133] step: 155900, training_loss: 3.03855e-02
I0209 04:12:10.497586 22542570456896 run_lib.py:146] step: 155900, eval_loss: 3.42434e-02
I0209 04:12:28.131375 22542570456896 run_lib.py:133] step: 155950, training_loss: 2.55469e-02
I0209 04:12:45.624247 22542570456896 run_lib.py:133] step: 156000, training_loss: 2.79797e-02
I0209 04:12:45.778398 22542570456896 run_lib.py:146] step: 156000, eval_loss: 3.37986e-02
I0209 04:13:03.177345 22542570456896 run_lib.py:133] step: 156050, training_loss: 3.43740e-02
I0209 04:13:20.584961 22542570456896 run_lib.py:133] step: 156100, training_loss: 2.78721e-02
I0209 04:13:20.749373 22542570456896 run_lib.py:146] step: 156100, eval_loss: 3.00483e-02
I0209 04:13:38.363023 22542570456896 run_lib.py:133] step: 156150, training_loss: 2.65599e-02
I0209 04:13:55.829597 22542570456896 run_lib.py:133] step: 156200, training_loss: 3.22447e-02
I0209 04:13:55.985633 22542570456896 run_lib.py:146] step: 156200, eval_loss: 2.75170e-02
I0209 04:14:13.613756 22542570456896 run_lib.py:133] step: 156250, training_loss: 2.74815e-02
I0209 04:14:31.029871 22542570456896 run_lib.py:133] step: 156300, training_loss: 2.40425e-02
I0209 04:14:31.185395 22542570456896 run_lib.py:146] step: 156300, eval_loss: 3.56187e-02
I0209 04:14:48.752596 22542570456896 run_lib.py:133] step: 156350, training_loss: 2.62213e-02
I0209 04:15:06.176556 22542570456896 run_lib.py:133] step: 156400, training_loss: 2.76066e-02
I0209 04:15:06.330443 22542570456896 run_lib.py:146] step: 156400, eval_loss: 2.55646e-02
I0209 04:15:24.013899 22542570456896 run_lib.py:133] step: 156450, training_loss: 2.56093e-02
I0209 04:15:41.440942 22542570456896 run_lib.py:133] step: 156500, training_loss: 3.19184e-02
I0209 04:15:41.595332 22542570456896 run_lib.py:146] step: 156500, eval_loss: 3.32399e-02
I0209 04:15:59.015489 22542570456896 run_lib.py:133] step: 156550, training_loss: 2.31055e-02
I0209 04:16:16.586115 22542570456896 run_lib.py:133] step: 156600, training_loss: 2.90375e-02
I0209 04:16:16.743635 22542570456896 run_lib.py:146] step: 156600, eval_loss: 2.57772e-02
I0209 04:16:34.194094 22542570456896 run_lib.py:133] step: 156650, training_loss: 3.01472e-02
I0209 04:16:51.670434 22542570456896 run_lib.py:133] step: 156700, training_loss: 2.27266e-02
I0209 04:16:51.833580 22542570456896 run_lib.py:146] step: 156700, eval_loss: 3.00508e-02
I0209 04:17:09.430507 22542570456896 run_lib.py:133] step: 156750, training_loss: 2.71304e-02
I0209 04:17:27.008484 22542570456896 run_lib.py:133] step: 156800, training_loss: 2.31884e-02
I0209 04:17:27.162328 22542570456896 run_lib.py:146] step: 156800, eval_loss: 3.16440e-02
I0209 04:17:44.582183 22542570456896 run_lib.py:133] step: 156850, training_loss: 2.69679e-02
I0209 04:18:02.011834 22542570456896 run_lib.py:133] step: 156900, training_loss: 2.78318e-02
I0209 04:18:02.165346 22542570456896 run_lib.py:146] step: 156900, eval_loss: 3.14634e-02
I0209 04:18:19.578641 22542570456896 run_lib.py:133] step: 156950, training_loss: 3.40549e-02
I0209 04:18:37.212543 22542570456896 run_lib.py:133] step: 157000, training_loss: 3.30073e-02
I0209 04:18:37.373406 22542570456896 run_lib.py:146] step: 157000, eval_loss: 2.74177e-02
I0209 04:18:54.771757 22542570456896 run_lib.py:133] step: 157050, training_loss: 2.35715e-02
I0209 04:19:12.160610 22542570456896 run_lib.py:133] step: 157100, training_loss: 2.78336e-02
I0209 04:19:12.316254 22542570456896 run_lib.py:146] step: 157100, eval_loss: 3.03989e-02
I0209 04:19:29.764986 22542570456896 run_lib.py:133] step: 157150, training_loss: 3.21016e-02
I0209 04:19:47.372599 22542570456896 run_lib.py:133] step: 157200, training_loss: 1.88910e-02
I0209 04:19:47.541517 22542570456896 run_lib.py:146] step: 157200, eval_loss: 2.88388e-02
I0209 04:20:05.030441 22542570456896 run_lib.py:133] step: 157250, training_loss: 2.41129e-02
I0209 04:20:22.553793 22542570456896 run_lib.py:133] step: 157300, training_loss: 3.10352e-02
I0209 04:20:22.711148 22542570456896 run_lib.py:146] step: 157300, eval_loss: 2.46462e-02
I0209 04:20:40.169325 22542570456896 run_lib.py:133] step: 157350, training_loss: 2.91677e-02
I0209 04:20:57.623390 22542570456896 run_lib.py:133] step: 157400, training_loss: 2.40107e-02
I0209 04:20:57.776394 22542570456896 run_lib.py:146] step: 157400, eval_loss: 2.50718e-02
I0209 04:21:15.337333 22542570456896 run_lib.py:133] step: 157450, training_loss: 2.27671e-02
I0209 04:21:32.826606 22542570456896 run_lib.py:133] step: 157500, training_loss: 3.07592e-02
I0209 04:21:33.002453 22542570456896 run_lib.py:146] step: 157500, eval_loss: 2.48445e-02
I0209 04:21:50.463176 22542570456896 run_lib.py:133] step: 157550, training_loss: 2.69971e-02
I0209 04:22:07.930195 22542570456896 run_lib.py:133] step: 157600, training_loss: 2.53204e-02
I0209 04:22:08.085738 22542570456896 run_lib.py:146] step: 157600, eval_loss: 2.71553e-02
I0209 04:22:25.656780 22542570456896 run_lib.py:133] step: 157650, training_loss: 2.66902e-02
I0209 04:22:43.034649 22542570456896 run_lib.py:133] step: 157700, training_loss: 2.98969e-02
I0209 04:22:43.189579 22542570456896 run_lib.py:146] step: 157700, eval_loss: 3.73994e-02
I0209 04:23:00.716167 22542570456896 run_lib.py:133] step: 157750, training_loss: 2.83199e-02
I0209 04:23:18.218461 22542570456896 run_lib.py:133] step: 157800, training_loss: 3.33554e-02
I0209 04:23:18.372083 22542570456896 run_lib.py:146] step: 157800, eval_loss: 2.74969e-02
I0209 04:23:35.947632 22542570456896 run_lib.py:133] step: 157850, training_loss: 2.54410e-02
I0209 04:23:53.388798 22542570456896 run_lib.py:133] step: 157900, training_loss: 2.73722e-02
I0209 04:23:53.549345 22542570456896 run_lib.py:146] step: 157900, eval_loss: 2.87505e-02
I0209 04:24:10.997096 22542570456896 run_lib.py:133] step: 157950, training_loss: 2.45622e-02
I0209 04:24:28.566878 22542570456896 run_lib.py:133] step: 158000, training_loss: 3.12212e-02
I0209 04:24:28.725696 22542570456896 run_lib.py:146] step: 158000, eval_loss: 2.54846e-02
I0209 04:24:46.187125 22542570456896 run_lib.py:133] step: 158050, training_loss: 3.14118e-02
I0209 04:25:03.822674 22542570456896 run_lib.py:133] step: 158100, training_loss: 3.38943e-02
I0209 04:25:03.978538 22542570456896 run_lib.py:146] step: 158100, eval_loss: 2.59094e-02
I0209 04:25:21.412797 22542570456896 run_lib.py:133] step: 158150, training_loss: 3.09411e-02
I0209 04:25:38.817486 22542570456896 run_lib.py:133] step: 158200, training_loss: 3.38324e-02
I0209 04:25:38.976062 22542570456896 run_lib.py:146] step: 158200, eval_loss: 2.83622e-02
I0209 04:25:56.527584 22542570456896 run_lib.py:133] step: 158250, training_loss: 2.97061e-02
I0209 04:26:13.999071 22542570456896 run_lib.py:133] step: 158300, training_loss: 2.56722e-02
I0209 04:26:14.159217 22542570456896 run_lib.py:146] step: 158300, eval_loss: 2.99594e-02
I0209 04:26:31.663879 22542570456896 run_lib.py:133] step: 158350, training_loss: 2.44974e-02
I0209 04:26:49.261015 22542570456896 run_lib.py:133] step: 158400, training_loss: 3.01736e-02
I0209 04:26:49.418388 22542570456896 run_lib.py:146] step: 158400, eval_loss: 2.68257e-02
I0209 04:27:06.808494 22542570456896 run_lib.py:133] step: 158450, training_loss: 2.82316e-02
I0209 04:27:24.258855 22542570456896 run_lib.py:133] step: 158500, training_loss: 2.45640e-02
I0209 04:27:24.416699 22542570456896 run_lib.py:146] step: 158500, eval_loss: 2.49345e-02
I0209 04:27:41.912058 22542570456896 run_lib.py:133] step: 158550, training_loss: 3.36782e-02
I0209 04:27:59.400536 22542570456896 run_lib.py:133] step: 158600, training_loss: 2.77456e-02
I0209 04:27:59.557015 22542570456896 run_lib.py:146] step: 158600, eval_loss: 2.86777e-02
I0209 04:28:16.988468 22542570456896 run_lib.py:133] step: 158650, training_loss: 3.83030e-02
I0209 04:28:34.406097 22542570456896 run_lib.py:133] step: 158700, training_loss: 2.81935e-02
I0209 04:28:34.561239 22542570456896 run_lib.py:146] step: 158700, eval_loss: 2.93780e-02
I0209 04:28:52.167580 22542570456896 run_lib.py:133] step: 158750, training_loss: 2.93294e-02
I0209 04:29:09.667310 22542570456896 run_lib.py:133] step: 158800, training_loss: 3.11683e-02
I0209 04:29:09.819228 22542570456896 run_lib.py:146] step: 158800, eval_loss: 3.28027e-02
I0209 04:29:27.246072 22542570456896 run_lib.py:133] step: 158850, training_loss: 3.49970e-02
I0209 04:29:44.690316 22542570456896 run_lib.py:133] step: 158900, training_loss: 2.92138e-02
I0209 04:29:44.857304 22542570456896 run_lib.py:146] step: 158900, eval_loss: 2.73913e-02
I0209 04:30:02.482840 22542570456896 run_lib.py:133] step: 158950, training_loss: 2.48345e-02
I0209 04:30:19.903429 22542570456896 run_lib.py:133] step: 159000, training_loss: 2.89073e-02
I0209 04:30:20.060475 22542570456896 run_lib.py:146] step: 159000, eval_loss: 3.06882e-02
I0209 04:30:37.633425 22542570456896 run_lib.py:133] step: 159050, training_loss: 3.69745e-02
I0209 04:30:55.043280 22542570456896 run_lib.py:133] step: 159100, training_loss: 3.52979e-02
I0209 04:30:55.199414 22542570456896 run_lib.py:146] step: 159100, eval_loss: 3.01032e-02
I0209 04:31:12.786673 22542570456896 run_lib.py:133] step: 159150, training_loss: 3.32769e-02
I0209 04:31:30.273202 22542570456896 run_lib.py:133] step: 159200, training_loss: 2.60945e-02
I0209 04:31:30.435852 22542570456896 run_lib.py:146] step: 159200, eval_loss: 2.52448e-02
I0209 04:31:48.074536 22542570456896 run_lib.py:133] step: 159250, training_loss: 3.05920e-02
I0209 04:32:05.489200 22542570456896 run_lib.py:133] step: 159300, training_loss: 3.11691e-02
I0209 04:32:05.651322 22542570456896 run_lib.py:146] step: 159300, eval_loss: 2.94378e-02
I0209 04:32:23.078867 22542570456896 run_lib.py:133] step: 159350, training_loss: 2.60922e-02
I0209 04:32:40.643206 22542570456896 run_lib.py:133] step: 159400, training_loss: 2.40501e-02
I0209 04:32:40.809459 22542570456896 run_lib.py:146] step: 159400, eval_loss: 2.94542e-02
I0209 04:32:58.229650 22542570456896 run_lib.py:133] step: 159450, training_loss: 2.71112e-02
I0209 04:33:15.693706 22542570456896 run_lib.py:133] step: 159500, training_loss: 2.06580e-02
I0209 04:33:15.849539 22542570456896 run_lib.py:146] step: 159500, eval_loss: 3.75285e-02
I0209 04:33:33.486453 22542570456896 run_lib.py:133] step: 159550, training_loss: 2.73152e-02
I0209 04:33:50.892904 22542570456896 run_lib.py:133] step: 159600, training_loss: 2.43045e-02
I0209 04:33:51.049477 22542570456896 run_lib.py:146] step: 159600, eval_loss: 3.76946e-02
I0209 04:34:08.600876 22542570456896 run_lib.py:133] step: 159650, training_loss: 2.93496e-02
I0209 04:34:26.000076 22542570456896 run_lib.py:133] step: 159700, training_loss: 2.97554e-02
I0209 04:34:26.158490 22542570456896 run_lib.py:146] step: 159700, eval_loss: 2.48620e-02
I0209 04:34:43.633659 22542570456896 run_lib.py:133] step: 159750, training_loss: 2.50972e-02
I0209 04:35:01.237240 22542570456896 run_lib.py:133] step: 159800, training_loss: 3.53369e-02
I0209 04:35:01.396984 22542570456896 run_lib.py:146] step: 159800, eval_loss: 2.92186e-02
I0209 04:35:18.832459 22542570456896 run_lib.py:133] step: 159850, training_loss: 3.09123e-02
I0209 04:35:36.261437 22542570456896 run_lib.py:133] step: 159900, training_loss: 3.16424e-02
I0209 04:35:36.419571 22542570456896 run_lib.py:146] step: 159900, eval_loss: 2.70312e-02
I0209 04:35:53.861584 22542570456896 run_lib.py:133] step: 159950, training_loss: 2.79089e-02
I0209 04:36:11.411236 22542570456896 run_lib.py:133] step: 160000, training_loss: 3.15976e-02
I0209 04:36:12.230218 22542570456896 run_lib.py:146] step: 160000, eval_loss: 2.60856e-02
I0209 04:36:32.280759 22542570456896 run_lib.py:133] step: 160050, training_loss: 2.62063e-02
I0209 04:36:49.901192 22542570456896 run_lib.py:133] step: 160100, training_loss: 3.08826e-02
I0209 04:36:50.057299 22542570456896 run_lib.py:146] step: 160100, eval_loss: 2.92098e-02
I0209 04:37:07.462754 22542570456896 run_lib.py:133] step: 160150, training_loss: 3.08901e-02
I0209 04:37:24.893282 22542570456896 run_lib.py:133] step: 160200, training_loss: 2.80065e-02
I0209 04:37:25.046304 22542570456896 run_lib.py:146] step: 160200, eval_loss: 3.18477e-02
I0209 04:37:42.476590 22542570456896 run_lib.py:133] step: 160250, training_loss: 4.04242e-02
I0209 04:38:00.055196 22542570456896 run_lib.py:133] step: 160300, training_loss: 2.46676e-02
I0209 04:38:00.216444 22542570456896 run_lib.py:146] step: 160300, eval_loss: 3.11566e-02
I0209 04:38:17.781415 22542570456896 run_lib.py:133] step: 160350, training_loss: 2.56361e-02
I0209 04:38:35.234135 22542570456896 run_lib.py:133] step: 160400, training_loss: 2.54423e-02
I0209 04:38:35.391551 22542570456896 run_lib.py:146] step: 160400, eval_loss: 3.08011e-02
I0209 04:38:52.779454 22542570456896 run_lib.py:133] step: 160450, training_loss: 2.97591e-02
I0209 04:39:10.169888 22542570456896 run_lib.py:133] step: 160500, training_loss: 2.58059e-02
I0209 04:39:10.325376 22542570456896 run_lib.py:146] step: 160500, eval_loss: 2.61209e-02
I0209 04:39:27.906848 22542570456896 run_lib.py:133] step: 160550, training_loss: 2.74409e-02
I0209 04:39:45.468822 22542570456896 run_lib.py:133] step: 160600, training_loss: 3.30522e-02
I0209 04:39:45.632027 22542570456896 run_lib.py:146] step: 160600, eval_loss: 2.87957e-02
I0209 04:40:03.121648 22542570456896 run_lib.py:133] step: 160650, training_loss: 2.84117e-02
I0209 04:40:20.548775 22542570456896 run_lib.py:133] step: 160700, training_loss: 2.70463e-02
I0209 04:40:20.701165 22542570456896 run_lib.py:146] step: 160700, eval_loss: 3.16070e-02
I0209 04:40:38.252407 22542570456896 run_lib.py:133] step: 160750, training_loss: 3.50352e-02
I0209 04:40:55.692778 22542570456896 run_lib.py:133] step: 160800, training_loss: 3.37702e-02
I0209 04:40:55.852693 22542570456896 run_lib.py:146] step: 160800, eval_loss: 3.00958e-02
I0209 04:41:13.462864 22542570456896 run_lib.py:133] step: 160850, training_loss: 2.66833e-02
I0209 04:41:30.932931 22542570456896 run_lib.py:133] step: 160900, training_loss: 3.17905e-02
I0209 04:41:31.091212 22542570456896 run_lib.py:146] step: 160900, eval_loss: 2.74551e-02
I0209 04:41:48.690590 22542570456896 run_lib.py:133] step: 160950, training_loss: 3.51819e-02
I0209 04:42:06.123350 22542570456896 run_lib.py:133] step: 161000, training_loss: 2.11234e-02
I0209 04:42:06.279395 22542570456896 run_lib.py:146] step: 161000, eval_loss: 2.66028e-02
I0209 04:42:23.690759 22542570456896 run_lib.py:133] step: 161050, training_loss: 2.65781e-02
I0209 04:42:41.300460 22542570456896 run_lib.py:133] step: 161100, training_loss: 2.98353e-02
I0209 04:42:41.464291 22542570456896 run_lib.py:146] step: 161100, eval_loss: 2.48419e-02
I0209 04:42:58.906266 22542570456896 run_lib.py:133] step: 161150, training_loss: 2.27054e-02
I0209 04:43:16.503479 22542570456896 run_lib.py:133] step: 161200, training_loss: 2.71237e-02
I0209 04:43:16.654503 22542570456896 run_lib.py:146] step: 161200, eval_loss: 3.66136e-02
I0209 04:43:34.066235 22542570456896 run_lib.py:133] step: 161250, training_loss: 2.35171e-02
I0209 04:43:51.536487 22542570456896 run_lib.py:133] step: 161300, training_loss: 2.62878e-02
I0209 04:43:51.692341 22542570456896 run_lib.py:146] step: 161300, eval_loss: 2.84546e-02
I0209 04:44:09.225726 22542570456896 run_lib.py:133] step: 161350, training_loss: 2.96718e-02
I0209 04:44:26.711863 22542570456896 run_lib.py:133] step: 161400, training_loss: 3.59794e-02
I0209 04:44:26.889216 22542570456896 run_lib.py:146] step: 161400, eval_loss: 2.77486e-02
I0209 04:44:44.331081 22542570456896 run_lib.py:133] step: 161450, training_loss: 3.48246e-02
I0209 04:45:01.938500 22542570456896 run_lib.py:133] step: 161500, training_loss: 3.02077e-02
I0209 04:45:02.093535 22542570456896 run_lib.py:146] step: 161500, eval_loss: 2.61780e-02
I0209 04:45:19.503581 22542570456896 run_lib.py:133] step: 161550, training_loss: 2.35522e-02
I0209 04:45:36.950288 22542570456896 run_lib.py:133] step: 161600, training_loss: 2.92449e-02
I0209 04:45:37.251255 22542570456896 run_lib.py:146] step: 161600, eval_loss: 2.79036e-02
I0209 04:45:54.672425 22542570456896 run_lib.py:133] step: 161650, training_loss: 2.73810e-02
I0209 04:46:12.143361 22542570456896 run_lib.py:133] step: 161700, training_loss: 3.23114e-02
I0209 04:46:12.304369 22542570456896 run_lib.py:146] step: 161700, eval_loss: 2.06555e-02
I0209 04:46:29.763718 22542570456896 run_lib.py:133] step: 161750, training_loss: 3.23896e-02
I0209 04:46:47.157587 22542570456896 run_lib.py:133] step: 161800, training_loss: 2.63666e-02
I0209 04:46:47.313241 22542570456896 run_lib.py:146] step: 161800, eval_loss: 2.61739e-02
I0209 04:47:04.891883 22542570456896 run_lib.py:133] step: 161850, training_loss: 3.49270e-02
I0209 04:47:22.377050 22542570456896 run_lib.py:133] step: 161900, training_loss: 2.30193e-02
I0209 04:47:22.539323 22542570456896 run_lib.py:146] step: 161900, eval_loss: 2.11781e-02
I0209 04:47:39.953004 22542570456896 run_lib.py:133] step: 161950, training_loss: 3.00048e-02
I0209 04:47:57.394196 22542570456896 run_lib.py:133] step: 162000, training_loss: 3.17063e-02
I0209 04:47:57.550135 22542570456896 run_lib.py:146] step: 162000, eval_loss: 3.03869e-02
I0209 04:48:15.159308 22542570456896 run_lib.py:133] step: 162050, training_loss: 2.46985e-02
I0209 04:48:32.658985 22542570456896 run_lib.py:133] step: 162100, training_loss: 2.30222e-02
I0209 04:48:32.812916 22542570456896 run_lib.py:146] step: 162100, eval_loss: 3.75976e-02
I0209 04:48:50.239855 22542570456896 run_lib.py:133] step: 162150, training_loss: 3.73800e-02
I0209 04:49:07.648629 22542570456896 run_lib.py:133] step: 162200, training_loss: 2.54529e-02
I0209 04:49:07.800486 22542570456896 run_lib.py:146] step: 162200, eval_loss: 2.50140e-02
I0209 04:49:25.390769 22542570456896 run_lib.py:133] step: 162250, training_loss: 2.88993e-02
I0209 04:49:42.878891 22542570456896 run_lib.py:133] step: 162300, training_loss: 2.34578e-02
I0209 04:49:43.039467 22542570456896 run_lib.py:146] step: 162300, eval_loss: 3.26718e-02
I0209 04:50:00.620695 22542570456896 run_lib.py:133] step: 162350, training_loss: 3.07016e-02
I0209 04:50:18.030610 22542570456896 run_lib.py:133] step: 162400, training_loss: 2.84247e-02
I0209 04:50:18.186555 22542570456896 run_lib.py:146] step: 162400, eval_loss: 3.21668e-02
I0209 04:50:35.767570 22542570456896 run_lib.py:133] step: 162450, training_loss: 2.80914e-02
I0209 04:50:53.188940 22542570456896 run_lib.py:133] step: 162500, training_loss: 3.31969e-02
I0209 04:50:53.344137 22542570456896 run_lib.py:146] step: 162500, eval_loss: 2.57379e-02
I0209 04:51:10.792292 22542570456896 run_lib.py:133] step: 162550, training_loss: 3.17412e-02
I0209 04:51:28.460078 22542570456896 run_lib.py:133] step: 162600, training_loss: 2.76581e-02
I0209 04:51:28.611076 22542570456896 run_lib.py:146] step: 162600, eval_loss: 2.68818e-02
I0209 04:51:46.001777 22542570456896 run_lib.py:133] step: 162650, training_loss: 2.95395e-02
I0209 04:52:03.576408 22542570456896 run_lib.py:133] step: 162700, training_loss: 2.74802e-02
I0209 04:52:03.736354 22542570456896 run_lib.py:146] step: 162700, eval_loss: 2.77392e-02
I0209 04:52:21.208969 22542570456896 run_lib.py:133] step: 162750, training_loss: 2.94214e-02
I0209 04:52:38.679001 22542570456896 run_lib.py:133] step: 162800, training_loss: 2.73619e-02
I0209 04:52:38.862283 22542570456896 run_lib.py:146] step: 162800, eval_loss: 2.29649e-02
I0209 04:52:56.532357 22542570456896 run_lib.py:133] step: 162850, training_loss: 3.14211e-02
I0209 04:53:13.942042 22542570456896 run_lib.py:133] step: 162900, training_loss: 3.00744e-02
I0209 04:53:14.097528 22542570456896 run_lib.py:146] step: 162900, eval_loss: 2.86402e-02
I0209 04:53:31.524593 22542570456896 run_lib.py:133] step: 162950, training_loss: 2.52402e-02
I0209 04:53:48.915969 22542570456896 run_lib.py:133] step: 163000, training_loss: 2.59599e-02
I0209 04:53:49.070395 22542570456896 run_lib.py:146] step: 163000, eval_loss: 3.24096e-02
I0209 04:54:06.654577 22542570456896 run_lib.py:133] step: 163050, training_loss: 3.05453e-02
I0209 04:54:24.113215 22542570456896 run_lib.py:133] step: 163100, training_loss: 3.13515e-02
I0209 04:54:24.276434 22542570456896 run_lib.py:146] step: 163100, eval_loss: 2.90674e-02
I0209 04:54:41.825692 22542570456896 run_lib.py:133] step: 163150, training_loss: 3.01265e-02
I0209 04:54:59.220125 22542570456896 run_lib.py:133] step: 163200, training_loss: 2.83799e-02
I0209 04:54:59.375432 22542570456896 run_lib.py:146] step: 163200, eval_loss: 3.79669e-02
I0209 04:55:16.794188 22542570456896 run_lib.py:133] step: 163250, training_loss: 3.10701e-02
I0209 04:55:34.200282 22542570456896 run_lib.py:133] step: 163300, training_loss: 3.08316e-02
I0209 04:55:34.358608 22542570456896 run_lib.py:146] step: 163300, eval_loss: 2.99234e-02
I0209 04:55:51.931016 22542570456896 run_lib.py:133] step: 163350, training_loss: 2.87923e-02
I0209 04:56:09.408974 22542570456896 run_lib.py:133] step: 163400, training_loss: 2.68192e-02
I0209 04:56:09.564570 22542570456896 run_lib.py:146] step: 163400, eval_loss: 2.26443e-02
I0209 04:56:27.015982 22542570456896 run_lib.py:133] step: 163450, training_loss: 2.99701e-02
I0209 04:56:44.396174 22542570456896 run_lib.py:133] step: 163500, training_loss: 2.93270e-02
I0209 04:56:44.551353 22542570456896 run_lib.py:146] step: 163500, eval_loss: 3.50590e-02
I0209 04:57:02.126820 22542570456896 run_lib.py:133] step: 163550, training_loss: 2.52625e-02
I0209 04:57:19.533858 22542570456896 run_lib.py:133] step: 163600, training_loss: 2.25889e-02
I0209 04:57:19.685340 22542570456896 run_lib.py:146] step: 163600, eval_loss: 2.52222e-02
I0209 04:57:37.269596 22542570456896 run_lib.py:133] step: 163650, training_loss: 2.62302e-02
I0209 04:57:54.724746 22542570456896 run_lib.py:133] step: 163700, training_loss: 2.93682e-02
I0209 04:57:54.896409 22542570456896 run_lib.py:146] step: 163700, eval_loss: 2.95272e-02
I0209 04:58:12.514564 22542570456896 run_lib.py:133] step: 163750, training_loss: 2.78916e-02
I0209 04:58:29.931288 22542570456896 run_lib.py:133] step: 163800, training_loss: 3.28180e-02
I0209 04:58:30.086519 22542570456896 run_lib.py:146] step: 163800, eval_loss: 3.19687e-02
I0209 04:58:47.627971 22542570456896 run_lib.py:133] step: 163850, training_loss: 2.74432e-02
I0209 04:59:05.048976 22542570456896 run_lib.py:133] step: 163900, training_loss: 2.77953e-02
I0209 04:59:05.205179 22542570456896 run_lib.py:146] step: 163900, eval_loss: 3.27172e-02
I0209 04:59:22.655092 22542570456896 run_lib.py:133] step: 163950, training_loss: 2.87813e-02
I0209 04:59:40.261134 22542570456896 run_lib.py:133] step: 164000, training_loss: 3.11046e-02
I0209 04:59:40.423324 22542570456896 run_lib.py:146] step: 164000, eval_loss: 3.43374e-02
I0209 04:59:57.809022 22542570456896 run_lib.py:133] step: 164050, training_loss: 3.18317e-02
I0209 05:00:15.212294 22542570456896 run_lib.py:133] step: 164100, training_loss: 2.44232e-02
I0209 05:00:15.372260 22542570456896 run_lib.py:146] step: 164100, eval_loss: 3.09628e-02
I0209 05:00:32.898884 22542570456896 run_lib.py:133] step: 164150, training_loss: 2.71635e-02
I0209 05:00:50.436400 22542570456896 run_lib.py:133] step: 164200, training_loss: 3.12984e-02
I0209 05:00:50.620326 22542570456896 run_lib.py:146] step: 164200, eval_loss: 3.68429e-02
I0209 05:01:08.117799 22542570456896 run_lib.py:133] step: 164250, training_loss: 2.18884e-02
I0209 05:01:25.570722 22542570456896 run_lib.py:133] step: 164300, training_loss: 3.16319e-02
I0209 05:01:25.726493 22542570456896 run_lib.py:146] step: 164300, eval_loss: 3.03480e-02
I0209 05:01:43.192099 22542570456896 run_lib.py:133] step: 164350, training_loss: 2.73355e-02
I0209 05:02:00.775898 22542570456896 run_lib.py:133] step: 164400, training_loss: 4.33270e-02
I0209 05:02:00.939114 22542570456896 run_lib.py:146] step: 164400, eval_loss: 2.67110e-02
I0209 05:02:18.362431 22542570456896 run_lib.py:133] step: 164450, training_loss: 3.13585e-02
I0209 05:02:35.832503 22542570456896 run_lib.py:133] step: 164500, training_loss: 2.54649e-02
I0209 05:02:35.985527 22542570456896 run_lib.py:146] step: 164500, eval_loss: 2.83653e-02
I0209 05:02:53.445541 22542570456896 run_lib.py:133] step: 164550, training_loss: 3.14309e-02
I0209 05:03:11.069383 22542570456896 run_lib.py:133] step: 164600, training_loss: 3.08121e-02
I0209 05:03:11.225303 22542570456896 run_lib.py:146] step: 164600, eval_loss: 2.28326e-02
I0209 05:03:28.628417 22542570456896 run_lib.py:133] step: 164650, training_loss: 2.76941e-02
I0209 05:03:46.070176 22542570456896 run_lib.py:133] step: 164700, training_loss: 2.70717e-02
I0209 05:03:46.234442 22542570456896 run_lib.py:146] step: 164700, eval_loss: 2.90430e-02
I0209 05:04:03.638382 22542570456896 run_lib.py:133] step: 164750, training_loss: 2.72834e-02
I0209 05:04:21.083144 22542570456896 run_lib.py:133] step: 164800, training_loss: 3.21995e-02
I0209 05:04:21.236656 22542570456896 run_lib.py:146] step: 164800, eval_loss: 3.05455e-02
I0209 05:04:38.808617 22542570456896 run_lib.py:133] step: 164850, training_loss: 3.46571e-02
I0209 05:04:56.199272 22542570456896 run_lib.py:133] step: 164900, training_loss: 3.81993e-02
I0209 05:04:56.353229 22542570456896 run_lib.py:146] step: 164900, eval_loss: 3.21285e-02
I0209 05:05:13.683175 22542570456896 run_lib.py:133] step: 164950, training_loss: 3.05385e-02
I0209 05:05:31.115708 22542570456896 run_lib.py:133] step: 165000, training_loss: 2.91681e-02
I0209 05:05:31.268169 22542570456896 run_lib.py:146] step: 165000, eval_loss: 2.47898e-02
I0209 05:05:48.890373 22542570456896 run_lib.py:133] step: 165050, training_loss: 2.85380e-02
I0209 05:06:06.345308 22542570456896 run_lib.py:133] step: 165100, training_loss: 2.97539e-02
I0209 05:06:06.508534 22542570456896 run_lib.py:146] step: 165100, eval_loss: 2.95203e-02
I0209 05:06:24.128733 22542570456896 run_lib.py:133] step: 165150, training_loss: 2.94813e-02
I0209 05:06:41.558547 22542570456896 run_lib.py:133] step: 165200, training_loss: 3.57605e-02
I0209 05:06:41.717600 22542570456896 run_lib.py:146] step: 165200, eval_loss: 3.00398e-02
I0209 05:06:59.310191 22542570456896 run_lib.py:133] step: 165250, training_loss: 3.05101e-02
I0209 05:07:16.748210 22542570456896 run_lib.py:133] step: 165300, training_loss: 3.30634e-02
I0209 05:07:16.918380 22542570456896 run_lib.py:146] step: 165300, eval_loss: 2.69214e-02
I0209 05:07:34.348669 22542570456896 run_lib.py:133] step: 165350, training_loss: 3.10051e-02
I0209 05:07:52.026739 22542570456896 run_lib.py:133] step: 165400, training_loss: 2.28219e-02
I0209 05:07:52.181737 22542570456896 run_lib.py:146] step: 165400, eval_loss: 2.96756e-02
I0209 05:08:09.671779 22542570456896 run_lib.py:133] step: 165450, training_loss: 3.21788e-02
I0209 05:08:27.246498 22542570456896 run_lib.py:133] step: 165500, training_loss: 3.10759e-02
I0209 05:08:27.399409 22542570456896 run_lib.py:146] step: 165500, eval_loss: 2.64310e-02
I0209 05:08:44.810591 22542570456896 run_lib.py:133] step: 165550, training_loss: 2.54027e-02
I0209 05:09:02.273217 22542570456896 run_lib.py:133] step: 165600, training_loss: 3.16429e-02
I0209 05:09:02.449313 22542570456896 run_lib.py:146] step: 165600, eval_loss: 2.94325e-02
I0209 05:09:20.113012 22542570456896 run_lib.py:133] step: 165650, training_loss: 3.34786e-02
I0209 05:09:37.542252 22542570456896 run_lib.py:133] step: 165700, training_loss: 2.09617e-02
I0209 05:09:37.702308 22542570456896 run_lib.py:146] step: 165700, eval_loss: 2.57882e-02
I0209 05:09:55.144009 22542570456896 run_lib.py:133] step: 165750, training_loss: 3.13984e-02
I0209 05:10:12.717800 22542570456896 run_lib.py:133] step: 165800, training_loss: 2.78296e-02
I0209 05:10:12.874055 22542570456896 run_lib.py:146] step: 165800, eval_loss: 2.29399e-02
I0209 05:10:30.313033 22542570456896 run_lib.py:133] step: 165850, training_loss: 2.84213e-02
I0209 05:10:47.803454 22542570456896 run_lib.py:133] step: 165900, training_loss: 2.91474e-02
I0209 05:10:47.957226 22542570456896 run_lib.py:146] step: 165900, eval_loss: 3.10082e-02
I0209 05:11:05.505023 22542570456896 run_lib.py:133] step: 165950, training_loss: 2.36465e-02
I0209 05:11:22.952866 22542570456896 run_lib.py:133] step: 166000, training_loss: 2.52116e-02
I0209 05:11:23.105379 22542570456896 run_lib.py:146] step: 166000, eval_loss: 3.03304e-02
I0209 05:11:40.509646 22542570456896 run_lib.py:133] step: 166050, training_loss: 2.57932e-02
I0209 05:11:57.899850 22542570456896 run_lib.py:133] step: 166100, training_loss: 3.19472e-02
I0209 05:11:58.058579 22542570456896 run_lib.py:146] step: 166100, eval_loss: 2.73167e-02
I0209 05:12:15.650558 22542570456896 run_lib.py:133] step: 166150, training_loss: 3.07598e-02
I0209 05:12:33.189399 22542570456896 run_lib.py:133] step: 166200, training_loss: 3.56225e-02
I0209 05:12:33.344772 22542570456896 run_lib.py:146] step: 166200, eval_loss: 2.67755e-02
I0209 05:12:50.816022 22542570456896 run_lib.py:133] step: 166250, training_loss: 2.77472e-02
I0209 05:13:08.248336 22542570456896 run_lib.py:133] step: 166300, training_loss: 3.01663e-02
I0209 05:13:08.400839 22542570456896 run_lib.py:146] step: 166300, eval_loss: 3.21305e-02
I0209 05:13:26.044970 22542570456896 run_lib.py:133] step: 166350, training_loss: 3.07603e-02
I0209 05:13:43.477349 22542570456896 run_lib.py:133] step: 166400, training_loss: 2.87047e-02
I0209 05:13:43.628402 22542570456896 run_lib.py:146] step: 166400, eval_loss: 3.58673e-02
I0209 05:14:01.194086 22542570456896 run_lib.py:133] step: 166450, training_loss: 2.53097e-02
I0209 05:14:18.643233 22542570456896 run_lib.py:133] step: 166500, training_loss: 2.98996e-02
I0209 05:14:18.809535 22542570456896 run_lib.py:146] step: 166500, eval_loss: 2.49675e-02
I0209 05:14:36.477163 22542570456896 run_lib.py:133] step: 166550, training_loss: 3.05610e-02
I0209 05:14:53.907343 22542570456896 run_lib.py:133] step: 166600, training_loss: 3.47366e-02
I0209 05:14:54.064999 22542570456896 run_lib.py:146] step: 166600, eval_loss: 3.21637e-02
I0209 05:15:11.614567 22542570456896 run_lib.py:133] step: 166650, training_loss: 2.89038e-02
I0209 05:15:29.027908 22542570456896 run_lib.py:133] step: 166700, training_loss: 3.62200e-02
I0209 05:15:29.192405 22542570456896 run_lib.py:146] step: 166700, eval_loss: 2.70774e-02
I0209 05:15:46.652982 22542570456896 run_lib.py:133] step: 166750, training_loss: 2.80824e-02
I0209 05:16:04.247837 22542570456896 run_lib.py:133] step: 166800, training_loss: 2.77951e-02
I0209 05:16:04.404746 22542570456896 run_lib.py:146] step: 166800, eval_loss: 2.80628e-02
I0209 05:16:21.858659 22542570456896 run_lib.py:133] step: 166850, training_loss: 2.81065e-02
I0209 05:16:39.290428 22542570456896 run_lib.py:133] step: 166900, training_loss: 2.50381e-02
I0209 05:16:39.445075 22542570456896 run_lib.py:146] step: 166900, eval_loss: 3.12805e-02
I0209 05:16:57.048122 22542570456896 run_lib.py:133] step: 166950, training_loss: 2.37525e-02
I0209 05:17:14.506344 22542570456896 run_lib.py:133] step: 167000, training_loss: 2.86714e-02
I0209 05:17:14.676523 22542570456896 run_lib.py:146] step: 167000, eval_loss: 2.34146e-02
I0209 05:17:32.290280 22542570456896 run_lib.py:133] step: 167050, training_loss: 2.69524e-02
I0209 05:17:49.735518 22542570456896 run_lib.py:133] step: 167100, training_loss: 2.19400e-02
I0209 05:17:49.892340 22542570456896 run_lib.py:146] step: 167100, eval_loss: 2.85428e-02
I0209 05:18:07.321668 22542570456896 run_lib.py:133] step: 167150, training_loss: 2.80020e-02
I0209 05:18:24.955099 22542570456896 run_lib.py:133] step: 167200, training_loss: 2.60035e-02
I0209 05:18:25.111406 22542570456896 run_lib.py:146] step: 167200, eval_loss: 2.89078e-02
I0209 05:18:42.513585 22542570456896 run_lib.py:133] step: 167250, training_loss: 2.73913e-02
I0209 05:18:59.960987 22542570456896 run_lib.py:133] step: 167300, training_loss: 2.35571e-02
I0209 05:19:00.116630 22542570456896 run_lib.py:146] step: 167300, eval_loss: 3.13576e-02
I0209 05:19:17.580406 22542570456896 run_lib.py:133] step: 167350, training_loss: 1.75582e-02
I0209 05:19:35.173534 22542570456896 run_lib.py:133] step: 167400, training_loss: 2.92927e-02
I0209 05:19:35.331362 22542570456896 run_lib.py:146] step: 167400, eval_loss: 2.58250e-02
I0209 05:19:52.768598 22542570456896 run_lib.py:133] step: 167450, training_loss: 3.65415e-02
I0209 05:20:10.282295 22542570456896 run_lib.py:133] step: 167500, training_loss: 2.66309e-02
I0209 05:20:10.438031 22542570456896 run_lib.py:146] step: 167500, eval_loss: 2.95647e-02
I0209 05:20:27.905706 22542570456896 run_lib.py:133] step: 167550, training_loss: 2.78551e-02
I0209 05:20:45.341385 22542570456896 run_lib.py:133] step: 167600, training_loss: 3.59788e-02
I0209 05:20:45.501566 22542570456896 run_lib.py:146] step: 167600, eval_loss: 2.32626e-02
I0209 05:21:03.134674 22542570456896 run_lib.py:133] step: 167650, training_loss: 2.29061e-02
I0209 05:21:20.602402 22542570456896 run_lib.py:133] step: 167700, training_loss: 2.54592e-02
I0209 05:21:20.758225 22542570456896 run_lib.py:146] step: 167700, eval_loss: 2.86376e-02
I0209 05:21:38.200162 22542570456896 run_lib.py:133] step: 167750, training_loss: 2.57685e-02
I0209 05:21:55.620889 22542570456896 run_lib.py:133] step: 167800, training_loss: 2.75289e-02
I0209 05:21:55.781195 22542570456896 run_lib.py:146] step: 167800, eval_loss: 2.56203e-02
I0209 05:22:13.433725 22542570456896 run_lib.py:133] step: 167850, training_loss: 2.82038e-02
I0209 05:22:30.845960 22542570456896 run_lib.py:133] step: 167900, training_loss: 1.86785e-02
I0209 05:22:30.999283 22542570456896 run_lib.py:146] step: 167900, eval_loss: 3.14775e-02
I0209 05:22:48.598647 22542570456896 run_lib.py:133] step: 167950, training_loss: 2.69997e-02
I0209 05:23:06.011447 22542570456896 run_lib.py:133] step: 168000, training_loss: 2.62557e-02
I0209 05:23:06.174617 22542570456896 run_lib.py:146] step: 168000, eval_loss: 2.93779e-02
I0209 05:23:23.716774 22542570456896 run_lib.py:133] step: 168050, training_loss: 2.59055e-02
I0209 05:23:41.113439 22542570456896 run_lib.py:133] step: 168100, training_loss: 3.59672e-02
I0209 05:23:41.282295 22542570456896 run_lib.py:146] step: 168100, eval_loss: 2.07778e-02
I0209 05:23:58.737815 22542570456896 run_lib.py:133] step: 168150, training_loss: 2.86867e-02
I0209 05:24:16.371110 22542570456896 run_lib.py:133] step: 168200, training_loss: 2.87338e-02
I0209 05:24:16.528680 22542570456896 run_lib.py:146] step: 168200, eval_loss: 2.38576e-02
I0209 05:24:33.995796 22542570456896 run_lib.py:133] step: 168250, training_loss: 2.75198e-02
I0209 05:24:51.531875 22542570456896 run_lib.py:133] step: 168300, training_loss: 2.16537e-02
I0209 05:24:51.683362 22542570456896 run_lib.py:146] step: 168300, eval_loss: 3.57372e-02
I0209 05:25:09.085421 22542570456896 run_lib.py:133] step: 168350, training_loss: 2.41898e-02
I0209 05:25:26.526427 22542570456896 run_lib.py:133] step: 168400, training_loss: 2.86269e-02
I0209 05:25:26.695553 22542570456896 run_lib.py:146] step: 168400, eval_loss: 3.59380e-02
I0209 05:25:44.362261 22542570456896 run_lib.py:133] step: 168450, training_loss: 2.87818e-02
I0209 05:26:01.806726 22542570456896 run_lib.py:133] step: 168500, training_loss: 3.01877e-02
I0209 05:26:01.964302 22542570456896 run_lib.py:146] step: 168500, eval_loss: 2.27122e-02
I0209 05:26:19.382368 22542570456896 run_lib.py:133] step: 168550, training_loss: 2.87930e-02
I0209 05:26:36.919363 22542570456896 run_lib.py:133] step: 168600, training_loss: 2.86539e-02
I0209 05:26:37.074231 22542570456896 run_lib.py:146] step: 168600, eval_loss: 2.60753e-02
I0209 05:26:54.487967 22542570456896 run_lib.py:133] step: 168650, training_loss: 3.37214e-02
I0209 05:27:11.978569 22542570456896 run_lib.py:133] step: 168700, training_loss: 2.88021e-02
I0209 05:27:12.319495 22542570456896 run_lib.py:146] step: 168700, eval_loss: 2.47159e-02
I0209 05:27:29.790122 22542570456896 run_lib.py:133] step: 168750, training_loss: 2.54723e-02
I0209 05:27:47.172948 22542570456896 run_lib.py:133] step: 168800, training_loss: 3.32593e-02
I0209 05:27:47.326502 22542570456896 run_lib.py:146] step: 168800, eval_loss: 3.28690e-02
I0209 05:28:04.718003 22542570456896 run_lib.py:133] step: 168850, training_loss: 3.44826e-02
I0209 05:28:22.143246 22542570456896 run_lib.py:133] step: 168900, training_loss: 2.49401e-02
I0209 05:28:22.298335 22542570456896 run_lib.py:146] step: 168900, eval_loss: 3.37153e-02
I0209 05:28:39.886722 22542570456896 run_lib.py:133] step: 168950, training_loss: 3.01285e-02
I0209 05:28:57.461858 22542570456896 run_lib.py:133] step: 169000, training_loss: 2.27092e-02
I0209 05:28:57.622371 22542570456896 run_lib.py:146] step: 169000, eval_loss: 2.89025e-02
I0209 05:29:15.032248 22542570456896 run_lib.py:133] step: 169050, training_loss: 3.27122e-02
I0209 05:29:32.466190 22542570456896 run_lib.py:133] step: 169100, training_loss: 2.87185e-02
I0209 05:29:32.627434 22542570456896 run_lib.py:146] step: 169100, eval_loss: 3.00309e-02
I0209 05:29:50.245992 22542570456896 run_lib.py:133] step: 169150, training_loss: 3.42051e-02
I0209 05:30:07.712179 22542570456896 run_lib.py:133] step: 169200, training_loss: 3.08375e-02
I0209 05:30:07.879354 22542570456896 run_lib.py:146] step: 169200, eval_loss: 2.74791e-02
I0209 05:30:25.328501 22542570456896 run_lib.py:133] step: 169250, training_loss: 2.73594e-02
I0209 05:30:42.823560 22542570456896 run_lib.py:133] step: 169300, training_loss: 3.30470e-02
I0209 05:30:42.977664 22542570456896 run_lib.py:146] step: 169300, eval_loss: 2.80594e-02
I0209 05:31:00.646461 22542570456896 run_lib.py:133] step: 169350, training_loss: 3.30675e-02
I0209 05:31:18.116779 22542570456896 run_lib.py:133] step: 169400, training_loss: 2.45904e-02
I0209 05:31:18.274543 22542570456896 run_lib.py:146] step: 169400, eval_loss: 2.91268e-02
I0209 05:31:35.846764 22542570456896 run_lib.py:133] step: 169450, training_loss: 2.98076e-02
I0209 05:31:53.299985 22542570456896 run_lib.py:133] step: 169500, training_loss: 2.66742e-02
I0209 05:31:53.468350 22542570456896 run_lib.py:146] step: 169500, eval_loss: 2.24241e-02
I0209 05:32:11.097979 22542570456896 run_lib.py:133] step: 169550, training_loss: 3.04998e-02
I0209 05:32:28.558781 22542570456896 run_lib.py:133] step: 169600, training_loss: 2.53957e-02
I0209 05:32:28.714786 22542570456896 run_lib.py:146] step: 169600, eval_loss: 2.91994e-02
I0209 05:32:46.135071 22542570456896 run_lib.py:133] step: 169650, training_loss: 2.99824e-02
I0209 05:33:03.688704 22542570456896 run_lib.py:133] step: 169700, training_loss: 2.74647e-02
I0209 05:33:03.841435 22542570456896 run_lib.py:146] step: 169700, eval_loss: 2.64149e-02
I0209 05:33:21.247362 22542570456896 run_lib.py:133] step: 169750, training_loss: 3.26826e-02
I0209 05:33:38.856696 22542570456896 run_lib.py:133] step: 169800, training_loss: 3.69481e-02
I0209 05:33:39.015582 22542570456896 run_lib.py:146] step: 169800, eval_loss: 3.11532e-02
I0209 05:33:56.463732 22542570456896 run_lib.py:133] step: 169850, training_loss: 2.75729e-02
I0209 05:34:13.913960 22542570456896 run_lib.py:133] step: 169900, training_loss: 2.23519e-02
I0209 05:34:14.073489 22542570456896 run_lib.py:146] step: 169900, eval_loss: 2.43182e-02
I0209 05:34:31.637402 22542570456896 run_lib.py:133] step: 169950, training_loss: 2.37417e-02
I0209 05:34:49.068811 22542570456896 run_lib.py:133] step: 170000, training_loss: 3.44202e-02
I0209 05:34:49.805105 22542570456896 run_lib.py:146] step: 170000, eval_loss: 2.30771e-02
I0209 05:35:10.084692 22542570456896 run_lib.py:133] step: 170050, training_loss: 2.86054e-02
I0209 05:35:27.671074 22542570456896 run_lib.py:133] step: 170100, training_loss: 2.92913e-02
I0209 05:35:27.830695 22542570456896 run_lib.py:146] step: 170100, eval_loss: 2.53862e-02
I0209 05:35:45.257257 22542570456896 run_lib.py:133] step: 170150, training_loss: 2.69228e-02
I0209 05:36:02.713871 22542570456896 run_lib.py:133] step: 170200, training_loss: 3.36149e-02
I0209 05:36:02.869406 22542570456896 run_lib.py:146] step: 170200, eval_loss: 3.40453e-02
I0209 05:36:20.398495 22542570456896 run_lib.py:133] step: 170250, training_loss: 2.77325e-02
I0209 05:36:37.985275 22542570456896 run_lib.py:133] step: 170300, training_loss: 3.17203e-02
I0209 05:36:38.138651 22542570456896 run_lib.py:146] step: 170300, eval_loss: 3.22444e-02
I0209 05:36:55.611233 22542570456896 run_lib.py:133] step: 170350, training_loss: 3.07200e-02
I0209 05:37:13.053962 22542570456896 run_lib.py:133] step: 170400, training_loss: 3.05362e-02
I0209 05:37:13.210349 22542570456896 run_lib.py:146] step: 170400, eval_loss: 2.79546e-02
I0209 05:37:30.815327 22542570456896 run_lib.py:133] step: 170450, training_loss: 2.68080e-02
I0209 05:37:48.242365 22542570456896 run_lib.py:133] step: 170500, training_loss: 2.46501e-02
I0209 05:37:48.400716 22542570456896 run_lib.py:146] step: 170500, eval_loss: 3.18120e-02
I0209 05:38:05.946331 22542570456896 run_lib.py:133] step: 170550, training_loss: 2.57639e-02
I0209 05:38:23.419259 22542570456896 run_lib.py:133] step: 170600, training_loss: 2.51796e-02
I0209 05:38:23.575304 22542570456896 run_lib.py:146] step: 170600, eval_loss: 2.58935e-02
I0209 05:38:41.162688 22542570456896 run_lib.py:133] step: 170650, training_loss: 3.10574e-02
I0209 05:38:58.559177 22542570456896 run_lib.py:133] step: 170700, training_loss: 2.84815e-02
I0209 05:38:58.718169 22542570456896 run_lib.py:146] step: 170700, eval_loss: 2.93134e-02
I0209 05:39:16.142803 22542570456896 run_lib.py:133] step: 170750, training_loss: 2.61071e-02
I0209 05:39:33.692277 22542570456896 run_lib.py:133] step: 170800, training_loss: 2.64317e-02
I0209 05:39:33.844414 22542570456896 run_lib.py:146] step: 170800, eval_loss: 2.18531e-02
I0209 05:39:51.255764 22542570456896 run_lib.py:133] step: 170850, training_loss: 2.55755e-02
I0209 05:40:08.862922 22542570456896 run_lib.py:133] step: 170900, training_loss: 2.89768e-02
I0209 05:40:09.040381 22542570456896 run_lib.py:146] step: 170900, eval_loss: 2.20249e-02
I0209 05:40:26.489557 22542570456896 run_lib.py:133] step: 170950, training_loss: 3.31013e-02
I0209 05:40:43.933144 22542570456896 run_lib.py:133] step: 171000, training_loss: 3.33312e-02
I0209 05:40:44.096922 22542570456896 run_lib.py:146] step: 171000, eval_loss: 3.64932e-02
I0209 05:41:01.725981 22542570456896 run_lib.py:133] step: 171050, training_loss: 3.02146e-02
I0209 05:41:19.136011 22542570456896 run_lib.py:133] step: 171100, training_loss: 2.30535e-02
I0209 05:41:19.293396 22542570456896 run_lib.py:146] step: 171100, eval_loss: 3.13352e-02
I0209 05:41:36.696349 22542570456896 run_lib.py:133] step: 171150, training_loss: 2.92106e-02
I0209 05:41:54.166050 22542570456896 run_lib.py:133] step: 171200, training_loss: 2.52540e-02
I0209 05:41:54.327095 22542570456896 run_lib.py:146] step: 171200, eval_loss: 2.92987e-02
I0209 05:42:12.001859 22542570456896 run_lib.py:133] step: 171250, training_loss: 2.81161e-02
I0209 05:42:29.373219 22542570456896 run_lib.py:133] step: 171300, training_loss: 3.38744e-02
I0209 05:42:29.528432 22542570456896 run_lib.py:146] step: 171300, eval_loss: 2.64154e-02
I0209 05:42:46.997689 22542570456896 run_lib.py:133] step: 171350, training_loss: 2.88566e-02
I0209 05:43:04.401916 22542570456896 run_lib.py:133] step: 171400, training_loss: 2.83649e-02
I0209 05:43:04.566681 22542570456896 run_lib.py:146] step: 171400, eval_loss: 2.62756e-02
I0209 05:43:22.059867 22542570456896 run_lib.py:133] step: 171450, training_loss: 2.95187e-02
I0209 05:43:39.490924 22542570456896 run_lib.py:133] step: 171500, training_loss: 3.57937e-02
I0209 05:43:39.649519 22542570456896 run_lib.py:146] step: 171500, eval_loss: 3.02224e-02
I0209 05:43:57.237361 22542570456896 run_lib.py:133] step: 171550, training_loss: 2.38091e-02
I0209 05:44:14.714044 22542570456896 run_lib.py:133] step: 171600, training_loss: 2.08645e-02
I0209 05:44:14.868182 22542570456896 run_lib.py:146] step: 171600, eval_loss: 2.68826e-02
I0209 05:44:32.283159 22542570456896 run_lib.py:133] step: 171650, training_loss: 3.35520e-02
I0209 05:44:49.693442 22542570456896 run_lib.py:133] step: 171700, training_loss: 2.68264e-02
I0209 05:44:49.850316 22542570456896 run_lib.py:146] step: 171700, eval_loss: 3.53245e-02
I0209 05:45:07.461569 22542570456896 run_lib.py:133] step: 171750, training_loss: 2.76136e-02
I0209 05:45:24.853794 22542570456896 run_lib.py:133] step: 171800, training_loss: 2.60655e-02
I0209 05:45:25.007241 22542570456896 run_lib.py:146] step: 171800, eval_loss: 3.04168e-02
I0209 05:45:42.590444 22542570456896 run_lib.py:133] step: 171850, training_loss: 2.74042e-02
I0209 05:46:00.024210 22542570456896 run_lib.py:133] step: 171900, training_loss: 3.51498e-02
I0209 05:46:00.184053 22542570456896 run_lib.py:146] step: 171900, eval_loss: 1.68322e-02
I0209 05:46:17.749009 22542570456896 run_lib.py:133] step: 171950, training_loss: 1.98005e-02
I0209 05:46:35.279312 22542570456896 run_lib.py:133] step: 172000, training_loss: 2.94081e-02
I0209 05:46:35.435533 22542570456896 run_lib.py:146] step: 172000, eval_loss: 3.19539e-02
I0209 05:46:53.077307 22542570456896 run_lib.py:133] step: 172050, training_loss: 3.34112e-02
I0209 05:47:10.490286 22542570456896 run_lib.py:133] step: 172100, training_loss: 3.20348e-02
I0209 05:47:10.642431 22542570456896 run_lib.py:146] step: 172100, eval_loss: 2.55103e-02
I0209 05:47:28.101446 22542570456896 run_lib.py:133] step: 172150, training_loss: 2.34822e-02
I0209 05:47:45.694369 22542570456896 run_lib.py:133] step: 172200, training_loss: 2.31416e-02
I0209 05:47:45.849437 22542570456896 run_lib.py:146] step: 172200, eval_loss: 3.59984e-02
I0209 05:48:03.300461 22542570456896 run_lib.py:133] step: 172250, training_loss: 2.81707e-02
I0209 05:48:20.754586 22542570456896 run_lib.py:133] step: 172300, training_loss: 3.19457e-02
I0209 05:48:20.925127 22542570456896 run_lib.py:146] step: 172300, eval_loss: 3.34432e-02
I0209 05:48:38.556181 22542570456896 run_lib.py:133] step: 172350, training_loss: 3.59991e-02
I0209 05:48:56.126323 22542570456896 run_lib.py:133] step: 172400, training_loss: 2.95844e-02
I0209 05:48:56.285491 22542570456896 run_lib.py:146] step: 172400, eval_loss: 2.67694e-02
I0209 05:49:13.712342 22542570456896 run_lib.py:133] step: 172450, training_loss: 2.96463e-02
I0209 05:49:31.142844 22542570456896 run_lib.py:133] step: 172500, training_loss: 2.29006e-02
I0209 05:49:31.308441 22542570456896 run_lib.py:146] step: 172500, eval_loss: 2.90111e-02
I0209 05:49:48.766968 22542570456896 run_lib.py:133] step: 172550, training_loss: 2.87400e-02
I0209 05:50:06.404652 22542570456896 run_lib.py:133] step: 172600, training_loss: 2.67599e-02
I0209 05:50:06.564869 22542570456896 run_lib.py:146] step: 172600, eval_loss: 2.57959e-02
I0209 05:50:24.005066 22542570456896 run_lib.py:133] step: 172650, training_loss: 2.65308e-02
I0209 05:50:41.427160 22542570456896 run_lib.py:133] step: 172700, training_loss: 3.07036e-02
I0209 05:50:41.580879 22542570456896 run_lib.py:146] step: 172700, eval_loss: 2.58794e-02
I0209 05:50:59.026709 22542570456896 run_lib.py:133] step: 172750, training_loss: 3.23229e-02
I0209 05:51:16.591650 22542570456896 run_lib.py:133] step: 172800, training_loss: 2.67310e-02
I0209 05:51:16.771850 22542570456896 run_lib.py:146] step: 172800, eval_loss: 2.97069e-02
I0209 05:51:34.258990 22542570456896 run_lib.py:133] step: 172850, training_loss: 2.77468e-02
I0209 05:51:51.796036 22542570456896 run_lib.py:133] step: 172900, training_loss: 2.51502e-02
I0209 05:51:51.954599 22542570456896 run_lib.py:146] step: 172900, eval_loss: 2.99056e-02
I0209 05:52:09.336535 22542570456896 run_lib.py:133] step: 172950, training_loss: 2.55914e-02
I0209 05:52:26.769908 22542570456896 run_lib.py:133] step: 173000, training_loss: 2.64526e-02
I0209 05:52:26.926151 22542570456896 run_lib.py:146] step: 173000, eval_loss: 3.13151e-02
I0209 05:52:44.504395 22542570456896 run_lib.py:133] step: 173050, training_loss: 2.97866e-02
I0209 05:53:02.036025 22542570456896 run_lib.py:133] step: 173100, training_loss: 2.87935e-02
I0209 05:53:02.197177 22542570456896 run_lib.py:146] step: 173100, eval_loss: 2.49183e-02
I0209 05:53:19.627653 22542570456896 run_lib.py:133] step: 173150, training_loss: 3.12335e-02
I0209 05:53:37.102089 22542570456896 run_lib.py:133] step: 173200, training_loss: 3.09949e-02
I0209 05:53:37.257449 22542570456896 run_lib.py:146] step: 173200, eval_loss: 3.40076e-02
I0209 05:53:54.826453 22542570456896 run_lib.py:133] step: 173250, training_loss: 2.86153e-02
I0209 05:54:12.245815 22542570456896 run_lib.py:133] step: 173300, training_loss: 3.83584e-02
I0209 05:54:12.407748 22542570456896 run_lib.py:146] step: 173300, eval_loss: 2.99594e-02
I0209 05:54:30.008667 22542570456896 run_lib.py:133] step: 173350, training_loss: 2.34310e-02
I0209 05:54:47.521736 22542570456896 run_lib.py:133] step: 173400, training_loss: 2.70987e-02
I0209 05:54:47.679501 22542570456896 run_lib.py:146] step: 173400, eval_loss: 2.53690e-02
I0209 05:55:05.256246 22542570456896 run_lib.py:133] step: 173450, training_loss: 3.14788e-02
I0209 05:55:22.637525 22542570456896 run_lib.py:133] step: 173500, training_loss: 2.93943e-02
I0209 05:55:22.796086 22542570456896 run_lib.py:146] step: 173500, eval_loss: 3.23313e-02
I0209 05:55:40.170732 22542570456896 run_lib.py:133] step: 173550, training_loss: 2.91512e-02
I0209 05:55:57.716493 22542570456896 run_lib.py:133] step: 173600, training_loss: 2.97213e-02
I0209 05:55:57.874374 22542570456896 run_lib.py:146] step: 173600, eval_loss: 2.36463e-02
I0209 05:56:15.295603 22542570456896 run_lib.py:133] step: 173650, training_loss: 3.20799e-02
I0209 05:56:32.908450 22542570456896 run_lib.py:133] step: 173700, training_loss: 2.60701e-02
I0209 05:56:33.083570 22542570456896 run_lib.py:146] step: 173700, eval_loss: 2.64467e-02
I0209 05:56:50.535855 22542570456896 run_lib.py:133] step: 173750, training_loss: 2.40597e-02
I0209 05:57:07.948732 22542570456896 run_lib.py:133] step: 173800, training_loss: 2.27415e-02
I0209 05:57:08.107704 22542570456896 run_lib.py:146] step: 173800, eval_loss: 2.49552e-02
I0209 05:57:25.690334 22542570456896 run_lib.py:133] step: 173850, training_loss: 3.27454e-02
I0209 05:57:43.085386 22542570456896 run_lib.py:133] step: 173900, training_loss: 2.51007e-02
I0209 05:57:43.241463 22542570456896 run_lib.py:146] step: 173900, eval_loss: 3.14789e-02
I0209 05:58:00.686272 22542570456896 run_lib.py:133] step: 173950, training_loss: 2.41699e-02
I0209 05:58:18.363264 22542570456896 run_lib.py:133] step: 174000, training_loss: 2.37743e-02
I0209 05:58:18.519571 22542570456896 run_lib.py:146] step: 174000, eval_loss: 2.28104e-02
I0209 05:58:35.950372 22542570456896 run_lib.py:133] step: 174050, training_loss: 2.42928e-02
I0209 05:58:53.330615 22542570456896 run_lib.py:133] step: 174100, training_loss: 2.18500e-02
I0209 05:58:53.482444 22542570456896 run_lib.py:146] step: 174100, eval_loss: 3.23519e-02
I0209 05:59:10.935762 22542570456896 run_lib.py:133] step: 174150, training_loss: 3.17307e-02
I0209 05:59:28.354432 22542570456896 run_lib.py:133] step: 174200, training_loss: 3.13944e-02
I0209 05:59:28.510598 22542570456896 run_lib.py:146] step: 174200, eval_loss: 2.77733e-02
I0209 05:59:45.979168 22542570456896 run_lib.py:133] step: 174250, training_loss: 2.81857e-02
I0209 06:00:03.420291 22542570456896 run_lib.py:133] step: 174300, training_loss: 2.34934e-02
I0209 06:00:03.578391 22542570456896 run_lib.py:146] step: 174300, eval_loss: 2.70419e-02
I0209 06:00:21.174766 22542570456896 run_lib.py:133] step: 174350, training_loss: 2.91726e-02
I0209 06:00:38.671472 22542570456896 run_lib.py:133] step: 174400, training_loss: 2.34349e-02
I0209 06:00:38.828133 22542570456896 run_lib.py:146] step: 174400, eval_loss: 2.68124e-02
I0209 06:00:56.275915 22542570456896 run_lib.py:133] step: 174450, training_loss: 2.02193e-02
I0209 06:01:13.679881 22542570456896 run_lib.py:133] step: 174500, training_loss: 2.46346e-02
I0209 06:01:13.832357 22542570456896 run_lib.py:146] step: 174500, eval_loss: 3.07522e-02
I0209 06:01:31.381861 22542570456896 run_lib.py:133] step: 174550, training_loss: 2.87771e-02
I0209 06:01:48.836370 22542570456896 run_lib.py:133] step: 174600, training_loss: 2.36523e-02
I0209 06:01:48.992567 22542570456896 run_lib.py:146] step: 174600, eval_loss: 2.62885e-02
I0209 06:02:06.591981 22542570456896 run_lib.py:133] step: 174650, training_loss: 2.67172e-02
I0209 06:02:23.998505 22542570456896 run_lib.py:133] step: 174700, training_loss: 2.99265e-02
I0209 06:02:24.156638 22542570456896 run_lib.py:146] step: 174700, eval_loss: 3.31451e-02
I0209 06:02:41.709959 22542570456896 run_lib.py:133] step: 174750, training_loss: 2.99522e-02
I0209 06:02:59.139466 22542570456896 run_lib.py:133] step: 174800, training_loss: 2.35429e-02
I0209 06:02:59.294660 22542570456896 run_lib.py:146] step: 174800, eval_loss: 3.03045e-02
I0209 06:03:16.877086 22542570456896 run_lib.py:133] step: 174850, training_loss: 2.87835e-02
I0209 06:03:34.312720 22542570456896 run_lib.py:133] step: 174900, training_loss: 2.61913e-02
I0209 06:03:34.468190 22542570456896 run_lib.py:146] step: 174900, eval_loss: 3.25039e-02
I0209 06:03:51.917167 22542570456896 run_lib.py:133] step: 174950, training_loss: 2.61530e-02
I0209 06:04:09.535378 22542570456896 run_lib.py:133] step: 175000, training_loss: 2.65889e-02
I0209 06:04:09.687457 22542570456896 run_lib.py:146] step: 175000, eval_loss: 3.35288e-02
I0209 06:04:27.079760 22542570456896 run_lib.py:133] step: 175050, training_loss: 2.72411e-02
I0209 06:04:44.543210 22542570456896 run_lib.py:133] step: 175100, training_loss: 2.45259e-02
I0209 06:04:44.706673 22542570456896 run_lib.py:146] step: 175100, eval_loss: 2.71932e-02
I0209 06:05:02.317505 22542570456896 run_lib.py:133] step: 175150, training_loss: 2.76609e-02
I0209 06:05:19.778094 22542570456896 run_lib.py:133] step: 175200, training_loss: 2.78707e-02
I0209 06:05:19.936231 22542570456896 run_lib.py:146] step: 175200, eval_loss: 3.05496e-02
I0209 06:05:37.537297 22542570456896 run_lib.py:133] step: 175250, training_loss: 2.18944e-02
I0209 06:05:54.967699 22542570456896 run_lib.py:133] step: 175300, training_loss: 3.05600e-02
I0209 06:05:55.124146 22542570456896 run_lib.py:146] step: 175300, eval_loss: 2.92780e-02
I0209 06:06:12.546471 22542570456896 run_lib.py:133] step: 175350, training_loss: 2.99364e-02
I0209 06:06:30.144666 22542570456896 run_lib.py:133] step: 175400, training_loss: 2.85585e-02
I0209 06:06:30.304592 22542570456896 run_lib.py:146] step: 175400, eval_loss: 2.85334e-02
I0209 06:06:47.757940 22542570456896 run_lib.py:133] step: 175450, training_loss: 2.96097e-02
I0209 06:07:05.184141 22542570456896 run_lib.py:133] step: 175500, training_loss: 2.58712e-02
I0209 06:07:05.333906 22542570456896 run_lib.py:146] step: 175500, eval_loss: 2.74724e-02
I0209 06:07:22.786057 22542570456896 run_lib.py:133] step: 175550, training_loss: 2.93450e-02
I0209 06:07:40.465316 22542570456896 run_lib.py:133] step: 175600, training_loss: 2.30354e-02
I0209 06:07:40.622318 22542570456896 run_lib.py:146] step: 175600, eval_loss: 2.69781e-02
I0209 06:07:58.020421 22542570456896 run_lib.py:133] step: 175650, training_loss: 3.08730e-02
I0209 06:08:15.514749 22542570456896 run_lib.py:133] step: 175700, training_loss: 2.50620e-02
I0209 06:08:15.690341 22542570456896 run_lib.py:146] step: 175700, eval_loss: 3.05387e-02
I0209 06:08:33.167604 22542570456896 run_lib.py:133] step: 175750, training_loss: 2.39435e-02
I0209 06:08:50.576705 22542570456896 run_lib.py:133] step: 175800, training_loss: 2.70332e-02
I0209 06:08:50.737298 22542570456896 run_lib.py:146] step: 175800, eval_loss: 3.66252e-02
I0209 06:09:08.361999 22542570456896 run_lib.py:133] step: 175850, training_loss: 3.06831e-02
I0209 06:09:25.857149 22542570456896 run_lib.py:133] step: 175900, training_loss: 2.60627e-02
I0209 06:09:26.011252 22542570456896 run_lib.py:146] step: 175900, eval_loss: 2.56182e-02
I0209 06:09:43.463809 22542570456896 run_lib.py:133] step: 175950, training_loss: 2.85588e-02
I0209 06:10:00.970380 22542570456896 run_lib.py:133] step: 176000, training_loss: 2.75002e-02
I0209 06:10:01.126285 22542570456896 run_lib.py:146] step: 176000, eval_loss: 2.98267e-02
I0209 06:10:18.779860 22542570456896 run_lib.py:133] step: 176050, training_loss: 3.05314e-02
I0209 06:10:36.233590 22542570456896 run_lib.py:133] step: 176100, training_loss: 2.32651e-02
I0209 06:10:36.391405 22542570456896 run_lib.py:146] step: 176100, eval_loss: 2.60223e-02
I0209 06:10:53.962216 22542570456896 run_lib.py:133] step: 176150, training_loss: 2.76367e-02
I0209 06:11:11.365123 22542570456896 run_lib.py:133] step: 176200, training_loss: 2.95485e-02
I0209 06:11:11.519006 22542570456896 run_lib.py:146] step: 176200, eval_loss: 3.11071e-02
I0209 06:11:29.095218 22542570456896 run_lib.py:133] step: 176250, training_loss: 4.02236e-02
I0209 06:11:46.590720 22542570456896 run_lib.py:133] step: 176300, training_loss: 3.05253e-02
I0209 06:11:46.746805 22542570456896 run_lib.py:146] step: 176300, eval_loss: 3.22775e-02
I0209 06:12:04.168035 22542570456896 run_lib.py:133] step: 176350, training_loss: 2.79128e-02
I0209 06:12:21.736510 22542570456896 run_lib.py:133] step: 176400, training_loss: 3.25660e-02
I0209 06:12:21.889938 22542570456896 run_lib.py:146] step: 176400, eval_loss: 2.65568e-02
I0209 06:12:39.303509 22542570456896 run_lib.py:133] step: 176450, training_loss: 3.53182e-02
I0209 06:12:56.835797 22542570456896 run_lib.py:133] step: 176500, training_loss: 2.92117e-02
I0209 06:12:56.988314 22542570456896 run_lib.py:146] step: 176500, eval_loss: 3.26429e-02
I0209 06:13:14.420098 22542570456896 run_lib.py:133] step: 176550, training_loss: 2.61187e-02
I0209 06:13:31.837048 22542570456896 run_lib.py:133] step: 176600, training_loss: 2.82510e-02
I0209 06:13:32.014269 22542570456896 run_lib.py:146] step: 176600, eval_loss: 2.77402e-02
I0209 06:13:49.571529 22542570456896 run_lib.py:133] step: 176650, training_loss: 3.71344e-02
I0209 06:14:06.940993 22542570456896 run_lib.py:133] step: 176700, training_loss: 3.15976e-02
I0209 06:14:07.096539 22542570456896 run_lib.py:146] step: 176700, eval_loss: 2.89325e-02
I0209 06:14:24.554292 22542570456896 run_lib.py:133] step: 176750, training_loss: 2.70712e-02
I0209 06:14:42.133303 22542570456896 run_lib.py:133] step: 176800, training_loss: 2.80654e-02
I0209 06:14:42.289293 22542570456896 run_lib.py:146] step: 176800, eval_loss: 3.03067e-02
I0209 06:14:59.724953 22542570456896 run_lib.py:133] step: 176850, training_loss: 3.66398e-02
I0209 06:15:17.180899 22542570456896 run_lib.py:133] step: 176900, training_loss: 3.39973e-02
I0209 06:15:17.524985 22542570456896 run_lib.py:146] step: 176900, eval_loss: 2.97650e-02
I0209 06:15:34.991045 22542570456896 run_lib.py:133] step: 176950, training_loss: 2.22277e-02
I0209 06:15:52.436800 22542570456896 run_lib.py:133] step: 177000, training_loss: 2.57378e-02
I0209 06:15:52.592556 22542570456896 run_lib.py:146] step: 177000, eval_loss: 2.78554e-02
I0209 06:16:09.992446 22542570456896 run_lib.py:133] step: 177050, training_loss: 2.64478e-02
I0209 06:16:27.375608 22542570456896 run_lib.py:133] step: 177100, training_loss: 2.79148e-02
I0209 06:16:27.532436 22542570456896 run_lib.py:146] step: 177100, eval_loss: 3.14972e-02
I0209 06:16:45.140060 22542570456896 run_lib.py:133] step: 177150, training_loss: 3.04513e-02
I0209 06:17:02.716794 22542570456896 run_lib.py:133] step: 177200, training_loss: 2.66387e-02
I0209 06:17:02.872559 22542570456896 run_lib.py:146] step: 177200, eval_loss: 3.38287e-02
I0209 06:17:20.297610 22542570456896 run_lib.py:133] step: 177250, training_loss: 3.27933e-02
I0209 06:17:37.730056 22542570456896 run_lib.py:133] step: 177300, training_loss: 2.31180e-02
I0209 06:17:37.886323 22542570456896 run_lib.py:146] step: 177300, eval_loss: 3.11632e-02
I0209 06:17:55.446690 22542570456896 run_lib.py:133] step: 177350, training_loss: 3.31432e-02
I0209 06:18:12.972038 22542570456896 run_lib.py:133] step: 177400, training_loss: 3.06030e-02
I0209 06:18:13.124601 22542570456896 run_lib.py:146] step: 177400, eval_loss: 3.22728e-02
I0209 06:18:30.616252 22542570456896 run_lib.py:133] step: 177450, training_loss: 2.61757e-02
I0209 06:18:48.037934 22542570456896 run_lib.py:133] step: 177500, training_loss: 2.47339e-02
I0209 06:18:48.193449 22542570456896 run_lib.py:146] step: 177500, eval_loss: 2.95725e-02
I0209 06:19:05.812637 22542570456896 run_lib.py:133] step: 177550, training_loss: 2.64635e-02
I0209 06:19:23.234116 22542570456896 run_lib.py:133] step: 177600, training_loss: 2.91242e-02
I0209 06:19:23.392529 22542570456896 run_lib.py:146] step: 177600, eval_loss: 2.51258e-02
I0209 06:19:40.998341 22542570456896 run_lib.py:133] step: 177650, training_loss: 3.10355e-02
I0209 06:19:58.473711 22542570456896 run_lib.py:133] step: 177700, training_loss: 3.02352e-02
I0209 06:19:58.628229 22542570456896 run_lib.py:146] step: 177700, eval_loss: 3.09442e-02
I0209 06:20:16.241748 22542570456896 run_lib.py:133] step: 177750, training_loss: 3.05169e-02
I0209 06:20:33.653418 22542570456896 run_lib.py:133] step: 177800, training_loss: 3.03577e-02
I0209 06:20:33.809349 22542570456896 run_lib.py:146] step: 177800, eval_loss: 3.20748e-02
I0209 06:20:51.256994 22542570456896 run_lib.py:133] step: 177850, training_loss: 2.58131e-02
I0209 06:21:08.838038 22542570456896 run_lib.py:133] step: 177900, training_loss: 2.55818e-02
I0209 06:21:08.989300 22542570456896 run_lib.py:146] step: 177900, eval_loss: 2.89754e-02
I0209 06:21:26.394458 22542570456896 run_lib.py:133] step: 177950, training_loss: 1.85489e-02
I0209 06:21:43.939268 22542570456896 run_lib.py:133] step: 178000, training_loss: 3.49353e-02
I0209 06:21:44.113187 22542570456896 run_lib.py:146] step: 178000, eval_loss: 2.83064e-02
I0209 06:22:01.569546 22542570456896 run_lib.py:133] step: 178050, training_loss: 2.57501e-02
I0209 06:22:19.022192 22542570456896 run_lib.py:133] step: 178100, training_loss: 2.46992e-02
I0209 06:22:19.181534 22542570456896 run_lib.py:146] step: 178100, eval_loss: 2.54089e-02
I0209 06:22:36.751287 22542570456896 run_lib.py:133] step: 178150, training_loss: 2.38011e-02
I0209 06:22:54.140195 22542570456896 run_lib.py:133] step: 178200, training_loss: 3.32280e-02
I0209 06:22:54.295040 22542570456896 run_lib.py:146] step: 178200, eval_loss: 3.35198e-02
I0209 06:23:11.719563 22542570456896 run_lib.py:133] step: 178250, training_loss: 2.80898e-02
I0209 06:23:29.143438 22542570456896 run_lib.py:133] step: 178300, training_loss: 2.50869e-02
I0209 06:23:29.298130 22542570456896 run_lib.py:146] step: 178300, eval_loss: 3.04899e-02
I0209 06:23:46.928542 22542570456896 run_lib.py:133] step: 178350, training_loss: 2.50943e-02
I0209 06:24:04.345852 22542570456896 run_lib.py:133] step: 178400, training_loss: 2.86066e-02
I0209 06:24:04.498474 22542570456896 run_lib.py:146] step: 178400, eval_loss: 2.32897e-02
I0209 06:24:22.019716 22542570456896 run_lib.py:133] step: 178450, training_loss: 2.52126e-02
I0209 06:24:39.462517 22542570456896 run_lib.py:133] step: 178500, training_loss: 3.42536e-02
I0209 06:24:39.621569 22542570456896 run_lib.py:146] step: 178500, eval_loss: 3.13712e-02
I0209 06:24:57.029038 22542570456896 run_lib.py:133] step: 178550, training_loss: 2.98269e-02
I0209 06:25:14.473655 22542570456896 run_lib.py:133] step: 178600, training_loss: 2.18608e-02
I0209 06:25:14.637869 22542570456896 run_lib.py:146] step: 178600, eval_loss: 3.17839e-02
I0209 06:25:32.236555 22542570456896 run_lib.py:133] step: 178650, training_loss: 2.93251e-02
I0209 06:25:49.726172 22542570456896 run_lib.py:133] step: 178700, training_loss: 3.51800e-02
I0209 06:25:49.883628 22542570456896 run_lib.py:146] step: 178700, eval_loss: 2.75046e-02
I0209 06:26:07.301817 22542570456896 run_lib.py:133] step: 178750, training_loss: 3.33435e-02
I0209 06:26:24.718945 22542570456896 run_lib.py:133] step: 178800, training_loss: 2.97115e-02
I0209 06:26:24.870208 22542570456896 run_lib.py:146] step: 178800, eval_loss: 2.56773e-02
I0209 06:26:42.442825 22542570456896 run_lib.py:133] step: 178850, training_loss: 2.56961e-02
I0209 06:26:59.936421 22542570456896 run_lib.py:133] step: 178900, training_loss: 2.75664e-02
I0209 06:27:00.104701 22542570456896 run_lib.py:146] step: 178900, eval_loss: 2.88368e-02
I0209 06:27:17.774955 22542570456896 run_lib.py:133] step: 178950, training_loss: 2.91607e-02
I0209 06:27:35.208272 22542570456896 run_lib.py:133] step: 179000, training_loss: 2.95594e-02
I0209 06:27:35.365648 22542570456896 run_lib.py:146] step: 179000, eval_loss: 3.14844e-02
I0209 06:27:52.894926 22542570456896 run_lib.py:133] step: 179050, training_loss: 2.22274e-02
I0209 06:28:10.316802 22542570456896 run_lib.py:133] step: 179100, training_loss: 2.53508e-02
I0209 06:28:10.483287 22542570456896 run_lib.py:146] step: 179100, eval_loss: 2.99395e-02
I0209 06:28:28.062871 22542570456896 run_lib.py:133] step: 179150, training_loss: 3.06053e-02
I0209 06:28:45.557336 22542570456896 run_lib.py:133] step: 179200, training_loss: 2.45089e-02
I0209 06:28:45.721624 22542570456896 run_lib.py:146] step: 179200, eval_loss: 2.90127e-02
I0209 06:29:03.183184 22542570456896 run_lib.py:133] step: 179250, training_loss: 3.04008e-02
I0209 06:29:20.766212 22542570456896 run_lib.py:133] step: 179300, training_loss: 2.90572e-02
I0209 06:29:20.922367 22542570456896 run_lib.py:146] step: 179300, eval_loss: 2.97226e-02
I0209 06:29:38.320490 22542570456896 run_lib.py:133] step: 179350, training_loss: 3.20131e-02
I0209 06:29:55.714980 22542570456896 run_lib.py:133] step: 179400, training_loss: 2.57740e-02
I0209 06:29:55.883191 22542570456896 run_lib.py:146] step: 179400, eval_loss: 2.69056e-02
I0209 06:30:13.529433 22542570456896 run_lib.py:133] step: 179450, training_loss: 3.21949e-02
I0209 06:30:31.127180 22542570456896 run_lib.py:133] step: 179500, training_loss: 3.46569e-02
I0209 06:30:31.293355 22542570456896 run_lib.py:146] step: 179500, eval_loss: 1.99818e-02
I0209 06:30:48.689883 22542570456896 run_lib.py:133] step: 179550, training_loss: 3.02955e-02
I0209 06:31:06.072146 22542570456896 run_lib.py:133] step: 179600, training_loss: 2.65084e-02
I0209 06:31:06.227359 22542570456896 run_lib.py:146] step: 179600, eval_loss: 3.03590e-02
I0209 06:31:23.637393 22542570456896 run_lib.py:133] step: 179650, training_loss: 2.89358e-02
I0209 06:31:41.220000 22542570456896 run_lib.py:133] step: 179700, training_loss: 2.15324e-02
I0209 06:31:41.373627 22542570456896 run_lib.py:146] step: 179700, eval_loss: 3.05889e-02
I0209 06:31:58.854208 22542570456896 run_lib.py:133] step: 179750, training_loss: 2.37395e-02
I0209 06:32:16.259053 22542570456896 run_lib.py:133] step: 179800, training_loss: 2.20530e-02
I0209 06:32:16.410532 22542570456896 run_lib.py:146] step: 179800, eval_loss: 2.69451e-02
I0209 06:32:33.858375 22542570456896 run_lib.py:133] step: 179850, training_loss: 3.26807e-02
I0209 06:32:51.472594 22542570456896 run_lib.py:133] step: 179900, training_loss: 3.15599e-02
I0209 06:32:51.632821 22542570456896 run_lib.py:146] step: 179900, eval_loss: 2.96111e-02
I0209 06:33:09.046780 22542570456896 run_lib.py:133] step: 179950, training_loss: 2.76972e-02
I0209 06:33:26.528300 22542570456896 run_lib.py:133] step: 180000, training_loss: 2.63172e-02
I0209 06:33:27.239914 22542570456896 run_lib.py:146] step: 180000, eval_loss: 3.70604e-02
I0209 06:33:47.419286 22542570456896 run_lib.py:133] step: 180050, training_loss: 2.71037e-02
I0209 06:34:04.836526 22542570456896 run_lib.py:133] step: 180100, training_loss: 2.51655e-02
I0209 06:34:04.992585 22542570456896 run_lib.py:146] step: 180100, eval_loss: 3.34091e-02
I0209 06:34:22.419943 22542570456896 run_lib.py:133] step: 180150, training_loss: 2.80751e-02
I0209 06:34:39.995225 22542570456896 run_lib.py:133] step: 180200, training_loss: 2.54043e-02
I0209 06:34:40.153660 22542570456896 run_lib.py:146] step: 180200, eval_loss: 2.94697e-02
I0209 06:34:57.587880 22542570456896 run_lib.py:133] step: 180250, training_loss: 2.77792e-02
I0209 06:35:15.158270 22542570456896 run_lib.py:133] step: 180300, training_loss: 2.38698e-02
I0209 06:35:15.312668 22542570456896 run_lib.py:146] step: 180300, eval_loss: 2.75172e-02
I0209 06:35:32.761896 22542570456896 run_lib.py:133] step: 180350, training_loss: 2.61668e-02
I0209 06:35:50.224640 22542570456896 run_lib.py:133] step: 180400, training_loss: 2.97748e-02
I0209 06:35:50.380887 22542570456896 run_lib.py:146] step: 180400, eval_loss: 3.13327e-02
I0209 06:36:07.968531 22542570456896 run_lib.py:133] step: 180450, training_loss: 3.60605e-02
I0209 06:36:25.453771 22542570456896 run_lib.py:133] step: 180500, training_loss: 2.56162e-02
I0209 06:36:25.628613 22542570456896 run_lib.py:146] step: 180500, eval_loss: 3.55055e-02
I0209 06:36:43.073281 22542570456896 run_lib.py:133] step: 180550, training_loss: 2.15395e-02
I0209 06:37:00.508191 22542570456896 run_lib.py:133] step: 180600, training_loss: 2.56664e-02
I0209 06:37:00.664744 22542570456896 run_lib.py:146] step: 180600, eval_loss: 3.84773e-02
I0209 06:37:18.276328 22542570456896 run_lib.py:133] step: 180650, training_loss: 2.73493e-02
I0209 06:37:35.666160 22542570456896 run_lib.py:133] step: 180700, training_loss: 2.33579e-02
I0209 06:37:35.821051 22542570456896 run_lib.py:146] step: 180700, eval_loss: 2.88317e-02
I0209 06:37:53.351379 22542570456896 run_lib.py:133] step: 180750, training_loss: 2.48300e-02
I0209 06:38:10.774368 22542570456896 run_lib.py:133] step: 180800, training_loss: 2.27798e-02
I0209 06:38:10.936285 22542570456896 run_lib.py:146] step: 180800, eval_loss: 2.46182e-02
I0209 06:38:28.579319 22542570456896 run_lib.py:133] step: 180850, training_loss: 2.44092e-02
I0209 06:38:45.994866 22542570456896 run_lib.py:133] step: 180900, training_loss: 2.55571e-02
I0209 06:38:46.147413 22542570456896 run_lib.py:146] step: 180900, eval_loss: 2.47393e-02
I0209 06:39:03.565471 22542570456896 run_lib.py:133] step: 180950, training_loss: 1.87079e-02
I0209 06:39:21.175261 22542570456896 run_lib.py:133] step: 181000, training_loss: 2.70198e-02
I0209 06:39:21.333639 22542570456896 run_lib.py:146] step: 181000, eval_loss: 2.71166e-02
I0209 06:39:38.766304 22542570456896 run_lib.py:133] step: 181050, training_loss: 2.87107e-02
I0209 06:39:56.329073 22542570456896 run_lib.py:133] step: 181100, training_loss: 3.35741e-02
I0209 06:39:56.498360 22542570456896 run_lib.py:146] step: 181100, eval_loss: 3.32847e-02
I0209 06:40:13.952031 22542570456896 run_lib.py:133] step: 181150, training_loss: 2.86479e-02
I0209 06:40:31.415755 22542570456896 run_lib.py:133] step: 181200, training_loss: 2.71082e-02
I0209 06:40:31.572511 22542570456896 run_lib.py:146] step: 181200, eval_loss: 2.46657e-02
I0209 06:40:49.189002 22542570456896 run_lib.py:133] step: 181250, training_loss: 2.63338e-02
I0209 06:41:06.611667 22542570456896 run_lib.py:133] step: 181300, training_loss: 2.73072e-02
I0209 06:41:06.763639 22542570456896 run_lib.py:146] step: 181300, eval_loss: 3.54423e-02
I0209 06:41:24.188508 22542570456896 run_lib.py:133] step: 181350, training_loss: 2.62726e-02
I0209 06:41:41.759922 22542570456896 run_lib.py:133] step: 181400, training_loss: 3.27660e-02
I0209 06:41:41.934372 22542570456896 run_lib.py:146] step: 181400, eval_loss: 3.49231e-02
I0209 06:41:59.424295 22542570456896 run_lib.py:133] step: 181450, training_loss: 2.53333e-02
I0209 06:42:16.863706 22542570456896 run_lib.py:133] step: 181500, training_loss: 2.24871e-02
I0209 06:42:17.018307 22542570456896 run_lib.py:146] step: 181500, eval_loss: 2.69652e-02
I0209 06:42:34.558526 22542570456896 run_lib.py:133] step: 181550, training_loss: 3.01608e-02
I0209 06:42:52.036711 22542570456896 run_lib.py:133] step: 181600, training_loss: 2.74063e-02
I0209 06:42:52.193546 22542570456896 run_lib.py:146] step: 181600, eval_loss: 2.81445e-02
I0209 06:43:09.619302 22542570456896 run_lib.py:133] step: 181650, training_loss: 2.96260e-02
I0209 06:43:27.043813 22542570456896 run_lib.py:133] step: 181700, training_loss: 3.09100e-02
I0209 06:43:27.201483 22542570456896 run_lib.py:146] step: 181700, eval_loss: 2.10929e-02
I0209 06:43:44.815011 22542570456896 run_lib.py:133] step: 181750, training_loss: 3.20269e-02
I0209 06:44:02.373010 22542570456896 run_lib.py:133] step: 181800, training_loss: 2.71797e-02
I0209 06:44:02.527325 22542570456896 run_lib.py:146] step: 181800, eval_loss: 3.23744e-02
I0209 06:44:19.963063 22542570456896 run_lib.py:133] step: 181850, training_loss: 3.30576e-02
I0209 06:44:37.393134 22542570456896 run_lib.py:133] step: 181900, training_loss: 3.02433e-02
I0209 06:44:37.551694 22542570456896 run_lib.py:146] step: 181900, eval_loss: 2.98692e-02
I0209 06:44:55.088629 22542570456896 run_lib.py:133] step: 181950, training_loss: 2.54586e-02
I0209 06:45:12.537722 22542570456896 run_lib.py:133] step: 182000, training_loss: 2.92861e-02
I0209 06:45:12.708606 22542570456896 run_lib.py:146] step: 182000, eval_loss: 2.41455e-02
I0209 06:45:30.340792 22542570456896 run_lib.py:133] step: 182050, training_loss: 3.52760e-02
I0209 06:45:47.791171 22542570456896 run_lib.py:133] step: 182100, training_loss: 2.95184e-02
I0209 06:45:47.954766 22542570456896 run_lib.py:146] step: 182100, eval_loss: 2.52479e-02
I0209 06:46:05.583203 22542570456896 run_lib.py:133] step: 182150, training_loss: 3.00513e-02
I0209 06:46:23.006672 22542570456896 run_lib.py:133] step: 182200, training_loss: 2.58504e-02
I0209 06:46:23.159117 22542570456896 run_lib.py:146] step: 182200, eval_loss: 3.47679e-02
I0209 06:46:40.718507 22542570456896 run_lib.py:133] step: 182250, training_loss: 3.41413e-02
I0209 06:46:58.201516 22542570456896 run_lib.py:133] step: 182300, training_loss: 3.24415e-02
I0209 06:46:58.368506 22542570456896 run_lib.py:146] step: 182300, eval_loss: 3.05769e-02
I0209 06:47:15.822105 22542570456896 run_lib.py:133] step: 182350, training_loss: 2.90204e-02
I0209 06:47:33.506680 22542570456896 run_lib.py:133] step: 182400, training_loss: 2.96042e-02
I0209 06:47:33.662573 22542570456896 run_lib.py:146] step: 182400, eval_loss: 2.53450e-02
I0209 06:47:51.092919 22542570456896 run_lib.py:133] step: 182450, training_loss: 2.44702e-02
I0209 06:48:08.505361 22542570456896 run_lib.py:133] step: 182500, training_loss: 2.14044e-02
I0209 06:48:08.661545 22542570456896 run_lib.py:146] step: 182500, eval_loss: 2.72961e-02
I0209 06:48:26.208683 22542570456896 run_lib.py:133] step: 182550, training_loss: 3.05489e-02
I0209 06:48:43.734226 22542570456896 run_lib.py:133] step: 182600, training_loss: 1.78251e-02
I0209 06:48:43.889505 22542570456896 run_lib.py:146] step: 182600, eval_loss: 2.33675e-02
I0209 06:49:01.524191 22542570456896 run_lib.py:133] step: 182650, training_loss: 3.03624e-02
I0209 06:49:18.949956 22542570456896 run_lib.py:133] step: 182700, training_loss: 2.34884e-02
I0209 06:49:19.103394 22542570456896 run_lib.py:146] step: 182700, eval_loss: 2.99455e-02
I0209 06:49:36.547246 22542570456896 run_lib.py:133] step: 182750, training_loss: 2.65892e-02
I0209 06:49:54.134629 22542570456896 run_lib.py:133] step: 182800, training_loss: 2.60889e-02
I0209 06:49:54.304620 22542570456896 run_lib.py:146] step: 182800, eval_loss: 2.81766e-02
I0209 06:50:11.765734 22542570456896 run_lib.py:133] step: 182850, training_loss: 2.87872e-02
I0209 06:50:29.210558 22542570456896 run_lib.py:133] step: 182900, training_loss: 2.38956e-02
I0209 06:50:29.370562 22542570456896 run_lib.py:146] step: 182900, eval_loss: 2.75962e-02
I0209 06:50:46.778011 22542570456896 run_lib.py:133] step: 182950, training_loss: 2.54823e-02
I0209 06:51:04.368545 22542570456896 run_lib.py:133] step: 183000, training_loss: 2.77273e-02
I0209 06:51:04.524087 22542570456896 run_lib.py:146] step: 183000, eval_loss: 3.51670e-02
I0209 06:51:21.933641 22542570456896 run_lib.py:133] step: 183050, training_loss: 2.93373e-02
I0209 06:51:39.449436 22542570456896 run_lib.py:133] step: 183100, training_loss: 2.85041e-02
I0209 06:51:39.606614 22542570456896 run_lib.py:146] step: 183100, eval_loss: 2.73949e-02
I0209 06:51:57.113833 22542570456896 run_lib.py:133] step: 183150, training_loss: 3.18741e-02
I0209 06:52:14.533268 22542570456896 run_lib.py:133] step: 183200, training_loss: 3.20963e-02
I0209 06:52:14.688297 22542570456896 run_lib.py:146] step: 183200, eval_loss: 2.73043e-02
I0209 06:52:32.274414 22542570456896 run_lib.py:133] step: 183250, training_loss: 2.64208e-02
I0209 06:52:49.758910 22542570456896 run_lib.py:133] step: 183300, training_loss: 2.85749e-02
I0209 06:52:49.917708 22542570456896 run_lib.py:146] step: 183300, eval_loss: 2.98995e-02
I0209 06:53:07.302690 22542570456896 run_lib.py:133] step: 183350, training_loss: 2.91922e-02
I0209 06:53:24.732858 22542570456896 run_lib.py:133] step: 183400, training_loss: 2.83452e-02
I0209 06:53:24.899235 22542570456896 run_lib.py:146] step: 183400, eval_loss: 2.56308e-02
I0209 06:53:42.527741 22542570456896 run_lib.py:133] step: 183450, training_loss: 2.36225e-02
I0209 06:53:59.995939 22542570456896 run_lib.py:133] step: 183500, training_loss: 2.94799e-02
I0209 06:54:00.160492 22542570456896 run_lib.py:146] step: 183500, eval_loss: 2.53073e-02
I0209 06:54:17.761589 22542570456896 run_lib.py:133] step: 183550, training_loss: 2.94825e-02
I0209 06:54:35.195972 22542570456896 run_lib.py:133] step: 183600, training_loss: 2.36043e-02
I0209 06:54:35.348162 22542570456896 run_lib.py:146] step: 183600, eval_loss: 3.32839e-02
I0209 06:54:52.938417 22542570456896 run_lib.py:133] step: 183650, training_loss: 2.47380e-02
I0209 06:55:10.392603 22542570456896 run_lib.py:133] step: 183700, training_loss: 2.75237e-02
I0209 06:55:10.553541 22542570456896 run_lib.py:146] step: 183700, eval_loss: 2.97173e-02
I0209 06:55:28.047334 22542570456896 run_lib.py:133] step: 183750, training_loss: 2.89349e-02
I0209 06:55:45.709382 22542570456896 run_lib.py:133] step: 183800, training_loss: 2.11901e-02
I0209 06:55:45.876190 22542570456896 run_lib.py:146] step: 183800, eval_loss: 2.59589e-02
I0209 06:56:03.310254 22542570456896 run_lib.py:133] step: 183850, training_loss: 2.56817e-02
I0209 06:56:20.891419 22542570456896 run_lib.py:133] step: 183900, training_loss: 2.25136e-02
I0209 06:56:21.057146 22542570456896 run_lib.py:146] step: 183900, eval_loss: 3.11767e-02
I0209 06:56:38.522950 22542570456896 run_lib.py:133] step: 183950, training_loss: 3.19137e-02
I0209 06:56:55.997349 22542570456896 run_lib.py:133] step: 184000, training_loss: 2.17740e-02
I0209 06:56:56.153732 22542570456896 run_lib.py:146] step: 184000, eval_loss: 2.37255e-02
I0209 06:57:13.769358 22542570456896 run_lib.py:133] step: 184050, training_loss: 2.87901e-02
I0209 06:57:31.188156 22542570456896 run_lib.py:133] step: 184100, training_loss: 2.95883e-02
I0209 06:57:31.340331 22542570456896 run_lib.py:146] step: 184100, eval_loss: 2.45357e-02
I0209 06:57:48.762151 22542570456896 run_lib.py:133] step: 184150, training_loss: 2.06001e-02
I0209 06:58:06.338711 22542570456896 run_lib.py:133] step: 184200, training_loss: 3.08183e-02
I0209 06:58:06.509662 22542570456896 run_lib.py:146] step: 184200, eval_loss: 3.08580e-02
I0209 06:58:23.994391 22542570456896 run_lib.py:133] step: 184250, training_loss: 3.21216e-02
I0209 06:58:41.497867 22542570456896 run_lib.py:133] step: 184300, training_loss: 2.84110e-02
I0209 06:58:41.849358 22542570456896 run_lib.py:146] step: 184300, eval_loss: 2.55963e-02
I0209 06:58:59.281253 22542570456896 run_lib.py:133] step: 184350, training_loss: 3.30707e-02
I0209 06:59:16.703511 22542570456896 run_lib.py:133] step: 184400, training_loss: 2.35934e-02
I0209 06:59:16.859328 22542570456896 run_lib.py:146] step: 184400, eval_loss: 3.15640e-02
I0209 06:59:34.276576 22542570456896 run_lib.py:133] step: 184450, training_loss: 2.25914e-02
I0209 06:59:51.738504 22542570456896 run_lib.py:133] step: 184500, training_loss: 2.95476e-02
I0209 06:59:51.895708 22542570456896 run_lib.py:146] step: 184500, eval_loss: 3.04368e-02
I0209 07:00:09.564967 22542570456896 run_lib.py:133] step: 184550, training_loss: 2.56577e-02
I0209 07:00:27.028003 22542570456896 run_lib.py:133] step: 184600, training_loss: 3.20277e-02
I0209 07:00:27.178433 22542570456896 run_lib.py:146] step: 184600, eval_loss: 3.13836e-02
I0209 07:00:44.585101 22542570456896 run_lib.py:133] step: 184650, training_loss: 3.20352e-02
I0209 07:01:02.045780 22542570456896 run_lib.py:133] step: 184700, training_loss: 3.88514e-02
I0209 07:01:02.209931 22542570456896 run_lib.py:146] step: 184700, eval_loss: 3.46048e-02
I0209 07:01:19.779385 22542570456896 run_lib.py:133] step: 184750, training_loss: 2.49392e-02
I0209 07:01:37.381454 22542570456896 run_lib.py:133] step: 184800, training_loss: 2.78142e-02
I0209 07:01:37.548194 22542570456896 run_lib.py:146] step: 184800, eval_loss: 2.69023e-02
I0209 07:01:54.989377 22542570456896 run_lib.py:133] step: 184850, training_loss: 2.84124e-02
I0209 07:02:12.392094 22542570456896 run_lib.py:133] step: 184900, training_loss: 3.14450e-02
I0209 07:02:12.547563 22542570456896 run_lib.py:146] step: 184900, eval_loss: 2.68802e-02
I0209 07:02:30.102591 22542570456896 run_lib.py:133] step: 184950, training_loss: 2.74527e-02
I0209 07:02:47.511575 22542570456896 run_lib.py:133] step: 185000, training_loss: 2.65802e-02
I0209 07:02:47.666423 22542570456896 run_lib.py:146] step: 185000, eval_loss: 2.76187e-02
I0209 07:03:05.257652 22542570456896 run_lib.py:133] step: 185050, training_loss: 2.49805e-02
I0209 07:03:22.718484 22542570456896 run_lib.py:133] step: 185100, training_loss: 2.67319e-02
I0209 07:03:22.873519 22542570456896 run_lib.py:146] step: 185100, eval_loss: 2.01414e-02
I0209 07:03:40.570043 22542570456896 run_lib.py:133] step: 185150, training_loss: 2.76281e-02
I0209 07:03:58.020328 22542570456896 run_lib.py:133] step: 185200, training_loss: 2.65326e-02
I0209 07:03:58.179205 22542570456896 run_lib.py:146] step: 185200, eval_loss: 2.54203e-02
I0209 07:04:15.603727 22542570456896 run_lib.py:133] step: 185250, training_loss: 2.74392e-02
I0209 07:04:33.157843 22542570456896 run_lib.py:133] step: 185300, training_loss: 2.42224e-02
I0209 07:04:33.313452 22542570456896 run_lib.py:146] step: 185300, eval_loss: 3.43519e-02
I0209 07:04:50.756998 22542570456896 run_lib.py:133] step: 185350, training_loss: 2.38734e-02
I0209 07:05:08.409543 22542570456896 run_lib.py:133] step: 185400, training_loss: 2.82500e-02
I0209 07:05:08.567181 22542570456896 run_lib.py:146] step: 185400, eval_loss: 2.70807e-02
I0209 07:05:26.025251 22542570456896 run_lib.py:133] step: 185450, training_loss: 2.78086e-02
I0209 07:05:43.478567 22542570456896 run_lib.py:133] step: 185500, training_loss: 2.69700e-02
I0209 07:05:43.632075 22542570456896 run_lib.py:146] step: 185500, eval_loss: 3.55138e-02
I0209 07:06:01.258243 22542570456896 run_lib.py:133] step: 185550, training_loss: 3.04475e-02
I0209 07:06:18.695930 22542570456896 run_lib.py:133] step: 185600, training_loss: 2.90318e-02
I0209 07:06:18.850639 22542570456896 run_lib.py:146] step: 185600, eval_loss: 3.10002e-02
I0209 07:06:36.318086 22542570456896 run_lib.py:133] step: 185650, training_loss: 2.88038e-02
I0209 07:06:53.803292 22542570456896 run_lib.py:133] step: 185700, training_loss: 2.98972e-02
I0209 07:06:53.963403 22542570456896 run_lib.py:146] step: 185700, eval_loss: 2.13785e-02
I0209 07:07:11.554872 22542570456896 run_lib.py:133] step: 185750, training_loss: 3.09400e-02
I0209 07:07:28.984668 22542570456896 run_lib.py:133] step: 185800, training_loss: 2.63875e-02
I0209 07:07:29.145408 22542570456896 run_lib.py:146] step: 185800, eval_loss: 3.52234e-02
I0209 07:07:46.671073 22542570456896 run_lib.py:133] step: 185850, training_loss: 2.92557e-02
I0209 07:08:04.157218 22542570456896 run_lib.py:133] step: 185900, training_loss: 3.38415e-02
I0209 07:08:04.317684 22542570456896 run_lib.py:146] step: 185900, eval_loss: 2.79189e-02
I0209 07:08:21.824272 22542570456896 run_lib.py:133] step: 185950, training_loss: 2.38510e-02
I0209 07:08:39.222447 22542570456896 run_lib.py:133] step: 186000, training_loss: 3.03766e-02
I0209 07:08:39.374420 22542570456896 run_lib.py:146] step: 186000, eval_loss: 2.70759e-02
I0209 07:08:56.968952 22542570456896 run_lib.py:133] step: 186050, training_loss: 3.56915e-02
I0209 07:09:14.444957 22542570456896 run_lib.py:133] step: 186100, training_loss: 2.86367e-02
I0209 07:09:14.597678 22542570456896 run_lib.py:146] step: 186100, eval_loss: 2.95086e-02
I0209 07:09:32.005519 22542570456896 run_lib.py:133] step: 186150, training_loss: 3.14170e-02
I0209 07:09:49.457612 22542570456896 run_lib.py:133] step: 186200, training_loss: 2.46398e-02
I0209 07:09:49.621484 22542570456896 run_lib.py:146] step: 186200, eval_loss: 3.19457e-02
I0209 07:10:07.277522 22542570456896 run_lib.py:133] step: 186250, training_loss: 3.15490e-02
I0209 07:10:24.742678 22542570456896 run_lib.py:133] step: 186300, training_loss: 2.73725e-02
I0209 07:10:24.898699 22542570456896 run_lib.py:146] step: 186300, eval_loss: 2.96115e-02
I0209 07:10:42.483800 22542570456896 run_lib.py:133] step: 186350, training_loss: 2.58135e-02
I0209 07:10:59.899097 22542570456896 run_lib.py:133] step: 186400, training_loss: 2.13484e-02
I0209 07:11:00.052405 22542570456896 run_lib.py:146] step: 186400, eval_loss: 2.89918e-02
I0209 07:11:17.599298 22542570456896 run_lib.py:133] step: 186450, training_loss: 2.75161e-02
I0209 07:11:35.025080 22542570456896 run_lib.py:133] step: 186500, training_loss: 2.91714e-02
I0209 07:11:35.190521 22542570456896 run_lib.py:146] step: 186500, eval_loss: 2.17158e-02
I0209 07:11:52.838537 22542570456896 run_lib.py:133] step: 186550, training_loss: 2.56764e-02
I0209 07:12:10.243727 22542570456896 run_lib.py:133] step: 186600, training_loss: 3.04156e-02
I0209 07:12:10.398307 22542570456896 run_lib.py:146] step: 186600, eval_loss: 3.41953e-02
I0209 07:12:27.815996 22542570456896 run_lib.py:133] step: 186650, training_loss: 2.80819e-02
I0209 07:12:45.390192 22542570456896 run_lib.py:133] step: 186700, training_loss: 3.08457e-02
I0209 07:12:45.556656 22542570456896 run_lib.py:146] step: 186700, eval_loss: 2.91146e-02
I0209 07:13:03.002126 22542570456896 run_lib.py:133] step: 186750, training_loss: 2.83198e-02
I0209 07:13:20.462660 22542570456896 run_lib.py:133] step: 186800, training_loss: 3.21124e-02
I0209 07:13:20.622098 22542570456896 run_lib.py:146] step: 186800, eval_loss: 3.50409e-02
I0209 07:13:38.247455 22542570456896 run_lib.py:133] step: 186850, training_loss: 3.28894e-02
I0209 07:13:55.884400 22542570456896 run_lib.py:133] step: 186900, training_loss: 3.27257e-02
I0209 07:13:56.039381 22542570456896 run_lib.py:146] step: 186900, eval_loss: 3.03687e-02
I0209 07:14:13.448045 22542570456896 run_lib.py:133] step: 186950, training_loss: 2.60919e-02
I0209 07:14:30.906874 22542570456896 run_lib.py:133] step: 187000, training_loss: 2.12936e-02
I0209 07:14:31.059142 22542570456896 run_lib.py:146] step: 187000, eval_loss: 2.47097e-02
I0209 07:14:48.468778 22542570456896 run_lib.py:133] step: 187050, training_loss: 2.07322e-02
I0209 07:15:06.039966 22542570456896 run_lib.py:133] step: 187100, training_loss: 2.96648e-02
I0209 07:15:06.213333 22542570456896 run_lib.py:146] step: 187100, eval_loss: 2.78483e-02
I0209 07:15:23.621398 22542570456896 run_lib.py:133] step: 187150, training_loss: 2.07605e-02
I0209 07:15:41.033037 22542570456896 run_lib.py:133] step: 187200, training_loss: 3.15376e-02
I0209 07:15:41.189549 22542570456896 run_lib.py:146] step: 187200, eval_loss: 2.51057e-02
I0209 07:15:58.616463 22542570456896 run_lib.py:133] step: 187250, training_loss: 2.30000e-02
I0209 07:16:16.205750 22542570456896 run_lib.py:133] step: 187300, training_loss: 2.07140e-02
I0209 07:16:16.359491 22542570456896 run_lib.py:146] step: 187300, eval_loss: 2.93784e-02
I0209 07:16:33.808464 22542570456896 run_lib.py:133] step: 187350, training_loss: 2.89633e-02
I0209 07:16:51.311596 22542570456896 run_lib.py:133] step: 187400, training_loss: 2.79416e-02
I0209 07:16:51.464956 22542570456896 run_lib.py:146] step: 187400, eval_loss: 3.15105e-02
I0209 07:17:08.969014 22542570456896 run_lib.py:133] step: 187450, training_loss: 2.76646e-02
I0209 07:17:26.392585 22542570456896 run_lib.py:133] step: 187500, training_loss: 2.51670e-02
I0209 07:17:26.552085 22542570456896 run_lib.py:146] step: 187500, eval_loss: 2.50849e-02
I0209 07:17:44.139641 22542570456896 run_lib.py:133] step: 187550, training_loss: 2.46773e-02
I0209 07:18:01.668656 22542570456896 run_lib.py:133] step: 187600, training_loss: 2.94750e-02
I0209 07:18:01.828552 22542570456896 run_lib.py:146] step: 187600, eval_loss: 3.54307e-02
I0209 07:18:19.262383 22542570456896 run_lib.py:133] step: 187650, training_loss: 2.65860e-02
I0209 07:18:36.722307 22542570456896 run_lib.py:133] step: 187700, training_loss: 1.87709e-02
I0209 07:18:36.883551 22542570456896 run_lib.py:146] step: 187700, eval_loss: 3.20013e-02
I0209 07:18:54.512961 22542570456896 run_lib.py:133] step: 187750, training_loss: 3.48700e-02
I0209 07:19:11.968343 22542570456896 run_lib.py:133] step: 187800, training_loss: 2.77679e-02
I0209 07:19:12.123293 22542570456896 run_lib.py:146] step: 187800, eval_loss: 2.69452e-02
I0209 07:19:29.713246 22542570456896 run_lib.py:133] step: 187850, training_loss: 2.65396e-02
I0209 07:19:47.156771 22542570456896 run_lib.py:133] step: 187900, training_loss: 2.39286e-02
I0209 07:19:47.307388 22542570456896 run_lib.py:146] step: 187900, eval_loss: 2.67799e-02
I0209 07:20:04.850214 22542570456896 run_lib.py:133] step: 187950, training_loss: 3.62007e-02
I0209 07:20:22.312566 22542570456896 run_lib.py:133] step: 188000, training_loss: 2.35535e-02
I0209 07:20:22.482620 22542570456896 run_lib.py:146] step: 188000, eval_loss: 2.63289e-02
I0209 07:20:39.947027 22542570456896 run_lib.py:133] step: 188050, training_loss: 2.78904e-02
I0209 07:20:57.555991 22542570456896 run_lib.py:133] step: 188100, training_loss: 3.32979e-02
I0209 07:20:57.714670 22542570456896 run_lib.py:146] step: 188100, eval_loss: 2.64674e-02
I0209 07:21:15.120793 22542570456896 run_lib.py:133] step: 188150, training_loss: 3.42507e-02
I0209 07:21:32.661237 22542570456896 run_lib.py:133] step: 188200, training_loss: 3.07262e-02
I0209 07:21:32.816427 22542570456896 run_lib.py:146] step: 188200, eval_loss: 3.43585e-02
I0209 07:21:50.230543 22542570456896 run_lib.py:133] step: 188250, training_loss: 3.11912e-02
I0209 07:22:07.640704 22542570456896 run_lib.py:133] step: 188300, training_loss: 2.40227e-02
I0209 07:22:07.795521 22542570456896 run_lib.py:146] step: 188300, eval_loss: 3.10303e-02
I0209 07:22:25.375255 22542570456896 run_lib.py:133] step: 188350, training_loss: 3.20042e-02
I0209 07:22:42.719020 22542570456896 run_lib.py:133] step: 188400, training_loss: 2.86904e-02
I0209 07:22:42.871264 22542570456896 run_lib.py:146] step: 188400, eval_loss: 3.25841e-02
I0209 07:23:00.178719 22542570456896 run_lib.py:133] step: 188450, training_loss: 2.69147e-02
I0209 07:23:17.796442 22542570456896 run_lib.py:133] step: 188500, training_loss: 2.80625e-02
I0209 07:23:17.954688 22542570456896 run_lib.py:146] step: 188500, eval_loss: 4.03589e-02
I0209 07:23:35.373393 22542570456896 run_lib.py:133] step: 188550, training_loss: 2.75909e-02
I0209 07:23:52.852232 22542570456896 run_lib.py:133] step: 188600, training_loss: 2.99079e-02
I0209 07:23:53.008533 22542570456896 run_lib.py:146] step: 188600, eval_loss: 2.41660e-02
I0209 07:24:10.594103 22542570456896 run_lib.py:133] step: 188650, training_loss: 3.11039e-02
I0209 07:24:28.005144 22542570456896 run_lib.py:133] step: 188700, training_loss: 2.69581e-02
I0209 07:24:28.164017 22542570456896 run_lib.py:146] step: 188700, eval_loss: 2.78174e-02
I0209 07:24:45.597454 22542570456896 run_lib.py:133] step: 188750, training_loss: 3.34980e-02
I0209 07:25:03.034936 22542570456896 run_lib.py:133] step: 188800, training_loss: 3.71282e-02
I0209 07:25:03.189319 22542570456896 run_lib.py:146] step: 188800, eval_loss: 3.30835e-02
I0209 07:25:20.775810 22542570456896 run_lib.py:133] step: 188850, training_loss: 2.05922e-02
I0209 07:25:38.365593 22542570456896 run_lib.py:133] step: 188900, training_loss: 2.68141e-02
I0209 07:25:38.522589 22542570456896 run_lib.py:146] step: 188900, eval_loss: 2.69767e-02
I0209 07:25:55.966686 22542570456896 run_lib.py:133] step: 188950, training_loss: 2.68173e-02
I0209 07:26:13.403579 22542570456896 run_lib.py:133] step: 189000, training_loss: 3.14332e-02
I0209 07:26:13.566548 22542570456896 run_lib.py:146] step: 189000, eval_loss: 3.03008e-02
I0209 07:26:31.143859 22542570456896 run_lib.py:133] step: 189050, training_loss: 3.47735e-02
I0209 07:26:48.562918 22542570456896 run_lib.py:133] step: 189100, training_loss: 2.96700e-02
I0209 07:26:48.740285 22542570456896 run_lib.py:146] step: 189100, eval_loss: 3.09837e-02
I0209 07:27:06.350230 22542570456896 run_lib.py:133] step: 189150, training_loss: 2.50119e-02
I0209 07:27:23.822812 22542570456896 run_lib.py:133] step: 189200, training_loss: 3.16826e-02
I0209 07:27:23.978153 22542570456896 run_lib.py:146] step: 189200, eval_loss: 3.17039e-02
I0209 07:27:41.598204 22542570456896 run_lib.py:133] step: 189250, training_loss: 2.40240e-02
I0209 07:27:59.018651 22542570456896 run_lib.py:133] step: 189300, training_loss: 2.57249e-02
I0209 07:27:59.170419 22542570456896 run_lib.py:146] step: 189300, eval_loss: 2.81894e-02
I0209 07:28:16.762700 22542570456896 run_lib.py:133] step: 189350, training_loss: 2.38883e-02
I0209 07:28:34.228543 22542570456896 run_lib.py:133] step: 189400, training_loss: 2.26631e-02
I0209 07:28:34.404695 22542570456896 run_lib.py:146] step: 189400, eval_loss: 3.38121e-02
I0209 07:28:51.873007 22542570456896 run_lib.py:133] step: 189450, training_loss: 3.16337e-02
I0209 07:29:09.484812 22542570456896 run_lib.py:133] step: 189500, training_loss: 2.66250e-02
I0209 07:29:09.643293 22542570456896 run_lib.py:146] step: 189500, eval_loss: 2.63292e-02
I0209 07:29:27.040856 22542570456896 run_lib.py:133] step: 189550, training_loss: 2.78352e-02
I0209 07:29:44.482555 22542570456896 run_lib.py:133] step: 189600, training_loss: 2.65822e-02
I0209 07:29:44.643496 22542570456896 run_lib.py:146] step: 189600, eval_loss: 3.85478e-02
I0209 07:30:02.225714 22542570456896 run_lib.py:133] step: 189650, training_loss: 2.68211e-02
I0209 07:30:19.714750 22542570456896 run_lib.py:133] step: 189700, training_loss: 2.64109e-02
I0209 07:30:19.871609 22542570456896 run_lib.py:146] step: 189700, eval_loss: 3.10250e-02
I0209 07:30:37.491399 22542570456896 run_lib.py:133] step: 189750, training_loss: 2.77303e-02
I0209 07:30:54.919275 22542570456896 run_lib.py:133] step: 189800, training_loss: 3.81649e-02
I0209 07:30:55.071318 22542570456896 run_lib.py:146] step: 189800, eval_loss: 3.54052e-02
I0209 07:31:12.535634 22542570456896 run_lib.py:133] step: 189850, training_loss: 2.83391e-02
I0209 07:31:30.114176 22542570456896 run_lib.py:133] step: 189900, training_loss: 2.98714e-02
I0209 07:31:30.291443 22542570456896 run_lib.py:146] step: 189900, eval_loss: 3.15579e-02
I0209 07:31:47.764022 22542570456896 run_lib.py:133] step: 189950, training_loss: 2.32091e-02
I0209 07:32:05.228557 22542570456896 run_lib.py:133] step: 190000, training_loss: 2.49294e-02
I0209 07:32:05.930842 22542570456896 run_lib.py:146] step: 190000, eval_loss: 2.40386e-02
I0209 07:32:25.996146 22542570456896 run_lib.py:133] step: 190050, training_loss: 2.47099e-02
I0209 07:32:43.420551 22542570456896 run_lib.py:133] step: 190100, training_loss: 2.09702e-02
I0209 07:32:43.581664 22542570456896 run_lib.py:146] step: 190100, eval_loss: 2.54576e-02
I0209 07:33:01.214011 22542570456896 run_lib.py:133] step: 190150, training_loss: 2.56479e-02
I0209 07:33:18.693887 22542570456896 run_lib.py:133] step: 190200, training_loss: 2.79282e-02
I0209 07:33:18.849068 22542570456896 run_lib.py:146] step: 190200, eval_loss: 2.64127e-02
I0209 07:33:36.355996 22542570456896 run_lib.py:133] step: 190250, training_loss: 3.16998e-02
I0209 07:33:53.771338 22542570456896 run_lib.py:133] step: 190300, training_loss: 2.69861e-02
I0209 07:33:53.925289 22542570456896 run_lib.py:146] step: 190300, eval_loss: 2.79443e-02
I0209 07:34:11.390655 22542570456896 run_lib.py:133] step: 190350, training_loss: 3.14763e-02
I0209 07:34:28.837088 22542570456896 run_lib.py:133] step: 190400, training_loss: 2.44076e-02
I0209 07:34:28.990368 22542570456896 run_lib.py:146] step: 190400, eval_loss: 3.36436e-02
I0209 07:34:46.591409 22542570456896 run_lib.py:133] step: 190450, training_loss: 2.75771e-02
I0209 07:35:04.101342 22542570456896 run_lib.py:133] step: 190500, training_loss: 2.76930e-02
I0209 07:35:04.279403 22542570456896 run_lib.py:146] step: 190500, eval_loss: 2.85472e-02
I0209 07:35:21.739857 22542570456896 run_lib.py:133] step: 190550, training_loss: 2.56079e-02
I0209 07:35:39.202101 22542570456896 run_lib.py:133] step: 190600, training_loss: 2.51936e-02
I0209 07:35:39.358620 22542570456896 run_lib.py:146] step: 190600, eval_loss: 3.22474e-02
I0209 07:35:56.962891 22542570456896 run_lib.py:133] step: 190650, training_loss: 3.51946e-02
I0209 07:36:14.408064 22542570456896 run_lib.py:133] step: 190700, training_loss: 2.10106e-02
I0209 07:36:14.563587 22542570456896 run_lib.py:146] step: 190700, eval_loss: 2.87002e-02
I0209 07:36:32.099303 22542570456896 run_lib.py:133] step: 190750, training_loss: 3.00421e-02
I0209 07:36:49.580149 22542570456896 run_lib.py:133] step: 190800, training_loss: 2.57530e-02
I0209 07:36:49.735786 22542570456896 run_lib.py:146] step: 190800, eval_loss: 2.70883e-02
I0209 07:37:07.424879 22542570456896 run_lib.py:133] step: 190850, training_loss: 2.37042e-02
I0209 07:37:24.853081 22542570456896 run_lib.py:133] step: 190900, training_loss: 3.40781e-02
I0209 07:37:25.009501 22542570456896 run_lib.py:146] step: 190900, eval_loss: 3.38149e-02
I0209 07:37:42.570840 22542570456896 run_lib.py:133] step: 190950, training_loss: 2.96565e-02
I0209 07:38:00.015325 22542570456896 run_lib.py:133] step: 191000, training_loss: 1.94408e-02
I0209 07:38:00.178555 22542570456896 run_lib.py:146] step: 191000, eval_loss: 3.23100e-02
I0209 07:38:17.562066 22542570456896 run_lib.py:133] step: 191050, training_loss: 2.15253e-02
I0209 07:38:35.128946 22542570456896 run_lib.py:133] step: 191100, training_loss: 2.75139e-02
I0209 07:38:35.298340 22542570456896 run_lib.py:146] step: 191100, eval_loss: 2.97820e-02
I0209 07:38:52.727459 22542570456896 run_lib.py:133] step: 191150, training_loss: 2.18231e-02
I0209 07:39:10.200654 22542570456896 run_lib.py:133] step: 191200, training_loss: 2.25155e-02
I0209 07:39:10.356585 22542570456896 run_lib.py:146] step: 191200, eval_loss: 2.65686e-02
I0209 07:39:27.969338 22542570456896 run_lib.py:133] step: 191250, training_loss: 3.14036e-02
I0209 07:39:45.517073 22542570456896 run_lib.py:133] step: 191300, training_loss: 2.50443e-02
I0209 07:39:45.668280 22542570456896 run_lib.py:146] step: 191300, eval_loss: 2.46901e-02
I0209 07:40:03.076982 22542570456896 run_lib.py:133] step: 191350, training_loss: 2.32742e-02
I0209 07:40:20.514986 22542570456896 run_lib.py:133] step: 191400, training_loss: 2.65354e-02
I0209 07:40:20.680473 22542570456896 run_lib.py:146] step: 191400, eval_loss: 3.17405e-02
I0209 07:40:38.156218 22542570456896 run_lib.py:133] step: 191450, training_loss: 3.25459e-02
I0209 07:40:55.821528 22542570456896 run_lib.py:133] step: 191500, training_loss: 3.02493e-02
I0209 07:40:55.985249 22542570456896 run_lib.py:146] step: 191500, eval_loss: 2.41598e-02
I0209 07:41:13.400382 22542570456896 run_lib.py:133] step: 191550, training_loss: 2.57356e-02
I0209 07:41:30.829705 22542570456896 run_lib.py:133] step: 191600, training_loss: 4.00523e-02
I0209 07:41:30.989361 22542570456896 run_lib.py:146] step: 191600, eval_loss: 2.80848e-02
I0209 07:41:48.407687 22542570456896 run_lib.py:133] step: 191650, training_loss: 3.53960e-02
I0209 07:42:05.980637 22542570456896 run_lib.py:133] step: 191700, training_loss: 3.02118e-02
I0209 07:42:06.132711 22542570456896 run_lib.py:146] step: 191700, eval_loss: 3.09908e-02
I0209 07:42:23.581570 22542570456896 run_lib.py:133] step: 191750, training_loss: 3.39096e-02
I0209 07:42:41.111204 22542570456896 run_lib.py:133] step: 191800, training_loss: 3.13846e-02
I0209 07:42:41.263386 22542570456896 run_lib.py:146] step: 191800, eval_loss: 2.97786e-02
I0209 07:42:58.693505 22542570456896 run_lib.py:133] step: 191850, training_loss: 2.34629e-02
I0209 07:43:16.128855 22542570456896 run_lib.py:133] step: 191900, training_loss: 2.92051e-02
I0209 07:43:16.287833 22542570456896 run_lib.py:146] step: 191900, eval_loss: 2.46757e-02
I0209 07:43:33.860594 22542570456896 run_lib.py:133] step: 191950, training_loss: 2.90382e-02
I0209 07:43:51.333159 22542570456896 run_lib.py:133] step: 192000, training_loss: 2.47693e-02
I0209 07:43:51.500332 22542570456896 run_lib.py:146] step: 192000, eval_loss: 3.33083e-02
I0209 07:44:08.969383 22542570456896 run_lib.py:133] step: 192050, training_loss: 3.46890e-02
I0209 07:44:26.424701 22542570456896 run_lib.py:133] step: 192100, training_loss: 2.67892e-02
I0209 07:44:26.582272 22542570456896 run_lib.py:146] step: 192100, eval_loss: 2.48254e-02
I0209 07:44:44.201052 22542570456896 run_lib.py:133] step: 192150, training_loss: 2.70711e-02
I0209 07:45:01.591803 22542570456896 run_lib.py:133] step: 192200, training_loss: 3.21324e-02
I0209 07:45:01.743180 22542570456896 run_lib.py:146] step: 192200, eval_loss: 1.98498e-02
I0209 07:45:19.320674 22542570456896 run_lib.py:133] step: 192250, training_loss: 2.21363e-02
I0209 07:45:36.751131 22542570456896 run_lib.py:133] step: 192300, training_loss: 2.40564e-02
I0209 07:45:36.920643 22542570456896 run_lib.py:146] step: 192300, eval_loss: 3.14710e-02
I0209 07:45:54.610748 22542570456896 run_lib.py:133] step: 192350, training_loss: 2.60148e-02
I0209 07:46:12.036375 22542570456896 run_lib.py:133] step: 192400, training_loss: 2.42561e-02
I0209 07:46:12.194404 22542570456896 run_lib.py:146] step: 192400, eval_loss: 2.59584e-02
I0209 07:46:29.622185 22542570456896 run_lib.py:133] step: 192450, training_loss: 3.02775e-02
I0209 07:46:47.210407 22542570456896 run_lib.py:133] step: 192500, training_loss: 2.44163e-02
I0209 07:46:47.366465 22542570456896 run_lib.py:146] step: 192500, eval_loss: 3.10060e-02
I0209 07:47:04.807082 22542570456896 run_lib.py:133] step: 192550, training_loss: 3.01186e-02
I0209 07:47:22.384257 22542570456896 run_lib.py:133] step: 192600, training_loss: 3.05969e-02
I0209 07:47:22.541525 22542570456896 run_lib.py:146] step: 192600, eval_loss: 2.72497e-02
I0209 07:47:39.984236 22542570456896 run_lib.py:133] step: 192650, training_loss: 2.74617e-02
I0209 07:47:57.387274 22542570456896 run_lib.py:133] step: 192700, training_loss: 2.66123e-02
I0209 07:47:57.538388 22542570456896 run_lib.py:146] step: 192700, eval_loss: 2.44764e-02
I0209 07:48:15.184478 22542570456896 run_lib.py:133] step: 192750, training_loss: 2.52992e-02
I0209 07:48:32.610560 22542570456896 run_lib.py:133] step: 192800, training_loss: 2.58883e-02
I0209 07:48:32.765413 22542570456896 run_lib.py:146] step: 192800, eval_loss: 3.43287e-02
I0209 07:48:50.184286 22542570456896 run_lib.py:133] step: 192850, training_loss: 2.81749e-02
I0209 07:49:07.766084 22542570456896 run_lib.py:133] step: 192900, training_loss: 2.96655e-02
I0209 07:49:07.949926 22542570456896 run_lib.py:146] step: 192900, eval_loss: 2.69619e-02
I0209 07:49:25.449462 22542570456896 run_lib.py:133] step: 192950, training_loss: 2.45575e-02
I0209 07:49:42.879867 22542570456896 run_lib.py:133] step: 193000, training_loss: 2.33453e-02
I0209 07:49:43.036657 22542570456896 run_lib.py:146] step: 193000, eval_loss: 2.07910e-02
I0209 07:50:00.606092 22542570456896 run_lib.py:133] step: 193050, training_loss: 2.14299e-02
I0209 07:50:18.031015 22542570456896 run_lib.py:133] step: 193100, training_loss: 2.71420e-02
I0209 07:50:18.185492 22542570456896 run_lib.py:146] step: 193100, eval_loss: 2.60626e-02
I0209 07:50:35.601275 22542570456896 run_lib.py:133] step: 193150, training_loss: 2.63707e-02
I0209 07:50:53.003185 22542570456896 run_lib.py:133] step: 193200, training_loss: 2.06503e-02
I0209 07:50:53.167580 22542570456896 run_lib.py:146] step: 193200, eval_loss: 2.77984e-02
I0209 07:51:10.790751 22542570456896 run_lib.py:133] step: 193250, training_loss: 2.80697e-02
I0209 07:51:28.317914 22542570456896 run_lib.py:133] step: 193300, training_loss: 3.34398e-02
I0209 07:51:28.476456 22542570456896 run_lib.py:146] step: 193300, eval_loss: 3.11208e-02
I0209 07:51:45.904893 22542570456896 run_lib.py:133] step: 193350, training_loss: 3.31643e-02
I0209 07:52:03.293056 22542570456896 run_lib.py:133] step: 193400, training_loss: 2.76565e-02
I0209 07:52:03.456538 22542570456896 run_lib.py:146] step: 193400, eval_loss: 2.79106e-02
I0209 07:52:21.013612 22542570456896 run_lib.py:133] step: 193450, training_loss: 2.01308e-02
I0209 07:52:38.440985 22542570456896 run_lib.py:133] step: 193500, training_loss: 2.62886e-02
I0209 07:52:38.596288 22542570456896 run_lib.py:146] step: 193500, eval_loss: 2.48438e-02
I0209 07:52:56.185657 22542570456896 run_lib.py:133] step: 193550, training_loss: 2.95132e-02
I0209 07:53:13.592541 22542570456896 run_lib.py:133] step: 193600, training_loss: 3.34310e-02
I0209 07:53:13.747364 22542570456896 run_lib.py:146] step: 193600, eval_loss: 2.32699e-02
I0209 07:53:31.344236 22542570456896 run_lib.py:133] step: 193650, training_loss: 3.15479e-02
I0209 07:53:48.808978 22542570456896 run_lib.py:133] step: 193700, training_loss: 2.71766e-02
I0209 07:53:48.957412 22542570456896 run_lib.py:146] step: 193700, eval_loss: 2.75241e-02
I0209 07:54:06.516100 22542570456896 run_lib.py:133] step: 193750, training_loss: 2.91243e-02
I0209 07:54:23.957594 22542570456896 run_lib.py:133] step: 193800, training_loss: 3.06997e-02
I0209 07:54:24.134337 22542570456896 run_lib.py:146] step: 193800, eval_loss: 2.26891e-02
I0209 07:54:41.598030 22542570456896 run_lib.py:133] step: 193850, training_loss: 2.95010e-02
I0209 07:54:59.246950 22542570456896 run_lib.py:133] step: 193900, training_loss: 2.46233e-02
I0209 07:54:59.401425 22542570456896 run_lib.py:146] step: 193900, eval_loss: 2.59195e-02
I0209 07:55:16.816899 22542570456896 run_lib.py:133] step: 193950, training_loss: 3.30502e-02
I0209 07:55:34.248542 22542570456896 run_lib.py:133] step: 194000, training_loss: 2.47282e-02
I0209 07:55:34.404525 22542570456896 run_lib.py:146] step: 194000, eval_loss: 2.51800e-02
I0209 07:55:51.960602 22542570456896 run_lib.py:133] step: 194050, training_loss: 2.89978e-02
I0209 07:56:09.436337 22542570456896 run_lib.py:133] step: 194100, training_loss: 2.94265e-02
I0209 07:56:09.590944 22542570456896 run_lib.py:146] step: 194100, eval_loss: 2.99912e-02
I0209 07:56:27.165398 22542570456896 run_lib.py:133] step: 194150, training_loss: 3.60841e-02
I0209 07:56:44.600378 22542570456896 run_lib.py:133] step: 194200, training_loss: 2.14784e-02
I0209 07:56:44.754387 22542570456896 run_lib.py:146] step: 194200, eval_loss: 2.73829e-02
I0209 07:57:02.134451 22542570456896 run_lib.py:133] step: 194250, training_loss: 2.81127e-02
I0209 07:57:19.722603 22542570456896 run_lib.py:133] step: 194300, training_loss: 2.47899e-02
I0209 07:57:19.880584 22542570456896 run_lib.py:146] step: 194300, eval_loss: 2.63386e-02
I0209 07:57:37.325602 22542570456896 run_lib.py:133] step: 194350, training_loss: 2.44810e-02
I0209 07:57:54.762437 22542570456896 run_lib.py:133] step: 194400, training_loss: 3.06091e-02
I0209 07:57:54.918665 22542570456896 run_lib.py:146] step: 194400, eval_loss: 3.56370e-02
I0209 07:58:12.332784 22542570456896 run_lib.py:133] step: 194450, training_loss: 2.94471e-02
I0209 07:58:29.906090 22542570456896 run_lib.py:133] step: 194500, training_loss: 2.78422e-02
I0209 07:58:30.069630 22542570456896 run_lib.py:146] step: 194500, eval_loss: 2.75017e-02
I0209 07:58:47.493757 22542570456896 run_lib.py:133] step: 194550, training_loss: 2.60550e-02
I0209 07:59:04.951178 22542570456896 run_lib.py:133] step: 194600, training_loss: 2.53074e-02
I0209 07:59:05.102995 22542570456896 run_lib.py:146] step: 194600, eval_loss: 2.59974e-02
I0209 07:59:22.509569 22542570456896 run_lib.py:133] step: 194650, training_loss: 2.72362e-02
I0209 07:59:39.961044 22542570456896 run_lib.py:133] step: 194700, training_loss: 2.67453e-02
I0209 07:59:40.123524 22542570456896 run_lib.py:146] step: 194700, eval_loss: 3.27453e-02
I0209 07:59:57.709769 22542570456896 run_lib.py:133] step: 194750, training_loss: 2.50465e-02
I0209 08:00:15.220771 22542570456896 run_lib.py:133] step: 194800, training_loss: 2.17510e-02
I0209 08:00:15.379757 22542570456896 run_lib.py:146] step: 194800, eval_loss: 2.87431e-02
I0209 08:00:32.800635 22542570456896 run_lib.py:133] step: 194850, training_loss: 2.23369e-02
I0209 08:00:50.218475 22542570456896 run_lib.py:133] step: 194900, training_loss: 3.91361e-02
I0209 08:00:50.382460 22542570456896 run_lib.py:146] step: 194900, eval_loss: 2.68293e-02
I0209 08:01:07.968106 22542570456896 run_lib.py:133] step: 194950, training_loss: 2.65841e-02
I0209 08:01:25.421880 22542570456896 run_lib.py:133] step: 195000, training_loss: 2.85939e-02
I0209 08:01:25.579512 22542570456896 run_lib.py:146] step: 195000, eval_loss: 2.79727e-02
I0209 08:01:43.208292 22542570456896 run_lib.py:133] step: 195050, training_loss: 2.80267e-02
I0209 08:02:00.648739 22542570456896 run_lib.py:133] step: 195100, training_loss: 2.72634e-02
I0209 08:02:00.800376 22542570456896 run_lib.py:146] step: 195100, eval_loss: 2.05451e-02
I0209 08:02:18.350169 22542570456896 run_lib.py:133] step: 195150, training_loss: 3.32528e-02
I0209 08:02:35.778358 22542570456896 run_lib.py:133] step: 195200, training_loss: 2.74756e-02
I0209 08:02:35.954607 22542570456896 run_lib.py:146] step: 195200, eval_loss: 2.43946e-02
I0209 08:02:53.448831 22542570456896 run_lib.py:133] step: 195250, training_loss: 2.66662e-02
I0209 08:03:11.078301 22542570456896 run_lib.py:133] step: 195300, training_loss: 3.29145e-02
I0209 08:03:11.239531 22542570456896 run_lib.py:146] step: 195300, eval_loss: 3.16566e-02
I0209 08:03:28.658783 22542570456896 run_lib.py:133] step: 195350, training_loss: 2.85556e-02
I0209 08:03:46.199018 22542570456896 run_lib.py:133] step: 195400, training_loss: 3.23316e-02
I0209 08:03:46.354023 22542570456896 run_lib.py:146] step: 195400, eval_loss: 3.44163e-02
I0209 08:04:03.757278 22542570456896 run_lib.py:133] step: 195450, training_loss: 2.63818e-02
I0209 08:04:21.200878 22542570456896 run_lib.py:133] step: 195500, training_loss: 2.46316e-02
I0209 08:04:21.355588 22542570456896 run_lib.py:146] step: 195500, eval_loss: 2.31884e-02
I0209 08:04:38.976273 22542570456896 run_lib.py:133] step: 195550, training_loss: 3.24220e-02
I0209 08:04:56.425713 22542570456896 run_lib.py:133] step: 195600, training_loss: 2.17516e-02
I0209 08:04:56.578464 22542570456896 run_lib.py:146] step: 195600, eval_loss: 3.24870e-02
I0209 08:05:14.005957 22542570456896 run_lib.py:133] step: 195650, training_loss: 3.06616e-02
I0209 08:05:31.615672 22542570456896 run_lib.py:133] step: 195700, training_loss: 2.35341e-02
I0209 08:05:31.773777 22542570456896 run_lib.py:146] step: 195700, eval_loss: 3.43221e-02
I0209 08:05:49.175696 22542570456896 run_lib.py:133] step: 195750, training_loss: 2.81636e-02
I0209 08:06:06.593688 22542570456896 run_lib.py:133] step: 195800, training_loss: 3.06591e-02
I0209 08:06:06.911350 22542570456896 run_lib.py:146] step: 195800, eval_loss: 3.42345e-02
I0209 08:06:24.366023 22542570456896 run_lib.py:133] step: 195850, training_loss: 2.33393e-02
I0209 08:06:41.831978 22542570456896 run_lib.py:133] step: 195900, training_loss: 2.36217e-02
I0209 08:06:41.988541 22542570456896 run_lib.py:146] step: 195900, eval_loss: 2.43470e-02
I0209 08:06:59.396783 22542570456896 run_lib.py:133] step: 195950, training_loss: 2.69451e-02
I0209 08:07:16.759421 22542570456896 run_lib.py:133] step: 196000, training_loss: 3.02849e-02
I0209 08:07:16.911042 22542570456896 run_lib.py:146] step: 196000, eval_loss: 2.30283e-02
I0209 08:07:34.472359 22542570456896 run_lib.py:133] step: 196050, training_loss: 2.31484e-02
I0209 08:07:51.947955 22542570456896 run_lib.py:133] step: 196100, training_loss: 2.58354e-02
I0209 08:07:52.108396 22542570456896 run_lib.py:146] step: 196100, eval_loss: 3.02325e-02
I0209 08:08:09.585613 22542570456896 run_lib.py:133] step: 196150, training_loss: 2.84234e-02
I0209 08:08:27.044652 22542570456896 run_lib.py:133] step: 196200, training_loss: 3.65144e-02
I0209 08:08:27.203200 22542570456896 run_lib.py:146] step: 196200, eval_loss: 2.96661e-02
I0209 08:08:44.798986 22542570456896 run_lib.py:133] step: 196250, training_loss: 1.87256e-02
I0209 08:09:02.257677 22542570456896 run_lib.py:133] step: 196300, training_loss: 2.76510e-02
I0209 08:09:02.413457 22542570456896 run_lib.py:146] step: 196300, eval_loss: 2.96782e-02
I0209 08:09:19.837044 22542570456896 run_lib.py:133] step: 196350, training_loss: 3.02234e-02
I0209 08:09:37.339436 22542570456896 run_lib.py:133] step: 196400, training_loss: 2.37130e-02
I0209 08:09:37.497274 22542570456896 run_lib.py:146] step: 196400, eval_loss: 2.81054e-02
I0209 08:09:55.118548 22542570456896 run_lib.py:133] step: 196450, training_loss: 3.00221e-02
I0209 08:10:12.550992 22542570456896 run_lib.py:133] step: 196500, training_loss: 3.02411e-02
I0209 08:10:12.703356 22542570456896 run_lib.py:146] step: 196500, eval_loss: 2.69358e-02
I0209 08:10:30.261570 22542570456896 run_lib.py:133] step: 196550, training_loss: 3.01699e-02
I0209 08:10:47.670017 22542570456896 run_lib.py:133] step: 196600, training_loss: 3.17587e-02
I0209 08:10:47.825249 22542570456896 run_lib.py:146] step: 196600, eval_loss: 2.37713e-02
I0209 08:11:05.395307 22542570456896 run_lib.py:133] step: 196650, training_loss: 3.58848e-02
I0209 08:11:22.835940 22542570456896 run_lib.py:133] step: 196700, training_loss: 2.70988e-02
I0209 08:11:23.007252 22542570456896 run_lib.py:146] step: 196700, eval_loss: 3.11219e-02
I0209 08:11:40.419052 22542570456896 run_lib.py:133] step: 196750, training_loss: 2.46780e-02
I0209 08:11:58.062005 22542570456896 run_lib.py:133] step: 196800, training_loss: 2.45468e-02
I0209 08:11:58.218608 22542570456896 run_lib.py:146] step: 196800, eval_loss: 2.82282e-02
I0209 08:12:15.638700 22542570456896 run_lib.py:133] step: 196850, training_loss: 3.41521e-02
I0209 08:12:33.189692 22542570456896 run_lib.py:133] step: 196900, training_loss: 3.44134e-02
I0209 08:12:33.352117 22542570456896 run_lib.py:146] step: 196900, eval_loss: 3.05150e-02
I0209 08:12:50.768218 22542570456896 run_lib.py:133] step: 196950, training_loss: 2.39057e-02
I0209 08:13:08.203108 22542570456896 run_lib.py:133] step: 197000, training_loss: 2.89612e-02
I0209 08:13:08.356549 22542570456896 run_lib.py:146] step: 197000, eval_loss: 3.27654e-02
I0209 08:13:25.974904 22542570456896 run_lib.py:133] step: 197050, training_loss: 3.18635e-02
I0209 08:13:43.391282 22542570456896 run_lib.py:133] step: 197100, training_loss: 2.60647e-02
I0209 08:13:43.546303 22542570456896 run_lib.py:146] step: 197100, eval_loss: 2.85002e-02
I0209 08:14:00.937696 22542570456896 run_lib.py:133] step: 197150, training_loss: 3.68352e-02
I0209 08:14:18.351225 22542570456896 run_lib.py:133] step: 197200, training_loss: 2.91442e-02
I0209 08:14:18.516343 22542570456896 run_lib.py:146] step: 197200, eval_loss: 3.04458e-02
I0209 08:14:36.142434 22542570456896 run_lib.py:133] step: 197250, training_loss: 2.79114e-02
I0209 08:14:53.571718 22542570456896 run_lib.py:133] step: 197300, training_loss: 3.22101e-02
I0209 08:14:53.728839 22542570456896 run_lib.py:146] step: 197300, eval_loss: 2.93379e-02
I0209 08:15:11.270266 22542570456896 run_lib.py:133] step: 197350, training_loss: 2.77099e-02
I0209 08:15:28.659296 22542570456896 run_lib.py:133] step: 197400, training_loss: 3.44288e-02
I0209 08:15:28.822334 22542570456896 run_lib.py:146] step: 197400, eval_loss: 2.32948e-02
I0209 08:15:46.254297 22542570456896 run_lib.py:133] step: 197450, training_loss: 2.69386e-02
I0209 08:16:03.714555 22542570456896 run_lib.py:133] step: 197500, training_loss: 2.77707e-02
I0209 08:16:03.871536 22542570456896 run_lib.py:146] step: 197500, eval_loss: 2.44007e-02
I0209 08:16:21.459657 22542570456896 run_lib.py:133] step: 197550, training_loss: 2.40020e-02
I0209 08:16:39.013852 22542570456896 run_lib.py:133] step: 197600, training_loss: 3.26975e-02
I0209 08:16:39.172185 22542570456896 run_lib.py:146] step: 197600, eval_loss: 1.94362e-02
I0209 08:16:56.574644 22542570456896 run_lib.py:133] step: 197650, training_loss: 2.01120e-02
I0209 08:17:13.967384 22542570456896 run_lib.py:133] step: 197700, training_loss: 2.56021e-02
I0209 08:17:14.123387 22542570456896 run_lib.py:146] step: 197700, eval_loss: 3.22447e-02
I0209 08:17:31.658972 22542570456896 run_lib.py:133] step: 197750, training_loss: 2.44337e-02
I0209 08:17:49.101803 22542570456896 run_lib.py:133] step: 197800, training_loss: 2.84920e-02
I0209 08:17:49.259355 22542570456896 run_lib.py:146] step: 197800, eval_loss: 2.57819e-02
I0209 08:18:06.903324 22542570456896 run_lib.py:133] step: 197850, training_loss: 2.50327e-02
I0209 08:18:24.336978 22542570456896 run_lib.py:133] step: 197900, training_loss: 3.01922e-02
I0209 08:18:24.488161 22542570456896 run_lib.py:146] step: 197900, eval_loss: 2.84307e-02
I0209 08:18:42.077522 22542570456896 run_lib.py:133] step: 197950, training_loss: 2.89972e-02
I0209 08:18:59.512704 22542570456896 run_lib.py:133] step: 198000, training_loss: 2.75048e-02
I0209 08:18:59.671378 22542570456896 run_lib.py:146] step: 198000, eval_loss: 3.27558e-02
I0209 08:19:17.205566 22542570456896 run_lib.py:133] step: 198050, training_loss: 2.54557e-02
I0209 08:19:34.663938 22542570456896 run_lib.py:133] step: 198100, training_loss: 2.55155e-02
I0209 08:19:34.841306 22542570456896 run_lib.py:146] step: 198100, eval_loss: 2.77292e-02
I0209 08:19:52.306884 22542570456896 run_lib.py:133] step: 198150, training_loss: 2.96179e-02
I0209 08:20:09.940207 22542570456896 run_lib.py:133] step: 198200, training_loss: 2.75183e-02
I0209 08:20:10.095053 22542570456896 run_lib.py:146] step: 198200, eval_loss: 2.90799e-02
I0209 08:20:27.518175 22542570456896 run_lib.py:133] step: 198250, training_loss: 3.21393e-02
I0209 08:20:44.922638 22542570456896 run_lib.py:133] step: 198300, training_loss: 3.06589e-02
I0209 08:20:45.077355 22542570456896 run_lib.py:146] step: 198300, eval_loss: 2.07880e-02
I0209 08:21:02.605229 22542570456896 run_lib.py:133] step: 198350, training_loss: 3.25446e-02
I0209 08:21:20.250834 22542570456896 run_lib.py:133] step: 198400, training_loss: 3.29792e-02
I0209 08:21:20.405609 22542570456896 run_lib.py:146] step: 198400, eval_loss: 3.23058e-02
I0209 08:21:37.885236 22542570456896 run_lib.py:133] step: 198450, training_loss: 2.87158e-02
I0209 08:21:55.281162 22542570456896 run_lib.py:133] step: 198500, training_loss: 3.30998e-02
I0209 08:21:55.444389 22542570456896 run_lib.py:146] step: 198500, eval_loss: 2.33815e-02
I0209 08:22:12.823273 22542570456896 run_lib.py:133] step: 198550, training_loss: 2.54424e-02
I0209 08:22:30.459764 22542570456896 run_lib.py:133] step: 198600, training_loss: 2.97600e-02
I0209 08:22:30.617527 22542570456896 run_lib.py:146] step: 198600, eval_loss: 3.11379e-02
I0209 08:22:48.067728 22542570456896 run_lib.py:133] step: 198650, training_loss: 2.60480e-02
I0209 08:23:05.554472 22542570456896 run_lib.py:133] step: 198700, training_loss: 2.48342e-02
I0209 08:23:05.706743 22542570456896 run_lib.py:146] step: 198700, eval_loss: 2.24408e-02
I0209 08:23:23.128369 22542570456896 run_lib.py:133] step: 198750, training_loss: 3.05250e-02
I0209 08:23:40.787395 22542570456896 run_lib.py:133] step: 198800, training_loss: 2.07852e-02
I0209 08:23:40.941569 22542570456896 run_lib.py:146] step: 198800, eval_loss: 2.77269e-02
I0209 08:23:58.345149 22542570456896 run_lib.py:133] step: 198850, training_loss: 2.72250e-02
I0209 08:24:15.825377 22542570456896 run_lib.py:133] step: 198900, training_loss: 3.26851e-02
I0209 08:24:15.979260 22542570456896 run_lib.py:146] step: 198900, eval_loss: 3.15687e-02
I0209 08:24:33.396367 22542570456896 run_lib.py:133] step: 198950, training_loss: 2.63733e-02
I0209 08:24:50.855107 22542570456896 run_lib.py:133] step: 199000, training_loss: 2.94784e-02
I0209 08:24:51.024303 22542570456896 run_lib.py:146] step: 199000, eval_loss: 3.46268e-02
I0209 08:25:08.639066 22542570456896 run_lib.py:133] step: 199050, training_loss: 2.32092e-02
I0209 08:25:26.143200 22542570456896 run_lib.py:133] step: 199100, training_loss: 3.53986e-02
I0209 08:25:26.300705 22542570456896 run_lib.py:146] step: 199100, eval_loss: 2.55060e-02
I0209 08:25:43.729352 22542570456896 run_lib.py:133] step: 199150, training_loss: 2.64228e-02
I0209 08:26:01.139552 22542570456896 run_lib.py:133] step: 199200, training_loss: 3.01395e-02
I0209 08:26:01.295100 22542570456896 run_lib.py:146] step: 199200, eval_loss: 3.26953e-02
I0209 08:26:18.817268 22542570456896 run_lib.py:133] step: 199250, training_loss: 3.29416e-02
I0209 08:26:36.321073 22542570456896 run_lib.py:133] step: 199300, training_loss: 2.08808e-02
I0209 08:26:36.476558 22542570456896 run_lib.py:146] step: 199300, eval_loss: 2.81428e-02
I0209 08:26:54.136131 22542570456896 run_lib.py:133] step: 199350, training_loss: 3.09066e-02
I0209 08:27:11.534091 22542570456896 run_lib.py:133] step: 199400, training_loss: 2.47406e-02
I0209 08:27:11.687318 22542570456896 run_lib.py:146] step: 199400, eval_loss: 2.59425e-02
I0209 08:27:29.219883 22542570456896 run_lib.py:133] step: 199450, training_loss: 3.10841e-02
I0209 08:27:46.616474 22542570456896 run_lib.py:133] step: 199500, training_loss: 3.05260e-02
I0209 08:27:46.779570 22542570456896 run_lib.py:146] step: 199500, eval_loss: 3.23613e-02
I0209 08:28:04.222577 22542570456896 run_lib.py:133] step: 199550, training_loss: 2.98343e-02
I0209 08:28:21.825533 22542570456896 run_lib.py:133] step: 199600, training_loss: 2.82068e-02
I0209 08:28:21.987550 22542570456896 run_lib.py:146] step: 199600, eval_loss: 3.03142e-02
I0209 08:28:39.408658 22542570456896 run_lib.py:133] step: 199650, training_loss: 2.93232e-02
I0209 08:28:57.001601 22542570456896 run_lib.py:133] step: 199700, training_loss: 2.64484e-02
I0209 08:28:57.157140 22542570456896 run_lib.py:146] step: 199700, eval_loss: 3.55435e-02
I0209 08:29:14.550147 22542570456896 run_lib.py:133] step: 199750, training_loss: 2.55474e-02
I0209 08:29:31.978758 22542570456896 run_lib.py:133] step: 199800, training_loss: 2.91587e-02
I0209 08:29:32.129093 22542570456896 run_lib.py:146] step: 199800, eval_loss: 2.96731e-02
I0209 08:29:49.737210 22542570456896 run_lib.py:133] step: 199850, training_loss: 2.79383e-02
I0209 08:30:07.220106 22542570456896 run_lib.py:133] step: 199900, training_loss: 3.13774e-02
I0209 08:30:07.382577 22542570456896 run_lib.py:146] step: 199900, eval_loss: 2.71045e-02
I0209 08:30:24.838237 22542570456896 run_lib.py:133] step: 199950, training_loss: 3.00909e-02
I0209 08:30:42.462753 22542570456896 run_lib.py:133] step: 200000, training_loss: 2.44922e-02
I0209 08:30:43.179432 22542570456896 run_lib.py:146] step: 200000, eval_loss: 2.90544e-02
I0209 08:31:03.250191 22542570456896 run_lib.py:133] step: 200050, training_loss: 2.63434e-02
I0209 08:31:20.687715 22542570456896 run_lib.py:133] step: 200100, training_loss: 2.13452e-02
I0209 08:31:20.865193 22542570456896 run_lib.py:146] step: 200100, eval_loss: 2.77928e-02
I0209 08:31:38.246463 22542570456896 run_lib.py:133] step: 200150, training_loss: 2.98827e-02
I0209 08:31:55.764061 22542570456896 run_lib.py:133] step: 200200, training_loss: 3.01243e-02
I0209 08:31:55.919518 22542570456896 run_lib.py:146] step: 200200, eval_loss: 3.16327e-02
I0209 08:32:13.312123 22542570456896 run_lib.py:133] step: 200250, training_loss: 3.16105e-02
I0209 08:32:30.729836 22542570456896 run_lib.py:133] step: 200300, training_loss: 3.21650e-02
I0209 08:32:30.885384 22542570456896 run_lib.py:146] step: 200300, eval_loss: 2.43674e-02
I0209 08:32:48.448120 22542570456896 run_lib.py:133] step: 200350, training_loss: 3.30412e-02
I0209 08:33:05.886697 22542570456896 run_lib.py:133] step: 200400, training_loss: 3.13290e-02
I0209 08:33:06.050445 22542570456896 run_lib.py:146] step: 200400, eval_loss: 3.49141e-02
I0209 08:33:23.649430 22542570456896 run_lib.py:133] step: 200450, training_loss: 2.60591e-02
I0209 08:33:41.078025 22542570456896 run_lib.py:133] step: 200500, training_loss: 3.74914e-02
I0209 08:33:41.233252 22542570456896 run_lib.py:146] step: 200500, eval_loss: 2.58391e-02
I0209 08:33:58.647351 22542570456896 run_lib.py:133] step: 200550, training_loss: 2.96563e-02
I0209 08:34:16.114227 22542570456896 run_lib.py:133] step: 200600, training_loss: 3.00617e-02
I0209 08:34:16.269740 22542570456896 run_lib.py:146] step: 200600, eval_loss: 2.78328e-02
I0209 08:34:33.863729 22542570456896 run_lib.py:133] step: 200650, training_loss: 3.48856e-02
I0209 08:34:51.462747 22542570456896 run_lib.py:133] step: 200700, training_loss: 3.51212e-02
I0209 08:34:51.618947 22542570456896 run_lib.py:146] step: 200700, eval_loss: 2.98449e-02
I0209 08:35:09.097493 22542570456896 run_lib.py:133] step: 200750, training_loss: 3.36856e-02
I0209 08:35:26.512552 22542570456896 run_lib.py:133] step: 200800, training_loss: 3.41669e-02
I0209 08:35:26.666579 22542570456896 run_lib.py:146] step: 200800, eval_loss: 3.11889e-02
I0209 08:35:44.258288 22542570456896 run_lib.py:133] step: 200850, training_loss: 2.64163e-02
I0209 08:36:01.675221 22542570456896 run_lib.py:133] step: 200900, training_loss: 3.20871e-02
I0209 08:36:01.828453 22542570456896 run_lib.py:146] step: 200900, eval_loss: 2.83964e-02
I0209 08:36:19.414243 22542570456896 run_lib.py:133] step: 200950, training_loss: 2.94107e-02
I0209 08:36:36.866070 22542570456896 run_lib.py:133] step: 201000, training_loss: 3.11212e-02
I0209 08:36:37.025339 22542570456896 run_lib.py:146] step: 201000, eval_loss: 3.15036e-02
I0209 08:36:54.644009 22542570456896 run_lib.py:133] step: 201050, training_loss: 2.36892e-02
I0209 08:37:12.036690 22542570456896 run_lib.py:133] step: 201100, training_loss: 2.51364e-02
I0209 08:37:12.199431 22542570456896 run_lib.py:146] step: 201100, eval_loss: 2.78193e-02
I0209 08:37:29.827753 22542570456896 run_lib.py:133] step: 201150, training_loss: 2.14063e-02
I0209 08:37:47.261815 22542570456896 run_lib.py:133] step: 201200, training_loss: 2.66560e-02
I0209 08:37:47.431152 22542570456896 run_lib.py:146] step: 201200, eval_loss: 3.01457e-02
I0209 08:38:04.917456 22542570456896 run_lib.py:133] step: 201250, training_loss: 3.07590e-02
I0209 08:38:22.539872 22542570456896 run_lib.py:133] step: 201300, training_loss: 3.83070e-02
I0209 08:38:22.691679 22542570456896 run_lib.py:146] step: 201300, eval_loss: 3.54800e-02
I0209 08:38:40.145301 22542570456896 run_lib.py:133] step: 201350, training_loss: 3.53832e-02
I0209 08:38:57.596269 22542570456896 run_lib.py:133] step: 201400, training_loss: 2.56903e-02
I0209 08:38:57.760465 22542570456896 run_lib.py:146] step: 201400, eval_loss: 2.32663e-02
I0209 08:39:15.374833 22542570456896 run_lib.py:133] step: 201450, training_loss: 2.90762e-02
I0209 08:39:32.786108 22542570456896 run_lib.py:133] step: 201500, training_loss: 2.35557e-02
I0209 08:39:32.963353 22542570456896 run_lib.py:146] step: 201500, eval_loss: 2.94744e-02
I0209 08:39:50.603995 22542570456896 run_lib.py:133] step: 201550, training_loss: 2.35091e-02
I0209 08:40:08.043139 22542570456896 run_lib.py:133] step: 201600, training_loss: 2.66362e-02
I0209 08:40:08.197061 22542570456896 run_lib.py:146] step: 201600, eval_loss: 2.41777e-02
I0209 08:40:25.613828 22542570456896 run_lib.py:133] step: 201650, training_loss: 2.79568e-02
I0209 08:40:43.214008 22542570456896 run_lib.py:133] step: 201700, training_loss: 2.50372e-02
I0209 08:40:43.370404 22542570456896 run_lib.py:146] step: 201700, eval_loss: 2.55302e-02
I0209 08:41:00.820782 22542570456896 run_lib.py:133] step: 201750, training_loss: 2.60040e-02
I0209 08:41:18.248535 22542570456896 run_lib.py:133] step: 201800, training_loss: 2.81874e-02
I0209 08:41:18.400766 22542570456896 run_lib.py:146] step: 201800, eval_loss: 2.85275e-02
I0209 08:41:35.859735 22542570456896 run_lib.py:133] step: 201850, training_loss: 2.27920e-02
I0209 08:41:53.473569 22542570456896 run_lib.py:133] step: 201900, training_loss: 2.92339e-02
I0209 08:41:53.640476 22542570456896 run_lib.py:146] step: 201900, eval_loss: 2.35913e-02
I0209 08:42:11.074182 22542570456896 run_lib.py:133] step: 201950, training_loss: 2.94950e-02
I0209 08:42:28.565489 22542570456896 run_lib.py:133] step: 202000, training_loss: 2.97720e-02
I0209 08:42:28.723618 22542570456896 run_lib.py:146] step: 202000, eval_loss: 3.60502e-02
I0209 08:42:46.125899 22542570456896 run_lib.py:133] step: 202050, training_loss: 2.59840e-02
I0209 08:43:03.544118 22542570456896 run_lib.py:133] step: 202100, training_loss: 2.71916e-02
I0209 08:43:03.718151 22542570456896 run_lib.py:146] step: 202100, eval_loss: 3.55812e-02
I0209 08:43:21.345802 22542570456896 run_lib.py:133] step: 202150, training_loss: 2.53157e-02
I0209 08:43:38.877528 22542570456896 run_lib.py:133] step: 202200, training_loss: 2.95830e-02
I0209 08:43:39.029756 22542570456896 run_lib.py:146] step: 202200, eval_loss: 2.87014e-02
I0209 08:43:56.511045 22542570456896 run_lib.py:133] step: 202250, training_loss: 2.66734e-02
I0209 08:44:13.919986 22542570456896 run_lib.py:133] step: 202300, training_loss: 2.48644e-02
I0209 08:44:14.072339 22542570456896 run_lib.py:146] step: 202300, eval_loss: 3.34100e-02
I0209 08:44:31.608668 22542570456896 run_lib.py:133] step: 202350, training_loss: 2.55018e-02
I0209 08:44:49.030693 22542570456896 run_lib.py:133] step: 202400, training_loss: 2.60521e-02
I0209 08:44:49.215279 22542570456896 run_lib.py:146] step: 202400, eval_loss: 3.32684e-02
I0209 08:45:06.834785 22542570456896 run_lib.py:133] step: 202450, training_loss: 2.30039e-02
I0209 08:45:24.330572 22542570456896 run_lib.py:133] step: 202500, training_loss: 3.01986e-02
I0209 08:45:24.497428 22542570456896 run_lib.py:146] step: 202500, eval_loss: 3.01489e-02
I0209 08:45:42.101888 22542570456896 run_lib.py:133] step: 202550, training_loss: 2.84258e-02
I0209 08:45:59.505102 22542570456896 run_lib.py:133] step: 202600, training_loss: 2.55694e-02
I0209 08:45:59.662128 22542570456896 run_lib.py:146] step: 202600, eval_loss: 2.62304e-02
I0209 08:46:17.101458 22542570456896 run_lib.py:133] step: 202650, training_loss: 2.87763e-02
I0209 08:46:34.747307 22542570456896 run_lib.py:133] step: 202700, training_loss: 3.22666e-02
I0209 08:46:34.904157 22542570456896 run_lib.py:146] step: 202700, eval_loss: 2.89330e-02
I0209 08:46:52.361365 22542570456896 run_lib.py:133] step: 202750, training_loss: 3.19170e-02
I0209 08:47:09.966018 22542570456896 run_lib.py:133] step: 202800, training_loss: 3.39197e-02
I0209 08:47:10.131387 22542570456896 run_lib.py:146] step: 202800, eval_loss: 3.14038e-02
I0209 08:47:27.566914 22542570456896 run_lib.py:133] step: 202850, training_loss: 2.97791e-02
I0209 08:47:45.033304 22542570456896 run_lib.py:133] step: 202900, training_loss: 2.49270e-02
I0209 08:47:45.191521 22542570456896 run_lib.py:146] step: 202900, eval_loss: 3.42895e-02
I0209 08:48:02.780575 22542570456896 run_lib.py:133] step: 202950, training_loss: 2.46023e-02
I0209 08:48:20.269612 22542570456896 run_lib.py:133] step: 203000, training_loss: 2.18747e-02
I0209 08:48:20.426786 22542570456896 run_lib.py:146] step: 203000, eval_loss: 2.51922e-02
I0209 08:48:37.870837 22542570456896 run_lib.py:133] step: 203050, training_loss: 3.31240e-02
I0209 08:48:55.493013 22542570456896 run_lib.py:133] step: 203100, training_loss: 2.56594e-02
I0209 08:48:55.648813 22542570456896 run_lib.py:146] step: 203100, eval_loss: 2.98610e-02
I0209 08:49:13.066512 22542570456896 run_lib.py:133] step: 203150, training_loss: 3.69050e-02
I0209 08:49:30.461903 22542570456896 run_lib.py:133] step: 203200, training_loss: 3.09891e-02
I0209 08:49:30.763775 22542570456896 run_lib.py:146] step: 203200, eval_loss: 2.67803e-02
I0209 08:49:48.245770 22542570456896 run_lib.py:133] step: 203250, training_loss: 3.22271e-02
I0209 08:50:05.705986 22542570456896 run_lib.py:133] step: 203300, training_loss: 2.18370e-02
I0209 08:50:05.861585 22542570456896 run_lib.py:146] step: 203300, eval_loss: 2.78684e-02
I0209 08:50:23.259454 22542570456896 run_lib.py:133] step: 203350, training_loss: 2.48673e-02
I0209 08:50:40.698755 22542570456896 run_lib.py:133] step: 203400, training_loss: 2.69768e-02
I0209 08:50:40.856753 22542570456896 run_lib.py:146] step: 203400, eval_loss: 2.13050e-02
I0209 08:50:58.488477 22542570456896 run_lib.py:133] step: 203450, training_loss: 3.41082e-02
I0209 08:51:16.007273 22542570456896 run_lib.py:133] step: 203500, training_loss: 2.28713e-02
I0209 08:51:16.176427 22542570456896 run_lib.py:146] step: 203500, eval_loss: 3.14013e-02
I0209 08:51:33.601900 22542570456896 run_lib.py:133] step: 203550, training_loss: 2.35645e-02
I0209 08:51:51.032045 22542570456896 run_lib.py:133] step: 203600, training_loss: 3.03698e-02
I0209 08:51:51.188637 22542570456896 run_lib.py:146] step: 203600, eval_loss: 3.02064e-02
I0209 08:52:08.783500 22542570456896 run_lib.py:133] step: 203650, training_loss: 3.50129e-02
I0209 08:52:26.294471 22542570456896 run_lib.py:133] step: 203700, training_loss: 2.23984e-02
I0209 08:52:26.441036 22542570456896 run_lib.py:146] step: 203700, eval_loss: 2.42856e-02
I0209 08:52:43.835409 22542570456896 run_lib.py:133] step: 203750, training_loss: 3.04918e-02
I0209 08:53:01.323214 22542570456896 run_lib.py:133] step: 203800, training_loss: 1.92904e-02
I0209 08:53:01.493595 22542570456896 run_lib.py:146] step: 203800, eval_loss: 2.99798e-02
I0209 08:53:19.142860 22542570456896 run_lib.py:133] step: 203850, training_loss: 2.85889e-02
I0209 08:53:36.605691 22542570456896 run_lib.py:133] step: 203900, training_loss: 2.82165e-02
I0209 08:53:36.768454 22542570456896 run_lib.py:146] step: 203900, eval_loss: 2.46717e-02
I0209 08:53:54.308682 22542570456896 run_lib.py:133] step: 203950, training_loss: 2.37703e-02
I0209 08:54:11.683904 22542570456896 run_lib.py:133] step: 204000, training_loss: 2.79794e-02
I0209 08:54:11.840392 22542570456896 run_lib.py:146] step: 204000, eval_loss: 3.45208e-02
I0209 08:54:29.413993 22542570456896 run_lib.py:133] step: 204050, training_loss: 3.35433e-02
I0209 08:54:46.883519 22542570456896 run_lib.py:133] step: 204100, training_loss: 2.80650e-02
I0209 08:54:47.039547 22542570456896 run_lib.py:146] step: 204100, eval_loss: 2.63577e-02
I0209 08:55:04.519225 22542570456896 run_lib.py:133] step: 204150, training_loss: 2.84480e-02
I0209 08:55:22.109998 22542570456896 run_lib.py:133] step: 204200, training_loss: 3.02227e-02
I0209 08:55:22.262421 22542570456896 run_lib.py:146] step: 204200, eval_loss: 2.41579e-02
I0209 08:55:39.650307 22542570456896 run_lib.py:133] step: 204250, training_loss: 2.62546e-02
I0209 08:55:57.200577 22542570456896 run_lib.py:133] step: 204300, training_loss: 3.49359e-02
I0209 08:55:57.359772 22542570456896 run_lib.py:146] step: 204300, eval_loss: 3.83288e-02
I0209 08:56:14.767126 22542570456896 run_lib.py:133] step: 204350, training_loss: 2.47014e-02
I0209 08:56:32.228883 22542570456896 run_lib.py:133] step: 204400, training_loss: 2.74221e-02
I0209 08:56:32.387320 22542570456896 run_lib.py:146] step: 204400, eval_loss: 3.15642e-02
I0209 08:56:50.015458 22542570456896 run_lib.py:133] step: 204450, training_loss: 2.90816e-02
I0209 08:57:07.489480 22542570456896 run_lib.py:133] step: 204500, training_loss: 3.23341e-02
I0209 08:57:07.646104 22542570456896 run_lib.py:146] step: 204500, eval_loss: 2.78323e-02
I0209 08:57:25.047492 22542570456896 run_lib.py:133] step: 204550, training_loss: 3.01434e-02
I0209 08:57:42.447510 22542570456896 run_lib.py:133] step: 204600, training_loss: 2.68130e-02
I0209 08:57:42.600462 22542570456896 run_lib.py:146] step: 204600, eval_loss: 2.47089e-02
I0209 08:58:00.186127 22542570456896 run_lib.py:133] step: 204650, training_loss: 2.25723e-02
I0209 08:58:17.632932 22542570456896 run_lib.py:133] step: 204700, training_loss: 3.14220e-02
I0209 08:58:17.790565 22542570456896 run_lib.py:146] step: 204700, eval_loss: 3.48165e-02
I0209 08:58:35.360307 22542570456896 run_lib.py:133] step: 204750, training_loss: 2.99517e-02
I0209 08:58:52.791668 22542570456896 run_lib.py:133] step: 204800, training_loss: 2.26106e-02
I0209 08:58:52.955455 22542570456896 run_lib.py:146] step: 204800, eval_loss: 3.41302e-02
I0209 08:59:10.371160 22542570456896 run_lib.py:133] step: 204850, training_loss: 2.69086e-02
I0209 08:59:27.781899 22542570456896 run_lib.py:133] step: 204900, training_loss: 2.90827e-02
I0209 08:59:27.937379 22542570456896 run_lib.py:146] step: 204900, eval_loss: 2.66623e-02
I0209 08:59:45.534795 22542570456896 run_lib.py:133] step: 204950, training_loss: 3.14025e-02
I0209 09:00:03.086149 22542570456896 run_lib.py:133] step: 205000, training_loss: 3.44109e-02
I0209 09:00:03.242919 22542570456896 run_lib.py:146] step: 205000, eval_loss: 2.97072e-02
I0209 09:00:20.737874 22542570456896 run_lib.py:133] step: 205050, training_loss: 2.94542e-02
I0209 09:00:38.112003 22542570456896 run_lib.py:133] step: 205100, training_loss: 2.79890e-02
I0209 09:00:38.265384 22542570456896 run_lib.py:146] step: 205100, eval_loss: 3.15082e-02
I0209 09:00:55.852137 22542570456896 run_lib.py:133] step: 205150, training_loss: 2.60612e-02
I0209 09:01:13.277656 22542570456896 run_lib.py:133] step: 205200, training_loss: 2.90097e-02
I0209 09:01:13.433371 22542570456896 run_lib.py:146] step: 205200, eval_loss: 3.77811e-02
I0209 09:01:30.967717 22542570456896 run_lib.py:133] step: 205250, training_loss: 2.83082e-02
I0209 09:01:48.457125 22542570456896 run_lib.py:133] step: 205300, training_loss: 3.25777e-02
I0209 09:01:48.623364 22542570456896 run_lib.py:146] step: 205300, eval_loss: 2.58057e-02
I0209 09:02:06.211881 22542570456896 run_lib.py:133] step: 205350, training_loss: 3.13859e-02
I0209 09:02:23.633133 22542570456896 run_lib.py:133] step: 205400, training_loss: 2.24717e-02
I0209 09:02:23.788763 22542570456896 run_lib.py:146] step: 205400, eval_loss: 3.18927e-02
I0209 09:02:41.361665 22542570456896 run_lib.py:133] step: 205450, training_loss: 3.25793e-02
I0209 09:02:58.768535 22542570456896 run_lib.py:133] step: 205500, training_loss: 2.64951e-02
I0209 09:02:58.923015 22542570456896 run_lib.py:146] step: 205500, eval_loss: 2.59213e-02
I0209 09:03:16.386350 22542570456896 run_lib.py:133] step: 205550, training_loss: 2.45048e-02
I0209 09:03:33.964827 22542570456896 run_lib.py:133] step: 205600, training_loss: 2.73679e-02
I0209 09:03:34.119632 22542570456896 run_lib.py:146] step: 205600, eval_loss: 3.12318e-02
I0209 09:03:51.604254 22542570456896 run_lib.py:133] step: 205650, training_loss: 3.04314e-02
I0209 09:04:09.027589 22542570456896 run_lib.py:133] step: 205700, training_loss: 3.00005e-02
I0209 09:04:09.183760 22542570456896 run_lib.py:146] step: 205700, eval_loss: 2.19804e-02
I0209 09:04:26.757997 22542570456896 run_lib.py:133] step: 205750, training_loss: 3.06890e-02
I0209 09:04:44.294637 22542570456896 run_lib.py:133] step: 205800, training_loss: 2.58032e-02
I0209 09:04:44.453580 22542570456896 run_lib.py:146] step: 205800, eval_loss: 2.80677e-02
I0209 09:05:01.935658 22542570456896 run_lib.py:133] step: 205850, training_loss: 2.81688e-02
I0209 09:05:19.366644 22542570456896 run_lib.py:133] step: 205900, training_loss: 3.54903e-02
I0209 09:05:19.531545 22542570456896 run_lib.py:146] step: 205900, eval_loss: 2.52572e-02
I0209 09:05:37.004526 22542570456896 run_lib.py:133] step: 205950, training_loss: 2.67078e-02
I0209 09:05:54.622058 22542570456896 run_lib.py:133] step: 206000, training_loss: 2.99983e-02
I0209 09:05:54.777058 22542570456896 run_lib.py:146] step: 206000, eval_loss: 2.63509e-02
I0209 09:06:12.166805 22542570456896 run_lib.py:133] step: 206050, training_loss: 2.81813e-02
I0209 09:06:29.558904 22542570456896 run_lib.py:133] step: 206100, training_loss: 2.34130e-02
I0209 09:06:29.713739 22542570456896 run_lib.py:146] step: 206100, eval_loss: 2.87510e-02
I0209 09:06:47.277205 22542570456896 run_lib.py:133] step: 206150, training_loss: 2.58207e-02
I0209 09:07:04.910232 22542570456896 run_lib.py:133] step: 206200, training_loss: 2.66567e-02
I0209 09:07:05.066426 22542570456896 run_lib.py:146] step: 206200, eval_loss: 2.59161e-02
I0209 09:07:22.477789 22542570456896 run_lib.py:133] step: 206250, training_loss: 3.08040e-02
I0209 09:07:39.934031 22542570456896 run_lib.py:133] step: 206300, training_loss: 2.92524e-02
I0209 09:07:40.090584 22542570456896 run_lib.py:146] step: 206300, eval_loss: 2.53956e-02
I0209 09:07:57.489926 22542570456896 run_lib.py:133] step: 206350, training_loss: 2.67916e-02
I0209 09:08:14.875651 22542570456896 run_lib.py:133] step: 206400, training_loss: 2.94576e-02
I0209 09:08:15.039457 22542570456896 run_lib.py:146] step: 206400, eval_loss: 3.62341e-02
I0209 09:08:32.608282 22542570456896 run_lib.py:133] step: 206450, training_loss: 2.74357e-02
I0209 09:08:50.157488 22542570456896 run_lib.py:133] step: 206500, training_loss: 3.35010e-02
I0209 09:08:50.310117 22542570456896 run_lib.py:146] step: 206500, eval_loss: 2.88449e-02
I0209 09:09:07.742999 22542570456896 run_lib.py:133] step: 206550, training_loss: 2.91013e-02
I0209 09:09:25.178445 22542570456896 run_lib.py:133] step: 206600, training_loss: 3.03281e-02
I0209 09:09:25.332365 22542570456896 run_lib.py:146] step: 206600, eval_loss: 2.50565e-02
I0209 09:09:42.879765 22542570456896 run_lib.py:133] step: 206650, training_loss: 2.89136e-02
I0209 09:10:00.288991 22542570456896 run_lib.py:133] step: 206700, training_loss: 3.09778e-02
I0209 09:10:00.471428 22542570456896 run_lib.py:146] step: 206700, eval_loss: 2.55934e-02
I0209 09:10:18.094806 22542570456896 run_lib.py:133] step: 206750, training_loss: 2.60265e-02
I0209 09:10:35.524581 22542570456896 run_lib.py:133] step: 206800, training_loss: 3.36624e-02
I0209 09:10:35.689376 22542570456896 run_lib.py:146] step: 206800, eval_loss: 3.38388e-02
I0209 09:10:53.259424 22542570456896 run_lib.py:133] step: 206850, training_loss: 3.09809e-02
I0209 09:11:10.668196 22542570456896 run_lib.py:133] step: 206900, training_loss: 2.78307e-02
I0209 09:11:10.823082 22542570456896 run_lib.py:146] step: 206900, eval_loss: 3.08417e-02
I0209 09:11:28.222224 22542570456896 run_lib.py:133] step: 206950, training_loss: 3.13037e-02
I0209 09:11:45.838180 22542570456896 run_lib.py:133] step: 207000, training_loss: 2.50158e-02
I0209 09:11:45.991338 22542570456896 run_lib.py:146] step: 207000, eval_loss: 3.24777e-02
I0209 09:12:03.464240 22542570456896 run_lib.py:133] step: 207050, training_loss: 3.04378e-02
I0209 09:12:21.069755 22542570456896 run_lib.py:133] step: 207100, training_loss: 2.33078e-02
I0209 09:12:21.226378 22542570456896 run_lib.py:146] step: 207100, eval_loss: 2.90276e-02
I0209 09:12:38.659927 22542570456896 run_lib.py:133] step: 207150, training_loss: 2.42377e-02
I0209 09:12:56.120971 22542570456896 run_lib.py:133] step: 207200, training_loss: 3.28589e-02
I0209 09:12:56.278697 22542570456896 run_lib.py:146] step: 207200, eval_loss: 2.53912e-02
I0209 09:13:13.830273 22542570456896 run_lib.py:133] step: 207250, training_loss: 3.14894e-02
I0209 09:13:31.283936 22542570456896 run_lib.py:133] step: 207300, training_loss: 3.46045e-02
I0209 09:13:31.440366 22542570456896 run_lib.py:146] step: 207300, eval_loss: 3.62964e-02
I0209 09:13:48.863964 22542570456896 run_lib.py:133] step: 207350, training_loss: 3.62337e-02
I0209 09:14:06.489131 22542570456896 run_lib.py:133] step: 207400, training_loss: 2.54025e-02
I0209 09:14:06.647407 22542570456896 run_lib.py:146] step: 207400, eval_loss: 3.33760e-02
I0209 09:14:24.056226 22542570456896 run_lib.py:133] step: 207450, training_loss: 3.29516e-02
I0209 09:14:41.463978 22542570456896 run_lib.py:133] step: 207500, training_loss: 3.11805e-02
I0209 09:14:41.615449 22542570456896 run_lib.py:146] step: 207500, eval_loss: 2.78144e-02
I0209 09:14:59.097317 22542570456896 run_lib.py:133] step: 207550, training_loss: 3.38723e-02
I0209 09:15:16.571670 22542570456896 run_lib.py:133] step: 207600, training_loss: 3.35794e-02
I0209 09:15:16.742661 22542570456896 run_lib.py:146] step: 207600, eval_loss: 3.12980e-02
I0209 09:15:34.205732 22542570456896 run_lib.py:133] step: 207650, training_loss: 2.99471e-02
I0209 09:15:51.651558 22542570456896 run_lib.py:133] step: 207700, training_loss: 2.76686e-02
I0209 09:15:51.816494 22542570456896 run_lib.py:146] step: 207700, eval_loss: 3.08314e-02
I0209 09:16:09.396279 22542570456896 run_lib.py:133] step: 207750, training_loss: 2.32289e-02
I0209 09:16:26.883967 22542570456896 run_lib.py:133] step: 207800, training_loss: 2.78694e-02
I0209 09:16:27.040235 22542570456896 run_lib.py:146] step: 207800, eval_loss: 3.00027e-02
I0209 09:16:44.470924 22542570456896 run_lib.py:133] step: 207850, training_loss: 2.49059e-02
I0209 09:17:01.967025 22542570456896 run_lib.py:133] step: 207900, training_loss: 3.05996e-02
I0209 09:17:02.129679 22542570456896 run_lib.py:146] step: 207900, eval_loss: 3.23889e-02
I0209 09:17:19.797227 22542570456896 run_lib.py:133] step: 207950, training_loss: 3.19169e-02
I0209 09:17:37.214979 22542570456896 run_lib.py:133] step: 208000, training_loss: 2.86824e-02
I0209 09:17:37.367343 22542570456896 run_lib.py:146] step: 208000, eval_loss: 2.93950e-02
I0209 09:17:54.943529 22542570456896 run_lib.py:133] step: 208050, training_loss: 2.49902e-02
I0209 09:18:12.345916 22542570456896 run_lib.py:133] step: 208100, training_loss: 3.06736e-02
I0209 09:18:12.505637 22542570456896 run_lib.py:146] step: 208100, eval_loss: 3.35208e-02
I0209 09:18:30.069827 22542570456896 run_lib.py:133] step: 208150, training_loss: 2.52307e-02
I0209 09:18:47.566036 22542570456896 run_lib.py:133] step: 208200, training_loss: 3.03684e-02
I0209 09:18:47.724612 22542570456896 run_lib.py:146] step: 208200, eval_loss: 2.67673e-02
I0209 09:19:05.342542 22542570456896 run_lib.py:133] step: 208250, training_loss: 2.95391e-02
I0209 09:19:22.802246 22542570456896 run_lib.py:133] step: 208300, training_loss: 2.78009e-02
I0209 09:19:22.966440 22542570456896 run_lib.py:146] step: 208300, eval_loss: 2.53117e-02
I0209 09:19:40.383954 22542570456896 run_lib.py:133] step: 208350, training_loss: 2.93563e-02
I0209 09:19:57.929278 22542570456896 run_lib.py:133] step: 208400, training_loss: 3.05451e-02
I0209 09:19:58.081411 22542570456896 run_lib.py:146] step: 208400, eval_loss: 3.07670e-02
I0209 09:20:15.467015 22542570456896 run_lib.py:133] step: 208450, training_loss: 2.75382e-02
I0209 09:20:32.907558 22542570456896 run_lib.py:133] step: 208500, training_loss: 3.03481e-02
I0209 09:20:33.070612 22542570456896 run_lib.py:146] step: 208500, eval_loss: 3.04205e-02
I0209 09:20:50.748151 22542570456896 run_lib.py:133] step: 208550, training_loss: 3.48497e-02
I0209 09:21:08.182491 22542570456896 run_lib.py:133] step: 208600, training_loss: 1.87548e-02
I0209 09:21:08.340138 22542570456896 run_lib.py:146] step: 208600, eval_loss: 2.52036e-02
I0209 09:21:25.902217 22542570456896 run_lib.py:133] step: 208650, training_loss: 3.89107e-02
I0209 09:21:43.306839 22542570456896 run_lib.py:133] step: 208700, training_loss: 3.27198e-02
I0209 09:21:43.462344 22542570456896 run_lib.py:146] step: 208700, eval_loss: 3.09748e-02
I0209 09:22:00.889746 22542570456896 run_lib.py:133] step: 208750, training_loss: 2.96940e-02
I0209 09:22:18.489470 22542570456896 run_lib.py:133] step: 208800, training_loss: 3.77668e-02
I0209 09:22:18.648990 22542570456896 run_lib.py:146] step: 208800, eval_loss: 3.03155e-02
I0209 09:22:36.116939 22542570456896 run_lib.py:133] step: 208850, training_loss: 3.34083e-02
I0209 09:22:53.520989 22542570456896 run_lib.py:133] step: 208900, training_loss: 2.85591e-02
I0209 09:22:53.672561 22542570456896 run_lib.py:146] step: 208900, eval_loss: 3.69716e-02
I0209 09:23:11.101743 22542570456896 run_lib.py:133] step: 208950, training_loss: 3.07738e-02
I0209 09:23:28.724527 22542570456896 run_lib.py:133] step: 209000, training_loss: 3.05701e-02
I0209 09:23:28.875686 22542570456896 run_lib.py:146] step: 209000, eval_loss: 3.18361e-02
I0209 09:23:46.282147 22542570456896 run_lib.py:133] step: 209050, training_loss: 3.31244e-02
I0209 09:24:03.770151 22542570456896 run_lib.py:133] step: 209100, training_loss: 2.63299e-02
I0209 09:24:03.946894 22542570456896 run_lib.py:146] step: 209100, eval_loss: 3.75337e-02
I0209 09:24:21.421071 22542570456896 run_lib.py:133] step: 209150, training_loss: 3.23673e-02
I0209 09:24:38.839575 22542570456896 run_lib.py:133] step: 209200, training_loss: 2.70492e-02
I0209 09:24:38.996580 22542570456896 run_lib.py:146] step: 209200, eval_loss: 3.03957e-02
I0209 09:24:56.591889 22542570456896 run_lib.py:133] step: 209250, training_loss: 2.68031e-02
I0209 09:25:14.038542 22542570456896 run_lib.py:133] step: 209300, training_loss: 2.57421e-02
I0209 09:25:14.192397 22542570456896 run_lib.py:146] step: 209300, eval_loss: 2.40554e-02
I0209 09:25:31.653339 22542570456896 run_lib.py:133] step: 209350, training_loss: 2.81625e-02
I0209 09:25:49.114404 22542570456896 run_lib.py:133] step: 209400, training_loss: 3.01834e-02
I0209 09:25:49.270666 22542570456896 run_lib.py:146] step: 209400, eval_loss: 3.57430e-02
I0209 09:26:06.911705 22542570456896 run_lib.py:133] step: 209450, training_loss: 2.96298e-02
I0209 09:26:24.314337 22542570456896 run_lib.py:133] step: 209500, training_loss: 2.71207e-02
I0209 09:26:24.469050 22542570456896 run_lib.py:146] step: 209500, eval_loss: 2.97848e-02
I0209 09:26:42.037473 22542570456896 run_lib.py:133] step: 209550, training_loss: 3.07973e-02
I0209 09:26:59.422884 22542570456896 run_lib.py:133] step: 209600, training_loss: 2.47863e-02
I0209 09:26:59.579080 22542570456896 run_lib.py:146] step: 209600, eval_loss: 2.66316e-02
I0209 09:27:17.122563 22542570456896 run_lib.py:133] step: 209650, training_loss: 3.18135e-02
I0209 09:27:34.558738 22542570456896 run_lib.py:133] step: 209700, training_loss: 3.21977e-02
I0209 09:27:34.716487 22542570456896 run_lib.py:146] step: 209700, eval_loss: 2.70111e-02
I0209 09:27:52.225946 22542570456896 run_lib.py:133] step: 209750, training_loss: 3.01538e-02
I0209 09:28:09.864534 22542570456896 run_lib.py:133] step: 209800, training_loss: 2.64710e-02
I0209 09:28:10.019362 22542570456896 run_lib.py:146] step: 209800, eval_loss: 2.17979e-02
I0209 09:28:27.468421 22542570456896 run_lib.py:133] step: 209850, training_loss: 2.60672e-02
I0209 09:28:45.020448 22542570456896 run_lib.py:133] step: 209900, training_loss: 3.14598e-02
I0209 09:28:45.172438 22542570456896 run_lib.py:146] step: 209900, eval_loss: 2.97138e-02
I0209 09:29:02.560696 22542570456896 run_lib.py:133] step: 209950, training_loss: 3.04788e-02
I0209 09:29:19.948524 22542570456896 run_lib.py:133] step: 210000, training_loss: 2.54510e-02
I0209 09:29:20.666273 22542570456896 run_lib.py:146] step: 210000, eval_loss: 2.71364e-02
I0209 09:29:40.958905 22542570456896 run_lib.py:133] step: 210050, training_loss: 3.14731e-02
I0209 09:29:58.402824 22542570456896 run_lib.py:133] step: 210100, training_loss: 2.17562e-02
I0209 09:29:58.560196 22542570456896 run_lib.py:146] step: 210100, eval_loss: 3.00116e-02
I0209 09:30:16.156050 22542570456896 run_lib.py:133] step: 210150, training_loss: 2.85796e-02
I0209 09:30:33.549885 22542570456896 run_lib.py:133] step: 210200, training_loss: 3.58709e-02
I0209 09:30:33.713427 22542570456896 run_lib.py:146] step: 210200, eval_loss: 2.67145e-02
I0209 09:30:51.129782 22542570456896 run_lib.py:133] step: 210250, training_loss: 3.84014e-02
I0209 09:31:08.816684 22542570456896 run_lib.py:133] step: 210300, training_loss: 3.17253e-02
I0209 09:31:08.972548 22542570456896 run_lib.py:146] step: 210300, eval_loss: 2.50364e-02
I0209 09:31:26.428471 22542570456896 run_lib.py:133] step: 210350, training_loss: 2.57662e-02
I0209 09:31:43.970255 22542570456896 run_lib.py:133] step: 210400, training_loss: 2.87407e-02
I0209 09:31:44.121331 22542570456896 run_lib.py:146] step: 210400, eval_loss: 3.07916e-02
I0209 09:32:01.511404 22542570456896 run_lib.py:133] step: 210450, training_loss: 3.17871e-02
I0209 09:32:18.950141 22542570456896 run_lib.py:133] step: 210500, training_loss: 2.55375e-02
I0209 09:32:19.108448 22542570456896 run_lib.py:146] step: 210500, eval_loss: 2.70643e-02
I0209 09:32:36.572749 22542570456896 run_lib.py:133] step: 210550, training_loss: 2.55281e-02
I0209 09:32:54.168351 22542570456896 run_lib.py:133] step: 210600, training_loss: 3.27860e-02
I0209 09:32:54.352305 22542570456896 run_lib.py:146] step: 210600, eval_loss: 2.32553e-02
I0209 09:33:11.801998 22542570456896 run_lib.py:133] step: 210650, training_loss: 2.51102e-02
I0209 09:33:29.275923 22542570456896 run_lib.py:133] step: 210700, training_loss: 2.34934e-02
I0209 09:33:29.431548 22542570456896 run_lib.py:146] step: 210700, eval_loss: 2.29075e-02
I0209 09:33:47.043823 22542570456896 run_lib.py:133] step: 210750, training_loss: 2.54662e-02
I0209 09:34:04.439079 22542570456896 run_lib.py:133] step: 210800, training_loss: 3.40910e-02
I0209 09:34:04.593218 22542570456896 run_lib.py:146] step: 210800, eval_loss: 2.89969e-02
I0209 09:34:22.088136 22542570456896 run_lib.py:133] step: 210850, training_loss: 2.83774e-02
I0209 09:34:39.586678 22542570456896 run_lib.py:133] step: 210900, training_loss: 2.61673e-02
I0209 09:34:39.743550 22542570456896 run_lib.py:146] step: 210900, eval_loss: 2.39131e-02
I0209 09:34:57.260532 22542570456896 run_lib.py:133] step: 210950, training_loss: 2.20809e-02
I0209 09:35:14.675431 22542570456896 run_lib.py:133] step: 211000, training_loss: 3.08610e-02
I0209 09:35:14.839515 22542570456896 run_lib.py:146] step: 211000, eval_loss: 3.36634e-02
I0209 09:35:32.450071 22542570456896 run_lib.py:133] step: 211050, training_loss: 2.67796e-02
I0209 09:35:49.924967 22542570456896 run_lib.py:133] step: 211100, training_loss: 3.36076e-02
I0209 09:35:50.101631 22542570456896 run_lib.py:146] step: 211100, eval_loss: 2.80836e-02
I0209 09:36:07.560818 22542570456896 run_lib.py:133] step: 211150, training_loss: 2.67293e-02
I0209 09:36:24.984262 22542570456896 run_lib.py:133] step: 211200, training_loss: 3.21477e-02
I0209 09:36:25.142122 22542570456896 run_lib.py:146] step: 211200, eval_loss: 2.34159e-02
I0209 09:36:42.762927 22542570456896 run_lib.py:133] step: 211250, training_loss: 2.98661e-02
I0209 09:37:00.205223 22542570456896 run_lib.py:133] step: 211300, training_loss: 3.25418e-02
I0209 09:37:00.360294 22542570456896 run_lib.py:146] step: 211300, eval_loss: 2.81310e-02
I0209 09:37:17.901855 22542570456896 run_lib.py:133] step: 211350, training_loss: 2.36699e-02
I0209 09:37:35.357290 22542570456896 run_lib.py:133] step: 211400, training_loss: 1.97610e-02
I0209 09:37:35.511538 22542570456896 run_lib.py:146] step: 211400, eval_loss: 2.92039e-02
I0209 09:37:53.174674 22542570456896 run_lib.py:133] step: 211450, training_loss: 3.40224e-02
I0209 09:38:10.613430 22542570456896 run_lib.py:133] step: 211500, training_loss: 2.99908e-02
I0209 09:38:10.775459 22542570456896 run_lib.py:146] step: 211500, eval_loss: 2.73841e-02
I0209 09:38:28.355555 22542570456896 run_lib.py:133] step: 211550, training_loss: 2.88556e-02
I0209 09:38:45.736069 22542570456896 run_lib.py:133] step: 211600, training_loss: 2.50269e-02
I0209 09:38:45.891414 22542570456896 run_lib.py:146] step: 211600, eval_loss: 3.14266e-02
I0209 09:39:03.316073 22542570456896 run_lib.py:133] step: 211650, training_loss: 3.01292e-02
I0209 09:39:20.944973 22542570456896 run_lib.py:133] step: 211700, training_loss: 3.57291e-02
I0209 09:39:21.101092 22542570456896 run_lib.py:146] step: 211700, eval_loss: 2.59323e-02
I0209 09:39:38.543383 22542570456896 run_lib.py:133] step: 211750, training_loss: 2.74321e-02
I0209 09:39:55.929807 22542570456896 run_lib.py:133] step: 211800, training_loss: 3.32159e-02
I0209 09:39:56.083102 22542570456896 run_lib.py:146] step: 211800, eval_loss: 2.55952e-02
I0209 09:40:13.643201 22542570456896 run_lib.py:133] step: 211850, training_loss: 3.13433e-02
I0209 09:40:31.009055 22542570456896 run_lib.py:133] step: 211900, training_loss: 2.90872e-02
I0209 09:40:31.163216 22542570456896 run_lib.py:146] step: 211900, eval_loss: 3.23928e-02
I0209 09:40:48.622303 22542570456896 run_lib.py:133] step: 211950, training_loss: 3.19023e-02
I0209 09:41:06.039194 22542570456896 run_lib.py:133] step: 212000, training_loss: 2.39264e-02
I0209 09:41:06.212185 22542570456896 run_lib.py:146] step: 212000, eval_loss: 2.82147e-02
I0209 09:41:23.648597 22542570456896 run_lib.py:133] step: 212050, training_loss: 2.66632e-02
I0209 09:41:41.255963 22542570456896 run_lib.py:133] step: 212100, training_loss: 2.68579e-02
I0209 09:41:41.412562 22542570456896 run_lib.py:146] step: 212100, eval_loss: 2.54816e-02
I0209 09:41:58.843487 22542570456896 run_lib.py:133] step: 212150, training_loss: 2.73144e-02
I0209 09:42:16.260545 22542570456896 run_lib.py:133] step: 212200, training_loss: 3.13571e-02
I0209 09:42:16.419125 22542570456896 run_lib.py:146] step: 212200, eval_loss: 2.99861e-02
I0209 09:42:33.879472 22542570456896 run_lib.py:133] step: 212250, training_loss: 3.17259e-02
I0209 09:42:51.518383 22542570456896 run_lib.py:133] step: 212300, training_loss: 2.50735e-02
I0209 09:42:51.671537 22542570456896 run_lib.py:146] step: 212300, eval_loss: 2.85334e-02
I0209 09:43:09.121519 22542570456896 run_lib.py:133] step: 212350, training_loss: 2.58054e-02
I0209 09:43:26.670884 22542570456896 run_lib.py:133] step: 212400, training_loss: 2.43532e-02
I0209 09:43:26.826377 22542570456896 run_lib.py:146] step: 212400, eval_loss: 3.32529e-02
I0209 09:43:44.223377 22542570456896 run_lib.py:133] step: 212450, training_loss: 2.32327e-02
I0209 09:44:01.661375 22542570456896 run_lib.py:133] step: 212500, training_loss: 2.94526e-02
I0209 09:44:01.819563 22542570456896 run_lib.py:146] step: 212500, eval_loss: 2.54096e-02
I0209 09:44:19.368254 22542570456896 run_lib.py:133] step: 212550, training_loss: 2.16639e-02
I0209 09:44:36.884677 22542570456896 run_lib.py:133] step: 212600, training_loss: 2.16180e-02
I0209 09:44:37.041605 22542570456896 run_lib.py:146] step: 212600, eval_loss: 2.72427e-02
I0209 09:44:54.476264 22542570456896 run_lib.py:133] step: 212650, training_loss: 2.98806e-02
I0209 09:45:11.929829 22542570456896 run_lib.py:133] step: 212700, training_loss: 2.91040e-02
I0209 09:45:12.085443 22542570456896 run_lib.py:146] step: 212700, eval_loss: 2.74614e-02
I0209 09:45:29.666039 22542570456896 run_lib.py:133] step: 212750, training_loss: 3.45643e-02
I0209 09:45:47.113780 22542570456896 run_lib.py:133] step: 212800, training_loss: 2.88962e-02
I0209 09:45:47.265503 22542570456896 run_lib.py:146] step: 212800, eval_loss: 2.58796e-02
I0209 09:46:04.860457 22542570456896 run_lib.py:133] step: 212850, training_loss: 3.14249e-02
I0209 09:46:22.290246 22542570456896 run_lib.py:133] step: 212900, training_loss: 2.50450e-02
I0209 09:46:22.460368 22542570456896 run_lib.py:146] step: 212900, eval_loss: 3.32669e-02
I0209 09:46:40.067984 22542570456896 run_lib.py:133] step: 212950, training_loss: 3.66693e-02
I0209 09:46:57.491384 22542570456896 run_lib.py:133] step: 213000, training_loss: 3.01223e-02
I0209 09:46:57.646291 22542570456896 run_lib.py:146] step: 213000, eval_loss: 3.11250e-02
I0209 09:47:15.114360 22542570456896 run_lib.py:133] step: 213050, training_loss: 2.39339e-02
I0209 09:47:32.649572 22542570456896 run_lib.py:133] step: 213100, training_loss: 3.20426e-02
I0209 09:47:32.804395 22542570456896 run_lib.py:146] step: 213100, eval_loss: 2.87062e-02
I0209 09:47:50.255723 22542570456896 run_lib.py:133] step: 213150, training_loss: 2.36756e-02
I0209 09:48:07.903176 22542570456896 run_lib.py:133] step: 213200, training_loss: 2.45722e-02
I0209 09:48:08.057583 22542570456896 run_lib.py:146] step: 213200, eval_loss: 3.02034e-02
I0209 09:48:25.527271 22542570456896 run_lib.py:133] step: 213250, training_loss: 3.16176e-02
I0209 09:48:42.968975 22542570456896 run_lib.py:133] step: 213300, training_loss: 2.73400e-02
I0209 09:48:43.127315 22542570456896 run_lib.py:146] step: 213300, eval_loss: 2.72394e-02
I0209 09:49:00.765830 22542570456896 run_lib.py:133] step: 213350, training_loss: 2.38454e-02
I0209 09:49:18.156816 22542570456896 run_lib.py:133] step: 213400, training_loss: 3.46910e-02
I0209 09:49:18.323575 22542570456896 run_lib.py:146] step: 213400, eval_loss: 2.48371e-02
I0209 09:49:35.762604 22542570456896 run_lib.py:133] step: 213450, training_loss: 3.03134e-02
I0209 09:49:53.398012 22542570456896 run_lib.py:133] step: 213500, training_loss: 2.35104e-02
I0209 09:49:53.551726 22542570456896 run_lib.py:146] step: 213500, eval_loss: 2.84017e-02
I0209 09:50:10.919463 22542570456896 run_lib.py:133] step: 213550, training_loss: 2.89771e-02
I0209 09:50:28.349182 22542570456896 run_lib.py:133] step: 213600, training_loss: 2.71459e-02
I0209 09:50:28.679391 22542570456896 run_lib.py:146] step: 213600, eval_loss: 3.06701e-02
I0209 09:50:46.128233 22542570456896 run_lib.py:133] step: 213650, training_loss: 3.05716e-02
I0209 09:51:03.539531 22542570456896 run_lib.py:133] step: 213700, training_loss: 2.39127e-02
I0209 09:51:03.690298 22542570456896 run_lib.py:146] step: 213700, eval_loss: 2.66495e-02
I0209 09:51:21.141754 22542570456896 run_lib.py:133] step: 213750, training_loss: 3.50539e-02
I0209 09:51:38.585969 22542570456896 run_lib.py:133] step: 213800, training_loss: 2.15402e-02
I0209 09:51:38.750567 22542570456896 run_lib.py:146] step: 213800, eval_loss: 3.14895e-02
I0209 09:51:56.378122 22542570456896 run_lib.py:133] step: 213850, training_loss: 3.38129e-02
I0209 09:52:13.867987 22542570456896 run_lib.py:133] step: 213900, training_loss: 2.39049e-02
I0209 09:52:14.025544 22542570456896 run_lib.py:146] step: 213900, eval_loss: 2.98276e-02
I0209 09:52:31.487515 22542570456896 run_lib.py:133] step: 213950, training_loss: 2.99001e-02
I0209 09:52:48.923489 22542570456896 run_lib.py:133] step: 214000, training_loss: 2.69155e-02
I0209 09:52:49.091344 22542570456896 run_lib.py:146] step: 214000, eval_loss: 3.13233e-02
I0209 09:53:06.712783 22542570456896 run_lib.py:133] step: 214050, training_loss: 2.54871e-02
I0209 09:53:24.218458 22542570456896 run_lib.py:133] step: 214100, training_loss: 2.82898e-02
I0209 09:53:24.378132 22542570456896 run_lib.py:146] step: 214100, eval_loss: 2.51454e-02
I0209 09:53:41.800957 22542570456896 run_lib.py:133] step: 214150, training_loss: 2.43971e-02
I0209 09:53:59.225115 22542570456896 run_lib.py:133] step: 214200, training_loss: 3.68223e-02
I0209 09:53:59.385337 22542570456896 run_lib.py:146] step: 214200, eval_loss: 2.84923e-02
I0209 09:54:16.944276 22542570456896 run_lib.py:133] step: 214250, training_loss: 2.90810e-02
I0209 09:54:34.367451 22542570456896 run_lib.py:133] step: 214300, training_loss: 2.99639e-02
I0209 09:54:34.540002 22542570456896 run_lib.py:146] step: 214300, eval_loss: 3.35558e-02
I0209 09:54:52.162309 22542570456896 run_lib.py:133] step: 214350, training_loss: 3.30848e-02
I0209 09:55:09.592659 22542570456896 run_lib.py:133] step: 214400, training_loss: 3.24563e-02
I0209 09:55:09.750320 22542570456896 run_lib.py:146] step: 214400, eval_loss: 3.12335e-02
I0209 09:55:27.323597 22542570456896 run_lib.py:133] step: 214450, training_loss: 3.34685e-02
I0209 09:55:44.743669 22542570456896 run_lib.py:133] step: 214500, training_loss: 3.00703e-02
I0209 09:55:44.909894 22542570456896 run_lib.py:146] step: 214500, eval_loss: 2.44555e-02
I0209 09:56:02.314055 22542570456896 run_lib.py:133] step: 214550, training_loss: 2.41799e-02
I0209 09:56:19.871977 22542570456896 run_lib.py:133] step: 214600, training_loss: 2.61406e-02
I0209 09:56:20.026536 22542570456896 run_lib.py:146] step: 214600, eval_loss: 3.12854e-02
I0209 09:56:37.484805 22542570456896 run_lib.py:133] step: 214650, training_loss: 2.48362e-02
I0209 09:56:55.069737 22542570456896 run_lib.py:133] step: 214700, training_loss: 2.55484e-02
I0209 09:56:55.220355 22542570456896 run_lib.py:146] step: 214700, eval_loss: 2.70031e-02
I0209 09:57:12.645570 22542570456896 run_lib.py:133] step: 214750, training_loss: 2.56930e-02
I0209 09:57:30.057950 22542570456896 run_lib.py:133] step: 214800, training_loss: 2.90459e-02
I0209 09:57:30.217548 22542570456896 run_lib.py:146] step: 214800, eval_loss: 3.11869e-02
I0209 09:57:47.753821 22542570456896 run_lib.py:133] step: 214850, training_loss: 2.36438e-02
I0209 09:58:05.155893 22542570456896 run_lib.py:133] step: 214900, training_loss: 2.61267e-02
I0209 09:58:05.331176 22542570456896 run_lib.py:146] step: 214900, eval_loss: 2.55718e-02
I0209 09:58:22.771305 22542570456896 run_lib.py:133] step: 214950, training_loss: 3.19616e-02
I0209 09:58:40.231374 22542570456896 run_lib.py:133] step: 215000, training_loss: 3.20138e-02
I0209 09:58:40.390119 22542570456896 run_lib.py:146] step: 215000, eval_loss: 3.17110e-02
I0209 09:58:57.961827 22542570456896 run_lib.py:133] step: 215050, training_loss: 2.57318e-02
I0209 09:59:15.388408 22542570456896 run_lib.py:133] step: 215100, training_loss: 2.76611e-02
I0209 09:59:15.542129 22542570456896 run_lib.py:146] step: 215100, eval_loss: 2.51037e-02
I0209 09:59:33.023899 22542570456896 run_lib.py:133] step: 215150, training_loss: 3.10718e-02
I0209 09:59:50.502465 22542570456896 run_lib.py:133] step: 215200, training_loss: 2.48550e-02
I0209 09:59:50.659089 22542570456896 run_lib.py:146] step: 215200, eval_loss: 2.99078e-02
I0209 10:00:08.144073 22542570456896 run_lib.py:133] step: 215250, training_loss: 3.28522e-02
I0209 10:00:25.604559 22542570456896 run_lib.py:133] step: 215300, training_loss: 2.84580e-02
I0209 10:00:25.771726 22542570456896 run_lib.py:146] step: 215300, eval_loss: 2.81357e-02
I0209 10:00:43.335772 22542570456896 run_lib.py:133] step: 215350, training_loss: 2.31970e-02
I0209 10:01:00.865881 22542570456896 run_lib.py:133] step: 215400, training_loss: 2.86377e-02
I0209 10:01:01.022197 22542570456896 run_lib.py:146] step: 215400, eval_loss: 2.88137e-02
I0209 10:01:18.469190 22542570456896 run_lib.py:133] step: 215450, training_loss: 2.80244e-02
I0209 10:01:35.905842 22542570456896 run_lib.py:133] step: 215500, training_loss: 2.65410e-02
I0209 10:01:36.062928 22542570456896 run_lib.py:146] step: 215500, eval_loss: 2.81542e-02
I0209 10:01:53.669575 22542570456896 run_lib.py:133] step: 215550, training_loss: 2.47650e-02
I0209 10:02:11.098561 22542570456896 run_lib.py:133] step: 215600, training_loss: 3.36411e-02
I0209 10:02:11.249106 22542570456896 run_lib.py:146] step: 215600, eval_loss: 2.70637e-02
I0209 10:02:28.837147 22542570456896 run_lib.py:133] step: 215650, training_loss: 3.00329e-02
I0209 10:02:46.280154 22542570456896 run_lib.py:133] step: 215700, training_loss: 2.75175e-02
I0209 10:02:46.440977 22542570456896 run_lib.py:146] step: 215700, eval_loss: 2.91672e-02
I0209 10:03:04.031155 22542570456896 run_lib.py:133] step: 215750, training_loss: 2.83616e-02
I0209 10:03:21.506332 22542570456896 run_lib.py:133] step: 215800, training_loss: 3.96610e-02
I0209 10:03:21.683341 22542570456896 run_lib.py:146] step: 215800, eval_loss: 2.64510e-02
I0209 10:03:39.306321 22542570456896 run_lib.py:133] step: 215850, training_loss: 2.90394e-02
I0209 10:03:56.718861 22542570456896 run_lib.py:133] step: 215900, training_loss: 2.38625e-02
I0209 10:03:56.875500 22542570456896 run_lib.py:146] step: 215900, eval_loss: 3.00215e-02
I0209 10:04:14.331464 22542570456896 run_lib.py:133] step: 215950, training_loss: 3.18807e-02
I0209 10:04:31.922676 22542570456896 run_lib.py:133] step: 216000, training_loss: 2.57554e-02
I0209 10:04:32.078181 22542570456896 run_lib.py:146] step: 216000, eval_loss: 3.03093e-02
I0209 10:04:49.490297 22542570456896 run_lib.py:133] step: 216050, training_loss: 2.73834e-02
I0209 10:05:06.934527 22542570456896 run_lib.py:133] step: 216100, training_loss: 3.40795e-02
I0209 10:05:07.091457 22542570456896 run_lib.py:146] step: 216100, eval_loss: 2.34259e-02
I0209 10:05:24.752747 22542570456896 run_lib.py:133] step: 216150, training_loss: 2.51553e-02
I0209 10:05:42.363198 22542570456896 run_lib.py:133] step: 216200, training_loss: 3.69042e-02
I0209 10:05:42.527103 22542570456896 run_lib.py:146] step: 216200, eval_loss: 2.94886e-02
I0209 10:05:59.951751 22542570456896 run_lib.py:133] step: 216250, training_loss: 2.77283e-02
I0209 10:06:17.379990 22542570456896 run_lib.py:133] step: 216300, training_loss: 2.70940e-02
I0209 10:06:17.536475 22542570456896 run_lib.py:146] step: 216300, eval_loss: 2.45332e-02
I0209 10:06:34.971469 22542570456896 run_lib.py:133] step: 216350, training_loss: 3.41800e-02
I0209 10:06:52.619223 22542570456896 run_lib.py:133] step: 216400, training_loss: 2.92012e-02
I0209 10:06:52.777738 22542570456896 run_lib.py:146] step: 216400, eval_loss: 3.31026e-02
I0209 10:07:10.179528 22542570456896 run_lib.py:133] step: 216450, training_loss: 3.89197e-02
I0209 10:07:27.630821 22542570456896 run_lib.py:133] step: 216500, training_loss: 2.54053e-02
I0209 10:07:27.785312 22542570456896 run_lib.py:146] step: 216500, eval_loss: 3.25053e-02
I0209 10:07:45.192382 22542570456896 run_lib.py:133] step: 216550, training_loss: 3.09594e-02
I0209 10:08:02.808105 22542570456896 run_lib.py:133] step: 216600, training_loss: 3.03623e-02
I0209 10:08:02.961539 22542570456896 run_lib.py:146] step: 216600, eval_loss: 2.67360e-02
I0209 10:08:20.406399 22542570456896 run_lib.py:133] step: 216650, training_loss: 2.97534e-02
I0209 10:08:37.892734 22542570456896 run_lib.py:133] step: 216700, training_loss: 2.75583e-02
I0209 10:08:38.050590 22542570456896 run_lib.py:146] step: 216700, eval_loss: 2.45353e-02
I0209 10:08:55.427742 22542570456896 run_lib.py:133] step: 216750, training_loss: 2.48825e-02
I0209 10:09:12.857921 22542570456896 run_lib.py:133] step: 216800, training_loss: 2.19178e-02
I0209 10:09:13.022544 22542570456896 run_lib.py:146] step: 216800, eval_loss: 2.65915e-02
I0209 10:09:30.649351 22542570456896 run_lib.py:133] step: 216850, training_loss: 2.90459e-02
I0209 10:09:48.113597 22542570456896 run_lib.py:133] step: 216900, training_loss: 3.18412e-02
I0209 10:09:48.278843 22542570456896 run_lib.py:146] step: 216900, eval_loss: 3.21188e-02
I0209 10:10:05.731557 22542570456896 run_lib.py:133] step: 216950, training_loss: 3.17271e-02
I0209 10:10:23.135521 22542570456896 run_lib.py:133] step: 217000, training_loss: 2.44756e-02
I0209 10:10:23.294253 22542570456896 run_lib.py:146] step: 217000, eval_loss: 3.44471e-02
I0209 10:10:40.904441 22542570456896 run_lib.py:133] step: 217050, training_loss: 2.93274e-02
I0209 10:10:58.303597 22542570456896 run_lib.py:133] step: 217100, training_loss: 2.02816e-02
I0209 10:10:58.457374 22542570456896 run_lib.py:146] step: 217100, eval_loss: 3.12997e-02
I0209 10:11:16.004394 22542570456896 run_lib.py:133] step: 217150, training_loss: 2.11675e-02
I0209 10:11:33.429124 22542570456896 run_lib.py:133] step: 217200, training_loss: 2.87152e-02
I0209 10:11:33.587434 22542570456896 run_lib.py:146] step: 217200, eval_loss: 3.28232e-02
I0209 10:11:51.180158 22542570456896 run_lib.py:133] step: 217250, training_loss: 3.39892e-02
I0209 10:12:08.681490 22542570456896 run_lib.py:133] step: 217300, training_loss: 2.83942e-02
I0209 10:12:08.837470 22542570456896 run_lib.py:146] step: 217300, eval_loss: 2.51787e-02
I0209 10:12:26.245187 22542570456896 run_lib.py:133] step: 217350, training_loss: 2.71898e-02
I0209 10:12:43.814166 22542570456896 run_lib.py:133] step: 217400, training_loss: 2.93732e-02
I0209 10:12:43.978638 22542570456896 run_lib.py:146] step: 217400, eval_loss: 3.30584e-02
I0209 10:13:01.394032 22542570456896 run_lib.py:133] step: 217450, training_loss: 2.28436e-02
I0209 10:13:18.962867 22542570456896 run_lib.py:133] step: 217500, training_loss: 2.62688e-02
I0209 10:13:19.114921 22542570456896 run_lib.py:146] step: 217500, eval_loss: 2.87566e-02
I0209 10:13:36.548072 22542570456896 run_lib.py:133] step: 217550, training_loss: 2.75716e-02
I0209 10:13:54.000868 22542570456896 run_lib.py:133] step: 217600, training_loss: 2.59243e-02
I0209 10:13:54.168659 22542570456896 run_lib.py:146] step: 217600, eval_loss: 2.80737e-02
I0209 10:14:11.769649 22542570456896 run_lib.py:133] step: 217650, training_loss: 2.43469e-02
I0209 10:14:29.213063 22542570456896 run_lib.py:133] step: 217700, training_loss: 2.87726e-02
I0209 10:14:29.372365 22542570456896 run_lib.py:146] step: 217700, eval_loss: 2.74212e-02
I0209 10:14:46.774131 22542570456896 run_lib.py:133] step: 217750, training_loss: 2.72114e-02
I0209 10:15:04.314486 22542570456896 run_lib.py:133] step: 217800, training_loss: 2.84760e-02
I0209 10:15:04.483232 22542570456896 run_lib.py:146] step: 217800, eval_loss: 3.81599e-02
I0209 10:15:21.909100 22542570456896 run_lib.py:133] step: 217850, training_loss: 2.89848e-02
I0209 10:15:39.364585 22542570456896 run_lib.py:133] step: 217900, training_loss: 2.76078e-02
I0209 10:15:39.519513 22542570456896 run_lib.py:146] step: 217900, eval_loss: 2.65219e-02
I0209 10:15:57.071539 22542570456896 run_lib.py:133] step: 217950, training_loss: 2.55528e-02
I0209 10:16:14.476418 22542570456896 run_lib.py:133] step: 218000, training_loss: 3.54264e-02
I0209 10:16:14.627365 22542570456896 run_lib.py:146] step: 218000, eval_loss: 2.96241e-02
I0209 10:16:32.009436 22542570456896 run_lib.py:133] step: 218050, training_loss: 2.95824e-02
I0209 10:16:49.441895 22542570456896 run_lib.py:133] step: 218100, training_loss: 2.23583e-02
I0209 10:16:49.607574 22542570456896 run_lib.py:146] step: 218100, eval_loss: 2.95420e-02
I0209 10:17:07.200347 22542570456896 run_lib.py:133] step: 218150, training_loss: 2.60285e-02
I0209 10:17:24.692112 22542570456896 run_lib.py:133] step: 218200, training_loss: 2.65047e-02
I0209 10:17:24.857403 22542570456896 run_lib.py:146] step: 218200, eval_loss: 3.01479e-02
I0209 10:17:42.234308 22542570456896 run_lib.py:133] step: 218250, training_loss: 2.37778e-02
I0209 10:17:59.628461 22542570456896 run_lib.py:133] step: 218300, training_loss: 2.82597e-02
I0209 10:17:59.784404 22542570456896 run_lib.py:146] step: 218300, eval_loss: 3.26700e-02
I0209 10:18:17.325896 22542570456896 run_lib.py:133] step: 218350, training_loss: 2.42978e-02
I0209 10:18:34.720880 22542570456896 run_lib.py:133] step: 218400, training_loss: 2.86569e-02
I0209 10:18:34.878664 22542570456896 run_lib.py:146] step: 218400, eval_loss: 3.20077e-02
I0209 10:18:52.467541 22542570456896 run_lib.py:133] step: 218450, training_loss: 3.45544e-02
I0209 10:19:09.865489 22542570456896 run_lib.py:133] step: 218500, training_loss: 2.84059e-02
I0209 10:19:10.019317 22542570456896 run_lib.py:146] step: 218500, eval_loss: 2.90115e-02
I0209 10:19:27.652780 22542570456896 run_lib.py:133] step: 218550, training_loss: 2.52736e-02
I0209 10:19:45.096074 22542570456896 run_lib.py:133] step: 218600, training_loss: 2.89475e-02
I0209 10:19:45.256986 22542570456896 run_lib.py:146] step: 218600, eval_loss: 2.40290e-02
I0209 10:20:02.793000 22542570456896 run_lib.py:133] step: 218650, training_loss: 2.79120e-02
I0209 10:20:20.217319 22542570456896 run_lib.py:133] step: 218700, training_loss: 2.59309e-02
I0209 10:20:20.386338 22542570456896 run_lib.py:146] step: 218700, eval_loss: 3.15630e-02
I0209 10:20:37.852765 22542570456896 run_lib.py:133] step: 218750, training_loss: 2.65500e-02
I0209 10:20:55.479341 22542570456896 run_lib.py:133] step: 218800, training_loss: 2.91851e-02
I0209 10:20:55.635859 22542570456896 run_lib.py:146] step: 218800, eval_loss: 3.75983e-02
I0209 10:21:13.063487 22542570456896 run_lib.py:133] step: 218850, training_loss: 2.76696e-02
I0209 10:21:30.476116 22542570456896 run_lib.py:133] step: 218900, training_loss: 2.75179e-02
I0209 10:21:30.628032 22542570456896 run_lib.py:146] step: 218900, eval_loss: 3.03831e-02
I0209 10:21:48.198915 22542570456896 run_lib.py:133] step: 218950, training_loss: 2.37476e-02
I0209 10:22:05.649091 22542570456896 run_lib.py:133] step: 219000, training_loss: 2.58606e-02
I0209 10:22:05.811133 22542570456896 run_lib.py:146] step: 219000, eval_loss: 2.63616e-02
I0209 10:22:23.431596 22542570456896 run_lib.py:133] step: 219050, training_loss: 2.79115e-02
I0209 10:22:40.870934 22542570456896 run_lib.py:133] step: 219100, training_loss: 3.18765e-02
I0209 10:22:41.030281 22542570456896 run_lib.py:146] step: 219100, eval_loss: 3.10061e-02
I0209 10:22:58.435276 22542570456896 run_lib.py:133] step: 219150, training_loss: 2.59360e-02
I0209 10:23:15.998498 22542570456896 run_lib.py:133] step: 219200, training_loss: 2.61160e-02
I0209 10:23:16.154295 22542570456896 run_lib.py:146] step: 219200, eval_loss: 3.37710e-02
I0209 10:23:33.585724 22542570456896 run_lib.py:133] step: 219250, training_loss: 4.13682e-02
I0209 10:23:51.090420 22542570456896 run_lib.py:133] step: 219300, training_loss: 2.31731e-02
I0209 10:23:51.245632 22542570456896 run_lib.py:146] step: 219300, eval_loss: 2.54827e-02
I0209 10:24:08.668022 22542570456896 run_lib.py:133] step: 219350, training_loss: 3.16419e-02
I0209 10:24:26.299659 22542570456896 run_lib.py:133] step: 219400, training_loss: 2.48410e-02
I0209 10:24:26.450987 22542570456896 run_lib.py:146] step: 219400, eval_loss: 2.98505e-02
I0209 10:24:43.876605 22542570456896 run_lib.py:133] step: 219450, training_loss: 2.53654e-02
I0209 10:25:01.355572 22542570456896 run_lib.py:133] step: 219500, training_loss: 2.79461e-02
I0209 10:25:01.510436 22542570456896 run_lib.py:146] step: 219500, eval_loss: 3.22958e-02
I0209 10:25:18.927312 22542570456896 run_lib.py:133] step: 219550, training_loss: 2.71773e-02
I0209 10:25:36.339607 22542570456896 run_lib.py:133] step: 219600, training_loss: 2.55838e-02
I0209 10:25:36.516276 22542570456896 run_lib.py:146] step: 219600, eval_loss: 2.93323e-02
I0209 10:25:54.135832 22542570456896 run_lib.py:133] step: 219650, training_loss: 3.43148e-02
I0209 10:26:11.709215 22542570456896 run_lib.py:133] step: 219700, training_loss: 3.45975e-02
I0209 10:26:11.865627 22542570456896 run_lib.py:146] step: 219700, eval_loss: 2.52242e-02
I0209 10:26:29.328238 22542570456896 run_lib.py:133] step: 219750, training_loss: 2.47843e-02
I0209 10:26:46.766740 22542570456896 run_lib.py:133] step: 219800, training_loss: 3.03197e-02
I0209 10:26:46.922427 22542570456896 run_lib.py:146] step: 219800, eval_loss: 3.24045e-02
I0209 10:27:04.481694 22542570456896 run_lib.py:133] step: 219850, training_loss: 2.76911e-02
I0209 10:27:22.025808 22542570456896 run_lib.py:133] step: 219900, training_loss: 2.47064e-02
I0209 10:27:22.180536 22542570456896 run_lib.py:146] step: 219900, eval_loss: 2.72255e-02
I0209 10:27:39.793897 22542570456896 run_lib.py:133] step: 219950, training_loss: 3.19581e-02
I0209 10:27:57.237930 22542570456896 run_lib.py:133] step: 220000, training_loss: 3.21532e-02
I0209 10:27:57.937238 22542570456896 run_lib.py:146] step: 220000, eval_loss: 2.24518e-02
I0209 10:28:18.241770 22542570456896 run_lib.py:133] step: 220050, training_loss: 2.92180e-02
I0209 10:28:35.651118 22542570456896 run_lib.py:133] step: 220100, training_loss: 3.09245e-02
I0209 10:28:35.820364 22542570456896 run_lib.py:146] step: 220100, eval_loss: 2.55412e-02
I0209 10:28:53.309870 22542570456896 run_lib.py:133] step: 220150, training_loss: 2.69796e-02
I0209 10:29:10.742711 22542570456896 run_lib.py:133] step: 220200, training_loss: 2.36434e-02
I0209 10:29:10.899394 22542570456896 run_lib.py:146] step: 220200, eval_loss: 2.60601e-02
I0209 10:29:28.315280 22542570456896 run_lib.py:133] step: 220250, training_loss: 3.10179e-02
I0209 10:29:45.742421 22542570456896 run_lib.py:133] step: 220300, training_loss: 2.81054e-02
I0209 10:29:45.899327 22542570456896 run_lib.py:146] step: 220300, eval_loss: 2.89226e-02
I0209 10:30:03.483092 22542570456896 run_lib.py:133] step: 220350, training_loss: 3.12781e-02
I0209 10:30:20.904445 22542570456896 run_lib.py:133] step: 220400, training_loss: 3.21909e-02
I0209 10:30:21.056438 22542570456896 run_lib.py:146] step: 220400, eval_loss: 2.64257e-02
I0209 10:30:38.514408 22542570456896 run_lib.py:133] step: 220450, training_loss: 3.02768e-02
I0209 10:30:56.033015 22542570456896 run_lib.py:133] step: 220500, training_loss: 2.41685e-02
I0209 10:30:56.203500 22542570456896 run_lib.py:146] step: 220500, eval_loss: 3.47325e-02
I0209 10:31:13.816278 22542570456896 run_lib.py:133] step: 220550, training_loss: 2.62527e-02
I0209 10:31:31.263483 22542570456896 run_lib.py:133] step: 220600, training_loss: 3.65965e-02
I0209 10:31:31.421593 22542570456896 run_lib.py:146] step: 220600, eval_loss: 2.75891e-02
I0209 10:31:48.949053 22542570456896 run_lib.py:133] step: 220650, training_loss: 3.29718e-02
I0209 10:32:06.373612 22542570456896 run_lib.py:133] step: 220700, training_loss: 2.64016e-02
I0209 10:32:06.546421 22542570456896 run_lib.py:146] step: 220700, eval_loss: 2.34707e-02
I0209 10:32:24.162366 22542570456896 run_lib.py:133] step: 220750, training_loss: 3.00210e-02
I0209 10:32:41.610244 22542570456896 run_lib.py:133] step: 220800, training_loss: 3.59528e-02
I0209 10:32:41.766816 22542570456896 run_lib.py:146] step: 220800, eval_loss: 3.35471e-02
I0209 10:32:59.217364 22542570456896 run_lib.py:133] step: 220850, training_loss: 3.03831e-02
I0209 10:33:16.825910 22542570456896 run_lib.py:133] step: 220900, training_loss: 3.09320e-02
I0209 10:33:16.976308 22542570456896 run_lib.py:146] step: 220900, eval_loss: 2.81934e-02
I0209 10:33:34.383942 22542570456896 run_lib.py:133] step: 220950, training_loss: 2.80988e-02
I0209 10:33:51.976927 22542570456896 run_lib.py:133] step: 221000, training_loss: 2.37505e-02
I0209 10:33:52.147465 22542570456896 run_lib.py:146] step: 221000, eval_loss: 3.27150e-02
I0209 10:34:09.588697 22542570456896 run_lib.py:133] step: 221050, training_loss: 2.52498e-02
I0209 10:34:27.079877 22542570456896 run_lib.py:133] step: 221100, training_loss: 3.56384e-02
I0209 10:34:27.240387 22542570456896 run_lib.py:146] step: 221100, eval_loss: 3.24903e-02
I0209 10:34:44.829347 22542570456896 run_lib.py:133] step: 221150, training_loss: 2.65180e-02
I0209 10:35:02.230948 22542570456896 run_lib.py:133] step: 221200, training_loss: 2.97447e-02
I0209 10:35:02.383827 22542570456896 run_lib.py:146] step: 221200, eval_loss: 2.53520e-02
I0209 10:35:19.850797 22542570456896 run_lib.py:133] step: 221250, training_loss: 2.59425e-02
I0209 10:35:37.397453 22542570456896 run_lib.py:133] step: 221300, training_loss: 2.86731e-02
I0209 10:35:37.552617 22542570456896 run_lib.py:146] step: 221300, eval_loss: 3.15634e-02
I0209 10:35:55.048106 22542570456896 run_lib.py:133] step: 221350, training_loss: 3.07410e-02
I0209 10:36:12.435696 22542570456896 run_lib.py:133] step: 221400, training_loss: 2.83805e-02
I0209 10:36:12.770095 22542570456896 run_lib.py:146] step: 221400, eval_loss: 2.80416e-02
I0209 10:36:30.209183 22542570456896 run_lib.py:133] step: 221450, training_loss: 2.94148e-02
I0209 10:36:47.616003 22542570456896 run_lib.py:133] step: 221500, training_loss: 2.48442e-02
I0209 10:36:47.771237 22542570456896 run_lib.py:146] step: 221500, eval_loss: 2.38348e-02
I0209 10:37:05.211424 22542570456896 run_lib.py:133] step: 221550, training_loss: 2.42786e-02
I0209 10:37:22.695108 22542570456896 run_lib.py:133] step: 221600, training_loss: 2.56896e-02
I0209 10:37:22.852495 22542570456896 run_lib.py:146] step: 221600, eval_loss: 2.96758e-02
I0209 10:37:40.440765 22542570456896 run_lib.py:133] step: 221650, training_loss: 2.82178e-02
I0209 10:37:57.909865 22542570456896 run_lib.py:133] step: 221700, training_loss: 2.52931e-02
I0209 10:37:58.064428 22542570456896 run_lib.py:146] step: 221700, eval_loss: 2.93040e-02
I0209 10:38:15.512304 22542570456896 run_lib.py:133] step: 221750, training_loss: 2.72213e-02
I0209 10:38:32.945677 22542570456896 run_lib.py:133] step: 221800, training_loss: 3.50177e-02
I0209 10:38:33.106359 22542570456896 run_lib.py:146] step: 221800, eval_loss: 2.73073e-02
I0209 10:38:50.751145 22542570456896 run_lib.py:133] step: 221850, training_loss: 2.71823e-02
I0209 10:39:08.274178 22542570456896 run_lib.py:133] step: 221900, training_loss: 2.76804e-02
I0209 10:39:08.429611 22542570456896 run_lib.py:146] step: 221900, eval_loss: 3.06749e-02
I0209 10:39:25.840169 22542570456896 run_lib.py:133] step: 221950, training_loss: 2.62912e-02
I0209 10:39:43.272509 22542570456896 run_lib.py:133] step: 222000, training_loss: 3.38287e-02
I0209 10:39:43.432195 22542570456896 run_lib.py:146] step: 222000, eval_loss: 2.98327e-02
I0209 10:40:00.990787 22542570456896 run_lib.py:133] step: 222050, training_loss: 3.12866e-02
I0209 10:40:18.407935 22542570456896 run_lib.py:133] step: 222100, training_loss: 2.66570e-02
I0209 10:40:18.575183 22542570456896 run_lib.py:146] step: 222100, eval_loss: 2.94061e-02
I0209 10:40:36.164858 22542570456896 run_lib.py:133] step: 222150, training_loss: 3.15111e-02
I0209 10:40:53.594537 22542570456896 run_lib.py:133] step: 222200, training_loss: 2.13983e-02
I0209 10:40:53.749391 22542570456896 run_lib.py:146] step: 222200, eval_loss: 2.64291e-02
I0209 10:41:11.367220 22542570456896 run_lib.py:133] step: 222250, training_loss: 2.75530e-02
I0209 10:41:28.761983 22542570456896 run_lib.py:133] step: 222300, training_loss: 2.18588e-02
I0209 10:41:28.916140 22542570456896 run_lib.py:146] step: 222300, eval_loss: 2.64868e-02
I0209 10:41:46.309009 22542570456896 run_lib.py:133] step: 222350, training_loss: 2.62589e-02
I0209 10:42:03.836346 22542570456896 run_lib.py:133] step: 222400, training_loss: 3.57189e-02
I0209 10:42:04.001518 22542570456896 run_lib.py:146] step: 222400, eval_loss: 2.78668e-02
I0209 10:42:21.513167 22542570456896 run_lib.py:133] step: 222450, training_loss: 2.93565e-02
I0209 10:42:39.115309 22542570456896 run_lib.py:133] step: 222500, training_loss: 2.93935e-02
I0209 10:42:39.274428 22542570456896 run_lib.py:146] step: 222500, eval_loss: 2.43776e-02
I0209 10:42:56.673707 22542570456896 run_lib.py:133] step: 222550, training_loss: 2.52624e-02
I0209 10:43:14.032649 22542570456896 run_lib.py:133] step: 222600, training_loss: 2.54799e-02
I0209 10:43:14.187336 22542570456896 run_lib.py:146] step: 222600, eval_loss: 2.53330e-02
I0209 10:43:31.758912 22542570456896 run_lib.py:133] step: 222650, training_loss: 2.46578e-02
I0209 10:43:49.156630 22542570456896 run_lib.py:133] step: 222700, training_loss: 2.09500e-02
I0209 10:43:49.324285 22542570456896 run_lib.py:146] step: 222700, eval_loss: 3.50602e-02
I0209 10:44:06.768057 22542570456896 run_lib.py:133] step: 222750, training_loss: 3.24408e-02
I0209 10:44:24.167493 22542570456896 run_lib.py:133] step: 222800, training_loss: 2.41147e-02
I0209 10:44:24.319587 22542570456896 run_lib.py:146] step: 222800, eval_loss: 2.66201e-02
I0209 10:44:41.976638 22542570456896 run_lib.py:133] step: 222850, training_loss: 2.69450e-02
I0209 10:44:59.394764 22542570456896 run_lib.py:133] step: 222900, training_loss: 2.80656e-02
I0209 10:44:59.550295 22542570456896 run_lib.py:146] step: 222900, eval_loss: 2.93976e-02
I0209 10:45:17.005959 22542570456896 run_lib.py:133] step: 222950, training_loss: 3.10692e-02
I0209 10:45:34.411962 22542570456896 run_lib.py:133] step: 223000, training_loss: 3.39157e-02
I0209 10:45:34.586345 22542570456896 run_lib.py:146] step: 223000, eval_loss: 3.38267e-02
I0209 10:45:52.047409 22542570456896 run_lib.py:133] step: 223050, training_loss: 3.41347e-02
I0209 10:46:09.464253 22542570456896 run_lib.py:133] step: 223100, training_loss: 3.33553e-02
I0209 10:46:09.619613 22542570456896 run_lib.py:146] step: 223100, eval_loss: 2.63478e-02
I0209 10:46:27.237539 22542570456896 run_lib.py:133] step: 223150, training_loss: 3.26090e-02
I0209 10:46:44.718304 22542570456896 run_lib.py:133] step: 223200, training_loss: 2.83202e-02
I0209 10:46:44.881400 22542570456896 run_lib.py:146] step: 223200, eval_loss: 2.28019e-02
I0209 10:47:02.349575 22542570456896 run_lib.py:133] step: 223250, training_loss: 2.87580e-02
I0209 10:47:19.792824 22542570456896 run_lib.py:133] step: 223300, training_loss: 2.57054e-02
I0209 10:47:19.947363 22542570456896 run_lib.py:146] step: 223300, eval_loss: 3.20400e-02
I0209 10:47:37.612037 22542570456896 run_lib.py:133] step: 223350, training_loss: 2.70169e-02
I0209 10:47:55.037544 22542570456896 run_lib.py:133] step: 223400, training_loss: 2.77867e-02
I0209 10:47:55.194280 22542570456896 run_lib.py:146] step: 223400, eval_loss: 2.79469e-02
I0209 10:48:12.789997 22542570456896 run_lib.py:133] step: 223450, training_loss: 2.64377e-02
I0209 10:48:30.216289 22542570456896 run_lib.py:133] step: 223500, training_loss: 2.12327e-02
I0209 10:48:30.374651 22542570456896 run_lib.py:146] step: 223500, eval_loss: 2.86437e-02
I0209 10:48:47.937593 22542570456896 run_lib.py:133] step: 223550, training_loss: 2.66005e-02
I0209 10:49:05.332312 22542570456896 run_lib.py:133] step: 223600, training_loss: 3.14630e-02
I0209 10:49:05.488093 22542570456896 run_lib.py:146] step: 223600, eval_loss: 2.71952e-02
I0209 10:49:23.024358 22542570456896 run_lib.py:133] step: 223650, training_loss: 2.50390e-02
I0209 10:49:40.336788 22542570456896 run_lib.py:133] step: 223700, training_loss: 3.28323e-02
I0209 10:49:40.490979 22542570456896 run_lib.py:146] step: 223700, eval_loss: 2.74133e-02
I0209 10:49:57.867298 22542570456896 run_lib.py:133] step: 223750, training_loss: 2.17868e-02
I0209 10:50:15.469141 22542570456896 run_lib.py:133] step: 223800, training_loss: 2.27744e-02
I0209 10:50:15.621371 22542570456896 run_lib.py:146] step: 223800, eval_loss: 3.00517e-02
I0209 10:50:33.066536 22542570456896 run_lib.py:133] step: 223850, training_loss: 2.36684e-02
I0209 10:50:50.507144 22542570456896 run_lib.py:133] step: 223900, training_loss: 2.80014e-02
I0209 10:50:50.685545 22542570456896 run_lib.py:146] step: 223900, eval_loss: 3.16547e-02
I0209 10:51:08.348758 22542570456896 run_lib.py:133] step: 223950, training_loss: 3.08035e-02
I0209 10:51:26.006312 22542570456896 run_lib.py:133] step: 224000, training_loss: 2.81756e-02
I0209 10:51:26.162536 22542570456896 run_lib.py:146] step: 224000, eval_loss: 3.22977e-02
I0209 10:51:43.589590 22542570456896 run_lib.py:133] step: 224050, training_loss: 3.20014e-02
I0209 10:52:01.043359 22542570456896 run_lib.py:133] step: 224100, training_loss: 2.33830e-02
I0209 10:52:01.198109 22542570456896 run_lib.py:146] step: 224100, eval_loss: 2.88176e-02
I0209 10:52:18.597412 22542570456896 run_lib.py:133] step: 224150, training_loss: 2.77255e-02
I0209 10:52:36.260711 22542570456896 run_lib.py:133] step: 224200, training_loss: 3.45150e-02
I0209 10:52:36.414220 22542570456896 run_lib.py:146] step: 224200, eval_loss: 2.60173e-02
I0209 10:52:53.864028 22542570456896 run_lib.py:133] step: 224250, training_loss: 2.58121e-02
I0209 10:53:11.264891 22542570456896 run_lib.py:133] step: 224300, training_loss: 3.36927e-02
I0209 10:53:11.417669 22542570456896 run_lib.py:146] step: 224300, eval_loss: 2.50523e-02
I0209 10:53:28.851296 22542570456896 run_lib.py:133] step: 224350, training_loss: 2.57522e-02
I0209 10:53:46.463432 22542570456896 run_lib.py:133] step: 224400, training_loss: 2.56346e-02
I0209 10:53:46.631498 22542570456896 run_lib.py:146] step: 224400, eval_loss: 3.13717e-02
I0209 10:54:04.079847 22542570456896 run_lib.py:133] step: 224450, training_loss: 2.85406e-02
I0209 10:54:21.599300 22542570456896 run_lib.py:133] step: 224500, training_loss: 2.69298e-02
I0209 10:54:21.755615 22542570456896 run_lib.py:146] step: 224500, eval_loss: 3.34694e-02
I0209 10:54:39.185992 22542570456896 run_lib.py:133] step: 224550, training_loss: 2.99981e-02
I0209 10:54:56.606690 22542570456896 run_lib.py:133] step: 224600, training_loss: 2.45630e-02
I0209 10:54:56.763373 22542570456896 run_lib.py:146] step: 224600, eval_loss: 2.60686e-02
I0209 10:55:14.350762 22542570456896 run_lib.py:133] step: 224650, training_loss: 2.58996e-02
I0209 10:55:31.810469 22542570456896 run_lib.py:133] step: 224700, training_loss: 2.50237e-02
I0209 10:55:31.963568 22542570456896 run_lib.py:146] step: 224700, eval_loss: 3.09929e-02
I0209 10:55:49.441541 22542570456896 run_lib.py:133] step: 224750, training_loss: 3.09657e-02
I0209 10:56:06.912750 22542570456896 run_lib.py:133] step: 224800, training_loss: 2.41105e-02
I0209 10:56:07.078353 22542570456896 run_lib.py:146] step: 224800, eval_loss: 2.56318e-02
I0209 10:56:24.678279 22542570456896 run_lib.py:133] step: 224850, training_loss: 2.64327e-02
I0209 10:56:42.120477 22542570456896 run_lib.py:133] step: 224900, training_loss: 2.72719e-02
I0209 10:56:42.278712 22542570456896 run_lib.py:146] step: 224900, eval_loss: 2.97453e-02
I0209 10:56:59.814094 22542570456896 run_lib.py:133] step: 224950, training_loss: 2.97764e-02
I0209 10:57:17.284336 22542570456896 run_lib.py:133] step: 225000, training_loss: 2.26863e-02
I0209 10:57:17.461358 22542570456896 run_lib.py:146] step: 225000, eval_loss: 2.94085e-02
I0209 10:57:35.078587 22542570456896 run_lib.py:133] step: 225050, training_loss: 2.47804e-02
I0209 10:57:52.511365 22542570456896 run_lib.py:133] step: 225100, training_loss: 2.94174e-02
I0209 10:57:52.667647 22542570456896 run_lib.py:146] step: 225100, eval_loss: 2.51803e-02
I0209 10:58:10.113864 22542570456896 run_lib.py:133] step: 225150, training_loss: 2.06032e-02
I0209 10:58:27.709655 22542570456896 run_lib.py:133] step: 225200, training_loss: 2.78002e-02
I0209 10:58:27.862451 22542570456896 run_lib.py:146] step: 225200, eval_loss: 3.43139e-02
I0209 10:58:45.287212 22542570456896 run_lib.py:133] step: 225250, training_loss: 3.02652e-02
I0209 10:59:02.821186 22542570456896 run_lib.py:133] step: 225300, training_loss: 2.24871e-02
I0209 10:59:02.995378 22542570456896 run_lib.py:146] step: 225300, eval_loss: 2.25050e-02
I0209 10:59:20.490848 22542570456896 run_lib.py:133] step: 225350, training_loss: 2.47862e-02
I0209 10:59:37.909376 22542570456896 run_lib.py:133] step: 225400, training_loss: 2.22501e-02
I0209 10:59:38.066286 22542570456896 run_lib.py:146] step: 225400, eval_loss: 2.42982e-02
I0209 10:59:55.707827 22542570456896 run_lib.py:133] step: 225450, training_loss: 2.40302e-02
I0209 11:00:13.129078 22542570456896 run_lib.py:133] step: 225500, training_loss: 2.72558e-02
I0209 11:00:13.285598 22542570456896 run_lib.py:146] step: 225500, eval_loss: 2.42665e-02
I0209 11:00:30.710830 22542570456896 run_lib.py:133] step: 225550, training_loss: 2.40973e-02
I0209 11:00:48.274998 22542570456896 run_lib.py:133] step: 225600, training_loss: 2.63732e-02
I0209 11:00:48.435188 22542570456896 run_lib.py:146] step: 225600, eval_loss: 2.59721e-02
I0209 11:01:05.905700 22542570456896 run_lib.py:133] step: 225650, training_loss: 3.21958e-02
I0209 11:01:23.368409 22542570456896 run_lib.py:133] step: 225700, training_loss: 2.46867e-02
I0209 11:01:23.520658 22542570456896 run_lib.py:146] step: 225700, eval_loss: 2.63130e-02
I0209 11:01:41.043998 22542570456896 run_lib.py:133] step: 225750, training_loss: 2.91306e-02
I0209 11:01:58.474690 22542570456896 run_lib.py:133] step: 225800, training_loss: 2.61583e-02
I0209 11:01:58.632702 22542570456896 run_lib.py:146] step: 225800, eval_loss: 2.67333e-02
I0209 11:02:16.018534 22542570456896 run_lib.py:133] step: 225850, training_loss: 2.51112e-02
I0209 11:02:33.474143 22542570456896 run_lib.py:133] step: 225900, training_loss: 2.78143e-02
I0209 11:02:33.634688 22542570456896 run_lib.py:146] step: 225900, eval_loss: 2.97041e-02
I0209 11:02:51.272053 22542570456896 run_lib.py:133] step: 225950, training_loss: 2.89625e-02
I0209 11:03:08.734364 22542570456896 run_lib.py:133] step: 226000, training_loss: 3.18466e-02
I0209 11:03:08.893168 22542570456896 run_lib.py:146] step: 226000, eval_loss: 2.93586e-02
I0209 11:03:26.308925 22542570456896 run_lib.py:133] step: 226050, training_loss: 3.36255e-02
I0209 11:03:43.717727 22542570456896 run_lib.py:133] step: 226100, training_loss: 3.99789e-02
I0209 11:03:43.868293 22542570456896 run_lib.py:146] step: 226100, eval_loss: 2.79963e-02
I0209 11:04:01.463292 22542570456896 run_lib.py:133] step: 226150, training_loss: 2.55034e-02
I0209 11:04:18.917906 22542570456896 run_lib.py:133] step: 226200, training_loss: 2.99288e-02
I0209 11:04:19.088688 22542570456896 run_lib.py:146] step: 226200, eval_loss: 2.83316e-02
I0209 11:04:36.720795 22542570456896 run_lib.py:133] step: 226250, training_loss: 3.32514e-02
I0209 11:04:54.175810 22542570456896 run_lib.py:133] step: 226300, training_loss: 2.83088e-02
I0209 11:04:54.341457 22542570456896 run_lib.py:146] step: 226300, eval_loss: 2.51305e-02
I0209 11:05:11.937070 22542570456896 run_lib.py:133] step: 226350, training_loss: 3.09981e-02
I0209 11:05:29.347576 22542570456896 run_lib.py:133] step: 226400, training_loss: 2.46716e-02
I0209 11:05:29.503218 22542570456896 run_lib.py:146] step: 226400, eval_loss: 2.17824e-02
I0209 11:05:47.114306 22542570456896 run_lib.py:133] step: 226450, training_loss: 3.12489e-02
I0209 11:06:04.573849 22542570456896 run_lib.py:133] step: 226500, training_loss: 2.39274e-02
I0209 11:06:04.736628 22542570456896 run_lib.py:146] step: 226500, eval_loss: 2.62555e-02
I0209 11:06:22.191222 22542570456896 run_lib.py:133] step: 226550, training_loss: 2.81297e-02
I0209 11:06:39.755356 22542570456896 run_lib.py:133] step: 226600, training_loss: 3.33594e-02
I0209 11:06:39.911372 22542570456896 run_lib.py:146] step: 226600, eval_loss: 2.64560e-02
I0209 11:06:57.318785 22542570456896 run_lib.py:133] step: 226650, training_loss: 3.01030e-02
I0209 11:07:14.749964 22542570456896 run_lib.py:133] step: 226700, training_loss: 3.11897e-02
I0209 11:07:14.911651 22542570456896 run_lib.py:146] step: 226700, eval_loss: 2.77498e-02
I0209 11:07:32.548740 22542570456896 run_lib.py:133] step: 226750, training_loss: 2.75889e-02
I0209 11:07:50.006649 22542570456896 run_lib.py:133] step: 226800, training_loss: 2.44332e-02
I0209 11:07:50.166370 22542570456896 run_lib.py:146] step: 226800, eval_loss: 3.54599e-02
I0209 11:08:07.811594 22542570456896 run_lib.py:133] step: 226850, training_loss: 2.81278e-02
I0209 11:08:25.229499 22542570456896 run_lib.py:133] step: 226900, training_loss: 2.67835e-02
I0209 11:08:25.384404 22542570456896 run_lib.py:146] step: 226900, eval_loss: 3.11504e-02
I0209 11:08:42.826458 22542570456896 run_lib.py:133] step: 226950, training_loss: 3.04090e-02
I0209 11:09:00.384584 22542570456896 run_lib.py:133] step: 227000, training_loss: 2.52138e-02
I0209 11:09:00.539297 22542570456896 run_lib.py:146] step: 227000, eval_loss: 2.66878e-02
I0209 11:09:18.024446 22542570456896 run_lib.py:133] step: 227050, training_loss: 2.75899e-02
I0209 11:09:35.506164 22542570456896 run_lib.py:133] step: 227100, training_loss: 2.66339e-02
I0209 11:09:35.661558 22542570456896 run_lib.py:146] step: 227100, eval_loss: 2.73752e-02
I0209 11:09:53.117110 22542570456896 run_lib.py:133] step: 227150, training_loss: 2.71079e-02
I0209 11:10:10.762514 22542570456896 run_lib.py:133] step: 227200, training_loss: 2.25670e-02
I0209 11:10:10.920776 22542570456896 run_lib.py:146] step: 227200, eval_loss: 2.80464e-02
I0209 11:10:28.315334 22542570456896 run_lib.py:133] step: 227250, training_loss: 2.89641e-02
I0209 11:10:45.792562 22542570456896 run_lib.py:133] step: 227300, training_loss: 2.65686e-02
I0209 11:10:45.960370 22542570456896 run_lib.py:146] step: 227300, eval_loss: 2.43446e-02
I0209 11:11:03.438043 22542570456896 run_lib.py:133] step: 227350, training_loss: 2.41357e-02
I0209 11:11:20.907599 22542570456896 run_lib.py:133] step: 227400, training_loss: 2.14319e-02
I0209 11:11:21.065371 22542570456896 run_lib.py:146] step: 227400, eval_loss: 2.75235e-02
I0209 11:11:38.680263 22542570456896 run_lib.py:133] step: 227450, training_loss: 2.34113e-02
I0209 11:11:56.203927 22542570456896 run_lib.py:133] step: 227500, training_loss: 3.18970e-02
I0209 11:11:56.358279 22542570456896 run_lib.py:146] step: 227500, eval_loss: 2.95168e-02
I0209 11:12:13.803282 22542570456896 run_lib.py:133] step: 227550, training_loss: 2.59070e-02
I0209 11:12:31.252536 22542570456896 run_lib.py:133] step: 227600, training_loss: 2.46846e-02
I0209 11:12:31.416957 22542570456896 run_lib.py:146] step: 227600, eval_loss: 2.48764e-02
I0209 11:12:49.038741 22542570456896 run_lib.py:133] step: 227650, training_loss: 2.68171e-02
I0209 11:13:06.504961 22542570456896 run_lib.py:133] step: 227700, training_loss: 2.64171e-02
I0209 11:13:06.671531 22542570456896 run_lib.py:146] step: 227700, eval_loss: 2.96265e-02
I0209 11:13:24.249274 22542570456896 run_lib.py:133] step: 227750, training_loss: 3.22075e-02
I0209 11:13:41.674908 22542570456896 run_lib.py:133] step: 227800, training_loss: 3.20080e-02
I0209 11:13:41.831374 22542570456896 run_lib.py:146] step: 227800, eval_loss: 2.87024e-02
I0209 11:13:59.389476 22542570456896 run_lib.py:133] step: 227850, training_loss: 3.20726e-02
I0209 11:14:16.827674 22542570456896 run_lib.py:133] step: 227900, training_loss: 3.17441e-02
I0209 11:14:16.984448 22542570456896 run_lib.py:146] step: 227900, eval_loss: 2.49080e-02
I0209 11:14:34.439112 22542570456896 run_lib.py:133] step: 227950, training_loss: 2.63190e-02
I0209 11:14:52.093275 22542570456896 run_lib.py:133] step: 228000, training_loss: 2.49628e-02
I0209 11:14:52.243496 22542570456896 run_lib.py:146] step: 228000, eval_loss: 3.28100e-02
I0209 11:15:09.643073 22542570456896 run_lib.py:133] step: 228050, training_loss: 2.32551e-02
I0209 11:15:27.209554 22542570456896 run_lib.py:133] step: 228100, training_loss: 2.93489e-02
I0209 11:15:27.364491 22542570456896 run_lib.py:146] step: 228100, eval_loss: 2.05334e-02
I0209 11:15:44.764451 22542570456896 run_lib.py:133] step: 228150, training_loss: 3.29674e-02
I0209 11:16:02.180258 22542570456896 run_lib.py:133] step: 228200, training_loss: 2.35722e-02
I0209 11:16:02.357359 22542570456896 run_lib.py:146] step: 228200, eval_loss: 2.96158e-02
I0209 11:16:19.984291 22542570456896 run_lib.py:133] step: 228250, training_loss: 2.22929e-02
I0209 11:16:37.451256 22542570456896 run_lib.py:133] step: 228300, training_loss: 2.81053e-02
I0209 11:16:37.616664 22542570456896 run_lib.py:146] step: 228300, eval_loss: 2.72031e-02
I0209 11:16:55.026662 22542570456896 run_lib.py:133] step: 228350, training_loss: 3.06929e-02
I0209 11:17:12.625616 22542570456896 run_lib.py:133] step: 228400, training_loss: 3.32145e-02
I0209 11:17:12.781183 22542570456896 run_lib.py:146] step: 228400, eval_loss: 3.60040e-02
I0209 11:17:30.247404 22542570456896 run_lib.py:133] step: 228450, training_loss: 3.13308e-02
I0209 11:17:47.670822 22542570456896 run_lib.py:133] step: 228500, training_loss: 3.05906e-02
I0209 11:17:47.977611 22542570456896 run_lib.py:146] step: 228500, eval_loss: 3.23156e-02
I0209 11:18:05.457946 22542570456896 run_lib.py:133] step: 228550, training_loss: 2.47629e-02
I0209 11:18:22.902704 22542570456896 run_lib.py:133] step: 228600, training_loss: 3.14811e-02
I0209 11:18:23.058674 22542570456896 run_lib.py:146] step: 228600, eval_loss: 3.39821e-02
I0209 11:18:40.506359 22542570456896 run_lib.py:133] step: 228650, training_loss: 2.75221e-02
I0209 11:18:57.944132 22542570456896 run_lib.py:133] step: 228700, training_loss: 2.27824e-02
I0209 11:18:58.103165 22542570456896 run_lib.py:146] step: 228700, eval_loss: 2.83854e-02
I0209 11:19:15.683574 22542570456896 run_lib.py:133] step: 228750, training_loss: 2.94144e-02
I0209 11:19:33.174887 22542570456896 run_lib.py:133] step: 228800, training_loss: 2.95963e-02
I0209 11:19:33.340740 22542570456896 run_lib.py:146] step: 228800, eval_loss: 2.38208e-02
I0209 11:19:50.789249 22542570456896 run_lib.py:133] step: 228850, training_loss: 3.00039e-02
I0209 11:20:08.260205 22542570456896 run_lib.py:133] step: 228900, training_loss: 2.97390e-02
I0209 11:20:08.414689 22542570456896 run_lib.py:146] step: 228900, eval_loss: 2.52568e-02
I0209 11:20:26.022170 22542570456896 run_lib.py:133] step: 228950, training_loss: 3.01970e-02
I0209 11:20:43.513251 22542570456896 run_lib.py:133] step: 229000, training_loss: 2.67678e-02
I0209 11:20:43.666367 22542570456896 run_lib.py:146] step: 229000, eval_loss: 3.21514e-02
I0209 11:21:01.101927 22542570456896 run_lib.py:133] step: 229050, training_loss: 3.04477e-02
I0209 11:21:18.551824 22542570456896 run_lib.py:133] step: 229100, training_loss: 3.18635e-02
I0209 11:21:18.727411 22542570456896 run_lib.py:146] step: 229100, eval_loss: 2.79189e-02
I0209 11:21:36.353500 22542570456896 run_lib.py:133] step: 229150, training_loss: 2.60765e-02
I0209 11:21:53.834138 22542570456896 run_lib.py:133] step: 229200, training_loss: 2.47011e-02
I0209 11:21:53.989421 22542570456896 run_lib.py:146] step: 229200, eval_loss: 3.27773e-02
I0209 11:22:11.610752 22542570456896 run_lib.py:133] step: 229250, training_loss: 2.49838e-02
I0209 11:22:29.063413 22542570456896 run_lib.py:133] step: 229300, training_loss: 2.95692e-02
I0209 11:22:29.215721 22542570456896 run_lib.py:146] step: 229300, eval_loss: 2.04941e-02
I0209 11:22:46.798919 22542570456896 run_lib.py:133] step: 229350, training_loss: 3.13366e-02
I0209 11:23:04.276190 22542570456896 run_lib.py:133] step: 229400, training_loss: 2.68819e-02
I0209 11:23:04.429201 22542570456896 run_lib.py:146] step: 229400, eval_loss: 2.33170e-02
I0209 11:23:21.941925 22542570456896 run_lib.py:133] step: 229450, training_loss: 3.49509e-02
I0209 11:23:39.572024 22542570456896 run_lib.py:133] step: 229500, training_loss: 2.16661e-02
I0209 11:23:39.726790 22542570456896 run_lib.py:146] step: 229500, eval_loss: 2.66760e-02
I0209 11:23:57.158044 22542570456896 run_lib.py:133] step: 229550, training_loss: 2.47814e-02
I0209 11:24:14.760055 22542570456896 run_lib.py:133] step: 229600, training_loss: 3.76800e-02
I0209 11:24:14.918619 22542570456896 run_lib.py:146] step: 229600, eval_loss: 2.53693e-02
I0209 11:24:32.384503 22542570456896 run_lib.py:133] step: 229650, training_loss: 2.91891e-02
I0209 11:24:49.826816 22542570456896 run_lib.py:133] step: 229700, training_loss: 4.39736e-02
I0209 11:24:49.995048 22542570456896 run_lib.py:146] step: 229700, eval_loss: 2.89013e-02
I0209 11:25:07.628243 22542570456896 run_lib.py:133] step: 229750, training_loss: 3.12415e-02
I0209 11:25:25.115003 22542570456896 run_lib.py:133] step: 229800, training_loss: 3.04067e-02
I0209 11:25:25.271739 22542570456896 run_lib.py:146] step: 229800, eval_loss: 3.71617e-02
I0209 11:25:42.773699 22542570456896 run_lib.py:133] step: 229850, training_loss: 2.95323e-02
I0209 11:26:00.232179 22542570456896 run_lib.py:133] step: 229900, training_loss: 2.65656e-02
I0209 11:26:00.382611 22542570456896 run_lib.py:146] step: 229900, eval_loss: 3.01108e-02
I0209 11:26:17.987506 22542570456896 run_lib.py:133] step: 229950, training_loss: 3.06040e-02
I0209 11:26:35.456362 22542570456896 run_lib.py:133] step: 230000, training_loss: 3.73062e-02
I0209 11:26:36.412558 22542570456896 run_lib.py:146] step: 230000, eval_loss: 2.90719e-02
I0209 11:26:56.854115 22542570456896 run_lib.py:133] step: 230050, training_loss: 2.70330e-02
I0209 11:27:14.293977 22542570456896 run_lib.py:133] step: 230100, training_loss: 2.98761e-02
I0209 11:27:14.453046 22542570456896 run_lib.py:146] step: 230100, eval_loss: 2.61597e-02
I0209 11:27:32.065514 22542570456896 run_lib.py:133] step: 230150, training_loss: 2.86045e-02
I0209 11:27:49.514609 22542570456896 run_lib.py:133] step: 230200, training_loss: 2.49363e-02
I0209 11:27:49.673681 22542570456896 run_lib.py:146] step: 230200, eval_loss: 2.11910e-02
I0209 11:28:07.122261 22542570456896 run_lib.py:133] step: 230250, training_loss: 2.60575e-02
I0209 11:28:24.687191 22542570456896 run_lib.py:133] step: 230300, training_loss: 3.31448e-02
I0209 11:28:24.859560 22542570456896 run_lib.py:146] step: 230300, eval_loss: 2.51938e-02
I0209 11:28:42.335936 22542570456896 run_lib.py:133] step: 230350, training_loss: 3.09679e-02
I0209 11:28:59.782005 22542570456896 run_lib.py:133] step: 230400, training_loss: 3.12204e-02
I0209 11:28:59.937636 22542570456896 run_lib.py:146] step: 230400, eval_loss: 3.02218e-02
I0209 11:29:17.431972 22542570456896 run_lib.py:133] step: 230450, training_loss: 2.87272e-02
I0209 11:29:35.077644 22542570456896 run_lib.py:133] step: 230500, training_loss: 3.08983e-02
I0209 11:29:35.230461 22542570456896 run_lib.py:146] step: 230500, eval_loss: 2.77834e-02
I0209 11:29:52.665763 22542570456896 run_lib.py:133] step: 230550, training_loss: 3.21490e-02
I0209 11:30:10.185316 22542570456896 run_lib.py:133] step: 230600, training_loss: 2.53622e-02
I0209 11:30:10.351397 22542570456896 run_lib.py:146] step: 230600, eval_loss: 2.53351e-02
I0209 11:30:27.839619 22542570456896 run_lib.py:133] step: 230650, training_loss: 3.52867e-02
I0209 11:30:45.279720 22542570456896 run_lib.py:133] step: 230700, training_loss: 3.11954e-02
I0209 11:30:45.440432 22542570456896 run_lib.py:146] step: 230700, eval_loss: 2.65432e-02
I0209 11:31:03.069732 22542570456896 run_lib.py:133] step: 230750, training_loss: 2.63748e-02
I0209 11:31:20.586980 22542570456896 run_lib.py:133] step: 230800, training_loss: 2.88417e-02
I0209 11:31:20.745634 22542570456896 run_lib.py:146] step: 230800, eval_loss: 2.90290e-02
I0209 11:31:38.218110 22542570456896 run_lib.py:133] step: 230850, training_loss: 2.87796e-02
I0209 11:31:55.654449 22542570456896 run_lib.py:133] step: 230900, training_loss: 2.48832e-02
I0209 11:31:55.809199 22542570456896 run_lib.py:146] step: 230900, eval_loss: 2.89797e-02
I0209 11:32:13.480154 22542570456896 run_lib.py:133] step: 230950, training_loss: 2.45717e-02
I0209 11:32:30.971461 22542570456896 run_lib.py:133] step: 231000, training_loss: 3.22642e-02
I0209 11:32:31.126375 22542570456896 run_lib.py:146] step: 231000, eval_loss: 2.59529e-02
I0209 11:32:48.737873 22542570456896 run_lib.py:133] step: 231050, training_loss: 3.12215e-02
I0209 11:33:06.175251 22542570456896 run_lib.py:133] step: 231100, training_loss: 2.15228e-02
I0209 11:33:06.334440 22542570456896 run_lib.py:146] step: 231100, eval_loss: 2.69969e-02
I0209 11:33:23.906672 22542570456896 run_lib.py:133] step: 231150, training_loss: 2.38729e-02
I0209 11:33:41.353998 22542570456896 run_lib.py:133] step: 231200, training_loss: 3.34011e-02
I0209 11:33:41.525527 22542570456896 run_lib.py:146] step: 231200, eval_loss: 3.02468e-02
I0209 11:33:59.067139 22542570456896 run_lib.py:133] step: 231250, training_loss: 2.46923e-02
I0209 11:34:16.799259 22542570456896 run_lib.py:133] step: 231300, training_loss: 2.97371e-02
I0209 11:34:16.955726 22542570456896 run_lib.py:146] step: 231300, eval_loss: 3.40420e-02
I0209 11:34:34.377248 22542570456896 run_lib.py:133] step: 231350, training_loss: 3.19012e-02
I0209 11:34:51.933729 22542570456896 run_lib.py:133] step: 231400, training_loss: 3.10865e-02
I0209 11:34:52.085117 22542570456896 run_lib.py:146] step: 231400, eval_loss: 2.96166e-02
I0209 11:35:09.517311 22542570456896 run_lib.py:133] step: 231450, training_loss: 3.38396e-02
I0209 11:35:26.921169 22542570456896 run_lib.py:133] step: 231500, training_loss: 2.78919e-02
I0209 11:35:27.100399 22542570456896 run_lib.py:146] step: 231500, eval_loss: 2.72824e-02
I0209 11:35:44.748291 22542570456896 run_lib.py:133] step: 231550, training_loss: 3.10406e-02
I0209 11:36:02.239928 22542570456896 run_lib.py:133] step: 231600, training_loss: 2.67711e-02
I0209 11:36:02.399348 22542570456896 run_lib.py:146] step: 231600, eval_loss: 3.49116e-02
I0209 11:36:19.810093 22542570456896 run_lib.py:133] step: 231650, training_loss: 2.69468e-02
I0209 11:36:37.242511 22542570456896 run_lib.py:133] step: 231700, training_loss: 2.63441e-02
I0209 11:36:37.399361 22542570456896 run_lib.py:146] step: 231700, eval_loss: 3.79932e-02
I0209 11:36:54.982954 22542570456896 run_lib.py:133] step: 231750, training_loss: 2.87521e-02
I0209 11:37:12.502233 22542570456896 run_lib.py:133] step: 231800, training_loss: 3.03875e-02
I0209 11:37:12.666356 22542570456896 run_lib.py:146] step: 231800, eval_loss: 2.32465e-02
I0209 11:37:30.209646 22542570456896 run_lib.py:133] step: 231850, training_loss: 2.68625e-02
I0209 11:37:47.659363 22542570456896 run_lib.py:133] step: 231900, training_loss: 2.37676e-02
I0209 11:37:47.812602 22542570456896 run_lib.py:146] step: 231900, eval_loss: 2.84474e-02
I0209 11:38:05.232302 22542570456896 run_lib.py:133] step: 231950, training_loss: 3.06649e-02
I0209 11:38:22.676978 22542570456896 run_lib.py:133] step: 232000, training_loss: 2.69848e-02
I0209 11:38:22.841618 22542570456896 run_lib.py:146] step: 232000, eval_loss: 2.80633e-02
I0209 11:38:40.437473 22542570456896 run_lib.py:133] step: 232050, training_loss: 2.73922e-02
I0209 11:38:57.997734 22542570456896 run_lib.py:133] step: 232100, training_loss: 2.84918e-02
I0209 11:38:58.160438 22542570456896 run_lib.py:146] step: 232100, eval_loss: 3.08477e-02
I0209 11:39:15.596750 22542570456896 run_lib.py:133] step: 232150, training_loss: 2.48054e-02
I0209 11:39:33.082629 22542570456896 run_lib.py:133] step: 232200, training_loss: 3.18954e-02
I0209 11:39:33.239188 22542570456896 run_lib.py:146] step: 232200, eval_loss: 2.98750e-02
I0209 11:39:50.873187 22542570456896 run_lib.py:133] step: 232250, training_loss: 2.79255e-02
I0209 11:40:08.301081 22542570456896 run_lib.py:133] step: 232300, training_loss: 2.24355e-02
I0209 11:40:08.455452 22542570456896 run_lib.py:146] step: 232300, eval_loss: 3.02520e-02
I0209 11:40:26.018388 22542570456896 run_lib.py:133] step: 232350, training_loss: 2.97542e-02
I0209 11:40:43.509264 22542570456896 run_lib.py:133] step: 232400, training_loss: 2.67486e-02
I0209 11:40:43.663682 22542570456896 run_lib.py:146] step: 232400, eval_loss: 3.16122e-02
I0209 11:41:01.280325 22542570456896 run_lib.py:133] step: 232450, training_loss: 3.32023e-02
I0209 11:41:18.710840 22542570456896 run_lib.py:133] step: 232500, training_loss: 3.37833e-02
I0209 11:41:18.877607 22542570456896 run_lib.py:146] step: 232500, eval_loss: 3.65198e-02
I0209 11:41:36.431972 22542570456896 run_lib.py:133] step: 232550, training_loss: 2.75038e-02
I0209 11:41:53.884591 22542570456896 run_lib.py:133] step: 232600, training_loss: 3.38904e-02
I0209 11:41:54.040308 22542570456896 run_lib.py:146] step: 232600, eval_loss: 3.42231e-02
I0209 11:42:11.453094 22542570456896 run_lib.py:133] step: 232650, training_loss: 2.77918e-02
I0209 11:42:29.131308 22542570456896 run_lib.py:133] step: 232700, training_loss: 2.67218e-02
I0209 11:42:29.287724 22542570456896 run_lib.py:146] step: 232700, eval_loss: 2.62798e-02
I0209 11:42:46.746092 22542570456896 run_lib.py:133] step: 232750, training_loss: 2.66389e-02
I0209 11:43:04.188176 22542570456896 run_lib.py:133] step: 232800, training_loss: 3.13347e-02
I0209 11:43:04.341526 22542570456896 run_lib.py:146] step: 232800, eval_loss: 3.67655e-02
I0209 11:43:21.987286 22542570456896 run_lib.py:133] step: 232850, training_loss: 2.33544e-02
I0209 11:43:39.557014 22542570456896 run_lib.py:133] step: 232900, training_loss: 2.42676e-02
I0209 11:43:39.711371 22542570456896 run_lib.py:146] step: 232900, eval_loss: 2.39554e-02
I0209 11:43:57.179913 22542570456896 run_lib.py:133] step: 232950, training_loss: 2.07819e-02
I0209 11:44:14.653096 22542570456896 run_lib.py:133] step: 233000, training_loss: 2.99222e-02
I0209 11:44:14.812401 22542570456896 run_lib.py:146] step: 233000, eval_loss: 2.46589e-02
I0209 11:44:32.230841 22542570456896 run_lib.py:133] step: 233050, training_loss: 2.45606e-02
I0209 11:44:49.856713 22542570456896 run_lib.py:133] step: 233100, training_loss: 2.96324e-02
I0209 11:44:50.012486 22542570456896 run_lib.py:146] step: 233100, eval_loss: 3.02442e-02
I0209 11:45:07.465874 22542570456896 run_lib.py:133] step: 233150, training_loss: 2.77206e-02
I0209 11:45:24.937009 22542570456896 run_lib.py:133] step: 233200, training_loss: 2.77064e-02
I0209 11:45:25.103065 22542570456896 run_lib.py:146] step: 233200, eval_loss: 2.97063e-02
I0209 11:45:42.600072 22542570456896 run_lib.py:133] step: 233250, training_loss: 2.97312e-02
I0209 11:46:00.212463 22542570456896 run_lib.py:133] step: 233300, training_loss: 2.71120e-02
I0209 11:46:00.364516 22542570456896 run_lib.py:146] step: 233300, eval_loss: 3.82420e-02
I0209 11:46:17.785186 22542570456896 run_lib.py:133] step: 233350, training_loss: 2.61229e-02
I0209 11:46:35.300881 22542570456896 run_lib.py:133] step: 233400, training_loss: 2.85858e-02
I0209 11:46:35.456419 22542570456896 run_lib.py:146] step: 233400, eval_loss: 3.03477e-02
I0209 11:46:52.872274 22542570456896 run_lib.py:133] step: 233450, training_loss: 2.95884e-02
I0209 11:47:10.312237 22542570456896 run_lib.py:133] step: 233500, training_loss: 2.84428e-02
I0209 11:47:10.489446 22542570456896 run_lib.py:146] step: 233500, eval_loss: 2.98127e-02
I0209 11:47:28.138971 22542570456896 run_lib.py:133] step: 233550, training_loss: 2.62573e-02
I0209 11:47:45.674932 22542570456896 run_lib.py:133] step: 233600, training_loss: 2.93905e-02
I0209 11:47:45.831582 22542570456896 run_lib.py:146] step: 233600, eval_loss: 3.18235e-02
I0209 11:48:03.254773 22542570456896 run_lib.py:133] step: 233650, training_loss: 2.43691e-02
I0209 11:48:20.651855 22542570456896 run_lib.py:133] step: 233700, training_loss: 2.49679e-02
I0209 11:48:20.806322 22542570456896 run_lib.py:146] step: 233700, eval_loss: 3.31568e-02
I0209 11:48:38.382446 22542570456896 run_lib.py:133] step: 233750, training_loss: 2.81454e-02
I0209 11:48:55.802045 22542570456896 run_lib.py:133] step: 233800, training_loss: 3.12217e-02
I0209 11:48:55.957852 22542570456896 run_lib.py:146] step: 233800, eval_loss: 2.57060e-02
I0209 11:49:13.614135 22542570456896 run_lib.py:133] step: 233850, training_loss: 2.76766e-02
I0209 11:49:31.056215 22542570456896 run_lib.py:133] step: 233900, training_loss: 2.68967e-02
I0209 11:49:31.212213 22542570456896 run_lib.py:146] step: 233900, eval_loss: 2.99952e-02
I0209 11:49:48.836869 22542570456896 run_lib.py:133] step: 233950, training_loss: 3.06232e-02
I0209 11:50:06.256033 22542570456896 run_lib.py:133] step: 234000, training_loss: 2.21242e-02
I0209 11:50:06.423776 22542570456896 run_lib.py:146] step: 234000, eval_loss: 2.93813e-02
I0209 11:50:23.871179 22542570456896 run_lib.py:133] step: 234050, training_loss: 3.21620e-02
I0209 11:50:41.504040 22542570456896 run_lib.py:133] step: 234100, training_loss: 2.02972e-02
I0209 11:50:41.659881 22542570456896 run_lib.py:146] step: 234100, eval_loss: 3.27406e-02
I0209 11:50:59.118763 22542570456896 run_lib.py:133] step: 234150, training_loss: 3.15559e-02
I0209 11:51:16.730752 22542570456896 run_lib.py:133] step: 234200, training_loss: 3.20136e-02
I0209 11:51:16.886422 22542570456896 run_lib.py:146] step: 234200, eval_loss: 2.43400e-02
I0209 11:51:34.317486 22542570456896 run_lib.py:133] step: 234250, training_loss: 2.99269e-02
I0209 11:51:51.778272 22542570456896 run_lib.py:133] step: 234300, training_loss: 2.84938e-02
I0209 11:51:51.931438 22542570456896 run_lib.py:146] step: 234300, eval_loss: 2.31400e-02
I0209 11:52:09.511843 22542570456896 run_lib.py:133] step: 234350, training_loss: 2.97875e-02
I0209 11:52:26.994746 22542570456896 run_lib.py:133] step: 234400, training_loss: 2.66114e-02
I0209 11:52:27.171065 22542570456896 run_lib.py:146] step: 234400, eval_loss: 2.55716e-02
I0209 11:52:44.639679 22542570456896 run_lib.py:133] step: 234450, training_loss: 2.79072e-02
I0209 11:53:02.262315 22542570456896 run_lib.py:133] step: 234500, training_loss: 3.04204e-02
I0209 11:53:02.418456 22542570456896 run_lib.py:146] step: 234500, eval_loss: 2.97829e-02
I0209 11:53:19.861210 22542570456896 run_lib.py:133] step: 234550, training_loss: 2.41905e-02
I0209 11:53:37.316419 22542570456896 run_lib.py:133] step: 234600, training_loss: 3.15297e-02
I0209 11:53:37.481238 22542570456896 run_lib.py:146] step: 234600, eval_loss: 2.58710e-02
I0209 11:53:55.011664 22542570456896 run_lib.py:133] step: 234650, training_loss: 3.43924e-02
I0209 11:54:12.488507 22542570456896 run_lib.py:133] step: 234700, training_loss: 2.96589e-02
I0209 11:54:12.641150 22542570456896 run_lib.py:146] step: 234700, eval_loss: 2.77153e-02
I0209 11:54:30.081984 22542570456896 run_lib.py:133] step: 234750, training_loss: 2.49152e-02
I0209 11:54:47.491919 22542570456896 run_lib.py:133] step: 234800, training_loss: 2.43046e-02
I0209 11:54:47.647409 22542570456896 run_lib.py:146] step: 234800, eval_loss: 2.90005e-02
I0209 11:55:05.234424 22542570456896 run_lib.py:133] step: 234850, training_loss: 2.53969e-02
I0209 11:55:22.733080 22542570456896 run_lib.py:133] step: 234900, training_loss: 3.50211e-02
I0209 11:55:22.911412 22542570456896 run_lib.py:146] step: 234900, eval_loss: 2.85396e-02
I0209 11:55:40.463602 22542570456896 run_lib.py:133] step: 234950, training_loss: 2.36267e-02
I0209 11:55:57.929545 22542570456896 run_lib.py:133] step: 235000, training_loss: 3.05641e-02
I0209 11:55:58.095216 22542570456896 run_lib.py:146] step: 235000, eval_loss: 2.93858e-02
I0209 11:56:15.716041 22542570456896 run_lib.py:133] step: 235050, training_loss: 2.62570e-02
I0209 11:56:33.157728 22542570456896 run_lib.py:133] step: 235100, training_loss: 3.10990e-02
I0209 11:56:33.321380 22542570456896 run_lib.py:146] step: 235100, eval_loss: 2.76683e-02
I0209 11:56:50.937862 22542570456896 run_lib.py:133] step: 235150, training_loss: 3.06427e-02
I0209 11:57:08.388044 22542570456896 run_lib.py:133] step: 235200, training_loss: 3.22697e-02
I0209 11:57:08.541678 22542570456896 run_lib.py:146] step: 235200, eval_loss: 2.73362e-02
I0209 11:57:26.220764 22542570456896 run_lib.py:133] step: 235250, training_loss: 3.59366e-02
I0209 11:57:43.652300 22542570456896 run_lib.py:133] step: 235300, training_loss: 2.64837e-02
I0209 11:57:43.808284 22542570456896 run_lib.py:146] step: 235300, eval_loss: 3.31862e-02
I0209 11:58:01.346592 22542570456896 run_lib.py:133] step: 235350, training_loss: 2.75702e-02
I0209 11:58:18.708981 22542570456896 run_lib.py:133] step: 235400, training_loss: 3.04017e-02
I0209 11:58:18.866525 22542570456896 run_lib.py:146] step: 235400, eval_loss: 2.90897e-02
I0209 11:58:36.221346 22542570456896 run_lib.py:133] step: 235450, training_loss: 2.78607e-02
I0209 11:58:53.711238 22542570456896 run_lib.py:133] step: 235500, training_loss: 2.97484e-02
I0209 11:58:53.882435 22542570456896 run_lib.py:146] step: 235500, eval_loss: 2.40310e-02
I0209 11:59:11.394194 22542570456896 run_lib.py:133] step: 235550, training_loss: 2.54573e-02
I0209 11:59:28.839771 22542570456896 run_lib.py:133] step: 235600, training_loss: 3.06489e-02
I0209 11:59:29.002806 22542570456896 run_lib.py:146] step: 235600, eval_loss: 2.79618e-02
I0209 11:59:46.710001 22542570456896 run_lib.py:133] step: 235650, training_loss: 2.69642e-02
I0209 12:00:04.176737 22542570456896 run_lib.py:133] step: 235700, training_loss: 2.55329e-02
I0209 12:00:04.329365 22542570456896 run_lib.py:146] step: 235700, eval_loss: 2.52426e-02
I0209 12:00:21.899783 22542570456896 run_lib.py:133] step: 235750, training_loss: 2.02250e-02
I0209 12:00:39.359071 22542570456896 run_lib.py:133] step: 235800, training_loss: 2.56011e-02
I0209 12:00:39.535340 22542570456896 run_lib.py:146] step: 235800, eval_loss: 2.92473e-02
I0209 12:00:56.995104 22542570456896 run_lib.py:133] step: 235850, training_loss: 2.86805e-02
I0209 12:01:14.678910 22542570456896 run_lib.py:133] step: 235900, training_loss: 2.48044e-02
I0209 12:01:14.837441 22542570456896 run_lib.py:146] step: 235900, eval_loss: 2.53501e-02
I0209 12:01:32.271238 22542570456896 run_lib.py:133] step: 235950, training_loss: 3.18046e-02
I0209 12:01:49.693619 22542570456896 run_lib.py:133] step: 236000, training_loss: 2.51287e-02
I0209 12:01:49.850171 22542570456896 run_lib.py:146] step: 236000, eval_loss: 2.28621e-02
I0209 12:02:07.286212 22542570456896 run_lib.py:133] step: 236050, training_loss: 2.57624e-02
I0209 12:02:24.950479 22542570456896 run_lib.py:133] step: 236100, training_loss: 3.78420e-02
I0209 12:02:25.106117 22542570456896 run_lib.py:146] step: 236100, eval_loss: 3.57662e-02
I0209 12:02:42.563235 22542570456896 run_lib.py:133] step: 236150, training_loss: 3.21676e-02
I0209 12:03:00.128619 22542570456896 run_lib.py:133] step: 236200, training_loss: 2.77376e-02
I0209 12:03:00.281596 22542570456896 run_lib.py:146] step: 236200, eval_loss: 3.26201e-02
I0209 12:03:17.694028 22542570456896 run_lib.py:133] step: 236250, training_loss: 2.44164e-02
I0209 12:03:35.141643 22542570456896 run_lib.py:133] step: 236300, training_loss: 2.86750e-02
I0209 12:03:35.301690 22542570456896 run_lib.py:146] step: 236300, eval_loss: 2.67219e-02
I0209 12:03:52.865627 22542570456896 run_lib.py:133] step: 236350, training_loss: 2.81974e-02
I0209 12:04:10.404671 22542570456896 run_lib.py:133] step: 236400, training_loss: 3.38581e-02
I0209 12:04:10.561325 22542570456896 run_lib.py:146] step: 236400, eval_loss: 3.56418e-02
I0209 12:04:28.037814 22542570456896 run_lib.py:133] step: 236450, training_loss: 3.25415e-02
I0209 12:04:45.507837 22542570456896 run_lib.py:133] step: 236500, training_loss: 3.18401e-02
I0209 12:04:45.663044 22542570456896 run_lib.py:146] step: 236500, eval_loss: 2.39065e-02
I0209 12:05:03.325578 22542570456896 run_lib.py:133] step: 236550, training_loss: 3.06814e-02
I0209 12:05:20.749919 22542570456896 run_lib.py:133] step: 236600, training_loss: 2.51362e-02
I0209 12:05:20.899077 22542570456896 run_lib.py:146] step: 236600, eval_loss: 2.96141e-02
I0209 12:05:38.481372 22542570456896 run_lib.py:133] step: 236650, training_loss: 2.17424e-02
I0209 12:05:55.985362 22542570456896 run_lib.py:133] step: 236700, training_loss: 2.80612e-02
I0209 12:05:56.149559 22542570456896 run_lib.py:146] step: 236700, eval_loss: 3.04684e-02
I0209 12:06:13.813055 22542570456896 run_lib.py:133] step: 236750, training_loss: 2.83668e-02
I0209 12:06:31.248849 22542570456896 run_lib.py:133] step: 236800, training_loss: 2.73029e-02
I0209 12:06:31.407778 22542570456896 run_lib.py:146] step: 236800, eval_loss: 2.62538e-02
I0209 12:06:48.834114 22542570456896 run_lib.py:133] step: 236850, training_loss: 3.14335e-02
I0209 12:07:06.386527 22542570456896 run_lib.py:133] step: 236900, training_loss: 3.29900e-02
I0209 12:07:06.542266 22542570456896 run_lib.py:146] step: 236900, eval_loss: 2.68513e-02
I0209 12:07:23.961100 22542570456896 run_lib.py:133] step: 236950, training_loss: 2.53479e-02
I0209 12:07:41.558938 22542570456896 run_lib.py:133] step: 237000, training_loss: 2.48593e-02
I0209 12:07:41.719731 22542570456896 run_lib.py:146] step: 237000, eval_loss: 3.49049e-02
I0209 12:07:59.191299 22542570456896 run_lib.py:133] step: 237050, training_loss: 3.19285e-02
I0209 12:08:16.674374 22542570456896 run_lib.py:133] step: 237100, training_loss: 2.59093e-02
I0209 12:08:16.826349 22542570456896 run_lib.py:146] step: 237100, eval_loss: 2.43619e-02
I0209 12:08:34.450860 22542570456896 run_lib.py:133] step: 237150, training_loss: 2.67244e-02
I0209 12:08:51.862164 22542570456896 run_lib.py:133] step: 237200, training_loss: 2.75536e-02
I0209 12:08:52.018659 22542570456896 run_lib.py:146] step: 237200, eval_loss: 2.80930e-02
I0209 12:09:09.461687 22542570456896 run_lib.py:133] step: 237250, training_loss: 2.71576e-02
I0209 12:09:27.113874 22542570456896 run_lib.py:133] step: 237300, training_loss: 3.41576e-02
I0209 12:09:27.274375 22542570456896 run_lib.py:146] step: 237300, eval_loss: 3.47650e-02
I0209 12:09:44.715740 22542570456896 run_lib.py:133] step: 237350, training_loss: 2.05612e-02
I0209 12:10:02.161391 22542570456896 run_lib.py:133] step: 237400, training_loss: 3.73242e-02
I0209 12:10:02.499354 22542570456896 run_lib.py:146] step: 237400, eval_loss: 3.64905e-02
I0209 12:10:19.958513 22542570456896 run_lib.py:133] step: 237450, training_loss: 2.54055e-02
I0209 12:10:37.390139 22542570456896 run_lib.py:133] step: 237500, training_loss: 2.65117e-02
I0209 12:10:37.544458 22542570456896 run_lib.py:146] step: 237500, eval_loss: 2.93342e-02
I0209 12:10:55.000095 22542570456896 run_lib.py:133] step: 237550, training_loss: 3.32547e-02
I0209 12:11:12.493261 22542570456896 run_lib.py:133] step: 237600, training_loss: 3.53294e-02
I0209 12:11:12.648649 22542570456896 run_lib.py:146] step: 237600, eval_loss: 2.67489e-02
I0209 12:11:30.279047 22542570456896 run_lib.py:133] step: 237650, training_loss: 2.98955e-02
I0209 12:11:47.839455 22542570456896 run_lib.py:133] step: 237700, training_loss: 2.41225e-02
I0209 12:11:47.998656 22542570456896 run_lib.py:146] step: 237700, eval_loss: 2.26441e-02
I0209 12:12:05.428216 22542570456896 run_lib.py:133] step: 237750, training_loss: 3.11499e-02
I0209 12:12:22.867578 22542570456896 run_lib.py:133] step: 237800, training_loss: 2.91622e-02
I0209 12:12:23.040515 22542570456896 run_lib.py:146] step: 237800, eval_loss: 2.31637e-02
I0209 12:12:40.682962 22542570456896 run_lib.py:133] step: 237850, training_loss: 2.56119e-02
I0209 12:12:58.274528 22542570456896 run_lib.py:133] step: 237900, training_loss: 3.25497e-02
I0209 12:12:58.433712 22542570456896 run_lib.py:146] step: 237900, eval_loss: 3.27216e-02
I0209 12:13:15.875724 22542570456896 run_lib.py:133] step: 237950, training_loss: 2.83084e-02
I0209 12:13:33.299686 22542570456896 run_lib.py:133] step: 238000, training_loss: 2.29602e-02
I0209 12:13:33.453329 22542570456896 run_lib.py:146] step: 238000, eval_loss: 3.18958e-02
I0209 12:13:51.028773 22542570456896 run_lib.py:133] step: 238050, training_loss: 2.83215e-02
I0209 12:14:08.462959 22542570456896 run_lib.py:133] step: 238100, training_loss: 2.56411e-02
I0209 12:14:08.622611 22542570456896 run_lib.py:146] step: 238100, eval_loss: 3.67689e-02
I0209 12:14:26.261303 22542570456896 run_lib.py:133] step: 238150, training_loss: 3.25190e-02
I0209 12:14:43.758357 22542570456896 run_lib.py:133] step: 238200, training_loss: 2.53341e-02
I0209 12:14:43.917370 22542570456896 run_lib.py:146] step: 238200, eval_loss: 3.14927e-02
I0209 12:15:01.538785 22542570456896 run_lib.py:133] step: 238250, training_loss: 2.81519e-02
I0209 12:15:18.963384 22542570456896 run_lib.py:133] step: 238300, training_loss: 2.31037e-02
I0209 12:15:19.119453 22542570456896 run_lib.py:146] step: 238300, eval_loss: 2.84769e-02
I0209 12:15:36.581747 22542570456896 run_lib.py:133] step: 238350, training_loss: 2.78869e-02
I0209 12:15:54.228032 22542570456896 run_lib.py:133] step: 238400, training_loss: 2.54446e-02
I0209 12:15:54.385297 22542570456896 run_lib.py:146] step: 238400, eval_loss: 2.32282e-02
I0209 12:16:11.896808 22542570456896 run_lib.py:133] step: 238450, training_loss: 2.69962e-02
I0209 12:16:29.481111 22542570456896 run_lib.py:133] step: 238500, training_loss: 2.67351e-02
I0209 12:16:29.633457 22542570456896 run_lib.py:146] step: 238500, eval_loss: 2.31425e-02
I0209 12:16:47.079823 22542570456896 run_lib.py:133] step: 238550, training_loss: 2.78134e-02
I0209 12:17:04.535012 22542570456896 run_lib.py:133] step: 238600, training_loss: 3.03341e-02
I0209 12:17:04.692417 22542570456896 run_lib.py:146] step: 238600, eval_loss: 2.92292e-02
I0209 12:17:22.275522 22542570456896 run_lib.py:133] step: 238650, training_loss: 3.72208e-02
I0209 12:17:39.707933 22542570456896 run_lib.py:133] step: 238700, training_loss: 2.48078e-02
I0209 12:17:39.884360 22542570456896 run_lib.py:146] step: 238700, eval_loss: 2.30366e-02
I0209 12:17:57.395936 22542570456896 run_lib.py:133] step: 238750, training_loss: 2.97484e-02
I0209 12:18:14.879579 22542570456896 run_lib.py:133] step: 238800, training_loss: 2.97973e-02
I0209 12:18:15.040646 22542570456896 run_lib.py:146] step: 238800, eval_loss: 2.51421e-02
I0209 12:18:32.650499 22542570456896 run_lib.py:133] step: 238850, training_loss: 3.05420e-02
I0209 12:18:50.076654 22542570456896 run_lib.py:133] step: 238900, training_loss: 2.80192e-02
I0209 12:18:50.232407 22542570456896 run_lib.py:146] step: 238900, eval_loss: 2.83495e-02
I0209 12:19:07.743825 22542570456896 run_lib.py:133] step: 238950, training_loss: 2.83297e-02
I0209 12:19:25.186247 22542570456896 run_lib.py:133] step: 239000, training_loss: 3.04887e-02
I0209 12:19:25.336958 22542570456896 run_lib.py:146] step: 239000, eval_loss: 2.68342e-02
I0209 12:19:42.896421 22542570456896 run_lib.py:133] step: 239050, training_loss: 2.31809e-02
I0209 12:20:00.306273 22542570456896 run_lib.py:133] step: 239100, training_loss: 3.51669e-02
I0209 12:20:00.462353 22542570456896 run_lib.py:146] step: 239100, eval_loss: 2.54551e-02
I0209 12:20:18.024465 22542570456896 run_lib.py:133] step: 239150, training_loss: 3.35898e-02
I0209 12:20:35.507942 22542570456896 run_lib.py:133] step: 239200, training_loss: 2.82214e-02
I0209 12:20:35.666577 22542570456896 run_lib.py:146] step: 239200, eval_loss: 2.69395e-02
I0209 12:20:53.099736 22542570456896 run_lib.py:133] step: 239250, training_loss: 3.56860e-02
I0209 12:21:10.558485 22542570456896 run_lib.py:133] step: 239300, training_loss: 2.47321e-02
I0209 12:21:10.714398 22542570456896 run_lib.py:146] step: 239300, eval_loss: 3.06234e-02
I0209 12:21:28.334474 22542570456896 run_lib.py:133] step: 239350, training_loss: 2.77648e-02
I0209 12:21:45.769473 22542570456896 run_lib.py:133] step: 239400, training_loss: 2.53391e-02
I0209 12:21:45.923420 22542570456896 run_lib.py:146] step: 239400, eval_loss: 3.18217e-02
I0209 12:22:03.494488 22542570456896 run_lib.py:133] step: 239450, training_loss: 3.66843e-02
I0209 12:22:20.922000 22542570456896 run_lib.py:133] step: 239500, training_loss: 2.77948e-02
I0209 12:22:21.072706 22542570456896 run_lib.py:146] step: 239500, eval_loss: 2.74107e-02
I0209 12:22:38.667326 22542570456896 run_lib.py:133] step: 239550, training_loss: 2.79693e-02
I0209 12:22:56.138664 22542570456896 run_lib.py:133] step: 239600, training_loss: 2.78292e-02
I0209 12:22:56.315389 22542570456896 run_lib.py:146] step: 239600, eval_loss: 2.46542e-02
I0209 12:23:14.011069 22542570456896 run_lib.py:133] step: 239650, training_loss: 3.17684e-02
I0209 12:23:31.518907 22542570456896 run_lib.py:133] step: 239700, training_loss: 2.93194e-02
I0209 12:23:31.674927 22542570456896 run_lib.py:146] step: 239700, eval_loss: 2.83653e-02
I0209 12:23:49.124321 22542570456896 run_lib.py:133] step: 239750, training_loss: 2.80706e-02
I0209 12:24:06.696628 22542570456896 run_lib.py:133] step: 239800, training_loss: 2.22186e-02
I0209 12:24:06.852227 22542570456896 run_lib.py:146] step: 239800, eval_loss: 3.05088e-02
I0209 12:24:24.303158 22542570456896 run_lib.py:133] step: 239850, training_loss: 2.34706e-02
I0209 12:24:41.811237 22542570456896 run_lib.py:133] step: 239900, training_loss: 3.69993e-02
I0209 12:24:41.967092 22542570456896 run_lib.py:146] step: 239900, eval_loss: 2.31837e-02
I0209 12:24:59.657640 22542570456896 run_lib.py:133] step: 239950, training_loss: 3.05785e-02
I0209 12:25:17.227806 22542570456896 run_lib.py:133] step: 240000, training_loss: 2.70711e-02
I0209 12:25:17.989214 22542570456896 run_lib.py:146] step: 240000, eval_loss: 2.93876e-02
I0209 12:25:38.232511 22542570456896 run_lib.py:133] step: 240050, training_loss: 3.38032e-02
I0209 12:25:55.731955 22542570456896 run_lib.py:133] step: 240100, training_loss: 2.78660e-02
I0209 12:25:55.899571 22542570456896 run_lib.py:146] step: 240100, eval_loss: 2.97617e-02
I0209 12:26:13.406511 22542570456896 run_lib.py:133] step: 240150, training_loss: 3.57416e-02
I0209 12:26:30.904885 22542570456896 run_lib.py:133] step: 240200, training_loss: 3.09388e-02
I0209 12:26:31.066405 22542570456896 run_lib.py:146] step: 240200, eval_loss: 2.30765e-02
I0209 12:26:48.672721 22542570456896 run_lib.py:133] step: 240250, training_loss: 2.39706e-02
I0209 12:27:06.194286 22542570456896 run_lib.py:133] step: 240300, training_loss: 3.23978e-02
I0209 12:27:06.350427 22542570456896 run_lib.py:146] step: 240300, eval_loss: 2.74957e-02
I0209 12:27:23.789859 22542570456896 run_lib.py:133] step: 240350, training_loss: 3.23857e-02
I0209 12:27:41.221348 22542570456896 run_lib.py:133] step: 240400, training_loss: 2.46381e-02
I0209 12:27:41.376577 22542570456896 run_lib.py:146] step: 240400, eval_loss: 2.32599e-02
I0209 12:27:58.990712 22542570456896 run_lib.py:133] step: 240450, training_loss: 2.84722e-02
I0209 12:28:16.440345 22542570456896 run_lib.py:133] step: 240500, training_loss: 3.08640e-02
I0209 12:28:16.592347 22542570456896 run_lib.py:146] step: 240500, eval_loss: 3.22950e-02
I0209 12:28:34.211277 22542570456896 run_lib.py:133] step: 240550, training_loss: 2.53866e-02
I0209 12:28:51.676977 22542570456896 run_lib.py:133] step: 240600, training_loss: 3.55589e-02
I0209 12:28:51.838409 22542570456896 run_lib.py:146] step: 240600, eval_loss: 3.12093e-02
I0209 12:29:09.414116 22542570456896 run_lib.py:133] step: 240650, training_loss: 2.92353e-02
I0209 12:29:26.841838 22542570456896 run_lib.py:133] step: 240700, training_loss: 2.96111e-02
I0209 12:29:27.009899 22542570456896 run_lib.py:146] step: 240700, eval_loss: 3.07021e-02
I0209 12:29:44.513747 22542570456896 run_lib.py:133] step: 240750, training_loss: 2.56046e-02
I0209 12:30:02.232934 22542570456896 run_lib.py:133] step: 240800, training_loss: 2.91028e-02
I0209 12:30:02.389659 22542570456896 run_lib.py:146] step: 240800, eval_loss: 3.17174e-02
I0209 12:30:19.860841 22542570456896 run_lib.py:133] step: 240850, training_loss: 2.65698e-02
I0209 12:30:37.436425 22542570456896 run_lib.py:133] step: 240900, training_loss: 2.49570e-02
I0209 12:30:37.591166 22542570456896 run_lib.py:146] step: 240900, eval_loss: 2.64511e-02
I0209 12:30:55.024091 22542570456896 run_lib.py:133] step: 240950, training_loss: 2.88173e-02
I0209 12:31:12.527054 22542570456896 run_lib.py:133] step: 241000, training_loss: 2.36589e-02
I0209 12:31:12.683753 22542570456896 run_lib.py:146] step: 241000, eval_loss: 2.75694e-02
I0209 12:31:30.362868 22542570456896 run_lib.py:133] step: 241050, training_loss: 3.04634e-02
I0209 12:31:47.830990 22542570456896 run_lib.py:133] step: 241100, training_loss: 2.77777e-02
I0209 12:31:47.988487 22542570456896 run_lib.py:146] step: 241100, eval_loss: 2.71109e-02
I0209 12:32:05.407257 22542570456896 run_lib.py:133] step: 241150, training_loss: 3.13912e-02
I0209 12:32:23.008125 22542570456896 run_lib.py:133] step: 241200, training_loss: 2.68837e-02
I0209 12:32:23.164698 22542570456896 run_lib.py:146] step: 241200, eval_loss: 2.31897e-02
I0209 12:32:40.585325 22542570456896 run_lib.py:133] step: 241250, training_loss: 2.69755e-02
I0209 12:32:58.081152 22542570456896 run_lib.py:133] step: 241300, training_loss: 2.37950e-02
I0209 12:32:58.237439 22542570456896 run_lib.py:146] step: 241300, eval_loss: 2.57817e-02
I0209 12:33:15.759127 22542570456896 run_lib.py:133] step: 241350, training_loss: 2.35620e-02
I0209 12:33:33.187628 22542570456896 run_lib.py:133] step: 241400, training_loss: 2.97046e-02
I0209 12:33:33.345196 22542570456896 run_lib.py:146] step: 241400, eval_loss: 2.30184e-02
I0209 12:33:50.811218 22542570456896 run_lib.py:133] step: 241450, training_loss: 2.74209e-02
I0209 12:34:08.268271 22542570456896 run_lib.py:133] step: 241500, training_loss: 2.66211e-02
I0209 12:34:08.422400 22542570456896 run_lib.py:146] step: 241500, eval_loss: 3.26145e-02
I0209 12:34:25.997191 22542570456896 run_lib.py:133] step: 241550, training_loss: 2.37969e-02
I0209 12:34:43.551895 22542570456896 run_lib.py:133] step: 241600, training_loss: 3.54391e-02
I0209 12:34:43.716468 22542570456896 run_lib.py:146] step: 241600, eval_loss: 3.23676e-02
I0209 12:35:01.156543 22542570456896 run_lib.py:133] step: 241650, training_loss: 2.62250e-02
I0209 12:35:18.633359 22542570456896 run_lib.py:133] step: 241700, training_loss: 2.64208e-02
I0209 12:35:18.797652 22542570456896 run_lib.py:146] step: 241700, eval_loss: 2.69036e-02
I0209 12:35:36.418254 22542570456896 run_lib.py:133] step: 241750, training_loss: 2.37108e-02
I0209 12:35:53.879429 22542570456896 run_lib.py:133] step: 241800, training_loss: 2.70258e-02
I0209 12:35:54.051647 22542570456896 run_lib.py:146] step: 241800, eval_loss: 3.22141e-02
I0209 12:36:11.679648 22542570456896 run_lib.py:133] step: 241850, training_loss: 2.76152e-02
I0209 12:36:29.130398 22542570456896 run_lib.py:133] step: 241900, training_loss: 2.43455e-02
I0209 12:36:29.282578 22542570456896 run_lib.py:146] step: 241900, eval_loss: 3.60649e-02
I0209 12:36:46.934501 22542570456896 run_lib.py:133] step: 241950, training_loss: 2.65023e-02
I0209 12:37:04.366671 22542570456896 run_lib.py:133] step: 242000, training_loss: 3.90331e-02
I0209 12:37:04.530182 22542570456896 run_lib.py:146] step: 242000, eval_loss: 2.91003e-02
I0209 12:37:22.074246 22542570456896 run_lib.py:133] step: 242050, training_loss: 2.50037e-02
I0209 12:37:39.511941 22542570456896 run_lib.py:133] step: 242100, training_loss: 2.44049e-02
I0209 12:37:39.687095 22542570456896 run_lib.py:146] step: 242100, eval_loss: 2.77794e-02
I0209 12:37:57.207005 22542570456896 run_lib.py:133] step: 242150, training_loss: 2.76803e-02
I0209 12:38:14.848340 22542570456896 run_lib.py:133] step: 242200, training_loss: 2.77625e-02
I0209 12:38:15.004583 22542570456896 run_lib.py:146] step: 242200, eval_loss: 3.17856e-02
I0209 12:38:32.447507 22542570456896 run_lib.py:133] step: 242250, training_loss: 1.86729e-02
I0209 12:38:49.865435 22542570456896 run_lib.py:133] step: 242300, training_loss: 2.77131e-02
I0209 12:38:50.021445 22542570456896 run_lib.py:146] step: 242300, eval_loss: 2.60561e-02
I0209 12:39:07.641965 22542570456896 run_lib.py:133] step: 242350, training_loss: 2.77214e-02
I0209 12:39:25.126781 22542570456896 run_lib.py:133] step: 242400, training_loss: 2.84705e-02
I0209 12:39:25.280672 22542570456896 run_lib.py:146] step: 242400, eval_loss: 3.65642e-02
I0209 12:39:42.917978 22542570456896 run_lib.py:133] step: 242450, training_loss: 2.63823e-02
I0209 12:40:00.325663 22542570456896 run_lib.py:133] step: 242500, training_loss: 3.13042e-02
I0209 12:40:00.486451 22542570456896 run_lib.py:146] step: 242500, eval_loss: 2.64165e-02
I0209 12:40:17.940232 22542570456896 run_lib.py:133] step: 242550, training_loss: 2.92164e-02
I0209 12:40:35.574990 22542570456896 run_lib.py:133] step: 242600, training_loss: 3.27516e-02
I0209 12:40:35.736620 22542570456896 run_lib.py:146] step: 242600, eval_loss: 2.90137e-02
I0209 12:40:53.220390 22542570456896 run_lib.py:133] step: 242650, training_loss: 3.42936e-02
I0209 12:41:10.698328 22542570456896 run_lib.py:133] step: 242700, training_loss: 2.96258e-02
I0209 12:41:10.855702 22542570456896 run_lib.py:146] step: 242700, eval_loss: 2.97844e-02
I0209 12:41:28.333786 22542570456896 run_lib.py:133] step: 242750, training_loss: 2.85378e-02
I0209 12:41:45.962350 22542570456896 run_lib.py:133] step: 242800, training_loss: 2.42765e-02
I0209 12:41:46.118447 22542570456896 run_lib.py:146] step: 242800, eval_loss: 2.78713e-02
I0209 12:42:03.554182 22542570456896 run_lib.py:133] step: 242850, training_loss: 3.00249e-02
I0209 12:42:21.047398 22542570456896 run_lib.py:133] step: 242900, training_loss: 2.84146e-02
I0209 12:42:21.198555 22542570456896 run_lib.py:146] step: 242900, eval_loss: 3.60213e-02
I0209 12:42:38.719367 22542570456896 run_lib.py:133] step: 242950, training_loss: 2.83033e-02
I0209 12:42:56.205697 22542570456896 run_lib.py:133] step: 243000, training_loss: 2.62482e-02
I0209 12:42:56.365504 22542570456896 run_lib.py:146] step: 243000, eval_loss: 3.13881e-02
I0209 12:43:13.995177 22542570456896 run_lib.py:133] step: 243050, training_loss: 3.08046e-02
I0209 12:43:31.555774 22542570456896 run_lib.py:133] step: 243100, training_loss: 2.73201e-02
I0209 12:43:31.711415 22542570456896 run_lib.py:146] step: 243100, eval_loss: 2.84982e-02
I0209 12:43:49.171444 22542570456896 run_lib.py:133] step: 243150, training_loss: 2.79939e-02
I0209 12:44:06.572858 22542570456896 run_lib.py:133] step: 243200, training_loss: 2.16808e-02
I0209 12:44:06.727562 22542570456896 run_lib.py:146] step: 243200, eval_loss: 2.77810e-02
I0209 12:44:24.300317 22542570456896 run_lib.py:133] step: 243250, training_loss: 2.92067e-02
I0209 12:44:41.793236 22542570456896 run_lib.py:133] step: 243300, training_loss: 3.22308e-02
I0209 12:44:41.954172 22542570456896 run_lib.py:146] step: 243300, eval_loss: 2.42638e-02
I0209 12:44:59.651883 22542570456896 run_lib.py:133] step: 243350, training_loss: 3.54473e-02
I0209 12:45:17.113327 22542570456896 run_lib.py:133] step: 243400, training_loss: 2.87325e-02
I0209 12:45:17.268405 22542570456896 run_lib.py:146] step: 243400, eval_loss: 2.80545e-02
I0209 12:45:34.840992 22542570456896 run_lib.py:133] step: 243450, training_loss: 3.25205e-02
I0209 12:45:52.249196 22542570456896 run_lib.py:133] step: 243500, training_loss: 2.77517e-02
I0209 12:45:52.416978 22542570456896 run_lib.py:146] step: 243500, eval_loss: 2.65005e-02
I0209 12:46:09.860584 22542570456896 run_lib.py:133] step: 243550, training_loss: 2.14459e-02
I0209 12:46:27.521538 22542570456896 run_lib.py:133] step: 243600, training_loss: 2.98121e-02
I0209 12:46:27.679619 22542570456896 run_lib.py:146] step: 243600, eval_loss: 3.41119e-02
I0209 12:46:45.138766 22542570456896 run_lib.py:133] step: 243650, training_loss: 2.42391e-02
I0209 12:47:02.754643 22542570456896 run_lib.py:133] step: 243700, training_loss: 2.78630e-02
I0209 12:47:02.911572 22542570456896 run_lib.py:146] step: 243700, eval_loss: 2.89118e-02
I0209 12:47:20.348527 22542570456896 run_lib.py:133] step: 243750, training_loss: 2.24321e-02
I0209 12:47:37.801041 22542570456896 run_lib.py:133] step: 243800, training_loss: 2.12428e-02
I0209 12:47:37.956432 22542570456896 run_lib.py:146] step: 243800, eval_loss: 2.53344e-02
I0209 12:47:55.612618 22542570456896 run_lib.py:133] step: 243850, training_loss: 3.38530e-02
I0209 12:48:13.066074 22542570456896 run_lib.py:133] step: 243900, training_loss: 2.59520e-02
I0209 12:48:13.221402 22542570456896 run_lib.py:146] step: 243900, eval_loss: 3.15377e-02
I0209 12:48:30.643055 22542570456896 run_lib.py:133] step: 243950, training_loss: 2.54887e-02
I0209 12:48:48.283134 22542570456896 run_lib.py:133] step: 244000, training_loss: 2.53085e-02
I0209 12:48:48.444608 22542570456896 run_lib.py:146] step: 244000, eval_loss: 3.46298e-02
I0209 12:49:05.868886 22542570456896 run_lib.py:133] step: 244050, training_loss: 3.64919e-02
I0209 12:49:23.400290 22542570456896 run_lib.py:133] step: 244100, training_loss: 2.88510e-02
I0209 12:49:23.721363 22542570456896 run_lib.py:146] step: 244100, eval_loss: 2.56133e-02
I0209 12:49:41.225544 22542570456896 run_lib.py:133] step: 244150, training_loss: 3.18679e-02
I0209 12:49:58.690915 22542570456896 run_lib.py:133] step: 244200, training_loss: 2.96074e-02
I0209 12:49:58.845505 22542570456896 run_lib.py:146] step: 244200, eval_loss: 2.63704e-02
I0209 12:50:16.306905 22542570456896 run_lib.py:133] step: 244250, training_loss: 2.18361e-02
I0209 12:50:33.753164 22542570456896 run_lib.py:133] step: 244300, training_loss: 3.18909e-02
I0209 12:50:33.911382 22542570456896 run_lib.py:146] step: 244300, eval_loss: 2.76249e-02
I0209 12:50:51.531211 22542570456896 run_lib.py:133] step: 244350, training_loss: 3.73794e-02
I0209 12:51:09.073856 22542570456896 run_lib.py:133] step: 244400, training_loss: 2.99622e-02
I0209 12:51:09.244732 22542570456896 run_lib.py:146] step: 244400, eval_loss: 1.94791e-02
I0209 12:51:26.753648 22542570456896 run_lib.py:133] step: 244450, training_loss: 2.75441e-02
I0209 12:51:44.236223 22542570456896 run_lib.py:133] step: 244500, training_loss: 3.04940e-02
I0209 12:51:44.394628 22542570456896 run_lib.py:146] step: 244500, eval_loss: 3.00800e-02
I0209 12:52:02.005249 22542570456896 run_lib.py:133] step: 244550, training_loss: 3.28299e-02
I0209 12:52:19.531361 22542570456896 run_lib.py:133] step: 244600, training_loss: 2.55156e-02
I0209 12:52:19.688187 22542570456896 run_lib.py:146] step: 244600, eval_loss: 3.07745e-02
I0209 12:52:37.142542 22542570456896 run_lib.py:133] step: 244650, training_loss: 2.92918e-02
I0209 12:52:54.669323 22542570456896 run_lib.py:133] step: 244700, training_loss: 2.32093e-02
I0209 12:52:54.823598 22542570456896 run_lib.py:146] step: 244700, eval_loss: 2.91973e-02
I0209 12:53:12.434602 22542570456896 run_lib.py:133] step: 244750, training_loss: 3.14843e-02
I0209 12:53:29.866045 22542570456896 run_lib.py:133] step: 244800, training_loss: 2.98793e-02
I0209 12:53:30.019414 22542570456896 run_lib.py:146] step: 244800, eval_loss: 2.26815e-02
I0209 12:53:47.561810 22542570456896 run_lib.py:133] step: 244850, training_loss: 2.42218e-02
I0209 12:54:05.021265 22542570456896 run_lib.py:133] step: 244900, training_loss: 2.58445e-02
I0209 12:54:05.180659 22542570456896 run_lib.py:146] step: 244900, eval_loss: 2.82352e-02
I0209 12:54:22.759144 22542570456896 run_lib.py:133] step: 244950, training_loss: 2.99357e-02
I0209 12:54:40.237467 22542570456896 run_lib.py:133] step: 245000, training_loss: 2.38991e-02
I0209 12:54:40.393737 22542570456896 run_lib.py:146] step: 245000, eval_loss: 3.09682e-02
I0209 12:54:57.826297 22542570456896 run_lib.py:133] step: 245050, training_loss: 2.72923e-02
I0209 12:55:15.433985 22542570456896 run_lib.py:133] step: 245100, training_loss: 3.29379e-02
I0209 12:55:15.590586 22542570456896 run_lib.py:146] step: 245100, eval_loss: 3.17329e-02
I0209 12:55:33.060260 22542570456896 run_lib.py:133] step: 245150, training_loss: 2.55307e-02
I0209 12:55:50.641921 22542570456896 run_lib.py:133] step: 245200, training_loss: 2.95410e-02
I0209 12:55:50.794167 22542570456896 run_lib.py:146] step: 245200, eval_loss: 2.51122e-02
I0209 12:56:08.233718 22542570456896 run_lib.py:133] step: 245250, training_loss: 3.49287e-02
I0209 12:56:25.710435 22542570456896 run_lib.py:133] step: 245300, training_loss: 2.59029e-02
I0209 12:56:25.872570 22542570456896 run_lib.py:146] step: 245300, eval_loss: 3.01092e-02
I0209 12:56:43.549337 22542570456896 run_lib.py:133] step: 245350, training_loss: 2.54064e-02
I0209 12:57:01.010739 22542570456896 run_lib.py:133] step: 245400, training_loss: 3.17602e-02
I0209 12:57:01.172599 22542570456896 run_lib.py:146] step: 245400, eval_loss: 2.53345e-02
I0209 12:57:18.595746 22542570456896 run_lib.py:133] step: 245450, training_loss: 2.61489e-02
I0209 12:57:36.034505 22542570456896 run_lib.py:133] step: 245500, training_loss: 2.49153e-02
I0209 12:57:36.204301 22542570456896 run_lib.py:146] step: 245500, eval_loss: 3.27260e-02
I0209 12:57:53.818444 22542570456896 run_lib.py:133] step: 245550, training_loss: 3.00758e-02
I0209 12:58:11.280220 22542570456896 run_lib.py:133] step: 245600, training_loss: 2.53046e-02
I0209 12:58:11.437938 22542570456896 run_lib.py:146] step: 245600, eval_loss: 2.76668e-02
I0209 12:58:29.017754 22542570456896 run_lib.py:133] step: 245650, training_loss: 2.36561e-02
I0209 12:58:46.456500 22542570456896 run_lib.py:133] step: 245700, training_loss: 2.96653e-02
I0209 12:58:46.620515 22542570456896 run_lib.py:146] step: 245700, eval_loss: 3.08903e-02
I0209 12:59:04.041701 22542570456896 run_lib.py:133] step: 245750, training_loss: 2.43833e-02
I0209 12:59:21.463368 22542570456896 run_lib.py:133] step: 245800, training_loss: 3.14016e-02
I0209 12:59:21.637538 22542570456896 run_lib.py:146] step: 245800, eval_loss: 2.03697e-02
I0209 12:59:39.258715 22542570456896 run_lib.py:133] step: 245850, training_loss: 3.14131e-02
I0209 12:59:56.840029 22542570456896 run_lib.py:133] step: 245900, training_loss: 3.38586e-02
I0209 12:59:56.998379 22542570456896 run_lib.py:146] step: 245900, eval_loss: 2.79358e-02
I0209 13:00:14.440142 22542570456896 run_lib.py:133] step: 245950, training_loss: 2.70630e-02
I0209 13:00:31.833355 22542570456896 run_lib.py:133] step: 246000, training_loss: 2.69014e-02
I0209 13:00:31.990638 22542570456896 run_lib.py:146] step: 246000, eval_loss: 2.93150e-02
I0209 13:00:49.595810 22542570456896 run_lib.py:133] step: 246050, training_loss: 3.25717e-02
I0209 13:01:07.081387 22542570456896 run_lib.py:133] step: 246100, training_loss: 3.47540e-02
I0209 13:01:07.237138 22542570456896 run_lib.py:146] step: 246100, eval_loss: 2.28689e-02
I0209 13:01:24.863148 22542570456896 run_lib.py:133] step: 246150, training_loss: 2.89678e-02
I0209 13:01:42.312117 22542570456896 run_lib.py:133] step: 246200, training_loss: 2.74245e-02
I0209 13:01:42.464372 22542570456896 run_lib.py:146] step: 246200, eval_loss: 2.54973e-02
I0209 13:02:00.114273 22542570456896 run_lib.py:133] step: 246250, training_loss: 2.86731e-02
I0209 13:02:17.529964 22542570456896 run_lib.py:133] step: 246300, training_loss: 2.56322e-02
I0209 13:02:17.686349 22542570456896 run_lib.py:146] step: 246300, eval_loss: 2.67776e-02
I0209 13:02:35.269516 22542570456896 run_lib.py:133] step: 246350, training_loss: 2.98103e-02
I0209 13:02:52.764359 22542570456896 run_lib.py:133] step: 246400, training_loss: 2.60508e-02
I0209 13:02:52.923364 22542570456896 run_lib.py:146] step: 246400, eval_loss: 2.27158e-02
I0209 13:03:10.378444 22542570456896 run_lib.py:133] step: 246450, training_loss: 3.23908e-02
I0209 13:03:27.999487 22542570456896 run_lib.py:133] step: 246500, training_loss: 2.86453e-02
I0209 13:03:28.155475 22542570456896 run_lib.py:146] step: 246500, eval_loss: 3.60911e-02
I0209 13:03:45.575388 22542570456896 run_lib.py:133] step: 246550, training_loss: 2.15126e-02
I0209 13:04:03.011517 22542570456896 run_lib.py:133] step: 246600, training_loss: 2.81023e-02
I0209 13:04:03.166508 22542570456896 run_lib.py:146] step: 246600, eval_loss: 2.85253e-02
I0209 13:04:20.755322 22542570456896 run_lib.py:133] step: 246650, training_loss: 2.38653e-02
I0209 13:04:38.432229 22542570456896 run_lib.py:133] step: 246700, training_loss: 3.09619e-02
I0209 13:04:38.587641 22542570456896 run_lib.py:146] step: 246700, eval_loss: 2.85273e-02
I0209 13:04:56.068513 22542570456896 run_lib.py:133] step: 246750, training_loss: 2.89087e-02
I0209 13:05:13.538269 22542570456896 run_lib.py:133] step: 246800, training_loss: 3.06009e-02
I0209 13:05:13.696719 22542570456896 run_lib.py:146] step: 246800, eval_loss: 2.91871e-02
I0209 13:05:31.140913 22542570456896 run_lib.py:133] step: 246850, training_loss: 2.65418e-02
I0209 13:05:48.710011 22542570456896 run_lib.py:133] step: 246900, training_loss: 3.37273e-02
I0209 13:05:48.866666 22542570456896 run_lib.py:146] step: 246900, eval_loss: 2.92748e-02
I0209 13:06:06.346524 22542570456896 run_lib.py:133] step: 246950, training_loss: 2.57186e-02
I0209 13:06:23.833602 22542570456896 run_lib.py:133] step: 247000, training_loss: 2.79343e-02
I0209 13:06:23.990407 22542570456896 run_lib.py:146] step: 247000, eval_loss: 3.21245e-02
I0209 13:06:41.438643 22542570456896 run_lib.py:133] step: 247050, training_loss: 2.88281e-02
I0209 13:06:58.996332 22542570456896 run_lib.py:133] step: 247100, training_loss: 2.37698e-02
I0209 13:06:59.153325 22542570456896 run_lib.py:146] step: 247100, eval_loss: 3.34289e-02
I0209 13:07:16.504997 22542570456896 run_lib.py:133] step: 247150, training_loss: 2.88649e-02
I0209 13:07:33.975544 22542570456896 run_lib.py:133] step: 247200, training_loss: 2.99294e-02
I0209 13:07:34.133598 22542570456896 run_lib.py:146] step: 247200, eval_loss: 3.23417e-02
I0209 13:07:51.642514 22542570456896 run_lib.py:133] step: 247250, training_loss: 3.13401e-02
I0209 13:08:09.097175 22542570456896 run_lib.py:133] step: 247300, training_loss: 3.20165e-02
I0209 13:08:09.255381 22542570456896 run_lib.py:146] step: 247300, eval_loss: 3.33404e-02
I0209 13:08:26.870549 22542570456896 run_lib.py:133] step: 247350, training_loss: 3.17755e-02
I0209 13:08:44.359254 22542570456896 run_lib.py:133] step: 247400, training_loss: 2.62635e-02
I0209 13:08:44.515514 22542570456896 run_lib.py:146] step: 247400, eval_loss: 3.15761e-02
I0209 13:09:01.984868 22542570456896 run_lib.py:133] step: 247450, training_loss: 2.90520e-02
I0209 13:09:19.415446 22542570456896 run_lib.py:133] step: 247500, training_loss: 2.61450e-02
I0209 13:09:19.581346 22542570456896 run_lib.py:146] step: 247500, eval_loss: 2.57819e-02
I0209 13:09:37.211041 22542570456896 run_lib.py:133] step: 247550, training_loss: 2.97514e-02
I0209 13:09:54.692900 22542570456896 run_lib.py:133] step: 247600, training_loss: 2.55914e-02
I0209 13:09:54.845671 22542570456896 run_lib.py:146] step: 247600, eval_loss: 2.40097e-02
I0209 13:10:12.505551 22542570456896 run_lib.py:133] step: 247650, training_loss: 3.36071e-02
I0209 13:10:29.951197 22542570456896 run_lib.py:133] step: 247700, training_loss: 2.82098e-02
I0209 13:10:30.106432 22542570456896 run_lib.py:146] step: 247700, eval_loss: 3.30384e-02
I0209 13:10:47.695277 22542570456896 run_lib.py:133] step: 247750, training_loss: 3.11544e-02
I0209 13:11:05.174157 22542570456896 run_lib.py:133] step: 247800, training_loss: 2.46033e-02
I0209 13:11:05.351525 22542570456896 run_lib.py:146] step: 247800, eval_loss: 2.62019e-02
I0209 13:11:22.861370 22542570456896 run_lib.py:133] step: 247850, training_loss: 2.37252e-02
I0209 13:11:40.514831 22542570456896 run_lib.py:133] step: 247900, training_loss: 2.57659e-02
I0209 13:11:40.671655 22542570456896 run_lib.py:146] step: 247900, eval_loss: 2.85932e-02
I0209 13:11:58.128793 22542570456896 run_lib.py:133] step: 247950, training_loss: 2.30527e-02
I0209 13:12:15.713306 22542570456896 run_lib.py:133] step: 248000, training_loss: 2.62270e-02
I0209 13:12:15.867337 22542570456896 run_lib.py:146] step: 248000, eval_loss: 3.30182e-02
I0209 13:12:33.300443 22542570456896 run_lib.py:133] step: 248050, training_loss: 3.16868e-02
I0209 13:12:50.752089 22542570456896 run_lib.py:133] step: 248100, training_loss: 2.39798e-02
I0209 13:12:50.908185 22542570456896 run_lib.py:146] step: 248100, eval_loss: 2.79749e-02
I0209 13:13:08.564192 22542570456896 run_lib.py:133] step: 248150, training_loss: 2.87052e-02
I0209 13:13:26.026605 22542570456896 run_lib.py:133] step: 248200, training_loss: 2.79890e-02
I0209 13:13:26.183564 22542570456896 run_lib.py:146] step: 248200, eval_loss: 2.50610e-02
I0209 13:13:43.626913 22542570456896 run_lib.py:133] step: 248250, training_loss: 2.79834e-02
I0209 13:14:01.208979 22542570456896 run_lib.py:133] step: 248300, training_loss: 2.64924e-02
I0209 13:14:01.375756 22542570456896 run_lib.py:146] step: 248300, eval_loss: 3.81271e-02
I0209 13:14:18.870734 22542570456896 run_lib.py:133] step: 248350, training_loss: 2.66517e-02
I0209 13:14:36.407162 22542570456896 run_lib.py:133] step: 248400, training_loss: 2.49540e-02
I0209 13:14:36.563148 22542570456896 run_lib.py:146] step: 248400, eval_loss: 2.60840e-02
I0209 13:14:54.089938 22542570456896 run_lib.py:133] step: 248450, training_loss: 2.78614e-02
I0209 13:15:11.557785 22542570456896 run_lib.py:133] step: 248500, training_loss: 3.08573e-02
I0209 13:15:11.708961 22542570456896 run_lib.py:146] step: 248500, eval_loss: 2.71885e-02
I0209 13:15:29.166447 22542570456896 run_lib.py:133] step: 248550, training_loss: 2.33959e-02
I0209 13:15:46.611274 22542570456896 run_lib.py:133] step: 248600, training_loss: 2.59479e-02
I0209 13:15:46.763993 22542570456896 run_lib.py:146] step: 248600, eval_loss: 3.74285e-02
I0209 13:16:04.373076 22542570456896 run_lib.py:133] step: 248650, training_loss: 3.03287e-02
I0209 13:16:21.916204 22542570456896 run_lib.py:133] step: 248700, training_loss: 2.19575e-02
I0209 13:16:22.076391 22542570456896 run_lib.py:146] step: 248700, eval_loss: 2.99245e-02
I0209 13:16:39.548511 22542570456896 run_lib.py:133] step: 248750, training_loss: 2.16693e-02
I0209 13:16:57.005074 22542570456896 run_lib.py:133] step: 248800, training_loss: 2.85544e-02
I0209 13:16:57.162597 22542570456896 run_lib.py:146] step: 248800, eval_loss: 2.68256e-02
I0209 13:17:14.777071 22542570456896 run_lib.py:133] step: 248850, training_loss: 2.54275e-02
I0209 13:17:32.201442 22542570456896 run_lib.py:133] step: 248900, training_loss: 2.69821e-02
I0209 13:17:32.374222 22542570456896 run_lib.py:146] step: 248900, eval_loss: 3.26216e-02
I0209 13:17:49.977661 22542570456896 run_lib.py:133] step: 248950, training_loss: 2.73816e-02
I0209 13:18:07.465293 22542570456896 run_lib.py:133] step: 249000, training_loss: 3.43470e-02
I0209 13:18:07.627202 22542570456896 run_lib.py:146] step: 249000, eval_loss: 3.03215e-02
I0209 13:18:25.274461 22542570456896 run_lib.py:133] step: 249050, training_loss: 2.99643e-02
I0209 13:18:42.719882 22542570456896 run_lib.py:133] step: 249100, training_loss: 2.51926e-02
I0209 13:18:42.873543 22542570456896 run_lib.py:146] step: 249100, eval_loss: 3.69079e-02
I0209 13:19:00.444662 22542570456896 run_lib.py:133] step: 249150, training_loss: 2.81501e-02
I0209 13:19:17.879384 22542570456896 run_lib.py:133] step: 249200, training_loss: 2.73717e-02
I0209 13:19:18.039479 22542570456896 run_lib.py:146] step: 249200, eval_loss: 2.70661e-02
I0209 13:19:35.521266 22542570456896 run_lib.py:133] step: 249250, training_loss: 3.31357e-02
I0209 13:19:53.144134 22542570456896 run_lib.py:133] step: 249300, training_loss: 3.67941e-02
I0209 13:19:53.309433 22542570456896 run_lib.py:146] step: 249300, eval_loss: 3.18177e-02
I0209 13:20:10.726271 22542570456896 run_lib.py:133] step: 249350, training_loss: 2.96770e-02
I0209 13:20:28.159198 22542570456896 run_lib.py:133] step: 249400, training_loss: 3.03356e-02
I0209 13:20:28.310228 22542570456896 run_lib.py:146] step: 249400, eval_loss: 2.71797e-02
I0209 13:20:45.928533 22542570456896 run_lib.py:133] step: 249450, training_loss: 2.78710e-02
I0209 13:21:03.344545 22542570456896 run_lib.py:133] step: 249500, training_loss: 2.81530e-02
I0209 13:21:03.499715 22542570456896 run_lib.py:146] step: 249500, eval_loss: 2.01670e-02
I0209 13:21:21.103049 22542570456896 run_lib.py:133] step: 249550, training_loss: 2.55232e-02
I0209 13:21:38.614343 22542570456896 run_lib.py:133] step: 249600, training_loss: 3.34596e-02
I0209 13:21:38.770696 22542570456896 run_lib.py:146] step: 249600, eval_loss: 2.59655e-02
I0209 13:21:56.203955 22542570456896 run_lib.py:133] step: 249650, training_loss: 1.72883e-02
I0209 13:22:13.853150 22542570456896 run_lib.py:133] step: 249700, training_loss: 2.52299e-02
I0209 13:22:14.019391 22542570456896 run_lib.py:146] step: 249700, eval_loss: 2.73282e-02
I0209 13:22:31.462815 22542570456896 run_lib.py:133] step: 249750, training_loss: 2.70335e-02
I0209 13:22:48.925438 22542570456896 run_lib.py:133] step: 249800, training_loss: 2.98941e-02
I0209 13:22:49.082506 22542570456896 run_lib.py:146] step: 249800, eval_loss: 3.39264e-02
I0209 13:23:06.566285 22542570456896 run_lib.py:133] step: 249850, training_loss: 2.75122e-02
I0209 13:23:24.233804 22542570456896 run_lib.py:133] step: 249900, training_loss: 2.65291e-02
I0209 13:23:24.388607 22542570456896 run_lib.py:146] step: 249900, eval_loss: 3.33680e-02
I0209 13:23:41.839993 22542570456896 run_lib.py:133] step: 249950, training_loss: 2.51746e-02
I0209 13:23:59.371364 22542570456896 run_lib.py:133] step: 250000, training_loss: 2.89892e-02
I0209 13:24:00.132797 22542570456896 run_lib.py:146] step: 250000, eval_loss: 2.57991e-02
I0209 13:24:20.212470 22542570456896 run_lib.py:133] step: 250050, training_loss: 2.84281e-02
I0209 13:24:37.662496 22542570456896 run_lib.py:133] step: 250100, training_loss: 2.73864e-02
I0209 13:24:37.819701 22542570456896 run_lib.py:146] step: 250100, eval_loss: 2.37266e-02
I0209 13:24:55.505598 22542570456896 run_lib.py:133] step: 250150, training_loss: 2.50160e-02
I0209 13:25:12.947981 22542570456896 run_lib.py:133] step: 250200, training_loss: 2.48607e-02
I0209 13:25:13.109594 22542570456896 run_lib.py:146] step: 250200, eval_loss: 3.19615e-02
I0209 13:25:30.622353 22542570456896 run_lib.py:133] step: 250250, training_loss: 2.80451e-02
I0209 13:25:48.039800 22542570456896 run_lib.py:133] step: 250300, training_loss: 3.27106e-02
I0209 13:25:48.203382 22542570456896 run_lib.py:146] step: 250300, eval_loss: 2.66916e-02
I0209 13:26:05.674983 22542570456896 run_lib.py:133] step: 250350, training_loss: 2.60344e-02
I0209 13:26:23.163369 22542570456896 run_lib.py:133] step: 250400, training_loss: 3.29473e-02
I0209 13:26:23.326299 22542570456896 run_lib.py:146] step: 250400, eval_loss: 2.80178e-02
I0209 13:26:40.976364 22542570456896 run_lib.py:133] step: 250450, training_loss: 3.18690e-02
I0209 13:26:58.491326 22542570456896 run_lib.py:133] step: 250500, training_loss: 2.34339e-02
I0209 13:26:58.643418 22542570456896 run_lib.py:146] step: 250500, eval_loss: 2.65632e-02
I0209 13:27:16.099741 22542570456896 run_lib.py:133] step: 250550, training_loss: 2.78946e-02
I0209 13:27:33.551447 22542570456896 run_lib.py:133] step: 250600, training_loss: 2.89782e-02
I0209 13:27:33.712500 22542570456896 run_lib.py:146] step: 250600, eval_loss: 3.23578e-02
I0209 13:27:51.261688 22542570456896 run_lib.py:133] step: 250650, training_loss: 3.36278e-02
I0209 13:28:08.730046 22542570456896 run_lib.py:133] step: 250700, training_loss: 2.51346e-02
I0209 13:28:08.900020 22542570456896 run_lib.py:146] step: 250700, eval_loss: 2.88914e-02
I0209 13:28:26.564616 22542570456896 run_lib.py:133] step: 250750, training_loss: 3.21994e-02
I0209 13:28:44.007534 22542570456896 run_lib.py:133] step: 250800, training_loss: 3.15252e-02
I0209 13:28:44.163681 22542570456896 run_lib.py:146] step: 250800, eval_loss: 2.24643e-02
I0209 13:29:01.754171 22542570456896 run_lib.py:133] step: 250850, training_loss: 3.13437e-02
I0209 13:29:19.175403 22542570456896 run_lib.py:133] step: 250900, training_loss: 2.72330e-02
I0209 13:29:19.330392 22542570456896 run_lib.py:146] step: 250900, eval_loss: 2.58691e-02
I0209 13:29:36.791448 22542570456896 run_lib.py:133] step: 250950, training_loss: 2.93489e-02
I0209 13:29:54.435455 22542570456896 run_lib.py:133] step: 251000, training_loss: 2.91417e-02
I0209 13:29:54.590617 22542570456896 run_lib.py:146] step: 251000, eval_loss: 2.76991e-02
I0209 13:30:12.092988 22542570456896 run_lib.py:133] step: 251050, training_loss: 2.92378e-02
I0209 13:30:29.712260 22542570456896 run_lib.py:133] step: 251100, training_loss: 2.85704e-02
I0209 13:30:29.868425 22542570456896 run_lib.py:146] step: 251100, eval_loss: 2.87878e-02
I0209 13:30:47.300925 22542570456896 run_lib.py:133] step: 251150, training_loss: 2.66391e-02
I0209 13:31:04.731430 22542570456896 run_lib.py:133] step: 251200, training_loss: 2.66768e-02
I0209 13:31:04.891646 22542570456896 run_lib.py:146] step: 251200, eval_loss: 3.57175e-02
I0209 13:31:22.521010 22542570456896 run_lib.py:133] step: 251250, training_loss: 3.07832e-02
I0209 13:31:40.023141 22542570456896 run_lib.py:133] step: 251300, training_loss: 2.24204e-02
I0209 13:31:40.179632 22542570456896 run_lib.py:146] step: 251300, eval_loss: 3.08412e-02
I0209 13:31:57.642106 22542570456896 run_lib.py:133] step: 251350, training_loss: 2.56053e-02
I0209 13:32:15.249615 22542570456896 run_lib.py:133] step: 251400, training_loss: 2.85331e-02
I0209 13:32:15.405371 22542570456896 run_lib.py:146] step: 251400, eval_loss: 2.55526e-02
I0209 13:32:32.853174 22542570456896 run_lib.py:133] step: 251450, training_loss: 2.41578e-02
I0209 13:32:50.333034 22542570456896 run_lib.py:133] step: 251500, training_loss: 2.94076e-02
I0209 13:32:50.638592 22542570456896 run_lib.py:146] step: 251500, eval_loss: 2.58023e-02
I0209 13:33:08.158534 22542570456896 run_lib.py:133] step: 251550, training_loss: 2.79753e-02
I0209 13:33:25.612655 22542570456896 run_lib.py:133] step: 251600, training_loss: 2.64849e-02
I0209 13:33:25.773361 22542570456896 run_lib.py:146] step: 251600, eval_loss: 3.07153e-02
I0209 13:33:43.203555 22542570456896 run_lib.py:133] step: 251650, training_loss: 3.00156e-02
I0209 13:34:00.661892 22542570456896 run_lib.py:133] step: 251700, training_loss: 2.61642e-02
I0209 13:34:00.825663 22542570456896 run_lib.py:146] step: 251700, eval_loss: 2.91170e-02
I0209 13:34:18.450591 22542570456896 run_lib.py:133] step: 251750, training_loss: 2.99521e-02
I0209 13:34:35.923818 22542570456896 run_lib.py:133] step: 251800, training_loss: 2.36131e-02
I0209 13:34:36.086100 22542570456896 run_lib.py:146] step: 251800, eval_loss: 2.84312e-02
I0209 13:34:53.538737 22542570456896 run_lib.py:133] step: 251850, training_loss: 2.50680e-02
I0209 13:35:10.996834 22542570456896 run_lib.py:133] step: 251900, training_loss: 2.72549e-02
I0209 13:35:11.151085 22542570456896 run_lib.py:146] step: 251900, eval_loss: 2.93628e-02
I0209 13:35:28.772583 22542570456896 run_lib.py:133] step: 251950, training_loss: 3.15284e-02
I0209 13:35:46.245208 22542570456896 run_lib.py:133] step: 252000, training_loss: 2.34243e-02
I0209 13:35:46.396153 22542570456896 run_lib.py:146] step: 252000, eval_loss: 2.65942e-02
I0209 13:36:03.761022 22542570456896 run_lib.py:133] step: 252050, training_loss: 3.21734e-02
I0209 13:36:21.161576 22542570456896 run_lib.py:133] step: 252100, training_loss: 3.22658e-02
I0209 13:36:21.328473 22542570456896 run_lib.py:146] step: 252100, eval_loss: 2.56150e-02
I0209 13:36:38.953978 22542570456896 run_lib.py:133] step: 252150, training_loss: 2.97930e-02
I0209 13:36:56.389153 22542570456896 run_lib.py:133] step: 252200, training_loss: 3.26107e-02
I0209 13:36:56.549617 22542570456896 run_lib.py:146] step: 252200, eval_loss: 2.62434e-02
I0209 13:37:14.170325 22542570456896 run_lib.py:133] step: 252250, training_loss: 3.04342e-02
I0209 13:37:31.590055 22542570456896 run_lib.py:133] step: 252300, training_loss: 2.27365e-02
I0209 13:37:31.746644 22542570456896 run_lib.py:146] step: 252300, eval_loss: 3.18499e-02
I0209 13:37:49.350204 22542570456896 run_lib.py:133] step: 252350, training_loss: 3.05429e-02
I0209 13:38:06.830792 22542570456896 run_lib.py:133] step: 252400, training_loss: 2.74803e-02
I0209 13:38:06.988113 22542570456896 run_lib.py:146] step: 252400, eval_loss: 3.35677e-02
I0209 13:38:24.466482 22542570456896 run_lib.py:133] step: 252450, training_loss: 2.50388e-02
I0209 13:38:42.114588 22542570456896 run_lib.py:133] step: 252500, training_loss: 2.62744e-02
I0209 13:38:42.273458 22542570456896 run_lib.py:146] step: 252500, eval_loss: 3.45975e-02
I0209 13:38:59.710719 22542570456896 run_lib.py:133] step: 252550, training_loss: 2.90992e-02
I0209 13:39:17.257836 22542570456896 run_lib.py:133] step: 252600, training_loss: 3.28851e-02
I0209 13:39:17.415620 22542570456896 run_lib.py:146] step: 252600, eval_loss: 2.63711e-02
I0209 13:39:34.823805 22542570456896 run_lib.py:133] step: 252650, training_loss: 2.59747e-02
I0209 13:39:52.310277 22542570456896 run_lib.py:133] step: 252700, training_loss: 2.67708e-02
I0209 13:39:52.474607 22542570456896 run_lib.py:146] step: 252700, eval_loss: 3.05413e-02
I0209 13:40:10.079985 22542570456896 run_lib.py:133] step: 252750, training_loss: 2.35049e-02
I0209 13:40:27.488711 22542570456896 run_lib.py:133] step: 252800, training_loss: 2.60504e-02
I0209 13:40:27.643425 22542570456896 run_lib.py:146] step: 252800, eval_loss: 3.30375e-02
I0209 13:40:45.076477 22542570456896 run_lib.py:133] step: 252850, training_loss: 2.57263e-02
I0209 13:41:02.532597 22542570456896 run_lib.py:133] step: 252900, training_loss: 2.50892e-02
I0209 13:41:02.685366 22542570456896 run_lib.py:146] step: 252900, eval_loss: 3.57541e-02
I0209 13:41:20.332206 22542570456896 run_lib.py:133] step: 252950, training_loss: 2.83672e-02
I0209 13:41:37.790113 22542570456896 run_lib.py:133] step: 253000, training_loss: 3.44725e-02
I0209 13:41:37.957578 22542570456896 run_lib.py:146] step: 253000, eval_loss: 2.71019e-02
I0209 13:41:55.531257 22542570456896 run_lib.py:133] step: 253050, training_loss: 2.86020e-02
I0209 13:42:12.989883 22542570456896 run_lib.py:133] step: 253100, training_loss: 3.17378e-02
I0209 13:42:13.147597 22542570456896 run_lib.py:146] step: 253100, eval_loss: 2.29973e-02
I0209 13:42:30.558106 22542570456896 run_lib.py:133] step: 253150, training_loss: 2.87985e-02
I0209 13:42:47.996597 22542570456896 run_lib.py:133] step: 253200, training_loss: 2.85767e-02
I0209 13:42:48.160385 22542570456896 run_lib.py:146] step: 253200, eval_loss: 2.74680e-02
I0209 13:43:05.732439 22542570456896 run_lib.py:133] step: 253250, training_loss: 3.11487e-02
I0209 13:43:23.321131 22542570456896 run_lib.py:133] step: 253300, training_loss: 2.68703e-02
I0209 13:43:23.479685 22542570456896 run_lib.py:146] step: 253300, eval_loss: 2.66594e-02
I0209 13:43:40.920292 22542570456896 run_lib.py:133] step: 253350, training_loss: 2.79887e-02
I0209 13:43:58.387941 22542570456896 run_lib.py:133] step: 253400, training_loss: 3.21612e-02
I0209 13:43:58.547883 22542570456896 run_lib.py:146] step: 253400, eval_loss: 3.65796e-02
I0209 13:44:16.137278 22542570456896 run_lib.py:133] step: 253450, training_loss: 3.05228e-02
I0209 13:44:33.585375 22542570456896 run_lib.py:133] step: 253500, training_loss: 3.08617e-02
I0209 13:44:33.762362 22542570456896 run_lib.py:146] step: 253500, eval_loss: 2.53153e-02
I0209 13:44:51.410377 22542570456896 run_lib.py:133] step: 253550, training_loss: 2.64183e-02
I0209 13:45:08.855228 22542570456896 run_lib.py:133] step: 253600, training_loss: 2.50421e-02
I0209 13:45:09.013237 22542570456896 run_lib.py:146] step: 253600, eval_loss: 2.69240e-02
I0209 13:45:26.598176 22542570456896 run_lib.py:133] step: 253650, training_loss: 3.11714e-02
I0209 13:45:44.041541 22542570456896 run_lib.py:133] step: 253700, training_loss: 2.45605e-02
I0209 13:45:44.197181 22542570456896 run_lib.py:146] step: 253700, eval_loss: 3.94944e-02
I0209 13:46:01.797323 22542570456896 run_lib.py:133] step: 253750, training_loss: 2.61906e-02
I0209 13:46:19.248234 22542570456896 run_lib.py:133] step: 253800, training_loss: 3.55121e-02
I0209 13:46:19.404294 22542570456896 run_lib.py:146] step: 253800, eval_loss: 2.88244e-02
I0209 13:46:36.901543 22542570456896 run_lib.py:133] step: 253850, training_loss: 3.26063e-02
I0209 13:46:54.519898 22542570456896 run_lib.py:133] step: 253900, training_loss: 3.68011e-02
I0209 13:46:54.669620 22542570456896 run_lib.py:146] step: 253900, eval_loss: 3.65548e-02
I0209 13:47:12.087524 22542570456896 run_lib.py:133] step: 253950, training_loss: 3.09520e-02
I0209 13:47:29.535720 22542570456896 run_lib.py:133] step: 254000, training_loss: 2.42521e-02
I0209 13:47:29.693592 22542570456896 run_lib.py:146] step: 254000, eval_loss: 2.49681e-02
I0209 13:47:47.260999 22542570456896 run_lib.py:133] step: 254050, training_loss: 2.64503e-02
I0209 13:48:04.918900 22542570456896 run_lib.py:133] step: 254100, training_loss: 2.60587e-02
I0209 13:48:05.076640 22542570456896 run_lib.py:146] step: 254100, eval_loss: 2.95932e-02
I0209 13:48:22.530866 22542570456896 run_lib.py:133] step: 254150, training_loss: 2.44995e-02
I0209 13:48:39.955539 22542570456896 run_lib.py:133] step: 254200, training_loss: 3.45862e-02
I0209 13:48:40.112534 22542570456896 run_lib.py:146] step: 254200, eval_loss: 3.01750e-02
I0209 13:48:57.539817 22542570456896 run_lib.py:133] step: 254250, training_loss: 2.84029e-02
I0209 13:49:15.176739 22542570456896 run_lib.py:133] step: 254300, training_loss: 2.77844e-02
I0209 13:49:15.328437 22542570456896 run_lib.py:146] step: 254300, eval_loss: 3.18789e-02
I0209 13:49:32.757827 22542570456896 run_lib.py:133] step: 254350, training_loss: 2.96229e-02
I0209 13:49:50.194154 22542570456896 run_lib.py:133] step: 254400, training_loss: 3.07110e-02
I0209 13:49:50.363547 22542570456896 run_lib.py:146] step: 254400, eval_loss: 2.82610e-02
I0209 13:50:07.836741 22542570456896 run_lib.py:133] step: 254450, training_loss: 3.05305e-02
I0209 13:50:25.462225 22542570456896 run_lib.py:133] step: 254500, training_loss: 2.93968e-02
I0209 13:50:25.621722 22542570456896 run_lib.py:146] step: 254500, eval_loss: 3.18973e-02
I0209 13:50:43.033158 22542570456896 run_lib.py:133] step: 254550, training_loss: 2.71142e-02
I0209 13:51:00.505897 22542570456896 run_lib.py:133] step: 254600, training_loss: 3.35178e-02
I0209 13:51:00.661445 22542570456896 run_lib.py:146] step: 254600, eval_loss: 2.76765e-02
I0209 13:51:18.115468 22542570456896 run_lib.py:133] step: 254650, training_loss: 2.84391e-02
I0209 13:51:35.578677 22542570456896 run_lib.py:133] step: 254700, training_loss: 3.37294e-02
I0209 13:51:35.734574 22542570456896 run_lib.py:146] step: 254700, eval_loss: 3.04156e-02
I0209 13:51:53.344057 22542570456896 run_lib.py:133] step: 254750, training_loss: 2.24535e-02
I0209 13:52:10.820798 22542570456896 run_lib.py:133] step: 254800, training_loss: 2.87224e-02
I0209 13:52:10.973421 22542570456896 run_lib.py:146] step: 254800, eval_loss: 3.14238e-02
I0209 13:52:28.401257 22542570456896 run_lib.py:133] step: 254850, training_loss: 2.98259e-02
I0209 13:52:45.823046 22542570456896 run_lib.py:133] step: 254900, training_loss: 3.51865e-02
I0209 13:52:45.990683 22542570456896 run_lib.py:146] step: 254900, eval_loss: 2.45563e-02
I0209 13:53:03.651610 22542570456896 run_lib.py:133] step: 254950, training_loss: 2.96145e-02
I0209 13:53:21.118828 22542570456896 run_lib.py:133] step: 255000, training_loss: 3.30190e-02
I0209 13:53:21.277585 22542570456896 run_lib.py:146] step: 255000, eval_loss: 2.79205e-02
I0209 13:53:38.891845 22542570456896 run_lib.py:133] step: 255050, training_loss: 3.12971e-02
I0209 13:53:56.300850 22542570456896 run_lib.py:133] step: 255100, training_loss: 2.32029e-02
I0209 13:53:56.456349 22542570456896 run_lib.py:146] step: 255100, eval_loss: 3.10244e-02
I0209 13:54:14.073395 22542570456896 run_lib.py:133] step: 255150, training_loss: 3.25189e-02
I0209 13:54:31.498344 22542570456896 run_lib.py:133] step: 255200, training_loss: 2.28282e-02
I0209 13:54:31.661599 22542570456896 run_lib.py:146] step: 255200, eval_loss: 3.42032e-02
I0209 13:54:49.241499 22542570456896 run_lib.py:133] step: 255250, training_loss: 2.97275e-02
I0209 13:55:06.815001 22542570456896 run_lib.py:133] step: 255300, training_loss: 2.36928e-02
I0209 13:55:06.967389 22542570456896 run_lib.py:146] step: 255300, eval_loss: 2.79140e-02
I0209 13:55:24.384674 22542570456896 run_lib.py:133] step: 255350, training_loss: 2.71848e-02
I0209 13:55:41.959715 22542570456896 run_lib.py:133] step: 255400, training_loss: 2.62706e-02
I0209 13:55:42.117548 22542570456896 run_lib.py:146] step: 255400, eval_loss: 3.45990e-02
I0209 13:55:59.533746 22542570456896 run_lib.py:133] step: 255450, training_loss: 2.66148e-02
I0209 13:56:16.952702 22542570456896 run_lib.py:133] step: 255500, training_loss: 3.38233e-02
I0209 13:56:17.121348 22542570456896 run_lib.py:146] step: 255500, eval_loss: 2.66246e-02
I0209 13:56:34.763823 22542570456896 run_lib.py:133] step: 255550, training_loss: 2.42849e-02
I0209 13:56:52.211556 22542570456896 run_lib.py:133] step: 255600, training_loss: 2.56908e-02
I0209 13:56:52.375695 22542570456896 run_lib.py:146] step: 255600, eval_loss: 3.18900e-02
I0209 13:57:09.804494 22542570456896 run_lib.py:133] step: 255650, training_loss: 2.61131e-02
I0209 13:57:27.397141 22542570456896 run_lib.py:133] step: 255700, training_loss: 2.63486e-02
I0209 13:57:27.557443 22542570456896 run_lib.py:146] step: 255700, eval_loss: 2.73703e-02
I0209 13:57:44.983679 22542570456896 run_lib.py:133] step: 255750, training_loss: 2.65117e-02
I0209 13:58:02.437340 22542570456896 run_lib.py:133] step: 255800, training_loss: 2.80086e-02
I0209 13:58:02.602243 22542570456896 run_lib.py:146] step: 255800, eval_loss: 2.81913e-02
I0209 13:58:20.164228 22542570456896 run_lib.py:133] step: 255850, training_loss: 3.11833e-02
I0209 13:58:37.610615 22542570456896 run_lib.py:133] step: 255900, training_loss: 2.54322e-02
I0209 13:58:37.768693 22542570456896 run_lib.py:146] step: 255900, eval_loss: 3.19505e-02
I0209 13:58:55.204200 22542570456896 run_lib.py:133] step: 255950, training_loss: 2.15200e-02
I0209 13:59:12.620546 22542570456896 run_lib.py:133] step: 256000, training_loss: 2.70291e-02
I0209 13:59:12.781507 22542570456896 run_lib.py:146] step: 256000, eval_loss: 3.06737e-02
I0209 13:59:30.364361 22542570456896 run_lib.py:133] step: 256050, training_loss: 2.65097e-02
I0209 13:59:47.903176 22542570456896 run_lib.py:133] step: 256100, training_loss: 2.29786e-02
I0209 13:59:48.058850 22542570456896 run_lib.py:146] step: 256100, eval_loss: 3.50734e-02
I0209 14:00:05.518808 22542570456896 run_lib.py:133] step: 256150, training_loss: 3.09516e-02
I0209 14:00:22.916673 22542570456896 run_lib.py:133] step: 256200, training_loss: 3.06032e-02
I0209 14:00:23.069164 22542570456896 run_lib.py:146] step: 256200, eval_loss: 3.07953e-02
I0209 14:00:40.665608 22542570456896 run_lib.py:133] step: 256250, training_loss: 2.69351e-02
I0209 14:00:58.119998 22542570456896 run_lib.py:133] step: 256300, training_loss: 3.49895e-02
I0209 14:00:58.287601 22542570456896 run_lib.py:146] step: 256300, eval_loss: 2.34827e-02
I0209 14:01:15.915058 22542570456896 run_lib.py:133] step: 256350, training_loss: 2.75261e-02
I0209 14:01:33.384455 22542570456896 run_lib.py:133] step: 256400, training_loss: 3.14211e-02
I0209 14:01:33.552297 22542570456896 run_lib.py:146] step: 256400, eval_loss: 2.85507e-02
I0209 14:01:51.173262 22542570456896 run_lib.py:133] step: 256450, training_loss: 2.45365e-02
I0209 14:02:08.591400 22542570456896 run_lib.py:133] step: 256500, training_loss: 2.69941e-02
I0209 14:02:08.754803 22542570456896 run_lib.py:146] step: 256500, eval_loss: 3.04013e-02
I0209 14:02:26.365026 22542570456896 run_lib.py:133] step: 256550, training_loss: 2.32916e-02
I0209 14:02:43.859702 22542570456896 run_lib.py:133] step: 256600, training_loss: 3.09708e-02
I0209 14:02:44.014534 22542570456896 run_lib.py:146] step: 256600, eval_loss: 3.12148e-02
I0209 14:03:01.486302 22542570456896 run_lib.py:133] step: 256650, training_loss: 3.64101e-02
I0209 14:03:19.079399 22542570456896 run_lib.py:133] step: 256700, training_loss: 2.82829e-02
I0209 14:03:19.237407 22542570456896 run_lib.py:146] step: 256700, eval_loss: 2.49684e-02
I0209 14:03:36.689366 22542570456896 run_lib.py:133] step: 256750, training_loss: 2.25860e-02
I0209 14:03:54.115061 22542570456896 run_lib.py:133] step: 256800, training_loss: 3.02571e-02
I0209 14:03:54.275420 22542570456896 run_lib.py:146] step: 256800, eval_loss: 2.68466e-02
I0209 14:04:11.859388 22542570456896 run_lib.py:133] step: 256850, training_loss: 2.52942e-02
I0209 14:04:29.326533 22542570456896 run_lib.py:133] step: 256900, training_loss: 2.56444e-02
I0209 14:04:29.486427 22542570456896 run_lib.py:146] step: 256900, eval_loss: 3.04548e-02
I0209 14:04:47.081819 22542570456896 run_lib.py:133] step: 256950, training_loss: 3.02609e-02
I0209 14:05:04.491761 22542570456896 run_lib.py:133] step: 257000, training_loss: 2.56108e-02
I0209 14:05:04.647105 22542570456896 run_lib.py:146] step: 257000, eval_loss: 2.54131e-02
I0209 14:05:22.101047 22542570456896 run_lib.py:133] step: 257050, training_loss: 2.62127e-02
I0209 14:05:39.664982 22542570456896 run_lib.py:133] step: 257100, training_loss: 2.70354e-02
I0209 14:05:39.820475 22542570456896 run_lib.py:146] step: 257100, eval_loss: 3.35548e-02
I0209 14:05:57.272010 22542570456896 run_lib.py:133] step: 257150, training_loss: 2.47452e-02
I0209 14:06:14.733757 22542570456896 run_lib.py:133] step: 257200, training_loss: 2.65244e-02
I0209 14:06:14.885687 22542570456896 run_lib.py:146] step: 257200, eval_loss: 3.20334e-02
I0209 14:06:32.311032 22542570456896 run_lib.py:133] step: 257250, training_loss: 2.59328e-02
I0209 14:06:49.934498 22542570456896 run_lib.py:133] step: 257300, training_loss: 2.52314e-02
I0209 14:06:50.098701 22542570456896 run_lib.py:146] step: 257300, eval_loss: 2.58247e-02
I0209 14:07:07.552308 22542570456896 run_lib.py:133] step: 257350, training_loss: 2.72861e-02
I0209 14:07:25.033494 22542570456896 run_lib.py:133] step: 257400, training_loss: 3.73880e-02
I0209 14:07:25.206338 22542570456896 run_lib.py:146] step: 257400, eval_loss: 2.84729e-02
I0209 14:07:42.673222 22542570456896 run_lib.py:133] step: 257450, training_loss: 2.21978e-02
I0209 14:08:00.113475 22542570456896 run_lib.py:133] step: 257500, training_loss: 2.79687e-02
I0209 14:08:00.272599 22542570456896 run_lib.py:146] step: 257500, eval_loss: 2.34244e-02
I0209 14:08:17.907472 22542570456896 run_lib.py:133] step: 257550, training_loss: 3.30822e-02
I0209 14:08:35.405572 22542570456896 run_lib.py:133] step: 257600, training_loss: 2.87700e-02
I0209 14:08:35.558137 22542570456896 run_lib.py:146] step: 257600, eval_loss: 3.06856e-02
I0209 14:08:52.993307 22542570456896 run_lib.py:133] step: 257650, training_loss: 2.77086e-02
I0209 14:09:10.413164 22542570456896 run_lib.py:133] step: 257700, training_loss: 3.06535e-02
I0209 14:09:10.572440 22542570456896 run_lib.py:146] step: 257700, eval_loss: 2.97814e-02
I0209 14:09:28.236838 22542570456896 run_lib.py:133] step: 257750, training_loss: 3.03179e-02
I0209 14:09:45.679627 22542570456896 run_lib.py:133] step: 257800, training_loss: 3.09601e-02
I0209 14:09:45.836840 22542570456896 run_lib.py:146] step: 257800, eval_loss: 3.02998e-02
I0209 14:10:03.435494 22542570456896 run_lib.py:133] step: 257850, training_loss: 2.58231e-02
I0209 14:10:20.852425 22542570456896 run_lib.py:133] step: 257900, training_loss: 2.56155e-02
I0209 14:10:21.007344 22542570456896 run_lib.py:146] step: 257900, eval_loss: 2.76412e-02
I0209 14:10:38.611578 22542570456896 run_lib.py:133] step: 257950, training_loss: 2.40194e-02
I0209 14:10:56.114043 22542570456896 run_lib.py:133] step: 258000, training_loss: 2.95760e-02
I0209 14:10:56.274258 22542570456896 run_lib.py:146] step: 258000, eval_loss: 2.91193e-02
I0209 14:11:13.723025 22542570456896 run_lib.py:133] step: 258050, training_loss: 2.78848e-02
I0209 14:11:31.342462 22542570456896 run_lib.py:133] step: 258100, training_loss: 2.75960e-02
I0209 14:11:31.496454 22542570456896 run_lib.py:146] step: 258100, eval_loss: 3.00940e-02
I0209 14:11:48.959820 22542570456896 run_lib.py:133] step: 258150, training_loss: 3.51947e-02
I0209 14:12:06.525178 22542570456896 run_lib.py:133] step: 258200, training_loss: 3.15013e-02
I0209 14:12:06.681390 22542570456896 run_lib.py:146] step: 258200, eval_loss: 2.33143e-02
I0209 14:12:24.127822 22542570456896 run_lib.py:133] step: 258250, training_loss: 3.10453e-02
I0209 14:12:41.605310 22542570456896 run_lib.py:133] step: 258300, training_loss: 3.02177e-02
I0209 14:12:41.765465 22542570456896 run_lib.py:146] step: 258300, eval_loss: 3.33040e-02
I0209 14:12:59.437002 22542570456896 run_lib.py:133] step: 258350, training_loss: 3.29407e-02
I0209 14:13:16.888662 22542570456896 run_lib.py:133] step: 258400, training_loss: 2.71527e-02
I0209 14:13:17.044544 22542570456896 run_lib.py:146] step: 258400, eval_loss: 3.40418e-02
I0209 14:13:34.521399 22542570456896 run_lib.py:133] step: 258450, training_loss: 3.16020e-02
I0209 14:13:52.052800 22542570456896 run_lib.py:133] step: 258500, training_loss: 3.03598e-02
I0209 14:13:52.212321 22542570456896 run_lib.py:146] step: 258500, eval_loss: 2.45001e-02
I0209 14:14:09.680773 22542570456896 run_lib.py:133] step: 258550, training_loss: 2.72913e-02
I0209 14:14:27.170365 22542570456896 run_lib.py:133] step: 258600, training_loss: 2.55221e-02
I0209 14:14:27.519290 22542570456896 run_lib.py:146] step: 258600, eval_loss: 2.90369e-02
I0209 14:14:44.967441 22542570456896 run_lib.py:133] step: 258650, training_loss: 3.54694e-02
I0209 14:15:02.417853 22542570456896 run_lib.py:133] step: 258700, training_loss: 3.26891e-02
I0209 14:15:02.573186 22542570456896 run_lib.py:146] step: 258700, eval_loss: 3.07477e-02
I0209 14:15:20.015938 22542570456896 run_lib.py:133] step: 258750, training_loss: 2.95394e-02
I0209 14:15:37.439419 22542570456896 run_lib.py:133] step: 258800, training_loss: 2.95096e-02
I0209 14:15:37.618241 22542570456896 run_lib.py:146] step: 258800, eval_loss: 2.58956e-02
I0209 14:15:55.157702 22542570456896 run_lib.py:133] step: 258850, training_loss: 2.67375e-02
I0209 14:16:12.645662 22542570456896 run_lib.py:133] step: 258900, training_loss: 2.96406e-02
I0209 14:16:12.805460 22542570456896 run_lib.py:146] step: 258900, eval_loss: 3.43235e-02
I0209 14:16:30.169537 22542570456896 run_lib.py:133] step: 258950, training_loss: 3.19029e-02
I0209 14:16:47.613590 22542570456896 run_lib.py:133] step: 259000, training_loss: 2.84482e-02
I0209 14:16:47.768413 22542570456896 run_lib.py:146] step: 259000, eval_loss: 3.01562e-02
I0209 14:17:05.333620 22542570456896 run_lib.py:133] step: 259050, training_loss: 3.18236e-02
I0209 14:17:22.831258 22542570456896 run_lib.py:133] step: 259100, training_loss: 2.14956e-02
I0209 14:17:22.987591 22542570456896 run_lib.py:146] step: 259100, eval_loss: 2.91603e-02
I0209 14:17:40.539729 22542570456896 run_lib.py:133] step: 259150, training_loss: 3.05551e-02
I0209 14:17:57.952379 22542570456896 run_lib.py:133] step: 259200, training_loss: 3.08609e-02
I0209 14:17:58.119369 22542570456896 run_lib.py:146] step: 259200, eval_loss: 2.68531e-02
I0209 14:18:15.721904 22542570456896 run_lib.py:133] step: 259250, training_loss: 2.66278e-02
I0209 14:18:33.163298 22542570456896 run_lib.py:133] step: 259300, training_loss: 2.00474e-02
I0209 14:18:33.319400 22542570456896 run_lib.py:146] step: 259300, eval_loss: 2.91171e-02
I0209 14:18:50.915930 22542570456896 run_lib.py:133] step: 259350, training_loss: 2.50419e-02
I0209 14:19:08.341637 22542570456896 run_lib.py:133] step: 259400, training_loss: 2.92113e-02
I0209 14:19:08.497101 22542570456896 run_lib.py:146] step: 259400, eval_loss: 2.77824e-02
I0209 14:19:26.142437 22542570456896 run_lib.py:133] step: 259450, training_loss: 2.87679e-02
I0209 14:19:43.603342 22542570456896 run_lib.py:133] step: 259500, training_loss: 3.04796e-02
I0209 14:19:43.756526 22542570456896 run_lib.py:146] step: 259500, eval_loss: 2.86060e-02
I0209 14:20:01.206922 22542570456896 run_lib.py:133] step: 259550, training_loss: 2.74977e-02
I0209 14:20:18.783575 22542570456896 run_lib.py:133] step: 259600, training_loss: 1.89625e-02
I0209 14:20:18.938897 22542570456896 run_lib.py:146] step: 259600, eval_loss: 2.69003e-02
I0209 14:20:36.384291 22542570456896 run_lib.py:133] step: 259650, training_loss: 2.95992e-02
I0209 14:20:54.004916 22542570456896 run_lib.py:133] step: 259700, training_loss: 2.73493e-02
I0209 14:20:54.181948 22542570456896 run_lib.py:146] step: 259700, eval_loss: 2.87906e-02
I0209 14:21:11.688732 22542570456896 run_lib.py:133] step: 259750, training_loss: 2.37554e-02
I0209 14:21:29.116577 22542570456896 run_lib.py:133] step: 259800, training_loss: 2.49460e-02
I0209 14:21:29.277543 22542570456896 run_lib.py:146] step: 259800, eval_loss: 3.50179e-02
I0209 14:21:46.879056 22542570456896 run_lib.py:133] step: 259850, training_loss: 3.20727e-02
I0209 14:22:04.314988 22542570456896 run_lib.py:133] step: 259900, training_loss: 2.76357e-02
I0209 14:22:04.476435 22542570456896 run_lib.py:146] step: 259900, eval_loss: 2.75239e-02
I0209 14:22:21.915193 22542570456896 run_lib.py:133] step: 259950, training_loss: 2.97261e-02
I0209 14:22:39.374671 22542570456896 run_lib.py:133] step: 260000, training_loss: 2.70440e-02
I0209 14:22:40.142701 22542570456896 run_lib.py:146] step: 260000, eval_loss: 3.34161e-02
I0209 14:23:00.446171 22542570456896 run_lib.py:133] step: 260050, training_loss: 2.67863e-02
I0209 14:23:18.006243 22542570456896 run_lib.py:133] step: 260100, training_loss: 2.64256e-02
I0209 14:23:18.161354 22542570456896 run_lib.py:146] step: 260100, eval_loss: 2.95946e-02
I0209 14:23:35.603198 22542570456896 run_lib.py:133] step: 260150, training_loss: 2.63859e-02
I0209 14:23:53.036768 22542570456896 run_lib.py:133] step: 260200, training_loss: 2.91448e-02
I0209 14:23:53.207443 22542570456896 run_lib.py:146] step: 260200, eval_loss: 2.11973e-02
I0209 14:24:10.884524 22542570456896 run_lib.py:133] step: 260250, training_loss: 2.41474e-02
I0209 14:24:28.330274 22542570456896 run_lib.py:133] step: 260300, training_loss: 3.09152e-02
I0209 14:24:28.488468 22542570456896 run_lib.py:146] step: 260300, eval_loss: 3.55366e-02
I0209 14:24:45.920245 22542570456896 run_lib.py:133] step: 260350, training_loss: 2.57965e-02
I0209 14:25:03.347884 22542570456896 run_lib.py:133] step: 260400, training_loss: 2.54997e-02
I0209 14:25:03.509667 22542570456896 run_lib.py:146] step: 260400, eval_loss: 3.07766e-02
I0209 14:25:21.134285 22542570456896 run_lib.py:133] step: 260450, training_loss: 2.83837e-02
I0209 14:25:38.568378 22542570456896 run_lib.py:133] step: 260500, training_loss: 3.80100e-02
I0209 14:25:38.723625 22542570456896 run_lib.py:146] step: 260500, eval_loss: 2.81883e-02
I0209 14:25:56.298533 22542570456896 run_lib.py:133] step: 260550, training_loss: 2.86407e-02
I0209 14:26:13.782715 22542570456896 run_lib.py:133] step: 260600, training_loss: 2.75156e-02
I0209 14:26:13.935440 22542570456896 run_lib.py:146] step: 260600, eval_loss: 2.85168e-02
I0209 14:26:31.356249 22542570456896 run_lib.py:133] step: 260650, training_loss: 2.87667e-02
I0209 14:26:48.811110 22542570456896 run_lib.py:133] step: 260700, training_loss: 3.22124e-02
I0209 14:26:48.976511 22542570456896 run_lib.py:146] step: 260700, eval_loss: 2.79893e-02
I0209 14:27:06.574148 22542570456896 run_lib.py:133] step: 260750, training_loss: 2.57594e-02
I0209 14:27:24.075134 22542570456896 run_lib.py:133] step: 260800, training_loss: 3.01379e-02
I0209 14:27:24.247489 22542570456896 run_lib.py:146] step: 260800, eval_loss: 2.61017e-02
I0209 14:27:41.719764 22542570456896 run_lib.py:133] step: 260850, training_loss: 2.65499e-02
I0209 14:27:59.202119 22542570456896 run_lib.py:133] step: 260900, training_loss: 2.82609e-02
I0209 14:27:59.357139 22542570456896 run_lib.py:146] step: 260900, eval_loss: 2.75773e-02
I0209 14:28:16.956785 22542570456896 run_lib.py:133] step: 260950, training_loss: 2.92411e-02
I0209 14:28:34.391240 22542570456896 run_lib.py:133] step: 261000, training_loss: 2.47231e-02
I0209 14:28:34.544183 22542570456896 run_lib.py:146] step: 261000, eval_loss: 2.67810e-02
I0209 14:28:52.136702 22542570456896 run_lib.py:133] step: 261050, training_loss: 2.78861e-02
I0209 14:29:09.556578 22542570456896 run_lib.py:133] step: 261100, training_loss: 3.20362e-02
I0209 14:29:09.718560 22542570456896 run_lib.py:146] step: 261100, eval_loss: 2.51351e-02
I0209 14:29:27.337728 22542570456896 run_lib.py:133] step: 261150, training_loss: 2.33424e-02
I0209 14:29:44.823188 22542570456896 run_lib.py:133] step: 261200, training_loss: 3.40446e-02
I0209 14:29:44.989390 22542570456896 run_lib.py:146] step: 261200, eval_loss: 2.79241e-02
I0209 14:30:02.592822 22542570456896 run_lib.py:133] step: 261250, training_loss: 3.04513e-02
I0209 14:30:20.057965 22542570456896 run_lib.py:133] step: 261300, training_loss: 3.00337e-02
I0209 14:30:20.213374 22542570456896 run_lib.py:146] step: 261300, eval_loss: 2.70992e-02
I0209 14:30:37.665845 22542570456896 run_lib.py:133] step: 261350, training_loss: 3.51844e-02
I0209 14:30:55.246348 22542570456896 run_lib.py:133] step: 261400, training_loss: 2.62006e-02
I0209 14:30:55.408412 22542570456896 run_lib.py:146] step: 261400, eval_loss: 2.63867e-02
I0209 14:31:12.912656 22542570456896 run_lib.py:133] step: 261450, training_loss: 3.41032e-02
I0209 14:31:30.404219 22542570456896 run_lib.py:133] step: 261500, training_loss: 2.40885e-02
I0209 14:31:30.556533 22542570456896 run_lib.py:146] step: 261500, eval_loss: 2.66697e-02
I0209 14:31:48.168487 22542570456896 run_lib.py:133] step: 261550, training_loss: 2.51708e-02
I0209 14:32:05.609584 22542570456896 run_lib.py:133] step: 261600, training_loss: 2.16625e-02
I0209 14:32:05.764545 22542570456896 run_lib.py:146] step: 261600, eval_loss: 2.93750e-02
I0209 14:32:23.304510 22542570456896 run_lib.py:133] step: 261650, training_loss: 2.77237e-02
I0209 14:32:40.738321 22542570456896 run_lib.py:133] step: 261700, training_loss: 2.80673e-02
I0209 14:32:40.914481 22542570456896 run_lib.py:146] step: 261700, eval_loss: 3.06526e-02
I0209 14:32:58.399378 22542570456896 run_lib.py:133] step: 261750, training_loss: 2.30645e-02
I0209 14:33:16.020040 22542570456896 run_lib.py:133] step: 261800, training_loss: 2.49070e-02
I0209 14:33:16.176620 22542570456896 run_lib.py:146] step: 261800, eval_loss: 2.34770e-02
I0209 14:33:33.610122 22542570456896 run_lib.py:133] step: 261850, training_loss: 3.02292e-02
I0209 14:33:51.081259 22542570456896 run_lib.py:133] step: 261900, training_loss: 2.61430e-02
I0209 14:33:51.242235 22542570456896 run_lib.py:146] step: 261900, eval_loss: 3.55565e-02
I0209 14:34:08.696408 22542570456896 run_lib.py:133] step: 261950, training_loss: 2.62224e-02
I0209 14:34:26.281769 22542570456896 run_lib.py:133] step: 262000, training_loss: 2.68972e-02
I0209 14:34:26.437751 22542570456896 run_lib.py:146] step: 262000, eval_loss: 2.65275e-02
I0209 14:34:43.919848 22542570456896 run_lib.py:133] step: 262050, training_loss: 2.62951e-02
I0209 14:35:01.477749 22542570456896 run_lib.py:133] step: 262100, training_loss: 2.33602e-02
I0209 14:35:01.635039 22542570456896 run_lib.py:146] step: 262100, eval_loss: 2.56097e-02
I0209 14:35:19.055802 22542570456896 run_lib.py:133] step: 262150, training_loss: 2.86807e-02
I0209 14:35:36.510646 22542570456896 run_lib.py:133] step: 262200, training_loss: 3.11290e-02
I0209 14:35:36.665564 22542570456896 run_lib.py:146] step: 262200, eval_loss: 3.54560e-02
I0209 14:35:54.229208 22542570456896 run_lib.py:133] step: 262250, training_loss: 3.40405e-02
I0209 14:36:11.764967 22542570456896 run_lib.py:133] step: 262300, training_loss: 2.59594e-02
I0209 14:36:11.918946 22542570456896 run_lib.py:146] step: 262300, eval_loss: 2.31552e-02
I0209 14:36:29.358717 22542570456896 run_lib.py:133] step: 262350, training_loss: 3.01616e-02
I0209 14:36:46.838232 22542570456896 run_lib.py:133] step: 262400, training_loss: 2.11906e-02
I0209 14:36:46.993340 22542570456896 run_lib.py:146] step: 262400, eval_loss: 3.27493e-02
I0209 14:37:04.628797 22542570456896 run_lib.py:133] step: 262450, training_loss: 2.10005e-02
I0209 14:37:22.080774 22542570456896 run_lib.py:133] step: 262500, training_loss: 3.34059e-02
I0209 14:37:22.241322 22542570456896 run_lib.py:146] step: 262500, eval_loss: 2.43472e-02
I0209 14:37:39.878329 22542570456896 run_lib.py:133] step: 262550, training_loss: 2.91854e-02
I0209 14:37:57.299477 22542570456896 run_lib.py:133] step: 262600, training_loss: 2.92164e-02
I0209 14:37:57.477451 22542570456896 run_lib.py:146] step: 262600, eval_loss: 2.51310e-02
I0209 14:38:15.218226 22542570456896 run_lib.py:133] step: 262650, training_loss: 3.30511e-02
I0209 14:38:32.675373 22542570456896 run_lib.py:133] step: 262700, training_loss: 2.90942e-02
I0209 14:38:32.837169 22542570456896 run_lib.py:146] step: 262700, eval_loss: 2.82586e-02
I0209 14:38:50.280408 22542570456896 run_lib.py:133] step: 262750, training_loss: 3.10297e-02
I0209 14:39:07.841337 22542570456896 run_lib.py:133] step: 262800, training_loss: 2.85295e-02
I0209 14:39:07.996678 22542570456896 run_lib.py:146] step: 262800, eval_loss: 3.00586e-02
I0209 14:39:25.455677 22542570456896 run_lib.py:133] step: 262850, training_loss: 2.94315e-02
I0209 14:39:43.062194 22542570456896 run_lib.py:133] step: 262900, training_loss: 3.83665e-02
I0209 14:39:43.223883 22542570456896 run_lib.py:146] step: 262900, eval_loss: 2.76380e-02
I0209 14:40:00.681001 22542570456896 run_lib.py:133] step: 262950, training_loss: 3.23266e-02
I0209 14:40:18.098212 22542570456896 run_lib.py:133] step: 263000, training_loss: 2.35558e-02
I0209 14:40:18.253222 22542570456896 run_lib.py:146] step: 263000, eval_loss: 2.46090e-02
I0209 14:40:35.892823 22542570456896 run_lib.py:133] step: 263050, training_loss: 2.91125e-02
I0209 14:40:53.354822 22542570456896 run_lib.py:133] step: 263100, training_loss: 3.17532e-02
I0209 14:40:53.511710 22542570456896 run_lib.py:146] step: 263100, eval_loss: 2.70019e-02
I0209 14:41:10.927448 22542570456896 run_lib.py:133] step: 263150, training_loss: 2.26368e-02
I0209 14:41:28.574215 22542570456896 run_lib.py:133] step: 263200, training_loss: 3.03465e-02
I0209 14:41:28.731632 22542570456896 run_lib.py:146] step: 263200, eval_loss: 2.60481e-02
I0209 14:41:46.219212 22542570456896 run_lib.py:133] step: 263250, training_loss: 3.62321e-02
I0209 14:42:03.631852 22542570456896 run_lib.py:133] step: 263300, training_loss: 2.73569e-02
I0209 14:42:03.981251 22542570456896 run_lib.py:146] step: 263300, eval_loss: 2.67402e-02
I0209 14:42:21.408397 22542570456896 run_lib.py:133] step: 263350, training_loss: 2.80195e-02
I0209 14:42:38.898487 22542570456896 run_lib.py:133] step: 263400, training_loss: 3.30309e-02
I0209 14:42:39.053659 22542570456896 run_lib.py:146] step: 263400, eval_loss: 4.81174e-02
I0209 14:42:56.562695 22542570456896 run_lib.py:133] step: 263450, training_loss: 3.14273e-02
I0209 14:43:13.973435 22542570456896 run_lib.py:133] step: 263500, training_loss: 2.84816e-02
I0209 14:43:14.130429 22542570456896 run_lib.py:146] step: 263500, eval_loss: 2.75247e-02
I0209 14:43:31.757834 22542570456896 run_lib.py:133] step: 263550, training_loss: 2.97970e-02
I0209 14:43:49.291726 22542570456896 run_lib.py:133] step: 263600, training_loss: 2.62515e-02
I0209 14:43:49.449588 22542570456896 run_lib.py:146] step: 263600, eval_loss: 2.78400e-02
I0209 14:44:06.866171 22542570456896 run_lib.py:133] step: 263650, training_loss: 2.56062e-02
I0209 14:44:24.364778 22542570456896 run_lib.py:133] step: 263700, training_loss: 2.87482e-02
I0209 14:44:24.523576 22542570456896 run_lib.py:146] step: 263700, eval_loss: 2.57412e-02
I0209 14:44:42.132881 22542570456896 run_lib.py:133] step: 263750, training_loss: 2.61934e-02
I0209 14:44:59.690913 22542570456896 run_lib.py:133] step: 263800, training_loss: 2.82126e-02
I0209 14:44:59.847639 22542570456896 run_lib.py:146] step: 263800, eval_loss: 2.90630e-02
I0209 14:45:17.310655 22542570456896 run_lib.py:133] step: 263850, training_loss: 2.57206e-02
I0209 14:45:34.792965 22542570456896 run_lib.py:133] step: 263900, training_loss: 2.17837e-02
I0209 14:45:34.942929 22542570456896 run_lib.py:146] step: 263900, eval_loss: 3.58235e-02
I0209 14:45:52.509235 22542570456896 run_lib.py:133] step: 263950, training_loss: 3.14439e-02
I0209 14:46:09.928006 22542570456896 run_lib.py:133] step: 264000, training_loss: 2.34174e-02
I0209 14:46:10.103362 22542570456896 run_lib.py:146] step: 264000, eval_loss: 4.03020e-02
I0209 14:46:27.806450 22542570456896 run_lib.py:133] step: 264050, training_loss: 2.44116e-02
I0209 14:46:45.270539 22542570456896 run_lib.py:133] step: 264100, training_loss: 2.99337e-02
I0209 14:46:45.429352 22542570456896 run_lib.py:146] step: 264100, eval_loss: 2.73426e-02
I0209 14:47:03.012650 22542570456896 run_lib.py:133] step: 264150, training_loss: 2.80390e-02
I0209 14:47:20.420237 22542570456896 run_lib.py:133] step: 264200, training_loss: 2.85007e-02
I0209 14:47:20.576200 22542570456896 run_lib.py:146] step: 264200, eval_loss: 3.17078e-02
I0209 14:47:38.052022 22542570456896 run_lib.py:133] step: 264250, training_loss: 2.49560e-02
I0209 14:47:55.682586 22542570456896 run_lib.py:133] step: 264300, training_loss: 2.61507e-02
I0209 14:47:55.838175 22542570456896 run_lib.py:146] step: 264300, eval_loss: 2.42153e-02
I0209 14:48:13.297375 22542570456896 run_lib.py:133] step: 264350, training_loss: 2.79928e-02
I0209 14:48:30.915237 22542570456896 run_lib.py:133] step: 264400, training_loss: 2.38742e-02
I0209 14:48:31.072411 22542570456896 run_lib.py:146] step: 264400, eval_loss: 2.34028e-02
I0209 14:48:48.484442 22542570456896 run_lib.py:133] step: 264450, training_loss: 2.73761e-02
I0209 14:49:05.931742 22542570456896 run_lib.py:133] step: 264500, training_loss: 3.04609e-02
I0209 14:49:06.089629 22542570456896 run_lib.py:146] step: 264500, eval_loss: 2.92042e-02
I0209 14:49:23.711914 22542570456896 run_lib.py:133] step: 264550, training_loss: 1.98896e-02
I0209 14:49:41.203725 22542570456896 run_lib.py:133] step: 264600, training_loss: 2.85600e-02
I0209 14:49:41.360587 22542570456896 run_lib.py:146] step: 264600, eval_loss: 2.04529e-02
I0209 14:49:58.784708 22542570456896 run_lib.py:133] step: 264650, training_loss: 2.23583e-02
I0209 14:50:16.187196 22542570456896 run_lib.py:133] step: 264700, training_loss: 3.60095e-02
I0209 14:50:16.343592 22542570456896 run_lib.py:146] step: 264700, eval_loss: 3.12450e-02
I0209 14:50:33.974767 22542570456896 run_lib.py:133] step: 264750, training_loss: 2.38884e-02
I0209 14:50:51.465864 22542570456896 run_lib.py:133] step: 264800, training_loss: 2.74786e-02
I0209 14:50:51.619240 22542570456896 run_lib.py:146] step: 264800, eval_loss: 1.89103e-02
I0209 14:51:09.175431 22542570456896 run_lib.py:133] step: 264850, training_loss: 2.83924e-02
I0209 14:51:26.606059 22542570456896 run_lib.py:133] step: 264900, training_loss: 3.19894e-02
I0209 14:51:26.763725 22542570456896 run_lib.py:146] step: 264900, eval_loss: 3.71525e-02
I0209 14:51:44.222181 22542570456896 run_lib.py:133] step: 264950, training_loss: 2.27620e-02
I0209 14:52:01.700680 22542570456896 run_lib.py:133] step: 265000, training_loss: 3.13658e-02
I0209 14:52:01.859654 22542570456896 run_lib.py:146] step: 265000, eval_loss: 2.64100e-02
I0209 14:52:19.466207 22542570456896 run_lib.py:133] step: 265050, training_loss: 2.71372e-02
I0209 14:52:36.950848 22542570456896 run_lib.py:133] step: 265100, training_loss: 2.60825e-02
I0209 14:52:37.107101 22542570456896 run_lib.py:146] step: 265100, eval_loss: 2.68060e-02
I0209 14:52:54.571043 22542570456896 run_lib.py:133] step: 265150, training_loss: 2.77236e-02
I0209 14:53:12.053983 22542570456896 run_lib.py:133] step: 265200, training_loss: 2.54300e-02
I0209 14:53:12.213454 22542570456896 run_lib.py:146] step: 265200, eval_loss: 2.66957e-02
I0209 14:53:29.879297 22542570456896 run_lib.py:133] step: 265250, training_loss: 2.91590e-02
I0209 14:53:47.285594 22542570456896 run_lib.py:133] step: 265300, training_loss: 2.68427e-02
I0209 14:53:47.440333 22542570456896 run_lib.py:146] step: 265300, eval_loss: 2.67715e-02
I0209 14:54:04.992289 22542570456896 run_lib.py:133] step: 265350, training_loss: 2.77736e-02
I0209 14:54:22.408462 22542570456896 run_lib.py:133] step: 265400, training_loss: 3.26202e-02
I0209 14:54:22.579699 22542570456896 run_lib.py:146] step: 265400, eval_loss: 3.03372e-02
I0209 14:54:40.220231 22542570456896 run_lib.py:133] step: 265450, training_loss: 2.77462e-02
I0209 14:54:57.691800 22542570456896 run_lib.py:133] step: 265500, training_loss: 2.16380e-02
I0209 14:54:57.852364 22542570456896 run_lib.py:146] step: 265500, eval_loss: 2.67616e-02
I0209 14:55:15.388132 22542570456896 run_lib.py:133] step: 265550, training_loss: 3.05155e-02
I0209 14:55:32.796707 22542570456896 run_lib.py:133] step: 265600, training_loss: 2.69596e-02
I0209 14:55:32.954364 22542570456896 run_lib.py:146] step: 265600, eval_loss: 2.49437e-02
I0209 14:55:50.376887 22542570456896 run_lib.py:133] step: 265650, training_loss: 3.13371e-02
I0209 14:56:07.915611 22542570456896 run_lib.py:133] step: 265700, training_loss: 2.98600e-02
I0209 14:56:08.081277 22542570456896 run_lib.py:146] step: 265700, eval_loss: 2.78932e-02
I0209 14:56:25.560966 22542570456896 run_lib.py:133] step: 265750, training_loss: 2.80129e-02
I0209 14:56:43.000374 22542570456896 run_lib.py:133] step: 265800, training_loss: 2.15898e-02
I0209 14:56:43.153385 22542570456896 run_lib.py:146] step: 265800, eval_loss: 2.60480e-02
I0209 14:57:00.760377 22542570456896 run_lib.py:133] step: 265850, training_loss: 2.93912e-02
I0209 14:57:18.370295 22542570456896 run_lib.py:133] step: 265900, training_loss: 2.56562e-02
I0209 14:57:18.529742 22542570456896 run_lib.py:146] step: 265900, eval_loss: 2.33718e-02
I0209 14:57:35.938463 22542570456896 run_lib.py:133] step: 265950, training_loss: 2.73388e-02
I0209 14:57:53.379286 22542570456896 run_lib.py:133] step: 266000, training_loss: 2.94428e-02
I0209 14:57:53.547346 22542570456896 run_lib.py:146] step: 266000, eval_loss: 2.54519e-02
I0209 14:58:11.023604 22542570456896 run_lib.py:133] step: 266050, training_loss: 3.41820e-02
I0209 14:58:28.683139 22542570456896 run_lib.py:133] step: 266100, training_loss: 2.54403e-02
I0209 14:58:28.838214 22542570456896 run_lib.py:146] step: 266100, eval_loss: 2.42308e-02
I0209 14:58:46.341277 22542570456896 run_lib.py:133] step: 266150, training_loss: 2.89281e-02
I0209 14:59:03.855722 22542570456896 run_lib.py:133] step: 266200, training_loss: 2.78971e-02
I0209 14:59:04.008151 22542570456896 run_lib.py:146] step: 266200, eval_loss: 3.04573e-02
I0209 14:59:21.450376 22542570456896 run_lib.py:133] step: 266250, training_loss: 2.13118e-02
I0209 14:59:39.089505 22542570456896 run_lib.py:133] step: 266300, training_loss: 3.06926e-02
I0209 14:59:39.254859 22542570456896 run_lib.py:146] step: 266300, eval_loss: 3.64142e-02
I0209 14:59:56.734422 22542570456896 run_lib.py:133] step: 266350, training_loss: 2.68783e-02
I0209 15:00:14.321310 22542570456896 run_lib.py:133] step: 266400, training_loss: 2.84272e-02
I0209 15:00:14.479257 22542570456896 run_lib.py:146] step: 266400, eval_loss: 3.29948e-02
I0209 15:00:31.910312 22542570456896 run_lib.py:133] step: 266450, training_loss: 3.08786e-02
I0209 15:00:49.354678 22542570456896 run_lib.py:133] step: 266500, training_loss: 2.47336e-02
I0209 15:00:49.511371 22542570456896 run_lib.py:146] step: 266500, eval_loss: 3.03069e-02
I0209 15:01:07.114287 22542570456896 run_lib.py:133] step: 266550, training_loss: 2.94830e-02
I0209 15:01:24.679238 22542570456896 run_lib.py:133] step: 266600, training_loss: 2.37361e-02
I0209 15:01:24.836880 22542570456896 run_lib.py:146] step: 266600, eval_loss: 4.33141e-02
I0209 15:01:42.293444 22542570456896 run_lib.py:133] step: 266650, training_loss: 3.16273e-02
I0209 15:01:59.716987 22542570456896 run_lib.py:133] step: 266700, training_loss: 2.78499e-02
I0209 15:01:59.869315 22542570456896 run_lib.py:146] step: 266700, eval_loss: 2.97657e-02
I0209 15:02:17.503597 22542570456896 run_lib.py:133] step: 266750, training_loss: 2.32885e-02
I0209 15:02:34.944069 22542570456896 run_lib.py:133] step: 266800, training_loss: 3.29074e-02
I0209 15:02:35.105011 22542570456896 run_lib.py:146] step: 266800, eval_loss: 3.02223e-02
I0209 15:02:52.704648 22542570456896 run_lib.py:133] step: 266850, training_loss: 3.01373e-02
I0209 15:03:10.205133 22542570456896 run_lib.py:133] step: 266900, training_loss: 2.72636e-02
I0209 15:03:10.364575 22542570456896 run_lib.py:146] step: 266900, eval_loss: 2.70970e-02
I0209 15:03:27.985162 22542570456896 run_lib.py:133] step: 266950, training_loss: 2.90386e-02
I0209 15:03:45.401172 22542570456896 run_lib.py:133] step: 267000, training_loss: 2.75305e-02
I0209 15:03:45.557413 22542570456896 run_lib.py:146] step: 267000, eval_loss: 2.30816e-02
I0209 15:04:02.992785 22542570456896 run_lib.py:133] step: 267050, training_loss: 3.39868e-02
I0209 15:04:20.553842 22542570456896 run_lib.py:133] step: 267100, training_loss: 2.91765e-02
I0209 15:04:20.708122 22542570456896 run_lib.py:146] step: 267100, eval_loss: 3.49579e-02
I0209 15:04:38.159438 22542570456896 run_lib.py:133] step: 267150, training_loss: 3.34104e-02
I0209 15:04:55.822314 22542570456896 run_lib.py:133] step: 267200, training_loss: 2.44022e-02
I0209 15:04:55.976580 22542570456896 run_lib.py:146] step: 267200, eval_loss: 2.79683e-02
I0209 15:05:13.443404 22542570456896 run_lib.py:133] step: 267250, training_loss: 2.70318e-02
I0209 15:05:30.901081 22542570456896 run_lib.py:133] step: 267300, training_loss: 2.89230e-02
I0209 15:05:31.057340 22542570456896 run_lib.py:146] step: 267300, eval_loss: 2.19081e-02
I0209 15:05:48.655381 22542570456896 run_lib.py:133] step: 267350, training_loss: 2.96927e-02
I0209 15:06:06.122120 22542570456896 run_lib.py:133] step: 267400, training_loss: 2.61448e-02
I0209 15:06:06.303332 22542570456896 run_lib.py:146] step: 267400, eval_loss: 2.71843e-02
I0209 15:06:23.761084 22542570456896 run_lib.py:133] step: 267450, training_loss: 2.77655e-02
I0209 15:06:41.384720 22542570456896 run_lib.py:133] step: 267500, training_loss: 2.68186e-02
I0209 15:06:41.541598 22542570456896 run_lib.py:146] step: 267500, eval_loss: 3.01957e-02
I0209 15:06:58.998686 22542570456896 run_lib.py:133] step: 267550, training_loss: 3.09614e-02
I0209 15:07:16.403690 22542570456896 run_lib.py:133] step: 267600, training_loss: 2.65342e-02
I0209 15:07:16.559302 22542570456896 run_lib.py:146] step: 267600, eval_loss: 2.72865e-02
I0209 15:07:34.031352 22542570456896 run_lib.py:133] step: 267650, training_loss: 2.48346e-02
I0209 15:07:51.442614 22542570456896 run_lib.py:133] step: 267700, training_loss: 2.70960e-02
I0209 15:07:51.597676 22542570456896 run_lib.py:146] step: 267700, eval_loss: 2.32138e-02
I0209 15:08:09.096221 22542570456896 run_lib.py:133] step: 267750, training_loss: 2.73905e-02
I0209 15:08:26.505977 22542570456896 run_lib.py:133] step: 267800, training_loss: 3.27788e-02
I0209 15:08:26.669400 22542570456896 run_lib.py:146] step: 267800, eval_loss: 3.29700e-02
I0209 15:08:44.280431 22542570456896 run_lib.py:133] step: 267850, training_loss: 2.75782e-02
I0209 15:09:01.777531 22542570456896 run_lib.py:133] step: 267900, training_loss: 3.20578e-02
I0209 15:09:01.933562 22542570456896 run_lib.py:146] step: 267900, eval_loss: 2.58056e-02
I0209 15:09:19.392964 22542570456896 run_lib.py:133] step: 267950, training_loss: 3.00250e-02
I0209 15:09:36.876325 22542570456896 run_lib.py:133] step: 268000, training_loss: 3.08263e-02
I0209 15:09:37.033208 22542570456896 run_lib.py:146] step: 268000, eval_loss: 2.35236e-02
I0209 15:09:54.672972 22542570456896 run_lib.py:133] step: 268050, training_loss: 3.11090e-02
I0209 15:10:12.088453 22542570456896 run_lib.py:133] step: 268100, training_loss: 3.16681e-02
I0209 15:10:12.241127 22542570456896 run_lib.py:146] step: 268100, eval_loss: 2.99393e-02
I0209 15:10:29.822122 22542570456896 run_lib.py:133] step: 268150, training_loss: 2.16581e-02
I0209 15:10:47.324889 22542570456896 run_lib.py:133] step: 268200, training_loss: 2.91986e-02
I0209 15:10:47.478343 22542570456896 run_lib.py:146] step: 268200, eval_loss: 3.07188e-02
I0209 15:11:05.050150 22542570456896 run_lib.py:133] step: 268250, training_loss: 2.51522e-02
I0209 15:11:22.516279 22542570456896 run_lib.py:133] step: 268300, training_loss: 3.44923e-02
I0209 15:11:22.696463 22542570456896 run_lib.py:146] step: 268300, eval_loss: 2.75062e-02
I0209 15:11:40.367154 22542570456896 run_lib.py:133] step: 268350, training_loss: 2.73185e-02
I0209 15:11:57.789562 22542570456896 run_lib.py:133] step: 268400, training_loss: 2.62917e-02
I0209 15:11:57.955514 22542570456896 run_lib.py:146] step: 268400, eval_loss: 2.30883e-02
I0209 15:12:15.377673 22542570456896 run_lib.py:133] step: 268450, training_loss: 2.59984e-02
I0209 15:12:32.917009 22542570456896 run_lib.py:133] step: 268500, training_loss: 2.91638e-02
I0209 15:12:33.071676 22542570456896 run_lib.py:146] step: 268500, eval_loss: 2.48504e-02
I0209 15:12:50.494424 22542570456896 run_lib.py:133] step: 268550, training_loss: 3.33846e-02
I0209 15:13:07.975723 22542570456896 run_lib.py:133] step: 268600, training_loss: 2.42983e-02
I0209 15:13:08.130264 22542570456896 run_lib.py:146] step: 268600, eval_loss: 3.23753e-02
I0209 15:13:25.778908 22542570456896 run_lib.py:133] step: 268650, training_loss: 2.83647e-02
I0209 15:13:43.208998 22542570456896 run_lib.py:133] step: 268700, training_loss: 3.03595e-02
I0209 15:13:43.365416 22542570456896 run_lib.py:146] step: 268700, eval_loss: 2.25042e-02
I0209 15:14:00.935006 22542570456896 run_lib.py:133] step: 268750, training_loss: 2.76304e-02
I0209 15:14:18.359686 22542570456896 run_lib.py:133] step: 268800, training_loss: 3.02266e-02
I0209 15:14:18.518568 22542570456896 run_lib.py:146] step: 268800, eval_loss: 2.40778e-02
I0209 15:14:35.961803 22542570456896 run_lib.py:133] step: 268850, training_loss: 2.28205e-02
I0209 15:14:53.582786 22542570456896 run_lib.py:133] step: 268900, training_loss: 2.04367e-02
I0209 15:14:53.738466 22542570456896 run_lib.py:146] step: 268900, eval_loss: 3.04496e-02
I0209 15:15:11.162040 22542570456896 run_lib.py:133] step: 268950, training_loss: 2.43453e-02
I0209 15:15:28.595469 22542570456896 run_lib.py:133] step: 269000, training_loss: 2.72350e-02
I0209 15:15:28.751376 22542570456896 run_lib.py:146] step: 269000, eval_loss: 2.76289e-02
I0209 15:15:46.206949 22542570456896 run_lib.py:133] step: 269050, training_loss: 3.34248e-02
I0209 15:16:03.812678 22542570456896 run_lib.py:133] step: 269100, training_loss: 2.81827e-02
I0209 15:16:03.964424 22542570456896 run_lib.py:146] step: 269100, eval_loss: 3.26398e-02
I0209 15:16:21.394044 22542570456896 run_lib.py:133] step: 269150, training_loss: 2.69073e-02
I0209 15:16:38.908560 22542570456896 run_lib.py:133] step: 269200, training_loss: 3.10345e-02
I0209 15:16:39.077651 22542570456896 run_lib.py:146] step: 269200, eval_loss: 2.38505e-02
I0209 15:16:56.544676 22542570456896 run_lib.py:133] step: 269250, training_loss: 2.56810e-02
I0209 15:17:14.028236 22542570456896 run_lib.py:133] step: 269300, training_loss: 3.34444e-02
I0209 15:17:14.186644 22542570456896 run_lib.py:146] step: 269300, eval_loss: 3.66049e-02
I0209 15:17:31.794577 22542570456896 run_lib.py:133] step: 269350, training_loss: 3.15064e-02
I0209 15:17:49.289764 22542570456896 run_lib.py:133] step: 269400, training_loss: 2.82082e-02
I0209 15:17:49.444181 22542570456896 run_lib.py:146] step: 269400, eval_loss: 2.47469e-02
I0209 15:18:06.827773 22542570456896 run_lib.py:133] step: 269450, training_loss: 3.38549e-02
I0209 15:18:24.323375 22542570456896 run_lib.py:133] step: 269500, training_loss: 2.34452e-02
I0209 15:18:24.487913 22542570456896 run_lib.py:146] step: 269500, eval_loss: 2.78513e-02
I0209 15:18:42.139233 22542570456896 run_lib.py:133] step: 269550, training_loss: 2.80323e-02
I0209 15:18:59.558531 22542570456896 run_lib.py:133] step: 269600, training_loss: 2.44042e-02
I0209 15:18:59.711321 22542570456896 run_lib.py:146] step: 269600, eval_loss: 2.76591e-02
I0209 15:19:17.277302 22542570456896 run_lib.py:133] step: 269650, training_loss: 2.82475e-02
I0209 15:19:34.778016 22542570456896 run_lib.py:133] step: 269700, training_loss: 2.53471e-02
I0209 15:19:34.941979 22542570456896 run_lib.py:146] step: 269700, eval_loss: 3.79987e-02
I0209 15:19:52.528290 22542570456896 run_lib.py:133] step: 269750, training_loss: 2.76888e-02
I0209 15:20:10.021381 22542570456896 run_lib.py:133] step: 269800, training_loss: 2.61788e-02
I0209 15:20:10.181540 22542570456896 run_lib.py:146] step: 269800, eval_loss: 2.45743e-02
I0209 15:20:27.589665 22542570456896 run_lib.py:133] step: 269850, training_loss: 3.47195e-02
I0209 15:20:45.193933 22542570456896 run_lib.py:133] step: 269900, training_loss: 2.48801e-02
I0209 15:20:45.350311 22542570456896 run_lib.py:146] step: 269900, eval_loss: 3.16142e-02
I0209 15:21:02.779564 22542570456896 run_lib.py:133] step: 269950, training_loss: 2.99231e-02
I0209 15:21:20.337636 22542570456896 run_lib.py:133] step: 270000, training_loss: 2.67419e-02
I0209 15:21:21.075052 22542570456896 run_lib.py:146] step: 270000, eval_loss: 2.17156e-02
I0209 15:21:41.226423 22542570456896 run_lib.py:133] step: 270050, training_loss: 2.97854e-02
I0209 15:21:58.679370 22542570456896 run_lib.py:133] step: 270100, training_loss: 3.62321e-02
I0209 15:21:58.841142 22542570456896 run_lib.py:146] step: 270100, eval_loss: 2.63278e-02
I0209 15:22:16.254635 22542570456896 run_lib.py:133] step: 270150, training_loss: 2.76729e-02
I0209 15:22:33.723448 22542570456896 run_lib.py:133] step: 270200, training_loss: 2.90556e-02
I0209 15:22:33.889352 22542570456896 run_lib.py:146] step: 270200, eval_loss: 2.88142e-02
I0209 15:22:51.466662 22542570456896 run_lib.py:133] step: 270250, training_loss: 2.51028e-02
I0209 15:23:08.956904 22542570456896 run_lib.py:133] step: 270300, training_loss: 2.63317e-02
I0209 15:23:09.137463 22542570456896 run_lib.py:146] step: 270300, eval_loss: 3.01208e-02
I0209 15:23:26.604461 22542570456896 run_lib.py:133] step: 270350, training_loss: 3.30997e-02
I0209 15:23:44.089468 22542570456896 run_lib.py:133] step: 270400, training_loss: 2.40305e-02
I0209 15:23:44.246387 22542570456896 run_lib.py:146] step: 270400, eval_loss: 2.70488e-02
I0209 15:24:01.859515 22542570456896 run_lib.py:133] step: 270450, training_loss: 2.66226e-02
I0209 15:24:19.252754 22542570456896 run_lib.py:133] step: 270500, training_loss: 2.00819e-02
I0209 15:24:19.405028 22542570456896 run_lib.py:146] step: 270500, eval_loss: 3.51439e-02
I0209 15:24:36.944831 22542570456896 run_lib.py:133] step: 270550, training_loss: 3.08746e-02
I0209 15:24:54.366873 22542570456896 run_lib.py:133] step: 270600, training_loss: 3.01668e-02
I0209 15:24:54.521476 22542570456896 run_lib.py:146] step: 270600, eval_loss: 2.76137e-02
I0209 15:25:12.125728 22542570456896 run_lib.py:133] step: 270650, training_loss: 2.55459e-02
I0209 15:25:29.509459 22542570456896 run_lib.py:133] step: 270700, training_loss: 2.13304e-02
I0209 15:25:29.666245 22542570456896 run_lib.py:146] step: 270700, eval_loss: 3.09987e-02
I0209 15:25:47.238753 22542570456896 run_lib.py:133] step: 270750, training_loss: 2.77906e-02
I0209 15:26:04.648000 22542570456896 run_lib.py:133] step: 270800, training_loss: 2.60422e-02
I0209 15:26:04.806810 22542570456896 run_lib.py:146] step: 270800, eval_loss: 2.96022e-02
I0209 15:26:22.267695 22542570456896 run_lib.py:133] step: 270850, training_loss: 2.93354e-02
I0209 15:26:39.927717 22542570456896 run_lib.py:133] step: 270900, training_loss: 2.63154e-02
I0209 15:26:40.091107 22542570456896 run_lib.py:146] step: 270900, eval_loss: 3.80162e-02
I0209 15:26:57.527910 22542570456896 run_lib.py:133] step: 270950, training_loss: 3.38344e-02
I0209 15:27:14.958038 22542570456896 run_lib.py:133] step: 271000, training_loss: 2.93159e-02
I0209 15:27:15.113416 22542570456896 run_lib.py:146] step: 271000, eval_loss: 2.60624e-02
I0209 15:27:32.753115 22542570456896 run_lib.py:133] step: 271050, training_loss: 3.25415e-02
I0209 15:27:50.330650 22542570456896 run_lib.py:133] step: 271100, training_loss: 2.56895e-02
I0209 15:27:50.485543 22542570456896 run_lib.py:146] step: 271100, eval_loss: 4.28566e-02
I0209 15:28:07.955717 22542570456896 run_lib.py:133] step: 271150, training_loss: 3.05052e-02
I0209 15:28:25.406256 22542570456896 run_lib.py:133] step: 271200, training_loss: 1.93517e-02
I0209 15:28:25.565310 22542570456896 run_lib.py:146] step: 271200, eval_loss: 2.32075e-02
I0209 15:28:42.982620 22542570456896 run_lib.py:133] step: 271250, training_loss: 2.93655e-02
I0209 15:29:00.601357 22542570456896 run_lib.py:133] step: 271300, training_loss: 3.77081e-02
I0209 15:29:00.761842 22542570456896 run_lib.py:146] step: 271300, eval_loss: 2.76424e-02
I0209 15:29:18.201591 22542570456896 run_lib.py:133] step: 271350, training_loss: 2.50123e-02
I0209 15:29:35.607331 22542570456896 run_lib.py:133] step: 271400, training_loss: 2.43453e-02
I0209 15:29:35.767150 22542570456896 run_lib.py:146] step: 271400, eval_loss: 2.78417e-02
I0209 15:29:53.246903 22542570456896 run_lib.py:133] step: 271450, training_loss: 3.31965e-02
I0209 15:30:10.877917 22542570456896 run_lib.py:133] step: 271500, training_loss: 2.49178e-02
I0209 15:30:11.031563 22542570456896 run_lib.py:146] step: 271500, eval_loss: 3.31617e-02
I0209 15:30:28.450876 22542570456896 run_lib.py:133] step: 271550, training_loss: 2.84557e-02
I0209 15:30:45.941954 22542570456896 run_lib.py:133] step: 271600, training_loss: 3.48345e-02
I0209 15:30:46.096420 22542570456896 run_lib.py:146] step: 271600, eval_loss: 2.70279e-02
I0209 15:31:03.528415 22542570456896 run_lib.py:133] step: 271650, training_loss: 3.33557e-02
I0209 15:31:20.984733 22542570456896 run_lib.py:133] step: 271700, training_loss: 2.97993e-02
I0209 15:31:21.158552 22542570456896 run_lib.py:146] step: 271700, eval_loss: 2.61508e-02
I0209 15:31:38.856165 22542570456896 run_lib.py:133] step: 271750, training_loss: 2.77364e-02
I0209 15:31:56.362405 22542570456896 run_lib.py:133] step: 271800, training_loss: 3.20668e-02
I0209 15:31:56.519666 22542570456896 run_lib.py:146] step: 271800, eval_loss: 3.62111e-02
I0209 15:32:13.985705 22542570456896 run_lib.py:133] step: 271850, training_loss: 2.60477e-02
I0209 15:32:31.411669 22542570456896 run_lib.py:133] step: 271900, training_loss: 2.94154e-02
I0209 15:32:31.567482 22542570456896 run_lib.py:146] step: 271900, eval_loss: 3.33847e-02
I0209 15:32:49.121785 22542570456896 run_lib.py:133] step: 271950, training_loss: 2.06368e-02
I0209 15:33:06.593165 22542570456896 run_lib.py:133] step: 272000, training_loss: 2.72025e-02
I0209 15:33:06.746563 22542570456896 run_lib.py:146] step: 272000, eval_loss: 2.46923e-02
I0209 15:33:24.395236 22542570456896 run_lib.py:133] step: 272050, training_loss: 2.86734e-02
I0209 15:33:41.809273 22542570456896 run_lib.py:133] step: 272100, training_loss: 2.45011e-02
I0209 15:33:41.965373 22542570456896 run_lib.py:146] step: 272100, eval_loss: 3.13167e-02
I0209 15:33:59.545670 22542570456896 run_lib.py:133] step: 272150, training_loss: 2.63154e-02
I0209 15:34:16.948199 22542570456896 run_lib.py:133] step: 272200, training_loss: 2.86584e-02
I0209 15:34:17.105479 22542570456896 run_lib.py:146] step: 272200, eval_loss: 3.33447e-02
I0209 15:34:34.556855 22542570456896 run_lib.py:133] step: 272250, training_loss: 2.91123e-02
I0209 15:34:52.178326 22542570456896 run_lib.py:133] step: 272300, training_loss: 3.17424e-02
I0209 15:34:52.334638 22542570456896 run_lib.py:146] step: 272300, eval_loss: 2.93500e-02
I0209 15:35:09.775756 22542570456896 run_lib.py:133] step: 272350, training_loss: 3.00252e-02
I0209 15:35:27.408495 22542570456896 run_lib.py:133] step: 272400, training_loss: 2.38977e-02
I0209 15:35:27.569388 22542570456896 run_lib.py:146] step: 272400, eval_loss: 3.36950e-02
I0209 15:35:45.011783 22542570456896 run_lib.py:133] step: 272450, training_loss: 2.71566e-02
I0209 15:36:02.467448 22542570456896 run_lib.py:133] step: 272500, training_loss: 2.74256e-02
I0209 15:36:02.624346 22542570456896 run_lib.py:146] step: 272500, eval_loss: 2.75737e-02
I0209 15:36:20.219783 22542570456896 run_lib.py:133] step: 272550, training_loss: 3.44903e-02
I0209 15:36:37.716480 22542570456896 run_lib.py:133] step: 272600, training_loss: 2.75734e-02
I0209 15:36:37.886472 22542570456896 run_lib.py:146] step: 272600, eval_loss: 3.31641e-02
I0209 15:36:55.368757 22542570456896 run_lib.py:133] step: 272650, training_loss: 2.33649e-02
I0209 15:37:13.011391 22542570456896 run_lib.py:133] step: 272700, training_loss: 2.99885e-02
I0209 15:37:13.173579 22542570456896 run_lib.py:146] step: 272700, eval_loss: 3.07407e-02
I0209 15:37:30.664561 22542570456896 run_lib.py:133] step: 272750, training_loss: 2.51906e-02
I0209 15:37:48.095089 22542570456896 run_lib.py:133] step: 272800, training_loss: 2.41871e-02
I0209 15:37:48.249186 22542570456896 run_lib.py:146] step: 272800, eval_loss: 2.56643e-02
I0209 15:38:05.763305 22542570456896 run_lib.py:133] step: 272850, training_loss: 3.07540e-02
I0209 15:38:23.237538 22542570456896 run_lib.py:133] step: 272900, training_loss: 3.07919e-02
I0209 15:38:23.392547 22542570456896 run_lib.py:146] step: 272900, eval_loss: 2.67756e-02
I0209 15:38:40.840385 22542570456896 run_lib.py:133] step: 272950, training_loss: 3.14697e-02
I0209 15:38:58.237798 22542570456896 run_lib.py:133] step: 273000, training_loss: 2.50924e-02
I0209 15:38:58.391321 22542570456896 run_lib.py:146] step: 273000, eval_loss: 2.96747e-02
I0209 15:39:16.007083 22542570456896 run_lib.py:133] step: 273050, training_loss: 3.29507e-02
I0209 15:39:33.483954 22542570456896 run_lib.py:133] step: 273100, training_loss: 2.48322e-02
I0209 15:39:33.643451 22542570456896 run_lib.py:146] step: 273100, eval_loss: 2.91247e-02
I0209 15:39:51.091837 22542570456896 run_lib.py:133] step: 273150, training_loss: 3.04658e-02
I0209 15:40:08.598305 22542570456896 run_lib.py:133] step: 273200, training_loss: 2.22623e-02
I0209 15:40:08.758337 22542570456896 run_lib.py:146] step: 273200, eval_loss: 3.08681e-02
I0209 15:40:26.333134 22542570456896 run_lib.py:133] step: 273250, training_loss: 2.53733e-02
I0209 15:40:43.720933 22542570456896 run_lib.py:133] step: 273300, training_loss: 2.98576e-02
I0209 15:40:43.876026 22542570456896 run_lib.py:146] step: 273300, eval_loss: 2.10679e-02
I0209 15:41:01.410611 22542570456896 run_lib.py:133] step: 273350, training_loss: 2.58791e-02
I0209 15:41:18.850896 22542570456896 run_lib.py:133] step: 273400, training_loss: 2.58929e-02
I0209 15:41:19.003169 22542570456896 run_lib.py:146] step: 273400, eval_loss: 3.90789e-02
I0209 15:41:36.586482 22542570456896 run_lib.py:133] step: 273450, training_loss: 3.00666e-02
I0209 15:41:54.034834 22542570456896 run_lib.py:133] step: 273500, training_loss: 2.61382e-02
I0209 15:41:54.194581 22542570456896 run_lib.py:146] step: 273500, eval_loss: 3.02685e-02
I0209 15:42:11.808586 22542570456896 run_lib.py:133] step: 273550, training_loss: 2.19095e-02
I0209 15:42:29.241371 22542570456896 run_lib.py:133] step: 273600, training_loss: 2.94292e-02
I0209 15:42:29.400428 22542570456896 run_lib.py:146] step: 273600, eval_loss: 2.97211e-02
I0209 15:42:46.846494 22542570456896 run_lib.py:133] step: 273650, training_loss: 2.49919e-02
I0209 15:43:04.385243 22542570456896 run_lib.py:133] step: 273700, training_loss: 2.50837e-02
I0209 15:43:04.553281 22542570456896 run_lib.py:146] step: 273700, eval_loss: 3.61655e-02
I0209 15:43:21.996861 22542570456896 run_lib.py:133] step: 273750, training_loss: 2.61731e-02
I0209 15:43:39.491485 22542570456896 run_lib.py:133] step: 273800, training_loss: 2.54591e-02
I0209 15:43:39.647605 22542570456896 run_lib.py:146] step: 273800, eval_loss: 2.30418e-02
I0209 15:43:57.303052 22542570456896 run_lib.py:133] step: 273850, training_loss: 2.95607e-02
I0209 15:44:14.720771 22542570456896 run_lib.py:133] step: 273900, training_loss: 3.03882e-02
I0209 15:44:14.872320 22542570456896 run_lib.py:146] step: 273900, eval_loss: 1.91615e-02
I0209 15:44:32.442209 22542570456896 run_lib.py:133] step: 273950, training_loss: 3.17448e-02
I0209 15:44:49.899802 22542570456896 run_lib.py:133] step: 274000, training_loss: 2.96899e-02
I0209 15:44:50.064558 22542570456896 run_lib.py:146] step: 274000, eval_loss: 2.58465e-02
I0209 15:45:07.535695 22542570456896 run_lib.py:133] step: 274050, training_loss: 2.36010e-02
I0209 15:45:25.196487 22542570456896 run_lib.py:133] step: 274100, training_loss: 3.18518e-02
I0209 15:45:25.354491 22542570456896 run_lib.py:146] step: 274100, eval_loss: 2.10046e-02
I0209 15:45:42.799501 22542570456896 run_lib.py:133] step: 274150, training_loss: 2.86187e-02
I0209 15:46:00.226457 22542570456896 run_lib.py:133] step: 274200, training_loss: 2.64177e-02
I0209 15:46:00.387410 22542570456896 run_lib.py:146] step: 274200, eval_loss: 3.00846e-02
I0209 15:46:17.796159 22542570456896 run_lib.py:133] step: 274250, training_loss: 3.90242e-02
I0209 15:46:35.377574 22542570456896 run_lib.py:133] step: 274300, training_loss: 3.70302e-02
I0209 15:46:35.536610 22542570456896 run_lib.py:146] step: 274300, eval_loss: 2.43215e-02
I0209 15:46:52.986852 22542570456896 run_lib.py:133] step: 274350, training_loss: 2.14347e-02
I0209 15:47:10.545472 22542570456896 run_lib.py:133] step: 274400, training_loss: 2.49787e-02
I0209 15:47:10.696319 22542570456896 run_lib.py:146] step: 274400, eval_loss: 2.90830e-02
I0209 15:47:28.114652 22542570456896 run_lib.py:133] step: 274450, training_loss: 3.14447e-02
I0209 15:47:45.557517 22542570456896 run_lib.py:133] step: 274500, training_loss: 3.43998e-02
I0209 15:47:45.713120 22542570456896 run_lib.py:146] step: 274500, eval_loss: 2.90453e-02
I0209 15:48:03.285658 22542570456896 run_lib.py:133] step: 274550, training_loss: 2.80157e-02
I0209 15:48:20.817041 22542570456896 run_lib.py:133] step: 274600, training_loss: 3.74570e-02
I0209 15:48:20.983409 22542570456896 run_lib.py:146] step: 274600, eval_loss: 2.61132e-02
I0209 15:48:38.413128 22542570456896 run_lib.py:133] step: 274650, training_loss: 2.28527e-02
I0209 15:48:55.862431 22542570456896 run_lib.py:133] step: 274700, training_loss: 2.67522e-02
I0209 15:48:56.017589 22542570456896 run_lib.py:146] step: 274700, eval_loss: 2.81502e-02
I0209 15:49:13.672550 22542570456896 run_lib.py:133] step: 274750, training_loss: 3.03009e-02
I0209 15:49:31.101905 22542570456896 run_lib.py:133] step: 274800, training_loss: 2.91198e-02
I0209 15:49:31.255394 22542570456896 run_lib.py:146] step: 274800, eval_loss: 2.40371e-02
I0209 15:49:48.881154 22542570456896 run_lib.py:133] step: 274850, training_loss: 2.63101e-02
I0209 15:50:06.318267 22542570456896 run_lib.py:133] step: 274900, training_loss: 3.14490e-02
I0209 15:50:06.474660 22542570456896 run_lib.py:146] step: 274900, eval_loss: 2.77486e-02
I0209 15:50:24.114227 22542570456896 run_lib.py:133] step: 274950, training_loss: 3.21516e-02
I0209 15:50:41.576820 22542570456896 run_lib.py:133] step: 275000, training_loss: 2.54284e-02
I0209 15:50:41.736817 22542570456896 run_lib.py:146] step: 275000, eval_loss: 3.57255e-02
I0209 15:50:59.140629 22542570456896 run_lib.py:133] step: 275050, training_loss: 2.68728e-02
I0209 15:51:16.678186 22542570456896 run_lib.py:133] step: 275100, training_loss: 3.21291e-02
I0209 15:51:16.842369 22542570456896 run_lib.py:146] step: 275100, eval_loss: 3.04457e-02
I0209 15:51:34.334391 22542570456896 run_lib.py:133] step: 275150, training_loss: 2.91479e-02
I0209 15:51:51.995430 22542570456896 run_lib.py:133] step: 275200, training_loss: 2.47754e-02
I0209 15:51:52.148262 22542570456896 run_lib.py:146] step: 275200, eval_loss: 2.54439e-02
I0209 15:52:09.585063 22542570456896 run_lib.py:133] step: 275250, training_loss: 2.33244e-02
I0209 15:52:27.012130 22542570456896 run_lib.py:133] step: 275300, training_loss: 2.61869e-02
I0209 15:52:27.164424 22542570456896 run_lib.py:146] step: 275300, eval_loss: 3.19689e-02
I0209 15:52:44.734997 22542570456896 run_lib.py:133] step: 275350, training_loss: 2.82873e-02
I0209 15:53:02.180829 22542570456896 run_lib.py:133] step: 275400, training_loss: 2.72368e-02
I0209 15:53:02.348608 22542570456896 run_lib.py:146] step: 275400, eval_loss: 2.30400e-02
I0209 15:53:19.831288 22542570456896 run_lib.py:133] step: 275450, training_loss: 2.51547e-02
I0209 15:53:37.467133 22542570456896 run_lib.py:133] step: 275500, training_loss: 2.42783e-02
I0209 15:53:37.626338 22542570456896 run_lib.py:146] step: 275500, eval_loss: 2.55404e-02
I0209 15:53:55.064540 22542570456896 run_lib.py:133] step: 275550, training_loss: 2.87203e-02
I0209 15:54:12.492084 22542570456896 run_lib.py:133] step: 275600, training_loss: 3.02751e-02
I0209 15:54:12.797349 22542570456896 run_lib.py:146] step: 275600, eval_loss: 2.61572e-02
I0209 15:54:30.218456 22542570456896 run_lib.py:133] step: 275650, training_loss: 4.01000e-02
I0209 15:54:47.744068 22542570456896 run_lib.py:133] step: 275700, training_loss: 2.46747e-02
I0209 15:54:47.897540 22542570456896 run_lib.py:146] step: 275700, eval_loss: 3.13390e-02
I0209 15:55:05.352175 22542570456896 run_lib.py:133] step: 275750, training_loss: 2.73975e-02
I0209 15:55:22.784493 22542570456896 run_lib.py:133] step: 275800, training_loss: 2.29320e-02
I0209 15:55:22.937394 22542570456896 run_lib.py:146] step: 275800, eval_loss: 2.93713e-02
I0209 15:55:40.526255 22542570456896 run_lib.py:133] step: 275850, training_loss: 2.85916e-02
I0209 15:55:58.008804 22542570456896 run_lib.py:133] step: 275900, training_loss: 2.45557e-02
I0209 15:55:58.170546 22542570456896 run_lib.py:146] step: 275900, eval_loss: 2.47669e-02
I0209 15:56:15.667562 22542570456896 run_lib.py:133] step: 275950, training_loss: 3.10770e-02
I0209 15:56:33.118162 22542570456896 run_lib.py:133] step: 276000, training_loss: 3.17302e-02
I0209 15:56:33.277359 22542570456896 run_lib.py:146] step: 276000, eval_loss: 3.03570e-02
I0209 15:56:50.882212 22542570456896 run_lib.py:133] step: 276050, training_loss: 2.53669e-02
I0209 15:57:08.358190 22542570456896 run_lib.py:133] step: 276100, training_loss: 2.84403e-02
I0209 15:57:08.514390 22542570456896 run_lib.py:146] step: 276100, eval_loss: 2.89912e-02
I0209 15:57:25.926862 22542570456896 run_lib.py:133] step: 276150, training_loss: 2.56472e-02
I0209 15:57:43.325923 22542570456896 run_lib.py:133] step: 276200, training_loss: 2.64540e-02
I0209 15:57:43.489326 22542570456896 run_lib.py:146] step: 276200, eval_loss: 3.05883e-02
I0209 15:58:01.110507 22542570456896 run_lib.py:133] step: 276250, training_loss: 2.63287e-02
I0209 15:58:18.559904 22542570456896 run_lib.py:133] step: 276300, training_loss: 3.18112e-02
I0209 15:58:18.719638 22542570456896 run_lib.py:146] step: 276300, eval_loss: 3.26247e-02
I0209 15:58:36.375729 22542570456896 run_lib.py:133] step: 276350, training_loss: 2.91704e-02
I0209 15:58:53.810486 22542570456896 run_lib.py:133] step: 276400, training_loss: 2.56672e-02
I0209 15:58:53.969661 22542570456896 run_lib.py:146] step: 276400, eval_loss: 2.94812e-02
I0209 15:59:11.502374 22542570456896 run_lib.py:133] step: 276450, training_loss: 3.62969e-02
I0209 15:59:28.914414 22542570456896 run_lib.py:133] step: 276500, training_loss: 2.58666e-02
I0209 15:59:29.089350 22542570456896 run_lib.py:146] step: 276500, eval_loss: 3.07489e-02
I0209 15:59:46.601893 22542570456896 run_lib.py:133] step: 276550, training_loss: 2.64332e-02
I0209 16:00:04.188697 22542570456896 run_lib.py:133] step: 276600, training_loss: 2.98443e-02
I0209 16:00:04.349187 22542570456896 run_lib.py:146] step: 276600, eval_loss: 3.15517e-02
I0209 16:00:21.812262 22542570456896 run_lib.py:133] step: 276650, training_loss: 2.55564e-02
I0209 16:00:39.361968 22542570456896 run_lib.py:133] step: 276700, training_loss: 2.88096e-02
I0209 16:00:39.512431 22542570456896 run_lib.py:146] step: 276700, eval_loss: 2.52049e-02
I0209 16:00:56.960663 22542570456896 run_lib.py:133] step: 276750, training_loss: 2.65560e-02
I0209 16:01:14.435039 22542570456896 run_lib.py:133] step: 276800, training_loss: 2.70988e-02
I0209 16:01:14.592291 22542570456896 run_lib.py:146] step: 276800, eval_loss: 3.10764e-02
I0209 16:01:32.236448 22542570456896 run_lib.py:133] step: 276850, training_loss: 2.36455e-02
I0209 16:01:49.676779 22542570456896 run_lib.py:133] step: 276900, training_loss: 2.69160e-02
I0209 16:01:49.835248 22542570456896 run_lib.py:146] step: 276900, eval_loss: 2.60479e-02
I0209 16:02:07.231614 22542570456896 run_lib.py:133] step: 276950, training_loss: 3.21991e-02
I0209 16:02:24.625012 22542570456896 run_lib.py:133] step: 277000, training_loss: 2.95293e-02
I0209 16:02:24.782204 22542570456896 run_lib.py:146] step: 277000, eval_loss: 2.27107e-02
I0209 16:02:42.363777 22542570456896 run_lib.py:133] step: 277050, training_loss: 2.91623e-02
I0209 16:02:59.867266 22542570456896 run_lib.py:133] step: 277100, training_loss: 2.73099e-02
I0209 16:03:00.024145 22542570456896 run_lib.py:146] step: 277100, eval_loss: 3.18430e-02
I0209 16:03:17.563341 22542570456896 run_lib.py:133] step: 277150, training_loss: 3.07253e-02
I0209 16:03:34.958530 22542570456896 run_lib.py:133] step: 277200, training_loss: 3.14139e-02
I0209 16:03:35.114573 22542570456896 run_lib.py:146] step: 277200, eval_loss: 2.57178e-02
I0209 16:03:52.517124 22542570456896 run_lib.py:133] step: 277250, training_loss: 3.66381e-02
I0209 16:04:09.935915 22542570456896 run_lib.py:133] step: 277300, training_loss: 3.29587e-02
I0209 16:04:10.087729 22542570456896 run_lib.py:146] step: 277300, eval_loss: 3.58688e-02
I0209 16:04:27.632687 22542570456896 run_lib.py:133] step: 277350, training_loss: 3.30826e-02
I0209 16:04:45.173381 22542570456896 run_lib.py:133] step: 277400, training_loss: 2.60860e-02
I0209 16:04:45.348578 22542570456896 run_lib.py:146] step: 277400, eval_loss: 2.75437e-02
I0209 16:05:02.762146 22542570456896 run_lib.py:133] step: 277450, training_loss: 2.50040e-02
I0209 16:05:20.185574 22542570456896 run_lib.py:133] step: 277500, training_loss: 3.05723e-02
I0209 16:05:20.336756 22542570456896 run_lib.py:146] step: 277500, eval_loss: 2.92094e-02
I0209 16:05:37.934820 22542570456896 run_lib.py:133] step: 277550, training_loss: 3.08396e-02
I0209 16:05:55.356403 22542570456896 run_lib.py:133] step: 277600, training_loss: 2.80334e-02
I0209 16:05:55.518931 22542570456896 run_lib.py:146] step: 277600, eval_loss: 3.88018e-02
I0209 16:06:13.134096 22542570456896 run_lib.py:133] step: 277650, training_loss: 2.52077e-02
I0209 16:06:30.593008 22542570456896 run_lib.py:133] step: 277700, training_loss: 2.62863e-02
I0209 16:06:30.747695 22542570456896 run_lib.py:146] step: 277700, eval_loss: 2.24771e-02
I0209 16:06:48.345571 22542570456896 run_lib.py:133] step: 277750, training_loss: 2.64641e-02
I0209 16:07:05.746777 22542570456896 run_lib.py:133] step: 277800, training_loss: 2.83413e-02
I0209 16:07:05.899272 22542570456896 run_lib.py:146] step: 277800, eval_loss: 2.18748e-02
I0209 16:07:23.449752 22542570456896 run_lib.py:133] step: 277850, training_loss: 1.80350e-02
I0209 16:07:40.916366 22542570456896 run_lib.py:133] step: 277900, training_loss: 2.40737e-02
I0209 16:07:41.090509 22542570456896 run_lib.py:146] step: 277900, eval_loss: 3.08323e-02
I0209 16:07:58.534722 22542570456896 run_lib.py:133] step: 277950, training_loss: 2.42057e-02
I0209 16:08:16.127736 22542570456896 run_lib.py:133] step: 278000, training_loss: 2.84303e-02
I0209 16:08:16.284654 22542570456896 run_lib.py:146] step: 278000, eval_loss: 2.31097e-02
I0209 16:08:33.693256 22542570456896 run_lib.py:133] step: 278050, training_loss: 2.16522e-02
I0209 16:08:51.075087 22542570456896 run_lib.py:133] step: 278100, training_loss: 2.86476e-02
I0209 16:08:51.225713 22542570456896 run_lib.py:146] step: 278100, eval_loss: 3.29184e-02
I0209 16:09:08.785317 22542570456896 run_lib.py:133] step: 278150, training_loss: 2.54774e-02
I0209 16:09:26.422741 22542570456896 run_lib.py:133] step: 278200, training_loss: 3.05482e-02
I0209 16:09:26.577423 22542570456896 run_lib.py:146] step: 278200, eval_loss: 3.63489e-02
I0209 16:09:44.021853 22542570456896 run_lib.py:133] step: 278250, training_loss: 2.70992e-02
I0209 16:10:01.442549 22542570456896 run_lib.py:133] step: 278300, training_loss: 3.12661e-02
I0209 16:10:01.598595 22542570456896 run_lib.py:146] step: 278300, eval_loss: 2.40215e-02
I0209 16:10:19.001893 22542570456896 run_lib.py:133] step: 278350, training_loss: 2.97990e-02
I0209 16:10:36.571034 22542570456896 run_lib.py:133] step: 278400, training_loss: 2.92130e-02
I0209 16:10:36.726253 22542570456896 run_lib.py:146] step: 278400, eval_loss: 2.34850e-02
I0209 16:10:54.131616 22542570456896 run_lib.py:133] step: 278450, training_loss: 2.44160e-02
I0209 16:11:11.594586 22542570456896 run_lib.py:133] step: 278500, training_loss: 3.00537e-02
I0209 16:11:11.758090 22542570456896 run_lib.py:146] step: 278500, eval_loss: 2.34503e-02
I0209 16:11:29.165441 22542570456896 run_lib.py:133] step: 278550, training_loss: 2.40738e-02
I0209 16:11:46.726096 22542570456896 run_lib.py:133] step: 278600, training_loss: 2.57896e-02
I0209 16:11:46.879853 22542570456896 run_lib.py:146] step: 278600, eval_loss: 2.85150e-02
I0209 16:12:04.285578 22542570456896 run_lib.py:133] step: 278650, training_loss: 2.41571e-02
I0209 16:12:21.794780 22542570456896 run_lib.py:133] step: 278700, training_loss: 3.51958e-02
I0209 16:12:21.954980 22542570456896 run_lib.py:146] step: 278700, eval_loss: 2.63247e-02
I0209 16:12:39.415543 22542570456896 run_lib.py:133] step: 278750, training_loss: 3.00173e-02
I0209 16:12:56.867469 22542570456896 run_lib.py:133] step: 278800, training_loss: 2.84406e-02
I0209 16:12:57.027329 22542570456896 run_lib.py:146] step: 278800, eval_loss: 2.29138e-02
I0209 16:13:14.624639 22542570456896 run_lib.py:133] step: 278850, training_loss: 2.98501e-02
I0209 16:13:32.113935 22542570456896 run_lib.py:133] step: 278900, training_loss: 3.66056e-02
I0209 16:13:32.272437 22542570456896 run_lib.py:146] step: 278900, eval_loss: 2.37156e-02
I0209 16:13:49.693739 22542570456896 run_lib.py:133] step: 278950, training_loss: 3.26151e-02
I0209 16:14:07.114602 22542570456896 run_lib.py:133] step: 279000, training_loss: 3.21472e-02
I0209 16:14:07.281153 22542570456896 run_lib.py:146] step: 279000, eval_loss: 2.88921e-02
I0209 16:14:24.892717 22542570456896 run_lib.py:133] step: 279050, training_loss: 2.64932e-02
I0209 16:14:42.300460 22542570456896 run_lib.py:133] step: 279100, training_loss: 3.01113e-02
I0209 16:14:42.452222 22542570456896 run_lib.py:146] step: 279100, eval_loss: 2.90141e-02
I0209 16:15:00.059267 22542570456896 run_lib.py:133] step: 279150, training_loss: 3.49141e-02
I0209 16:15:17.478747 22542570456896 run_lib.py:133] step: 279200, training_loss: 2.83746e-02
I0209 16:15:17.636373 22542570456896 run_lib.py:146] step: 279200, eval_loss: 3.25137e-02
I0209 16:15:35.188658 22542570456896 run_lib.py:133] step: 279250, training_loss: 2.50870e-02
I0209 16:15:52.659404 22542570456896 run_lib.py:133] step: 279300, training_loss: 3.42314e-02
I0209 16:15:52.833352 22542570456896 run_lib.py:146] step: 279300, eval_loss: 2.79439e-02
I0209 16:16:10.306600 22542570456896 run_lib.py:133] step: 279350, training_loss: 2.26391e-02
I0209 16:16:27.902445 22542570456896 run_lib.py:133] step: 279400, training_loss: 2.55497e-02
I0209 16:16:28.057577 22542570456896 run_lib.py:146] step: 279400, eval_loss: 2.65660e-02
I0209 16:16:45.473246 22542570456896 run_lib.py:133] step: 279450, training_loss: 2.83951e-02
I0209 16:17:03.043301 22542570456896 run_lib.py:133] step: 279500, training_loss: 2.96839e-02
I0209 16:17:03.199376 22542570456896 run_lib.py:146] step: 279500, eval_loss: 2.74452e-02
I0209 16:17:20.626747 22542570456896 run_lib.py:133] step: 279550, training_loss: 2.48620e-02
I0209 16:17:38.073356 22542570456896 run_lib.py:133] step: 279600, training_loss: 3.35509e-02
I0209 16:17:38.228513 22542570456896 run_lib.py:146] step: 279600, eval_loss: 2.36434e-02
I0209 16:17:55.887237 22542570456896 run_lib.py:133] step: 279650, training_loss: 2.91590e-02
I0209 16:18:13.302873 22542570456896 run_lib.py:133] step: 279700, training_loss: 2.38695e-02
I0209 16:18:13.466487 22542570456896 run_lib.py:146] step: 279700, eval_loss: 2.53202e-02
I0209 16:18:30.878634 22542570456896 run_lib.py:133] step: 279750, training_loss: 3.28091e-02
I0209 16:18:48.434707 22542570456896 run_lib.py:133] step: 279800, training_loss: 3.67969e-02
I0209 16:18:48.592384 22542570456896 run_lib.py:146] step: 279800, eval_loss: 2.60561e-02
I0209 16:19:06.052439 22542570456896 run_lib.py:133] step: 279850, training_loss: 2.73042e-02
I0209 16:19:23.489103 22542570456896 run_lib.py:133] step: 279900, training_loss: 2.63884e-02
I0209 16:19:23.645552 22542570456896 run_lib.py:146] step: 279900, eval_loss: 2.35159e-02
I0209 16:19:41.168606 22542570456896 run_lib.py:133] step: 279950, training_loss: 2.65954e-02
I0209 16:19:58.599540 22542570456896 run_lib.py:133] step: 280000, training_loss: 2.68670e-02
I0209 16:19:59.297075 22542570456896 run_lib.py:146] step: 280000, eval_loss: 3.28212e-02
I0209 16:20:19.331299 22542570456896 run_lib.py:133] step: 280050, training_loss: 2.81722e-02
I0209 16:20:36.721139 22542570456896 run_lib.py:133] step: 280100, training_loss: 3.31955e-02
I0209 16:20:36.879257 22542570456896 run_lib.py:146] step: 280100, eval_loss: 2.64098e-02
I0209 16:20:54.463126 22542570456896 run_lib.py:133] step: 280150, training_loss: 2.80402e-02
I0209 16:21:11.902929 22542570456896 run_lib.py:133] step: 280200, training_loss: 2.94317e-02
I0209 16:21:12.057527 22542570456896 run_lib.py:146] step: 280200, eval_loss: 2.79880e-02
I0209 16:21:29.614883 22542570456896 run_lib.py:133] step: 280250, training_loss: 2.83712e-02
I0209 16:21:47.062101 22542570456896 run_lib.py:133] step: 280300, training_loss: 2.63624e-02
I0209 16:21:47.221198 22542570456896 run_lib.py:146] step: 280300, eval_loss: 3.07335e-02
I0209 16:22:04.596613 22542570456896 run_lib.py:133] step: 280350, training_loss: 2.92687e-02
I0209 16:22:21.978881 22542570456896 run_lib.py:133] step: 280400, training_loss: 2.73485e-02
I0209 16:22:22.146084 22542570456896 run_lib.py:146] step: 280400, eval_loss: 3.53515e-02
I0209 16:22:39.716995 22542570456896 run_lib.py:133] step: 280450, training_loss: 3.80381e-02
I0209 16:22:57.286148 22542570456896 run_lib.py:133] step: 280500, training_loss: 2.95135e-02
I0209 16:22:57.441796 22542570456896 run_lib.py:146] step: 280500, eval_loss: 2.57780e-02
I0209 16:23:14.877439 22542570456896 run_lib.py:133] step: 280550, training_loss: 3.19291e-02
I0209 16:23:32.271140 22542570456896 run_lib.py:133] step: 280600, training_loss: 1.88056e-02
I0209 16:23:32.423101 22542570456896 run_lib.py:146] step: 280600, eval_loss: 3.28171e-02
I0209 16:23:49.994606 22542570456896 run_lib.py:133] step: 280650, training_loss: 3.29106e-02
I0209 16:24:07.438021 22542570456896 run_lib.py:133] step: 280700, training_loss: 3.23365e-02
I0209 16:24:07.604531 22542570456896 run_lib.py:146] step: 280700, eval_loss: 2.22535e-02
I0209 16:24:25.222246 22542570456896 run_lib.py:133] step: 280750, training_loss: 3.59723e-02
I0209 16:24:42.716253 22542570456896 run_lib.py:133] step: 280800, training_loss: 2.66055e-02
I0209 16:24:42.875319 22542570456896 run_lib.py:146] step: 280800, eval_loss: 2.11306e-02
I0209 16:25:00.510428 22542570456896 run_lib.py:133] step: 280850, training_loss: 2.75603e-02
I0209 16:25:17.963160 22542570456896 run_lib.py:133] step: 280900, training_loss: 3.27623e-02
I0209 16:25:18.123013 22542570456896 run_lib.py:146] step: 280900, eval_loss: 2.35863e-02
I0209 16:25:35.716469 22542570456896 run_lib.py:133] step: 280950, training_loss: 2.33123e-02
I0209 16:25:53.158237 22542570456896 run_lib.py:133] step: 281000, training_loss: 3.58574e-02
I0209 16:25:53.319529 22542570456896 run_lib.py:146] step: 281000, eval_loss: 2.47852e-02
I0209 16:26:10.813427 22542570456896 run_lib.py:133] step: 281050, training_loss: 2.75360e-02
I0209 16:26:28.400922 22542570456896 run_lib.py:133] step: 281100, training_loss: 2.35886e-02
I0209 16:26:28.553368 22542570456896 run_lib.py:146] step: 281100, eval_loss: 3.25771e-02
I0209 16:26:45.954166 22542570456896 run_lib.py:133] step: 281150, training_loss: 3.12309e-02
I0209 16:27:03.363069 22542570456896 run_lib.py:133] step: 281200, training_loss: 2.79254e-02
I0209 16:27:03.516992 22542570456896 run_lib.py:146] step: 281200, eval_loss: 2.50213e-02
I0209 16:27:21.096005 22542570456896 run_lib.py:133] step: 281250, training_loss: 2.29208e-02
I0209 16:27:38.551160 22542570456896 run_lib.py:133] step: 281300, training_loss: 2.98407e-02
I0209 16:27:38.730346 22542570456896 run_lib.py:146] step: 281300, eval_loss: 2.55399e-02
I0209 16:27:56.342555 22542570456896 run_lib.py:133] step: 281350, training_loss: 3.51862e-02
I0209 16:28:13.811021 22542570456896 run_lib.py:133] step: 281400, training_loss: 2.68714e-02
I0209 16:28:13.974025 22542570456896 run_lib.py:146] step: 281400, eval_loss: 2.90113e-02
I0209 16:28:31.436081 22542570456896 run_lib.py:133] step: 281450, training_loss: 2.96848e-02
I0209 16:28:48.996810 22542570456896 run_lib.py:133] step: 281500, training_loss: 2.30207e-02
I0209 16:28:49.151319 22542570456896 run_lib.py:146] step: 281500, eval_loss: 2.85457e-02
I0209 16:29:06.571300 22542570456896 run_lib.py:133] step: 281550, training_loss: 2.38586e-02
I0209 16:29:24.060016 22542570456896 run_lib.py:133] step: 281600, training_loss: 2.06768e-02
I0209 16:29:24.215576 22542570456896 run_lib.py:146] step: 281600, eval_loss: 2.97376e-02
I0209 16:29:41.649811 22542570456896 run_lib.py:133] step: 281650, training_loss: 2.75988e-02
I0209 16:29:59.297894 22542570456896 run_lib.py:133] step: 281700, training_loss: 2.89507e-02
I0209 16:29:59.456415 22542570456896 run_lib.py:146] step: 281700, eval_loss: 2.84697e-02
I0209 16:30:16.857572 22542570456896 run_lib.py:133] step: 281750, training_loss: 2.88421e-02
I0209 16:30:34.336346 22542570456896 run_lib.py:133] step: 281800, training_loss: 2.85220e-02
I0209 16:30:34.492352 22542570456896 run_lib.py:146] step: 281800, eval_loss: 2.82848e-02
I0209 16:30:51.936309 22542570456896 run_lib.py:133] step: 281850, training_loss: 3.57040e-02
I0209 16:31:09.388530 22542570456896 run_lib.py:133] step: 281900, training_loss: 2.38217e-02
I0209 16:31:09.549223 22542570456896 run_lib.py:146] step: 281900, eval_loss: 2.38108e-02
I0209 16:31:27.157048 22542570456896 run_lib.py:133] step: 281950, training_loss: 3.55693e-02
I0209 16:31:44.679970 22542570456896 run_lib.py:133] step: 282000, training_loss: 3.13068e-02
I0209 16:31:44.834241 22542570456896 run_lib.py:146] step: 282000, eval_loss: 2.75314e-02
I0209 16:32:02.237585 22542570456896 run_lib.py:133] step: 282050, training_loss: 3.43179e-02
I0209 16:32:19.632726 22542570456896 run_lib.py:133] step: 282100, training_loss: 3.15912e-02
I0209 16:32:19.786844 22542570456896 run_lib.py:146] step: 282100, eval_loss: 2.83067e-02
I0209 16:32:37.340970 22542570456896 run_lib.py:133] step: 282150, training_loss: 2.48735e-02
I0209 16:32:54.820659 22542570456896 run_lib.py:133] step: 282200, training_loss: 3.06932e-02
I0209 16:32:54.995259 22542570456896 run_lib.py:146] step: 282200, eval_loss: 3.09283e-02
I0209 16:33:12.593768 22542570456896 run_lib.py:133] step: 282250, training_loss: 2.36939e-02
I0209 16:33:29.920433 22542570456896 run_lib.py:133] step: 282300, training_loss: 2.67092e-02
I0209 16:33:30.074127 22542570456896 run_lib.py:146] step: 282300, eval_loss: 3.05433e-02
I0209 16:33:47.507573 22542570456896 run_lib.py:133] step: 282350, training_loss: 2.88837e-02
I0209 16:34:04.802654 22542570456896 run_lib.py:133] step: 282400, training_loss: 2.26087e-02
I0209 16:34:04.970499 22542570456896 run_lib.py:146] step: 282400, eval_loss: 3.18335e-02
I0209 16:34:22.305114 22542570456896 run_lib.py:133] step: 282450, training_loss: 2.77897e-02
I0209 16:34:39.955120 22542570456896 run_lib.py:133] step: 282500, training_loss: 2.77138e-02
I0209 16:34:40.115682 22542570456896 run_lib.py:146] step: 282500, eval_loss: 2.86820e-02
I0209 16:34:57.537436 22542570456896 run_lib.py:133] step: 282550, training_loss: 3.03245e-02
I0209 16:35:15.136881 22542570456896 run_lib.py:133] step: 282600, training_loss: 2.61732e-02
I0209 16:35:15.293322 22542570456896 run_lib.py:146] step: 282600, eval_loss: 2.78222e-02
I0209 16:35:32.695447 22542570456896 run_lib.py:133] step: 282650, training_loss: 2.03432e-02
I0209 16:35:50.125230 22542570456896 run_lib.py:133] step: 282700, training_loss: 2.41950e-02
I0209 16:35:50.298278 22542570456896 run_lib.py:146] step: 282700, eval_loss: 2.82243e-02
I0209 16:36:07.892495 22542570456896 run_lib.py:133] step: 282750, training_loss: 2.54671e-02
I0209 16:36:25.343286 22542570456896 run_lib.py:133] step: 282800, training_loss: 2.75747e-02
I0209 16:36:25.501605 22542570456896 run_lib.py:146] step: 282800, eval_loss: 2.90967e-02
I0209 16:36:42.890778 22542570456896 run_lib.py:133] step: 282850, training_loss: 2.36653e-02
I0209 16:37:00.485728 22542570456896 run_lib.py:133] step: 282900, training_loss: 2.50224e-02
I0209 16:37:00.641470 22542570456896 run_lib.py:146] step: 282900, eval_loss: 2.55231e-02
I0209 16:37:18.071561 22542570456896 run_lib.py:133] step: 282950, training_loss: 3.46865e-02
I0209 16:37:35.571740 22542570456896 run_lib.py:133] step: 283000, training_loss: 2.81253e-02
I0209 16:37:35.872560 22542570456896 run_lib.py:146] step: 283000, eval_loss: 3.27915e-02
I0209 16:37:53.306372 22542570456896 run_lib.py:133] step: 283050, training_loss: 2.43437e-02
I0209 16:38:10.727560 22542570456896 run_lib.py:133] step: 283100, training_loss: 2.81159e-02
I0209 16:38:10.883193 22542570456896 run_lib.py:146] step: 283100, eval_loss: 2.80549e-02
I0209 16:38:28.365571 22542570456896 run_lib.py:133] step: 283150, training_loss: 2.67245e-02
I0209 16:38:45.807989 22542570456896 run_lib.py:133] step: 283200, training_loss: 3.41926e-02
I0209 16:38:45.974442 22542570456896 run_lib.py:146] step: 283200, eval_loss: 2.80458e-02
I0209 16:39:03.615725 22542570456896 run_lib.py:133] step: 283250, training_loss: 3.30826e-02
I0209 16:39:21.099170 22542570456896 run_lib.py:133] step: 283300, training_loss: 2.44172e-02
I0209 16:39:21.271723 22542570456896 run_lib.py:146] step: 283300, eval_loss: 2.95891e-02
I0209 16:39:38.691812 22542570456896 run_lib.py:133] step: 283350, training_loss: 3.14620e-02
I0209 16:39:56.162240 22542570456896 run_lib.py:133] step: 283400, training_loss: 2.54767e-02
I0209 16:39:56.317059 22542570456896 run_lib.py:146] step: 283400, eval_loss: 3.16449e-02
I0209 16:40:13.949110 22542570456896 run_lib.py:133] step: 283450, training_loss: 3.32751e-02
I0209 16:40:31.388289 22542570456896 run_lib.py:133] step: 283500, training_loss: 3.41647e-02
I0209 16:40:31.541298 22542570456896 run_lib.py:146] step: 283500, eval_loss: 3.13026e-02
I0209 16:40:48.956497 22542570456896 run_lib.py:133] step: 283550, training_loss: 2.20454e-02
I0209 16:41:06.420106 22542570456896 run_lib.py:133] step: 283600, training_loss: 2.97225e-02
I0209 16:41:06.596405 22542570456896 run_lib.py:146] step: 283600, eval_loss: 2.73053e-02
I0209 16:41:24.181946 22542570456896 run_lib.py:133] step: 283650, training_loss: 3.00652e-02
I0209 16:41:41.600389 22542570456896 run_lib.py:133] step: 283700, training_loss: 3.34479e-02
I0209 16:41:41.755523 22542570456896 run_lib.py:146] step: 283700, eval_loss: 2.91228e-02
I0209 16:41:59.320639 22542570456896 run_lib.py:133] step: 283750, training_loss: 2.67006e-02
I0209 16:42:16.731853 22542570456896 run_lib.py:133] step: 283800, training_loss: 3.00943e-02
I0209 16:42:16.891644 22542570456896 run_lib.py:146] step: 283800, eval_loss: 2.37671e-02
I0209 16:42:34.441439 22542570456896 run_lib.py:133] step: 283850, training_loss: 2.63067e-02
I0209 16:42:51.873311 22542570456896 run_lib.py:133] step: 283900, training_loss: 2.47167e-02
I0209 16:42:52.033332 22542570456896 run_lib.py:146] step: 283900, eval_loss: 3.69505e-02
I0209 16:43:09.486568 22542570456896 run_lib.py:133] step: 283950, training_loss: 2.58380e-02
I0209 16:43:27.044082 22542570456896 run_lib.py:133] step: 284000, training_loss: 2.48114e-02
I0209 16:43:27.198433 22542570456896 run_lib.py:146] step: 284000, eval_loss: 4.00668e-02
I0209 16:43:44.605647 22542570456896 run_lib.py:133] step: 284050, training_loss: 2.84370e-02
I0209 16:44:02.188881 22542570456896 run_lib.py:133] step: 284100, training_loss: 2.65361e-02
I0209 16:44:02.368882 22542570456896 run_lib.py:146] step: 284100, eval_loss: 3.16889e-02
I0209 16:44:19.842282 22542570456896 run_lib.py:133] step: 284150, training_loss: 2.90324e-02
I0209 16:44:37.244084 22542570456896 run_lib.py:133] step: 284200, training_loss: 2.57972e-02
I0209 16:44:37.401657 22542570456896 run_lib.py:146] step: 284200, eval_loss: 2.52516e-02
I0209 16:44:55.017747 22542570456896 run_lib.py:133] step: 284250, training_loss: 3.31105e-02
I0209 16:45:12.421027 22542570456896 run_lib.py:133] step: 284300, training_loss: 3.13814e-02
I0209 16:45:12.576257 22542570456896 run_lib.py:146] step: 284300, eval_loss: 2.86578e-02
I0209 16:45:30.039010 22542570456896 run_lib.py:133] step: 284350, training_loss: 3.17211e-02
I0209 16:45:47.520858 22542570456896 run_lib.py:133] step: 284400, training_loss: 2.36567e-02
I0209 16:45:47.681107 22542570456896 run_lib.py:146] step: 284400, eval_loss: 2.44937e-02
I0209 16:46:05.308476 22542570456896 run_lib.py:133] step: 284450, training_loss: 2.73007e-02
I0209 16:46:22.744144 22542570456896 run_lib.py:133] step: 284500, training_loss: 4.24389e-02
I0209 16:46:22.899195 22542570456896 run_lib.py:146] step: 284500, eval_loss: 3.15136e-02
I0209 16:46:40.385095 22542570456896 run_lib.py:133] step: 284550, training_loss: 2.75886e-02
I0209 16:46:57.774092 22542570456896 run_lib.py:133] step: 284600, training_loss: 3.21685e-02
I0209 16:46:57.933519 22542570456896 run_lib.py:146] step: 284600, eval_loss: 2.92146e-02
I0209 16:47:15.386820 22542570456896 run_lib.py:133] step: 284650, training_loss: 2.77322e-02
I0209 16:47:32.851388 22542570456896 run_lib.py:133] step: 284700, training_loss: 2.82235e-02
I0209 16:47:33.008668 22542570456896 run_lib.py:146] step: 284700, eval_loss: 2.32901e-02
I0209 16:47:50.640138 22542570456896 run_lib.py:133] step: 284750, training_loss: 3.28337e-02
I0209 16:48:08.097533 22542570456896 run_lib.py:133] step: 284800, training_loss: 2.77450e-02
I0209 16:48:08.257366 22542570456896 run_lib.py:146] step: 284800, eval_loss: 3.38434e-02
I0209 16:48:25.690111 22542570456896 run_lib.py:133] step: 284850, training_loss: 3.14476e-02
I0209 16:48:43.094940 22542570456896 run_lib.py:133] step: 284900, training_loss: 2.69876e-02
I0209 16:48:43.246243 22542570456896 run_lib.py:146] step: 284900, eval_loss: 2.87645e-02
I0209 16:49:00.821325 22542570456896 run_lib.py:133] step: 284950, training_loss: 2.56270e-02
I0209 16:49:18.230966 22542570456896 run_lib.py:133] step: 285000, training_loss: 3.32953e-02
I0209 16:49:18.398238 22542570456896 run_lib.py:146] step: 285000, eval_loss: 2.33108e-02
I0209 16:49:36.024207 22542570456896 run_lib.py:133] step: 285050, training_loss: 2.56447e-02
I0209 16:49:53.516058 22542570456896 run_lib.py:133] step: 285100, training_loss: 2.69659e-02
I0209 16:49:53.674546 22542570456896 run_lib.py:146] step: 285100, eval_loss: 2.75778e-02
I0209 16:50:11.261530 22542570456896 run_lib.py:133] step: 285150, training_loss: 2.51276e-02
I0209 16:50:28.653763 22542570456896 run_lib.py:133] step: 285200, training_loss: 3.01401e-02
I0209 16:50:28.808161 22542570456896 run_lib.py:146] step: 285200, eval_loss: 3.31344e-02
I0209 16:50:46.381120 22542570456896 run_lib.py:133] step: 285250, training_loss: 3.34182e-02
I0209 16:51:03.819777 22542570456896 run_lib.py:133] step: 285300, training_loss: 2.85025e-02
I0209 16:51:03.974535 22542570456896 run_lib.py:146] step: 285300, eval_loss: 3.05256e-02
I0209 16:51:21.444689 22542570456896 run_lib.py:133] step: 285350, training_loss: 2.31493e-02
I0209 16:51:39.028085 22542570456896 run_lib.py:133] step: 285400, training_loss: 2.95268e-02
I0209 16:51:39.188453 22542570456896 run_lib.py:146] step: 285400, eval_loss: 3.41310e-02
I0209 16:51:56.596713 22542570456896 run_lib.py:133] step: 285450, training_loss: 2.78531e-02
I0209 16:52:13.988146 22542570456896 run_lib.py:133] step: 285500, training_loss: 2.40984e-02
I0209 16:52:14.147614 22542570456896 run_lib.py:146] step: 285500, eval_loss: 3.22024e-02
I0209 16:52:31.756610 22542570456896 run_lib.py:133] step: 285550, training_loss: 2.72733e-02
I0209 16:52:49.421376 22542570456896 run_lib.py:133] step: 285600, training_loss: 2.06040e-02
I0209 16:52:49.577592 22542570456896 run_lib.py:146] step: 285600, eval_loss: 2.73229e-02
I0209 16:53:06.970898 22542570456896 run_lib.py:133] step: 285650, training_loss: 3.00693e-02
I0209 16:53:24.421841 22542570456896 run_lib.py:133] step: 285700, training_loss: 2.44667e-02
I0209 16:53:24.585182 22542570456896 run_lib.py:146] step: 285700, eval_loss: 2.82440e-02
I0209 16:53:41.999353 22542570456896 run_lib.py:133] step: 285750, training_loss: 2.84053e-02
I0209 16:53:59.546087 22542570456896 run_lib.py:133] step: 285800, training_loss: 2.91017e-02
I0209 16:53:59.699094 22542570456896 run_lib.py:146] step: 285800, eval_loss: 2.91018e-02
I0209 16:54:17.166238 22542570456896 run_lib.py:133] step: 285850, training_loss: 2.70685e-02
I0209 16:54:34.577584 22542570456896 run_lib.py:133] step: 285900, training_loss: 2.50078e-02
I0209 16:54:34.733517 22542570456896 run_lib.py:146] step: 285900, eval_loss: 2.81618e-02
I0209 16:54:52.127165 22542570456896 run_lib.py:133] step: 285950, training_loss: 3.17797e-02
I0209 16:55:09.747849 22542570456896 run_lib.py:133] step: 286000, training_loss: 3.04949e-02
I0209 16:55:09.912433 22542570456896 run_lib.py:146] step: 286000, eval_loss: 2.24429e-02
I0209 16:55:27.318069 22542570456896 run_lib.py:133] step: 286050, training_loss: 2.83935e-02
I0209 16:55:44.860324 22542570456896 run_lib.py:133] step: 286100, training_loss: 3.16410e-02
I0209 16:55:45.024568 22542570456896 run_lib.py:146] step: 286100, eval_loss: 2.89835e-02
I0209 16:56:02.462461 22542570456896 run_lib.py:133] step: 286150, training_loss: 3.15751e-02
I0209 16:56:19.875597 22542570456896 run_lib.py:133] step: 286200, training_loss: 2.53522e-02
I0209 16:56:20.033965 22542570456896 run_lib.py:146] step: 286200, eval_loss: 2.77023e-02
I0209 16:56:37.619415 22542570456896 run_lib.py:133] step: 286250, training_loss: 2.82201e-02
I0209 16:56:55.114506 22542570456896 run_lib.py:133] step: 286300, training_loss: 3.11554e-02
I0209 16:56:55.266401 22542570456896 run_lib.py:146] step: 286300, eval_loss: 2.68974e-02
I0209 16:57:12.652506 22542570456896 run_lib.py:133] step: 286350, training_loss: 2.87076e-02
I0209 16:57:30.102130 22542570456896 run_lib.py:133] step: 286400, training_loss: 1.92153e-02
I0209 16:57:30.271616 22542570456896 run_lib.py:146] step: 286400, eval_loss: 2.81237e-02
I0209 16:57:47.869128 22542570456896 run_lib.py:133] step: 286450, training_loss: 2.98665e-02
I0209 16:58:05.305856 22542570456896 run_lib.py:133] step: 286500, training_loss: 2.26201e-02
I0209 16:58:05.472377 22542570456896 run_lib.py:146] step: 286500, eval_loss: 2.33906e-02
I0209 16:58:22.995510 22542570456896 run_lib.py:133] step: 286550, training_loss: 3.11478e-02
I0209 16:58:40.359718 22542570456896 run_lib.py:133] step: 286600, training_loss: 2.38888e-02
I0209 16:58:40.515338 22542570456896 run_lib.py:146] step: 286600, eval_loss: 2.77814e-02
I0209 16:58:58.039845 22542570456896 run_lib.py:133] step: 286650, training_loss: 2.13555e-02
I0209 16:59:15.507406 22542570456896 run_lib.py:133] step: 286700, training_loss: 2.65201e-02
I0209 16:59:15.665661 22542570456896 run_lib.py:146] step: 286700, eval_loss: 2.72428e-02
I0209 16:59:33.089177 22542570456896 run_lib.py:133] step: 286750, training_loss: 2.47379e-02
I0209 16:59:50.678154 22542570456896 run_lib.py:133] step: 286800, training_loss: 2.99803e-02
I0209 16:59:50.836418 22542570456896 run_lib.py:146] step: 286800, eval_loss: 2.60773e-02
I0209 17:00:08.226735 22542570456896 run_lib.py:133] step: 286850, training_loss: 2.39192e-02
I0209 17:00:25.765078 22542570456896 run_lib.py:133] step: 286900, training_loss: 2.89743e-02
I0209 17:00:25.920930 22542570456896 run_lib.py:146] step: 286900, eval_loss: 3.37774e-02
I0209 17:00:43.368823 22542570456896 run_lib.py:133] step: 286950, training_loss: 2.50127e-02
I0209 17:01:00.813057 22542570456896 run_lib.py:133] step: 287000, training_loss: 3.19419e-02
I0209 17:01:00.968274 22542570456896 run_lib.py:146] step: 287000, eval_loss: 3.21347e-02
I0209 17:01:18.563904 22542570456896 run_lib.py:133] step: 287050, training_loss: 3.00838e-02
I0209 17:01:36.001432 22542570456896 run_lib.py:133] step: 287100, training_loss: 3.38668e-02
I0209 17:01:36.157567 22542570456896 run_lib.py:146] step: 287100, eval_loss: 2.48415e-02
I0209 17:01:53.593493 22542570456896 run_lib.py:133] step: 287150, training_loss: 2.50836e-02
I0209 17:02:11.184843 22542570456896 run_lib.py:133] step: 287200, training_loss: 3.46831e-02
I0209 17:02:11.346313 22542570456896 run_lib.py:146] step: 287200, eval_loss: 2.66843e-02
I0209 17:02:28.797668 22542570456896 run_lib.py:133] step: 287250, training_loss: 3.31486e-02
I0209 17:02:46.268332 22542570456896 run_lib.py:133] step: 287300, training_loss: 2.72823e-02
I0209 17:02:46.422510 22542570456896 run_lib.py:146] step: 287300, eval_loss: 2.38590e-02
I0209 17:03:03.955252 22542570456896 run_lib.py:133] step: 287350, training_loss: 2.88173e-02
I0209 17:03:21.392512 22542570456896 run_lib.py:133] step: 287400, training_loss: 2.67778e-02
I0209 17:03:21.558558 22542570456896 run_lib.py:146] step: 287400, eval_loss: 2.37748e-02
I0209 17:03:38.984806 22542570456896 run_lib.py:133] step: 287450, training_loss: 2.49257e-02
I0209 17:03:56.377439 22542570456896 run_lib.py:133] step: 287500, training_loss: 3.29911e-02
I0209 17:03:56.555350 22542570456896 run_lib.py:146] step: 287500, eval_loss: 3.04757e-02
I0209 17:04:14.173293 22542570456896 run_lib.py:133] step: 287550, training_loss: 2.74204e-02
I0209 17:04:31.746138 22542570456896 run_lib.py:133] step: 287600, training_loss: 2.85613e-02
I0209 17:04:31.899064 22542570456896 run_lib.py:146] step: 287600, eval_loss: 2.80609e-02
I0209 17:04:49.305977 22542570456896 run_lib.py:133] step: 287650, training_loss: 2.15161e-02
I0209 17:05:06.723534 22542570456896 run_lib.py:133] step: 287700, training_loss: 1.49578e-02
I0209 17:05:06.871597 22542570456896 run_lib.py:146] step: 287700, eval_loss: 3.04174e-02
I0209 17:05:24.391914 22542570456896 run_lib.py:133] step: 287750, training_loss: 2.67761e-02
I0209 17:05:41.809762 22542570456896 run_lib.py:133] step: 287800, training_loss: 3.03101e-02
I0209 17:05:41.977517 22542570456896 run_lib.py:146] step: 287800, eval_loss: 2.50482e-02
I0209 17:05:59.598480 22542570456896 run_lib.py:133] step: 287850, training_loss: 2.56387e-02
I0209 17:06:17.002349 22542570456896 run_lib.py:133] step: 287900, training_loss: 2.79597e-02
I0209 17:06:17.160417 22542570456896 run_lib.py:146] step: 287900, eval_loss: 2.82935e-02
I0209 17:06:34.771536 22542570456896 run_lib.py:133] step: 287950, training_loss: 2.67124e-02
I0209 17:06:52.162259 22542570456896 run_lib.py:133] step: 288000, training_loss: 2.82501e-02
I0209 17:06:52.317943 22542570456896 run_lib.py:146] step: 288000, eval_loss: 3.00090e-02
I0209 17:07:09.864135 22542570456896 run_lib.py:133] step: 288050, training_loss: 2.81198e-02
I0209 17:07:27.327816 22542570456896 run_lib.py:133] step: 288100, training_loss: 3.16072e-02
I0209 17:07:27.484717 22542570456896 run_lib.py:146] step: 288100, eval_loss: 3.02651e-02
I0209 17:07:44.926412 22542570456896 run_lib.py:133] step: 288150, training_loss: 2.81712e-02
I0209 17:08:02.505374 22542570456896 run_lib.py:133] step: 288200, training_loss: 3.35372e-02
I0209 17:08:02.657389 22542570456896 run_lib.py:146] step: 288200, eval_loss: 3.07243e-02
I0209 17:08:20.067888 22542570456896 run_lib.py:133] step: 288250, training_loss: 2.91177e-02
I0209 17:08:37.538763 22542570456896 run_lib.py:133] step: 288300, training_loss: 2.75355e-02
I0209 17:08:37.704539 22542570456896 run_lib.py:146] step: 288300, eval_loss: 2.74389e-02
I0209 17:08:55.272177 22542570456896 run_lib.py:133] step: 288350, training_loss: 2.55740e-02
I0209 17:09:12.755008 22542570456896 run_lib.py:133] step: 288400, training_loss: 3.00314e-02
I0209 17:09:12.914405 22542570456896 run_lib.py:146] step: 288400, eval_loss: 2.95791e-02
I0209 17:09:30.536148 22542570456896 run_lib.py:133] step: 288450, training_loss: 2.69328e-02
I0209 17:09:47.943777 22542570456896 run_lib.py:133] step: 288500, training_loss: 2.92451e-02
I0209 17:09:48.098269 22542570456896 run_lib.py:146] step: 288500, eval_loss: 2.22086e-02
I0209 17:10:05.509964 22542570456896 run_lib.py:133] step: 288550, training_loss: 2.41280e-02
I0209 17:10:23.108283 22542570456896 run_lib.py:133] step: 288600, training_loss: 3.05649e-02
I0209 17:10:23.270236 22542570456896 run_lib.py:146] step: 288600, eval_loss: 2.47355e-02
I0209 17:10:40.775773 22542570456896 run_lib.py:133] step: 288650, training_loss: 2.57892e-02
I0209 17:10:58.187682 22542570456896 run_lib.py:133] step: 288700, training_loss: 2.41751e-02
I0209 17:10:58.342719 22542570456896 run_lib.py:146] step: 288700, eval_loss: 2.28155e-02
I0209 17:11:15.758465 22542570456896 run_lib.py:133] step: 288750, training_loss: 3.10078e-02
I0209 17:11:33.360654 22542570456896 run_lib.py:133] step: 288800, training_loss: 3.03893e-02
I0209 17:11:33.519572 22542570456896 run_lib.py:146] step: 288800, eval_loss: 2.91287e-02
I0209 17:11:50.896957 22542570456896 run_lib.py:133] step: 288850, training_loss: 2.48941e-02
I0209 17:12:08.391045 22542570456896 run_lib.py:133] step: 288900, training_loss: 3.05858e-02
I0209 17:12:08.565352 22542570456896 run_lib.py:146] step: 288900, eval_loss: 2.89293e-02
I0209 17:12:26.011573 22542570456896 run_lib.py:133] step: 288950, training_loss: 2.74626e-02
I0209 17:12:43.436218 22542570456896 run_lib.py:133] step: 289000, training_loss: 2.83307e-02
I0209 17:12:43.591249 22542570456896 run_lib.py:146] step: 289000, eval_loss: 2.88572e-02
I0209 17:13:01.204906 22542570456896 run_lib.py:133] step: 289050, training_loss: 3.39894e-02
I0209 17:13:18.685621 22542570456896 run_lib.py:133] step: 289100, training_loss: 2.80693e-02
I0209 17:13:18.843026 22542570456896 run_lib.py:146] step: 289100, eval_loss: 2.96002e-02
I0209 17:13:36.236628 22542570456896 run_lib.py:133] step: 289150, training_loss: 2.53258e-02
I0209 17:13:53.725202 22542570456896 run_lib.py:133] step: 289200, training_loss: 3.40180e-02
I0209 17:13:53.887642 22542570456896 run_lib.py:146] step: 289200, eval_loss: 2.82273e-02
I0209 17:14:11.556317 22542570456896 run_lib.py:133] step: 289250, training_loss: 2.84525e-02
I0209 17:14:28.959278 22542570456896 run_lib.py:133] step: 289300, training_loss: 3.04134e-02
I0209 17:14:29.118411 22542570456896 run_lib.py:146] step: 289300, eval_loss: 2.65769e-02
I0209 17:14:46.688132 22542570456896 run_lib.py:133] step: 289350, training_loss: 2.74096e-02
I0209 17:15:04.113799 22542570456896 run_lib.py:133] step: 289400, training_loss: 2.60952e-02
I0209 17:15:04.268446 22542570456896 run_lib.py:146] step: 289400, eval_loss: 3.49344e-02
I0209 17:15:21.852874 22542570456896 run_lib.py:133] step: 289450, training_loss: 2.49086e-02
I0209 17:15:39.306051 22542570456896 run_lib.py:133] step: 289500, training_loss: 2.74333e-02
I0209 17:15:39.463077 22542570456896 run_lib.py:146] step: 289500, eval_loss: 2.75411e-02
I0209 17:15:56.935660 22542570456896 run_lib.py:133] step: 289550, training_loss: 3.31326e-02
I0209 17:16:14.587417 22542570456896 run_lib.py:133] step: 289600, training_loss: 2.77832e-02
I0209 17:16:14.747023 22542570456896 run_lib.py:146] step: 289600, eval_loss: 2.95262e-02
I0209 17:16:32.170588 22542570456896 run_lib.py:133] step: 289650, training_loss: 2.68899e-02
I0209 17:16:49.759534 22542570456896 run_lib.py:133] step: 289700, training_loss: 2.76110e-02
I0209 17:16:49.915426 22542570456896 run_lib.py:146] step: 289700, eval_loss: 2.97600e-02
I0209 17:17:07.385374 22542570456896 run_lib.py:133] step: 289750, training_loss: 2.85536e-02
I0209 17:17:24.802008 22542570456896 run_lib.py:133] step: 289800, training_loss: 2.88102e-02
I0209 17:17:24.975338 22542570456896 run_lib.py:146] step: 289800, eval_loss: 2.67821e-02
I0209 17:17:42.630651 22542570456896 run_lib.py:133] step: 289850, training_loss: 3.11759e-02
I0209 17:18:00.055089 22542570456896 run_lib.py:133] step: 289900, training_loss: 1.93967e-02
I0209 17:18:00.211634 22542570456896 run_lib.py:146] step: 289900, eval_loss: 3.15368e-02
I0209 17:18:17.655909 22542570456896 run_lib.py:133] step: 289950, training_loss: 2.05136e-02
I0209 17:18:35.227303 22542570456896 run_lib.py:133] step: 290000, training_loss: 3.18349e-02
I0209 17:18:35.932992 22542570456896 run_lib.py:146] step: 290000, eval_loss: 3.23169e-02
I0209 17:18:55.927095 22542570456896 run_lib.py:133] step: 290050, training_loss: 2.48824e-02
I0209 17:19:13.350324 22542570456896 run_lib.py:133] step: 290100, training_loss: 2.72837e-02
I0209 17:19:13.507704 22542570456896 run_lib.py:146] step: 290100, eval_loss: 3.05405e-02
I0209 17:19:31.127409 22542570456896 run_lib.py:133] step: 290150, training_loss: 3.00614e-02
I0209 17:19:48.550310 22542570456896 run_lib.py:133] step: 290200, training_loss: 3.10014e-02
I0209 17:19:48.700702 22542570456896 run_lib.py:146] step: 290200, eval_loss: 3.02082e-02
I0209 17:20:06.126478 22542570456896 run_lib.py:133] step: 290250, training_loss: 3.24110e-02
I0209 17:20:23.528708 22542570456896 run_lib.py:133] step: 290300, training_loss: 3.48981e-02
I0209 17:20:23.688319 22542570456896 run_lib.py:146] step: 290300, eval_loss: 2.11288e-02
I0209 17:20:41.261578 22542570456896 run_lib.py:133] step: 290350, training_loss: 2.49636e-02
I0209 17:20:58.756241 22542570456896 run_lib.py:133] step: 290400, training_loss: 3.34865e-02
I0209 17:20:58.912310 22542570456896 run_lib.py:146] step: 290400, eval_loss: 3.14118e-02
I0209 17:21:16.433220 22542570456896 run_lib.py:133] step: 290450, training_loss: 3.04925e-02
I0209 17:21:33.815746 22542570456896 run_lib.py:133] step: 290500, training_loss: 3.13692e-02
I0209 17:21:33.971405 22542570456896 run_lib.py:146] step: 290500, eval_loss: 2.81869e-02
I0209 17:21:51.417869 22542570456896 run_lib.py:133] step: 290550, training_loss: 2.52603e-02
I0209 17:22:08.886967 22542570456896 run_lib.py:133] step: 290600, training_loss: 2.36224e-02
I0209 17:22:09.040713 22542570456896 run_lib.py:146] step: 290600, eval_loss: 2.94410e-02
I0209 17:22:26.597775 22542570456896 run_lib.py:133] step: 290650, training_loss: 3.10444e-02
I0209 17:22:44.125327 22542570456896 run_lib.py:133] step: 290700, training_loss: 3.20192e-02
I0209 17:22:44.281609 22542570456896 run_lib.py:146] step: 290700, eval_loss: 2.99613e-02
I0209 17:23:01.697980 22542570456896 run_lib.py:133] step: 290750, training_loss: 2.80942e-02
I0209 17:23:19.174090 22542570456896 run_lib.py:133] step: 290800, training_loss: 3.04645e-02
I0209 17:23:19.332695 22542570456896 run_lib.py:146] step: 290800, eval_loss: 2.45982e-02
I0209 17:23:36.902408 22542570456896 run_lib.py:133] step: 290850, training_loss: 2.71415e-02
I0209 17:23:54.312530 22542570456896 run_lib.py:133] step: 290900, training_loss: 2.60918e-02
I0209 17:23:54.464365 22542570456896 run_lib.py:146] step: 290900, eval_loss: 2.82900e-02
I0209 17:24:12.022288 22542570456896 run_lib.py:133] step: 290950, training_loss: 3.61406e-02
I0209 17:24:29.509955 22542570456896 run_lib.py:133] step: 291000, training_loss: 2.19377e-02
I0209 17:24:29.666579 22542570456896 run_lib.py:146] step: 291000, eval_loss: 3.14373e-02
I0209 17:24:47.303416 22542570456896 run_lib.py:133] step: 291050, training_loss: 2.77232e-02
I0209 17:25:04.695181 22542570456896 run_lib.py:133] step: 291100, training_loss: 2.91922e-02
I0209 17:25:04.847208 22542570456896 run_lib.py:146] step: 291100, eval_loss: 2.92314e-02
I0209 17:25:22.431946 22542570456896 run_lib.py:133] step: 291150, training_loss: 2.98010e-02
I0209 17:25:39.852925 22542570456896 run_lib.py:133] step: 291200, training_loss: 2.70915e-02
I0209 17:25:40.016663 22542570456896 run_lib.py:146] step: 291200, eval_loss: 2.77759e-02
I0209 17:25:57.519047 22542570456896 run_lib.py:133] step: 291250, training_loss: 2.92466e-02
I0209 17:26:15.120418 22542570456896 run_lib.py:133] step: 291300, training_loss: 3.01847e-02
I0209 17:26:15.289217 22542570456896 run_lib.py:146] step: 291300, eval_loss: 2.36393e-02
I0209 17:26:32.712500 22542570456896 run_lib.py:133] step: 291350, training_loss: 2.91289e-02
I0209 17:26:50.143093 22542570456896 run_lib.py:133] step: 291400, training_loss: 3.10108e-02
I0209 17:26:50.298376 22542570456896 run_lib.py:146] step: 291400, eval_loss: 2.76680e-02
I0209 17:27:07.881473 22542570456896 run_lib.py:133] step: 291450, training_loss: 2.12539e-02
I0209 17:27:25.457466 22542570456896 run_lib.py:133] step: 291500, training_loss: 2.52946e-02
I0209 17:27:25.608633 22542570456896 run_lib.py:146] step: 291500, eval_loss: 2.69743e-02
I0209 17:27:43.009636 22542570456896 run_lib.py:133] step: 291550, training_loss: 2.64604e-02
I0209 17:28:00.473910 22542570456896 run_lib.py:133] step: 291600, training_loss: 3.13914e-02
I0209 17:28:00.628526 22542570456896 run_lib.py:146] step: 291600, eval_loss: 2.57674e-02
I0209 17:28:18.062349 22542570456896 run_lib.py:133] step: 291650, training_loss: 2.17200e-02
I0209 17:28:35.665524 22542570456896 run_lib.py:133] step: 291700, training_loss: 2.68181e-02
I0209 17:28:35.829363 22542570456896 run_lib.py:146] step: 291700, eval_loss: 2.06944e-02
I0209 17:28:53.238294 22542570456896 run_lib.py:133] step: 291750, training_loss: 2.73716e-02
I0209 17:29:10.668071 22542570456896 run_lib.py:133] step: 291800, training_loss: 3.36649e-02
I0209 17:29:10.844334 22542570456896 run_lib.py:146] step: 291800, eval_loss: 2.89518e-02
I0209 17:29:28.310188 22542570456896 run_lib.py:133] step: 291850, training_loss: 2.76530e-02
I0209 17:29:45.934103 22542570456896 run_lib.py:133] step: 291900, training_loss: 3.20091e-02
I0209 17:29:46.090661 22542570456896 run_lib.py:146] step: 291900, eval_loss: 2.81961e-02
I0209 17:30:03.523228 22542570456896 run_lib.py:133] step: 291950, training_loss: 2.91774e-02
I0209 17:30:20.982011 22542570456896 run_lib.py:133] step: 292000, training_loss: 3.26702e-02
I0209 17:30:21.136127 22542570456896 run_lib.py:146] step: 292000, eval_loss: 2.34789e-02
I0209 17:30:38.549546 22542570456896 run_lib.py:133] step: 292050, training_loss: 2.82091e-02
I0209 17:30:55.986166 22542570456896 run_lib.py:133] step: 292100, training_loss: 2.69466e-02
I0209 17:30:56.140504 22542570456896 run_lib.py:146] step: 292100, eval_loss: 2.74925e-02
I0209 17:31:13.818977 22542570456896 run_lib.py:133] step: 292150, training_loss: 3.06955e-02
I0209 17:31:31.288450 22542570456896 run_lib.py:133] step: 292200, training_loss: 2.90584e-02
I0209 17:31:31.446266 22542570456896 run_lib.py:146] step: 292200, eval_loss: 2.63792e-02
I0209 17:31:48.873631 22542570456896 run_lib.py:133] step: 292250, training_loss: 2.83001e-02
I0209 17:32:06.264024 22542570456896 run_lib.py:133] step: 292300, training_loss: 2.42257e-02
I0209 17:32:06.419515 22542570456896 run_lib.py:146] step: 292300, eval_loss: 2.67100e-02
I0209 17:32:24.024254 22542570456896 run_lib.py:133] step: 292350, training_loss: 2.27911e-02
I0209 17:32:41.512196 22542570456896 run_lib.py:133] step: 292400, training_loss: 3.58603e-02
I0209 17:32:41.669916 22542570456896 run_lib.py:146] step: 292400, eval_loss: 2.67060e-02
I0209 17:32:59.278985 22542570456896 run_lib.py:133] step: 292450, training_loss: 3.31563e-02
I0209 17:33:16.703920 22542570456896 run_lib.py:133] step: 292500, training_loss: 3.14929e-02
I0209 17:33:16.858082 22542570456896 run_lib.py:146] step: 292500, eval_loss: 2.94589e-02
I0209 17:33:34.472185 22542570456896 run_lib.py:133] step: 292550, training_loss: 3.10513e-02
I0209 17:33:51.896072 22542570456896 run_lib.py:133] step: 292600, training_loss: 3.02157e-02
I0209 17:33:52.057565 22542570456896 run_lib.py:146] step: 292600, eval_loss: 2.56199e-02
I0209 17:34:09.515539 22542570456896 run_lib.py:133] step: 292650, training_loss: 2.20827e-02
I0209 17:34:27.139691 22542570456896 run_lib.py:133] step: 292700, training_loss: 3.04754e-02
I0209 17:34:27.297221 22542570456896 run_lib.py:146] step: 292700, eval_loss: 2.73986e-02
I0209 17:34:44.728842 22542570456896 run_lib.py:133] step: 292750, training_loss: 2.52005e-02
I0209 17:35:02.250161 22542570456896 run_lib.py:133] step: 292800, training_loss: 2.56473e-02
I0209 17:35:02.406288 22542570456896 run_lib.py:146] step: 292800, eval_loss: 2.76903e-02
I0209 17:35:19.854589 22542570456896 run_lib.py:133] step: 292850, training_loss: 2.90337e-02
I0209 17:35:37.297399 22542570456896 run_lib.py:133] step: 292900, training_loss: 3.57619e-02
I0209 17:35:37.454566 22542570456896 run_lib.py:146] step: 292900, eval_loss: 2.76633e-02
I0209 17:35:55.073954 22542570456896 run_lib.py:133] step: 292950, training_loss: 2.63427e-02
I0209 17:36:12.528005 22542570456896 run_lib.py:133] step: 293000, training_loss: 2.38601e-02
I0209 17:36:12.680093 22542570456896 run_lib.py:146] step: 293000, eval_loss: 2.89837e-02
I0209 17:36:30.097321 22542570456896 run_lib.py:133] step: 293050, training_loss: 2.78268e-02
I0209 17:36:47.700696 22542570456896 run_lib.py:133] step: 293100, training_loss: 3.03135e-02
I0209 17:36:47.852450 22542570456896 run_lib.py:146] step: 293100, eval_loss: 2.84477e-02
I0209 17:37:05.267134 22542570456896 run_lib.py:133] step: 293150, training_loss: 2.44491e-02
I0209 17:37:22.728333 22542570456896 run_lib.py:133] step: 293200, training_loss: 3.21384e-02
I0209 17:37:22.894779 22542570456896 run_lib.py:146] step: 293200, eval_loss: 3.10394e-02
I0209 17:37:40.444065 22542570456896 run_lib.py:133] step: 293250, training_loss: 2.81101e-02
I0209 17:37:57.905188 22542570456896 run_lib.py:133] step: 293300, training_loss: 2.84076e-02
I0209 17:37:58.061636 22542570456896 run_lib.py:146] step: 293300, eval_loss: 2.47031e-02
I0209 17:38:15.531635 22542570456896 run_lib.py:133] step: 293350, training_loss: 2.71454e-02
I0209 17:38:32.903895 22542570456896 run_lib.py:133] step: 293400, training_loss: 2.71829e-02
I0209 17:38:33.056015 22542570456896 run_lib.py:146] step: 293400, eval_loss: 2.69758e-02
I0209 17:38:50.677512 22542570456896 run_lib.py:133] step: 293450, training_loss: 2.96920e-02
I0209 17:39:08.172366 22542570456896 run_lib.py:133] step: 293500, training_loss: 3.52892e-02
I0209 17:39:08.323907 22542570456896 run_lib.py:146] step: 293500, eval_loss: 3.00878e-02
I0209 17:39:25.788336 22542570456896 run_lib.py:133] step: 293550, training_loss: 2.33405e-02
I0209 17:39:43.215276 22542570456896 run_lib.py:133] step: 293600, training_loss: 3.40300e-02
I0209 17:39:43.370440 22542570456896 run_lib.py:146] step: 293600, eval_loss: 3.37899e-02
I0209 17:40:00.965691 22542570456896 run_lib.py:133] step: 293650, training_loss: 2.85228e-02
I0209 17:40:18.349294 22542570456896 run_lib.py:133] step: 293700, training_loss: 2.84489e-02
I0209 17:40:18.516556 22542570456896 run_lib.py:146] step: 293700, eval_loss: 2.63685e-02
I0209 17:40:36.137933 22542570456896 run_lib.py:133] step: 293750, training_loss: 3.18217e-02
I0209 17:40:53.573302 22542570456896 run_lib.py:133] step: 293800, training_loss: 2.84626e-02
I0209 17:40:53.730169 22542570456896 run_lib.py:146] step: 293800, eval_loss: 2.23010e-02
I0209 17:41:11.314326 22542570456896 run_lib.py:133] step: 293850, training_loss: 2.39718e-02
I0209 17:41:28.701753 22542570456896 run_lib.py:133] step: 293900, training_loss: 3.03276e-02
I0209 17:41:28.857418 22542570456896 run_lib.py:146] step: 293900, eval_loss: 2.40454e-02
I0209 17:41:46.421237 22542570456896 run_lib.py:133] step: 293950, training_loss: 3.93545e-02
I0209 17:42:03.814109 22542570456896 run_lib.py:133] step: 294000, training_loss: 3.19422e-02
I0209 17:42:03.966427 22542570456896 run_lib.py:146] step: 294000, eval_loss: 2.55738e-02
I0209 17:42:21.329534 22542570456896 run_lib.py:133] step: 294050, training_loss: 3.12984e-02
I0209 17:42:38.786856 22542570456896 run_lib.py:133] step: 294100, training_loss: 4.10838e-02
I0209 17:42:38.941401 22542570456896 run_lib.py:146] step: 294100, eval_loss: 2.42776e-02
I0209 17:42:56.237402 22542570456896 run_lib.py:133] step: 294150, training_loss: 3.13099e-02
I0209 17:43:13.618844 22542570456896 run_lib.py:133] step: 294200, training_loss: 3.11273e-02
I0209 17:43:13.772317 22542570456896 run_lib.py:146] step: 294200, eval_loss: 3.00543e-02
I0209 17:43:31.392038 22542570456896 run_lib.py:133] step: 294250, training_loss: 3.01258e-02
I0209 17:43:48.913956 22542570456896 run_lib.py:133] step: 294300, training_loss: 2.56088e-02
I0209 17:43:49.079344 22542570456896 run_lib.py:146] step: 294300, eval_loss: 2.27925e-02
I0209 17:44:06.679825 22542570456896 run_lib.py:133] step: 294350, training_loss: 1.92775e-02
I0209 17:44:24.111270 22542570456896 run_lib.py:133] step: 294400, training_loss: 2.37181e-02
I0209 17:44:24.263990 22542570456896 run_lib.py:146] step: 294400, eval_loss: 2.31433e-02
I0209 17:44:41.693149 22542570456896 run_lib.py:133] step: 294450, training_loss: 3.08904e-02
I0209 17:44:59.305676 22542570456896 run_lib.py:133] step: 294500, training_loss: 2.39028e-02
I0209 17:44:59.459323 22542570456896 run_lib.py:146] step: 294500, eval_loss: 2.84855e-02
I0209 17:45:16.898378 22542570456896 run_lib.py:133] step: 294550, training_loss: 3.04050e-02
I0209 17:45:34.354205 22542570456896 run_lib.py:133] step: 294600, training_loss: 3.18713e-02
I0209 17:45:34.532371 22542570456896 run_lib.py:146] step: 294600, eval_loss: 2.99618e-02
I0209 17:45:51.966718 22542570456896 run_lib.py:133] step: 294650, training_loss: 3.58648e-02
I0209 17:46:09.604102 22542570456896 run_lib.py:133] step: 294700, training_loss: 2.48992e-02
I0209 17:46:09.760532 22542570456896 run_lib.py:146] step: 294700, eval_loss: 2.74748e-02
I0209 17:46:27.165254 22542570456896 run_lib.py:133] step: 294750, training_loss: 2.77215e-02
I0209 17:46:44.636609 22542570456896 run_lib.py:133] step: 294800, training_loss: 2.85258e-02
I0209 17:46:44.792664 22542570456896 run_lib.py:146] step: 294800, eval_loss: 3.27795e-02
I0209 17:47:02.175254 22542570456896 run_lib.py:133] step: 294850, training_loss: 3.01016e-02
I0209 17:47:19.671668 22542570456896 run_lib.py:133] step: 294900, training_loss: 4.01896e-02
I0209 17:47:19.834607 22542570456896 run_lib.py:146] step: 294900, eval_loss: 2.74493e-02
I0209 17:47:37.443348 22542570456896 run_lib.py:133] step: 294950, training_loss: 2.13742e-02
I0209 17:47:54.924889 22542570456896 run_lib.py:133] step: 295000, training_loss: 2.47368e-02
I0209 17:47:55.081384 22542570456896 run_lib.py:146] step: 295000, eval_loss: 2.97385e-02
I0209 17:48:12.468702 22542570456896 run_lib.py:133] step: 295050, training_loss: 2.69670e-02
I0209 17:48:29.888147 22542570456896 run_lib.py:133] step: 295100, training_loss: 2.83022e-02
I0209 17:48:30.052023 22542570456896 run_lib.py:146] step: 295100, eval_loss: 2.56717e-02
I0209 17:48:47.647414 22542570456896 run_lib.py:133] step: 295150, training_loss: 2.51156e-02
I0209 17:49:05.127768 22542570456896 run_lib.py:133] step: 295200, training_loss: 2.91560e-02
I0209 17:49:05.284569 22542570456896 run_lib.py:146] step: 295200, eval_loss: 2.87224e-02
I0209 17:49:22.905631 22542570456896 run_lib.py:133] step: 295250, training_loss: 2.84401e-02
I0209 17:49:40.296124 22542570456896 run_lib.py:133] step: 295300, training_loss: 3.51203e-02
I0209 17:49:40.451272 22542570456896 run_lib.py:146] step: 295300, eval_loss: 2.69627e-02
I0209 17:49:57.977939 22542570456896 run_lib.py:133] step: 295350, training_loss: 2.65202e-02
I0209 17:50:15.389765 22542570456896 run_lib.py:133] step: 295400, training_loss: 2.97073e-02
I0209 17:50:15.543582 22542570456896 run_lib.py:146] step: 295400, eval_loss: 2.72737e-02
I0209 17:50:32.988430 22542570456896 run_lib.py:133] step: 295450, training_loss: 2.66709e-02
I0209 17:50:50.579900 22542570456896 run_lib.py:133] step: 295500, training_loss: 3.06273e-02
I0209 17:50:50.734370 22542570456896 run_lib.py:146] step: 295500, eval_loss: 2.90361e-02
I0209 17:51:08.152225 22542570456896 run_lib.py:133] step: 295550, training_loss: 3.94636e-02
I0209 17:51:25.722372 22542570456896 run_lib.py:133] step: 295600, training_loss: 2.82304e-02
I0209 17:51:25.879663 22542570456896 run_lib.py:146] step: 295600, eval_loss: 3.53848e-02
I0209 17:51:43.265328 22542570456896 run_lib.py:133] step: 295650, training_loss: 2.33159e-02
I0209 17:52:00.715243 22542570456896 run_lib.py:133] step: 295700, training_loss: 2.28523e-02
I0209 17:52:00.871975 22542570456896 run_lib.py:146] step: 295700, eval_loss: 3.32182e-02
I0209 17:52:18.470410 22542570456896 run_lib.py:133] step: 295750, training_loss: 3.17713e-02
I0209 17:52:35.902491 22542570456896 run_lib.py:133] step: 295800, training_loss: 3.05613e-02
I0209 17:52:36.057399 22542570456896 run_lib.py:146] step: 295800, eval_loss: 3.36992e-02
I0209 17:52:53.472203 22542570456896 run_lib.py:133] step: 295850, training_loss: 2.63053e-02
I0209 17:53:11.084206 22542570456896 run_lib.py:133] step: 295900, training_loss: 2.80495e-02
I0209 17:53:11.235368 22542570456896 run_lib.py:146] step: 295900, eval_loss: 2.97691e-02
I0209 17:53:28.662462 22542570456896 run_lib.py:133] step: 295950, training_loss: 3.07819e-02
I0209 17:53:46.137282 22542570456896 run_lib.py:133] step: 296000, training_loss: 3.05483e-02
I0209 17:53:46.503356 22542570456896 run_lib.py:146] step: 296000, eval_loss: 2.06963e-02
I0209 17:54:03.974810 22542570456896 run_lib.py:133] step: 296050, training_loss: 3.50962e-02
I0209 17:54:21.425383 22542570456896 run_lib.py:133] step: 296100, training_loss: 3.37824e-02
I0209 17:54:21.578710 22542570456896 run_lib.py:146] step: 296100, eval_loss: 2.90624e-02
I0209 17:54:39.025589 22542570456896 run_lib.py:133] step: 296150, training_loss: 2.98080e-02
I0209 17:54:56.468026 22542570456896 run_lib.py:133] step: 296200, training_loss: 3.52637e-02
I0209 17:54:56.623503 22542570456896 run_lib.py:146] step: 296200, eval_loss: 2.84934e-02
I0209 17:55:14.244352 22542570456896 run_lib.py:133] step: 296250, training_loss: 2.34344e-02
I0209 17:55:31.773937 22542570456896 run_lib.py:133] step: 296300, training_loss: 2.92999e-02
I0209 17:55:31.926245 22542570456896 run_lib.py:146] step: 296300, eval_loss: 2.66620e-02
I0209 17:55:49.328205 22542570456896 run_lib.py:133] step: 296350, training_loss: 2.14775e-02
I0209 17:56:06.754593 22542570456896 run_lib.py:133] step: 296400, training_loss: 2.84872e-02
I0209 17:56:06.911379 22542570456896 run_lib.py:146] step: 296400, eval_loss: 2.55678e-02
I0209 17:56:24.516064 22542570456896 run_lib.py:133] step: 296450, training_loss: 2.38477e-02
I0209 17:56:42.025566 22542570456896 run_lib.py:133] step: 296500, training_loss: 3.31068e-02
I0209 17:56:42.204332 22542570456896 run_lib.py:146] step: 296500, eval_loss: 2.96382e-02
I0209 17:56:59.653884 22542570456896 run_lib.py:133] step: 296550, training_loss: 3.02383e-02
I0209 17:57:17.075643 22542570456896 run_lib.py:133] step: 296600, training_loss: 3.28020e-02
I0209 17:57:17.231188 22542570456896 run_lib.py:146] step: 296600, eval_loss: 2.37749e-02
I0209 17:57:34.829674 22542570456896 run_lib.py:133] step: 296650, training_loss: 2.32260e-02
I0209 17:57:52.199337 22542570456896 run_lib.py:133] step: 296700, training_loss: 2.24263e-02
I0209 17:57:52.353176 22542570456896 run_lib.py:146] step: 296700, eval_loss: 2.69138e-02
I0209 17:58:09.906019 22542570456896 run_lib.py:133] step: 296750, training_loss: 3.33385e-02
I0209 17:58:27.312034 22542570456896 run_lib.py:133] step: 296800, training_loss: 2.39830e-02
I0209 17:58:27.464613 22542570456896 run_lib.py:146] step: 296800, eval_loss: 3.16570e-02
I0209 17:58:45.139655 22542570456896 run_lib.py:133] step: 296850, training_loss: 2.45176e-02
I0209 17:59:02.532611 22542570456896 run_lib.py:133] step: 296900, training_loss: 2.98412e-02
I0209 17:59:02.687541 22542570456896 run_lib.py:146] step: 296900, eval_loss: 2.71613e-02
I0209 17:59:20.116218 22542570456896 run_lib.py:133] step: 296950, training_loss: 2.13597e-02
I0209 17:59:37.686484 22542570456896 run_lib.py:133] step: 297000, training_loss: 2.75546e-02
I0209 17:59:37.849626 22542570456896 run_lib.py:146] step: 297000, eval_loss: 2.35282e-02
I0209 17:59:55.260661 22542570456896 run_lib.py:133] step: 297050, training_loss: 3.57583e-02
I0209 18:00:12.855457 22542570456896 run_lib.py:133] step: 297100, training_loss: 3.11949e-02
I0209 18:00:13.011477 22542570456896 run_lib.py:146] step: 297100, eval_loss: 2.88978e-02
I0209 18:00:30.449894 22542570456896 run_lib.py:133] step: 297150, training_loss: 2.66823e-02
I0209 18:00:47.856919 22542570456896 run_lib.py:133] step: 297200, training_loss: 2.30189e-02
I0209 18:00:48.012331 22542570456896 run_lib.py:146] step: 297200, eval_loss: 2.40849e-02
I0209 18:01:05.613743 22542570456896 run_lib.py:133] step: 297250, training_loss: 3.30139e-02
I0209 18:01:23.031016 22542570456896 run_lib.py:133] step: 297300, training_loss: 2.35908e-02
I0209 18:01:23.183309 22542570456896 run_lib.py:146] step: 297300, eval_loss: 2.80162e-02
I0209 18:01:40.606365 22542570456896 run_lib.py:133] step: 297350, training_loss: 2.84315e-02
I0209 18:01:58.040869 22542570456896 run_lib.py:133] step: 297400, training_loss: 2.75957e-02
I0209 18:01:58.208365 22542570456896 run_lib.py:146] step: 297400, eval_loss: 2.67606e-02
I0209 18:02:15.866795 22542570456896 run_lib.py:133] step: 297450, training_loss: 3.13111e-02
I0209 18:02:33.280982 22542570456896 run_lib.py:133] step: 297500, training_loss: 2.74634e-02
I0209 18:02:33.438592 22542570456896 run_lib.py:146] step: 297500, eval_loss: 2.80637e-02
I0209 18:02:50.901210 22542570456896 run_lib.py:133] step: 297550, training_loss: 3.12706e-02
I0209 18:03:08.278362 22542570456896 run_lib.py:133] step: 297600, training_loss: 2.30637e-02
I0209 18:03:08.442136 22542570456896 run_lib.py:146] step: 297600, eval_loss: 2.72135e-02
I0209 18:03:25.879539 22542570456896 run_lib.py:133] step: 297650, training_loss: 2.74423e-02
I0209 18:03:43.315936 22542570456896 run_lib.py:133] step: 297700, training_loss: 2.94454e-02
I0209 18:03:43.474106 22542570456896 run_lib.py:146] step: 297700, eval_loss: 3.10656e-02
I0209 18:04:01.130745 22542570456896 run_lib.py:133] step: 297750, training_loss: 2.88376e-02
I0209 18:04:18.631578 22542570456896 run_lib.py:133] step: 297800, training_loss: 2.86840e-02
I0209 18:04:18.782347 22542570456896 run_lib.py:146] step: 297800, eval_loss: 2.68345e-02
I0209 18:04:36.183424 22542570456896 run_lib.py:133] step: 297850, training_loss: 2.67787e-02
I0209 18:04:53.589887 22542570456896 run_lib.py:133] step: 297900, training_loss: 2.19605e-02
I0209 18:04:53.765078 22542570456896 run_lib.py:146] step: 297900, eval_loss: 3.13177e-02
I0209 18:05:11.353773 22542570456896 run_lib.py:133] step: 297950, training_loss: 2.74019e-02
I0209 18:05:28.814209 22542570456896 run_lib.py:133] step: 298000, training_loss: 2.24642e-02
I0209 18:05:28.970540 22542570456896 run_lib.py:146] step: 298000, eval_loss: 3.06425e-02
I0209 18:05:46.591164 22542570456896 run_lib.py:133] step: 298050, training_loss: 2.83044e-02
I0209 18:06:04.044246 22542570456896 run_lib.py:133] step: 298100, training_loss: 3.20020e-02
I0209 18:06:04.199257 22542570456896 run_lib.py:146] step: 298100, eval_loss: 2.89330e-02
I0209 18:06:21.742259 22542570456896 run_lib.py:133] step: 298150, training_loss: 2.64479e-02
I0209 18:06:39.210804 22542570456896 run_lib.py:133] step: 298200, training_loss: 3.10171e-02
I0209 18:06:39.365175 22542570456896 run_lib.py:146] step: 298200, eval_loss: 3.02154e-02
I0209 18:06:56.959613 22542570456896 run_lib.py:133] step: 298250, training_loss: 2.91642e-02
I0209 18:07:14.335276 22542570456896 run_lib.py:133] step: 298300, training_loss: 2.84545e-02
I0209 18:07:14.490302 22542570456896 run_lib.py:146] step: 298300, eval_loss: 3.03112e-02
I0209 18:07:31.913007 22542570456896 run_lib.py:133] step: 298350, training_loss: 1.88127e-02
I0209 18:07:49.504092 22542570456896 run_lib.py:133] step: 298400, training_loss: 2.65136e-02
I0209 18:07:49.663594 22542570456896 run_lib.py:146] step: 298400, eval_loss: 2.55336e-02
I0209 18:08:07.070551 22542570456896 run_lib.py:133] step: 298450, training_loss: 3.39061e-02
I0209 18:08:24.523394 22542570456896 run_lib.py:133] step: 298500, training_loss: 2.73222e-02
I0209 18:08:24.679587 22542570456896 run_lib.py:146] step: 298500, eval_loss: 3.26689e-02
I0209 18:08:42.288080 22542570456896 run_lib.py:133] step: 298550, training_loss: 2.35483e-02
I0209 18:08:59.907684 22542570456896 run_lib.py:133] step: 298600, training_loss: 2.30056e-02
I0209 18:09:00.062299 22542570456896 run_lib.py:146] step: 298600, eval_loss: 2.68118e-02
I0209 18:09:17.503992 22542570456896 run_lib.py:133] step: 298650, training_loss: 3.32586e-02
I0209 18:09:34.904317 22542570456896 run_lib.py:133] step: 298700, training_loss: 3.12540e-02
I0209 18:09:35.063337 22542570456896 run_lib.py:146] step: 298700, eval_loss: 2.98440e-02
I0209 18:09:52.469103 22542570456896 run_lib.py:133] step: 298750, training_loss: 2.98960e-02
I0209 18:10:10.101749 22542570456896 run_lib.py:133] step: 298800, training_loss: 2.89142e-02
I0209 18:10:10.272166 22542570456896 run_lib.py:146] step: 298800, eval_loss: 3.18434e-02
I0209 18:10:27.712012 22542570456896 run_lib.py:133] step: 298850, training_loss: 3.02745e-02
I0209 18:10:45.115938 22542570456896 run_lib.py:133] step: 298900, training_loss: 2.49906e-02
I0209 18:10:45.274497 22542570456896 run_lib.py:146] step: 298900, eval_loss: 2.65847e-02
I0209 18:11:02.708228 22542570456896 run_lib.py:133] step: 298950, training_loss: 2.97696e-02
I0209 18:11:20.309386 22542570456896 run_lib.py:133] step: 299000, training_loss: 2.48557e-02
I0209 18:11:20.464275 22542570456896 run_lib.py:146] step: 299000, eval_loss: 2.81363e-02
I0209 18:11:37.868353 22542570456896 run_lib.py:133] step: 299050, training_loss: 2.55062e-02
I0209 18:11:55.376796 22542570456896 run_lib.py:133] step: 299100, training_loss: 2.77776e-02
I0209 18:11:55.532616 22542570456896 run_lib.py:146] step: 299100, eval_loss: 3.11011e-02
I0209 18:12:12.962376 22542570456896 run_lib.py:133] step: 299150, training_loss: 3.13409e-02
I0209 18:12:30.371002 22542570456896 run_lib.py:133] step: 299200, training_loss: 3.46097e-02
I0209 18:12:30.523445 22542570456896 run_lib.py:146] step: 299200, eval_loss: 2.98244e-02
I0209 18:12:48.125914 22542570456896 run_lib.py:133] step: 299250, training_loss: 2.97280e-02
I0209 18:13:05.630317 22542570456896 run_lib.py:133] step: 299300, training_loss: 2.92929e-02
I0209 18:13:05.793507 22542570456896 run_lib.py:146] step: 299300, eval_loss: 3.25077e-02
I0209 18:13:23.222046 22542570456896 run_lib.py:133] step: 299350, training_loss: 2.20835e-02
I0209 18:13:40.717933 22542570456896 run_lib.py:133] step: 299400, training_loss: 3.32830e-02
I0209 18:13:40.874520 22542570456896 run_lib.py:146] step: 299400, eval_loss: 2.67560e-02
I0209 18:13:58.467471 22542570456896 run_lib.py:133] step: 299450, training_loss: 2.52017e-02
I0209 18:14:15.891440 22542570456896 run_lib.py:133] step: 299500, training_loss: 2.29773e-02
I0209 18:14:16.056526 22542570456896 run_lib.py:146] step: 299500, eval_loss: 2.65728e-02
I0209 18:14:33.634461 22542570456896 run_lib.py:133] step: 299550, training_loss: 3.46796e-02
I0209 18:14:51.080570 22542570456896 run_lib.py:133] step: 299600, training_loss: 4.14080e-02
I0209 18:14:51.235486 22542570456896 run_lib.py:146] step: 299600, eval_loss: 3.05110e-02
I0209 18:15:08.925919 22542570456896 run_lib.py:133] step: 299650, training_loss: 3.02300e-02
I0209 18:15:26.349396 22542570456896 run_lib.py:133] step: 299700, training_loss: 2.67973e-02
I0209 18:15:26.502449 22542570456896 run_lib.py:146] step: 299700, eval_loss: 2.70377e-02
I0209 18:15:43.915727 22542570456896 run_lib.py:133] step: 299750, training_loss: 3.44931e-02
I0209 18:16:01.483498 22542570456896 run_lib.py:133] step: 299800, training_loss: 2.41435e-02
I0209 18:16:01.644557 22542570456896 run_lib.py:146] step: 299800, eval_loss: 2.47450e-02
I0209 18:16:19.062565 22542570456896 run_lib.py:133] step: 299850, training_loss: 3.11352e-02
I0209 18:16:36.601283 22542570456896 run_lib.py:133] step: 299900, training_loss: 2.88307e-02
I0209 18:16:36.772215 22542570456896 run_lib.py:146] step: 299900, eval_loss: 2.40983e-02
I0209 18:16:54.204200 22542570456896 run_lib.py:133] step: 299950, training_loss: 3.01916e-02
I0209 18:17:11.673012 22542570456896 run_lib.py:133] step: 300000, training_loss: 2.84761e-02
I0209 18:17:12.371868 22542570456896 run_lib.py:146] step: 300000, eval_loss: 3.12248e-02
I0209 18:17:32.407305 22542570456896 run_lib.py:133] step: 300050, training_loss: 2.48802e-02
I0209 18:17:50.023050 22542570456896 run_lib.py:133] step: 300100, training_loss: 3.60631e-02
I0209 18:17:50.179375 22542570456896 run_lib.py:146] step: 300100, eval_loss: 3.69533e-02
I0209 18:18:07.592521 22542570456896 run_lib.py:133] step: 300150, training_loss: 2.81857e-02
I0209 18:18:25.216341 22542570456896 run_lib.py:133] step: 300200, training_loss: 2.82985e-02
I0209 18:18:25.370479 22542570456896 run_lib.py:146] step: 300200, eval_loss: 2.57809e-02
I0209 18:18:42.836528 22542570456896 run_lib.py:133] step: 300250, training_loss: 3.34849e-02
I0209 18:19:00.250790 22542570456896 run_lib.py:133] step: 300300, training_loss: 2.41947e-02
I0209 18:19:00.407390 22542570456896 run_lib.py:146] step: 300300, eval_loss: 2.75400e-02
I0209 18:19:18.007169 22542570456896 run_lib.py:133] step: 300350, training_loss: 2.79216e-02
I0209 18:19:35.431237 22542570456896 run_lib.py:133] step: 300400, training_loss: 2.67521e-02
I0209 18:19:35.593657 22542570456896 run_lib.py:146] step: 300400, eval_loss: 3.21027e-02
I0209 18:19:53.140127 22542570456896 run_lib.py:133] step: 300450, training_loss: 2.88702e-02
I0209 18:20:10.614277 22542570456896 run_lib.py:133] step: 300500, training_loss: 3.34348e-02
I0209 18:20:10.778393 22542570456896 run_lib.py:146] step: 300500, eval_loss: 2.20850e-02
I0209 18:20:28.230013 22542570456896 run_lib.py:133] step: 300550, training_loss: 2.95289e-02
I0209 18:20:45.816174 22542570456896 run_lib.py:133] step: 300600, training_loss: 2.55520e-02
I0209 18:20:45.970564 22542570456896 run_lib.py:146] step: 300600, eval_loss: 3.15418e-02
I0209 18:21:03.349335 22542570456896 run_lib.py:133] step: 300650, training_loss: 2.95663e-02
I0209 18:21:20.738857 22542570456896 run_lib.py:133] step: 300700, training_loss: 2.43537e-02
I0209 18:21:20.890922 22542570456896 run_lib.py:146] step: 300700, eval_loss: 2.97315e-02
I0209 18:21:38.336304 22542570456896 run_lib.py:133] step: 300750, training_loss: 2.62511e-02
I0209 18:21:55.964107 22542570456896 run_lib.py:133] step: 300800, training_loss: 2.39784e-02
I0209 18:21:56.137304 22542570456896 run_lib.py:146] step: 300800, eval_loss: 3.09719e-02
I0209 18:22:13.557521 22542570456896 run_lib.py:133] step: 300850, training_loss: 2.06338e-02
I0209 18:22:31.071923 22542570456896 run_lib.py:133] step: 300900, training_loss: 2.71976e-02
I0209 18:22:31.230510 22542570456896 run_lib.py:146] step: 300900, eval_loss: 3.51341e-02
I0209 18:22:48.693196 22542570456896 run_lib.py:133] step: 300950, training_loss: 3.46130e-02
I0209 18:23:06.099872 22542570456896 run_lib.py:133] step: 301000, training_loss: 3.06323e-02
I0209 18:23:06.265193 22542570456896 run_lib.py:146] step: 301000, eval_loss: 3.54477e-02
I0209 18:23:23.854206 22542570456896 run_lib.py:133] step: 301050, training_loss: 2.97293e-02
I0209 18:23:41.406596 22542570456896 run_lib.py:133] step: 301100, training_loss: 2.68338e-02
I0209 18:23:41.561140 22542570456896 run_lib.py:146] step: 301100, eval_loss: 3.13901e-02
I0209 18:23:58.999974 22542570456896 run_lib.py:133] step: 301150, training_loss: 2.58366e-02
I0209 18:24:16.421935 22542570456896 run_lib.py:133] step: 301200, training_loss: 3.10170e-02
I0209 18:24:16.575290 22542570456896 run_lib.py:146] step: 301200, eval_loss: 3.14283e-02
I0209 18:24:34.134945 22542570456896 run_lib.py:133] step: 301250, training_loss: 2.56818e-02
I0209 18:24:51.520582 22542570456896 run_lib.py:133] step: 301300, training_loss: 2.43659e-02
I0209 18:24:51.695300 22542570456896 run_lib.py:146] step: 301300, eval_loss: 2.46787e-02
I0209 18:25:09.298572 22542570456896 run_lib.py:133] step: 301350, training_loss: 3.39762e-02
I0209 18:25:26.691818 22542570456896 run_lib.py:133] step: 301400, training_loss: 2.55873e-02
I0209 18:25:26.846590 22542570456896 run_lib.py:146] step: 301400, eval_loss: 3.11586e-02
I0209 18:25:44.485075 22542570456896 run_lib.py:133] step: 301450, training_loss: 2.66859e-02
I0209 18:26:01.851600 22542570456896 run_lib.py:133] step: 301500, training_loss: 3.21980e-02
I0209 18:26:02.013585 22542570456896 run_lib.py:146] step: 301500, eval_loss: 2.45321e-02
I0209 18:26:19.437280 22542570456896 run_lib.py:133] step: 301550, training_loss: 2.38395e-02
I0209 18:26:37.036659 22542570456896 run_lib.py:133] step: 301600, training_loss: 2.26256e-02
I0209 18:26:37.197131 22542570456896 run_lib.py:146] step: 301600, eval_loss: 2.72270e-02
I0209 18:26:54.623448 22542570456896 run_lib.py:133] step: 301650, training_loss: 2.82123e-02
I0209 18:27:12.217745 22542570456896 run_lib.py:133] step: 301700, training_loss: 2.72382e-02
I0209 18:27:12.373413 22542570456896 run_lib.py:146] step: 301700, eval_loss: 3.05995e-02
I0209 18:27:29.762502 22542570456896 run_lib.py:133] step: 301750, training_loss: 2.67783e-02
I0209 18:27:47.175766 22542570456896 run_lib.py:133] step: 301800, training_loss: 3.24934e-02
I0209 18:27:47.335574 22542570456896 run_lib.py:146] step: 301800, eval_loss: 3.22340e-02
I0209 18:28:04.907754 22542570456896 run_lib.py:133] step: 301850, training_loss: 2.60430e-02
I0209 18:28:22.368301 22542570456896 run_lib.py:133] step: 301900, training_loss: 2.71754e-02
I0209 18:28:22.524543 22542570456896 run_lib.py:146] step: 301900, eval_loss: 3.77029e-02
I0209 18:28:39.978864 22542570456896 run_lib.py:133] step: 301950, training_loss: 2.49172e-02
I0209 18:28:57.616925 22542570456896 run_lib.py:133] step: 302000, training_loss: 3.04213e-02
I0209 18:28:57.770569 22542570456896 run_lib.py:146] step: 302000, eval_loss: 2.67609e-02
I0209 18:29:15.213662 22542570456896 run_lib.py:133] step: 302050, training_loss: 2.52617e-02
I0209 18:29:32.626100 22542570456896 run_lib.py:133] step: 302100, training_loss: 2.51937e-02
I0209 18:29:32.777410 22542570456896 run_lib.py:146] step: 302100, eval_loss: 2.99932e-02
I0209 18:29:50.279188 22542570456896 run_lib.py:133] step: 302150, training_loss: 2.64407e-02
I0209 18:30:07.738021 22542570456896 run_lib.py:133] step: 302200, training_loss: 3.58088e-02
I0209 18:30:07.899456 22542570456896 run_lib.py:146] step: 302200, eval_loss: 2.78947e-02
I0209 18:30:25.343514 22542570456896 run_lib.py:133] step: 302250, training_loss: 3.24876e-02
I0209 18:30:42.780194 22542570456896 run_lib.py:133] step: 302300, training_loss: 3.79971e-02
I0209 18:30:42.941788 22542570456896 run_lib.py:146] step: 302300, eval_loss: 2.82462e-02
I0209 18:31:00.530767 22542570456896 run_lib.py:133] step: 302350, training_loss: 2.97380e-02
I0209 18:31:17.989306 22542570456896 run_lib.py:133] step: 302400, training_loss: 2.67514e-02
I0209 18:31:18.160330 22542570456896 run_lib.py:146] step: 302400, eval_loss: 3.10995e-02
I0209 18:31:35.567417 22542570456896 run_lib.py:133] step: 302450, training_loss: 3.25454e-02
I0209 18:31:53.001930 22542570456896 run_lib.py:133] step: 302500, training_loss: 2.71011e-02
I0209 18:31:53.159592 22542570456896 run_lib.py:146] step: 302500, eval_loss: 3.04837e-02
I0209 18:32:10.763209 22542570456896 run_lib.py:133] step: 302550, training_loss: 2.65785e-02
I0209 18:32:28.214416 22542570456896 run_lib.py:133] step: 302600, training_loss: 2.34354e-02
I0209 18:32:28.364647 22542570456896 run_lib.py:146] step: 302600, eval_loss: 2.34544e-02
I0209 18:32:45.930996 22542570456896 run_lib.py:133] step: 302650, training_loss: 2.85056e-02
I0209 18:33:03.387688 22542570456896 run_lib.py:133] step: 302700, training_loss: 2.65964e-02
I0209 18:33:03.565324 22542570456896 run_lib.py:146] step: 302700, eval_loss: 3.30196e-02
I0209 18:33:21.143439 22542570456896 run_lib.py:133] step: 302750, training_loss: 2.74746e-02
I0209 18:33:38.601202 22542570456896 run_lib.py:133] step: 302800, training_loss: 2.99214e-02
I0209 18:33:38.753397 22542570456896 run_lib.py:146] step: 302800, eval_loss: 3.30666e-02
I0209 18:33:56.314321 22542570456896 run_lib.py:133] step: 302850, training_loss: 2.92130e-02
I0209 18:34:13.760654 22542570456896 run_lib.py:133] step: 302900, training_loss: 2.26911e-02
I0209 18:34:13.916103 22542570456896 run_lib.py:146] step: 302900, eval_loss: 2.84912e-02
I0209 18:34:31.319319 22542570456896 run_lib.py:133] step: 302950, training_loss: 2.37687e-02
I0209 18:34:48.903898 22542570456896 run_lib.py:133] step: 303000, training_loss: 2.40864e-02
I0209 18:34:49.063043 22542570456896 run_lib.py:146] step: 303000, eval_loss: 3.12138e-02
I0209 18:35:06.564585 22542570456896 run_lib.py:133] step: 303050, training_loss: 2.65910e-02
I0209 18:35:23.974689 22542570456896 run_lib.py:133] step: 303100, training_loss: 2.91853e-02
I0209 18:35:24.128332 22542570456896 run_lib.py:146] step: 303100, eval_loss: 2.72142e-02
I0209 18:35:41.735454 22542570456896 run_lib.py:133] step: 303150, training_loss: 2.93276e-02
I0209 18:35:59.157835 22542570456896 run_lib.py:133] step: 303200, training_loss: 2.77931e-02
I0209 18:35:59.325637 22542570456896 run_lib.py:146] step: 303200, eval_loss: 3.32037e-02
I0209 18:36:16.926717 22542570456896 run_lib.py:133] step: 303250, training_loss: 2.63810e-02
I0209 18:36:34.415932 22542570456896 run_lib.py:133] step: 303300, training_loss: 2.71351e-02
I0209 18:36:34.571520 22542570456896 run_lib.py:146] step: 303300, eval_loss: 2.94473e-02
I0209 18:36:51.983469 22542570456896 run_lib.py:133] step: 303350, training_loss: 2.91053e-02
I0209 18:37:09.572818 22542570456896 run_lib.py:133] step: 303400, training_loss: 2.49784e-02
I0209 18:37:09.731606 22542570456896 run_lib.py:146] step: 303400, eval_loss: 3.71081e-02
I0209 18:37:27.156247 22542570456896 run_lib.py:133] step: 303450, training_loss: 2.78853e-02
I0209 18:37:44.551850 22542570456896 run_lib.py:133] step: 303500, training_loss: 2.63161e-02
I0209 18:37:44.703607 22542570456896 run_lib.py:146] step: 303500, eval_loss: 3.16182e-02
I0209 18:38:02.076494 22542570456896 run_lib.py:133] step: 303550, training_loss: 2.67710e-02
I0209 18:38:19.716931 22542570456896 run_lib.py:133] step: 303600, training_loss: 2.69347e-02
I0209 18:38:19.888575 22542570456896 run_lib.py:146] step: 303600, eval_loss: 3.20436e-02
I0209 18:38:37.328040 22542570456896 run_lib.py:133] step: 303650, training_loss: 2.53386e-02
I0209 18:38:54.851488 22542570456896 run_lib.py:133] step: 303700, training_loss: 2.07779e-02
I0209 18:38:55.008880 22542570456896 run_lib.py:146] step: 303700, eval_loss: 2.99519e-02
I0209 18:39:12.434915 22542570456896 run_lib.py:133] step: 303750, training_loss: 3.16244e-02
I0209 18:39:29.855899 22542570456896 run_lib.py:133] step: 303800, training_loss: 2.70356e-02
I0209 18:39:30.011453 22542570456896 run_lib.py:146] step: 303800, eval_loss: 2.45950e-02
I0209 18:39:47.560114 22542570456896 run_lib.py:133] step: 303850, training_loss: 3.10977e-02
I0209 18:40:05.116322 22542570456896 run_lib.py:133] step: 303900, training_loss: 3.09346e-02
I0209 18:40:05.273653 22542570456896 run_lib.py:146] step: 303900, eval_loss: 2.75169e-02
I0209 18:40:22.729243 22542570456896 run_lib.py:133] step: 303950, training_loss: 2.58573e-02
I0209 18:40:40.124801 22542570456896 run_lib.py:133] step: 304000, training_loss: 3.16633e-02
I0209 18:40:40.276432 22542570456896 run_lib.py:146] step: 304000, eval_loss: 3.59039e-02
I0209 18:40:57.848584 22542570456896 run_lib.py:133] step: 304050, training_loss: 2.32989e-02
I0209 18:41:15.233095 22542570456896 run_lib.py:133] step: 304100, training_loss: 2.97897e-02
I0209 18:41:15.403549 22542570456896 run_lib.py:146] step: 304100, eval_loss: 3.23454e-02
I0209 18:41:33.007268 22542570456896 run_lib.py:133] step: 304150, training_loss: 2.61857e-02
I0209 18:41:50.436772 22542570456896 run_lib.py:133] step: 304200, training_loss: 2.64751e-02
I0209 18:41:50.594986 22542570456896 run_lib.py:146] step: 304200, eval_loss: 2.87239e-02
I0209 18:42:08.172369 22542570456896 run_lib.py:133] step: 304250, training_loss: 3.02846e-02
I0209 18:42:25.621493 22542570456896 run_lib.py:133] step: 304300, training_loss: 3.97379e-02
I0209 18:42:25.782361 22542570456896 run_lib.py:146] step: 304300, eval_loss: 3.31457e-02
I0209 18:42:43.216216 22542570456896 run_lib.py:133] step: 304350, training_loss: 3.93164e-02
I0209 18:43:00.812496 22542570456896 run_lib.py:133] step: 304400, training_loss: 3.43442e-02
I0209 18:43:00.969603 22542570456896 run_lib.py:146] step: 304400, eval_loss: 2.36698e-02
I0209 18:43:18.493956 22542570456896 run_lib.py:133] step: 304450, training_loss: 3.79190e-02
I0209 18:43:36.101183 22542570456896 run_lib.py:133] step: 304500, training_loss: 3.03187e-02
I0209 18:43:36.254324 22542570456896 run_lib.py:146] step: 304500, eval_loss: 3.18414e-02
I0209 18:43:53.671849 22542570456896 run_lib.py:133] step: 304550, training_loss: 2.66847e-02
I0209 18:44:11.096034 22542570456896 run_lib.py:133] step: 304600, training_loss: 3.61105e-02
I0209 18:44:11.254678 22542570456896 run_lib.py:146] step: 304600, eval_loss: 2.79569e-02
I0209 18:44:28.839439 22542570456896 run_lib.py:133] step: 304650, training_loss: 2.46217e-02
I0209 18:44:46.306807 22542570456896 run_lib.py:133] step: 304700, training_loss: 2.85943e-02
I0209 18:44:46.462348 22542570456896 run_lib.py:146] step: 304700, eval_loss: 2.57562e-02
I0209 18:45:03.894864 22542570456896 run_lib.py:133] step: 304750, training_loss: 1.89576e-02
I0209 18:45:21.491743 22542570456896 run_lib.py:133] step: 304800, training_loss: 2.67367e-02
I0209 18:45:21.648134 22542570456896 run_lib.py:146] step: 304800, eval_loss: 2.72209e-02
I0209 18:45:39.091852 22542570456896 run_lib.py:133] step: 304850, training_loss: 2.71018e-02
I0209 18:45:56.483986 22542570456896 run_lib.py:133] step: 304900, training_loss: 2.45095e-02
I0209 18:45:56.784089 22542570456896 run_lib.py:146] step: 304900, eval_loss: 3.00811e-02
I0209 18:46:14.221027 22542570456896 run_lib.py:133] step: 304950, training_loss: 3.60429e-02
I0209 18:46:31.690970 22542570456896 run_lib.py:133] step: 305000, training_loss: 2.70695e-02
I0209 18:46:31.844554 22542570456896 run_lib.py:146] step: 305000, eval_loss: 3.92128e-02
I0209 18:46:49.272542 22542570456896 run_lib.py:133] step: 305050, training_loss: 3.13736e-02
I0209 18:47:06.664974 22542570456896 run_lib.py:133] step: 305100, training_loss: 2.35215e-02
I0209 18:47:06.821614 22542570456896 run_lib.py:146] step: 305100, eval_loss: 2.37509e-02
I0209 18:47:24.417760 22542570456896 run_lib.py:133] step: 305150, training_loss: 3.05945e-02
I0209 18:47:41.880500 22542570456896 run_lib.py:133] step: 305200, training_loss: 2.61467e-02
I0209 18:47:42.039343 22542570456896 run_lib.py:146] step: 305200, eval_loss: 3.21365e-02
I0209 18:47:59.519142 22542570456896 run_lib.py:133] step: 305250, training_loss: 2.92014e-02
I0209 18:48:16.924332 22542570456896 run_lib.py:133] step: 305300, training_loss: 3.17078e-02
I0209 18:48:17.079621 22542570456896 run_lib.py:146] step: 305300, eval_loss: 3.20302e-02
I0209 18:48:34.666337 22542570456896 run_lib.py:133] step: 305350, training_loss: 2.61435e-02
I0209 18:48:52.153401 22542570456896 run_lib.py:133] step: 305400, training_loss: 3.00330e-02
I0209 18:48:52.304103 22542570456896 run_lib.py:146] step: 305400, eval_loss: 2.59466e-02
I0209 18:49:09.766855 22542570456896 run_lib.py:133] step: 305450, training_loss: 2.77331e-02
I0209 18:49:27.216875 22542570456896 run_lib.py:133] step: 305500, training_loss: 2.89700e-02
I0209 18:49:27.386643 22542570456896 run_lib.py:146] step: 305500, eval_loss: 2.71851e-02
I0209 18:49:44.994915 22542570456896 run_lib.py:133] step: 305550, training_loss: 2.31427e-02
I0209 18:50:02.445028 22542570456896 run_lib.py:133] step: 305600, training_loss: 2.88775e-02
I0209 18:50:02.601220 22542570456896 run_lib.py:146] step: 305600, eval_loss: 2.59293e-02
I0209 18:50:20.163574 22542570456896 run_lib.py:133] step: 305650, training_loss: 2.17789e-02
I0209 18:50:37.546613 22542570456896 run_lib.py:133] step: 305700, training_loss: 2.34185e-02
I0209 18:50:37.704950 22542570456896 run_lib.py:146] step: 305700, eval_loss: 3.31668e-02
I0209 18:50:55.214986 22542570456896 run_lib.py:133] step: 305750, training_loss: 2.72053e-02
I0209 18:51:12.595381 22542570456896 run_lib.py:133] step: 305800, training_loss: 3.00099e-02
I0209 18:51:12.749515 22542570456896 run_lib.py:146] step: 305800, eval_loss: 2.78209e-02
I0209 18:51:30.119153 22542570456896 run_lib.py:133] step: 305850, training_loss: 2.15725e-02
I0209 18:51:47.613546 22542570456896 run_lib.py:133] step: 305900, training_loss: 2.14014e-02
I0209 18:51:47.765213 22542570456896 run_lib.py:146] step: 305900, eval_loss: 2.66872e-02
I0209 18:52:05.200642 22542570456896 run_lib.py:133] step: 305950, training_loss: 3.51935e-02
I0209 18:52:22.780124 22542570456896 run_lib.py:133] step: 306000, training_loss: 3.33239e-02
I0209 18:52:22.941833 22542570456896 run_lib.py:146] step: 306000, eval_loss: 3.05143e-02
I0209 18:52:40.396760 22542570456896 run_lib.py:133] step: 306050, training_loss: 3.30079e-02
I0209 18:52:57.840403 22542570456896 run_lib.py:133] step: 306100, training_loss: 2.43156e-02
I0209 18:52:57.998333 22542570456896 run_lib.py:146] step: 306100, eval_loss: 2.90561e-02
I0209 18:53:15.556717 22542570456896 run_lib.py:133] step: 306150, training_loss: 2.14740e-02
I0209 18:53:32.973553 22542570456896 run_lib.py:133] step: 306200, training_loss: 2.77807e-02
I0209 18:53:33.129104 22542570456896 run_lib.py:146] step: 306200, eval_loss: 2.76480e-02
I0209 18:53:50.579872 22542570456896 run_lib.py:133] step: 306250, training_loss: 2.41586e-02
I0209 18:54:08.021288 22542570456896 run_lib.py:133] step: 306300, training_loss: 2.65560e-02
I0209 18:54:08.182610 22542570456896 run_lib.py:146] step: 306300, eval_loss: 2.82624e-02
I0209 18:54:25.777298 22542570456896 run_lib.py:133] step: 306350, training_loss: 2.70217e-02
I0209 18:54:43.198348 22542570456896 run_lib.py:133] step: 306400, training_loss: 3.50384e-02
I0209 18:54:43.351391 22542570456896 run_lib.py:146] step: 306400, eval_loss: 2.81826e-02
I0209 18:55:00.864705 22542570456896 run_lib.py:133] step: 306450, training_loss: 2.20418e-02
I0209 18:55:18.262269 22542570456896 run_lib.py:133] step: 306500, training_loss: 2.36418e-02
I0209 18:55:18.420696 22542570456896 run_lib.py:146] step: 306500, eval_loss: 2.99813e-02
I0209 18:55:35.822145 22542570456896 run_lib.py:133] step: 306550, training_loss: 2.58931e-02
I0209 18:55:53.321698 22542570456896 run_lib.py:133] step: 306600, training_loss: 2.39558e-02
I0209 18:55:53.481611 22542570456896 run_lib.py:146] step: 306600, eval_loss: 2.65337e-02
I0209 18:56:11.059563 22542570456896 run_lib.py:133] step: 306650, training_loss: 2.76328e-02
I0209 18:56:28.550857 22542570456896 run_lib.py:133] step: 306700, training_loss: 2.29873e-02
I0209 18:56:28.707711 22542570456896 run_lib.py:146] step: 306700, eval_loss: 2.95607e-02
I0209 18:56:46.127269 22542570456896 run_lib.py:133] step: 306750, training_loss: 2.13161e-02
I0209 18:57:03.533269 22542570456896 run_lib.py:133] step: 306800, training_loss: 2.93021e-02
I0209 18:57:03.685041 22542570456896 run_lib.py:146] step: 306800, eval_loss: 2.46571e-02
I0209 18:57:21.212450 22542570456896 run_lib.py:133] step: 306850, training_loss: 2.76908e-02
I0209 18:57:38.676910 22542570456896 run_lib.py:133] step: 306900, training_loss: 2.15775e-02
I0209 18:57:38.839486 22542570456896 run_lib.py:146] step: 306900, eval_loss: 2.89252e-02
I0209 18:57:56.427153 22542570456896 run_lib.py:133] step: 306950, training_loss: 2.37009e-02
I0209 18:58:13.857786 22542570456896 run_lib.py:133] step: 307000, training_loss: 2.92928e-02
I0209 18:58:14.016625 22542570456896 run_lib.py:146] step: 307000, eval_loss: 2.93713e-02
I0209 18:58:31.560213 22542570456896 run_lib.py:133] step: 307050, training_loss: 2.53704e-02
I0209 18:58:48.962430 22542570456896 run_lib.py:133] step: 307100, training_loss: 2.49665e-02
I0209 18:58:49.117401 22542570456896 run_lib.py:146] step: 307100, eval_loss: 2.92763e-02
I0209 18:59:06.675650 22542570456896 run_lib.py:133] step: 307150, training_loss: 2.49043e-02
I0209 18:59:24.156675 22542570456896 run_lib.py:133] step: 307200, training_loss: 4.20041e-02
I0209 18:59:24.311820 22542570456896 run_lib.py:146] step: 307200, eval_loss: 3.00332e-02
I0209 18:59:41.757902 22542570456896 run_lib.py:133] step: 307250, training_loss: 3.06404e-02
I0209 18:59:59.360866 22542570456896 run_lib.py:133] step: 307300, training_loss: 2.42678e-02
I0209 18:59:59.512410 22542570456896 run_lib.py:146] step: 307300, eval_loss: 2.89324e-02
I0209 19:00:16.922572 22542570456896 run_lib.py:133] step: 307350, training_loss: 3.69455e-02
I0209 19:00:34.368751 22542570456896 run_lib.py:133] step: 307400, training_loss: 2.53869e-02
I0209 19:00:34.540556 22542570456896 run_lib.py:146] step: 307400, eval_loss: 2.47301e-02
I0209 19:00:52.185041 22542570456896 run_lib.py:133] step: 307450, training_loss: 2.28976e-02
I0209 19:01:09.835819 22542570456896 run_lib.py:133] step: 307500, training_loss: 2.89400e-02
I0209 19:01:09.991858 22542570456896 run_lib.py:146] step: 307500, eval_loss: 3.30891e-02
I0209 19:01:27.404829 22542570456896 run_lib.py:133] step: 307550, training_loss: 2.74721e-02
I0209 19:01:44.817728 22542570456896 run_lib.py:133] step: 307600, training_loss: 2.56430e-02
I0209 19:01:44.974401 22542570456896 run_lib.py:146] step: 307600, eval_loss: 3.38741e-02
I0209 19:02:02.443783 22542570456896 run_lib.py:133] step: 307650, training_loss: 2.85372e-02
I0209 19:02:20.030638 22542570456896 run_lib.py:133] step: 307700, training_loss: 2.16979e-02
I0209 19:02:20.190262 22542570456896 run_lib.py:146] step: 307700, eval_loss: 3.19603e-02
I0209 19:02:37.618256 22542570456896 run_lib.py:133] step: 307750, training_loss: 2.90047e-02
I0209 19:02:55.086979 22542570456896 run_lib.py:133] step: 307800, training_loss: 2.05978e-02
I0209 19:02:55.245490 22542570456896 run_lib.py:146] step: 307800, eval_loss: 3.23490e-02
I0209 19:03:12.684137 22542570456896 run_lib.py:133] step: 307850, training_loss: 2.77923e-02
I0209 19:03:30.307349 22542570456896 run_lib.py:133] step: 307900, training_loss: 2.92275e-02
I0209 19:03:30.463223 22542570456896 run_lib.py:146] step: 307900, eval_loss: 2.77800e-02
I0209 19:03:47.885151 22542570456896 run_lib.py:133] step: 307950, training_loss: 2.66072e-02
I0209 19:04:05.412246 22542570456896 run_lib.py:133] step: 308000, training_loss: 2.57125e-02
I0209 19:04:05.587274 22542570456896 run_lib.py:146] step: 308000, eval_loss: 3.94389e-02
I0209 19:04:23.058104 22542570456896 run_lib.py:133] step: 308050, training_loss: 2.99236e-02
I0209 19:04:40.462304 22542570456896 run_lib.py:133] step: 308100, training_loss: 2.55864e-02
I0209 19:04:40.621648 22542570456896 run_lib.py:146] step: 308100, eval_loss: 3.17480e-02
I0209 19:04:58.202446 22542570456896 run_lib.py:133] step: 308150, training_loss: 2.62827e-02
I0209 19:05:15.682183 22542570456896 run_lib.py:133] step: 308200, training_loss: 2.28257e-02
I0209 19:05:15.840372 22542570456896 run_lib.py:146] step: 308200, eval_loss: 3.27832e-02
I0209 19:05:33.270685 22542570456896 run_lib.py:133] step: 308250, training_loss: 3.16966e-02
I0209 19:05:50.693468 22542570456896 run_lib.py:133] step: 308300, training_loss: 2.21921e-02
I0209 19:05:50.848531 22542570456896 run_lib.py:146] step: 308300, eval_loss: 2.58816e-02
I0209 19:06:08.442769 22542570456896 run_lib.py:133] step: 308350, training_loss: 3.27309e-02
I0209 19:06:25.882303 22542570456896 run_lib.py:133] step: 308400, training_loss: 2.54479e-02
I0209 19:06:26.041328 22542570456896 run_lib.py:146] step: 308400, eval_loss: 2.74255e-02
I0209 19:06:43.618977 22542570456896 run_lib.py:133] step: 308450, training_loss: 2.47944e-02
I0209 19:07:01.041661 22542570456896 run_lib.py:133] step: 308500, training_loss: 3.43504e-02
I0209 19:07:01.196872 22542570456896 run_lib.py:146] step: 308500, eval_loss: 2.76937e-02
I0209 19:07:18.768229 22542570456896 run_lib.py:133] step: 308550, training_loss: 2.94846e-02
I0209 19:07:36.259046 22542570456896 run_lib.py:133] step: 308600, training_loss: 2.49892e-02
I0209 19:07:36.417174 22542570456896 run_lib.py:146] step: 308600, eval_loss: 2.27545e-02
I0209 19:07:53.839080 22542570456896 run_lib.py:133] step: 308650, training_loss: 3.10198e-02
I0209 19:08:11.431159 22542570456896 run_lib.py:133] step: 308700, training_loss: 2.67645e-02
I0209 19:08:11.589067 22542570456896 run_lib.py:146] step: 308700, eval_loss: 2.47535e-02
I0209 19:08:29.019524 22542570456896 run_lib.py:133] step: 308750, training_loss: 2.63611e-02
I0209 19:08:46.601719 22542570456896 run_lib.py:133] step: 308800, training_loss: 3.03848e-02
I0209 19:08:46.756308 22542570456896 run_lib.py:146] step: 308800, eval_loss: 2.95070e-02
I0209 19:09:04.155473 22542570456896 run_lib.py:133] step: 308850, training_loss: 3.74034e-02
I0209 19:09:21.637384 22542570456896 run_lib.py:133] step: 308900, training_loss: 2.18402e-02
I0209 19:09:21.811310 22542570456896 run_lib.py:146] step: 308900, eval_loss: 3.50798e-02
I0209 19:09:39.468658 22542570456896 run_lib.py:133] step: 308950, training_loss: 3.09664e-02
I0209 19:09:56.859506 22542570456896 run_lib.py:133] step: 309000, training_loss: 2.07176e-02
I0209 19:09:57.016678 22542570456896 run_lib.py:146] step: 309000, eval_loss: 2.23132e-02
I0209 19:10:14.427139 22542570456896 run_lib.py:133] step: 309050, training_loss: 2.22221e-02
I0209 19:10:31.973199 22542570456896 run_lib.py:133] step: 309100, training_loss: 2.85288e-02
I0209 19:10:32.128368 22542570456896 run_lib.py:146] step: 309100, eval_loss: 2.50107e-02
I0209 19:10:49.568376 22542570456896 run_lib.py:133] step: 309150, training_loss: 2.48790e-02
I0209 19:11:06.998661 22542570456896 run_lib.py:133] step: 309200, training_loss: 2.67857e-02
I0209 19:11:07.158574 22542570456896 run_lib.py:146] step: 309200, eval_loss: 2.40153e-02
I0209 19:11:24.683092 22542570456896 run_lib.py:133] step: 309250, training_loss: 3.34010e-02
I0209 19:11:42.134915 22542570456896 run_lib.py:133] step: 309300, training_loss: 2.76311e-02
I0209 19:11:42.295341 22542570456896 run_lib.py:146] step: 309300, eval_loss: 3.46336e-02
I0209 19:11:59.710825 22542570456896 run_lib.py:133] step: 309350, training_loss: 3.22895e-02
I0209 19:12:17.093176 22542570456896 run_lib.py:133] step: 309400, training_loss: 2.72407e-02
I0209 19:12:17.278347 22542570456896 run_lib.py:146] step: 309400, eval_loss: 2.48575e-02
I0209 19:12:34.886128 22542570456896 run_lib.py:133] step: 309450, training_loss: 2.93530e-02
I0209 19:12:52.467759 22542570456896 run_lib.py:133] step: 309500, training_loss: 3.24849e-02
I0209 19:12:52.624550 22542570456896 run_lib.py:146] step: 309500, eval_loss: 3.05327e-02
I0209 19:13:10.089721 22542570456896 run_lib.py:133] step: 309550, training_loss: 2.76186e-02
I0209 19:13:27.511406 22542570456896 run_lib.py:133] step: 309600, training_loss: 2.74230e-02
I0209 19:13:27.665340 22542570456896 run_lib.py:146] step: 309600, eval_loss: 2.57574e-02
I0209 19:13:45.218618 22542570456896 run_lib.py:133] step: 309650, training_loss: 3.10359e-02
I0209 19:14:02.665818 22542570456896 run_lib.py:133] step: 309700, training_loss: 2.23274e-02
I0209 19:14:02.820762 22542570456896 run_lib.py:146] step: 309700, eval_loss: 2.84565e-02
I0209 19:14:20.524558 22542570456896 run_lib.py:133] step: 309750, training_loss: 2.67268e-02
I0209 19:14:37.951066 22542570456896 run_lib.py:133] step: 309800, training_loss: 2.45414e-02
I0209 19:14:38.113279 22542570456896 run_lib.py:146] step: 309800, eval_loss: 3.20983e-02
I0209 19:14:55.645916 22542570456896 run_lib.py:133] step: 309850, training_loss: 3.06062e-02
I0209 19:15:13.052079 22542570456896 run_lib.py:133] step: 309900, training_loss: 2.60601e-02
I0209 19:15:13.209537 22542570456896 run_lib.py:146] step: 309900, eval_loss: 3.27643e-02
I0209 19:15:30.817822 22542570456896 run_lib.py:133] step: 309950, training_loss: 3.17616e-02
I0209 19:15:48.256987 22542570456896 run_lib.py:133] step: 310000, training_loss: 2.62348e-02
I0209 19:15:48.961477 22542570456896 run_lib.py:146] step: 310000, eval_loss: 2.42788e-02
I0209 19:16:09.034813 22542570456896 run_lib.py:133] step: 310050, training_loss: 2.48483e-02
I0209 19:16:26.615300 22542570456896 run_lib.py:133] step: 310100, training_loss: 3.11286e-02
I0209 19:16:26.771123 22542570456896 run_lib.py:146] step: 310100, eval_loss: 2.74566e-02
I0209 19:16:44.252157 22542570456896 run_lib.py:133] step: 310150, training_loss: 3.14841e-02
I0209 19:17:01.729168 22542570456896 run_lib.py:133] step: 310200, training_loss: 2.28086e-02
I0209 19:17:01.881084 22542570456896 run_lib.py:146] step: 310200, eval_loss: 2.81093e-02
I0209 19:17:19.266337 22542570456896 run_lib.py:133] step: 310250, training_loss: 2.48485e-02
I0209 19:17:36.746768 22542570456896 run_lib.py:133] step: 310300, training_loss: 2.44518e-02
I0209 19:17:36.912566 22542570456896 run_lib.py:146] step: 310300, eval_loss: 2.73993e-02
I0209 19:17:54.584439 22542570456896 run_lib.py:133] step: 310350, training_loss: 2.26428e-02
I0209 19:18:12.069656 22542570456896 run_lib.py:133] step: 310400, training_loss: 2.57058e-02
I0209 19:18:12.226661 22542570456896 run_lib.py:146] step: 310400, eval_loss: 3.57243e-02
I0209 19:18:29.616434 22542570456896 run_lib.py:133] step: 310450, training_loss: 2.90633e-02
I0209 19:18:46.996402 22542570456896 run_lib.py:133] step: 310500, training_loss: 2.08470e-02
I0209 19:18:47.156415 22542570456896 run_lib.py:146] step: 310500, eval_loss: 3.28634e-02
I0209 19:19:04.723089 22542570456896 run_lib.py:133] step: 310550, training_loss: 2.61069e-02
I0209 19:19:22.180105 22542570456896 run_lib.py:133] step: 310600, training_loss: 3.24572e-02
I0209 19:19:22.344380 22542570456896 run_lib.py:146] step: 310600, eval_loss: 2.86242e-02
I0209 19:19:39.958019 22542570456896 run_lib.py:133] step: 310650, training_loss: 2.67718e-02
I0209 19:19:57.393465 22542570456896 run_lib.py:133] step: 310700, training_loss: 3.24955e-02
I0209 19:19:57.545286 22542570456896 run_lib.py:146] step: 310700, eval_loss: 3.04586e-02
I0209 19:20:15.086265 22542570456896 run_lib.py:133] step: 310750, training_loss: 3.62889e-02
I0209 19:20:32.555761 22542570456896 run_lib.py:133] step: 310800, training_loss: 2.75819e-02
I0209 19:20:32.731255 22542570456896 run_lib.py:146] step: 310800, eval_loss: 3.85541e-02
I0209 19:20:50.159560 22542570456896 run_lib.py:133] step: 310850, training_loss: 2.47334e-02
I0209 19:21:07.787160 22542570456896 run_lib.py:133] step: 310900, training_loss: 1.96717e-02
I0209 19:21:07.953397 22542570456896 run_lib.py:146] step: 310900, eval_loss: 2.12434e-02
I0209 19:21:25.379264 22542570456896 run_lib.py:133] step: 310950, training_loss: 2.74767e-02
I0209 19:21:42.913249 22542570456896 run_lib.py:133] step: 311000, training_loss: 2.85045e-02
I0209 19:21:43.068356 22542570456896 run_lib.py:146] step: 311000, eval_loss: 2.57607e-02
I0209 19:22:00.474849 22542570456896 run_lib.py:133] step: 311050, training_loss: 3.28736e-02
I0209 19:22:17.945574 22542570456896 run_lib.py:133] step: 311100, training_loss: 2.57249e-02
I0209 19:22:18.101594 22542570456896 run_lib.py:146] step: 311100, eval_loss: 3.31429e-02
I0209 19:22:35.731155 22542570456896 run_lib.py:133] step: 311150, training_loss: 2.53310e-02
I0209 19:22:53.242273 22542570456896 run_lib.py:133] step: 311200, training_loss: 2.58653e-02
I0209 19:22:53.396327 22542570456896 run_lib.py:146] step: 311200, eval_loss: 3.00811e-02
I0209 19:23:10.776136 22542570456896 run_lib.py:133] step: 311250, training_loss: 3.03609e-02
I0209 19:23:28.369150 22542570456896 run_lib.py:133] step: 311300, training_loss: 2.29422e-02
I0209 19:23:28.539853 22542570456896 run_lib.py:146] step: 311300, eval_loss: 2.74410e-02
I0209 19:23:46.015266 22542570456896 run_lib.py:133] step: 311350, training_loss: 2.68948e-02
I0209 19:24:03.481654 22542570456896 run_lib.py:133] step: 311400, training_loss: 2.90307e-02
I0209 19:24:03.637334 22542570456896 run_lib.py:146] step: 311400, eval_loss: 3.12487e-02
I0209 19:24:21.133133 22542570456896 run_lib.py:133] step: 311450, training_loss: 2.59865e-02
I0209 19:24:38.601771 22542570456896 run_lib.py:133] step: 311500, training_loss: 3.10681e-02
I0209 19:24:38.756413 22542570456896 run_lib.py:146] step: 311500, eval_loss: 3.72750e-02
I0209 19:24:56.193075 22542570456896 run_lib.py:133] step: 311550, training_loss: 2.61584e-02
I0209 19:25:13.654001 22542570456896 run_lib.py:133] step: 311600, training_loss: 3.10603e-02
I0209 19:25:13.808482 22542570456896 run_lib.py:146] step: 311600, eval_loss: 2.92017e-02
I0209 19:25:31.389431 22542570456896 run_lib.py:133] step: 311650, training_loss: 2.37568e-02
I0209 19:25:48.950704 22542570456896 run_lib.py:133] step: 311700, training_loss: 2.84332e-02
I0209 19:25:49.108153 22542570456896 run_lib.py:146] step: 311700, eval_loss: 2.50964e-02
I0209 19:26:06.528520 22542570456896 run_lib.py:133] step: 311750, training_loss: 2.39894e-02
I0209 19:26:23.952795 22542570456896 run_lib.py:133] step: 311800, training_loss: 2.51262e-02
I0209 19:26:24.120645 22542570456896 run_lib.py:146] step: 311800, eval_loss: 2.97829e-02
I0209 19:26:41.663995 22542570456896 run_lib.py:133] step: 311850, training_loss: 3.51630e-02
I0209 19:26:59.100454 22542570456896 run_lib.py:133] step: 311900, training_loss: 2.90370e-02
I0209 19:26:59.267699 22542570456896 run_lib.py:146] step: 311900, eval_loss: 2.45491e-02
I0209 19:27:16.884723 22542570456896 run_lib.py:133] step: 311950, training_loss: 2.59353e-02
I0209 19:27:34.269143 22542570456896 run_lib.py:133] step: 312000, training_loss: 2.59393e-02
I0209 19:27:34.425067 22542570456896 run_lib.py:146] step: 312000, eval_loss: 2.66927e-02
I0209 19:27:52.028706 22542570456896 run_lib.py:133] step: 312050, training_loss: 2.64602e-02
I0209 19:28:09.435384 22542570456896 run_lib.py:133] step: 312100, training_loss: 3.23380e-02
I0209 19:28:09.593428 22542570456896 run_lib.py:146] step: 312100, eval_loss: 2.72357e-02
I0209 19:28:27.175846 22542570456896 run_lib.py:133] step: 312150, training_loss: 3.47358e-02
I0209 19:28:44.657121 22542570456896 run_lib.py:133] step: 312200, training_loss: 2.36212e-02
I0209 19:28:44.819654 22542570456896 run_lib.py:146] step: 312200, eval_loss: 2.63730e-02
I0209 19:29:02.280952 22542570456896 run_lib.py:133] step: 312250, training_loss: 2.72995e-02
I0209 19:29:19.923886 22542570456896 run_lib.py:133] step: 312300, training_loss: 3.03833e-02
I0209 19:29:20.090378 22542570456896 run_lib.py:146] step: 312300, eval_loss: 3.24507e-02
I0209 19:29:37.475702 22542570456896 run_lib.py:133] step: 312350, training_loss: 2.19863e-02
I0209 19:29:54.911381 22542570456896 run_lib.py:133] step: 312400, training_loss: 2.90552e-02
I0209 19:29:55.080404 22542570456896 run_lib.py:146] step: 312400, eval_loss: 2.09998e-02
I0209 19:30:12.725847 22542570456896 run_lib.py:133] step: 312450, training_loss: 2.69599e-02
I0209 19:30:30.254465 22542570456896 run_lib.py:133] step: 312500, training_loss: 2.45337e-02
I0209 19:30:30.411225 22542570456896 run_lib.py:146] step: 312500, eval_loss: 3.71824e-02
I0209 19:30:48.034052 22542570456896 run_lib.py:133] step: 312550, training_loss: 2.33705e-02
I0209 19:31:05.419589 22542570456896 run_lib.py:133] step: 312600, training_loss: 2.59112e-02
I0209 19:31:05.573364 22542570456896 run_lib.py:146] step: 312600, eval_loss: 3.07384e-02
I0209 19:31:22.994345 22542570456896 run_lib.py:133] step: 312650, training_loss: 2.39818e-02
I0209 19:31:40.562404 22542570456896 run_lib.py:133] step: 312700, training_loss: 2.93880e-02
I0209 19:31:40.731619 22542570456896 run_lib.py:146] step: 312700, eval_loss: 2.52049e-02
I0209 19:31:58.225060 22542570456896 run_lib.py:133] step: 312750, training_loss: 2.87763e-02
I0209 19:32:15.667816 22542570456896 run_lib.py:133] step: 312800, training_loss: 3.52960e-02
I0209 19:32:15.833327 22542570456896 run_lib.py:146] step: 312800, eval_loss: 3.09713e-02
I0209 19:32:33.263293 22542570456896 run_lib.py:133] step: 312850, training_loss: 2.90788e-02
I0209 19:32:50.843698 22542570456896 run_lib.py:133] step: 312900, training_loss: 2.58515e-02
I0209 19:32:50.999429 22542570456896 run_lib.py:146] step: 312900, eval_loss: 3.69220e-02
I0209 19:33:08.423337 22542570456896 run_lib.py:133] step: 312950, training_loss: 2.41656e-02
I0209 19:33:25.938756 22542570456896 run_lib.py:133] step: 313000, training_loss: 2.72732e-02
I0209 19:33:26.093666 22542570456896 run_lib.py:146] step: 313000, eval_loss: 2.49734e-02
I0209 19:33:43.625864 22542570456896 run_lib.py:133] step: 313050, training_loss: 2.57876e-02
I0209 19:34:01.002631 22542570456896 run_lib.py:133] step: 313100, training_loss: 2.28276e-02
I0209 19:34:01.155839 22542570456896 run_lib.py:146] step: 313100, eval_loss: 2.65471e-02
I0209 19:34:18.764250 22542570456896 run_lib.py:133] step: 313150, training_loss: 2.84845e-02
I0209 19:34:36.251802 22542570456896 run_lib.py:133] step: 313200, training_loss: 3.26907e-02
I0209 19:34:36.410606 22542570456896 run_lib.py:146] step: 313200, eval_loss: 2.97119e-02
I0209 19:34:53.851269 22542570456896 run_lib.py:133] step: 313250, training_loss: 2.73513e-02
I0209 19:35:11.294261 22542570456896 run_lib.py:133] step: 313300, training_loss: 3.51438e-02
I0209 19:35:11.453318 22542570456896 run_lib.py:146] step: 313300, eval_loss: 3.33624e-02
I0209 19:35:29.052334 22542570456896 run_lib.py:133] step: 313350, training_loss: 2.92543e-02
I0209 19:35:46.470561 22542570456896 run_lib.py:133] step: 313400, training_loss: 3.04631e-02
I0209 19:35:46.626206 22542570456896 run_lib.py:146] step: 313400, eval_loss: 3.63520e-02
I0209 19:36:04.260097 22542570456896 run_lib.py:133] step: 313450, training_loss: 2.36058e-02
I0209 19:36:21.680490 22542570456896 run_lib.py:133] step: 313500, training_loss: 2.35961e-02
I0209 19:36:21.834126 22542570456896 run_lib.py:146] step: 313500, eval_loss: 2.85096e-02
I0209 19:36:39.397918 22542570456896 run_lib.py:133] step: 313550, training_loss: 3.11618e-02
I0209 19:36:56.827792 22542570456896 run_lib.py:133] step: 313600, training_loss: 2.31879e-02
I0209 19:36:56.984625 22542570456896 run_lib.py:146] step: 313600, eval_loss: 3.21763e-02
I0209 19:37:14.466731 22542570456896 run_lib.py:133] step: 313650, training_loss: 2.72466e-02
I0209 19:37:32.077440 22542570456896 run_lib.py:133] step: 313700, training_loss: 3.09518e-02
I0209 19:37:32.241509 22542570456896 run_lib.py:146] step: 313700, eval_loss: 2.74634e-02
I0209 19:37:49.664882 22542570456896 run_lib.py:133] step: 313750, training_loss: 2.56731e-02
I0209 19:38:07.224819 22542570456896 run_lib.py:133] step: 313800, training_loss: 3.60555e-02
I0209 19:38:07.380960 22542570456896 run_lib.py:146] step: 313800, eval_loss: 2.72459e-02
I0209 19:38:24.839650 22542570456896 run_lib.py:133] step: 313850, training_loss: 2.72375e-02
I0209 19:38:42.312831 22542570456896 run_lib.py:133] step: 313900, training_loss: 2.99731e-02
I0209 19:38:42.469804 22542570456896 run_lib.py:146] step: 313900, eval_loss: 2.65310e-02
I0209 19:39:00.086800 22542570456896 run_lib.py:133] step: 313950, training_loss: 2.55336e-02
I0209 19:39:17.538229 22542570456896 run_lib.py:133] step: 314000, training_loss: 1.92685e-02
I0209 19:39:17.690448 22542570456896 run_lib.py:146] step: 314000, eval_loss: 2.88377e-02
I0209 19:39:35.134909 22542570456896 run_lib.py:133] step: 314050, training_loss: 3.87060e-02
I0209 19:39:52.811191 22542570456896 run_lib.py:133] step: 314100, training_loss: 2.74787e-02
I0209 19:39:52.975497 22542570456896 run_lib.py:146] step: 314100, eval_loss: 3.03988e-02
I0209 19:40:10.449502 22542570456896 run_lib.py:133] step: 314150, training_loss: 3.22654e-02
I0209 19:40:27.852053 22542570456896 run_lib.py:133] step: 314200, training_loss: 3.65874e-02
I0209 19:40:28.196241 22542570456896 run_lib.py:146] step: 314200, eval_loss: 3.31225e-02
I0209 19:40:45.626244 22542570456896 run_lib.py:133] step: 314250, training_loss: 3.31119e-02
I0209 19:41:03.044031 22542570456896 run_lib.py:133] step: 314300, training_loss: 3.37518e-02
I0209 19:41:03.198499 22542570456896 run_lib.py:146] step: 314300, eval_loss: 2.83645e-02
I0209 19:41:20.609528 22542570456896 run_lib.py:133] step: 314350, training_loss: 2.78417e-02
I0209 19:41:38.052251 22542570456896 run_lib.py:133] step: 314400, training_loss: 2.84251e-02
I0209 19:41:38.207579 22542570456896 run_lib.py:146] step: 314400, eval_loss: 2.17142e-02
I0209 19:41:55.862938 22542570456896 run_lib.py:133] step: 314450, training_loss: 3.04736e-02
I0209 19:42:13.395308 22542570456896 run_lib.py:133] step: 314500, training_loss: 2.23859e-02
I0209 19:42:13.544560 22542570456896 run_lib.py:146] step: 314500, eval_loss: 3.17783e-02
I0209 19:42:30.957824 22542570456896 run_lib.py:133] step: 314550, training_loss: 2.77177e-02
I0209 19:42:48.393080 22542570456896 run_lib.py:133] step: 314600, training_loss: 2.49749e-02
I0209 19:42:48.548459 22542570456896 run_lib.py:146] step: 314600, eval_loss: 3.59583e-02
I0209 19:43:06.141165 22542570456896 run_lib.py:133] step: 314650, training_loss: 2.57853e-02
I0209 19:43:23.714343 22542570456896 run_lib.py:133] step: 314700, training_loss: 2.53272e-02
I0209 19:43:23.873328 22542570456896 run_lib.py:146] step: 314700, eval_loss: 2.32322e-02
I0209 19:43:41.278565 22542570456896 run_lib.py:133] step: 314750, training_loss: 2.03371e-02
I0209 19:43:58.698788 22542570456896 run_lib.py:133] step: 314800, training_loss: 3.13649e-02
I0209 19:43:58.854070 22542570456896 run_lib.py:146] step: 314800, eval_loss: 3.26492e-02
I0209 19:44:16.451733 22542570456896 run_lib.py:133] step: 314850, training_loss: 2.81864e-02
I0209 19:44:33.868412 22542570456896 run_lib.py:133] step: 314900, training_loss: 2.35141e-02
I0209 19:44:34.023443 22542570456896 run_lib.py:146] step: 314900, eval_loss: 3.01028e-02
I0209 19:44:51.649460 22542570456896 run_lib.py:133] step: 314950, training_loss: 2.86267e-02
I0209 19:45:09.141802 22542570456896 run_lib.py:133] step: 315000, training_loss: 2.18859e-02
I0209 19:45:09.296401 22542570456896 run_lib.py:146] step: 315000, eval_loss: 2.78847e-02
I0209 19:45:26.910883 22542570456896 run_lib.py:133] step: 315050, training_loss: 2.70768e-02
I0209 19:45:44.368372 22542570456896 run_lib.py:133] step: 315100, training_loss: 2.44660e-02
I0209 19:45:44.525820 22542570456896 run_lib.py:146] step: 315100, eval_loss: 2.58572e-02
I0209 19:46:01.924541 22542570456896 run_lib.py:133] step: 315150, training_loss: 2.28180e-02
I0209 19:46:19.520077 22542570456896 run_lib.py:133] step: 315200, training_loss: 2.79823e-02
I0209 19:46:19.677143 22542570456896 run_lib.py:146] step: 315200, eval_loss: 2.67052e-02
I0209 19:46:37.123880 22542570456896 run_lib.py:133] step: 315250, training_loss: 2.61482e-02
I0209 19:46:54.753541 22542570456896 run_lib.py:133] step: 315300, training_loss: 2.68381e-02
I0209 19:46:54.912131 22542570456896 run_lib.py:146] step: 315300, eval_loss: 2.68336e-02
I0209 19:47:12.338416 22542570456896 run_lib.py:133] step: 315350, training_loss: 2.85028e-02
I0209 19:47:29.732765 22542570456896 run_lib.py:133] step: 315400, training_loss: 3.28631e-02
I0209 19:47:29.883338 22542570456896 run_lib.py:146] step: 315400, eval_loss: 2.42718e-02
I0209 19:47:47.438190 22542570456896 run_lib.py:133] step: 315450, training_loss: 3.10077e-02
I0209 19:48:04.904710 22542570456896 run_lib.py:133] step: 315500, training_loss: 2.72619e-02
I0209 19:48:05.060523 22542570456896 run_lib.py:146] step: 315500, eval_loss: 3.14537e-02
I0209 19:48:22.577780 22542570456896 run_lib.py:133] step: 315550, training_loss: 2.11677e-02
I0209 19:48:40.046696 22542570456896 run_lib.py:133] step: 315600, training_loss: 2.77485e-02
I0209 19:48:40.205971 22542570456896 run_lib.py:146] step: 315600, eval_loss: 2.63044e-02
I0209 19:48:57.828262 22542570456896 run_lib.py:133] step: 315650, training_loss: 2.48423e-02
I0209 19:49:15.241124 22542570456896 run_lib.py:133] step: 315700, training_loss: 2.77443e-02
I0209 19:49:15.396397 22542570456896 run_lib.py:146] step: 315700, eval_loss: 3.79967e-02
I0209 19:49:32.868106 22542570456896 run_lib.py:133] step: 315750, training_loss: 2.79929e-02
I0209 19:49:50.303761 22542570456896 run_lib.py:133] step: 315800, training_loss: 2.89848e-02
I0209 19:49:50.463328 22542570456896 run_lib.py:146] step: 315800, eval_loss: 2.53322e-02
I0209 19:50:07.901095 22542570456896 run_lib.py:133] step: 315850, training_loss: 3.06220e-02
I0209 19:50:25.341511 22542570456896 run_lib.py:133] step: 315900, training_loss: 2.76424e-02
I0209 19:50:25.492726 22542570456896 run_lib.py:146] step: 315900, eval_loss: 2.39615e-02
I0209 19:50:43.102977 22542570456896 run_lib.py:133] step: 315950, training_loss: 3.39347e-02
I0209 19:51:00.623914 22542570456896 run_lib.py:133] step: 316000, training_loss: 2.72994e-02
I0209 19:51:00.779315 22542570456896 run_lib.py:146] step: 316000, eval_loss: 2.88908e-02
I0209 19:51:18.195152 22542570456896 run_lib.py:133] step: 316050, training_loss: 3.10259e-02
I0209 19:51:35.622813 22542570456896 run_lib.py:133] step: 316100, training_loss: 3.31286e-02
I0209 19:51:35.791409 22542570456896 run_lib.py:146] step: 316100, eval_loss: 2.93505e-02
I0209 19:51:53.425937 22542570456896 run_lib.py:133] step: 316150, training_loss: 2.34827e-02
I0209 19:52:10.882884 22542570456896 run_lib.py:133] step: 316200, training_loss: 2.67254e-02
I0209 19:52:11.042566 22542570456896 run_lib.py:146] step: 316200, eval_loss: 2.80665e-02
I0209 19:52:28.671708 22542570456896 run_lib.py:133] step: 316250, training_loss: 3.23690e-02
I0209 19:52:46.101673 22542570456896 run_lib.py:133] step: 316300, training_loss: 2.17879e-02
I0209 19:52:46.257457 22542570456896 run_lib.py:146] step: 316300, eval_loss: 2.50334e-02
I0209 19:53:03.830746 22542570456896 run_lib.py:133] step: 316350, training_loss: 2.31403e-02
I0209 19:53:21.287455 22542570456896 run_lib.py:133] step: 316400, training_loss: 3.63732e-02
I0209 19:53:21.441495 22542570456896 run_lib.py:146] step: 316400, eval_loss: 2.90431e-02
I0209 19:53:39.092026 22542570456896 run_lib.py:133] step: 316450, training_loss: 2.50869e-02
I0209 19:53:56.489198 22542570456896 run_lib.py:133] step: 316500, training_loss: 2.85180e-02
I0209 19:53:56.644320 22542570456896 run_lib.py:146] step: 316500, eval_loss: 2.63257e-02
I0209 19:54:14.076717 22542570456896 run_lib.py:133] step: 316550, training_loss: 2.85607e-02
I0209 19:54:31.656941 22542570456896 run_lib.py:133] step: 316600, training_loss: 2.67440e-02
I0209 19:54:31.814675 22542570456896 run_lib.py:146] step: 316600, eval_loss: 2.79278e-02
I0209 19:54:49.220516 22542570456896 run_lib.py:133] step: 316650, training_loss: 3.17598e-02
I0209 19:55:06.634446 22542570456896 run_lib.py:133] step: 316700, training_loss: 2.98217e-02
I0209 19:55:06.792355 22542570456896 run_lib.py:146] step: 316700, eval_loss: 2.74411e-02
I0209 19:55:24.435223 22542570456896 run_lib.py:133] step: 316750, training_loss: 2.28238e-02
I0209 19:55:42.018215 22542570456896 run_lib.py:133] step: 316800, training_loss: 2.89288e-02
I0209 19:55:42.173041 22542570456896 run_lib.py:146] step: 316800, eval_loss: 2.46971e-02
I0209 19:55:59.605182 22542570456896 run_lib.py:133] step: 316850, training_loss: 2.31312e-02
I0209 19:56:17.027123 22542570456896 run_lib.py:133] step: 316900, training_loss: 2.24352e-02
I0209 19:56:17.174629 22542570456896 run_lib.py:146] step: 316900, eval_loss: 2.62047e-02
I0209 19:56:34.617660 22542570456896 run_lib.py:133] step: 316950, training_loss: 2.70683e-02
I0209 19:56:52.215390 22542570456896 run_lib.py:133] step: 317000, training_loss: 2.74139e-02
I0209 19:56:52.399434 22542570456896 run_lib.py:146] step: 317000, eval_loss: 3.19672e-02
I0209 19:57:09.873591 22542570456896 run_lib.py:133] step: 317050, training_loss: 3.06668e-02
I0209 19:57:27.336738 22542570456896 run_lib.py:133] step: 317100, training_loss: 2.74216e-02
I0209 19:57:27.492523 22542570456896 run_lib.py:146] step: 317100, eval_loss: 2.58201e-02
I0209 19:57:44.938480 22542570456896 run_lib.py:133] step: 317150, training_loss: 2.87845e-02
I0209 19:58:02.547040 22542570456896 run_lib.py:133] step: 317200, training_loss: 3.11244e-02
I0209 19:58:02.721953 22542570456896 run_lib.py:146] step: 317200, eval_loss: 2.72464e-02
I0209 19:58:20.169883 22542570456896 run_lib.py:133] step: 317250, training_loss: 2.90912e-02
I0209 19:58:37.702604 22542570456896 run_lib.py:133] step: 317300, training_loss: 1.95731e-02
I0209 19:58:37.854489 22542570456896 run_lib.py:146] step: 317300, eval_loss: 3.72242e-02
I0209 19:58:55.294295 22542570456896 run_lib.py:133] step: 317350, training_loss: 2.97196e-02
I0209 19:59:12.702480 22542570456896 run_lib.py:133] step: 317400, training_loss: 2.96339e-02
I0209 19:59:12.856461 22542570456896 run_lib.py:146] step: 317400, eval_loss: 2.06290e-02
I0209 19:59:30.396424 22542570456896 run_lib.py:133] step: 317450, training_loss: 2.61405e-02
I0209 19:59:47.765059 22542570456896 run_lib.py:133] step: 317500, training_loss: 2.35866e-02
I0209 19:59:47.940164 22542570456896 run_lib.py:146] step: 317500, eval_loss: 2.95371e-02
I0209 20:00:05.320385 22542570456896 run_lib.py:133] step: 317550, training_loss: 2.59973e-02
I0209 20:00:22.628169 22542570456896 run_lib.py:133] step: 317600, training_loss: 3.22966e-02
I0209 20:00:22.782367 22542570456896 run_lib.py:146] step: 317600, eval_loss: 3.08400e-02
I0209 20:00:40.289606 22542570456896 run_lib.py:133] step: 317650, training_loss: 2.70447e-02
I0209 20:00:57.695949 22542570456896 run_lib.py:133] step: 317700, training_loss: 2.79103e-02
I0209 20:00:57.852546 22542570456896 run_lib.py:146] step: 317700, eval_loss: 3.46500e-02
I0209 20:01:15.401756 22542570456896 run_lib.py:133] step: 317750, training_loss: 2.73796e-02
I0209 20:01:32.851757 22542570456896 run_lib.py:133] step: 317800, training_loss: 2.27674e-02
I0209 20:01:33.005140 22542570456896 run_lib.py:146] step: 317800, eval_loss: 2.32485e-02
I0209 20:01:50.682796 22542570456896 run_lib.py:133] step: 317850, training_loss: 3.39609e-02
I0209 20:02:08.115732 22542570456896 run_lib.py:133] step: 317900, training_loss: 2.64466e-02
I0209 20:02:08.276318 22542570456896 run_lib.py:146] step: 317900, eval_loss: 3.06664e-02
I0209 20:02:25.688901 22542570456896 run_lib.py:133] step: 317950, training_loss: 2.62968e-02
I0209 20:02:43.227835 22542570456896 run_lib.py:133] step: 318000, training_loss: 3.05438e-02
I0209 20:02:43.386676 22542570456896 run_lib.py:146] step: 318000, eval_loss: 2.18526e-02
I0209 20:03:00.837897 22542570456896 run_lib.py:133] step: 318050, training_loss: 2.88438e-02
I0209 20:03:18.423881 22542570456896 run_lib.py:133] step: 318100, training_loss: 2.57705e-02
I0209 20:03:18.580598 22542570456896 run_lib.py:146] step: 318100, eval_loss: 2.55776e-02
I0209 20:03:36.025898 22542570456896 run_lib.py:133] step: 318150, training_loss: 3.34812e-02
I0209 20:03:53.426587 22542570456896 run_lib.py:133] step: 318200, training_loss: 2.26275e-02
I0209 20:03:53.582336 22542570456896 run_lib.py:146] step: 318200, eval_loss: 3.50326e-02
I0209 20:04:11.208108 22542570456896 run_lib.py:133] step: 318250, training_loss: 3.80960e-02
I0209 20:04:28.647104 22542570456896 run_lib.py:133] step: 318300, training_loss: 2.42798e-02
I0209 20:04:28.805340 22542570456896 run_lib.py:146] step: 318300, eval_loss: 2.73821e-02
I0209 20:04:46.229370 22542570456896 run_lib.py:133] step: 318350, training_loss: 2.69028e-02
I0209 20:05:03.828469 22542570456896 run_lib.py:133] step: 318400, training_loss: 3.87124e-02
I0209 20:05:03.998585 22542570456896 run_lib.py:146] step: 318400, eval_loss: 3.40285e-02
I0209 20:05:21.419703 22542570456896 run_lib.py:133] step: 318450, training_loss: 2.67561e-02
I0209 20:05:38.858093 22542570456896 run_lib.py:133] step: 318500, training_loss: 2.47833e-02
I0209 20:05:39.017571 22542570456896 run_lib.py:146] step: 318500, eval_loss: 2.51138e-02
I0209 20:05:56.508400 22542570456896 run_lib.py:133] step: 318550, training_loss: 3.61675e-02
I0209 20:06:13.919860 22542570456896 run_lib.py:133] step: 318600, training_loss: 2.19852e-02
I0209 20:06:14.077021 22542570456896 run_lib.py:146] step: 318600, eval_loss: 3.17986e-02
I0209 20:06:31.468846 22542570456896 run_lib.py:133] step: 318650, training_loss: 2.80540e-02
I0209 20:06:48.923161 22542570456896 run_lib.py:133] step: 318700, training_loss: 2.54263e-02
I0209 20:06:49.080643 22542570456896 run_lib.py:146] step: 318700, eval_loss: 2.58633e-02
I0209 20:07:06.734648 22542570456896 run_lib.py:133] step: 318750, training_loss: 2.46902e-02
I0209 20:07:24.186403 22542570456896 run_lib.py:133] step: 318800, training_loss: 2.71323e-02
I0209 20:07:24.346388 22542570456896 run_lib.py:146] step: 318800, eval_loss: 2.56766e-02
I0209 20:07:41.775329 22542570456896 run_lib.py:133] step: 318850, training_loss: 2.72850e-02
I0209 20:07:59.227420 22542570456896 run_lib.py:133] step: 318900, training_loss: 2.72036e-02
I0209 20:07:59.400374 22542570456896 run_lib.py:146] step: 318900, eval_loss: 2.57691e-02
I0209 20:08:17.000399 22542570456896 run_lib.py:133] step: 318950, training_loss: 2.39009e-02
I0209 20:08:34.463480 22542570456896 run_lib.py:133] step: 319000, training_loss: 2.43852e-02
I0209 20:08:34.619618 22542570456896 run_lib.py:146] step: 319000, eval_loss: 2.87163e-02
I0209 20:08:52.231026 22542570456896 run_lib.py:133] step: 319050, training_loss: 2.85579e-02
I0209 20:09:09.649800 22542570456896 run_lib.py:133] step: 319100, training_loss: 2.34168e-02
I0209 20:09:09.804405 22542570456896 run_lib.py:146] step: 319100, eval_loss: 2.84981e-02
I0209 20:09:27.353731 22542570456896 run_lib.py:133] step: 319150, training_loss: 2.82819e-02
I0209 20:09:44.814528 22542570456896 run_lib.py:133] step: 319200, training_loss: 2.60746e-02
I0209 20:09:44.968241 22542570456896 run_lib.py:146] step: 319200, eval_loss: 3.42288e-02
I0209 20:10:02.611170 22542570456896 run_lib.py:133] step: 319250, training_loss: 2.38304e-02
I0209 20:10:20.056429 22542570456896 run_lib.py:133] step: 319300, training_loss: 2.47831e-02
I0209 20:10:20.211511 22542570456896 run_lib.py:146] step: 319300, eval_loss: 3.19102e-02
I0209 20:10:37.634387 22542570456896 run_lib.py:133] step: 319350, training_loss: 2.83777e-02
I0209 20:10:55.202962 22542570456896 run_lib.py:133] step: 319400, training_loss: 3.07542e-02
I0209 20:10:55.361636 22542570456896 run_lib.py:146] step: 319400, eval_loss: 2.77974e-02
I0209 20:11:12.771128 22542570456896 run_lib.py:133] step: 319450, training_loss: 2.59766e-02
I0209 20:11:30.230464 22542570456896 run_lib.py:133] step: 319500, training_loss: 2.66623e-02
I0209 20:11:30.386595 22542570456896 run_lib.py:146] step: 319500, eval_loss: 3.69801e-02
I0209 20:11:47.987898 22542570456896 run_lib.py:133] step: 319550, training_loss: 2.76385e-02
I0209 20:12:05.463148 22542570456896 run_lib.py:133] step: 319600, training_loss: 2.32666e-02
I0209 20:12:05.619470 22542570456896 run_lib.py:146] step: 319600, eval_loss: 3.50855e-02
I0209 20:12:23.199870 22542570456896 run_lib.py:133] step: 319650, training_loss: 2.87077e-02
I0209 20:12:40.612782 22542570456896 run_lib.py:133] step: 319700, training_loss: 3.33589e-02
I0209 20:12:40.764492 22542570456896 run_lib.py:146] step: 319700, eval_loss: 2.53346e-02
I0209 20:12:58.175942 22542570456896 run_lib.py:133] step: 319750, training_loss: 2.74611e-02
I0209 20:13:15.796277 22542570456896 run_lib.py:133] step: 319800, training_loss: 3.30933e-02
I0209 20:13:15.973262 22542570456896 run_lib.py:146] step: 319800, eval_loss: 3.37698e-02
I0209 20:13:33.446320 22542570456896 run_lib.py:133] step: 319850, training_loss: 3.06351e-02
I0209 20:13:50.961480 22542570456896 run_lib.py:133] step: 319900, training_loss: 2.78159e-02
I0209 20:13:51.119834 22542570456896 run_lib.py:146] step: 319900, eval_loss: 2.97932e-02
I0209 20:14:08.522924 22542570456896 run_lib.py:133] step: 319950, training_loss: 2.40017e-02
I0209 20:14:26.097422 22542570456896 run_lib.py:133] step: 320000, training_loss: 3.06816e-02
I0209 20:14:26.820158 22542570456896 run_lib.py:146] step: 320000, eval_loss: 3.20481e-02
I0209 20:14:47.091994 22542570456896 run_lib.py:133] step: 320050, training_loss: 3.08651e-02
I0209 20:15:04.758107 22542570456896 run_lib.py:133] step: 320100, training_loss: 2.96500e-02
I0209 20:15:04.916613 22542570456896 run_lib.py:146] step: 320100, eval_loss: 2.61748e-02
I0209 20:15:22.322306 22542570456896 run_lib.py:133] step: 320150, training_loss: 3.01902e-02
I0209 20:15:39.730757 22542570456896 run_lib.py:133] step: 320200, training_loss: 2.80457e-02
I0209 20:15:39.886392 22542570456896 run_lib.py:146] step: 320200, eval_loss: 2.47119e-02
I0209 20:15:57.312392 22542570456896 run_lib.py:133] step: 320250, training_loss: 3.14968e-02
I0209 20:16:14.966174 22542570456896 run_lib.py:133] step: 320300, training_loss: 2.79018e-02
I0209 20:16:15.120254 22542570456896 run_lib.py:146] step: 320300, eval_loss: 3.17471e-02
I0209 20:16:32.694238 22542570456896 run_lib.py:133] step: 320350, training_loss: 2.48760e-02
I0209 20:16:50.114468 22542570456896 run_lib.py:133] step: 320400, training_loss: 3.52463e-02
I0209 20:16:50.271486 22542570456896 run_lib.py:146] step: 320400, eval_loss: 3.06057e-02
I0209 20:17:07.683901 22542570456896 run_lib.py:133] step: 320450, training_loss: 2.87288e-02
I0209 20:17:25.167753 22542570456896 run_lib.py:133] step: 320500, training_loss: 2.94327e-02
I0209 20:17:25.322222 22542570456896 run_lib.py:146] step: 320500, eval_loss: 2.79190e-02
I0209 20:17:42.894271 22542570456896 run_lib.py:133] step: 320550, training_loss: 3.20147e-02
I0209 20:18:00.417874 22542570456896 run_lib.py:133] step: 320600, training_loss: 3.05522e-02
I0209 20:18:00.583993 22542570456896 run_lib.py:146] step: 320600, eval_loss: 3.35159e-02
I0209 20:18:18.001394 22542570456896 run_lib.py:133] step: 320650, training_loss: 2.89044e-02
I0209 20:18:35.397545 22542570456896 run_lib.py:133] step: 320700, training_loss: 2.32896e-02
I0209 20:18:35.554066 22542570456896 run_lib.py:146] step: 320700, eval_loss: 3.27315e-02
I0209 20:18:53.159348 22542570456896 run_lib.py:133] step: 320750, training_loss: 3.12860e-02
I0209 20:19:10.577993 22542570456896 run_lib.py:133] step: 320800, training_loss: 3.50231e-02
I0209 20:19:10.740339 22542570456896 run_lib.py:146] step: 320800, eval_loss: 3.26521e-02
I0209 20:19:28.321987 22542570456896 run_lib.py:133] step: 320850, training_loss: 2.93762e-02
I0209 20:19:45.797145 22542570456896 run_lib.py:133] step: 320900, training_loss: 3.22241e-02
I0209 20:19:45.957458 22542570456896 run_lib.py:146] step: 320900, eval_loss: 2.76070e-02
I0209 20:20:03.554035 22542570456896 run_lib.py:133] step: 320950, training_loss: 2.90504e-02
I0209 20:20:20.942534 22542570456896 run_lib.py:133] step: 321000, training_loss: 2.79120e-02
I0209 20:20:21.097487 22542570456896 run_lib.py:146] step: 321000, eval_loss: 4.13366e-02
I0209 20:20:38.512788 22542570456896 run_lib.py:133] step: 321050, training_loss: 2.63280e-02
I0209 20:20:56.101515 22542570456896 run_lib.py:133] step: 321100, training_loss: 2.87356e-02
I0209 20:20:56.263533 22542570456896 run_lib.py:146] step: 321100, eval_loss: 3.22797e-02
I0209 20:21:13.725239 22542570456896 run_lib.py:133] step: 321150, training_loss: 2.60268e-02
I0209 20:21:31.331331 22542570456896 run_lib.py:133] step: 321200, training_loss: 2.34296e-02
I0209 20:21:31.482324 22542570456896 run_lib.py:146] step: 321200, eval_loss: 2.47076e-02
I0209 20:21:48.904378 22542570456896 run_lib.py:133] step: 321250, training_loss: 2.58738e-02
I0209 20:22:06.372787 22542570456896 run_lib.py:133] step: 321300, training_loss: 2.61073e-02
I0209 20:22:06.527438 22542570456896 run_lib.py:146] step: 321300, eval_loss: 2.65171e-02
I0209 20:22:24.066949 22542570456896 run_lib.py:133] step: 321350, training_loss: 2.92737e-02
I0209 20:22:41.534615 22542570456896 run_lib.py:133] step: 321400, training_loss: 2.36030e-02
I0209 20:22:41.715732 22542570456896 run_lib.py:146] step: 321400, eval_loss: 2.75893e-02
I0209 20:22:59.179045 22542570456896 run_lib.py:133] step: 321450, training_loss: 3.12983e-02
I0209 20:23:16.771712 22542570456896 run_lib.py:133] step: 321500, training_loss: 2.61273e-02
I0209 20:23:16.936351 22542570456896 run_lib.py:146] step: 321500, eval_loss: 2.82428e-02
I0209 20:23:34.378533 22542570456896 run_lib.py:133] step: 321550, training_loss: 3.18360e-02
I0209 20:23:51.787696 22542570456896 run_lib.py:133] step: 321600, training_loss: 2.41180e-02
I0209 20:23:52.097305 22542570456896 run_lib.py:146] step: 321600, eval_loss: 3.76132e-02
I0209 20:24:09.538599 22542570456896 run_lib.py:133] step: 321650, training_loss: 2.28628e-02
I0209 20:24:26.998105 22542570456896 run_lib.py:133] step: 321700, training_loss: 3.46596e-02
I0209 20:24:27.153572 22542570456896 run_lib.py:146] step: 321700, eval_loss: 2.83031e-02
I0209 20:24:44.585507 22542570456896 run_lib.py:133] step: 321750, training_loss: 2.61148e-02
I0209 20:25:02.021002 22542570456896 run_lib.py:133] step: 321800, training_loss: 3.33046e-02
I0209 20:25:02.174346 22542570456896 run_lib.py:146] step: 321800, eval_loss: 3.24889e-02
I0209 20:25:19.761458 22542570456896 run_lib.py:133] step: 321850, training_loss: 2.66615e-02
I0209 20:25:37.223528 22542570456896 run_lib.py:133] step: 321900, training_loss: 3.47122e-02
I0209 20:25:37.379544 22542570456896 run_lib.py:146] step: 321900, eval_loss: 2.64447e-02
I0209 20:25:54.819067 22542570456896 run_lib.py:133] step: 321950, training_loss: 2.91160e-02
I0209 20:26:12.255214 22542570456896 run_lib.py:133] step: 322000, training_loss: 2.47220e-02
I0209 20:26:12.416090 22542570456896 run_lib.py:146] step: 322000, eval_loss: 2.93574e-02
I0209 20:26:30.096486 22542570456896 run_lib.py:133] step: 322050, training_loss: 2.24983e-02
I0209 20:26:47.570690 22542570456896 run_lib.py:133] step: 322100, training_loss: 3.01002e-02
I0209 20:26:47.726329 22542570456896 run_lib.py:146] step: 322100, eval_loss: 3.04360e-02
I0209 20:27:05.131169 22542570456896 run_lib.py:133] step: 322150, training_loss: 2.85825e-02
I0209 20:27:22.569394 22542570456896 run_lib.py:133] step: 322200, training_loss: 2.06694e-02
I0209 20:27:22.722602 22542570456896 run_lib.py:146] step: 322200, eval_loss: 2.64653e-02
I0209 20:27:40.411376 22542570456896 run_lib.py:133] step: 322250, training_loss: 3.67459e-02
I0209 20:27:57.854869 22542570456896 run_lib.py:133] step: 322300, training_loss: 2.65569e-02
I0209 20:27:58.014434 22542570456896 run_lib.py:146] step: 322300, eval_loss: 3.23877e-02
I0209 20:28:15.583637 22542570456896 run_lib.py:133] step: 322350, training_loss: 2.44501e-02
I0209 20:28:33.012582 22542570456896 run_lib.py:133] step: 322400, training_loss: 3.33702e-02
I0209 20:28:33.170813 22542570456896 run_lib.py:146] step: 322400, eval_loss: 3.18974e-02
I0209 20:28:50.780279 22542570456896 run_lib.py:133] step: 322450, training_loss: 2.48841e-02
I0209 20:29:08.247011 22542570456896 run_lib.py:133] step: 322500, training_loss: 2.89479e-02
I0209 20:29:08.403048 22542570456896 run_lib.py:146] step: 322500, eval_loss: 3.22654e-02
I0209 20:29:25.876898 22542570456896 run_lib.py:133] step: 322550, training_loss: 2.59782e-02
I0209 20:29:43.491902 22542570456896 run_lib.py:133] step: 322600, training_loss: 2.92778e-02
I0209 20:29:43.644129 22542570456896 run_lib.py:146] step: 322600, eval_loss: 2.62769e-02
I0209 20:30:01.048635 22542570456896 run_lib.py:133] step: 322650, training_loss: 2.71834e-02
I0209 20:30:18.605041 22542570456896 run_lib.py:133] step: 322700, training_loss: 2.66218e-02
I0209 20:30:18.762560 22542570456896 run_lib.py:146] step: 322700, eval_loss: 3.15290e-02
I0209 20:30:36.202532 22542570456896 run_lib.py:133] step: 322750, training_loss: 2.36704e-02
I0209 20:30:53.676181 22542570456896 run_lib.py:133] step: 322800, training_loss: 2.19030e-02
I0209 20:30:53.835270 22542570456896 run_lib.py:146] step: 322800, eval_loss: 3.17500e-02
I0209 20:31:11.504716 22542570456896 run_lib.py:133] step: 322850, training_loss: 2.53111e-02
I0209 20:31:28.939876 22542570456896 run_lib.py:133] step: 322900, training_loss: 2.28712e-02
I0209 20:31:29.092651 22542570456896 run_lib.py:146] step: 322900, eval_loss: 3.30259e-02
I0209 20:31:46.516450 22542570456896 run_lib.py:133] step: 322950, training_loss: 2.19663e-02
I0209 20:32:03.945465 22542570456896 run_lib.py:133] step: 323000, training_loss: 3.53284e-02
I0209 20:32:04.101696 22542570456896 run_lib.py:146] step: 323000, eval_loss: 2.20959e-02
I0209 20:32:21.661159 22542570456896 run_lib.py:133] step: 323050, training_loss: 3.06539e-02
I0209 20:32:39.114569 22542570456896 run_lib.py:133] step: 323100, training_loss: 2.33776e-02
I0209 20:32:39.269451 22542570456896 run_lib.py:146] step: 323100, eval_loss: 3.24294e-02
I0209 20:32:56.813979 22542570456896 run_lib.py:133] step: 323150, training_loss: 3.69368e-02
I0209 20:33:14.278459 22542570456896 run_lib.py:133] step: 323200, training_loss: 2.81606e-02
I0209 20:33:14.433467 22542570456896 run_lib.py:146] step: 323200, eval_loss: 2.46124e-02
I0209 20:33:31.823931 22542570456896 run_lib.py:133] step: 323250, training_loss: 2.60122e-02
I0209 20:33:49.259596 22542570456896 run_lib.py:133] step: 323300, training_loss: 2.85957e-02
I0209 20:33:49.418606 22542570456896 run_lib.py:146] step: 323300, eval_loss: 2.88362e-02
I0209 20:34:07.008105 22542570456896 run_lib.py:133] step: 323350, training_loss: 2.98962e-02
I0209 20:34:24.553569 22542570456896 run_lib.py:133] step: 323400, training_loss: 3.27416e-02
I0209 20:34:24.709508 22542570456896 run_lib.py:146] step: 323400, eval_loss: 3.17999e-02
I0209 20:34:42.139721 22542570456896 run_lib.py:133] step: 323450, training_loss: 2.63914e-02
I0209 20:34:59.561617 22542570456896 run_lib.py:133] step: 323500, training_loss: 3.08063e-02
I0209 20:34:59.716327 22542570456896 run_lib.py:146] step: 323500, eval_loss: 3.10337e-02
I0209 20:35:17.274179 22542570456896 run_lib.py:133] step: 323550, training_loss: 3.61633e-02
I0209 20:35:34.701500 22542570456896 run_lib.py:133] step: 323600, training_loss: 2.67226e-02
I0209 20:35:34.855747 22542570456896 run_lib.py:146] step: 323600, eval_loss: 2.37226e-02
I0209 20:35:52.478668 22542570456896 run_lib.py:133] step: 323650, training_loss: 2.67635e-02
I0209 20:36:09.879957 22542570456896 run_lib.py:133] step: 323700, training_loss: 2.94939e-02
I0209 20:36:10.036303 22542570456896 run_lib.py:146] step: 323700, eval_loss: 2.35737e-02
I0209 20:36:27.638474 22542570456896 run_lib.py:133] step: 323750, training_loss: 2.64412e-02
I0209 20:36:45.059899 22542570456896 run_lib.py:133] step: 323800, training_loss: 2.29278e-02
I0209 20:36:45.215448 22542570456896 run_lib.py:146] step: 323800, eval_loss: 2.66896e-02
I0209 20:37:02.808795 22542570456896 run_lib.py:133] step: 323850, training_loss: 2.89526e-02
I0209 20:37:20.283720 22542570456896 run_lib.py:133] step: 323900, training_loss: 3.00851e-02
I0209 20:37:20.444811 22542570456896 run_lib.py:146] step: 323900, eval_loss: 2.81713e-02
I0209 20:37:37.902903 22542570456896 run_lib.py:133] step: 323950, training_loss: 2.13975e-02
I0209 20:37:55.548248 22542570456896 run_lib.py:133] step: 324000, training_loss: 2.53102e-02
I0209 20:37:55.702019 22542570456896 run_lib.py:146] step: 324000, eval_loss: 2.93075e-02
I0209 20:38:13.137829 22542570456896 run_lib.py:133] step: 324050, training_loss: 2.75011e-02
I0209 20:38:30.534184 22542570456896 run_lib.py:133] step: 324100, training_loss: 3.12468e-02
I0209 20:38:30.685318 22542570456896 run_lib.py:146] step: 324100, eval_loss: 2.54596e-02
I0209 20:38:48.291233 22542570456896 run_lib.py:133] step: 324150, training_loss: 2.41647e-02
I0209 20:39:05.907416 22542570456896 run_lib.py:133] step: 324200, training_loss: 3.03581e-02
I0209 20:39:06.071367 22542570456896 run_lib.py:146] step: 324200, eval_loss: 3.40477e-02
I0209 20:39:23.502516 22542570456896 run_lib.py:133] step: 324250, training_loss: 3.33531e-02
I0209 20:39:40.896661 22542570456896 run_lib.py:133] step: 324300, training_loss: 2.20436e-02
I0209 20:39:41.052368 22542570456896 run_lib.py:146] step: 324300, eval_loss: 3.15214e-02
I0209 20:39:58.473311 22542570456896 run_lib.py:133] step: 324350, training_loss: 2.99956e-02
I0209 20:40:16.037940 22542570456896 run_lib.py:133] step: 324400, training_loss: 2.68419e-02
I0209 20:40:16.198164 22542570456896 run_lib.py:146] step: 324400, eval_loss: 2.38122e-02
I0209 20:40:33.635510 22542570456896 run_lib.py:133] step: 324450, training_loss: 2.76621e-02
I0209 20:40:51.050147 22542570456896 run_lib.py:133] step: 324500, training_loss: 2.93061e-02
I0209 20:40:51.206681 22542570456896 run_lib.py:146] step: 324500, eval_loss: 2.78564e-02
I0209 20:41:08.642181 22542570456896 run_lib.py:133] step: 324550, training_loss: 3.42424e-02
I0209 20:41:26.276018 22542570456896 run_lib.py:133] step: 324600, training_loss: 2.84516e-02
I0209 20:41:26.431339 22542570456896 run_lib.py:146] step: 324600, eval_loss: 3.62286e-02
I0209 20:41:43.847313 22542570456896 run_lib.py:133] step: 324650, training_loss: 2.59996e-02
I0209 20:42:01.326862 22542570456896 run_lib.py:133] step: 324700, training_loss: 2.57809e-02
I0209 20:42:01.502261 22542570456896 run_lib.py:146] step: 324700, eval_loss: 2.66048e-02
I0209 20:42:18.951566 22542570456896 run_lib.py:133] step: 324750, training_loss: 2.69947e-02
I0209 20:42:36.394525 22542570456896 run_lib.py:133] step: 324800, training_loss: 2.76888e-02
I0209 20:42:36.558587 22542570456896 run_lib.py:146] step: 324800, eval_loss: 2.91422e-02
I0209 20:42:54.165369 22542570456896 run_lib.py:133] step: 324850, training_loss: 3.05894e-02
I0209 20:43:11.651112 22542570456896 run_lib.py:133] step: 324900, training_loss: 3.32952e-02
I0209 20:43:11.804337 22542570456896 run_lib.py:146] step: 324900, eval_loss: 2.83707e-02
I0209 20:43:29.219446 22542570456896 run_lib.py:133] step: 324950, training_loss: 2.25567e-02
I0209 20:43:46.711208 22542570456896 run_lib.py:133] step: 325000, training_loss: 3.40546e-02
I0209 20:43:46.865503 22542570456896 run_lib.py:146] step: 325000, eval_loss: 2.73010e-02
I0209 20:44:04.499395 22542570456896 run_lib.py:133] step: 325050, training_loss: 2.82320e-02
I0209 20:44:21.922587 22542570456896 run_lib.py:133] step: 325100, training_loss: 2.53440e-02
I0209 20:44:22.077312 22542570456896 run_lib.py:146] step: 325100, eval_loss: 2.76935e-02
I0209 20:44:39.654355 22542570456896 run_lib.py:133] step: 325150, training_loss: 2.72207e-02
I0209 20:44:57.118556 22542570456896 run_lib.py:133] step: 325200, training_loss: 2.17293e-02
I0209 20:44:57.275567 22542570456896 run_lib.py:146] step: 325200, eval_loss: 3.04369e-02
I0209 20:45:14.836185 22542570456896 run_lib.py:133] step: 325250, training_loss: 2.28781e-02
I0209 20:45:32.294585 22542570456896 run_lib.py:133] step: 325300, training_loss: 2.46990e-02
I0209 20:45:32.451493 22542570456896 run_lib.py:146] step: 325300, eval_loss: 2.14476e-02
I0209 20:45:49.915178 22542570456896 run_lib.py:133] step: 325350, training_loss: 3.06141e-02
I0209 20:46:07.539009 22542570456896 run_lib.py:133] step: 325400, training_loss: 3.42432e-02
I0209 20:46:07.696401 22542570456896 run_lib.py:146] step: 325400, eval_loss: 3.13497e-02
I0209 20:46:25.130423 22542570456896 run_lib.py:133] step: 325450, training_loss: 2.98205e-02
I0209 20:46:42.689792 22542570456896 run_lib.py:133] step: 325500, training_loss: 2.81656e-02
I0209 20:46:42.842431 22542570456896 run_lib.py:146] step: 325500, eval_loss: 2.51998e-02
I0209 20:47:00.250454 22542570456896 run_lib.py:133] step: 325550, training_loss: 2.57743e-02
I0209 20:47:17.706036 22542570456896 run_lib.py:133] step: 325600, training_loss: 3.49364e-02
I0209 20:47:17.881288 22542570456896 run_lib.py:146] step: 325600, eval_loss: 2.83913e-02
I0209 20:47:35.519463 22542570456896 run_lib.py:133] step: 325650, training_loss: 3.07114e-02
I0209 20:47:52.937702 22542570456896 run_lib.py:133] step: 325700, training_loss: 2.67988e-02
I0209 20:47:53.102428 22542570456896 run_lib.py:146] step: 325700, eval_loss: 2.49701e-02
I0209 20:48:10.505079 22542570456896 run_lib.py:133] step: 325750, training_loss: 2.84944e-02
I0209 20:48:28.070402 22542570456896 run_lib.py:133] step: 325800, training_loss: 2.88375e-02
I0209 20:48:28.225367 22542570456896 run_lib.py:146] step: 325800, eval_loss: 3.17044e-02
I0209 20:48:45.646227 22542570456896 run_lib.py:133] step: 325850, training_loss: 2.36898e-02
I0209 20:49:03.113892 22542570456896 run_lib.py:133] step: 325900, training_loss: 2.88086e-02
I0209 20:49:03.268138 22542570456896 run_lib.py:146] step: 325900, eval_loss: 3.79042e-02
I0209 20:49:20.820246 22542570456896 run_lib.py:133] step: 325950, training_loss: 2.69804e-02
I0209 20:49:38.237640 22542570456896 run_lib.py:133] step: 326000, training_loss: 2.37350e-02
I0209 20:49:38.390897 22542570456896 run_lib.py:146] step: 326000, eval_loss: 2.56732e-02
I0209 20:49:55.778701 22542570456896 run_lib.py:133] step: 326050, training_loss: 2.93555e-02
I0209 20:50:13.267812 22542570456896 run_lib.py:133] step: 326100, training_loss: 2.78911e-02
I0209 20:50:13.435056 22542570456896 run_lib.py:146] step: 326100, eval_loss: 3.16569e-02
I0209 20:50:31.025445 22542570456896 run_lib.py:133] step: 326150, training_loss: 2.39323e-02
I0209 20:50:48.560365 22542570456896 run_lib.py:133] step: 326200, training_loss: 2.94794e-02
I0209 20:50:48.713698 22542570456896 run_lib.py:146] step: 326200, eval_loss: 2.43647e-02
I0209 20:51:06.101247 22542570456896 run_lib.py:133] step: 326250, training_loss: 2.94337e-02
I0209 20:51:23.477991 22542570456896 run_lib.py:133] step: 326300, training_loss: 2.54783e-02
I0209 20:51:23.634550 22542570456896 run_lib.py:146] step: 326300, eval_loss: 2.75351e-02
I0209 20:51:41.206869 22542570456896 run_lib.py:133] step: 326350, training_loss: 2.64880e-02
I0209 20:51:58.678782 22542570456896 run_lib.py:133] step: 326400, training_loss: 2.18302e-02
I0209 20:51:58.841259 22542570456896 run_lib.py:146] step: 326400, eval_loss: 2.89540e-02
I0209 20:52:16.475837 22542570456896 run_lib.py:133] step: 326450, training_loss: 2.52546e-02
I0209 20:52:33.864301 22542570456896 run_lib.py:133] step: 326500, training_loss: 2.86776e-02
I0209 20:52:34.019279 22542570456896 run_lib.py:146] step: 326500, eval_loss: 3.00710e-02
I0209 20:52:51.610500 22542570456896 run_lib.py:133] step: 326550, training_loss: 2.84517e-02
I0209 20:53:09.016819 22542570456896 run_lib.py:133] step: 326600, training_loss: 2.60860e-02
I0209 20:53:09.171571 22542570456896 run_lib.py:146] step: 326600, eval_loss: 2.65604e-02
I0209 20:53:26.743343 22542570456896 run_lib.py:133] step: 326650, training_loss: 2.43597e-02
I0209 20:53:44.212789 22542570456896 run_lib.py:133] step: 326700, training_loss: 2.57211e-02
I0209 20:53:44.368837 22542570456896 run_lib.py:146] step: 326700, eval_loss: 2.49216e-02
I0209 20:54:01.843716 22542570456896 run_lib.py:133] step: 326750, training_loss: 2.50247e-02
I0209 20:54:19.430459 22542570456896 run_lib.py:133] step: 326800, training_loss: 2.54652e-02
I0209 20:54:19.586381 22542570456896 run_lib.py:146] step: 326800, eval_loss: 3.14054e-02
I0209 20:54:37.062571 22542570456896 run_lib.py:133] step: 326850, training_loss: 2.15941e-02
I0209 20:54:54.420951 22542570456896 run_lib.py:133] step: 326900, training_loss: 2.82839e-02
I0209 20:54:54.574442 22542570456896 run_lib.py:146] step: 326900, eval_loss: 2.98499e-02
I0209 20:55:12.128820 22542570456896 run_lib.py:133] step: 326950, training_loss: 2.91800e-02
I0209 20:55:29.565427 22542570456896 run_lib.py:133] step: 327000, training_loss: 2.22973e-02
I0209 20:55:29.734513 22542570456896 run_lib.py:146] step: 327000, eval_loss: 2.62870e-02
I0209 20:55:47.364148 22542570456896 run_lib.py:133] step: 327050, training_loss: 3.11546e-02
I0209 20:56:04.835797 22542570456896 run_lib.py:133] step: 327100, training_loss: 3.07441e-02
I0209 20:56:05.000430 22542570456896 run_lib.py:146] step: 327100, eval_loss: 2.60141e-02
I0209 20:56:22.407673 22542570456896 run_lib.py:133] step: 327150, training_loss: 2.72105e-02
I0209 20:56:39.962531 22542570456896 run_lib.py:133] step: 327200, training_loss: 3.24780e-02
I0209 20:56:40.118391 22542570456896 run_lib.py:146] step: 327200, eval_loss: 2.89823e-02
I0209 20:56:57.502890 22542570456896 run_lib.py:133] step: 327250, training_loss: 2.73423e-02
I0209 20:57:14.970875 22542570456896 run_lib.py:133] step: 327300, training_loss: 3.04784e-02
I0209 20:57:15.126515 22542570456896 run_lib.py:146] step: 327300, eval_loss: 2.41528e-02
I0209 20:57:32.597995 22542570456896 run_lib.py:133] step: 327350, training_loss: 2.81532e-02
I0209 20:57:50.219083 22542570456896 run_lib.py:133] step: 327400, training_loss: 2.48978e-02
I0209 20:57:50.371348 22542570456896 run_lib.py:146] step: 327400, eval_loss: 2.38283e-02
I0209 20:58:07.761581 22542570456896 run_lib.py:133] step: 327450, training_loss: 2.29967e-02
I0209 20:58:25.254302 22542570456896 run_lib.py:133] step: 327500, training_loss: 3.03969e-02
I0209 20:58:25.424188 22542570456896 run_lib.py:146] step: 327500, eval_loss: 2.27389e-02
I0209 20:58:42.875766 22542570456896 run_lib.py:133] step: 327550, training_loss: 2.55255e-02
I0209 20:59:00.311864 22542570456896 run_lib.py:133] step: 327600, training_loss: 2.28102e-02
I0209 20:59:00.467318 22542570456896 run_lib.py:146] step: 327600, eval_loss: 3.51155e-02
I0209 20:59:18.051038 22542570456896 run_lib.py:133] step: 327650, training_loss: 3.19480e-02
I0209 20:59:35.545689 22542570456896 run_lib.py:133] step: 327700, training_loss: 3.08487e-02
I0209 20:59:35.699559 22542570456896 run_lib.py:146] step: 327700, eval_loss: 2.98244e-02
I0209 20:59:53.097817 22542570456896 run_lib.py:133] step: 327750, training_loss: 2.18740e-02
I0209 21:00:10.539370 22542570456896 run_lib.py:133] step: 327800, training_loss: 3.33788e-02
I0209 21:00:10.705192 22542570456896 run_lib.py:146] step: 327800, eval_loss: 3.29800e-02
I0209 21:00:28.304149 22542570456896 run_lib.py:133] step: 327850, training_loss: 2.79984e-02
I0209 21:00:45.759293 22542570456896 run_lib.py:133] step: 327900, training_loss: 2.51497e-02
I0209 21:00:45.913341 22542570456896 run_lib.py:146] step: 327900, eval_loss: 3.34200e-02
I0209 21:01:03.462492 22542570456896 run_lib.py:133] step: 327950, training_loss: 2.49624e-02
I0209 21:01:20.864251 22542570456896 run_lib.py:133] step: 328000, training_loss: 3.25853e-02
I0209 21:01:21.023521 22542570456896 run_lib.py:146] step: 328000, eval_loss: 3.16345e-02
I0209 21:01:38.568734 22542570456896 run_lib.py:133] step: 328050, training_loss: 2.55128e-02
I0209 21:01:55.958387 22542570456896 run_lib.py:133] step: 328100, training_loss: 2.76364e-02
I0209 21:01:56.124480 22542570456896 run_lib.py:146] step: 328100, eval_loss: 2.55310e-02
I0209 21:02:13.607312 22542570456896 run_lib.py:133] step: 328150, training_loss: 2.62495e-02
I0209 21:02:31.236014 22542570456896 run_lib.py:133] step: 328200, training_loss: 3.15203e-02
I0209 21:02:31.400641 22542570456896 run_lib.py:146] step: 328200, eval_loss: 2.93438e-02
I0209 21:02:48.807189 22542570456896 run_lib.py:133] step: 328250, training_loss: 2.53966e-02
I0209 21:03:06.367765 22542570456896 run_lib.py:133] step: 328300, training_loss: 3.41964e-02
I0209 21:03:06.527404 22542570456896 run_lib.py:146] step: 328300, eval_loss: 3.22170e-02
I0209 21:03:23.913550 22542570456896 run_lib.py:133] step: 328350, training_loss: 2.65051e-02
I0209 21:03:41.302198 22542570456896 run_lib.py:133] step: 328400, training_loss: 2.62823e-02
I0209 21:03:41.475552 22542570456896 run_lib.py:146] step: 328400, eval_loss: 2.97233e-02
I0209 21:03:59.120329 22542570456896 run_lib.py:133] step: 328450, training_loss: 2.77223e-02
I0209 21:04:16.559179 22542570456896 run_lib.py:133] step: 328500, training_loss: 2.27983e-02
I0209 21:04:16.717546 22542570456896 run_lib.py:146] step: 328500, eval_loss: 2.76713e-02
I0209 21:04:34.122195 22542570456896 run_lib.py:133] step: 328550, training_loss: 2.52823e-02
I0209 21:04:51.679182 22542570456896 run_lib.py:133] step: 328600, training_loss: 2.80331e-02
I0209 21:04:51.835278 22542570456896 run_lib.py:146] step: 328600, eval_loss: 2.68523e-02
I0209 21:05:09.228715 22542570456896 run_lib.py:133] step: 328650, training_loss: 2.80186e-02
I0209 21:05:26.751556 22542570456896 run_lib.py:133] step: 328700, training_loss: 3.43716e-02
I0209 21:05:27.105362 22542570456896 run_lib.py:146] step: 328700, eval_loss: 2.98170e-02
I0209 21:05:44.570146 22542570456896 run_lib.py:133] step: 328750, training_loss: 2.57739e-02
I0209 21:06:01.989616 22542570456896 run_lib.py:133] step: 328800, training_loss: 2.49114e-02
I0209 21:06:02.138395 22542570456896 run_lib.py:146] step: 328800, eval_loss: 2.60517e-02
I0209 21:06:19.572178 22542570456896 run_lib.py:133] step: 328850, training_loss: 3.10156e-02
I0209 21:06:37.002525 22542570456896 run_lib.py:133] step: 328900, training_loss: 2.76094e-02
I0209 21:06:37.170517 22542570456896 run_lib.py:146] step: 328900, eval_loss: 3.11842e-02
I0209 21:06:54.776422 22542570456896 run_lib.py:133] step: 328950, training_loss: 3.35638e-02
I0209 21:07:12.324384 22542570456896 run_lib.py:133] step: 329000, training_loss: 2.63088e-02
I0209 21:07:12.482312 22542570456896 run_lib.py:146] step: 329000, eval_loss: 3.31882e-02
I0209 21:07:29.891028 22542570456896 run_lib.py:133] step: 329050, training_loss: 2.35371e-02
I0209 21:07:47.327604 22542570456896 run_lib.py:133] step: 329100, training_loss: 3.06938e-02
I0209 21:07:47.484316 22542570456896 run_lib.py:146] step: 329100, eval_loss: 2.76619e-02
I0209 21:08:05.060041 22542570456896 run_lib.py:133] step: 329150, training_loss: 2.50756e-02
I0209 21:08:22.575002 22542570456896 run_lib.py:133] step: 329200, training_loss: 2.35212e-02
I0209 21:08:22.730396 22542570456896 run_lib.py:146] step: 329200, eval_loss: 2.68970e-02
I0209 21:08:40.120709 22542570456896 run_lib.py:133] step: 329250, training_loss: 2.60026e-02
I0209 21:08:57.399227 22542570456896 run_lib.py:133] step: 329300, training_loss: 3.18088e-02
I0209 21:08:57.549178 22542570456896 run_lib.py:146] step: 329300, eval_loss: 3.23038e-02
I0209 21:09:15.076595 22542570456896 run_lib.py:133] step: 329350, training_loss: 3.16144e-02
I0209 21:09:32.485940 22542570456896 run_lib.py:133] step: 329400, training_loss: 2.71620e-02
I0209 21:09:32.645561 22542570456896 run_lib.py:146] step: 329400, eval_loss: 2.80037e-02
I0209 21:09:50.226433 22542570456896 run_lib.py:133] step: 329450, training_loss: 3.19582e-02
I0209 21:10:07.677119 22542570456896 run_lib.py:133] step: 329500, training_loss: 2.66198e-02
I0209 21:10:07.844413 22542570456896 run_lib.py:146] step: 329500, eval_loss: 2.80104e-02
I0209 21:10:25.426024 22542570456896 run_lib.py:133] step: 329550, training_loss: 3.02964e-02
I0209 21:10:42.828966 22542570456896 run_lib.py:133] step: 329600, training_loss: 2.46333e-02
I0209 21:10:42.983886 22542570456896 run_lib.py:146] step: 329600, eval_loss: 2.43157e-02
I0209 21:11:00.463462 22542570456896 run_lib.py:133] step: 329650, training_loss: 2.68134e-02
I0209 21:11:18.032431 22542570456896 run_lib.py:133] step: 329700, training_loss: 3.29048e-02
I0209 21:11:18.187453 22542570456896 run_lib.py:146] step: 329700, eval_loss: 2.16201e-02
I0209 21:11:35.654645 22542570456896 run_lib.py:133] step: 329750, training_loss: 3.21097e-02
I0209 21:11:53.268311 22542570456896 run_lib.py:133] step: 329800, training_loss: 2.83506e-02
I0209 21:11:53.426642 22542570456896 run_lib.py:146] step: 329800, eval_loss: 3.33263e-02
I0209 21:12:10.872069 22542570456896 run_lib.py:133] step: 329850, training_loss: 2.89277e-02
I0209 21:12:28.343422 22542570456896 run_lib.py:133] step: 329900, training_loss: 3.00929e-02
I0209 21:12:28.502604 22542570456896 run_lib.py:146] step: 329900, eval_loss: 3.06450e-02
I0209 21:12:46.079115 22542570456896 run_lib.py:133] step: 329950, training_loss: 2.81758e-02
I0209 21:13:03.521161 22542570456896 run_lib.py:133] step: 330000, training_loss: 2.23044e-02
I0209 21:13:04.282163 22542570456896 run_lib.py:146] step: 330000, eval_loss: 2.51898e-02
I0209 21:13:24.754417 22542570456896 run_lib.py:133] step: 330050, training_loss: 3.25604e-02
I0209 21:13:42.268219 22542570456896 run_lib.py:133] step: 330100, training_loss: 2.71202e-02
I0209 21:13:42.421784 22542570456896 run_lib.py:146] step: 330100, eval_loss: 3.39840e-02
I0209 21:13:59.810447 22542570456896 run_lib.py:133] step: 330150, training_loss: 2.51331e-02
I0209 21:14:17.228606 22542570456896 run_lib.py:133] step: 330200, training_loss: 2.62856e-02
I0209 21:14:17.387714 22542570456896 run_lib.py:146] step: 330200, eval_loss: 3.40891e-02
I0209 21:14:34.907900 22542570456896 run_lib.py:133] step: 330250, training_loss: 2.96246e-02
I0209 21:14:52.367736 22542570456896 run_lib.py:133] step: 330300, training_loss: 2.67075e-02
I0209 21:14:52.521467 22542570456896 run_lib.py:146] step: 330300, eval_loss: 2.47263e-02
I0209 21:15:09.985384 22542570456896 run_lib.py:133] step: 330350, training_loss: 2.90616e-02
I0209 21:15:27.426495 22542570456896 run_lib.py:133] step: 330400, training_loss: 2.93002e-02
I0209 21:15:27.581539 22542570456896 run_lib.py:146] step: 330400, eval_loss: 3.05704e-02
I0209 21:15:45.202178 22542570456896 run_lib.py:133] step: 330450, training_loss: 2.52643e-02
I0209 21:16:02.658121 22542570456896 run_lib.py:133] step: 330500, training_loss: 2.92844e-02
I0209 21:16:02.816582 22542570456896 run_lib.py:146] step: 330500, eval_loss: 2.70989e-02
I0209 21:16:20.386889 22542570456896 run_lib.py:133] step: 330550, training_loss: 3.38569e-02
I0209 21:16:37.816102 22542570456896 run_lib.py:133] step: 330600, training_loss: 3.13923e-02
I0209 21:16:37.980875 22542570456896 run_lib.py:146] step: 330600, eval_loss: 2.54516e-02
I0209 21:16:55.631704 22542570456896 run_lib.py:133] step: 330650, training_loss: 3.55460e-02
I0209 21:17:13.041586 22542570456896 run_lib.py:133] step: 330700, training_loss: 2.49072e-02
I0209 21:17:13.196318 22542570456896 run_lib.py:146] step: 330700, eval_loss: 3.47327e-02
I0209 21:17:30.641558 22542570456896 run_lib.py:133] step: 330750, training_loss: 2.80089e-02
I0209 21:17:48.212452 22542570456896 run_lib.py:133] step: 330800, training_loss: 2.61178e-02
I0209 21:17:48.365359 22542570456896 run_lib.py:146] step: 330800, eval_loss: 2.49362e-02
I0209 21:18:05.775619 22542570456896 run_lib.py:133] step: 330850, training_loss: 2.54718e-02
I0209 21:18:23.331011 22542570456896 run_lib.py:133] step: 330900, training_loss: 3.87728e-02
I0209 21:18:23.516294 22542570456896 run_lib.py:146] step: 330900, eval_loss: 3.18912e-02
I0209 21:18:40.955684 22542570456896 run_lib.py:133] step: 330950, training_loss: 2.57977e-02
I0209 21:18:58.408109 22542570456896 run_lib.py:133] step: 331000, training_loss: 3.17049e-02
I0209 21:18:58.564569 22542570456896 run_lib.py:146] step: 331000, eval_loss: 2.72749e-02
I0209 21:19:16.207508 22542570456896 run_lib.py:133] step: 331050, training_loss: 3.11343e-02
I0209 21:19:33.638058 22542570456896 run_lib.py:133] step: 331100, training_loss: 3.63148e-02
I0209 21:19:33.799382 22542570456896 run_lib.py:146] step: 331100, eval_loss: 2.88979e-02
I0209 21:19:51.228193 22542570456896 run_lib.py:133] step: 331150, training_loss: 2.53606e-02
I0209 21:20:08.668618 22542570456896 run_lib.py:133] step: 331200, training_loss: 1.96835e-02
I0209 21:20:08.825301 22542570456896 run_lib.py:146] step: 331200, eval_loss: 3.03052e-02
I0209 21:20:26.460681 22542570456896 run_lib.py:133] step: 331250, training_loss: 2.80508e-02
I0209 21:20:43.877674 22542570456896 run_lib.py:133] step: 331300, training_loss: 2.84045e-02
I0209 21:20:44.032334 22542570456896 run_lib.py:146] step: 331300, eval_loss: 3.77885e-02
I0209 21:21:01.491631 22542570456896 run_lib.py:133] step: 331350, training_loss: 2.80545e-02
I0209 21:21:18.912508 22542570456896 run_lib.py:133] step: 331400, training_loss: 3.12392e-02
I0209 21:21:19.070577 22542570456896 run_lib.py:146] step: 331400, eval_loss: 2.79170e-02
I0209 21:21:36.529206 22542570456896 run_lib.py:133] step: 331450, training_loss: 2.58506e-02
I0209 21:21:54.035724 22542570456896 run_lib.py:133] step: 331500, training_loss: 2.38210e-02
I0209 21:21:54.197050 22542570456896 run_lib.py:146] step: 331500, eval_loss: 2.52227e-02
I0209 21:22:11.794157 22542570456896 run_lib.py:133] step: 331550, training_loss: 3.36097e-02
I0209 21:22:29.285023 22542570456896 run_lib.py:133] step: 331600, training_loss: 2.55582e-02
I0209 21:22:29.447391 22542570456896 run_lib.py:146] step: 331600, eval_loss: 2.55844e-02
I0209 21:22:46.879359 22542570456896 run_lib.py:133] step: 331650, training_loss: 2.06847e-02
I0209 21:23:04.317927 22542570456896 run_lib.py:133] step: 331700, training_loss: 3.17940e-02
I0209 21:23:04.478370 22542570456896 run_lib.py:146] step: 331700, eval_loss: 2.67045e-02
I0209 21:23:22.094615 22542570456896 run_lib.py:133] step: 331750, training_loss: 2.63582e-02
I0209 21:23:39.516552 22542570456896 run_lib.py:133] step: 331800, training_loss: 2.44805e-02
I0209 21:23:39.670753 22542570456896 run_lib.py:146] step: 331800, eval_loss: 2.77922e-02
I0209 21:23:57.243715 22542570456896 run_lib.py:133] step: 331850, training_loss: 2.67947e-02
I0209 21:24:14.617277 22542570456896 run_lib.py:133] step: 331900, training_loss: 2.28437e-02
I0209 21:24:14.775596 22542570456896 run_lib.py:146] step: 331900, eval_loss: 3.07233e-02
I0209 21:24:32.318447 22542570456896 run_lib.py:133] step: 331950, training_loss: 2.36089e-02
I0209 21:24:49.812294 22542570456896 run_lib.py:133] step: 332000, training_loss: 2.77738e-02
I0209 21:24:49.968392 22542570456896 run_lib.py:146] step: 332000, eval_loss: 2.73380e-02
I0209 21:25:07.570473 22542570456896 run_lib.py:133] step: 332050, training_loss: 2.79780e-02
I0209 21:25:24.994325 22542570456896 run_lib.py:133] step: 332100, training_loss: 2.76859e-02
I0209 21:25:25.148280 22542570456896 run_lib.py:146] step: 332100, eval_loss: 2.20223e-02
I0209 21:25:42.567808 22542570456896 run_lib.py:133] step: 332150, training_loss: 3.26551e-02
I0209 21:26:00.098266 22542570456896 run_lib.py:133] step: 332200, training_loss: 3.17384e-02
I0209 21:26:00.250370 22542570456896 run_lib.py:146] step: 332200, eval_loss: 2.72667e-02
I0209 21:26:17.636676 22542570456896 run_lib.py:133] step: 332250, training_loss: 2.89181e-02
I0209 21:26:35.072124 22542570456896 run_lib.py:133] step: 332300, training_loss: 3.43022e-02
I0209 21:26:35.249175 22542570456896 run_lib.py:146] step: 332300, eval_loss: 2.75818e-02
I0209 21:26:52.853187 22542570456896 run_lib.py:133] step: 332350, training_loss: 3.51223e-02
I0209 21:27:10.443388 22542570456896 run_lib.py:133] step: 332400, training_loss: 2.96975e-02
I0209 21:27:10.605997 22542570456896 run_lib.py:146] step: 332400, eval_loss: 3.16818e-02
I0209 21:27:28.031275 22542570456896 run_lib.py:133] step: 332450, training_loss: 2.63400e-02
I0209 21:27:45.414023 22542570456896 run_lib.py:133] step: 332500, training_loss: 3.53855e-02
I0209 21:27:45.569546 22542570456896 run_lib.py:146] step: 332500, eval_loss: 2.48119e-02
I0209 21:28:02.992518 22542570456896 run_lib.py:133] step: 332550, training_loss: 2.66093e-02
I0209 21:28:20.643860 22542570456896 run_lib.py:133] step: 332600, training_loss: 2.73545e-02
I0209 21:28:20.807492 22542570456896 run_lib.py:146] step: 332600, eval_loss: 2.59761e-02
I0209 21:28:38.254289 22542570456896 run_lib.py:133] step: 332650, training_loss: 2.65253e-02
I0209 21:28:55.639646 22542570456896 run_lib.py:133] step: 332700, training_loss: 3.25719e-02
I0209 21:28:55.797249 22542570456896 run_lib.py:146] step: 332700, eval_loss: 2.60458e-02
I0209 21:29:13.194855 22542570456896 run_lib.py:133] step: 332750, training_loss: 3.33575e-02
I0209 21:29:30.823202 22542570456896 run_lib.py:133] step: 332800, training_loss: 3.02161e-02
I0209 21:29:30.987364 22542570456896 run_lib.py:146] step: 332800, eval_loss: 3.26901e-02
I0209 21:29:48.417826 22542570456896 run_lib.py:133] step: 332850, training_loss: 2.04988e-02
I0209 21:30:05.953997 22542570456896 run_lib.py:133] step: 332900, training_loss: 2.69713e-02
I0209 21:30:06.109770 22542570456896 run_lib.py:146] step: 332900, eval_loss: 2.68916e-02
I0209 21:30:23.529788 22542570456896 run_lib.py:133] step: 332950, training_loss: 1.99886e-02
I0209 21:30:40.959582 22542570456896 run_lib.py:133] step: 333000, training_loss: 2.92592e-02
I0209 21:30:41.118220 22542570456896 run_lib.py:146] step: 333000, eval_loss: 3.48624e-02
I0209 21:30:58.710776 22542570456896 run_lib.py:133] step: 333050, training_loss: 3.13083e-02
I0209 21:31:16.212194 22542570456896 run_lib.py:133] step: 333100, training_loss: 3.49528e-02
I0209 21:31:16.365126 22542570456896 run_lib.py:146] step: 333100, eval_loss: 2.86186e-02
I0209 21:31:33.840738 22542570456896 run_lib.py:133] step: 333150, training_loss: 2.30518e-02
I0209 21:31:51.261533 22542570456896 run_lib.py:133] step: 333200, training_loss: 2.73763e-02
I0209 21:31:51.423274 22542570456896 run_lib.py:146] step: 333200, eval_loss: 2.84885e-02
I0209 21:32:09.001002 22542570456896 run_lib.py:133] step: 333250, training_loss: 3.19044e-02
I0209 21:32:26.430095 22542570456896 run_lib.py:133] step: 333300, training_loss: 2.21279e-02
I0209 21:32:26.589511 22542570456896 run_lib.py:146] step: 333300, eval_loss: 2.28908e-02
I0209 21:32:44.164414 22542570456896 run_lib.py:133] step: 333350, training_loss: 3.32681e-02
I0209 21:33:01.647647 22542570456896 run_lib.py:133] step: 333400, training_loss: 3.00934e-02
I0209 21:33:01.804356 22542570456896 run_lib.py:146] step: 333400, eval_loss: 3.05234e-02
I0209 21:33:19.395008 22542570456896 run_lib.py:133] step: 333450, training_loss: 2.83870e-02
I0209 21:33:36.828873 22542570456896 run_lib.py:133] step: 333500, training_loss: 3.44351e-02
I0209 21:33:36.984179 22542570456896 run_lib.py:146] step: 333500, eval_loss: 3.26174e-02
I0209 21:33:54.422322 22542570456896 run_lib.py:133] step: 333550, training_loss: 3.88426e-02
I0209 21:34:11.980300 22542570456896 run_lib.py:133] step: 333600, training_loss: 2.46731e-02
I0209 21:34:12.131313 22542570456896 run_lib.py:146] step: 333600, eval_loss: 2.80917e-02
I0209 21:34:29.568453 22542570456896 run_lib.py:133] step: 333650, training_loss: 3.37440e-02
I0209 21:34:47.174424 22542570456896 run_lib.py:133] step: 333700, training_loss: 3.25880e-02
I0209 21:34:47.341610 22542570456896 run_lib.py:146] step: 333700, eval_loss: 2.87983e-02
I0209 21:35:04.743188 22542570456896 run_lib.py:133] step: 333750, training_loss: 3.08288e-02
I0209 21:35:22.174367 22542570456896 run_lib.py:133] step: 333800, training_loss: 2.36146e-02
I0209 21:35:22.338692 22542570456896 run_lib.py:146] step: 333800, eval_loss: 2.72215e-02
I0209 21:35:39.921783 22542570456896 run_lib.py:133] step: 333850, training_loss: 2.29125e-02
I0209 21:35:57.334079 22542570456896 run_lib.py:133] step: 333900, training_loss: 3.09363e-02
I0209 21:35:57.502430 22542570456896 run_lib.py:146] step: 333900, eval_loss: 2.61600e-02
I0209 21:36:14.959619 22542570456896 run_lib.py:133] step: 333950, training_loss: 2.82694e-02
I0209 21:36:32.580129 22542570456896 run_lib.py:133] step: 334000, training_loss: 2.77651e-02
I0209 21:36:32.735541 22542570456896 run_lib.py:146] step: 334000, eval_loss: 2.93813e-02
I0209 21:36:50.174814 22542570456896 run_lib.py:133] step: 334050, training_loss: 2.89748e-02
I0209 21:37:07.604960 22542570456896 run_lib.py:133] step: 334100, training_loss: 2.10647e-02
I0209 21:37:07.756416 22542570456896 run_lib.py:146] step: 334100, eval_loss: 2.86541e-02
I0209 21:37:25.225819 22542570456896 run_lib.py:133] step: 334150, training_loss: 3.14990e-02
I0209 21:37:42.680554 22542570456896 run_lib.py:133] step: 334200, training_loss: 2.76308e-02
I0209 21:37:42.849358 22542570456896 run_lib.py:146] step: 334200, eval_loss: 3.12051e-02
I0209 21:38:00.314756 22542570456896 run_lib.py:133] step: 334250, training_loss: 2.40263e-02
I0209 21:38:17.754920 22542570456896 run_lib.py:133] step: 334300, training_loss: 3.46786e-02
I0209 21:38:17.912314 22542570456896 run_lib.py:146] step: 334300, eval_loss: 2.99751e-02
I0209 21:38:35.515372 22542570456896 run_lib.py:133] step: 334350, training_loss: 3.18738e-02
I0209 21:38:53.013830 22542570456896 run_lib.py:133] step: 334400, training_loss: 3.19562e-02
I0209 21:38:53.169302 22542570456896 run_lib.py:146] step: 334400, eval_loss: 3.17298e-02
I0209 21:39:10.623319 22542570456896 run_lib.py:133] step: 334450, training_loss: 2.31397e-02
I0209 21:39:28.032376 22542570456896 run_lib.py:133] step: 334500, training_loss: 2.56666e-02
I0209 21:39:28.187595 22542570456896 run_lib.py:146] step: 334500, eval_loss: 3.00446e-02
I0209 21:39:45.815175 22542570456896 run_lib.py:133] step: 334550, training_loss: 2.54204e-02
I0209 21:40:03.198552 22542570456896 run_lib.py:133] step: 334600, training_loss: 2.62663e-02
I0209 21:40:03.350238 22542570456896 run_lib.py:146] step: 334600, eval_loss: 3.22884e-02
I0209 21:40:20.949377 22542570456896 run_lib.py:133] step: 334650, training_loss: 2.26698e-02
I0209 21:40:38.376093 22542570456896 run_lib.py:133] step: 334700, training_loss: 3.06103e-02
I0209 21:40:38.535582 22542570456896 run_lib.py:146] step: 334700, eval_loss: 2.98874e-02
I0209 21:40:56.056107 22542570456896 run_lib.py:133] step: 334750, training_loss: 2.56562e-02
I0209 21:41:13.477292 22542570456896 run_lib.py:133] step: 334800, training_loss: 2.92563e-02
I0209 21:41:13.647345 22542570456896 run_lib.py:146] step: 334800, eval_loss: 3.20335e-02
I0209 21:41:31.276431 22542570456896 run_lib.py:133] step: 334850, training_loss: 2.10815e-02
I0209 21:41:48.705217 22542570456896 run_lib.py:133] step: 334900, training_loss: 3.12371e-02
I0209 21:41:48.860091 22542570456896 run_lib.py:146] step: 334900, eval_loss: 3.31807e-02
I0209 21:42:06.318513 22542570456896 run_lib.py:133] step: 334950, training_loss: 3.39817e-02
I0209 21:42:23.879554 22542570456896 run_lib.py:133] step: 335000, training_loss: 2.65442e-02
I0209 21:42:24.034252 22542570456896 run_lib.py:146] step: 335000, eval_loss: 2.77067e-02
I0209 21:42:41.443723 22542570456896 run_lib.py:133] step: 335050, training_loss: 2.54755e-02
I0209 21:42:58.933780 22542570456896 run_lib.py:133] step: 335100, training_loss: 2.67205e-02
I0209 21:42:59.109166 22542570456896 run_lib.py:146] step: 335100, eval_loss: 2.82591e-02
I0209 21:43:16.793872 22542570456896 run_lib.py:133] step: 335150, training_loss: 2.30592e-02
I0209 21:43:34.277971 22542570456896 run_lib.py:133] step: 335200, training_loss: 2.90239e-02
I0209 21:43:34.436375 22542570456896 run_lib.py:146] step: 335200, eval_loss: 3.36275e-02
I0209 21:43:51.994165 22542570456896 run_lib.py:133] step: 335250, training_loss: 2.74797e-02
I0209 21:44:09.461266 22542570456896 run_lib.py:133] step: 335300, training_loss: 2.61816e-02
I0209 21:44:09.617283 22542570456896 run_lib.py:146] step: 335300, eval_loss: 2.56791e-02
I0209 21:44:27.054388 22542570456896 run_lib.py:133] step: 335350, training_loss: 2.50568e-02
I0209 21:44:44.668632 22542570456896 run_lib.py:133] step: 335400, training_loss: 3.03000e-02
I0209 21:44:44.825259 22542570456896 run_lib.py:146] step: 335400, eval_loss: 3.02218e-02
I0209 21:45:02.243466 22542570456896 run_lib.py:133] step: 335450, training_loss: 2.72052e-02
I0209 21:45:19.631846 22542570456896 run_lib.py:133] step: 335500, training_loss: 2.68730e-02
I0209 21:45:19.791060 22542570456896 run_lib.py:146] step: 335500, eval_loss: 2.63936e-02
I0209 21:45:37.193542 22542570456896 run_lib.py:133] step: 335550, training_loss: 3.05122e-02
I0209 21:45:54.796637 22542570456896 run_lib.py:133] step: 335600, training_loss: 2.95830e-02
I0209 21:45:54.955321 22542570456896 run_lib.py:146] step: 335600, eval_loss: 3.85979e-02
I0209 21:46:12.387942 22542570456896 run_lib.py:133] step: 335650, training_loss: 2.28786e-02
I0209 21:46:29.925592 22542570456896 run_lib.py:133] step: 335700, training_loss: 2.26791e-02
I0209 21:46:30.085521 22542570456896 run_lib.py:146] step: 335700, eval_loss: 2.45081e-02
I0209 21:46:47.474465 22542570456896 run_lib.py:133] step: 335750, training_loss: 2.58706e-02
I0209 21:47:04.873318 22542570456896 run_lib.py:133] step: 335800, training_loss: 2.44764e-02
I0209 21:47:05.028011 22542570456896 run_lib.py:146] step: 335800, eval_loss: 3.74637e-02
I0209 21:47:22.602814 22542570456896 run_lib.py:133] step: 335850, training_loss: 2.43375e-02
I0209 21:47:40.123954 22542570456896 run_lib.py:133] step: 335900, training_loss: 2.85286e-02
I0209 21:47:40.280736 22542570456896 run_lib.py:146] step: 335900, eval_loss: 3.15764e-02
I0209 21:47:57.728158 22542570456896 run_lib.py:133] step: 335950, training_loss: 2.93049e-02
I0209 21:48:15.163571 22542570456896 run_lib.py:133] step: 336000, training_loss: 3.68116e-02
I0209 21:48:15.315289 22542570456896 run_lib.py:146] step: 336000, eval_loss: 3.74179e-02
I0209 21:48:32.889789 22542570456896 run_lib.py:133] step: 336050, training_loss: 2.69010e-02
I0209 21:48:50.326839 22542570456896 run_lib.py:133] step: 336100, training_loss: 3.59225e-02
I0209 21:48:50.482668 22542570456896 run_lib.py:146] step: 336100, eval_loss: 2.70926e-02
I0209 21:49:08.020642 22542570456896 run_lib.py:133] step: 336150, training_loss: 2.47486e-02
I0209 21:49:25.415344 22542570456896 run_lib.py:133] step: 336200, training_loss: 2.48430e-02
I0209 21:49:25.586327 22542570456896 run_lib.py:146] step: 336200, eval_loss: 2.88691e-02
I0209 21:49:43.246906 22542570456896 run_lib.py:133] step: 336250, training_loss: 2.67073e-02
I0209 21:50:00.674721 22542570456896 run_lib.py:133] step: 336300, training_loss: 2.57112e-02
I0209 21:50:00.831646 22542570456896 run_lib.py:146] step: 336300, eval_loss: 2.83400e-02
I0209 21:50:18.252729 22542570456896 run_lib.py:133] step: 336350, training_loss: 3.07829e-02
I0209 21:50:35.806425 22542570456896 run_lib.py:133] step: 336400, training_loss: 2.67057e-02
I0209 21:50:35.960787 22542570456896 run_lib.py:146] step: 336400, eval_loss: 2.94983e-02
I0209 21:50:53.378781 22542570456896 run_lib.py:133] step: 336450, training_loss: 2.98143e-02
I0209 21:51:10.922003 22542570456896 run_lib.py:133] step: 336500, training_loss: 2.70729e-02
I0209 21:51:11.086624 22542570456896 run_lib.py:146] step: 336500, eval_loss: 2.73012e-02
I0209 21:51:28.539078 22542570456896 run_lib.py:133] step: 336550, training_loss: 2.09296e-02
I0209 21:51:45.968702 22542570456896 run_lib.py:133] step: 336600, training_loss: 3.68737e-02
I0209 21:51:46.133348 22542570456896 run_lib.py:146] step: 336600, eval_loss: 2.40699e-02
I0209 21:52:03.732947 22542570456896 run_lib.py:133] step: 336650, training_loss: 2.98809e-02
I0209 21:52:21.140377 22542570456896 run_lib.py:133] step: 336700, training_loss: 2.49307e-02
I0209 21:52:21.304272 22542570456896 run_lib.py:146] step: 336700, eval_loss: 3.05648e-02
I0209 21:52:38.716530 22542570456896 run_lib.py:133] step: 336750, training_loss: 2.33998e-02
I0209 21:52:56.306027 22542570456896 run_lib.py:133] step: 336800, training_loss: 2.59830e-02
I0209 21:52:56.462105 22542570456896 run_lib.py:146] step: 336800, eval_loss: 2.74027e-02
I0209 21:53:13.900139 22542570456896 run_lib.py:133] step: 336850, training_loss: 2.59888e-02
I0209 21:53:31.333188 22542570456896 run_lib.py:133] step: 336900, training_loss: 2.54540e-02
I0209 21:53:31.672284 22542570456896 run_lib.py:146] step: 336900, eval_loss: 2.89587e-02
I0209 21:53:49.045494 22542570456896 run_lib.py:133] step: 336950, training_loss: 2.94730e-02
I0209 21:54:06.492102 22542570456896 run_lib.py:133] step: 337000, training_loss: 2.54993e-02
I0209 21:54:06.647373 22542570456896 run_lib.py:146] step: 337000, eval_loss: 2.72589e-02
I0209 21:54:24.097023 22542570456896 run_lib.py:133] step: 337050, training_loss: 2.82839e-02
I0209 21:54:41.545073 22542570456896 run_lib.py:133] step: 337100, training_loss: 3.21174e-02
I0209 21:54:41.700617 22542570456896 run_lib.py:146] step: 337100, eval_loss: 3.25665e-02
I0209 21:54:59.282419 22542570456896 run_lib.py:133] step: 337150, training_loss: 3.34713e-02
I0209 21:55:16.773166 22542570456896 run_lib.py:133] step: 337200, training_loss: 2.37706e-02
I0209 21:55:16.928357 22542570456896 run_lib.py:146] step: 337200, eval_loss: 2.83483e-02
I0209 21:55:34.341358 22542570456896 run_lib.py:133] step: 337250, training_loss: 2.97572e-02
I0209 21:55:51.773501 22542570456896 run_lib.py:133] step: 337300, training_loss: 3.08797e-02
I0209 21:55:51.927362 22542570456896 run_lib.py:146] step: 337300, eval_loss: 3.52962e-02
I0209 21:56:09.517414 22542570456896 run_lib.py:133] step: 337350, training_loss: 2.60256e-02
I0209 21:56:27.084865 22542570456896 run_lib.py:133] step: 337400, training_loss: 2.72047e-02
I0209 21:56:27.240561 22542570456896 run_lib.py:146] step: 337400, eval_loss: 2.81446e-02
I0209 21:56:44.697251 22542570456896 run_lib.py:133] step: 337450, training_loss: 2.98689e-02
I0209 21:57:02.176644 22542570456896 run_lib.py:133] step: 337500, training_loss: 2.96927e-02
I0209 21:57:02.332536 22542570456896 run_lib.py:146] step: 337500, eval_loss: 2.38623e-02
I0209 21:57:19.858695 22542570456896 run_lib.py:133] step: 337550, training_loss: 2.99510e-02
I0209 21:57:37.262977 22542570456896 run_lib.py:133] step: 337600, training_loss: 3.20808e-02
I0209 21:57:37.422459 22542570456896 run_lib.py:146] step: 337600, eval_loss: 3.32050e-02
I0209 21:57:54.998821 22542570456896 run_lib.py:133] step: 337650, training_loss: 2.42152e-02
I0209 21:58:12.459116 22542570456896 run_lib.py:133] step: 337700, training_loss: 2.85785e-02
I0209 21:58:12.615633 22542570456896 run_lib.py:146] step: 337700, eval_loss: 2.37217e-02
I0209 21:58:30.199196 22542570456896 run_lib.py:133] step: 337750, training_loss: 2.62222e-02
I0209 21:58:47.621508 22542570456896 run_lib.py:133] step: 337800, training_loss: 2.47080e-02
I0209 21:58:47.777320 22542570456896 run_lib.py:146] step: 337800, eval_loss: 3.66639e-02
I0209 21:59:05.214438 22542570456896 run_lib.py:133] step: 337850, training_loss: 3.13625e-02
I0209 21:59:22.792376 22542570456896 run_lib.py:133] step: 337900, training_loss: 3.43665e-02
I0209 21:59:22.955427 22542570456896 run_lib.py:146] step: 337900, eval_loss: 2.16704e-02
I0209 21:59:40.463109 22542570456896 run_lib.py:133] step: 337950, training_loss: 3.39055e-02
I0209 21:59:58.077519 22542570456896 run_lib.py:133] step: 338000, training_loss: 3.02027e-02
I0209 21:59:58.236258 22542570456896 run_lib.py:146] step: 338000, eval_loss: 2.27995e-02
I0209 22:00:15.646711 22542570456896 run_lib.py:133] step: 338050, training_loss: 3.11562e-02
I0209 22:00:33.102312 22542570456896 run_lib.py:133] step: 338100, training_loss: 2.13334e-02
I0209 22:00:33.267635 22542570456896 run_lib.py:146] step: 338100, eval_loss: 2.57259e-02
I0209 22:00:50.814486 22542570456896 run_lib.py:133] step: 338150, training_loss: 2.89080e-02
I0209 22:01:08.265902 22542570456896 run_lib.py:133] step: 338200, training_loss: 2.76533e-02
I0209 22:01:08.434771 22542570456896 run_lib.py:146] step: 338200, eval_loss: 2.60942e-02
I0209 22:01:25.951772 22542570456896 run_lib.py:133] step: 338250, training_loss: 2.58428e-02
I0209 22:01:43.409499 22542570456896 run_lib.py:133] step: 338300, training_loss: 2.60163e-02
I0209 22:01:43.563103 22542570456896 run_lib.py:146] step: 338300, eval_loss: 3.36712e-02
I0209 22:02:01.224198 22542570456896 run_lib.py:133] step: 338350, training_loss: 2.51904e-02
I0209 22:02:18.689027 22542570456896 run_lib.py:133] step: 338400, training_loss: 3.33851e-02
I0209 22:02:18.843634 22542570456896 run_lib.py:146] step: 338400, eval_loss: 3.06735e-02
I0209 22:02:36.298407 22542570456896 run_lib.py:133] step: 338450, training_loss: 3.12193e-02
I0209 22:02:53.706830 22542570456896 run_lib.py:133] step: 338500, training_loss: 3.64375e-02
I0209 22:02:53.882409 22542570456896 run_lib.py:146] step: 338500, eval_loss: 3.83831e-02
I0209 22:03:11.353382 22542570456896 run_lib.py:133] step: 338550, training_loss: 3.26553e-02
I0209 22:03:28.792724 22542570456896 run_lib.py:133] step: 338600, training_loss: 2.95068e-02
I0209 22:03:28.954548 22542570456896 run_lib.py:146] step: 338600, eval_loss: 3.22088e-02
I0209 22:03:46.613706 22542570456896 run_lib.py:133] step: 338650, training_loss: 2.84073e-02
I0209 22:04:04.061992 22542570456896 run_lib.py:133] step: 338700, training_loss: 3.40188e-02
I0209 22:04:04.227482 22542570456896 run_lib.py:146] step: 338700, eval_loss: 3.00870e-02
I0209 22:04:21.697836 22542570456896 run_lib.py:133] step: 338750, training_loss: 3.12862e-02
I0209 22:04:39.161644 22542570456896 run_lib.py:133] step: 338800, training_loss: 2.71364e-02
I0209 22:04:39.315145 22542570456896 run_lib.py:146] step: 338800, eval_loss: 3.49563e-02
I0209 22:04:56.964669 22542570456896 run_lib.py:133] step: 338850, training_loss: 2.46047e-02
I0209 22:05:14.409147 22542570456896 run_lib.py:133] step: 338900, training_loss: 2.83416e-02
I0209 22:05:14.564529 22542570456896 run_lib.py:146] step: 338900, eval_loss: 3.52767e-02
I0209 22:05:32.097335 22542570456896 run_lib.py:133] step: 338950, training_loss: 2.69270e-02
I0209 22:05:49.523935 22542570456896 run_lib.py:133] step: 339000, training_loss: 2.56099e-02
I0209 22:05:49.687538 22542570456896 run_lib.py:146] step: 339000, eval_loss: 2.67969e-02
I0209 22:06:07.341674 22542570456896 run_lib.py:133] step: 339050, training_loss: 2.85252e-02
I0209 22:06:24.793855 22542570456896 run_lib.py:133] step: 339100, training_loss: 3.29012e-02
I0209 22:06:24.954501 22542570456896 run_lib.py:146] step: 339100, eval_loss: 3.19648e-02
I0209 22:06:42.548663 22542570456896 run_lib.py:133] step: 339150, training_loss: 2.76419e-02
I0209 22:06:59.957054 22542570456896 run_lib.py:133] step: 339200, training_loss: 2.74804e-02
I0209 22:07:00.112422 22542570456896 run_lib.py:146] step: 339200, eval_loss: 2.63368e-02
I0209 22:07:17.537376 22542570456896 run_lib.py:133] step: 339250, training_loss: 3.28336e-02
I0209 22:07:35.077910 22542570456896 run_lib.py:133] step: 339300, training_loss: 3.08137e-02
I0209 22:07:35.229392 22542570456896 run_lib.py:146] step: 339300, eval_loss: 2.32795e-02
I0209 22:07:52.670289 22542570456896 run_lib.py:133] step: 339350, training_loss: 2.74027e-02
I0209 22:08:10.109803 22542570456896 run_lib.py:133] step: 339400, training_loss: 2.59195e-02
I0209 22:08:10.268574 22542570456896 run_lib.py:146] step: 339400, eval_loss: 2.73307e-02
I0209 22:08:27.915364 22542570456896 run_lib.py:133] step: 339450, training_loss: 3.00793e-02
I0209 22:08:45.490675 22542570456896 run_lib.py:133] step: 339500, training_loss: 2.31285e-02
I0209 22:08:45.653662 22542570456896 run_lib.py:146] step: 339500, eval_loss: 2.73790e-02
I0209 22:09:03.045829 22542570456896 run_lib.py:133] step: 339550, training_loss: 2.01463e-02
I0209 22:09:20.421326 22542570456896 run_lib.py:133] step: 339600, training_loss: 3.46207e-02
I0209 22:09:20.582384 22542570456896 run_lib.py:146] step: 339600, eval_loss: 2.63778e-02
I0209 22:09:37.948014 22542570456896 run_lib.py:133] step: 339650, training_loss: 3.01861e-02
I0209 22:09:55.595481 22542570456896 run_lib.py:133] step: 339700, training_loss: 3.58252e-02
I0209 22:09:55.751707 22542570456896 run_lib.py:146] step: 339700, eval_loss: 2.83131e-02
I0209 22:10:13.218959 22542570456896 run_lib.py:133] step: 339750, training_loss: 2.79484e-02
I0209 22:10:30.626218 22542570456896 run_lib.py:133] step: 339800, training_loss: 2.51295e-02
I0209 22:10:30.778370 22542570456896 run_lib.py:146] step: 339800, eval_loss: 2.97525e-02
I0209 22:10:48.201801 22542570456896 run_lib.py:133] step: 339850, training_loss: 2.77786e-02
I0209 22:11:05.756830 22542570456896 run_lib.py:133] step: 339900, training_loss: 2.07573e-02
I0209 22:11:05.933331 22542570456896 run_lib.py:146] step: 339900, eval_loss: 2.61205e-02
I0209 22:11:23.409927 22542570456896 run_lib.py:133] step: 339950, training_loss: 3.29148e-02
I0209 22:11:40.981747 22542570456896 run_lib.py:133] step: 340000, training_loss: 3.22189e-02
I0209 22:11:41.679223 22542570456896 run_lib.py:146] step: 340000, eval_loss: 2.21770e-02
I0209 22:12:01.685477 22542570456896 run_lib.py:133] step: 340050, training_loss: 2.85726e-02
I0209 22:12:19.100033 22542570456896 run_lib.py:133] step: 340100, training_loss: 3.11309e-02
I0209 22:12:19.256321 22542570456896 run_lib.py:146] step: 340100, eval_loss: 3.23270e-02
I0209 22:12:36.660165 22542570456896 run_lib.py:133] step: 340150, training_loss: 2.75023e-02
I0209 22:12:54.248596 22542570456896 run_lib.py:133] step: 340200, training_loss: 2.74521e-02
I0209 22:12:54.405525 22542570456896 run_lib.py:146] step: 340200, eval_loss: 3.07297e-02
I0209 22:13:11.857443 22542570456896 run_lib.py:133] step: 340250, training_loss: 2.04324e-02
I0209 22:13:29.387428 22542570456896 run_lib.py:133] step: 340300, training_loss: 3.03184e-02
I0209 22:13:29.538350 22542570456896 run_lib.py:146] step: 340300, eval_loss: 3.18974e-02
I0209 22:13:46.985770 22542570456896 run_lib.py:133] step: 340350, training_loss: 3.05562e-02
I0209 22:14:04.406263 22542570456896 run_lib.py:133] step: 340400, training_loss: 2.64291e-02
I0209 22:14:04.563310 22542570456896 run_lib.py:146] step: 340400, eval_loss: 2.51730e-02
I0209 22:14:22.115208 22542570456896 run_lib.py:133] step: 340450, training_loss: 2.50528e-02
I0209 22:14:39.600984 22542570456896 run_lib.py:133] step: 340500, training_loss: 3.36631e-02
I0209 22:14:39.776352 22542570456896 run_lib.py:146] step: 340500, eval_loss: 2.41096e-02
I0209 22:14:57.223590 22542570456896 run_lib.py:133] step: 340550, training_loss: 3.24914e-02
I0209 22:15:14.725088 22542570456896 run_lib.py:133] step: 340600, training_loss: 3.02602e-02
I0209 22:15:14.888364 22542570456896 run_lib.py:146] step: 340600, eval_loss: 3.14376e-02
I0209 22:15:32.466751 22542570456896 run_lib.py:133] step: 340650, training_loss: 2.47493e-02
I0209 22:15:49.874137 22542570456896 run_lib.py:133] step: 340700, training_loss: 3.00060e-02
I0209 22:15:50.030318 22542570456896 run_lib.py:146] step: 340700, eval_loss: 2.74272e-02
I0209 22:16:07.592009 22542570456896 run_lib.py:133] step: 340750, training_loss: 2.48169e-02
I0209 22:16:25.027519 22542570456896 run_lib.py:133] step: 340800, training_loss: 2.80375e-02
I0209 22:16:25.182615 22542570456896 run_lib.py:146] step: 340800, eval_loss: 3.01820e-02
I0209 22:16:42.820173 22542570456896 run_lib.py:133] step: 340850, training_loss: 3.43518e-02
I0209 22:17:00.252257 22542570456896 run_lib.py:133] step: 340900, training_loss: 2.98023e-02
I0209 22:17:00.406171 22542570456896 run_lib.py:146] step: 340900, eval_loss: 3.30387e-02
I0209 22:17:17.704073 22542570456896 run_lib.py:133] step: 340950, training_loss: 3.23224e-02
I0209 22:17:35.194955 22542570456896 run_lib.py:133] step: 341000, training_loss: 2.79438e-02
I0209 22:17:35.351360 22542570456896 run_lib.py:146] step: 341000, eval_loss: 2.66733e-02
I0209 22:17:52.678452 22542570456896 run_lib.py:133] step: 341050, training_loss: 2.92637e-02
I0209 22:18:10.210066 22542570456896 run_lib.py:133] step: 341100, training_loss: 2.41494e-02
I0209 22:18:10.367425 22542570456896 run_lib.py:146] step: 341100, eval_loss: 2.63687e-02
I0209 22:18:27.841237 22542570456896 run_lib.py:133] step: 341150, training_loss: 2.62780e-02
I0209 22:18:45.260651 22542570456896 run_lib.py:133] step: 341200, training_loss: 2.97260e-02
I0209 22:18:45.415065 22542570456896 run_lib.py:146] step: 341200, eval_loss: 2.51460e-02
I0209 22:19:03.048175 22542570456896 run_lib.py:133] step: 341250, training_loss: 3.08973e-02
I0209 22:19:20.473075 22542570456896 run_lib.py:133] step: 341300, training_loss: 2.53384e-02
I0209 22:19:20.625433 22542570456896 run_lib.py:146] step: 341300, eval_loss: 2.26122e-02
I0209 22:19:38.022964 22542570456896 run_lib.py:133] step: 341350, training_loss: 2.15312e-02
I0209 22:19:55.613149 22542570456896 run_lib.py:133] step: 341400, training_loss: 3.14264e-02
I0209 22:19:55.793278 22542570456896 run_lib.py:146] step: 341400, eval_loss: 3.04522e-02
I0209 22:20:13.240292 22542570456896 run_lib.py:133] step: 341450, training_loss: 3.01070e-02
I0209 22:20:30.688683 22542570456896 run_lib.py:133] step: 341500, training_loss: 3.08320e-02
I0209 22:20:30.844670 22542570456896 run_lib.py:146] step: 341500, eval_loss: 2.93802e-02
I0209 22:20:48.382019 22542570456896 run_lib.py:133] step: 341550, training_loss: 2.30464e-02
I0209 22:21:05.813317 22542570456896 run_lib.py:133] step: 341600, training_loss: 3.81208e-02
I0209 22:21:05.967881 22542570456896 run_lib.py:146] step: 341600, eval_loss: 2.49569e-02
I0209 22:21:23.343306 22542570456896 run_lib.py:133] step: 341650, training_loss: 3.01403e-02
I0209 22:21:40.853524 22542570456896 run_lib.py:133] step: 341700, training_loss: 2.42993e-02
I0209 22:21:41.007268 22542570456896 run_lib.py:146] step: 341700, eval_loss: 3.07584e-02
I0209 22:21:58.618062 22542570456896 run_lib.py:133] step: 341750, training_loss: 2.82013e-02
I0209 22:22:16.143943 22542570456896 run_lib.py:133] step: 341800, training_loss: 2.71199e-02
I0209 22:22:16.297292 22542570456896 run_lib.py:146] step: 341800, eval_loss: 2.60810e-02
I0209 22:22:33.686091 22542570456896 run_lib.py:133] step: 341850, training_loss: 2.14934e-02
I0209 22:22:51.102079 22542570456896 run_lib.py:133] step: 341900, training_loss: 2.56382e-02
I0209 22:22:51.276867 22542570456896 run_lib.py:146] step: 341900, eval_loss: 2.82121e-02
I0209 22:23:08.897698 22542570456896 run_lib.py:133] step: 341950, training_loss: 2.44951e-02
I0209 22:23:26.327272 22542570456896 run_lib.py:133] step: 342000, training_loss: 2.76140e-02
I0209 22:23:26.483573 22542570456896 run_lib.py:146] step: 342000, eval_loss: 3.50752e-02
I0209 22:23:44.043693 22542570456896 run_lib.py:133] step: 342050, training_loss: 3.00650e-02
I0209 22:24:01.457924 22542570456896 run_lib.py:133] step: 342100, training_loss: 2.72376e-02
I0209 22:24:01.614060 22542570456896 run_lib.py:146] step: 342100, eval_loss: 2.77341e-02
I0209 22:24:19.198951 22542570456896 run_lib.py:133] step: 342150, training_loss: 2.67687e-02
I0209 22:24:36.643011 22542570456896 run_lib.py:133] step: 342200, training_loss: 2.59101e-02
I0209 22:24:36.797168 22542570456896 run_lib.py:146] step: 342200, eval_loss: 3.10088e-02
I0209 22:24:54.413488 22542570456896 run_lib.py:133] step: 342250, training_loss: 2.66920e-02
I0209 22:25:11.814033 22542570456896 run_lib.py:133] step: 342300, training_loss: 2.76464e-02
I0209 22:25:11.978326 22542570456896 run_lib.py:146] step: 342300, eval_loss: 3.14594e-02
I0209 22:25:29.381220 22542570456896 run_lib.py:133] step: 342350, training_loss: 2.57631e-02
I0209 22:25:46.932688 22542570456896 run_lib.py:133] step: 342400, training_loss: 3.01719e-02
I0209 22:25:47.091606 22542570456896 run_lib.py:146] step: 342400, eval_loss: 2.45801e-02
I0209 22:26:04.504410 22542570456896 run_lib.py:133] step: 342450, training_loss: 2.60837e-02
I0209 22:26:21.914301 22542570456896 run_lib.py:133] step: 342500, training_loss: 2.72658e-02
I0209 22:26:22.080885 22542570456896 run_lib.py:146] step: 342500, eval_loss: 2.94486e-02
I0209 22:26:39.699886 22542570456896 run_lib.py:133] step: 342550, training_loss: 2.85793e-02
I0209 22:26:57.125714 22542570456896 run_lib.py:133] step: 342600, training_loss: 3.06840e-02
I0209 22:26:57.280570 22542570456896 run_lib.py:146] step: 342600, eval_loss: 2.73194e-02
I0209 22:27:14.844547 22542570456896 run_lib.py:133] step: 342650, training_loss: 2.41391e-02
I0209 22:27:32.252917 22542570456896 run_lib.py:133] step: 342700, training_loss: 3.05015e-02
I0209 22:27:32.404431 22542570456896 run_lib.py:146] step: 342700, eval_loss: 2.92736e-02
I0209 22:27:49.860956 22542570456896 run_lib.py:133] step: 342750, training_loss: 2.48146e-02
I0209 22:28:07.467579 22542570456896 run_lib.py:133] step: 342800, training_loss: 2.41233e-02
I0209 22:28:07.642769 22542570456896 run_lib.py:146] step: 342800, eval_loss: 3.16792e-02
I0209 22:28:25.074313 22542570456896 run_lib.py:133] step: 342850, training_loss: 2.89637e-02
I0209 22:28:42.531396 22542570456896 run_lib.py:133] step: 342900, training_loss: 3.29467e-02
I0209 22:28:42.689671 22542570456896 run_lib.py:146] step: 342900, eval_loss: 2.31540e-02
I0209 22:29:00.155666 22542570456896 run_lib.py:133] step: 342950, training_loss: 2.75593e-02
I0209 22:29:17.737547 22542570456896 run_lib.py:133] step: 343000, training_loss: 2.68510e-02
I0209 22:29:17.893157 22542570456896 run_lib.py:146] step: 343000, eval_loss: 3.27204e-02
I0209 22:29:35.315825 22542570456896 run_lib.py:133] step: 343050, training_loss: 2.80666e-02
I0209 22:29:52.851177 22542570456896 run_lib.py:133] step: 343100, training_loss: 2.63740e-02
I0209 22:29:53.007173 22542570456896 run_lib.py:146] step: 343100, eval_loss: 2.34026e-02
I0209 22:30:10.427267 22542570456896 run_lib.py:133] step: 343150, training_loss: 2.73753e-02
I0209 22:30:27.832433 22542570456896 run_lib.py:133] step: 343200, training_loss: 2.66042e-02
I0209 22:30:27.985437 22542570456896 run_lib.py:146] step: 343200, eval_loss: 3.14124e-02
I0209 22:30:45.575414 22542570456896 run_lib.py:133] step: 343250, training_loss: 3.53471e-02
I0209 22:31:03.096478 22542570456896 run_lib.py:133] step: 343300, training_loss: 2.80668e-02
I0209 22:31:03.274488 22542570456896 run_lib.py:146] step: 343300, eval_loss: 2.82350e-02
I0209 22:31:20.757631 22542570456896 run_lib.py:133] step: 343350, training_loss: 3.39245e-02
I0209 22:31:38.175839 22542570456896 run_lib.py:133] step: 343400, training_loss: 3.26258e-02
I0209 22:31:38.335701 22542570456896 run_lib.py:146] step: 343400, eval_loss: 2.47986e-02
I0209 22:31:55.955275 22542570456896 run_lib.py:133] step: 343450, training_loss: 2.91672e-02
I0209 22:32:13.373357 22542570456896 run_lib.py:133] step: 343500, training_loss: 2.63091e-02
I0209 22:32:13.531383 22542570456896 run_lib.py:146] step: 343500, eval_loss: 2.61545e-02
I0209 22:32:31.114521 22542570456896 run_lib.py:133] step: 343550, training_loss: 2.78280e-02
I0209 22:32:48.571390 22542570456896 run_lib.py:133] step: 343600, training_loss: 3.17162e-02
I0209 22:32:48.723519 22542570456896 run_lib.py:146] step: 343600, eval_loss: 2.58753e-02
I0209 22:33:06.383545 22542570456896 run_lib.py:133] step: 343650, training_loss: 3.04918e-02
I0209 22:33:23.799351 22542570456896 run_lib.py:133] step: 343700, training_loss: 2.85611e-02
I0209 22:33:23.954468 22542570456896 run_lib.py:146] step: 343700, eval_loss: 2.63844e-02
I0209 22:33:41.410573 22542570456896 run_lib.py:133] step: 343750, training_loss: 2.43392e-02
I0209 22:33:58.983642 22542570456896 run_lib.py:133] step: 343800, training_loss: 2.93932e-02
I0209 22:33:59.142583 22542570456896 run_lib.py:146] step: 343800, eval_loss: 3.46948e-02
I0209 22:34:16.553841 22542570456896 run_lib.py:133] step: 343850, training_loss: 2.63400e-02
I0209 22:34:34.164387 22542570456896 run_lib.py:133] step: 343900, training_loss: 2.84717e-02
I0209 22:34:34.329086 22542570456896 run_lib.py:146] step: 343900, eval_loss: 2.23694e-02
I0209 22:34:51.826300 22542570456896 run_lib.py:133] step: 343950, training_loss: 2.33903e-02
I0209 22:35:09.242357 22542570456896 run_lib.py:133] step: 344000, training_loss: 3.14346e-02
I0209 22:35:09.403760 22542570456896 run_lib.py:146] step: 344000, eval_loss: 3.49081e-02
I0209 22:35:27.024124 22542570456896 run_lib.py:133] step: 344050, training_loss: 2.80593e-02
I0209 22:35:44.461233 22542570456896 run_lib.py:133] step: 344100, training_loss: 3.50748e-02
I0209 22:35:44.617048 22542570456896 run_lib.py:146] step: 344100, eval_loss: 2.84648e-02
I0209 22:36:02.052357 22542570456896 run_lib.py:133] step: 344150, training_loss: 3.45474e-02
I0209 22:36:19.689943 22542570456896 run_lib.py:133] step: 344200, training_loss: 3.31033e-02
I0209 22:36:19.853721 22542570456896 run_lib.py:146] step: 344200, eval_loss: 2.65201e-02
I0209 22:36:37.305578 22542570456896 run_lib.py:133] step: 344250, training_loss: 2.67473e-02
I0209 22:36:54.761601 22542570456896 run_lib.py:133] step: 344300, training_loss: 3.04205e-02
I0209 22:36:55.107135 22542570456896 run_lib.py:146] step: 344300, eval_loss: 3.14541e-02
I0209 22:37:12.512577 22542570456896 run_lib.py:133] step: 344350, training_loss: 2.45056e-02
I0209 22:37:29.932647 22542570456896 run_lib.py:133] step: 344400, training_loss: 2.80698e-02
I0209 22:37:30.098313 22542570456896 run_lib.py:146] step: 344400, eval_loss: 2.45440e-02
I0209 22:37:47.550222 22542570456896 run_lib.py:133] step: 344450, training_loss: 1.92533e-02
I0209 22:38:05.024832 22542570456896 run_lib.py:133] step: 344500, training_loss: 2.97750e-02
I0209 22:38:05.180536 22542570456896 run_lib.py:146] step: 344500, eval_loss: 2.56066e-02
I0209 22:38:22.822890 22542570456896 run_lib.py:133] step: 344550, training_loss: 3.39306e-02
I0209 22:38:40.321136 22542570456896 run_lib.py:133] step: 344600, training_loss: 2.62938e-02
I0209 22:38:40.473451 22542570456896 run_lib.py:146] step: 344600, eval_loss: 2.63524e-02
I0209 22:38:57.884087 22542570456896 run_lib.py:133] step: 344650, training_loss: 2.90726e-02
I0209 22:39:15.302915 22542570456896 run_lib.py:133] step: 344700, training_loss: 2.98150e-02
I0209 22:39:15.472232 22542570456896 run_lib.py:146] step: 344700, eval_loss: 3.35929e-02
I0209 22:39:33.059267 22542570456896 run_lib.py:133] step: 344750, training_loss: 3.31263e-02
I0209 22:39:50.584594 22542570456896 run_lib.py:133] step: 344800, training_loss: 2.27201e-02
I0209 22:39:50.739100 22542570456896 run_lib.py:146] step: 344800, eval_loss: 2.58194e-02
I0209 22:40:08.141201 22542570456896 run_lib.py:133] step: 344850, training_loss: 2.68501e-02
I0209 22:40:25.586961 22542570456896 run_lib.py:133] step: 344900, training_loss: 2.65316e-02
I0209 22:40:25.748533 22542570456896 run_lib.py:146] step: 344900, eval_loss: 2.91392e-02
I0209 22:40:43.313552 22542570456896 run_lib.py:133] step: 344950, training_loss: 2.30828e-02
I0209 22:41:00.746638 22542570456896 run_lib.py:133] step: 345000, training_loss: 2.66312e-02
I0209 22:41:00.898978 22542570456896 run_lib.py:146] step: 345000, eval_loss: 2.25907e-02
I0209 22:41:18.520083 22542570456896 run_lib.py:133] step: 345050, training_loss: 2.58055e-02
I0209 22:41:35.939794 22542570456896 run_lib.py:133] step: 345100, training_loss: 2.91831e-02
I0209 22:41:36.092423 22542570456896 run_lib.py:146] step: 345100, eval_loss: 3.03424e-02
I0209 22:41:53.662014 22542570456896 run_lib.py:133] step: 345150, training_loss: 2.85282e-02
I0209 22:42:11.041893 22542570456896 run_lib.py:133] step: 345200, training_loss: 3.18636e-02
I0209 22:42:11.200615 22542570456896 run_lib.py:146] step: 345200, eval_loss: 2.71401e-02
I0209 22:42:28.637471 22542570456896 run_lib.py:133] step: 345250, training_loss: 3.22524e-02
I0209 22:42:46.251007 22542570456896 run_lib.py:133] step: 345300, training_loss: 2.39762e-02
I0209 22:42:46.407582 22542570456896 run_lib.py:146] step: 345300, eval_loss: 2.98329e-02
I0209 22:43:03.817848 22542570456896 run_lib.py:133] step: 345350, training_loss: 2.85873e-02
I0209 22:43:21.400500 22542570456896 run_lib.py:133] step: 345400, training_loss: 2.21654e-02
I0209 22:43:21.556781 22542570456896 run_lib.py:146] step: 345400, eval_loss: 2.49980e-02
I0209 22:43:38.993702 22542570456896 run_lib.py:133] step: 345450, training_loss: 2.25581e-02
I0209 22:43:56.411592 22542570456896 run_lib.py:133] step: 345500, training_loss: 2.60779e-02
I0209 22:43:56.560131 22542570456896 run_lib.py:146] step: 345500, eval_loss: 3.69416e-02
I0209 22:44:14.167734 22542570456896 run_lib.py:133] step: 345550, training_loss: 2.69499e-02
I0209 22:44:31.612651 22542570456896 run_lib.py:133] step: 345600, training_loss: 2.75747e-02
I0209 22:44:31.780101 22542570456896 run_lib.py:146] step: 345600, eval_loss: 3.65898e-02
I0209 22:44:49.223786 22542570456896 run_lib.py:133] step: 345650, training_loss: 3.04373e-02
I0209 22:45:06.653637 22542570456896 run_lib.py:133] step: 345700, training_loss: 3.16117e-02
I0209 22:45:06.820483 22542570456896 run_lib.py:146] step: 345700, eval_loss: 2.40484e-02
I0209 22:45:24.458803 22542570456896 run_lib.py:133] step: 345750, training_loss: 2.51980e-02
I0209 22:45:41.859515 22542570456896 run_lib.py:133] step: 345800, training_loss: 3.56522e-02
I0209 22:45:42.018446 22542570456896 run_lib.py:146] step: 345800, eval_loss: 2.41800e-02
I0209 22:45:59.524531 22542570456896 run_lib.py:133] step: 345850, training_loss: 3.25864e-02
I0209 22:46:17.019317 22542570456896 run_lib.py:133] step: 345900, training_loss: 2.68213e-02
I0209 22:46:17.175637 22542570456896 run_lib.py:146] step: 345900, eval_loss: 2.95610e-02
I0209 22:46:34.641182 22542570456896 run_lib.py:133] step: 345950, training_loss: 3.11290e-02
I0209 22:46:52.067090 22542570456896 run_lib.py:133] step: 346000, training_loss: 2.80325e-02
I0209 22:46:52.220069 22542570456896 run_lib.py:146] step: 346000, eval_loss: 2.76269e-02
I0209 22:47:09.839342 22542570456896 run_lib.py:133] step: 346050, training_loss: 2.51352e-02
I0209 22:47:27.344706 22542570456896 run_lib.py:133] step: 346100, training_loss: 2.39455e-02
I0209 22:47:27.500582 22542570456896 run_lib.py:146] step: 346100, eval_loss: 2.96262e-02
I0209 22:47:44.938036 22542570456896 run_lib.py:133] step: 346150, training_loss: 3.10970e-02
I0209 22:48:02.400209 22542570456896 run_lib.py:133] step: 346200, training_loss: 2.84051e-02
I0209 22:48:02.568265 22542570456896 run_lib.py:146] step: 346200, eval_loss: 2.85282e-02
I0209 22:48:20.175101 22542570456896 run_lib.py:133] step: 346250, training_loss: 3.35586e-02
I0209 22:48:37.575674 22542570456896 run_lib.py:133] step: 346300, training_loss: 2.58948e-02
I0209 22:48:37.737350 22542570456896 run_lib.py:146] step: 346300, eval_loss: 2.82683e-02
I0209 22:48:55.294221 22542570456896 run_lib.py:133] step: 346350, training_loss: 2.40213e-02
I0209 22:49:12.746186 22542570456896 run_lib.py:133] step: 346400, training_loss: 3.33321e-02
I0209 22:49:12.899583 22542570456896 run_lib.py:146] step: 346400, eval_loss: 3.50694e-02
I0209 22:49:30.567883 22542570456896 run_lib.py:133] step: 346450, training_loss: 2.65374e-02
I0209 22:49:47.965086 22542570456896 run_lib.py:133] step: 346500, training_loss: 2.46378e-02
I0209 22:49:48.116423 22542570456896 run_lib.py:146] step: 346500, eval_loss: 2.88848e-02
I0209 22:50:05.739747 22542570456896 run_lib.py:133] step: 346550, training_loss: 2.16898e-02
I0209 22:50:23.176420 22542570456896 run_lib.py:133] step: 346600, training_loss: 3.21167e-02
I0209 22:50:23.338505 22542570456896 run_lib.py:146] step: 346600, eval_loss: 2.85994e-02
I0209 22:50:40.739594 22542570456896 run_lib.py:133] step: 346650, training_loss: 3.46829e-02
I0209 22:50:58.309085 22542570456896 run_lib.py:133] step: 346700, training_loss: 2.92264e-02
I0209 22:50:58.489438 22542570456896 run_lib.py:146] step: 346700, eval_loss: 2.85188e-02
I0209 22:51:15.946118 22542570456896 run_lib.py:133] step: 346750, training_loss: 3.66029e-02
I0209 22:51:33.390234 22542570456896 run_lib.py:133] step: 346800, training_loss: 3.06403e-02
I0209 22:51:33.546592 22542570456896 run_lib.py:146] step: 346800, eval_loss: 3.46458e-02
I0209 22:51:51.218759 22542570456896 run_lib.py:133] step: 346850, training_loss: 2.58018e-02
I0209 22:52:08.750469 22542570456896 run_lib.py:133] step: 346900, training_loss: 2.78598e-02
I0209 22:52:08.911510 22542570456896 run_lib.py:146] step: 346900, eval_loss: 3.08973e-02
I0209 22:52:26.325579 22542570456896 run_lib.py:133] step: 346950, training_loss: 2.92281e-02
I0209 22:52:43.760045 22542570456896 run_lib.py:133] step: 347000, training_loss: 3.70767e-02
I0209 22:52:43.917576 22542570456896 run_lib.py:146] step: 347000, eval_loss: 2.88406e-02
I0209 22:53:01.404721 22542570456896 run_lib.py:133] step: 347050, training_loss: 2.65383e-02
I0209 22:53:19.035722 22542570456896 run_lib.py:133] step: 347100, training_loss: 2.35851e-02
I0209 22:53:19.201611 22542570456896 run_lib.py:146] step: 347100, eval_loss: 2.88260e-02
I0209 22:53:36.599068 22542570456896 run_lib.py:133] step: 347150, training_loss: 3.00893e-02
I0209 22:53:54.004787 22542570456896 run_lib.py:133] step: 347200, training_loss: 2.45709e-02
I0209 22:53:54.160490 22542570456896 run_lib.py:146] step: 347200, eval_loss: 2.70018e-02
I0209 22:54:11.613737 22542570456896 run_lib.py:133] step: 347250, training_loss: 2.84881e-02
I0209 22:54:29.262446 22542570456896 run_lib.py:133] step: 347300, training_loss: 2.76015e-02
I0209 22:54:29.421675 22542570456896 run_lib.py:146] step: 347300, eval_loss: 2.89682e-02
I0209 22:54:46.839371 22542570456896 run_lib.py:133] step: 347350, training_loss: 2.51438e-02
I0209 22:55:04.361814 22542570456896 run_lib.py:133] step: 347400, training_loss: 2.60709e-02
I0209 22:55:04.513473 22542570456896 run_lib.py:146] step: 347400, eval_loss: 3.17436e-02
I0209 22:55:21.930761 22542570456896 run_lib.py:133] step: 347450, training_loss: 2.53648e-02
I0209 22:55:39.354046 22542570456896 run_lib.py:133] step: 347500, training_loss: 3.63660e-02
I0209 22:55:39.504863 22542570456896 run_lib.py:146] step: 347500, eval_loss: 2.75599e-02
I0209 22:55:57.092459 22542570456896 run_lib.py:133] step: 347550, training_loss: 2.15044e-02
I0209 22:56:14.654324 22542570456896 run_lib.py:133] step: 347600, training_loss: 3.07771e-02
I0209 22:56:14.813374 22542570456896 run_lib.py:146] step: 347600, eval_loss: 2.34616e-02
I0209 22:56:32.283838 22542570456896 run_lib.py:133] step: 347650, training_loss: 3.16820e-02
I0209 22:56:49.686409 22542570456896 run_lib.py:133] step: 347700, training_loss: 3.03473e-02
I0209 22:56:49.839473 22542570456896 run_lib.py:146] step: 347700, eval_loss: 2.72174e-02
I0209 22:57:07.368448 22542570456896 run_lib.py:133] step: 347750, training_loss: 2.70288e-02
I0209 22:57:24.770340 22542570456896 run_lib.py:133] step: 347800, training_loss: 3.08624e-02
I0209 22:57:24.927144 22542570456896 run_lib.py:146] step: 347800, eval_loss: 2.37037e-02
I0209 22:57:42.539395 22542570456896 run_lib.py:133] step: 347850, training_loss: 2.36772e-02
I0209 22:57:59.986166 22542570456896 run_lib.py:133] step: 347900, training_loss: 2.65575e-02
I0209 22:58:00.139652 22542570456896 run_lib.py:146] step: 347900, eval_loss: 2.62732e-02
I0209 22:58:17.750340 22542570456896 run_lib.py:133] step: 347950, training_loss: 3.17484e-02
I0209 22:58:35.177169 22542570456896 run_lib.py:133] step: 348000, training_loss: 2.96418e-02
I0209 22:58:35.335416 22542570456896 run_lib.py:146] step: 348000, eval_loss: 3.22694e-02
I0209 22:58:52.763959 22542570456896 run_lib.py:133] step: 348050, training_loss: 2.68261e-02
I0209 22:59:10.333201 22542570456896 run_lib.py:133] step: 348100, training_loss: 3.51233e-02
I0209 22:59:10.509405 22542570456896 run_lib.py:146] step: 348100, eval_loss: 2.62815e-02
I0209 22:59:27.982214 22542570456896 run_lib.py:133] step: 348150, training_loss: 3.59687e-02
I0209 22:59:45.594564 22542570456896 run_lib.py:133] step: 348200, training_loss: 2.96109e-02
I0209 22:59:45.756609 22542570456896 run_lib.py:146] step: 348200, eval_loss: 2.95307e-02
I0209 23:00:03.217189 22542570456896 run_lib.py:133] step: 348250, training_loss: 2.33149e-02
I0209 23:00:20.630954 22542570456896 run_lib.py:133] step: 348300, training_loss: 3.43480e-02
I0209 23:00:20.793480 22542570456896 run_lib.py:146] step: 348300, eval_loss: 3.41011e-02
I0209 23:00:38.365892 22542570456896 run_lib.py:133] step: 348350, training_loss: 2.61240e-02
I0209 23:00:55.862590 22542570456896 run_lib.py:133] step: 348400, training_loss: 2.98327e-02
I0209 23:00:56.017567 22542570456896 run_lib.py:146] step: 348400, eval_loss: 3.25665e-02
I0209 23:01:13.481933 22542570456896 run_lib.py:133] step: 348450, training_loss: 2.78998e-02
I0209 23:01:31.096834 22542570456896 run_lib.py:133] step: 348500, training_loss: 2.57540e-02
I0209 23:01:31.254230 22542570456896 run_lib.py:146] step: 348500, eval_loss: 2.74778e-02
I0209 23:01:48.664816 22542570456896 run_lib.py:133] step: 348550, training_loss: 3.58835e-02
I0209 23:02:06.111534 22542570456896 run_lib.py:133] step: 348600, training_loss: 3.32794e-02
I0209 23:02:06.266475 22542570456896 run_lib.py:146] step: 348600, eval_loss: 2.82658e-02
I0209 23:02:23.745994 22542570456896 run_lib.py:133] step: 348650, training_loss: 3.29532e-02
I0209 23:02:41.231426 22542570456896 run_lib.py:133] step: 348700, training_loss: 2.88149e-02
I0209 23:02:41.384390 22542570456896 run_lib.py:146] step: 348700, eval_loss: 3.23897e-02
I0209 23:02:58.823653 22542570456896 run_lib.py:133] step: 348750, training_loss: 3.08581e-02
I0209 23:03:16.241554 22542570456896 run_lib.py:133] step: 348800, training_loss: 2.96581e-02
I0209 23:03:16.395400 22542570456896 run_lib.py:146] step: 348800, eval_loss: 3.56284e-02
I0209 23:03:33.973556 22542570456896 run_lib.py:133] step: 348850, training_loss: 3.36088e-02
I0209 23:03:51.442381 22542570456896 run_lib.py:133] step: 348900, training_loss: 2.52521e-02
I0209 23:03:51.594957 22542570456896 run_lib.py:146] step: 348900, eval_loss: 1.78056e-02
I0209 23:04:08.982630 22542570456896 run_lib.py:133] step: 348950, training_loss: 3.25793e-02
I0209 23:04:26.466962 22542570456896 run_lib.py:133] step: 349000, training_loss: 2.74665e-02
I0209 23:04:26.644975 22542570456896 run_lib.py:146] step: 349000, eval_loss: 3.01285e-02
I0209 23:04:44.251457 22542570456896 run_lib.py:133] step: 349050, training_loss: 2.29954e-02
I0209 23:05:01.726277 22542570456896 run_lib.py:133] step: 349100, training_loss: 2.72993e-02
I0209 23:05:01.881615 22542570456896 run_lib.py:146] step: 349100, eval_loss: 2.50697e-02
I0209 23:05:19.442438 22542570456896 run_lib.py:133] step: 349150, training_loss: 2.53760e-02
I0209 23:05:36.883962 22542570456896 run_lib.py:133] step: 349200, training_loss: 2.86622e-02
I0209 23:05:37.049076 22542570456896 run_lib.py:146] step: 349200, eval_loss: 2.84727e-02
I0209 23:05:54.624847 22542570456896 run_lib.py:133] step: 349250, training_loss: 2.52839e-02
I0209 23:06:12.067568 22542570456896 run_lib.py:133] step: 349300, training_loss: 2.38919e-02
I0209 23:06:12.219608 22542570456896 run_lib.py:146] step: 349300, eval_loss: 2.85924e-02
I0209 23:06:29.847989 22542570456896 run_lib.py:133] step: 349350, training_loss: 2.84498e-02
I0209 23:06:47.291928 22542570456896 run_lib.py:133] step: 349400, training_loss: 2.29735e-02
I0209 23:06:47.446388 22542570456896 run_lib.py:146] step: 349400, eval_loss: 3.31873e-02
I0209 23:07:04.839162 22542570456896 run_lib.py:133] step: 349450, training_loss: 3.52812e-02
I0209 23:07:22.404714 22542570456896 run_lib.py:133] step: 349500, training_loss: 2.93756e-02
I0209 23:07:22.581380 22542570456896 run_lib.py:146] step: 349500, eval_loss: 3.12473e-02
I0209 23:07:40.061902 22542570456896 run_lib.py:133] step: 349550, training_loss: 3.00326e-02
I0209 23:07:57.489227 22542570456896 run_lib.py:133] step: 349600, training_loss: 2.57509e-02
I0209 23:07:57.644611 22542570456896 run_lib.py:146] step: 349600, eval_loss: 3.11992e-02
I0209 23:08:15.315817 22542570456896 run_lib.py:133] step: 349650, training_loss: 3.08216e-02
I0209 23:08:32.762860 22542570456896 run_lib.py:133] step: 349700, training_loss: 2.52755e-02
I0209 23:08:32.918411 22542570456896 run_lib.py:146] step: 349700, eval_loss: 2.61868e-02
I0209 23:08:50.475930 22542570456896 run_lib.py:133] step: 349750, training_loss: 3.33601e-02
I0209 23:09:07.973405 22542570456896 run_lib.py:133] step: 349800, training_loss: 2.25732e-02
I0209 23:09:08.128563 22542570456896 run_lib.py:146] step: 349800, eval_loss: 2.84523e-02
I0209 23:09:25.610192 22542570456896 run_lib.py:133] step: 349850, training_loss: 2.33387e-02
I0209 23:09:43.241610 22542570456896 run_lib.py:133] step: 349900, training_loss: 2.81209e-02
I0209 23:09:43.397349 22542570456896 run_lib.py:146] step: 349900, eval_loss: 2.93334e-02
I0209 23:10:00.794673 22542570456896 run_lib.py:133] step: 349950, training_loss: 2.93219e-02
I0209 23:10:18.207390 22542570456896 run_lib.py:133] step: 350000, training_loss: 2.93779e-02
I0209 23:10:18.930602 22542570456896 run_lib.py:146] step: 350000, eval_loss: 2.72067e-02
I0209 23:10:39.014892 22542570456896 run_lib.py:133] step: 350050, training_loss: 2.79772e-02
I0209 23:10:56.514965 22542570456896 run_lib.py:133] step: 350100, training_loss: 2.69272e-02
I0209 23:10:56.673398 22542570456896 run_lib.py:146] step: 350100, eval_loss: 2.49481e-02
I0209 23:11:14.311409 22542570456896 run_lib.py:133] step: 350150, training_loss: 2.27378e-02
I0209 23:11:31.752856 22542570456896 run_lib.py:133] step: 350200, training_loss: 3.67579e-02
I0209 23:11:31.910110 22542570456896 run_lib.py:146] step: 350200, eval_loss: 2.94513e-02
I0209 23:11:49.409076 22542570456896 run_lib.py:133] step: 350250, training_loss: 2.40920e-02
I0209 23:12:06.856489 22542570456896 run_lib.py:133] step: 350300, training_loss: 3.12234e-02
I0209 23:12:07.016239 22542570456896 run_lib.py:146] step: 350300, eval_loss: 2.88016e-02
I0209 23:12:24.517492 22542570456896 run_lib.py:133] step: 350350, training_loss: 2.48461e-02
I0209 23:12:41.932907 22542570456896 run_lib.py:133] step: 350400, training_loss: 2.65793e-02
I0209 23:12:42.087349 22542570456896 run_lib.py:146] step: 350400, eval_loss: 2.41603e-02
I0209 23:12:59.662461 22542570456896 run_lib.py:133] step: 350450, training_loss: 2.79497e-02
I0209 23:13:17.156445 22542570456896 run_lib.py:133] step: 350500, training_loss: 2.37872e-02
I0209 23:13:17.314556 22542570456896 run_lib.py:146] step: 350500, eval_loss: 3.54879e-02
I0209 23:13:34.780779 22542570456896 run_lib.py:133] step: 350550, training_loss: 2.29676e-02
I0209 23:13:52.255650 22542570456896 run_lib.py:133] step: 350600, training_loss: 2.93610e-02
I0209 23:13:52.411551 22542570456896 run_lib.py:146] step: 350600, eval_loss: 2.75313e-02
I0209 23:14:10.011228 22542570456896 run_lib.py:133] step: 350650, training_loss: 2.90231e-02
I0209 23:14:27.455242 22542570456896 run_lib.py:133] step: 350700, training_loss: 2.82859e-02
I0209 23:14:27.613523 22542570456896 run_lib.py:146] step: 350700, eval_loss: 2.82620e-02
I0209 23:14:45.220101 22542570456896 run_lib.py:133] step: 350750, training_loss: 3.05466e-02
I0209 23:15:02.656227 22542570456896 run_lib.py:133] step: 350800, training_loss: 3.18576e-02
I0209 23:15:02.808271 22542570456896 run_lib.py:146] step: 350800, eval_loss: 2.74730e-02
I0209 23:15:20.359180 22542570456896 run_lib.py:133] step: 350850, training_loss: 3.55200e-02
I0209 23:15:37.814291 22542570456896 run_lib.py:133] step: 350900, training_loss: 3.07390e-02
I0209 23:15:37.987669 22542570456896 run_lib.py:146] step: 350900, eval_loss: 3.31954e-02
I0209 23:15:55.664233 22542570456896 run_lib.py:133] step: 350950, training_loss: 2.67858e-02
I0209 23:16:13.132347 22542570456896 run_lib.py:133] step: 351000, training_loss: 2.61342e-02
I0209 23:16:13.289562 22542570456896 run_lib.py:146] step: 351000, eval_loss: 3.94744e-02
I0209 23:16:30.714292 22542570456896 run_lib.py:133] step: 351050, training_loss: 3.08325e-02
I0209 23:16:48.258328 22542570456896 run_lib.py:133] step: 351100, training_loss: 2.68896e-02
I0209 23:16:48.414082 22542570456896 run_lib.py:146] step: 351100, eval_loss: 2.36225e-02
I0209 23:17:05.821469 22542570456896 run_lib.py:133] step: 351150, training_loss: 2.55676e-02
I0209 23:17:23.269392 22542570456896 run_lib.py:133] step: 351200, training_loss: 2.57139e-02
I0209 23:17:23.428640 22542570456896 run_lib.py:146] step: 351200, eval_loss: 2.91729e-02
I0209 23:17:41.061614 22542570456896 run_lib.py:133] step: 351250, training_loss: 2.64894e-02
I0209 23:17:58.621900 22542570456896 run_lib.py:133] step: 351300, training_loss: 2.70751e-02
I0209 23:17:58.774682 22542570456896 run_lib.py:146] step: 351300, eval_loss: 3.26059e-02
I0209 23:18:16.199314 22542570456896 run_lib.py:133] step: 351350, training_loss: 3.04805e-02
I0209 23:18:33.626772 22542570456896 run_lib.py:133] step: 351400, training_loss: 2.27131e-02
I0209 23:18:33.782734 22542570456896 run_lib.py:146] step: 351400, eval_loss: 2.75513e-02
I0209 23:18:51.271442 22542570456896 run_lib.py:133] step: 351450, training_loss: 2.78325e-02
I0209 23:19:08.933414 22542570456896 run_lib.py:133] step: 351500, training_loss: 2.39289e-02
I0209 23:19:09.091458 22542570456896 run_lib.py:146] step: 351500, eval_loss: 3.10289e-02
I0209 23:19:26.533285 22542570456896 run_lib.py:133] step: 351550, training_loss: 2.96102e-02
I0209 23:19:43.943255 22542570456896 run_lib.py:133] step: 351600, training_loss: 2.16896e-02
I0209 23:19:44.098236 22542570456896 run_lib.py:146] step: 351600, eval_loss: 2.48540e-02
I0209 23:20:01.508492 22542570456896 run_lib.py:133] step: 351650, training_loss: 2.69963e-02
I0209 23:20:19.090128 22542570456896 run_lib.py:133] step: 351700, training_loss: 2.02389e-02
I0209 23:20:19.247606 22542570456896 run_lib.py:146] step: 351700, eval_loss: 3.13140e-02
I0209 23:20:36.764632 22542570456896 run_lib.py:133] step: 351750, training_loss: 2.87432e-02
I0209 23:20:54.289219 22542570456896 run_lib.py:133] step: 351800, training_loss: 2.89017e-02
I0209 23:20:54.440417 22542570456896 run_lib.py:146] step: 351800, eval_loss: 3.32844e-02
I0209 23:21:11.817642 22542570456896 run_lib.py:133] step: 351850, training_loss: 2.70818e-02
I0209 23:21:29.230420 22542570456896 run_lib.py:133] step: 351900, training_loss: 2.56760e-02
I0209 23:21:29.393187 22542570456896 run_lib.py:146] step: 351900, eval_loss: 2.55797e-02
I0209 23:21:46.933557 22542570456896 run_lib.py:133] step: 351950, training_loss: 2.57388e-02
I0209 23:22:04.437023 22542570456896 run_lib.py:133] step: 352000, training_loss: 2.67592e-02
I0209 23:22:04.605393 22542570456896 run_lib.py:146] step: 352000, eval_loss: 2.44001e-02
I0209 23:22:22.045544 22542570456896 run_lib.py:133] step: 352050, training_loss: 2.79933e-02
I0209 23:22:39.485040 22542570456896 run_lib.py:133] step: 352100, training_loss: 2.60385e-02
I0209 23:22:39.640199 22542570456896 run_lib.py:146] step: 352100, eval_loss: 2.70375e-02
I0209 23:22:57.284538 22542570456896 run_lib.py:133] step: 352150, training_loss: 2.99626e-02
I0209 23:23:14.664891 22542570456896 run_lib.py:133] step: 352200, training_loss: 2.72044e-02
I0209 23:23:14.817162 22542570456896 run_lib.py:146] step: 352200, eval_loss: 2.12160e-02
I0209 23:23:32.362706 22542570456896 run_lib.py:133] step: 352250, training_loss: 3.79496e-02
I0209 23:23:49.822193 22542570456896 run_lib.py:133] step: 352300, training_loss: 3.06020e-02
I0209 23:23:49.978502 22542570456896 run_lib.py:146] step: 352300, eval_loss: 2.81632e-02
I0209 23:24:07.628869 22542570456896 run_lib.py:133] step: 352350, training_loss: 2.67698e-02
I0209 23:24:25.058468 22542570456896 run_lib.py:133] step: 352400, training_loss: 2.83247e-02
I0209 23:24:25.216677 22542570456896 run_lib.py:146] step: 352400, eval_loss: 2.36304e-02
I0209 23:24:42.639599 22542570456896 run_lib.py:133] step: 352450, training_loss: 2.51691e-02
I0209 23:25:00.214244 22542570456896 run_lib.py:133] step: 352500, training_loss: 2.58575e-02
I0209 23:25:00.369239 22542570456896 run_lib.py:146] step: 352500, eval_loss: 2.66906e-02
I0209 23:25:17.766220 22542570456896 run_lib.py:133] step: 352550, training_loss: 3.71961e-02
I0209 23:25:35.409514 22542570456896 run_lib.py:133] step: 352600, training_loss: 2.55542e-02
I0209 23:25:35.567923 22542570456896 run_lib.py:146] step: 352600, eval_loss: 3.21185e-02
I0209 23:25:52.944777 22542570456896 run_lib.py:133] step: 352650, training_loss: 3.61518e-02
I0209 23:26:10.295502 22542570456896 run_lib.py:133] step: 352700, training_loss: 3.52060e-02
I0209 23:26:10.447248 22542570456896 run_lib.py:146] step: 352700, eval_loss: 2.57047e-02
I0209 23:26:27.927344 22542570456896 run_lib.py:133] step: 352750, training_loss: 2.66498e-02
I0209 23:26:45.232704 22542570456896 run_lib.py:133] step: 352800, training_loss: 3.00231e-02
I0209 23:26:45.406416 22542570456896 run_lib.py:146] step: 352800, eval_loss: 2.71612e-02
I0209 23:27:02.843015 22542570456896 run_lib.py:133] step: 352850, training_loss: 2.79212e-02
I0209 23:27:20.467086 22542570456896 run_lib.py:133] step: 352900, training_loss: 3.05025e-02
I0209 23:27:20.625407 22542570456896 run_lib.py:146] step: 352900, eval_loss: 1.78725e-02
I0209 23:27:38.031067 22542570456896 run_lib.py:133] step: 352950, training_loss: 2.85510e-02
I0209 23:27:55.478906 22542570456896 run_lib.py:133] step: 353000, training_loss: 3.06585e-02
I0209 23:27:55.634241 22542570456896 run_lib.py:146] step: 353000, eval_loss: 2.27173e-02
I0209 23:28:13.099411 22542570456896 run_lib.py:133] step: 353050, training_loss: 3.15129e-02
I0209 23:28:30.534378 22542570456896 run_lib.py:133] step: 353100, training_loss: 2.56090e-02
I0209 23:28:30.692090 22542570456896 run_lib.py:146] step: 353100, eval_loss: 2.91558e-02
I0209 23:28:48.158893 22542570456896 run_lib.py:133] step: 353150, training_loss: 3.10297e-02
I0209 23:29:05.573493 22542570456896 run_lib.py:133] step: 353200, training_loss: 2.50938e-02
I0209 23:29:05.724399 22542570456896 run_lib.py:146] step: 353200, eval_loss: 2.77619e-02
I0209 23:29:23.336652 22542570456896 run_lib.py:133] step: 353250, training_loss: 2.38776e-02
I0209 23:29:40.851938 22542570456896 run_lib.py:133] step: 353300, training_loss: 2.93929e-02
I0209 23:29:41.006393 22542570456896 run_lib.py:146] step: 353300, eval_loss: 3.13369e-02
I0209 23:29:58.439141 22542570456896 run_lib.py:133] step: 353350, training_loss: 3.15869e-02
I0209 23:30:15.897701 22542570456896 run_lib.py:133] step: 353400, training_loss: 2.81004e-02
I0209 23:30:16.057441 22542570456896 run_lib.py:146] step: 353400, eval_loss: 3.08144e-02
I0209 23:30:33.667257 22542570456896 run_lib.py:133] step: 353450, training_loss: 2.42879e-02
I0209 23:30:51.082738 22542570456896 run_lib.py:133] step: 353500, training_loss: 2.88638e-02
I0209 23:30:51.239410 22542570456896 run_lib.py:146] step: 353500, eval_loss: 2.99610e-02
I0209 23:31:08.833418 22542570456896 run_lib.py:133] step: 353550, training_loss: 3.43071e-02
I0209 23:31:26.275131 22542570456896 run_lib.py:133] step: 353600, training_loss: 2.75306e-02
I0209 23:31:26.430648 22542570456896 run_lib.py:146] step: 353600, eval_loss: 3.23143e-02
I0209 23:31:44.142267 22542570456896 run_lib.py:133] step: 353650, training_loss: 2.52012e-02
I0209 23:32:01.572731 22542570456896 run_lib.py:133] step: 353700, training_loss: 2.89245e-02
I0209 23:32:01.731006 22542570456896 run_lib.py:146] step: 353700, eval_loss: 2.92344e-02
I0209 23:32:19.271605 22542570456896 run_lib.py:133] step: 353750, training_loss: 2.21286e-02
I0209 23:32:36.678042 22542570456896 run_lib.py:133] step: 353800, training_loss: 3.04771e-02
I0209 23:32:36.837360 22542570456896 run_lib.py:146] step: 353800, eval_loss: 2.77519e-02
I0209 23:32:54.248002 22542570456896 run_lib.py:133] step: 353850, training_loss: 3.43629e-02
I0209 23:33:11.799497 22542570456896 run_lib.py:133] step: 353900, training_loss: 3.29383e-02
I0209 23:33:11.963398 22542570456896 run_lib.py:146] step: 353900, eval_loss: 2.11749e-02
I0209 23:33:29.384727 22542570456896 run_lib.py:133] step: 353950, training_loss: 2.62067e-02
I0209 23:33:46.864053 22542570456896 run_lib.py:133] step: 354000, training_loss: 2.77870e-02
I0209 23:33:47.022361 22542570456896 run_lib.py:146] step: 354000, eval_loss: 2.18460e-02
I0209 23:34:04.644909 22542570456896 run_lib.py:133] step: 354050, training_loss: 3.54074e-02
I0209 23:34:22.082643 22542570456896 run_lib.py:133] step: 354100, training_loss: 2.95123e-02
I0209 23:34:22.234157 22542570456896 run_lib.py:146] step: 354100, eval_loss: 2.74361e-02
I0209 23:34:39.811678 22542570456896 run_lib.py:133] step: 354150, training_loss: 2.94771e-02
I0209 23:34:57.274867 22542570456896 run_lib.py:133] step: 354200, training_loss: 3.05569e-02
I0209 23:34:57.441715 22542570456896 run_lib.py:146] step: 354200, eval_loss: 2.58808e-02
I0209 23:35:14.970552 22542570456896 run_lib.py:133] step: 354250, training_loss: 2.36684e-02
I0209 23:35:32.611938 22542570456896 run_lib.py:133] step: 354300, training_loss: 2.68660e-02
I0209 23:35:32.769878 22542570456896 run_lib.py:146] step: 354300, eval_loss: 3.36827e-02
I0209 23:35:50.185659 22542570456896 run_lib.py:133] step: 354350, training_loss: 2.53908e-02
I0209 23:36:07.616104 22542570456896 run_lib.py:133] step: 354400, training_loss: 2.58752e-02
I0209 23:36:07.767789 22542570456896 run_lib.py:146] step: 354400, eval_loss: 3.06709e-02
I0209 23:36:25.231980 22542570456896 run_lib.py:133] step: 354450, training_loss: 2.35954e-02
I0209 23:36:42.870173 22542570456896 run_lib.py:133] step: 354500, training_loss: 2.50214e-02
I0209 23:36:43.025584 22542570456896 run_lib.py:146] step: 354500, eval_loss: 2.89237e-02
I0209 23:37:00.477306 22542570456896 run_lib.py:133] step: 354550, training_loss: 3.47414e-02
I0209 23:37:17.963477 22542570456896 run_lib.py:133] step: 354600, training_loss: 2.63698e-02
I0209 23:37:18.115129 22542570456896 run_lib.py:146] step: 354600, eval_loss: 3.15844e-02
I0209 23:37:35.515306 22542570456896 run_lib.py:133] step: 354650, training_loss: 3.24065e-02
I0209 23:37:52.951150 22542570456896 run_lib.py:133] step: 354700, training_loss: 3.71788e-02
I0209 23:37:53.121605 22542570456896 run_lib.py:146] step: 354700, eval_loss: 2.88032e-02
I0209 23:38:10.761051 22542570456896 run_lib.py:133] step: 354750, training_loss: 3.35579e-02
I0209 23:38:28.308725 22542570456896 run_lib.py:133] step: 354800, training_loss: 3.04371e-02
I0209 23:38:28.466208 22542570456896 run_lib.py:146] step: 354800, eval_loss: 2.53862e-02
I0209 23:38:45.902478 22542570456896 run_lib.py:133] step: 354850, training_loss: 2.57074e-02
I0209 23:39:03.266451 22542570456896 run_lib.py:133] step: 354900, training_loss: 2.93572e-02
I0209 23:39:03.420601 22542570456896 run_lib.py:146] step: 354900, eval_loss: 2.92391e-02
I0209 23:39:20.957019 22542570456896 run_lib.py:133] step: 354950, training_loss: 2.31321e-02
I0209 23:39:38.386548 22542570456896 run_lib.py:133] step: 355000, training_loss: 2.56856e-02
I0209 23:39:38.543684 22542570456896 run_lib.py:146] step: 355000, eval_loss: 2.36272e-02
I0209 23:39:56.183582 22542570456896 run_lib.py:133] step: 355050, training_loss: 3.05539e-02
I0209 23:40:13.591150 22542570456896 run_lib.py:133] step: 355100, training_loss: 2.62577e-02
I0209 23:40:13.749468 22542570456896 run_lib.py:146] step: 355100, eval_loss: 2.96837e-02
I0209 23:40:31.328468 22542570456896 run_lib.py:133] step: 355150, training_loss: 2.64016e-02
I0209 23:40:48.781127 22542570456896 run_lib.py:133] step: 355200, training_loss: 2.46972e-02
I0209 23:40:48.936347 22542570456896 run_lib.py:146] step: 355200, eval_loss: 2.90541e-02
I0209 23:41:06.376983 22542570456896 run_lib.py:133] step: 355250, training_loss: 2.81554e-02
I0209 23:41:23.990157 22542570456896 run_lib.py:133] step: 355300, training_loss: 3.03351e-02
I0209 23:41:24.161384 22542570456896 run_lib.py:146] step: 355300, eval_loss: 2.45170e-02
I0209 23:41:41.611790 22542570456896 run_lib.py:133] step: 355350, training_loss: 3.48388e-02
I0209 23:41:59.220804 22542570456896 run_lib.py:133] step: 355400, training_loss: 2.57506e-02
I0209 23:41:59.383194 22542570456896 run_lib.py:146] step: 355400, eval_loss: 3.29696e-02
I0209 23:42:16.822308 22542570456896 run_lib.py:133] step: 355450, training_loss: 3.56321e-02
I0209 23:42:34.180462 22542570456896 run_lib.py:133] step: 355500, training_loss: 2.97121e-02
I0209 23:42:34.335381 22542570456896 run_lib.py:146] step: 355500, eval_loss: 2.99674e-02
I0209 23:42:51.914813 22542570456896 run_lib.py:133] step: 355550, training_loss: 3.16541e-02
I0209 23:43:09.369601 22542570456896 run_lib.py:133] step: 355600, training_loss: 2.87389e-02
I0209 23:43:09.524451 22542570456896 run_lib.py:146] step: 355600, eval_loss: 3.42370e-02
I0209 23:43:26.982951 22542570456896 run_lib.py:133] step: 355650, training_loss: 3.75921e-02
I0209 23:43:44.598088 22542570456896 run_lib.py:133] step: 355700, training_loss: 2.56012e-02
I0209 23:43:44.753931 22542570456896 run_lib.py:146] step: 355700, eval_loss: 2.92233e-02
I0209 23:44:02.154534 22542570456896 run_lib.py:133] step: 355750, training_loss: 2.44076e-02
I0209 23:44:19.564165 22542570456896 run_lib.py:133] step: 355800, training_loss: 2.72984e-02
I0209 23:44:19.881299 22542570456896 run_lib.py:146] step: 355800, eval_loss: 2.78771e-02
I0209 23:44:37.311409 22542570456896 run_lib.py:133] step: 355850, training_loss: 2.70525e-02
I0209 23:44:54.770740 22542570456896 run_lib.py:133] step: 355900, training_loss: 2.92666e-02
I0209 23:44:54.927595 22542570456896 run_lib.py:146] step: 355900, eval_loss: 2.73491e-02
I0209 23:45:12.378048 22542570456896 run_lib.py:133] step: 355950, training_loss: 2.42387e-02
I0209 23:45:29.771271 22542570456896 run_lib.py:133] step: 356000, training_loss: 3.18362e-02
I0209 23:45:29.922984 22542570456896 run_lib.py:146] step: 356000, eval_loss: 3.24272e-02
I0209 23:45:47.550280 22542570456896 run_lib.py:133] step: 356050, training_loss: 3.15025e-02
I0209 23:46:05.054484 22542570456896 run_lib.py:133] step: 356100, training_loss: 2.51846e-02
I0209 23:46:05.217497 22542570456896 run_lib.py:146] step: 356100, eval_loss: 2.95715e-02
I0209 23:46:22.675611 22542570456896 run_lib.py:133] step: 356150, training_loss: 2.83336e-02
I0209 23:46:40.144117 22542570456896 run_lib.py:133] step: 356200, training_loss: 3.38450e-02
I0209 23:46:40.302417 22542570456896 run_lib.py:146] step: 356200, eval_loss: 2.62879e-02
I0209 23:46:57.896836 22542570456896 run_lib.py:133] step: 356250, training_loss: 2.78552e-02
I0209 23:47:15.361955 22542570456896 run_lib.py:133] step: 356300, training_loss: 2.25360e-02
I0209 23:47:15.518350 22542570456896 run_lib.py:146] step: 356300, eval_loss: 3.04342e-02
I0209 23:47:32.957265 22542570456896 run_lib.py:133] step: 356350, training_loss: 3.26338e-02
I0209 23:47:50.444298 22542570456896 run_lib.py:133] step: 356400, training_loss: 2.98528e-02
I0209 23:47:50.601037 22542570456896 run_lib.py:146] step: 356400, eval_loss: 3.16986e-02
I0209 23:48:08.255889 22542570456896 run_lib.py:133] step: 356450, training_loss: 3.69494e-02
I0209 23:48:25.656180 22542570456896 run_lib.py:133] step: 356500, training_loss: 2.35860e-02
I0209 23:48:25.808467 22542570456896 run_lib.py:146] step: 356500, eval_loss: 3.26211e-02
I0209 23:48:43.345939 22542570456896 run_lib.py:133] step: 356550, training_loss: 2.21437e-02
I0209 23:49:00.767638 22542570456896 run_lib.py:133] step: 356600, training_loss: 2.49732e-02
I0209 23:49:00.923359 22542570456896 run_lib.py:146] step: 356600, eval_loss: 2.56605e-02
I0209 23:49:18.511530 22542570456896 run_lib.py:133] step: 356650, training_loss: 3.36714e-02
I0209 23:49:35.968314 22542570456896 run_lib.py:133] step: 356700, training_loss: 3.00281e-02
I0209 23:49:36.126286 22542570456896 run_lib.py:146] step: 356700, eval_loss: 2.63986e-02
I0209 23:49:53.560754 22542570456896 run_lib.py:133] step: 356750, training_loss: 2.35241e-02
I0209 23:50:11.160735 22542570456896 run_lib.py:133] step: 356800, training_loss: 3.11527e-02
I0209 23:50:11.325311 22542570456896 run_lib.py:146] step: 356800, eval_loss: 3.24646e-02
I0209 23:50:28.734663 22542570456896 run_lib.py:133] step: 356850, training_loss: 2.69847e-02
I0209 23:50:46.275118 22542570456896 run_lib.py:133] step: 356900, training_loss: 2.57685e-02
I0209 23:50:46.431854 22542570456896 run_lib.py:146] step: 356900, eval_loss: 2.63520e-02
I0209 23:51:03.909982 22542570456896 run_lib.py:133] step: 356950, training_loss: 2.51188e-02
I0209 23:51:21.356443 22542570456896 run_lib.py:133] step: 357000, training_loss: 2.99695e-02
I0209 23:51:21.514554 22542570456896 run_lib.py:146] step: 357000, eval_loss: 3.12029e-02
I0209 23:51:39.132668 22542570456896 run_lib.py:133] step: 357050, training_loss: 2.72472e-02
I0209 23:51:56.602469 22542570456896 run_lib.py:133] step: 357100, training_loss: 3.32274e-02
I0209 23:51:56.758364 22542570456896 run_lib.py:146] step: 357100, eval_loss: 3.28400e-02
I0209 23:52:14.143604 22542570456896 run_lib.py:133] step: 357150, training_loss: 1.94970e-02
I0209 23:52:31.623588 22542570456896 run_lib.py:133] step: 357200, training_loss: 2.68743e-02
I0209 23:52:31.801553 22542570456896 run_lib.py:146] step: 357200, eval_loss: 2.33054e-02
I0209 23:52:49.420125 22542570456896 run_lib.py:133] step: 357250, training_loss: 3.00942e-02
I0209 23:53:06.821269 22542570456896 run_lib.py:133] step: 357300, training_loss: 3.00888e-02
I0209 23:53:06.983774 22542570456896 run_lib.py:146] step: 357300, eval_loss: 3.53161e-02
I0209 23:53:24.505329 22542570456896 run_lib.py:133] step: 357350, training_loss: 3.07128e-02
I0209 23:53:41.913247 22542570456896 run_lib.py:133] step: 357400, training_loss: 1.89458e-02
I0209 23:53:42.076358 22542570456896 run_lib.py:146] step: 357400, eval_loss: 2.62422e-02
I0209 23:53:59.486482 22542570456896 run_lib.py:133] step: 357450, training_loss: 2.83405e-02
I0209 23:54:16.924351 22542570456896 run_lib.py:133] step: 357500, training_loss: 2.43426e-02
I0209 23:54:17.082521 22542570456896 run_lib.py:146] step: 357500, eval_loss: 2.71731e-02
I0209 23:54:34.709907 22542570456896 run_lib.py:133] step: 357550, training_loss: 2.42347e-02
I0209 23:54:52.208265 22542570456896 run_lib.py:133] step: 357600, training_loss: 2.62117e-02
I0209 23:54:52.365551 22542570456896 run_lib.py:146] step: 357600, eval_loss: 2.86285e-02
I0209 23:55:09.782201 22542570456896 run_lib.py:133] step: 357650, training_loss: 2.44225e-02
I0209 23:55:27.191689 22542570456896 run_lib.py:133] step: 357700, training_loss: 2.78405e-02
I0209 23:55:27.351337 22542570456896 run_lib.py:146] step: 357700, eval_loss: 2.75251e-02
I0209 23:55:44.922569 22542570456896 run_lib.py:133] step: 357750, training_loss: 3.23605e-02
I0209 23:56:02.437299 22542570456896 run_lib.py:133] step: 357800, training_loss: 2.77622e-02
I0209 23:56:02.601244 22542570456896 run_lib.py:146] step: 357800, eval_loss: 2.40592e-02
I0209 23:56:20.207059 22542570456896 run_lib.py:133] step: 357850, training_loss: 3.49705e-02
I0209 23:56:37.612742 22542570456896 run_lib.py:133] step: 357900, training_loss: 2.88032e-02
I0209 23:56:37.766137 22542570456896 run_lib.py:146] step: 357900, eval_loss: 3.31891e-02
I0209 23:56:55.370947 22542570456896 run_lib.py:133] step: 357950, training_loss: 3.24016e-02
I0209 23:57:12.809398 22542570456896 run_lib.py:133] step: 358000, training_loss: 2.95199e-02
I0209 23:57:12.970562 22542570456896 run_lib.py:146] step: 358000, eval_loss: 3.48578e-02
I0209 23:57:30.623255 22542570456896 run_lib.py:133] step: 358050, training_loss: 2.73243e-02
I0209 23:57:48.073547 22542570456896 run_lib.py:133] step: 358100, training_loss: 2.30562e-02
I0209 23:57:48.233395 22542570456896 run_lib.py:146] step: 358100, eval_loss: 3.34007e-02
I0209 23:58:05.653794 22542570456896 run_lib.py:133] step: 358150, training_loss: 2.92298e-02
I0209 23:58:23.232455 22542570456896 run_lib.py:133] step: 358200, training_loss: 2.26765e-02
I0209 23:58:23.389168 22542570456896 run_lib.py:146] step: 358200, eval_loss: 2.73338e-02
I0209 23:58:40.762250 22542570456896 run_lib.py:133] step: 358250, training_loss: 3.26817e-02
I0209 23:58:58.198357 22542570456896 run_lib.py:133] step: 358300, training_loss: 2.68820e-02
I0209 23:58:58.362478 22542570456896 run_lib.py:146] step: 358300, eval_loss: 2.85084e-02
I0209 23:59:15.997261 22542570456896 run_lib.py:133] step: 358350, training_loss: 3.17308e-02
I0209 23:59:33.644546 22542570456896 run_lib.py:133] step: 358400, training_loss: 2.35406e-02
I0209 23:59:33.796577 22542570456896 run_lib.py:146] step: 358400, eval_loss: 3.08405e-02
I0209 23:59:51.195374 22542570456896 run_lib.py:133] step: 358450, training_loss: 3.30074e-02
I0210 00:00:08.604164 22542570456896 run_lib.py:133] step: 358500, training_loss: 2.96244e-02
I0210 00:00:08.759395 22542570456896 run_lib.py:146] step: 358500, eval_loss: 3.19194e-02
I0210 00:00:26.184388 22542570456896 run_lib.py:133] step: 358550, training_loss: 3.03996e-02
I0210 00:00:43.771366 22542570456896 run_lib.py:133] step: 358600, training_loss: 2.63933e-02
I0210 00:00:43.954441 22542570456896 run_lib.py:146] step: 358600, eval_loss: 1.94067e-02
I0210 00:01:01.395998 22542570456896 run_lib.py:133] step: 358650, training_loss: 2.35348e-02
I0210 00:01:18.794460 22542570456896 run_lib.py:133] step: 358700, training_loss: 2.69238e-02
I0210 00:01:18.954615 22542570456896 run_lib.py:146] step: 358700, eval_loss: 2.92229e-02
I0210 00:01:36.383924 22542570456896 run_lib.py:133] step: 358750, training_loss: 2.67656e-02
I0210 00:01:53.982383 22542570456896 run_lib.py:133] step: 358800, training_loss: 3.13258e-02
I0210 00:01:54.134669 22542570456896 run_lib.py:146] step: 358800, eval_loss: 2.99506e-02
I0210 00:02:11.516744 22542570456896 run_lib.py:133] step: 358850, training_loss: 3.25228e-02
I0210 00:02:29.028386 22542570456896 run_lib.py:133] step: 358900, training_loss: 2.58325e-02
I0210 00:02:29.179403 22542570456896 run_lib.py:146] step: 358900, eval_loss: 3.31808e-02
I0210 00:02:46.672420 22542570456896 run_lib.py:133] step: 358950, training_loss: 2.75787e-02
I0210 00:03:04.084392 22542570456896 run_lib.py:133] step: 359000, training_loss: 3.06405e-02
I0210 00:03:04.247976 22542570456896 run_lib.py:146] step: 359000, eval_loss: 2.70788e-02
I0210 00:03:21.827864 22542570456896 run_lib.py:133] step: 359050, training_loss: 3.76656e-02
I0210 00:03:39.288323 22542570456896 run_lib.py:133] step: 359100, training_loss: 4.06963e-02
I0210 00:03:39.445642 22542570456896 run_lib.py:146] step: 359100, eval_loss: 3.04082e-02
I0210 00:03:56.909308 22542570456896 run_lib.py:133] step: 359150, training_loss: 2.54335e-02
I0210 00:04:14.428120 22542570456896 run_lib.py:133] step: 359200, training_loss: 2.69456e-02
I0210 00:04:14.588198 22542570456896 run_lib.py:146] step: 359200, eval_loss: 3.16256e-02
I0210 00:04:32.228989 22542570456896 run_lib.py:133] step: 359250, training_loss: 2.97741e-02
I0210 00:04:49.639823 22542570456896 run_lib.py:133] step: 359300, training_loss: 2.77508e-02
I0210 00:04:49.794406 22542570456896 run_lib.py:146] step: 359300, eval_loss: 3.21041e-02
I0210 00:05:07.396093 22542570456896 run_lib.py:133] step: 359350, training_loss: 2.76811e-02
I0210 00:05:24.839967 22542570456896 run_lib.py:133] step: 359400, training_loss: 2.67814e-02
I0210 00:05:24.993528 22542570456896 run_lib.py:146] step: 359400, eval_loss: 2.75275e-02
I0210 00:05:42.604870 22542570456896 run_lib.py:133] step: 359450, training_loss: 3.01242e-02
I0210 00:06:00.177748 22542570456896 run_lib.py:133] step: 359500, training_loss: 2.64651e-02
I0210 00:06:00.340349 22542570456896 run_lib.py:146] step: 359500, eval_loss: 2.56166e-02
I0210 00:06:17.813184 22542570456896 run_lib.py:133] step: 359550, training_loss: 2.44734e-02
I0210 00:06:35.412135 22542570456896 run_lib.py:133] step: 359600, training_loss: 2.36261e-02
I0210 00:06:35.570891 22542570456896 run_lib.py:146] step: 359600, eval_loss: 3.25716e-02
I0210 00:06:53.012037 22542570456896 run_lib.py:133] step: 359650, training_loss: 3.14919e-02
I0210 00:07:10.596560 22542570456896 run_lib.py:133] step: 359700, training_loss: 2.85008e-02
I0210 00:07:10.762215 22542570456896 run_lib.py:146] step: 359700, eval_loss: 3.29437e-02
I0210 00:07:28.264206 22542570456896 run_lib.py:133] step: 359750, training_loss: 3.95982e-02
I0210 00:07:45.708114 22542570456896 run_lib.py:133] step: 359800, training_loss: 3.09052e-02
I0210 00:07:45.860944 22542570456896 run_lib.py:146] step: 359800, eval_loss: 2.14198e-02
I0210 00:08:03.476917 22542570456896 run_lib.py:133] step: 359850, training_loss: 2.92125e-02
I0210 00:08:20.902042 22542570456896 run_lib.py:133] step: 359900, training_loss: 2.59382e-02
I0210 00:08:21.057402 22542570456896 run_lib.py:146] step: 359900, eval_loss: 3.57303e-02
I0210 00:08:38.510893 22542570456896 run_lib.py:133] step: 359950, training_loss: 3.19008e-02
I0210 00:08:56.084200 22542570456896 run_lib.py:133] step: 360000, training_loss: 3.46052e-02
I0210 00:08:56.821241 22542570456896 run_lib.py:146] step: 360000, eval_loss: 2.36499e-02
I0210 00:09:16.910515 22542570456896 run_lib.py:133] step: 360050, training_loss: 2.97692e-02
I0210 00:09:34.368268 22542570456896 run_lib.py:133] step: 360100, training_loss: 2.61246e-02
I0210 00:09:34.534329 22542570456896 run_lib.py:146] step: 360100, eval_loss: 3.16447e-02
I0210 00:09:51.939174 22542570456896 run_lib.py:133] step: 360150, training_loss: 3.17000e-02
I0210 00:10:09.535855 22542570456896 run_lib.py:133] step: 360200, training_loss: 2.86137e-02
I0210 00:10:09.699918 22542570456896 run_lib.py:146] step: 360200, eval_loss: 2.67475e-02
I0210 00:10:27.117552 22542570456896 run_lib.py:133] step: 360250, training_loss: 2.56496e-02
I0210 00:10:44.616772 22542570456896 run_lib.py:133] step: 360300, training_loss: 3.14553e-02
I0210 00:10:44.773609 22542570456896 run_lib.py:146] step: 360300, eval_loss: 3.02236e-02
I0210 00:11:02.481281 22542570456896 run_lib.py:133] step: 360350, training_loss: 2.27947e-02
I0210 00:11:19.896613 22542570456896 run_lib.py:133] step: 360400, training_loss: 3.01800e-02
I0210 00:11:20.049369 22542570456896 run_lib.py:146] step: 360400, eval_loss: 2.61483e-02
I0210 00:11:37.561790 22542570456896 run_lib.py:133] step: 360450, training_loss: 3.17363e-02
I0210 00:11:55.017841 22542570456896 run_lib.py:133] step: 360500, training_loss: 2.33243e-02
I0210 00:11:55.175454 22542570456896 run_lib.py:146] step: 360500, eval_loss: 2.89123e-02
I0210 00:12:12.638259 22542570456896 run_lib.py:133] step: 360550, training_loss: 3.71242e-02
I0210 00:12:30.102265 22542570456896 run_lib.py:133] step: 360600, training_loss: 2.17065e-02
I0210 00:12:30.268445 22542570456896 run_lib.py:146] step: 360600, eval_loss: 2.89221e-02
I0210 00:12:47.914228 22542570456896 run_lib.py:133] step: 360650, training_loss: 2.66169e-02
I0210 00:13:05.389556 22542570456896 run_lib.py:133] step: 360700, training_loss: 2.72398e-02
I0210 00:13:05.546529 22542570456896 run_lib.py:146] step: 360700, eval_loss: 2.65535e-02
I0210 00:13:22.989179 22542570456896 run_lib.py:133] step: 360750, training_loss: 3.10800e-02
I0210 00:13:40.387413 22542570456896 run_lib.py:133] step: 360800, training_loss: 3.16448e-02
I0210 00:13:40.541384 22542570456896 run_lib.py:146] step: 360800, eval_loss: 3.01697e-02
I0210 00:13:58.101263 22542570456896 run_lib.py:133] step: 360850, training_loss: 3.00166e-02
I0210 00:14:15.595202 22542570456896 run_lib.py:133] step: 360900, training_loss: 3.29487e-02
I0210 00:14:15.758575 22542570456896 run_lib.py:146] step: 360900, eval_loss: 2.90731e-02
I0210 00:14:33.405534 22542570456896 run_lib.py:133] step: 360950, training_loss: 3.11642e-02
I0210 00:14:50.856395 22542570456896 run_lib.py:133] step: 361000, training_loss: 2.84429e-02
I0210 00:14:51.015355 22542570456896 run_lib.py:146] step: 361000, eval_loss: 2.59236e-02
I0210 00:15:08.578665 22542570456896 run_lib.py:133] step: 361050, training_loss: 2.82604e-02
I0210 00:15:26.006447 22542570456896 run_lib.py:133] step: 361100, training_loss: 2.83180e-02
I0210 00:15:26.162453 22542570456896 run_lib.py:146] step: 361100, eval_loss: 2.62670e-02
I0210 00:15:43.742815 22542570456896 run_lib.py:133] step: 361150, training_loss: 3.36218e-02
I0210 00:16:01.230786 22542570456896 run_lib.py:133] step: 361200, training_loss: 2.11256e-02
I0210 00:16:01.387199 22542570456896 run_lib.py:146] step: 361200, eval_loss: 3.21895e-02
I0210 00:16:18.831787 22542570456896 run_lib.py:133] step: 361250, training_loss: 2.63406e-02
I0210 00:16:36.432646 22542570456896 run_lib.py:133] step: 361300, training_loss: 2.77571e-02
I0210 00:16:36.591363 22542570456896 run_lib.py:146] step: 361300, eval_loss: 3.38009e-02
I0210 00:16:54.026134 22542570456896 run_lib.py:133] step: 361350, training_loss: 3.59373e-02
I0210 00:17:11.530873 22542570456896 run_lib.py:133] step: 361400, training_loss: 1.94041e-02
I0210 00:17:11.698589 22542570456896 run_lib.py:146] step: 361400, eval_loss: 3.07525e-02
I0210 00:17:29.343187 22542570456896 run_lib.py:133] step: 361450, training_loss: 3.22214e-02
I0210 00:17:46.812008 22542570456896 run_lib.py:133] step: 361500, training_loss: 2.54682e-02
I0210 00:17:46.977395 22542570456896 run_lib.py:146] step: 361500, eval_loss: 2.77291e-02
I0210 00:18:04.574047 22542570456896 run_lib.py:133] step: 361550, training_loss: 2.57060e-02
I0210 00:18:21.994148 22542570456896 run_lib.py:133] step: 361600, training_loss: 2.83166e-02
I0210 00:18:22.157403 22542570456896 run_lib.py:146] step: 361600, eval_loss: 3.41765e-02
I0210 00:18:39.608734 22542570456896 run_lib.py:133] step: 361650, training_loss: 2.35761e-02
I0210 00:18:57.261731 22542570456896 run_lib.py:133] step: 361700, training_loss: 2.93426e-02
I0210 00:18:57.414203 22542570456896 run_lib.py:146] step: 361700, eval_loss: 2.77925e-02
I0210 00:19:14.863696 22542570456896 run_lib.py:133] step: 361750, training_loss: 2.95227e-02
I0210 00:19:32.260776 22542570456896 run_lib.py:133] step: 361800, training_loss: 3.53394e-02
I0210 00:19:32.413429 22542570456896 run_lib.py:146] step: 361800, eval_loss: 3.07829e-02
I0210 00:19:49.831278 22542570456896 run_lib.py:133] step: 361850, training_loss: 2.09839e-02
I0210 00:20:07.514042 22542570456896 run_lib.py:133] step: 361900, training_loss: 3.14184e-02
I0210 00:20:07.670774 22542570456896 run_lib.py:146] step: 361900, eval_loss: 2.78410e-02
I0210 00:20:25.097161 22542570456896 run_lib.py:133] step: 361950, training_loss: 2.58457e-02
I0210 00:20:42.610657 22542570456896 run_lib.py:133] step: 362000, training_loss: 2.42675e-02
I0210 00:20:42.786408 22542570456896 run_lib.py:146] step: 362000, eval_loss: 2.42205e-02
I0210 00:21:00.253222 22542570456896 run_lib.py:133] step: 362050, training_loss: 3.54675e-02
I0210 00:21:17.691212 22542570456896 run_lib.py:133] step: 362100, training_loss: 2.19519e-02
I0210 00:21:17.848642 22542570456896 run_lib.py:146] step: 362100, eval_loss: 2.54470e-02
I0210 00:21:35.448920 22542570456896 run_lib.py:133] step: 362150, training_loss: 3.03440e-02
I0210 00:21:52.922120 22542570456896 run_lib.py:133] step: 362200, training_loss: 2.91907e-02
I0210 00:21:53.077510 22542570456896 run_lib.py:146] step: 362200, eval_loss: 3.00671e-02
I0210 00:22:10.506806 22542570456896 run_lib.py:133] step: 362250, training_loss: 3.19190e-02
I0210 00:22:28.011193 22542570456896 run_lib.py:133] step: 362300, training_loss: 3.35486e-02
I0210 00:22:28.174319 22542570456896 run_lib.py:146] step: 362300, eval_loss: 3.42212e-02
I0210 00:22:45.785367 22542570456896 run_lib.py:133] step: 362350, training_loss: 3.70901e-02
I0210 00:23:03.234782 22542570456896 run_lib.py:133] step: 362400, training_loss: 2.71526e-02
I0210 00:23:03.394700 22542570456896 run_lib.py:146] step: 362400, eval_loss: 2.58773e-02
I0210 00:23:20.940432 22542570456896 run_lib.py:133] step: 362450, training_loss: 3.22840e-02
I0210 00:23:38.370545 22542570456896 run_lib.py:133] step: 362500, training_loss: 2.60939e-02
I0210 00:23:38.530378 22542570456896 run_lib.py:146] step: 362500, eval_loss: 2.46011e-02
I0210 00:23:56.181424 22542570456896 run_lib.py:133] step: 362550, training_loss: 2.81911e-02
I0210 00:24:13.634654 22542570456896 run_lib.py:133] step: 362600, training_loss: 2.55210e-02
I0210 00:24:13.791164 22542570456896 run_lib.py:146] step: 362600, eval_loss: 3.58711e-02
I0210 00:24:31.246918 22542570456896 run_lib.py:133] step: 362650, training_loss: 2.93156e-02
I0210 00:24:48.903317 22542570456896 run_lib.py:133] step: 362700, training_loss: 3.15361e-02
I0210 00:24:49.057229 22542570456896 run_lib.py:146] step: 362700, eval_loss: 2.75937e-02
I0210 00:25:06.478456 22542570456896 run_lib.py:133] step: 362750, training_loss: 2.95983e-02
I0210 00:25:24.121026 22542570456896 run_lib.py:133] step: 362800, training_loss: 2.60733e-02
I0210 00:25:24.284721 22542570456896 run_lib.py:146] step: 362800, eval_loss: 2.57174e-02
I0210 00:25:41.810468 22542570456896 run_lib.py:133] step: 362850, training_loss: 3.11430e-02
I0210 00:25:59.309969 22542570456896 run_lib.py:133] step: 362900, training_loss: 3.23128e-02
I0210 00:25:59.478406 22542570456896 run_lib.py:146] step: 362900, eval_loss: 3.14616e-02
I0210 00:26:17.086337 22542570456896 run_lib.py:133] step: 362950, training_loss: 2.80201e-02
I0210 00:26:34.504855 22542570456896 run_lib.py:133] step: 363000, training_loss: 3.45872e-02
I0210 00:26:34.659418 22542570456896 run_lib.py:146] step: 363000, eval_loss: 3.55801e-02
I0210 00:26:52.071207 22542570456896 run_lib.py:133] step: 363050, training_loss: 2.46911e-02
I0210 00:27:09.664192 22542570456896 run_lib.py:133] step: 363100, training_loss: 2.76442e-02
I0210 00:27:09.822364 22542570456896 run_lib.py:146] step: 363100, eval_loss: 3.73020e-02
I0210 00:27:27.304523 22542570456896 run_lib.py:133] step: 363150, training_loss: 3.25446e-02
I0210 00:27:44.746776 22542570456896 run_lib.py:133] step: 363200, training_loss: 2.66878e-02
I0210 00:27:45.088365 22542570456896 run_lib.py:146] step: 363200, eval_loss: 2.62803e-02
I0210 00:28:02.515035 22542570456896 run_lib.py:133] step: 363250, training_loss: 2.68668e-02
I0210 00:28:19.949366 22542570456896 run_lib.py:133] step: 363300, training_loss: 2.64622e-02
I0210 00:28:20.114407 22542570456896 run_lib.py:146] step: 363300, eval_loss: 2.72268e-02
I0210 00:28:37.551777 22542570456896 run_lib.py:133] step: 363350, training_loss: 3.36290e-02
I0210 00:28:54.994055 22542570456896 run_lib.py:133] step: 363400, training_loss: 2.19901e-02
I0210 00:28:55.168346 22542570456896 run_lib.py:146] step: 363400, eval_loss: 2.64565e-02
I0210 00:29:12.809957 22542570456896 run_lib.py:133] step: 363450, training_loss: 3.62288e-02
I0210 00:29:30.304251 22542570456896 run_lib.py:133] step: 363500, training_loss: 2.97804e-02
I0210 00:29:30.460554 22542570456896 run_lib.py:146] step: 363500, eval_loss: 2.53869e-02
I0210 00:29:47.908008 22542570456896 run_lib.py:133] step: 363550, training_loss: 3.04142e-02
I0210 00:30:05.333183 22542570456896 run_lib.py:133] step: 363600, training_loss: 3.07498e-02
I0210 00:30:05.499127 22542570456896 run_lib.py:146] step: 363600, eval_loss: 2.45497e-02
I0210 00:30:23.178858 22542570456896 run_lib.py:133] step: 363650, training_loss: 3.87509e-02
I0210 00:30:40.758108 22542570456896 run_lib.py:133] step: 363700, training_loss: 3.42340e-02
I0210 00:30:40.911554 22542570456896 run_lib.py:146] step: 363700, eval_loss: 2.91008e-02
I0210 00:30:58.323872 22542570456896 run_lib.py:133] step: 363750, training_loss: 2.99161e-02
I0210 00:31:15.788543 22542570456896 run_lib.py:133] step: 363800, training_loss: 2.08066e-02
I0210 00:31:15.952426 22542570456896 run_lib.py:146] step: 363800, eval_loss: 3.13801e-02
I0210 00:31:33.523123 22542570456896 run_lib.py:133] step: 363850, training_loss: 2.99128e-02
I0210 00:31:50.983476 22542570456896 run_lib.py:133] step: 363900, training_loss: 3.01742e-02
I0210 00:31:51.160391 22542570456896 run_lib.py:146] step: 363900, eval_loss: 2.48775e-02
I0210 00:32:08.809642 22542570456896 run_lib.py:133] step: 363950, training_loss: 2.98911e-02
I0210 00:32:26.256072 22542570456896 run_lib.py:133] step: 364000, training_loss: 2.86265e-02
I0210 00:32:26.411647 22542570456896 run_lib.py:146] step: 364000, eval_loss: 3.17542e-02
I0210 00:32:43.994920 22542570456896 run_lib.py:133] step: 364050, training_loss: 2.45006e-02
I0210 00:33:01.412518 22542570456896 run_lib.py:133] step: 364100, training_loss: 2.67543e-02
I0210 00:33:01.567366 22542570456896 run_lib.py:146] step: 364100, eval_loss: 2.92711e-02
I0210 00:33:18.987940 22542570456896 run_lib.py:133] step: 364150, training_loss: 2.29136e-02
I0210 00:33:36.585868 22542570456896 run_lib.py:133] step: 364200, training_loss: 2.15901e-02
I0210 00:33:36.747702 22542570456896 run_lib.py:146] step: 364200, eval_loss: 3.60115e-02
I0210 00:33:54.261755 22542570456896 run_lib.py:133] step: 364250, training_loss: 2.33396e-02
I0210 00:34:11.870324 22542570456896 run_lib.py:133] step: 364300, training_loss: 3.02589e-02
I0210 00:34:12.038116 22542570456896 run_lib.py:146] step: 364300, eval_loss: 3.28035e-02
I0210 00:34:29.476371 22542570456896 run_lib.py:133] step: 364350, training_loss: 2.29221e-02
I0210 00:34:46.858476 22542570456896 run_lib.py:133] step: 364400, training_loss: 2.53302e-02
I0210 00:34:47.014532 22542570456896 run_lib.py:146] step: 364400, eval_loss: 2.72869e-02
I0210 00:35:04.604122 22542570456896 run_lib.py:133] step: 364450, training_loss: 2.95259e-02
I0210 00:35:22.017856 22542570456896 run_lib.py:133] step: 364500, training_loss: 2.46977e-02
I0210 00:35:22.170656 22542570456896 run_lib.py:146] step: 364500, eval_loss: 2.52828e-02
I0210 00:35:39.483514 22542570456896 run_lib.py:133] step: 364550, training_loss: 2.83686e-02
I0210 00:35:56.902314 22542570456896 run_lib.py:133] step: 364600, training_loss: 3.66206e-02
I0210 00:35:57.055083 22542570456896 run_lib.py:146] step: 364600, eval_loss: 3.30043e-02
I0210 00:36:14.662765 22542570456896 run_lib.py:133] step: 364650, training_loss: 2.60746e-02
I0210 00:36:32.114177 22542570456896 run_lib.py:133] step: 364700, training_loss: 3.02288e-02
I0210 00:36:32.264834 22542570456896 run_lib.py:146] step: 364700, eval_loss: 2.37425e-02
I0210 00:36:49.775854 22542570456896 run_lib.py:133] step: 364750, training_loss: 2.61688e-02
I0210 00:37:07.209057 22542570456896 run_lib.py:133] step: 364800, training_loss: 2.65955e-02
I0210 00:37:07.390131 22542570456896 run_lib.py:146] step: 364800, eval_loss: 2.73896e-02
I0210 00:37:24.855392 22542570456896 run_lib.py:133] step: 364850, training_loss: 2.37155e-02
I0210 00:37:42.320435 22542570456896 run_lib.py:133] step: 364900, training_loss: 2.77229e-02
I0210 00:37:42.476763 22542570456896 run_lib.py:146] step: 364900, eval_loss: 2.96981e-02
I0210 00:38:00.086718 22542570456896 run_lib.py:133] step: 364950, training_loss: 2.46324e-02
I0210 00:38:17.573184 22542570456896 run_lib.py:133] step: 365000, training_loss: 3.20792e-02
I0210 00:38:17.735696 22542570456896 run_lib.py:146] step: 365000, eval_loss: 2.32592e-02
I0210 00:38:35.157283 22542570456896 run_lib.py:133] step: 365050, training_loss: 2.42822e-02
I0210 00:38:52.678980 22542570456896 run_lib.py:133] step: 365100, training_loss: 2.26665e-02
I0210 00:38:52.833630 22542570456896 run_lib.py:146] step: 365100, eval_loss: 2.44570e-02
I0210 00:39:10.501658 22542570456896 run_lib.py:133] step: 365150, training_loss: 2.52251e-02
I0210 00:39:27.937667 22542570456896 run_lib.py:133] step: 365200, training_loss: 3.46428e-02
I0210 00:39:28.094465 22542570456896 run_lib.py:146] step: 365200, eval_loss: 2.04174e-02
I0210 00:39:45.647096 22542570456896 run_lib.py:133] step: 365250, training_loss: 3.36708e-02
I0210 00:40:03.071763 22542570456896 run_lib.py:133] step: 365300, training_loss: 3.03816e-02
I0210 00:40:03.231597 22542570456896 run_lib.py:146] step: 365300, eval_loss: 2.53627e-02
I0210 00:40:20.834867 22542570456896 run_lib.py:133] step: 365350, training_loss: 3.27333e-02
I0210 00:40:38.288825 22542570456896 run_lib.py:133] step: 365400, training_loss: 3.32057e-02
I0210 00:40:38.446194 22542570456896 run_lib.py:146] step: 365400, eval_loss: 2.79267e-02
I0210 00:40:56.067877 22542570456896 run_lib.py:133] step: 365450, training_loss: 2.28724e-02
I0210 00:41:13.466364 22542570456896 run_lib.py:133] step: 365500, training_loss: 2.60626e-02
I0210 00:41:13.630898 22542570456896 run_lib.py:146] step: 365500, eval_loss: 3.02594e-02
I0210 00:41:31.045480 22542570456896 run_lib.py:133] step: 365550, training_loss: 2.94392e-02
I0210 00:41:48.635204 22542570456896 run_lib.py:133] step: 365600, training_loss: 3.34617e-02
I0210 00:41:48.790652 22542570456896 run_lib.py:146] step: 365600, eval_loss: 3.38776e-02
I0210 00:42:06.289203 22542570456896 run_lib.py:133] step: 365650, training_loss: 3.02290e-02
I0210 00:42:23.734506 22542570456896 run_lib.py:133] step: 365700, training_loss: 3.45512e-02
I0210 00:42:23.890382 22542570456896 run_lib.py:146] step: 365700, eval_loss: 3.00337e-02
I0210 00:42:41.512864 22542570456896 run_lib.py:133] step: 365750, training_loss: 2.56258e-02
I0210 00:42:59.088278 22542570456896 run_lib.py:133] step: 365800, training_loss: 2.63052e-02
I0210 00:42:59.247606 22542570456896 run_lib.py:146] step: 365800, eval_loss: 3.56105e-02
I0210 00:43:16.702096 22542570456896 run_lib.py:133] step: 365850, training_loss: 3.57977e-02
I0210 00:43:34.213373 22542570456896 run_lib.py:133] step: 365900, training_loss: 3.19920e-02
I0210 00:43:34.370703 22542570456896 run_lib.py:146] step: 365900, eval_loss: 2.88518e-02
I0210 00:43:51.815642 22542570456896 run_lib.py:133] step: 365950, training_loss: 2.83206e-02
I0210 00:44:09.425315 22542570456896 run_lib.py:133] step: 366000, training_loss: 2.41307e-02
I0210 00:44:09.581140 22542570456896 run_lib.py:146] step: 366000, eval_loss: 2.61091e-02
I0210 00:44:27.014142 22542570456896 run_lib.py:133] step: 366050, training_loss: 2.53071e-02
I0210 00:44:44.421527 22542570456896 run_lib.py:133] step: 366100, training_loss: 2.30918e-02
I0210 00:44:44.573429 22542570456896 run_lib.py:146] step: 366100, eval_loss: 3.07551e-02
I0210 00:45:02.000653 22542570456896 run_lib.py:133] step: 366150, training_loss: 3.28913e-02
I0210 00:45:19.634083 22542570456896 run_lib.py:133] step: 366200, training_loss: 2.45716e-02
I0210 00:45:19.809009 22542570456896 run_lib.py:146] step: 366200, eval_loss: 2.20869e-02
I0210 00:45:37.232244 22542570456896 run_lib.py:133] step: 366250, training_loss: 2.11961e-02
I0210 00:45:54.794980 22542570456896 run_lib.py:133] step: 366300, training_loss: 2.20289e-02
I0210 00:45:54.954372 22542570456896 run_lib.py:146] step: 366300, eval_loss: 2.96689e-02
I0210 00:46:12.392621 22542570456896 run_lib.py:133] step: 366350, training_loss: 2.77333e-02
I0210 00:46:29.787811 22542570456896 run_lib.py:133] step: 366400, training_loss: 2.77706e-02
I0210 00:46:29.941892 22542570456896 run_lib.py:146] step: 366400, eval_loss: 2.94033e-02
I0210 00:46:47.522318 22542570456896 run_lib.py:133] step: 366450, training_loss: 2.35528e-02
I0210 00:47:05.116191 22542570456896 run_lib.py:133] step: 366500, training_loss: 2.67347e-02
I0210 00:47:05.278950 22542570456896 run_lib.py:146] step: 366500, eval_loss: 2.82958e-02
I0210 00:47:22.749734 22542570456896 run_lib.py:133] step: 366550, training_loss: 3.23329e-02
I0210 00:47:40.163640 22542570456896 run_lib.py:133] step: 366600, training_loss: 2.63206e-02
I0210 00:47:40.319050 22542570456896 run_lib.py:146] step: 366600, eval_loss: 2.80845e-02
I0210 00:47:57.916310 22542570456896 run_lib.py:133] step: 366650, training_loss: 2.20144e-02
I0210 00:48:15.357814 22542570456896 run_lib.py:133] step: 366700, training_loss: 2.40218e-02
I0210 00:48:15.516648 22542570456896 run_lib.py:146] step: 366700, eval_loss: 3.03481e-02
I0210 00:48:33.114739 22542570456896 run_lib.py:133] step: 366750, training_loss: 3.66007e-02
I0210 00:48:50.561107 22542570456896 run_lib.py:133] step: 366800, training_loss: 2.27816e-02
I0210 00:48:50.722592 22542570456896 run_lib.py:146] step: 366800, eval_loss: 2.51486e-02
I0210 00:49:08.323025 22542570456896 run_lib.py:133] step: 366850, training_loss: 2.56267e-02
I0210 00:49:25.691051 22542570456896 run_lib.py:133] step: 366900, training_loss: 2.56951e-02
I0210 00:49:25.846532 22542570456896 run_lib.py:146] step: 366900, eval_loss: 3.04802e-02
I0210 00:49:43.314513 22542570456896 run_lib.py:133] step: 366950, training_loss: 2.53608e-02
I0210 00:50:00.921689 22542570456896 run_lib.py:133] step: 367000, training_loss: 2.90659e-02
I0210 00:50:01.082164 22542570456896 run_lib.py:146] step: 367000, eval_loss: 2.33583e-02
I0210 00:50:18.566980 22542570456896 run_lib.py:133] step: 367050, training_loss: 2.49680e-02
I0210 00:50:36.186541 22542570456896 run_lib.py:133] step: 367100, training_loss: 2.83013e-02
I0210 00:50:36.342470 22542570456896 run_lib.py:146] step: 367100, eval_loss: 2.45831e-02
I0210 00:50:53.747016 22542570456896 run_lib.py:133] step: 367150, training_loss: 2.85662e-02
I0210 00:51:11.218983 22542570456896 run_lib.py:133] step: 367200, training_loss: 2.61635e-02
I0210 00:51:11.377709 22542570456896 run_lib.py:146] step: 367200, eval_loss: 3.16831e-02
I0210 00:51:29.000006 22542570456896 run_lib.py:133] step: 367250, training_loss: 2.85224e-02
I0210 00:51:46.459520 22542570456896 run_lib.py:133] step: 367300, training_loss: 2.78733e-02
I0210 00:51:46.624442 22542570456896 run_lib.py:146] step: 367300, eval_loss: 2.88860e-02
I0210 00:52:04.086162 22542570456896 run_lib.py:133] step: 367350, training_loss: 2.86335e-02
I0210 00:52:21.730943 22542570456896 run_lib.py:133] step: 367400, training_loss: 2.55613e-02
I0210 00:52:21.885577 22542570456896 run_lib.py:146] step: 367400, eval_loss: 3.24834e-02
I0210 00:52:39.371935 22542570456896 run_lib.py:133] step: 367450, training_loss: 3.20259e-02
I0210 00:52:56.825206 22542570456896 run_lib.py:133] step: 367500, training_loss: 2.91404e-02
I0210 00:52:56.981355 22542570456896 run_lib.py:146] step: 367500, eval_loss: 2.21069e-02
I0210 00:53:14.480513 22542570456896 run_lib.py:133] step: 367550, training_loss: 3.44799e-02
I0210 00:53:31.934332 22542570456896 run_lib.py:133] step: 367600, training_loss: 3.31135e-02
I0210 00:53:32.102608 22542570456896 run_lib.py:146] step: 367600, eval_loss: 2.47677e-02
I0210 00:53:49.581759 22542570456896 run_lib.py:133] step: 367650, training_loss: 2.18915e-02
I0210 00:54:07.009093 22542570456896 run_lib.py:133] step: 367700, training_loss: 1.97880e-02
I0210 00:54:07.167524 22542570456896 run_lib.py:146] step: 367700, eval_loss: 2.56338e-02
I0210 00:54:24.833673 22542570456896 run_lib.py:133] step: 367750, training_loss: 2.76925e-02
I0210 00:54:42.350411 22542570456896 run_lib.py:133] step: 367800, training_loss: 3.29854e-02
I0210 00:54:42.506308 22542570456896 run_lib.py:146] step: 367800, eval_loss: 2.43863e-02
I0210 00:54:59.917029 22542570456896 run_lib.py:133] step: 367850, training_loss: 2.54684e-02
I0210 00:55:17.392799 22542570456896 run_lib.py:133] step: 367900, training_loss: 3.43678e-02
I0210 00:55:17.549531 22542570456896 run_lib.py:146] step: 367900, eval_loss: 2.71346e-02
I0210 00:55:35.216563 22542570456896 run_lib.py:133] step: 367950, training_loss: 2.65921e-02
I0210 00:55:52.621057 22542570456896 run_lib.py:133] step: 368000, training_loss: 3.01449e-02
I0210 00:55:52.773399 22542570456896 run_lib.py:146] step: 368000, eval_loss: 2.62841e-02
I0210 00:56:10.321959 22542570456896 run_lib.py:133] step: 368050, training_loss: 2.69493e-02
I0210 00:56:27.764399 22542570456896 run_lib.py:133] step: 368100, training_loss: 2.90606e-02
I0210 00:56:27.925665 22542570456896 run_lib.py:146] step: 368100, eval_loss: 2.82709e-02
I0210 00:56:45.528508 22542570456896 run_lib.py:133] step: 368150, training_loss: 2.85424e-02
I0210 00:57:02.975205 22542570456896 run_lib.py:133] step: 368200, training_loss: 2.84866e-02
I0210 00:57:03.132652 22542570456896 run_lib.py:146] step: 368200, eval_loss: 2.41467e-02
I0210 00:57:20.760529 22542570456896 run_lib.py:133] step: 368250, training_loss: 2.50227e-02
I0210 00:57:38.190232 22542570456896 run_lib.py:133] step: 368300, training_loss: 2.40010e-02
I0210 00:57:38.346329 22542570456896 run_lib.py:146] step: 368300, eval_loss: 2.96896e-02
I0210 00:57:55.795120 22542570456896 run_lib.py:133] step: 368350, training_loss: 3.05075e-02
I0210 00:58:13.353060 22542570456896 run_lib.py:133] step: 368400, training_loss: 2.23227e-02
I0210 00:58:13.505105 22542570456896 run_lib.py:146] step: 368400, eval_loss: 2.90390e-02
I0210 00:58:30.953629 22542570456896 run_lib.py:133] step: 368450, training_loss: 2.57883e-02
I0210 00:58:48.410783 22542570456896 run_lib.py:133] step: 368500, training_loss: 2.64548e-02
I0210 00:58:48.574343 22542570456896 run_lib.py:146] step: 368500, eval_loss: 2.88988e-02
I0210 00:59:06.237708 22542570456896 run_lib.py:133] step: 368550, training_loss: 3.14463e-02
I0210 00:59:23.653252 22542570456896 run_lib.py:133] step: 368600, training_loss: 2.36833e-02
I0210 00:59:23.817627 22542570456896 run_lib.py:146] step: 368600, eval_loss: 2.63168e-02
I0210 00:59:41.383383 22542570456896 run_lib.py:133] step: 368650, training_loss: 3.45250e-02
I0210 00:59:58.802911 22542570456896 run_lib.py:133] step: 368700, training_loss: 2.63662e-02
I0210 00:59:58.970416 22542570456896 run_lib.py:146] step: 368700, eval_loss: 2.97658e-02
I0210 01:00:16.434629 22542570456896 run_lib.py:133] step: 368750, training_loss: 3.08813e-02
I0210 01:00:34.100548 22542570456896 run_lib.py:133] step: 368800, training_loss: 3.57470e-02
I0210 01:00:34.258687 22542570456896 run_lib.py:146] step: 368800, eval_loss: 3.28298e-02
I0210 01:00:51.707556 22542570456896 run_lib.py:133] step: 368850, training_loss: 3.00296e-02
I0210 01:01:09.143907 22542570456896 run_lib.py:133] step: 368900, training_loss: 2.96190e-02
I0210 01:01:09.295583 22542570456896 run_lib.py:146] step: 368900, eval_loss: 2.58196e-02
I0210 01:01:26.747549 22542570456896 run_lib.py:133] step: 368950, training_loss: 2.56089e-02
I0210 01:01:44.345268 22542570456896 run_lib.py:133] step: 369000, training_loss: 3.45504e-02
I0210 01:01:44.513647 22542570456896 run_lib.py:146] step: 369000, eval_loss: 2.94806e-02
I0210 01:02:01.998930 22542570456896 run_lib.py:133] step: 369050, training_loss: 3.41040e-02
I0210 01:02:19.600679 22542570456896 run_lib.py:133] step: 369100, training_loss: 3.16380e-02
I0210 01:02:19.760251 22542570456896 run_lib.py:146] step: 369100, eval_loss: 2.50759e-02
I0210 01:02:37.159359 22542570456896 run_lib.py:133] step: 369150, training_loss: 2.58550e-02
I0210 01:02:54.586432 22542570456896 run_lib.py:133] step: 369200, training_loss: 3.89858e-02
I0210 01:02:54.742388 22542570456896 run_lib.py:146] step: 369200, eval_loss: 2.92521e-02
I0210 01:03:12.293796 22542570456896 run_lib.py:133] step: 369250, training_loss: 2.53648e-02
I0210 01:03:29.884042 22542570456896 run_lib.py:133] step: 369300, training_loss: 2.59055e-02
I0210 01:03:30.047648 22542570456896 run_lib.py:146] step: 369300, eval_loss: 3.71521e-02
I0210 01:03:47.546078 22542570456896 run_lib.py:133] step: 369350, training_loss: 3.65353e-02
I0210 01:04:04.987275 22542570456896 run_lib.py:133] step: 369400, training_loss: 2.61086e-02
I0210 01:04:05.142018 22542570456896 run_lib.py:146] step: 369400, eval_loss: 3.00303e-02
I0210 01:04:22.747551 22542570456896 run_lib.py:133] step: 369450, training_loss: 3.35150e-02
I0210 01:04:40.180220 22542570456896 run_lib.py:133] step: 369500, training_loss: 2.64541e-02
I0210 01:04:40.343300 22542570456896 run_lib.py:146] step: 369500, eval_loss: 2.79597e-02
I0210 01:04:57.912321 22542570456896 run_lib.py:133] step: 369550, training_loss: 3.08404e-02
I0210 01:05:15.321196 22542570456896 run_lib.py:133] step: 369600, training_loss: 2.85886e-02
I0210 01:05:15.495884 22542570456896 run_lib.py:146] step: 369600, eval_loss: 2.59660e-02
I0210 01:05:33.168639 22542570456896 run_lib.py:133] step: 369650, training_loss: 2.36661e-02
I0210 01:05:50.621204 22542570456896 run_lib.py:133] step: 369700, training_loss: 3.11101e-02
I0210 01:05:50.777645 22542570456896 run_lib.py:146] step: 369700, eval_loss: 2.45686e-02
I0210 01:06:08.234826 22542570456896 run_lib.py:133] step: 369750, training_loss: 2.33152e-02
I0210 01:06:25.825543 22542570456896 run_lib.py:133] step: 369800, training_loss: 2.80460e-02
I0210 01:06:25.981426 22542570456896 run_lib.py:146] step: 369800, eval_loss: 2.74769e-02
I0210 01:06:43.386877 22542570456896 run_lib.py:133] step: 369850, training_loss: 2.60266e-02
I0210 01:07:00.965871 22542570456896 run_lib.py:133] step: 369900, training_loss: 3.22562e-02
I0210 01:07:01.121609 22542570456896 run_lib.py:146] step: 369900, eval_loss: 2.89094e-02
I0210 01:07:18.614874 22542570456896 run_lib.py:133] step: 369950, training_loss: 3.20221e-02
I0210 01:07:36.028578 22542570456896 run_lib.py:133] step: 370000, training_loss: 3.19244e-02
I0210 01:07:36.742358 22542570456896 run_lib.py:146] step: 370000, eval_loss: 2.55263e-02
I0210 01:07:57.183510 22542570456896 run_lib.py:133] step: 370050, training_loss: 3.11677e-02
I0210 01:08:14.647160 22542570456896 run_lib.py:133] step: 370100, training_loss: 3.07954e-02
I0210 01:08:14.805644 22542570456896 run_lib.py:146] step: 370100, eval_loss: 3.60231e-02
I0210 01:08:32.358633 22542570456896 run_lib.py:133] step: 370150, training_loss: 2.48032e-02
I0210 01:08:49.855106 22542570456896 run_lib.py:133] step: 370200, training_loss: 3.32997e-02
I0210 01:08:50.011524 22542570456896 run_lib.py:146] step: 370200, eval_loss: 2.72978e-02
I0210 01:09:07.475977 22542570456896 run_lib.py:133] step: 370250, training_loss: 2.40973e-02
I0210 01:09:25.111590 22542570456896 run_lib.py:133] step: 370300, training_loss: 3.00066e-02
I0210 01:09:25.275971 22542570456896 run_lib.py:146] step: 370300, eval_loss: 2.66400e-02
I0210 01:09:42.717999 22542570456896 run_lib.py:133] step: 370350, training_loss: 2.53441e-02
I0210 01:10:00.283499 22542570456896 run_lib.py:133] step: 370400, training_loss: 3.61822e-02
I0210 01:10:00.435354 22542570456896 run_lib.py:146] step: 370400, eval_loss: 2.70579e-02
I0210 01:10:17.889088 22542570456896 run_lib.py:133] step: 370450, training_loss: 3.15168e-02
I0210 01:10:35.365962 22542570456896 run_lib.py:133] step: 370500, training_loss: 2.30863e-02
I0210 01:10:35.536630 22542570456896 run_lib.py:146] step: 370500, eval_loss: 3.64789e-02
I0210 01:10:52.974725 22542570456896 run_lib.py:133] step: 370550, training_loss: 2.51199e-02
I0210 01:11:10.614192 22542570456896 run_lib.py:133] step: 370600, training_loss: 2.79077e-02
I0210 01:11:10.781608 22542570456896 run_lib.py:146] step: 370600, eval_loss: 2.52078e-02
I0210 01:11:28.237774 22542570456896 run_lib.py:133] step: 370650, training_loss: 2.77807e-02
I0210 01:11:45.693760 22542570456896 run_lib.py:133] step: 370700, training_loss: 2.50745e-02
I0210 01:11:45.852438 22542570456896 run_lib.py:146] step: 370700, eval_loss: 3.27442e-02
I0210 01:12:03.452568 22542570456896 run_lib.py:133] step: 370750, training_loss: 2.98809e-02
I0210 01:12:20.926733 22542570456896 run_lib.py:133] step: 370800, training_loss: 3.02171e-02
I0210 01:12:21.082617 22542570456896 run_lib.py:146] step: 370800, eval_loss: 2.75538e-02
I0210 01:12:38.649762 22542570456896 run_lib.py:133] step: 370850, training_loss: 2.12793e-02
I0210 01:12:56.044866 22542570456896 run_lib.py:133] step: 370900, training_loss: 3.22563e-02
I0210 01:12:56.205359 22542570456896 run_lib.py:146] step: 370900, eval_loss: 2.77505e-02
I0210 01:13:13.668673 22542570456896 run_lib.py:133] step: 370950, training_loss: 3.34457e-02
I0210 01:13:31.113410 22542570456896 run_lib.py:133] step: 371000, training_loss: 2.31574e-02
I0210 01:13:31.288323 22542570456896 run_lib.py:146] step: 371000, eval_loss: 3.48013e-02
I0210 01:13:48.929472 22542570456896 run_lib.py:133] step: 371050, training_loss: 3.01561e-02
I0210 01:14:06.485286 22542570456896 run_lib.py:133] step: 371100, training_loss: 2.93262e-02
I0210 01:14:06.641299 22542570456896 run_lib.py:146] step: 371100, eval_loss: 3.29021e-02
I0210 01:14:24.074278 22542570456896 run_lib.py:133] step: 371150, training_loss: 3.18891e-02
I0210 01:14:41.511671 22542570456896 run_lib.py:133] step: 371200, training_loss: 3.01703e-02
I0210 01:14:41.667160 22542570456896 run_lib.py:146] step: 371200, eval_loss: 2.66387e-02
I0210 01:14:59.279154 22542570456896 run_lib.py:133] step: 371250, training_loss: 2.36910e-02
I0210 01:15:16.737338 22542570456896 run_lib.py:133] step: 371300, training_loss: 3.55633e-02
I0210 01:15:16.893581 22542570456896 run_lib.py:146] step: 371300, eval_loss: 2.72547e-02
I0210 01:15:34.543721 22542570456896 run_lib.py:133] step: 371350, training_loss: 3.92046e-02
I0210 01:15:52.002645 22542570456896 run_lib.py:133] step: 371400, training_loss: 2.62061e-02
I0210 01:15:52.155332 22542570456896 run_lib.py:146] step: 371400, eval_loss: 2.90156e-02
I0210 01:16:09.771542 22542570456896 run_lib.py:133] step: 371450, training_loss: 2.60687e-02
I0210 01:16:27.199340 22542570456896 run_lib.py:133] step: 371500, training_loss: 2.63076e-02
I0210 01:16:27.358686 22542570456896 run_lib.py:146] step: 371500, eval_loss: 2.97525e-02
I0210 01:16:44.926706 22542570456896 run_lib.py:133] step: 371550, training_loss: 2.99143e-02
I0210 01:17:02.376713 22542570456896 run_lib.py:133] step: 371600, training_loss: 3.24894e-02
I0210 01:17:02.533498 22542570456896 run_lib.py:146] step: 371600, eval_loss: 2.29841e-02
I0210 01:17:19.984379 22542570456896 run_lib.py:133] step: 371650, training_loss: 2.70354e-02
I0210 01:17:37.597564 22542570456896 run_lib.py:133] step: 371700, training_loss: 2.89959e-02
I0210 01:17:37.753100 22542570456896 run_lib.py:146] step: 371700, eval_loss: 2.95256e-02
I0210 01:17:55.208698 22542570456896 run_lib.py:133] step: 371750, training_loss: 2.91758e-02
I0210 01:18:12.616424 22542570456896 run_lib.py:133] step: 371800, training_loss: 2.56762e-02
I0210 01:18:12.768269 22542570456896 run_lib.py:146] step: 371800, eval_loss: 2.34665e-02
I0210 01:18:30.393281 22542570456896 run_lib.py:133] step: 371850, training_loss: 2.53738e-02
I0210 01:18:47.881701 22542570456896 run_lib.py:133] step: 371900, training_loss: 2.52818e-02
I0210 01:18:48.050684 22542570456896 run_lib.py:146] step: 371900, eval_loss: 3.56033e-02
I0210 01:19:05.691970 22542570456896 run_lib.py:133] step: 371950, training_loss: 2.62541e-02
I0210 01:19:23.140198 22542570456896 run_lib.py:133] step: 372000, training_loss: 2.77340e-02
I0210 01:19:23.298691 22542570456896 run_lib.py:146] step: 372000, eval_loss: 2.82595e-02
I0210 01:19:40.726402 22542570456896 run_lib.py:133] step: 372050, training_loss: 2.65058e-02
I0210 01:19:58.292581 22542570456896 run_lib.py:133] step: 372100, training_loss: 2.69632e-02
I0210 01:19:58.461525 22542570456896 run_lib.py:146] step: 372100, eval_loss: 2.05691e-02
I0210 01:20:15.939100 22542570456896 run_lib.py:133] step: 372150, training_loss: 3.07202e-02
I0210 01:20:33.400535 22542570456896 run_lib.py:133] step: 372200, training_loss: 2.77160e-02
I0210 01:20:33.563821 22542570456896 run_lib.py:146] step: 372200, eval_loss: 3.88829e-02
I0210 01:20:51.043366 22542570456896 run_lib.py:133] step: 372250, training_loss: 2.08540e-02
I0210 01:21:08.713012 22542570456896 run_lib.py:133] step: 372300, training_loss: 3.92374e-02
I0210 01:21:08.865383 22542570456896 run_lib.py:146] step: 372300, eval_loss: 2.80946e-02
I0210 01:21:26.259647 22542570456896 run_lib.py:133] step: 372350, training_loss: 2.56702e-02
I0210 01:21:43.769497 22542570456896 run_lib.py:133] step: 372400, training_loss: 3.04177e-02
I0210 01:21:43.941901 22542570456896 run_lib.py:146] step: 372400, eval_loss: 2.83555e-02
I0210 01:22:01.448364 22542570456896 run_lib.py:133] step: 372450, training_loss: 2.68978e-02
I0210 01:22:18.892852 22542570456896 run_lib.py:133] step: 372500, training_loss: 3.18374e-02
I0210 01:22:19.051462 22542570456896 run_lib.py:146] step: 372500, eval_loss: 3.45450e-02
I0210 01:22:36.667606 22542570456896 run_lib.py:133] step: 372550, training_loss: 2.79309e-02
I0210 01:22:54.174225 22542570456896 run_lib.py:133] step: 372600, training_loss: 2.60764e-02
I0210 01:22:54.337270 22542570456896 run_lib.py:146] step: 372600, eval_loss: 2.62487e-02
I0210 01:23:11.796479 22542570456896 run_lib.py:133] step: 372650, training_loss: 2.91804e-02
I0210 01:23:29.286474 22542570456896 run_lib.py:133] step: 372700, training_loss: 2.25138e-02
I0210 01:23:29.448639 22542570456896 run_lib.py:146] step: 372700, eval_loss: 2.85610e-02
I0210 01:23:47.101733 22542570456896 run_lib.py:133] step: 372750, training_loss: 3.02301e-02
I0210 01:24:04.520253 22542570456896 run_lib.py:133] step: 372800, training_loss: 2.67922e-02
I0210 01:24:04.680434 22542570456896 run_lib.py:146] step: 372800, eval_loss: 2.88549e-02
I0210 01:24:22.265957 22542570456896 run_lib.py:133] step: 372850, training_loss: 2.15048e-02
I0210 01:24:39.686085 22542570456896 run_lib.py:133] step: 372900, training_loss: 2.42990e-02
I0210 01:24:39.844062 22542570456896 run_lib.py:146] step: 372900, eval_loss: 2.87144e-02
I0210 01:24:57.411320 22542570456896 run_lib.py:133] step: 372950, training_loss: 2.61734e-02
I0210 01:25:14.952645 22542570456896 run_lib.py:133] step: 373000, training_loss: 2.58828e-02
I0210 01:25:15.110071 22542570456896 run_lib.py:146] step: 373000, eval_loss: 2.73038e-02
I0210 01:25:32.588166 22542570456896 run_lib.py:133] step: 373050, training_loss: 3.20917e-02
I0210 01:25:50.209407 22542570456896 run_lib.py:133] step: 373100, training_loss: 2.82593e-02
I0210 01:25:50.364558 22542570456896 run_lib.py:146] step: 373100, eval_loss: 2.49650e-02
I0210 01:26:07.811317 22542570456896 run_lib.py:133] step: 373150, training_loss: 2.41471e-02
I0210 01:26:25.394652 22542570456896 run_lib.py:133] step: 373200, training_loss: 2.17374e-02
I0210 01:26:25.549363 22542570456896 run_lib.py:146] step: 373200, eval_loss: 2.43432e-02
I0210 01:26:42.990288 22542570456896 run_lib.py:133] step: 373250, training_loss: 2.58688e-02
I0210 01:27:00.479507 22542570456896 run_lib.py:133] step: 373300, training_loss: 2.74741e-02
I0210 01:27:00.634655 22542570456896 run_lib.py:146] step: 373300, eval_loss: 3.30853e-02
I0210 01:27:18.300009 22542570456896 run_lib.py:133] step: 373350, training_loss: 2.38653e-02
I0210 01:27:35.744431 22542570456896 run_lib.py:133] step: 373400, training_loss: 2.74751e-02
I0210 01:27:35.900196 22542570456896 run_lib.py:146] step: 373400, eval_loss: 2.21849e-02
I0210 01:27:53.279592 22542570456896 run_lib.py:133] step: 373450, training_loss: 3.23787e-02
I0210 01:28:10.833742 22542570456896 run_lib.py:133] step: 373500, training_loss: 2.81825e-02
I0210 01:28:10.989315 22542570456896 run_lib.py:146] step: 373500, eval_loss: 2.58383e-02
I0210 01:28:28.440036 22542570456896 run_lib.py:133] step: 373550, training_loss: 2.90840e-02
I0210 01:28:45.965115 22542570456896 run_lib.py:133] step: 373600, training_loss: 3.26484e-02
I0210 01:28:46.311043 22542570456896 run_lib.py:146] step: 373600, eval_loss: 3.24954e-02
I0210 01:29:03.760434 22542570456896 run_lib.py:133] step: 373650, training_loss: 2.67474e-02
I0210 01:29:21.160672 22542570456896 run_lib.py:133] step: 373700, training_loss: 2.80435e-02
I0210 01:29:21.313436 22542570456896 run_lib.py:146] step: 373700, eval_loss: 2.78265e-02
I0210 01:29:38.732475 22542570456896 run_lib.py:133] step: 373750, training_loss: 2.69437e-02
I0210 01:29:56.213011 22542570456896 run_lib.py:133] step: 373800, training_loss: 2.39983e-02
I0210 01:29:56.383525 22542570456896 run_lib.py:146] step: 373800, eval_loss: 3.02809e-02
I0210 01:30:13.984426 22542570456896 run_lib.py:133] step: 373850, training_loss: 2.90395e-02
I0210 01:30:31.551963 22542570456896 run_lib.py:133] step: 373900, training_loss: 2.57102e-02
I0210 01:30:31.711356 22542570456896 run_lib.py:146] step: 373900, eval_loss: 3.03186e-02
I0210 01:30:49.139658 22542570456896 run_lib.py:133] step: 373950, training_loss: 3.37404e-02
I0210 01:31:06.585481 22542570456896 run_lib.py:133] step: 374000, training_loss: 2.72233e-02
I0210 01:31:06.741541 22542570456896 run_lib.py:146] step: 374000, eval_loss: 3.18151e-02
I0210 01:31:24.363025 22542570456896 run_lib.py:133] step: 374050, training_loss: 3.45425e-02
I0210 01:31:41.881887 22542570456896 run_lib.py:133] step: 374100, training_loss: 3.32684e-02
I0210 01:31:42.037494 22542570456896 run_lib.py:146] step: 374100, eval_loss: 2.55600e-02
I0210 01:31:59.505284 22542570456896 run_lib.py:133] step: 374150, training_loss: 3.89115e-02
I0210 01:32:16.937895 22542570456896 run_lib.py:133] step: 374200, training_loss: 2.65847e-02
I0210 01:32:17.090012 22542570456896 run_lib.py:146] step: 374200, eval_loss: 2.52654e-02
I0210 01:32:34.710932 22542570456896 run_lib.py:133] step: 374250, training_loss: 2.57108e-02
I0210 01:32:52.161651 22542570456896 run_lib.py:133] step: 374300, training_loss: 3.10827e-02
I0210 01:32:52.317411 22542570456896 run_lib.py:146] step: 374300, eval_loss: 2.80532e-02
I0210 01:33:09.852385 22542570456896 run_lib.py:133] step: 374350, training_loss: 2.99798e-02
I0210 01:33:27.291865 22542570456896 run_lib.py:133] step: 374400, training_loss: 3.24830e-02
I0210 01:33:27.464971 22542570456896 run_lib.py:146] step: 374400, eval_loss: 2.84967e-02
I0210 01:33:45.114691 22542570456896 run_lib.py:133] step: 374450, training_loss: 2.06013e-02
I0210 01:34:02.557360 22542570456896 run_lib.py:133] step: 374500, training_loss: 2.48599e-02
I0210 01:34:02.710694 22542570456896 run_lib.py:146] step: 374500, eval_loss: 1.99012e-02
I0210 01:34:20.165452 22542570456896 run_lib.py:133] step: 374550, training_loss: 2.43216e-02
I0210 01:34:37.734421 22542570456896 run_lib.py:133] step: 374600, training_loss: 2.47716e-02
I0210 01:34:37.889437 22542570456896 run_lib.py:146] step: 374600, eval_loss: 3.07056e-02
I0210 01:34:55.313068 22542570456896 run_lib.py:133] step: 374650, training_loss: 2.86516e-02
I0210 01:35:12.928853 22542570456896 run_lib.py:133] step: 374700, training_loss: 2.57861e-02
I0210 01:35:13.089692 22542570456896 run_lib.py:146] step: 374700, eval_loss: 3.67219e-02
I0210 01:35:30.579475 22542570456896 run_lib.py:133] step: 374750, training_loss: 3.34943e-02
I0210 01:35:48.006263 22542570456896 run_lib.py:133] step: 374800, training_loss: 3.24425e-02
I0210 01:35:48.163598 22542570456896 run_lib.py:146] step: 374800, eval_loss: 2.67204e-02
I0210 01:36:05.739599 22542570456896 run_lib.py:133] step: 374850, training_loss: 2.76107e-02
I0210 01:36:23.172265 22542570456896 run_lib.py:133] step: 374900, training_loss: 2.80790e-02
I0210 01:36:23.330533 22542570456896 run_lib.py:146] step: 374900, eval_loss: 2.98836e-02
I0210 01:36:40.767096 22542570456896 run_lib.py:133] step: 374950, training_loss: 2.74400e-02
I0210 01:36:58.303801 22542570456896 run_lib.py:133] step: 375000, training_loss: 3.43190e-02
I0210 01:36:58.460235 22542570456896 run_lib.py:146] step: 375000, eval_loss: 2.52284e-02
I0210 01:37:16.083680 22542570456896 run_lib.py:133] step: 375050, training_loss: 2.68719e-02
I0210 01:37:33.482919 22542570456896 run_lib.py:133] step: 375100, training_loss: 2.52738e-02
I0210 01:37:33.637473 22542570456896 run_lib.py:146] step: 375100, eval_loss: 3.00274e-02
I0210 01:37:51.122670 22542570456896 run_lib.py:133] step: 375150, training_loss: 3.52218e-02
I0210 01:38:08.565387 22542570456896 run_lib.py:133] step: 375200, training_loss: 2.82800e-02
I0210 01:38:08.721575 22542570456896 run_lib.py:146] step: 375200, eval_loss: 2.84918e-02
I0210 01:38:26.208416 22542570456896 run_lib.py:133] step: 375250, training_loss: 3.27073e-02
I0210 01:38:43.683645 22542570456896 run_lib.py:133] step: 375300, training_loss: 2.43736e-02
I0210 01:38:43.850310 22542570456896 run_lib.py:146] step: 375300, eval_loss: 2.20969e-02
I0210 01:39:01.470838 22542570456896 run_lib.py:133] step: 375350, training_loss: 2.56349e-02
I0210 01:39:18.953308 22542570456896 run_lib.py:133] step: 375400, training_loss: 3.44782e-02
I0210 01:39:19.109411 22542570456896 run_lib.py:146] step: 375400, eval_loss: 3.24661e-02
I0210 01:39:36.561800 22542570456896 run_lib.py:133] step: 375450, training_loss: 2.67207e-02
I0210 01:39:54.010544 22542570456896 run_lib.py:133] step: 375500, training_loss: 2.70974e-02
I0210 01:39:54.167469 22542570456896 run_lib.py:146] step: 375500, eval_loss: 2.79161e-02
I0210 01:40:11.822061 22542570456896 run_lib.py:133] step: 375550, training_loss: 2.63413e-02
I0210 01:40:29.226898 22542570456896 run_lib.py:133] step: 375600, training_loss: 3.17577e-02
I0210 01:40:29.377995 22542570456896 run_lib.py:146] step: 375600, eval_loss: 2.36773e-02
I0210 01:40:46.948182 22542570456896 run_lib.py:133] step: 375650, training_loss: 2.69935e-02
I0210 01:41:04.379678 22542570456896 run_lib.py:133] step: 375700, training_loss: 2.67829e-02
I0210 01:41:04.535367 22542570456896 run_lib.py:146] step: 375700, eval_loss: 3.85655e-02
I0210 01:41:22.123430 22542570456896 run_lib.py:133] step: 375750, training_loss: 2.69125e-02
I0210 01:41:39.556232 22542570456896 run_lib.py:133] step: 375800, training_loss: 2.51449e-02
I0210 01:41:39.731204 22542570456896 run_lib.py:146] step: 375800, eval_loss: 2.82132e-02
I0210 01:41:57.444396 22542570456896 run_lib.py:133] step: 375850, training_loss: 2.32653e-02
I0210 01:42:14.873635 22542570456896 run_lib.py:133] step: 375900, training_loss: 3.14097e-02
I0210 01:42:15.027709 22542570456896 run_lib.py:146] step: 375900, eval_loss: 1.91231e-02
I0210 01:42:32.480225 22542570456896 run_lib.py:133] step: 375950, training_loss: 3.25995e-02
I0210 01:42:50.067493 22542570456896 run_lib.py:133] step: 376000, training_loss: 2.85361e-02
I0210 01:42:50.224075 22542570456896 run_lib.py:146] step: 376000, eval_loss: 2.13043e-02
I0210 01:43:07.668156 22542570456896 run_lib.py:133] step: 376050, training_loss: 3.41343e-02
I0210 01:43:25.127728 22542570456896 run_lib.py:133] step: 376100, training_loss: 2.13078e-02
I0210 01:43:25.282984 22542570456896 run_lib.py:146] step: 376100, eval_loss: 2.72581e-02
I0210 01:43:42.897451 22542570456896 run_lib.py:133] step: 376150, training_loss: 3.03873e-02
I0210 01:44:00.419646 22542570456896 run_lib.py:133] step: 376200, training_loss: 2.48602e-02
I0210 01:44:00.574390 22542570456896 run_lib.py:146] step: 376200, eval_loss: 2.33003e-02
I0210 01:44:17.869587 22542570456896 run_lib.py:133] step: 376250, training_loss: 2.99543e-02
I0210 01:44:35.263272 22542570456896 run_lib.py:133] step: 376300, training_loss: 2.86857e-02
I0210 01:44:35.423294 22542570456896 run_lib.py:146] step: 376300, eval_loss: 3.23199e-02
I0210 01:44:52.906332 22542570456896 run_lib.py:133] step: 376350, training_loss: 2.48459e-02
I0210 01:45:10.580581 22542570456896 run_lib.py:133] step: 376400, training_loss: 2.34477e-02
I0210 01:45:10.737174 22542570456896 run_lib.py:146] step: 376400, eval_loss: 3.70195e-02
I0210 01:45:28.188147 22542570456896 run_lib.py:133] step: 376450, training_loss: 2.50377e-02
I0210 01:45:45.629129 22542570456896 run_lib.py:133] step: 376500, training_loss: 2.69585e-02
I0210 01:45:45.784279 22542570456896 run_lib.py:146] step: 376500, eval_loss: 2.70504e-02
I0210 01:46:03.220077 22542570456896 run_lib.py:133] step: 376550, training_loss: 2.35202e-02
I0210 01:46:20.836024 22542570456896 run_lib.py:133] step: 376600, training_loss: 3.36403e-02
I0210 01:46:20.989880 22542570456896 run_lib.py:146] step: 376600, eval_loss: 2.42466e-02
I0210 01:46:38.465121 22542570456896 run_lib.py:133] step: 376650, training_loss: 3.01425e-02
I0210 01:46:56.024827 22542570456896 run_lib.py:133] step: 376700, training_loss: 2.88887e-02
I0210 01:46:56.189095 22542570456896 run_lib.py:146] step: 376700, eval_loss: 2.48861e-02
I0210 01:47:13.610054 22542570456896 run_lib.py:133] step: 376750, training_loss: 2.79351e-02
I0210 01:47:30.991152 22542570456896 run_lib.py:133] step: 376800, training_loss: 2.92547e-02
I0210 01:47:31.147592 22542570456896 run_lib.py:146] step: 376800, eval_loss: 2.84262e-02
I0210 01:47:48.729806 22542570456896 run_lib.py:133] step: 376850, training_loss: 2.08285e-02
I0210 01:48:06.287480 22542570456896 run_lib.py:133] step: 376900, training_loss: 3.16970e-02
I0210 01:48:06.443045 22542570456896 run_lib.py:146] step: 376900, eval_loss: 2.65732e-02
I0210 01:48:23.907953 22542570456896 run_lib.py:133] step: 376950, training_loss: 2.99432e-02
I0210 01:48:41.345281 22542570456896 run_lib.py:133] step: 377000, training_loss: 2.97192e-02
I0210 01:48:41.499498 22542570456896 run_lib.py:146] step: 377000, eval_loss: 3.03033e-02
I0210 01:48:59.092259 22542570456896 run_lib.py:133] step: 377050, training_loss: 2.97298e-02
I0210 01:49:16.503819 22542570456896 run_lib.py:133] step: 377100, training_loss: 2.42290e-02
I0210 01:49:16.657353 22542570456896 run_lib.py:146] step: 377100, eval_loss: 2.28576e-02
I0210 01:49:34.217361 22542570456896 run_lib.py:133] step: 377150, training_loss: 2.56817e-02
I0210 01:49:51.682000 22542570456896 run_lib.py:133] step: 377200, training_loss: 2.57200e-02
I0210 01:49:51.852357 22542570456896 run_lib.py:146] step: 377200, eval_loss: 2.84228e-02
I0210 01:50:09.506603 22542570456896 run_lib.py:133] step: 377250, training_loss: 2.95247e-02
I0210 01:50:26.971084 22542570456896 run_lib.py:133] step: 377300, training_loss: 3.03097e-02
I0210 01:50:27.133583 22542570456896 run_lib.py:146] step: 377300, eval_loss: 2.81712e-02
I0210 01:50:44.558232 22542570456896 run_lib.py:133] step: 377350, training_loss: 2.76919e-02
I0210 01:51:02.114165 22542570456896 run_lib.py:133] step: 377400, training_loss: 2.42030e-02
I0210 01:51:02.270505 22542570456896 run_lib.py:146] step: 377400, eval_loss: 2.41166e-02
I0210 01:51:19.725999 22542570456896 run_lib.py:133] step: 377450, training_loss: 2.40252e-02
I0210 01:51:37.399810 22542570456896 run_lib.py:133] step: 377500, training_loss: 2.46422e-02
I0210 01:51:37.555619 22542570456896 run_lib.py:146] step: 377500, eval_loss: 3.08957e-02
I0210 01:51:54.998522 22542570456896 run_lib.py:133] step: 377550, training_loss: 2.78702e-02
I0210 01:52:12.397220 22542570456896 run_lib.py:133] step: 377600, training_loss: 2.50271e-02
I0210 01:52:12.553405 22542570456896 run_lib.py:146] step: 377600, eval_loss: 2.70167e-02
I0210 01:52:30.185136 22542570456896 run_lib.py:133] step: 377650, training_loss: 2.93197e-02
I0210 01:52:47.616288 22542570456896 run_lib.py:133] step: 377700, training_loss: 3.15137e-02
I0210 01:52:47.774417 22542570456896 run_lib.py:146] step: 377700, eval_loss: 2.94725e-02
I0210 01:53:05.220906 22542570456896 run_lib.py:133] step: 377750, training_loss: 2.89008e-02
I0210 01:53:22.866548 22542570456896 run_lib.py:133] step: 377800, training_loss: 2.54749e-02
I0210 01:53:23.018545 22542570456896 run_lib.py:146] step: 377800, eval_loss: 2.96677e-02
I0210 01:53:40.411186 22542570456896 run_lib.py:133] step: 377850, training_loss: 2.85087e-02
I0210 01:53:57.819866 22542570456896 run_lib.py:133] step: 377900, training_loss: 2.70514e-02
I0210 01:53:57.974533 22542570456896 run_lib.py:146] step: 377900, eval_loss: 2.75225e-02
I0210 01:54:15.462036 22542570456896 run_lib.py:133] step: 377950, training_loss: 2.87497e-02
I0210 01:54:32.875459 22542570456896 run_lib.py:133] step: 378000, training_loss: 2.59635e-02
I0210 01:54:33.039319 22542570456896 run_lib.py:146] step: 378000, eval_loss: 2.96959e-02
I0210 01:54:50.480165 22542570456896 run_lib.py:133] step: 378050, training_loss: 2.72211e-02
I0210 01:55:07.956042 22542570456896 run_lib.py:133] step: 378100, training_loss: 3.05254e-02
I0210 01:55:08.111646 22542570456896 run_lib.py:146] step: 378100, eval_loss: 2.13224e-02
I0210 01:55:25.711680 22542570456896 run_lib.py:133] step: 378150, training_loss: 3.36562e-02
I0210 01:55:43.202321 22542570456896 run_lib.py:133] step: 378200, training_loss: 2.21232e-02
I0210 01:55:43.363515 22542570456896 run_lib.py:146] step: 378200, eval_loss: 2.63819e-02
I0210 01:56:00.771812 22542570456896 run_lib.py:133] step: 378250, training_loss: 2.95557e-02
I0210 01:56:18.209685 22542570456896 run_lib.py:133] step: 378300, training_loss: 2.70248e-02
I0210 01:56:18.380339 22542570456896 run_lib.py:146] step: 378300, eval_loss: 3.54987e-02
I0210 01:56:35.964682 22542570456896 run_lib.py:133] step: 378350, training_loss: 3.46424e-02
I0210 01:56:53.426143 22542570456896 run_lib.py:133] step: 378400, training_loss: 2.28555e-02
I0210 01:56:53.581219 22542570456896 run_lib.py:146] step: 378400, eval_loss: 2.29842e-02
I0210 01:57:11.188387 22542570456896 run_lib.py:133] step: 378450, training_loss: 2.93983e-02
I0210 01:57:28.647998 22542570456896 run_lib.py:133] step: 378500, training_loss: 2.22193e-02
I0210 01:57:28.801378 22542570456896 run_lib.py:146] step: 378500, eval_loss: 2.38501e-02
I0210 01:57:46.351111 22542570456896 run_lib.py:133] step: 378550, training_loss: 3.09318e-02
I0210 01:58:03.781040 22542570456896 run_lib.py:133] step: 378600, training_loss: 3.05980e-02
I0210 01:58:03.954388 22542570456896 run_lib.py:146] step: 378600, eval_loss: 2.77325e-02
I0210 01:58:21.575505 22542570456896 run_lib.py:133] step: 378650, training_loss: 2.73016e-02
I0210 01:58:39.043597 22542570456896 run_lib.py:133] step: 378700, training_loss: 2.74821e-02
I0210 01:58:39.201341 22542570456896 run_lib.py:146] step: 378700, eval_loss: 2.17199e-02
I0210 01:58:56.605094 22542570456896 run_lib.py:133] step: 378750, training_loss: 3.11326e-02
I0210 01:59:14.165166 22542570456896 run_lib.py:133] step: 378800, training_loss: 3.01371e-02
I0210 01:59:14.320635 22542570456896 run_lib.py:146] step: 378800, eval_loss: 2.96187e-02
I0210 01:59:31.734658 22542570456896 run_lib.py:133] step: 378850, training_loss: 3.43318e-02
I0210 01:59:49.261272 22542570456896 run_lib.py:133] step: 378900, training_loss: 3.05407e-02
I0210 01:59:49.416180 22542570456896 run_lib.py:146] step: 378900, eval_loss: 3.24611e-02
I0210 02:00:07.020125 22542570456896 run_lib.py:133] step: 378950, training_loss: 3.10102e-02
I0210 02:00:24.415473 22542570456896 run_lib.py:133] step: 379000, training_loss: 2.86159e-02
I0210 02:00:24.569406 22542570456896 run_lib.py:146] step: 379000, eval_loss: 3.25192e-02
I0210 02:00:42.140920 22542570456896 run_lib.py:133] step: 379050, training_loss: 2.84058e-02
I0210 02:00:59.581894 22542570456896 run_lib.py:133] step: 379100, training_loss: 2.81541e-02
I0210 02:00:59.742292 22542570456896 run_lib.py:146] step: 379100, eval_loss: 3.22111e-02
I0210 02:01:17.170834 22542570456896 run_lib.py:133] step: 379150, training_loss: 3.66887e-02
I0210 02:01:34.817382 22542570456896 run_lib.py:133] step: 379200, training_loss: 2.97810e-02
I0210 02:01:34.974679 22542570456896 run_lib.py:146] step: 379200, eval_loss: 2.39267e-02
I0210 02:01:52.397741 22542570456896 run_lib.py:133] step: 379250, training_loss: 3.79927e-02
I0210 02:02:09.853573 22542570456896 run_lib.py:133] step: 379300, training_loss: 2.50411e-02
I0210 02:02:10.010505 22542570456896 run_lib.py:146] step: 379300, eval_loss: 2.59103e-02
I0210 02:02:27.405959 22542570456896 run_lib.py:133] step: 379350, training_loss: 2.98160e-02
I0210 02:02:44.986431 22542570456896 run_lib.py:133] step: 379400, training_loss: 3.09872e-02
I0210 02:02:45.138059 22542570456896 run_lib.py:146] step: 379400, eval_loss: 2.25861e-02
I0210 02:03:02.580476 22542570456896 run_lib.py:133] step: 379450, training_loss: 3.09693e-02
I0210 02:03:20.106302 22542570456896 run_lib.py:133] step: 379500, training_loss: 2.74390e-02
I0210 02:03:20.276647 22542570456896 run_lib.py:146] step: 379500, eval_loss: 2.57461e-02
I0210 02:03:37.713824 22542570456896 run_lib.py:133] step: 379550, training_loss: 2.12489e-02
I0210 02:03:55.158517 22542570456896 run_lib.py:133] step: 379600, training_loss: 3.15953e-02
I0210 02:03:55.322547 22542570456896 run_lib.py:146] step: 379600, eval_loss: 2.99262e-02
I0210 02:04:12.976113 22542570456896 run_lib.py:133] step: 379650, training_loss: 2.58521e-02
I0210 02:04:30.479349 22542570456896 run_lib.py:133] step: 379700, training_loss: 2.47508e-02
I0210 02:04:30.649846 22542570456896 run_lib.py:146] step: 379700, eval_loss: 3.45093e-02
I0210 02:04:48.080204 22542570456896 run_lib.py:133] step: 379750, training_loss: 2.09112e-02
I0210 02:05:05.561007 22542570456896 run_lib.py:133] step: 379800, training_loss: 3.61561e-02
I0210 02:05:05.717658 22542570456896 run_lib.py:146] step: 379800, eval_loss: 3.00247e-02
I0210 02:05:23.368476 22542570456896 run_lib.py:133] step: 379850, training_loss: 2.36243e-02
I0210 02:05:40.769431 22542570456896 run_lib.py:133] step: 379900, training_loss: 3.31475e-02
I0210 02:05:40.921430 22542570456896 run_lib.py:146] step: 379900, eval_loss: 2.81655e-02
I0210 02:05:58.486819 22542570456896 run_lib.py:133] step: 379950, training_loss: 2.95024e-02
I0210 02:06:15.907678 22542570456896 run_lib.py:133] step: 380000, training_loss: 2.11434e-02
I0210 02:06:16.629445 22542570456896 run_lib.py:146] step: 380000, eval_loss: 2.62563e-02
I0210 02:06:36.918146 22542570456896 run_lib.py:133] step: 380050, training_loss: 2.80425e-02
I0210 02:06:54.299321 22542570456896 run_lib.py:133] step: 380100, training_loss: 2.79012e-02
I0210 02:06:54.458402 22542570456896 run_lib.py:146] step: 380100, eval_loss: 3.04618e-02
I0210 02:07:11.944817 22542570456896 run_lib.py:133] step: 380150, training_loss: 2.73957e-02
I0210 02:07:29.351731 22542570456896 run_lib.py:133] step: 380200, training_loss: 2.70500e-02
I0210 02:07:29.508370 22542570456896 run_lib.py:146] step: 380200, eval_loss: 1.80071e-02
I0210 02:07:46.991262 22542570456896 run_lib.py:133] step: 380250, training_loss: 2.53729e-02
I0210 02:08:04.485641 22542570456896 run_lib.py:133] step: 380300, training_loss: 3.11123e-02
I0210 02:08:04.640441 22542570456896 run_lib.py:146] step: 380300, eval_loss: 3.69258e-02
I0210 02:08:22.255378 22542570456896 run_lib.py:133] step: 380350, training_loss: 2.89135e-02
I0210 02:08:39.719228 22542570456896 run_lib.py:133] step: 380400, training_loss: 3.15804e-02
I0210 02:08:39.874085 22542570456896 run_lib.py:146] step: 380400, eval_loss: 3.17023e-02
I0210 02:08:57.296270 22542570456896 run_lib.py:133] step: 380450, training_loss: 2.84429e-02
I0210 02:09:14.709399 22542570456896 run_lib.py:133] step: 380500, training_loss: 3.02539e-02
I0210 02:09:14.873563 22542570456896 run_lib.py:146] step: 380500, eval_loss: 3.06755e-02
I0210 02:09:32.495778 22542570456896 run_lib.py:133] step: 380550, training_loss: 2.44428e-02
I0210 02:09:49.934145 22542570456896 run_lib.py:133] step: 380600, training_loss: 2.70120e-02
I0210 02:09:50.093405 22542570456896 run_lib.py:146] step: 380600, eval_loss: 3.14235e-02
I0210 02:10:07.696825 22542570456896 run_lib.py:133] step: 380650, training_loss: 2.97426e-02
I0210 02:10:25.075107 22542570456896 run_lib.py:133] step: 380700, training_loss: 2.72515e-02
I0210 02:10:25.230394 22542570456896 run_lib.py:146] step: 380700, eval_loss: 2.97256e-02
I0210 02:10:42.832716 22542570456896 run_lib.py:133] step: 380750, training_loss: 2.76912e-02
I0210 02:11:00.236010 22542570456896 run_lib.py:133] step: 380800, training_loss: 2.57146e-02
I0210 02:11:00.411885 22542570456896 run_lib.py:146] step: 380800, eval_loss: 2.94065e-02
I0210 02:11:17.892447 22542570456896 run_lib.py:133] step: 380850, training_loss: 2.31013e-02
I0210 02:11:35.524331 22542570456896 run_lib.py:133] step: 380900, training_loss: 2.95687e-02
I0210 02:11:35.675334 22542570456896 run_lib.py:146] step: 380900, eval_loss: 2.85637e-02
I0210 02:11:53.125644 22542570456896 run_lib.py:133] step: 380950, training_loss: 2.39976e-02
I0210 02:12:10.758800 22542570456896 run_lib.py:133] step: 381000, training_loss: 2.82040e-02
I0210 02:12:10.915358 22542570456896 run_lib.py:146] step: 381000, eval_loss: 2.60731e-02
I0210 02:12:28.355762 22542570456896 run_lib.py:133] step: 381050, training_loss: 2.95791e-02
I0210 02:12:45.817412 22542570456896 run_lib.py:133] step: 381100, training_loss: 2.53417e-02
I0210 02:12:45.992258 22542570456896 run_lib.py:146] step: 381100, eval_loss: 2.55077e-02
I0210 02:13:03.618566 22542570456896 run_lib.py:133] step: 381150, training_loss: 2.84462e-02
I0210 02:13:21.101023 22542570456896 run_lib.py:133] step: 381200, training_loss: 1.60112e-02
I0210 02:13:21.256421 22542570456896 run_lib.py:146] step: 381200, eval_loss: 2.82447e-02
I0210 02:13:38.677845 22542570456896 run_lib.py:133] step: 381250, training_loss: 2.61838e-02
I0210 02:13:56.240075 22542570456896 run_lib.py:133] step: 381300, training_loss: 2.97059e-02
I0210 02:13:56.391116 22542570456896 run_lib.py:146] step: 381300, eval_loss: 2.64087e-02
I0210 02:14:13.825514 22542570456896 run_lib.py:133] step: 381350, training_loss: 3.26718e-02
I0210 02:14:31.241647 22542570456896 run_lib.py:133] step: 381400, training_loss: 3.00785e-02
I0210 02:14:31.544248 22542570456896 run_lib.py:146] step: 381400, eval_loss: 2.49284e-02
I0210 02:14:49.014764 22542570456896 run_lib.py:133] step: 381450, training_loss: 3.31984e-02
I0210 02:15:06.435128 22542570456896 run_lib.py:133] step: 381500, training_loss: 2.38487e-02
I0210 02:15:06.591176 22542570456896 run_lib.py:146] step: 381500, eval_loss: 2.25919e-02
I0210 02:15:23.994927 22542570456896 run_lib.py:133] step: 381550, training_loss: 3.19419e-02
I0210 02:15:41.516021 22542570456896 run_lib.py:133] step: 381600, training_loss: 3.50689e-02
I0210 02:15:41.676757 22542570456896 run_lib.py:146] step: 381600, eval_loss: 2.72582e-02
I0210 02:15:59.304803 22542570456896 run_lib.py:133] step: 381650, training_loss: 3.07682e-02
I0210 02:16:16.829937 22542570456896 run_lib.py:133] step: 381700, training_loss: 3.05799e-02
I0210 02:16:16.985988 22542570456896 run_lib.py:146] step: 381700, eval_loss: 3.05668e-02
I0210 02:16:34.418784 22542570456896 run_lib.py:133] step: 381750, training_loss: 3.04549e-02
I0210 02:16:51.854052 22542570456896 run_lib.py:133] step: 381800, training_loss: 2.75383e-02
I0210 02:16:52.015605 22542570456896 run_lib.py:146] step: 381800, eval_loss: 2.52461e-02
I0210 02:17:09.633197 22542570456896 run_lib.py:133] step: 381850, training_loss: 2.51926e-02
I0210 02:17:27.129952 22542570456896 run_lib.py:133] step: 381900, training_loss: 2.16698e-02
I0210 02:17:27.289982 22542570456896 run_lib.py:146] step: 381900, eval_loss: 3.00075e-02
I0210 02:17:44.696228 22542570456896 run_lib.py:133] step: 381950, training_loss: 3.15002e-02
I0210 02:18:02.159436 22542570456896 run_lib.py:133] step: 382000, training_loss: 2.72876e-02
I0210 02:18:02.335499 22542570456896 run_lib.py:146] step: 382000, eval_loss: 2.84446e-02
I0210 02:18:19.995059 22542570456896 run_lib.py:133] step: 382050, training_loss: 2.66989e-02
I0210 02:18:37.420173 22542570456896 run_lib.py:133] step: 382100, training_loss: 2.39205e-02
I0210 02:18:37.576630 22542570456896 run_lib.py:146] step: 382100, eval_loss: 2.76146e-02
I0210 02:18:55.185316 22542570456896 run_lib.py:133] step: 382150, training_loss: 2.46606e-02
I0210 02:19:12.609235 22542570456896 run_lib.py:133] step: 382200, training_loss: 2.69651e-02
I0210 02:19:12.766073 22542570456896 run_lib.py:146] step: 382200, eval_loss: 3.01108e-02
I0210 02:19:30.314990 22542570456896 run_lib.py:133] step: 382250, training_loss: 2.71411e-02
I0210 02:19:47.761183 22542570456896 run_lib.py:133] step: 382300, training_loss: 2.70368e-02
I0210 02:19:47.915110 22542570456896 run_lib.py:146] step: 382300, eval_loss: 2.20464e-02
I0210 02:20:05.342714 22542570456896 run_lib.py:133] step: 382350, training_loss: 2.70574e-02
I0210 02:20:22.945180 22542570456896 run_lib.py:133] step: 382400, training_loss: 2.79898e-02
I0210 02:20:23.100331 22542570456896 run_lib.py:146] step: 382400, eval_loss: 2.82289e-02
I0210 02:20:40.541837 22542570456896 run_lib.py:133] step: 382450, training_loss: 2.47336e-02
I0210 02:20:58.144239 22542570456896 run_lib.py:133] step: 382500, training_loss: 3.15702e-02
I0210 02:20:58.307593 22542570456896 run_lib.py:146] step: 382500, eval_loss: 3.37964e-02
I0210 02:21:15.738567 22542570456896 run_lib.py:133] step: 382550, training_loss: 2.57856e-02
I0210 02:21:33.216292 22542570456896 run_lib.py:133] step: 382600, training_loss: 2.55653e-02
I0210 02:21:33.379492 22542570456896 run_lib.py:146] step: 382600, eval_loss: 3.32630e-02
I0210 02:21:50.979167 22542570456896 run_lib.py:133] step: 382650, training_loss: 3.00475e-02
I0210 02:22:08.420925 22542570456896 run_lib.py:133] step: 382700, training_loss: 2.60949e-02
I0210 02:22:08.576077 22542570456896 run_lib.py:146] step: 382700, eval_loss: 2.35686e-02
I0210 02:22:26.029084 22542570456896 run_lib.py:133] step: 382750, training_loss: 3.04456e-02
I0210 02:22:43.466104 22542570456896 run_lib.py:133] step: 382800, training_loss: 2.14070e-02
I0210 02:22:43.621847 22542570456896 run_lib.py:146] step: 382800, eval_loss: 2.80737e-02
I0210 02:23:01.206950 22542570456896 run_lib.py:133] step: 382850, training_loss: 3.11686e-02
I0210 02:23:18.619283 22542570456896 run_lib.py:133] step: 382900, training_loss: 3.29093e-02
I0210 02:23:18.776493 22542570456896 run_lib.py:146] step: 382900, eval_loss: 3.04747e-02
I0210 02:23:36.327253 22542570456896 run_lib.py:133] step: 382950, training_loss: 2.42055e-02
I0210 02:23:53.757574 22542570456896 run_lib.py:133] step: 383000, training_loss: 2.77521e-02
I0210 02:23:53.916547 22542570456896 run_lib.py:146] step: 383000, eval_loss: 2.51120e-02
I0210 02:24:11.312716 22542570456896 run_lib.py:133] step: 383050, training_loss: 3.56061e-02
I0210 02:24:28.781340 22542570456896 run_lib.py:133] step: 383100, training_loss: 2.96043e-02
I0210 02:24:28.936297 22542570456896 run_lib.py:146] step: 383100, eval_loss: 2.90453e-02
I0210 02:24:46.491969 22542570456896 run_lib.py:133] step: 383150, training_loss: 2.84696e-02
I0210 02:25:04.101720 22542570456896 run_lib.py:133] step: 383200, training_loss: 2.81682e-02
I0210 02:25:04.257139 22542570456896 run_lib.py:146] step: 383200, eval_loss: 2.58064e-02
I0210 02:25:21.677521 22542570456896 run_lib.py:133] step: 383250, training_loss: 2.98429e-02
I0210 02:25:39.126451 22542570456896 run_lib.py:133] step: 383300, training_loss: 2.56719e-02
I0210 02:25:39.279437 22542570456896 run_lib.py:146] step: 383300, eval_loss: 2.57617e-02
I0210 02:25:56.825180 22542570456896 run_lib.py:133] step: 383350, training_loss: 2.87722e-02
I0210 02:26:14.260700 22542570456896 run_lib.py:133] step: 383400, training_loss: 2.86187e-02
I0210 02:26:14.431300 22542570456896 run_lib.py:146] step: 383400, eval_loss: 2.65331e-02
I0210 02:26:32.047033 22542570456896 run_lib.py:133] step: 383450, training_loss: 2.92994e-02
I0210 02:26:49.504119 22542570456896 run_lib.py:133] step: 383500, training_loss: 3.13518e-02
I0210 02:26:49.662488 22542570456896 run_lib.py:146] step: 383500, eval_loss: 2.94065e-02
I0210 02:27:07.267800 22542570456896 run_lib.py:133] step: 383550, training_loss: 3.09141e-02
I0210 02:27:24.688710 22542570456896 run_lib.py:133] step: 383600, training_loss: 3.55560e-02
I0210 02:27:24.844835 22542570456896 run_lib.py:146] step: 383600, eval_loss: 3.77567e-02
I0210 02:27:42.382885 22542570456896 run_lib.py:133] step: 383650, training_loss: 2.89513e-02
I0210 02:27:59.822070 22542570456896 run_lib.py:133] step: 383700, training_loss: 2.56225e-02
I0210 02:27:59.979095 22542570456896 run_lib.py:146] step: 383700, eval_loss: 2.23306e-02
I0210 02:28:17.462651 22542570456896 run_lib.py:133] step: 383750, training_loss: 2.84128e-02
I0210 02:28:35.039378 22542570456896 run_lib.py:133] step: 383800, training_loss: 2.38544e-02
I0210 02:28:35.192346 22542570456896 run_lib.py:146] step: 383800, eval_loss: 2.89496e-02
I0210 02:28:52.592958 22542570456896 run_lib.py:133] step: 383850, training_loss: 2.71787e-02
I0210 02:29:09.998806 22542570456896 run_lib.py:133] step: 383900, training_loss: 3.25374e-02
I0210 02:29:10.154435 22542570456896 run_lib.py:146] step: 383900, eval_loss: 3.26059e-02
I0210 02:29:27.779815 22542570456896 run_lib.py:133] step: 383950, training_loss: 3.46082e-02
I0210 02:29:45.439123 22542570456896 run_lib.py:133] step: 384000, training_loss: 2.91324e-02
I0210 02:29:45.600626 22542570456896 run_lib.py:146] step: 384000, eval_loss: 3.11283e-02
I0210 02:30:03.000083 22542570456896 run_lib.py:133] step: 384050, training_loss: 2.95215e-02
I0210 02:30:20.406530 22542570456896 run_lib.py:133] step: 384100, training_loss: 2.53015e-02
I0210 02:30:20.562057 22542570456896 run_lib.py:146] step: 384100, eval_loss: 2.66245e-02
I0210 02:30:37.986999 22542570456896 run_lib.py:133] step: 384150, training_loss: 3.43899e-02
I0210 02:30:55.586289 22542570456896 run_lib.py:133] step: 384200, training_loss: 2.63402e-02
I0210 02:30:55.744331 22542570456896 run_lib.py:146] step: 384200, eval_loss: 2.90504e-02
I0210 02:31:13.213877 22542570456896 run_lib.py:133] step: 384250, training_loss: 2.39488e-02
I0210 02:31:30.659384 22542570456896 run_lib.py:133] step: 384300, training_loss: 3.19598e-02
I0210 02:31:30.814344 22542570456896 run_lib.py:146] step: 384300, eval_loss: 2.70976e-02
I0210 02:31:48.242375 22542570456896 run_lib.py:133] step: 384350, training_loss: 2.74851e-02
I0210 02:32:05.837215 22542570456896 run_lib.py:133] step: 384400, training_loss: 2.70053e-02
I0210 02:32:06.002336 22542570456896 run_lib.py:146] step: 384400, eval_loss: 2.67918e-02
I0210 02:32:23.460481 22542570456896 run_lib.py:133] step: 384450, training_loss: 3.24214e-02
I0210 02:32:40.937545 22542570456896 run_lib.py:133] step: 384500, training_loss: 2.54291e-02
I0210 02:32:41.104384 22542570456896 run_lib.py:146] step: 384500, eval_loss: 2.68599e-02
I0210 02:32:58.582913 22542570456896 run_lib.py:133] step: 384550, training_loss: 2.50546e-02
I0210 02:33:16.013064 22542570456896 run_lib.py:133] step: 384600, training_loss: 2.57632e-02
I0210 02:33:16.169550 22542570456896 run_lib.py:146] step: 384600, eval_loss: 2.61727e-02
I0210 02:33:33.752236 22542570456896 run_lib.py:133] step: 384650, training_loss: 2.63387e-02
I0210 02:33:51.234417 22542570456896 run_lib.py:133] step: 384700, training_loss: 2.75591e-02
I0210 02:33:51.386380 22542570456896 run_lib.py:146] step: 384700, eval_loss: 3.81722e-02
I0210 02:34:08.786991 22542570456896 run_lib.py:133] step: 384750, training_loss: 3.20784e-02
I0210 02:34:26.201302 22542570456896 run_lib.py:133] step: 384800, training_loss: 2.94535e-02
I0210 02:34:26.379613 22542570456896 run_lib.py:146] step: 384800, eval_loss: 2.94725e-02
I0210 02:34:44.013371 22542570456896 run_lib.py:133] step: 384850, training_loss: 2.90180e-02
I0210 02:35:01.439326 22542570456896 run_lib.py:133] step: 384900, training_loss: 2.78352e-02
I0210 02:35:01.596235 22542570456896 run_lib.py:146] step: 384900, eval_loss: 2.06055e-02
I0210 02:35:19.157936 22542570456896 run_lib.py:133] step: 384950, training_loss: 3.30994e-02
I0210 02:35:36.598466 22542570456896 run_lib.py:133] step: 385000, training_loss: 2.67053e-02
I0210 02:35:36.754359 22542570456896 run_lib.py:146] step: 385000, eval_loss: 2.47487e-02
I0210 02:35:54.365954 22542570456896 run_lib.py:133] step: 385050, training_loss: 3.03641e-02
I0210 02:36:11.818560 22542570456896 run_lib.py:133] step: 385100, training_loss: 3.09829e-02
I0210 02:36:11.974527 22542570456896 run_lib.py:146] step: 385100, eval_loss: 2.66140e-02
I0210 02:36:29.446151 22542570456896 run_lib.py:133] step: 385150, training_loss: 2.31039e-02
I0210 02:36:47.050761 22542570456896 run_lib.py:133] step: 385200, training_loss: 2.46498e-02
I0210 02:36:47.201484 22542570456896 run_lib.py:146] step: 385200, eval_loss: 2.39353e-02
I0210 02:37:04.623213 22542570456896 run_lib.py:133] step: 385250, training_loss: 2.70779e-02
I0210 02:37:22.177658 22542570456896 run_lib.py:133] step: 385300, training_loss: 2.52302e-02
I0210 02:37:22.334559 22542570456896 run_lib.py:146] step: 385300, eval_loss: 3.11973e-02
I0210 02:37:39.752948 22542570456896 run_lib.py:133] step: 385350, training_loss: 2.58884e-02
I0210 02:37:57.232011 22542570456896 run_lib.py:133] step: 385400, training_loss: 2.98217e-02
I0210 02:37:57.389359 22542570456896 run_lib.py:146] step: 385400, eval_loss: 3.75448e-02
I0210 02:38:14.965558 22542570456896 run_lib.py:133] step: 385450, training_loss: 2.73299e-02
I0210 02:38:32.353550 22542570456896 run_lib.py:133] step: 385500, training_loss: 3.06954e-02
I0210 02:38:32.505791 22542570456896 run_lib.py:146] step: 385500, eval_loss: 3.43193e-02
I0210 02:38:49.970525 22542570456896 run_lib.py:133] step: 385550, training_loss: 2.90064e-02
I0210 02:39:07.509351 22542570456896 run_lib.py:133] step: 385600, training_loss: 2.80079e-02
I0210 02:39:07.672098 22542570456896 run_lib.py:146] step: 385600, eval_loss: 3.03228e-02
I0210 02:39:25.136536 22542570456896 run_lib.py:133] step: 385650, training_loss: 3.38976e-02
I0210 02:39:42.621175 22542570456896 run_lib.py:133] step: 385700, training_loss: 2.83046e-02
I0210 02:39:42.775598 22542570456896 run_lib.py:146] step: 385700, eval_loss: 3.13569e-02
I0210 02:40:00.290801 22542570456896 run_lib.py:133] step: 385750, training_loss: 2.45523e-02
I0210 02:40:17.721921 22542570456896 run_lib.py:133] step: 385800, training_loss: 2.95787e-02
I0210 02:40:17.879476 22542570456896 run_lib.py:146] step: 385800, eval_loss: 3.77176e-02
I0210 02:40:35.286737 22542570456896 run_lib.py:133] step: 385850, training_loss: 2.82712e-02
I0210 02:40:52.701324 22542570456896 run_lib.py:133] step: 385900, training_loss: 3.35369e-02
I0210 02:40:52.875305 22542570456896 run_lib.py:146] step: 385900, eval_loss: 3.31590e-02
I0210 02:41:10.444726 22542570456896 run_lib.py:133] step: 385950, training_loss: 2.82949e-02
I0210 02:41:28.008153 22542570456896 run_lib.py:133] step: 386000, training_loss: 3.34137e-02
I0210 02:41:28.164149 22542570456896 run_lib.py:146] step: 386000, eval_loss: 3.81275e-02
I0210 02:41:45.595123 22542570456896 run_lib.py:133] step: 386050, training_loss: 2.88400e-02
I0210 02:42:03.037390 22542570456896 run_lib.py:133] step: 386100, training_loss: 3.38350e-02
I0210 02:42:03.190433 22542570456896 run_lib.py:146] step: 386100, eval_loss: 3.68770e-02
I0210 02:42:20.753938 22542570456896 run_lib.py:133] step: 386150, training_loss: 2.09516e-02
I0210 02:42:38.199059 22542570456896 run_lib.py:133] step: 386200, training_loss: 3.02695e-02
I0210 02:42:38.367583 22542570456896 run_lib.py:146] step: 386200, eval_loss: 2.49691e-02
I0210 02:42:56.004866 22542570456896 run_lib.py:133] step: 386250, training_loss: 2.62238e-02
I0210 02:43:13.462090 22542570456896 run_lib.py:133] step: 386300, training_loss: 2.59599e-02
I0210 02:43:13.620238 22542570456896 run_lib.py:146] step: 386300, eval_loss: 3.27753e-02
I0210 02:43:31.180956 22542570456896 run_lib.py:133] step: 386350, training_loss: 2.75002e-02
I0210 02:43:48.594690 22542570456896 run_lib.py:133] step: 386400, training_loss: 2.58864e-02
I0210 02:43:48.753344 22542570456896 run_lib.py:146] step: 386400, eval_loss: 3.10654e-02
I0210 02:44:06.323307 22542570456896 run_lib.py:133] step: 386450, training_loss: 2.36712e-02
I0210 02:44:23.786385 22542570456896 run_lib.py:133] step: 386500, training_loss: 2.74553e-02
I0210 02:44:23.941956 22542570456896 run_lib.py:146] step: 386500, eval_loss: 2.94053e-02
I0210 02:44:41.396362 22542570456896 run_lib.py:133] step: 386550, training_loss: 3.35744e-02
I0210 02:44:59.066316 22542570456896 run_lib.py:133] step: 386600, training_loss: 3.14626e-02
I0210 02:44:59.218340 22542570456896 run_lib.py:146] step: 386600, eval_loss: 3.03846e-02
I0210 02:45:16.651519 22542570456896 run_lib.py:133] step: 386650, training_loss: 3.28704e-02
I0210 02:45:34.121234 22542570456896 run_lib.py:133] step: 386700, training_loss: 2.59367e-02
I0210 02:45:34.277275 22542570456896 run_lib.py:146] step: 386700, eval_loss: 3.71653e-02
I0210 02:45:51.830479 22542570456896 run_lib.py:133] step: 386750, training_loss: 2.66248e-02
I0210 02:46:09.282749 22542570456896 run_lib.py:133] step: 386800, training_loss: 2.77992e-02
I0210 02:46:09.463244 22542570456896 run_lib.py:146] step: 386800, eval_loss: 2.79885e-02
I0210 02:46:27.077544 22542570456896 run_lib.py:133] step: 386850, training_loss: 2.50147e-02
I0210 02:46:44.499336 22542570456896 run_lib.py:133] step: 386900, training_loss: 2.89024e-02
I0210 02:46:44.655600 22542570456896 run_lib.py:146] step: 386900, eval_loss: 2.40241e-02
I0210 02:47:02.113156 22542570456896 run_lib.py:133] step: 386950, training_loss: 2.62571e-02
I0210 02:47:19.706281 22542570456896 run_lib.py:133] step: 387000, training_loss: 3.01995e-02
I0210 02:47:19.860979 22542570456896 run_lib.py:146] step: 387000, eval_loss: 2.34049e-02
I0210 02:47:37.290020 22542570456896 run_lib.py:133] step: 387050, training_loss: 3.16607e-02
I0210 02:47:54.775890 22542570456896 run_lib.py:133] step: 387100, training_loss: 2.37729e-02
I0210 02:47:54.932459 22542570456896 run_lib.py:146] step: 387100, eval_loss: 2.54492e-02
I0210 02:48:12.355453 22542570456896 run_lib.py:133] step: 387150, training_loss: 2.78904e-02
I0210 02:48:29.946958 22542570456896 run_lib.py:133] step: 387200, training_loss: 2.15144e-02
I0210 02:48:30.105667 22542570456896 run_lib.py:146] step: 387200, eval_loss: 3.19576e-02
I0210 02:48:47.545583 22542570456896 run_lib.py:133] step: 387250, training_loss: 3.13995e-02
I0210 02:49:05.039881 22542570456896 run_lib.py:133] step: 387300, training_loss: 3.01066e-02
I0210 02:49:05.213370 22542570456896 run_lib.py:146] step: 387300, eval_loss: 2.61515e-02
I0210 02:49:22.668664 22542570456896 run_lib.py:133] step: 387350, training_loss: 3.12481e-02
I0210 02:49:40.122001 22542570456896 run_lib.py:133] step: 387400, training_loss: 2.79148e-02
I0210 02:49:40.279124 22542570456896 run_lib.py:146] step: 387400, eval_loss: 3.05201e-02
I0210 02:49:57.850947 22542570456896 run_lib.py:133] step: 387450, training_loss: 3.02577e-02
I0210 02:50:15.335764 22542570456896 run_lib.py:133] step: 387500, training_loss: 2.39913e-02
I0210 02:50:15.489377 22542570456896 run_lib.py:146] step: 387500, eval_loss: 3.01107e-02
I0210 02:50:32.955209 22542570456896 run_lib.py:133] step: 387550, training_loss: 2.52789e-02
I0210 02:50:50.430656 22542570456896 run_lib.py:133] step: 387600, training_loss: 2.55538e-02
I0210 02:50:50.586536 22542570456896 run_lib.py:146] step: 387600, eval_loss: 3.38279e-02
I0210 02:51:08.205772 22542570456896 run_lib.py:133] step: 387650, training_loss: 2.88902e-02
I0210 02:51:25.633383 22542570456896 run_lib.py:133] step: 387700, training_loss: 2.73416e-02
I0210 02:51:25.792926 22542570456896 run_lib.py:146] step: 387700, eval_loss: 2.90434e-02
I0210 02:51:43.387190 22542570456896 run_lib.py:133] step: 387750, training_loss: 3.45304e-02
I0210 02:52:00.801593 22542570456896 run_lib.py:133] step: 387800, training_loss: 3.13764e-02
I0210 02:52:00.958019 22542570456896 run_lib.py:146] step: 387800, eval_loss: 2.79104e-02
I0210 02:52:18.401375 22542570456896 run_lib.py:133] step: 387850, training_loss: 3.07087e-02
I0210 02:52:35.761728 22542570456896 run_lib.py:133] step: 387900, training_loss: 3.01129e-02
I0210 02:52:35.915910 22542570456896 run_lib.py:146] step: 387900, eval_loss: 3.99335e-02
I0210 02:52:53.275299 22542570456896 run_lib.py:133] step: 387950, training_loss: 2.70165e-02
I0210 02:53:10.774513 22542570456896 run_lib.py:133] step: 388000, training_loss: 2.28535e-02
I0210 02:53:10.926073 22542570456896 run_lib.py:146] step: 388000, eval_loss: 3.06755e-02
I0210 02:53:28.367998 22542570456896 run_lib.py:133] step: 388050, training_loss: 3.46452e-02
I0210 02:53:45.944676 22542570456896 run_lib.py:133] step: 388100, training_loss: 3.26623e-02
I0210 02:53:46.100352 22542570456896 run_lib.py:146] step: 388100, eval_loss: 2.26604e-02
I0210 02:54:03.524574 22542570456896 run_lib.py:133] step: 388150, training_loss: 2.33920e-02
I0210 02:54:20.955353 22542570456896 run_lib.py:133] step: 388200, training_loss: 2.46476e-02
I0210 02:54:21.133404 22542570456896 run_lib.py:146] step: 388200, eval_loss: 3.22179e-02
I0210 02:54:38.805720 22542570456896 run_lib.py:133] step: 388250, training_loss: 3.21905e-02
I0210 02:54:56.210287 22542570456896 run_lib.py:133] step: 388300, training_loss: 2.58131e-02
I0210 02:54:56.370587 22542570456896 run_lib.py:146] step: 388300, eval_loss: 3.31969e-02
I0210 02:55:13.787587 22542570456896 run_lib.py:133] step: 388350, training_loss: 2.73421e-02
I0210 02:55:31.329310 22542570456896 run_lib.py:133] step: 388400, training_loss: 2.31081e-02
I0210 02:55:31.484305 22542570456896 run_lib.py:146] step: 388400, eval_loss: 3.72152e-02
I0210 02:55:48.947107 22542570456896 run_lib.py:133] step: 388450, training_loss: 2.71681e-02
I0210 02:56:06.366404 22542570456896 run_lib.py:133] step: 388500, training_loss: 2.99287e-02
I0210 02:56:06.705210 22542570456896 run_lib.py:146] step: 388500, eval_loss: 2.81062e-02
I0210 02:56:24.113950 22542570456896 run_lib.py:133] step: 388550, training_loss: 2.68612e-02
I0210 02:56:41.578159 22542570456896 run_lib.py:133] step: 388600, training_loss: 2.68610e-02
I0210 02:56:41.733672 22542570456896 run_lib.py:146] step: 388600, eval_loss: 2.31447e-02
I0210 02:56:59.163849 22542570456896 run_lib.py:133] step: 388650, training_loss: 2.85496e-02
I0210 02:57:16.599258 22542570456896 run_lib.py:133] step: 388700, training_loss: 3.27122e-02
I0210 02:57:16.759495 22542570456896 run_lib.py:146] step: 388700, eval_loss: 3.89901e-02
I0210 02:57:34.330650 22542570456896 run_lib.py:133] step: 388750, training_loss: 2.74840e-02
I0210 02:57:51.870664 22542570456896 run_lib.py:133] step: 388800, training_loss: 2.56674e-02
I0210 02:57:52.026484 22542570456896 run_lib.py:146] step: 388800, eval_loss: 3.15588e-02
I0210 02:58:09.421229 22542570456896 run_lib.py:133] step: 388850, training_loss: 3.22017e-02
I0210 02:58:26.830550 22542570456896 run_lib.py:133] step: 388900, training_loss: 2.45679e-02
I0210 02:58:26.990333 22542570456896 run_lib.py:146] step: 388900, eval_loss: 3.05683e-02
I0210 02:58:44.552193 22542570456896 run_lib.py:133] step: 388950, training_loss: 3.74504e-02
I0210 02:59:02.058368 22542570456896 run_lib.py:133] step: 389000, training_loss: 3.21130e-02
I0210 02:59:02.212580 22542570456896 run_lib.py:146] step: 389000, eval_loss: 3.14831e-02
I0210 02:59:19.697328 22542570456896 run_lib.py:133] step: 389050, training_loss: 2.48752e-02
I0210 02:59:37.094061 22542570456896 run_lib.py:133] step: 389100, training_loss: 3.16338e-02
I0210 02:59:37.253407 22542570456896 run_lib.py:146] step: 389100, eval_loss: 2.67473e-02
I0210 02:59:54.881539 22542570456896 run_lib.py:133] step: 389150, training_loss: 2.43714e-02
I0210 03:00:12.339491 22542570456896 run_lib.py:133] step: 389200, training_loss: 2.69348e-02
I0210 03:00:12.501635 22542570456896 run_lib.py:146] step: 389200, eval_loss: 3.80092e-02
I0210 03:00:30.050376 22542570456896 run_lib.py:133] step: 389250, training_loss: 2.96332e-02
I0210 03:00:47.574870 22542570456896 run_lib.py:133] step: 389300, training_loss: 2.02453e-02
I0210 03:00:47.731130 22542570456896 run_lib.py:146] step: 389300, eval_loss: 3.16768e-02
I0210 03:01:05.351186 22542570456896 run_lib.py:133] step: 389350, training_loss: 2.64479e-02
I0210 03:01:22.768502 22542570456896 run_lib.py:133] step: 389400, training_loss: 2.28052e-02
I0210 03:01:22.921210 22542570456896 run_lib.py:146] step: 389400, eval_loss: 2.91683e-02
I0210 03:01:40.348160 22542570456896 run_lib.py:133] step: 389450, training_loss: 2.32584e-02
I0210 03:01:57.899651 22542570456896 run_lib.py:133] step: 389500, training_loss: 3.17754e-02
I0210 03:01:58.052385 22542570456896 run_lib.py:146] step: 389500, eval_loss: 2.77065e-02
I0210 03:02:15.448778 22542570456896 run_lib.py:133] step: 389550, training_loss: 3.12684e-02
I0210 03:02:33.057333 22542570456896 run_lib.py:133] step: 389600, training_loss: 2.71957e-02
I0210 03:02:33.228339 22542570456896 run_lib.py:146] step: 389600, eval_loss: 3.00303e-02
I0210 03:02:50.666664 22542570456896 run_lib.py:133] step: 389650, training_loss: 2.39227e-02
I0210 03:03:08.131739 22542570456896 run_lib.py:133] step: 389700, training_loss: 2.08217e-02
I0210 03:03:08.287359 22542570456896 run_lib.py:146] step: 389700, eval_loss: 3.15997e-02
I0210 03:03:25.911939 22542570456896 run_lib.py:133] step: 389750, training_loss: 2.92412e-02
I0210 03:03:43.317996 22542570456896 run_lib.py:133] step: 389800, training_loss: 2.94980e-02
I0210 03:03:43.484448 22542570456896 run_lib.py:146] step: 389800, eval_loss: 3.09926e-02
I0210 03:04:00.945406 22542570456896 run_lib.py:133] step: 389850, training_loss: 2.03921e-02
I0210 03:04:18.414235 22542570456896 run_lib.py:133] step: 389900, training_loss: 2.97940e-02
I0210 03:04:18.573549 22542570456896 run_lib.py:146] step: 389900, eval_loss: 2.40626e-02
I0210 03:04:36.174921 22542570456896 run_lib.py:133] step: 389950, training_loss: 2.77461e-02
I0210 03:04:53.586057 22542570456896 run_lib.py:133] step: 390000, training_loss: 2.28001e-02
I0210 03:04:54.343224 22542570456896 run_lib.py:146] step: 390000, eval_loss: 2.82427e-02
I0210 03:05:14.520603 22542570456896 run_lib.py:133] step: 390050, training_loss: 2.82464e-02
I0210 03:05:31.963308 22542570456896 run_lib.py:133] step: 390100, training_loss: 3.09618e-02
I0210 03:05:32.132651 22542570456896 run_lib.py:146] step: 390100, eval_loss: 2.87460e-02
I0210 03:05:49.705619 22542570456896 run_lib.py:133] step: 390150, training_loss: 2.43449e-02
I0210 03:06:07.161355 22542570456896 run_lib.py:133] step: 390200, training_loss: 2.43230e-02
I0210 03:06:07.319376 22542570456896 run_lib.py:146] step: 390200, eval_loss: 2.96220e-02
I0210 03:06:24.744704 22542570456896 run_lib.py:133] step: 390250, training_loss: 2.73090e-02
I0210 03:06:42.286449 22542570456896 run_lib.py:133] step: 390300, training_loss: 2.80305e-02
I0210 03:06:42.448426 22542570456896 run_lib.py:146] step: 390300, eval_loss: 2.92131e-02
I0210 03:06:59.863217 22542570456896 run_lib.py:133] step: 390350, training_loss: 2.60516e-02
I0210 03:07:17.327812 22542570456896 run_lib.py:133] step: 390400, training_loss: 2.77396e-02
I0210 03:07:17.491008 22542570456896 run_lib.py:146] step: 390400, eval_loss: 2.89229e-02
I0210 03:07:34.914077 22542570456896 run_lib.py:133] step: 390450, training_loss: 3.43921e-02
I0210 03:07:52.514062 22542570456896 run_lib.py:133] step: 390500, training_loss: 2.88382e-02
I0210 03:07:52.671331 22542570456896 run_lib.py:146] step: 390500, eval_loss: 1.87584e-02
I0210 03:08:10.090282 22542570456896 run_lib.py:133] step: 390550, training_loss: 2.43713e-02
I0210 03:08:27.610502 22542570456896 run_lib.py:133] step: 390600, training_loss: 3.55419e-02
I0210 03:08:27.771338 22542570456896 run_lib.py:146] step: 390600, eval_loss: 2.63927e-02
I0210 03:08:45.180128 22542570456896 run_lib.py:133] step: 390650, training_loss: 2.79782e-02
I0210 03:09:02.641619 22542570456896 run_lib.py:133] step: 390700, training_loss: 2.96439e-02
I0210 03:09:02.799824 22542570456896 run_lib.py:146] step: 390700, eval_loss: 3.53310e-02
I0210 03:09:20.417208 22542570456896 run_lib.py:133] step: 390750, training_loss: 2.91359e-02
I0210 03:09:37.924687 22542570456896 run_lib.py:133] step: 390800, training_loss: 2.53104e-02
I0210 03:09:38.079679 22542570456896 run_lib.py:146] step: 390800, eval_loss: 3.06315e-02
I0210 03:09:55.491763 22542570456896 run_lib.py:133] step: 390850, training_loss: 3.60150e-02
I0210 03:10:12.877442 22542570456896 run_lib.py:133] step: 390900, training_loss: 2.95789e-02
I0210 03:10:13.035243 22542570456896 run_lib.py:146] step: 390900, eval_loss: 2.48057e-02
I0210 03:10:30.606155 22542570456896 run_lib.py:133] step: 390950, training_loss: 3.99382e-02
I0210 03:10:48.054791 22542570456896 run_lib.py:133] step: 391000, training_loss: 3.61671e-02
I0210 03:10:48.220588 22542570456896 run_lib.py:146] step: 391000, eval_loss: 2.59509e-02
I0210 03:11:05.815713 22542570456896 run_lib.py:133] step: 391050, training_loss: 3.36790e-02
I0210 03:11:23.255857 22542570456896 run_lib.py:133] step: 391100, training_loss: 2.96154e-02
I0210 03:11:23.414617 22542570456896 run_lib.py:146] step: 391100, eval_loss: 2.49002e-02
I0210 03:11:40.949313 22542570456896 run_lib.py:133] step: 391150, training_loss: 2.23527e-02
I0210 03:11:58.334370 22542570456896 run_lib.py:133] step: 391200, training_loss: 3.13397e-02
I0210 03:11:58.487565 22542570456896 run_lib.py:146] step: 391200, eval_loss: 3.06682e-02
I0210 03:12:15.887338 22542570456896 run_lib.py:133] step: 391250, training_loss: 2.41552e-02
I0210 03:12:33.506601 22542570456896 run_lib.py:133] step: 391300, training_loss: 2.98946e-02
I0210 03:12:33.660289 22542570456896 run_lib.py:146] step: 391300, eval_loss: 3.48247e-02
I0210 03:12:51.156936 22542570456896 run_lib.py:133] step: 391350, training_loss: 3.61162e-02
I0210 03:13:08.731174 22542570456896 run_lib.py:133] step: 391400, training_loss: 2.26061e-02
I0210 03:13:08.882208 22542570456896 run_lib.py:146] step: 391400, eval_loss: 2.79272e-02
I0210 03:13:26.305778 22542570456896 run_lib.py:133] step: 391450, training_loss: 2.76379e-02
I0210 03:13:43.695118 22542570456896 run_lib.py:133] step: 391500, training_loss: 2.65008e-02
I0210 03:13:43.851559 22542570456896 run_lib.py:146] step: 391500, eval_loss: 2.73316e-02
I0210 03:14:01.440992 22542570456896 run_lib.py:133] step: 391550, training_loss: 3.46112e-02
I0210 03:14:18.900988 22542570456896 run_lib.py:133] step: 391600, training_loss: 2.58868e-02
I0210 03:14:19.076288 22542570456896 run_lib.py:146] step: 391600, eval_loss: 2.66427e-02
I0210 03:14:36.493146 22542570456896 run_lib.py:133] step: 391650, training_loss: 3.30014e-02
I0210 03:14:53.930145 22542570456896 run_lib.py:133] step: 391700, training_loss: 2.67441e-02
I0210 03:14:54.087578 22542570456896 run_lib.py:146] step: 391700, eval_loss: 2.59845e-02
I0210 03:15:11.722665 22542570456896 run_lib.py:133] step: 391750, training_loss: 3.27971e-02
I0210 03:15:29.142362 22542570456896 run_lib.py:133] step: 391800, training_loss: 2.12326e-02
I0210 03:15:29.297453 22542570456896 run_lib.py:146] step: 391800, eval_loss: 3.11513e-02
I0210 03:15:46.786104 22542570456896 run_lib.py:133] step: 391850, training_loss: 2.80644e-02
I0210 03:16:04.254172 22542570456896 run_lib.py:133] step: 391900, training_loss: 2.49549e-02
I0210 03:16:04.408493 22542570456896 run_lib.py:146] step: 391900, eval_loss: 2.92951e-02
I0210 03:16:21.873894 22542570456896 run_lib.py:133] step: 391950, training_loss: 3.27059e-02
I0210 03:16:39.287647 22542570456896 run_lib.py:133] step: 392000, training_loss: 3.25465e-02
I0210 03:16:39.443353 22542570456896 run_lib.py:146] step: 392000, eval_loss: 2.79044e-02
I0210 03:16:56.994457 22542570456896 run_lib.py:133] step: 392050, training_loss: 3.15445e-02
I0210 03:17:14.461471 22542570456896 run_lib.py:133] step: 392100, training_loss: 2.56440e-02
I0210 03:17:14.630192 22542570456896 run_lib.py:146] step: 392100, eval_loss: 3.10451e-02
I0210 03:17:32.112229 22542570456896 run_lib.py:133] step: 392150, training_loss: 2.64337e-02
I0210 03:17:49.515276 22542570456896 run_lib.py:133] step: 392200, training_loss: 3.10172e-02
I0210 03:17:49.678043 22542570456896 run_lib.py:146] step: 392200, eval_loss: 2.90263e-02
I0210 03:18:07.300272 22542570456896 run_lib.py:133] step: 392250, training_loss: 2.23612e-02
I0210 03:18:24.684308 22542570456896 run_lib.py:133] step: 392300, training_loss: 2.96562e-02
I0210 03:18:24.839056 22542570456896 run_lib.py:146] step: 392300, eval_loss: 3.32557e-02
I0210 03:18:42.399505 22542570456896 run_lib.py:133] step: 392350, training_loss: 2.93500e-02
I0210 03:18:59.837572 22542570456896 run_lib.py:133] step: 392400, training_loss: 2.60217e-02
I0210 03:18:59.991639 22542570456896 run_lib.py:146] step: 392400, eval_loss: 2.67166e-02
I0210 03:19:17.608567 22542570456896 run_lib.py:133] step: 392450, training_loss: 2.53556e-02
I0210 03:19:35.031087 22542570456896 run_lib.py:133] step: 392500, training_loss: 3.03347e-02
I0210 03:19:35.188198 22542570456896 run_lib.py:146] step: 392500, eval_loss: 3.07067e-02
I0210 03:19:52.783065 22542570456896 run_lib.py:133] step: 392550, training_loss: 3.15227e-02
I0210 03:20:10.216558 22542570456896 run_lib.py:133] step: 392600, training_loss: 2.76354e-02
I0210 03:20:10.372350 22542570456896 run_lib.py:146] step: 392600, eval_loss: 2.65479e-02
I0210 03:20:27.808409 22542570456896 run_lib.py:133] step: 392650, training_loss: 2.84023e-02
I0210 03:20:45.439653 22542570456896 run_lib.py:133] step: 392700, training_loss: 2.81526e-02
I0210 03:20:45.596685 22542570456896 run_lib.py:146] step: 392700, eval_loss: 2.95601e-02
I0210 03:21:03.044873 22542570456896 run_lib.py:133] step: 392750, training_loss: 3.36163e-02
I0210 03:21:20.430258 22542570456896 run_lib.py:133] step: 392800, training_loss: 2.94051e-02
I0210 03:21:20.582109 22542570456896 run_lib.py:146] step: 392800, eval_loss: 2.63927e-02
I0210 03:21:38.141168 22542570456896 run_lib.py:133] step: 392850, training_loss: 3.06172e-02
I0210 03:21:55.659987 22542570456896 run_lib.py:133] step: 392900, training_loss: 3.65783e-02
I0210 03:21:55.820279 22542570456896 run_lib.py:146] step: 392900, eval_loss: 2.66207e-02
I0210 03:22:13.225877 22542570456896 run_lib.py:133] step: 392950, training_loss: 3.08416e-02
I0210 03:22:30.668492 22542570456896 run_lib.py:133] step: 393000, training_loss: 2.55651e-02
I0210 03:22:30.843424 22542570456896 run_lib.py:146] step: 393000, eval_loss: 2.60090e-02
I0210 03:22:48.277862 22542570456896 run_lib.py:133] step: 393050, training_loss: 2.17972e-02
I0210 03:23:05.895339 22542570456896 run_lib.py:133] step: 393100, training_loss: 2.73180e-02
I0210 03:23:06.050340 22542570456896 run_lib.py:146] step: 393100, eval_loss: 2.80821e-02
I0210 03:23:23.459285 22542570456896 run_lib.py:133] step: 393150, training_loss: 2.66841e-02
I0210 03:23:40.855310 22542570456896 run_lib.py:133] step: 393200, training_loss: 3.37547e-02
I0210 03:23:41.011532 22542570456896 run_lib.py:146] step: 393200, eval_loss: 2.29215e-02
I0210 03:23:58.462560 22542570456896 run_lib.py:133] step: 393250, training_loss: 3.55731e-02
I0210 03:24:16.087362 22542570456896 run_lib.py:133] step: 393300, training_loss: 2.25074e-02
I0210 03:24:16.241629 22542570456896 run_lib.py:146] step: 393300, eval_loss: 2.50876e-02
I0210 03:24:33.684072 22542570456896 run_lib.py:133] step: 393350, training_loss: 3.21188e-02
I0210 03:24:51.177659 22542570456896 run_lib.py:133] step: 393400, training_loss: 2.70818e-02
I0210 03:24:51.334280 22542570456896 run_lib.py:146] step: 393400, eval_loss: 2.95424e-02
I0210 03:25:08.732111 22542570456896 run_lib.py:133] step: 393450, training_loss: 2.58147e-02
I0210 03:25:26.144458 22542570456896 run_lib.py:133] step: 393500, training_loss: 2.46890e-02
I0210 03:25:26.310680 22542570456896 run_lib.py:146] step: 393500, eval_loss: 2.52936e-02
I0210 03:25:43.900380 22542570456896 run_lib.py:133] step: 393550, training_loss: 1.98234e-02
I0210 03:26:01.463733 22542570456896 run_lib.py:133] step: 393600, training_loss: 3.44293e-02
I0210 03:26:01.619510 22542570456896 run_lib.py:146] step: 393600, eval_loss: 2.74604e-02
I0210 03:26:19.014372 22542570456896 run_lib.py:133] step: 393650, training_loss: 2.52518e-02
I0210 03:26:36.430829 22542570456896 run_lib.py:133] step: 393700, training_loss: 2.08857e-02
I0210 03:26:36.586083 22542570456896 run_lib.py:146] step: 393700, eval_loss: 3.32000e-02
I0210 03:26:54.141032 22542570456896 run_lib.py:133] step: 393750, training_loss: 2.66891e-02
I0210 03:27:11.513265 22542570456896 run_lib.py:133] step: 393800, training_loss: 3.32018e-02
I0210 03:27:11.666486 22542570456896 run_lib.py:146] step: 393800, eval_loss: 2.90993e-02
I0210 03:27:29.291821 22542570456896 run_lib.py:133] step: 393850, training_loss: 2.23295e-02
I0210 03:27:46.727456 22542570456896 run_lib.py:133] step: 393900, training_loss: 3.07591e-02
I0210 03:27:46.883156 22542570456896 run_lib.py:146] step: 393900, eval_loss: 3.30566e-02
I0210 03:28:04.488612 22542570456896 run_lib.py:133] step: 393950, training_loss: 3.11066e-02
I0210 03:28:21.890564 22542570456896 run_lib.py:133] step: 394000, training_loss: 2.35675e-02
I0210 03:28:22.048475 22542570456896 run_lib.py:146] step: 394000, eval_loss: 2.57824e-02
I0210 03:28:39.426478 22542570456896 run_lib.py:133] step: 394050, training_loss: 2.92488e-02
I0210 03:28:57.046084 22542570456896 run_lib.py:133] step: 394100, training_loss: 2.49305e-02
I0210 03:28:57.202642 22542570456896 run_lib.py:146] step: 394100, eval_loss: 3.25416e-02
I0210 03:29:14.610465 22542570456896 run_lib.py:133] step: 394150, training_loss: 2.88706e-02
I0210 03:29:32.184156 22542570456896 run_lib.py:133] step: 394200, training_loss: 2.66757e-02
I0210 03:29:32.345031 22542570456896 run_lib.py:146] step: 394200, eval_loss: 2.63546e-02
I0210 03:29:49.786375 22542570456896 run_lib.py:133] step: 394250, training_loss: 2.66032e-02
I0210 03:30:07.183196 22542570456896 run_lib.py:133] step: 394300, training_loss: 3.00991e-02
I0210 03:30:07.336363 22542570456896 run_lib.py:146] step: 394300, eval_loss: 3.02732e-02
I0210 03:30:24.956109 22542570456896 run_lib.py:133] step: 394350, training_loss: 2.02355e-02
I0210 03:30:42.463616 22542570456896 run_lib.py:133] step: 394400, training_loss: 2.85414e-02
I0210 03:30:42.623512 22542570456896 run_lib.py:146] step: 394400, eval_loss: 2.96918e-02
I0210 03:31:00.063650 22542570456896 run_lib.py:133] step: 394450, training_loss: 2.96645e-02
I0210 03:31:17.678542 22542570456896 run_lib.py:133] step: 394500, training_loss: 3.67376e-02
I0210 03:31:17.834434 22542570456896 run_lib.py:146] step: 394500, eval_loss: 3.55991e-02
I0210 03:31:35.236257 22542570456896 run_lib.py:133] step: 394550, training_loss: 2.98505e-02
I0210 03:31:52.642524 22542570456896 run_lib.py:133] step: 394600, training_loss: 2.63153e-02
I0210 03:31:52.809114 22542570456896 run_lib.py:146] step: 394600, eval_loss: 2.50784e-02
I0210 03:32:10.300511 22542570456896 run_lib.py:133] step: 394650, training_loss: 2.54638e-02
I0210 03:32:27.811285 22542570456896 run_lib.py:133] step: 394700, training_loss: 2.58119e-02
I0210 03:32:27.965206 22542570456896 run_lib.py:146] step: 394700, eval_loss: 3.90385e-02
I0210 03:32:45.427218 22542570456896 run_lib.py:133] step: 394750, training_loss: 2.89352e-02
I0210 03:33:02.869772 22542570456896 run_lib.py:133] step: 394800, training_loss: 2.70001e-02
I0210 03:33:03.023929 22542570456896 run_lib.py:146] step: 394800, eval_loss: 2.83763e-02
I0210 03:33:20.604280 22542570456896 run_lib.py:133] step: 394850, training_loss: 3.02310e-02
I0210 03:33:38.101135 22542570456896 run_lib.py:133] step: 394900, training_loss: 3.38866e-02
I0210 03:33:38.276006 22542570456896 run_lib.py:146] step: 394900, eval_loss: 2.70200e-02
I0210 03:33:55.709038 22542570456896 run_lib.py:133] step: 394950, training_loss: 2.83604e-02
I0210 03:34:13.130534 22542570456896 run_lib.py:133] step: 395000, training_loss: 3.48724e-02
I0210 03:34:13.294656 22542570456896 run_lib.py:146] step: 395000, eval_loss: 3.06223e-02
I0210 03:34:30.904420 22542570456896 run_lib.py:133] step: 395050, training_loss: 2.68466e-02
I0210 03:34:48.348436 22542570456896 run_lib.py:133] step: 395100, training_loss: 2.34915e-02
I0210 03:34:48.509329 22542570456896 run_lib.py:146] step: 395100, eval_loss: 2.82472e-02
I0210 03:35:06.081259 22542570456896 run_lib.py:133] step: 395150, training_loss: 2.90752e-02
I0210 03:35:23.550118 22542570456896 run_lib.py:133] step: 395200, training_loss: 2.91394e-02
I0210 03:35:23.704628 22542570456896 run_lib.py:146] step: 395200, eval_loss: 2.73825e-02
I0210 03:35:41.342296 22542570456896 run_lib.py:133] step: 395250, training_loss: 2.57217e-02
I0210 03:35:58.784409 22542570456896 run_lib.py:133] step: 395300, training_loss: 3.08895e-02
I0210 03:35:58.940281 22542570456896 run_lib.py:146] step: 395300, eval_loss: 2.92390e-02
I0210 03:36:16.487466 22542570456896 run_lib.py:133] step: 395350, training_loss: 2.84644e-02
I0210 03:36:33.928259 22542570456896 run_lib.py:133] step: 395400, training_loss: 2.98714e-02
I0210 03:36:34.092993 22542570456896 run_lib.py:146] step: 395400, eval_loss: 2.09389e-02
I0210 03:36:51.537965 22542570456896 run_lib.py:133] step: 395450, training_loss: 2.55700e-02
I0210 03:37:09.160795 22542570456896 run_lib.py:133] step: 395500, training_loss: 2.86512e-02
I0210 03:37:09.316669 22542570456896 run_lib.py:146] step: 395500, eval_loss: 2.85926e-02
I0210 03:37:26.727272 22542570456896 run_lib.py:133] step: 395550, training_loss: 2.64149e-02
I0210 03:37:44.168829 22542570456896 run_lib.py:133] step: 395600, training_loss: 2.57912e-02
I0210 03:37:44.323121 22542570456896 run_lib.py:146] step: 395600, eval_loss: 2.55941e-02
I0210 03:38:01.863967 22542570456896 run_lib.py:133] step: 395650, training_loss: 2.64442e-02
I0210 03:38:19.324605 22542570456896 run_lib.py:133] step: 395700, training_loss: 3.40031e-02
I0210 03:38:19.485893 22542570456896 run_lib.py:146] step: 395700, eval_loss: 3.06719e-02
I0210 03:38:37.060689 22542570456896 run_lib.py:133] step: 395750, training_loss: 2.73412e-02
I0210 03:38:54.473507 22542570456896 run_lib.py:133] step: 395800, training_loss: 2.83236e-02
I0210 03:38:54.630784 22542570456896 run_lib.py:146] step: 395800, eval_loss: 4.15515e-02
I0210 03:39:12.075099 22542570456896 run_lib.py:133] step: 395850, training_loss: 2.81820e-02
I0210 03:39:29.724487 22542570456896 run_lib.py:133] step: 395900, training_loss: 2.44265e-02
I0210 03:39:29.888557 22542570456896 run_lib.py:146] step: 395900, eval_loss: 3.42388e-02
I0210 03:39:47.310080 22542570456896 run_lib.py:133] step: 395950, training_loss: 2.50138e-02
I0210 03:40:04.734736 22542570456896 run_lib.py:133] step: 396000, training_loss: 3.28957e-02
I0210 03:40:04.891192 22542570456896 run_lib.py:146] step: 396000, eval_loss: 2.95919e-02
I0210 03:40:22.349653 22542570456896 run_lib.py:133] step: 396050, training_loss: 2.94184e-02
I0210 03:40:39.987702 22542570456896 run_lib.py:133] step: 396100, training_loss: 2.36263e-02
I0210 03:40:40.140427 22542570456896 run_lib.py:146] step: 396100, eval_loss: 3.07550e-02
I0210 03:40:57.566505 22542570456896 run_lib.py:133] step: 396150, training_loss: 2.49234e-02
I0210 03:41:15.043416 22542570456896 run_lib.py:133] step: 396200, training_loss: 2.46612e-02
I0210 03:41:15.195427 22542570456896 run_lib.py:146] step: 396200, eval_loss: 2.41063e-02
I0210 03:41:32.610351 22542570456896 run_lib.py:133] step: 396250, training_loss: 3.32807e-02
I0210 03:41:50.070721 22542570456896 run_lib.py:133] step: 396300, training_loss: 2.59239e-02
I0210 03:41:50.244664 22542570456896 run_lib.py:146] step: 396300, eval_loss: 2.64832e-02
I0210 03:42:07.857307 22542570456896 run_lib.py:133] step: 396350, training_loss: 2.92998e-02
I0210 03:42:25.341070 22542570456896 run_lib.py:133] step: 396400, training_loss: 3.14957e-02
I0210 03:42:25.497546 22542570456896 run_lib.py:146] step: 396400, eval_loss: 3.24930e-02
I0210 03:42:42.897475 22542570456896 run_lib.py:133] step: 396450, training_loss: 2.65685e-02
I0210 03:43:00.266813 22542570456896 run_lib.py:133] step: 396500, training_loss: 2.85520e-02
I0210 03:43:00.418380 22542570456896 run_lib.py:146] step: 396500, eval_loss: 2.51909e-02
I0210 03:43:17.979169 22542570456896 run_lib.py:133] step: 396550, training_loss: 2.69415e-02
I0210 03:43:35.463736 22542570456896 run_lib.py:133] step: 396600, training_loss: 2.27218e-02
I0210 03:43:35.618196 22542570456896 run_lib.py:146] step: 396600, eval_loss: 2.49995e-02
I0210 03:43:53.258612 22542570456896 run_lib.py:133] step: 396650, training_loss: 3.24767e-02
I0210 03:44:10.640215 22542570456896 run_lib.py:133] step: 396700, training_loss: 2.70814e-02
I0210 03:44:10.795303 22542570456896 run_lib.py:146] step: 396700, eval_loss: 2.24470e-02
I0210 03:44:28.387004 22542570456896 run_lib.py:133] step: 396750, training_loss: 3.23270e-02
I0210 03:44:45.789304 22542570456896 run_lib.py:133] step: 396800, training_loss: 2.15527e-02
I0210 03:44:45.967929 22542570456896 run_lib.py:146] step: 396800, eval_loss: 2.75154e-02
I0210 03:45:03.492272 22542570456896 run_lib.py:133] step: 396850, training_loss: 2.78744e-02
I0210 03:45:21.087307 22542570456896 run_lib.py:133] step: 396900, training_loss: 3.27475e-02
I0210 03:45:21.251732 22542570456896 run_lib.py:146] step: 396900, eval_loss: 2.39027e-02
I0210 03:45:38.709498 22542570456896 run_lib.py:133] step: 396950, training_loss: 2.56160e-02
I0210 03:45:56.239433 22542570456896 run_lib.py:133] step: 397000, training_loss: 2.98314e-02
I0210 03:45:56.394342 22542570456896 run_lib.py:146] step: 397000, eval_loss: 2.57620e-02
I0210 03:46:13.813952 22542570456896 run_lib.py:133] step: 397050, training_loss: 2.74588e-02
I0210 03:46:31.230952 22542570456896 run_lib.py:133] step: 397100, training_loss: 2.87567e-02
I0210 03:46:31.393446 22542570456896 run_lib.py:146] step: 397100, eval_loss: 3.50340e-02
I0210 03:46:49.056412 22542570456896 run_lib.py:133] step: 397150, training_loss: 3.32593e-02
I0210 03:47:06.474010 22542570456896 run_lib.py:133] step: 397200, training_loss: 3.21874e-02
I0210 03:47:06.627237 22542570456896 run_lib.py:146] step: 397200, eval_loss: 3.04125e-02
I0210 03:47:24.084889 22542570456896 run_lib.py:133] step: 397250, training_loss: 2.59489e-02
I0210 03:47:41.646232 22542570456896 run_lib.py:133] step: 397300, training_loss: 2.43896e-02
I0210 03:47:41.804978 22542570456896 run_lib.py:146] step: 397300, eval_loss: 4.11822e-02
I0210 03:47:59.232693 22542570456896 run_lib.py:133] step: 397350, training_loss: 2.92955e-02
I0210 03:48:16.700157 22542570456896 run_lib.py:133] step: 397400, training_loss: 2.53539e-02
I0210 03:48:17.003377 22542570456896 run_lib.py:146] step: 397400, eval_loss: 2.42105e-02
I0210 03:48:34.459390 22542570456896 run_lib.py:133] step: 397450, training_loss: 2.99281e-02
I0210 03:48:51.848308 22542570456896 run_lib.py:133] step: 397500, training_loss: 2.28128e-02
I0210 03:48:52.003225 22542570456896 run_lib.py:146] step: 397500, eval_loss: 2.91587e-02
I0210 03:49:09.408824 22542570456896 run_lib.py:133] step: 397550, training_loss: 2.65670e-02
I0210 03:49:26.808821 22542570456896 run_lib.py:133] step: 397600, training_loss: 2.49043e-02
I0210 03:49:26.960353 22542570456896 run_lib.py:146] step: 397600, eval_loss: 2.78092e-02
I0210 03:49:44.504245 22542570456896 run_lib.py:133] step: 397650, training_loss: 3.18198e-02
I0210 03:50:02.013150 22542570456896 run_lib.py:133] step: 397700, training_loss: 2.59133e-02
I0210 03:50:02.185311 22542570456896 run_lib.py:146] step: 397700, eval_loss: 3.16966e-02
I0210 03:50:19.605703 22542570456896 run_lib.py:133] step: 397750, training_loss: 2.56838e-02
I0210 03:50:37.041161 22542570456896 run_lib.py:133] step: 397800, training_loss: 2.99523e-02
I0210 03:50:37.199631 22542570456896 run_lib.py:146] step: 397800, eval_loss: 2.51755e-02
I0210 03:50:54.774710 22542570456896 run_lib.py:133] step: 397850, training_loss: 2.50876e-02
I0210 03:51:12.267013 22542570456896 run_lib.py:133] step: 397900, training_loss: 2.50110e-02
I0210 03:51:12.428579 22542570456896 run_lib.py:146] step: 397900, eval_loss: 3.08734e-02
I0210 03:51:29.897742 22542570456896 run_lib.py:133] step: 397950, training_loss: 2.13205e-02
I0210 03:51:47.410587 22542570456896 run_lib.py:133] step: 398000, training_loss: 2.64595e-02
I0210 03:51:47.564628 22542570456896 run_lib.py:146] step: 398000, eval_loss: 2.70103e-02
I0210 03:52:05.293616 22542570456896 run_lib.py:133] step: 398050, training_loss: 3.42106e-02
I0210 03:52:22.715915 22542570456896 run_lib.py:133] step: 398100, training_loss: 2.78114e-02
I0210 03:52:22.872439 22542570456896 run_lib.py:146] step: 398100, eval_loss: 2.44567e-02
I0210 03:52:40.386789 22542570456896 run_lib.py:133] step: 398150, training_loss: 2.59532e-02
I0210 03:52:57.855681 22542570456896 run_lib.py:133] step: 398200, training_loss: 2.71556e-02
I0210 03:52:58.033680 22542570456896 run_lib.py:146] step: 398200, eval_loss: 3.08675e-02
I0210 03:53:15.633826 22542570456896 run_lib.py:133] step: 398250, training_loss: 3.13052e-02
I0210 03:53:33.088001 22542570456896 run_lib.py:133] step: 398300, training_loss: 2.72786e-02
I0210 03:53:33.243561 22542570456896 run_lib.py:146] step: 398300, eval_loss: 2.79999e-02
I0210 03:53:50.649707 22542570456896 run_lib.py:133] step: 398350, training_loss: 2.13746e-02
I0210 03:54:08.224123 22542570456896 run_lib.py:133] step: 398400, training_loss: 2.95559e-02
I0210 03:54:08.379259 22542570456896 run_lib.py:146] step: 398400, eval_loss: 3.81114e-02
I0210 03:54:25.808274 22542570456896 run_lib.py:133] step: 398450, training_loss: 3.45843e-02
I0210 03:54:43.367094 22542570456896 run_lib.py:133] step: 398500, training_loss: 3.32584e-02
I0210 03:54:43.519704 22542570456896 run_lib.py:146] step: 398500, eval_loss: 2.81661e-02
I0210 03:55:00.963954 22542570456896 run_lib.py:133] step: 398550, training_loss: 2.16694e-02
I0210 03:55:18.419261 22542570456896 run_lib.py:133] step: 398600, training_loss: 3.12319e-02
I0210 03:55:18.580437 22542570456896 run_lib.py:146] step: 398600, eval_loss: 2.59268e-02
I0210 03:55:36.210092 22542570456896 run_lib.py:133] step: 398650, training_loss: 3.08483e-02
I0210 03:55:53.639677 22542570456896 run_lib.py:133] step: 398700, training_loss: 3.08660e-02
I0210 03:55:53.798603 22542570456896 run_lib.py:146] step: 398700, eval_loss: 2.61049e-02
I0210 03:56:11.201500 22542570456896 run_lib.py:133] step: 398750, training_loss: 2.26226e-02
I0210 03:56:28.719056 22542570456896 run_lib.py:133] step: 398800, training_loss: 3.27260e-02
I0210 03:56:28.883351 22542570456896 run_lib.py:146] step: 398800, eval_loss: 2.57997e-02
I0210 03:56:46.465934 22542570456896 run_lib.py:133] step: 398850, training_loss: 4.28261e-02
I0210 03:57:03.862172 22542570456896 run_lib.py:133] step: 398900, training_loss: 2.93764e-02
I0210 03:57:04.014705 22542570456896 run_lib.py:146] step: 398900, eval_loss: 3.07498e-02
I0210 03:57:21.503886 22542570456896 run_lib.py:133] step: 398950, training_loss: 3.29614e-02
I0210 03:57:38.917736 22542570456896 run_lib.py:133] step: 399000, training_loss: 2.30064e-02
I0210 03:57:39.079621 22542570456896 run_lib.py:146] step: 399000, eval_loss: 3.06807e-02
I0210 03:57:56.530380 22542570456896 run_lib.py:133] step: 399050, training_loss: 3.16326e-02
I0210 03:58:13.918298 22542570456896 run_lib.py:133] step: 399100, training_loss: 2.46818e-02
I0210 03:58:14.081965 22542570456896 run_lib.py:146] step: 399100, eval_loss: 2.80008e-02
I0210 03:58:31.665138 22542570456896 run_lib.py:133] step: 399150, training_loss: 3.26309e-02
I0210 03:58:49.166314 22542570456896 run_lib.py:133] step: 399200, training_loss: 2.10043e-02
I0210 03:58:49.323611 22542570456896 run_lib.py:146] step: 399200, eval_loss: 3.24645e-02
I0210 03:59:06.757456 22542570456896 run_lib.py:133] step: 399250, training_loss: 2.85925e-02
I0210 03:59:24.171425 22542570456896 run_lib.py:133] step: 399300, training_loss: 3.42585e-02
I0210 03:59:24.337903 22542570456896 run_lib.py:146] step: 399300, eval_loss: 2.58901e-02
I0210 03:59:41.915813 22542570456896 run_lib.py:133] step: 399350, training_loss: 3.00156e-02
I0210 03:59:59.378514 22542570456896 run_lib.py:133] step: 399400, training_loss: 2.92427e-02
I0210 03:59:59.536628 22542570456896 run_lib.py:146] step: 399400, eval_loss: 2.91610e-02
I0210 04:00:17.139169 22542570456896 run_lib.py:133] step: 399450, training_loss: 2.63065e-02
I0210 04:00:34.587922 22542570456896 run_lib.py:133] step: 399500, training_loss: 3.03089e-02
I0210 04:00:34.741413 22542570456896 run_lib.py:146] step: 399500, eval_loss: 2.74056e-02
I0210 04:00:52.260963 22542570456896 run_lib.py:133] step: 399550, training_loss: 2.65900e-02
I0210 04:01:09.660309 22542570456896 run_lib.py:133] step: 399600, training_loss: 3.09619e-02
I0210 04:01:09.839315 22542570456896 run_lib.py:146] step: 399600, eval_loss: 2.73627e-02
I0210 04:01:27.386380 22542570456896 run_lib.py:133] step: 399650, training_loss: 3.08420e-02
I0210 04:01:44.788815 22542570456896 run_lib.py:133] step: 399700, training_loss: 2.96464e-02
I0210 04:01:44.941880 22542570456896 run_lib.py:146] step: 399700, eval_loss: 3.93807e-02
I0210 04:02:02.363762 22542570456896 run_lib.py:133] step: 399750, training_loss: 2.30793e-02
I0210 04:02:19.932571 22542570456896 run_lib.py:133] step: 399800, training_loss: 2.77046e-02
I0210 04:02:20.088192 22542570456896 run_lib.py:146] step: 399800, eval_loss: 3.07407e-02
I0210 04:02:37.470808 22542570456896 run_lib.py:133] step: 399850, training_loss: 2.76671e-02
I0210 04:02:54.929491 22542570456896 run_lib.py:133] step: 399900, training_loss: 2.41689e-02
I0210 04:02:55.087181 22542570456896 run_lib.py:146] step: 399900, eval_loss: 2.71635e-02
I0210 04:03:12.723661 22542570456896 run_lib.py:133] step: 399950, training_loss: 2.52929e-02
I0210 04:03:30.271123 22542570456896 run_lib.py:133] step: 400000, training_loss: 2.37520e-02
I0210 04:03:30.997349 22542570456896 run_lib.py:146] step: 400000, eval_loss: 2.80316e-02
I0210 04:03:51.044216 22542570456896 run_lib.py:133] step: 400050, training_loss: 2.74578e-02
I0210 04:04:08.547103 22542570456896 run_lib.py:133] step: 400100, training_loss: 2.78530e-02
I0210 04:04:08.702582 22542570456896 run_lib.py:146] step: 400100, eval_loss: 4.01431e-02
I0210 04:04:26.127008 22542570456896 run_lib.py:133] step: 400150, training_loss: 3.28772e-02
I0210 04:04:43.596944 22542570456896 run_lib.py:133] step: 400200, training_loss: 2.48540e-02
I0210 04:04:43.755274 22542570456896 run_lib.py:146] step: 400200, eval_loss: 2.75800e-02
I0210 04:05:01.349229 22542570456896 run_lib.py:133] step: 400250, training_loss: 2.80772e-02
I0210 04:05:18.793348 22542570456896 run_lib.py:133] step: 400300, training_loss: 3.69781e-02
I0210 04:05:18.954426 22542570456896 run_lib.py:146] step: 400300, eval_loss: 2.64750e-02
I0210 04:05:36.374808 22542570456896 run_lib.py:133] step: 400350, training_loss: 3.33309e-02
I0210 04:05:53.763845 22542570456896 run_lib.py:133] step: 400400, training_loss: 2.57543e-02
I0210 04:05:53.918454 22542570456896 run_lib.py:146] step: 400400, eval_loss: 3.36516e-02
I0210 04:06:11.465745 22542570456896 run_lib.py:133] step: 400450, training_loss: 3.01820e-02
I0210 04:06:28.938668 22542570456896 run_lib.py:133] step: 400500, training_loss: 2.82492e-02
I0210 04:06:29.092590 22542570456896 run_lib.py:146] step: 400500, eval_loss: 2.78943e-02
I0210 04:06:46.715241 22542570456896 run_lib.py:133] step: 400550, training_loss: 2.49239e-02
I0210 04:07:04.137269 22542570456896 run_lib.py:133] step: 400600, training_loss: 2.75322e-02
I0210 04:07:04.300358 22542570456896 run_lib.py:146] step: 400600, eval_loss: 2.89645e-02
I0210 04:07:21.857831 22542570456896 run_lib.py:133] step: 400650, training_loss: 4.16740e-02
I0210 04:07:39.281348 22542570456896 run_lib.py:133] step: 400700, training_loss: 2.90332e-02
I0210 04:07:39.457469 22542570456896 run_lib.py:146] step: 400700, eval_loss: 2.60076e-02
I0210 04:07:56.923748 22542570456896 run_lib.py:133] step: 400750, training_loss: 2.75481e-02
I0210 04:08:14.526367 22542570456896 run_lib.py:133] step: 400800, training_loss: 2.33378e-02
I0210 04:08:14.682732 22542570456896 run_lib.py:146] step: 400800, eval_loss: 2.97927e-02
I0210 04:08:32.125647 22542570456896 run_lib.py:133] step: 400850, training_loss: 2.50056e-02
I0210 04:08:49.659172 22542570456896 run_lib.py:133] step: 400900, training_loss: 3.10686e-02
I0210 04:08:49.812789 22542570456896 run_lib.py:146] step: 400900, eval_loss: 2.77444e-02
I0210 04:09:07.239799 22542570456896 run_lib.py:133] step: 400950, training_loss: 3.33669e-02
I0210 04:09:24.674360 22542570456896 run_lib.py:133] step: 401000, training_loss: 2.87032e-02
I0210 04:09:24.832556 22542570456896 run_lib.py:146] step: 401000, eval_loss: 4.06087e-02
I0210 04:09:42.432189 22542570456896 run_lib.py:133] step: 401050, training_loss: 2.79874e-02
I0210 04:09:59.879249 22542570456896 run_lib.py:133] step: 401100, training_loss: 2.92368e-02
I0210 04:10:00.043147 22542570456896 run_lib.py:146] step: 401100, eval_loss: 3.08964e-02
I0210 04:10:17.470505 22542570456896 run_lib.py:133] step: 401150, training_loss: 2.73707e-02
I0210 04:10:35.036359 22542570456896 run_lib.py:133] step: 401200, training_loss: 2.64855e-02
I0210 04:10:35.193497 22542570456896 run_lib.py:146] step: 401200, eval_loss: 2.95952e-02
I0210 04:10:52.613714 22542570456896 run_lib.py:133] step: 401250, training_loss: 2.87803e-02
I0210 04:11:10.051253 22542570456896 run_lib.py:133] step: 401300, training_loss: 2.53438e-02
I0210 04:11:10.208069 22542570456896 run_lib.py:146] step: 401300, eval_loss: 4.08156e-02
I0210 04:11:27.735015 22542570456896 run_lib.py:133] step: 401350, training_loss: 2.75806e-02
I0210 04:11:45.135587 22542570456896 run_lib.py:133] step: 401400, training_loss: 2.49161e-02
I0210 04:11:45.289047 22542570456896 run_lib.py:146] step: 401400, eval_loss: 2.95037e-02
I0210 04:12:02.747648 22542570456896 run_lib.py:133] step: 401450, training_loss: 2.49112e-02
I0210 04:12:20.186118 22542570456896 run_lib.py:133] step: 401500, training_loss: 2.71176e-02
I0210 04:12:20.339383 22542570456896 run_lib.py:146] step: 401500, eval_loss: 2.85474e-02
I0210 04:12:38.005327 22542570456896 run_lib.py:133] step: 401550, training_loss: 2.69317e-02
I0210 04:12:55.567226 22542570456896 run_lib.py:133] step: 401600, training_loss: 2.17929e-02
I0210 04:12:55.731342 22542570456896 run_lib.py:146] step: 401600, eval_loss: 2.86112e-02
I0210 04:13:13.153112 22542570456896 run_lib.py:133] step: 401650, training_loss: 2.77980e-02
I0210 04:13:30.579778 22542570456896 run_lib.py:133] step: 401700, training_loss: 2.94624e-02
I0210 04:13:30.731556 22542570456896 run_lib.py:146] step: 401700, eval_loss: 2.60377e-02
I0210 04:13:48.298799 22542570456896 run_lib.py:133] step: 401750, training_loss: 2.01624e-02
I0210 04:14:05.711524 22542570456896 run_lib.py:133] step: 401800, training_loss: 3.07739e-02
I0210 04:14:05.867169 22542570456896 run_lib.py:146] step: 401800, eval_loss: 2.61419e-02
I0210 04:14:23.456858 22542570456896 run_lib.py:133] step: 401850, training_loss: 3.39652e-02
I0210 04:14:40.933156 22542570456896 run_lib.py:133] step: 401900, training_loss: 2.52584e-02
I0210 04:14:41.086607 22542570456896 run_lib.py:146] step: 401900, eval_loss: 3.28355e-02
I0210 04:14:58.708275 22542570456896 run_lib.py:133] step: 401950, training_loss: 3.05340e-02
I0210 04:15:16.115123 22542570456896 run_lib.py:133] step: 402000, training_loss: 2.43402e-02
I0210 04:15:16.274424 22542570456896 run_lib.py:146] step: 402000, eval_loss: 2.47873e-02
I0210 04:15:33.829197 22542570456896 run_lib.py:133] step: 402050, training_loss: 2.56137e-02
I0210 04:15:51.251217 22542570456896 run_lib.py:133] step: 402100, training_loss: 2.91790e-02
I0210 04:15:51.426427 22542570456896 run_lib.py:146] step: 402100, eval_loss: 3.11361e-02
I0210 04:16:08.911596 22542570456896 run_lib.py:133] step: 402150, training_loss: 3.24163e-02
I0210 04:16:26.508700 22542570456896 run_lib.py:133] step: 402200, training_loss: 2.64653e-02
I0210 04:16:26.664535 22542570456896 run_lib.py:146] step: 402200, eval_loss: 2.66581e-02
I0210 04:16:44.084391 22542570456896 run_lib.py:133] step: 402250, training_loss: 2.70020e-02
I0210 04:17:01.515741 22542570456896 run_lib.py:133] step: 402300, training_loss: 2.54420e-02
I0210 04:17:01.667433 22542570456896 run_lib.py:146] step: 402300, eval_loss: 2.49718e-02
I0210 04:17:19.271577 22542570456896 run_lib.py:133] step: 402350, training_loss: 2.62415e-02
I0210 04:17:36.698379 22542570456896 run_lib.py:133] step: 402400, training_loss: 3.08878e-02
I0210 04:17:36.849254 22542570456896 run_lib.py:146] step: 402400, eval_loss: 3.23319e-02
I0210 04:17:54.455342 22542570456896 run_lib.py:133] step: 402450, training_loss: 2.52206e-02
I0210 04:18:11.927235 22542570456896 run_lib.py:133] step: 402500, training_loss: 2.86433e-02
I0210 04:18:12.083604 22542570456896 run_lib.py:146] step: 402500, eval_loss: 3.36804e-02
I0210 04:18:29.481542 22542570456896 run_lib.py:133] step: 402550, training_loss: 2.47439e-02
I0210 04:18:47.079751 22542570456896 run_lib.py:133] step: 402600, training_loss: 2.97954e-02
I0210 04:18:47.238700 22542570456896 run_lib.py:146] step: 402600, eval_loss: 3.08281e-02
I0210 04:19:04.642647 22542570456896 run_lib.py:133] step: 402650, training_loss: 3.14279e-02
I0210 04:19:22.087175 22542570456896 run_lib.py:133] step: 402700, training_loss: 3.49167e-02
I0210 04:19:22.248360 22542570456896 run_lib.py:146] step: 402700, eval_loss: 3.27668e-02
I0210 04:19:39.681889 22542570456896 run_lib.py:133] step: 402750, training_loss: 2.50160e-02
I0210 04:19:57.313576 22542570456896 run_lib.py:133] step: 402800, training_loss: 3.04231e-02
I0210 04:19:57.471142 22542570456896 run_lib.py:146] step: 402800, eval_loss: 2.86941e-02
I0210 04:20:14.894250 22542570456896 run_lib.py:133] step: 402850, training_loss: 2.84622e-02
I0210 04:20:32.396498 22542570456896 run_lib.py:133] step: 402900, training_loss: 2.62682e-02
I0210 04:20:32.554372 22542570456896 run_lib.py:146] step: 402900, eval_loss: 2.17294e-02
I0210 04:20:49.950020 22542570456896 run_lib.py:133] step: 402950, training_loss: 3.56753e-02
I0210 04:21:07.391190 22542570456896 run_lib.py:133] step: 403000, training_loss: 3.23125e-02
I0210 04:21:07.567839 22542570456896 run_lib.py:146] step: 403000, eval_loss: 2.92020e-02
I0210 04:21:25.178421 22542570456896 run_lib.py:133] step: 403050, training_loss: 2.01615e-02
I0210 04:21:42.699194 22542570456896 run_lib.py:133] step: 403100, training_loss: 2.80289e-02
I0210 04:21:42.854598 22542570456896 run_lib.py:146] step: 403100, eval_loss: 3.00340e-02
I0210 04:22:00.266605 22542570456896 run_lib.py:133] step: 403150, training_loss: 2.80480e-02
I0210 04:22:17.648469 22542570456896 run_lib.py:133] step: 403200, training_loss: 3.44033e-02
I0210 04:22:17.803627 22542570456896 run_lib.py:146] step: 403200, eval_loss: 3.15518e-02
I0210 04:22:35.410767 22542570456896 run_lib.py:133] step: 403250, training_loss: 2.62195e-02
I0210 04:22:52.901587 22542570456896 run_lib.py:133] step: 403300, training_loss: 2.78064e-02
I0210 04:22:53.055789 22542570456896 run_lib.py:146] step: 403300, eval_loss: 2.99892e-02
I0210 04:23:10.708848 22542570456896 run_lib.py:133] step: 403350, training_loss: 3.43160e-02
I0210 04:23:28.114311 22542570456896 run_lib.py:133] step: 403400, training_loss: 2.68675e-02
I0210 04:23:28.267833 22542570456896 run_lib.py:146] step: 403400, eval_loss: 2.06945e-02
I0210 04:23:45.842994 22542570456896 run_lib.py:133] step: 403450, training_loss: 2.79821e-02
I0210 04:24:03.294030 22542570456896 run_lib.py:133] step: 403500, training_loss: 2.59960e-02
I0210 04:24:03.462471 22542570456896 run_lib.py:146] step: 403500, eval_loss: 3.59472e-02
I0210 04:24:20.880728 22542570456896 run_lib.py:133] step: 403550, training_loss: 2.03564e-02
I0210 04:24:38.515848 22542570456896 run_lib.py:133] step: 403600, training_loss: 3.45264e-02
I0210 04:24:38.672527 22542570456896 run_lib.py:146] step: 403600, eval_loss: 3.06592e-02
I0210 04:24:56.067152 22542570456896 run_lib.py:133] step: 403650, training_loss: 2.81933e-02
I0210 04:25:13.642366 22542570456896 run_lib.py:133] step: 403700, training_loss: 2.89301e-02
I0210 04:25:13.797549 22542570456896 run_lib.py:146] step: 403700, eval_loss: 2.88196e-02
I0210 04:25:31.247246 22542570456896 run_lib.py:133] step: 403750, training_loss: 2.84579e-02
I0210 04:25:48.732794 22542570456896 run_lib.py:133] step: 403800, training_loss: 3.01760e-02
I0210 04:25:48.887177 22542570456896 run_lib.py:146] step: 403800, eval_loss: 2.77567e-02
I0210 04:26:06.517796 22542570456896 run_lib.py:133] step: 403850, training_loss: 3.12599e-02
I0210 04:26:23.946076 22542570456896 run_lib.py:133] step: 403900, training_loss: 3.08788e-02
I0210 04:26:24.103082 22542570456896 run_lib.py:146] step: 403900, eval_loss: 3.37781e-02
I0210 04:26:41.515612 22542570456896 run_lib.py:133] step: 403950, training_loss: 3.26634e-02
I0210 04:26:59.124048 22542570456896 run_lib.py:133] step: 404000, training_loss: 3.67344e-02
I0210 04:26:59.282561 22542570456896 run_lib.py:146] step: 404000, eval_loss: 2.57528e-02
I0210 04:27:16.736083 22542570456896 run_lib.py:133] step: 404050, training_loss: 2.61089e-02
I0210 04:27:34.209327 22542570456896 run_lib.py:133] step: 404100, training_loss: 2.79353e-02
I0210 04:27:34.524303 22542570456896 run_lib.py:146] step: 404100, eval_loss: 2.88277e-02
I0210 04:27:51.968587 22542570456896 run_lib.py:133] step: 404150, training_loss: 2.52359e-02
I0210 04:28:09.384833 22542570456896 run_lib.py:133] step: 404200, training_loss: 3.06443e-02
I0210 04:28:09.544231 22542570456896 run_lib.py:146] step: 404200, eval_loss: 3.31426e-02
I0210 04:28:26.999091 22542570456896 run_lib.py:133] step: 404250, training_loss: 2.46662e-02
I0210 04:28:44.412199 22542570456896 run_lib.py:133] step: 404300, training_loss: 2.27474e-02
I0210 04:28:44.563873 22542570456896 run_lib.py:146] step: 404300, eval_loss: 3.40603e-02
I0210 04:29:02.148419 22542570456896 run_lib.py:133] step: 404350, training_loss: 3.29439e-02
I0210 04:29:19.703515 22542570456896 run_lib.py:133] step: 404400, training_loss: 2.43597e-02
I0210 04:29:19.871480 22542570456896 run_lib.py:146] step: 404400, eval_loss: 2.66278e-02
I0210 04:29:37.310014 22542570456896 run_lib.py:133] step: 404450, training_loss: 3.17420e-02
I0210 04:29:54.729567 22542570456896 run_lib.py:133] step: 404500, training_loss: 3.07490e-02
I0210 04:29:54.887480 22542570456896 run_lib.py:146] step: 404500, eval_loss: 2.64104e-02
I0210 04:30:12.416043 22542570456896 run_lib.py:133] step: 404550, training_loss: 2.51689e-02
I0210 04:30:29.870358 22542570456896 run_lib.py:133] step: 404600, training_loss: 2.88313e-02
I0210 04:30:30.029300 22542570456896 run_lib.py:146] step: 404600, eval_loss: 3.19451e-02
I0210 04:30:47.489338 22542570456896 run_lib.py:133] step: 404650, training_loss: 2.54904e-02
I0210 04:31:04.969236 22542570456896 run_lib.py:133] step: 404700, training_loss: 2.54047e-02
I0210 04:31:05.133395 22542570456896 run_lib.py:146] step: 404700, eval_loss: 2.94598e-02
I0210 04:31:22.721858 22542570456896 run_lib.py:133] step: 404750, training_loss: 1.95729e-02
I0210 04:31:40.163198 22542570456896 run_lib.py:133] step: 404800, training_loss: 2.73074e-02
I0210 04:31:40.316277 22542570456896 run_lib.py:146] step: 404800, eval_loss: 2.95644e-02
I0210 04:31:57.877496 22542570456896 run_lib.py:133] step: 404850, training_loss: 2.56943e-02
I0210 04:32:15.280184 22542570456896 run_lib.py:133] step: 404900, training_loss: 3.23056e-02
I0210 04:32:15.452407 22542570456896 run_lib.py:146] step: 404900, eval_loss: 2.36001e-02
I0210 04:32:33.064425 22542570456896 run_lib.py:133] step: 404950, training_loss: 2.61117e-02
I0210 04:32:50.535762 22542570456896 run_lib.py:133] step: 405000, training_loss: 2.74105e-02
I0210 04:32:50.694197 22542570456896 run_lib.py:146] step: 405000, eval_loss: 2.57100e-02
I0210 04:33:08.114167 22542570456896 run_lib.py:133] step: 405050, training_loss: 2.68457e-02
I0210 04:33:25.694063 22542570456896 run_lib.py:133] step: 405100, training_loss: 2.38184e-02
I0210 04:33:25.849385 22542570456896 run_lib.py:146] step: 405100, eval_loss: 3.31539e-02
I0210 04:33:43.267060 22542570456896 run_lib.py:133] step: 405150, training_loss: 2.36713e-02
I0210 04:34:00.847666 22542570456896 run_lib.py:133] step: 405200, training_loss: 2.90852e-02
I0210 04:34:01.001117 22542570456896 run_lib.py:146] step: 405200, eval_loss: 2.92645e-02
I0210 04:34:18.447503 22542570456896 run_lib.py:133] step: 405250, training_loss: 2.39036e-02
I0210 04:34:35.865197 22542570456896 run_lib.py:133] step: 405300, training_loss: 2.69272e-02
I0210 04:34:36.019369 22542570456896 run_lib.py:146] step: 405300, eval_loss: 2.96576e-02
I0210 04:34:53.613689 22542570456896 run_lib.py:133] step: 405350, training_loss: 3.07513e-02
I0210 04:35:11.061395 22542570456896 run_lib.py:133] step: 405400, training_loss: 2.31987e-02
I0210 04:35:11.219840 22542570456896 run_lib.py:146] step: 405400, eval_loss: 3.20320e-02
I0210 04:35:28.657863 22542570456896 run_lib.py:133] step: 405450, training_loss: 2.56213e-02
I0210 04:35:46.052203 22542570456896 run_lib.py:133] step: 405500, training_loss: 2.94609e-02
I0210 04:35:46.227342 22542570456896 run_lib.py:146] step: 405500, eval_loss: 2.59224e-02
I0210 04:36:03.816486 22542570456896 run_lib.py:133] step: 405550, training_loss: 3.16814e-02
I0210 04:36:21.265702 22542570456896 run_lib.py:133] step: 405600, training_loss: 3.35552e-02
I0210 04:36:21.422688 22542570456896 run_lib.py:146] step: 405600, eval_loss: 2.96034e-02
I0210 04:36:38.980443 22542570456896 run_lib.py:133] step: 405650, training_loss: 2.66674e-02
I0210 04:36:56.443437 22542570456896 run_lib.py:133] step: 405700, training_loss: 2.95041e-02
I0210 04:36:56.594386 22542570456896 run_lib.py:146] step: 405700, eval_loss: 2.46475e-02
I0210 04:37:13.993525 22542570456896 run_lib.py:133] step: 405750, training_loss: 3.41664e-02
I0210 04:37:31.421502 22542570456896 run_lib.py:133] step: 405800, training_loss: 1.96616e-02
I0210 04:37:31.593555 22542570456896 run_lib.py:146] step: 405800, eval_loss: 2.79574e-02
I0210 04:37:49.246810 22542570456896 run_lib.py:133] step: 405850, training_loss: 2.98953e-02
I0210 04:38:06.712196 22542570456896 run_lib.py:133] step: 405900, training_loss: 3.13537e-02
I0210 04:38:06.872267 22542570456896 run_lib.py:146] step: 405900, eval_loss: 2.53041e-02
I0210 04:38:24.254534 22542570456896 run_lib.py:133] step: 405950, training_loss: 2.62069e-02
I0210 04:38:41.647217 22542570456896 run_lib.py:133] step: 406000, training_loss: 2.46319e-02
I0210 04:38:41.802350 22542570456896 run_lib.py:146] step: 406000, eval_loss: 2.70813e-02
I0210 04:38:59.396044 22542570456896 run_lib.py:133] step: 406050, training_loss: 3.15349e-02
I0210 04:39:16.832710 22542570456896 run_lib.py:133] step: 406100, training_loss: 3.12149e-02
I0210 04:39:16.988553 22542570456896 run_lib.py:146] step: 406100, eval_loss: 2.83559e-02
I0210 04:39:34.644392 22542570456896 run_lib.py:133] step: 406150, training_loss: 3.04846e-02
I0210 04:39:52.073456 22542570456896 run_lib.py:133] step: 406200, training_loss: 2.14774e-02
I0210 04:39:52.225281 22542570456896 run_lib.py:146] step: 406200, eval_loss: 2.88582e-02
I0210 04:40:09.756931 22542570456896 run_lib.py:133] step: 406250, training_loss: 2.59272e-02
I0210 04:40:27.181199 22542570456896 run_lib.py:133] step: 406300, training_loss: 2.77442e-02
I0210 04:40:27.352207 22542570456896 run_lib.py:146] step: 406300, eval_loss: 2.87128e-02
I0210 04:40:44.971192 22542570456896 run_lib.py:133] step: 406350, training_loss: 2.34814e-02
I0210 04:41:02.426434 22542570456896 run_lib.py:133] step: 406400, training_loss: 2.66671e-02
I0210 04:41:02.585368 22542570456896 run_lib.py:146] step: 406400, eval_loss: 2.98796e-02
I0210 04:41:20.010908 22542570456896 run_lib.py:133] step: 406450, training_loss: 2.08092e-02
I0210 04:41:37.570636 22542570456896 run_lib.py:133] step: 406500, training_loss: 2.69345e-02
I0210 04:41:37.726385 22542570456896 run_lib.py:146] step: 406500, eval_loss: 2.62248e-02
I0210 04:41:55.120680 22542570456896 run_lib.py:133] step: 406550, training_loss: 2.57152e-02
I0210 04:42:12.514619 22542570456896 run_lib.py:133] step: 406600, training_loss: 2.70862e-02
I0210 04:42:12.668411 22542570456896 run_lib.py:146] step: 406600, eval_loss: 2.79083e-02
I0210 04:42:30.264561 22542570456896 run_lib.py:133] step: 406650, training_loss: 2.39188e-02
I0210 04:42:47.925993 22542570456896 run_lib.py:133] step: 406700, training_loss: 2.57909e-02
I0210 04:42:48.081421 22542570456896 run_lib.py:146] step: 406700, eval_loss: 2.28708e-02
I0210 04:43:05.517977 22542570456896 run_lib.py:133] step: 406750, training_loss: 2.67095e-02
I0210 04:43:22.932046 22542570456896 run_lib.py:133] step: 406800, training_loss: 2.34029e-02
I0210 04:43:23.091486 22542570456896 run_lib.py:146] step: 406800, eval_loss: 2.59442e-02
I0210 04:43:40.489904 22542570456896 run_lib.py:133] step: 406850, training_loss: 3.69019e-02
I0210 04:43:58.051378 22542570456896 run_lib.py:133] step: 406900, training_loss: 3.03437e-02
I0210 04:43:58.207304 22542570456896 run_lib.py:146] step: 406900, eval_loss: 2.97332e-02
I0210 04:44:15.637455 22542570456896 run_lib.py:133] step: 406950, training_loss: 2.82944e-02
I0210 04:44:33.049026 22542570456896 run_lib.py:133] step: 407000, training_loss: 2.28258e-02
I0210 04:44:33.205056 22542570456896 run_lib.py:146] step: 407000, eval_loss: 3.13127e-02
I0210 04:44:50.611688 22542570456896 run_lib.py:133] step: 407050, training_loss: 3.33541e-02
I0210 04:45:08.182178 22542570456896 run_lib.py:133] step: 407100, training_loss: 2.79120e-02
I0210 04:45:08.334063 22542570456896 run_lib.py:146] step: 407100, eval_loss: 2.89833e-02
I0210 04:45:25.734446 22542570456896 run_lib.py:133] step: 407150, training_loss: 2.68741e-02
I0210 04:45:43.284003 22542570456896 run_lib.py:133] step: 407200, training_loss: 2.41565e-02
I0210 04:45:43.459674 22542570456896 run_lib.py:146] step: 407200, eval_loss: 3.13019e-02
I0210 04:46:00.881565 22542570456896 run_lib.py:133] step: 407250, training_loss: 3.13388e-02
I0210 04:46:18.313998 22542570456896 run_lib.py:133] step: 407300, training_loss: 2.97172e-02
I0210 04:46:18.471642 22542570456896 run_lib.py:146] step: 407300, eval_loss: 3.08874e-02
I0210 04:46:36.052655 22542570456896 run_lib.py:133] step: 407350, training_loss: 2.66857e-02
I0210 04:46:53.547456 22542570456896 run_lib.py:133] step: 407400, training_loss: 2.72471e-02
I0210 04:46:53.704248 22542570456896 run_lib.py:146] step: 407400, eval_loss: 2.74882e-02
I0210 04:47:11.165861 22542570456896 run_lib.py:133] step: 407450, training_loss: 3.39571e-02
I0210 04:47:28.646966 22542570456896 run_lib.py:133] step: 407500, training_loss: 3.35072e-02
I0210 04:47:28.804091 22542570456896 run_lib.py:146] step: 407500, eval_loss: 3.28152e-02
I0210 04:47:46.410061 22542570456896 run_lib.py:133] step: 407550, training_loss: 3.05244e-02
I0210 04:48:03.825740 22542570456896 run_lib.py:133] step: 407600, training_loss: 3.18351e-02
I0210 04:48:03.978384 22542570456896 run_lib.py:146] step: 407600, eval_loss: 2.61606e-02
I0210 04:48:21.508598 22542570456896 run_lib.py:133] step: 407650, training_loss: 2.31711e-02
I0210 04:48:38.923988 22542570456896 run_lib.py:133] step: 407700, training_loss: 3.36673e-02
I0210 04:48:39.094595 22542570456896 run_lib.py:146] step: 407700, eval_loss: 2.38441e-02
I0210 04:48:56.684419 22542570456896 run_lib.py:133] step: 407750, training_loss: 3.27747e-02
I0210 04:49:14.102114 22542570456896 run_lib.py:133] step: 407800, training_loss: 2.77244e-02
I0210 04:49:14.270215 22542570456896 run_lib.py:146] step: 407800, eval_loss: 3.04600e-02
I0210 04:49:31.673345 22542570456896 run_lib.py:133] step: 407850, training_loss: 3.60651e-02
I0210 04:49:49.239529 22542570456896 run_lib.py:133] step: 407900, training_loss: 2.38820e-02
I0210 04:49:49.397462 22542570456896 run_lib.py:146] step: 407900, eval_loss: 2.43515e-02
I0210 04:50:06.842728 22542570456896 run_lib.py:133] step: 407950, training_loss: 3.04198e-02
I0210 04:50:24.442270 22542570456896 run_lib.py:133] step: 408000, training_loss: 2.88280e-02
I0210 04:50:24.597434 22542570456896 run_lib.py:146] step: 408000, eval_loss: 2.84038e-02
I0210 04:50:42.038534 22542570456896 run_lib.py:133] step: 408050, training_loss: 2.96382e-02
I0210 04:50:59.467444 22542570456896 run_lib.py:133] step: 408100, training_loss: 2.63543e-02
I0210 04:50:59.615602 22542570456896 run_lib.py:146] step: 408100, eval_loss: 3.25225e-02
I0210 04:51:17.224101 22542570456896 run_lib.py:133] step: 408150, training_loss: 2.87429e-02
I0210 04:51:34.645166 22542570456896 run_lib.py:133] step: 408200, training_loss: 2.55111e-02
I0210 04:51:34.809310 22542570456896 run_lib.py:146] step: 408200, eval_loss: 3.13368e-02
I0210 04:51:52.284349 22542570456896 run_lib.py:133] step: 408250, training_loss: 2.85909e-02
I0210 04:52:09.934060 22542570456896 run_lib.py:133] step: 408300, training_loss: 2.32259e-02
I0210 04:52:10.092338 22542570456896 run_lib.py:146] step: 408300, eval_loss: 3.09509e-02
I0210 04:52:27.491672 22542570456896 run_lib.py:133] step: 408350, training_loss: 2.57263e-02
I0210 04:52:44.962893 22542570456896 run_lib.py:133] step: 408400, training_loss: 3.05648e-02
I0210 04:52:45.118676 22542570456896 run_lib.py:146] step: 408400, eval_loss: 2.90064e-02
I0210 04:53:02.585694 22542570456896 run_lib.py:133] step: 408450, training_loss: 3.14302e-02
I0210 04:53:20.025287 22542570456896 run_lib.py:133] step: 408500, training_loss: 3.06076e-02
I0210 04:53:20.180421 22542570456896 run_lib.py:146] step: 408500, eval_loss: 2.97551e-02
I0210 04:53:37.598750 22542570456896 run_lib.py:133] step: 408550, training_loss: 3.25305e-02
I0210 04:53:55.114825 22542570456896 run_lib.py:133] step: 408600, training_loss: 2.86237e-02
I0210 04:53:55.269481 22542570456896 run_lib.py:146] step: 408600, eval_loss: 2.73533e-02
I0210 04:54:12.881419 22542570456896 run_lib.py:133] step: 408650, training_loss: 2.72992e-02
I0210 04:54:30.387699 22542570456896 run_lib.py:133] step: 408700, training_loss: 2.68601e-02
I0210 04:54:30.546635 22542570456896 run_lib.py:146] step: 408700, eval_loss: 2.57157e-02
I0210 04:54:47.953275 22542570456896 run_lib.py:133] step: 408750, training_loss: 2.90466e-02
I0210 04:55:05.346790 22542570456896 run_lib.py:133] step: 408800, training_loss: 3.26671e-02
I0210 04:55:05.502392 22542570456896 run_lib.py:146] step: 408800, eval_loss: 2.73403e-02
I0210 04:55:23.113699 22542570456896 run_lib.py:133] step: 408850, training_loss: 3.14372e-02
I0210 04:55:40.601529 22542570456896 run_lib.py:133] step: 408900, training_loss: 2.51881e-02
I0210 04:55:40.756116 22542570456896 run_lib.py:146] step: 408900, eval_loss: 2.57522e-02
I0210 04:55:58.393507 22542570456896 run_lib.py:133] step: 408950, training_loss: 2.98927e-02
I0210 04:56:15.803598 22542570456896 run_lib.py:133] step: 409000, training_loss: 2.60477e-02
I0210 04:56:15.955736 22542570456896 run_lib.py:146] step: 409000, eval_loss: 2.72265e-02
I0210 04:56:33.490001 22542570456896 run_lib.py:133] step: 409050, training_loss: 2.73639e-02
I0210 04:56:50.908175 22542570456896 run_lib.py:133] step: 409100, training_loss: 2.98768e-02
I0210 04:56:51.073496 22542570456896 run_lib.py:146] step: 409100, eval_loss: 3.21256e-02
I0210 04:57:08.709208 22542570456896 run_lib.py:133] step: 409150, training_loss: 2.32277e-02
I0210 04:57:26.130297 22542570456896 run_lib.py:133] step: 409200, training_loss: 2.57686e-02
I0210 04:57:26.286608 22542570456896 run_lib.py:146] step: 409200, eval_loss: 2.92886e-02
I0210 04:57:43.697546 22542570456896 run_lib.py:133] step: 409250, training_loss: 3.09433e-02
I0210 04:58:01.253691 22542570456896 run_lib.py:133] step: 409300, training_loss: 2.61076e-02
I0210 04:58:01.406600 22542570456896 run_lib.py:146] step: 409300, eval_loss: 2.98841e-02
I0210 04:58:18.841553 22542570456896 run_lib.py:133] step: 409350, training_loss: 2.47842e-02
I0210 04:58:36.326380 22542570456896 run_lib.py:133] step: 409400, training_loss: 3.50040e-02
I0210 04:58:36.482604 22542570456896 run_lib.py:146] step: 409400, eval_loss: 2.39887e-02
I0210 04:58:54.097798 22542570456896 run_lib.py:133] step: 409450, training_loss: 3.08559e-02
I0210 04:59:11.523184 22542570456896 run_lib.py:133] step: 409500, training_loss: 2.38714e-02
I0210 04:59:11.683304 22542570456896 run_lib.py:146] step: 409500, eval_loss: 2.94638e-02
I0210 04:59:29.230349 22542570456896 run_lib.py:133] step: 409550, training_loss: 2.50283e-02
I0210 04:59:46.656400 22542570456896 run_lib.py:133] step: 409600, training_loss: 2.62481e-02
I0210 04:59:46.811351 22542570456896 run_lib.py:146] step: 409600, eval_loss: 3.36433e-02
I0210 05:00:04.221383 22542570456896 run_lib.py:133] step: 409650, training_loss: 3.39125e-02
I0210 05:00:21.878313 22542570456896 run_lib.py:133] step: 409700, training_loss: 3.24851e-02
I0210 05:00:22.037379 22542570456896 run_lib.py:146] step: 409700, eval_loss: 2.79623e-02
I0210 05:00:39.441555 22542570456896 run_lib.py:133] step: 409750, training_loss: 2.86390e-02
I0210 05:00:56.857773 22542570456896 run_lib.py:133] step: 409800, training_loss: 3.30558e-02
I0210 05:00:57.016327 22542570456896 run_lib.py:146] step: 409800, eval_loss: 2.61104e-02
I0210 05:01:14.426391 22542570456896 run_lib.py:133] step: 409850, training_loss: 2.18358e-02
I0210 05:01:31.980344 22542570456896 run_lib.py:133] step: 409900, training_loss: 2.70585e-02
I0210 05:01:32.135348 22542570456896 run_lib.py:146] step: 409900, eval_loss: 2.90845e-02
I0210 05:01:49.593026 22542570456896 run_lib.py:133] step: 409950, training_loss: 3.21657e-02
I0210 05:02:07.103808 22542570456896 run_lib.py:133] step: 410000, training_loss: 2.93204e-02
I0210 05:02:08.106931 22542570456896 run_lib.py:146] step: 410000, eval_loss: 2.95233e-02
I0210 05:02:28.253413 22542570456896 run_lib.py:133] step: 410050, training_loss: 2.81623e-02
I0210 05:02:45.679994 22542570456896 run_lib.py:133] step: 410100, training_loss: 2.35390e-02
I0210 05:02:45.841348 22542570456896 run_lib.py:146] step: 410100, eval_loss: 2.78557e-02
I0210 05:03:03.411801 22542570456896 run_lib.py:133] step: 410150, training_loss: 3.01603e-02
I0210 05:03:20.871798 22542570456896 run_lib.py:133] step: 410200, training_loss: 3.05533e-02
I0210 05:03:21.028594 22542570456896 run_lib.py:146] step: 410200, eval_loss: 2.79717e-02
I0210 05:03:38.547865 22542570456896 run_lib.py:133] step: 410250, training_loss: 2.77930e-02
I0210 05:03:55.993432 22542570456896 run_lib.py:133] step: 410300, training_loss: 2.69930e-02
I0210 05:03:56.149521 22542570456896 run_lib.py:146] step: 410300, eval_loss: 3.36576e-02
I0210 05:04:13.603882 22542570456896 run_lib.py:133] step: 410350, training_loss: 2.81269e-02
I0210 05:04:30.987037 22542570456896 run_lib.py:133] step: 410400, training_loss: 2.86344e-02
I0210 05:04:31.151949 22542570456896 run_lib.py:146] step: 410400, eval_loss: 2.12728e-02
I0210 05:04:48.763775 22542570456896 run_lib.py:133] step: 410450, training_loss: 2.89161e-02
I0210 05:05:06.247497 22542570456896 run_lib.py:133] step: 410500, training_loss: 2.86898e-02
I0210 05:05:06.400601 22542570456896 run_lib.py:146] step: 410500, eval_loss: 2.40585e-02
I0210 05:05:23.884975 22542570456896 run_lib.py:133] step: 410550, training_loss: 2.65316e-02
I0210 05:05:41.337605 22542570456896 run_lib.py:133] step: 410600, training_loss: 2.86839e-02
I0210 05:05:41.494293 22542570456896 run_lib.py:146] step: 410600, eval_loss: 3.36305e-02
I0210 05:05:59.084119 22542570456896 run_lib.py:133] step: 410650, training_loss: 2.94235e-02
I0210 05:06:16.491668 22542570456896 run_lib.py:133] step: 410700, training_loss: 2.69136e-02
I0210 05:06:16.650710 22542570456896 run_lib.py:146] step: 410700, eval_loss: 2.97515e-02
I0210 05:06:34.218020 22542570456896 run_lib.py:133] step: 410750, training_loss: 2.46518e-02
I0210 05:06:51.697341 22542570456896 run_lib.py:133] step: 410800, training_loss: 2.99310e-02
I0210 05:06:51.862260 22542570456896 run_lib.py:146] step: 410800, eval_loss: 3.28520e-02
I0210 05:07:09.477326 22542570456896 run_lib.py:133] step: 410850, training_loss: 2.54650e-02
I0210 05:07:26.928704 22542570456896 run_lib.py:133] step: 410900, training_loss: 2.64321e-02
I0210 05:07:27.084367 22542570456896 run_lib.py:146] step: 410900, eval_loss: 3.08379e-02
I0210 05:07:44.510140 22542570456896 run_lib.py:133] step: 410950, training_loss: 2.53555e-02
I0210 05:08:02.084013 22542570456896 run_lib.py:133] step: 411000, training_loss: 2.62016e-02
I0210 05:08:02.242578 22542570456896 run_lib.py:146] step: 411000, eval_loss: 2.13879e-02
I0210 05:08:19.714001 22542570456896 run_lib.py:133] step: 411050, training_loss: 2.44027e-02
I0210 05:08:37.359408 22542570456896 run_lib.py:133] step: 411100, training_loss: 3.35973e-02
I0210 05:08:37.515559 22542570456896 run_lib.py:146] step: 411100, eval_loss: 2.92775e-02
I0210 05:08:54.899256 22542570456896 run_lib.py:133] step: 411150, training_loss: 2.77913e-02
I0210 05:09:12.310748 22542570456896 run_lib.py:133] step: 411200, training_loss: 2.90459e-02
I0210 05:09:12.470630 22542570456896 run_lib.py:146] step: 411200, eval_loss: 2.93370e-02
I0210 05:09:30.027734 22542570456896 run_lib.py:133] step: 411250, training_loss: 3.22137e-02
I0210 05:09:47.375842 22542570456896 run_lib.py:133] step: 411300, training_loss: 2.73262e-02
I0210 05:09:47.544719 22542570456896 run_lib.py:146] step: 411300, eval_loss: 3.59526e-02
I0210 05:10:04.888584 22542570456896 run_lib.py:133] step: 411350, training_loss: 2.95300e-02
I0210 05:10:22.444018 22542570456896 run_lib.py:133] step: 411400, training_loss: 2.59343e-02
I0210 05:10:22.598667 22542570456896 run_lib.py:146] step: 411400, eval_loss: 2.49031e-02
I0210 05:10:39.946979 22542570456896 run_lib.py:133] step: 411450, training_loss: 3.55985e-02
I0210 05:10:57.387160 22542570456896 run_lib.py:133] step: 411500, training_loss: 2.88779e-02
I0210 05:10:57.695412 22542570456896 run_lib.py:146] step: 411500, eval_loss: 2.38431e-02
I0210 05:11:15.116823 22542570456896 run_lib.py:133] step: 411550, training_loss: 4.04020e-02
I0210 05:11:32.503279 22542570456896 run_lib.py:133] step: 411600, training_loss: 3.21676e-02
I0210 05:11:32.679352 22542570456896 run_lib.py:146] step: 411600, eval_loss: 2.83433e-02
I0210 05:11:50.141183 22542570456896 run_lib.py:133] step: 411650, training_loss: 2.31295e-02
I0210 05:12:07.613067 22542570456896 run_lib.py:133] step: 411700, training_loss: 2.36904e-02
I0210 05:12:07.771281 22542570456896 run_lib.py:146] step: 411700, eval_loss: 2.73826e-02
I0210 05:12:25.341264 22542570456896 run_lib.py:133] step: 411750, training_loss: 3.16182e-02
I0210 05:12:42.833407 22542570456896 run_lib.py:133] step: 411800, training_loss: 2.27499e-02
I0210 05:12:42.987959 22542570456896 run_lib.py:146] step: 411800, eval_loss: 2.54568e-02
I0210 05:13:00.400199 22542570456896 run_lib.py:133] step: 411850, training_loss: 3.01875e-02
I0210 05:13:17.855998 22542570456896 run_lib.py:133] step: 411900, training_loss: 3.39613e-02
I0210 05:13:18.010138 22542570456896 run_lib.py:146] step: 411900, eval_loss: 2.68803e-02
I0210 05:13:35.656236 22542570456896 run_lib.py:133] step: 411950, training_loss: 2.76304e-02
I0210 05:13:53.102961 22542570456896 run_lib.py:133] step: 412000, training_loss: 2.74547e-02
I0210 05:13:53.258372 22542570456896 run_lib.py:146] step: 412000, eval_loss: 3.11132e-02
I0210 05:14:10.717927 22542570456896 run_lib.py:133] step: 412050, training_loss: 2.47304e-02
I0210 05:14:28.171041 22542570456896 run_lib.py:133] step: 412100, training_loss: 2.68479e-02
I0210 05:14:28.330463 22542570456896 run_lib.py:146] step: 412100, eval_loss: 2.71024e-02
I0210 05:14:45.909101 22542570456896 run_lib.py:133] step: 412150, training_loss: 2.43555e-02
I0210 05:15:03.354764 22542570456896 run_lib.py:133] step: 412200, training_loss: 3.48780e-02
I0210 05:15:03.510549 22542570456896 run_lib.py:146] step: 412200, eval_loss: 2.55619e-02
I0210 05:15:21.115406 22542570456896 run_lib.py:133] step: 412250, training_loss: 3.00066e-02
I0210 05:15:38.547174 22542570456896 run_lib.py:133] step: 412300, training_loss: 2.80266e-02
I0210 05:15:38.698896 22542570456896 run_lib.py:146] step: 412300, eval_loss: 3.03574e-02
I0210 05:15:56.255414 22542570456896 run_lib.py:133] step: 412350, training_loss: 3.69306e-02
I0210 05:16:13.709578 22542570456896 run_lib.py:133] step: 412400, training_loss: 2.67452e-02
I0210 05:16:13.867243 22542570456896 run_lib.py:146] step: 412400, eval_loss: 3.81057e-02
I0210 05:16:31.308832 22542570456896 run_lib.py:133] step: 412450, training_loss: 3.01710e-02
I0210 05:16:48.912671 22542570456896 run_lib.py:133] step: 412500, training_loss: 3.15927e-02
I0210 05:16:49.090112 22542570456896 run_lib.py:146] step: 412500, eval_loss: 2.39165e-02
I0210 05:17:06.505114 22542570456896 run_lib.py:133] step: 412550, training_loss: 2.98383e-02
I0210 05:17:24.058252 22542570456896 run_lib.py:133] step: 412600, training_loss: 2.70618e-02
I0210 05:17:24.219503 22542570456896 run_lib.py:146] step: 412600, eval_loss: 3.23722e-02
I0210 05:17:41.626923 22542570456896 run_lib.py:133] step: 412650, training_loss: 3.66852e-02
I0210 05:17:59.027283 22542570456896 run_lib.py:133] step: 412700, training_loss: 2.27250e-02
I0210 05:17:59.181353 22542570456896 run_lib.py:146] step: 412700, eval_loss: 3.00474e-02
I0210 05:18:16.767488 22542570456896 run_lib.py:133] step: 412750, training_loss: 2.69983e-02
I0210 05:18:34.257359 22542570456896 run_lib.py:133] step: 412800, training_loss: 2.64871e-02
I0210 05:18:34.412560 22542570456896 run_lib.py:146] step: 412800, eval_loss: 3.25305e-02
I0210 05:18:51.866221 22542570456896 run_lib.py:133] step: 412850, training_loss: 2.61839e-02
I0210 05:19:09.248592 22542570456896 run_lib.py:133] step: 412900, training_loss: 2.27837e-02
I0210 05:19:09.400336 22542570456896 run_lib.py:146] step: 412900, eval_loss: 3.16849e-02
I0210 05:19:26.989263 22542570456896 run_lib.py:133] step: 412950, training_loss: 1.87052e-02
I0210 05:19:44.393725 22542570456896 run_lib.py:133] step: 413000, training_loss: 2.73299e-02
I0210 05:19:44.558850 22542570456896 run_lib.py:146] step: 413000, eval_loss: 2.77687e-02
I0210 05:20:02.118827 22542570456896 run_lib.py:133] step: 413050, training_loss: 2.26383e-02
I0210 05:20:19.518970 22542570456896 run_lib.py:133] step: 413100, training_loss: 2.12147e-02
I0210 05:20:19.677175 22542570456896 run_lib.py:146] step: 413100, eval_loss: 2.87814e-02
I0210 05:20:37.088983 22542570456896 run_lib.py:133] step: 413150, training_loss: 3.56075e-02
I0210 05:20:54.472377 22542570456896 run_lib.py:133] step: 413200, training_loss: 2.66351e-02
I0210 05:20:54.629417 22542570456896 run_lib.py:146] step: 413200, eval_loss: 2.72040e-02
I0210 05:21:12.203490 22542570456896 run_lib.py:133] step: 413250, training_loss: 2.17737e-02
I0210 05:21:29.691704 22542570456896 run_lib.py:133] step: 413300, training_loss: 2.95374e-02
I0210 05:21:29.850600 22542570456896 run_lib.py:146] step: 413300, eval_loss: 2.54765e-02
I0210 05:21:47.285471 22542570456896 run_lib.py:133] step: 413350, training_loss: 2.60359e-02
I0210 05:22:04.695137 22542570456896 run_lib.py:133] step: 413400, training_loss: 3.30636e-02
I0210 05:22:04.850939 22542570456896 run_lib.py:146] step: 413400, eval_loss: 2.59306e-02
I0210 05:22:22.476689 22542570456896 run_lib.py:133] step: 413450, training_loss: 2.91071e-02
I0210 05:22:39.916567 22542570456896 run_lib.py:133] step: 413500, training_loss: 2.37343e-02
I0210 05:22:40.080845 22542570456896 run_lib.py:146] step: 413500, eval_loss: 3.42742e-02
I0210 05:22:57.614188 22542570456896 run_lib.py:133] step: 413550, training_loss: 2.93199e-02
I0210 05:23:15.048149 22542570456896 run_lib.py:133] step: 413600, training_loss: 2.82949e-02
I0210 05:23:15.221323 22542570456896 run_lib.py:146] step: 413600, eval_loss: 2.47940e-02
I0210 05:23:32.866854 22542570456896 run_lib.py:133] step: 413650, training_loss: 2.85072e-02
I0210 05:23:50.316819 22542570456896 run_lib.py:133] step: 413700, training_loss: 2.52985e-02
I0210 05:23:50.475193 22542570456896 run_lib.py:146] step: 413700, eval_loss: 2.86347e-02
I0210 05:24:08.119346 22542570456896 run_lib.py:133] step: 413750, training_loss: 2.91884e-02
I0210 05:24:25.530077 22542570456896 run_lib.py:133] step: 413800, training_loss: 3.11606e-02
I0210 05:24:25.687394 22542570456896 run_lib.py:146] step: 413800, eval_loss: 2.71600e-02
I0210 05:24:43.222529 22542570456896 run_lib.py:133] step: 413850, training_loss: 2.70177e-02
I0210 05:25:00.834759 22542570456896 run_lib.py:133] step: 413900, training_loss: 2.75598e-02
I0210 05:25:00.992521 22542570456896 run_lib.py:146] step: 413900, eval_loss: 3.09554e-02
I0210 05:25:18.433983 22542570456896 run_lib.py:133] step: 413950, training_loss: 2.65633e-02
I0210 05:25:35.861790 22542570456896 run_lib.py:133] step: 414000, training_loss: 2.38237e-02
I0210 05:25:36.020084 22542570456896 run_lib.py:146] step: 414000, eval_loss: 2.77589e-02
I0210 05:25:53.636073 22542570456896 run_lib.py:133] step: 414050, training_loss: 3.20423e-02
I0210 05:26:11.206764 22542570456896 run_lib.py:133] step: 414100, training_loss: 2.97722e-02
I0210 05:26:11.379310 22542570456896 run_lib.py:146] step: 414100, eval_loss: 2.40204e-02
I0210 05:26:28.852393 22542570456896 run_lib.py:133] step: 414150, training_loss: 2.84759e-02
I0210 05:26:46.306398 22542570456896 run_lib.py:133] step: 414200, training_loss: 2.80976e-02
I0210 05:26:46.467685 22542570456896 run_lib.py:146] step: 414200, eval_loss: 3.15290e-02
I0210 05:27:03.946151 22542570456896 run_lib.py:133] step: 414250, training_loss: 3.27052e-02
I0210 05:27:21.551601 22542570456896 run_lib.py:133] step: 414300, training_loss: 2.60770e-02
I0210 05:27:21.704309 22542570456896 run_lib.py:146] step: 414300, eval_loss: 2.72878e-02
I0210 05:27:39.151911 22542570456896 run_lib.py:133] step: 414350, training_loss: 2.69884e-02
I0210 05:27:56.601091 22542570456896 run_lib.py:133] step: 414400, training_loss: 2.91506e-02
I0210 05:27:56.769593 22542570456896 run_lib.py:146] step: 414400, eval_loss: 2.36945e-02
I0210 05:28:14.263846 22542570456896 run_lib.py:133] step: 414450, training_loss: 2.27443e-02
I0210 05:28:31.877793 22542570456896 run_lib.py:133] step: 414500, training_loss: 2.29234e-02
I0210 05:28:32.034633 22542570456896 run_lib.py:146] step: 414500, eval_loss: 2.83154e-02
I0210 05:28:49.460961 22542570456896 run_lib.py:133] step: 414550, training_loss: 2.95063e-02
I0210 05:29:06.919635 22542570456896 run_lib.py:133] step: 414600, training_loss: 2.12829e-02
I0210 05:29:07.088484 22542570456896 run_lib.py:146] step: 414600, eval_loss: 2.55781e-02
I0210 05:29:24.544936 22542570456896 run_lib.py:133] step: 414650, training_loss: 2.67103e-02
I0210 05:29:41.960210 22542570456896 run_lib.py:133] step: 414700, training_loss: 3.03518e-02
I0210 05:29:42.115199 22542570456896 run_lib.py:146] step: 414700, eval_loss: 2.81503e-02
I0210 05:29:59.753307 22542570456896 run_lib.py:133] step: 414750, training_loss: 2.98674e-02
I0210 05:30:17.229076 22542570456896 run_lib.py:133] step: 414800, training_loss: 3.58730e-02
I0210 05:30:17.381453 22542570456896 run_lib.py:146] step: 414800, eval_loss: 2.96366e-02
I0210 05:30:34.832608 22542570456896 run_lib.py:133] step: 414850, training_loss: 2.73760e-02
I0210 05:30:52.229162 22542570456896 run_lib.py:133] step: 414900, training_loss: 2.45807e-02
I0210 05:30:52.398081 22542570456896 run_lib.py:146] step: 414900, eval_loss: 2.35072e-02
I0210 05:31:10.045320 22542570456896 run_lib.py:133] step: 414950, training_loss: 2.63322e-02
I0210 05:31:27.547097 22542570456896 run_lib.py:133] step: 415000, training_loss: 2.30393e-02
I0210 05:31:27.711392 22542570456896 run_lib.py:146] step: 415000, eval_loss: 3.26784e-02
I0210 05:31:45.344891 22542570456896 run_lib.py:133] step: 415050, training_loss: 2.96553e-02
I0210 05:32:02.747638 22542570456896 run_lib.py:133] step: 415100, training_loss: 2.46414e-02
I0210 05:32:02.911398 22542570456896 run_lib.py:146] step: 415100, eval_loss: 2.53109e-02
I0210 05:32:20.464597 22542570456896 run_lib.py:133] step: 415150, training_loss: 2.65800e-02
I0210 05:32:37.953761 22542570456896 run_lib.py:133] step: 415200, training_loss: 2.65661e-02
I0210 05:32:38.110701 22542570456896 run_lib.py:146] step: 415200, eval_loss: 3.38933e-02
I0210 05:32:55.557495 22542570456896 run_lib.py:133] step: 415250, training_loss: 2.92062e-02
I0210 05:33:13.196080 22542570456896 run_lib.py:133] step: 415300, training_loss: 2.98525e-02
I0210 05:33:13.347688 22542570456896 run_lib.py:146] step: 415300, eval_loss: 2.36819e-02
I0210 05:33:30.800469 22542570456896 run_lib.py:133] step: 415350, training_loss: 2.66104e-02
I0210 05:33:48.378993 22542570456896 run_lib.py:133] step: 415400, training_loss: 2.49552e-02
I0210 05:33:48.536784 22542570456896 run_lib.py:146] step: 415400, eval_loss: 3.25163e-02
I0210 05:34:05.943675 22542570456896 run_lib.py:133] step: 415450, training_loss: 3.21450e-02
I0210 05:34:23.410394 22542570456896 run_lib.py:133] step: 415500, training_loss: 3.32745e-02
I0210 05:34:23.571263 22542570456896 run_lib.py:146] step: 415500, eval_loss: 2.36464e-02
I0210 05:34:41.156604 22542570456896 run_lib.py:133] step: 415550, training_loss: 2.63090e-02
I0210 05:34:58.601591 22542570456896 run_lib.py:133] step: 415600, training_loss: 2.78361e-02
I0210 05:34:58.757531 22542570456896 run_lib.py:146] step: 415600, eval_loss: 2.93776e-02
I0210 05:35:16.183389 22542570456896 run_lib.py:133] step: 415650, training_loss: 2.58280e-02
I0210 05:35:33.735019 22542570456896 run_lib.py:133] step: 415700, training_loss: 2.53634e-02
I0210 05:35:33.887399 22542570456896 run_lib.py:146] step: 415700, eval_loss: 2.53501e-02
I0210 05:35:51.279466 22542570456896 run_lib.py:133] step: 415750, training_loss: 2.92576e-02
I0210 05:36:08.766422 22542570456896 run_lib.py:133] step: 415800, training_loss: 2.96548e-02
I0210 05:36:08.927612 22542570456896 run_lib.py:146] step: 415800, eval_loss: 2.78773e-02
I0210 05:36:26.463690 22542570456896 run_lib.py:133] step: 415850, training_loss: 2.37547e-02
I0210 05:36:43.902027 22542570456896 run_lib.py:133] step: 415900, training_loss: 3.52472e-02
I0210 05:36:44.059689 22542570456896 run_lib.py:146] step: 415900, eval_loss: 2.94758e-02
I0210 05:37:01.470637 22542570456896 run_lib.py:133] step: 415950, training_loss: 2.77601e-02
I0210 05:37:18.905380 22542570456896 run_lib.py:133] step: 416000, training_loss: 3.38990e-02
I0210 05:37:19.060341 22542570456896 run_lib.py:146] step: 416000, eval_loss: 3.66308e-02
I0210 05:37:36.622674 22542570456896 run_lib.py:133] step: 416050, training_loss: 2.88759e-02
I0210 05:37:54.178469 22542570456896 run_lib.py:133] step: 416100, training_loss: 2.10712e-02
I0210 05:37:54.335088 22542570456896 run_lib.py:146] step: 416100, eval_loss: 3.10791e-02
I0210 05:38:11.811969 22542570456896 run_lib.py:133] step: 416150, training_loss: 2.67955e-02
I0210 05:38:29.286643 22542570456896 run_lib.py:133] step: 416200, training_loss: 2.95483e-02
I0210 05:38:29.447294 22542570456896 run_lib.py:146] step: 416200, eval_loss: 3.79383e-02
I0210 05:38:47.043292 22542570456896 run_lib.py:133] step: 416250, training_loss: 2.96569e-02
I0210 05:39:04.467804 22542570456896 run_lib.py:133] step: 416300, training_loss: 3.63165e-02
I0210 05:39:04.632605 22542570456896 run_lib.py:146] step: 416300, eval_loss: 2.69380e-02
I0210 05:39:22.252465 22542570456896 run_lib.py:133] step: 416350, training_loss: 2.27044e-02
I0210 05:39:39.731876 22542570456896 run_lib.py:133] step: 416400, training_loss: 2.47772e-02
I0210 05:39:39.890362 22542570456896 run_lib.py:146] step: 416400, eval_loss: 2.52062e-02
I0210 05:39:57.473221 22542570456896 run_lib.py:133] step: 416450, training_loss: 3.01803e-02
I0210 05:40:14.920967 22542570456896 run_lib.py:133] step: 416500, training_loss: 3.19216e-02
I0210 05:40:15.080312 22542570456896 run_lib.py:146] step: 416500, eval_loss: 2.65343e-02
I0210 05:40:32.633963 22542570456896 run_lib.py:133] step: 416550, training_loss: 2.28732e-02
I0210 05:40:50.130584 22542570456896 run_lib.py:133] step: 416600, training_loss: 2.56645e-02
I0210 05:40:50.286694 22542570456896 run_lib.py:146] step: 416600, eval_loss: 2.41901e-02
I0210 05:41:07.754042 22542570456896 run_lib.py:133] step: 416650, training_loss: 2.60459e-02
I0210 05:41:25.344970 22542570456896 run_lib.py:133] step: 416700, training_loss: 2.77913e-02
I0210 05:41:25.497395 22542570456896 run_lib.py:146] step: 416700, eval_loss: 3.04201e-02
I0210 05:41:42.909852 22542570456896 run_lib.py:133] step: 416750, training_loss: 2.61938e-02
I0210 05:42:00.351589 22542570456896 run_lib.py:133] step: 416800, training_loss: 3.13343e-02
I0210 05:42:00.507341 22542570456896 run_lib.py:146] step: 416800, eval_loss: 2.72237e-02
I0210 05:42:18.078910 22542570456896 run_lib.py:133] step: 416850, training_loss: 3.20124e-02
I0210 05:42:35.557883 22542570456896 run_lib.py:133] step: 416900, training_loss: 2.31777e-02
I0210 05:42:35.716387 22542570456896 run_lib.py:146] step: 416900, eval_loss: 1.86353e-02
I0210 05:42:53.309239 22542570456896 run_lib.py:133] step: 416950, training_loss: 2.83276e-02
I0210 05:43:10.751493 22542570456896 run_lib.py:133] step: 417000, training_loss: 2.37499e-02
I0210 05:43:10.911098 22542570456896 run_lib.py:146] step: 417000, eval_loss: 2.37019e-02
I0210 05:43:28.326920 22542570456896 run_lib.py:133] step: 417050, training_loss: 3.12672e-02
I0210 05:43:45.919690 22542570456896 run_lib.py:133] step: 417100, training_loss: 3.06987e-02
I0210 05:43:46.076556 22542570456896 run_lib.py:146] step: 417100, eval_loss: 3.34859e-02
I0210 05:44:03.594335 22542570456896 run_lib.py:133] step: 417150, training_loss: 3.17270e-02
I0210 05:44:20.998134 22542570456896 run_lib.py:133] step: 417200, training_loss: 3.02897e-02
I0210 05:44:21.150331 22542570456896 run_lib.py:146] step: 417200, eval_loss: 2.89078e-02
I0210 05:44:38.558183 22542570456896 run_lib.py:133] step: 417250, training_loss: 2.38773e-02
I0210 05:44:56.207998 22542570456896 run_lib.py:133] step: 417300, training_loss: 2.58839e-02
I0210 05:44:56.366610 22542570456896 run_lib.py:146] step: 417300, eval_loss: 2.41031e-02
I0210 05:45:13.808254 22542570456896 run_lib.py:133] step: 417350, training_loss: 2.55194e-02
I0210 05:45:31.314653 22542570456896 run_lib.py:133] step: 417400, training_loss: 3.00824e-02
I0210 05:45:31.481338 22542570456896 run_lib.py:146] step: 417400, eval_loss: 2.70552e-02
I0210 05:45:48.930824 22542570456896 run_lib.py:133] step: 417450, training_loss: 2.47771e-02
I0210 05:46:06.350371 22542570456896 run_lib.py:133] step: 417500, training_loss: 3.06242e-02
I0210 05:46:06.507540 22542570456896 run_lib.py:146] step: 417500, eval_loss: 3.19819e-02
I0210 05:46:24.159208 22542570456896 run_lib.py:133] step: 417550, training_loss: 2.52767e-02
I0210 05:46:41.629601 22542570456896 run_lib.py:133] step: 417600, training_loss: 2.09838e-02
I0210 05:46:41.783173 22542570456896 run_lib.py:146] step: 417600, eval_loss: 3.07385e-02
I0210 05:46:59.220456 22542570456896 run_lib.py:133] step: 417650, training_loss: 3.32489e-02
I0210 05:47:16.690322 22542570456896 run_lib.py:133] step: 417700, training_loss: 3.06759e-02
I0210 05:47:16.858156 22542570456896 run_lib.py:146] step: 417700, eval_loss: 2.94344e-02
I0210 05:47:34.482548 22542570456896 run_lib.py:133] step: 417750, training_loss: 2.56433e-02
I0210 05:47:51.916071 22542570456896 run_lib.py:133] step: 417800, training_loss: 2.81159e-02
I0210 05:47:52.073620 22542570456896 run_lib.py:146] step: 417800, eval_loss: 3.30027e-02
I0210 05:48:09.664577 22542570456896 run_lib.py:133] step: 417850, training_loss: 3.02312e-02
I0210 05:48:27.075750 22542570456896 run_lib.py:133] step: 417900, training_loss: 2.42298e-02
I0210 05:48:27.231416 22542570456896 run_lib.py:146] step: 417900, eval_loss: 2.80858e-02
I0210 05:48:44.822377 22542570456896 run_lib.py:133] step: 417950, training_loss: 3.07293e-02
I0210 05:49:02.279150 22542570456896 run_lib.py:133] step: 418000, training_loss: 2.53496e-02
I0210 05:49:02.435744 22542570456896 run_lib.py:146] step: 418000, eval_loss: 3.41084e-02
I0210 05:49:19.878340 22542570456896 run_lib.py:133] step: 418050, training_loss: 2.56486e-02
I0210 05:49:37.477962 22542570456896 run_lib.py:133] step: 418100, training_loss: 2.24470e-02
I0210 05:49:37.629375 22542570456896 run_lib.py:146] step: 418100, eval_loss: 2.65812e-02
I0210 05:49:55.043678 22542570456896 run_lib.py:133] step: 418150, training_loss: 2.53317e-02
I0210 05:50:12.619576 22542570456896 run_lib.py:133] step: 418200, training_loss: 2.60714e-02
I0210 05:50:12.787642 22542570456896 run_lib.py:146] step: 418200, eval_loss: 3.11482e-02
I0210 05:50:30.235640 22542570456896 run_lib.py:133] step: 418250, training_loss: 3.05907e-02
I0210 05:50:47.725344 22542570456896 run_lib.py:133] step: 418300, training_loss: 3.52253e-02
I0210 05:50:47.883309 22542570456896 run_lib.py:146] step: 418300, eval_loss: 2.49808e-02
I0210 05:51:05.503276 22542570456896 run_lib.py:133] step: 418350, training_loss: 2.64564e-02
I0210 05:51:22.917651 22542570456896 run_lib.py:133] step: 418400, training_loss: 2.22708e-02
I0210 05:51:23.073410 22542570456896 run_lib.py:146] step: 418400, eval_loss: 3.33870e-02
I0210 05:51:40.517857 22542570456896 run_lib.py:133] step: 418450, training_loss: 2.68417e-02
I0210 05:51:58.190700 22542570456896 run_lib.py:133] step: 418500, training_loss: 2.67479e-02
I0210 05:51:58.354423 22542570456896 run_lib.py:146] step: 418500, eval_loss: 2.15090e-02
I0210 05:52:15.819678 22542570456896 run_lib.py:133] step: 418550, training_loss: 2.89327e-02
I0210 05:52:33.211563 22542570456896 run_lib.py:133] step: 418600, training_loss: 3.02726e-02
I0210 05:52:33.548859 22542570456896 run_lib.py:146] step: 418600, eval_loss: 3.00447e-02
I0210 05:52:50.952593 22542570456896 run_lib.py:133] step: 418650, training_loss: 2.81122e-02
I0210 05:53:08.356220 22542570456896 run_lib.py:133] step: 418700, training_loss: 2.80613e-02
I0210 05:53:08.511985 22542570456896 run_lib.py:146] step: 418700, eval_loss: 3.04642e-02
I0210 05:53:25.924677 22542570456896 run_lib.py:133] step: 418750, training_loss: 2.60302e-02
I0210 05:53:43.368706 22542570456896 run_lib.py:133] step: 418800, training_loss: 2.82341e-02
I0210 05:53:43.528346 22542570456896 run_lib.py:146] step: 418800, eval_loss: 2.89851e-02
I0210 05:54:01.096746 22542570456896 run_lib.py:133] step: 418850, training_loss: 3.42265e-02
I0210 05:54:18.599384 22542570456896 run_lib.py:133] step: 418900, training_loss: 2.71360e-02
I0210 05:54:18.754560 22542570456896 run_lib.py:146] step: 418900, eval_loss: 2.19752e-02
I0210 05:54:36.201911 22542570456896 run_lib.py:133] step: 418950, training_loss: 2.62845e-02
I0210 05:54:53.633188 22542570456896 run_lib.py:133] step: 419000, training_loss: 3.10900e-02
I0210 05:54:53.787404 22542570456896 run_lib.py:146] step: 419000, eval_loss: 3.18486e-02
I0210 05:55:11.371590 22542570456896 run_lib.py:133] step: 419050, training_loss: 2.82385e-02
I0210 05:55:28.964803 22542570456896 run_lib.py:133] step: 419100, training_loss: 3.00226e-02
I0210 05:55:29.120640 22542570456896 run_lib.py:146] step: 419100, eval_loss: 2.49790e-02
I0210 05:55:46.578734 22542570456896 run_lib.py:133] step: 419150, training_loss: 2.71673e-02
I0210 05:56:03.990441 22542570456896 run_lib.py:133] step: 419200, training_loss: 2.89809e-02
I0210 05:56:04.149343 22542570456896 run_lib.py:146] step: 419200, eval_loss: 2.73144e-02
I0210 05:56:21.729091 22542570456896 run_lib.py:133] step: 419250, training_loss: 2.17043e-02
I0210 05:56:39.167333 22542570456896 run_lib.py:133] step: 419300, training_loss: 2.02626e-02
I0210 05:56:39.322307 22542570456896 run_lib.py:146] step: 419300, eval_loss: 2.77465e-02
I0210 05:56:56.898012 22542570456896 run_lib.py:133] step: 419350, training_loss: 2.87827e-02
I0210 05:57:14.362706 22542570456896 run_lib.py:133] step: 419400, training_loss: 3.86084e-02
I0210 05:57:14.520350 22542570456896 run_lib.py:146] step: 419400, eval_loss: 3.27239e-02
I0210 05:57:32.142432 22542570456896 run_lib.py:133] step: 419450, training_loss: 2.05811e-02
I0210 05:57:49.559169 22542570456896 run_lib.py:133] step: 419500, training_loss: 2.51805e-02
I0210 05:57:49.711073 22542570456896 run_lib.py:146] step: 419500, eval_loss: 2.99614e-02
I0210 05:58:07.113494 22542570456896 run_lib.py:133] step: 419550, training_loss: 3.08018e-02
I0210 05:58:24.745640 22542570456896 run_lib.py:133] step: 419600, training_loss: 3.00155e-02
I0210 05:58:24.897332 22542570456896 run_lib.py:146] step: 419600, eval_loss: 2.99772e-02
I0210 05:58:42.319963 22542570456896 run_lib.py:133] step: 419650, training_loss: 2.90993e-02
I0210 05:58:59.966812 22542570456896 run_lib.py:133] step: 419700, training_loss: 2.38838e-02
I0210 05:59:00.125370 22542570456896 run_lib.py:146] step: 419700, eval_loss: 2.65748e-02
I0210 05:59:17.547734 22542570456896 run_lib.py:133] step: 419750, training_loss: 2.52759e-02
I0210 05:59:34.947130 22542570456896 run_lib.py:133] step: 419800, training_loss: 3.09741e-02
I0210 05:59:35.103283 22542570456896 run_lib.py:146] step: 419800, eval_loss: 2.42739e-02
I0210 05:59:52.691837 22542570456896 run_lib.py:133] step: 419850, training_loss: 3.03181e-02
I0210 06:00:10.100164 22542570456896 run_lib.py:133] step: 419900, training_loss: 2.59744e-02
I0210 06:00:10.258445 22542570456896 run_lib.py:146] step: 419900, eval_loss: 2.76309e-02
I0210 06:00:27.712744 22542570456896 run_lib.py:133] step: 419950, training_loss: 2.74037e-02
I0210 06:00:45.190813 22542570456896 run_lib.py:133] step: 420000, training_loss: 2.45387e-02
I0210 06:00:45.889496 22542570456896 run_lib.py:146] step: 420000, eval_loss: 2.77013e-02
I0210 06:01:06.365794 22542570456896 run_lib.py:133] step: 420050, training_loss: 2.60398e-02
I0210 06:01:23.940849 22542570456896 run_lib.py:133] step: 420100, training_loss: 2.26521e-02
I0210 06:01:24.093592 22542570456896 run_lib.py:146] step: 420100, eval_loss: 2.79213e-02
I0210 06:01:41.466137 22542570456896 run_lib.py:133] step: 420150, training_loss: 2.42401e-02
I0210 06:01:58.867105 22542570456896 run_lib.py:133] step: 420200, training_loss: 3.09205e-02
I0210 06:01:59.033342 22542570456896 run_lib.py:146] step: 420200, eval_loss: 3.19528e-02
I0210 06:02:16.735532 22542570456896 run_lib.py:133] step: 420250, training_loss: 2.57623e-02
I0210 06:02:34.205557 22542570456896 run_lib.py:133] step: 420300, training_loss: 2.49840e-02
I0210 06:02:34.367262 22542570456896 run_lib.py:146] step: 420300, eval_loss: 2.36328e-02
I0210 06:02:51.767019 22542570456896 run_lib.py:133] step: 420350, training_loss: 2.37559e-02
I0210 06:03:09.186537 22542570456896 run_lib.py:133] step: 420400, training_loss: 2.95623e-02
I0210 06:03:09.341137 22542570456896 run_lib.py:146] step: 420400, eval_loss: 3.49858e-02
I0210 06:03:26.944006 22542570456896 run_lib.py:133] step: 420450, training_loss: 2.76782e-02
I0210 06:03:44.385975 22542570456896 run_lib.py:133] step: 420500, training_loss: 2.92527e-02
I0210 06:03:44.540772 22542570456896 run_lib.py:146] step: 420500, eval_loss: 3.39512e-02
I0210 06:04:02.093590 22542570456896 run_lib.py:133] step: 420550, training_loss: 2.87550e-02
I0210 06:04:19.535103 22542570456896 run_lib.py:133] step: 420600, training_loss: 2.74650e-02
I0210 06:04:19.696215 22542570456896 run_lib.py:146] step: 420600, eval_loss: 2.86382e-02
I0210 06:04:37.114753 22542570456896 run_lib.py:133] step: 420650, training_loss: 2.12061e-02
I0210 06:04:54.586917 22542570456896 run_lib.py:133] step: 420700, training_loss: 3.06896e-02
I0210 06:04:54.750678 22542570456896 run_lib.py:146] step: 420700, eval_loss: 3.07167e-02
I0210 06:05:12.326882 22542570456896 run_lib.py:133] step: 420750, training_loss: 3.03805e-02
I0210 06:05:29.855376 22542570456896 run_lib.py:133] step: 420800, training_loss: 2.77865e-02
I0210 06:05:30.019260 22542570456896 run_lib.py:146] step: 420800, eval_loss: 2.89238e-02
I0210 06:05:47.434619 22542570456896 run_lib.py:133] step: 420850, training_loss: 3.69105e-02
I0210 06:06:04.869449 22542570456896 run_lib.py:133] step: 420900, training_loss: 2.71665e-02
I0210 06:06:05.031208 22542570456896 run_lib.py:146] step: 420900, eval_loss: 2.98378e-02
I0210 06:06:22.639771 22542570456896 run_lib.py:133] step: 420950, training_loss: 2.34685e-02
I0210 06:06:40.004202 22542570456896 run_lib.py:133] step: 421000, training_loss: 2.30815e-02
I0210 06:06:40.154019 22542570456896 run_lib.py:146] step: 421000, eval_loss: 3.14095e-02
I0210 06:06:57.687199 22542570456896 run_lib.py:133] step: 421050, training_loss: 2.75532e-02
I0210 06:07:15.156803 22542570456896 run_lib.py:133] step: 421100, training_loss: 3.00023e-02
I0210 06:07:15.318496 22542570456896 run_lib.py:146] step: 421100, eval_loss: 3.24375e-02
I0210 06:07:32.949363 22542570456896 run_lib.py:133] step: 421150, training_loss: 2.64241e-02
I0210 06:07:50.368666 22542570456896 run_lib.py:133] step: 421200, training_loss: 2.47771e-02
I0210 06:07:50.526608 22542570456896 run_lib.py:146] step: 421200, eval_loss: 2.59549e-02
I0210 06:08:08.113894 22542570456896 run_lib.py:133] step: 421250, training_loss: 3.19891e-02
I0210 06:08:25.517881 22542570456896 run_lib.py:133] step: 421300, training_loss: 2.46401e-02
I0210 06:08:25.678299 22542570456896 run_lib.py:146] step: 421300, eval_loss: 2.41476e-02
I0210 06:08:43.120950 22542570456896 run_lib.py:133] step: 421350, training_loss: 3.40464e-02
I0210 06:09:00.739067 22542570456896 run_lib.py:133] step: 421400, training_loss: 2.16948e-02
I0210 06:09:00.891498 22542570456896 run_lib.py:146] step: 421400, eval_loss: 2.73432e-02
I0210 06:09:18.362410 22542570456896 run_lib.py:133] step: 421450, training_loss: 3.11830e-02
I0210 06:09:35.780343 22542570456896 run_lib.py:133] step: 421500, training_loss: 2.59463e-02
I0210 06:09:35.939392 22542570456896 run_lib.py:146] step: 421500, eval_loss: 2.05595e-02
I0210 06:09:53.551386 22542570456896 run_lib.py:133] step: 421550, training_loss: 2.87461e-02
I0210 06:10:10.970363 22542570456896 run_lib.py:133] step: 421600, training_loss: 3.07880e-02
I0210 06:10:11.144403 22542570456896 run_lib.py:146] step: 421600, eval_loss: 3.30487e-02
I0210 06:10:28.805131 22542570456896 run_lib.py:133] step: 421650, training_loss: 2.86288e-02
I0210 06:10:46.236470 22542570456896 run_lib.py:133] step: 421700, training_loss: 2.87073e-02
I0210 06:10:46.395321 22542570456896 run_lib.py:146] step: 421700, eval_loss: 3.38104e-02
I0210 06:11:03.809862 22542570456896 run_lib.py:133] step: 421750, training_loss: 2.31784e-02
I0210 06:11:21.436182 22542570456896 run_lib.py:133] step: 421800, training_loss: 2.53718e-02
I0210 06:11:21.592357 22542570456896 run_lib.py:146] step: 421800, eval_loss: 2.89180e-02
I0210 06:11:39.058315 22542570456896 run_lib.py:133] step: 421850, training_loss: 2.37499e-02
I0210 06:11:56.526153 22542570456896 run_lib.py:133] step: 421900, training_loss: 2.12870e-02
I0210 06:11:56.684626 22542570456896 run_lib.py:146] step: 421900, eval_loss: 2.68696e-02
I0210 06:12:14.126760 22542570456896 run_lib.py:133] step: 421950, training_loss: 2.38350e-02
I0210 06:12:31.729832 22542570456896 run_lib.py:133] step: 422000, training_loss: 2.61250e-02
I0210 06:12:31.887349 22542570456896 run_lib.py:146] step: 422000, eval_loss: 2.61889e-02
I0210 06:12:49.350010 22542570456896 run_lib.py:133] step: 422050, training_loss: 2.87406e-02
I0210 06:13:06.831950 22542570456896 run_lib.py:133] step: 422100, training_loss: 3.29625e-02
I0210 06:13:06.987748 22542570456896 run_lib.py:146] step: 422100, eval_loss: 3.25988e-02
I0210 06:13:24.386101 22542570456896 run_lib.py:133] step: 422150, training_loss: 3.18339e-02
I0210 06:13:41.844928 22542570456896 run_lib.py:133] step: 422200, training_loss: 2.79131e-02
I0210 06:13:42.001494 22542570456896 run_lib.py:146] step: 422200, eval_loss: 2.76742e-02
I0210 06:13:59.628638 22542570456896 run_lib.py:133] step: 422250, training_loss: 3.41797e-02
I0210 06:14:17.140670 22542570456896 run_lib.py:133] step: 422300, training_loss: 3.08679e-02
I0210 06:14:17.304502 22542570456896 run_lib.py:146] step: 422300, eval_loss: 3.34475e-02
I0210 06:14:34.750637 22542570456896 run_lib.py:133] step: 422350, training_loss: 2.73716e-02
I0210 06:14:52.156837 22542570456896 run_lib.py:133] step: 422400, training_loss: 2.24862e-02
I0210 06:14:52.319330 22542570456896 run_lib.py:146] step: 422400, eval_loss: 2.38923e-02
I0210 06:15:09.920545 22542570456896 run_lib.py:133] step: 422450, training_loss: 2.81251e-02
I0210 06:15:27.361186 22542570456896 run_lib.py:133] step: 422500, training_loss: 3.94706e-02
I0210 06:15:27.524609 22542570456896 run_lib.py:146] step: 422500, eval_loss: 3.63051e-02
I0210 06:15:45.142164 22542570456896 run_lib.py:133] step: 422550, training_loss: 3.45522e-02
I0210 06:16:02.573929 22542570456896 run_lib.py:133] step: 422600, training_loss: 3.35463e-02
I0210 06:16:02.732665 22542570456896 run_lib.py:146] step: 422600, eval_loss: 2.80234e-02
I0210 06:16:20.284005 22542570456896 run_lib.py:133] step: 422650, training_loss: 2.51931e-02
I0210 06:16:37.672914 22542570456896 run_lib.py:133] step: 422700, training_loss: 2.82242e-02
I0210 06:16:37.840355 22542570456896 run_lib.py:146] step: 422700, eval_loss: 2.85459e-02
I0210 06:16:55.269090 22542570456896 run_lib.py:133] step: 422750, training_loss: 3.05496e-02
I0210 06:17:12.920966 22542570456896 run_lib.py:133] step: 422800, training_loss: 3.26037e-02
I0210 06:17:13.074056 22542570456896 run_lib.py:146] step: 422800, eval_loss: 2.48901e-02
I0210 06:17:30.557300 22542570456896 run_lib.py:133] step: 422850, training_loss: 2.57281e-02
I0210 06:17:48.094352 22542570456896 run_lib.py:133] step: 422900, training_loss: 3.33262e-02
I0210 06:17:48.246397 22542570456896 run_lib.py:146] step: 422900, eval_loss: 2.80247e-02
I0210 06:18:05.637294 22542570456896 run_lib.py:133] step: 422950, training_loss: 2.82281e-02
I0210 06:18:23.042243 22542570456896 run_lib.py:133] step: 423000, training_loss: 2.22264e-02
I0210 06:18:23.209422 22542570456896 run_lib.py:146] step: 423000, eval_loss: 2.81336e-02
I0210 06:18:40.756967 22542570456896 run_lib.py:133] step: 423050, training_loss: 2.66717e-02
I0210 06:18:58.080298 22542570456896 run_lib.py:133] step: 423100, training_loss: 2.41298e-02
I0210 06:18:58.245295 22542570456896 run_lib.py:146] step: 423100, eval_loss: 3.11344e-02
I0210 06:19:15.564864 22542570456896 run_lib.py:133] step: 423150, training_loss: 3.75936e-02
I0210 06:19:33.102062 22542570456896 run_lib.py:133] step: 423200, training_loss: 2.86996e-02
I0210 06:19:33.263286 22542570456896 run_lib.py:146] step: 423200, eval_loss: 2.99502e-02
I0210 06:19:50.718427 22542570456896 run_lib.py:133] step: 423250, training_loss: 2.77682e-02
I0210 06:20:08.169017 22542570456896 run_lib.py:133] step: 423300, training_loss: 2.03723e-02
I0210 06:20:08.483588 22542570456896 run_lib.py:146] step: 423300, eval_loss: 2.47545e-02
I0210 06:20:25.937080 22542570456896 run_lib.py:133] step: 423350, training_loss: 2.65838e-02
I0210 06:20:43.364580 22542570456896 run_lib.py:133] step: 423400, training_loss: 2.68510e-02
I0210 06:20:43.518416 22542570456896 run_lib.py:146] step: 423400, eval_loss: 2.22846e-02
I0210 06:21:00.905713 22542570456896 run_lib.py:133] step: 423450, training_loss: 3.26048e-02
I0210 06:21:18.303148 22542570456896 run_lib.py:133] step: 423500, training_loss: 2.32892e-02
I0210 06:21:18.462877 22542570456896 run_lib.py:146] step: 423500, eval_loss: 3.11997e-02
I0210 06:21:36.049163 22542570456896 run_lib.py:133] step: 423550, training_loss: 2.65248e-02
I0210 06:21:53.559605 22542570456896 run_lib.py:133] step: 423600, training_loss: 3.41784e-02
I0210 06:21:53.735394 22542570456896 run_lib.py:146] step: 423600, eval_loss: 2.72757e-02
I0210 06:22:11.157712 22542570456896 run_lib.py:133] step: 423650, training_loss: 2.56221e-02
I0210 06:22:28.580483 22542570456896 run_lib.py:133] step: 423700, training_loss: 2.47232e-02
I0210 06:22:28.744313 22542570456896 run_lib.py:146] step: 423700, eval_loss: 2.72456e-02
I0210 06:22:46.341753 22542570456896 run_lib.py:133] step: 423750, training_loss: 2.92409e-02
I0210 06:23:03.820921 22542570456896 run_lib.py:133] step: 423800, training_loss: 2.66983e-02
I0210 06:23:03.976254 22542570456896 run_lib.py:146] step: 423800, eval_loss: 3.76022e-02
I0210 06:23:21.397198 22542570456896 run_lib.py:133] step: 423850, training_loss: 2.13268e-02
I0210 06:23:38.815423 22542570456896 run_lib.py:133] step: 423900, training_loss: 2.95155e-02
I0210 06:23:38.979459 22542570456896 run_lib.py:146] step: 423900, eval_loss: 2.65676e-02
I0210 06:23:56.584086 22542570456896 run_lib.py:133] step: 423950, training_loss: 2.88860e-02
I0210 06:24:14.031578 22542570456896 run_lib.py:133] step: 424000, training_loss: 2.82385e-02
I0210 06:24:14.193966 22542570456896 run_lib.py:146] step: 424000, eval_loss: 2.29743e-02
I0210 06:24:31.721405 22542570456896 run_lib.py:133] step: 424050, training_loss: 3.05405e-02
I0210 06:24:49.136578 22542570456896 run_lib.py:133] step: 424100, training_loss: 2.58135e-02
I0210 06:24:49.301994 22542570456896 run_lib.py:146] step: 424100, eval_loss: 2.67849e-02
I0210 06:25:06.919595 22542570456896 run_lib.py:133] step: 424150, training_loss: 2.67987e-02
I0210 06:25:24.371893 22542570456896 run_lib.py:133] step: 424200, training_loss: 2.00770e-02
I0210 06:25:24.535051 22542570456896 run_lib.py:146] step: 424200, eval_loss: 3.32866e-02
I0210 06:25:42.007176 22542570456896 run_lib.py:133] step: 424250, training_loss: 3.00016e-02
I0210 06:25:59.612067 22542570456896 run_lib.py:133] step: 424300, training_loss: 2.59290e-02
I0210 06:25:59.765191 22542570456896 run_lib.py:146] step: 424300, eval_loss: 2.22687e-02
I0210 06:26:17.213810 22542570456896 run_lib.py:133] step: 424350, training_loss: 2.79530e-02
I0210 06:26:34.785701 22542570456896 run_lib.py:133] step: 424400, training_loss: 2.69693e-02
I0210 06:26:34.941915 22542570456896 run_lib.py:146] step: 424400, eval_loss: 2.55631e-02
I0210 06:26:52.430516 22542570456896 run_lib.py:133] step: 424450, training_loss: 2.73636e-02
I0210 06:27:09.848158 22542570456896 run_lib.py:133] step: 424500, training_loss: 3.27521e-02
I0210 06:27:10.005300 22542570456896 run_lib.py:146] step: 424500, eval_loss: 2.81906e-02
I0210 06:27:27.562576 22542570456896 run_lib.py:133] step: 424550, training_loss: 2.25494e-02
I0210 06:27:45.013169 22542570456896 run_lib.py:133] step: 424600, training_loss: 2.87605e-02
I0210 06:27:45.168426 22542570456896 run_lib.py:146] step: 424600, eval_loss: 3.40673e-02
I0210 06:28:02.592662 22542570456896 run_lib.py:133] step: 424650, training_loss: 2.69884e-02
I0210 06:28:20.060758 22542570456896 run_lib.py:133] step: 424700, training_loss: 3.36719e-02
I0210 06:28:20.216329 22542570456896 run_lib.py:146] step: 424700, eval_loss: 2.34293e-02
I0210 06:28:37.863493 22542570456896 run_lib.py:133] step: 424750, training_loss: 2.62270e-02
I0210 06:28:55.328488 22542570456896 run_lib.py:133] step: 424800, training_loss: 3.10605e-02
I0210 06:28:55.480339 22542570456896 run_lib.py:146] step: 424800, eval_loss: 3.31362e-02
I0210 06:29:12.939759 22542570456896 run_lib.py:133] step: 424850, training_loss: 2.74303e-02
I0210 06:29:30.348994 22542570456896 run_lib.py:133] step: 424900, training_loss: 2.52173e-02
I0210 06:29:30.503215 22542570456896 run_lib.py:146] step: 424900, eval_loss: 2.96933e-02
I0210 06:29:47.901849 22542570456896 run_lib.py:133] step: 424950, training_loss: 2.85041e-02
I0210 06:30:05.384181 22542570456896 run_lib.py:133] step: 425000, training_loss: 3.14560e-02
I0210 06:30:05.544128 22542570456896 run_lib.py:146] step: 425000, eval_loss: 2.42962e-02
I0210 06:30:23.156879 22542570456896 run_lib.py:133] step: 425050, training_loss: 3.13584e-02
I0210 06:30:40.657941 22542570456896 run_lib.py:133] step: 425100, training_loss: 2.52149e-02
I0210 06:30:40.821218 22542570456896 run_lib.py:146] step: 425100, eval_loss: 2.38534e-02
I0210 06:30:58.212195 22542570456896 run_lib.py:133] step: 425150, training_loss: 2.51409e-02
I0210 06:31:15.659291 22542570456896 run_lib.py:133] step: 425200, training_loss: 2.56007e-02
I0210 06:31:15.819092 22542570456896 run_lib.py:146] step: 425200, eval_loss: 2.59569e-02
I0210 06:31:33.377989 22542570456896 run_lib.py:133] step: 425250, training_loss: 2.75002e-02
I0210 06:31:50.796666 22542570456896 run_lib.py:133] step: 425300, training_loss: 2.46716e-02
I0210 06:31:50.955037 22542570456896 run_lib.py:146] step: 425300, eval_loss: 2.81252e-02
I0210 06:32:08.598704 22542570456896 run_lib.py:133] step: 425350, training_loss: 2.94338e-02
I0210 06:32:26.009567 22542570456896 run_lib.py:133] step: 425400, training_loss: 2.92955e-02
I0210 06:32:26.168482 22542570456896 run_lib.py:146] step: 425400, eval_loss: 2.57777e-02
I0210 06:32:43.673296 22542570456896 run_lib.py:133] step: 425450, training_loss: 3.19712e-02
I0210 06:33:01.080748 22542570456896 run_lib.py:133] step: 425500, training_loss: 2.54394e-02
I0210 06:33:01.238379 22542570456896 run_lib.py:146] step: 425500, eval_loss: 2.59584e-02
I0210 06:33:18.816662 22542570456896 run_lib.py:133] step: 425550, training_loss: 2.50578e-02
I0210 06:33:36.267706 22542570456896 run_lib.py:133] step: 425600, training_loss: 2.36536e-02
I0210 06:33:36.423510 22542570456896 run_lib.py:146] step: 425600, eval_loss: 2.61556e-02
I0210 06:33:53.860675 22542570456896 run_lib.py:133] step: 425650, training_loss: 2.72136e-02
I0210 06:34:11.441139 22542570456896 run_lib.py:133] step: 425700, training_loss: 2.54599e-02
I0210 06:34:11.595088 22542570456896 run_lib.py:146] step: 425700, eval_loss: 2.31509e-02
I0210 06:34:28.982988 22542570456896 run_lib.py:133] step: 425750, training_loss: 2.29191e-02
I0210 06:34:46.433136 22542570456896 run_lib.py:133] step: 425800, training_loss: 3.01309e-02
I0210 06:34:46.586338 22542570456896 run_lib.py:146] step: 425800, eval_loss: 2.98841e-02
I0210 06:35:04.202394 22542570456896 run_lib.py:133] step: 425850, training_loss: 2.55199e-02
I0210 06:35:21.836194 22542570456896 run_lib.py:133] step: 425900, training_loss: 2.59103e-02
I0210 06:35:21.994577 22542570456896 run_lib.py:146] step: 425900, eval_loss: 2.60551e-02
I0210 06:35:39.439882 22542570456896 run_lib.py:133] step: 425950, training_loss: 2.70302e-02
I0210 06:35:56.870025 22542570456896 run_lib.py:133] step: 426000, training_loss: 2.97308e-02
I0210 06:35:57.025797 22542570456896 run_lib.py:146] step: 426000, eval_loss: 2.05459e-02
I0210 06:36:14.454487 22542570456896 run_lib.py:133] step: 426050, training_loss: 2.85465e-02
I0210 06:36:32.010233 22542570456896 run_lib.py:133] step: 426100, training_loss: 2.55160e-02
I0210 06:36:32.171130 22542570456896 run_lib.py:146] step: 426100, eval_loss: 3.20932e-02
I0210 06:36:49.613881 22542570456896 run_lib.py:133] step: 426150, training_loss: 3.18257e-02
I0210 06:37:07.062659 22542570456896 run_lib.py:133] step: 426200, training_loss: 3.32733e-02
I0210 06:37:07.217048 22542570456896 run_lib.py:146] step: 426200, eval_loss: 2.98587e-02
I0210 06:37:24.663723 22542570456896 run_lib.py:133] step: 426250, training_loss: 3.43267e-02
I0210 06:37:42.262013 22542570456896 run_lib.py:133] step: 426300, training_loss: 3.62441e-02
I0210 06:37:42.415356 22542570456896 run_lib.py:146] step: 426300, eval_loss: 2.92783e-02
I0210 06:37:59.850709 22542570456896 run_lib.py:133] step: 426350, training_loss: 2.59191e-02
I0210 06:38:17.293576 22542570456896 run_lib.py:133] step: 426400, training_loss: 2.81475e-02
I0210 06:38:17.458434 22542570456896 run_lib.py:146] step: 426400, eval_loss: 3.05800e-02
I0210 06:38:34.904314 22542570456896 run_lib.py:133] step: 426450, training_loss: 2.55539e-02
I0210 06:38:52.356930 22542570456896 run_lib.py:133] step: 426500, training_loss: 3.10860e-02
I0210 06:38:52.521452 22542570456896 run_lib.py:146] step: 426500, eval_loss: 2.73340e-02
I0210 06:39:10.121279 22542570456896 run_lib.py:133] step: 426550, training_loss: 2.72595e-02
I0210 06:39:27.642947 22542570456896 run_lib.py:133] step: 426600, training_loss: 2.20019e-02
I0210 06:39:27.801521 22542570456896 run_lib.py:146] step: 426600, eval_loss: 2.58791e-02
I0210 06:39:45.226599 22542570456896 run_lib.py:133] step: 426650, training_loss: 2.20586e-02
I0210 06:40:02.648579 22542570456896 run_lib.py:133] step: 426700, training_loss: 2.88675e-02
I0210 06:40:02.809324 22542570456896 run_lib.py:146] step: 426700, eval_loss: 2.81870e-02
I0210 06:40:20.416085 22542570456896 run_lib.py:133] step: 426750, training_loss: 2.28643e-02
I0210 06:40:37.853339 22542570456896 run_lib.py:133] step: 426800, training_loss: 3.07007e-02
I0210 06:40:38.009679 22542570456896 run_lib.py:146] step: 426800, eval_loss: 3.66170e-02
I0210 06:40:55.620431 22542570456896 run_lib.py:133] step: 426850, training_loss: 3.30634e-02
I0210 06:41:13.056127 22542570456896 run_lib.py:133] step: 426900, training_loss: 2.93778e-02
I0210 06:41:13.215614 22542570456896 run_lib.py:146] step: 426900, eval_loss: 2.52229e-02
I0210 06:41:30.796482 22542570456896 run_lib.py:133] step: 426950, training_loss: 2.76159e-02
I0210 06:41:48.246536 22542570456896 run_lib.py:133] step: 427000, training_loss: 2.70796e-02
I0210 06:41:48.411322 22542570456896 run_lib.py:146] step: 427000, eval_loss: 3.82085e-02
I0210 06:42:05.862058 22542570456896 run_lib.py:133] step: 427050, training_loss: 2.93639e-02
I0210 06:42:23.514458 22542570456896 run_lib.py:133] step: 427100, training_loss: 2.53348e-02
I0210 06:42:23.668152 22542570456896 run_lib.py:146] step: 427100, eval_loss: 2.03429e-02
I0210 06:42:41.157159 22542570456896 run_lib.py:133] step: 427150, training_loss: 2.81251e-02
I0210 06:42:58.735727 22542570456896 run_lib.py:133] step: 427200, training_loss: 2.44967e-02
I0210 06:42:58.887397 22542570456896 run_lib.py:146] step: 427200, eval_loss: 2.77725e-02
I0210 06:43:16.311914 22542570456896 run_lib.py:133] step: 427250, training_loss: 2.82109e-02
I0210 06:43:33.764405 22542570456896 run_lib.py:133] step: 427300, training_loss: 3.35344e-02
I0210 06:43:33.931584 22542570456896 run_lib.py:146] step: 427300, eval_loss: 1.93208e-02
I0210 06:43:51.571206 22542570456896 run_lib.py:133] step: 427350, training_loss: 3.13229e-02
I0210 06:44:09.012437 22542570456896 run_lib.py:133] step: 427400, training_loss: 2.57129e-02
I0210 06:44:09.179235 22542570456896 run_lib.py:146] step: 427400, eval_loss: 3.26538e-02
I0210 06:44:26.606714 22542570456896 run_lib.py:133] step: 427450, training_loss: 3.80757e-02
I0210 06:44:44.218271 22542570456896 run_lib.py:133] step: 427500, training_loss: 2.98284e-02
I0210 06:44:44.373341 22542570456896 run_lib.py:146] step: 427500, eval_loss: 2.68938e-02
I0210 06:45:01.818551 22542570456896 run_lib.py:133] step: 427550, training_loss: 3.01288e-02
I0210 06:45:19.316107 22542570456896 run_lib.py:133] step: 427600, training_loss: 2.54094e-02
I0210 06:45:19.470672 22542570456896 run_lib.py:146] step: 427600, eval_loss: 3.14537e-02
I0210 06:45:37.036383 22542570456896 run_lib.py:133] step: 427650, training_loss: 2.50978e-02
I0210 06:45:54.494281 22542570456896 run_lib.py:133] step: 427700, training_loss: 2.47585e-02
I0210 06:45:54.647432 22542570456896 run_lib.py:146] step: 427700, eval_loss: 2.89183e-02
I0210 06:46:12.053757 22542570456896 run_lib.py:133] step: 427750, training_loss: 2.66019e-02
I0210 06:46:29.458197 22542570456896 run_lib.py:133] step: 427800, training_loss: 2.73807e-02
I0210 06:46:29.635352 22542570456896 run_lib.py:146] step: 427800, eval_loss: 2.91383e-02
I0210 06:46:47.253016 22542570456896 run_lib.py:133] step: 427850, training_loss: 3.56060e-02
I0210 06:47:04.809810 22542570456896 run_lib.py:133] step: 427900, training_loss: 2.39401e-02
I0210 06:47:04.964432 22542570456896 run_lib.py:146] step: 427900, eval_loss: 3.12413e-02
I0210 06:47:22.375878 22542570456896 run_lib.py:133] step: 427950, training_loss: 2.79123e-02
I0210 06:47:39.831982 22542570456896 run_lib.py:133] step: 428000, training_loss: 3.11539e-02
I0210 06:47:39.987439 22542570456896 run_lib.py:146] step: 428000, eval_loss: 2.75798e-02
I0210 06:47:57.534836 22542570456896 run_lib.py:133] step: 428050, training_loss: 2.78966e-02
I0210 06:48:14.955095 22542570456896 run_lib.py:133] step: 428100, training_loss: 2.70242e-02
I0210 06:48:15.114151 22542570456896 run_lib.py:146] step: 428100, eval_loss: 2.87609e-02
I0210 06:48:32.698680 22542570456896 run_lib.py:133] step: 428150, training_loss: 2.20806e-02
I0210 06:48:50.122844 22542570456896 run_lib.py:133] step: 428200, training_loss: 2.13775e-02
I0210 06:48:50.281682 22542570456896 run_lib.py:146] step: 428200, eval_loss: 3.37841e-02
I0210 06:49:07.916021 22542570456896 run_lib.py:133] step: 428250, training_loss: 3.53968e-02
I0210 06:49:25.363639 22542570456896 run_lib.py:133] step: 428300, training_loss: 2.37744e-02
I0210 06:49:25.522645 22542570456896 run_lib.py:146] step: 428300, eval_loss: 2.13225e-02
I0210 06:49:43.043170 22542570456896 run_lib.py:133] step: 428350, training_loss: 3.24372e-02
I0210 06:50:00.419707 22542570456896 run_lib.py:133] step: 428400, training_loss: 2.42731e-02
I0210 06:50:00.582417 22542570456896 run_lib.py:146] step: 428400, eval_loss: 2.85459e-02
I0210 06:50:18.036320 22542570456896 run_lib.py:133] step: 428450, training_loss: 2.22931e-02
I0210 06:50:35.624307 22542570456896 run_lib.py:133] step: 428500, training_loss: 2.63396e-02
I0210 06:50:35.780637 22542570456896 run_lib.py:146] step: 428500, eval_loss: 2.61866e-02
I0210 06:50:53.167239 22542570456896 run_lib.py:133] step: 428550, training_loss: 2.31829e-02
I0210 06:51:10.574814 22542570456896 run_lib.py:133] step: 428600, training_loss: 3.32701e-02
I0210 06:51:10.735141 22542570456896 run_lib.py:146] step: 428600, eval_loss: 2.81622e-02
I0210 06:51:28.338634 22542570456896 run_lib.py:133] step: 428650, training_loss: 2.77533e-02
I0210 06:51:45.767492 22542570456896 run_lib.py:133] step: 428700, training_loss: 2.87364e-02
I0210 06:51:45.929630 22542570456896 run_lib.py:146] step: 428700, eval_loss: 3.26679e-02
I0210 06:52:03.550208 22542570456896 run_lib.py:133] step: 428750, training_loss: 2.71374e-02
I0210 06:52:21.012173 22542570456896 run_lib.py:133] step: 428800, training_loss: 2.77203e-02
I0210 06:52:21.171416 22542570456896 run_lib.py:146] step: 428800, eval_loss: 2.48012e-02
I0210 06:52:38.626140 22542570456896 run_lib.py:133] step: 428850, training_loss: 2.77378e-02
I0210 06:52:56.227347 22542570456896 run_lib.py:133] step: 428900, training_loss: 2.81575e-02
I0210 06:52:56.388611 22542570456896 run_lib.py:146] step: 428900, eval_loss: 2.42936e-02
I0210 06:53:13.792242 22542570456896 run_lib.py:133] step: 428950, training_loss: 2.48066e-02
I0210 06:53:31.232974 22542570456896 run_lib.py:133] step: 429000, training_loss: 2.79245e-02
I0210 06:53:31.388627 22542570456896 run_lib.py:146] step: 429000, eval_loss: 2.75370e-02
I0210 06:53:48.839866 22542570456896 run_lib.py:133] step: 429050, training_loss: 2.62447e-02
I0210 06:54:06.443919 22542570456896 run_lib.py:133] step: 429100, training_loss: 2.94374e-02
I0210 06:54:06.594997 22542570456896 run_lib.py:146] step: 429100, eval_loss: 2.54917e-02
I0210 06:54:24.023855 22542570456896 run_lib.py:133] step: 429150, training_loss: 2.89007e-02
I0210 06:54:41.491307 22542570456896 run_lib.py:133] step: 429200, training_loss: 2.53669e-02
I0210 06:54:41.645403 22542570456896 run_lib.py:146] step: 429200, eval_loss: 3.17056e-02
I0210 06:54:59.059864 22542570456896 run_lib.py:133] step: 429250, training_loss: 2.66331e-02
I0210 06:55:16.529022 22542570456896 run_lib.py:133] step: 429300, training_loss: 2.71055e-02
I0210 06:55:16.688335 22542570456896 run_lib.py:146] step: 429300, eval_loss: 2.61562e-02
I0210 06:55:34.270724 22542570456896 run_lib.py:133] step: 429350, training_loss: 2.97264e-02
I0210 06:55:51.737769 22542570456896 run_lib.py:133] step: 429400, training_loss: 2.53543e-02
I0210 06:55:51.891204 22542570456896 run_lib.py:146] step: 429400, eval_loss: 2.42779e-02
I0210 06:56:09.313143 22542570456896 run_lib.py:133] step: 429450, training_loss: 2.53578e-02
I0210 06:56:26.738015 22542570456896 run_lib.py:133] step: 429500, training_loss: 2.55166e-02
I0210 06:56:26.896406 22542570456896 run_lib.py:146] step: 429500, eval_loss: 2.88628e-02
I0210 06:56:44.531424 22542570456896 run_lib.py:133] step: 429550, training_loss: 2.98324e-02
I0210 06:57:01.992950 22542570456896 run_lib.py:133] step: 429600, training_loss: 3.01396e-02
I0210 06:57:02.148287 22542570456896 run_lib.py:146] step: 429600, eval_loss: 2.91193e-02
I0210 06:57:19.819352 22542570456896 run_lib.py:133] step: 429650, training_loss: 2.66839e-02
I0210 06:57:37.259745 22542570456896 run_lib.py:133] step: 429700, training_loss: 3.08276e-02
I0210 06:57:37.419584 22542570456896 run_lib.py:146] step: 429700, eval_loss: 3.09630e-02
I0210 06:57:54.984876 22542570456896 run_lib.py:133] step: 429750, training_loss: 2.73709e-02
I0210 06:58:12.403241 22542570456896 run_lib.py:133] step: 429800, training_loss: 3.02085e-02
I0210 06:58:12.558408 22542570456896 run_lib.py:146] step: 429800, eval_loss: 3.18728e-02
I0210 06:58:30.006270 22542570456896 run_lib.py:133] step: 429850, training_loss: 2.57560e-02
I0210 06:58:47.656498 22542570456896 run_lib.py:133] step: 429900, training_loss: 2.27885e-02
I0210 06:58:47.813585 22542570456896 run_lib.py:146] step: 429900, eval_loss: 3.45183e-02
I0210 06:59:05.302659 22542570456896 run_lib.py:133] step: 429950, training_loss: 2.90883e-02
I0210 06:59:22.901502 22542570456896 run_lib.py:133] step: 430000, training_loss: 2.65192e-02
I0210 06:59:23.601036 22542570456896 run_lib.py:146] step: 430000, eval_loss: 2.95378e-02
I0210 06:59:43.972085 22542570456896 run_lib.py:133] step: 430050, training_loss: 3.03309e-02
I0210 07:00:01.346729 22542570456896 run_lib.py:133] step: 430100, training_loss: 3.48489e-02
I0210 07:00:01.498393 22542570456896 run_lib.py:146] step: 430100, eval_loss: 2.70480e-02
I0210 07:00:18.929630 22542570456896 run_lib.py:133] step: 430150, training_loss: 2.90769e-02
I0210 07:00:36.380632 22542570456896 run_lib.py:133] step: 430200, training_loss: 3.19354e-02
I0210 07:00:36.540581 22542570456896 run_lib.py:146] step: 430200, eval_loss: 2.91378e-02
I0210 07:00:54.171199 22542570456896 run_lib.py:133] step: 430250, training_loss: 2.67607e-02
I0210 07:01:11.645160 22542570456896 run_lib.py:133] step: 430300, training_loss: 3.15107e-02
I0210 07:01:11.803633 22542570456896 run_lib.py:146] step: 430300, eval_loss: 2.68153e-02
I0210 07:01:29.219677 22542570456896 run_lib.py:133] step: 430350, training_loss: 2.85162e-02
I0210 07:01:46.630784 22542570456896 run_lib.py:133] step: 430400, training_loss: 2.63345e-02
I0210 07:01:46.796414 22542570456896 run_lib.py:146] step: 430400, eval_loss: 3.04251e-02
I0210 07:02:04.409553 22542570456896 run_lib.py:133] step: 430450, training_loss: 2.53070e-02
I0210 07:02:21.847249 22542570456896 run_lib.py:133] step: 430500, training_loss: 2.52011e-02
I0210 07:02:22.002209 22542570456896 run_lib.py:146] step: 430500, eval_loss: 2.94594e-02
I0210 07:02:39.612573 22542570456896 run_lib.py:133] step: 430550, training_loss: 2.81933e-02
I0210 07:02:57.043928 22542570456896 run_lib.py:133] step: 430600, training_loss: 2.11727e-02
I0210 07:02:57.204326 22542570456896 run_lib.py:146] step: 430600, eval_loss: 3.21977e-02
I0210 07:03:14.732608 22542570456896 run_lib.py:133] step: 430650, training_loss: 2.83406e-02
I0210 07:03:32.100757 22542570456896 run_lib.py:133] step: 430700, training_loss: 2.95323e-02
I0210 07:03:32.270165 22542570456896 run_lib.py:146] step: 430700, eval_loss: 1.94375e-02
I0210 07:03:49.928577 22542570456896 run_lib.py:133] step: 430750, training_loss: 2.14406e-02
I0210 07:04:07.428115 22542570456896 run_lib.py:133] step: 430800, training_loss: 2.48570e-02
I0210 07:04:07.587466 22542570456896 run_lib.py:146] step: 430800, eval_loss: 2.29951e-02
I0210 07:04:25.027436 22542570456896 run_lib.py:133] step: 430850, training_loss: 2.43874e-02
I0210 07:04:42.601706 22542570456896 run_lib.py:133] step: 430900, training_loss: 2.43792e-02
I0210 07:04:42.756309 22542570456896 run_lib.py:146] step: 430900, eval_loss: 3.38542e-02
I0210 07:05:00.180350 22542570456896 run_lib.py:133] step: 430950, training_loss: 2.84981e-02
I0210 07:05:17.648192 22542570456896 run_lib.py:133] step: 431000, training_loss: 2.88626e-02
I0210 07:05:17.803536 22542570456896 run_lib.py:146] step: 431000, eval_loss: 3.05166e-02
I0210 07:05:35.453913 22542570456896 run_lib.py:133] step: 431050, training_loss: 2.01123e-02
I0210 07:05:53.010194 22542570456896 run_lib.py:133] step: 431100, training_loss: 2.55107e-02
I0210 07:05:53.162353 22542570456896 run_lib.py:146] step: 431100, eval_loss: 2.62117e-02
I0210 07:06:10.555018 22542570456896 run_lib.py:133] step: 431150, training_loss: 2.37230e-02
I0210 07:06:27.977436 22542570456896 run_lib.py:133] step: 431200, training_loss: 2.82804e-02
I0210 07:06:28.136612 22542570456896 run_lib.py:146] step: 431200, eval_loss: 2.25868e-02
I0210 07:06:45.576442 22542570456896 run_lib.py:133] step: 431250, training_loss: 2.40096e-02
I0210 07:07:03.207325 22542570456896 run_lib.py:133] step: 431300, training_loss: 2.80326e-02
I0210 07:07:03.363652 22542570456896 run_lib.py:146] step: 431300, eval_loss: 3.25335e-02
I0210 07:07:20.748832 22542570456896 run_lib.py:133] step: 431350, training_loss: 1.98876e-02
I0210 07:07:38.163686 22542570456896 run_lib.py:133] step: 431400, training_loss: 2.67414e-02
I0210 07:07:38.319079 22542570456896 run_lib.py:146] step: 431400, eval_loss: 3.03819e-02
I0210 07:07:55.729857 22542570456896 run_lib.py:133] step: 431450, training_loss: 2.48899e-02
I0210 07:08:13.314054 22542570456896 run_lib.py:133] step: 431500, training_loss: 3.29964e-02
I0210 07:08:13.467123 22542570456896 run_lib.py:146] step: 431500, eval_loss: 2.84047e-02
I0210 07:08:30.925776 22542570456896 run_lib.py:133] step: 431550, training_loss: 2.62142e-02
I0210 07:08:48.471016 22542570456896 run_lib.py:133] step: 431600, training_loss: 2.93450e-02
I0210 07:08:48.633486 22542570456896 run_lib.py:146] step: 431600, eval_loss: 2.43116e-02
I0210 07:09:06.019937 22542570456896 run_lib.py:133] step: 431650, training_loss: 2.95017e-02
I0210 07:09:23.463298 22542570456896 run_lib.py:133] step: 431700, training_loss: 2.76861e-02
I0210 07:09:23.623017 22542570456896 run_lib.py:146] step: 431700, eval_loss: 2.91546e-02
I0210 07:09:41.142567 22542570456896 run_lib.py:133] step: 431750, training_loss: 2.73359e-02
I0210 07:09:58.634495 22542570456896 run_lib.py:133] step: 431800, training_loss: 2.56000e-02
I0210 07:09:58.804394 22542570456896 run_lib.py:146] step: 431800, eval_loss: 2.21837e-02
I0210 07:10:16.231496 22542570456896 run_lib.py:133] step: 431850, training_loss: 3.62622e-02
I0210 07:10:33.649597 22542570456896 run_lib.py:133] step: 431900, training_loss: 3.61963e-02
I0210 07:10:33.805079 22542570456896 run_lib.py:146] step: 431900, eval_loss: 2.95440e-02
I0210 07:10:51.411889 22542570456896 run_lib.py:133] step: 431950, training_loss: 3.19325e-02
I0210 07:11:08.816240 22542570456896 run_lib.py:133] step: 432000, training_loss: 2.75753e-02
I0210 07:11:08.967259 22542570456896 run_lib.py:146] step: 432000, eval_loss: 2.49736e-02
I0210 07:11:26.505634 22542570456896 run_lib.py:133] step: 432050, training_loss: 2.42423e-02
I0210 07:11:43.928740 22542570456896 run_lib.py:133] step: 432100, training_loss: 2.49178e-02
I0210 07:11:44.098519 22542570456896 run_lib.py:146] step: 432100, eval_loss: 3.10868e-02
I0210 07:12:01.723218 22542570456896 run_lib.py:133] step: 432150, training_loss: 3.26199e-02
I0210 07:12:19.167202 22542570456896 run_lib.py:133] step: 432200, training_loss: 2.63823e-02
I0210 07:12:19.329644 22542570456896 run_lib.py:146] step: 432200, eval_loss: 3.72724e-02
I0210 07:12:36.751450 22542570456896 run_lib.py:133] step: 432250, training_loss: 2.51329e-02
I0210 07:12:54.311684 22542570456896 run_lib.py:133] step: 432300, training_loss: 2.18028e-02
I0210 07:12:54.466364 22542570456896 run_lib.py:146] step: 432300, eval_loss: 2.67273e-02
I0210 07:13:11.904810 22542570456896 run_lib.py:133] step: 432350, training_loss: 3.00724e-02
I0210 07:13:29.566667 22542570456896 run_lib.py:133] step: 432400, training_loss: 2.41224e-02
I0210 07:13:29.730300 22542570456896 run_lib.py:146] step: 432400, eval_loss: 3.55955e-02
I0210 07:13:47.178963 22542570456896 run_lib.py:133] step: 432450, training_loss: 2.78621e-02
I0210 07:14:04.568005 22542570456896 run_lib.py:133] step: 432500, training_loss: 2.46946e-02
I0210 07:14:04.716128 22542570456896 run_lib.py:146] step: 432500, eval_loss: 3.32862e-02
I0210 07:14:22.312309 22542570456896 run_lib.py:133] step: 432550, training_loss: 3.27211e-02
I0210 07:14:39.719588 22542570456896 run_lib.py:133] step: 432600, training_loss: 2.73387e-02
I0210 07:14:39.882501 22542570456896 run_lib.py:146] step: 432600, eval_loss: 2.22673e-02
I0210 07:14:57.329242 22542570456896 run_lib.py:133] step: 432650, training_loss: 2.53698e-02
I0210 07:15:14.947875 22542570456896 run_lib.py:133] step: 432700, training_loss: 2.32221e-02
I0210 07:15:15.105467 22542570456896 run_lib.py:146] step: 432700, eval_loss: 3.49174e-02
I0210 07:15:32.570366 22542570456896 run_lib.py:133] step: 432750, training_loss: 2.98466e-02
I0210 07:15:49.992929 22542570456896 run_lib.py:133] step: 432800, training_loss: 2.50848e-02
I0210 07:15:50.147142 22542570456896 run_lib.py:146] step: 432800, eval_loss: 2.61990e-02
I0210 07:16:07.659256 22542570456896 run_lib.py:133] step: 432850, training_loss: 2.91855e-02
I0210 07:16:25.054407 22542570456896 run_lib.py:133] step: 432900, training_loss: 3.19291e-02
I0210 07:16:25.212422 22542570456896 run_lib.py:146] step: 432900, eval_loss: 2.65382e-02
I0210 07:16:42.705387 22542570456896 run_lib.py:133] step: 432950, training_loss: 3.49328e-02
I0210 07:17:00.141774 22542570456896 run_lib.py:133] step: 433000, training_loss: 2.65140e-02
I0210 07:17:00.303395 22542570456896 run_lib.py:146] step: 433000, eval_loss: 2.95523e-02
I0210 07:17:17.901627 22542570456896 run_lib.py:133] step: 433050, training_loss: 2.93265e-02
I0210 07:17:35.395349 22542570456896 run_lib.py:133] step: 433100, training_loss: 2.95886e-02
I0210 07:17:35.562559 22542570456896 run_lib.py:146] step: 433100, eval_loss: 2.94521e-02
I0210 07:17:52.993409 22542570456896 run_lib.py:133] step: 433150, training_loss: 2.90717e-02
I0210 07:18:10.423583 22542570456896 run_lib.py:133] step: 433200, training_loss: 2.32989e-02
I0210 07:18:10.592378 22542570456896 run_lib.py:146] step: 433200, eval_loss: 3.00569e-02
I0210 07:18:28.177312 22542570456896 run_lib.py:133] step: 433250, training_loss: 2.92793e-02
I0210 07:18:45.624324 22542570456896 run_lib.py:133] step: 433300, training_loss: 2.71183e-02
I0210 07:18:45.780526 22542570456896 run_lib.py:146] step: 433300, eval_loss: 3.38995e-02
I0210 07:19:03.381933 22542570456896 run_lib.py:133] step: 433350, training_loss: 2.61870e-02
I0210 07:19:20.829557 22542570456896 run_lib.py:133] step: 433400, training_loss: 2.37649e-02
I0210 07:19:20.981461 22542570456896 run_lib.py:146] step: 433400, eval_loss: 3.18967e-02
I0210 07:19:38.533191 22542570456896 run_lib.py:133] step: 433450, training_loss: 2.99176e-02
I0210 07:19:55.985195 22542570456896 run_lib.py:133] step: 433500, training_loss: 2.85525e-02
I0210 07:19:56.160426 22542570456896 run_lib.py:146] step: 433500, eval_loss: 2.83158e-02
I0210 07:20:13.774870 22542570456896 run_lib.py:133] step: 433550, training_loss: 2.36707e-02
I0210 07:20:31.263309 22542570456896 run_lib.py:133] step: 433600, training_loss: 3.32041e-02
I0210 07:20:31.428292 22542570456896 run_lib.py:146] step: 433600, eval_loss: 3.03519e-02
I0210 07:20:48.836311 22542570456896 run_lib.py:133] step: 433650, training_loss: 2.29089e-02
I0210 07:21:06.437387 22542570456896 run_lib.py:133] step: 433700, training_loss: 3.35740e-02
I0210 07:21:06.592862 22542570456896 run_lib.py:146] step: 433700, eval_loss: 2.89696e-02
I0210 07:21:24.011905 22542570456896 run_lib.py:133] step: 433750, training_loss: 2.91829e-02
I0210 07:21:41.447559 22542570456896 run_lib.py:133] step: 433800, training_loss: 2.83081e-02
I0210 07:21:41.603340 22542570456896 run_lib.py:146] step: 433800, eval_loss: 3.39945e-02
I0210 07:21:59.221112 22542570456896 run_lib.py:133] step: 433850, training_loss: 2.80754e-02
I0210 07:22:16.667667 22542570456896 run_lib.py:133] step: 433900, training_loss: 2.79477e-02
I0210 07:22:16.827450 22542570456896 run_lib.py:146] step: 433900, eval_loss: 2.99578e-02
I0210 07:22:34.475594 22542570456896 run_lib.py:133] step: 433950, training_loss: 1.97336e-02
I0210 07:22:51.878513 22542570456896 run_lib.py:133] step: 434000, training_loss: 3.56538e-02
I0210 07:22:52.034368 22542570456896 run_lib.py:146] step: 434000, eval_loss: 3.00302e-02
I0210 07:23:09.464441 22542570456896 run_lib.py:133] step: 434050, training_loss: 2.73284e-02
I0210 07:23:27.045564 22542570456896 run_lib.py:133] step: 434100, training_loss: 2.49695e-02
I0210 07:23:27.220427 22542570456896 run_lib.py:146] step: 434100, eval_loss: 2.94567e-02
I0210 07:23:44.693523 22542570456896 run_lib.py:133] step: 434150, training_loss: 2.75055e-02
I0210 07:24:02.158145 22542570456896 run_lib.py:133] step: 434200, training_loss: 2.71249e-02
I0210 07:24:02.315146 22542570456896 run_lib.py:146] step: 434200, eval_loss: 3.44006e-02
I0210 07:24:19.750144 22542570456896 run_lib.py:133] step: 434250, training_loss: 2.79137e-02
I0210 07:24:37.360547 22542570456896 run_lib.py:133] step: 434300, training_loss: 2.89944e-02
I0210 07:24:37.513841 22542570456896 run_lib.py:146] step: 434300, eval_loss: 2.67789e-02
I0210 07:24:54.920199 22542570456896 run_lib.py:133] step: 434350, training_loss: 2.97152e-02
I0210 07:25:12.440808 22542570456896 run_lib.py:133] step: 434400, training_loss: 3.79611e-02
I0210 07:25:12.596537 22542570456896 run_lib.py:146] step: 434400, eval_loss: 3.09748e-02
I0210 07:25:30.042611 22542570456896 run_lib.py:133] step: 434450, training_loss: 2.77644e-02
I0210 07:25:47.466704 22542570456896 run_lib.py:133] step: 434500, training_loss: 3.04513e-02
I0210 07:25:47.626757 22542570456896 run_lib.py:146] step: 434500, eval_loss: 3.14233e-02
I0210 07:26:05.224517 22542570456896 run_lib.py:133] step: 434550, training_loss: 2.89082e-02
I0210 07:26:22.697307 22542570456896 run_lib.py:133] step: 434600, training_loss: 2.67046e-02
I0210 07:26:22.857629 22542570456896 run_lib.py:146] step: 434600, eval_loss: 2.75811e-02
I0210 07:26:40.306743 22542570456896 run_lib.py:133] step: 434650, training_loss: 3.76390e-02
I0210 07:26:57.749926 22542570456896 run_lib.py:133] step: 434700, training_loss: 2.73359e-02
I0210 07:26:57.912734 22542570456896 run_lib.py:146] step: 434700, eval_loss: 2.29243e-02
I0210 07:27:15.432564 22542570456896 run_lib.py:133] step: 434750, training_loss: 2.61125e-02
I0210 07:27:32.739152 22542570456896 run_lib.py:133] step: 434800, training_loss: 2.56566e-02
I0210 07:27:32.894270 22542570456896 run_lib.py:146] step: 434800, eval_loss: 3.06981e-02
I0210 07:27:50.340745 22542570456896 run_lib.py:133] step: 434850, training_loss: 3.04066e-02
I0210 07:28:07.683568 22542570456896 run_lib.py:133] step: 434900, training_loss: 2.23431e-02
I0210 07:28:07.838244 22542570456896 run_lib.py:146] step: 434900, eval_loss: 2.53114e-02
I0210 07:28:25.493349 22542570456896 run_lib.py:133] step: 434950, training_loss: 2.88841e-02
I0210 07:28:42.967373 22542570456896 run_lib.py:133] step: 435000, training_loss: 3.37290e-02
I0210 07:28:43.127331 22542570456896 run_lib.py:146] step: 435000, eval_loss: 2.86675e-02
I0210 07:29:00.521458 22542570456896 run_lib.py:133] step: 435050, training_loss: 3.00522e-02
I0210 07:29:18.080798 22542570456896 run_lib.py:133] step: 435100, training_loss: 2.91180e-02
I0210 07:29:18.236485 22542570456896 run_lib.py:146] step: 435100, eval_loss: 3.07399e-02
I0210 07:29:35.700369 22542570456896 run_lib.py:133] step: 435150, training_loss: 3.05059e-02
I0210 07:29:53.320609 22542570456896 run_lib.py:133] step: 435200, training_loss: 2.41693e-02
I0210 07:29:53.477937 22542570456896 run_lib.py:146] step: 435200, eval_loss: 3.35066e-02
I0210 07:30:10.933256 22542570456896 run_lib.py:133] step: 435250, training_loss: 2.32335e-02
I0210 07:30:28.368972 22542570456896 run_lib.py:133] step: 435300, training_loss: 3.16446e-02
I0210 07:30:28.521412 22542570456896 run_lib.py:146] step: 435300, eval_loss: 2.75743e-02
I0210 07:30:46.156846 22542570456896 run_lib.py:133] step: 435350, training_loss: 2.30130e-02
I0210 07:31:03.595372 22542570456896 run_lib.py:133] step: 435400, training_loss: 3.67628e-02
I0210 07:31:03.750881 22542570456896 run_lib.py:146] step: 435400, eval_loss: 2.60382e-02
I0210 07:31:21.156782 22542570456896 run_lib.py:133] step: 435450, training_loss: 2.72730e-02
I0210 07:31:38.751156 22542570456896 run_lib.py:133] step: 435500, training_loss: 2.88464e-02
I0210 07:31:38.912253 22542570456896 run_lib.py:146] step: 435500, eval_loss: 2.50793e-02
I0210 07:31:56.373924 22542570456896 run_lib.py:133] step: 435550, training_loss: 3.06464e-02
I0210 07:32:13.808150 22542570456896 run_lib.py:133] step: 435600, training_loss: 2.80224e-02
I0210 07:32:14.147247 22542570456896 run_lib.py:146] step: 435600, eval_loss: 2.94603e-02
I0210 07:32:31.560256 22542570456896 run_lib.py:133] step: 435650, training_loss: 3.17636e-02
I0210 07:32:48.976016 22542570456896 run_lib.py:133] step: 435700, training_loss: 4.03064e-02
I0210 07:32:49.131290 22542570456896 run_lib.py:146] step: 435700, eval_loss: 3.25923e-02
I0210 07:33:06.562701 22542570456896 run_lib.py:133] step: 435750, training_loss: 3.04272e-02
I0210 07:33:24.022980 22542570456896 run_lib.py:133] step: 435800, training_loss: 2.67130e-02
I0210 07:33:24.177568 22542570456896 run_lib.py:146] step: 435800, eval_loss: 2.47027e-02
I0210 07:33:41.842151 22542570456896 run_lib.py:133] step: 435850, training_loss: 4.02358e-02
I0210 07:33:59.388692 22542570456896 run_lib.py:133] step: 435900, training_loss: 3.11484e-02
I0210 07:33:59.544363 22542570456896 run_lib.py:146] step: 435900, eval_loss: 3.01753e-02
I0210 07:34:16.954062 22542570456896 run_lib.py:133] step: 435950, training_loss: 2.83167e-02
I0210 07:34:34.387013 22542570456896 run_lib.py:133] step: 436000, training_loss: 3.42295e-02
I0210 07:34:34.546686 22542570456896 run_lib.py:146] step: 436000, eval_loss: 3.64247e-02
I0210 07:34:52.154191 22542570456896 run_lib.py:133] step: 436050, training_loss: 2.56042e-02
I0210 07:35:09.718766 22542570456896 run_lib.py:133] step: 436100, training_loss: 2.86748e-02
I0210 07:35:09.874574 22542570456896 run_lib.py:146] step: 436100, eval_loss: 2.54484e-02
I0210 07:35:27.320517 22542570456896 run_lib.py:133] step: 436150, training_loss: 2.57674e-02
I0210 07:35:44.689971 22542570456896 run_lib.py:133] step: 436200, training_loss: 2.66561e-02
I0210 07:35:44.845998 22542570456896 run_lib.py:146] step: 436200, eval_loss: 3.72242e-02
I0210 07:36:02.415711 22542570456896 run_lib.py:133] step: 436250, training_loss: 2.68214e-02
I0210 07:36:19.824683 22542570456896 run_lib.py:133] step: 436300, training_loss: 2.56064e-02
I0210 07:36:19.979592 22542570456896 run_lib.py:146] step: 436300, eval_loss: 2.94479e-02
I0210 07:36:37.579490 22542570456896 run_lib.py:133] step: 436350, training_loss: 2.45641e-02
I0210 07:36:55.028230 22542570456896 run_lib.py:133] step: 436400, training_loss: 2.52552e-02
I0210 07:36:55.186286 22542570456896 run_lib.py:146] step: 436400, eval_loss: 2.78174e-02
I0210 07:37:12.863723 22542570456896 run_lib.py:133] step: 436450, training_loss: 2.73892e-02
I0210 07:37:30.312873 22542570456896 run_lib.py:133] step: 436500, training_loss: 2.51912e-02
I0210 07:37:30.471758 22542570456896 run_lib.py:146] step: 436500, eval_loss: 3.40195e-02
I0210 07:37:47.882848 22542570456896 run_lib.py:133] step: 436550, training_loss: 2.72101e-02
I0210 07:38:05.435684 22542570456896 run_lib.py:133] step: 436600, training_loss: 3.05958e-02
I0210 07:38:05.603080 22542570456896 run_lib.py:146] step: 436600, eval_loss: 2.73152e-02
I0210 07:38:23.045328 22542570456896 run_lib.py:133] step: 436650, training_loss: 2.54259e-02
I0210 07:38:40.680536 22542570456896 run_lib.py:133] step: 436700, training_loss: 2.52617e-02
I0210 07:38:40.837170 22542570456896 run_lib.py:146] step: 436700, eval_loss: 3.02863e-02
I0210 07:38:58.254610 22542570456896 run_lib.py:133] step: 436750, training_loss: 2.58749e-02
I0210 07:39:15.676518 22542570456896 run_lib.py:133] step: 436800, training_loss: 2.25437e-02
I0210 07:39:15.833332 22542570456896 run_lib.py:146] step: 436800, eval_loss: 3.35165e-02
I0210 07:39:33.378046 22542570456896 run_lib.py:133] step: 436850, training_loss: 2.51602e-02
I0210 07:39:50.782856 22542570456896 run_lib.py:133] step: 436900, training_loss: 3.21873e-02
I0210 07:39:50.959308 22542570456896 run_lib.py:146] step: 436900, eval_loss: 2.76860e-02
I0210 07:40:08.422720 22542570456896 run_lib.py:133] step: 436950, training_loss: 3.08103e-02
I0210 07:40:25.853081 22542570456896 run_lib.py:133] step: 437000, training_loss: 3.16648e-02
I0210 07:40:26.008675 22542570456896 run_lib.py:146] step: 437000, eval_loss: 2.74522e-02
I0210 07:40:43.615432 22542570456896 run_lib.py:133] step: 437050, training_loss: 2.39590e-02
I0210 07:41:01.025847 22542570456896 run_lib.py:133] step: 437100, training_loss: 2.81985e-02
I0210 07:41:01.182038 22542570456896 run_lib.py:146] step: 437100, eval_loss: 2.38955e-02
I0210 07:41:18.637077 22542570456896 run_lib.py:133] step: 437150, training_loss: 2.20711e-02
I0210 07:41:36.116360 22542570456896 run_lib.py:133] step: 437200, training_loss: 2.77928e-02
I0210 07:41:36.275830 22542570456896 run_lib.py:146] step: 437200, eval_loss: 2.57775e-02
I0210 07:41:53.736596 22542570456896 run_lib.py:133] step: 437250, training_loss: 2.89198e-02
I0210 07:42:11.144253 22542570456896 run_lib.py:133] step: 437300, training_loss: 2.05631e-02
I0210 07:42:11.299335 22542570456896 run_lib.py:146] step: 437300, eval_loss: 2.28497e-02
I0210 07:42:28.894815 22542570456896 run_lib.py:133] step: 437350, training_loss: 2.97761e-02
I0210 07:42:46.381098 22542570456896 run_lib.py:133] step: 437400, training_loss: 3.38233e-02
I0210 07:42:46.540536 22542570456896 run_lib.py:146] step: 437400, eval_loss: 2.71695e-02
I0210 07:43:04.018406 22542570456896 run_lib.py:133] step: 437450, training_loss: 3.30390e-02
I0210 07:43:21.477092 22542570456896 run_lib.py:133] step: 437500, training_loss: 3.09375e-02
I0210 07:43:21.633679 22542570456896 run_lib.py:146] step: 437500, eval_loss: 2.76463e-02
I0210 07:43:39.243905 22542570456896 run_lib.py:133] step: 437550, training_loss: 2.26525e-02
I0210 07:43:56.634673 22542570456896 run_lib.py:133] step: 437600, training_loss: 2.88761e-02
I0210 07:43:56.791379 22542570456896 run_lib.py:146] step: 437600, eval_loss: 3.05681e-02
I0210 07:44:14.377975 22542570456896 run_lib.py:133] step: 437650, training_loss: 3.24468e-02
I0210 07:44:31.856174 22542570456896 run_lib.py:133] step: 437700, training_loss: 3.24214e-02
I0210 07:44:32.010541 22542570456896 run_lib.py:146] step: 437700, eval_loss: 3.30729e-02
I0210 07:44:49.608642 22542570456896 run_lib.py:133] step: 437750, training_loss: 2.88547e-02
I0210 07:45:07.063250 22542570456896 run_lib.py:133] step: 437800, training_loss: 2.45889e-02
I0210 07:45:07.217369 22542570456896 run_lib.py:146] step: 437800, eval_loss: 2.47920e-02
I0210 07:45:24.852411 22542570456896 run_lib.py:133] step: 437850, training_loss: 2.55790e-02
I0210 07:45:42.268228 22542570456896 run_lib.py:133] step: 437900, training_loss: 2.39208e-02
I0210 07:45:42.425532 22542570456896 run_lib.py:146] step: 437900, eval_loss: 2.48351e-02
I0210 07:45:59.852552 22542570456896 run_lib.py:133] step: 437950, training_loss: 2.60738e-02
I0210 07:46:17.471897 22542570456896 run_lib.py:133] step: 438000, training_loss: 2.56904e-02
I0210 07:46:17.628599 22542570456896 run_lib.py:146] step: 438000, eval_loss: 2.97844e-02
I0210 07:46:35.076769 22542570456896 run_lib.py:133] step: 438050, training_loss: 2.91495e-02
I0210 07:46:52.495329 22542570456896 run_lib.py:133] step: 438100, training_loss: 2.75896e-02
I0210 07:46:52.658120 22542570456896 run_lib.py:146] step: 438100, eval_loss: 3.11350e-02
I0210 07:47:10.268031 22542570456896 run_lib.py:133] step: 438150, training_loss: 2.76096e-02
I0210 07:47:27.786422 22542570456896 run_lib.py:133] step: 438200, training_loss: 2.50411e-02
I0210 07:47:27.937419 22542570456896 run_lib.py:146] step: 438200, eval_loss: 2.99438e-02
I0210 07:47:45.408499 22542570456896 run_lib.py:133] step: 438250, training_loss: 2.43533e-02
I0210 07:48:02.851758 22542570456896 run_lib.py:133] step: 438300, training_loss: 2.64628e-02
I0210 07:48:03.024153 22542570456896 run_lib.py:146] step: 438300, eval_loss: 3.05875e-02
I0210 07:48:20.455475 22542570456896 run_lib.py:133] step: 438350, training_loss: 2.70288e-02
I0210 07:48:38.080207 22542570456896 run_lib.py:133] step: 438400, training_loss: 2.66666e-02
I0210 07:48:38.236565 22542570456896 run_lib.py:146] step: 438400, eval_loss: 2.58232e-02
I0210 07:48:55.695635 22542570456896 run_lib.py:133] step: 438450, training_loss: 3.09533e-02
I0210 07:49:13.125319 22542570456896 run_lib.py:133] step: 438500, training_loss: 2.38629e-02
I0210 07:49:13.281161 22542570456896 run_lib.py:146] step: 438500, eval_loss: 2.43806e-02
I0210 07:49:30.696909 22542570456896 run_lib.py:133] step: 438550, training_loss: 3.03801e-02
I0210 07:49:48.334973 22542570456896 run_lib.py:133] step: 438600, training_loss: 3.09667e-02
I0210 07:49:48.489136 22542570456896 run_lib.py:146] step: 438600, eval_loss: 2.97623e-02
I0210 07:50:05.981175 22542570456896 run_lib.py:133] step: 438650, training_loss: 2.54797e-02
I0210 07:50:23.459527 22542570456896 run_lib.py:133] step: 438700, training_loss: 2.49286e-02
I0210 07:50:23.609916 22542570456896 run_lib.py:146] step: 438700, eval_loss: 2.68198e-02
I0210 07:50:41.034799 22542570456896 run_lib.py:133] step: 438750, training_loss: 2.55841e-02
I0210 07:50:58.431680 22542570456896 run_lib.py:133] step: 438800, training_loss: 3.15535e-02
I0210 07:50:58.608367 22542570456896 run_lib.py:146] step: 438800, eval_loss: 2.86534e-02
I0210 07:51:16.269194 22542570456896 run_lib.py:133] step: 438850, training_loss: 3.34460e-02
I0210 07:51:33.775734 22542570456896 run_lib.py:133] step: 438900, training_loss: 2.42720e-02
I0210 07:51:33.934538 22542570456896 run_lib.py:146] step: 438900, eval_loss: 4.38647e-02
I0210 07:51:51.353975 22542570456896 run_lib.py:133] step: 438950, training_loss: 2.58407e-02
I0210 07:52:08.735348 22542570456896 run_lib.py:133] step: 439000, training_loss: 2.47715e-02
I0210 07:52:08.892521 22542570456896 run_lib.py:146] step: 439000, eval_loss: 3.26327e-02
I0210 07:52:26.462756 22542570456896 run_lib.py:133] step: 439050, training_loss: 2.89124e-02
I0210 07:52:43.938354 22542570456896 run_lib.py:133] step: 439100, training_loss: 2.97762e-02
I0210 07:52:44.091552 22542570456896 run_lib.py:146] step: 439100, eval_loss: 2.72101e-02
I0210 07:53:01.719317 22542570456896 run_lib.py:133] step: 439150, training_loss: 2.52770e-02
I0210 07:53:19.119173 22542570456896 run_lib.py:133] step: 439200, training_loss: 2.64894e-02
I0210 07:53:19.275496 22542570456896 run_lib.py:146] step: 439200, eval_loss: 3.18083e-02
I0210 07:53:36.837495 22542570456896 run_lib.py:133] step: 439250, training_loss: 2.58430e-02
I0210 07:53:54.247948 22542570456896 run_lib.py:133] step: 439300, training_loss: 2.62477e-02
I0210 07:53:54.407642 22542570456896 run_lib.py:146] step: 439300, eval_loss: 2.79168e-02
I0210 07:54:11.836620 22542570456896 run_lib.py:133] step: 439350, training_loss: 2.54648e-02
I0210 07:54:29.486971 22542570456896 run_lib.py:133] step: 439400, training_loss: 3.20332e-02
I0210 07:54:29.643579 22542570456896 run_lib.py:146] step: 439400, eval_loss: 2.99428e-02
I0210 07:54:47.073923 22542570456896 run_lib.py:133] step: 439450, training_loss: 1.84728e-02
I0210 07:55:04.663654 22542570456896 run_lib.py:133] step: 439500, training_loss: 2.40273e-02
I0210 07:55:04.825345 22542570456896 run_lib.py:146] step: 439500, eval_loss: 2.72938e-02
I0210 07:55:22.258896 22542570456896 run_lib.py:133] step: 439550, training_loss: 2.69772e-02
I0210 07:55:39.669930 22542570456896 run_lib.py:133] step: 439600, training_loss: 2.75662e-02
I0210 07:55:39.829447 22542570456896 run_lib.py:146] step: 439600, eval_loss: 3.03137e-02
I0210 07:55:57.415743 22542570456896 run_lib.py:133] step: 439650, training_loss: 2.44599e-02
I0210 07:56:14.869504 22542570456896 run_lib.py:133] step: 439700, training_loss: 2.78755e-02
I0210 07:56:15.047086 22542570456896 run_lib.py:146] step: 439700, eval_loss: 3.42274e-02
I0210 07:56:32.512486 22542570456896 run_lib.py:133] step: 439750, training_loss: 2.65195e-02
I0210 07:56:50.114161 22542570456896 run_lib.py:133] step: 439800, training_loss: 2.37169e-02
I0210 07:56:50.273538 22542570456896 run_lib.py:146] step: 439800, eval_loss: 3.70451e-02
I0210 07:57:07.692499 22542570456896 run_lib.py:133] step: 439850, training_loss: 2.65950e-02
I0210 07:57:25.081822 22542570456896 run_lib.py:133] step: 439900, training_loss: 2.59022e-02
I0210 07:57:25.253348 22542570456896 run_lib.py:146] step: 439900, eval_loss: 3.02851e-02
I0210 07:57:42.752397 22542570456896 run_lib.py:133] step: 439950, training_loss: 2.67597e-02
I0210 07:58:00.234959 22542570456896 run_lib.py:133] step: 440000, training_loss: 2.79289e-02
I0210 07:58:01.000007 22542570456896 run_lib.py:146] step: 440000, eval_loss: 3.50071e-02
I0210 07:58:21.035578 22542570456896 run_lib.py:133] step: 440050, training_loss: 3.56049e-02
I0210 07:58:38.431222 22542570456896 run_lib.py:133] step: 440100, training_loss: 3.36350e-02
I0210 07:58:38.584841 22542570456896 run_lib.py:146] step: 440100, eval_loss: 3.20305e-02
I0210 07:58:56.163594 22542570456896 run_lib.py:133] step: 440150, training_loss: 2.65451e-02
I0210 07:59:13.650728 22542570456896 run_lib.py:133] step: 440200, training_loss: 2.62104e-02
I0210 07:59:13.813574 22542570456896 run_lib.py:146] step: 440200, eval_loss: 2.54025e-02
I0210 07:59:31.342873 22542570456896 run_lib.py:133] step: 440250, training_loss: 2.64658e-02
I0210 07:59:48.782026 22542570456896 run_lib.py:133] step: 440300, training_loss: 2.35287e-02
I0210 07:59:48.940691 22542570456896 run_lib.py:146] step: 440300, eval_loss: 2.60232e-02
I0210 08:00:06.376481 22542570456896 run_lib.py:133] step: 440350, training_loss: 3.37985e-02
I0210 08:00:23.779609 22542570456896 run_lib.py:133] step: 440400, training_loss: 3.36117e-02
I0210 08:00:23.935398 22542570456896 run_lib.py:146] step: 440400, eval_loss: 3.03060e-02
I0210 08:00:41.560851 22542570456896 run_lib.py:133] step: 440450, training_loss: 2.97758e-02
I0210 08:00:59.084101 22542570456896 run_lib.py:133] step: 440500, training_loss: 2.68493e-02
I0210 08:00:59.242046 22542570456896 run_lib.py:146] step: 440500, eval_loss: 2.79466e-02
I0210 08:01:16.684218 22542570456896 run_lib.py:133] step: 440550, training_loss: 2.84835e-02
I0210 08:01:34.121041 22542570456896 run_lib.py:133] step: 440600, training_loss: 2.66035e-02
I0210 08:01:34.273128 22542570456896 run_lib.py:146] step: 440600, eval_loss: 3.14464e-02
I0210 08:01:51.881493 22542570456896 run_lib.py:133] step: 440650, training_loss: 2.89359e-02
I0210 08:02:09.330478 22542570456896 run_lib.py:133] step: 440700, training_loss: 2.61382e-02
I0210 08:02:09.491116 22542570456896 run_lib.py:146] step: 440700, eval_loss: 2.99926e-02
I0210 08:02:27.036314 22542570456896 run_lib.py:133] step: 440750, training_loss: 2.41311e-02
I0210 08:02:44.503714 22542570456896 run_lib.py:133] step: 440800, training_loss: 3.10785e-02
I0210 08:02:44.668387 22542570456896 run_lib.py:146] step: 440800, eval_loss: 3.76708e-02
I0210 08:03:02.319936 22542570456896 run_lib.py:133] step: 440850, training_loss: 2.36547e-02
I0210 08:03:19.741754 22542570456896 run_lib.py:133] step: 440900, training_loss: 2.54785e-02
I0210 08:03:19.897361 22542570456896 run_lib.py:146] step: 440900, eval_loss: 3.25233e-02
I0210 08:03:37.442723 22542570456896 run_lib.py:133] step: 440950, training_loss: 2.94538e-02
I0210 08:03:54.865001 22542570456896 run_lib.py:133] step: 441000, training_loss: 3.24590e-02
I0210 08:03:55.020419 22542570456896 run_lib.py:146] step: 441000, eval_loss: 2.40814e-02
I0210 08:04:12.425275 22542570456896 run_lib.py:133] step: 441050, training_loss: 4.10537e-02
I0210 08:04:30.039541 22542570456896 run_lib.py:133] step: 441100, training_loss: 3.54933e-02
I0210 08:04:30.200656 22542570456896 run_lib.py:146] step: 441100, eval_loss: 3.73362e-02
I0210 08:04:47.655748 22542570456896 run_lib.py:133] step: 441150, training_loss: 2.51487e-02
I0210 08:05:05.095537 22542570456896 run_lib.py:133] step: 441200, training_loss: 2.79163e-02
I0210 08:05:05.254359 22542570456896 run_lib.py:146] step: 441200, eval_loss: 3.05905e-02
I0210 08:05:22.855440 22542570456896 run_lib.py:133] step: 441250, training_loss: 3.00084e-02
I0210 08:05:40.279834 22542570456896 run_lib.py:133] step: 441300, training_loss: 2.47285e-02
I0210 08:05:40.446906 22542570456896 run_lib.py:146] step: 441300, eval_loss: 3.44882e-02
I0210 08:05:58.020684 22542570456896 run_lib.py:133] step: 441350, training_loss: 3.39318e-02
I0210 08:06:15.483301 22542570456896 run_lib.py:133] step: 441400, training_loss: 2.29304e-02
I0210 08:06:15.638164 22542570456896 run_lib.py:146] step: 441400, eval_loss: 3.16853e-02
I0210 08:06:33.113653 22542570456896 run_lib.py:133] step: 441450, training_loss: 3.06975e-02
I0210 08:06:50.704493 22542570456896 run_lib.py:133] step: 441500, training_loss: 2.79032e-02
I0210 08:06:50.866908 22542570456896 run_lib.py:146] step: 441500, eval_loss: 2.95791e-02
I0210 08:07:08.284656 22542570456896 run_lib.py:133] step: 441550, training_loss: 2.78382e-02
I0210 08:07:25.717080 22542570456896 run_lib.py:133] step: 441600, training_loss: 3.04626e-02
I0210 08:07:25.871628 22542570456896 run_lib.py:146] step: 441600, eval_loss: 2.90928e-02
I0210 08:07:43.397600 22542570456896 run_lib.py:133] step: 441650, training_loss: 2.10511e-02
I0210 08:08:01.035678 22542570456896 run_lib.py:133] step: 441700, training_loss: 3.39473e-02
I0210 08:08:01.193278 22542570456896 run_lib.py:146] step: 441700, eval_loss: 2.72191e-02
I0210 08:08:18.596780 22542570456896 run_lib.py:133] step: 441750, training_loss: 2.44938e-02
I0210 08:08:36.056556 22542570456896 run_lib.py:133] step: 441800, training_loss: 3.02684e-02
I0210 08:08:36.212381 22542570456896 run_lib.py:146] step: 441800, eval_loss: 3.43383e-02
I0210 08:08:53.618198 22542570456896 run_lib.py:133] step: 441850, training_loss: 2.61062e-02
I0210 08:09:11.003590 22542570456896 run_lib.py:133] step: 441900, training_loss: 3.40488e-02
I0210 08:09:11.172357 22542570456896 run_lib.py:146] step: 441900, eval_loss: 2.50824e-02
I0210 08:09:28.788879 22542570456896 run_lib.py:133] step: 441950, training_loss: 2.59625e-02
I0210 08:09:46.323145 22542570456896 run_lib.py:133] step: 442000, training_loss: 2.93586e-02
I0210 08:09:46.475199 22542570456896 run_lib.py:146] step: 442000, eval_loss: 2.45315e-02
I0210 08:10:03.900955 22542570456896 run_lib.py:133] step: 442050, training_loss: 3.13216e-02
I0210 08:10:21.315523 22542570456896 run_lib.py:133] step: 442100, training_loss: 3.27009e-02
I0210 08:10:21.470344 22542570456896 run_lib.py:146] step: 442100, eval_loss: 3.32147e-02
I0210 08:10:39.013012 22542570456896 run_lib.py:133] step: 442150, training_loss: 2.82847e-02
I0210 08:10:56.433839 22542570456896 run_lib.py:133] step: 442200, training_loss: 2.70403e-02
I0210 08:10:56.612486 22542570456896 run_lib.py:146] step: 442200, eval_loss: 2.36444e-02
I0210 08:11:14.220635 22542570456896 run_lib.py:133] step: 442250, training_loss: 2.26950e-02
I0210 08:11:31.656813 22542570456896 run_lib.py:133] step: 442300, training_loss: 2.71509e-02
I0210 08:11:31.809744 22542570456896 run_lib.py:146] step: 442300, eval_loss: 2.67086e-02
I0210 08:11:49.426163 22542570456896 run_lib.py:133] step: 442350, training_loss: 2.69508e-02
I0210 08:12:06.811119 22542570456896 run_lib.py:133] step: 442400, training_loss: 2.87489e-02
I0210 08:12:06.966516 22542570456896 run_lib.py:146] step: 442400, eval_loss: 2.55269e-02
I0210 08:12:24.433498 22542570456896 run_lib.py:133] step: 442450, training_loss: 2.59083e-02
I0210 08:12:42.064881 22542570456896 run_lib.py:133] step: 442500, training_loss: 2.62153e-02
I0210 08:12:42.228832 22542570456896 run_lib.py:146] step: 442500, eval_loss: 2.65840e-02
I0210 08:12:59.721970 22542570456896 run_lib.py:133] step: 442550, training_loss: 2.17225e-02
I0210 08:13:17.319290 22542570456896 run_lib.py:133] step: 442600, training_loss: 2.45130e-02
I0210 08:13:17.475498 22542570456896 run_lib.py:146] step: 442600, eval_loss: 2.73083e-02
I0210 08:13:34.888079 22542570456896 run_lib.py:133] step: 442650, training_loss: 3.20495e-02
I0210 08:13:52.327668 22542570456896 run_lib.py:133] step: 442700, training_loss: 2.26820e-02
I0210 08:13:52.483818 22542570456896 run_lib.py:146] step: 442700, eval_loss: 2.79606e-02
I0210 08:14:10.088806 22542570456896 run_lib.py:133] step: 442750, training_loss: 2.84076e-02
I0210 08:14:27.573469 22542570456896 run_lib.py:133] step: 442800, training_loss: 2.35790e-02
I0210 08:14:27.730605 22542570456896 run_lib.py:146] step: 442800, eval_loss: 2.93125e-02
I0210 08:14:45.161319 22542570456896 run_lib.py:133] step: 442850, training_loss: 2.33521e-02
I0210 08:15:02.740142 22542570456896 run_lib.py:133] step: 442900, training_loss: 2.73256e-02
I0210 08:15:02.895101 22542570456896 run_lib.py:146] step: 442900, eval_loss: 3.40231e-02
I0210 08:15:20.323851 22542570456896 run_lib.py:133] step: 442950, training_loss: 2.82252e-02
I0210 08:15:37.785646 22542570456896 run_lib.py:133] step: 443000, training_loss: 1.99012e-02
I0210 08:15:38.095105 22542570456896 run_lib.py:146] step: 443000, eval_loss: 2.81628e-02
I0210 08:15:55.478121 22542570456896 run_lib.py:133] step: 443050, training_loss: 2.54429e-02
I0210 08:16:12.932217 22542570456896 run_lib.py:133] step: 443100, training_loss: 2.80685e-02
I0210 08:16:13.101177 22542570456896 run_lib.py:146] step: 443100, eval_loss: 2.68572e-02
I0210 08:16:30.549229 22542570456896 run_lib.py:133] step: 443150, training_loss: 3.12930e-02
I0210 08:16:47.976173 22542570456896 run_lib.py:133] step: 443200, training_loss: 2.50088e-02
I0210 08:16:48.133591 22542570456896 run_lib.py:146] step: 443200, eval_loss: 2.98209e-02
I0210 08:17:05.735570 22542570456896 run_lib.py:133] step: 443250, training_loss: 3.16718e-02
I0210 08:17:23.187909 22542570456896 run_lib.py:133] step: 443300, training_loss: 3.25231e-02
I0210 08:17:23.352123 22542570456896 run_lib.py:146] step: 443300, eval_loss: 3.34128e-02
I0210 08:17:40.864788 22542570456896 run_lib.py:133] step: 443350, training_loss: 3.10397e-02
I0210 08:17:58.275763 22542570456896 run_lib.py:133] step: 443400, training_loss: 2.82893e-02
I0210 08:17:58.429987 22542570456896 run_lib.py:146] step: 443400, eval_loss: 2.90507e-02
I0210 08:18:16.068969 22542570456896 run_lib.py:133] step: 443450, training_loss: 3.02797e-02
I0210 08:18:33.541512 22542570456896 run_lib.py:133] step: 443500, training_loss: 2.89852e-02
I0210 08:18:33.693299 22542570456896 run_lib.py:146] step: 443500, eval_loss: 3.11415e-02
I0210 08:18:51.118588 22542570456896 run_lib.py:133] step: 443550, training_loss: 2.79602e-02
I0210 08:19:08.539350 22542570456896 run_lib.py:133] step: 443600, training_loss: 3.22459e-02
I0210 08:19:08.716334 22542570456896 run_lib.py:146] step: 443600, eval_loss: 2.91737e-02
I0210 08:19:26.363466 22542570456896 run_lib.py:133] step: 443650, training_loss: 3.05682e-02
I0210 08:19:43.811185 22542570456896 run_lib.py:133] step: 443700, training_loss: 3.47305e-02
I0210 08:19:43.970650 22542570456896 run_lib.py:146] step: 443700, eval_loss: 2.87620e-02
I0210 08:20:01.556287 22542570456896 run_lib.py:133] step: 443750, training_loss: 2.70123e-02
I0210 08:20:18.970891 22542570456896 run_lib.py:133] step: 443800, training_loss: 2.72667e-02
I0210 08:20:19.127249 22542570456896 run_lib.py:146] step: 443800, eval_loss: 2.40694e-02
I0210 08:20:36.725004 22542570456896 run_lib.py:133] step: 443850, training_loss: 2.66293e-02
I0210 08:20:54.161687 22542570456896 run_lib.py:133] step: 443900, training_loss: 2.44735e-02
I0210 08:20:54.315162 22542570456896 run_lib.py:146] step: 443900, eval_loss: 2.31965e-02
I0210 08:21:11.836975 22542570456896 run_lib.py:133] step: 443950, training_loss: 2.78543e-02
I0210 08:21:29.434275 22542570456896 run_lib.py:133] step: 444000, training_loss: 2.61693e-02
I0210 08:21:29.589381 22542570456896 run_lib.py:146] step: 444000, eval_loss: 2.73854e-02
I0210 08:21:47.009835 22542570456896 run_lib.py:133] step: 444050, training_loss: 2.64568e-02
I0210 08:22:04.578849 22542570456896 run_lib.py:133] step: 444100, training_loss: 2.40466e-02
I0210 08:22:04.744330 22542570456896 run_lib.py:146] step: 444100, eval_loss: 2.53608e-02
I0210 08:22:22.137264 22542570456896 run_lib.py:133] step: 444150, training_loss: 2.79377e-02
I0210 08:22:39.546694 22542570456896 run_lib.py:133] step: 444200, training_loss: 2.89531e-02
I0210 08:22:39.717472 22542570456896 run_lib.py:146] step: 444200, eval_loss: 2.44478e-02
I0210 08:22:57.375041 22542570456896 run_lib.py:133] step: 444250, training_loss: 2.76209e-02
I0210 08:23:14.811232 22542570456896 run_lib.py:133] step: 444300, training_loss: 2.59960e-02
I0210 08:23:14.965911 22542570456896 run_lib.py:146] step: 444300, eval_loss: 3.23251e-02
I0210 08:23:32.381598 22542570456896 run_lib.py:133] step: 444350, training_loss: 2.86627e-02
I0210 08:23:49.803060 22542570456896 run_lib.py:133] step: 444400, training_loss: 2.74003e-02
I0210 08:23:49.954418 22542570456896 run_lib.py:146] step: 444400, eval_loss: 3.17562e-02
I0210 08:24:07.548391 22542570456896 run_lib.py:133] step: 444450, training_loss: 2.75527e-02
I0210 08:24:25.051055 22542570456896 run_lib.py:133] step: 444500, training_loss: 2.45558e-02
I0210 08:24:25.221606 22542570456896 run_lib.py:146] step: 444500, eval_loss: 2.73662e-02
I0210 08:24:42.751573 22542570456896 run_lib.py:133] step: 444550, training_loss: 3.26119e-02
I0210 08:25:00.203400 22542570456896 run_lib.py:133] step: 444600, training_loss: 2.41619e-02
I0210 08:25:00.361544 22542570456896 run_lib.py:146] step: 444600, eval_loss: 2.74163e-02
I0210 08:25:17.792635 22542570456896 run_lib.py:133] step: 444650, training_loss: 3.25015e-02
I0210 08:25:35.257062 22542570456896 run_lib.py:133] step: 444700, training_loss: 2.70586e-02
I0210 08:25:35.412401 22542570456896 run_lib.py:146] step: 444700, eval_loss: 3.36521e-02
I0210 08:25:52.995220 22542570456896 run_lib.py:133] step: 444750, training_loss: 2.97954e-02
I0210 08:26:10.550673 22542570456896 run_lib.py:133] step: 444800, training_loss: 2.58550e-02
I0210 08:26:10.707177 22542570456896 run_lib.py:146] step: 444800, eval_loss: 2.89890e-02
I0210 08:26:28.163951 22542570456896 run_lib.py:133] step: 444850, training_loss: 3.11551e-02
I0210 08:26:45.586954 22542570456896 run_lib.py:133] step: 444900, training_loss: 3.44131e-02
I0210 08:26:45.739392 22542570456896 run_lib.py:146] step: 444900, eval_loss: 2.94934e-02
I0210 08:27:03.295270 22542570456896 run_lib.py:133] step: 444950, training_loss: 3.19717e-02
I0210 08:27:20.702227 22542570456896 run_lib.py:133] step: 445000, training_loss: 2.55824e-02
I0210 08:27:20.875371 22542570456896 run_lib.py:146] step: 445000, eval_loss: 2.99686e-02
I0210 08:27:38.492031 22542570456896 run_lib.py:133] step: 445050, training_loss: 3.09800e-02
I0210 08:27:55.964656 22542570456896 run_lib.py:133] step: 445100, training_loss: 3.41359e-02
I0210 08:27:56.131858 22542570456896 run_lib.py:146] step: 445100, eval_loss: 2.62410e-02
I0210 08:28:13.703981 22542570456896 run_lib.py:133] step: 445150, training_loss: 2.84628e-02
I0210 08:28:31.132266 22542570456896 run_lib.py:133] step: 445200, training_loss: 2.83993e-02
I0210 08:28:31.288194 22542570456896 run_lib.py:146] step: 445200, eval_loss: 2.84825e-02
I0210 08:28:48.843243 22542570456896 run_lib.py:133] step: 445250, training_loss: 3.14044e-02
I0210 08:29:06.267208 22542570456896 run_lib.py:133] step: 445300, training_loss: 3.51202e-02
I0210 08:29:06.430296 22542570456896 run_lib.py:146] step: 445300, eval_loss: 2.20229e-02
I0210 08:29:23.875839 22542570456896 run_lib.py:133] step: 445350, training_loss: 3.37528e-02
I0210 08:29:41.483092 22542570456896 run_lib.py:133] step: 445400, training_loss: 2.11681e-02
I0210 08:29:41.635338 22542570456896 run_lib.py:146] step: 445400, eval_loss: 2.41918e-02
I0210 08:29:59.069013 22542570456896 run_lib.py:133] step: 445450, training_loss: 2.77909e-02
I0210 08:30:16.519002 22542570456896 run_lib.py:133] step: 445500, training_loss: 2.91538e-02
I0210 08:30:16.674364 22542570456896 run_lib.py:146] step: 445500, eval_loss: 3.44737e-02
I0210 08:30:34.276278 22542570456896 run_lib.py:133] step: 445550, training_loss: 2.91598e-02
I0210 08:30:51.878600 22542570456896 run_lib.py:133] step: 445600, training_loss: 2.41541e-02
I0210 08:30:52.047377 22542570456896 run_lib.py:146] step: 445600, eval_loss: 3.32411e-02
I0210 08:31:09.494436 22542570456896 run_lib.py:133] step: 445650, training_loss: 2.98219e-02
I0210 08:31:26.931335 22542570456896 run_lib.py:133] step: 445700, training_loss: 3.04250e-02
I0210 08:31:27.095646 22542570456896 run_lib.py:146] step: 445700, eval_loss: 2.86153e-02
I0210 08:31:44.527697 22542570456896 run_lib.py:133] step: 445750, training_loss: 2.71338e-02
I0210 08:32:02.100427 22542570456896 run_lib.py:133] step: 445800, training_loss: 2.93446e-02
I0210 08:32:02.251097 22542570456896 run_lib.py:146] step: 445800, eval_loss: 3.95935e-02
I0210 08:32:19.648169 22542570456896 run_lib.py:133] step: 445850, training_loss: 3.00949e-02
I0210 08:32:37.089891 22542570456896 run_lib.py:133] step: 445900, training_loss: 3.07881e-02
I0210 08:32:37.264450 22542570456896 run_lib.py:146] step: 445900, eval_loss: 2.33614e-02
I0210 08:32:54.714585 22542570456896 run_lib.py:133] step: 445950, training_loss: 3.32331e-02
I0210 08:33:12.372250 22542570456896 run_lib.py:133] step: 446000, training_loss: 2.63225e-02
I0210 08:33:12.530280 22542570456896 run_lib.py:146] step: 446000, eval_loss: 2.97568e-02
I0210 08:33:29.940893 22542570456896 run_lib.py:133] step: 446050, training_loss: 2.18832e-02
I0210 08:33:47.409495 22542570456896 run_lib.py:133] step: 446100, training_loss: 3.04605e-02
I0210 08:33:47.565132 22542570456896 run_lib.py:146] step: 446100, eval_loss: 2.57678e-02
I0210 08:34:05.025004 22542570456896 run_lib.py:133] step: 446150, training_loss: 2.89475e-02
I0210 08:34:22.502113 22542570456896 run_lib.py:133] step: 446200, training_loss: 2.83892e-02
I0210 08:34:22.657178 22542570456896 run_lib.py:146] step: 446200, eval_loss: 2.33283e-02
I0210 08:34:40.309452 22542570456896 run_lib.py:133] step: 446250, training_loss: 2.76995e-02
I0210 08:34:57.765534 22542570456896 run_lib.py:133] step: 446300, training_loss: 1.79456e-02
I0210 08:34:57.917331 22542570456896 run_lib.py:146] step: 446300, eval_loss: 2.94219e-02
I0210 08:35:15.334230 22542570456896 run_lib.py:133] step: 446350, training_loss: 3.05102e-02
I0210 08:35:32.762537 22542570456896 run_lib.py:133] step: 446400, training_loss: 2.53097e-02
I0210 08:35:32.929558 22542570456896 run_lib.py:146] step: 446400, eval_loss: 2.87275e-02
I0210 08:35:50.516907 22542570456896 run_lib.py:133] step: 446450, training_loss: 2.77590e-02
I0210 08:36:07.871997 22542570456896 run_lib.py:133] step: 446500, training_loss: 3.06181e-02
I0210 08:36:08.027232 22542570456896 run_lib.py:146] step: 446500, eval_loss: 3.44014e-02
I0210 08:36:25.517789 22542570456896 run_lib.py:133] step: 446550, training_loss: 2.44007e-02
I0210 08:36:42.815354 22542570456896 run_lib.py:133] step: 446600, training_loss: 3.65324e-02
I0210 08:36:42.969121 22542570456896 run_lib.py:146] step: 446600, eval_loss: 2.74689e-02
I0210 08:37:00.538825 22542570456896 run_lib.py:133] step: 446650, training_loss: 3.03984e-02
I0210 08:37:17.955324 22542570456896 run_lib.py:133] step: 446700, training_loss: 2.90344e-02
I0210 08:37:18.111658 22542570456896 run_lib.py:146] step: 446700, eval_loss: 3.43895e-02
I0210 08:37:35.614213 22542570456896 run_lib.py:133] step: 446750, training_loss: 2.26487e-02
I0210 08:37:53.215942 22542570456896 run_lib.py:133] step: 446800, training_loss: 3.25017e-02
I0210 08:37:53.368507 22542570456896 run_lib.py:146] step: 446800, eval_loss: 2.73525e-02
I0210 08:38:10.808937 22542570456896 run_lib.py:133] step: 446850, training_loss: 2.65006e-02
I0210 08:38:28.393119 22542570456896 run_lib.py:133] step: 446900, training_loss: 2.54064e-02
I0210 08:38:28.551640 22542570456896 run_lib.py:146] step: 446900, eval_loss: 3.37397e-02
I0210 08:38:45.980041 22542570456896 run_lib.py:133] step: 446950, training_loss: 2.63425e-02
I0210 08:39:03.472696 22542570456896 run_lib.py:133] step: 447000, training_loss: 3.70254e-02
I0210 08:39:03.643395 22542570456896 run_lib.py:146] step: 447000, eval_loss: 3.16891e-02
I0210 08:39:21.316303 22542570456896 run_lib.py:133] step: 447050, training_loss: 2.13746e-02
I0210 08:39:38.729467 22542570456896 run_lib.py:133] step: 447100, training_loss: 2.73541e-02
I0210 08:39:38.884633 22542570456896 run_lib.py:146] step: 447100, eval_loss: 2.82595e-02
I0210 08:39:56.319776 22542570456896 run_lib.py:133] step: 447150, training_loss: 2.63411e-02
I0210 08:40:13.851400 22542570456896 run_lib.py:133] step: 447200, training_loss: 3.00550e-02
I0210 08:40:14.004365 22542570456896 run_lib.py:146] step: 447200, eval_loss: 2.29239e-02
I0210 08:40:31.460345 22542570456896 run_lib.py:133] step: 447250, training_loss: 2.88532e-02
I0210 08:40:48.910360 22542570456896 run_lib.py:133] step: 447300, training_loss: 2.92540e-02
I0210 08:40:49.067630 22542570456896 run_lib.py:146] step: 447300, eval_loss: 2.86376e-02
I0210 08:41:06.636581 22542570456896 run_lib.py:133] step: 447350, training_loss: 3.62346e-02
I0210 08:41:24.071954 22542570456896 run_lib.py:133] step: 447400, training_loss: 2.54090e-02
I0210 08:41:24.230377 22542570456896 run_lib.py:146] step: 447400, eval_loss: 2.95395e-02
I0210 08:41:41.636643 22542570456896 run_lib.py:133] step: 447450, training_loss: 2.27391e-02
I0210 08:41:59.068106 22542570456896 run_lib.py:133] step: 447500, training_loss: 2.84447e-02
I0210 08:41:59.231461 22542570456896 run_lib.py:146] step: 447500, eval_loss: 2.84085e-02
I0210 08:42:16.808161 22542570456896 run_lib.py:133] step: 447550, training_loss: 2.88198e-02
I0210 08:42:34.317277 22542570456896 run_lib.py:133] step: 447600, training_loss: 2.57827e-02
I0210 08:42:34.480303 22542570456896 run_lib.py:146] step: 447600, eval_loss: 2.80299e-02
I0210 08:42:51.952462 22542570456896 run_lib.py:133] step: 447650, training_loss: 2.84949e-02
I0210 08:43:09.366730 22542570456896 run_lib.py:133] step: 447700, training_loss: 2.56591e-02
I0210 08:43:09.517256 22542570456896 run_lib.py:146] step: 447700, eval_loss: 3.61385e-02
I0210 08:43:27.103019 22542570456896 run_lib.py:133] step: 447750, training_loss: 2.40014e-02
I0210 08:43:44.527283 22542570456896 run_lib.py:133] step: 447800, training_loss: 2.58044e-02
I0210 08:43:44.691454 22542570456896 run_lib.py:146] step: 447800, eval_loss: 3.07704e-02
I0210 08:44:02.296562 22542570456896 run_lib.py:133] step: 447850, training_loss: 2.61421e-02
I0210 08:44:19.727509 22542570456896 run_lib.py:133] step: 447900, training_loss: 2.86213e-02
I0210 08:44:19.886447 22542570456896 run_lib.py:146] step: 447900, eval_loss: 2.67798e-02
I0210 08:44:37.491657 22542570456896 run_lib.py:133] step: 447950, training_loss: 2.96081e-02
I0210 08:44:54.865968 22542570456896 run_lib.py:133] step: 448000, training_loss: 2.60771e-02
I0210 08:44:55.021318 22542570456896 run_lib.py:146] step: 448000, eval_loss: 3.34741e-02
I0210 08:45:12.588559 22542570456896 run_lib.py:133] step: 448050, training_loss: 3.17583e-02
I0210 08:45:30.027450 22542570456896 run_lib.py:133] step: 448100, training_loss: 2.37283e-02
I0210 08:45:30.182526 22542570456896 run_lib.py:146] step: 448100, eval_loss: 3.13774e-02
I0210 08:45:47.632330 22542570456896 run_lib.py:133] step: 448150, training_loss: 3.00850e-02
I0210 08:46:05.241764 22542570456896 run_lib.py:133] step: 448200, training_loss: 2.78406e-02
I0210 08:46:05.394399 22542570456896 run_lib.py:146] step: 448200, eval_loss: 3.18081e-02
I0210 08:46:22.825739 22542570456896 run_lib.py:133] step: 448250, training_loss: 3.15949e-02
I0210 08:46:40.220210 22542570456896 run_lib.py:133] step: 448300, training_loss: 2.88821e-02
I0210 08:46:40.372626 22542570456896 run_lib.py:146] step: 448300, eval_loss: 2.59552e-02
I0210 08:46:57.955515 22542570456896 run_lib.py:133] step: 448350, training_loss: 3.08815e-02
I0210 08:47:15.458082 22542570456896 run_lib.py:133] step: 448400, training_loss: 2.63235e-02
I0210 08:47:15.617466 22542570456896 run_lib.py:146] step: 448400, eval_loss: 2.84787e-02
I0210 08:47:33.195858 22542570456896 run_lib.py:133] step: 448450, training_loss: 2.92898e-02
I0210 08:47:50.591750 22542570456896 run_lib.py:133] step: 448500, training_loss: 2.07620e-02
I0210 08:47:50.747295 22542570456896 run_lib.py:146] step: 448500, eval_loss: 2.98926e-02
I0210 08:48:08.185910 22542570456896 run_lib.py:133] step: 448550, training_loss: 2.77172e-02
I0210 08:48:25.756372 22542570456896 run_lib.py:133] step: 448600, training_loss: 2.33339e-02
I0210 08:48:25.919353 22542570456896 run_lib.py:146] step: 448600, eval_loss: 3.62874e-02
I0210 08:48:43.341166 22542570456896 run_lib.py:133] step: 448650, training_loss: 1.99854e-02
I0210 08:49:00.769749 22542570456896 run_lib.py:133] step: 448700, training_loss: 3.01175e-02
I0210 08:49:00.925580 22542570456896 run_lib.py:146] step: 448700, eval_loss: 2.66285e-02
I0210 08:49:18.385552 22542570456896 run_lib.py:133] step: 448750, training_loss: 3.19157e-02
I0210 08:49:36.027223 22542570456896 run_lib.py:133] step: 448800, training_loss: 2.74645e-02
I0210 08:49:36.185673 22542570456896 run_lib.py:146] step: 448800, eval_loss: 2.60944e-02
I0210 08:49:53.609378 22542570456896 run_lib.py:133] step: 448850, training_loss: 2.61588e-02
I0210 08:50:11.094242 22542570456896 run_lib.py:133] step: 448900, training_loss: 2.77276e-02
I0210 08:50:11.259584 22542570456896 run_lib.py:146] step: 448900, eval_loss: 3.01909e-02
I0210 08:50:28.744868 22542570456896 run_lib.py:133] step: 448950, training_loss: 2.51137e-02
I0210 08:50:46.286082 22542570456896 run_lib.py:133] step: 449000, training_loss: 2.78758e-02
I0210 08:50:46.442188 22542570456896 run_lib.py:146] step: 449000, eval_loss: 3.02501e-02
I0210 08:51:04.068002 22542570456896 run_lib.py:133] step: 449050, training_loss: 3.26002e-02
I0210 08:51:21.539478 22542570456896 run_lib.py:133] step: 449100, training_loss: 1.87426e-02
I0210 08:51:21.694554 22542570456896 run_lib.py:146] step: 449100, eval_loss: 2.87263e-02
I0210 08:51:39.113926 22542570456896 run_lib.py:133] step: 449150, training_loss: 2.95740e-02
I0210 08:51:56.571496 22542570456896 run_lib.py:133] step: 449200, training_loss: 2.28407e-02
I0210 08:51:56.726645 22542570456896 run_lib.py:146] step: 449200, eval_loss: 2.89547e-02
I0210 08:52:14.368213 22542570456896 run_lib.py:133] step: 449250, training_loss: 2.62986e-02
I0210 08:52:31.792015 22542570456896 run_lib.py:133] step: 449300, training_loss: 2.70114e-02
I0210 08:52:31.952643 22542570456896 run_lib.py:146] step: 449300, eval_loss: 2.74122e-02
I0210 08:52:49.527287 22542570456896 run_lib.py:133] step: 449350, training_loss: 3.02523e-02
I0210 08:53:06.948470 22542570456896 run_lib.py:133] step: 449400, training_loss: 2.41034e-02
I0210 08:53:07.108432 22542570456896 run_lib.py:146] step: 449400, eval_loss: 3.64803e-02
I0210 08:53:24.715098 22542570456896 run_lib.py:133] step: 449450, training_loss: 2.15718e-02
I0210 08:53:42.203283 22542570456896 run_lib.py:133] step: 449500, training_loss: 2.76248e-02
I0210 08:53:42.365879 22542570456896 run_lib.py:146] step: 449500, eval_loss: 2.65222e-02
I0210 08:53:59.801414 22542570456896 run_lib.py:133] step: 449550, training_loss: 2.26283e-02
I0210 08:54:17.417396 22542570456896 run_lib.py:133] step: 449600, training_loss: 2.65517e-02
I0210 08:54:17.569363 22542570456896 run_lib.py:146] step: 449600, eval_loss: 2.80440e-02
I0210 08:54:34.970808 22542570456896 run_lib.py:133] step: 449650, training_loss: 2.54621e-02
I0210 08:54:52.549285 22542570456896 run_lib.py:133] step: 449700, training_loss: 3.60363e-02
I0210 08:54:52.710777 22542570456896 run_lib.py:146] step: 449700, eval_loss: 2.40350e-02
I0210 08:55:10.164141 22542570456896 run_lib.py:133] step: 449750, training_loss: 2.23762e-02
I0210 08:55:27.657527 22542570456896 run_lib.py:133] step: 449800, training_loss: 2.31871e-02
I0210 08:55:27.816460 22542570456896 run_lib.py:146] step: 449800, eval_loss: 2.53480e-02
I0210 08:55:45.393168 22542570456896 run_lib.py:133] step: 449850, training_loss: 2.35957e-02
I0210 08:56:02.812928 22542570456896 run_lib.py:133] step: 449900, training_loss: 2.64880e-02
I0210 08:56:02.968420 22542570456896 run_lib.py:146] step: 449900, eval_loss: 2.94604e-02
I0210 08:56:20.383576 22542570456896 run_lib.py:133] step: 449950, training_loss: 2.55321e-02
I0210 08:56:37.985149 22542570456896 run_lib.py:133] step: 450000, training_loss: 2.96035e-02
I0210 08:56:38.739090 22542570456896 run_lib.py:146] step: 450000, eval_loss: 3.63122e-02
I0210 08:56:58.831739 22542570456896 run_lib.py:133] step: 450050, training_loss: 3.19666e-02
I0210 08:57:16.263851 22542570456896 run_lib.py:133] step: 450100, training_loss: 2.95502e-02
I0210 08:57:16.420392 22542570456896 run_lib.py:146] step: 450100, eval_loss: 2.67232e-02
I0210 08:57:34.049520 22542570456896 run_lib.py:133] step: 450150, training_loss: 2.40023e-02
I0210 08:57:51.479159 22542570456896 run_lib.py:133] step: 450200, training_loss: 3.20471e-02
I0210 08:57:51.631386 22542570456896 run_lib.py:146] step: 450200, eval_loss: 2.37667e-02
I0210 08:58:09.086103 22542570456896 run_lib.py:133] step: 450250, training_loss: 2.64042e-02
I0210 08:58:26.480144 22542570456896 run_lib.py:133] step: 450300, training_loss: 2.56697e-02
I0210 08:58:26.657340 22542570456896 run_lib.py:146] step: 450300, eval_loss: 2.74402e-02
I0210 08:58:44.402668 22542570456896 run_lib.py:133] step: 450350, training_loss: 2.94890e-02
I0210 08:59:01.851973 22542570456896 run_lib.py:133] step: 450400, training_loss: 2.71772e-02
I0210 08:59:02.006495 22542570456896 run_lib.py:146] step: 450400, eval_loss: 2.74050e-02
I0210 08:59:19.504652 22542570456896 run_lib.py:133] step: 450450, training_loss: 3.18181e-02
I0210 08:59:36.910253 22542570456896 run_lib.py:133] step: 450500, training_loss: 2.69776e-02
I0210 08:59:37.065075 22542570456896 run_lib.py:146] step: 450500, eval_loss: 2.55018e-02
I0210 08:59:54.488368 22542570456896 run_lib.py:133] step: 450550, training_loss: 1.95920e-02
I0210 09:00:11.938552 22542570456896 run_lib.py:133] step: 450600, training_loss: 2.57439e-02
I0210 09:00:12.098146 22542570456896 run_lib.py:146] step: 450600, eval_loss: 2.47520e-02
I0210 09:00:29.788994 22542570456896 run_lib.py:133] step: 450650, training_loss: 3.00046e-02
I0210 09:00:47.271317 22542570456896 run_lib.py:133] step: 450700, training_loss: 2.87403e-02
I0210 09:00:47.425386 22542570456896 run_lib.py:146] step: 450700, eval_loss: 2.82437e-02
I0210 09:01:04.875614 22542570456896 run_lib.py:133] step: 450750, training_loss: 2.65715e-02
I0210 09:01:22.302269 22542570456896 run_lib.py:133] step: 450800, training_loss: 2.98035e-02
I0210 09:01:22.464648 22542570456896 run_lib.py:146] step: 450800, eval_loss: 3.29308e-02
I0210 09:01:40.077342 22542570456896 run_lib.py:133] step: 450850, training_loss: 2.36111e-02
I0210 09:01:57.556400 22542570456896 run_lib.py:133] step: 450900, training_loss: 2.95163e-02
I0210 09:01:57.715299 22542570456896 run_lib.py:146] step: 450900, eval_loss: 3.21446e-02
I0210 09:02:15.336378 22542570456896 run_lib.py:133] step: 450950, training_loss: 2.28303e-02
I0210 09:02:32.735400 22542570456896 run_lib.py:133] step: 451000, training_loss: 2.75013e-02
I0210 09:02:32.892614 22542570456896 run_lib.py:146] step: 451000, eval_loss: 2.49982e-02
I0210 09:02:50.445011 22542570456896 run_lib.py:133] step: 451050, training_loss: 3.18668e-02
I0210 09:03:07.843795 22542570456896 run_lib.py:133] step: 451100, training_loss: 2.73731e-02
I0210 09:03:08.001431 22542570456896 run_lib.py:146] step: 451100, eval_loss: 3.29263e-02
I0210 09:03:25.599526 22542570456896 run_lib.py:133] step: 451150, training_loss: 2.55099e-02
I0210 09:03:43.045616 22542570456896 run_lib.py:133] step: 451200, training_loss: 3.06207e-02
I0210 09:03:43.206616 22542570456896 run_lib.py:146] step: 451200, eval_loss: 2.63675e-02
I0210 09:04:00.594246 22542570456896 run_lib.py:133] step: 451250, training_loss: 2.73684e-02
I0210 09:04:18.210030 22542570456896 run_lib.py:133] step: 451300, training_loss: 2.70207e-02
I0210 09:04:18.368605 22542570456896 run_lib.py:146] step: 451300, eval_loss: 3.20244e-02
I0210 09:04:35.796898 22542570456896 run_lib.py:133] step: 451350, training_loss: 2.70931e-02
I0210 09:04:53.219013 22542570456896 run_lib.py:133] step: 451400, training_loss: 2.39145e-02
I0210 09:04:53.374271 22542570456896 run_lib.py:146] step: 451400, eval_loss: 2.89774e-02
I0210 09:05:10.935284 22542570456896 run_lib.py:133] step: 451450, training_loss: 3.03178e-02
I0210 09:05:28.628891 22542570456896 run_lib.py:133] step: 451500, training_loss: 2.73708e-02
I0210 09:05:28.784487 22542570456896 run_lib.py:146] step: 451500, eval_loss: 3.08746e-02
I0210 09:05:46.233335 22542570456896 run_lib.py:133] step: 451550, training_loss: 2.45540e-02
I0210 09:06:03.600392 22542570456896 run_lib.py:133] step: 451600, training_loss: 3.66829e-02
I0210 09:06:03.752306 22542570456896 run_lib.py:146] step: 451600, eval_loss: 2.79757e-02
I0210 09:06:21.189356 22542570456896 run_lib.py:133] step: 451650, training_loss: 3.17544e-02
I0210 09:06:38.758792 22542570456896 run_lib.py:133] step: 451700, training_loss: 3.09935e-02
I0210 09:06:38.920642 22542570456896 run_lib.py:146] step: 451700, eval_loss: 2.97515e-02
I0210 09:06:56.379741 22542570456896 run_lib.py:133] step: 451750, training_loss: 2.50859e-02
I0210 09:07:13.830685 22542570456896 run_lib.py:133] step: 451800, training_loss: 2.78502e-02
I0210 09:07:13.991336 22542570456896 run_lib.py:146] step: 451800, eval_loss: 2.97971e-02
I0210 09:07:31.413066 22542570456896 run_lib.py:133] step: 451850, training_loss: 2.77287e-02
I0210 09:07:49.046412 22542570456896 run_lib.py:133] step: 451900, training_loss: 3.42026e-02
I0210 09:07:49.202424 22542570456896 run_lib.py:146] step: 451900, eval_loss: 3.06376e-02
I0210 09:08:06.602726 22542570456896 run_lib.py:133] step: 451950, training_loss: 2.73986e-02
I0210 09:08:24.085209 22542570456896 run_lib.py:133] step: 452000, training_loss: 3.20829e-02
I0210 09:08:24.246616 22542570456896 run_lib.py:146] step: 452000, eval_loss: 2.71431e-02
I0210 09:08:41.740951 22542570456896 run_lib.py:133] step: 452050, training_loss: 2.83200e-02
I0210 09:08:59.171245 22542570456896 run_lib.py:133] step: 452100, training_loss: 3.04406e-02
I0210 09:08:59.324670 22542570456896 run_lib.py:146] step: 452100, eval_loss: 2.62030e-02
I0210 09:09:16.924146 22542570456896 run_lib.py:133] step: 452150, training_loss: 2.61217e-02
I0210 09:09:34.415985 22542570456896 run_lib.py:133] step: 452200, training_loss: 2.78093e-02
I0210 09:09:34.574732 22542570456896 run_lib.py:146] step: 452200, eval_loss: 2.69743e-02
I0210 09:09:52.006800 22542570456896 run_lib.py:133] step: 452250, training_loss: 2.54921e-02
I0210 09:10:09.433701 22542570456896 run_lib.py:133] step: 452300, training_loss: 2.76697e-02
I0210 09:10:09.598268 22542570456896 run_lib.py:146] step: 452300, eval_loss: 2.51085e-02
I0210 09:10:27.251947 22542570456896 run_lib.py:133] step: 452350, training_loss: 2.32699e-02
I0210 09:10:44.652294 22542570456896 run_lib.py:133] step: 452400, training_loss: 2.29579e-02
I0210 09:10:44.807888 22542570456896 run_lib.py:146] step: 452400, eval_loss: 3.14845e-02
I0210 09:11:02.395445 22542570456896 run_lib.py:133] step: 452450, training_loss: 2.66186e-02
I0210 09:11:19.836807 22542570456896 run_lib.py:133] step: 452500, training_loss: 2.80770e-02
I0210 09:11:19.989105 22542570456896 run_lib.py:146] step: 452500, eval_loss: 2.64841e-02
I0210 09:11:37.549184 22542570456896 run_lib.py:133] step: 452550, training_loss: 1.95062e-02
I0210 09:11:54.982671 22542570456896 run_lib.py:133] step: 452600, training_loss: 2.63017e-02
I0210 09:11:55.140682 22542570456896 run_lib.py:146] step: 452600, eval_loss: 2.95657e-02
I0210 09:12:12.593598 22542570456896 run_lib.py:133] step: 452650, training_loss: 3.21613e-02
I0210 09:12:30.230355 22542570456896 run_lib.py:133] step: 452700, training_loss: 3.26832e-02
I0210 09:12:30.387576 22542570456896 run_lib.py:146] step: 452700, eval_loss: 2.55318e-02
I0210 09:12:47.798561 22542570456896 run_lib.py:133] step: 452750, training_loss: 2.43813e-02
I0210 09:13:05.342718 22542570456896 run_lib.py:133] step: 452800, training_loss: 3.28416e-02
I0210 09:13:05.500213 22542570456896 run_lib.py:146] step: 452800, eval_loss: 2.71690e-02
I0210 09:13:22.923171 22542570456896 run_lib.py:133] step: 452850, training_loss: 3.28535e-02
I0210 09:13:40.423877 22542570456896 run_lib.py:133] step: 452900, training_loss: 2.49219e-02
I0210 09:13:40.587388 22542570456896 run_lib.py:146] step: 452900, eval_loss: 2.86346e-02
I0210 09:13:58.220472 22542570456896 run_lib.py:133] step: 452950, training_loss: 2.60153e-02
I0210 09:14:15.630517 22542570456896 run_lib.py:133] step: 453000, training_loss: 2.16706e-02
I0210 09:14:15.788235 22542570456896 run_lib.py:146] step: 453000, eval_loss: 2.36396e-02
I0210 09:14:33.214088 22542570456896 run_lib.py:133] step: 453050, training_loss: 3.71159e-02
I0210 09:14:50.790323 22542570456896 run_lib.py:133] step: 453100, training_loss: 3.37900e-02
I0210 09:14:50.954543 22542570456896 run_lib.py:146] step: 453100, eval_loss: 2.32205e-02
I0210 09:15:08.439568 22542570456896 run_lib.py:133] step: 453150, training_loss: 3.46703e-02
I0210 09:15:25.896402 22542570456896 run_lib.py:133] step: 453200, training_loss: 2.79538e-02
I0210 09:15:26.055403 22542570456896 run_lib.py:146] step: 453200, eval_loss: 2.54645e-02
I0210 09:15:43.559134 22542570456896 run_lib.py:133] step: 453250, training_loss: 2.19487e-02
I0210 09:16:01.021906 22542570456896 run_lib.py:133] step: 453300, training_loss: 2.83615e-02
I0210 09:16:01.175389 22542570456896 run_lib.py:146] step: 453300, eval_loss: 3.05681e-02
I0210 09:16:18.592442 22542570456896 run_lib.py:133] step: 453350, training_loss: 2.20390e-02
I0210 09:16:36.101285 22542570456896 run_lib.py:133] step: 453400, training_loss: 2.27561e-02
I0210 09:16:36.257744 22542570456896 run_lib.py:146] step: 453400, eval_loss: 2.85562e-02
I0210 09:16:53.897791 22542570456896 run_lib.py:133] step: 453450, training_loss: 3.01134e-02
I0210 09:17:11.419488 22542570456896 run_lib.py:133] step: 453500, training_loss: 2.75284e-02
I0210 09:17:11.571948 22542570456896 run_lib.py:146] step: 453500, eval_loss: 3.46310e-02
I0210 09:17:28.986566 22542570456896 run_lib.py:133] step: 453550, training_loss: 2.99071e-02
I0210 09:17:46.387290 22542570456896 run_lib.py:133] step: 453600, training_loss: 2.02361e-02
I0210 09:17:46.542325 22542570456896 run_lib.py:146] step: 453600, eval_loss: 2.54964e-02
I0210 09:18:04.123703 22542570456896 run_lib.py:133] step: 453650, training_loss: 3.67372e-02
I0210 09:18:21.596446 22542570456896 run_lib.py:133] step: 453700, training_loss: 3.80803e-02
I0210 09:18:21.758241 22542570456896 run_lib.py:146] step: 453700, eval_loss: 2.98421e-02
I0210 09:18:39.379220 22542570456896 run_lib.py:133] step: 453750, training_loss: 2.99446e-02
I0210 09:18:56.785069 22542570456896 run_lib.py:133] step: 453800, training_loss: 3.28610e-02
I0210 09:18:56.941189 22542570456896 run_lib.py:146] step: 453800, eval_loss: 2.87863e-02
I0210 09:19:14.561028 22542570456896 run_lib.py:133] step: 453850, training_loss: 2.31513e-02
I0210 09:19:31.993480 22542570456896 run_lib.py:133] step: 453900, training_loss: 2.71595e-02
I0210 09:19:32.148450 22542570456896 run_lib.py:146] step: 453900, eval_loss: 2.68181e-02
I0210 09:19:49.700129 22542570456896 run_lib.py:133] step: 453950, training_loss: 3.05556e-02
I0210 09:20:07.172706 22542570456896 run_lib.py:133] step: 454000, training_loss: 3.46940e-02
I0210 09:20:07.329608 22542570456896 run_lib.py:146] step: 454000, eval_loss: 3.53513e-02
I0210 09:20:24.805619 22542570456896 run_lib.py:133] step: 454050, training_loss: 2.78545e-02
I0210 09:20:42.423834 22542570456896 run_lib.py:133] step: 454100, training_loss: 2.47044e-02
I0210 09:20:42.581557 22542570456896 run_lib.py:146] step: 454100, eval_loss: 3.51697e-02
I0210 09:20:59.972882 22542570456896 run_lib.py:133] step: 454150, training_loss: 2.89429e-02
I0210 09:21:17.426142 22542570456896 run_lib.py:133] step: 454200, training_loss: 3.50292e-02
I0210 09:21:17.582336 22542570456896 run_lib.py:146] step: 454200, eval_loss: 3.47694e-02
I0210 09:21:35.205036 22542570456896 run_lib.py:133] step: 454250, training_loss: 2.66116e-02
I0210 09:21:52.670900 22542570456896 run_lib.py:133] step: 454300, training_loss: 2.48440e-02
I0210 09:21:52.827594 22542570456896 run_lib.py:146] step: 454300, eval_loss: 2.68841e-02
I0210 09:22:10.430710 22542570456896 run_lib.py:133] step: 454350, training_loss: 2.83868e-02
I0210 09:22:27.838505 22542570456896 run_lib.py:133] step: 454400, training_loss: 2.60780e-02
I0210 09:22:27.992132 22542570456896 run_lib.py:146] step: 454400, eval_loss: 3.76931e-02
I0210 09:22:45.419190 22542570456896 run_lib.py:133] step: 454450, training_loss: 2.63729e-02
I0210 09:23:02.996164 22542570456896 run_lib.py:133] step: 454500, training_loss: 2.62121e-02
I0210 09:23:03.158605 22542570456896 run_lib.py:146] step: 454500, eval_loss: 3.09600e-02
I0210 09:23:20.634614 22542570456896 run_lib.py:133] step: 454550, training_loss: 2.45542e-02
I0210 09:23:38.063105 22542570456896 run_lib.py:133] step: 454600, training_loss: 2.48466e-02
I0210 09:23:38.222729 22542570456896 run_lib.py:146] step: 454600, eval_loss: 2.45435e-02
I0210 09:23:55.653170 22542570456896 run_lib.py:133] step: 454650, training_loss: 2.90238e-02
I0210 09:24:13.253035 22542570456896 run_lib.py:133] step: 454700, training_loss: 3.37017e-02
I0210 09:24:13.416895 22542570456896 run_lib.py:146] step: 454700, eval_loss: 2.54383e-02
I0210 09:24:30.840538 22542570456896 run_lib.py:133] step: 454750, training_loss: 2.56290e-02
I0210 09:24:48.380527 22542570456896 run_lib.py:133] step: 454800, training_loss: 3.09109e-02
I0210 09:24:48.536950 22542570456896 run_lib.py:146] step: 454800, eval_loss: 3.54873e-02
I0210 09:25:06.051659 22542570456896 run_lib.py:133] step: 454850, training_loss: 2.84244e-02
I0210 09:25:23.462193 22542570456896 run_lib.py:133] step: 454900, training_loss: 2.47390e-02
I0210 09:25:23.614550 22542570456896 run_lib.py:146] step: 454900, eval_loss: 3.05773e-02
I0210 09:25:41.207445 22542570456896 run_lib.py:133] step: 454950, training_loss: 2.85167e-02
I0210 09:25:58.685406 22542570456896 run_lib.py:133] step: 455000, training_loss: 2.92184e-02
I0210 09:25:58.842552 22542570456896 run_lib.py:146] step: 455000, eval_loss: 2.70242e-02
I0210 09:26:16.321888 22542570456896 run_lib.py:133] step: 455050, training_loss: 2.12151e-02
I0210 09:26:33.791509 22542570456896 run_lib.py:133] step: 455100, training_loss: 2.19308e-02
I0210 09:26:33.948489 22542570456896 run_lib.py:146] step: 455100, eval_loss: 3.26393e-02
I0210 09:26:51.616549 22542570456896 run_lib.py:133] step: 455150, training_loss: 2.24819e-02
I0210 09:27:09.047523 22542570456896 run_lib.py:133] step: 455200, training_loss: 2.98713e-02
I0210 09:27:09.203670 22542570456896 run_lib.py:146] step: 455200, eval_loss: 3.24386e-02
I0210 09:27:26.834144 22542570456896 run_lib.py:133] step: 455250, training_loss: 2.63948e-02
I0210 09:27:44.264456 22542570456896 run_lib.py:133] step: 455300, training_loss: 2.89208e-02
I0210 09:27:44.418425 22542570456896 run_lib.py:146] step: 455300, eval_loss: 2.87919e-02
I0210 09:28:01.991250 22542570456896 run_lib.py:133] step: 455350, training_loss: 2.99210e-02
I0210 09:28:19.508143 22542570456896 run_lib.py:133] step: 455400, training_loss: 2.63516e-02
I0210 09:28:19.665580 22542570456896 run_lib.py:146] step: 455400, eval_loss: 3.23518e-02
I0210 09:28:37.185212 22542570456896 run_lib.py:133] step: 455450, training_loss: 2.69830e-02
I0210 09:28:54.784013 22542570456896 run_lib.py:133] step: 455500, training_loss: 2.44508e-02
I0210 09:28:54.941163 22542570456896 run_lib.py:146] step: 455500, eval_loss: 2.80058e-02
I0210 09:29:12.374786 22542570456896 run_lib.py:133] step: 455550, training_loss: 2.67914e-02
I0210 09:29:29.936918 22542570456896 run_lib.py:133] step: 455600, training_loss: 2.47177e-02
I0210 09:29:30.096595 22542570456896 run_lib.py:146] step: 455600, eval_loss: 2.58016e-02
I0210 09:29:47.555584 22542570456896 run_lib.py:133] step: 455650, training_loss: 2.28715e-02
I0210 09:30:05.030828 22542570456896 run_lib.py:133] step: 455700, training_loss: 2.59004e-02
I0210 09:30:05.195875 22542570456896 run_lib.py:146] step: 455700, eval_loss: 3.17745e-02
I0210 09:30:22.851833 22542570456896 run_lib.py:133] step: 455750, training_loss: 2.44651e-02
I0210 09:30:40.293743 22542570456896 run_lib.py:133] step: 455800, training_loss: 3.38911e-02
I0210 09:30:40.449339 22542570456896 run_lib.py:146] step: 455800, eval_loss: 2.35054e-02
I0210 09:30:57.885868 22542570456896 run_lib.py:133] step: 455850, training_loss: 3.02272e-02
I0210 09:31:15.493297 22542570456896 run_lib.py:133] step: 455900, training_loss: 2.38337e-02
I0210 09:31:15.646755 22542570456896 run_lib.py:146] step: 455900, eval_loss: 2.70674e-02
I0210 09:31:33.102836 22542570456896 run_lib.py:133] step: 455950, training_loss: 3.02915e-02
I0210 09:31:50.567869 22542570456896 run_lib.py:133] step: 456000, training_loss: 2.63907e-02
I0210 09:31:50.913397 22542570456896 run_lib.py:146] step: 456000, eval_loss: 3.25959e-02
I0210 09:32:08.338496 22542570456896 run_lib.py:133] step: 456050, training_loss: 2.83739e-02
I0210 09:32:25.773670 22542570456896 run_lib.py:133] step: 456100, training_loss: 3.70429e-02
I0210 09:32:25.930659 22542570456896 run_lib.py:146] step: 456100, eval_loss: 2.46479e-02
I0210 09:32:43.358124 22542570456896 run_lib.py:133] step: 456150, training_loss: 2.64888e-02
I0210 09:33:00.766906 22542570456896 run_lib.py:133] step: 456200, training_loss: 2.43134e-02
I0210 09:33:00.928119 22542570456896 run_lib.py:146] step: 456200, eval_loss: 2.56715e-02
I0210 09:33:18.565745 22542570456896 run_lib.py:133] step: 456250, training_loss: 2.43901e-02
I0210 09:33:36.128114 22542570456896 run_lib.py:133] step: 456300, training_loss: 2.95935e-02
I0210 09:33:36.285311 22542570456896 run_lib.py:146] step: 456300, eval_loss: 2.95081e-02
I0210 09:33:53.754223 22542570456896 run_lib.py:133] step: 456350, training_loss: 2.65702e-02
I0210 09:34:11.185466 22542570456896 run_lib.py:133] step: 456400, training_loss: 3.38155e-02
I0210 09:34:11.346483 22542570456896 run_lib.py:146] step: 456400, eval_loss: 2.90966e-02
I0210 09:34:28.913520 22542570456896 run_lib.py:133] step: 456450, training_loss: 2.71426e-02
I0210 09:34:46.406889 22542570456896 run_lib.py:133] step: 456500, training_loss: 2.56800e-02
I0210 09:34:46.581382 22542570456896 run_lib.py:146] step: 456500, eval_loss: 2.43661e-02
I0210 09:35:04.091562 22542570456896 run_lib.py:133] step: 456550, training_loss: 2.49663e-02
I0210 09:35:21.537546 22542570456896 run_lib.py:133] step: 456600, training_loss: 3.02092e-02
I0210 09:35:21.693674 22542570456896 run_lib.py:146] step: 456600, eval_loss: 2.74236e-02
I0210 09:35:39.302299 22542570456896 run_lib.py:133] step: 456650, training_loss: 2.76339e-02
I0210 09:35:56.708269 22542570456896 run_lib.py:133] step: 456700, training_loss: 2.40290e-02
I0210 09:35:56.867086 22542570456896 run_lib.py:146] step: 456700, eval_loss: 2.79476e-02
I0210 09:36:14.506319 22542570456896 run_lib.py:133] step: 456750, training_loss: 3.28666e-02
I0210 09:36:31.964684 22542570456896 run_lib.py:133] step: 456800, training_loss: 2.86598e-02
I0210 09:36:32.118522 22542570456896 run_lib.py:146] step: 456800, eval_loss: 2.56453e-02
I0210 09:36:49.773806 22542570456896 run_lib.py:133] step: 456850, training_loss: 2.29723e-02
I0210 09:37:07.166234 22542570456896 run_lib.py:133] step: 456900, training_loss: 2.72931e-02
I0210 09:37:07.321561 22542570456896 run_lib.py:146] step: 456900, eval_loss: 2.70205e-02
I0210 09:37:24.731035 22542570456896 run_lib.py:133] step: 456950, training_loss: 2.11688e-02
I0210 09:37:42.311993 22542570456896 run_lib.py:133] step: 457000, training_loss: 2.58702e-02
I0210 09:37:42.469620 22542570456896 run_lib.py:146] step: 457000, eval_loss: 2.81995e-02
I0210 09:37:59.919186 22542570456896 run_lib.py:133] step: 457050, training_loss: 3.16995e-02
I0210 09:38:17.570553 22542570456896 run_lib.py:133] step: 457100, training_loss: 2.43935e-02
I0210 09:38:17.733642 22542570456896 run_lib.py:146] step: 457100, eval_loss: 3.25267e-02
I0210 09:38:35.158620 22542570456896 run_lib.py:133] step: 457150, training_loss: 2.70796e-02
I0210 09:38:52.633833 22542570456896 run_lib.py:133] step: 457200, training_loss: 2.55554e-02
I0210 09:38:52.790462 22542570456896 run_lib.py:146] step: 457200, eval_loss: 2.57101e-02
I0210 09:39:10.402585 22542570456896 run_lib.py:133] step: 457250, training_loss: 2.55214e-02
I0210 09:39:27.864668 22542570456896 run_lib.py:133] step: 457300, training_loss: 2.67587e-02
I0210 09:39:28.024130 22542570456896 run_lib.py:146] step: 457300, eval_loss: 3.66371e-02
I0210 09:39:45.467589 22542570456896 run_lib.py:133] step: 457350, training_loss: 2.54056e-02
I0210 09:40:02.961551 22542570456896 run_lib.py:133] step: 457400, training_loss: 2.52456e-02
I0210 09:40:03.132365 22542570456896 run_lib.py:146] step: 457400, eval_loss: 2.43409e-02
I0210 09:40:20.765424 22542570456896 run_lib.py:133] step: 457450, training_loss: 2.68144e-02
I0210 09:40:38.227165 22542570456896 run_lib.py:133] step: 457500, training_loss: 2.41795e-02
I0210 09:40:38.384855 22542570456896 run_lib.py:146] step: 457500, eval_loss: 2.22425e-02
I0210 09:40:55.882636 22542570456896 run_lib.py:133] step: 457550, training_loss: 2.97574e-02
I0210 09:41:13.307677 22542570456896 run_lib.py:133] step: 457600, training_loss: 3.15026e-02
I0210 09:41:13.484307 22542570456896 run_lib.py:146] step: 457600, eval_loss: 2.78827e-02
I0210 09:41:30.978267 22542570456896 run_lib.py:133] step: 457650, training_loss: 3.20868e-02
I0210 09:41:48.435442 22542570456896 run_lib.py:133] step: 457700, training_loss: 3.00146e-02
I0210 09:41:48.590250 22542570456896 run_lib.py:146] step: 457700, eval_loss: 2.39461e-02
I0210 09:42:06.242676 22542570456896 run_lib.py:133] step: 457750, training_loss: 2.84745e-02
I0210 09:42:23.762955 22542570456896 run_lib.py:133] step: 457800, training_loss: 2.76595e-02
I0210 09:42:23.918449 22542570456896 run_lib.py:146] step: 457800, eval_loss: 2.66834e-02
I0210 09:42:41.342637 22542570456896 run_lib.py:133] step: 457850, training_loss: 3.13097e-02
I0210 09:42:58.810948 22542570456896 run_lib.py:133] step: 457900, training_loss: 3.12354e-02
I0210 09:42:58.988446 22542570456896 run_lib.py:146] step: 457900, eval_loss: 2.52016e-02
I0210 09:43:16.633264 22542570456896 run_lib.py:133] step: 457950, training_loss: 2.76003e-02
I0210 09:43:34.113627 22542570456896 run_lib.py:133] step: 458000, training_loss: 3.28448e-02
I0210 09:43:34.265795 22542570456896 run_lib.py:146] step: 458000, eval_loss: 3.28410e-02
I0210 09:43:51.839937 22542570456896 run_lib.py:133] step: 458050, training_loss: 2.72186e-02
I0210 09:44:09.267757 22542570456896 run_lib.py:133] step: 458100, training_loss: 2.95665e-02
I0210 09:44:09.423362 22542570456896 run_lib.py:146] step: 458100, eval_loss: 3.51172e-02
I0210 09:44:26.997035 22542570456896 run_lib.py:133] step: 458150, training_loss: 3.27152e-02
I0210 09:44:44.519350 22542570456896 run_lib.py:133] step: 458200, training_loss: 3.79174e-02
I0210 09:44:44.672186 22542570456896 run_lib.py:146] step: 458200, eval_loss: 2.74949e-02
I0210 09:45:02.286794 22542570456896 run_lib.py:133] step: 458250, training_loss: 3.20025e-02
I0210 09:45:19.666026 22542570456896 run_lib.py:133] step: 458300, training_loss: 2.75702e-02
I0210 09:45:19.819370 22542570456896 run_lib.py:146] step: 458300, eval_loss: 3.01523e-02
I0210 09:45:37.177433 22542570456896 run_lib.py:133] step: 458350, training_loss: 3.26781e-02
I0210 09:45:54.816040 22542570456896 run_lib.py:133] step: 458400, training_loss: 2.13745e-02
I0210 09:45:54.974669 22542570456896 run_lib.py:146] step: 458400, eval_loss: 2.79033e-02
I0210 09:46:12.476821 22542570456896 run_lib.py:133] step: 458450, training_loss: 2.67177e-02
I0210 09:46:29.981194 22542570456896 run_lib.py:133] step: 458500, training_loss: 2.88585e-02
I0210 09:46:30.139728 22542570456896 run_lib.py:146] step: 458500, eval_loss: 2.85748e-02
I0210 09:46:47.769890 22542570456896 run_lib.py:133] step: 458550, training_loss: 3.63920e-02
I0210 09:47:05.355388 22542570456896 run_lib.py:133] step: 458600, training_loss: 2.79689e-02
I0210 09:47:05.510620 22542570456896 run_lib.py:146] step: 458600, eval_loss: 3.37329e-02
I0210 09:47:22.953358 22542570456896 run_lib.py:133] step: 458650, training_loss: 2.22117e-02
I0210 09:47:40.388153 22542570456896 run_lib.py:133] step: 458700, training_loss: 2.75893e-02
I0210 09:47:40.540475 22542570456896 run_lib.py:146] step: 458700, eval_loss: 2.27760e-02
I0210 09:47:58.064718 22542570456896 run_lib.py:133] step: 458750, training_loss: 2.55254e-02
I0210 09:48:15.649135 22542570456896 run_lib.py:133] step: 458800, training_loss: 2.80092e-02
I0210 09:48:15.804330 22542570456896 run_lib.py:146] step: 458800, eval_loss: 3.02116e-02
I0210 09:48:33.213257 22542570456896 run_lib.py:133] step: 458850, training_loss: 2.41950e-02
I0210 09:48:50.626558 22542570456896 run_lib.py:133] step: 458900, training_loss: 2.40327e-02
I0210 09:48:50.785634 22542570456896 run_lib.py:146] step: 458900, eval_loss: 2.79114e-02
I0210 09:49:08.200030 22542570456896 run_lib.py:133] step: 458950, training_loss: 3.52265e-02
I0210 09:49:25.762300 22542570456896 run_lib.py:133] step: 459000, training_loss: 2.46413e-02
I0210 09:49:25.932333 22542570456896 run_lib.py:146] step: 459000, eval_loss: 4.17924e-02
I0210 09:49:43.413261 22542570456896 run_lib.py:133] step: 459050, training_loss: 3.33049e-02
I0210 09:50:00.956516 22542570456896 run_lib.py:133] step: 459100, training_loss: 2.90372e-02
I0210 09:50:01.111677 22542570456896 run_lib.py:146] step: 459100, eval_loss: 3.30535e-02
I0210 09:50:18.554087 22542570456896 run_lib.py:133] step: 459150, training_loss: 2.56545e-02
I0210 09:50:35.988387 22542570456896 run_lib.py:133] step: 459200, training_loss: 2.76048e-02
I0210 09:50:36.140392 22542570456896 run_lib.py:146] step: 459200, eval_loss: 2.57117e-02
I0210 09:50:53.710649 22542570456896 run_lib.py:133] step: 459250, training_loss: 3.36776e-02
I0210 09:51:11.185004 22542570456896 run_lib.py:133] step: 459300, training_loss: 2.38107e-02
I0210 09:51:11.362330 22542570456896 run_lib.py:146] step: 459300, eval_loss: 2.82499e-02
I0210 09:51:28.898894 22542570456896 run_lib.py:133] step: 459350, training_loss: 2.88742e-02
I0210 09:51:46.322022 22542570456896 run_lib.py:133] step: 459400, training_loss: 2.40536e-02
I0210 09:51:46.478452 22542570456896 run_lib.py:146] step: 459400, eval_loss: 3.43296e-02
I0210 09:52:04.076514 22542570456896 run_lib.py:133] step: 459450, training_loss: 2.28198e-02
I0210 09:52:21.491740 22542570456896 run_lib.py:133] step: 459500, training_loss: 2.82510e-02
I0210 09:52:21.647596 22542570456896 run_lib.py:146] step: 459500, eval_loss: 2.86984e-02
I0210 09:52:39.269083 22542570456896 run_lib.py:133] step: 459550, training_loss: 2.61081e-02
I0210 09:52:56.713747 22542570456896 run_lib.py:133] step: 459600, training_loss: 2.30576e-02
I0210 09:52:56.869827 22542570456896 run_lib.py:146] step: 459600, eval_loss: 3.32645e-02
I0210 09:53:14.476574 22542570456896 run_lib.py:133] step: 459650, training_loss: 3.30836e-02
I0210 09:53:31.893974 22542570456896 run_lib.py:133] step: 459700, training_loss: 2.62265e-02
I0210 09:53:32.047359 22542570456896 run_lib.py:146] step: 459700, eval_loss: 2.63706e-02
I0210 09:53:49.520237 22542570456896 run_lib.py:133] step: 459750, training_loss: 2.50173e-02
I0210 09:54:07.114693 22542570456896 run_lib.py:133] step: 459800, training_loss: 3.56114e-02
I0210 09:54:07.272851 22542570456896 run_lib.py:146] step: 459800, eval_loss: 3.67859e-02
I0210 09:54:24.732933 22542570456896 run_lib.py:133] step: 459850, training_loss: 2.40011e-02
I0210 09:54:42.399687 22542570456896 run_lib.py:133] step: 459900, training_loss: 3.23328e-02
I0210 09:54:42.556679 22542570456896 run_lib.py:146] step: 459900, eval_loss: 2.97833e-02
I0210 09:55:00.007046 22542570456896 run_lib.py:133] step: 459950, training_loss: 3.19595e-02
I0210 09:55:17.428964 22542570456896 run_lib.py:133] step: 460000, training_loss: 2.44103e-02
I0210 09:55:18.175360 22542570456896 run_lib.py:146] step: 460000, eval_loss: 2.73593e-02
I0210 09:55:38.434241 22542570456896 run_lib.py:133] step: 460050, training_loss: 3.38903e-02
I0210 09:55:56.072716 22542570456896 run_lib.py:133] step: 460100, training_loss: 3.23028e-02
I0210 09:55:56.237796 22542570456896 run_lib.py:146] step: 460100, eval_loss: 2.21169e-02
I0210 09:56:13.735783 22542570456896 run_lib.py:133] step: 460150, training_loss: 2.95306e-02
I0210 09:56:31.361481 22542570456896 run_lib.py:133] step: 460200, training_loss: 2.56654e-02
I0210 09:56:31.518332 22542570456896 run_lib.py:146] step: 460200, eval_loss: 2.61383e-02
I0210 09:56:48.934799 22542570456896 run_lib.py:133] step: 460250, training_loss: 2.53549e-02
I0210 09:57:06.403432 22542570456896 run_lib.py:133] step: 460300, training_loss: 2.39641e-02
I0210 09:57:06.559368 22542570456896 run_lib.py:146] step: 460300, eval_loss: 3.26851e-02
I0210 09:57:24.162289 22542570456896 run_lib.py:133] step: 460350, training_loss: 1.96390e-02
I0210 09:57:41.657596 22542570456896 run_lib.py:133] step: 460400, training_loss: 3.11971e-02
I0210 09:57:41.834407 22542570456896 run_lib.py:146] step: 460400, eval_loss: 2.39375e-02
I0210 09:57:59.455454 22542570456896 run_lib.py:133] step: 460450, training_loss: 3.36235e-02
I0210 09:58:16.881130 22542570456896 run_lib.py:133] step: 460500, training_loss: 3.07809e-02
I0210 09:58:17.037753 22542570456896 run_lib.py:146] step: 460500, eval_loss: 2.53751e-02
I0210 09:58:34.493358 22542570456896 run_lib.py:133] step: 460550, training_loss: 2.61652e-02
I0210 09:58:52.101196 22542570456896 run_lib.py:133] step: 460600, training_loss: 2.78138e-02
I0210 09:58:52.268239 22542570456896 run_lib.py:146] step: 460600, eval_loss: 2.46043e-02
I0210 09:59:09.723175 22542570456896 run_lib.py:133] step: 460650, training_loss: 2.06341e-02
I0210 09:59:27.226289 22542570456896 run_lib.py:133] step: 460700, training_loss: 3.12072e-02
I0210 09:59:27.387517 22542570456896 run_lib.py:146] step: 460700, eval_loss: 2.83246e-02
I0210 09:59:44.824501 22542570456896 run_lib.py:133] step: 460750, training_loss: 2.32234e-02
I0210 10:00:02.450829 22542570456896 run_lib.py:133] step: 460800, training_loss: 3.02429e-02
I0210 10:00:02.609637 22542570456896 run_lib.py:146] step: 460800, eval_loss: 3.66418e-02
I0210 10:00:20.039377 22542570456896 run_lib.py:133] step: 460850, training_loss: 2.45157e-02
I0210 10:00:37.558213 22542570456896 run_lib.py:133] step: 460900, training_loss: 3.29318e-02
I0210 10:00:37.728601 22542570456896 run_lib.py:146] step: 460900, eval_loss: 2.79328e-02
I0210 10:00:55.161989 22542570456896 run_lib.py:133] step: 460950, training_loss: 2.40551e-02
I0210 10:01:12.603269 22542570456896 run_lib.py:133] step: 461000, training_loss: 1.99982e-02
I0210 10:01:12.759177 22542570456896 run_lib.py:146] step: 461000, eval_loss: 2.73579e-02
I0210 10:01:30.384078 22542570456896 run_lib.py:133] step: 461050, training_loss: 2.68997e-02
I0210 10:01:47.868897 22542570456896 run_lib.py:133] step: 461100, training_loss: 2.46607e-02
I0210 10:01:48.025066 22542570456896 run_lib.py:146] step: 461100, eval_loss: 2.89501e-02
I0210 10:02:05.432334 22542570456896 run_lib.py:133] step: 461150, training_loss: 2.99756e-02
I0210 10:02:22.857029 22542570456896 run_lib.py:133] step: 461200, training_loss: 2.34035e-02
I0210 10:02:23.019679 22542570456896 run_lib.py:146] step: 461200, eval_loss: 3.81708e-02
I0210 10:02:40.702189 22542570456896 run_lib.py:133] step: 461250, training_loss: 3.31289e-02
I0210 10:02:58.164322 22542570456896 run_lib.py:133] step: 461300, training_loss: 2.77102e-02
I0210 10:02:58.323415 22542570456896 run_lib.py:146] step: 461300, eval_loss: 3.07583e-02
I0210 10:03:15.930029 22542570456896 run_lib.py:133] step: 461350, training_loss: 3.39935e-02
I0210 10:03:33.326392 22542570456896 run_lib.py:133] step: 461400, training_loss: 3.05880e-02
I0210 10:03:33.481316 22542570456896 run_lib.py:146] step: 461400, eval_loss: 2.71064e-02
I0210 10:03:51.043344 22542570456896 run_lib.py:133] step: 461450, training_loss: 2.98334e-02
I0210 10:04:08.523717 22542570456896 run_lib.py:133] step: 461500, training_loss: 2.09792e-02
I0210 10:04:08.681113 22542570456896 run_lib.py:146] step: 461500, eval_loss: 2.82043e-02
I0210 10:04:26.127935 22542570456896 run_lib.py:133] step: 461550, training_loss: 3.13963e-02
I0210 10:04:43.757237 22542570456896 run_lib.py:133] step: 461600, training_loss: 2.16516e-02
I0210 10:04:43.911253 22542570456896 run_lib.py:146] step: 461600, eval_loss: 2.76683e-02
I0210 10:05:01.317364 22542570456896 run_lib.py:133] step: 461650, training_loss: 3.42218e-02
I0210 10:05:18.918843 22542570456896 run_lib.py:133] step: 461700, training_loss: 2.78948e-02
I0210 10:05:19.072893 22542570456896 run_lib.py:146] step: 461700, eval_loss: 2.86458e-02
I0210 10:05:36.536513 22542570456896 run_lib.py:133] step: 461750, training_loss: 2.90555e-02
I0210 10:05:54.000325 22542570456896 run_lib.py:133] step: 461800, training_loss: 2.58575e-02
I0210 10:05:54.167469 22542570456896 run_lib.py:146] step: 461800, eval_loss: 2.80899e-02
I0210 10:06:11.827856 22542570456896 run_lib.py:133] step: 461850, training_loss: 3.30466e-02
I0210 10:06:29.256821 22542570456896 run_lib.py:133] step: 461900, training_loss: 2.85627e-02
I0210 10:06:29.412276 22542570456896 run_lib.py:146] step: 461900, eval_loss: 3.64938e-02
I0210 10:06:46.877229 22542570456896 run_lib.py:133] step: 461950, training_loss: 2.62132e-02
I0210 10:07:04.463204 22542570456896 run_lib.py:133] step: 462000, training_loss: 3.27481e-02
I0210 10:07:04.619728 22542570456896 run_lib.py:146] step: 462000, eval_loss: 3.09146e-02
I0210 10:07:22.095475 22542570456896 run_lib.py:133] step: 462050, training_loss: 2.29894e-02
I0210 10:07:39.576718 22542570456896 run_lib.py:133] step: 462100, training_loss: 3.50675e-02
I0210 10:07:39.728626 22542570456896 run_lib.py:146] step: 462100, eval_loss: 2.45780e-02
I0210 10:07:57.290241 22542570456896 run_lib.py:133] step: 462150, training_loss: 3.42510e-02
I0210 10:08:14.698137 22542570456896 run_lib.py:133] step: 462200, training_loss: 2.46283e-02
I0210 10:08:14.854375 22542570456896 run_lib.py:146] step: 462200, eval_loss: 3.71953e-02
I0210 10:08:32.272413 22542570456896 run_lib.py:133] step: 462250, training_loss: 2.80805e-02
I0210 10:08:49.722635 22542570456896 run_lib.py:133] step: 462300, training_loss: 2.63468e-02
I0210 10:08:49.899297 22542570456896 run_lib.py:146] step: 462300, eval_loss: 2.75782e-02
I0210 10:09:07.514910 22542570456896 run_lib.py:133] step: 462350, training_loss: 2.92587e-02
I0210 10:09:25.037403 22542570456896 run_lib.py:133] step: 462400, training_loss: 2.40924e-02
I0210 10:09:25.189708 22542570456896 run_lib.py:146] step: 462400, eval_loss: 2.85832e-02
I0210 10:09:42.635284 22542570456896 run_lib.py:133] step: 462450, training_loss: 2.63047e-02
I0210 10:10:00.054456 22542570456896 run_lib.py:133] step: 462500, training_loss: 2.55627e-02
I0210 10:10:00.210439 22542570456896 run_lib.py:146] step: 462500, eval_loss: 2.60759e-02
I0210 10:10:17.745055 22542570456896 run_lib.py:133] step: 462550, training_loss: 2.38703e-02
I0210 10:10:35.195738 22542570456896 run_lib.py:133] step: 462600, training_loss: 2.53809e-02
I0210 10:10:35.350605 22542570456896 run_lib.py:146] step: 462600, eval_loss: 2.94523e-02
I0210 10:10:53.001955 22542570456896 run_lib.py:133] step: 462650, training_loss: 2.90175e-02
I0210 10:11:10.436237 22542570456896 run_lib.py:133] step: 462700, training_loss: 2.19064e-02
I0210 10:11:10.596529 22542570456896 run_lib.py:146] step: 462700, eval_loss: 2.83652e-02
I0210 10:11:28.169067 22542570456896 run_lib.py:133] step: 462750, training_loss: 2.77363e-02
I0210 10:11:45.586341 22542570456896 run_lib.py:133] step: 462800, training_loss: 2.65516e-02
I0210 10:11:45.742867 22542570456896 run_lib.py:146] step: 462800, eval_loss: 3.00258e-02
I0210 10:12:03.335058 22542570456896 run_lib.py:133] step: 462850, training_loss: 3.44844e-02
I0210 10:12:20.820025 22542570456896 run_lib.py:133] step: 462900, training_loss: 2.55997e-02
I0210 10:12:20.975363 22542570456896 run_lib.py:146] step: 462900, eval_loss: 2.82061e-02
I0210 10:12:38.427761 22542570456896 run_lib.py:133] step: 462950, training_loss: 3.56619e-02
I0210 10:12:56.030026 22542570456896 run_lib.py:133] step: 463000, training_loss: 2.31385e-02
I0210 10:12:56.183204 22542570456896 run_lib.py:146] step: 463000, eval_loss: 2.39133e-02
I0210 10:13:13.618077 22542570456896 run_lib.py:133] step: 463050, training_loss: 3.30402e-02
I0210 10:13:31.024312 22542570456896 run_lib.py:133] step: 463100, training_loss: 2.69947e-02
I0210 10:13:31.175469 22542570456896 run_lib.py:146] step: 463100, eval_loss: 2.52699e-02
I0210 10:13:48.758691 22542570456896 run_lib.py:133] step: 463150, training_loss: 2.74772e-02
I0210 10:14:06.258990 22542570456896 run_lib.py:133] step: 463200, training_loss: 2.65489e-02
I0210 10:14:06.418421 22542570456896 run_lib.py:146] step: 463200, eval_loss: 2.26146e-02
I0210 10:14:24.110343 22542570456896 run_lib.py:133] step: 463250, training_loss: 2.85455e-02
I0210 10:14:41.546952 22542570456896 run_lib.py:133] step: 463300, training_loss: 2.43931e-02
I0210 10:14:41.702472 22542570456896 run_lib.py:146] step: 463300, eval_loss: 2.22187e-02
I0210 10:14:59.140618 22542570456896 run_lib.py:133] step: 463350, training_loss: 2.53565e-02
I0210 10:15:16.751407 22542570456896 run_lib.py:133] step: 463400, training_loss: 2.66427e-02
I0210 10:15:16.918556 22542570456896 run_lib.py:146] step: 463400, eval_loss: 2.83022e-02
I0210 10:15:34.423665 22542570456896 run_lib.py:133] step: 463450, training_loss: 2.53145e-02
I0210 10:15:51.864488 22542570456896 run_lib.py:133] step: 463500, training_loss: 4.13311e-02
I0210 10:15:52.017611 22542570456896 run_lib.py:146] step: 463500, eval_loss: 2.70381e-02
I0210 10:16:09.428912 22542570456896 run_lib.py:133] step: 463550, training_loss: 2.69277e-02
I0210 10:16:27.040241 22542570456896 run_lib.py:133] step: 463600, training_loss: 2.63561e-02
I0210 10:16:27.196466 22542570456896 run_lib.py:146] step: 463600, eval_loss: 3.69474e-02
I0210 10:16:44.609670 22542570456896 run_lib.py:133] step: 463650, training_loss: 2.38499e-02
I0210 10:17:02.088296 22542570456896 run_lib.py:133] step: 463700, training_loss: 2.38723e-02
I0210 10:17:02.261238 22542570456896 run_lib.py:146] step: 463700, eval_loss: 3.26981e-02
I0210 10:17:19.764148 22542570456896 run_lib.py:133] step: 463750, training_loss: 2.99585e-02
I0210 10:17:37.216276 22542570456896 run_lib.py:133] step: 463800, training_loss: 2.43006e-02
I0210 10:17:37.381655 22542570456896 run_lib.py:146] step: 463800, eval_loss: 2.46567e-02
I0210 10:17:55.019475 22542570456896 run_lib.py:133] step: 463850, training_loss: 2.66083e-02
I0210 10:18:12.500162 22542570456896 run_lib.py:133] step: 463900, training_loss: 2.66185e-02
I0210 10:18:12.657546 22542570456896 run_lib.py:146] step: 463900, eval_loss: 2.52610e-02
I0210 10:18:30.085496 22542570456896 run_lib.py:133] step: 463950, training_loss: 2.99491e-02
I0210 10:18:47.580643 22542570456896 run_lib.py:133] step: 464000, training_loss: 2.55059e-02
I0210 10:18:47.734681 22542570456896 run_lib.py:146] step: 464000, eval_loss: 2.24221e-02
I0210 10:19:05.414959 22542570456896 run_lib.py:133] step: 464050, training_loss: 3.01033e-02
I0210 10:19:22.831015 22542570456896 run_lib.py:133] step: 464100, training_loss: 2.64687e-02
I0210 10:19:22.986449 22542570456896 run_lib.py:146] step: 464100, eval_loss: 2.99166e-02
I0210 10:19:40.565171 22542570456896 run_lib.py:133] step: 464150, training_loss: 3.08118e-02
I0210 10:19:57.981969 22542570456896 run_lib.py:133] step: 464200, training_loss: 2.80574e-02
I0210 10:19:58.141604 22542570456896 run_lib.py:146] step: 464200, eval_loss: 3.03700e-02
I0210 10:20:15.761266 22542570456896 run_lib.py:133] step: 464250, training_loss: 2.53000e-02
I0210 10:20:33.240652 22542570456896 run_lib.py:133] step: 464300, training_loss: 2.55540e-02
I0210 10:20:33.397626 22542570456896 run_lib.py:146] step: 464300, eval_loss: 2.74586e-02
I0210 10:20:50.857582 22542570456896 run_lib.py:133] step: 464350, training_loss: 2.60847e-02
I0210 10:21:08.484998 22542570456896 run_lib.py:133] step: 464400, training_loss: 3.17846e-02
I0210 10:21:08.648373 22542570456896 run_lib.py:146] step: 464400, eval_loss: 3.55724e-02
I0210 10:21:26.125695 22542570456896 run_lib.py:133] step: 464450, training_loss: 2.28020e-02
I0210 10:21:43.691828 22542570456896 run_lib.py:133] step: 464500, training_loss: 2.59175e-02
I0210 10:21:43.846446 22542570456896 run_lib.py:146] step: 464500, eval_loss: 2.83142e-02
I0210 10:22:01.274190 22542570456896 run_lib.py:133] step: 464550, training_loss: 2.88943e-02
I0210 10:22:18.787789 22542570456896 run_lib.py:133] step: 464600, training_loss: 2.08629e-02
I0210 10:22:18.963518 22542570456896 run_lib.py:146] step: 464600, eval_loss: 2.33639e-02
I0210 10:22:36.607582 22542570456896 run_lib.py:133] step: 464650, training_loss: 2.84790e-02
I0210 10:22:54.060473 22542570456896 run_lib.py:133] step: 464700, training_loss: 2.33504e-02
I0210 10:22:54.222543 22542570456896 run_lib.py:146] step: 464700, eval_loss: 3.18120e-02
I0210 10:23:11.648490 22542570456896 run_lib.py:133] step: 464750, training_loss: 2.28490e-02
I0210 10:23:29.205696 22542570456896 run_lib.py:133] step: 464800, training_loss: 2.89107e-02
I0210 10:23:29.361569 22542570456896 run_lib.py:146] step: 464800, eval_loss: 2.88458e-02
I0210 10:23:46.816920 22542570456896 run_lib.py:133] step: 464850, training_loss: 3.07027e-02
I0210 10:24:04.269184 22542570456896 run_lib.py:133] step: 464900, training_loss: 2.84447e-02
I0210 10:24:04.597985 22542570456896 run_lib.py:146] step: 464900, eval_loss: 3.14297e-02
I0210 10:24:22.054334 22542570456896 run_lib.py:133] step: 464950, training_loss: 3.32598e-02
I0210 10:24:39.491349 22542570456896 run_lib.py:133] step: 465000, training_loss: 3.04360e-02
I0210 10:24:39.647395 22542570456896 run_lib.py:146] step: 465000, eval_loss: 2.79981e-02
I0210 10:24:57.055614 22542570456896 run_lib.py:133] step: 465050, training_loss: 2.86409e-02
I0210 10:25:14.488948 22542570456896 run_lib.py:133] step: 465100, training_loss: 2.83215e-02
I0210 10:25:14.647653 22542570456896 run_lib.py:146] step: 465100, eval_loss: 2.50326e-02
I0210 10:25:32.280600 22542570456896 run_lib.py:133] step: 465150, training_loss: 3.83895e-02
I0210 10:25:49.904572 22542570456896 run_lib.py:133] step: 465200, training_loss: 2.38069e-02
I0210 10:25:50.060664 22542570456896 run_lib.py:146] step: 465200, eval_loss: 2.82097e-02
I0210 10:26:07.480978 22542570456896 run_lib.py:133] step: 465250, training_loss: 2.32999e-02
I0210 10:26:24.910841 22542570456896 run_lib.py:133] step: 465300, training_loss: 3.74706e-02
I0210 10:26:25.069116 22542570456896 run_lib.py:146] step: 465300, eval_loss: 3.00982e-02
I0210 10:26:42.635547 22542570456896 run_lib.py:133] step: 465350, training_loss: 3.14766e-02
I0210 10:27:00.149414 22542570456896 run_lib.py:133] step: 465400, training_loss: 2.51342e-02
I0210 10:27:00.302154 22542570456896 run_lib.py:146] step: 465400, eval_loss: 3.14894e-02
I0210 10:27:17.735716 22542570456896 run_lib.py:133] step: 465450, training_loss: 2.51342e-02
I0210 10:27:35.226895 22542570456896 run_lib.py:133] step: 465500, training_loss: 3.29059e-02
I0210 10:27:35.388657 22542570456896 run_lib.py:146] step: 465500, eval_loss: 2.57336e-02
I0210 10:27:53.009575 22542570456896 run_lib.py:133] step: 465550, training_loss: 3.48744e-02
I0210 10:28:10.472261 22542570456896 run_lib.py:133] step: 465600, training_loss: 3.37512e-02
I0210 10:28:10.631698 22542570456896 run_lib.py:146] step: 465600, eval_loss: 2.10152e-02
I0210 10:28:28.214919 22542570456896 run_lib.py:133] step: 465650, training_loss: 2.29369e-02
I0210 10:28:45.641477 22542570456896 run_lib.py:133] step: 465700, training_loss: 2.23874e-02
I0210 10:28:45.817464 22542570456896 run_lib.py:146] step: 465700, eval_loss: 2.12275e-02
I0210 10:29:03.418589 22542570456896 run_lib.py:133] step: 465750, training_loss: 3.02047e-02
I0210 10:29:20.872021 22542570456896 run_lib.py:133] step: 465800, training_loss: 2.23258e-02
I0210 10:29:21.028126 22542570456896 run_lib.py:146] step: 465800, eval_loss: 3.15533e-02
I0210 10:29:38.440576 22542570456896 run_lib.py:133] step: 465850, training_loss: 3.62566e-02
I0210 10:29:56.036828 22542570456896 run_lib.py:133] step: 465900, training_loss: 2.57237e-02
I0210 10:29:56.188361 22542570456896 run_lib.py:146] step: 465900, eval_loss: 2.73271e-02
I0210 10:30:13.595508 22542570456896 run_lib.py:133] step: 465950, training_loss: 1.76131e-02
I0210 10:30:31.156587 22542570456896 run_lib.py:133] step: 466000, training_loss: 3.09479e-02
I0210 10:30:31.325675 22542570456896 run_lib.py:146] step: 466000, eval_loss: 2.30324e-02
I0210 10:30:48.810593 22542570456896 run_lib.py:133] step: 466050, training_loss: 2.09696e-02
I0210 10:31:06.255781 22542570456896 run_lib.py:133] step: 466100, training_loss: 3.50273e-02
I0210 10:31:06.413300 22542570456896 run_lib.py:146] step: 466100, eval_loss: 2.70166e-02
I0210 10:31:24.038643 22542570456896 run_lib.py:133] step: 466150, training_loss: 2.80563e-02
I0210 10:31:41.461160 22542570456896 run_lib.py:133] step: 466200, training_loss: 2.53669e-02
I0210 10:31:41.614155 22542570456896 run_lib.py:146] step: 466200, eval_loss: 2.49061e-02
I0210 10:31:59.044149 22542570456896 run_lib.py:133] step: 466250, training_loss: 2.72068e-02
I0210 10:32:16.476392 22542570456896 run_lib.py:133] step: 466300, training_loss: 2.83502e-02
I0210 10:32:16.632057 22542570456896 run_lib.py:146] step: 466300, eval_loss: 2.62247e-02
I0210 10:32:34.290351 22542570456896 run_lib.py:133] step: 466350, training_loss: 2.44607e-02
I0210 10:32:51.706763 22542570456896 run_lib.py:133] step: 466400, training_loss: 3.02166e-02
I0210 10:32:51.859357 22542570456896 run_lib.py:146] step: 466400, eval_loss: 3.51268e-02
I0210 10:33:09.381345 22542570456896 run_lib.py:133] step: 466450, training_loss: 3.62019e-02
I0210 10:33:26.799649 22542570456896 run_lib.py:133] step: 466500, training_loss: 2.35490e-02
I0210 10:33:26.958817 22542570456896 run_lib.py:146] step: 466500, eval_loss: 2.77776e-02
I0210 10:33:44.378214 22542570456896 run_lib.py:133] step: 466550, training_loss: 3.34459e-02
I0210 10:34:01.810744 22542570456896 run_lib.py:133] step: 466600, training_loss: 2.45397e-02
I0210 10:34:01.983446 22542570456896 run_lib.py:146] step: 466600, eval_loss: 3.47047e-02
I0210 10:34:19.622284 22542570456896 run_lib.py:133] step: 466650, training_loss: 2.58506e-02
I0210 10:34:37.157723 22542570456896 run_lib.py:133] step: 466700, training_loss: 2.69130e-02
I0210 10:34:37.313495 22542570456896 run_lib.py:146] step: 466700, eval_loss: 2.90637e-02
I0210 10:34:54.764332 22542570456896 run_lib.py:133] step: 466750, training_loss: 2.57339e-02
I0210 10:35:12.230856 22542570456896 run_lib.py:133] step: 466800, training_loss: 2.81724e-02
I0210 10:35:12.384135 22542570456896 run_lib.py:146] step: 466800, eval_loss: 2.72153e-02
I0210 10:35:29.929366 22542570456896 run_lib.py:133] step: 466850, training_loss: 2.46297e-02
I0210 10:35:47.383630 22542570456896 run_lib.py:133] step: 466900, training_loss: 2.43943e-02
I0210 10:35:47.545598 22542570456896 run_lib.py:146] step: 466900, eval_loss: 2.24706e-02
I0210 10:36:05.237956 22542570456896 run_lib.py:133] step: 466950, training_loss: 2.82561e-02
I0210 10:36:22.672795 22542570456896 run_lib.py:133] step: 467000, training_loss: 3.22465e-02
I0210 10:36:22.828605 22542570456896 run_lib.py:146] step: 467000, eval_loss: 2.66098e-02
I0210 10:36:40.402268 22542570456896 run_lib.py:133] step: 467050, training_loss: 3.27759e-02
I0210 10:36:57.837149 22542570456896 run_lib.py:133] step: 467100, training_loss: 2.93447e-02
I0210 10:36:58.008085 22542570456896 run_lib.py:146] step: 467100, eval_loss: 2.65041e-02
I0210 10:37:15.635123 22542570456896 run_lib.py:133] step: 467150, training_loss: 2.44949e-02
I0210 10:37:33.059908 22542570456896 run_lib.py:133] step: 467200, training_loss: 3.23683e-02
I0210 10:37:33.216678 22542570456896 run_lib.py:146] step: 467200, eval_loss: 3.66853e-02
I0210 10:37:50.686578 22542570456896 run_lib.py:133] step: 467250, training_loss: 2.79045e-02
I0210 10:38:08.255848 22542570456896 run_lib.py:133] step: 467300, training_loss: 2.71878e-02
I0210 10:38:08.407528 22542570456896 run_lib.py:146] step: 467300, eval_loss: 3.11978e-02
I0210 10:38:25.838521 22542570456896 run_lib.py:133] step: 467350, training_loss: 2.22712e-02
I0210 10:38:43.260739 22542570456896 run_lib.py:133] step: 467400, training_loss: 2.72939e-02
I0210 10:38:43.430598 22542570456896 run_lib.py:146] step: 467400, eval_loss: 2.51869e-02
I0210 10:39:01.068761 22542570456896 run_lib.py:133] step: 467450, training_loss: 2.80227e-02
I0210 10:39:18.705693 22542570456896 run_lib.py:133] step: 467500, training_loss: 2.66588e-02
I0210 10:39:18.864493 22542570456896 run_lib.py:146] step: 467500, eval_loss: 2.88876e-02
I0210 10:39:36.289774 22542570456896 run_lib.py:133] step: 467550, training_loss: 2.30383e-02
I0210 10:39:53.748954 22542570456896 run_lib.py:133] step: 467600, training_loss: 2.80699e-02
I0210 10:39:53.911481 22542570456896 run_lib.py:146] step: 467600, eval_loss: 3.22855e-02
I0210 10:40:11.317083 22542570456896 run_lib.py:133] step: 467650, training_loss: 2.64186e-02
I0210 10:40:28.923780 22542570456896 run_lib.py:133] step: 467700, training_loss: 2.62563e-02
I0210 10:40:29.085403 22542570456896 run_lib.py:146] step: 467700, eval_loss: 2.94955e-02
I0210 10:40:46.570414 22542570456896 run_lib.py:133] step: 467750, training_loss: 2.74658e-02
I0210 10:41:03.981481 22542570456896 run_lib.py:133] step: 467800, training_loss: 2.77977e-02
I0210 10:41:04.134404 22542570456896 run_lib.py:146] step: 467800, eval_loss: 2.73567e-02
I0210 10:41:21.538470 22542570456896 run_lib.py:133] step: 467850, training_loss: 2.35326e-02
I0210 10:41:39.162802 22542570456896 run_lib.py:133] step: 467900, training_loss: 2.05815e-02
I0210 10:41:39.319267 22542570456896 run_lib.py:146] step: 467900, eval_loss: 2.75505e-02
I0210 10:41:56.804033 22542570456896 run_lib.py:133] step: 467950, training_loss: 2.93923e-02
I0210 10:42:14.350050 22542570456896 run_lib.py:133] step: 468000, training_loss: 2.39634e-02
I0210 10:42:14.509316 22542570456896 run_lib.py:146] step: 468000, eval_loss: 2.59922e-02
I0210 10:42:31.940580 22542570456896 run_lib.py:133] step: 468050, training_loss: 3.05321e-02
I0210 10:42:49.378424 22542570456896 run_lib.py:133] step: 468100, training_loss: 2.45401e-02
I0210 10:42:49.533584 22542570456896 run_lib.py:146] step: 468100, eval_loss: 2.86611e-02
I0210 10:43:07.161657 22542570456896 run_lib.py:133] step: 468150, training_loss: 2.60823e-02
I0210 10:43:24.659204 22542570456896 run_lib.py:133] step: 468200, training_loss: 3.74107e-02
I0210 10:43:24.817341 22542570456896 run_lib.py:146] step: 468200, eval_loss: 3.00153e-02
I0210 10:43:42.300428 22542570456896 run_lib.py:133] step: 468250, training_loss: 3.34850e-02
I0210 10:43:59.761675 22542570456896 run_lib.py:133] step: 468300, training_loss: 2.15667e-02
I0210 10:43:59.916542 22542570456896 run_lib.py:146] step: 468300, eval_loss: 2.33311e-02
I0210 10:44:17.580714 22542570456896 run_lib.py:133] step: 468350, training_loss: 2.44010e-02
I0210 10:44:35.011962 22542570456896 run_lib.py:133] step: 468400, training_loss: 2.35115e-02
I0210 10:44:35.174833 22542570456896 run_lib.py:146] step: 468400, eval_loss: 2.75786e-02
I0210 10:44:52.751464 22542570456896 run_lib.py:133] step: 468450, training_loss: 2.65521e-02
I0210 10:45:10.219159 22542570456896 run_lib.py:133] step: 468500, training_loss: 3.19350e-02
I0210 10:45:10.390728 22542570456896 run_lib.py:146] step: 468500, eval_loss: 2.28477e-02
I0210 10:45:28.052333 22542570456896 run_lib.py:133] step: 468550, training_loss: 2.71016e-02
I0210 10:45:45.524958 22542570456896 run_lib.py:133] step: 468600, training_loss: 2.70547e-02
I0210 10:45:45.687213 22542570456896 run_lib.py:146] step: 468600, eval_loss: 2.69329e-02
I0210 10:46:03.175347 22542570456896 run_lib.py:133] step: 468650, training_loss: 2.94269e-02
I0210 10:46:20.744908 22542570456896 run_lib.py:133] step: 468700, training_loss: 3.02084e-02
I0210 10:46:20.899114 22542570456896 run_lib.py:146] step: 468700, eval_loss: 3.18316e-02
I0210 10:46:38.314736 22542570456896 run_lib.py:133] step: 468750, training_loss: 2.33348e-02
I0210 10:46:55.947036 22542570456896 run_lib.py:133] step: 468800, training_loss: 2.98570e-02
I0210 10:46:56.111638 22542570456896 run_lib.py:146] step: 468800, eval_loss: 2.40890e-02
I0210 10:47:13.570419 22542570456896 run_lib.py:133] step: 468850, training_loss: 2.86264e-02
I0210 10:47:31.029014 22542570456896 run_lib.py:133] step: 468900, training_loss: 2.80513e-02
I0210 10:47:31.196415 22542570456896 run_lib.py:146] step: 468900, eval_loss: 2.20914e-02
I0210 10:47:48.833292 22542570456896 run_lib.py:133] step: 468950, training_loss: 2.43500e-02
I0210 10:48:06.263419 22542570456896 run_lib.py:133] step: 469000, training_loss: 3.22616e-02
I0210 10:48:06.427337 22542570456896 run_lib.py:146] step: 469000, eval_loss: 2.98923e-02
I0210 10:48:23.862391 22542570456896 run_lib.py:133] step: 469050, training_loss: 2.47046e-02
I0210 10:48:41.541136 22542570456896 run_lib.py:133] step: 469100, training_loss: 3.15475e-02
I0210 10:48:41.704644 22542570456896 run_lib.py:146] step: 469100, eval_loss: 2.66125e-02
I0210 10:48:59.113107 22542570456896 run_lib.py:133] step: 469150, training_loss: 2.78686e-02
I0210 10:49:16.554497 22542570456896 run_lib.py:133] step: 469200, training_loss: 3.10098e-02
I0210 10:49:16.703413 22542570456896 run_lib.py:146] step: 469200, eval_loss: 2.54240e-02
I0210 10:49:34.233445 22542570456896 run_lib.py:133] step: 469250, training_loss: 2.49154e-02
I0210 10:49:51.710065 22542570456896 run_lib.py:133] step: 469300, training_loss: 2.66817e-02
I0210 10:49:51.872693 22542570456896 run_lib.py:146] step: 469300, eval_loss: 2.85514e-02
I0210 10:50:09.356259 22542570456896 run_lib.py:133] step: 469350, training_loss: 2.37338e-02
I0210 10:50:26.820632 22542570456896 run_lib.py:133] step: 469400, training_loss: 2.59022e-02
I0210 10:50:26.980348 22542570456896 run_lib.py:146] step: 469400, eval_loss: 3.61504e-02
I0210 10:50:44.551866 22542570456896 run_lib.py:133] step: 469450, training_loss: 2.58349e-02
I0210 10:51:02.047788 22542570456896 run_lib.py:133] step: 469500, training_loss: 2.71903e-02
I0210 10:51:02.203386 22542570456896 run_lib.py:146] step: 469500, eval_loss: 3.33418e-02
I0210 10:51:19.658725 22542570456896 run_lib.py:133] step: 469550, training_loss: 2.84434e-02
I0210 10:51:37.052067 22542570456896 run_lib.py:133] step: 469600, training_loss: 2.97837e-02
I0210 10:51:37.208658 22542570456896 run_lib.py:146] step: 469600, eval_loss: 2.57102e-02
I0210 10:51:54.856264 22542570456896 run_lib.py:133] step: 469650, training_loss: 3.15580e-02
I0210 10:52:12.294022 22542570456896 run_lib.py:133] step: 469700, training_loss: 2.93427e-02
I0210 10:52:12.446578 22542570456896 run_lib.py:146] step: 469700, eval_loss: 2.69996e-02
I0210 10:52:30.072561 22542570456896 run_lib.py:133] step: 469750, training_loss: 1.98897e-02
I0210 10:52:47.538769 22542570456896 run_lib.py:133] step: 469800, training_loss: 2.76805e-02
I0210 10:52:47.695407 22542570456896 run_lib.py:146] step: 469800, eval_loss: 2.43449e-02
I0210 10:53:05.223121 22542570456896 run_lib.py:133] step: 469850, training_loss: 2.82277e-02
I0210 10:53:22.648214 22542570456896 run_lib.py:133] step: 469900, training_loss: 2.81686e-02
I0210 10:53:22.831403 22542570456896 run_lib.py:146] step: 469900, eval_loss: 2.95534e-02
I0210 10:53:40.411044 22542570456896 run_lib.py:133] step: 469950, training_loss: 2.16182e-02
I0210 10:53:57.807188 22542570456896 run_lib.py:133] step: 470000, training_loss: 2.36687e-02
I0210 10:53:58.868947 22542570456896 run_lib.py:146] step: 470000, eval_loss: 2.73901e-02
I0210 10:54:19.037995 22542570456896 run_lib.py:133] step: 470050, training_loss: 2.71749e-02
I0210 10:54:36.634191 22542570456896 run_lib.py:133] step: 470100, training_loss: 2.52829e-02
I0210 10:54:36.789296 22542570456896 run_lib.py:146] step: 470100, eval_loss: 2.10274e-02
I0210 10:54:54.203081 22542570456896 run_lib.py:133] step: 470150, training_loss: 2.96424e-02
I0210 10:55:11.770579 22542570456896 run_lib.py:133] step: 470200, training_loss: 2.69907e-02
I0210 10:55:11.924266 22542570456896 run_lib.py:146] step: 470200, eval_loss: 2.65269e-02
I0210 10:55:29.408099 22542570456896 run_lib.py:133] step: 470250, training_loss: 1.96953e-02
I0210 10:55:46.841783 22542570456896 run_lib.py:133] step: 470300, training_loss: 3.11759e-02
I0210 10:55:47.004410 22542570456896 run_lib.py:146] step: 470300, eval_loss: 3.18620e-02
I0210 10:56:04.595333 22542570456896 run_lib.py:133] step: 470350, training_loss: 3.49167e-02
I0210 10:56:22.080008 22542570456896 run_lib.py:133] step: 470400, training_loss: 2.64405e-02
I0210 10:56:22.241568 22542570456896 run_lib.py:146] step: 470400, eval_loss: 2.84610e-02
I0210 10:56:39.699831 22542570456896 run_lib.py:133] step: 470450, training_loss: 2.47009e-02
I0210 10:56:57.185475 22542570456896 run_lib.py:133] step: 470500, training_loss: 2.74040e-02
I0210 10:56:57.338844 22542570456896 run_lib.py:146] step: 470500, eval_loss: 3.96059e-02
I0210 10:57:14.917783 22542570456896 run_lib.py:133] step: 470550, training_loss: 2.73524e-02
I0210 10:57:32.331308 22542570456896 run_lib.py:133] step: 470600, training_loss: 2.69908e-02
I0210 10:57:32.487480 22542570456896 run_lib.py:146] step: 470600, eval_loss: 3.27326e-02
I0210 10:57:50.054529 22542570456896 run_lib.py:133] step: 470650, training_loss: 2.88300e-02
I0210 10:58:07.478954 22542570456896 run_lib.py:133] step: 470700, training_loss: 3.00810e-02
I0210 10:58:07.632593 22542570456896 run_lib.py:146] step: 470700, eval_loss: 3.19848e-02
I0210 10:58:25.283751 22542570456896 run_lib.py:133] step: 470750, training_loss: 3.31394e-02
I0210 10:58:42.733542 22542570456896 run_lib.py:133] step: 470800, training_loss: 2.43273e-02
I0210 10:58:42.893382 22542570456896 run_lib.py:146] step: 470800, eval_loss: 3.01152e-02
I0210 10:59:00.306333 22542570456896 run_lib.py:133] step: 470850, training_loss: 2.47579e-02
I0210 10:59:17.893421 22542570456896 run_lib.py:133] step: 470900, training_loss: 2.73484e-02
I0210 10:59:18.057590 22542570456896 run_lib.py:146] step: 470900, eval_loss: 2.72207e-02
I0210 10:59:35.508732 22542570456896 run_lib.py:133] step: 470950, training_loss: 2.82760e-02
I0210 10:59:53.138094 22542570456896 run_lib.py:133] step: 471000, training_loss: 2.44615e-02
I0210 10:59:53.297678 22542570456896 run_lib.py:146] step: 471000, eval_loss: 2.78548e-02
I0210 11:00:10.797461 22542570456896 run_lib.py:133] step: 471050, training_loss: 2.60855e-02
I0210 11:00:28.266750 22542570456896 run_lib.py:133] step: 471100, training_loss: 2.95398e-02
I0210 11:00:28.430375 22542570456896 run_lib.py:146] step: 471100, eval_loss: 2.99837e-02
I0210 11:00:46.056732 22542570456896 run_lib.py:133] step: 471150, training_loss: 2.46870e-02
I0210 11:01:03.467284 22542570456896 run_lib.py:133] step: 471200, training_loss: 2.34969e-02
I0210 11:01:03.627336 22542570456896 run_lib.py:146] step: 471200, eval_loss: 2.98463e-02
I0210 11:01:21.079443 22542570456896 run_lib.py:133] step: 471250, training_loss: 2.08642e-02
I0210 11:01:38.710138 22542570456896 run_lib.py:133] step: 471300, training_loss: 2.80243e-02
I0210 11:01:38.883689 22542570456896 run_lib.py:146] step: 471300, eval_loss: 2.41525e-02
I0210 11:01:56.339181 22542570456896 run_lib.py:133] step: 471350, training_loss: 2.85962e-02
I0210 11:02:13.754670 22542570456896 run_lib.py:133] step: 471400, training_loss: 3.20699e-02
I0210 11:02:13.911546 22542570456896 run_lib.py:146] step: 471400, eval_loss: 3.35543e-02
I0210 11:02:31.410663 22542570456896 run_lib.py:133] step: 471450, training_loss: 2.64496e-02
I0210 11:02:48.813154 22542570456896 run_lib.py:133] step: 471500, training_loss: 2.64435e-02
I0210 11:02:48.971436 22542570456896 run_lib.py:146] step: 471500, eval_loss: 3.59582e-02
I0210 11:03:06.413121 22542570456896 run_lib.py:133] step: 471550, training_loss: 2.89225e-02
I0210 11:03:23.856791 22542570456896 run_lib.py:133] step: 471600, training_loss: 2.38821e-02
I0210 11:03:24.012550 22542570456896 run_lib.py:146] step: 471600, eval_loss: 3.02688e-02
I0210 11:03:41.660724 22542570456896 run_lib.py:133] step: 471650, training_loss: 2.68085e-02
I0210 11:03:59.174031 22542570456896 run_lib.py:133] step: 471700, training_loss: 2.35200e-02
I0210 11:03:59.326352 22542570456896 run_lib.py:146] step: 471700, eval_loss: 3.21282e-02
I0210 11:04:16.778085 22542570456896 run_lib.py:133] step: 471750, training_loss: 3.02570e-02
I0210 11:04:34.183528 22542570456896 run_lib.py:133] step: 471800, training_loss: 2.96039e-02
I0210 11:04:34.348474 22542570456896 run_lib.py:146] step: 471800, eval_loss: 2.78370e-02
I0210 11:04:51.995119 22542570456896 run_lib.py:133] step: 471850, training_loss: 2.73348e-02
I0210 11:05:09.479900 22542570456896 run_lib.py:133] step: 471900, training_loss: 2.30061e-02
I0210 11:05:09.639568 22542570456896 run_lib.py:146] step: 471900, eval_loss: 3.45711e-02
I0210 11:05:27.251440 22542570456896 run_lib.py:133] step: 471950, training_loss: 3.27795e-02
I0210 11:05:44.684727 22542570456896 run_lib.py:133] step: 472000, training_loss: 2.37170e-02
I0210 11:05:44.850655 22542570456896 run_lib.py:146] step: 472000, eval_loss: 3.33100e-02
I0210 11:06:02.447402 22542570456896 run_lib.py:133] step: 472050, training_loss: 3.17327e-02
I0210 11:06:19.887670 22542570456896 run_lib.py:133] step: 472100, training_loss: 2.02201e-02
I0210 11:06:20.041731 22542570456896 run_lib.py:146] step: 472100, eval_loss: 3.86383e-02
I0210 11:06:37.696026 22542570456896 run_lib.py:133] step: 472150, training_loss: 2.87207e-02
I0210 11:06:55.142822 22542570456896 run_lib.py:133] step: 472200, training_loss: 3.04038e-02
I0210 11:06:55.298364 22542570456896 run_lib.py:146] step: 472200, eval_loss: 2.96083e-02
I0210 11:07:12.743126 22542570456896 run_lib.py:133] step: 472250, training_loss: 2.93199e-02
I0210 11:07:30.328907 22542570456896 run_lib.py:133] step: 472300, training_loss: 2.74851e-02
I0210 11:07:30.490843 22542570456896 run_lib.py:146] step: 472300, eval_loss: 3.01083e-02
I0210 11:07:47.937874 22542570456896 run_lib.py:133] step: 472350, training_loss: 2.68288e-02
I0210 11:08:05.409541 22542570456896 run_lib.py:133] step: 472400, training_loss: 2.45002e-02
I0210 11:08:05.566740 22542570456896 run_lib.py:146] step: 472400, eval_loss: 2.67569e-02
I0210 11:08:23.160916 22542570456896 run_lib.py:133] step: 472450, training_loss: 2.60300e-02
I0210 11:08:40.563172 22542570456896 run_lib.py:133] step: 472500, training_loss: 2.98063e-02
I0210 11:08:40.718428 22542570456896 run_lib.py:146] step: 472500, eval_loss: 2.48179e-02
I0210 11:08:58.305631 22542570456896 run_lib.py:133] step: 472550, training_loss: 3.42902e-02
I0210 11:09:15.719457 22542570456896 run_lib.py:133] step: 472600, training_loss: 3.29976e-02
I0210 11:09:15.871298 22542570456896 run_lib.py:146] step: 472600, eval_loss: 2.29451e-02
I0210 11:09:33.422371 22542570456896 run_lib.py:133] step: 472650, training_loss: 2.95460e-02
I0210 11:09:51.086539 22542570456896 run_lib.py:133] step: 472700, training_loss: 2.60745e-02
I0210 11:09:51.243594 22542570456896 run_lib.py:146] step: 472700, eval_loss: 2.68955e-02
I0210 11:10:08.656710 22542570456896 run_lib.py:133] step: 472750, training_loss: 2.73363e-02
I0210 11:10:26.114787 22542570456896 run_lib.py:133] step: 472800, training_loss: 2.31101e-02
I0210 11:10:26.273716 22542570456896 run_lib.py:146] step: 472800, eval_loss: 3.66452e-02
I0210 11:10:43.707037 22542570456896 run_lib.py:133] step: 472850, training_loss: 2.53901e-02
I0210 11:11:01.264013 22542570456896 run_lib.py:133] step: 472900, training_loss: 3.95334e-02
I0210 11:11:01.431297 22542570456896 run_lib.py:146] step: 472900, eval_loss: 2.85240e-02
I0210 11:11:18.883247 22542570456896 run_lib.py:133] step: 472950, training_loss: 3.12749e-02
I0210 11:11:36.442553 22542570456896 run_lib.py:133] step: 473000, training_loss: 3.25461e-02
I0210 11:11:36.606899 22542570456896 run_lib.py:146] step: 473000, eval_loss: 2.44346e-02
I0210 11:11:54.057958 22542570456896 run_lib.py:133] step: 473050, training_loss: 2.71453e-02
I0210 11:12:11.569790 22542570456896 run_lib.py:133] step: 473100, training_loss: 2.29154e-02
I0210 11:12:11.730354 22542570456896 run_lib.py:146] step: 473100, eval_loss: 2.71728e-02
I0210 11:12:29.302628 22542570456896 run_lib.py:133] step: 473150, training_loss: 2.52629e-02
I0210 11:12:46.898573 22542570456896 run_lib.py:133] step: 473200, training_loss: 2.83200e-02
I0210 11:12:47.077708 22542570456896 run_lib.py:146] step: 473200, eval_loss: 3.37861e-02
I0210 11:13:04.534449 22542570456896 run_lib.py:133] step: 473250, training_loss: 2.53590e-02
I0210 11:13:21.990666 22542570456896 run_lib.py:133] step: 473300, training_loss: 2.97943e-02
I0210 11:13:22.157864 22542570456896 run_lib.py:146] step: 473300, eval_loss: 3.50575e-02
I0210 11:13:39.793558 22542570456896 run_lib.py:133] step: 473350, training_loss: 2.50092e-02
I0210 11:13:57.251574 22542570456896 run_lib.py:133] step: 473400, training_loss: 3.06854e-02
I0210 11:13:57.407193 22542570456896 run_lib.py:146] step: 473400, eval_loss: 2.70964e-02
I0210 11:14:14.971304 22542570456896 run_lib.py:133] step: 473450, training_loss: 2.78574e-02
I0210 11:14:32.451884 22542570456896 run_lib.py:133] step: 473500, training_loss: 2.67916e-02
I0210 11:14:32.606256 22542570456896 run_lib.py:146] step: 473500, eval_loss: 3.22701e-02
I0210 11:14:50.283085 22542570456896 run_lib.py:133] step: 473550, training_loss: 2.51481e-02
I0210 11:15:07.729372 22542570456896 run_lib.py:133] step: 473600, training_loss: 2.53260e-02
I0210 11:15:07.883438 22542570456896 run_lib.py:146] step: 473600, eval_loss: 2.90918e-02
I0210 11:15:25.315797 22542570456896 run_lib.py:133] step: 473650, training_loss: 2.08336e-02
I0210 11:15:42.899042 22542570456896 run_lib.py:133] step: 473700, training_loss: 3.01237e-02
I0210 11:15:43.058518 22542570456896 run_lib.py:146] step: 473700, eval_loss: 2.99376e-02
I0210 11:16:00.487853 22542570456896 run_lib.py:133] step: 473750, training_loss: 2.89761e-02
I0210 11:16:18.177223 22542570456896 run_lib.py:133] step: 473800, training_loss: 2.51188e-02
I0210 11:16:18.334337 22542570456896 run_lib.py:146] step: 473800, eval_loss: 2.73680e-02
I0210 11:16:35.757989 22542570456896 run_lib.py:133] step: 473850, training_loss: 2.44471e-02
I0210 11:16:53.162292 22542570456896 run_lib.py:133] step: 473900, training_loss: 2.36753e-02
I0210 11:16:53.319257 22542570456896 run_lib.py:146] step: 473900, eval_loss: 2.63934e-02
I0210 11:17:10.929152 22542570456896 run_lib.py:133] step: 473950, training_loss: 2.78818e-02
I0210 11:17:28.380303 22542570456896 run_lib.py:133] step: 474000, training_loss: 3.31114e-02
I0210 11:17:28.540908 22542570456896 run_lib.py:146] step: 474000, eval_loss: 3.31911e-02
I0210 11:17:46.016086 22542570456896 run_lib.py:133] step: 474050, training_loss: 2.94922e-02
I0210 11:18:03.642097 22542570456896 run_lib.py:133] step: 474100, training_loss: 3.05450e-02
I0210 11:18:03.807628 22542570456896 run_lib.py:146] step: 474100, eval_loss: 2.43877e-02
I0210 11:18:21.235393 22542570456896 run_lib.py:133] step: 474150, training_loss: 2.95139e-02
I0210 11:18:38.692510 22542570456896 run_lib.py:133] step: 474200, training_loss: 3.21833e-02
I0210 11:18:39.011651 22542570456896 run_lib.py:146] step: 474200, eval_loss: 3.14988e-02
I0210 11:18:56.445222 22542570456896 run_lib.py:133] step: 474250, training_loss: 2.67206e-02
I0210 11:19:13.916112 22542570456896 run_lib.py:133] step: 474300, training_loss: 3.20722e-02
I0210 11:19:14.084357 22542570456896 run_lib.py:146] step: 474300, eval_loss: 2.53305e-02
I0210 11:19:31.564921 22542570456896 run_lib.py:133] step: 474350, training_loss: 3.12782e-02
I0210 11:19:49.074392 22542570456896 run_lib.py:133] step: 474400, training_loss: 2.65291e-02
I0210 11:19:49.230225 22542570456896 run_lib.py:146] step: 474400, eval_loss: 2.70621e-02
I0210 11:20:06.878312 22542570456896 run_lib.py:133] step: 474450, training_loss: 3.28462e-02
I0210 11:20:24.361471 22542570456896 run_lib.py:133] step: 474500, training_loss: 2.99110e-02
I0210 11:20:24.517495 22542570456896 run_lib.py:146] step: 474500, eval_loss: 2.43355e-02
I0210 11:20:41.951012 22542570456896 run_lib.py:133] step: 474550, training_loss: 2.49950e-02
I0210 11:20:59.441265 22542570456896 run_lib.py:133] step: 474600, training_loss: 2.50643e-02
I0210 11:20:59.612548 22542570456896 run_lib.py:146] step: 474600, eval_loss: 2.40100e-02
I0210 11:21:17.215215 22542570456896 run_lib.py:133] step: 474650, training_loss: 2.35328e-02
I0210 11:21:34.758938 22542570456896 run_lib.py:133] step: 474700, training_loss: 2.94060e-02
I0210 11:21:34.918319 22542570456896 run_lib.py:146] step: 474700, eval_loss: 2.10867e-02
I0210 11:21:52.327934 22542570456896 run_lib.py:133] step: 474750, training_loss: 2.45621e-02
I0210 11:22:09.733976 22542570456896 run_lib.py:133] step: 474800, training_loss: 2.55023e-02
I0210 11:22:09.891235 22542570456896 run_lib.py:146] step: 474800, eval_loss: 2.60477e-02
I0210 11:22:27.444259 22542570456896 run_lib.py:133] step: 474850, training_loss: 2.30981e-02
I0210 11:22:44.894730 22542570456896 run_lib.py:133] step: 474900, training_loss: 2.93917e-02
I0210 11:22:45.050147 22542570456896 run_lib.py:146] step: 474900, eval_loss: 2.81482e-02
I0210 11:23:02.684687 22542570456896 run_lib.py:133] step: 474950, training_loss: 3.46243e-02
I0210 11:23:20.158013 22542570456896 run_lib.py:133] step: 475000, training_loss: 2.95409e-02
I0210 11:23:20.316439 22542570456896 run_lib.py:146] step: 475000, eval_loss: 2.48675e-02
I0210 11:23:37.931789 22542570456896 run_lib.py:133] step: 475050, training_loss: 3.20017e-02
I0210 11:23:55.357406 22542570456896 run_lib.py:133] step: 475100, training_loss: 1.84545e-02
I0210 11:23:55.516762 22542570456896 run_lib.py:146] step: 475100, eval_loss: 3.06391e-02
I0210 11:24:12.929649 22542570456896 run_lib.py:133] step: 475150, training_loss: 3.39647e-02
I0210 11:24:30.581372 22542570456896 run_lib.py:133] step: 475200, training_loss: 3.42244e-02
I0210 11:24:30.750411 22542570456896 run_lib.py:146] step: 475200, eval_loss: 2.85353e-02
I0210 11:24:48.201690 22542570456896 run_lib.py:133] step: 475250, training_loss: 2.67708e-02
I0210 11:25:05.818959 22542570456896 run_lib.py:133] step: 475300, training_loss: 2.98088e-02
I0210 11:25:05.974163 22542570456896 run_lib.py:146] step: 475300, eval_loss: 3.23640e-02
I0210 11:25:23.469369 22542570456896 run_lib.py:133] step: 475350, training_loss: 2.78779e-02
I0210 11:25:40.964815 22542570456896 run_lib.py:133] step: 475400, training_loss: 2.54183e-02
I0210 11:25:41.120118 22542570456896 run_lib.py:146] step: 475400, eval_loss: 3.08819e-02
I0210 11:25:58.812933 22542570456896 run_lib.py:133] step: 475450, training_loss: 3.05772e-02
I0210 11:26:16.226403 22542570456896 run_lib.py:133] step: 475500, training_loss: 2.32018e-02
I0210 11:26:16.381869 22542570456896 run_lib.py:146] step: 475500, eval_loss: 2.53091e-02
I0210 11:26:33.890825 22542570456896 run_lib.py:133] step: 475550, training_loss: 2.86592e-02
I0210 11:26:51.306310 22542570456896 run_lib.py:133] step: 475600, training_loss: 2.79906e-02
I0210 11:26:51.465815 22542570456896 run_lib.py:146] step: 475600, eval_loss: 2.93440e-02
I0210 11:27:09.017309 22542570456896 run_lib.py:133] step: 475650, training_loss: 2.61344e-02
I0210 11:27:26.485678 22542570456896 run_lib.py:133] step: 475700, training_loss: 2.56702e-02
I0210 11:27:26.656432 22542570456896 run_lib.py:146] step: 475700, eval_loss: 2.92060e-02
I0210 11:27:44.260813 22542570456896 run_lib.py:133] step: 475750, training_loss: 2.05818e-02
I0210 11:28:01.709522 22542570456896 run_lib.py:133] step: 475800, training_loss: 2.76895e-02
I0210 11:28:01.873658 22542570456896 run_lib.py:146] step: 475800, eval_loss: 2.98863e-02
I0210 11:28:19.298905 22542570456896 run_lib.py:133] step: 475850, training_loss: 2.34115e-02
I0210 11:28:36.733522 22542570456896 run_lib.py:133] step: 475900, training_loss: 3.30374e-02
I0210 11:28:36.885302 22542570456896 run_lib.py:146] step: 475900, eval_loss: 3.30975e-02
I0210 11:28:54.487003 22542570456896 run_lib.py:133] step: 475950, training_loss: 2.99898e-02
I0210 11:29:12.031193 22542570456896 run_lib.py:133] step: 476000, training_loss: 3.11117e-02
I0210 11:29:12.201270 22542570456896 run_lib.py:146] step: 476000, eval_loss: 2.78373e-02
I0210 11:29:29.678893 22542570456896 run_lib.py:133] step: 476050, training_loss: 2.83293e-02
I0210 11:29:47.127679 22542570456896 run_lib.py:133] step: 476100, training_loss: 2.76746e-02
I0210 11:29:47.287426 22542570456896 run_lib.py:146] step: 476100, eval_loss: 2.36480e-02
I0210 11:30:04.895147 22542570456896 run_lib.py:133] step: 476150, training_loss: 3.39698e-02
I0210 11:30:22.312803 22542570456896 run_lib.py:133] step: 476200, training_loss: 2.39568e-02
I0210 11:30:22.471428 22542570456896 run_lib.py:146] step: 476200, eval_loss: 3.02721e-02
I0210 11:30:40.026832 22542570456896 run_lib.py:133] step: 476250, training_loss: 2.61039e-02
I0210 11:30:57.522193 22542570456896 run_lib.py:133] step: 476300, training_loss: 2.95197e-02
I0210 11:30:57.678163 22542570456896 run_lib.py:146] step: 476300, eval_loss: 4.08455e-02
I0210 11:31:15.305677 22542570456896 run_lib.py:133] step: 476350, training_loss: 2.16597e-02
I0210 11:31:32.713405 22542570456896 run_lib.py:133] step: 476400, training_loss: 2.31838e-02
I0210 11:31:32.866398 22542570456896 run_lib.py:146] step: 476400, eval_loss: 2.52713e-02
I0210 11:31:50.465974 22542570456896 run_lib.py:133] step: 476450, training_loss: 3.11897e-02
I0210 11:32:07.929828 22542570456896 run_lib.py:133] step: 476500, training_loss: 2.21679e-02
I0210 11:32:08.088399 22542570456896 run_lib.py:146] step: 476500, eval_loss: 3.17762e-02
I0210 11:32:25.568993 22542570456896 run_lib.py:133] step: 476550, training_loss: 3.30737e-02
I0210 11:32:43.205055 22542570456896 run_lib.py:133] step: 476600, training_loss: 3.37221e-02
I0210 11:32:43.360444 22542570456896 run_lib.py:146] step: 476600, eval_loss: 2.81134e-02
I0210 11:33:00.810710 22542570456896 run_lib.py:133] step: 476650, training_loss: 2.63597e-02
I0210 11:33:18.220652 22542570456896 run_lib.py:133] step: 476700, training_loss: 2.89250e-02
I0210 11:33:18.377392 22542570456896 run_lib.py:146] step: 476700, eval_loss: 2.88548e-02
I0210 11:33:35.965419 22542570456896 run_lib.py:133] step: 476750, training_loss: 2.43425e-02
I0210 11:33:53.578030 22542570456896 run_lib.py:133] step: 476800, training_loss: 2.39985e-02
I0210 11:33:53.733628 22542570456896 run_lib.py:146] step: 476800, eval_loss: 2.72182e-02
I0210 11:34:11.215705 22542570456896 run_lib.py:133] step: 476850, training_loss: 2.63062e-02
I0210 11:34:28.603100 22542570456896 run_lib.py:133] step: 476900, training_loss: 2.63491e-02
I0210 11:34:28.755403 22542570456896 run_lib.py:146] step: 476900, eval_loss: 3.25311e-02
I0210 11:34:46.218388 22542570456896 run_lib.py:133] step: 476950, training_loss: 2.83318e-02
I0210 11:35:03.833856 22542570456896 run_lib.py:133] step: 477000, training_loss: 3.24829e-02
I0210 11:35:03.994696 22542570456896 run_lib.py:146] step: 477000, eval_loss: 2.95819e-02
I0210 11:35:21.417296 22542570456896 run_lib.py:133] step: 477050, training_loss: 2.54353e-02
I0210 11:35:38.864039 22542570456896 run_lib.py:133] step: 477100, training_loss: 2.91548e-02
I0210 11:35:39.023390 22542570456896 run_lib.py:146] step: 477100, eval_loss: 3.11353e-02
I0210 11:35:56.540041 22542570456896 run_lib.py:133] step: 477150, training_loss: 2.63656e-02
I0210 11:36:14.146392 22542570456896 run_lib.py:133] step: 477200, training_loss: 2.87472e-02
I0210 11:36:14.302593 22542570456896 run_lib.py:146] step: 477200, eval_loss: 3.20180e-02
I0210 11:36:31.742223 22542570456896 run_lib.py:133] step: 477250, training_loss: 2.54863e-02
I0210 11:36:49.214318 22542570456896 run_lib.py:133] step: 477300, training_loss: 3.12230e-02
I0210 11:36:49.367100 22542570456896 run_lib.py:146] step: 477300, eval_loss: 2.87591e-02
I0210 11:37:06.784898 22542570456896 run_lib.py:133] step: 477350, training_loss: 3.00085e-02
I0210 11:37:24.256710 22542570456896 run_lib.py:133] step: 477400, training_loss: 3.17225e-02
I0210 11:37:24.416136 22542570456896 run_lib.py:146] step: 477400, eval_loss: 2.82926e-02
I0210 11:37:42.064729 22542570456896 run_lib.py:133] step: 477450, training_loss: 3.15670e-02
I0210 11:37:59.592949 22542570456896 run_lib.py:133] step: 477500, training_loss: 2.32537e-02
I0210 11:37:59.755568 22542570456896 run_lib.py:146] step: 477500, eval_loss: 2.60406e-02
I0210 11:38:17.159634 22542570456896 run_lib.py:133] step: 477550, training_loss: 2.64712e-02
I0210 11:38:34.601116 22542570456896 run_lib.py:133] step: 477600, training_loss: 2.93543e-02
I0210 11:38:34.755990 22542570456896 run_lib.py:146] step: 477600, eval_loss: 2.77949e-02
I0210 11:38:52.337214 22542570456896 run_lib.py:133] step: 477650, training_loss: 2.32664e-02
I0210 11:39:09.819081 22542570456896 run_lib.py:133] step: 477700, training_loss: 2.95251e-02
I0210 11:39:09.974767 22542570456896 run_lib.py:146] step: 477700, eval_loss: 3.09007e-02
I0210 11:39:27.619260 22542570456896 run_lib.py:133] step: 477750, training_loss: 2.66015e-02
I0210 11:39:45.027898 22542570456896 run_lib.py:133] step: 477800, training_loss: 2.79900e-02
I0210 11:39:45.184136 22542570456896 run_lib.py:146] step: 477800, eval_loss: 2.61253e-02
I0210 11:40:02.753209 22542570456896 run_lib.py:133] step: 477850, training_loss: 2.59325e-02
I0210 11:40:20.188437 22542570456896 run_lib.py:133] step: 477900, training_loss: 2.45633e-02
I0210 11:40:20.345200 22542570456896 run_lib.py:146] step: 477900, eval_loss: 3.22593e-02
I0210 11:40:37.790996 22542570456896 run_lib.py:133] step: 477950, training_loss: 2.85098e-02
I0210 11:40:55.432909 22542570456896 run_lib.py:133] step: 478000, training_loss: 2.55801e-02
I0210 11:40:55.592318 22542570456896 run_lib.py:146] step: 478000, eval_loss: 2.80592e-02
I0210 11:41:13.002943 22542570456896 run_lib.py:133] step: 478050, training_loss: 2.48934e-02
I0210 11:41:30.597133 22542570456896 run_lib.py:133] step: 478100, training_loss: 2.64121e-02
I0210 11:41:30.753341 22542570456896 run_lib.py:146] step: 478100, eval_loss: 2.57650e-02
I0210 11:41:48.208863 22542570456896 run_lib.py:133] step: 478150, training_loss: 3.28788e-02
I0210 11:42:05.650685 22542570456896 run_lib.py:133] step: 478200, training_loss: 3.21071e-02
I0210 11:42:05.804563 22542570456896 run_lib.py:146] step: 478200, eval_loss: 3.02878e-02
I0210 11:42:23.443778 22542570456896 run_lib.py:133] step: 478250, training_loss: 2.66307e-02
I0210 11:42:40.885087 22542570456896 run_lib.py:133] step: 478300, training_loss: 4.14048e-02
I0210 11:42:41.037471 22542570456896 run_lib.py:146] step: 478300, eval_loss: 3.22759e-02
I0210 11:42:58.451256 22542570456896 run_lib.py:133] step: 478350, training_loss: 2.20395e-02
I0210 11:43:15.989018 22542570456896 run_lib.py:133] step: 478400, training_loss: 2.86761e-02
I0210 11:43:16.144317 22542570456896 run_lib.py:146] step: 478400, eval_loss: 2.42883e-02
I0210 11:43:33.523359 22542570456896 run_lib.py:133] step: 478450, training_loss: 3.41613e-02
I0210 11:43:50.968644 22542570456896 run_lib.py:133] step: 478500, training_loss: 2.50711e-02
I0210 11:43:51.144297 22542570456896 run_lib.py:146] step: 478500, eval_loss: 3.02934e-02
I0210 11:44:08.655112 22542570456896 run_lib.py:133] step: 478550, training_loss: 3.14764e-02
I0210 11:44:26.144355 22542570456896 run_lib.py:133] step: 478600, training_loss: 3.08572e-02
I0210 11:44:26.298442 22542570456896 run_lib.py:146] step: 478600, eval_loss: 2.61194e-02
I0210 11:44:43.710579 22542570456896 run_lib.py:133] step: 478650, training_loss: 2.87549e-02
I0210 11:45:01.163477 22542570456896 run_lib.py:133] step: 478700, training_loss: 2.72987e-02
I0210 11:45:01.318832 22542570456896 run_lib.py:146] step: 478700, eval_loss: 2.30192e-02
I0210 11:45:18.915381 22542570456896 run_lib.py:133] step: 478750, training_loss: 3.10073e-02
I0210 11:45:36.451990 22542570456896 run_lib.py:133] step: 478800, training_loss: 3.73068e-02
I0210 11:45:36.613675 22542570456896 run_lib.py:146] step: 478800, eval_loss: 3.51877e-02
I0210 11:45:54.154433 22542570456896 run_lib.py:133] step: 478850, training_loss: 2.62915e-02
I0210 11:46:11.591783 22542570456896 run_lib.py:133] step: 478900, training_loss: 3.15555e-02
I0210 11:46:11.750401 22542570456896 run_lib.py:146] step: 478900, eval_loss: 3.38280e-02
I0210 11:46:29.285947 22542570456896 run_lib.py:133] step: 478950, training_loss: 2.46565e-02
I0210 11:46:46.674113 22542570456896 run_lib.py:133] step: 479000, training_loss: 2.32621e-02
I0210 11:46:46.840345 22542570456896 run_lib.py:146] step: 479000, eval_loss: 2.64456e-02
I0210 11:47:04.420670 22542570456896 run_lib.py:133] step: 479050, training_loss: 2.27902e-02
I0210 11:47:21.902352 22542570456896 run_lib.py:133] step: 479100, training_loss: 2.82778e-02
I0210 11:47:22.058579 22542570456896 run_lib.py:146] step: 479100, eval_loss: 3.14796e-02
I0210 11:47:39.637575 22542570456896 run_lib.py:133] step: 479150, training_loss: 2.30863e-02
I0210 11:47:57.063475 22542570456896 run_lib.py:133] step: 479200, training_loss: 2.10822e-02
I0210 11:47:57.216438 22542570456896 run_lib.py:146] step: 479200, eval_loss: 2.99722e-02
I0210 11:48:14.783877 22542570456896 run_lib.py:133] step: 479250, training_loss: 2.17305e-02
I0210 11:48:32.254986 22542570456896 run_lib.py:133] step: 479300, training_loss: 2.59376e-02
I0210 11:48:32.414573 22542570456896 run_lib.py:146] step: 479300, eval_loss: 2.93466e-02
I0210 11:48:49.892569 22542570456896 run_lib.py:133] step: 479350, training_loss: 2.52601e-02
I0210 11:49:07.488601 22542570456896 run_lib.py:133] step: 479400, training_loss: 1.97775e-02
I0210 11:49:07.649328 22542570456896 run_lib.py:146] step: 479400, eval_loss: 2.37695e-02
I0210 11:49:25.069074 22542570456896 run_lib.py:133] step: 479450, training_loss: 3.07695e-02
I0210 11:49:42.449509 22542570456896 run_lib.py:133] step: 479500, training_loss: 2.79116e-02
I0210 11:49:42.605385 22542570456896 run_lib.py:146] step: 479500, eval_loss: 2.67955e-02
I0210 11:50:00.198074 22542570456896 run_lib.py:133] step: 479550, training_loss: 3.00298e-02
I0210 11:50:17.589095 22542570456896 run_lib.py:133] step: 479600, training_loss: 3.11154e-02
I0210 11:50:17.752487 22542570456896 run_lib.py:146] step: 479600, eval_loss: 2.84191e-02
I0210 11:50:35.376027 22542570456896 run_lib.py:133] step: 479650, training_loss: 2.70831e-02
I0210 11:50:52.783375 22542570456896 run_lib.py:133] step: 479700, training_loss: 3.00827e-02
I0210 11:50:52.934912 22542570456896 run_lib.py:146] step: 479700, eval_loss: 3.11488e-02
I0210 11:51:10.395826 22542570456896 run_lib.py:133] step: 479750, training_loss: 2.91088e-02
I0210 11:51:27.989068 22542570456896 run_lib.py:133] step: 479800, training_loss: 2.64180e-02
I0210 11:51:28.143649 22542570456896 run_lib.py:146] step: 479800, eval_loss: 2.12573e-02
I0210 11:51:45.585936 22542570456896 run_lib.py:133] step: 479850, training_loss: 3.43453e-02
I0210 11:52:03.014430 22542570456896 run_lib.py:133] step: 479900, training_loss: 2.65363e-02
I0210 11:52:03.191410 22542570456896 run_lib.py:146] step: 479900, eval_loss: 2.66538e-02
I0210 11:52:20.622329 22542570456896 run_lib.py:133] step: 479950, training_loss: 2.82226e-02
I0210 11:52:38.218206 22542570456896 run_lib.py:133] step: 480000, training_loss: 2.28652e-02
I0210 11:52:39.258536 22542570456896 run_lib.py:146] step: 480000, eval_loss: 3.62170e-02
I0210 11:52:59.923997 22542570456896 run_lib.py:133] step: 480050, training_loss: 3.21375e-02
I0210 11:53:17.501646 22542570456896 run_lib.py:133] step: 480100, training_loss: 2.61971e-02
I0210 11:53:17.661479 22542570456896 run_lib.py:146] step: 480100, eval_loss: 3.25474e-02
I0210 11:53:35.046494 22542570456896 run_lib.py:133] step: 480150, training_loss: 2.87768e-02
I0210 11:53:52.488476 22542570456896 run_lib.py:133] step: 480200, training_loss: 2.13730e-02
I0210 11:53:52.643650 22542570456896 run_lib.py:146] step: 480200, eval_loss: 2.54694e-02
I0210 11:54:10.127796 22542570456896 run_lib.py:133] step: 480250, training_loss: 2.99196e-02
I0210 11:54:27.703037 22542570456896 run_lib.py:133] step: 480300, training_loss: 2.79017e-02
I0210 11:54:27.856332 22542570456896 run_lib.py:146] step: 480300, eval_loss: 3.96946e-02
I0210 11:54:45.326828 22542570456896 run_lib.py:133] step: 480350, training_loss: 2.97133e-02
I0210 11:55:02.768724 22542570456896 run_lib.py:133] step: 480400, training_loss: 2.55526e-02
I0210 11:55:02.927658 22542570456896 run_lib.py:146] step: 480400, eval_loss: 2.93321e-02
I0210 11:55:20.376032 22542570456896 run_lib.py:133] step: 480450, training_loss: 2.54538e-02
I0210 11:55:37.778610 22542570456896 run_lib.py:133] step: 480500, training_loss: 2.47260e-02
I0210 11:55:37.944951 22542570456896 run_lib.py:146] step: 480500, eval_loss: 3.39111e-02
I0210 11:55:55.550853 22542570456896 run_lib.py:133] step: 480550, training_loss: 3.01493e-02
I0210 11:56:13.085688 22542570456896 run_lib.py:133] step: 480600, training_loss: 2.53837e-02
I0210 11:56:13.242334 22542570456896 run_lib.py:146] step: 480600, eval_loss: 3.12322e-02
I0210 11:56:30.663295 22542570456896 run_lib.py:133] step: 480650, training_loss: 3.08914e-02
I0210 11:56:48.069789 22542570456896 run_lib.py:133] step: 480700, training_loss: 2.98832e-02
I0210 11:56:48.221095 22542570456896 run_lib.py:146] step: 480700, eval_loss: 3.05131e-02
I0210 11:57:05.769520 22542570456896 run_lib.py:133] step: 480750, training_loss: 2.50321e-02
I0210 11:57:23.188913 22542570456896 run_lib.py:133] step: 480800, training_loss: 2.74908e-02
I0210 11:57:23.354669 22542570456896 run_lib.py:146] step: 480800, eval_loss: 3.40082e-02
I0210 11:57:40.988113 22542570456896 run_lib.py:133] step: 480850, training_loss: 2.85363e-02
I0210 11:57:58.382935 22542570456896 run_lib.py:133] step: 480900, training_loss: 2.95529e-02
I0210 11:57:58.546534 22542570456896 run_lib.py:146] step: 480900, eval_loss: 2.45074e-02
I0210 11:58:16.117404 22542570456896 run_lib.py:133] step: 480950, training_loss: 2.08582e-02
I0210 11:58:33.531522 22542570456896 run_lib.py:133] step: 481000, training_loss: 3.02259e-02
I0210 11:58:33.695484 22542570456896 run_lib.py:146] step: 481000, eval_loss: 3.17810e-02
I0210 11:58:51.146274 22542570456896 run_lib.py:133] step: 481050, training_loss: 2.85282e-02
I0210 11:59:08.694903 22542570456896 run_lib.py:133] step: 481100, training_loss: 2.43460e-02
I0210 11:59:08.857660 22542570456896 run_lib.py:146] step: 481100, eval_loss: 3.41607e-02
I0210 11:59:26.319778 22542570456896 run_lib.py:133] step: 481150, training_loss: 2.51912e-02
I0210 11:59:43.923452 22542570456896 run_lib.py:133] step: 481200, training_loss: 3.10364e-02
I0210 11:59:44.075313 22542570456896 run_lib.py:146] step: 481200, eval_loss: 3.54365e-02
I0210 12:00:01.478524 22542570456896 run_lib.py:133] step: 481250, training_loss: 3.42334e-02
I0210 12:00:18.939337 22542570456896 run_lib.py:133] step: 481300, training_loss: 3.32892e-02
I0210 12:00:19.094301 22542570456896 run_lib.py:146] step: 481300, eval_loss: 2.94547e-02
I0210 12:00:36.667219 22542570456896 run_lib.py:133] step: 481350, training_loss: 2.37337e-02
I0210 12:00:54.105069 22542570456896 run_lib.py:133] step: 481400, training_loss: 2.05386e-02
I0210 12:00:54.284321 22542570456896 run_lib.py:146] step: 481400, eval_loss: 2.77843e-02
I0210 12:01:11.716208 22542570456896 run_lib.py:133] step: 481450, training_loss: 3.17591e-02
I0210 12:01:29.291204 22542570456896 run_lib.py:133] step: 481500, training_loss: 2.54202e-02
I0210 12:01:29.449782 22542570456896 run_lib.py:146] step: 481500, eval_loss: 2.70405e-02
I0210 12:01:46.866194 22542570456896 run_lib.py:133] step: 481550, training_loss: 3.48229e-02
I0210 12:02:04.210692 22542570456896 run_lib.py:133] step: 481600, training_loss: 2.14459e-02
I0210 12:02:04.501278 22542570456896 run_lib.py:146] step: 481600, eval_loss: 2.22970e-02
I0210 12:02:21.846645 22542570456896 run_lib.py:133] step: 481650, training_loss: 3.32691e-02
I0210 12:02:39.199104 22542570456896 run_lib.py:133] step: 481700, training_loss: 3.20271e-02
I0210 12:02:39.352448 22542570456896 run_lib.py:146] step: 481700, eval_loss: 3.15906e-02
I0210 12:02:56.693572 22542570456896 run_lib.py:133] step: 481750, training_loss: 3.32824e-02
I0210 12:03:14.160331 22542570456896 run_lib.py:133] step: 481800, training_loss: 3.22866e-02
I0210 12:03:14.316285 22542570456896 run_lib.py:146] step: 481800, eval_loss: 2.42597e-02
I0210 12:03:31.931440 22542570456896 run_lib.py:133] step: 481850, training_loss: 2.22349e-02
I0210 12:03:49.408039 22542570456896 run_lib.py:133] step: 481900, training_loss: 2.78075e-02
I0210 12:03:49.572648 22542570456896 run_lib.py:146] step: 481900, eval_loss: 3.06293e-02
I0210 12:04:07.018551 22542570456896 run_lib.py:133] step: 481950, training_loss: 2.89222e-02
I0210 12:04:24.505703 22542570456896 run_lib.py:133] step: 482000, training_loss: 2.80125e-02
I0210 12:04:24.662267 22542570456896 run_lib.py:146] step: 482000, eval_loss: 2.79564e-02
I0210 12:04:42.243404 22542570456896 run_lib.py:133] step: 482050, training_loss: 3.08433e-02
I0210 12:04:59.701452 22542570456896 run_lib.py:133] step: 482100, training_loss: 2.78014e-02
I0210 12:04:59.857241 22542570456896 run_lib.py:146] step: 482100, eval_loss: 3.06487e-02
I0210 12:05:17.261574 22542570456896 run_lib.py:133] step: 482150, training_loss: 3.62975e-02
I0210 12:05:34.720722 22542570456896 run_lib.py:133] step: 482200, training_loss: 2.70615e-02
I0210 12:05:34.874693 22542570456896 run_lib.py:146] step: 482200, eval_loss: 3.04576e-02
I0210 12:05:52.497147 22542570456896 run_lib.py:133] step: 482250, training_loss: 2.81477e-02
I0210 12:06:09.984951 22542570456896 run_lib.py:133] step: 482300, training_loss: 2.99076e-02
I0210 12:06:10.147416 22542570456896 run_lib.py:146] step: 482300, eval_loss: 3.04945e-02
I0210 12:06:27.792571 22542570456896 run_lib.py:133] step: 482350, training_loss: 2.55446e-02
I0210 12:06:45.239680 22542570456896 run_lib.py:133] step: 482400, training_loss: 2.84117e-02
I0210 12:06:45.403288 22542570456896 run_lib.py:146] step: 482400, eval_loss: 2.71313e-02
I0210 12:07:02.973640 22542570456896 run_lib.py:133] step: 482450, training_loss: 2.71557e-02
I0210 12:07:20.444115 22542570456896 run_lib.py:133] step: 482500, training_loss: 2.26416e-02
I0210 12:07:20.609018 22542570456896 run_lib.py:146] step: 482500, eval_loss: 3.28274e-02
I0210 12:07:38.063028 22542570456896 run_lib.py:133] step: 482550, training_loss: 2.74697e-02
I0210 12:07:55.679301 22542570456896 run_lib.py:133] step: 482600, training_loss: 2.81140e-02
I0210 12:07:55.833387 22542570456896 run_lib.py:146] step: 482600, eval_loss: 3.47548e-02
I0210 12:08:13.280007 22542570456896 run_lib.py:133] step: 482650, training_loss: 2.70564e-02
I0210 12:08:30.856240 22542570456896 run_lib.py:133] step: 482700, training_loss: 3.21078e-02
I0210 12:08:31.011370 22542570456896 run_lib.py:146] step: 482700, eval_loss: 2.81667e-02
I0210 12:08:48.421087 22542570456896 run_lib.py:133] step: 482750, training_loss: 3.20259e-02
I0210 12:09:05.881717 22542570456896 run_lib.py:133] step: 482800, training_loss: 2.84888e-02
I0210 12:09:06.059026 22542570456896 run_lib.py:146] step: 482800, eval_loss: 2.96132e-02
I0210 12:09:23.677634 22542570456896 run_lib.py:133] step: 482850, training_loss: 2.95576e-02
I0210 12:09:41.156494 22542570456896 run_lib.py:133] step: 482900, training_loss: 2.31202e-02
I0210 12:09:41.314576 22542570456896 run_lib.py:146] step: 482900, eval_loss: 3.06916e-02
I0210 12:09:58.756822 22542570456896 run_lib.py:133] step: 482950, training_loss: 2.80338e-02
I0210 12:10:16.182579 22542570456896 run_lib.py:133] step: 483000, training_loss: 2.68140e-02
I0210 12:10:16.338281 22542570456896 run_lib.py:146] step: 483000, eval_loss: 2.86306e-02
I0210 12:10:33.954411 22542570456896 run_lib.py:133] step: 483050, training_loss: 2.99962e-02
I0210 12:10:51.419113 22542570456896 run_lib.py:133] step: 483100, training_loss: 3.11116e-02
I0210 12:10:51.573455 22542570456896 run_lib.py:146] step: 483100, eval_loss: 2.61899e-02
I0210 12:11:09.162462 22542570456896 run_lib.py:133] step: 483150, training_loss: 2.70543e-02
I0210 12:11:26.612555 22542570456896 run_lib.py:133] step: 483200, training_loss: 2.67290e-02
I0210 12:11:26.768527 22542570456896 run_lib.py:146] step: 483200, eval_loss: 3.64854e-02
I0210 12:11:44.215191 22542570456896 run_lib.py:133] step: 483250, training_loss: 2.78106e-02
I0210 12:12:01.682608 22542570456896 run_lib.py:133] step: 483300, training_loss: 2.18183e-02
I0210 12:12:01.860391 22542570456896 run_lib.py:146] step: 483300, eval_loss: 2.67273e-02
I0210 12:12:19.462920 22542570456896 run_lib.py:133] step: 483350, training_loss: 2.05570e-02
I0210 12:12:36.989310 22542570456896 run_lib.py:133] step: 483400, training_loss: 2.85273e-02
I0210 12:12:37.145585 22542570456896 run_lib.py:146] step: 483400, eval_loss: 2.94463e-02
I0210 12:12:54.572150 22542570456896 run_lib.py:133] step: 483450, training_loss: 2.50383e-02
I0210 12:13:11.983088 22542570456896 run_lib.py:133] step: 483500, training_loss: 3.05317e-02
I0210 12:13:12.138376 22542570456896 run_lib.py:146] step: 483500, eval_loss: 2.34707e-02
I0210 12:13:29.690652 22542570456896 run_lib.py:133] step: 483550, training_loss: 3.10093e-02
I0210 12:13:47.131414 22542570456896 run_lib.py:133] step: 483600, training_loss: 2.78419e-02
I0210 12:13:47.284549 22542570456896 run_lib.py:146] step: 483600, eval_loss: 2.57508e-02
I0210 12:14:04.902985 22542570456896 run_lib.py:133] step: 483650, training_loss: 2.00924e-02
I0210 12:14:22.303561 22542570456896 run_lib.py:133] step: 483700, training_loss: 2.73050e-02
I0210 12:14:22.460367 22542570456896 run_lib.py:146] step: 483700, eval_loss: 2.61942e-02
I0210 12:14:40.041800 22542570456896 run_lib.py:133] step: 483750, training_loss: 3.07014e-02
I0210 12:14:57.482792 22542570456896 run_lib.py:133] step: 483800, training_loss: 1.88154e-02
I0210 12:14:57.637776 22542570456896 run_lib.py:146] step: 483800, eval_loss: 2.53473e-02
I0210 12:15:15.170651 22542570456896 run_lib.py:133] step: 483850, training_loss: 2.55158e-02
I0210 12:15:32.619092 22542570456896 run_lib.py:133] step: 483900, training_loss: 3.35617e-02
I0210 12:15:32.776416 22542570456896 run_lib.py:146] step: 483900, eval_loss: 2.53429e-02
I0210 12:15:50.228650 22542570456896 run_lib.py:133] step: 483950, training_loss: 3.18578e-02
I0210 12:16:07.812583 22542570456896 run_lib.py:133] step: 484000, training_loss: 2.61871e-02
I0210 12:16:07.970853 22542570456896 run_lib.py:146] step: 484000, eval_loss: 2.54939e-02
I0210 12:16:25.369602 22542570456896 run_lib.py:133] step: 484050, training_loss: 3.05315e-02
I0210 12:16:42.774057 22542570456896 run_lib.py:133] step: 484100, training_loss: 2.60464e-02
I0210 12:16:42.933231 22542570456896 run_lib.py:146] step: 484100, eval_loss: 2.60118e-02
I0210 12:17:00.482737 22542570456896 run_lib.py:133] step: 484150, training_loss: 2.57834e-02
I0210 12:17:18.029186 22542570456896 run_lib.py:133] step: 484200, training_loss: 3.38874e-02
I0210 12:17:18.207436 22542570456896 run_lib.py:146] step: 484200, eval_loss: 3.15021e-02
I0210 12:17:35.659066 22542570456896 run_lib.py:133] step: 484250, training_loss: 2.78247e-02
I0210 12:17:53.101309 22542570456896 run_lib.py:133] step: 484300, training_loss: 2.90297e-02
I0210 12:17:53.257600 22542570456896 run_lib.py:146] step: 484300, eval_loss: 2.91337e-02
I0210 12:18:10.688100 22542570456896 run_lib.py:133] step: 484350, training_loss: 2.52352e-02
I0210 12:18:28.339151 22542570456896 run_lib.py:133] step: 484400, training_loss: 2.65391e-02
I0210 12:18:28.495550 22542570456896 run_lib.py:146] step: 484400, eval_loss: 2.26941e-02
I0210 12:18:45.892451 22542570456896 run_lib.py:133] step: 484450, training_loss: 2.53722e-02
I0210 12:19:03.328671 22542570456896 run_lib.py:133] step: 484500, training_loss: 2.50519e-02
I0210 12:19:03.486122 22542570456896 run_lib.py:146] step: 484500, eval_loss: 3.05113e-02
I0210 12:19:20.944878 22542570456896 run_lib.py:133] step: 484550, training_loss: 2.78345e-02
I0210 12:19:38.532827 22542570456896 run_lib.py:133] step: 484600, training_loss: 2.16346e-02
I0210 12:19:38.696859 22542570456896 run_lib.py:146] step: 484600, eval_loss: 3.15793e-02
I0210 12:19:56.078270 22542570456896 run_lib.py:133] step: 484650, training_loss: 2.83034e-02
I0210 12:20:13.595430 22542570456896 run_lib.py:133] step: 484700, training_loss: 2.21236e-02
I0210 12:20:13.782350 22542570456896 run_lib.py:146] step: 484700, eval_loss: 2.48346e-02
I0210 12:20:31.267323 22542570456896 run_lib.py:133] step: 484750, training_loss: 3.06115e-02
I0210 12:20:48.703857 22542570456896 run_lib.py:133] step: 484800, training_loss: 2.79344e-02
I0210 12:20:48.860667 22542570456896 run_lib.py:146] step: 484800, eval_loss: 2.77051e-02
I0210 12:21:06.484848 22542570456896 run_lib.py:133] step: 484850, training_loss: 2.52984e-02
I0210 12:21:24.006291 22542570456896 run_lib.py:133] step: 484900, training_loss: 2.54490e-02
I0210 12:21:24.167489 22542570456896 run_lib.py:146] step: 484900, eval_loss: 2.57938e-02
I0210 12:21:41.605652 22542570456896 run_lib.py:133] step: 484950, training_loss: 4.02884e-02
I0210 12:21:59.043210 22542570456896 run_lib.py:133] step: 485000, training_loss: 3.24036e-02
I0210 12:21:59.199548 22542570456896 run_lib.py:146] step: 485000, eval_loss: 2.97871e-02
I0210 12:22:16.842016 22542570456896 run_lib.py:133] step: 485050, training_loss: 2.83964e-02
I0210 12:22:34.254552 22542570456896 run_lib.py:133] step: 485100, training_loss: 2.94834e-02
I0210 12:22:34.410781 22542570456896 run_lib.py:146] step: 485100, eval_loss: 2.67748e-02
I0210 12:22:52.037153 22542570456896 run_lib.py:133] step: 485150, training_loss: 2.63048e-02
I0210 12:23:09.447732 22542570456896 run_lib.py:133] step: 485200, training_loss: 2.64626e-02
I0210 12:23:09.605607 22542570456896 run_lib.py:146] step: 485200, eval_loss: 3.02857e-02
I0210 12:23:27.237445 22542570456896 run_lib.py:133] step: 485250, training_loss: 2.64707e-02
I0210 12:23:44.736181 22542570456896 run_lib.py:133] step: 485300, training_loss: 3.78673e-02
I0210 12:23:44.896616 22542570456896 run_lib.py:146] step: 485300, eval_loss: 2.62790e-02
I0210 12:24:02.367896 22542570456896 run_lib.py:133] step: 485350, training_loss: 2.59781e-02
I0210 12:24:19.978926 22542570456896 run_lib.py:133] step: 485400, training_loss: 3.03709e-02
I0210 12:24:20.134309 22542570456896 run_lib.py:146] step: 485400, eval_loss: 2.47292e-02
I0210 12:24:37.558676 22542570456896 run_lib.py:133] step: 485450, training_loss: 2.52173e-02
I0210 12:24:55.097496 22542570456896 run_lib.py:133] step: 485500, training_loss: 2.91076e-02
I0210 12:24:55.251341 22542570456896 run_lib.py:146] step: 485500, eval_loss: 2.81557e-02
I0210 12:25:12.683292 22542570456896 run_lib.py:133] step: 485550, training_loss: 2.56363e-02
I0210 12:25:30.124994 22542570456896 run_lib.py:133] step: 485600, training_loss: 2.23279e-02
I0210 12:25:30.301352 22542570456896 run_lib.py:146] step: 485600, eval_loss: 2.76387e-02
I0210 12:25:47.975842 22542570456896 run_lib.py:133] step: 485650, training_loss: 3.26199e-02
I0210 12:26:05.432689 22542570456896 run_lib.py:133] step: 485700, training_loss: 3.37592e-02
I0210 12:26:05.585337 22542570456896 run_lib.py:146] step: 485700, eval_loss: 3.29676e-02
I0210 12:26:22.989452 22542570456896 run_lib.py:133] step: 485750, training_loss: 2.54807e-02
I0210 12:26:40.581349 22542570456896 run_lib.py:133] step: 485800, training_loss: 2.21148e-02
I0210 12:26:40.740076 22542570456896 run_lib.py:146] step: 485800, eval_loss: 2.48656e-02
I0210 12:26:58.174008 22542570456896 run_lib.py:133] step: 485850, training_loss: 2.97681e-02
I0210 12:27:15.698168 22542570456896 run_lib.py:133] step: 485900, training_loss: 2.51863e-02
I0210 12:27:15.849332 22542570456896 run_lib.py:146] step: 485900, eval_loss: 2.92333e-02
I0210 12:27:33.355598 22542570456896 run_lib.py:133] step: 485950, training_loss: 2.45496e-02
I0210 12:27:50.772003 22542570456896 run_lib.py:133] step: 486000, training_loss: 3.02642e-02
I0210 12:27:50.925292 22542570456896 run_lib.py:146] step: 486000, eval_loss: 2.74052e-02
I0210 12:28:08.374877 22542570456896 run_lib.py:133] step: 486050, training_loss: 2.85209e-02
I0210 12:28:25.795273 22542570456896 run_lib.py:133] step: 486100, training_loss: 3.13713e-02
I0210 12:28:25.967519 22542570456896 run_lib.py:146] step: 486100, eval_loss: 2.78521e-02
I0210 12:28:43.583705 22542570456896 run_lib.py:133] step: 486150, training_loss: 2.86336e-02
I0210 12:29:01.145050 22542570456896 run_lib.py:133] step: 486200, training_loss: 2.57097e-02
I0210 12:29:01.301576 22542570456896 run_lib.py:146] step: 486200, eval_loss: 3.47020e-02
I0210 12:29:18.734570 22542570456896 run_lib.py:133] step: 486250, training_loss: 2.74922e-02
I0210 12:29:36.181263 22542570456896 run_lib.py:133] step: 486300, training_loss: 3.29101e-02
I0210 12:29:36.335906 22542570456896 run_lib.py:146] step: 486300, eval_loss: 3.37553e-02
I0210 12:29:53.915699 22542570456896 run_lib.py:133] step: 486350, training_loss: 2.31523e-02
I0210 12:30:11.313617 22542570456896 run_lib.py:133] step: 486400, training_loss: 3.30980e-02
I0210 12:30:11.466433 22542570456896 run_lib.py:146] step: 486400, eval_loss: 2.93626e-02
I0210 12:30:29.111170 22542570456896 run_lib.py:133] step: 486450, training_loss: 2.43947e-02
I0210 12:30:46.577616 22542570456896 run_lib.py:133] step: 486500, training_loss: 2.74908e-02
I0210 12:30:46.732387 22542570456896 run_lib.py:146] step: 486500, eval_loss: 2.51212e-02
I0210 12:31:04.346135 22542570456896 run_lib.py:133] step: 486550, training_loss: 2.72653e-02
I0210 12:31:21.748536 22542570456896 run_lib.py:133] step: 486600, training_loss: 2.85313e-02
I0210 12:31:21.911654 22542570456896 run_lib.py:146] step: 486600, eval_loss: 2.79974e-02
I0210 12:31:39.456039 22542570456896 run_lib.py:133] step: 486650, training_loss: 2.29661e-02
I0210 12:31:56.956368 22542570456896 run_lib.py:133] step: 486700, training_loss: 2.43947e-02
I0210 12:31:57.112554 22542570456896 run_lib.py:146] step: 486700, eval_loss: 2.73767e-02
I0210 12:32:14.561508 22542570456896 run_lib.py:133] step: 486750, training_loss: 3.33183e-02
I0210 12:32:32.171869 22542570456896 run_lib.py:133] step: 486800, training_loss: 2.12190e-02
I0210 12:32:32.327435 22542570456896 run_lib.py:146] step: 486800, eval_loss: 3.47051e-02
I0210 12:32:49.761679 22542570456896 run_lib.py:133] step: 486850, training_loss: 2.50955e-02
I0210 12:33:07.183943 22542570456896 run_lib.py:133] step: 486900, training_loss: 2.83785e-02
I0210 12:33:07.334284 22542570456896 run_lib.py:146] step: 486900, eval_loss: 2.87693e-02
I0210 12:33:24.911188 22542570456896 run_lib.py:133] step: 486950, training_loss: 2.90199e-02
I0210 12:33:42.379224 22542570456896 run_lib.py:133] step: 487000, training_loss: 2.55558e-02
I0210 12:33:42.549569 22542570456896 run_lib.py:146] step: 487000, eval_loss: 2.90933e-02
I0210 12:34:00.157808 22542570456896 run_lib.py:133] step: 487050, training_loss: 2.44430e-02
I0210 12:34:17.571251 22542570456896 run_lib.py:133] step: 487100, training_loss: 2.81625e-02
I0210 12:34:17.746045 22542570456896 run_lib.py:146] step: 487100, eval_loss: 3.02477e-02
I0210 12:34:35.180280 22542570456896 run_lib.py:133] step: 487150, training_loss: 2.08514e-02
I0210 12:34:52.731770 22542570456896 run_lib.py:133] step: 487200, training_loss: 3.14570e-02
I0210 12:34:52.895255 22542570456896 run_lib.py:146] step: 487200, eval_loss: 3.14490e-02
I0210 12:35:10.288069 22542570456896 run_lib.py:133] step: 487250, training_loss: 2.71714e-02
I0210 12:35:27.774757 22542570456896 run_lib.py:133] step: 487300, training_loss: 2.66735e-02
I0210 12:35:27.930085 22542570456896 run_lib.py:146] step: 487300, eval_loss: 3.28886e-02
I0210 12:35:45.373450 22542570456896 run_lib.py:133] step: 487350, training_loss: 2.91449e-02
I0210 12:36:02.959108 22542570456896 run_lib.py:133] step: 487400, training_loss: 3.45895e-02
I0210 12:36:03.108849 22542570456896 run_lib.py:146] step: 487400, eval_loss: 2.96322e-02
I0210 12:36:20.517458 22542570456896 run_lib.py:133] step: 487450, training_loss: 2.40175e-02
I0210 12:36:37.994668 22542570456896 run_lib.py:133] step: 487500, training_loss: 3.09456e-02
I0210 12:36:38.160428 22542570456896 run_lib.py:146] step: 487500, eval_loss: 3.07530e-02
I0210 12:36:55.613656 22542570456896 run_lib.py:133] step: 487550, training_loss: 2.72486e-02
I0210 12:37:13.055689 22542570456896 run_lib.py:133] step: 487600, training_loss: 2.82267e-02
I0210 12:37:13.219434 22542570456896 run_lib.py:146] step: 487600, eval_loss: 3.13686e-02
I0210 12:37:30.817718 22542570456896 run_lib.py:133] step: 487650, training_loss: 2.62312e-02
I0210 12:37:48.289861 22542570456896 run_lib.py:133] step: 487700, training_loss: 2.39876e-02
I0210 12:37:48.445173 22542570456896 run_lib.py:146] step: 487700, eval_loss: 2.75804e-02
I0210 12:38:05.872252 22542570456896 run_lib.py:133] step: 487750, training_loss: 2.70171e-02
I0210 12:38:23.274998 22542570456896 run_lib.py:133] step: 487800, training_loss: 2.82079e-02
I0210 12:38:23.429427 22542570456896 run_lib.py:146] step: 487800, eval_loss: 2.87602e-02
I0210 12:38:40.983830 22542570456896 run_lib.py:133] step: 487850, training_loss: 2.97141e-02
I0210 12:38:58.435583 22542570456896 run_lib.py:133] step: 487900, training_loss: 3.26681e-02
I0210 12:38:58.607253 22542570456896 run_lib.py:146] step: 487900, eval_loss: 3.20671e-02
I0210 12:39:16.265396 22542570456896 run_lib.py:133] step: 487950, training_loss: 2.39943e-02
I0210 12:39:33.754593 22542570456896 run_lib.py:133] step: 488000, training_loss: 2.39919e-02
I0210 12:39:33.913754 22542570456896 run_lib.py:146] step: 488000, eval_loss: 2.52130e-02
I0210 12:39:51.518658 22542570456896 run_lib.py:133] step: 488050, training_loss: 3.08617e-02
I0210 12:40:08.937515 22542570456896 run_lib.py:133] step: 488100, training_loss: 2.56545e-02
I0210 12:40:09.106361 22542570456896 run_lib.py:146] step: 488100, eval_loss: 2.96934e-02
I0210 12:40:26.572744 22542570456896 run_lib.py:133] step: 488150, training_loss: 2.92864e-02
I0210 12:40:44.221558 22542570456896 run_lib.py:133] step: 488200, training_loss: 2.91314e-02
I0210 12:40:44.377775 22542570456896 run_lib.py:146] step: 488200, eval_loss: 2.99439e-02
I0210 12:41:01.837896 22542570456896 run_lib.py:133] step: 488250, training_loss: 2.49505e-02
I0210 12:41:19.395691 22542570456896 run_lib.py:133] step: 488300, training_loss: 2.72839e-02
I0210 12:41:19.546277 22542570456896 run_lib.py:146] step: 488300, eval_loss: 2.86497e-02
I0210 12:41:36.914127 22542570456896 run_lib.py:133] step: 488350, training_loss: 3.42500e-02
I0210 12:41:54.349276 22542570456896 run_lib.py:133] step: 488400, training_loss: 2.59335e-02
I0210 12:41:54.521552 22542570456896 run_lib.py:146] step: 488400, eval_loss: 2.61828e-02
I0210 12:42:12.181612 22542570456896 run_lib.py:133] step: 488450, training_loss: 2.65835e-02
I0210 12:42:29.617041 22542570456896 run_lib.py:133] step: 488500, training_loss: 2.85199e-02
I0210 12:42:29.779926 22542570456896 run_lib.py:146] step: 488500, eval_loss: 3.54747e-02
I0210 12:42:47.223092 22542570456896 run_lib.py:133] step: 488550, training_loss: 3.34401e-02
I0210 12:43:04.794957 22542570456896 run_lib.py:133] step: 488600, training_loss: 2.32139e-02
I0210 12:43:04.954424 22542570456896 run_lib.py:146] step: 488600, eval_loss: 2.63738e-02
I0210 12:43:22.406502 22542570456896 run_lib.py:133] step: 488650, training_loss: 2.79571e-02
I0210 12:43:39.862084 22542570456896 run_lib.py:133] step: 488700, training_loss: 2.31075e-02
I0210 12:43:40.180529 22542570456896 run_lib.py:146] step: 488700, eval_loss: 3.33485e-02
I0210 12:43:57.626279 22542570456896 run_lib.py:133] step: 488750, training_loss: 3.04122e-02
I0210 12:44:15.055637 22542570456896 run_lib.py:133] step: 488800, training_loss: 2.73913e-02
I0210 12:44:15.208401 22542570456896 run_lib.py:146] step: 488800, eval_loss: 2.97724e-02
I0210 12:44:32.639870 22542570456896 run_lib.py:133] step: 488850, training_loss: 2.78960e-02
I0210 12:44:50.064053 22542570456896 run_lib.py:133] step: 488900, training_loss: 2.79323e-02
I0210 12:44:50.227997 22542570456896 run_lib.py:146] step: 488900, eval_loss: 3.09003e-02
I0210 12:45:07.844785 22542570456896 run_lib.py:133] step: 488950, training_loss: 3.02399e-02
I0210 12:45:25.398860 22542570456896 run_lib.py:133] step: 489000, training_loss: 2.57215e-02
I0210 12:45:25.561131 22542570456896 run_lib.py:146] step: 489000, eval_loss: 3.07933e-02
I0210 12:45:42.972326 22542570456896 run_lib.py:133] step: 489050, training_loss: 2.50130e-02
I0210 12:46:00.349887 22542570456896 run_lib.py:133] step: 489100, training_loss: 2.35539e-02
I0210 12:46:00.508356 22542570456896 run_lib.py:146] step: 489100, eval_loss: 2.63230e-02
I0210 12:46:18.113785 22542570456896 run_lib.py:133] step: 489150, training_loss: 2.66266e-02
I0210 12:46:35.576099 22542570456896 run_lib.py:133] step: 489200, training_loss: 3.15972e-02
I0210 12:46:35.731190 22542570456896 run_lib.py:146] step: 489200, eval_loss: 4.44255e-02
I0210 12:46:53.172199 22542570456896 run_lib.py:133] step: 489250, training_loss: 2.50015e-02
I0210 12:47:10.617189 22542570456896 run_lib.py:133] step: 489300, training_loss: 3.09516e-02
I0210 12:47:10.779426 22542570456896 run_lib.py:146] step: 489300, eval_loss: 2.12908e-02
I0210 12:47:28.421380 22542570456896 run_lib.py:133] step: 489350, training_loss: 2.90097e-02
I0210 12:47:45.854925 22542570456896 run_lib.py:133] step: 489400, training_loss: 3.11625e-02
I0210 12:47:46.013696 22542570456896 run_lib.py:146] step: 489400, eval_loss: 2.61288e-02
I0210 12:48:03.596088 22542570456896 run_lib.py:133] step: 489450, training_loss: 2.20985e-02
I0210 12:48:21.010910 22542570456896 run_lib.py:133] step: 489500, training_loss: 2.48564e-02
I0210 12:48:21.172532 22542570456896 run_lib.py:146] step: 489500, eval_loss: 3.34757e-02
I0210 12:48:38.764602 22542570456896 run_lib.py:133] step: 489550, training_loss: 3.04939e-02
I0210 12:48:56.218829 22542570456896 run_lib.py:133] step: 489600, training_loss: 2.76505e-02
I0210 12:48:56.375831 22542570456896 run_lib.py:146] step: 489600, eval_loss: 2.75988e-02
I0210 12:49:13.824806 22542570456896 run_lib.py:133] step: 489650, training_loss: 2.40632e-02
I0210 12:49:31.412502 22542570456896 run_lib.py:133] step: 489700, training_loss: 2.59460e-02
I0210 12:49:31.566206 22542570456896 run_lib.py:146] step: 489700, eval_loss: 2.87322e-02
I0210 12:49:49.013240 22542570456896 run_lib.py:133] step: 489750, training_loss: 3.42349e-02
I0210 12:50:06.579432 22542570456896 run_lib.py:133] step: 489800, training_loss: 3.12675e-02
I0210 12:50:06.746422 22542570456896 run_lib.py:146] step: 489800, eval_loss: 2.85690e-02
I0210 12:50:24.207458 22542570456896 run_lib.py:133] step: 489850, training_loss: 2.84225e-02
I0210 12:50:41.656095 22542570456896 run_lib.py:133] step: 489900, training_loss: 2.90654e-02
I0210 12:50:41.816384 22542570456896 run_lib.py:146] step: 489900, eval_loss: 2.81722e-02
I0210 12:50:59.404642 22542570456896 run_lib.py:133] step: 489950, training_loss: 2.23781e-02
I0210 12:51:16.831596 22542570456896 run_lib.py:133] step: 490000, training_loss: 3.12267e-02
I0210 12:51:17.625239 22542570456896 run_lib.py:146] step: 490000, eval_loss: 3.32557e-02
I0210 12:51:37.883514 22542570456896 run_lib.py:133] step: 490050, training_loss: 2.66754e-02
I0210 12:51:55.434672 22542570456896 run_lib.py:133] step: 490100, training_loss: 2.72346e-02
I0210 12:51:55.591603 22542570456896 run_lib.py:146] step: 490100, eval_loss: 2.71760e-02
I0210 12:52:12.993615 22542570456896 run_lib.py:133] step: 490150, training_loss: 2.71053e-02
I0210 12:52:30.400192 22542570456896 run_lib.py:133] step: 490200, training_loss: 2.81689e-02
I0210 12:52:30.555382 22542570456896 run_lib.py:146] step: 490200, eval_loss: 2.44073e-02
I0210 12:52:48.128937 22542570456896 run_lib.py:133] step: 490250, training_loss: 2.86358e-02
I0210 12:53:05.640662 22542570456896 run_lib.py:133] step: 490300, training_loss: 2.65778e-02
I0210 12:53:05.793554 22542570456896 run_lib.py:146] step: 490300, eval_loss: 2.22757e-02
I0210 12:53:23.261855 22542570456896 run_lib.py:133] step: 490350, training_loss: 2.53498e-02
I0210 12:53:40.739103 22542570456896 run_lib.py:133] step: 490400, training_loss: 3.62883e-02
I0210 12:53:40.899103 22542570456896 run_lib.py:146] step: 490400, eval_loss: 2.25735e-02
I0210 12:53:58.493045 22542570456896 run_lib.py:133] step: 490450, training_loss: 2.88445e-02
I0210 12:54:15.895538 22542570456896 run_lib.py:133] step: 490500, training_loss: 2.59469e-02
I0210 12:54:16.059656 22542570456896 run_lib.py:146] step: 490500, eval_loss: 3.39741e-02
I0210 12:54:33.611530 22542570456896 run_lib.py:133] step: 490550, training_loss: 2.49415e-02
I0210 12:54:51.050907 22542570456896 run_lib.py:133] step: 490600, training_loss: 2.66897e-02
I0210 12:54:51.221053 22542570456896 run_lib.py:146] step: 490600, eval_loss: 3.17860e-02
I0210 12:55:08.825029 22542570456896 run_lib.py:133] step: 490650, training_loss: 2.38939e-02
I0210 12:55:26.278071 22542570456896 run_lib.py:133] step: 490700, training_loss: 2.64353e-02
I0210 12:55:26.432690 22542570456896 run_lib.py:146] step: 490700, eval_loss: 2.65107e-02
I0210 12:55:43.868314 22542570456896 run_lib.py:133] step: 490750, training_loss: 2.32779e-02
I0210 12:56:01.436942 22542570456896 run_lib.py:133] step: 490800, training_loss: 2.54926e-02
I0210 12:56:01.589428 22542570456896 run_lib.py:146] step: 490800, eval_loss: 2.69366e-02
I0210 12:56:18.994655 22542570456896 run_lib.py:133] step: 490850, training_loss: 2.83179e-02
I0210 12:56:36.601690 22542570456896 run_lib.py:133] step: 490900, training_loss: 2.22481e-02
I0210 12:56:36.765383 22542570456896 run_lib.py:146] step: 490900, eval_loss: 2.52801e-02
I0210 12:56:54.203490 22542570456896 run_lib.py:133] step: 490950, training_loss: 3.03674e-02
I0210 12:57:11.651382 22542570456896 run_lib.py:133] step: 491000, training_loss: 3.13885e-02
I0210 12:57:11.806585 22542570456896 run_lib.py:146] step: 491000, eval_loss: 3.02425e-02
I0210 12:57:29.432409 22542570456896 run_lib.py:133] step: 491050, training_loss: 2.61883e-02
I0210 12:57:46.833207 22542570456896 run_lib.py:133] step: 491100, training_loss: 2.70475e-02
I0210 12:57:46.998459 22542570456896 run_lib.py:146] step: 491100, eval_loss: 2.60987e-02
I0210 12:58:04.410639 22542570456896 run_lib.py:133] step: 491150, training_loss: 2.69443e-02
I0210 12:58:21.905896 22542570456896 run_lib.py:133] step: 491200, training_loss: 2.59340e-02
I0210 12:58:22.059016 22542570456896 run_lib.py:146] step: 491200, eval_loss: 3.01725e-02
I0210 12:58:39.683313 22542570456896 run_lib.py:133] step: 491250, training_loss: 3.27946e-02
I0210 12:58:57.094187 22542570456896 run_lib.py:133] step: 491300, training_loss: 3.23588e-02
I0210 12:58:57.254423 22542570456896 run_lib.py:146] step: 491300, eval_loss: 2.80523e-02
I0210 12:59:14.717035 22542570456896 run_lib.py:133] step: 491350, training_loss: 2.48645e-02
I0210 12:59:32.119649 22542570456896 run_lib.py:133] step: 491400, training_loss: 2.47890e-02
I0210 12:59:32.283432 22542570456896 run_lib.py:146] step: 491400, eval_loss: 2.97770e-02
I0210 12:59:49.727610 22542570456896 run_lib.py:133] step: 491450, training_loss: 2.83169e-02
I0210 13:00:07.160407 22542570456896 run_lib.py:133] step: 491500, training_loss: 2.61558e-02
I0210 13:00:07.316535 22542570456896 run_lib.py:146] step: 491500, eval_loss: 3.16133e-02
I0210 13:00:24.946297 22542570456896 run_lib.py:133] step: 491550, training_loss: 2.74926e-02
I0210 13:00:42.421016 22542570456896 run_lib.py:133] step: 491600, training_loss: 2.42582e-02
I0210 13:00:42.576514 22542570456896 run_lib.py:146] step: 491600, eval_loss: 2.94636e-02
I0210 13:00:59.989262 22542570456896 run_lib.py:133] step: 491650, training_loss: 2.48443e-02
I0210 13:01:17.371870 22542570456896 run_lib.py:133] step: 491700, training_loss: 3.09876e-02
I0210 13:01:17.529862 22542570456896 run_lib.py:146] step: 491700, eval_loss: 3.24414e-02
I0210 13:01:35.171231 22542570456896 run_lib.py:133] step: 491750, training_loss: 3.95647e-02
I0210 13:01:52.610815 22542570456896 run_lib.py:133] step: 491800, training_loss: 2.36943e-02
I0210 13:01:52.770445 22542570456896 run_lib.py:146] step: 491800, eval_loss: 2.29253e-02
I0210 13:02:10.359976 22542570456896 run_lib.py:133] step: 491850, training_loss: 2.62217e-02
I0210 13:02:27.768325 22542570456896 run_lib.py:133] step: 491900, training_loss: 2.54838e-02
I0210 13:02:27.927329 22542570456896 run_lib.py:146] step: 491900, eval_loss: 2.37169e-02
I0210 13:02:45.496264 22542570456896 run_lib.py:133] step: 491950, training_loss: 3.04768e-02
I0210 13:03:02.983149 22542570456896 run_lib.py:133] step: 492000, training_loss: 2.25015e-02
I0210 13:03:03.139561 22542570456896 run_lib.py:146] step: 492000, eval_loss: 2.29686e-02
I0210 13:03:20.743371 22542570456896 run_lib.py:133] step: 492050, training_loss: 2.53161e-02
I0210 13:03:38.166847 22542570456896 run_lib.py:133] step: 492100, training_loss: 3.26923e-02
I0210 13:03:38.322418 22542570456896 run_lib.py:146] step: 492100, eval_loss: 2.94010e-02
I0210 13:03:55.761715 22542570456896 run_lib.py:133] step: 492150, training_loss: 2.63159e-02
I0210 13:04:13.332517 22542570456896 run_lib.py:133] step: 492200, training_loss: 2.97447e-02
I0210 13:04:13.485523 22542570456896 run_lib.py:146] step: 492200, eval_loss: 3.59521e-02
I0210 13:04:30.883276 22542570456896 run_lib.py:133] step: 492250, training_loss: 1.57478e-02
I0210 13:04:48.326747 22542570456896 run_lib.py:133] step: 492300, training_loss: 2.49046e-02
I0210 13:04:48.496318 22542570456896 run_lib.py:146] step: 492300, eval_loss: 3.61464e-02
I0210 13:05:06.132330 22542570456896 run_lib.py:133] step: 492350, training_loss: 2.70785e-02
I0210 13:05:23.766554 22542570456896 run_lib.py:133] step: 492400, training_loss: 2.77862e-02
I0210 13:05:23.924334 22542570456896 run_lib.py:146] step: 492400, eval_loss: 2.73619e-02
I0210 13:05:41.339545 22542570456896 run_lib.py:133] step: 492450, training_loss: 2.60721e-02
I0210 13:05:58.743989 22542570456896 run_lib.py:133] step: 492500, training_loss: 2.89866e-02
I0210 13:05:58.899351 22542570456896 run_lib.py:146] step: 492500, eval_loss: 2.56870e-02
I0210 13:06:16.327239 22542570456896 run_lib.py:133] step: 492550, training_loss: 2.82913e-02
I0210 13:06:33.934058 22542570456896 run_lib.py:133] step: 492600, training_loss: 2.80458e-02
I0210 13:06:34.087286 22542570456896 run_lib.py:146] step: 492600, eval_loss: 2.74362e-02
I0210 13:06:51.531578 22542570456896 run_lib.py:133] step: 492650, training_loss: 2.87341e-02
I0210 13:07:08.958226 22542570456896 run_lib.py:133] step: 492700, training_loss: 2.98256e-02
I0210 13:07:09.111305 22542570456896 run_lib.py:146] step: 492700, eval_loss: 2.48823e-02
I0210 13:07:26.561002 22542570456896 run_lib.py:133] step: 492750, training_loss: 2.64510e-02
I0210 13:07:44.209121 22542570456896 run_lib.py:133] step: 492800, training_loss: 2.68290e-02
I0210 13:07:44.369608 22542570456896 run_lib.py:146] step: 492800, eval_loss: 2.66868e-02
I0210 13:08:01.771559 22542570456896 run_lib.py:133] step: 492850, training_loss: 2.35678e-02
I0210 13:08:19.276212 22542570456896 run_lib.py:133] step: 492900, training_loss: 3.03848e-02
I0210 13:08:19.448244 22542570456896 run_lib.py:146] step: 492900, eval_loss: 3.29691e-02
I0210 13:08:36.905065 22542570456896 run_lib.py:133] step: 492950, training_loss: 2.85330e-02
I0210 13:08:54.327573 22542570456896 run_lib.py:133] step: 493000, training_loss: 2.35552e-02
I0210 13:08:54.484167 22542570456896 run_lib.py:146] step: 493000, eval_loss: 3.25180e-02
I0210 13:09:12.113529 22542570456896 run_lib.py:133] step: 493050, training_loss: 2.22662e-02
I0210 13:09:29.612794 22542570456896 run_lib.py:133] step: 493100, training_loss: 2.85722e-02
I0210 13:09:29.764214 22542570456896 run_lib.py:146] step: 493100, eval_loss: 2.92443e-02
I0210 13:09:47.163208 22542570456896 run_lib.py:133] step: 493150, training_loss: 3.22195e-02
I0210 13:10:04.633975 22542570456896 run_lib.py:133] step: 493200, training_loss: 2.69149e-02
I0210 13:10:04.799207 22542570456896 run_lib.py:146] step: 493200, eval_loss: 3.91887e-02
I0210 13:10:22.417574 22542570456896 run_lib.py:133] step: 493250, training_loss: 2.52656e-02
I0210 13:10:39.877148 22542570456896 run_lib.py:133] step: 493300, training_loss: 2.76459e-02
I0210 13:10:40.038489 22542570456896 run_lib.py:146] step: 493300, eval_loss: 2.74637e-02
I0210 13:10:57.500811 22542570456896 run_lib.py:133] step: 493350, training_loss: 2.42733e-02
I0210 13:11:14.809260 22542570456896 run_lib.py:133] step: 493400, training_loss: 3.24734e-02
I0210 13:11:14.968387 22542570456896 run_lib.py:146] step: 493400, eval_loss: 2.79986e-02
I0210 13:11:32.501536 22542570456896 run_lib.py:133] step: 493450, training_loss: 2.66104e-02
I0210 13:11:49.910583 22542570456896 run_lib.py:133] step: 493500, training_loss: 2.22832e-02
I0210 13:11:50.068639 22542570456896 run_lib.py:146] step: 493500, eval_loss: 2.48495e-02
I0210 13:12:07.533194 22542570456896 run_lib.py:133] step: 493550, training_loss: 3.15086e-02
I0210 13:12:25.162566 22542570456896 run_lib.py:133] step: 493600, training_loss: 3.09932e-02
I0210 13:12:25.313436 22542570456896 run_lib.py:146] step: 493600, eval_loss: 3.14704e-02
I0210 13:12:42.746269 22542570456896 run_lib.py:133] step: 493650, training_loss: 2.95198e-02
I0210 13:13:00.284775 22542570456896 run_lib.py:133] step: 493700, training_loss: 2.50728e-02
I0210 13:13:00.454535 22542570456896 run_lib.py:146] step: 493700, eval_loss: 2.60499e-02
I0210 13:13:17.901618 22542570456896 run_lib.py:133] step: 493750, training_loss: 3.18265e-02
I0210 13:13:35.336731 22542570456896 run_lib.py:133] step: 493800, training_loss: 3.43543e-02
I0210 13:13:35.493276 22542570456896 run_lib.py:146] step: 493800, eval_loss: 2.95187e-02
I0210 13:13:53.112908 22542570456896 run_lib.py:133] step: 493850, training_loss: 2.97063e-02
I0210 13:14:10.515594 22542570456896 run_lib.py:133] step: 493900, training_loss: 2.54169e-02
I0210 13:14:10.671973 22542570456896 run_lib.py:146] step: 493900, eval_loss: 3.07972e-02
I0210 13:14:28.160372 22542570456896 run_lib.py:133] step: 493950, training_loss: 2.54794e-02
I0210 13:14:45.791380 22542570456896 run_lib.py:133] step: 494000, training_loss: 2.59784e-02
I0210 13:14:45.954514 22542570456896 run_lib.py:146] step: 494000, eval_loss: 3.12063e-02
I0210 13:15:03.379432 22542570456896 run_lib.py:133] step: 494050, training_loss: 3.77686e-02
I0210 13:15:20.794281 22542570456896 run_lib.py:133] step: 494100, training_loss: 2.48995e-02
I0210 13:15:20.954390 22542570456896 run_lib.py:146] step: 494100, eval_loss: 2.82760e-02
I0210 13:15:38.468165 22542570456896 run_lib.py:133] step: 494150, training_loss: 3.24597e-02
I0210 13:15:55.848517 22542570456896 run_lib.py:133] step: 494200, training_loss: 2.24567e-02
I0210 13:15:56.009608 22542570456896 run_lib.py:146] step: 494200, eval_loss: 3.42702e-02
I0210 13:16:13.467293 22542570456896 run_lib.py:133] step: 494250, training_loss: 3.21290e-02
I0210 13:16:30.942218 22542570456896 run_lib.py:133] step: 494300, training_loss: 2.33288e-02
I0210 13:16:31.099368 22542570456896 run_lib.py:146] step: 494300, eval_loss: 2.50172e-02
I0210 13:16:48.680920 22542570456896 run_lib.py:133] step: 494350, training_loss: 2.39111e-02
I0210 13:17:06.191047 22542570456896 run_lib.py:133] step: 494400, training_loss: 2.84043e-02
I0210 13:17:06.346551 22542570456896 run_lib.py:146] step: 494400, eval_loss: 3.43477e-02
I0210 13:17:23.741819 22542570456896 run_lib.py:133] step: 494450, training_loss: 3.24294e-02
I0210 13:17:41.237320 22542570456896 run_lib.py:133] step: 494500, training_loss: 3.08348e-02
I0210 13:17:41.388596 22542570456896 run_lib.py:146] step: 494500, eval_loss: 2.98877e-02
I0210 13:17:59.023352 22542570456896 run_lib.py:133] step: 494550, training_loss: 2.81537e-02
I0210 13:18:16.419383 22542570456896 run_lib.py:133] step: 494600, training_loss: 2.74978e-02
I0210 13:18:16.569699 22542570456896 run_lib.py:146] step: 494600, eval_loss: 2.54077e-02
I0210 13:18:34.186630 22542570456896 run_lib.py:133] step: 494650, training_loss: 2.75990e-02
I0210 13:18:51.658543 22542570456896 run_lib.py:133] step: 494700, training_loss: 2.93000e-02
I0210 13:18:51.816717 22542570456896 run_lib.py:146] step: 494700, eval_loss: 2.93334e-02
I0210 13:19:09.375786 22542570456896 run_lib.py:133] step: 494750, training_loss: 2.12963e-02
I0210 13:19:26.784336 22542570456896 run_lib.py:133] step: 494800, training_loss: 2.88010e-02
I0210 13:19:26.941607 22542570456896 run_lib.py:146] step: 494800, eval_loss: 3.36956e-02
I0210 13:19:44.534592 22542570456896 run_lib.py:133] step: 494850, training_loss: 2.68572e-02
I0210 13:20:02.001493 22542570456896 run_lib.py:133] step: 494900, training_loss: 2.76845e-02
I0210 13:20:02.160145 22542570456896 run_lib.py:146] step: 494900, eval_loss: 2.98939e-02
I0210 13:20:19.571860 22542570456896 run_lib.py:133] step: 494950, training_loss: 3.43581e-02
I0210 13:20:37.161803 22542570456896 run_lib.py:133] step: 495000, training_loss: 2.50337e-02
I0210 13:20:37.314395 22542570456896 run_lib.py:146] step: 495000, eval_loss: 2.67572e-02
I0210 13:20:54.719928 22542570456896 run_lib.py:133] step: 495050, training_loss: 2.61187e-02
I0210 13:21:12.141800 22542570456896 run_lib.py:133] step: 495100, training_loss: 3.37422e-02
I0210 13:21:12.309600 22542570456896 run_lib.py:146] step: 495100, eval_loss: 3.20790e-02
I0210 13:21:29.943717 22542570456896 run_lib.py:133] step: 495150, training_loss: 2.54358e-02
I0210 13:21:47.386729 22542570456896 run_lib.py:133] step: 495200, training_loss: 2.27456e-02
I0210 13:21:47.544457 22542570456896 run_lib.py:146] step: 495200, eval_loss: 2.47287e-02
I0210 13:22:05.104095 22542570456896 run_lib.py:133] step: 495250, training_loss: 3.43342e-02
I0210 13:22:22.568547 22542570456896 run_lib.py:133] step: 495300, training_loss: 2.56778e-02
I0210 13:22:22.733023 22542570456896 run_lib.py:146] step: 495300, eval_loss: 2.91981e-02
I0210 13:22:40.156733 22542570456896 run_lib.py:133] step: 495350, training_loss: 3.30367e-02
I0210 13:22:57.723919 22542570456896 run_lib.py:133] step: 495400, training_loss: 2.88462e-02
I0210 13:22:57.879678 22542570456896 run_lib.py:146] step: 495400, eval_loss: 2.70201e-02
I0210 13:23:15.381498 22542570456896 run_lib.py:133] step: 495450, training_loss: 2.50609e-02
I0210 13:23:32.847719 22542570456896 run_lib.py:133] step: 495500, training_loss: 2.77301e-02
I0210 13:23:32.999412 22542570456896 run_lib.py:146] step: 495500, eval_loss: 2.26694e-02
I0210 13:23:50.406336 22542570456896 run_lib.py:133] step: 495550, training_loss: 2.58581e-02
I0210 13:24:08.018117 22542570456896 run_lib.py:133] step: 495600, training_loss: 2.63340e-02
I0210 13:24:08.175344 22542570456896 run_lib.py:146] step: 495600, eval_loss: 3.10544e-02
I0210 13:24:25.604034 22542570456896 run_lib.py:133] step: 495650, training_loss: 2.90682e-02
I0210 13:24:43.126642 22542570456896 run_lib.py:133] step: 495700, training_loss: 2.50981e-02
I0210 13:24:43.311369 22542570456896 run_lib.py:146] step: 495700, eval_loss: 2.74499e-02
I0210 13:25:00.808572 22542570456896 run_lib.py:133] step: 495750, training_loss: 2.98538e-02
I0210 13:25:18.267208 22542570456896 run_lib.py:133] step: 495800, training_loss: 2.75098e-02
I0210 13:25:18.423524 22542570456896 run_lib.py:146] step: 495800, eval_loss: 2.91604e-02
I0210 13:25:35.990254 22542570456896 run_lib.py:133] step: 495850, training_loss: 2.25885e-02
I0210 13:25:53.434666 22542570456896 run_lib.py:133] step: 495900, training_loss: 3.60331e-02
I0210 13:25:53.590446 22542570456896 run_lib.py:146] step: 495900, eval_loss: 3.05690e-02
I0210 13:26:11.011360 22542570456896 run_lib.py:133] step: 495950, training_loss: 2.67303e-02
I0210 13:26:28.449049 22542570456896 run_lib.py:133] step: 496000, training_loss: 2.79074e-02
I0210 13:26:28.603682 22542570456896 run_lib.py:146] step: 496000, eval_loss: 2.33566e-02
I0210 13:26:46.253012 22542570456896 run_lib.py:133] step: 496050, training_loss: 2.65060e-02
I0210 13:27:03.712051 22542570456896 run_lib.py:133] step: 496100, training_loss: 3.21125e-02
I0210 13:27:03.868366 22542570456896 run_lib.py:146] step: 496100, eval_loss: 2.31896e-02
I0210 13:27:21.460271 22542570456896 run_lib.py:133] step: 496150, training_loss: 3.11468e-02
I0210 13:27:38.883511 22542570456896 run_lib.py:133] step: 496200, training_loss: 2.60938e-02
I0210 13:27:39.039695 22542570456896 run_lib.py:146] step: 496200, eval_loss: 2.99773e-02
I0210 13:27:56.658534 22542570456896 run_lib.py:133] step: 496250, training_loss: 2.47713e-02
I0210 13:28:14.083674 22542570456896 run_lib.py:133] step: 496300, training_loss: 2.62286e-02
I0210 13:28:14.240936 22542570456896 run_lib.py:146] step: 496300, eval_loss: 2.63008e-02
I0210 13:28:31.678656 22542570456896 run_lib.py:133] step: 496350, training_loss: 2.97768e-02
I0210 13:28:49.288869 22542570456896 run_lib.py:133] step: 496400, training_loss: 3.17903e-02
I0210 13:28:49.450310 22542570456896 run_lib.py:146] step: 496400, eval_loss: 3.04661e-02
I0210 13:29:06.903203 22542570456896 run_lib.py:133] step: 496450, training_loss: 2.48850e-02
I0210 13:29:24.477723 22542570456896 run_lib.py:133] step: 496500, training_loss: 2.43418e-02
I0210 13:29:24.631542 22542570456896 run_lib.py:146] step: 496500, eval_loss: 2.60737e-02
I0210 13:29:42.103142 22542570456896 run_lib.py:133] step: 496550, training_loss: 2.25372e-02
I0210 13:29:59.523664 22542570456896 run_lib.py:133] step: 496600, training_loss: 2.80396e-02
I0210 13:29:59.682341 22542570456896 run_lib.py:146] step: 496600, eval_loss: 2.92189e-02
I0210 13:30:17.300280 22542570456896 run_lib.py:133] step: 496650, training_loss: 3.00619e-02
I0210 13:30:34.777895 22542570456896 run_lib.py:133] step: 496700, training_loss: 3.34322e-02
I0210 13:30:34.941380 22542570456896 run_lib.py:146] step: 496700, eval_loss: 2.77493e-02
I0210 13:30:52.370006 22542570456896 run_lib.py:133] step: 496750, training_loss: 3.37403e-02
I0210 13:31:09.952314 22542570456896 run_lib.py:133] step: 496800, training_loss: 3.08047e-02
I0210 13:31:10.113030 22542570456896 run_lib.py:146] step: 496800, eval_loss: 2.89004e-02
I0210 13:31:27.596728 22542570456896 run_lib.py:133] step: 496850, training_loss: 2.89066e-02
I0210 13:31:45.013184 22542570456896 run_lib.py:133] step: 496900, training_loss: 3.00347e-02
I0210 13:31:45.349967 22542570456896 run_lib.py:146] step: 496900, eval_loss: 3.62529e-02
I0210 13:32:02.757446 22542570456896 run_lib.py:133] step: 496950, training_loss: 3.24429e-02
I0210 13:32:20.180031 22542570456896 run_lib.py:133] step: 497000, training_loss: 2.68248e-02
I0210 13:32:20.334367 22542570456896 run_lib.py:146] step: 497000, eval_loss: 2.62909e-02
I0210 13:32:37.761656 22542570456896 run_lib.py:133] step: 497050, training_loss: 2.89238e-02
I0210 13:32:55.210548 22542570456896 run_lib.py:133] step: 497100, training_loss: 2.86155e-02
I0210 13:32:55.367472 22542570456896 run_lib.py:146] step: 497100, eval_loss: 2.96065e-02
I0210 13:33:12.965888 22542570456896 run_lib.py:133] step: 497150, training_loss: 3.15111e-02
I0210 13:33:30.479725 22542570456896 run_lib.py:133] step: 497200, training_loss: 3.24192e-02
I0210 13:33:30.634441 22542570456896 run_lib.py:146] step: 497200, eval_loss: 2.78241e-02
I0210 13:33:48.101713 22542570456896 run_lib.py:133] step: 497250, training_loss: 2.44452e-02
I0210 13:34:05.482262 22542570456896 run_lib.py:133] step: 497300, training_loss: 3.10193e-02
I0210 13:34:05.643319 22542570456896 run_lib.py:146] step: 497300, eval_loss: 2.23566e-02
I0210 13:34:23.211507 22542570456896 run_lib.py:133] step: 497350, training_loss: 2.93015e-02
I0210 13:34:40.764196 22542570456896 run_lib.py:133] step: 497400, training_loss: 2.81106e-02
I0210 13:34:40.923913 22542570456896 run_lib.py:146] step: 497400, eval_loss: 2.54964e-02
I0210 13:34:58.397785 22542570456896 run_lib.py:133] step: 497450, training_loss: 2.93145e-02
I0210 13:35:15.842928 22542570456896 run_lib.py:133] step: 497500, training_loss: 2.66957e-02
I0210 13:35:16.006446 22542570456896 run_lib.py:146] step: 497500, eval_loss: 2.78642e-02
I0210 13:35:33.550013 22542570456896 run_lib.py:133] step: 497550, training_loss: 2.40371e-02
I0210 13:35:50.958180 22542570456896 run_lib.py:133] step: 497600, training_loss: 2.99419e-02
I0210 13:35:51.142870 22542570456896 run_lib.py:146] step: 497600, eval_loss: 3.54739e-02
I0210 13:36:08.770977 22542570456896 run_lib.py:133] step: 497650, training_loss: 2.91399e-02
I0210 13:36:26.212747 22542570456896 run_lib.py:133] step: 497700, training_loss: 3.36111e-02
I0210 13:36:26.368839 22542570456896 run_lib.py:146] step: 497700, eval_loss: 3.26808e-02
I0210 13:36:44.018298 22542570456896 run_lib.py:133] step: 497750, training_loss: 2.55553e-02
I0210 13:37:01.391453 22542570456896 run_lib.py:133] step: 497800, training_loss: 2.93296e-02
I0210 13:37:01.542611 22542570456896 run_lib.py:146] step: 497800, eval_loss: 3.28924e-02
I0210 13:37:18.948224 22542570456896 run_lib.py:133] step: 497850, training_loss: 2.52429e-02
I0210 13:37:36.518415 22542570456896 run_lib.py:133] step: 497900, training_loss: 2.44074e-02
I0210 13:37:36.681164 22542570456896 run_lib.py:146] step: 497900, eval_loss: 3.39775e-02
I0210 13:37:54.161220 22542570456896 run_lib.py:133] step: 497950, training_loss: 2.97380e-02
I0210 13:38:11.775282 22542570456896 run_lib.py:133] step: 498000, training_loss: 3.01801e-02
I0210 13:38:11.933415 22542570456896 run_lib.py:146] step: 498000, eval_loss: 2.99692e-02
I0210 13:38:29.333698 22542570456896 run_lib.py:133] step: 498050, training_loss: 2.77092e-02
I0210 13:38:46.767247 22542570456896 run_lib.py:133] step: 498100, training_loss: 2.45898e-02
I0210 13:38:46.925620 22542570456896 run_lib.py:146] step: 498100, eval_loss: 2.27665e-02
I0210 13:39:04.485592 22542570456896 run_lib.py:133] step: 498150, training_loss: 2.27830e-02
I0210 13:39:21.948090 22542570456896 run_lib.py:133] step: 498200, training_loss: 2.33555e-02
I0210 13:39:22.099643 22542570456896 run_lib.py:146] step: 498200, eval_loss: 2.60796e-02
I0210 13:39:39.552451 22542570456896 run_lib.py:133] step: 498250, training_loss: 2.72891e-02
I0210 13:39:56.960504 22542570456896 run_lib.py:133] step: 498300, training_loss: 2.38225e-02
I0210 13:39:57.114236 22542570456896 run_lib.py:146] step: 498300, eval_loss: 2.54322e-02
I0210 13:40:14.756805 22542570456896 run_lib.py:133] step: 498350, training_loss: 3.23716e-02
I0210 13:40:32.169997 22542570456896 run_lib.py:133] step: 498400, training_loss: 2.77857e-02
I0210 13:40:32.323228 22542570456896 run_lib.py:146] step: 498400, eval_loss: 3.48899e-02
I0210 13:40:49.852483 22542570456896 run_lib.py:133] step: 498450, training_loss: 2.73213e-02
I0210 13:41:07.271917 22542570456896 run_lib.py:133] step: 498500, training_loss: 2.50742e-02
I0210 13:41:07.457225 22542570456896 run_lib.py:146] step: 498500, eval_loss: 2.48805e-02
I0210 13:41:24.896616 22542570456896 run_lib.py:133] step: 498550, training_loss: 3.57520e-02
I0210 13:41:42.364480 22542570456896 run_lib.py:133] step: 498600, training_loss: 3.13758e-02
I0210 13:41:42.526726 22542570456896 run_lib.py:146] step: 498600, eval_loss: 2.69130e-02
I0210 13:42:00.130594 22542570456896 run_lib.py:133] step: 498650, training_loss: 2.41398e-02
I0210 13:42:17.617973 22542570456896 run_lib.py:133] step: 498700, training_loss: 2.77374e-02
I0210 13:42:17.773573 22542570456896 run_lib.py:146] step: 498700, eval_loss: 2.78267e-02
I0210 13:42:35.179414 22542570456896 run_lib.py:133] step: 498750, training_loss: 2.95257e-02
I0210 13:42:52.650968 22542570456896 run_lib.py:133] step: 498800, training_loss: 2.54695e-02
I0210 13:42:52.803431 22542570456896 run_lib.py:146] step: 498800, eval_loss: 3.01144e-02
I0210 13:43:10.412471 22542570456896 run_lib.py:133] step: 498850, training_loss: 2.48210e-02
I0210 13:43:27.893305 22542570456896 run_lib.py:133] step: 498900, training_loss: 2.55483e-02
I0210 13:43:28.048895 22542570456896 run_lib.py:146] step: 498900, eval_loss: 2.59105e-02
I0210 13:43:45.587608 22542570456896 run_lib.py:133] step: 498950, training_loss: 2.62024e-02
I0210 13:44:03.012306 22542570456896 run_lib.py:133] step: 499000, training_loss: 2.28549e-02
I0210 13:44:03.170557 22542570456896 run_lib.py:146] step: 499000, eval_loss: 2.76704e-02
I0210 13:44:20.738239 22542570456896 run_lib.py:133] step: 499050, training_loss: 3.23145e-02
I0210 13:44:38.231522 22542570456896 run_lib.py:133] step: 499100, training_loss: 2.50662e-02
I0210 13:44:38.387693 22542570456896 run_lib.py:146] step: 499100, eval_loss: 2.68985e-02
I0210 13:44:55.983953 22542570456896 run_lib.py:133] step: 499150, training_loss: 2.82004e-02
I0210 13:45:13.438621 22542570456896 run_lib.py:133] step: 499200, training_loss: 3.35027e-02
I0210 13:45:13.594516 22542570456896 run_lib.py:146] step: 499200, eval_loss: 2.38470e-02
I0210 13:45:30.984113 22542570456896 run_lib.py:133] step: 499250, training_loss: 2.75778e-02
I0210 13:45:48.518232 22542570456896 run_lib.py:133] step: 499300, training_loss: 3.22650e-02
I0210 13:45:48.678380 22542570456896 run_lib.py:146] step: 499300, eval_loss: 2.41893e-02
I0210 13:46:06.136030 22542570456896 run_lib.py:133] step: 499350, training_loss: 2.70630e-02
I0210 13:46:23.626368 22542570456896 run_lib.py:133] step: 499400, training_loss: 3.49393e-02
I0210 13:46:23.803884 22542570456896 run_lib.py:146] step: 499400, eval_loss: 2.61836e-02
I0210 13:46:41.418292 22542570456896 run_lib.py:133] step: 499450, training_loss: 2.46169e-02
I0210 13:46:59.028457 22542570456896 run_lib.py:133] step: 499500, training_loss: 2.68525e-02
I0210 13:46:59.186687 22542570456896 run_lib.py:146] step: 499500, eval_loss: 2.62778e-02
I0210 13:47:16.593334 22542570456896 run_lib.py:133] step: 499550, training_loss: 2.93694e-02
I0210 13:47:34.032438 22542570456896 run_lib.py:133] step: 499600, training_loss: 3.21308e-02
I0210 13:47:34.188340 22542570456896 run_lib.py:146] step: 499600, eval_loss: 2.74138e-02
I0210 13:47:51.594124 22542570456896 run_lib.py:133] step: 499650, training_loss: 2.33389e-02
I0210 13:48:09.212534 22542570456896 run_lib.py:133] step: 499700, training_loss: 3.10944e-02
I0210 13:48:09.369808 22542570456896 run_lib.py:146] step: 499700, eval_loss: 2.63979e-02
I0210 13:48:26.831107 22542570456896 run_lib.py:133] step: 499750, training_loss: 2.19670e-02
I0210 13:48:44.263199 22542570456896 run_lib.py:133] step: 499800, training_loss: 2.18836e-02
I0210 13:48:44.417413 22542570456896 run_lib.py:146] step: 499800, eval_loss: 2.38860e-02
I0210 13:49:01.862632 22542570456896 run_lib.py:133] step: 499850, training_loss: 2.85708e-02
I0210 13:49:19.508115 22542570456896 run_lib.py:133] step: 499900, training_loss: 3.06161e-02
I0210 13:49:19.668483 22542570456896 run_lib.py:146] step: 499900, eval_loss: 3.24067e-02
I0210 13:49:37.157346 22542570456896 run_lib.py:133] step: 499950, training_loss: 3.12296e-02
I0210 13:49:54.737454 22542570456896 run_lib.py:133] step: 500000, training_loss: 2.72274e-02
I0210 13:49:55.462497 22542570456896 run_lib.py:146] step: 500000, eval_loss: 2.87799e-02
I0210 13:50:15.991030 22542570456896 run_lib.py:133] step: 500050, training_loss: 2.73059e-02
I0210 13:50:33.398592 22542570456896 run_lib.py:133] step: 500100, training_loss: 2.73248e-02
I0210 13:50:33.555341 22542570456896 run_lib.py:146] step: 500100, eval_loss: 3.12370e-02
I0210 13:50:50.969731 22542570456896 run_lib.py:133] step: 500150, training_loss: 3.05367e-02
I0210 13:51:08.610861 22542570456896 run_lib.py:133] step: 500200, training_loss: 3.12471e-02
I0210 13:51:08.773944 22542570456896 run_lib.py:146] step: 500200, eval_loss: 2.98272e-02
I0210 13:51:26.283339 22542570456896 run_lib.py:133] step: 500250, training_loss: 2.93429e-02
I0210 13:51:43.826911 22542570456896 run_lib.py:133] step: 500300, training_loss: 3.25690e-02
I0210 13:51:43.986894 22542570456896 run_lib.py:146] step: 500300, eval_loss: 3.31183e-02
I0210 13:52:01.441686 22542570456896 run_lib.py:133] step: 500350, training_loss: 2.77359e-02
I0210 13:52:18.877834 22542570456896 run_lib.py:133] step: 500400, training_loss: 2.61739e-02
I0210 13:52:19.033378 22542570456896 run_lib.py:146] step: 500400, eval_loss: 2.78249e-02
I0210 13:52:36.613988 22542570456896 run_lib.py:133] step: 500450, training_loss: 2.79328e-02
I0210 13:52:54.167184 22542570456896 run_lib.py:133] step: 500500, training_loss: 2.62702e-02
I0210 13:52:54.334383 22542570456896 run_lib.py:146] step: 500500, eval_loss: 3.08632e-02
I0210 13:53:11.833670 22542570456896 run_lib.py:133] step: 500550, training_loss: 2.86072e-02
I0210 13:53:29.272305 22542570456896 run_lib.py:133] step: 500600, training_loss: 2.46744e-02
I0210 13:53:29.428606 22542570456896 run_lib.py:146] step: 500600, eval_loss: 2.50464e-02
I0210 13:53:47.038078 22542570456896 run_lib.py:133] step: 500650, training_loss: 2.91631e-02
I0210 13:54:04.466159 22542570456896 run_lib.py:133] step: 500700, training_loss: 2.50648e-02
I0210 13:54:04.629366 22542570456896 run_lib.py:146] step: 500700, eval_loss: 3.07499e-02
I0210 13:54:22.263910 22542570456896 run_lib.py:133] step: 500750, training_loss: 2.61506e-02
I0210 13:54:39.700965 22542570456896 run_lib.py:133] step: 500800, training_loss: 2.60375e-02
I0210 13:54:39.861689 22542570456896 run_lib.py:146] step: 500800, eval_loss: 2.36184e-02
I0210 13:54:57.466308 22542570456896 run_lib.py:133] step: 500850, training_loss: 2.91133e-02
I0210 13:55:14.890612 22542570456896 run_lib.py:133] step: 500900, training_loss: 2.65758e-02
I0210 13:55:15.050414 22542570456896 run_lib.py:146] step: 500900, eval_loss: 3.08320e-02
I0210 13:55:32.488799 22542570456896 run_lib.py:133] step: 500950, training_loss: 2.86370e-02
I0210 13:55:50.091097 22542570456896 run_lib.py:133] step: 501000, training_loss: 2.43667e-02
I0210 13:55:50.256781 22542570456896 run_lib.py:146] step: 501000, eval_loss: 2.20399e-02
I0210 13:56:07.677634 22542570456896 run_lib.py:133] step: 501050, training_loss: 2.49761e-02
I0210 13:56:25.337795 22542570456896 run_lib.py:133] step: 501100, training_loss: 2.32742e-02
I0210 13:56:25.490934 22542570456896 run_lib.py:146] step: 501100, eval_loss: 3.56232e-02
I0210 13:56:42.971585 22542570456896 run_lib.py:133] step: 501150, training_loss: 3.13951e-02
I0210 13:57:00.397871 22542570456896 run_lib.py:133] step: 501200, training_loss: 2.03435e-02
I0210 13:57:00.553528 22542570456896 run_lib.py:146] step: 501200, eval_loss: 2.64841e-02
I0210 13:57:18.183389 22542570456896 run_lib.py:133] step: 501250, training_loss: 3.14413e-02
I0210 13:57:35.610113 22542570456896 run_lib.py:133] step: 501300, training_loss: 2.46567e-02
I0210 13:57:35.763290 22542570456896 run_lib.py:146] step: 501300, eval_loss: 2.99119e-02
I0210 13:57:53.234491 22542570456896 run_lib.py:133] step: 501350, training_loss: 3.73734e-02
I0210 13:58:10.915524 22542570456896 run_lib.py:133] step: 501400, training_loss: 2.34357e-02
I0210 13:58:11.075440 22542570456896 run_lib.py:146] step: 501400, eval_loss: 2.70397e-02
I0210 13:58:28.552147 22542570456896 run_lib.py:133] step: 501450, training_loss: 2.62011e-02
I0210 13:58:45.999132 22542570456896 run_lib.py:133] step: 501500, training_loss: 2.25834e-02
I0210 13:58:46.160616 22542570456896 run_lib.py:146] step: 501500, eval_loss: 2.71078e-02
I0210 13:59:03.802290 22542570456896 run_lib.py:133] step: 501550, training_loss: 3.48411e-02
I0210 13:59:21.219123 22542570456896 run_lib.py:133] step: 501600, training_loss: 2.17177e-02
I0210 13:59:21.380336 22542570456896 run_lib.py:146] step: 501600, eval_loss: 2.51675e-02
I0210 13:59:38.797273 22542570456896 run_lib.py:133] step: 501650, training_loss: 3.25560e-02
I0210 13:59:56.227893 22542570456896 run_lib.py:133] step: 501700, training_loss: 2.48994e-02
I0210 13:59:56.379980 22542570456896 run_lib.py:146] step: 501700, eval_loss: 3.20295e-02
I0210 14:00:14.023783 22542570456896 run_lib.py:133] step: 501750, training_loss: 2.59127e-02
I0210 14:00:31.550644 22542570456896 run_lib.py:133] step: 501800, training_loss: 2.71236e-02
I0210 14:00:31.709437 22542570456896 run_lib.py:146] step: 501800, eval_loss: 3.00355e-02
I0210 14:00:49.099094 22542570456896 run_lib.py:133] step: 501850, training_loss: 2.64762e-02
I0210 14:01:06.518572 22542570456896 run_lib.py:133] step: 501900, training_loss: 2.30881e-02
I0210 14:01:06.681658 22542570456896 run_lib.py:146] step: 501900, eval_loss: 2.51024e-02
I0210 14:01:24.309579 22542570456896 run_lib.py:133] step: 501950, training_loss: 2.04561e-02
I0210 14:01:41.795135 22542570456896 run_lib.py:133] step: 502000, training_loss: 2.33080e-02
I0210 14:01:41.954641 22542570456896 run_lib.py:146] step: 502000, eval_loss: 1.89694e-02
I0210 14:01:59.563927 22542570456896 run_lib.py:133] step: 502050, training_loss: 2.58702e-02
I0210 14:02:16.975900 22542570456896 run_lib.py:133] step: 502100, training_loss: 2.56488e-02
I0210 14:02:17.131596 22542570456896 run_lib.py:146] step: 502100, eval_loss: 3.19280e-02
I0210 14:02:34.730269 22542570456896 run_lib.py:133] step: 502150, training_loss: 2.54145e-02
I0210 14:02:52.195180 22542570456896 run_lib.py:133] step: 502200, training_loss: 2.39939e-02
I0210 14:02:52.349255 22542570456896 run_lib.py:146] step: 502200, eval_loss: 2.67181e-02
I0210 14:03:10.035214 22542570456896 run_lib.py:133] step: 502250, training_loss: 3.57245e-02
I0210 14:03:27.480305 22542570456896 run_lib.py:133] step: 502300, training_loss: 2.32750e-02
I0210 14:03:27.636394 22542570456896 run_lib.py:146] step: 502300, eval_loss: 2.60538e-02
I0210 14:03:45.081597 22542570456896 run_lib.py:133] step: 502350, training_loss: 2.31115e-02
I0210 14:04:02.628506 22542570456896 run_lib.py:133] step: 502400, training_loss: 2.34110e-02
I0210 14:04:02.792630 22542570456896 run_lib.py:146] step: 502400, eval_loss: 2.45997e-02
I0210 14:04:20.229659 22542570456896 run_lib.py:133] step: 502450, training_loss: 3.08126e-02
I0210 14:04:37.767066 22542570456896 run_lib.py:133] step: 502500, training_loss: 1.95232e-02
I0210 14:04:37.926334 22542570456896 run_lib.py:146] step: 502500, eval_loss: 3.42390e-02
I0210 14:04:55.558977 22542570456896 run_lib.py:133] step: 502550, training_loss: 2.67772e-02
I0210 14:05:12.992538 22542570456896 run_lib.py:133] step: 502600, training_loss: 2.72664e-02
I0210 14:05:13.147268 22542570456896 run_lib.py:146] step: 502600, eval_loss: 3.21282e-02
I0210 14:05:30.714335 22542570456896 run_lib.py:133] step: 502650, training_loss: 2.74630e-02
I0210 14:05:48.158843 22542570456896 run_lib.py:133] step: 502700, training_loss: 2.19039e-02
I0210 14:05:48.312616 22542570456896 run_lib.py:146] step: 502700, eval_loss: 2.53151e-02
I0210 14:06:05.838215 22542570456896 run_lib.py:133] step: 502750, training_loss: 2.79638e-02
I0210 14:06:23.490120 22542570456896 run_lib.py:133] step: 502800, training_loss: 2.72522e-02
I0210 14:06:23.644817 22542570456896 run_lib.py:146] step: 502800, eval_loss: 3.06330e-02
I0210 14:06:41.113305 22542570456896 run_lib.py:133] step: 502850, training_loss: 2.31971e-02
I0210 14:06:58.512270 22542570456896 run_lib.py:133] step: 502900, training_loss: 2.87991e-02
I0210 14:06:58.678206 22542570456896 run_lib.py:146] step: 502900, eval_loss: 3.03550e-02
I0210 14:07:16.052206 22542570456896 run_lib.py:133] step: 502950, training_loss: 2.75692e-02
I0210 14:07:33.620157 22542570456896 run_lib.py:133] step: 503000, training_loss: 2.55659e-02
I0210 14:07:33.775014 22542570456896 run_lib.py:146] step: 503000, eval_loss: 2.11942e-02
I0210 14:07:51.178272 22542570456896 run_lib.py:133] step: 503050, training_loss: 2.90075e-02
I0210 14:08:08.761415 22542570456896 run_lib.py:133] step: 503100, training_loss: 2.67110e-02
I0210 14:08:08.916289 22542570456896 run_lib.py:146] step: 503100, eval_loss: 2.97871e-02
I0210 14:08:26.274532 22542570456896 run_lib.py:133] step: 503150, training_loss: 2.38673e-02
I0210 14:08:43.667740 22542570456896 run_lib.py:133] step: 503200, training_loss: 2.66432e-02
I0210 14:08:43.818856 22542570456896 run_lib.py:146] step: 503200, eval_loss: 3.04145e-02
I0210 14:09:01.340080 22542570456896 run_lib.py:133] step: 503250, training_loss: 2.34866e-02
I0210 14:09:18.901729 22542570456896 run_lib.py:133] step: 503300, training_loss: 3.06406e-02
I0210 14:09:19.079590 22542570456896 run_lib.py:146] step: 503300, eval_loss: 3.92286e-02
I0210 14:09:36.512213 22542570456896 run_lib.py:133] step: 503350, training_loss: 2.99813e-02
I0210 14:09:53.985253 22542570456896 run_lib.py:133] step: 503400, training_loss: 2.85954e-02
I0210 14:09:54.147332 22542570456896 run_lib.py:146] step: 503400, eval_loss: 2.81114e-02
I0210 14:10:11.735692 22542570456896 run_lib.py:133] step: 503450, training_loss: 2.73266e-02
I0210 14:10:29.143344 22542570456896 run_lib.py:133] step: 503500, training_loss: 2.69595e-02
I0210 14:10:29.297421 22542570456896 run_lib.py:146] step: 503500, eval_loss: 3.10756e-02
I0210 14:10:46.817963 22542570456896 run_lib.py:133] step: 503550, training_loss: 2.47120e-02
I0210 14:11:04.287800 22542570456896 run_lib.py:133] step: 503600, training_loss: 3.00198e-02
I0210 14:11:04.448103 22542570456896 run_lib.py:146] step: 503600, eval_loss: 3.04879e-02
I0210 14:11:22.039443 22542570456896 run_lib.py:133] step: 503650, training_loss: 2.62079e-02
I0210 14:11:39.412568 22542570456896 run_lib.py:133] step: 503700, training_loss: 2.91110e-02
I0210 14:11:39.563341 22542570456896 run_lib.py:146] step: 503700, eval_loss: 3.65623e-02
I0210 14:11:56.958258 22542570456896 run_lib.py:133] step: 503750, training_loss: 2.31716e-02
I0210 14:12:14.562438 22542570456896 run_lib.py:133] step: 503800, training_loss: 3.38283e-02
I0210 14:12:14.721518 22542570456896 run_lib.py:146] step: 503800, eval_loss: 2.45448e-02
I0210 14:12:32.159738 22542570456896 run_lib.py:133] step: 503850, training_loss: 2.41997e-02
I0210 14:12:49.797048 22542570456896 run_lib.py:133] step: 503900, training_loss: 3.19381e-02
I0210 14:12:49.954511 22542570456896 run_lib.py:146] step: 503900, eval_loss: 2.58790e-02
I0210 14:13:07.345573 22542570456896 run_lib.py:133] step: 503950, training_loss: 3.11458e-02
I0210 14:13:24.750775 22542570456896 run_lib.py:133] step: 504000, training_loss: 2.77986e-02
I0210 14:13:24.911599 22542570456896 run_lib.py:146] step: 504000, eval_loss: 3.02053e-02
I0210 14:13:42.550284 22542570456896 run_lib.py:133] step: 504050, training_loss: 3.21798e-02
I0210 14:13:59.939306 22542570456896 run_lib.py:133] step: 504100, training_loss: 2.46436e-02
I0210 14:14:00.091400 22542570456896 run_lib.py:146] step: 504100, eval_loss: 2.72696e-02
I0210 14:14:17.509616 22542570456896 run_lib.py:133] step: 504150, training_loss: 2.68204e-02
I0210 14:14:35.053884 22542570456896 run_lib.py:133] step: 504200, training_loss: 2.85938e-02
I0210 14:14:35.222545 22542570456896 run_lib.py:146] step: 504200, eval_loss: 2.23695e-02
I0210 14:14:52.673105 22542570456896 run_lib.py:133] step: 504250, training_loss: 2.78528e-02
I0210 14:15:10.144946 22542570456896 run_lib.py:133] step: 504300, training_loss: 3.17734e-02
I0210 14:15:10.490255 22542570456896 run_lib.py:146] step: 504300, eval_loss: 2.56296e-02
I0210 14:15:27.920655 22542570456896 run_lib.py:133] step: 504350, training_loss: 2.81175e-02
I0210 14:15:45.349887 22542570456896 run_lib.py:133] step: 504400, training_loss: 2.27132e-02
I0210 14:15:45.511378 22542570456896 run_lib.py:146] step: 504400, eval_loss: 2.93127e-02
I0210 14:16:02.961575 22542570456896 run_lib.py:133] step: 504450, training_loss: 3.10432e-02
I0210 14:16:20.463403 22542570456896 run_lib.py:133] step: 504500, training_loss: 3.20766e-02
I0210 14:16:20.625557 22542570456896 run_lib.py:146] step: 504500, eval_loss: 3.15892e-02
I0210 14:16:38.280525 22542570456896 run_lib.py:133] step: 504550, training_loss: 2.53389e-02
I0210 14:16:55.745554 22542570456896 run_lib.py:133] step: 504600, training_loss: 2.38960e-02
I0210 14:16:55.899089 22542570456896 run_lib.py:146] step: 504600, eval_loss: 2.70316e-02
I0210 14:17:13.335272 22542570456896 run_lib.py:133] step: 504650, training_loss: 2.81439e-02
I0210 14:17:30.765618 22542570456896 run_lib.py:133] step: 504700, training_loss: 2.81983e-02
I0210 14:17:30.927205 22542570456896 run_lib.py:146] step: 504700, eval_loss: 3.12714e-02
I0210 14:17:48.532773 22542570456896 run_lib.py:133] step: 504750, training_loss: 3.06380e-02
I0210 14:18:06.139987 22542570456896 run_lib.py:133] step: 504800, training_loss: 2.39541e-02
I0210 14:18:06.299706 22542570456896 run_lib.py:146] step: 504800, eval_loss: 2.86230e-02
I0210 14:18:23.738435 22542570456896 run_lib.py:133] step: 504850, training_loss: 2.72933e-02
I0210 14:18:41.180049 22542570456896 run_lib.py:133] step: 504900, training_loss: 2.56399e-02
I0210 14:18:41.336215 22542570456896 run_lib.py:146] step: 504900, eval_loss: 2.23825e-02
I0210 14:18:58.913933 22542570456896 run_lib.py:133] step: 504950, training_loss: 2.43515e-02
I0210 14:19:16.347275 22542570456896 run_lib.py:133] step: 505000, training_loss: 2.86778e-02
I0210 14:19:16.503560 22542570456896 run_lib.py:146] step: 505000, eval_loss: 2.31452e-02
I0210 14:19:34.134243 22542570456896 run_lib.py:133] step: 505050, training_loss: 2.91341e-02
I0210 14:19:51.593605 22542570456896 run_lib.py:133] step: 505100, training_loss: 2.52175e-02
I0210 14:19:51.746634 22542570456896 run_lib.py:146] step: 505100, eval_loss: 3.00848e-02
I0210 14:20:09.302454 22542570456896 run_lib.py:133] step: 505150, training_loss: 3.33716e-02
I0210 14:20:26.678287 22542570456896 run_lib.py:133] step: 505200, training_loss: 2.87055e-02
I0210 14:20:26.837595 22542570456896 run_lib.py:146] step: 505200, eval_loss: 2.88962e-02
I0210 14:20:44.253650 22542570456896 run_lib.py:133] step: 505250, training_loss: 2.72168e-02
I0210 14:21:01.846837 22542570456896 run_lib.py:133] step: 505300, training_loss: 3.13182e-02
I0210 14:21:02.016538 22542570456896 run_lib.py:146] step: 505300, eval_loss: 3.37104e-02
I0210 14:21:19.511309 22542570456896 run_lib.py:133] step: 505350, training_loss: 2.60707e-02
I0210 14:21:37.168912 22542570456896 run_lib.py:133] step: 505400, training_loss: 2.75733e-02
I0210 14:21:37.325287 22542570456896 run_lib.py:146] step: 505400, eval_loss: 2.62881e-02
I0210 14:21:54.796812 22542570456896 run_lib.py:133] step: 505450, training_loss: 2.80150e-02
I0210 14:22:12.215710 22542570456896 run_lib.py:133] step: 505500, training_loss: 3.34987e-02
I0210 14:22:12.368511 22542570456896 run_lib.py:146] step: 505500, eval_loss: 2.93808e-02
I0210 14:22:29.984186 22542570456896 run_lib.py:133] step: 505550, training_loss: 2.67274e-02
I0210 14:22:47.486029 22542570456896 run_lib.py:133] step: 505600, training_loss: 2.61526e-02
I0210 14:22:47.651803 22542570456896 run_lib.py:146] step: 505600, eval_loss: 2.84549e-02
I0210 14:23:05.137885 22542570456896 run_lib.py:133] step: 505650, training_loss: 3.08974e-02
I0210 14:23:22.596600 22542570456896 run_lib.py:133] step: 505700, training_loss: 2.69757e-02
I0210 14:23:22.756326 22542570456896 run_lib.py:146] step: 505700, eval_loss: 2.71867e-02
I0210 14:23:40.387113 22542570456896 run_lib.py:133] step: 505750, training_loss: 3.09228e-02
I0210 14:23:57.826813 22542570456896 run_lib.py:133] step: 505800, training_loss: 2.05821e-02
I0210 14:23:57.982064 22542570456896 run_lib.py:146] step: 505800, eval_loss: 2.39523e-02
I0210 14:24:15.491940 22542570456896 run_lib.py:133] step: 505850, training_loss: 2.51926e-02
I0210 14:24:32.989171 22542570456896 run_lib.py:133] step: 505900, training_loss: 3.05218e-02
I0210 14:24:33.143562 22542570456896 run_lib.py:146] step: 505900, eval_loss: 3.06006e-02
I0210 14:24:50.621955 22542570456896 run_lib.py:133] step: 505950, training_loss: 2.60576e-02
I0210 14:25:08.091325 22542570456896 run_lib.py:133] step: 506000, training_loss: 3.03664e-02
I0210 14:25:08.248427 22542570456896 run_lib.py:146] step: 506000, eval_loss: 2.89696e-02
I0210 14:25:25.898119 22542570456896 run_lib.py:133] step: 506050, training_loss: 2.78492e-02
I0210 14:25:43.423600 22542570456896 run_lib.py:133] step: 506100, training_loss: 3.31676e-02
I0210 14:25:43.592571 22542570456896 run_lib.py:146] step: 506100, eval_loss: 3.14751e-02
I0210 14:26:01.071457 22542570456896 run_lib.py:133] step: 506150, training_loss: 2.86333e-02
I0210 14:26:18.575445 22542570456896 run_lib.py:133] step: 506200, training_loss: 2.54032e-02
I0210 14:26:18.731806 22542570456896 run_lib.py:146] step: 506200, eval_loss: 2.54220e-02
I0210 14:26:36.336770 22542570456896 run_lib.py:133] step: 506250, training_loss: 2.41189e-02
I0210 14:26:53.771117 22542570456896 run_lib.py:133] step: 506300, training_loss: 2.60399e-02
I0210 14:26:53.927439 22542570456896 run_lib.py:146] step: 506300, eval_loss: 3.22298e-02
I0210 14:27:11.533057 22542570456896 run_lib.py:133] step: 506350, training_loss: 3.07683e-02
I0210 14:27:28.969081 22542570456896 run_lib.py:133] step: 506400, training_loss: 3.23004e-02
I0210 14:27:29.127243 22542570456896 run_lib.py:146] step: 506400, eval_loss: 3.14649e-02
I0210 14:27:46.781746 22542570456896 run_lib.py:133] step: 506450, training_loss: 3.60656e-02
I0210 14:28:04.262409 22542570456896 run_lib.py:133] step: 506500, training_loss: 2.81837e-02
I0210 14:28:04.423614 22542570456896 run_lib.py:146] step: 506500, eval_loss: 2.44243e-02
I0210 14:28:22.143610 22542570456896 run_lib.py:133] step: 506550, training_loss: 2.52563e-02
I0210 14:28:39.609907 22542570456896 run_lib.py:133] step: 506600, training_loss: 2.31975e-02
I0210 14:28:39.774398 22542570456896 run_lib.py:146] step: 506600, eval_loss: 3.31374e-02
I0210 14:28:57.182147 22542570456896 run_lib.py:133] step: 506650, training_loss: 3.01669e-02
I0210 14:29:14.741322 22542570456896 run_lib.py:133] step: 506700, training_loss: 2.95314e-02
I0210 14:29:14.918487 22542570456896 run_lib.py:146] step: 506700, eval_loss: 2.61140e-02
I0210 14:29:32.398712 22542570456896 run_lib.py:133] step: 506750, training_loss: 2.54149e-02
I0210 14:29:49.861014 22542570456896 run_lib.py:133] step: 506800, training_loss: 2.71419e-02
I0210 14:29:50.017241 22542570456896 run_lib.py:146] step: 506800, eval_loss: 3.06903e-02
I0210 14:30:07.658950 22542570456896 run_lib.py:133] step: 506850, training_loss: 3.31997e-02
I0210 14:30:25.237110 22542570456896 run_lib.py:133] step: 506900, training_loss: 2.96631e-02
I0210 14:30:25.391453 22542570456896 run_lib.py:146] step: 506900, eval_loss: 2.61408e-02
I0210 14:30:42.827052 22542570456896 run_lib.py:133] step: 506950, training_loss: 2.24613e-02
I0210 14:31:00.319574 22542570456896 run_lib.py:133] step: 507000, training_loss: 2.48383e-02
I0210 14:31:00.476814 22542570456896 run_lib.py:146] step: 507000, eval_loss: 3.12714e-02
I0210 14:31:17.952205 22542570456896 run_lib.py:133] step: 507050, training_loss: 3.06286e-02
I0210 14:31:35.635984 22542570456896 run_lib.py:133] step: 507100, training_loss: 2.80190e-02
I0210 14:31:35.794564 22542570456896 run_lib.py:146] step: 507100, eval_loss: 2.64294e-02
I0210 14:31:53.224313 22542570456896 run_lib.py:133] step: 507150, training_loss: 2.31719e-02
I0210 14:32:10.650682 22542570456896 run_lib.py:133] step: 507200, training_loss: 2.87310e-02
I0210 14:32:10.809271 22542570456896 run_lib.py:146] step: 507200, eval_loss: 2.74170e-02
I0210 14:32:28.251891 22542570456896 run_lib.py:133] step: 507250, training_loss: 2.70152e-02
I0210 14:32:45.969797 22542570456896 run_lib.py:133] step: 507300, training_loss: 2.90332e-02
I0210 14:32:46.125191 22542570456896 run_lib.py:146] step: 507300, eval_loss: 2.53907e-02
I0210 14:33:03.555850 22542570456896 run_lib.py:133] step: 507350, training_loss: 2.97266e-02
I0210 14:33:21.082991 22542570456896 run_lib.py:133] step: 507400, training_loss: 2.88963e-02
I0210 14:33:21.236149 22542570456896 run_lib.py:146] step: 507400, eval_loss: 2.58141e-02
I0210 14:33:38.657316 22542570456896 run_lib.py:133] step: 507450, training_loss: 2.28163e-02
I0210 14:33:56.090464 22542570456896 run_lib.py:133] step: 507500, training_loss: 2.90130e-02
I0210 14:33:56.248380 22542570456896 run_lib.py:146] step: 507500, eval_loss: 3.22050e-02
I0210 14:34:13.797125 22542570456896 run_lib.py:133] step: 507550, training_loss: 2.77799e-02
I0210 14:34:31.391887 22542570456896 run_lib.py:133] step: 507600, training_loss: 2.52696e-02
I0210 14:34:31.558310 22542570456896 run_lib.py:146] step: 507600, eval_loss: 2.80017e-02
I0210 14:34:48.986869 22542570456896 run_lib.py:133] step: 507650, training_loss: 2.67384e-02
I0210 14:35:06.433555 22542570456896 run_lib.py:133] step: 507700, training_loss: 3.50261e-02
I0210 14:35:06.598637 22542570456896 run_lib.py:146] step: 507700, eval_loss: 2.37704e-02
I0210 14:35:24.206999 22542570456896 run_lib.py:133] step: 507750, training_loss: 2.92595e-02
I0210 14:35:41.687389 22542570456896 run_lib.py:133] step: 507800, training_loss: 2.93584e-02
I0210 14:35:41.842243 22542570456896 run_lib.py:146] step: 507800, eval_loss: 2.62185e-02
I0210 14:35:59.428072 22542570456896 run_lib.py:133] step: 507850, training_loss: 3.44289e-02
I0210 14:36:16.956542 22542570456896 run_lib.py:133] step: 507900, training_loss: 2.86670e-02
I0210 14:36:17.110273 22542570456896 run_lib.py:146] step: 507900, eval_loss: 2.84241e-02
I0210 14:36:34.734964 22542570456896 run_lib.py:133] step: 507950, training_loss: 2.77775e-02
I0210 14:36:52.175218 22542570456896 run_lib.py:133] step: 508000, training_loss: 3.27660e-02
I0210 14:36:52.331390 22542570456896 run_lib.py:146] step: 508000, eval_loss: 2.26761e-02
I0210 14:37:09.730196 22542570456896 run_lib.py:133] step: 508050, training_loss: 2.75422e-02
I0210 14:37:27.307153 22542570456896 run_lib.py:133] step: 508100, training_loss: 3.29715e-02
I0210 14:37:27.465671 22542570456896 run_lib.py:146] step: 508100, eval_loss: 3.27095e-02
I0210 14:37:44.931574 22542570456896 run_lib.py:133] step: 508150, training_loss: 2.19382e-02
I0210 14:38:02.612590 22542570456896 run_lib.py:133] step: 508200, training_loss: 3.69295e-02
I0210 14:38:02.769686 22542570456896 run_lib.py:146] step: 508200, eval_loss: 2.63656e-02
I0210 14:38:20.219780 22542570456896 run_lib.py:133] step: 508250, training_loss: 2.54707e-02
I0210 14:38:37.676594 22542570456896 run_lib.py:133] step: 508300, training_loss: 2.96592e-02
I0210 14:38:37.835398 22542570456896 run_lib.py:146] step: 508300, eval_loss: 2.97574e-02
I0210 14:38:55.465749 22542570456896 run_lib.py:133] step: 508350, training_loss: 3.26644e-02
I0210 14:39:12.937107 22542570456896 run_lib.py:133] step: 508400, training_loss: 2.59234e-02
I0210 14:39:13.097378 22542570456896 run_lib.py:146] step: 508400, eval_loss: 3.39571e-02
I0210 14:39:30.579345 22542570456896 run_lib.py:133] step: 508450, training_loss: 3.18877e-02
I0210 14:39:48.231217 22542570456896 run_lib.py:133] step: 508500, training_loss: 2.69303e-02
I0210 14:39:48.382656 22542570456896 run_lib.py:146] step: 508500, eval_loss: 2.60470e-02
I0210 14:40:05.828722 22542570456896 run_lib.py:133] step: 508550, training_loss: 2.95507e-02
I0210 14:40:23.259186 22542570456896 run_lib.py:133] step: 508600, training_loss: 2.77155e-02
I0210 14:40:23.413686 22542570456896 run_lib.py:146] step: 508600, eval_loss: 2.70324e-02
I0210 14:40:40.917462 22542570456896 run_lib.py:133] step: 508650, training_loss: 2.71537e-02
I0210 14:40:58.434557 22542570456896 run_lib.py:133] step: 508700, training_loss: 2.80119e-02
I0210 14:40:58.602543 22542570456896 run_lib.py:146] step: 508700, eval_loss: 2.93251e-02
I0210 14:41:16.073508 22542570456896 run_lib.py:133] step: 508750, training_loss: 3.22804e-02
I0210 14:41:33.550100 22542570456896 run_lib.py:133] step: 508800, training_loss: 2.25499e-02
I0210 14:41:33.708679 22542570456896 run_lib.py:146] step: 508800, eval_loss: 2.47389e-02
I0210 14:41:51.323476 22542570456896 run_lib.py:133] step: 508850, training_loss: 2.13945e-02
I0210 14:42:08.808066 22542570456896 run_lib.py:133] step: 508900, training_loss: 2.77848e-02
I0210 14:42:08.961388 22542570456896 run_lib.py:146] step: 508900, eval_loss: 2.56317e-02
I0210 14:42:26.398857 22542570456896 run_lib.py:133] step: 508950, training_loss: 2.66183e-02
I0210 14:42:43.805651 22542570456896 run_lib.py:133] step: 509000, training_loss: 2.64323e-02
I0210 14:42:43.982274 22542570456896 run_lib.py:146] step: 509000, eval_loss: 2.40158e-02
I0210 14:43:01.575739 22542570456896 run_lib.py:133] step: 509050, training_loss: 2.51469e-02
I0210 14:43:18.975825 22542570456896 run_lib.py:133] step: 509100, training_loss: 2.12182e-02
I0210 14:43:19.131869 22542570456896 run_lib.py:146] step: 509100, eval_loss: 2.66693e-02
I0210 14:43:36.729290 22542570456896 run_lib.py:133] step: 509150, training_loss: 1.98763e-02
I0210 14:43:54.161935 22542570456896 run_lib.py:133] step: 509200, training_loss: 2.51740e-02
I0210 14:43:54.324420 22542570456896 run_lib.py:146] step: 509200, eval_loss: 2.10280e-02
I0210 14:44:11.880546 22542570456896 run_lib.py:133] step: 509250, training_loss: 2.04134e-02
I0210 14:44:29.314979 22542570456896 run_lib.py:133] step: 509300, training_loss: 2.20083e-02
I0210 14:44:29.471639 22542570456896 run_lib.py:146] step: 509300, eval_loss: 2.92654e-02
I0210 14:44:47.164786 22542570456896 run_lib.py:133] step: 509350, training_loss: 3.15618e-02
I0210 14:45:04.636466 22542570456896 run_lib.py:133] step: 509400, training_loss: 3.57314e-02
I0210 14:45:04.793456 22542570456896 run_lib.py:146] step: 509400, eval_loss: 2.38987e-02
I0210 14:45:22.229921 22542570456896 run_lib.py:133] step: 509450, training_loss: 2.79392e-02
I0210 14:45:39.821939 22542570456896 run_lib.py:133] step: 509500, training_loss: 2.64434e-02
I0210 14:45:39.979583 22542570456896 run_lib.py:146] step: 509500, eval_loss: 3.14703e-02
I0210 14:45:57.431699 22542570456896 run_lib.py:133] step: 509550, training_loss: 1.99147e-02
I0210 14:46:14.938378 22542570456896 run_lib.py:133] step: 509600, training_loss: 2.76163e-02
I0210 14:46:15.096630 22542570456896 run_lib.py:146] step: 509600, eval_loss: 2.51466e-02
I0210 14:46:32.714753 22542570456896 run_lib.py:133] step: 509650, training_loss: 2.51073e-02
I0210 14:46:50.177012 22542570456896 run_lib.py:133] step: 509700, training_loss: 2.84153e-02
I0210 14:46:50.332401 22542570456896 run_lib.py:146] step: 509700, eval_loss: 3.01255e-02
I0210 14:47:07.964144 22542570456896 run_lib.py:133] step: 509750, training_loss: 2.68729e-02
I0210 14:47:25.365775 22542570456896 run_lib.py:133] step: 509800, training_loss: 2.07194e-02
I0210 14:47:25.517268 22542570456896 run_lib.py:146] step: 509800, eval_loss: 2.46433e-02
I0210 14:47:42.970818 22542570456896 run_lib.py:133] step: 509850, training_loss: 2.81837e-02
I0210 14:48:00.590466 22542570456896 run_lib.py:133] step: 509900, training_loss: 2.65362e-02
I0210 14:48:00.752576 22542570456896 run_lib.py:146] step: 509900, eval_loss: 2.97204e-02
I0210 14:48:18.170262 22542570456896 run_lib.py:133] step: 509950, training_loss: 2.61922e-02
I0210 14:48:35.598235 22542570456896 run_lib.py:133] step: 510000, training_loss: 3.53404e-02
I0210 14:48:36.367528 22542570456896 run_lib.py:146] step: 510000, eval_loss: 3.25075e-02
I0210 14:48:56.481757 22542570456896 run_lib.py:133] step: 510050, training_loss: 2.97731e-02
I0210 14:49:13.852679 22542570456896 run_lib.py:133] step: 510100, training_loss: 3.09918e-02
I0210 14:49:14.027338 22542570456896 run_lib.py:146] step: 510100, eval_loss: 2.73600e-02
I0210 14:49:31.623347 22542570456896 run_lib.py:133] step: 510150, training_loss: 2.84639e-02
I0210 14:49:49.042963 22542570456896 run_lib.py:133] step: 510200, training_loss: 2.48856e-02
I0210 14:49:49.197113 22542570456896 run_lib.py:146] step: 510200, eval_loss: 2.79542e-02
I0210 14:50:06.720350 22542570456896 run_lib.py:133] step: 510250, training_loss: 2.03826e-02
I0210 14:50:24.169452 22542570456896 run_lib.py:133] step: 510300, training_loss: 2.15730e-02
I0210 14:50:24.322665 22542570456896 run_lib.py:146] step: 510300, eval_loss: 2.90731e-02
I0210 14:50:41.720420 22542570456896 run_lib.py:133] step: 510350, training_loss: 2.98998e-02
I0210 14:50:59.164295 22542570456896 run_lib.py:133] step: 510400, training_loss: 2.59372e-02
I0210 14:50:59.320692 22542570456896 run_lib.py:146] step: 510400, eval_loss: 3.56649e-02
I0210 14:51:16.987276 22542570456896 run_lib.py:133] step: 510450, training_loss: 3.14576e-02
I0210 14:51:34.560430 22542570456896 run_lib.py:133] step: 510500, training_loss: 2.84659e-02
I0210 14:51:34.719323 22542570456896 run_lib.py:146] step: 510500, eval_loss: 3.04571e-02
I0210 14:51:52.185728 22542570456896 run_lib.py:133] step: 510550, training_loss: 2.84722e-02
I0210 14:52:09.636216 22542570456896 run_lib.py:133] step: 510600, training_loss: 2.55798e-02
I0210 14:52:09.798381 22542570456896 run_lib.py:146] step: 510600, eval_loss: 3.24732e-02
I0210 14:52:27.379216 22542570456896 run_lib.py:133] step: 510650, training_loss: 2.47901e-02
I0210 14:52:44.878933 22542570456896 run_lib.py:133] step: 510700, training_loss: 3.44440e-02
I0210 14:52:45.037289 22542570456896 run_lib.py:146] step: 510700, eval_loss: 3.15847e-02
I0210 14:53:02.678960 22542570456896 run_lib.py:133] step: 510750, training_loss: 2.68396e-02
I0210 14:53:20.117658 22542570456896 run_lib.py:133] step: 510800, training_loss: 2.54382e-02
I0210 14:53:20.269659 22542570456896 run_lib.py:146] step: 510800, eval_loss: 2.98747e-02
I0210 14:53:37.852972 22542570456896 run_lib.py:133] step: 510850, training_loss: 3.07351e-02
I0210 14:53:55.283112 22542570456896 run_lib.py:133] step: 510900, training_loss: 2.91393e-02
I0210 14:53:55.454765 22542570456896 run_lib.py:146] step: 510900, eval_loss: 2.58819e-02
I0210 14:54:13.093322 22542570456896 run_lib.py:133] step: 510950, training_loss: 3.10211e-02
I0210 14:54:30.578703 22542570456896 run_lib.py:133] step: 511000, training_loss: 3.08836e-02
I0210 14:54:30.738193 22542570456896 run_lib.py:146] step: 511000, eval_loss: 2.81725e-02
I0210 14:54:48.179394 22542570456896 run_lib.py:133] step: 511050, training_loss: 3.11838e-02
I0210 14:55:05.783758 22542570456896 run_lib.py:133] step: 511100, training_loss: 2.62047e-02
I0210 14:55:05.940501 22542570456896 run_lib.py:146] step: 511100, eval_loss: 2.81396e-02
I0210 14:55:23.355758 22542570456896 run_lib.py:133] step: 511150, training_loss: 2.93756e-02
I0210 14:55:40.816054 22542570456896 run_lib.py:133] step: 511200, training_loss: 3.10985e-02
I0210 14:55:40.972372 22542570456896 run_lib.py:146] step: 511200, eval_loss: 2.40922e-02
I0210 14:55:58.620376 22542570456896 run_lib.py:133] step: 511250, training_loss: 2.69888e-02
I0210 14:56:16.269101 22542570456896 run_lib.py:133] step: 511300, training_loss: 2.32497e-02
I0210 14:56:16.420480 22542570456896 run_lib.py:146] step: 511300, eval_loss: 2.79362e-02
I0210 14:56:33.852213 22542570456896 run_lib.py:133] step: 511350, training_loss: 2.21354e-02
I0210 14:56:51.313697 22542570456896 run_lib.py:133] step: 511400, training_loss: 2.97218e-02
I0210 14:56:51.471484 22542570456896 run_lib.py:146] step: 511400, eval_loss: 3.58631e-02
I0210 14:57:08.900989 22542570456896 run_lib.py:133] step: 511450, training_loss: 2.69430e-02
I0210 14:57:26.474588 22542570456896 run_lib.py:133] step: 511500, training_loss: 3.52708e-02
I0210 14:57:26.650381 22542570456896 run_lib.py:146] step: 511500, eval_loss: 2.96230e-02
I0210 14:57:44.157125 22542570456896 run_lib.py:133] step: 511550, training_loss: 2.33265e-02
I0210 14:58:01.582070 22542570456896 run_lib.py:133] step: 511600, training_loss: 2.92918e-02
I0210 14:58:01.738671 22542570456896 run_lib.py:146] step: 511600, eval_loss: 3.18759e-02
I0210 14:58:19.185077 22542570456896 run_lib.py:133] step: 511650, training_loss: 2.60445e-02
I0210 14:58:36.788186 22542570456896 run_lib.py:133] step: 511700, training_loss: 3.34988e-02
I0210 14:58:36.941715 22542570456896 run_lib.py:146] step: 511700, eval_loss: 2.96418e-02
I0210 14:58:54.366059 22542570456896 run_lib.py:133] step: 511750, training_loss: 2.78650e-02
I0210 14:59:11.898544 22542570456896 run_lib.py:133] step: 511800, training_loss: 2.57773e-02
I0210 14:59:12.055773 22542570456896 run_lib.py:146] step: 511800, eval_loss: 2.80712e-02
I0210 14:59:29.576928 22542570456896 run_lib.py:133] step: 511850, training_loss: 2.66697e-02
I0210 14:59:47.057595 22542570456896 run_lib.py:133] step: 511900, training_loss: 3.43959e-02
I0210 14:59:47.217684 22542570456896 run_lib.py:146] step: 511900, eval_loss: 2.64053e-02
I0210 15:00:04.816876 22542570456896 run_lib.py:133] step: 511950, training_loss: 3.25156e-02
I0210 15:00:22.299216 22542570456896 run_lib.py:133] step: 512000, training_loss: 3.14783e-02
I0210 15:00:22.455672 22542570456896 run_lib.py:146] step: 512000, eval_loss: 2.74536e-02
I0210 15:00:39.909589 22542570456896 run_lib.py:133] step: 512050, training_loss: 2.19763e-02
I0210 15:00:57.360086 22542570456896 run_lib.py:133] step: 512100, training_loss: 2.30363e-02
I0210 15:00:57.524186 22542570456896 run_lib.py:146] step: 512100, eval_loss: 2.72782e-02
I0210 15:01:15.214461 22542570456896 run_lib.py:133] step: 512150, training_loss: 2.99174e-02
I0210 15:01:32.705125 22542570456896 run_lib.py:133] step: 512200, training_loss: 2.90056e-02
I0210 15:01:32.858128 22542570456896 run_lib.py:146] step: 512200, eval_loss: 2.58051e-02
I0210 15:01:50.493439 22542570456896 run_lib.py:133] step: 512250, training_loss: 2.43170e-02
I0210 15:02:07.950124 22542570456896 run_lib.py:133] step: 512300, training_loss: 2.56306e-02
I0210 15:02:08.104466 22542570456896 run_lib.py:146] step: 512300, eval_loss: 3.10101e-02
I0210 15:02:25.696726 22542570456896 run_lib.py:133] step: 512350, training_loss: 3.87923e-02
I0210 15:02:43.178023 22542570456896 run_lib.py:133] step: 512400, training_loss: 2.75436e-02
I0210 15:02:43.352437 22542570456896 run_lib.py:146] step: 512400, eval_loss: 2.96400e-02
I0210 15:03:00.851677 22542570456896 run_lib.py:133] step: 512450, training_loss: 2.69233e-02
I0210 15:03:18.577980 22542570456896 run_lib.py:133] step: 512500, training_loss: 2.81187e-02
I0210 15:03:18.734642 22542570456896 run_lib.py:146] step: 512500, eval_loss: 2.89918e-02
I0210 15:03:36.188017 22542570456896 run_lib.py:133] step: 512550, training_loss: 2.51433e-02
I0210 15:03:53.766669 22542570456896 run_lib.py:133] step: 512600, training_loss: 2.62853e-02
I0210 15:03:53.930576 22542570456896 run_lib.py:146] step: 512600, eval_loss: 3.38318e-02
I0210 15:04:11.387768 22542570456896 run_lib.py:133] step: 512650, training_loss: 2.92615e-02
I0210 15:04:28.908822 22542570456896 run_lib.py:133] step: 512700, training_loss: 2.84751e-02
I0210 15:04:29.062569 22542570456896 run_lib.py:146] step: 512700, eval_loss: 2.54651e-02
I0210 15:04:46.721298 22542570456896 run_lib.py:133] step: 512750, training_loss: 1.91686e-02
I0210 15:05:04.177061 22542570456896 run_lib.py:133] step: 512800, training_loss: 2.79180e-02
I0210 15:05:04.333615 22542570456896 run_lib.py:146] step: 512800, eval_loss: 2.72106e-02
I0210 15:05:21.758184 22542570456896 run_lib.py:133] step: 512850, training_loss: 2.35731e-02
I0210 15:05:39.383291 22542570456896 run_lib.py:133] step: 512900, training_loss: 2.77589e-02
I0210 15:05:39.541235 22542570456896 run_lib.py:146] step: 512900, eval_loss: 2.51725e-02
I0210 15:05:57.024077 22542570456896 run_lib.py:133] step: 512950, training_loss: 2.88295e-02
I0210 15:06:14.537072 22542570456896 run_lib.py:133] step: 513000, training_loss: 2.63157e-02
I0210 15:06:14.693828 22542570456896 run_lib.py:146] step: 513000, eval_loss: 2.85069e-02
I0210 15:06:32.262777 22542570456896 run_lib.py:133] step: 513050, training_loss: 2.62856e-02
I0210 15:06:49.693544 22542570456896 run_lib.py:133] step: 513100, training_loss: 2.88514e-02
I0210 15:06:49.849496 22542570456896 run_lib.py:146] step: 513100, eval_loss: 2.70744e-02
I0210 15:07:07.271143 22542570456896 run_lib.py:133] step: 513150, training_loss: 2.91856e-02
I0210 15:07:24.750040 22542570456896 run_lib.py:133] step: 513200, training_loss: 2.61718e-02
I0210 15:07:24.911750 22542570456896 run_lib.py:146] step: 513200, eval_loss: 2.85880e-02
I0210 15:07:42.615421 22542570456896 run_lib.py:133] step: 513250, training_loss: 2.57775e-02
I0210 15:08:00.133763 22542570456896 run_lib.py:133] step: 513300, training_loss: 3.01808e-02
I0210 15:08:00.516187 22542570456896 run_lib.py:146] step: 513300, eval_loss: 3.22861e-02
I0210 15:08:17.896878 22542570456896 run_lib.py:133] step: 513350, training_loss: 2.99996e-02
I0210 15:08:35.320180 22542570456896 run_lib.py:133] step: 513400, training_loss: 2.70277e-02
I0210 15:08:35.478642 22542570456896 run_lib.py:146] step: 513400, eval_loss: 2.75865e-02
I0210 15:08:53.136090 22542570456896 run_lib.py:133] step: 513450, training_loss: 2.95273e-02
I0210 15:09:10.620508 22542570456896 run_lib.py:133] step: 513500, training_loss: 2.61196e-02
I0210 15:09:10.777173 22542570456896 run_lib.py:146] step: 513500, eval_loss: 2.84939e-02
I0210 15:09:28.405469 22542570456896 run_lib.py:133] step: 513550, training_loss: 3.40112e-02
I0210 15:09:45.838668 22542570456896 run_lib.py:133] step: 513600, training_loss: 3.31371e-02
I0210 15:09:45.999627 22542570456896 run_lib.py:146] step: 513600, eval_loss: 2.65131e-02
I0210 15:10:03.597708 22542570456896 run_lib.py:133] step: 513650, training_loss: 2.22372e-02
I0210 15:10:21.047116 22542570456896 run_lib.py:133] step: 513700, training_loss: 2.88902e-02
I0210 15:10:21.201657 22542570456896 run_lib.py:146] step: 513700, eval_loss: 3.16296e-02
I0210 15:10:38.852846 22542570456896 run_lib.py:133] step: 513750, training_loss: 2.68411e-02
I0210 15:10:56.297243 22542570456896 run_lib.py:133] step: 513800, training_loss: 2.65157e-02
I0210 15:10:56.456330 22542570456896 run_lib.py:146] step: 513800, eval_loss: 2.65267e-02
I0210 15:11:13.898704 22542570456896 run_lib.py:133] step: 513850, training_loss: 2.47371e-02
I0210 15:11:31.509286 22542570456896 run_lib.py:133] step: 513900, training_loss: 2.67422e-02
I0210 15:11:31.662297 22542570456896 run_lib.py:146] step: 513900, eval_loss: 2.98233e-02
I0210 15:11:49.101909 22542570456896 run_lib.py:133] step: 513950, training_loss: 2.98669e-02
I0210 15:12:06.524996 22542570456896 run_lib.py:133] step: 514000, training_loss: 2.41064e-02
I0210 15:12:06.686520 22542570456896 run_lib.py:146] step: 514000, eval_loss: 3.13681e-02
I0210 15:12:24.329715 22542570456896 run_lib.py:133] step: 514050, training_loss: 2.23438e-02
I0210 15:12:41.856642 22542570456896 run_lib.py:133] step: 514100, training_loss: 2.75818e-02
I0210 15:12:42.014022 22542570456896 run_lib.py:146] step: 514100, eval_loss: 3.42651e-02
I0210 15:12:59.680352 22542570456896 run_lib.py:133] step: 514150, training_loss: 3.18914e-02
I0210 15:13:17.141320 22542570456896 run_lib.py:133] step: 514200, training_loss: 2.05469e-02
I0210 15:13:17.300975 22542570456896 run_lib.py:146] step: 514200, eval_loss: 3.18515e-02
I0210 15:13:34.737910 22542570456896 run_lib.py:133] step: 514250, training_loss: 2.28785e-02
I0210 15:13:52.334603 22542570456896 run_lib.py:133] step: 514300, training_loss: 3.37929e-02
I0210 15:13:52.512440 22542570456896 run_lib.py:146] step: 514300, eval_loss: 3.23960e-02
I0210 15:14:09.990526 22542570456896 run_lib.py:133] step: 514350, training_loss: 2.88594e-02
I0210 15:14:27.519573 22542570456896 run_lib.py:133] step: 514400, training_loss: 3.00518e-02
I0210 15:14:27.706565 22542570456896 run_lib.py:146] step: 514400, eval_loss: 2.67082e-02
I0210 15:14:45.153115 22542570456896 run_lib.py:133] step: 514450, training_loss: 3.45884e-02
I0210 15:15:02.768035 22542570456896 run_lib.py:133] step: 514500, training_loss: 2.46181e-02
I0210 15:15:02.923521 22542570456896 run_lib.py:146] step: 514500, eval_loss: 2.88683e-02
I0210 15:15:20.387191 22542570456896 run_lib.py:133] step: 514550, training_loss: 2.67134e-02
I0210 15:15:37.931642 22542570456896 run_lib.py:133] step: 514600, training_loss: 2.69960e-02
I0210 15:15:38.092182 22542570456896 run_lib.py:146] step: 514600, eval_loss: 3.21101e-02
I0210 15:15:55.625774 22542570456896 run_lib.py:133] step: 514650, training_loss: 2.10186e-02
I0210 15:16:13.075735 22542570456896 run_lib.py:133] step: 514700, training_loss: 2.91218e-02
I0210 15:16:13.232560 22542570456896 run_lib.py:146] step: 514700, eval_loss: 2.93727e-02
I0210 15:16:30.834464 22542570456896 run_lib.py:133] step: 514750, training_loss: 2.76201e-02
I0210 15:16:48.351902 22542570456896 run_lib.py:133] step: 514800, training_loss: 2.40855e-02
I0210 15:16:48.518731 22542570456896 run_lib.py:146] step: 514800, eval_loss: 2.63246e-02
I0210 15:17:06.021821 22542570456896 run_lib.py:133] step: 514850, training_loss: 2.73130e-02
I0210 15:17:23.556178 22542570456896 run_lib.py:133] step: 514900, training_loss: 3.71383e-02
I0210 15:17:23.719699 22542570456896 run_lib.py:146] step: 514900, eval_loss: 2.87796e-02
I0210 15:17:41.368817 22542570456896 run_lib.py:133] step: 514950, training_loss: 2.52731e-02
I0210 15:17:58.820179 22542570456896 run_lib.py:133] step: 515000, training_loss: 2.96580e-02
I0210 15:17:58.976410 22542570456896 run_lib.py:146] step: 515000, eval_loss: 3.11671e-02
I0210 15:18:16.579545 22542570456896 run_lib.py:133] step: 515050, training_loss: 3.01582e-02
I0210 15:18:34.039456 22542570456896 run_lib.py:133] step: 515100, training_loss: 2.43410e-02
I0210 15:18:34.191328 22542570456896 run_lib.py:146] step: 515100, eval_loss: 2.72120e-02
I0210 15:18:51.778015 22542570456896 run_lib.py:133] step: 515150, training_loss: 2.08420e-02
I0210 15:19:09.349681 22542570456896 run_lib.py:133] step: 515200, training_loss: 2.57127e-02
I0210 15:19:09.517653 22542570456896 run_lib.py:146] step: 515200, eval_loss: 3.10423e-02
I0210 15:19:26.970827 22542570456896 run_lib.py:133] step: 515250, training_loss: 2.74552e-02
I0210 15:19:44.592378 22542570456896 run_lib.py:133] step: 515300, training_loss: 2.65532e-02
I0210 15:19:44.754489 22542570456896 run_lib.py:146] step: 515300, eval_loss: 3.20097e-02
I0210 15:20:02.132347 22542570456896 run_lib.py:133] step: 515350, training_loss: 2.66770e-02
I0210 15:20:19.681694 22542570456896 run_lib.py:133] step: 515400, training_loss: 3.92484e-02
I0210 15:20:19.848084 22542570456896 run_lib.py:146] step: 515400, eval_loss: 3.16556e-02
I0210 15:20:37.292933 22542570456896 run_lib.py:133] step: 515450, training_loss: 3.38887e-02
I0210 15:20:54.724814 22542570456896 run_lib.py:133] step: 515500, training_loss: 2.54504e-02
I0210 15:20:54.879578 22542570456896 run_lib.py:146] step: 515500, eval_loss: 2.33735e-02
I0210 15:21:12.515499 22542570456896 run_lib.py:133] step: 515550, training_loss: 2.76645e-02
I0210 15:21:29.943248 22542570456896 run_lib.py:133] step: 515600, training_loss: 2.66319e-02
I0210 15:21:30.095251 22542570456896 run_lib.py:146] step: 515600, eval_loss: 2.77027e-02
I0210 15:21:47.464995 22542570456896 run_lib.py:133] step: 515650, training_loss: 2.75669e-02
I0210 15:22:05.058994 22542570456896 run_lib.py:133] step: 515700, training_loss: 3.04574e-02
I0210 15:22:05.238360 22542570456896 run_lib.py:146] step: 515700, eval_loss: 3.17377e-02
I0210 15:22:22.722293 22542570456896 run_lib.py:133] step: 515750, training_loss: 2.49961e-02
I0210 15:22:40.202299 22542570456896 run_lib.py:133] step: 515800, training_loss: 2.33463e-02
I0210 15:22:40.552933 22542570456896 run_lib.py:146] step: 515800, eval_loss: 2.36136e-02
I0210 15:22:57.992463 22542570456896 run_lib.py:133] step: 515850, training_loss: 2.70440e-02
I0210 15:23:15.426200 22542570456896 run_lib.py:133] step: 515900, training_loss: 2.76885e-02
I0210 15:23:15.582372 22542570456896 run_lib.py:146] step: 515900, eval_loss: 3.28306e-02
I0210 15:23:33.024765 22542570456896 run_lib.py:133] step: 515950, training_loss: 3.01476e-02
I0210 15:23:50.532014 22542570456896 run_lib.py:133] step: 516000, training_loss: 2.28430e-02
I0210 15:23:50.686559 22542570456896 run_lib.py:146] step: 516000, eval_loss: 2.90318e-02
I0210 15:24:08.321405 22542570456896 run_lib.py:133] step: 516050, training_loss: 3.33829e-02
I0210 15:24:25.866408 22542570456896 run_lib.py:133] step: 516100, training_loss: 2.55165e-02
I0210 15:24:26.026671 22542570456896 run_lib.py:146] step: 516100, eval_loss: 2.76611e-02
I0210 15:24:43.496066 22542570456896 run_lib.py:133] step: 516150, training_loss: 2.66447e-02
I0210 15:25:00.971208 22542570456896 run_lib.py:133] step: 516200, training_loss: 2.54823e-02
I0210 15:25:01.127562 22542570456896 run_lib.py:146] step: 516200, eval_loss: 2.38306e-02
I0210 15:25:18.713260 22542570456896 run_lib.py:133] step: 516250, training_loss: 2.66320e-02
I0210 15:25:36.247149 22542570456896 run_lib.py:133] step: 516300, training_loss: 2.26311e-02
I0210 15:25:36.403507 22542570456896 run_lib.py:146] step: 516300, eval_loss: 2.85283e-02
I0210 15:25:53.828505 22542570456896 run_lib.py:133] step: 516350, training_loss: 2.65173e-02
I0210 15:26:11.266836 22542570456896 run_lib.py:133] step: 516400, training_loss: 3.42752e-02
I0210 15:26:11.430696 22542570456896 run_lib.py:146] step: 516400, eval_loss: 1.84811e-02
I0210 15:26:29.010281 22542570456896 run_lib.py:133] step: 516450, training_loss: 2.99285e-02
I0210 15:26:46.411953 22542570456896 run_lib.py:133] step: 516500, training_loss: 2.41864e-02
I0210 15:26:46.564900 22542570456896 run_lib.py:146] step: 516500, eval_loss: 3.25418e-02
I0210 15:27:04.161635 22542570456896 run_lib.py:133] step: 516550, training_loss: 2.87627e-02
I0210 15:27:21.613256 22542570456896 run_lib.py:133] step: 516600, training_loss: 3.13893e-02
I0210 15:27:21.770716 22542570456896 run_lib.py:146] step: 516600, eval_loss: 2.64443e-02
I0210 15:27:39.342476 22542570456896 run_lib.py:133] step: 516650, training_loss: 2.61237e-02
I0210 15:27:56.753676 22542570456896 run_lib.py:133] step: 516700, training_loss: 2.44716e-02
I0210 15:27:56.925545 22542570456896 run_lib.py:146] step: 516700, eval_loss: 3.23660e-02
I0210 15:28:14.333054 22542570456896 run_lib.py:133] step: 516750, training_loss: 2.97432e-02
I0210 15:28:31.849462 22542570456896 run_lib.py:133] step: 516800, training_loss: 2.67867e-02
I0210 15:28:32.009150 22542570456896 run_lib.py:146] step: 516800, eval_loss: 2.80292e-02
I0210 15:28:49.324340 22542570456896 run_lib.py:133] step: 516850, training_loss: 2.95173e-02
I0210 15:29:06.842044 22542570456896 run_lib.py:133] step: 516900, training_loss: 2.79333e-02
I0210 15:29:06.995359 22542570456896 run_lib.py:146] step: 516900, eval_loss: 3.41810e-02
I0210 15:29:24.358814 22542570456896 run_lib.py:133] step: 516950, training_loss: 2.88378e-02
I0210 15:29:41.716088 22542570456896 run_lib.py:133] step: 517000, training_loss: 2.53930e-02
I0210 15:29:41.869542 22542570456896 run_lib.py:146] step: 517000, eval_loss: 3.29427e-02
I0210 15:29:59.411300 22542570456896 run_lib.py:133] step: 517050, training_loss: 2.57358e-02
I0210 15:30:16.831306 22542570456896 run_lib.py:133] step: 517100, training_loss: 3.37433e-02
I0210 15:30:16.995636 22542570456896 run_lib.py:146] step: 517100, eval_loss: 2.84024e-02
I0210 15:30:34.490506 22542570456896 run_lib.py:133] step: 517150, training_loss: 2.55582e-02
I0210 15:30:51.962193 22542570456896 run_lib.py:133] step: 517200, training_loss: 2.73335e-02
I0210 15:30:52.121336 22542570456896 run_lib.py:146] step: 517200, eval_loss: 3.22702e-02
I0210 15:31:09.704468 22542570456896 run_lib.py:133] step: 517250, training_loss: 2.47581e-02
I0210 15:31:27.119874 22542570456896 run_lib.py:133] step: 517300, training_loss: 1.80947e-02
I0210 15:31:27.275368 22542570456896 run_lib.py:146] step: 517300, eval_loss: 2.81095e-02
I0210 15:31:44.802555 22542570456896 run_lib.py:133] step: 517350, training_loss: 2.59772e-02
I0210 15:32:02.225074 22542570456896 run_lib.py:133] step: 517400, training_loss: 2.73251e-02
I0210 15:32:02.377326 22542570456896 run_lib.py:146] step: 517400, eval_loss: 2.73481e-02
I0210 15:32:19.840045 22542570456896 run_lib.py:133] step: 517450, training_loss: 1.81132e-02
I0210 15:32:37.235775 22542570456896 run_lib.py:133] step: 517500, training_loss: 3.09371e-02
I0210 15:32:37.387427 22542570456896 run_lib.py:146] step: 517500, eval_loss: 2.75005e-02
I0210 15:32:55.044928 22542570456896 run_lib.py:133] step: 517550, training_loss: 2.28071e-02
I0210 15:33:12.561018 22542570456896 run_lib.py:133] step: 517600, training_loss: 3.06893e-02
I0210 15:33:12.728674 22542570456896 run_lib.py:146] step: 517600, eval_loss: 3.54463e-02
I0210 15:33:30.155091 22542570456896 run_lib.py:133] step: 517650, training_loss: 3.74276e-02
I0210 15:33:47.625497 22542570456896 run_lib.py:133] step: 517700, training_loss: 3.29136e-02
I0210 15:33:47.789642 22542570456896 run_lib.py:146] step: 517700, eval_loss: 3.45445e-02
I0210 15:34:05.431546 22542570456896 run_lib.py:133] step: 517750, training_loss: 2.98416e-02
I0210 15:34:22.853577 22542570456896 run_lib.py:133] step: 517800, training_loss: 2.08060e-02
I0210 15:34:23.013205 22542570456896 run_lib.py:146] step: 517800, eval_loss: 2.76259e-02
I0210 15:34:40.583348 22542570456896 run_lib.py:133] step: 517850, training_loss: 2.65385e-02
I0210 15:34:58.027481 22542570456896 run_lib.py:133] step: 517900, training_loss: 3.58214e-02
I0210 15:34:58.180475 22542570456896 run_lib.py:146] step: 517900, eval_loss: 3.47462e-02
I0210 15:35:15.799608 22542570456896 run_lib.py:133] step: 517950, training_loss: 3.20087e-02
I0210 15:35:33.275399 22542570456896 run_lib.py:133] step: 518000, training_loss: 2.12816e-02
I0210 15:35:33.439771 22542570456896 run_lib.py:146] step: 518000, eval_loss: 3.18681e-02
I0210 15:35:51.088171 22542570456896 run_lib.py:133] step: 518050, training_loss: 2.74759e-02
I0210 15:36:08.530248 22542570456896 run_lib.py:133] step: 518100, training_loss: 2.47819e-02
I0210 15:36:08.688670 22542570456896 run_lib.py:146] step: 518100, eval_loss: 2.92820e-02
I0210 15:36:26.114400 22542570456896 run_lib.py:133] step: 518150, training_loss: 2.35475e-02
I0210 15:36:43.668607 22542570456896 run_lib.py:133] step: 518200, training_loss: 2.64174e-02
I0210 15:36:43.838137 22542570456896 run_lib.py:146] step: 518200, eval_loss: 2.87115e-02
I0210 15:37:01.286971 22542570456896 run_lib.py:133] step: 518250, training_loss: 2.70620e-02
I0210 15:37:18.722747 22542570456896 run_lib.py:133] step: 518300, training_loss: 2.72374e-02
I0210 15:37:18.941854 22542570456896 run_lib.py:146] step: 518300, eval_loss: 2.78342e-02
I0210 15:37:36.601196 22542570456896 run_lib.py:133] step: 518350, training_loss: 3.18069e-02
I0210 15:37:54.159994 22542570456896 run_lib.py:133] step: 518400, training_loss: 2.73506e-02
I0210 15:37:54.311267 22542570456896 run_lib.py:146] step: 518400, eval_loss: 2.79552e-02
I0210 15:38:11.728708 22542570456896 run_lib.py:133] step: 518450, training_loss: 2.42550e-02
I0210 15:38:29.164470 22542570456896 run_lib.py:133] step: 518500, training_loss: 3.72221e-02
I0210 15:38:29.334548 22542570456896 run_lib.py:146] step: 518500, eval_loss: 2.62270e-02
I0210 15:38:46.807524 22542570456896 run_lib.py:133] step: 518550, training_loss: 2.57959e-02
I0210 15:39:04.462566 22542570456896 run_lib.py:133] step: 518600, training_loss: 2.55117e-02
I0210 15:39:04.622380 22542570456896 run_lib.py:146] step: 518600, eval_loss: 3.58012e-02
I0210 15:39:22.037812 22542570456896 run_lib.py:133] step: 518650, training_loss: 2.84868e-02
I0210 15:39:39.461965 22542570456896 run_lib.py:133] step: 518700, training_loss: 2.49176e-02
I0210 15:39:39.618439 22542570456896 run_lib.py:146] step: 518700, eval_loss: 2.60033e-02
I0210 15:39:57.083024 22542570456896 run_lib.py:133] step: 518750, training_loss: 3.30701e-02
I0210 15:40:14.728610 22542570456896 run_lib.py:133] step: 518800, training_loss: 2.64787e-02
I0210 15:40:14.915607 22542570456896 run_lib.py:146] step: 518800, eval_loss: 2.96735e-02
I0210 15:40:32.362104 22542570456896 run_lib.py:133] step: 518850, training_loss: 2.54627e-02
I0210 15:40:49.882848 22542570456896 run_lib.py:133] step: 518900, training_loss: 2.77439e-02
I0210 15:40:50.036422 22542570456896 run_lib.py:146] step: 518900, eval_loss: 2.68172e-02
I0210 15:41:07.493299 22542570456896 run_lib.py:133] step: 518950, training_loss: 2.15901e-02
I0210 15:41:24.949048 22542570456896 run_lib.py:133] step: 519000, training_loss: 2.74342e-02
I0210 15:41:25.105605 22542570456896 run_lib.py:146] step: 519000, eval_loss: 3.19814e-02
I0210 15:41:42.677664 22542570456896 run_lib.py:133] step: 519050, training_loss: 2.67072e-02
I0210 15:42:00.221738 22542570456896 run_lib.py:133] step: 519100, training_loss: 2.37650e-02
I0210 15:42:00.398505 22542570456896 run_lib.py:146] step: 519100, eval_loss: 2.91352e-02
I0210 15:42:17.866617 22542570456896 run_lib.py:133] step: 519150, training_loss: 2.71102e-02
I0210 15:42:35.296452 22542570456896 run_lib.py:133] step: 519200, training_loss: 2.76782e-02
I0210 15:42:35.458111 22542570456896 run_lib.py:146] step: 519200, eval_loss: 3.62819e-02
I0210 15:42:53.131609 22542570456896 run_lib.py:133] step: 519250, training_loss: 3.45804e-02
I0210 15:43:10.532892 22542570456896 run_lib.py:133] step: 519300, training_loss: 2.00335e-02
I0210 15:43:10.687183 22542570456896 run_lib.py:146] step: 519300, eval_loss: 3.63679e-02
I0210 15:43:28.247640 22542570456896 run_lib.py:133] step: 519350, training_loss: 2.11468e-02
I0210 15:43:45.707636 22542570456896 run_lib.py:133] step: 519400, training_loss: 3.21659e-02
I0210 15:43:45.865919 22542570456896 run_lib.py:146] step: 519400, eval_loss: 2.58363e-02
I0210 15:44:03.503993 22542570456896 run_lib.py:133] step: 519450, training_loss: 2.99162e-02
I0210 15:44:20.946263 22542570456896 run_lib.py:133] step: 519500, training_loss: 2.82235e-02
I0210 15:44:21.113519 22542570456896 run_lib.py:146] step: 519500, eval_loss: 3.19571e-02
I0210 15:44:38.570974 22542570456896 run_lib.py:133] step: 519550, training_loss: 2.08217e-02
I0210 15:44:56.175611 22542570456896 run_lib.py:133] step: 519600, training_loss: 2.63727e-02
I0210 15:44:56.331346 22542570456896 run_lib.py:146] step: 519600, eval_loss: 2.78886e-02
I0210 15:45:13.821908 22542570456896 run_lib.py:133] step: 519650, training_loss: 2.20323e-02
I0210 15:45:31.505634 22542570456896 run_lib.py:133] step: 519700, training_loss: 3.03449e-02
I0210 15:45:31.661151 22542570456896 run_lib.py:146] step: 519700, eval_loss: 2.54077e-02
I0210 15:45:49.114659 22542570456896 run_lib.py:133] step: 519750, training_loss: 3.38129e-02
I0210 15:46:06.535964 22542570456896 run_lib.py:133] step: 519800, training_loss: 2.18307e-02
I0210 15:46:06.687482 22542570456896 run_lib.py:146] step: 519800, eval_loss: 2.79537e-02
I0210 15:46:24.268802 22542570456896 run_lib.py:133] step: 519850, training_loss: 2.42660e-02
I0210 15:46:41.739633 22542570456896 run_lib.py:133] step: 519900, training_loss: 3.42034e-02
I0210 15:46:41.970606 22542570456896 run_lib.py:146] step: 519900, eval_loss: 2.50044e-02
I0210 15:46:59.447025 22542570456896 run_lib.py:133] step: 519950, training_loss: 3.46014e-02
I0210 15:47:17.158008 22542570456896 run_lib.py:133] step: 520000, training_loss: 2.63404e-02
I0210 15:47:18.056163 22542570456896 run_lib.py:146] step: 520000, eval_loss: 3.62864e-02
I0210 15:47:38.547567 22542570456896 run_lib.py:133] step: 520050, training_loss: 2.46690e-02
I0210 15:47:56.015323 22542570456896 run_lib.py:133] step: 520100, training_loss: 2.58935e-02
I0210 15:47:56.175566 22542570456896 run_lib.py:146] step: 520100, eval_loss: 2.95413e-02
I0210 15:48:13.583864 22542570456896 run_lib.py:133] step: 520150, training_loss: 2.89571e-02
I0210 15:48:31.228751 22542570456896 run_lib.py:133] step: 520200, training_loss: 2.11077e-02
I0210 15:48:31.390656 22542570456896 run_lib.py:146] step: 520200, eval_loss: 3.22337e-02
I0210 15:48:48.786508 22542570456896 run_lib.py:133] step: 520250, training_loss: 2.04855e-02
I0210 15:49:06.183260 22542570456896 run_lib.py:133] step: 520300, training_loss: 2.86236e-02
I0210 15:49:06.338366 22542570456896 run_lib.py:146] step: 520300, eval_loss: 3.63809e-02
I0210 15:49:23.919229 22542570456896 run_lib.py:133] step: 520350, training_loss: 2.16207e-02
I0210 15:49:41.406810 22542570456896 run_lib.py:133] step: 520400, training_loss: 2.67223e-02
I0210 15:49:41.554501 22542570456896 run_lib.py:146] step: 520400, eval_loss: 3.01529e-02
I0210 15:49:59.079985 22542570456896 run_lib.py:133] step: 520450, training_loss: 3.05590e-02
I0210 15:50:16.533375 22542570456896 run_lib.py:133] step: 520500, training_loss: 2.60619e-02
I0210 15:50:16.703302 22542570456896 run_lib.py:146] step: 520500, eval_loss: 2.62908e-02
I0210 15:50:34.113483 22542570456896 run_lib.py:133] step: 520550, training_loss: 2.44263e-02
I0210 15:50:51.557300 22542570456896 run_lib.py:133] step: 520600, training_loss: 2.67366e-02
I0210 15:50:51.714713 22542570456896 run_lib.py:146] step: 520600, eval_loss: 2.77647e-02
I0210 15:51:09.309498 22542570456896 run_lib.py:133] step: 520650, training_loss: 2.69194e-02
I0210 15:51:26.812600 22542570456896 run_lib.py:133] step: 520700, training_loss: 2.92590e-02
I0210 15:51:26.974516 22542570456896 run_lib.py:146] step: 520700, eval_loss: 2.09270e-02
I0210 15:51:44.424158 22542570456896 run_lib.py:133] step: 520750, training_loss: 2.61191e-02
I0210 15:52:01.928848 22542570456896 run_lib.py:133] step: 520800, training_loss: 2.85188e-02
I0210 15:52:02.084814 22542570456896 run_lib.py:146] step: 520800, eval_loss: 2.60266e-02
I0210 15:52:19.720692 22542570456896 run_lib.py:133] step: 520850, training_loss: 3.01889e-02
I0210 15:52:37.234861 22542570456896 run_lib.py:133] step: 520900, training_loss: 2.30428e-02
I0210 15:52:37.385511 22542570456896 run_lib.py:146] step: 520900, eval_loss: 2.57064e-02
I0210 15:52:54.930911 22542570456896 run_lib.py:133] step: 520950, training_loss: 2.77245e-02
I0210 15:53:12.346888 22542570456896 run_lib.py:133] step: 521000, training_loss: 2.48564e-02
I0210 15:53:12.523298 22542570456896 run_lib.py:146] step: 521000, eval_loss: 2.90149e-02
I0210 15:53:30.169914 22542570456896 run_lib.py:133] step: 521050, training_loss: 2.33450e-02
I0210 15:53:47.613391 22542570456896 run_lib.py:133] step: 521100, training_loss: 2.99972e-02
I0210 15:53:47.768689 22542570456896 run_lib.py:146] step: 521100, eval_loss: 2.61394e-02
I0210 15:54:05.336256 22542570456896 run_lib.py:133] step: 521150, training_loss: 2.56701e-02
I0210 15:54:22.749855 22542570456896 run_lib.py:133] step: 521200, training_loss: 2.72618e-02
I0210 15:54:22.910041 22542570456896 run_lib.py:146] step: 521200, eval_loss: 1.93834e-02
I0210 15:54:40.372995 22542570456896 run_lib.py:133] step: 521250, training_loss: 3.15076e-02
I0210 15:54:57.919837 22542570456896 run_lib.py:133] step: 521300, training_loss: 3.07464e-02
I0210 15:54:58.073135 22542570456896 run_lib.py:146] step: 521300, eval_loss: 3.30547e-02
I0210 15:55:15.522996 22542570456896 run_lib.py:133] step: 521350, training_loss: 2.71927e-02
I0210 15:55:32.969716 22542570456896 run_lib.py:133] step: 521400, training_loss: 3.56762e-02
I0210 15:55:33.124362 22542570456896 run_lib.py:146] step: 521400, eval_loss: 3.58806e-02
I0210 15:55:50.753968 22542570456896 run_lib.py:133] step: 521450, training_loss: 3.26691e-02
I0210 15:56:08.196251 22542570456896 run_lib.py:133] step: 521500, training_loss: 2.59036e-02
I0210 15:56:08.385393 22542570456896 run_lib.py:146] step: 521500, eval_loss: 2.63356e-02
I0210 15:56:25.939299 22542570456896 run_lib.py:133] step: 521550, training_loss: 2.64033e-02
I0210 15:56:43.346451 22542570456896 run_lib.py:133] step: 521600, training_loss: 2.58100e-02
I0210 15:56:43.516364 22542570456896 run_lib.py:146] step: 521600, eval_loss: 2.26479e-02
I0210 15:57:00.994730 22542570456896 run_lib.py:133] step: 521650, training_loss: 2.67848e-02
I0210 15:57:18.622112 22542570456896 run_lib.py:133] step: 521700, training_loss: 2.58602e-02
I0210 15:57:18.777585 22542570456896 run_lib.py:146] step: 521700, eval_loss: 4.01533e-02
I0210 15:57:36.218900 22542570456896 run_lib.py:133] step: 521750, training_loss: 2.52164e-02
I0210 15:57:53.751525 22542570456896 run_lib.py:133] step: 521800, training_loss: 2.51400e-02
I0210 15:57:53.908271 22542570456896 run_lib.py:146] step: 521800, eval_loss: 2.97929e-02
I0210 15:58:11.329470 22542570456896 run_lib.py:133] step: 521850, training_loss: 3.16190e-02
I0210 15:58:28.961164 22542570456896 run_lib.py:133] step: 521900, training_loss: 3.06689e-02
I0210 15:58:29.130760 22542570456896 run_lib.py:146] step: 521900, eval_loss: 3.02850e-02
I0210 15:58:46.593870 22542570456896 run_lib.py:133] step: 521950, training_loss: 3.36459e-02
I0210 15:59:04.140643 22542570456896 run_lib.py:133] step: 522000, training_loss: 2.76978e-02
I0210 15:59:04.298612 22542570456896 run_lib.py:146] step: 522000, eval_loss: 3.18580e-02
I0210 15:59:21.728890 22542570456896 run_lib.py:133] step: 522050, training_loss: 2.97003e-02
I0210 15:59:39.144427 22542570456896 run_lib.py:133] step: 522100, training_loss: 3.25628e-02
I0210 15:59:39.347362 22542570456896 run_lib.py:146] step: 522100, eval_loss: 3.62368e-02
I0210 15:59:56.936063 22542570456896 run_lib.py:133] step: 522150, training_loss: 2.79885e-02
I0210 16:00:14.506860 22542570456896 run_lib.py:133] step: 522200, training_loss: 2.88085e-02
I0210 16:00:14.661051 22542570456896 run_lib.py:146] step: 522200, eval_loss: 2.71952e-02
I0210 16:00:32.118597 22542570456896 run_lib.py:133] step: 522250, training_loss: 2.79830e-02
I0210 16:00:49.524723 22542570456896 run_lib.py:133] step: 522300, training_loss: 2.85990e-02
I0210 16:00:49.676368 22542570456896 run_lib.py:146] step: 522300, eval_loss: 2.26009e-02
I0210 16:01:07.230423 22542570456896 run_lib.py:133] step: 522350, training_loss: 3.17580e-02
I0210 16:01:24.644015 22542570456896 run_lib.py:133] step: 522400, training_loss: 2.81167e-02
I0210 16:01:24.821239 22542570456896 run_lib.py:146] step: 522400, eval_loss: 3.30776e-02
I0210 16:01:42.427822 22542570456896 run_lib.py:133] step: 522450, training_loss: 2.52474e-02
I0210 16:01:59.885806 22542570456896 run_lib.py:133] step: 522500, training_loss: 2.26489e-02
I0210 16:02:00.043649 22542570456896 run_lib.py:146] step: 522500, eval_loss: 3.09724e-02
I0210 16:02:17.605902 22542570456896 run_lib.py:133] step: 522550, training_loss: 2.35938e-02
I0210 16:02:34.975797 22542570456896 run_lib.py:133] step: 522600, training_loss: 3.18156e-02
I0210 16:02:35.139185 22542570456896 run_lib.py:146] step: 522600, eval_loss: 2.70817e-02
I0210 16:02:52.527190 22542570456896 run_lib.py:133] step: 522650, training_loss: 2.84454e-02
I0210 16:03:10.113455 22542570456896 run_lib.py:133] step: 522700, training_loss: 2.97983e-02
I0210 16:03:10.267001 22542570456896 run_lib.py:146] step: 522700, eval_loss: 3.62039e-02
I0210 16:03:27.680917 22542570456896 run_lib.py:133] step: 522750, training_loss: 3.18308e-02
I0210 16:03:45.230365 22542570456896 run_lib.py:133] step: 522800, training_loss: 2.10444e-02
I0210 16:03:45.382314 22542570456896 run_lib.py:146] step: 522800, eval_loss: 2.67093e-02
I0210 16:04:02.761187 22542570456896 run_lib.py:133] step: 522850, training_loss: 3.65760e-02
I0210 16:04:20.188848 22542570456896 run_lib.py:133] step: 522900, training_loss: 2.64737e-02
I0210 16:04:20.348070 22542570456896 run_lib.py:146] step: 522900, eval_loss: 2.43316e-02
I0210 16:04:37.873692 22542570456896 run_lib.py:133] step: 522950, training_loss: 2.77114e-02
I0210 16:04:55.338341 22542570456896 run_lib.py:133] step: 523000, training_loss: 3.02872e-02
I0210 16:04:55.494500 22542570456896 run_lib.py:146] step: 523000, eval_loss: 3.57490e-02
I0210 16:05:12.921997 22542570456896 run_lib.py:133] step: 523050, training_loss: 2.01125e-02
I0210 16:05:30.476511 22542570456896 run_lib.py:133] step: 523100, training_loss: 2.93224e-02
I0210 16:05:30.654508 22542570456896 run_lib.py:146] step: 523100, eval_loss: 2.19797e-02
I0210 16:05:48.033579 22542570456896 run_lib.py:133] step: 523150, training_loss: 2.30220e-02
I0210 16:06:05.462260 22542570456896 run_lib.py:133] step: 523200, training_loss: 2.95415e-02
I0210 16:06:05.762148 22542570456896 run_lib.py:146] step: 523200, eval_loss: 2.75968e-02
I0210 16:06:23.179698 22542570456896 run_lib.py:133] step: 523250, training_loss: 2.90871e-02
I0210 16:06:40.636999 22542570456896 run_lib.py:133] step: 523300, training_loss: 2.95779e-02
I0210 16:06:40.803560 22542570456896 run_lib.py:146] step: 523300, eval_loss: 3.23336e-02
I0210 16:06:58.255172 22542570456896 run_lib.py:133] step: 523350, training_loss: 2.42870e-02
I0210 16:07:15.716567 22542570456896 run_lib.py:133] step: 523400, training_loss: 2.40967e-02
I0210 16:07:15.874651 22542570456896 run_lib.py:146] step: 523400, eval_loss: 2.38798e-02
I0210 16:07:33.475055 22542570456896 run_lib.py:133] step: 523450, training_loss: 2.36938e-02
I0210 16:07:50.954025 22542570456896 run_lib.py:133] step: 523500, training_loss: 2.45341e-02
I0210 16:07:51.109281 22542570456896 run_lib.py:146] step: 523500, eval_loss: 3.02539e-02
I0210 16:08:08.539669 22542570456896 run_lib.py:133] step: 523550, training_loss: 2.88055e-02
I0210 16:08:26.035487 22542570456896 run_lib.py:133] step: 523600, training_loss: 2.54289e-02
I0210 16:08:26.200341 22542570456896 run_lib.py:146] step: 523600, eval_loss: 2.30423e-02
I0210 16:08:43.815322 22542570456896 run_lib.py:133] step: 523650, training_loss: 2.30097e-02
I0210 16:09:01.312087 22542570456896 run_lib.py:133] step: 523700, training_loss: 2.53834e-02
I0210 16:09:01.463390 22542570456896 run_lib.py:146] step: 523700, eval_loss: 3.32258e-02
I0210 16:09:18.976952 22542570456896 run_lib.py:133] step: 523750, training_loss: 2.16246e-02
I0210 16:09:36.417237 22542570456896 run_lib.py:133] step: 523800, training_loss: 2.13510e-02
I0210 16:09:36.572500 22542570456896 run_lib.py:146] step: 523800, eval_loss: 2.48705e-02
I0210 16:09:54.171711 22542570456896 run_lib.py:133] step: 523850, training_loss: 3.54716e-02
I0210 16:10:11.673200 22542570456896 run_lib.py:133] step: 523900, training_loss: 2.05696e-02
I0210 16:10:11.833483 22542570456896 run_lib.py:146] step: 523900, eval_loss: 2.90700e-02
I0210 16:10:29.431356 22542570456896 run_lib.py:133] step: 523950, training_loss: 2.37748e-02
I0210 16:10:46.861560 22542570456896 run_lib.py:133] step: 524000, training_loss: 3.08465e-02
I0210 16:10:47.021300 22542570456896 run_lib.py:146] step: 524000, eval_loss: 3.07582e-02
I0210 16:11:04.607672 22542570456896 run_lib.py:133] step: 524050, training_loss: 2.99504e-02
I0210 16:11:22.007944 22542570456896 run_lib.py:133] step: 524100, training_loss: 2.70191e-02
I0210 16:11:22.167416 22542570456896 run_lib.py:146] step: 524100, eval_loss: 2.85725e-02
I0210 16:11:39.678700 22542570456896 run_lib.py:133] step: 524150, training_loss: 2.52851e-02
I0210 16:11:57.329489 22542570456896 run_lib.py:133] step: 524200, training_loss: 2.74024e-02
I0210 16:11:57.483594 22542570456896 run_lib.py:146] step: 524200, eval_loss: 2.61468e-02
I0210 16:12:14.921060 22542570456896 run_lib.py:133] step: 524250, training_loss: 2.72849e-02
I0210 16:12:32.486927 22542570456896 run_lib.py:133] step: 524300, training_loss: 2.64669e-02
I0210 16:12:32.646027 22542570456896 run_lib.py:146] step: 524300, eval_loss: 3.02462e-02
I0210 16:12:50.058904 22542570456896 run_lib.py:133] step: 524350, training_loss: 1.77245e-02
I0210 16:13:07.521364 22542570456896 run_lib.py:133] step: 524400, training_loss: 2.59586e-02
I0210 16:13:07.694500 22542570456896 run_lib.py:146] step: 524400, eval_loss: 3.10695e-02
I0210 16:13:25.346977 22542570456896 run_lib.py:133] step: 524450, training_loss: 2.72087e-02
I0210 16:13:42.778999 22542570456896 run_lib.py:133] step: 524500, training_loss: 2.54177e-02
I0210 16:13:42.933666 22542570456896 run_lib.py:146] step: 524500, eval_loss: 2.61431e-02
I0210 16:14:00.366033 22542570456896 run_lib.py:133] step: 524550, training_loss: 2.13530e-02
I0210 16:14:17.811025 22542570456896 run_lib.py:133] step: 524600, training_loss: 2.80413e-02
I0210 16:14:17.964083 22542570456896 run_lib.py:146] step: 524600, eval_loss: 2.61995e-02
I0210 16:14:35.521257 22542570456896 run_lib.py:133] step: 524650, training_loss: 2.92797e-02
I0210 16:14:52.994072 22542570456896 run_lib.py:133] step: 524700, training_loss: 2.05038e-02
I0210 16:14:53.168050 22542570456896 run_lib.py:146] step: 524700, eval_loss: 3.48149e-02
I0210 16:15:10.739334 22542570456896 run_lib.py:133] step: 524750, training_loss: 3.02826e-02
I0210 16:15:28.184217 22542570456896 run_lib.py:133] step: 524800, training_loss: 2.28649e-02
I0210 16:15:28.345678 22542570456896 run_lib.py:146] step: 524800, eval_loss: 3.04157e-02
I0210 16:15:45.767020 22542570456896 run_lib.py:133] step: 524850, training_loss: 2.95457e-02
I0210 16:16:03.190225 22542570456896 run_lib.py:133] step: 524900, training_loss: 2.83392e-02
I0210 16:16:03.345510 22542570456896 run_lib.py:146] step: 524900, eval_loss: 3.00880e-02
I0210 16:16:20.890830 22542570456896 run_lib.py:133] step: 524950, training_loss: 2.32876e-02
I0210 16:16:38.462579 22542570456896 run_lib.py:133] step: 525000, training_loss: 2.65623e-02
I0210 16:16:38.621988 22542570456896 run_lib.py:146] step: 525000, eval_loss: 3.40254e-02
I0210 16:16:56.072124 22542570456896 run_lib.py:133] step: 525050, training_loss: 2.20451e-02
I0210 16:17:13.516778 22542570456896 run_lib.py:133] step: 525100, training_loss: 2.72737e-02
I0210 16:17:13.668317 22542570456896 run_lib.py:146] step: 525100, eval_loss: 2.70115e-02
I0210 16:17:31.327691 22542570456896 run_lib.py:133] step: 525150, training_loss: 3.26463e-02
I0210 16:17:48.775031 22542570456896 run_lib.py:133] step: 525200, training_loss: 2.45766e-02
I0210 16:17:48.930639 22542570456896 run_lib.py:146] step: 525200, eval_loss: 3.70066e-02
I0210 16:18:06.512468 22542570456896 run_lib.py:133] step: 525250, training_loss: 2.62384e-02
I0210 16:18:23.999484 22542570456896 run_lib.py:133] step: 525300, training_loss: 2.47025e-02
I0210 16:18:24.166449 22542570456896 run_lib.py:146] step: 525300, eval_loss: 2.90969e-02
I0210 16:18:41.814047 22542570456896 run_lib.py:133] step: 525350, training_loss: 3.02101e-02
I0210 16:18:59.156383 22542570456896 run_lib.py:133] step: 525400, training_loss: 2.30983e-02
I0210 16:18:59.310310 22542570456896 run_lib.py:146] step: 525400, eval_loss: 2.48589e-02
I0210 16:19:16.828988 22542570456896 run_lib.py:133] step: 525450, training_loss: 2.99633e-02
I0210 16:19:34.214054 22542570456896 run_lib.py:133] step: 525500, training_loss: 2.39918e-02
I0210 16:19:34.368191 22542570456896 run_lib.py:146] step: 525500, eval_loss: 3.30902e-02
I0210 16:19:51.782338 22542570456896 run_lib.py:133] step: 525550, training_loss: 2.91359e-02
I0210 16:20:09.310949 22542570456896 run_lib.py:133] step: 525600, training_loss: 2.92074e-02
I0210 16:20:09.471567 22542570456896 run_lib.py:146] step: 525600, eval_loss: 3.11925e-02
I0210 16:20:26.919072 22542570456896 run_lib.py:133] step: 525650, training_loss: 2.63166e-02
I0210 16:20:44.348351 22542570456896 run_lib.py:133] step: 525700, training_loss: 2.53887e-02
I0210 16:20:44.504340 22542570456896 run_lib.py:146] step: 525700, eval_loss: 2.61073e-02
I0210 16:21:02.085461 22542570456896 run_lib.py:133] step: 525750, training_loss: 2.68612e-02
I0210 16:21:19.662438 22542570456896 run_lib.py:133] step: 525800, training_loss: 2.12862e-02
I0210 16:21:19.847416 22542570456896 run_lib.py:146] step: 525800, eval_loss: 3.02062e-02
I0210 16:21:37.313900 22542570456896 run_lib.py:133] step: 525850, training_loss: 2.63718e-02
I0210 16:21:54.788794 22542570456896 run_lib.py:133] step: 525900, training_loss: 3.21945e-02
I0210 16:21:54.941952 22542570456896 run_lib.py:146] step: 525900, eval_loss: 3.20232e-02
I0210 16:22:12.426310 22542570456896 run_lib.py:133] step: 525950, training_loss: 2.78626e-02
I0210 16:22:30.046279 22542570456896 run_lib.py:133] step: 526000, training_loss: 2.66135e-02
I0210 16:22:30.206376 22542570456896 run_lib.py:146] step: 526000, eval_loss: 2.30565e-02
I0210 16:22:47.686451 22542570456896 run_lib.py:133] step: 526050, training_loss: 2.59717e-02
I0210 16:23:05.159837 22542570456896 run_lib.py:133] step: 526100, training_loss: 2.91501e-02
I0210 16:23:05.314794 22542570456896 run_lib.py:146] step: 526100, eval_loss: 2.64779e-02
I0210 16:23:22.771237 22542570456896 run_lib.py:133] step: 526150, training_loss: 2.58143e-02
I0210 16:23:40.438151 22542570456896 run_lib.py:133] step: 526200, training_loss: 2.77236e-02
I0210 16:23:40.597995 22542570456896 run_lib.py:146] step: 526200, eval_loss: 3.12566e-02
I0210 16:23:58.006738 22542570456896 run_lib.py:133] step: 526250, training_loss: 2.62715e-02
I0210 16:24:15.456823 22542570456896 run_lib.py:133] step: 526300, training_loss: 2.82074e-02
I0210 16:24:15.619002 22542570456896 run_lib.py:146] step: 526300, eval_loss: 3.29383e-02
I0210 16:24:33.004572 22542570456896 run_lib.py:133] step: 526350, training_loss: 3.38635e-02
I0210 16:24:50.462692 22542570456896 run_lib.py:133] step: 526400, training_loss: 2.47907e-02
I0210 16:24:50.623906 22542570456896 run_lib.py:146] step: 526400, eval_loss: 2.66243e-02
I0210 16:25:08.270918 22542570456896 run_lib.py:133] step: 526450, training_loss: 2.68217e-02
I0210 16:25:25.773433 22542570456896 run_lib.py:133] step: 526500, training_loss: 2.62470e-02
I0210 16:25:25.924166 22542570456896 run_lib.py:146] step: 526500, eval_loss: 2.84910e-02
I0210 16:25:43.366120 22542570456896 run_lib.py:133] step: 526550, training_loss: 2.73166e-02
I0210 16:26:00.884001 22542570456896 run_lib.py:133] step: 526600, training_loss: 2.72332e-02
I0210 16:26:01.044578 22542570456896 run_lib.py:146] step: 526600, eval_loss: 2.50420e-02
I0210 16:26:18.662472 22542570456896 run_lib.py:133] step: 526650, training_loss: 2.93520e-02
I0210 16:26:36.136426 22542570456896 run_lib.py:133] step: 526700, training_loss: 2.73836e-02
I0210 16:26:36.299383 22542570456896 run_lib.py:146] step: 526700, eval_loss: 3.12686e-02
I0210 16:26:53.898279 22542570456896 run_lib.py:133] step: 526750, training_loss: 2.56587e-02
I0210 16:27:11.308607 22542570456896 run_lib.py:133] step: 526800, training_loss: 2.87021e-02
I0210 16:27:11.464384 22542570456896 run_lib.py:146] step: 526800, eval_loss: 2.30748e-02
I0210 16:27:29.081065 22542570456896 run_lib.py:133] step: 526850, training_loss: 2.38891e-02
I0210 16:27:46.558462 22542570456896 run_lib.py:133] step: 526900, training_loss: 2.57976e-02
I0210 16:27:46.716307 22542570456896 run_lib.py:146] step: 526900, eval_loss: 2.84781e-02
I0210 16:28:04.204597 22542570456896 run_lib.py:133] step: 526950, training_loss: 2.77041e-02
I0210 16:28:21.804418 22542570456896 run_lib.py:133] step: 527000, training_loss: 2.79424e-02
I0210 16:28:21.959108 22542570456896 run_lib.py:146] step: 527000, eval_loss: 2.82559e-02
I0210 16:28:39.376147 22542570456896 run_lib.py:133] step: 527050, training_loss: 2.34958e-02
I0210 16:28:56.960706 22542570456896 run_lib.py:133] step: 527100, training_loss: 2.84484e-02
I0210 16:28:57.116471 22542570456896 run_lib.py:146] step: 527100, eval_loss: 3.04859e-02
I0210 16:29:14.580408 22542570456896 run_lib.py:133] step: 527150, training_loss: 2.88877e-02
I0210 16:29:32.069755 22542570456896 run_lib.py:133] step: 527200, training_loss: 2.71924e-02
I0210 16:29:32.231413 22542570456896 run_lib.py:146] step: 527200, eval_loss: 2.90087e-02
I0210 16:29:49.860111 22542570456896 run_lib.py:133] step: 527250, training_loss: 2.52006e-02
I0210 16:30:07.305551 22542570456896 run_lib.py:133] step: 527300, training_loss: 3.16774e-02
I0210 16:30:07.463734 22542570456896 run_lib.py:146] step: 527300, eval_loss: 3.20470e-02
I0210 16:30:24.942235 22542570456896 run_lib.py:133] step: 527350, training_loss: 2.25197e-02
I0210 16:30:42.492398 22542570456896 run_lib.py:133] step: 527400, training_loss: 3.53406e-02
I0210 16:30:42.652512 22542570456896 run_lib.py:146] step: 527400, eval_loss: 2.93310e-02
I0210 16:31:00.120716 22542570456896 run_lib.py:133] step: 527450, training_loss: 2.79811e-02
I0210 16:31:17.624095 22542570456896 run_lib.py:133] step: 527500, training_loss: 2.61306e-02
I0210 16:31:17.785577 22542570456896 run_lib.py:146] step: 527500, eval_loss: 3.06937e-02
I0210 16:31:35.328419 22542570456896 run_lib.py:133] step: 527550, training_loss: 3.17995e-02
I0210 16:31:52.772864 22542570456896 run_lib.py:133] step: 527600, training_loss: 2.37038e-02
I0210 16:31:52.930433 22542570456896 run_lib.py:146] step: 527600, eval_loss: 2.56834e-02
I0210 16:32:10.375673 22542570456896 run_lib.py:133] step: 527650, training_loss: 2.88902e-02
I0210 16:32:27.847836 22542570456896 run_lib.py:133] step: 527700, training_loss: 3.16867e-02
I0210 16:32:28.024430 22542570456896 run_lib.py:146] step: 527700, eval_loss: 2.52083e-02
I0210 16:32:45.623630 22542570456896 run_lib.py:133] step: 527750, training_loss: 3.35693e-02
I0210 16:33:03.167250 22542570456896 run_lib.py:133] step: 527800, training_loss: 2.50715e-02
I0210 16:33:03.321201 22542570456896 run_lib.py:146] step: 527800, eval_loss: 3.41411e-02
I0210 16:33:20.761316 22542570456896 run_lib.py:133] step: 527850, training_loss: 3.68582e-02
I0210 16:33:38.212221 22542570456896 run_lib.py:133] step: 527900, training_loss: 2.54522e-02
I0210 16:33:38.363389 22542570456896 run_lib.py:146] step: 527900, eval_loss: 3.02752e-02
I0210 16:33:55.916874 22542570456896 run_lib.py:133] step: 527950, training_loss: 3.06790e-02
I0210 16:34:13.419377 22542570456896 run_lib.py:133] step: 528000, training_loss: 3.04433e-02
I0210 16:34:13.573746 22542570456896 run_lib.py:146] step: 528000, eval_loss: 2.56292e-02
I0210 16:34:31.217214 22542570456896 run_lib.py:133] step: 528050, training_loss: 2.76542e-02
I0210 16:34:48.678123 22542570456896 run_lib.py:133] step: 528100, training_loss: 2.70673e-02
I0210 16:34:48.836307 22542570456896 run_lib.py:146] step: 528100, eval_loss: 2.42707e-02
I0210 16:35:06.439670 22542570456896 run_lib.py:133] step: 528150, training_loss: 2.46082e-02
I0210 16:35:23.851538 22542570456896 run_lib.py:133] step: 528200, training_loss: 2.72532e-02
I0210 16:35:24.012398 22542570456896 run_lib.py:146] step: 528200, eval_loss: 2.89623e-02
I0210 16:35:41.567140 22542570456896 run_lib.py:133] step: 528250, training_loss: 2.68963e-02
I0210 16:35:59.005893 22542570456896 run_lib.py:133] step: 528300, training_loss: 2.94535e-02
I0210 16:35:59.168750 22542570456896 run_lib.py:146] step: 528300, eval_loss: 2.79619e-02
I0210 16:36:16.657152 22542570456896 run_lib.py:133] step: 528350, training_loss: 3.09981e-02
I0210 16:36:34.256390 22542570456896 run_lib.py:133] step: 528400, training_loss: 2.22698e-02
I0210 16:36:34.409097 22542570456896 run_lib.py:146] step: 528400, eval_loss: 2.26336e-02
I0210 16:36:51.820990 22542570456896 run_lib.py:133] step: 528450, training_loss: 3.15073e-02
I0210 16:37:09.302031 22542570456896 run_lib.py:133] step: 528500, training_loss: 2.54430e-02
I0210 16:37:09.452399 22542570456896 run_lib.py:146] step: 528500, eval_loss: 3.20486e-02
I0210 16:37:26.926636 22542570456896 run_lib.py:133] step: 528550, training_loss: 2.52505e-02
I0210 16:37:44.214462 22542570456896 run_lib.py:133] step: 528600, training_loss: 2.45347e-02
I0210 16:37:44.400254 22542570456896 run_lib.py:146] step: 528600, eval_loss: 3.27863e-02
I0210 16:38:01.915603 22542570456896 run_lib.py:133] step: 528650, training_loss: 3.29719e-02
I0210 16:38:19.276969 22542570456896 run_lib.py:133] step: 528700, training_loss: 2.14059e-02
I0210 16:38:19.428908 22542570456896 run_lib.py:146] step: 528700, eval_loss: 3.03869e-02
I0210 16:38:36.793762 22542570456896 run_lib.py:133] step: 528750, training_loss: 3.06723e-02
I0210 16:38:54.372380 22542570456896 run_lib.py:133] step: 528800, training_loss: 2.84560e-02
I0210 16:38:54.528606 22542570456896 run_lib.py:146] step: 528800, eval_loss: 3.01244e-02
I0210 16:39:11.919960 22542570456896 run_lib.py:133] step: 528850, training_loss: 3.01123e-02
I0210 16:39:29.400119 22542570456896 run_lib.py:133] step: 528900, training_loss: 2.87754e-02
I0210 16:39:29.554183 22542570456896 run_lib.py:146] step: 528900, eval_loss: 2.68554e-02
I0210 16:39:47.032144 22542570456896 run_lib.py:133] step: 528950, training_loss: 3.27203e-02
I0210 16:40:04.609736 22542570456896 run_lib.py:133] step: 529000, training_loss: 2.44482e-02
I0210 16:40:04.765406 22542570456896 run_lib.py:146] step: 529000, eval_loss: 3.15651e-02
I0210 16:40:22.161312 22542570456896 run_lib.py:133] step: 529050, training_loss: 3.63112e-02
I0210 16:40:39.662074 22542570456896 run_lib.py:133] step: 529100, training_loss: 3.23469e-02
I0210 16:40:39.820595 22542570456896 run_lib.py:146] step: 529100, eval_loss: 2.89401e-02
I0210 16:40:57.299256 22542570456896 run_lib.py:133] step: 529150, training_loss: 2.96824e-02
I0210 16:41:14.744160 22542570456896 run_lib.py:133] step: 529200, training_loss: 2.63864e-02
I0210 16:41:14.899570 22542570456896 run_lib.py:146] step: 529200, eval_loss: 3.24375e-02
I0210 16:41:32.485269 22542570456896 run_lib.py:133] step: 529250, training_loss: 2.65315e-02
I0210 16:41:49.970359 22542570456896 run_lib.py:133] step: 529300, training_loss: 2.78485e-02
I0210 16:41:50.126325 22542570456896 run_lib.py:146] step: 529300, eval_loss: 3.28049e-02
I0210 16:42:07.557556 22542570456896 run_lib.py:133] step: 529350, training_loss: 2.80668e-02
I0210 16:42:25.028383 22542570456896 run_lib.py:133] step: 529400, training_loss: 2.77228e-02
I0210 16:42:25.181733 22542570456896 run_lib.py:146] step: 529400, eval_loss: 3.37043e-02
I0210 16:42:42.819899 22542570456896 run_lib.py:133] step: 529450, training_loss: 3.20382e-02
I0210 16:43:00.269619 22542570456896 run_lib.py:133] step: 529500, training_loss: 2.32066e-02
I0210 16:43:00.426099 22542570456896 run_lib.py:146] step: 529500, eval_loss: 2.88756e-02
I0210 16:43:17.964901 22542570456896 run_lib.py:133] step: 529550, training_loss: 2.16269e-02
I0210 16:43:35.359001 22542570456896 run_lib.py:133] step: 529600, training_loss: 2.82595e-02
I0210 16:43:35.516448 22542570456896 run_lib.py:146] step: 529600, eval_loss: 3.11904e-02
I0210 16:43:53.049779 22542570456896 run_lib.py:133] step: 529650, training_loss: 2.72543e-02
I0210 16:44:10.438687 22542570456896 run_lib.py:133] step: 529700, training_loss: 2.71691e-02
I0210 16:44:10.607365 22542570456896 run_lib.py:146] step: 529700, eval_loss: 2.39304e-02
I0210 16:44:28.050466 22542570456896 run_lib.py:133] step: 529750, training_loss: 2.95069e-02
I0210 16:44:45.642661 22542570456896 run_lib.py:133] step: 529800, training_loss: 3.64353e-02
I0210 16:44:45.797118 22542570456896 run_lib.py:146] step: 529800, eval_loss: 2.63399e-02
I0210 16:45:03.267359 22542570456896 run_lib.py:133] step: 529850, training_loss: 2.93473e-02
I0210 16:45:20.809762 22542570456896 run_lib.py:133] step: 529900, training_loss: 2.43002e-02
I0210 16:45:20.961295 22542570456896 run_lib.py:146] step: 529900, eval_loss: 2.86396e-02
I0210 16:45:38.347247 22542570456896 run_lib.py:133] step: 529950, training_loss: 2.67330e-02
I0210 16:45:55.706960 22542570456896 run_lib.py:133] step: 530000, training_loss: 2.58468e-02
I0210 16:45:56.435022 22542570456896 run_lib.py:146] step: 530000, eval_loss: 3.04668e-02
I0210 16:46:16.734886 22542570456896 run_lib.py:133] step: 530050, training_loss: 2.88282e-02
I0210 16:46:34.156088 22542570456896 run_lib.py:133] step: 530100, training_loss: 2.71465e-02
I0210 16:46:34.314404 22542570456896 run_lib.py:146] step: 530100, eval_loss: 2.47074e-02
I0210 16:46:51.869223 22542570456896 run_lib.py:133] step: 530150, training_loss: 2.45505e-02
I0210 16:47:09.260420 22542570456896 run_lib.py:133] step: 530200, training_loss: 2.77772e-02
I0210 16:47:09.416321 22542570456896 run_lib.py:146] step: 530200, eval_loss: 2.86822e-02
I0210 16:47:26.853567 22542570456896 run_lib.py:133] step: 530250, training_loss: 2.67036e-02
I0210 16:47:44.479564 22542570456896 run_lib.py:133] step: 530300, training_loss: 3.27932e-02
I0210 16:47:44.645032 22542570456896 run_lib.py:146] step: 530300, eval_loss: 2.83669e-02
I0210 16:48:02.073578 22542570456896 run_lib.py:133] step: 530350, training_loss: 2.83097e-02
I0210 16:48:19.629360 22542570456896 run_lib.py:133] step: 530400, training_loss: 3.38026e-02
I0210 16:48:19.781316 22542570456896 run_lib.py:146] step: 530400, eval_loss: 3.22026e-02
I0210 16:48:37.176779 22542570456896 run_lib.py:133] step: 530450, training_loss: 2.89273e-02
I0210 16:48:54.573875 22542570456896 run_lib.py:133] step: 530500, training_loss: 3.46077e-02
I0210 16:48:54.728546 22542570456896 run_lib.py:146] step: 530500, eval_loss: 3.65135e-02
I0210 16:49:12.169109 22542570456896 run_lib.py:133] step: 530550, training_loss: 2.74656e-02
I0210 16:49:29.774837 22542570456896 run_lib.py:133] step: 530600, training_loss: 2.09986e-02
I0210 16:49:29.958270 22542570456896 run_lib.py:146] step: 530600, eval_loss: 2.72308e-02
I0210 16:49:47.385763 22542570456896 run_lib.py:133] step: 530650, training_loss: 2.70985e-02
I0210 16:50:04.761669 22542570456896 run_lib.py:133] step: 530700, training_loss: 2.60603e-02
I0210 16:50:04.917318 22542570456896 run_lib.py:146] step: 530700, eval_loss: 2.42520e-02
I0210 16:50:22.538357 22542570456896 run_lib.py:133] step: 530750, training_loss: 3.06030e-02
I0210 16:50:39.923753 22542570456896 run_lib.py:133] step: 530800, training_loss: 3.55646e-02
I0210 16:50:40.086907 22542570456896 run_lib.py:146] step: 530800, eval_loss: 2.16128e-02
I0210 16:50:57.551657 22542570456896 run_lib.py:133] step: 530850, training_loss: 2.65816e-02
I0210 16:51:14.980641 22542570456896 run_lib.py:133] step: 530900, training_loss: 3.11135e-02
I0210 16:51:15.143514 22542570456896 run_lib.py:146] step: 530900, eval_loss: 2.88124e-02
I0210 16:51:32.575802 22542570456896 run_lib.py:133] step: 530950, training_loss: 3.15398e-02
I0210 16:51:50.046917 22542570456896 run_lib.py:133] step: 531000, training_loss: 3.04754e-02
I0210 16:51:50.201473 22542570456896 run_lib.py:146] step: 531000, eval_loss: 2.79708e-02
I0210 16:52:07.803138 22542570456896 run_lib.py:133] step: 531050, training_loss: 2.83842e-02
I0210 16:52:25.318463 22542570456896 run_lib.py:133] step: 531100, training_loss: 2.51717e-02
I0210 16:52:25.483376 22542570456896 run_lib.py:146] step: 531100, eval_loss: 3.11913e-02
I0210 16:52:42.897236 22542570456896 run_lib.py:133] step: 531150, training_loss: 2.96953e-02
I0210 16:53:00.341447 22542570456896 run_lib.py:133] step: 531200, training_loss: 2.67400e-02
I0210 16:53:00.497320 22542570456896 run_lib.py:146] step: 531200, eval_loss: 3.26718e-02
I0210 16:53:18.100389 22542570456896 run_lib.py:133] step: 531250, training_loss: 2.45730e-02
I0210 16:53:35.489131 22542570456896 run_lib.py:133] step: 531300, training_loss: 2.84616e-02
I0210 16:53:35.640863 22542570456896 run_lib.py:146] step: 531300, eval_loss: 2.99709e-02
I0210 16:53:53.184363 22542570456896 run_lib.py:133] step: 531350, training_loss: 3.31283e-02
I0210 16:54:10.597303 22542570456896 run_lib.py:133] step: 531400, training_loss: 2.94346e-02
I0210 16:54:10.751557 22542570456896 run_lib.py:146] step: 531400, eval_loss: 3.70237e-02
I0210 16:54:28.398254 22542570456896 run_lib.py:133] step: 531450, training_loss: 3.77639e-02
I0210 16:54:45.821857 22542570456896 run_lib.py:133] step: 531500, training_loss: 2.67557e-02
I0210 16:54:45.990451 22542570456896 run_lib.py:146] step: 531500, eval_loss: 2.60127e-02
I0210 16:55:03.566007 22542570456896 run_lib.py:133] step: 531550, training_loss: 2.52945e-02
I0210 16:55:20.986496 22542570456896 run_lib.py:133] step: 531600, training_loss: 2.95341e-02
I0210 16:55:21.141393 22542570456896 run_lib.py:146] step: 531600, eval_loss: 3.69937e-02
I0210 16:55:38.598861 22542570456896 run_lib.py:133] step: 531650, training_loss: 2.67856e-02
I0210 16:55:56.173377 22542570456896 run_lib.py:133] step: 531700, training_loss: 2.61515e-02
I0210 16:55:56.335098 22542570456896 run_lib.py:146] step: 531700, eval_loss: 3.34160e-02
I0210 16:56:13.756374 22542570456896 run_lib.py:133] step: 531750, training_loss: 2.36256e-02
I0210 16:56:31.165974 22542570456896 run_lib.py:133] step: 531800, training_loss: 3.13000e-02
I0210 16:56:31.316894 22542570456896 run_lib.py:146] step: 531800, eval_loss: 3.07432e-02
I0210 16:56:48.921920 22542570456896 run_lib.py:133] step: 531850, training_loss: 3.47730e-02
I0210 16:57:06.318446 22542570456896 run_lib.py:133] step: 531900, training_loss: 2.94279e-02
I0210 16:57:06.472272 22542570456896 run_lib.py:146] step: 531900, eval_loss: 2.69104e-02
I0210 16:57:24.017499 22542570456896 run_lib.py:133] step: 531950, training_loss: 3.15896e-02
I0210 16:57:41.489995 22542570456896 run_lib.py:133] step: 532000, training_loss: 2.83119e-02
I0210 16:57:41.649328 22542570456896 run_lib.py:146] step: 532000, eval_loss: 3.53225e-02
I0210 16:57:59.070535 22542570456896 run_lib.py:133] step: 532050, training_loss: 2.98211e-02
I0210 16:58:16.688321 22542570456896 run_lib.py:133] step: 532100, training_loss: 3.10979e-02
I0210 16:58:16.852306 22542570456896 run_lib.py:146] step: 532100, eval_loss: 2.73867e-02
I0210 16:58:34.262723 22542570456896 run_lib.py:133] step: 532150, training_loss: 2.59275e-02
I0210 16:58:51.648885 22542570456896 run_lib.py:133] step: 532200, training_loss: 2.67077e-02
I0210 16:58:51.807317 22542570456896 run_lib.py:146] step: 532200, eval_loss: 2.71542e-02
I0210 16:59:09.230893 22542570456896 run_lib.py:133] step: 532250, training_loss: 2.47389e-02
I0210 16:59:26.898512 22542570456896 run_lib.py:133] step: 532300, training_loss: 3.31098e-02
I0210 16:59:27.052617 22542570456896 run_lib.py:146] step: 532300, eval_loss: 3.55131e-02
I0210 16:59:44.476161 22542570456896 run_lib.py:133] step: 532350, training_loss: 2.95031e-02
I0210 17:00:01.958190 22542570456896 run_lib.py:133] step: 532400, training_loss: 3.60347e-02
I0210 17:00:02.113240 22542570456896 run_lib.py:146] step: 532400, eval_loss: 3.04570e-02
I0210 17:00:19.520945 22542570456896 run_lib.py:133] step: 532450, training_loss: 2.35226e-02
I0210 17:00:36.962460 22542570456896 run_lib.py:133] step: 532500, training_loss: 2.67331e-02
I0210 17:00:37.124273 22542570456896 run_lib.py:146] step: 532500, eval_loss: 2.85555e-02
I0210 17:00:54.753098 22542570456896 run_lib.py:133] step: 532550, training_loss: 2.12535e-02
I0210 17:01:12.318999 22542570456896 run_lib.py:133] step: 532600, training_loss: 3.11801e-02
I0210 17:01:12.473608 22542570456896 run_lib.py:146] step: 532600, eval_loss: 3.49539e-02
I0210 17:01:29.852205 22542570456896 run_lib.py:133] step: 532650, training_loss: 2.62385e-02
I0210 17:01:47.252358 22542570456896 run_lib.py:133] step: 532700, training_loss: 2.46535e-02
I0210 17:01:47.406255 22542570456896 run_lib.py:146] step: 532700, eval_loss: 2.39146e-02
I0210 17:02:04.935205 22542570456896 run_lib.py:133] step: 532750, training_loss: 3.03870e-02
I0210 17:02:22.408301 22542570456896 run_lib.py:133] step: 532800, training_loss: 2.17953e-02
I0210 17:02:22.560246 22542570456896 run_lib.py:146] step: 532800, eval_loss: 3.85491e-02
I0210 17:02:40.100100 22542570456896 run_lib.py:133] step: 532850, training_loss: 3.55159e-02
I0210 17:02:57.534823 22542570456896 run_lib.py:133] step: 532900, training_loss: 2.58593e-02
I0210 17:02:57.695068 22542570456896 run_lib.py:146] step: 532900, eval_loss: 2.95822e-02
I0210 17:03:15.317811 22542570456896 run_lib.py:133] step: 532950, training_loss: 2.73643e-02
I0210 17:03:32.740978 22542570456896 run_lib.py:133] step: 533000, training_loss: 2.85243e-02
I0210 17:03:32.899348 22542570456896 run_lib.py:146] step: 533000, eval_loss: 3.23331e-02
I0210 17:03:50.362070 22542570456896 run_lib.py:133] step: 533050, training_loss: 3.78390e-02
I0210 17:04:07.868062 22542570456896 run_lib.py:133] step: 533100, training_loss: 1.91411e-02
I0210 17:04:08.022503 22542570456896 run_lib.py:146] step: 533100, eval_loss: 2.05730e-02
I0210 17:04:25.423063 22542570456896 run_lib.py:133] step: 533150, training_loss: 2.15058e-02
I0210 17:04:43.028608 22542570456896 run_lib.py:133] step: 533200, training_loss: 2.64013e-02
I0210 17:04:43.183595 22542570456896 run_lib.py:146] step: 533200, eval_loss: 2.44595e-02
I0210 17:05:00.611643 22542570456896 run_lib.py:133] step: 533250, training_loss: 2.85092e-02
I0210 17:05:18.006058 22542570456896 run_lib.py:133] step: 533300, training_loss: 3.23023e-02
I0210 17:05:18.160366 22542570456896 run_lib.py:146] step: 533300, eval_loss: 3.28002e-02
I0210 17:05:35.738682 22542570456896 run_lib.py:133] step: 533350, training_loss: 3.14844e-02
I0210 17:05:53.127797 22542570456896 run_lib.py:133] step: 533400, training_loss: 2.76871e-02
I0210 17:05:53.291224 22542570456896 run_lib.py:146] step: 533400, eval_loss: 2.36412e-02
I0210 17:06:10.740864 22542570456896 run_lib.py:133] step: 533450, training_loss: 2.41288e-02
I0210 17:06:28.328684 22542570456896 run_lib.py:133] step: 533500, training_loss: 2.84566e-02
I0210 17:06:28.485635 22542570456896 run_lib.py:146] step: 533500, eval_loss: 2.82739e-02
I0210 17:06:45.881672 22542570456896 run_lib.py:133] step: 533550, training_loss: 2.39348e-02
I0210 17:07:03.283350 22542570456896 run_lib.py:133] step: 533600, training_loss: 2.30836e-02
I0210 17:07:03.597609 22542570456896 run_lib.py:146] step: 533600, eval_loss: 2.18364e-02
I0210 17:07:20.989568 22542570456896 run_lib.py:133] step: 533650, training_loss: 2.96119e-02
I0210 17:07:38.379097 22542570456896 run_lib.py:133] step: 533700, training_loss: 3.01850e-02
I0210 17:07:38.531899 22542570456896 run_lib.py:146] step: 533700, eval_loss: 3.03262e-02
I0210 17:07:55.999489 22542570456896 run_lib.py:133] step: 533750, training_loss: 3.41939e-02
I0210 17:08:13.376869 22542570456896 run_lib.py:133] step: 533800, training_loss: 3.13104e-02
I0210 17:08:13.531202 22542570456896 run_lib.py:146] step: 533800, eval_loss: 2.17592e-02
I0210 17:08:31.082592 22542570456896 run_lib.py:133] step: 533850, training_loss: 2.48800e-02
I0210 17:08:48.525598 22542570456896 run_lib.py:133] step: 533900, training_loss: 3.16573e-02
I0210 17:08:48.690354 22542570456896 run_lib.py:146] step: 533900, eval_loss: 2.64680e-02
I0210 17:09:06.113854 22542570456896 run_lib.py:133] step: 533950, training_loss: 2.28239e-02
I0210 17:09:23.566070 22542570456896 run_lib.py:133] step: 534000, training_loss: 2.92054e-02
I0210 17:09:23.732287 22542570456896 run_lib.py:146] step: 534000, eval_loss: 3.08446e-02
I0210 17:09:41.373416 22542570456896 run_lib.py:133] step: 534050, training_loss: 2.79539e-02
I0210 17:09:58.833266 22542570456896 run_lib.py:133] step: 534100, training_loss: 2.28821e-02
I0210 17:09:58.994554 22542570456896 run_lib.py:146] step: 534100, eval_loss: 3.11986e-02
I0210 17:10:16.426971 22542570456896 run_lib.py:133] step: 534150, training_loss: 2.41126e-02
I0210 17:10:33.830288 22542570456896 run_lib.py:133] step: 534200, training_loss: 2.95550e-02
I0210 17:10:33.989280 22542570456896 run_lib.py:146] step: 534200, eval_loss: 3.28342e-02
I0210 17:10:51.562054 22542570456896 run_lib.py:133] step: 534250, training_loss: 2.53879e-02
I0210 17:11:08.985537 22542570456896 run_lib.py:133] step: 534300, training_loss: 2.85418e-02
I0210 17:11:09.155470 22542570456896 run_lib.py:146] step: 534300, eval_loss: 3.02023e-02
I0210 17:11:26.777011 22542570456896 run_lib.py:133] step: 534350, training_loss: 2.50182e-02
I0210 17:11:44.201708 22542570456896 run_lib.py:133] step: 534400, training_loss: 2.61431e-02
I0210 17:11:44.359556 22542570456896 run_lib.py:146] step: 534400, eval_loss: 2.74820e-02
I0210 17:12:01.867619 22542570456896 run_lib.py:133] step: 534450, training_loss: 2.31084e-02
I0210 17:12:19.261949 22542570456896 run_lib.py:133] step: 534500, training_loss: 2.70722e-02
I0210 17:12:19.428310 22542570456896 run_lib.py:146] step: 534500, eval_loss: 3.20921e-02
I0210 17:12:36.879203 22542570456896 run_lib.py:133] step: 534550, training_loss: 2.43884e-02
I0210 17:12:54.490323 22542570456896 run_lib.py:133] step: 534600, training_loss: 2.78889e-02
I0210 17:12:54.645513 22542570456896 run_lib.py:146] step: 534600, eval_loss: 3.06942e-02
I0210 17:13:12.093918 22542570456896 run_lib.py:133] step: 534650, training_loss: 2.78665e-02
I0210 17:13:29.661231 22542570456896 run_lib.py:133] step: 534700, training_loss: 3.13948e-02
I0210 17:13:29.817319 22542570456896 run_lib.py:146] step: 534700, eval_loss: 2.50164e-02
I0210 17:13:47.229106 22542570456896 run_lib.py:133] step: 534750, training_loss: 2.56991e-02
I0210 17:14:04.657008 22542570456896 run_lib.py:133] step: 534800, training_loss: 2.37103e-02
I0210 17:14:04.837320 22542570456896 run_lib.py:146] step: 534800, eval_loss: 3.03338e-02
I0210 17:14:22.486704 22542570456896 run_lib.py:133] step: 534850, training_loss: 3.08043e-02
I0210 17:14:39.914958 22542570456896 run_lib.py:133] step: 534900, training_loss: 2.48295e-02
I0210 17:14:40.072405 22542570456896 run_lib.py:146] step: 534900, eval_loss: 2.95708e-02
I0210 17:14:57.488054 22542570456896 run_lib.py:133] step: 534950, training_loss: 2.56130e-02
I0210 17:15:14.892353 22542570456896 run_lib.py:133] step: 535000, training_loss: 2.60990e-02
I0210 17:15:15.055982 22542570456896 run_lib.py:146] step: 535000, eval_loss: 2.40852e-02
I0210 17:15:32.616716 22542570456896 run_lib.py:133] step: 535050, training_loss: 2.76837e-02
I0210 17:15:50.053131 22542570456896 run_lib.py:133] step: 535100, training_loss: 2.26122e-02
I0210 17:15:50.214228 22542570456896 run_lib.py:146] step: 535100, eval_loss: 2.36637e-02
I0210 17:16:07.790607 22542570456896 run_lib.py:133] step: 535150, training_loss: 2.57718e-02
I0210 17:16:25.212506 22542570456896 run_lib.py:133] step: 535200, training_loss: 3.23014e-02
I0210 17:16:25.360893 22542570456896 run_lib.py:146] step: 535200, eval_loss: 3.04346e-02
I0210 17:16:42.771577 22542570456896 run_lib.py:133] step: 535250, training_loss: 2.89464e-02
I0210 17:17:00.209184 22542570456896 run_lib.py:133] step: 535300, training_loss: 3.52444e-02
I0210 17:17:00.366539 22542570456896 run_lib.py:146] step: 535300, eval_loss: 3.49312e-02
I0210 17:17:17.935062 22542570456896 run_lib.py:133] step: 535350, training_loss: 3.12481e-02
I0210 17:17:35.419632 22542570456896 run_lib.py:133] step: 535400, training_loss: 2.54332e-02
I0210 17:17:35.596344 22542570456896 run_lib.py:146] step: 535400, eval_loss: 2.37841e-02
I0210 17:17:53.054841 22542570456896 run_lib.py:133] step: 535450, training_loss: 2.23600e-02
I0210 17:18:10.484259 22542570456896 run_lib.py:133] step: 535500, training_loss: 2.84734e-02
I0210 17:18:10.640035 22542570456896 run_lib.py:146] step: 535500, eval_loss: 2.67392e-02
I0210 17:18:28.227077 22542570456896 run_lib.py:133] step: 535550, training_loss: 2.36888e-02
I0210 17:18:45.590212 22542570456896 run_lib.py:133] step: 535600, training_loss: 2.88037e-02
I0210 17:18:45.748375 22542570456896 run_lib.py:146] step: 535600, eval_loss: 3.17893e-02
I0210 17:19:03.265393 22542570456896 run_lib.py:133] step: 535650, training_loss: 3.07173e-02
I0210 17:19:20.736541 22542570456896 run_lib.py:133] step: 535700, training_loss: 3.38991e-02
I0210 17:19:20.911481 22542570456896 run_lib.py:146] step: 535700, eval_loss: 2.37003e-02
I0210 17:19:38.474029 22542570456896 run_lib.py:133] step: 535750, training_loss: 2.47938e-02
I0210 17:19:55.920605 22542570456896 run_lib.py:133] step: 535800, training_loss: 2.91451e-02
I0210 17:19:56.081341 22542570456896 run_lib.py:146] step: 535800, eval_loss: 3.53084e-02
I0210 17:20:13.693085 22542570456896 run_lib.py:133] step: 535850, training_loss: 2.34831e-02
I0210 17:20:31.113784 22542570456896 run_lib.py:133] step: 535900, training_loss: 3.42116e-02
I0210 17:20:31.269400 22542570456896 run_lib.py:146] step: 535900, eval_loss: 2.31356e-02
I0210 17:20:48.704612 22542570456896 run_lib.py:133] step: 535950, training_loss: 3.35093e-02
I0210 17:21:06.283803 22542570456896 run_lib.py:133] step: 536000, training_loss: 3.55818e-02
I0210 17:21:06.439636 22542570456896 run_lib.py:146] step: 536000, eval_loss: 2.94271e-02
I0210 17:21:23.870524 22542570456896 run_lib.py:133] step: 536050, training_loss: 3.21365e-02
I0210 17:21:41.301707 22542570456896 run_lib.py:133] step: 536100, training_loss: 2.76421e-02
I0210 17:21:41.453309 22542570456896 run_lib.py:146] step: 536100, eval_loss: 2.92844e-02
I0210 17:21:59.058028 22542570456896 run_lib.py:133] step: 536150, training_loss: 2.92670e-02
I0210 17:22:16.606768 22542570456896 run_lib.py:133] step: 536200, training_loss: 3.02219e-02
I0210 17:22:16.764125 22542570456896 run_lib.py:146] step: 536200, eval_loss: 2.81545e-02
I0210 17:22:34.209019 22542570456896 run_lib.py:133] step: 536250, training_loss: 2.65101e-02
I0210 17:22:51.680998 22542570456896 run_lib.py:133] step: 536300, training_loss: 2.84544e-02
I0210 17:22:51.839326 22542570456896 run_lib.py:146] step: 536300, eval_loss: 2.53220e-02
I0210 17:23:09.215391 22542570456896 run_lib.py:133] step: 536350, training_loss: 2.45285e-02
I0210 17:23:26.739806 22542570456896 run_lib.py:133] step: 536400, training_loss: 2.51097e-02
I0210 17:23:26.894310 22542570456896 run_lib.py:146] step: 536400, eval_loss: 3.07899e-02
I0210 17:23:44.279748 22542570456896 run_lib.py:133] step: 536450, training_loss: 2.38003e-02
I0210 17:24:01.660973 22542570456896 run_lib.py:133] step: 536500, training_loss: 2.83427e-02
I0210 17:24:01.849051 22542570456896 run_lib.py:146] step: 536500, eval_loss: 2.77117e-02
I0210 17:24:19.329040 22542570456896 run_lib.py:133] step: 536550, training_loss: 3.29225e-02
I0210 17:24:36.940161 22542570456896 run_lib.py:133] step: 536600, training_loss: 2.23336e-02
I0210 17:24:37.093600 22542570456896 run_lib.py:146] step: 536600, eval_loss: 2.70552e-02
I0210 17:24:54.524283 22542570456896 run_lib.py:133] step: 536650, training_loss: 2.96900e-02
I0210 17:25:12.003685 22542570456896 run_lib.py:133] step: 536700, training_loss: 3.05626e-02
I0210 17:25:12.161691 22542570456896 run_lib.py:146] step: 536700, eval_loss: 2.96940e-02
I0210 17:25:29.516105 22542570456896 run_lib.py:133] step: 536750, training_loss: 2.66096e-02
I0210 17:25:46.874756 22542570456896 run_lib.py:133] step: 536800, training_loss: 2.96799e-02
I0210 17:25:47.043353 22542570456896 run_lib.py:146] step: 536800, eval_loss: 2.45957e-02
I0210 17:26:04.621141 22542570456896 run_lib.py:133] step: 536850, training_loss: 3.52945e-02
I0210 17:26:22.159019 22542570456896 run_lib.py:133] step: 536900, training_loss: 3.43498e-02
I0210 17:26:22.314208 22542570456896 run_lib.py:146] step: 536900, eval_loss: 3.28650e-02
I0210 17:26:39.751697 22542570456896 run_lib.py:133] step: 536950, training_loss: 3.27189e-02
I0210 17:26:57.092681 22542570456896 run_lib.py:133] step: 537000, training_loss: 2.65275e-02
I0210 17:26:57.245038 22542570456896 run_lib.py:146] step: 537000, eval_loss: 3.10865e-02
I0210 17:27:14.709220 22542570456896 run_lib.py:133] step: 537050, training_loss: 2.43934e-02
I0210 17:27:32.107204 22542570456896 run_lib.py:133] step: 537100, training_loss: 2.70812e-02
I0210 17:27:32.272644 22542570456896 run_lib.py:146] step: 537100, eval_loss: 3.22829e-02
I0210 17:27:49.883685 22542570456896 run_lib.py:133] step: 537150, training_loss: 2.58332e-02
I0210 17:28:07.267522 22542570456896 run_lib.py:133] step: 537200, training_loss: 2.77149e-02
I0210 17:28:07.424278 22542570456896 run_lib.py:146] step: 537200, eval_loss: 2.59687e-02
I0210 17:28:24.969006 22542570456896 run_lib.py:133] step: 537250, training_loss: 2.46634e-02
I0210 17:28:42.336600 22542570456896 run_lib.py:133] step: 537300, training_loss: 3.33885e-02
I0210 17:28:42.491253 22542570456896 run_lib.py:146] step: 537300, eval_loss: 2.86172e-02
I0210 17:28:59.928295 22542570456896 run_lib.py:133] step: 537350, training_loss: 2.56470e-02
I0210 17:29:17.531956 22542570456896 run_lib.py:133] step: 537400, training_loss: 2.55563e-02
I0210 17:29:17.692982 22542570456896 run_lib.py:146] step: 537400, eval_loss: 3.26956e-02
I0210 17:29:35.177269 22542570456896 run_lib.py:133] step: 537450, training_loss: 3.10067e-02
I0210 17:29:52.749629 22542570456896 run_lib.py:133] step: 537500, training_loss: 2.49158e-02
I0210 17:29:52.899260 22542570456896 run_lib.py:146] step: 537500, eval_loss: 2.79315e-02
I0210 17:30:10.284685 22542570456896 run_lib.py:133] step: 537550, training_loss: 3.04529e-02
I0210 17:30:27.688762 22542570456896 run_lib.py:133] step: 537600, training_loss: 2.71320e-02
I0210 17:30:27.843369 22542570456896 run_lib.py:146] step: 537600, eval_loss: 3.45216e-02
I0210 17:30:45.387910 22542570456896 run_lib.py:133] step: 537650, training_loss: 2.22313e-02
I0210 17:31:02.840041 22542570456896 run_lib.py:133] step: 537700, training_loss: 3.41965e-02
I0210 17:31:03.007356 22542570456896 run_lib.py:146] step: 537700, eval_loss: 3.09360e-02
I0210 17:31:20.401101 22542570456896 run_lib.py:133] step: 537750, training_loss: 2.92503e-02
I0210 17:31:37.971174 22542570456896 run_lib.py:133] step: 537800, training_loss: 2.55287e-02
I0210 17:31:38.128201 22542570456896 run_lib.py:146] step: 537800, eval_loss: 2.56246e-02
I0210 17:31:55.534819 22542570456896 run_lib.py:133] step: 537850, training_loss: 3.16706e-02
I0210 17:32:12.886287 22542570456896 run_lib.py:133] step: 537900, training_loss: 3.16218e-02
I0210 17:32:13.041020 22542570456896 run_lib.py:146] step: 537900, eval_loss: 2.73005e-02
I0210 17:32:30.486713 22542570456896 run_lib.py:133] step: 537950, training_loss: 3.58949e-02
I0210 17:32:48.048347 22542570456896 run_lib.py:133] step: 538000, training_loss: 2.66125e-02
I0210 17:32:48.202544 22542570456896 run_lib.py:146] step: 538000, eval_loss: 3.33268e-02
I0210 17:33:05.616158 22542570456896 run_lib.py:133] step: 538050, training_loss: 2.82392e-02
I0210 17:33:23.012394 22542570456896 run_lib.py:133] step: 538100, training_loss: 3.66888e-02
I0210 17:33:23.167375 22542570456896 run_lib.py:146] step: 538100, eval_loss: 2.27660e-02
I0210 17:33:40.746878 22542570456896 run_lib.py:133] step: 538150, training_loss: 3.58502e-02
I0210 17:33:58.185864 22542570456896 run_lib.py:133] step: 538200, training_loss: 2.78985e-02
I0210 17:33:58.353829 22542570456896 run_lib.py:146] step: 538200, eval_loss: 3.11933e-02
I0210 17:34:15.763042 22542570456896 run_lib.py:133] step: 538250, training_loss: 2.78508e-02
I0210 17:34:33.177361 22542570456896 run_lib.py:133] step: 538300, training_loss: 2.72466e-02
I0210 17:34:33.336597 22542570456896 run_lib.py:146] step: 538300, eval_loss: 2.85596e-02
I0210 17:34:50.891184 22542570456896 run_lib.py:133] step: 538350, training_loss: 3.16262e-02
I0210 17:35:08.281003 22542570456896 run_lib.py:133] step: 538400, training_loss: 2.94046e-02
I0210 17:35:08.435956 22542570456896 run_lib.py:146] step: 538400, eval_loss: 2.45821e-02
I0210 17:35:26.038002 22542570456896 run_lib.py:133] step: 538450, training_loss: 2.82733e-02
I0210 17:35:43.460129 22542570456896 run_lib.py:133] step: 538500, training_loss: 3.43505e-02
I0210 17:35:43.613443 22542570456896 run_lib.py:146] step: 538500, eval_loss: 2.73012e-02
I0210 17:36:01.180703 22542570456896 run_lib.py:133] step: 538550, training_loss: 2.43516e-02
I0210 17:36:18.583243 22542570456896 run_lib.py:133] step: 538600, training_loss: 2.64886e-02
I0210 17:36:18.748351 22542570456896 run_lib.py:146] step: 538600, eval_loss: 2.85123e-02
I0210 17:36:36.306467 22542570456896 run_lib.py:133] step: 538650, training_loss: 3.06258e-02
I0210 17:36:53.694387 22542570456896 run_lib.py:133] step: 538700, training_loss: 2.80831e-02
I0210 17:36:53.853590 22542570456896 run_lib.py:146] step: 538700, eval_loss: 2.67028e-02
I0210 17:37:11.241590 22542570456896 run_lib.py:133] step: 538750, training_loss: 3.02312e-02
I0210 17:37:28.826888 22542570456896 run_lib.py:133] step: 538800, training_loss: 2.68659e-02
I0210 17:37:28.990388 22542570456896 run_lib.py:146] step: 538800, eval_loss: 2.58696e-02
I0210 17:37:46.401933 22542570456896 run_lib.py:133] step: 538850, training_loss: 2.65238e-02
I0210 17:38:03.860272 22542570456896 run_lib.py:133] step: 538900, training_loss: 2.89645e-02
I0210 17:38:04.012126 22542570456896 run_lib.py:146] step: 538900, eval_loss: 3.17445e-02
I0210 17:38:21.611897 22542570456896 run_lib.py:133] step: 538950, training_loss: 2.53022e-02
I0210 17:38:39.045951 22542570456896 run_lib.py:133] step: 539000, training_loss: 2.82695e-02
I0210 17:38:39.199316 22542570456896 run_lib.py:146] step: 539000, eval_loss: 3.30452e-02
I0210 17:38:56.762790 22542570456896 run_lib.py:133] step: 539050, training_loss: 3.01300e-02
I0210 17:39:14.177295 22542570456896 run_lib.py:133] step: 539100, training_loss: 3.04885e-02
I0210 17:39:14.354334 22542570456896 run_lib.py:146] step: 539100, eval_loss: 2.14700e-02
I0210 17:39:31.777353 22542570456896 run_lib.py:133] step: 539150, training_loss: 2.27592e-02
I0210 17:39:49.351758 22542570456896 run_lib.py:133] step: 539200, training_loss: 2.55269e-02
I0210 17:39:49.507504 22542570456896 run_lib.py:146] step: 539200, eval_loss: 2.68107e-02
I0210 17:40:06.896117 22542570456896 run_lib.py:133] step: 539250, training_loss: 3.02726e-02
I0210 17:40:24.285769 22542570456896 run_lib.py:133] step: 539300, training_loss: 2.26692e-02
I0210 17:40:24.438944 22542570456896 run_lib.py:146] step: 539300, eval_loss: 2.54730e-02
I0210 17:40:41.816099 22542570456896 run_lib.py:133] step: 539350, training_loss: 2.55104e-02
I0210 17:40:59.399357 22542570456896 run_lib.py:133] step: 539400, training_loss: 2.22061e-02
I0210 17:40:59.552068 22542570456896 run_lib.py:146] step: 539400, eval_loss: 2.97005e-02
I0210 17:41:16.989438 22542570456896 run_lib.py:133] step: 539450, training_loss: 3.45548e-02
I0210 17:41:34.487309 22542570456896 run_lib.py:133] step: 539500, training_loss: 3.48569e-02
I0210 17:41:34.641360 22542570456896 run_lib.py:146] step: 539500, eval_loss: 2.70998e-02
I0210 17:41:52.039279 22542570456896 run_lib.py:133] step: 539550, training_loss: 3.15988e-02
I0210 17:42:09.448528 22542570456896 run_lib.py:133] step: 539600, training_loss: 3.35721e-02
I0210 17:42:09.607470 22542570456896 run_lib.py:146] step: 539600, eval_loss: 2.45570e-02
I0210 17:42:27.119087 22542570456896 run_lib.py:133] step: 539650, training_loss: 2.10104e-02
I0210 17:42:44.601349 22542570456896 run_lib.py:133] step: 539700, training_loss: 2.57266e-02
I0210 17:42:44.771388 22542570456896 run_lib.py:146] step: 539700, eval_loss: 3.32470e-02
I0210 17:43:02.226559 22542570456896 run_lib.py:133] step: 539750, training_loss: 2.91608e-02
I0210 17:43:19.634918 22542570456896 run_lib.py:133] step: 539800, training_loss: 2.10717e-02
I0210 17:43:19.786360 22542570456896 run_lib.py:146] step: 539800, eval_loss: 3.15728e-02
I0210 17:43:37.364838 22542570456896 run_lib.py:133] step: 539850, training_loss: 2.66841e-02
I0210 17:43:54.777880 22542570456896 run_lib.py:133] step: 539900, training_loss: 2.63178e-02
I0210 17:43:54.929314 22542570456896 run_lib.py:146] step: 539900, eval_loss: 3.11878e-02
I0210 17:44:12.421939 22542570456896 run_lib.py:133] step: 539950, training_loss: 3.23349e-02
I0210 17:44:29.866804 22542570456896 run_lib.py:133] step: 540000, training_loss: 2.38796e-02
I0210 17:44:30.912096 22542570456896 run_lib.py:146] step: 540000, eval_loss: 3.06298e-02
I0210 17:44:51.310441 22542570456896 run_lib.py:133] step: 540050, training_loss: 2.46319e-02
I0210 17:45:08.678399 22542570456896 run_lib.py:133] step: 540100, training_loss: 2.80030e-02
I0210 17:45:08.836544 22542570456896 run_lib.py:146] step: 540100, eval_loss: 2.53270e-02
I0210 17:45:26.242714 22542570456896 run_lib.py:133] step: 540150, training_loss: 2.68918e-02
I0210 17:45:43.664312 22542570456896 run_lib.py:133] step: 540200, training_loss: 3.18539e-02
I0210 17:45:43.819423 22542570456896 run_lib.py:146] step: 540200, eval_loss: 3.41036e-02
I0210 17:46:01.193452 22542570456896 run_lib.py:133] step: 540250, training_loss: 3.43371e-02
I0210 17:46:18.616667 22542570456896 run_lib.py:133] step: 540300, training_loss: 2.94011e-02
I0210 17:46:18.771444 22542570456896 run_lib.py:146] step: 540300, eval_loss: 2.52657e-02
I0210 17:46:36.282813 22542570456896 run_lib.py:133] step: 540350, training_loss: 3.49371e-02
I0210 17:46:53.635909 22542570456896 run_lib.py:133] step: 540400, training_loss: 3.17435e-02
I0210 17:46:53.794093 22542570456896 run_lib.py:146] step: 540400, eval_loss: 3.05091e-02
I0210 17:47:11.057651 22542570456896 run_lib.py:133] step: 540450, training_loss: 2.62763e-02
I0210 17:47:28.469492 22542570456896 run_lib.py:133] step: 540500, training_loss: 2.73980e-02
I0210 17:47:28.624370 22542570456896 run_lib.py:146] step: 540500, eval_loss: 3.12030e-02
I0210 17:47:46.205617 22542570456896 run_lib.py:133] step: 540550, training_loss: 3.01231e-02
I0210 17:48:03.669570 22542570456896 run_lib.py:133] step: 540600, training_loss: 2.36832e-02
I0210 17:48:03.833468 22542570456896 run_lib.py:146] step: 540600, eval_loss: 3.70992e-02
I0210 17:48:21.524742 22542570456896 run_lib.py:133] step: 540650, training_loss: 2.63164e-02
I0210 17:48:38.921128 22542570456896 run_lib.py:133] step: 540700, training_loss: 2.50424e-02
I0210 17:48:39.076332 22542570456896 run_lib.py:146] step: 540700, eval_loss: 2.57623e-02
I0210 17:48:56.618968 22542570456896 run_lib.py:133] step: 540750, training_loss: 3.24276e-02
I0210 17:49:14.021730 22542570456896 run_lib.py:133] step: 540800, training_loss: 3.65023e-02
I0210 17:49:14.190456 22542570456896 run_lib.py:146] step: 540800, eval_loss: 3.07734e-02
I0210 17:49:31.655464 22542570456896 run_lib.py:133] step: 540850, training_loss: 3.53078e-02
I0210 17:49:49.273792 22542570456896 run_lib.py:133] step: 540900, training_loss: 2.92502e-02
I0210 17:49:49.453641 22542570456896 run_lib.py:146] step: 540900, eval_loss: 3.66391e-02
I0210 17:50:06.906050 22542570456896 run_lib.py:133] step: 540950, training_loss: 2.41040e-02
I0210 17:50:24.490229 22542570456896 run_lib.py:133] step: 541000, training_loss: 3.13776e-02
I0210 17:50:24.651371 22542570456896 run_lib.py:146] step: 541000, eval_loss: 2.91652e-02
I0210 17:50:42.051221 22542570456896 run_lib.py:133] step: 541050, training_loss: 2.78737e-02
I0210 17:50:59.475642 22542570456896 run_lib.py:133] step: 541100, training_loss: 2.59524e-02
I0210 17:50:59.650305 22542570456896 run_lib.py:146] step: 541100, eval_loss: 3.56732e-02
I0210 17:51:17.284579 22542570456896 run_lib.py:133] step: 541150, training_loss: 2.96842e-02
I0210 17:51:34.744232 22542570456896 run_lib.py:133] step: 541200, training_loss: 2.04740e-02
I0210 17:51:34.899498 22542570456896 run_lib.py:146] step: 541200, eval_loss: 2.86576e-02
I0210 17:51:52.296015 22542570456896 run_lib.py:133] step: 541250, training_loss: 2.99170e-02
I0210 17:52:09.851857 22542570456896 run_lib.py:133] step: 541300, training_loss: 2.26598e-02
I0210 17:52:10.007308 22542570456896 run_lib.py:146] step: 541300, eval_loss: 2.66704e-02
I0210 17:52:27.444641 22542570456896 run_lib.py:133] step: 541350, training_loss: 3.00341e-02
I0210 17:52:44.887458 22542570456896 run_lib.py:133] step: 541400, training_loss: 2.52202e-02
I0210 17:52:45.183531 22542570456896 run_lib.py:146] step: 541400, eval_loss: 2.88312e-02
I0210 17:53:02.641701 22542570456896 run_lib.py:133] step: 541450, training_loss: 2.70156e-02
I0210 17:53:20.096832 22542570456896 run_lib.py:133] step: 541500, training_loss: 2.42914e-02
I0210 17:53:20.254130 22542570456896 run_lib.py:146] step: 541500, eval_loss: 2.93988e-02
I0210 17:53:37.652890 22542570456896 run_lib.py:133] step: 541550, training_loss: 2.50923e-02
I0210 17:53:55.060776 22542570456896 run_lib.py:133] step: 541600, training_loss: 3.17635e-02
I0210 17:53:55.223592 22542570456896 run_lib.py:146] step: 541600, eval_loss: 2.63256e-02
I0210 17:54:12.808936 22542570456896 run_lib.py:133] step: 541650, training_loss: 3.58080e-02
I0210 17:54:30.306397 22542570456896 run_lib.py:133] step: 541700, training_loss: 2.86401e-02
I0210 17:54:30.462807 22542570456896 run_lib.py:146] step: 541700, eval_loss: 3.06203e-02
I0210 17:54:47.894902 22542570456896 run_lib.py:133] step: 541750, training_loss: 2.88161e-02
I0210 17:55:05.303603 22542570456896 run_lib.py:133] step: 541800, training_loss: 2.18009e-02
I0210 17:55:05.458285 22542570456896 run_lib.py:146] step: 541800, eval_loss: 3.14020e-02
I0210 17:55:23.045221 22542570456896 run_lib.py:133] step: 541850, training_loss: 2.75003e-02
I0210 17:55:40.519902 22542570456896 run_lib.py:133] step: 541900, training_loss: 1.81319e-02
I0210 17:55:40.672404 22542570456896 run_lib.py:146] step: 541900, eval_loss: 2.57973e-02
I0210 17:55:58.128669 22542570456896 run_lib.py:133] step: 541950, training_loss: 3.06054e-02
I0210 17:56:15.586252 22542570456896 run_lib.py:133] step: 542000, training_loss: 3.31531e-02
I0210 17:56:15.748681 22542570456896 run_lib.py:146] step: 542000, eval_loss: 3.05424e-02
I0210 17:56:33.350595 22542570456896 run_lib.py:133] step: 542050, training_loss: 2.65249e-02
I0210 17:56:50.745690 22542570456896 run_lib.py:133] step: 542100, training_loss: 2.61374e-02
I0210 17:56:50.898936 22542570456896 run_lib.py:146] step: 542100, eval_loss: 2.63794e-02
I0210 17:57:08.498555 22542570456896 run_lib.py:133] step: 542150, training_loss: 2.79127e-02
I0210 17:57:25.876771 22542570456896 run_lib.py:133] step: 542200, training_loss: 2.86698e-02
I0210 17:57:26.048143 22542570456896 run_lib.py:146] step: 542200, eval_loss: 2.88009e-02
I0210 17:57:43.639365 22542570456896 run_lib.py:133] step: 542250, training_loss: 3.88326e-02
I0210 17:58:01.070192 22542570456896 run_lib.py:133] step: 542300, training_loss: 2.66773e-02
I0210 17:58:01.224003 22542570456896 run_lib.py:146] step: 542300, eval_loss: 3.56181e-02
I0210 17:58:18.655867 22542570456896 run_lib.py:133] step: 542350, training_loss: 3.14922e-02
I0210 17:58:36.386684 22542570456896 run_lib.py:133] step: 542400, training_loss: 2.97188e-02
I0210 17:58:36.548412 22542570456896 run_lib.py:146] step: 542400, eval_loss: 3.15553e-02
I0210 17:58:53.936362 22542570456896 run_lib.py:133] step: 542450, training_loss: 2.34510e-02
I0210 17:59:11.487929 22542570456896 run_lib.py:133] step: 542500, training_loss: 3.07329e-02
I0210 17:59:11.664382 22542570456896 run_lib.py:146] step: 542500, eval_loss: 1.97563e-02
I0210 17:59:29.112994 22542570456896 run_lib.py:133] step: 542550, training_loss: 2.43336e-02
I0210 17:59:46.517305 22542570456896 run_lib.py:133] step: 542600, training_loss: 3.36864e-02
I0210 17:59:46.676523 22542570456896 run_lib.py:146] step: 542600, eval_loss: 2.71984e-02
I0210 18:00:04.264314 22542570456896 run_lib.py:133] step: 542650, training_loss: 3.24302e-02
I0210 18:00:21.681098 22542570456896 run_lib.py:133] step: 542700, training_loss: 3.06016e-02
I0210 18:00:21.832011 22542570456896 run_lib.py:146] step: 542700, eval_loss: 2.79684e-02
I0210 18:00:39.288171 22542570456896 run_lib.py:133] step: 542750, training_loss: 2.61748e-02
I0210 18:00:56.739372 22542570456896 run_lib.py:133] step: 542800, training_loss: 3.02674e-02
I0210 18:00:56.893520 22542570456896 run_lib.py:146] step: 542800, eval_loss: 3.16825e-02
I0210 18:01:14.531135 22542570456896 run_lib.py:133] step: 542850, training_loss: 2.68875e-02
I0210 18:01:31.909120 22542570456896 run_lib.py:133] step: 542900, training_loss: 2.37608e-02
I0210 18:01:32.064332 22542570456896 run_lib.py:146] step: 542900, eval_loss: 2.73305e-02
I0210 18:01:49.502968 22542570456896 run_lib.py:133] step: 542950, training_loss: 2.58847e-02
I0210 18:02:06.911249 22542570456896 run_lib.py:133] step: 543000, training_loss: 2.87341e-02
I0210 18:02:07.070568 22542570456896 run_lib.py:146] step: 543000, eval_loss: 2.67409e-02
I0210 18:02:24.507172 22542570456896 run_lib.py:133] step: 543050, training_loss: 2.84721e-02
I0210 18:02:41.956122 22542570456896 run_lib.py:133] step: 543100, training_loss: 2.75532e-02
I0210 18:02:42.112430 22542570456896 run_lib.py:146] step: 543100, eval_loss: 2.97168e-02
I0210 18:02:59.707064 22542570456896 run_lib.py:133] step: 543150, training_loss: 2.77187e-02
I0210 18:03:17.132827 22542570456896 run_lib.py:133] step: 543200, training_loss: 2.72395e-02
I0210 18:03:17.295223 22542570456896 run_lib.py:146] step: 543200, eval_loss: 2.71263e-02
I0210 18:03:34.663748 22542570456896 run_lib.py:133] step: 543250, training_loss: 1.94743e-02
I0210 18:03:52.091471 22542570456896 run_lib.py:133] step: 543300, training_loss: 2.91331e-02
I0210 18:03:52.254360 22542570456896 run_lib.py:146] step: 543300, eval_loss: 2.14362e-02
I0210 18:04:09.878008 22542570456896 run_lib.py:133] step: 543350, training_loss: 2.29557e-02
I0210 18:04:27.250155 22542570456896 run_lib.py:133] step: 543400, training_loss: 2.64498e-02
I0210 18:04:27.405373 22542570456896 run_lib.py:146] step: 543400, eval_loss: 3.10077e-02
I0210 18:04:44.872516 22542570456896 run_lib.py:133] step: 543450, training_loss: 2.93806e-02
I0210 18:05:02.218366 22542570456896 run_lib.py:133] step: 543500, training_loss: 2.44012e-02
I0210 18:05:02.375540 22542570456896 run_lib.py:146] step: 543500, eval_loss: 3.29086e-02
I0210 18:05:19.965110 22542570456896 run_lib.py:133] step: 543550, training_loss: 2.83824e-02
I0210 18:05:37.418976 22542570456896 run_lib.py:133] step: 543600, training_loss: 3.07523e-02
I0210 18:05:37.575040 22542570456896 run_lib.py:146] step: 543600, eval_loss: 3.03067e-02
I0210 18:05:55.113761 22542570456896 run_lib.py:133] step: 543650, training_loss: 3.13979e-02
I0210 18:06:12.533238 22542570456896 run_lib.py:133] step: 543700, training_loss: 2.66898e-02
I0210 18:06:12.684338 22542570456896 run_lib.py:146] step: 543700, eval_loss: 2.79046e-02
I0210 18:06:30.134894 22542570456896 run_lib.py:133] step: 543750, training_loss: 2.63443e-02
I0210 18:06:47.642588 22542570456896 run_lib.py:133] step: 543800, training_loss: 2.45700e-02
I0210 18:06:47.811464 22542570456896 run_lib.py:146] step: 543800, eval_loss: 2.76135e-02
I0210 18:07:05.224944 22542570456896 run_lib.py:133] step: 543850, training_loss: 2.53985e-02
I0210 18:07:22.637127 22542570456896 run_lib.py:133] step: 543900, training_loss: 2.55966e-02
I0210 18:07:22.796289 22542570456896 run_lib.py:146] step: 543900, eval_loss: 2.91542e-02
I0210 18:07:40.355255 22542570456896 run_lib.py:133] step: 543950, training_loss: 3.21581e-02
I0210 18:07:57.856276 22542570456896 run_lib.py:133] step: 544000, training_loss: 2.59522e-02
I0210 18:07:58.012443 22542570456896 run_lib.py:146] step: 544000, eval_loss: 2.58623e-02
I0210 18:08:15.408404 22542570456896 run_lib.py:133] step: 544050, training_loss: 3.06836e-02
I0210 18:08:32.810079 22542570456896 run_lib.py:133] step: 544100, training_loss: 2.24270e-02
I0210 18:08:32.978573 22542570456896 run_lib.py:146] step: 544100, eval_loss: 2.92140e-02
I0210 18:08:50.395552 22542570456896 run_lib.py:133] step: 544150, training_loss: 2.82332e-02
I0210 18:09:07.964527 22542570456896 run_lib.py:133] step: 544200, training_loss: 3.07473e-02
I0210 18:09:08.116088 22542570456896 run_lib.py:146] step: 544200, eval_loss: 2.67815e-02
I0210 18:09:25.503164 22542570456896 run_lib.py:133] step: 544250, training_loss: 3.06253e-02
I0210 18:09:42.893237 22542570456896 run_lib.py:133] step: 544300, training_loss: 2.64772e-02
I0210 18:09:43.047828 22542570456896 run_lib.py:146] step: 544300, eval_loss: 3.05304e-02
I0210 18:10:00.431699 22542570456896 run_lib.py:133] step: 544350, training_loss: 2.88369e-02
I0210 18:10:18.001920 22542570456896 run_lib.py:133] step: 544400, training_loss: 2.99486e-02
I0210 18:10:18.183981 22542570456896 run_lib.py:146] step: 544400, eval_loss: 2.87668e-02
I0210 18:10:35.610771 22542570456896 run_lib.py:133] step: 544450, training_loss: 3.11876e-02
I0210 18:10:53.140259 22542570456896 run_lib.py:133] step: 544500, training_loss: 2.81787e-02
I0210 18:10:53.295586 22542570456896 run_lib.py:146] step: 544500, eval_loss: 2.24399e-02
I0210 18:11:10.695334 22542570456896 run_lib.py:133] step: 544550, training_loss: 2.71766e-02
I0210 18:11:28.053703 22542570456896 run_lib.py:133] step: 544600, training_loss: 2.11623e-02
I0210 18:11:28.209276 22542570456896 run_lib.py:146] step: 544600, eval_loss: 3.46951e-02
I0210 18:11:45.723760 22542570456896 run_lib.py:133] step: 544650, training_loss: 2.75426e-02
I0210 18:12:03.224433 22542570456896 run_lib.py:133] step: 544700, training_loss: 2.79109e-02
I0210 18:12:03.377526 22542570456896 run_lib.py:146] step: 544700, eval_loss: 3.23189e-02
I0210 18:12:20.767706 22542570456896 run_lib.py:133] step: 544750, training_loss: 3.57230e-02
I0210 18:12:38.206315 22542570456896 run_lib.py:133] step: 544800, training_loss: 3.16961e-02
I0210 18:12:38.362855 22542570456896 run_lib.py:146] step: 544800, eval_loss: 2.97584e-02
I0210 18:12:55.910399 22542570456896 run_lib.py:133] step: 544850, training_loss: 2.56305e-02
I0210 18:13:13.314795 22542570456896 run_lib.py:133] step: 544900, training_loss: 2.91824e-02
I0210 18:13:13.471634 22542570456896 run_lib.py:146] step: 544900, eval_loss: 3.21930e-02
I0210 18:13:31.012059 22542570456896 run_lib.py:133] step: 544950, training_loss: 3.19052e-02
I0210 18:13:48.488848 22542570456896 run_lib.py:133] step: 545000, training_loss: 2.65216e-02
I0210 18:13:48.643475 22542570456896 run_lib.py:146] step: 545000, eval_loss: 3.45833e-02
I0210 18:14:06.223115 22542570456896 run_lib.py:133] step: 545050, training_loss: 3.13731e-02
I0210 18:14:23.625648 22542570456896 run_lib.py:133] step: 545100, training_loss: 3.56182e-02
I0210 18:14:23.780783 22542570456896 run_lib.py:146] step: 545100, eval_loss: 2.95133e-02
I0210 18:14:41.179786 22542570456896 run_lib.py:133] step: 545150, training_loss: 2.43334e-02
I0210 18:14:58.717503 22542570456896 run_lib.py:133] step: 545200, training_loss: 2.71418e-02
I0210 18:14:58.870677 22542570456896 run_lib.py:146] step: 545200, eval_loss: 2.84016e-02
I0210 18:15:16.293423 22542570456896 run_lib.py:133] step: 545250, training_loss: 3.29342e-02
I0210 18:15:33.872492 22542570456896 run_lib.py:133] step: 545300, training_loss: 2.39692e-02
I0210 18:15:34.044284 22542570456896 run_lib.py:146] step: 545300, eval_loss: 2.83952e-02
I0210 18:15:51.510717 22542570456896 run_lib.py:133] step: 545350, training_loss: 2.43178e-02
I0210 18:16:08.908646 22542570456896 run_lib.py:133] step: 545400, training_loss: 2.99634e-02
I0210 18:16:09.110550 22542570456896 run_lib.py:146] step: 545400, eval_loss: 2.60574e-02
I0210 18:16:26.726281 22542570456896 run_lib.py:133] step: 545450, training_loss: 2.31154e-02
I0210 18:16:44.157014 22542570456896 run_lib.py:133] step: 545500, training_loss: 2.94450e-02
I0210 18:16:44.317918 22542570456896 run_lib.py:146] step: 545500, eval_loss: 2.59381e-02
I0210 18:17:01.714884 22542570456896 run_lib.py:133] step: 545550, training_loss: 2.67473e-02
I0210 18:17:19.323581 22542570456896 run_lib.py:133] step: 545600, training_loss: 2.86814e-02
I0210 18:17:19.474201 22542570456896 run_lib.py:146] step: 545600, eval_loss: 3.26231e-02
I0210 18:17:36.908309 22542570456896 run_lib.py:133] step: 545650, training_loss: 2.09520e-02
I0210 18:17:54.336051 22542570456896 run_lib.py:133] step: 545700, training_loss: 2.99615e-02
I0210 18:17:54.495365 22542570456896 run_lib.py:146] step: 545700, eval_loss: 2.58145e-02
I0210 18:18:11.927522 22542570456896 run_lib.py:133] step: 545750, training_loss: 2.34147e-02
I0210 18:18:29.311209 22542570456896 run_lib.py:133] step: 545800, training_loss: 2.75538e-02
I0210 18:18:29.481044 22542570456896 run_lib.py:146] step: 545800, eval_loss: 3.29733e-02
I0210 18:18:46.929605 22542570456896 run_lib.py:133] step: 545850, training_loss: 2.24729e-02
I0210 18:19:04.371750 22542570456896 run_lib.py:133] step: 545900, training_loss: 3.23176e-02
I0210 18:19:04.535048 22542570456896 run_lib.py:146] step: 545900, eval_loss: 3.26473e-02
I0210 18:19:22.113790 22542570456896 run_lib.py:133] step: 545950, training_loss: 3.31776e-02
I0210 18:19:39.599617 22542570456896 run_lib.py:133] step: 546000, training_loss: 2.44275e-02
I0210 18:19:39.755743 22542570456896 run_lib.py:146] step: 546000, eval_loss: 2.98170e-02
I0210 18:19:57.179818 22542570456896 run_lib.py:133] step: 546050, training_loss: 2.92275e-02
I0210 18:20:14.581941 22542570456896 run_lib.py:133] step: 546100, training_loss: 3.15371e-02
I0210 18:20:14.735593 22542570456896 run_lib.py:146] step: 546100, eval_loss: 2.37540e-02
I0210 18:20:32.371405 22542570456896 run_lib.py:133] step: 546150, training_loss: 2.93559e-02
I0210 18:20:49.755253 22542570456896 run_lib.py:133] step: 546200, training_loss: 2.81124e-02
I0210 18:20:49.917823 22542570456896 run_lib.py:146] step: 546200, eval_loss: 3.89170e-02
I0210 18:21:07.463397 22542570456896 run_lib.py:133] step: 546250, training_loss: 2.55856e-02
I0210 18:21:24.842423 22542570456896 run_lib.py:133] step: 546300, training_loss: 2.95469e-02
I0210 18:21:25.003735 22542570456896 run_lib.py:146] step: 546300, eval_loss: 2.75866e-02
I0210 18:21:42.528297 22542570456896 run_lib.py:133] step: 546350, training_loss: 3.56500e-02
I0210 18:21:59.965332 22542570456896 run_lib.py:133] step: 546400, training_loss: 2.90315e-02
I0210 18:22:00.121662 22542570456896 run_lib.py:146] step: 546400, eval_loss: 2.96453e-02
I0210 18:22:17.756732 22542570456896 run_lib.py:133] step: 546450, training_loss: 2.97210e-02
I0210 18:22:35.069507 22542570456896 run_lib.py:133] step: 546500, training_loss: 2.79268e-02
I0210 18:22:35.228297 22542570456896 run_lib.py:146] step: 546500, eval_loss: 2.61885e-02
I0210 18:22:52.609182 22542570456896 run_lib.py:133] step: 546550, training_loss: 3.00440e-02
I0210 18:23:10.184802 22542570456896 run_lib.py:133] step: 546600, training_loss: 2.10820e-02
I0210 18:23:10.337482 22542570456896 run_lib.py:146] step: 546600, eval_loss: 2.86004e-02
I0210 18:23:27.774241 22542570456896 run_lib.py:133] step: 546650, training_loss: 2.79620e-02
I0210 18:23:45.137421 22542570456896 run_lib.py:133] step: 546700, training_loss: 2.17407e-02
I0210 18:23:45.299279 22542570456896 run_lib.py:146] step: 546700, eval_loss: 3.06030e-02
I0210 18:24:02.857404 22542570456896 run_lib.py:133] step: 546750, training_loss: 2.17498e-02
I0210 18:24:20.230116 22542570456896 run_lib.py:133] step: 546800, training_loss: 2.77691e-02
I0210 18:24:20.398688 22542570456896 run_lib.py:146] step: 546800, eval_loss: 3.89973e-02
I0210 18:24:37.955471 22542570456896 run_lib.py:133] step: 546850, training_loss: 3.13745e-02
I0210 18:24:55.357527 22542570456896 run_lib.py:133] step: 546900, training_loss: 2.92013e-02
I0210 18:24:55.524270 22542570456896 run_lib.py:146] step: 546900, eval_loss: 2.59648e-02
I0210 18:25:12.942514 22542570456896 run_lib.py:133] step: 546950, training_loss: 3.06985e-02
I0210 18:25:30.541497 22542570456896 run_lib.py:133] step: 547000, training_loss: 3.47860e-02
I0210 18:25:30.750474 22542570456896 run_lib.py:146] step: 547000, eval_loss: 2.47331e-02
I0210 18:25:48.191593 22542570456896 run_lib.py:133] step: 547050, training_loss: 2.44534e-02
I0210 18:26:05.612671 22542570456896 run_lib.py:133] step: 547100, training_loss: 2.20266e-02
I0210 18:26:05.763208 22542570456896 run_lib.py:146] step: 547100, eval_loss: 2.68347e-02
I0210 18:26:23.138214 22542570456896 run_lib.py:133] step: 547150, training_loss: 3.38668e-02
I0210 18:26:40.709375 22542570456896 run_lib.py:133] step: 547200, training_loss: 2.77261e-02
I0210 18:26:40.890963 22542570456896 run_lib.py:146] step: 547200, eval_loss: 2.10484e-02
I0210 18:26:58.345306 22542570456896 run_lib.py:133] step: 547250, training_loss: 2.29942e-02
I0210 18:27:15.829372 22542570456896 run_lib.py:133] step: 547300, training_loss: 2.72949e-02
I0210 18:27:15.986282 22542570456896 run_lib.py:146] step: 547300, eval_loss: 3.22309e-02
I0210 18:27:33.361780 22542570456896 run_lib.py:133] step: 547350, training_loss: 2.86441e-02
I0210 18:27:50.710690 22542570456896 run_lib.py:133] step: 547400, training_loss: 3.02897e-02
I0210 18:27:50.865005 22542570456896 run_lib.py:146] step: 547400, eval_loss: 2.89550e-02
I0210 18:28:08.404385 22542570456896 run_lib.py:133] step: 547450, training_loss: 2.69300e-02
I0210 18:28:25.918682 22542570456896 run_lib.py:133] step: 547500, training_loss: 2.84362e-02
I0210 18:28:26.075177 22542570456896 run_lib.py:146] step: 547500, eval_loss: 2.95622e-02
I0210 18:28:43.503446 22542570456896 run_lib.py:133] step: 547550, training_loss: 2.71684e-02
I0210 18:29:00.895872 22542570456896 run_lib.py:133] step: 547600, training_loss: 3.03105e-02
I0210 18:29:01.049983 22542570456896 run_lib.py:146] step: 547600, eval_loss: 3.21292e-02
I0210 18:29:18.605987 22542570456896 run_lib.py:133] step: 547650, training_loss: 2.71057e-02
I0210 18:29:35.981509 22542570456896 run_lib.py:133] step: 547700, training_loss: 2.70466e-02
I0210 18:29:36.139748 22542570456896 run_lib.py:146] step: 547700, eval_loss: 3.43989e-02
I0210 18:29:53.695594 22542570456896 run_lib.py:133] step: 547750, training_loss: 2.68406e-02
I0210 18:30:11.165250 22542570456896 run_lib.py:133] step: 547800, training_loss: 3.03400e-02
I0210 18:30:11.319587 22542570456896 run_lib.py:146] step: 547800, eval_loss: 3.08215e-02
I0210 18:30:28.871034 22542570456896 run_lib.py:133] step: 547850, training_loss: 2.89120e-02
I0210 18:30:46.251924 22542570456896 run_lib.py:133] step: 547900, training_loss: 2.54303e-02
I0210 18:30:46.407428 22542570456896 run_lib.py:146] step: 547900, eval_loss: 3.37243e-02
I0210 18:31:03.774417 22542570456896 run_lib.py:133] step: 547950, training_loss: 2.55784e-02
I0210 18:31:21.283331 22542570456896 run_lib.py:133] step: 548000, training_loss: 3.30151e-02
I0210 18:31:21.435092 22542570456896 run_lib.py:146] step: 548000, eval_loss: 3.03140e-02
I0210 18:31:38.886915 22542570456896 run_lib.py:133] step: 548050, training_loss: 3.89963e-02
I0210 18:31:56.478504 22542570456896 run_lib.py:133] step: 548100, training_loss: 2.01710e-02
I0210 18:31:56.633654 22542570456896 run_lib.py:146] step: 548100, eval_loss: 2.66854e-02
I0210 18:32:14.026898 22542570456896 run_lib.py:133] step: 548150, training_loss: 2.40939e-02
I0210 18:32:31.425235 22542570456896 run_lib.py:133] step: 548200, training_loss: 2.65897e-02
I0210 18:32:31.581464 22542570456896 run_lib.py:146] step: 548200, eval_loss: 2.82957e-02
I0210 18:32:49.144194 22542570456896 run_lib.py:133] step: 548250, training_loss: 2.06616e-02
I0210 18:33:06.557564 22542570456896 run_lib.py:133] step: 548300, training_loss: 2.55870e-02
I0210 18:33:06.718377 22542570456896 run_lib.py:146] step: 548300, eval_loss: 3.20769e-02
I0210 18:33:24.143359 22542570456896 run_lib.py:133] step: 548350, training_loss: 2.40199e-02
I0210 18:33:41.764171 22542570456896 run_lib.py:133] step: 548400, training_loss: 2.13178e-02
I0210 18:33:41.916667 22542570456896 run_lib.py:146] step: 548400, eval_loss: 3.16035e-02
I0210 18:33:59.346383 22542570456896 run_lib.py:133] step: 548450, training_loss: 2.77757e-02
I0210 18:34:16.717489 22542570456896 run_lib.py:133] step: 548500, training_loss: 2.99792e-02
I0210 18:34:17.013014 22542570456896 run_lib.py:146] step: 548500, eval_loss: 2.95222e-02
I0210 18:34:34.386544 22542570456896 run_lib.py:133] step: 548550, training_loss: 2.61716e-02
I0210 18:34:51.810688 22542570456896 run_lib.py:133] step: 548600, training_loss: 2.31719e-02
I0210 18:34:51.995432 22542570456896 run_lib.py:146] step: 548600, eval_loss: 2.77230e-02
I0210 18:35:09.442411 22542570456896 run_lib.py:133] step: 548650, training_loss: 2.80745e-02
I0210 18:35:26.824968 22542570456896 run_lib.py:133] step: 548700, training_loss: 2.25887e-02
I0210 18:35:26.985441 22542570456896 run_lib.py:146] step: 548700, eval_loss: 2.89397e-02
I0210 18:35:44.536001 22542570456896 run_lib.py:133] step: 548750, training_loss: 3.13055e-02
I0210 18:36:01.982381 22542570456896 run_lib.py:133] step: 548800, training_loss: 2.95774e-02
I0210 18:36:02.138398 22542570456896 run_lib.py:146] step: 548800, eval_loss: 2.87967e-02
I0210 18:36:19.539204 22542570456896 run_lib.py:133] step: 548850, training_loss: 3.39501e-02
I0210 18:36:36.982746 22542570456896 run_lib.py:133] step: 548900, training_loss: 2.58164e-02
I0210 18:36:37.137733 22542570456896 run_lib.py:146] step: 548900, eval_loss: 2.36855e-02
I0210 18:36:54.746044 22542570456896 run_lib.py:133] step: 548950, training_loss: 2.58690e-02
I0210 18:37:12.185618 22542570456896 run_lib.py:133] step: 549000, training_loss: 2.60088e-02
I0210 18:37:12.342382 22542570456896 run_lib.py:146] step: 549000, eval_loss: 3.18356e-02
I0210 18:37:29.722660 22542570456896 run_lib.py:133] step: 549050, training_loss: 2.44166e-02
I0210 18:37:47.101421 22542570456896 run_lib.py:133] step: 549100, training_loss: 3.28735e-02
I0210 18:37:47.256372 22542570456896 run_lib.py:146] step: 549100, eval_loss: 3.04414e-02
I0210 18:38:04.775027 22542570456896 run_lib.py:133] step: 549150, training_loss: 2.68530e-02
I0210 18:38:22.198416 22542570456896 run_lib.py:133] step: 549200, training_loss: 3.53811e-02
I0210 18:38:22.357327 22542570456896 run_lib.py:146] step: 549200, eval_loss: 3.19690e-02
I0210 18:38:39.934626 22542570456896 run_lib.py:133] step: 549250, training_loss: 3.01340e-02
I0210 18:38:57.351860 22542570456896 run_lib.py:133] step: 549300, training_loss: 2.20703e-02
I0210 18:38:57.507116 22542570456896 run_lib.py:146] step: 549300, eval_loss: 2.78815e-02
I0210 18:39:15.062479 22542570456896 run_lib.py:133] step: 549350, training_loss: 4.12056e-02
I0210 18:39:32.486570 22542570456896 run_lib.py:133] step: 549400, training_loss: 2.39519e-02
I0210 18:39:32.638503 22542570456896 run_lib.py:146] step: 549400, eval_loss: 3.63309e-02
I0210 18:39:50.020154 22542570456896 run_lib.py:133] step: 549450, training_loss: 2.40024e-02
I0210 18:40:07.622459 22542570456896 run_lib.py:133] step: 549500, training_loss: 2.76095e-02
I0210 18:40:07.778494 22542570456896 run_lib.py:146] step: 549500, eval_loss: 2.59222e-02
I0210 18:40:25.215363 22542570456896 run_lib.py:133] step: 549550, training_loss: 2.89156e-02
I0210 18:40:42.823269 22542570456896 run_lib.py:133] step: 549600, training_loss: 2.65707e-02
I0210 18:40:42.981513 22542570456896 run_lib.py:146] step: 549600, eval_loss: 2.46228e-02
I0210 18:41:00.363752 22542570456896 run_lib.py:133] step: 549650, training_loss: 2.61085e-02
I0210 18:41:17.756344 22542570456896 run_lib.py:133] step: 549700, training_loss: 2.49616e-02
I0210 18:41:17.908632 22542570456896 run_lib.py:146] step: 549700, eval_loss: 2.84533e-02
I0210 18:41:35.515030 22542570456896 run_lib.py:133] step: 549750, training_loss: 2.77085e-02
I0210 18:41:52.998183 22542570456896 run_lib.py:133] step: 549800, training_loss: 3.83699e-02
I0210 18:41:53.154655 22542570456896 run_lib.py:146] step: 549800, eval_loss: 3.38428e-02
I0210 18:42:10.535034 22542570456896 run_lib.py:133] step: 549850, training_loss: 3.00839e-02
I0210 18:42:27.948676 22542570456896 run_lib.py:133] step: 549900, training_loss: 3.37004e-02
I0210 18:42:28.101044 22542570456896 run_lib.py:146] step: 549900, eval_loss: 3.15162e-02
I0210 18:42:45.662310 22542570456896 run_lib.py:133] step: 549950, training_loss: 2.30032e-02
I0210 18:43:03.162203 22542570456896 run_lib.py:133] step: 550000, training_loss: 4.15376e-02
I0210 18:43:03.885443 22542570456896 run_lib.py:146] step: 550000, eval_loss: 3.13405e-02
I0210 18:43:24.144259 22542570456896 run_lib.py:133] step: 550050, training_loss: 2.95993e-02
I0210 18:43:41.540762 22542570456896 run_lib.py:133] step: 550100, training_loss: 2.58745e-02
I0210 18:43:41.696254 22542570456896 run_lib.py:146] step: 550100, eval_loss: 2.74653e-02
I0210 18:43:59.226089 22542570456896 run_lib.py:133] step: 550150, training_loss: 2.24583e-02
I0210 18:44:16.694646 22542570456896 run_lib.py:133] step: 550200, training_loss: 3.50274e-02
I0210 18:44:16.861673 22542570456896 run_lib.py:146] step: 550200, eval_loss: 2.26020e-02
I0210 18:44:34.298945 22542570456896 run_lib.py:133] step: 550250, training_loss: 2.68834e-02
I0210 18:44:51.907034 22542570456896 run_lib.py:133] step: 550300, training_loss: 3.52968e-02
I0210 18:44:52.064525 22542570456896 run_lib.py:146] step: 550300, eval_loss: 3.14899e-02
I0210 18:45:09.490304 22542570456896 run_lib.py:133] step: 550350, training_loss: 3.10699e-02
I0210 18:45:26.867325 22542570456896 run_lib.py:133] step: 550400, training_loss: 2.75850e-02
I0210 18:45:27.026335 22542570456896 run_lib.py:146] step: 550400, eval_loss: 2.56600e-02
I0210 18:45:44.402484 22542570456896 run_lib.py:133] step: 550450, training_loss: 2.40591e-02
I0210 18:46:01.911475 22542570456896 run_lib.py:133] step: 550500, training_loss: 3.16759e-02
I0210 18:46:02.063263 22542570456896 run_lib.py:146] step: 550500, eval_loss: 3.14868e-02
I0210 18:46:19.431171 22542570456896 run_lib.py:133] step: 550550, training_loss: 2.92370e-02
I0210 18:46:36.917469 22542570456896 run_lib.py:133] step: 550600, training_loss: 3.54919e-02
I0210 18:46:37.087357 22542570456896 run_lib.py:146] step: 550600, eval_loss: 2.45530e-02
I0210 18:46:54.486599 22542570456896 run_lib.py:133] step: 550650, training_loss: 2.80309e-02
I0210 18:47:11.957026 22542570456896 run_lib.py:133] step: 550700, training_loss: 2.89858e-02
I0210 18:47:12.117635 22542570456896 run_lib.py:146] step: 550700, eval_loss: 2.81855e-02
I0210 18:47:29.720556 22542570456896 run_lib.py:133] step: 550750, training_loss: 3.40419e-02
I0210 18:47:47.143873 22542570456896 run_lib.py:133] step: 550800, training_loss: 2.76372e-02
I0210 18:47:47.297469 22542570456896 run_lib.py:146] step: 550800, eval_loss: 3.19171e-02
I0210 18:48:04.711823 22542570456896 run_lib.py:133] step: 550850, training_loss: 2.40878e-02
I0210 18:48:22.141355 22542570456896 run_lib.py:133] step: 550900, training_loss: 2.81700e-02
I0210 18:48:22.293065 22542570456896 run_lib.py:146] step: 550900, eval_loss: 3.61745e-02
I0210 18:48:39.926615 22542570456896 run_lib.py:133] step: 550950, training_loss: 2.71166e-02
I0210 18:48:57.344241 22542570456896 run_lib.py:133] step: 551000, training_loss: 3.37586e-02
I0210 18:48:57.497287 22542570456896 run_lib.py:146] step: 551000, eval_loss: 2.80190e-02
I0210 18:49:15.050880 22542570456896 run_lib.py:133] step: 551050, training_loss: 2.37930e-02
I0210 18:49:32.412415 22542570456896 run_lib.py:133] step: 551100, training_loss: 2.38445e-02
I0210 18:49:32.584104 22542570456896 run_lib.py:146] step: 551100, eval_loss: 3.01264e-02
I0210 18:49:50.122123 22542570456896 run_lib.py:133] step: 551150, training_loss: 3.49275e-02
I0210 18:50:07.548095 22542570456896 run_lib.py:133] step: 551200, training_loss: 2.24810e-02
I0210 18:50:07.704222 22542570456896 run_lib.py:146] step: 551200, eval_loss: 2.41716e-02
I0210 18:50:25.118888 22542570456896 run_lib.py:133] step: 551250, training_loss: 2.89205e-02
I0210 18:50:42.743048 22542570456896 run_lib.py:133] step: 551300, training_loss: 1.95292e-02
I0210 18:50:42.898533 22542570456896 run_lib.py:146] step: 551300, eval_loss: 2.81489e-02
I0210 18:51:00.283704 22542570456896 run_lib.py:133] step: 551350, training_loss: 3.42274e-02
I0210 18:51:17.827006 22542570456896 run_lib.py:133] step: 551400, training_loss: 2.87378e-02
I0210 18:51:17.985026 22542570456896 run_lib.py:146] step: 551400, eval_loss: 2.80823e-02
I0210 18:51:35.427707 22542570456896 run_lib.py:133] step: 551450, training_loss: 2.33098e-02
I0210 18:51:52.860023 22542570456896 run_lib.py:133] step: 551500, training_loss: 2.45322e-02
I0210 18:51:53.020526 22542570456896 run_lib.py:146] step: 551500, eval_loss: 3.29553e-02
I0210 18:52:10.626707 22542570456896 run_lib.py:133] step: 551550, training_loss: 2.17501e-02
I0210 18:52:28.037746 22542570456896 run_lib.py:133] step: 551600, training_loss: 2.75078e-02
I0210 18:52:28.195474 22542570456896 run_lib.py:146] step: 551600, eval_loss: 3.56376e-02
I0210 18:52:45.630052 22542570456896 run_lib.py:133] step: 551650, training_loss: 2.46452e-02
I0210 18:53:03.005112 22542570456896 run_lib.py:133] step: 551700, training_loss: 2.63315e-02
I0210 18:53:03.171369 22542570456896 run_lib.py:146] step: 551700, eval_loss: 2.40513e-02
I0210 18:53:20.766337 22542570456896 run_lib.py:133] step: 551750, training_loss: 2.48412e-02
I0210 18:53:38.253477 22542570456896 run_lib.py:133] step: 551800, training_loss: 2.11984e-02
I0210 18:53:38.409492 22542570456896 run_lib.py:146] step: 551800, eval_loss: 2.72004e-02
I0210 18:53:55.899551 22542570456896 run_lib.py:133] step: 551850, training_loss: 2.59363e-02
I0210 18:54:13.304122 22542570456896 run_lib.py:133] step: 551900, training_loss: 2.48538e-02
I0210 18:54:13.455956 22542570456896 run_lib.py:146] step: 551900, eval_loss: 3.08839e-02
I0210 18:54:30.896700 22542570456896 run_lib.py:133] step: 551950, training_loss: 2.27469e-02
I0210 18:54:48.292453 22542570456896 run_lib.py:133] step: 552000, training_loss: 3.35489e-02
I0210 18:54:48.460493 22542570456896 run_lib.py:146] step: 552000, eval_loss: 3.17065e-02
I0210 18:55:06.006481 22542570456896 run_lib.py:133] step: 552050, training_loss: 2.58485e-02
I0210 18:55:23.409979 22542570456896 run_lib.py:133] step: 552100, training_loss: 3.07922e-02
I0210 18:55:23.567231 22542570456896 run_lib.py:146] step: 552100, eval_loss: 3.39117e-02
I0210 18:55:40.860471 22542570456896 run_lib.py:133] step: 552150, training_loss: 3.15070e-02
I0210 18:55:58.121039 22542570456896 run_lib.py:133] step: 552200, training_loss: 2.45057e-02
I0210 18:55:58.272245 22542570456896 run_lib.py:146] step: 552200, eval_loss: 2.88617e-02
I0210 18:56:15.772521 22542570456896 run_lib.py:133] step: 552250, training_loss: 2.87126e-02
I0210 18:56:33.212676 22542570456896 run_lib.py:133] step: 552300, training_loss: 2.97379e-02
I0210 18:56:33.378428 22542570456896 run_lib.py:146] step: 552300, eval_loss: 2.15205e-02
I0210 18:56:51.042768 22542570456896 run_lib.py:133] step: 552350, training_loss: 3.07081e-02
I0210 18:57:08.483515 22542570456896 run_lib.py:133] step: 552400, training_loss: 3.09917e-02
I0210 18:57:08.636336 22542570456896 run_lib.py:146] step: 552400, eval_loss: 3.00458e-02
I0210 18:57:26.212873 22542570456896 run_lib.py:133] step: 552450, training_loss: 2.92252e-02
I0210 18:57:43.630560 22542570456896 run_lib.py:133] step: 552500, training_loss: 2.03266e-02
I0210 18:57:43.793701 22542570456896 run_lib.py:146] step: 552500, eval_loss: 2.65901e-02
I0210 18:58:01.346075 22542570456896 run_lib.py:133] step: 552550, training_loss: 2.36476e-02
I0210 18:58:18.837679 22542570456896 run_lib.py:133] step: 552600, training_loss: 2.61168e-02
I0210 18:58:18.992073 22542570456896 run_lib.py:146] step: 552600, eval_loss: 2.64594e-02
I0210 18:58:36.404875 22542570456896 run_lib.py:133] step: 552650, training_loss: 2.06214e-02
I0210 18:58:54.020200 22542570456896 run_lib.py:133] step: 552700, training_loss: 3.32819e-02
I0210 18:58:54.192386 22542570456896 run_lib.py:146] step: 552700, eval_loss: 2.72469e-02
I0210 18:59:11.599998 22542570456896 run_lib.py:133] step: 552750, training_loss: 2.66826e-02
I0210 18:59:28.963012 22542570456896 run_lib.py:133] step: 552800, training_loss: 2.69682e-02
I0210 18:59:29.115120 22542570456896 run_lib.py:146] step: 552800, eval_loss: 2.37672e-02
I0210 18:59:46.709353 22542570456896 run_lib.py:133] step: 552850, training_loss: 3.25288e-02
I0210 19:00:04.332132 22542570456896 run_lib.py:133] step: 552900, training_loss: 2.99446e-02
I0210 19:00:04.493548 22542570456896 run_lib.py:146] step: 552900, eval_loss: 3.12122e-02
I0210 19:00:21.896459 22542570456896 run_lib.py:133] step: 552950, training_loss: 3.08579e-02
I0210 19:00:39.310264 22542570456896 run_lib.py:133] step: 553000, training_loss: 3.02215e-02
I0210 19:00:39.467597 22542570456896 run_lib.py:146] step: 553000, eval_loss: 3.56484e-02
I0210 19:00:56.925930 22542570456896 run_lib.py:133] step: 553050, training_loss: 2.73440e-02
I0210 19:01:14.491276 22542570456896 run_lib.py:133] step: 553100, training_loss: 3.39337e-02
I0210 19:01:14.667216 22542570456896 run_lib.py:146] step: 553100, eval_loss: 2.93258e-02
I0210 19:01:32.101935 22542570456896 run_lib.py:133] step: 553150, training_loss: 2.99535e-02
I0210 19:01:49.544613 22542570456896 run_lib.py:133] step: 553200, training_loss: 2.93699e-02
I0210 19:01:49.702875 22542570456896 run_lib.py:146] step: 553200, eval_loss: 2.91303e-02
I0210 19:02:07.192329 22542570456896 run_lib.py:133] step: 553250, training_loss: 2.73603e-02
I0210 19:02:24.815451 22542570456896 run_lib.py:133] step: 553300, training_loss: 2.35099e-02
I0210 19:02:24.967421 22542570456896 run_lib.py:146] step: 553300, eval_loss: 3.01541e-02
I0210 19:02:42.386056 22542570456896 run_lib.py:133] step: 553350, training_loss: 2.79649e-02
I0210 19:02:59.868616 22542570456896 run_lib.py:133] step: 553400, training_loss: 2.63680e-02
I0210 19:03:00.039579 22542570456896 run_lib.py:146] step: 553400, eval_loss: 2.56508e-02
I0210 19:03:17.543953 22542570456896 run_lib.py:133] step: 553450, training_loss: 2.84729e-02
I0210 19:03:34.974841 22542570456896 run_lib.py:133] step: 553500, training_loss: 2.19653e-02
I0210 19:03:35.132306 22542570456896 run_lib.py:146] step: 553500, eval_loss: 3.42861e-02
I0210 19:03:52.718528 22542570456896 run_lib.py:133] step: 553550, training_loss: 3.32792e-02
I0210 19:04:10.183008 22542570456896 run_lib.py:133] step: 553600, training_loss: 3.24369e-02
I0210 19:04:10.338610 22542570456896 run_lib.py:146] step: 553600, eval_loss: 2.60843e-02
I0210 19:04:27.716089 22542570456896 run_lib.py:133] step: 553650, training_loss: 2.98941e-02
I0210 19:04:45.216934 22542570456896 run_lib.py:133] step: 553700, training_loss: 2.50901e-02
I0210 19:04:45.378672 22542570456896 run_lib.py:146] step: 553700, eval_loss: 2.37874e-02
I0210 19:05:02.993141 22542570456896 run_lib.py:133] step: 553750, training_loss: 2.86441e-02
I0210 19:05:20.403387 22542570456896 run_lib.py:133] step: 553800, training_loss: 2.71498e-02
I0210 19:05:20.562330 22542570456896 run_lib.py:146] step: 553800, eval_loss: 3.12376e-02
I0210 19:05:38.091978 22542570456896 run_lib.py:133] step: 553850, training_loss: 3.54241e-02
I0210 19:05:55.507384 22542570456896 run_lib.py:133] step: 553900, training_loss: 2.50089e-02
I0210 19:05:55.661145 22542570456896 run_lib.py:146] step: 553900, eval_loss: 2.60111e-02
I0210 19:06:13.214349 22542570456896 run_lib.py:133] step: 553950, training_loss: 2.66424e-02
I0210 19:06:30.688706 22542570456896 run_lib.py:133] step: 554000, training_loss: 2.26415e-02
I0210 19:06:30.854489 22542570456896 run_lib.py:146] step: 554000, eval_loss: 3.51692e-02
I0210 19:06:48.240579 22542570456896 run_lib.py:133] step: 554050, training_loss: 2.22074e-02
I0210 19:07:05.792496 22542570456896 run_lib.py:133] step: 554100, training_loss: 2.80078e-02
I0210 19:07:05.954646 22542570456896 run_lib.py:146] step: 554100, eval_loss: 2.43695e-02
I0210 19:07:23.367818 22542570456896 run_lib.py:133] step: 554150, training_loss: 2.44595e-02
I0210 19:07:40.903071 22542570456896 run_lib.py:133] step: 554200, training_loss: 2.85931e-02
I0210 19:07:41.057375 22542570456896 run_lib.py:146] step: 554200, eval_loss: 2.98004e-02
I0210 19:07:58.467066 22542570456896 run_lib.py:133] step: 554250, training_loss: 2.27259e-02
I0210 19:08:15.949766 22542570456896 run_lib.py:133] step: 554300, training_loss: 3.26479e-02
I0210 19:08:16.112563 22542570456896 run_lib.py:146] step: 554300, eval_loss: 2.36032e-02
I0210 19:08:33.767071 22542570456896 run_lib.py:133] step: 554350, training_loss: 2.80123e-02
I0210 19:08:51.166988 22542570456896 run_lib.py:133] step: 554400, training_loss: 2.04123e-02
I0210 19:08:51.324613 22542570456896 run_lib.py:146] step: 554400, eval_loss: 2.91393e-02
I0210 19:09:08.747617 22542570456896 run_lib.py:133] step: 554450, training_loss: 2.79423e-02
I0210 19:09:26.308749 22542570456896 run_lib.py:133] step: 554500, training_loss: 3.00697e-02
I0210 19:09:26.484961 22542570456896 run_lib.py:146] step: 554500, eval_loss: 3.16963e-02
I0210 19:09:43.950389 22542570456896 run_lib.py:133] step: 554550, training_loss: 2.85002e-02
I0210 19:10:01.373118 22542570456896 run_lib.py:133] step: 554600, training_loss: 2.10066e-02
I0210 19:10:01.529765 22542570456896 run_lib.py:146] step: 554600, eval_loss: 2.87281e-02
I0210 19:10:19.075290 22542570456896 run_lib.py:133] step: 554650, training_loss: 2.79132e-02
I0210 19:10:36.496663 22542570456896 run_lib.py:133] step: 554700, training_loss: 2.03862e-02
I0210 19:10:36.648064 22542570456896 run_lib.py:146] step: 554700, eval_loss: 2.72865e-02
I0210 19:10:54.038765 22542570456896 run_lib.py:133] step: 554750, training_loss: 2.98590e-02
I0210 19:11:11.458305 22542570456896 run_lib.py:133] step: 554800, training_loss: 2.80793e-02
I0210 19:11:11.624761 22542570456896 run_lib.py:146] step: 554800, eval_loss: 2.55217e-02
I0210 19:11:29.235520 22542570456896 run_lib.py:133] step: 554850, training_loss: 2.32992e-02
I0210 19:11:46.745903 22542570456896 run_lib.py:133] step: 554900, training_loss: 2.57679e-02
I0210 19:11:46.911875 22542570456896 run_lib.py:146] step: 554900, eval_loss: 3.00075e-02
I0210 19:12:04.285521 22542570456896 run_lib.py:133] step: 554950, training_loss: 2.21663e-02
I0210 19:12:21.686308 22542570456896 run_lib.py:133] step: 555000, training_loss: 2.89194e-02
I0210 19:12:21.841381 22542570456896 run_lib.py:146] step: 555000, eval_loss: 3.51867e-02
I0210 19:12:39.447822 22542570456896 run_lib.py:133] step: 555050, training_loss: 2.61333e-02
I0210 19:12:56.898567 22542570456896 run_lib.py:133] step: 555100, training_loss: 3.19374e-02
I0210 19:12:57.055555 22542570456896 run_lib.py:146] step: 555100, eval_loss: 4.00477e-02
I0210 19:13:14.689814 22542570456896 run_lib.py:133] step: 555150, training_loss: 2.38594e-02
I0210 19:13:32.083330 22542570456896 run_lib.py:133] step: 555200, training_loss: 3.03980e-02
I0210 19:13:32.240340 22542570456896 run_lib.py:146] step: 555200, eval_loss: 2.68039e-02
I0210 19:13:49.796996 22542570456896 run_lib.py:133] step: 555250, training_loss: 2.49614e-02
I0210 19:14:07.194953 22542570456896 run_lib.py:133] step: 555300, training_loss: 2.45316e-02
I0210 19:14:07.355610 22542570456896 run_lib.py:146] step: 555300, eval_loss: 3.39616e-02
I0210 19:14:24.932710 22542570456896 run_lib.py:133] step: 555350, training_loss: 3.01117e-02
I0210 19:14:42.375485 22542570456896 run_lib.py:133] step: 555400, training_loss: 2.67905e-02
I0210 19:14:42.540349 22542570456896 run_lib.py:146] step: 555400, eval_loss: 2.45546e-02
I0210 19:14:59.979463 22542570456896 run_lib.py:133] step: 555450, training_loss: 2.52315e-02
I0210 19:15:17.558104 22542570456896 run_lib.py:133] step: 555500, training_loss: 2.87087e-02
I0210 19:15:17.713276 22542570456896 run_lib.py:146] step: 555500, eval_loss: 2.55840e-02
I0210 19:15:35.113215 22542570456896 run_lib.py:133] step: 555550, training_loss: 2.66207e-02
I0210 19:15:52.522988 22542570456896 run_lib.py:133] step: 555600, training_loss: 4.13929e-02
I0210 19:15:52.682528 22542570456896 run_lib.py:146] step: 555600, eval_loss: 3.21637e-02
I0210 19:16:10.386182 22542570456896 run_lib.py:133] step: 555650, training_loss: 2.59298e-02
I0210 19:16:27.780373 22542570456896 run_lib.py:133] step: 555700, training_loss: 3.17076e-02
I0210 19:16:27.929203 22542570456896 run_lib.py:146] step: 555700, eval_loss: 2.33171e-02
I0210 19:16:45.544066 22542570456896 run_lib.py:133] step: 555750, training_loss: 2.39875e-02
I0210 19:17:02.981184 22542570456896 run_lib.py:133] step: 555800, training_loss: 2.63731e-02
I0210 19:17:03.145332 22542570456896 run_lib.py:146] step: 555800, eval_loss: 2.85205e-02
I0210 19:17:20.617633 22542570456896 run_lib.py:133] step: 555850, training_loss: 2.89987e-02
I0210 19:17:38.159447 22542570456896 run_lib.py:133] step: 555900, training_loss: 2.46850e-02
I0210 19:17:38.333327 22542570456896 run_lib.py:146] step: 555900, eval_loss: 2.97429e-02
I0210 19:17:55.763356 22542570456896 run_lib.py:133] step: 555950, training_loss: 2.84668e-02
I0210 19:18:13.175818 22542570456896 run_lib.py:133] step: 556000, training_loss: 2.94503e-02
I0210 19:18:13.331099 22542570456896 run_lib.py:146] step: 556000, eval_loss: 3.38743e-02
I0210 19:18:30.751557 22542570456896 run_lib.py:133] step: 556050, training_loss: 2.77792e-02
I0210 19:18:48.325635 22542570456896 run_lib.py:133] step: 556100, training_loss: 2.79335e-02
I0210 19:18:48.483291 22542570456896 run_lib.py:146] step: 556100, eval_loss: 2.28560e-02
I0210 19:19:05.879650 22542570456896 run_lib.py:133] step: 556150, training_loss: 2.52529e-02
I0210 19:19:23.372848 22542570456896 run_lib.py:133] step: 556200, training_loss: 2.72041e-02
I0210 19:19:23.528498 22542570456896 run_lib.py:146] step: 556200, eval_loss: 2.28239e-02
I0210 19:19:41.011646 22542570456896 run_lib.py:133] step: 556250, training_loss: 2.36044e-02
I0210 19:19:58.483253 22542570456896 run_lib.py:133] step: 556300, training_loss: 3.44582e-02
I0210 19:19:58.639230 22542570456896 run_lib.py:146] step: 556300, eval_loss: 2.91861e-02
I0210 19:20:16.173012 22542570456896 run_lib.py:133] step: 556350, training_loss: 2.77697e-02
I0210 19:20:33.601633 22542570456896 run_lib.py:133] step: 556400, training_loss: 2.26148e-02
I0210 19:20:33.756284 22542570456896 run_lib.py:146] step: 556400, eval_loss: 2.75469e-02
I0210 19:20:51.139998 22542570456896 run_lib.py:133] step: 556450, training_loss: 1.88166e-02
I0210 19:21:08.560186 22542570456896 run_lib.py:133] step: 556500, training_loss: 3.09791e-02
I0210 19:21:08.714109 22542570456896 run_lib.py:146] step: 556500, eval_loss: 3.87190e-02
I0210 19:21:26.338079 22542570456896 run_lib.py:133] step: 556550, training_loss: 3.39583e-02
I0210 19:21:43.833667 22542570456896 run_lib.py:133] step: 556600, training_loss: 2.78080e-02
I0210 19:21:43.984059 22542570456896 run_lib.py:146] step: 556600, eval_loss: 2.70640e-02
I0210 19:22:01.569543 22542570456896 run_lib.py:133] step: 556650, training_loss: 2.63246e-02
I0210 19:22:19.024628 22542570456896 run_lib.py:133] step: 556700, training_loss: 3.33037e-02
I0210 19:22:19.179420 22542570456896 run_lib.py:146] step: 556700, eval_loss: 2.83287e-02
I0210 19:22:36.682447 22542570456896 run_lib.py:133] step: 556750, training_loss: 2.74060e-02
I0210 19:22:54.156150 22542570456896 run_lib.py:133] step: 556800, training_loss: 2.81238e-02
I0210 19:22:54.339452 22542570456896 run_lib.py:146] step: 556800, eval_loss: 3.12649e-02
I0210 19:23:11.773242 22542570456896 run_lib.py:133] step: 556850, training_loss: 3.72765e-02
I0210 19:23:29.398780 22542570456896 run_lib.py:133] step: 556900, training_loss: 2.31168e-02
I0210 19:23:29.556138 22542570456896 run_lib.py:146] step: 556900, eval_loss: 2.35202e-02
I0210 19:23:46.989278 22542570456896 run_lib.py:133] step: 556950, training_loss: 2.15881e-02
I0210 19:24:04.515289 22542570456896 run_lib.py:133] step: 557000, training_loss: 2.44414e-02
I0210 19:24:04.670271 22542570456896 run_lib.py:146] step: 557000, eval_loss: 3.38771e-02
I0210 19:24:22.124846 22542570456896 run_lib.py:133] step: 557050, training_loss: 2.73616e-02
I0210 19:24:39.553867 22542570456896 run_lib.py:133] step: 557100, training_loss: 2.73542e-02
I0210 19:24:39.899328 22542570456896 run_lib.py:146] step: 557100, eval_loss: 2.34787e-02
I0210 19:24:57.476244 22542570456896 run_lib.py:133] step: 557150, training_loss: 2.22682e-02
I0210 19:25:14.894295 22542570456896 run_lib.py:133] step: 557200, training_loss: 3.18095e-02
I0210 19:25:15.050276 22542570456896 run_lib.py:146] step: 557200, eval_loss: 2.25225e-02
I0210 19:25:32.389689 22542570456896 run_lib.py:133] step: 557250, training_loss: 3.21616e-02
I0210 19:25:49.945070 22542570456896 run_lib.py:133] step: 557300, training_loss: 3.23346e-02
I0210 19:25:50.116303 22542570456896 run_lib.py:146] step: 557300, eval_loss: 2.95329e-02
I0210 19:26:07.555586 22542570456896 run_lib.py:133] step: 557350, training_loss: 3.31827e-02
I0210 19:26:24.994431 22542570456896 run_lib.py:133] step: 557400, training_loss: 2.47308e-02
I0210 19:26:25.330328 22542570456896 run_lib.py:146] step: 557400, eval_loss: 2.77506e-02
I0210 19:26:42.761464 22542570456896 run_lib.py:133] step: 557450, training_loss: 2.81651e-02
I0210 19:27:00.159027 22542570456896 run_lib.py:133] step: 557500, training_loss: 2.76634e-02
I0210 19:27:00.312318 22542570456896 run_lib.py:146] step: 557500, eval_loss: 2.74014e-02
I0210 19:27:17.730609 22542570456896 run_lib.py:133] step: 557550, training_loss: 2.39820e-02
I0210 19:27:35.199298 22542570456896 run_lib.py:133] step: 557600, training_loss: 2.38496e-02
I0210 19:27:35.353497 22542570456896 run_lib.py:146] step: 557600, eval_loss: 2.97814e-02
I0210 19:27:52.957466 22542570456896 run_lib.py:133] step: 557650, training_loss: 2.64802e-02
I0210 19:28:10.441502 22542570456896 run_lib.py:133] step: 557700, training_loss: 2.80806e-02
I0210 19:28:10.604609 22542570456896 run_lib.py:146] step: 557700, eval_loss: 2.98400e-02
I0210 19:28:28.031421 22542570456896 run_lib.py:133] step: 557750, training_loss: 2.41220e-02
I0210 19:28:45.485007 22542570456896 run_lib.py:133] step: 557800, training_loss: 2.96493e-02
I0210 19:28:45.639493 22542570456896 run_lib.py:146] step: 557800, eval_loss: 2.82973e-02
I0210 19:29:03.217645 22542570456896 run_lib.py:133] step: 557850, training_loss: 2.75683e-02
I0210 19:29:20.733442 22542570456896 run_lib.py:133] step: 557900, training_loss: 2.46180e-02
I0210 19:29:20.890616 22542570456896 run_lib.py:146] step: 557900, eval_loss: 2.49813e-02
I0210 19:29:38.282366 22542570456896 run_lib.py:133] step: 557950, training_loss: 2.69824e-02
I0210 19:29:55.639311 22542570456896 run_lib.py:133] step: 558000, training_loss: 2.65900e-02
I0210 19:29:55.792323 22542570456896 run_lib.py:146] step: 558000, eval_loss: 3.36466e-02
I0210 19:30:13.306722 22542570456896 run_lib.py:133] step: 558050, training_loss: 2.91237e-02
I0210 19:30:30.694137 22542570456896 run_lib.py:133] step: 558100, training_loss: 2.91500e-02
I0210 19:30:30.848492 22542570456896 run_lib.py:146] step: 558100, eval_loss: 2.53169e-02
I0210 19:30:48.398114 22542570456896 run_lib.py:133] step: 558150, training_loss: 2.38695e-02
I0210 19:31:05.865676 22542570456896 run_lib.py:133] step: 558200, training_loss: 2.81586e-02
I0210 19:31:06.027292 22542570456896 run_lib.py:146] step: 558200, eval_loss: 3.02518e-02
I0210 19:31:23.601606 22542570456896 run_lib.py:133] step: 558250, training_loss: 2.90552e-02
I0210 19:31:40.943705 22542570456896 run_lib.py:133] step: 558300, training_loss: 2.45941e-02
I0210 19:31:41.097221 22542570456896 run_lib.py:146] step: 558300, eval_loss: 2.82076e-02
I0210 19:31:58.474709 22542570456896 run_lib.py:133] step: 558350, training_loss: 2.10287e-02
I0210 19:32:16.015556 22542570456896 run_lib.py:133] step: 558400, training_loss: 2.43787e-02
I0210 19:32:16.183088 22542570456896 run_lib.py:146] step: 558400, eval_loss: 3.38762e-02
I0210 19:32:33.585084 22542570456896 run_lib.py:133] step: 558450, training_loss: 2.54021e-02
I0210 19:32:51.231690 22542570456896 run_lib.py:133] step: 558500, training_loss: 2.66164e-02
I0210 19:32:51.383218 22542570456896 run_lib.py:146] step: 558500, eval_loss: 3.15290e-02
I0210 19:33:08.818749 22542570456896 run_lib.py:133] step: 558550, training_loss: 2.75892e-02
I0210 19:33:26.196204 22542570456896 run_lib.py:133] step: 558600, training_loss: 3.11136e-02
I0210 19:33:26.366324 22542570456896 run_lib.py:146] step: 558600, eval_loss: 2.60737e-02
I0210 19:33:43.912255 22542570456896 run_lib.py:133] step: 558650, training_loss: 2.89906e-02
I0210 19:34:01.311944 22542570456896 run_lib.py:133] step: 558700, training_loss: 2.30642e-02
I0210 19:34:01.472439 22542570456896 run_lib.py:146] step: 558700, eval_loss: 2.86383e-02
I0210 19:34:18.961724 22542570456896 run_lib.py:133] step: 558750, training_loss: 2.48585e-02
I0210 19:34:36.390283 22542570456896 run_lib.py:133] step: 558800, training_loss: 2.49674e-02
I0210 19:34:36.544601 22542570456896 run_lib.py:146] step: 558800, eval_loss: 2.60353e-02
I0210 19:34:54.132283 22542570456896 run_lib.py:133] step: 558850, training_loss: 2.59895e-02
I0210 19:35:11.540283 22542570456896 run_lib.py:133] step: 558900, training_loss: 3.03796e-02
I0210 19:35:11.695288 22542570456896 run_lib.py:146] step: 558900, eval_loss: 3.22866e-02
I0210 19:35:29.167517 22542570456896 run_lib.py:133] step: 558950, training_loss: 2.51270e-02
I0210 19:35:46.570754 22542570456896 run_lib.py:133] step: 559000, training_loss: 2.89376e-02
I0210 19:35:46.724532 22542570456896 run_lib.py:146] step: 559000, eval_loss: 2.61951e-02
I0210 19:36:04.181021 22542570456896 run_lib.py:133] step: 559050, training_loss: 2.37495e-02
I0210 19:36:21.609186 22542570456896 run_lib.py:133] step: 559100, training_loss: 2.29640e-02
I0210 19:36:21.764277 22542570456896 run_lib.py:146] step: 559100, eval_loss: 3.32533e-02
I0210 19:36:39.337560 22542570456896 run_lib.py:133] step: 559150, training_loss: 3.59912e-02
I0210 19:36:56.788279 22542570456896 run_lib.py:133] step: 559200, training_loss: 3.25897e-02
I0210 19:36:56.941746 22542570456896 run_lib.py:146] step: 559200, eval_loss: 3.23451e-02
I0210 19:37:14.348614 22542570456896 run_lib.py:133] step: 559250, training_loss: 2.76174e-02
I0210 19:37:31.758259 22542570456896 run_lib.py:133] step: 559300, training_loss: 2.87102e-02
I0210 19:37:31.914620 22542570456896 run_lib.py:146] step: 559300, eval_loss: 2.59751e-02
I0210 19:37:49.526786 22542570456896 run_lib.py:133] step: 559350, training_loss: 3.27877e-02
I0210 19:38:06.956603 22542570456896 run_lib.py:133] step: 559400, training_loss: 3.12505e-02
I0210 19:38:07.110857 22542570456896 run_lib.py:146] step: 559400, eval_loss: 2.22239e-02
I0210 19:38:24.677538 22542570456896 run_lib.py:133] step: 559450, training_loss: 3.04791e-02
I0210 19:38:42.051816 22542570456896 run_lib.py:133] step: 559500, training_loss: 2.81889e-02
I0210 19:38:42.204357 22542570456896 run_lib.py:146] step: 559500, eval_loss: 3.07002e-02
I0210 19:38:59.769177 22542570456896 run_lib.py:133] step: 559550, training_loss: 2.61100e-02
I0210 19:39:17.224210 22542570456896 run_lib.py:133] step: 559600, training_loss: 2.97712e-02
I0210 19:39:17.398260 22542570456896 run_lib.py:146] step: 559600, eval_loss: 3.09986e-02
I0210 19:39:35.063019 22542570456896 run_lib.py:133] step: 559650, training_loss: 2.88415e-02
I0210 19:39:52.483944 22542570456896 run_lib.py:133] step: 559700, training_loss: 2.68093e-02
I0210 19:39:52.637526 22542570456896 run_lib.py:146] step: 559700, eval_loss: 2.70250e-02
I0210 19:40:10.064539 22542570456896 run_lib.py:133] step: 559750, training_loss: 2.67917e-02
I0210 19:40:27.564844 22542570456896 run_lib.py:133] step: 559800, training_loss: 2.33953e-02
I0210 19:40:27.729102 22542570456896 run_lib.py:146] step: 559800, eval_loss: 3.19095e-02
I0210 19:40:45.196784 22542570456896 run_lib.py:133] step: 559850, training_loss: 2.98020e-02
I0210 19:41:02.656511 22542570456896 run_lib.py:133] step: 559900, training_loss: 2.72971e-02
I0210 19:41:02.817155 22542570456896 run_lib.py:146] step: 559900, eval_loss: 2.49213e-02
I0210 19:41:20.476311 22542570456896 run_lib.py:133] step: 559950, training_loss: 3.41709e-02
I0210 19:41:38.012866 22542570456896 run_lib.py:133] step: 560000, training_loss: 1.68447e-02
I0210 19:41:38.716213 22542570456896 run_lib.py:146] step: 560000, eval_loss: 2.65942e-02
I0210 19:41:58.732311 22542570456896 run_lib.py:133] step: 560050, training_loss: 2.25651e-02
I0210 19:42:16.234351 22542570456896 run_lib.py:133] step: 560100, training_loss: 2.36692e-02
I0210 19:42:16.401492 22542570456896 run_lib.py:146] step: 560100, eval_loss: 2.66988e-02
I0210 19:42:33.858363 22542570456896 run_lib.py:133] step: 560150, training_loss: 3.73488e-02
I0210 19:42:51.247483 22542570456896 run_lib.py:133] step: 560200, training_loss: 1.89800e-02
I0210 19:42:51.406149 22542570456896 run_lib.py:146] step: 560200, eval_loss: 2.80827e-02
I0210 19:43:08.954573 22542570456896 run_lib.py:133] step: 560250, training_loss: 3.87316e-02
I0210 19:43:26.349528 22542570456896 run_lib.py:133] step: 560300, training_loss: 3.31646e-02
I0210 19:43:26.505479 22542570456896 run_lib.py:146] step: 560300, eval_loss: 2.62710e-02
I0210 19:43:43.922982 22542570456896 run_lib.py:133] step: 560350, training_loss: 2.74304e-02
I0210 19:44:01.374253 22542570456896 run_lib.py:133] step: 560400, training_loss: 2.75551e-02
I0210 19:44:01.530658 22542570456896 run_lib.py:146] step: 560400, eval_loss: 3.00240e-02
I0210 19:44:19.140148 22542570456896 run_lib.py:133] step: 560450, training_loss: 2.57449e-02
I0210 19:44:36.521312 22542570456896 run_lib.py:133] step: 560500, training_loss: 2.67471e-02
I0210 19:44:36.672488 22542570456896 run_lib.py:146] step: 560500, eval_loss: 3.36849e-02
I0210 19:44:54.198071 22542570456896 run_lib.py:133] step: 560550, training_loss: 2.87501e-02
I0210 19:45:11.600619 22542570456896 run_lib.py:133] step: 560600, training_loss: 2.28672e-02
I0210 19:45:11.752646 22542570456896 run_lib.py:146] step: 560600, eval_loss: 3.15395e-02
I0210 19:45:29.275636 22542570456896 run_lib.py:133] step: 560650, training_loss: 2.66273e-02
I0210 19:45:46.712696 22542570456896 run_lib.py:133] step: 560700, training_loss: 3.34900e-02
I0210 19:45:46.874384 22542570456896 run_lib.py:146] step: 560700, eval_loss: 3.04618e-02
I0210 19:46:04.261561 22542570456896 run_lib.py:133] step: 560750, training_loss: 2.59029e-02
I0210 19:46:21.817665 22542570456896 run_lib.py:133] step: 560800, training_loss: 2.56631e-02
I0210 19:46:21.974633 22542570456896 run_lib.py:146] step: 560800, eval_loss: 2.89895e-02
I0210 19:46:39.391252 22542570456896 run_lib.py:133] step: 560850, training_loss: 2.61069e-02
I0210 19:46:56.951264 22542570456896 run_lib.py:133] step: 560900, training_loss: 2.92935e-02
I0210 19:46:57.110194 22542570456896 run_lib.py:146] step: 560900, eval_loss: 2.51202e-02
I0210 19:47:14.562146 22542570456896 run_lib.py:133] step: 560950, training_loss: 2.82258e-02
I0210 19:47:32.000459 22542570456896 run_lib.py:133] step: 561000, training_loss: 2.62013e-02
I0210 19:47:32.153656 22542570456896 run_lib.py:146] step: 561000, eval_loss: 2.74195e-02
I0210 19:47:49.772746 22542570456896 run_lib.py:133] step: 561050, training_loss: 2.26506e-02
I0210 19:48:07.179557 22542570456896 run_lib.py:133] step: 561100, training_loss: 2.42300e-02
I0210 19:48:07.337642 22542570456896 run_lib.py:146] step: 561100, eval_loss: 2.86683e-02
I0210 19:48:24.726552 22542570456896 run_lib.py:133] step: 561150, training_loss: 3.41512e-02
I0210 19:48:42.324737 22542570456896 run_lib.py:133] step: 561200, training_loss: 2.61698e-02
I0210 19:48:42.494351 22542570456896 run_lib.py:146] step: 561200, eval_loss: 2.82305e-02
I0210 19:48:59.968510 22542570456896 run_lib.py:133] step: 561250, training_loss: 2.32370e-02
I0210 19:49:17.413829 22542570456896 run_lib.py:133] step: 561300, training_loss: 1.80863e-02
I0210 19:49:17.567976 22542570456896 run_lib.py:146] step: 561300, eval_loss: 2.81120e-02
I0210 19:49:35.093586 22542570456896 run_lib.py:133] step: 561350, training_loss: 2.10445e-02
I0210 19:49:52.461239 22542570456896 run_lib.py:133] step: 561400, training_loss: 3.44265e-02
I0210 19:49:52.613123 22542570456896 run_lib.py:146] step: 561400, eval_loss: 2.67802e-02
I0210 19:50:10.027050 22542570456896 run_lib.py:133] step: 561450, training_loss: 2.71143e-02
I0210 19:50:27.451248 22542570456896 run_lib.py:133] step: 561500, training_loss: 2.40218e-02
I0210 19:50:27.608356 22542570456896 run_lib.py:146] step: 561500, eval_loss: 3.27310e-02
I0210 19:50:45.188153 22542570456896 run_lib.py:133] step: 561550, training_loss: 2.49318e-02
I0210 19:51:02.718797 22542570456896 run_lib.py:133] step: 561600, training_loss: 3.23877e-02
I0210 19:51:02.878348 22542570456896 run_lib.py:146] step: 561600, eval_loss: 2.32175e-02
I0210 19:51:20.272063 22542570456896 run_lib.py:133] step: 561650, training_loss: 2.62271e-02
I0210 19:51:37.671148 22542570456896 run_lib.py:133] step: 561700, training_loss: 3.15498e-02
I0210 19:51:37.826272 22542570456896 run_lib.py:146] step: 561700, eval_loss: 3.26451e-02
I0210 19:51:55.340596 22542570456896 run_lib.py:133] step: 561750, training_loss: 2.85612e-02
I0210 19:52:12.760488 22542570456896 run_lib.py:133] step: 561800, training_loss: 2.75244e-02
I0210 19:52:12.921171 22542570456896 run_lib.py:146] step: 561800, eval_loss: 3.32141e-02
I0210 19:52:30.531412 22542570456896 run_lib.py:133] step: 561850, training_loss: 1.95318e-02
I0210 19:52:47.984698 22542570456896 run_lib.py:133] step: 561900, training_loss: 2.92057e-02
I0210 19:52:48.136377 22542570456896 run_lib.py:146] step: 561900, eval_loss: 2.37061e-02
I0210 19:53:05.687489 22542570456896 run_lib.py:133] step: 561950, training_loss: 2.48247e-02
I0210 19:53:23.079375 22542570456896 run_lib.py:133] step: 562000, training_loss: 2.37645e-02
I0210 19:53:23.235269 22542570456896 run_lib.py:146] step: 562000, eval_loss: 2.87328e-02
I0210 19:53:40.768946 22542570456896 run_lib.py:133] step: 562050, training_loss: 2.20519e-02
I0210 19:53:58.288744 22542570456896 run_lib.py:133] step: 562100, training_loss: 2.57105e-02
I0210 19:53:58.452456 22542570456896 run_lib.py:146] step: 562100, eval_loss: 2.85939e-02
I0210 19:54:15.887760 22542570456896 run_lib.py:133] step: 562150, training_loss: 2.11502e-02
I0210 19:54:33.488789 22542570456896 run_lib.py:133] step: 562200, training_loss: 3.15572e-02
I0210 19:54:33.651459 22542570456896 run_lib.py:146] step: 562200, eval_loss: 3.72675e-02
I0210 19:54:51.055307 22542570456896 run_lib.py:133] step: 562250, training_loss: 3.17102e-02
I0210 19:55:08.465733 22542570456896 run_lib.py:133] step: 562300, training_loss: 3.10060e-02
I0210 19:55:08.622119 22542570456896 run_lib.py:146] step: 562300, eval_loss: 3.38385e-02
I0210 19:55:26.143555 22542570456896 run_lib.py:133] step: 562350, training_loss: 3.15177e-02
I0210 19:55:43.612215 22542570456896 run_lib.py:133] step: 562400, training_loss: 2.23613e-02
I0210 19:55:43.766577 22542570456896 run_lib.py:146] step: 562400, eval_loss: 3.08672e-02
I0210 19:56:01.363338 22542570456896 run_lib.py:133] step: 562450, training_loss: 2.61020e-02
I0210 19:56:18.767324 22542570456896 run_lib.py:133] step: 562500, training_loss: 2.77968e-02
I0210 19:56:18.922313 22542570456896 run_lib.py:146] step: 562500, eval_loss: 2.80038e-02
I0210 19:56:36.278147 22542570456896 run_lib.py:133] step: 562550, training_loss: 3.04184e-02
I0210 19:56:53.807864 22542570456896 run_lib.py:133] step: 562600, training_loss: 2.03660e-02
I0210 19:56:53.964450 22542570456896 run_lib.py:146] step: 562600, eval_loss: 3.23909e-02
I0210 19:57:11.423897 22542570456896 run_lib.py:133] step: 562650, training_loss: 2.00072e-02
I0210 19:57:28.909069 22542570456896 run_lib.py:133] step: 562700, training_loss: 3.21577e-02
I0210 19:57:29.064410 22542570456896 run_lib.py:146] step: 562700, eval_loss: 3.08382e-02
I0210 19:57:46.480607 22542570456896 run_lib.py:133] step: 562750, training_loss: 2.50519e-02
I0210 19:58:04.038724 22542570456896 run_lib.py:133] step: 562800, training_loss: 2.50161e-02
I0210 19:58:04.194253 22542570456896 run_lib.py:146] step: 562800, eval_loss: 2.86296e-02
I0210 19:58:21.635056 22542570456896 run_lib.py:133] step: 562850, training_loss: 2.45437e-02
I0210 19:58:39.078278 22542570456896 run_lib.py:133] step: 562900, training_loss: 2.41620e-02
I0210 19:58:39.227904 22542570456896 run_lib.py:146] step: 562900, eval_loss: 2.29338e-02
I0210 19:58:56.690881 22542570456896 run_lib.py:133] step: 562950, training_loss: 2.69249e-02
I0210 19:59:14.121558 22542570456896 run_lib.py:133] step: 563000, training_loss: 3.44327e-02
I0210 19:59:14.335784 22542570456896 run_lib.py:146] step: 563000, eval_loss: 3.50123e-02
I0210 19:59:31.982329 22542570456896 run_lib.py:133] step: 563050, training_loss: 2.62569e-02
I0210 19:59:49.438049 22542570456896 run_lib.py:133] step: 563100, training_loss: 2.70682e-02
I0210 19:59:49.592653 22542570456896 run_lib.py:146] step: 563100, eval_loss: 2.70930e-02
I0210 20:00:06.980126 22542570456896 run_lib.py:133] step: 563150, training_loss: 2.42457e-02
I0210 20:00:24.381555 22542570456896 run_lib.py:133] step: 563200, training_loss: 3.56952e-02
I0210 20:00:24.540625 22542570456896 run_lib.py:146] step: 563200, eval_loss: 2.99817e-02
I0210 20:00:42.119938 22542570456896 run_lib.py:133] step: 563250, training_loss: 2.66596e-02
I0210 20:00:59.530209 22542570456896 run_lib.py:133] step: 563300, training_loss: 3.10155e-02
I0210 20:00:59.684896 22542570456896 run_lib.py:146] step: 563300, eval_loss: 2.54759e-02
I0210 20:01:17.298098 22542570456896 run_lib.py:133] step: 563350, training_loss: 2.43315e-02
I0210 20:01:34.688648 22542570456896 run_lib.py:133] step: 563400, training_loss: 2.74615e-02
I0210 20:01:34.846164 22542570456896 run_lib.py:146] step: 563400, eval_loss: 3.06837e-02
I0210 20:01:52.386858 22542570456896 run_lib.py:133] step: 563450, training_loss: 2.84820e-02
I0210 20:02:09.740982 22542570456896 run_lib.py:133] step: 563500, training_loss: 2.63727e-02
I0210 20:02:09.912359 22542570456896 run_lib.py:146] step: 563500, eval_loss: 2.36192e-02
I0210 20:02:27.358453 22542570456896 run_lib.py:133] step: 563550, training_loss: 4.04996e-02
I0210 20:02:44.928985 22542570456896 run_lib.py:133] step: 563600, training_loss: 2.88077e-02
I0210 20:02:45.085536 22542570456896 run_lib.py:146] step: 563600, eval_loss: 2.74792e-02
I0210 20:03:02.547466 22542570456896 run_lib.py:133] step: 563650, training_loss: 2.90746e-02
I0210 20:03:20.069009 22542570456896 run_lib.py:133] step: 563700, training_loss: 2.57422e-02
I0210 20:03:20.224398 22542570456896 run_lib.py:146] step: 563700, eval_loss: 2.76385e-02
I0210 20:03:37.647137 22542570456896 run_lib.py:133] step: 563750, training_loss: 2.66147e-02
I0210 20:03:55.007629 22542570456896 run_lib.py:133] step: 563800, training_loss: 2.55915e-02
I0210 20:03:55.159913 22542570456896 run_lib.py:146] step: 563800, eval_loss: 2.69124e-02
I0210 20:04:12.721885 22542570456896 run_lib.py:133] step: 563850, training_loss: 2.36788e-02
I0210 20:04:29.991391 22542570456896 run_lib.py:133] step: 563900, training_loss: 2.86374e-02
I0210 20:04:30.147357 22542570456896 run_lib.py:146] step: 563900, eval_loss: 2.77282e-02
I0210 20:04:47.379030 22542570456896 run_lib.py:133] step: 563950, training_loss: 3.35403e-02
I0210 20:05:04.879240 22542570456896 run_lib.py:133] step: 564000, training_loss: 3.05209e-02
I0210 20:05:05.041567 22542570456896 run_lib.py:146] step: 564000, eval_loss: 2.88250e-02
I0210 20:05:22.462673 22542570456896 run_lib.py:133] step: 564050, training_loss: 2.69261e-02
I0210 20:05:39.922379 22542570456896 run_lib.py:133] step: 564100, training_loss: 2.59843e-02
I0210 20:05:40.253593 22542570456896 run_lib.py:146] step: 564100, eval_loss: 2.77215e-02
I0210 20:05:57.680338 22542570456896 run_lib.py:133] step: 564150, training_loss: 2.14941e-02
I0210 20:06:15.125674 22542570456896 run_lib.py:133] step: 564200, training_loss: 3.02607e-02
I0210 20:06:15.280381 22542570456896 run_lib.py:146] step: 564200, eval_loss: 3.18948e-02
I0210 20:06:32.702645 22542570456896 run_lib.py:133] step: 564250, training_loss: 2.32783e-02
I0210 20:06:50.094155 22542570456896 run_lib.py:133] step: 564300, training_loss: 2.47460e-02
I0210 20:06:50.246306 22542570456896 run_lib.py:146] step: 564300, eval_loss: 3.09623e-02
I0210 20:07:07.789064 22542570456896 run_lib.py:133] step: 564350, training_loss: 3.05366e-02
I0210 20:07:25.315300 22542570456896 run_lib.py:133] step: 564400, training_loss: 2.73915e-02
I0210 20:07:25.483627 22542570456896 run_lib.py:146] step: 564400, eval_loss: 2.50851e-02
I0210 20:07:42.947275 22542570456896 run_lib.py:133] step: 564450, training_loss: 2.54056e-02
I0210 20:08:00.386274 22542570456896 run_lib.py:133] step: 564500, training_loss: 2.48040e-02
I0210 20:08:00.543442 22542570456896 run_lib.py:146] step: 564500, eval_loss: 2.50202e-02
I0210 20:08:18.112559 22542570456896 run_lib.py:133] step: 564550, training_loss: 2.98210e-02
I0210 20:08:35.555222 22542570456896 run_lib.py:133] step: 564600, training_loss: 2.39163e-02
I0210 20:08:35.712178 22542570456896 run_lib.py:146] step: 564600, eval_loss: 2.68494e-02
I0210 20:08:53.155846 22542570456896 run_lib.py:133] step: 564650, training_loss: 3.01470e-02
I0210 20:09:10.603982 22542570456896 run_lib.py:133] step: 564700, training_loss: 3.64374e-02
I0210 20:09:10.759461 22542570456896 run_lib.py:146] step: 564700, eval_loss: 3.00340e-02
I0210 20:09:28.372066 22542570456896 run_lib.py:133] step: 564750, training_loss: 2.78480e-02
I0210 20:09:45.802140 22542570456896 run_lib.py:133] step: 564800, training_loss: 2.64073e-02
I0210 20:09:45.954456 22542570456896 run_lib.py:146] step: 564800, eval_loss: 2.75275e-02
I0210 20:10:03.503228 22542570456896 run_lib.py:133] step: 564850, training_loss: 2.38483e-02
I0210 20:10:20.890229 22542570456896 run_lib.py:133] step: 564900, training_loss: 2.77692e-02
I0210 20:10:21.064288 22542570456896 run_lib.py:146] step: 564900, eval_loss: 3.16350e-02
I0210 20:10:38.657611 22542570456896 run_lib.py:133] step: 564950, training_loss: 2.84211e-02
I0210 20:10:56.087677 22542570456896 run_lib.py:133] step: 565000, training_loss: 2.79152e-02
I0210 20:10:56.243703 22542570456896 run_lib.py:146] step: 565000, eval_loss: 2.94391e-02
I0210 20:11:13.647441 22542570456896 run_lib.py:133] step: 565050, training_loss: 2.82402e-02
I0210 20:11:31.169741 22542570456896 run_lib.py:133] step: 565100, training_loss: 2.38289e-02
I0210 20:11:31.325328 22542570456896 run_lib.py:146] step: 565100, eval_loss: 2.93555e-02
I0210 20:11:48.722297 22542570456896 run_lib.py:133] step: 565150, training_loss: 2.49596e-02
I0210 20:12:06.337421 22542570456896 run_lib.py:133] step: 565200, training_loss: 2.70345e-02
I0210 20:12:06.487563 22542570456896 run_lib.py:146] step: 565200, eval_loss: 3.17316e-02
I0210 20:12:23.930460 22542570456896 run_lib.py:133] step: 565250, training_loss: 3.43072e-02
I0210 20:12:41.328660 22542570456896 run_lib.py:133] step: 565300, training_loss: 3.06542e-02
I0210 20:12:41.485478 22542570456896 run_lib.py:146] step: 565300, eval_loss: 2.74318e-02
I0210 20:12:59.037317 22542570456896 run_lib.py:133] step: 565350, training_loss: 1.99828e-02
I0210 20:13:16.430083 22542570456896 run_lib.py:133] step: 565400, training_loss: 2.37129e-02
I0210 20:13:16.592596 22542570456896 run_lib.py:146] step: 565400, eval_loss: 2.43648e-02
I0210 20:13:34.021282 22542570456896 run_lib.py:133] step: 565450, training_loss: 2.68338e-02
I0210 20:13:51.478134 22542570456896 run_lib.py:133] step: 565500, training_loss: 2.85893e-02
I0210 20:13:51.637632 22542570456896 run_lib.py:146] step: 565500, eval_loss: 3.43176e-02
I0210 20:14:09.242585 22542570456896 run_lib.py:133] step: 565550, training_loss: 2.45073e-02
I0210 20:14:26.689753 22542570456896 run_lib.py:133] step: 565600, training_loss: 2.68267e-02
I0210 20:14:26.846395 22542570456896 run_lib.py:146] step: 565600, eval_loss: 2.79375e-02
I0210 20:14:44.291832 22542570456896 run_lib.py:133] step: 565650, training_loss: 2.89813e-02
I0210 20:15:01.670396 22542570456896 run_lib.py:133] step: 565700, training_loss: 2.38348e-02
I0210 20:15:01.822337 22542570456896 run_lib.py:146] step: 565700, eval_loss: 2.73997e-02
I0210 20:15:19.200090 22542570456896 run_lib.py:133] step: 565750, training_loss: 2.54146e-02
I0210 20:15:36.644250 22542570456896 run_lib.py:133] step: 565800, training_loss: 3.19209e-02
I0210 20:15:36.812582 22542570456896 run_lib.py:146] step: 565800, eval_loss: 2.41862e-02
I0210 20:15:54.372789 22542570456896 run_lib.py:133] step: 565850, training_loss: 3.10274e-02
I0210 20:16:11.865644 22542570456896 run_lib.py:133] step: 565900, training_loss: 2.70868e-02
I0210 20:16:12.021492 22542570456896 run_lib.py:146] step: 565900, eval_loss: 2.44650e-02
I0210 20:16:29.442857 22542570456896 run_lib.py:133] step: 565950, training_loss: 2.68353e-02
I0210 20:16:46.835261 22542570456896 run_lib.py:133] step: 566000, training_loss: 3.25790e-02
I0210 20:16:46.995335 22542570456896 run_lib.py:146] step: 566000, eval_loss: 2.73921e-02
I0210 20:17:04.520339 22542570456896 run_lib.py:133] step: 566050, training_loss: 2.81611e-02
I0210 20:17:21.968540 22542570456896 run_lib.py:133] step: 566100, training_loss: 4.03759e-02
I0210 20:17:22.130604 22542570456896 run_lib.py:146] step: 566100, eval_loss: 3.78584e-02
I0210 20:17:39.765431 22542570456896 run_lib.py:133] step: 566150, training_loss: 2.69897e-02
I0210 20:17:57.178126 22542570456896 run_lib.py:133] step: 566200, training_loss: 2.87896e-02
I0210 20:17:57.327390 22542570456896 run_lib.py:146] step: 566200, eval_loss: 2.38204e-02
I0210 20:18:14.855915 22542570456896 run_lib.py:133] step: 566250, training_loss: 3.41494e-02
I0210 20:18:32.289298 22542570456896 run_lib.py:133] step: 566300, training_loss: 2.51452e-02
I0210 20:18:32.460237 22542570456896 run_lib.py:146] step: 566300, eval_loss: 3.57642e-02
I0210 20:18:50.138962 22542570456896 run_lib.py:133] step: 566350, training_loss: 2.72819e-02
I0210 20:19:07.583203 22542570456896 run_lib.py:133] step: 566400, training_loss: 2.82244e-02
I0210 20:19:07.740235 22542570456896 run_lib.py:146] step: 566400, eval_loss: 2.98955e-02
I0210 20:19:25.083842 22542570456896 run_lib.py:133] step: 566450, training_loss: 2.56881e-02
I0210 20:19:42.601543 22542570456896 run_lib.py:133] step: 566500, training_loss: 3.33885e-02
I0210 20:19:42.757442 22542570456896 run_lib.py:146] step: 566500, eval_loss: 2.64728e-02
I0210 20:20:00.144099 22542570456896 run_lib.py:133] step: 566550, training_loss: 2.13508e-02
I0210 20:20:17.550542 22542570456896 run_lib.py:133] step: 566600, training_loss: 3.20517e-02
I0210 20:20:17.705113 22542570456896 run_lib.py:146] step: 566600, eval_loss: 2.77567e-02
I0210 20:20:35.291253 22542570456896 run_lib.py:133] step: 566650, training_loss: 2.59084e-02
I0210 20:20:52.876145 22542570456896 run_lib.py:133] step: 566700, training_loss: 3.31352e-02
I0210 20:20:53.033852 22542570456896 run_lib.py:146] step: 566700, eval_loss: 2.20439e-02
I0210 20:21:10.439681 22542570456896 run_lib.py:133] step: 566750, training_loss: 2.35504e-02
I0210 20:21:27.840178 22542570456896 run_lib.py:133] step: 566800, training_loss: 3.76605e-02
I0210 20:21:28.007582 22542570456896 run_lib.py:146] step: 566800, eval_loss: 3.40118e-02
I0210 20:21:45.379172 22542570456896 run_lib.py:133] step: 566850, training_loss: 3.06463e-02
I0210 20:22:02.898171 22542570456896 run_lib.py:133] step: 566900, training_loss: 3.01509e-02
I0210 20:22:03.064228 22542570456896 run_lib.py:146] step: 566900, eval_loss: 2.32131e-02
I0210 20:22:20.534283 22542570456896 run_lib.py:133] step: 566950, training_loss: 2.93507e-02
I0210 20:22:37.901178 22542570456896 run_lib.py:133] step: 567000, training_loss: 2.67254e-02
I0210 20:22:38.056113 22542570456896 run_lib.py:146] step: 567000, eval_loss: 3.33524e-02
I0210 20:22:55.445422 22542570456896 run_lib.py:133] step: 567050, training_loss: 2.65625e-02
I0210 20:23:12.985467 22542570456896 run_lib.py:133] step: 567100, training_loss: 2.89332e-02
I0210 20:23:13.136120 22542570456896 run_lib.py:146] step: 567100, eval_loss: 2.33773e-02
I0210 20:23:30.504149 22542570456896 run_lib.py:133] step: 567150, training_loss: 2.08512e-02
I0210 20:23:47.942430 22542570456896 run_lib.py:133] step: 567200, training_loss: 2.71775e-02
I0210 20:23:48.107490 22542570456896 run_lib.py:146] step: 567200, eval_loss: 2.45519e-02
I0210 20:24:05.539077 22542570456896 run_lib.py:133] step: 567250, training_loss: 3.00346e-02
I0210 20:24:22.932509 22542570456896 run_lib.py:133] step: 567300, training_loss: 2.68197e-02
I0210 20:24:23.090287 22542570456896 run_lib.py:146] step: 567300, eval_loss: 3.14432e-02
I0210 20:24:40.642525 22542570456896 run_lib.py:133] step: 567350, training_loss: 2.99660e-02
I0210 20:24:58.101709 22542570456896 run_lib.py:133] step: 567400, training_loss: 2.72190e-02
I0210 20:24:58.254621 22542570456896 run_lib.py:146] step: 567400, eval_loss: 2.38799e-02
I0210 20:25:15.727651 22542570456896 run_lib.py:133] step: 567450, training_loss: 2.15506e-02
I0210 20:25:33.178233 22542570456896 run_lib.py:133] step: 567500, training_loss: 2.78192e-02
I0210 20:25:33.341019 22542570456896 run_lib.py:146] step: 567500, eval_loss: 3.64424e-02
I0210 20:25:50.938320 22542570456896 run_lib.py:133] step: 567550, training_loss: 2.60700e-02
I0210 20:26:08.297175 22542570456896 run_lib.py:133] step: 567600, training_loss: 2.62538e-02
I0210 20:26:08.448367 22542570456896 run_lib.py:146] step: 567600, eval_loss: 3.16293e-02
I0210 20:26:25.961878 22542570456896 run_lib.py:133] step: 567650, training_loss: 2.62264e-02
I0210 20:26:43.337122 22542570456896 run_lib.py:133] step: 567700, training_loss: 2.45302e-02
I0210 20:26:43.511989 22542570456896 run_lib.py:146] step: 567700, eval_loss: 3.25298e-02
I0210 20:27:01.059692 22542570456896 run_lib.py:133] step: 567750, training_loss: 2.44241e-02
I0210 20:27:18.471070 22542570456896 run_lib.py:133] step: 567800, training_loss: 2.90905e-02
I0210 20:27:18.629350 22542570456896 run_lib.py:146] step: 567800, eval_loss: 2.51161e-02
I0210 20:27:36.009695 22542570456896 run_lib.py:133] step: 567850, training_loss: 2.84222e-02
I0210 20:27:53.567894 22542570456896 run_lib.py:133] step: 567900, training_loss: 2.30378e-02
I0210 20:27:53.723570 22542570456896 run_lib.py:146] step: 567900, eval_loss: 2.65510e-02
I0210 20:28:11.101879 22542570456896 run_lib.py:133] step: 567950, training_loss: 2.39483e-02
I0210 20:28:28.610566 22542570456896 run_lib.py:133] step: 568000, training_loss: 3.12757e-02
I0210 20:28:28.767087 22542570456896 run_lib.py:146] step: 568000, eval_loss: 3.39197e-02
I0210 20:28:46.158492 22542570456896 run_lib.py:133] step: 568050, training_loss: 2.73643e-02
I0210 20:29:03.567921 22542570456896 run_lib.py:133] step: 568100, training_loss: 3.25735e-02
I0210 20:29:03.722528 22542570456896 run_lib.py:146] step: 568100, eval_loss: 2.11301e-02
I0210 20:29:21.330393 22542570456896 run_lib.py:133] step: 568150, training_loss: 2.26370e-02
I0210 20:29:38.712464 22542570456896 run_lib.py:133] step: 568200, training_loss: 3.19560e-02
I0210 20:29:38.869222 22542570456896 run_lib.py:146] step: 568200, eval_loss: 3.74374e-02
I0210 20:29:56.258677 22542570456896 run_lib.py:133] step: 568250, training_loss: 2.32488e-02
I0210 20:30:13.821654 22542570456896 run_lib.py:133] step: 568300, training_loss: 3.07495e-02
I0210 20:30:13.984287 22542570456896 run_lib.py:146] step: 568300, eval_loss: 2.67181e-02
I0210 20:30:31.434439 22542570456896 run_lib.py:133] step: 568350, training_loss: 2.91991e-02
I0210 20:30:48.818599 22542570456896 run_lib.py:133] step: 568400, training_loss: 2.29629e-02
I0210 20:30:48.978148 22542570456896 run_lib.py:146] step: 568400, eval_loss: 2.92359e-02
I0210 20:31:06.441659 22542570456896 run_lib.py:133] step: 568450, training_loss: 2.76395e-02
I0210 20:31:23.791119 22542570456896 run_lib.py:133] step: 568500, training_loss: 2.81065e-02
I0210 20:31:23.941603 22542570456896 run_lib.py:146] step: 568500, eval_loss: 2.69265e-02
I0210 20:31:41.328512 22542570456896 run_lib.py:133] step: 568550, training_loss: 3.96062e-02
I0210 20:31:58.722274 22542570456896 run_lib.py:133] step: 568600, training_loss: 2.62858e-02
I0210 20:31:58.876512 22542570456896 run_lib.py:146] step: 568600, eval_loss: 2.97729e-02
I0210 20:32:16.462711 22542570456896 run_lib.py:133] step: 568650, training_loss: 2.54975e-02
I0210 20:32:33.971096 22542570456896 run_lib.py:133] step: 568700, training_loss: 1.79549e-02
I0210 20:32:34.129289 22542570456896 run_lib.py:146] step: 568700, eval_loss: 3.65404e-02
I0210 20:32:51.489361 22542570456896 run_lib.py:133] step: 568750, training_loss: 2.83266e-02
I0210 20:33:08.887652 22542570456896 run_lib.py:133] step: 568800, training_loss: 3.09588e-02
I0210 20:33:09.048261 22542570456896 run_lib.py:146] step: 568800, eval_loss: 2.89066e-02
I0210 20:33:26.598127 22542570456896 run_lib.py:133] step: 568850, training_loss: 2.60264e-02
I0210 20:33:43.973123 22542570456896 run_lib.py:133] step: 568900, training_loss: 2.49369e-02
I0210 20:33:44.138997 22542570456896 run_lib.py:146] step: 568900, eval_loss: 3.23492e-02
I0210 20:34:01.707841 22542570456896 run_lib.py:133] step: 568950, training_loss: 2.77982e-02
I0210 20:34:19.116800 22542570456896 run_lib.py:133] step: 569000, training_loss: 2.49780e-02
I0210 20:34:19.269062 22542570456896 run_lib.py:146] step: 569000, eval_loss: 3.02381e-02
I0210 20:34:36.831377 22542570456896 run_lib.py:133] step: 569050, training_loss: 2.63657e-02
I0210 20:34:54.211497 22542570456896 run_lib.py:133] step: 569100, training_loss: 2.13108e-02
I0210 20:34:54.364328 22542570456896 run_lib.py:146] step: 569100, eval_loss: 2.90395e-02
I0210 20:35:11.931752 22542570456896 run_lib.py:133] step: 569150, training_loss: 2.29346e-02
I0210 20:35:29.388702 22542570456896 run_lib.py:133] step: 569200, training_loss: 3.03771e-02
I0210 20:35:29.546411 22542570456896 run_lib.py:146] step: 569200, eval_loss: 2.72114e-02
I0210 20:35:46.920740 22542570456896 run_lib.py:133] step: 569250, training_loss: 3.18934e-02
I0210 20:36:04.507430 22542570456896 run_lib.py:133] step: 569300, training_loss: 3.26995e-02
I0210 20:36:04.693348 22542570456896 run_lib.py:146] step: 569300, eval_loss: 2.83261e-02
I0210 20:36:22.034193 22542570456896 run_lib.py:133] step: 569350, training_loss: 3.57321e-02
I0210 20:36:39.387581 22542570456896 run_lib.py:133] step: 569400, training_loss: 3.47926e-02
I0210 20:36:39.543320 22542570456896 run_lib.py:146] step: 569400, eval_loss: 2.68836e-02
I0210 20:36:57.140736 22542570456896 run_lib.py:133] step: 569450, training_loss: 3.03750e-02
I0210 20:37:14.620682 22542570456896 run_lib.py:133] step: 569500, training_loss: 2.44712e-02
I0210 20:37:14.774972 22542570456896 run_lib.py:146] step: 569500, eval_loss: 2.83017e-02
I0210 20:37:32.385768 22542570456896 run_lib.py:133] step: 569550, training_loss: 2.95182e-02
I0210 20:37:49.844497 22542570456896 run_lib.py:133] step: 569600, training_loss: 2.40720e-02
I0210 20:37:50.004312 22542570456896 run_lib.py:146] step: 569600, eval_loss: 3.12849e-02
I0210 20:38:07.395158 22542570456896 run_lib.py:133] step: 569650, training_loss: 2.93388e-02
I0210 20:38:24.941060 22542570456896 run_lib.py:133] step: 569700, training_loss: 2.40283e-02
I0210 20:38:25.113286 22542570456896 run_lib.py:146] step: 569700, eval_loss: 2.85221e-02
I0210 20:38:42.603974 22542570456896 run_lib.py:133] step: 569750, training_loss: 2.83732e-02
I0210 20:39:00.022824 22542570456896 run_lib.py:133] step: 569800, training_loss: 2.27123e-02
I0210 20:39:00.185683 22542570456896 run_lib.py:146] step: 569800, eval_loss: 3.06613e-02
I0210 20:39:17.603383 22542570456896 run_lib.py:133] step: 569850, training_loss: 2.50776e-02
I0210 20:39:35.162811 22542570456896 run_lib.py:133] step: 569900, training_loss: 2.86734e-02
I0210 20:39:35.317319 22542570456896 run_lib.py:146] step: 569900, eval_loss: 3.12847e-02
I0210 20:39:52.700763 22542570456896 run_lib.py:133] step: 569950, training_loss: 2.35025e-02
I0210 20:40:10.180443 22542570456896 run_lib.py:133] step: 570000, training_loss: 2.99624e-02
I0210 20:40:10.893118 22542570456896 run_lib.py:146] step: 570000, eval_loss: 3.63123e-02
I0210 20:40:31.057225 22542570456896 run_lib.py:133] step: 570050, training_loss: 3.21870e-02
I0210 20:40:48.509951 22542570456896 run_lib.py:133] step: 570100, training_loss: 2.82272e-02
I0210 20:40:48.661345 22542570456896 run_lib.py:146] step: 570100, eval_loss: 2.57444e-02
I0210 20:41:06.222533 22542570456896 run_lib.py:133] step: 570150, training_loss: 2.72816e-02
I0210 20:41:23.614415 22542570456896 run_lib.py:133] step: 570200, training_loss: 2.90170e-02
I0210 20:41:23.777570 22542570456896 run_lib.py:146] step: 570200, eval_loss: 2.76672e-02
I0210 20:41:41.230987 22542570456896 run_lib.py:133] step: 570250, training_loss: 3.14583e-02
I0210 20:41:58.614107 22542570456896 run_lib.py:133] step: 570300, training_loss: 3.12257e-02
I0210 20:41:58.780410 22542570456896 run_lib.py:146] step: 570300, eval_loss: 3.18184e-02
I0210 20:42:16.214778 22542570456896 run_lib.py:133] step: 570350, training_loss: 2.44678e-02
I0210 20:42:33.678277 22542570456896 run_lib.py:133] step: 570400, training_loss: 2.30514e-02
I0210 20:42:33.836108 22542570456896 run_lib.py:146] step: 570400, eval_loss: 3.34972e-02
I0210 20:42:51.425667 22542570456896 run_lib.py:133] step: 570450, training_loss: 2.45598e-02
I0210 20:43:08.917478 22542570456896 run_lib.py:133] step: 570500, training_loss: 2.75545e-02
I0210 20:43:09.069378 22542570456896 run_lib.py:146] step: 570500, eval_loss: 2.30557e-02
I0210 20:43:26.428633 22542570456896 run_lib.py:133] step: 570550, training_loss: 3.07089e-02
I0210 20:43:43.857641 22542570456896 run_lib.py:133] step: 570600, training_loss: 3.01662e-02
I0210 20:43:44.022557 22542570456896 run_lib.py:146] step: 570600, eval_loss: 2.83432e-02
I0210 20:44:01.618463 22542570456896 run_lib.py:133] step: 570650, training_loss: 3.69976e-02
I0210 20:44:19.044390 22542570456896 run_lib.py:133] step: 570700, training_loss: 3.48152e-02
I0210 20:44:19.202514 22542570456896 run_lib.py:146] step: 570700, eval_loss: 3.15239e-02
I0210 20:44:36.742285 22542570456896 run_lib.py:133] step: 570750, training_loss: 2.75591e-02
I0210 20:44:54.130451 22542570456896 run_lib.py:133] step: 570800, training_loss: 3.21155e-02
I0210 20:44:54.296424 22542570456896 run_lib.py:146] step: 570800, eval_loss: 2.58459e-02
I0210 20:45:11.797864 22542570456896 run_lib.py:133] step: 570850, training_loss: 3.11127e-02
I0210 20:45:29.270432 22542570456896 run_lib.py:133] step: 570900, training_loss: 2.06428e-02
I0210 20:45:29.437504 22542570456896 run_lib.py:146] step: 570900, eval_loss: 2.90307e-02
I0210 20:45:46.874223 22542570456896 run_lib.py:133] step: 570950, training_loss: 2.92942e-02
I0210 20:46:04.485870 22542570456896 run_lib.py:133] step: 571000, training_loss: 2.80109e-02
I0210 20:46:04.636218 22542570456896 run_lib.py:146] step: 571000, eval_loss: 3.30476e-02
I0210 20:46:22.002529 22542570456896 run_lib.py:133] step: 571050, training_loss: 2.66203e-02
I0210 20:46:39.561443 22542570456896 run_lib.py:133] step: 571100, training_loss: 2.68589e-02
I0210 20:46:39.736104 22542570456896 run_lib.py:146] step: 571100, eval_loss: 3.25771e-02
I0210 20:46:57.184331 22542570456896 run_lib.py:133] step: 571150, training_loss: 2.69165e-02
I0210 20:47:14.682377 22542570456896 run_lib.py:133] step: 571200, training_loss: 3.37889e-02
I0210 20:47:14.841783 22542570456896 run_lib.py:146] step: 571200, eval_loss: 2.85763e-02
I0210 20:47:32.407399 22542570456896 run_lib.py:133] step: 571250, training_loss: 3.59983e-02
I0210 20:47:49.802127 22542570456896 run_lib.py:133] step: 571300, training_loss: 2.38426e-02
I0210 20:47:49.958413 22542570456896 run_lib.py:146] step: 571300, eval_loss: 2.95914e-02
I0210 20:48:07.389889 22542570456896 run_lib.py:133] step: 571350, training_loss: 2.51704e-02
I0210 20:48:24.941309 22542570456896 run_lib.py:133] step: 571400, training_loss: 3.04695e-02
I0210 20:48:25.096536 22542570456896 run_lib.py:146] step: 571400, eval_loss: 2.62415e-02
I0210 20:48:42.631555 22542570456896 run_lib.py:133] step: 571450, training_loss: 2.87110e-02
I0210 20:49:00.022042 22542570456896 run_lib.py:133] step: 571500, training_loss: 2.99224e-02
I0210 20:49:00.357182 22542570456896 run_lib.py:146] step: 571500, eval_loss: 1.77767e-02
I0210 20:49:17.740607 22542570456896 run_lib.py:133] step: 571550, training_loss: 3.00377e-02
I0210 20:49:35.127664 22542570456896 run_lib.py:133] step: 571600, training_loss: 2.24239e-02
I0210 20:49:35.285451 22542570456896 run_lib.py:146] step: 571600, eval_loss: 3.18958e-02
I0210 20:49:52.692221 22542570456896 run_lib.py:133] step: 571650, training_loss: 3.00142e-02
I0210 20:50:10.117195 22542570456896 run_lib.py:133] step: 571700, training_loss: 3.08154e-02
I0210 20:50:10.275265 22542570456896 run_lib.py:146] step: 571700, eval_loss: 3.12404e-02
I0210 20:50:27.828934 22542570456896 run_lib.py:133] step: 571750, training_loss: 2.40672e-02
I0210 20:50:45.311795 22542570456896 run_lib.py:133] step: 571800, training_loss: 2.09372e-02
I0210 20:50:45.467020 22542570456896 run_lib.py:146] step: 571800, eval_loss: 3.16750e-02
I0210 20:51:02.852034 22542570456896 run_lib.py:133] step: 571850, training_loss: 2.80124e-02
I0210 20:51:20.503407 22542570456896 run_lib.py:133] step: 571900, training_loss: 3.01392e-02
I0210 20:51:20.656136 22542570456896 run_lib.py:146] step: 571900, eval_loss: 3.13768e-02
I0210 20:51:38.220481 22542570456896 run_lib.py:133] step: 571950, training_loss: 3.15578e-02
I0210 20:51:55.726235 22542570456896 run_lib.py:133] step: 572000, training_loss: 2.80357e-02
I0210 20:51:55.880499 22542570456896 run_lib.py:146] step: 572000, eval_loss: 2.31896e-02
I0210 20:52:13.308120 22542570456896 run_lib.py:133] step: 572050, training_loss: 2.55682e-02
I0210 20:52:30.718592 22542570456896 run_lib.py:133] step: 572100, training_loss: 2.62559e-02
I0210 20:52:30.883854 22542570456896 run_lib.py:146] step: 572100, eval_loss: 3.00446e-02
I0210 20:52:48.428212 22542570456896 run_lib.py:133] step: 572150, training_loss: 2.99308e-02
I0210 20:53:05.815167 22542570456896 run_lib.py:133] step: 572200, training_loss: 2.15359e-02
I0210 20:53:05.983395 22542570456896 run_lib.py:146] step: 572200, eval_loss: 2.23059e-02
I0210 20:53:23.609350 22542570456896 run_lib.py:133] step: 572250, training_loss: 2.89627e-02
I0210 20:53:41.012724 22542570456896 run_lib.py:133] step: 572300, training_loss: 3.03464e-02
I0210 20:53:41.167587 22542570456896 run_lib.py:146] step: 572300, eval_loss: 3.24144e-02
I0210 20:53:58.768671 22542570456896 run_lib.py:133] step: 572350, training_loss: 2.89414e-02
I0210 20:54:16.172019 22542570456896 run_lib.py:133] step: 572400, training_loss: 3.31273e-02
I0210 20:54:16.323093 22542570456896 run_lib.py:146] step: 572400, eval_loss: 3.95796e-02
I0210 20:54:33.715321 22542570456896 run_lib.py:133] step: 572450, training_loss: 2.95010e-02
I0210 20:54:51.235581 22542570456896 run_lib.py:133] step: 572500, training_loss: 2.89659e-02
I0210 20:54:51.435521 22542570456896 run_lib.py:146] step: 572500, eval_loss: 3.60456e-02
I0210 20:55:08.874644 22542570456896 run_lib.py:133] step: 572550, training_loss: 3.03362e-02
I0210 20:55:26.437048 22542570456896 run_lib.py:133] step: 572600, training_loss: 2.55751e-02
I0210 20:55:26.595357 22542570456896 run_lib.py:146] step: 572600, eval_loss: 2.70919e-02
I0210 20:55:43.975675 22542570456896 run_lib.py:133] step: 572650, training_loss: 2.34999e-02
I0210 20:56:01.387596 22542570456896 run_lib.py:133] step: 572700, training_loss: 3.08490e-02
I0210 20:56:01.545515 22542570456896 run_lib.py:146] step: 572700, eval_loss: 2.11124e-02
I0210 20:56:19.094298 22542570456896 run_lib.py:133] step: 572750, training_loss: 2.53430e-02
I0210 20:56:36.574879 22542570456896 run_lib.py:133] step: 572800, training_loss: 3.64872e-02
I0210 20:56:36.732631 22542570456896 run_lib.py:146] step: 572800, eval_loss: 3.36011e-02
I0210 20:56:54.187217 22542570456896 run_lib.py:133] step: 572850, training_loss: 2.86657e-02
I0210 20:57:11.621613 22542570456896 run_lib.py:133] step: 572900, training_loss: 3.10497e-02
I0210 20:57:11.774456 22542570456896 run_lib.py:146] step: 572900, eval_loss: 3.06346e-02
I0210 20:57:29.357422 22542570456896 run_lib.py:133] step: 572950, training_loss: 2.45698e-02
I0210 20:57:46.769746 22542570456896 run_lib.py:133] step: 573000, training_loss: 2.51872e-02
I0210 20:57:46.927703 22542570456896 run_lib.py:146] step: 573000, eval_loss: 2.72406e-02
I0210 20:58:04.432829 22542570456896 run_lib.py:133] step: 573050, training_loss: 2.22701e-02
I0210 20:58:21.871289 22542570456896 run_lib.py:133] step: 573100, training_loss: 2.99946e-02
I0210 20:58:22.029296 22542570456896 run_lib.py:146] step: 573100, eval_loss: 3.31868e-02
I0210 20:58:39.448165 22542570456896 run_lib.py:133] step: 573150, training_loss: 2.81044e-02
I0210 20:58:56.871405 22542570456896 run_lib.py:133] step: 573200, training_loss: 1.99998e-02
I0210 20:58:57.029335 22542570456896 run_lib.py:146] step: 573200, eval_loss: 2.54403e-02
I0210 20:59:14.597775 22542570456896 run_lib.py:133] step: 573250, training_loss: 3.59862e-02
I0210 20:59:32.091467 22542570456896 run_lib.py:133] step: 573300, training_loss: 2.31023e-02
I0210 20:59:32.245547 22542570456896 run_lib.py:146] step: 573300, eval_loss: 3.47890e-02
I0210 20:59:49.816464 22542570456896 run_lib.py:133] step: 573350, training_loss: 2.69440e-02
I0210 21:00:07.252053 22542570456896 run_lib.py:133] step: 573400, training_loss: 2.80067e-02
I0210 21:00:07.404386 22542570456896 run_lib.py:146] step: 573400, eval_loss: 2.82988e-02
I0210 21:00:24.996193 22542570456896 run_lib.py:133] step: 573450, training_loss: 2.67012e-02
I0210 21:00:42.396036 22542570456896 run_lib.py:133] step: 573500, training_loss: 2.25489e-02
I0210 21:00:42.555749 22542570456896 run_lib.py:146] step: 573500, eval_loss: 3.27613e-02
I0210 21:01:00.120771 22542570456896 run_lib.py:133] step: 573550, training_loss: 2.59308e-02
I0210 21:01:17.642202 22542570456896 run_lib.py:133] step: 573600, training_loss: 2.77179e-02
I0210 21:01:17.794725 22542570456896 run_lib.py:146] step: 573600, eval_loss: 2.35252e-02
I0210 21:01:35.374373 22542570456896 run_lib.py:133] step: 573650, training_loss: 2.35809e-02
I0210 21:01:52.759946 22542570456896 run_lib.py:133] step: 573700, training_loss: 2.30530e-02
I0210 21:01:52.918126 22542570456896 run_lib.py:146] step: 573700, eval_loss: 2.62695e-02
I0210 21:02:10.480532 22542570456896 run_lib.py:133] step: 573750, training_loss: 2.51559e-02
I0210 21:02:27.914617 22542570456896 run_lib.py:133] step: 573800, training_loss: 1.74538e-02
I0210 21:02:28.067180 22542570456896 run_lib.py:146] step: 573800, eval_loss: 3.07962e-02
I0210 21:02:45.441812 22542570456896 run_lib.py:133] step: 573850, training_loss: 2.44259e-02
I0210 21:03:03.044118 22542570456896 run_lib.py:133] step: 573900, training_loss: 2.67548e-02
I0210 21:03:03.206491 22542570456896 run_lib.py:146] step: 573900, eval_loss: 2.89725e-02
I0210 21:03:20.638171 22542570456896 run_lib.py:133] step: 573950, training_loss: 2.61527e-02
I0210 21:03:38.036738 22542570456896 run_lib.py:133] step: 574000, training_loss: 2.78826e-02
I0210 21:03:38.199404 22542570456896 run_lib.py:146] step: 574000, eval_loss: 3.69695e-02
I0210 21:03:55.812047 22542570456896 run_lib.py:133] step: 574050, training_loss: 2.90624e-02
I0210 21:04:13.344204 22542570456896 run_lib.py:133] step: 574100, training_loss: 2.26786e-02
I0210 21:04:13.536230 22542570456896 run_lib.py:146] step: 574100, eval_loss: 2.32611e-02
I0210 21:04:30.975415 22542570456896 run_lib.py:133] step: 574150, training_loss: 2.65806e-02
I0210 21:04:48.465016 22542570456896 run_lib.py:133] step: 574200, training_loss: 2.97806e-02
I0210 21:04:48.620612 22542570456896 run_lib.py:146] step: 574200, eval_loss: 2.88577e-02
I0210 21:05:06.038132 22542570456896 run_lib.py:133] step: 574250, training_loss: 2.56477e-02
I0210 21:05:23.577953 22542570456896 run_lib.py:133] step: 574300, training_loss: 2.71074e-02
I0210 21:05:23.733277 22542570456896 run_lib.py:146] step: 574300, eval_loss: 2.34951e-02
I0210 21:05:41.131851 22542570456896 run_lib.py:133] step: 574350, training_loss: 2.57294e-02
I0210 21:05:58.548874 22542570456896 run_lib.py:133] step: 574400, training_loss: 3.41082e-02
I0210 21:05:58.707455 22542570456896 run_lib.py:146] step: 574400, eval_loss: 2.99610e-02
I0210 21:06:16.158572 22542570456896 run_lib.py:133] step: 574450, training_loss: 2.29659e-02
I0210 21:06:33.806633 22542570456896 run_lib.py:133] step: 574500, training_loss: 2.18425e-02
I0210 21:06:33.966450 22542570456896 run_lib.py:146] step: 574500, eval_loss: 2.75280e-02
I0210 21:06:51.379493 22542570456896 run_lib.py:133] step: 574550, training_loss: 2.35442e-02
I0210 21:07:08.836370 22542570456896 run_lib.py:133] step: 574600, training_loss: 2.79965e-02
I0210 21:07:08.990241 22542570456896 run_lib.py:146] step: 574600, eval_loss: 2.74792e-02
I0210 21:07:26.443975 22542570456896 run_lib.py:133] step: 574650, training_loss: 2.79469e-02
I0210 21:07:43.825295 22542570456896 run_lib.py:133] step: 574700, training_loss: 2.97219e-02
I0210 21:07:43.979353 22542570456896 run_lib.py:146] step: 574700, eval_loss: 2.97264e-02
I0210 21:08:01.505325 22542570456896 run_lib.py:133] step: 574750, training_loss: 2.43084e-02
I0210 21:08:19.036545 22542570456896 run_lib.py:133] step: 574800, training_loss: 2.34695e-02
I0210 21:08:19.220586 22542570456896 run_lib.py:146] step: 574800, eval_loss: 3.07747e-02
I0210 21:08:36.653463 22542570456896 run_lib.py:133] step: 574850, training_loss: 2.62619e-02
I0210 21:08:54.057117 22542570456896 run_lib.py:133] step: 574900, training_loss: 2.65908e-02
I0210 21:08:54.212268 22542570456896 run_lib.py:146] step: 574900, eval_loss: 3.04248e-02
I0210 21:09:11.720466 22542570456896 run_lib.py:133] step: 574950, training_loss: 2.93967e-02
I0210 21:09:29.143032 22542570456896 run_lib.py:133] step: 575000, training_loss: 2.42371e-02
I0210 21:09:29.315420 22542570456896 run_lib.py:146] step: 575000, eval_loss: 2.53802e-02
I0210 21:09:46.912207 22542570456896 run_lib.py:133] step: 575050, training_loss: 3.09047e-02
I0210 21:10:04.300199 22542570456896 run_lib.py:133] step: 575100, training_loss: 3.00562e-02
I0210 21:10:04.456471 22542570456896 run_lib.py:146] step: 575100, eval_loss: 2.41910e-02
I0210 21:10:22.092043 22542570456896 run_lib.py:133] step: 575150, training_loss: 2.70173e-02
I0210 21:10:39.427829 22542570456896 run_lib.py:133] step: 575200, training_loss: 3.87291e-02
I0210 21:10:39.583275 22542570456896 run_lib.py:146] step: 575200, eval_loss: 2.57131e-02
I0210 21:10:56.970575 22542570456896 run_lib.py:133] step: 575250, training_loss: 2.43258e-02
I0210 21:11:14.471424 22542570456896 run_lib.py:133] step: 575300, training_loss: 2.79291e-02
I0210 21:11:14.633238 22542570456896 run_lib.py:146] step: 575300, eval_loss: 3.67817e-02
I0210 21:11:32.158051 22542570456896 run_lib.py:133] step: 575350, training_loss: 2.92417e-02
I0210 21:11:49.769108 22542570456896 run_lib.py:133] step: 575400, training_loss: 2.81190e-02
I0210 21:11:49.931827 22542570456896 run_lib.py:146] step: 575400, eval_loss: 3.19731e-02
I0210 21:12:07.336543 22542570456896 run_lib.py:133] step: 575450, training_loss: 2.73340e-02
I0210 21:12:24.690645 22542570456896 run_lib.py:133] step: 575500, training_loss: 2.79309e-02
I0210 21:12:24.846531 22542570456896 run_lib.py:146] step: 575500, eval_loss: 2.94293e-02
I0210 21:12:42.391927 22542570456896 run_lib.py:133] step: 575550, training_loss: 2.81877e-02
I0210 21:12:59.731310 22542570456896 run_lib.py:133] step: 575600, training_loss: 2.69375e-02
I0210 21:12:59.885997 22542570456896 run_lib.py:146] step: 575600, eval_loss: 3.42276e-02
I0210 21:13:17.210748 22542570456896 run_lib.py:133] step: 575650, training_loss: 2.83912e-02
I0210 21:13:34.656067 22542570456896 run_lib.py:133] step: 575700, training_loss: 3.13322e-02
I0210 21:13:34.806895 22542570456896 run_lib.py:146] step: 575700, eval_loss: 2.78161e-02
I0210 21:13:52.114363 22542570456896 run_lib.py:133] step: 575750, training_loss: 2.59995e-02
I0210 21:14:09.591867 22542570456896 run_lib.py:133] step: 575800, training_loss: 2.59820e-02
I0210 21:14:09.748597 22542570456896 run_lib.py:146] step: 575800, eval_loss: 2.65329e-02
I0210 21:14:27.260287 22542570456896 run_lib.py:133] step: 575850, training_loss: 2.79557e-02
I0210 21:14:44.743155 22542570456896 run_lib.py:133] step: 575900, training_loss: 2.59689e-02
I0210 21:14:44.909275 22542570456896 run_lib.py:146] step: 575900, eval_loss: 2.53606e-02
I0210 21:15:02.318578 22542570456896 run_lib.py:133] step: 575950, training_loss: 2.88637e-02
I0210 21:15:19.720948 22542570456896 run_lib.py:133] step: 576000, training_loss: 2.73143e-02
I0210 21:15:19.880322 22542570456896 run_lib.py:146] step: 576000, eval_loss: 2.65859e-02
I0210 21:15:37.485062 22542570456896 run_lib.py:133] step: 576050, training_loss: 2.63256e-02
I0210 21:15:54.927629 22542570456896 run_lib.py:133] step: 576100, training_loss: 2.99537e-02
I0210 21:15:55.086540 22542570456896 run_lib.py:146] step: 576100, eval_loss: 2.63903e-02
I0210 21:16:12.508973 22542570456896 run_lib.py:133] step: 576150, training_loss: 2.91460e-02
I0210 21:16:29.934082 22542570456896 run_lib.py:133] step: 576200, training_loss: 2.88618e-02
I0210 21:16:30.087071 22542570456896 run_lib.py:146] step: 576200, eval_loss: 2.70880e-02
I0210 21:16:47.712723 22542570456896 run_lib.py:133] step: 576250, training_loss: 2.11478e-02
I0210 21:17:05.203101 22542570456896 run_lib.py:133] step: 576300, training_loss: 2.43671e-02
I0210 21:17:05.357568 22542570456896 run_lib.py:146] step: 576300, eval_loss: 3.29541e-02
I0210 21:17:22.914934 22542570456896 run_lib.py:133] step: 576350, training_loss: 2.72538e-02
I0210 21:17:40.300554 22542570456896 run_lib.py:133] step: 576400, training_loss: 2.58167e-02
I0210 21:17:40.473389 22542570456896 run_lib.py:146] step: 576400, eval_loss: 2.88381e-02
I0210 21:17:58.063523 22542570456896 run_lib.py:133] step: 576450, training_loss: 2.51663e-02
I0210 21:18:15.489118 22542570456896 run_lib.py:133] step: 576500, training_loss: 2.41659e-02
I0210 21:18:15.645508 22542570456896 run_lib.py:146] step: 576500, eval_loss: 3.05040e-02
I0210 21:18:33.263389 22542570456896 run_lib.py:133] step: 576550, training_loss: 2.61918e-02
I0210 21:18:50.644211 22542570456896 run_lib.py:133] step: 576600, training_loss: 2.91108e-02
I0210 21:18:50.796055 22542570456896 run_lib.py:146] step: 576600, eval_loss: 3.06365e-02
I0210 21:19:08.234947 22542570456896 run_lib.py:133] step: 576650, training_loss: 2.51322e-02
I0210 21:19:25.784509 22542570456896 run_lib.py:133] step: 576700, training_loss: 2.59961e-02
I0210 21:19:25.938579 22542570456896 run_lib.py:146] step: 576700, eval_loss: 2.26943e-02
I0210 21:19:43.423250 22542570456896 run_lib.py:133] step: 576750, training_loss: 2.33034e-02
I0210 21:20:00.808089 22542570456896 run_lib.py:133] step: 576800, training_loss: 3.16693e-02
I0210 21:20:00.966271 22542570456896 run_lib.py:146] step: 576800, eval_loss: 2.91524e-02
I0210 21:20:18.563690 22542570456896 run_lib.py:133] step: 576850, training_loss: 2.61055e-02
I0210 21:20:35.973722 22542570456896 run_lib.py:133] step: 576900, training_loss: 3.32050e-02
I0210 21:20:36.132673 22542570456896 run_lib.py:146] step: 576900, eval_loss: 2.69826e-02
I0210 21:20:53.688844 22542570456896 run_lib.py:133] step: 576950, training_loss: 3.01168e-02
I0210 21:21:11.126927 22542570456896 run_lib.py:133] step: 577000, training_loss: 3.63081e-02
I0210 21:21:11.288108 22542570456896 run_lib.py:146] step: 577000, eval_loss: 3.19984e-02
I0210 21:21:28.709043 22542570456896 run_lib.py:133] step: 577050, training_loss: 2.54383e-02
I0210 21:21:46.299194 22542570456896 run_lib.py:133] step: 577100, training_loss: 2.25697e-02
I0210 21:21:46.453304 22542570456896 run_lib.py:146] step: 577100, eval_loss: 3.57173e-02
I0210 21:22:03.895630 22542570456896 run_lib.py:133] step: 577150, training_loss: 3.02461e-02
I0210 21:22:21.300748 22542570456896 run_lib.py:133] step: 577200, training_loss: 2.99788e-02
I0210 21:22:21.457258 22542570456896 run_lib.py:146] step: 577200, eval_loss: 2.41438e-02
I0210 21:22:38.840390 22542570456896 run_lib.py:133] step: 577250, training_loss: 3.22247e-02
I0210 21:22:56.514175 22542570456896 run_lib.py:133] step: 577300, training_loss: 2.68984e-02
I0210 21:22:56.689905 22542570456896 run_lib.py:146] step: 577300, eval_loss: 2.88078e-02
I0210 21:23:14.097454 22542570456896 run_lib.py:133] step: 577350, training_loss: 2.68339e-02
I0210 21:23:31.550396 22542570456896 run_lib.py:133] step: 577400, training_loss: 2.84723e-02
I0210 21:23:31.705326 22542570456896 run_lib.py:146] step: 577400, eval_loss: 2.68381e-02
I0210 21:23:49.101664 22542570456896 run_lib.py:133] step: 577450, training_loss: 2.49377e-02
I0210 21:24:06.482345 22542570456896 run_lib.py:133] step: 577500, training_loss: 2.68984e-02
I0210 21:24:06.641418 22542570456896 run_lib.py:146] step: 577500, eval_loss: 2.36706e-02
I0210 21:24:24.201023 22542570456896 run_lib.py:133] step: 577550, training_loss: 2.68425e-02
I0210 21:24:41.721074 22542570456896 run_lib.py:133] step: 577600, training_loss: 2.25176e-02
I0210 21:24:41.878097 22542570456896 run_lib.py:146] step: 577600, eval_loss: 2.73063e-02
I0210 21:24:59.313762 22542570456896 run_lib.py:133] step: 577650, training_loss: 2.50738e-02
I0210 21:25:16.776577 22542570456896 run_lib.py:133] step: 577700, training_loss: 2.83524e-02
I0210 21:25:16.930352 22542570456896 run_lib.py:146] step: 577700, eval_loss: 3.22149e-02
I0210 21:25:34.688120 22542570456896 run_lib.py:133] step: 577750, training_loss: 3.04257e-02
I0210 21:25:52.118546 22542570456896 run_lib.py:133] step: 577800, training_loss: 1.95220e-02
I0210 21:25:52.300193 22542570456896 run_lib.py:146] step: 577800, eval_loss: 2.61631e-02
I0210 21:26:09.955291 22542570456896 run_lib.py:133] step: 577850, training_loss: 2.17564e-02
I0210 21:26:27.403526 22542570456896 run_lib.py:133] step: 577900, training_loss: 3.02049e-02
I0210 21:26:27.569613 22542570456896 run_lib.py:146] step: 577900, eval_loss: 2.31945e-02
I0210 21:26:45.143538 22542570456896 run_lib.py:133] step: 577950, training_loss: 3.14445e-02
I0210 21:27:02.597351 22542570456896 run_lib.py:133] step: 578000, training_loss: 2.66386e-02
I0210 21:27:02.753441 22542570456896 run_lib.py:146] step: 578000, eval_loss: 2.52024e-02
I0210 21:27:20.144234 22542570456896 run_lib.py:133] step: 578050, training_loss: 3.14540e-02
I0210 21:27:37.754436 22542570456896 run_lib.py:133] step: 578100, training_loss: 2.75954e-02
I0210 21:27:37.911643 22542570456896 run_lib.py:146] step: 578100, eval_loss: 2.32738e-02
I0210 21:27:55.390540 22542570456896 run_lib.py:133] step: 578150, training_loss: 2.36048e-02
I0210 21:28:12.971135 22542570456896 run_lib.py:133] step: 578200, training_loss: 2.90810e-02
I0210 21:28:13.127363 22542570456896 run_lib.py:146] step: 578200, eval_loss: 2.92344e-02
I0210 21:28:30.543070 22542570456896 run_lib.py:133] step: 578250, training_loss: 2.15649e-02
I0210 21:28:47.980058 22542570456896 run_lib.py:133] step: 578300, training_loss: 2.43685e-02
I0210 21:28:48.138827 22542570456896 run_lib.py:146] step: 578300, eval_loss: 3.26644e-02
I0210 21:29:05.684505 22542570456896 run_lib.py:133] step: 578350, training_loss: 2.62219e-02
I0210 21:29:23.169992 22542570456896 run_lib.py:133] step: 578400, training_loss: 3.07625e-02
I0210 21:29:23.327526 22542570456896 run_lib.py:146] step: 578400, eval_loss: 3.35537e-02
I0210 21:29:40.764073 22542570456896 run_lib.py:133] step: 578450, training_loss: 2.08616e-02
I0210 21:29:58.366143 22542570456896 run_lib.py:133] step: 578500, training_loss: 2.37056e-02
I0210 21:29:58.523839 22542570456896 run_lib.py:146] step: 578500, eval_loss: 2.98708e-02
I0210 21:30:15.919316 22542570456896 run_lib.py:133] step: 578550, training_loss: 2.83372e-02
I0210 21:30:33.359737 22542570456896 run_lib.py:133] step: 578600, training_loss: 3.31905e-02
I0210 21:30:33.653234 22542570456896 run_lib.py:146] step: 578600, eval_loss: 2.88400e-02
I0210 21:30:51.018858 22542570456896 run_lib.py:133] step: 578650, training_loss: 3.27319e-02
I0210 21:31:08.462991 22542570456896 run_lib.py:133] step: 578700, training_loss: 2.87949e-02
I0210 21:31:08.631058 22542570456896 run_lib.py:146] step: 578700, eval_loss: 2.63092e-02
I0210 21:31:26.030703 22542570456896 run_lib.py:133] step: 578750, training_loss: 2.85095e-02
I0210 21:31:43.441815 22542570456896 run_lib.py:133] step: 578800, training_loss: 3.29020e-02
I0210 21:31:43.600322 22542570456896 run_lib.py:146] step: 578800, eval_loss: 2.76766e-02
I0210 21:32:01.140303 22542570456896 run_lib.py:133] step: 578850, training_loss: 2.91637e-02
I0210 21:32:18.688959 22542570456896 run_lib.py:133] step: 578900, training_loss: 3.07698e-02
I0210 21:32:18.844331 22542570456896 run_lib.py:146] step: 578900, eval_loss: 3.10944e-02
I0210 21:32:36.249765 22542570456896 run_lib.py:133] step: 578950, training_loss: 2.74526e-02
I0210 21:32:53.703937 22542570456896 run_lib.py:133] step: 579000, training_loss: 3.26663e-02
I0210 21:32:53.858620 22542570456896 run_lib.py:146] step: 579000, eval_loss: 2.66296e-02
I0210 21:33:11.479389 22542570456896 run_lib.py:133] step: 579050, training_loss: 3.31367e-02
I0210 21:33:28.926306 22542570456896 run_lib.py:133] step: 579100, training_loss: 3.04839e-02
I0210 21:33:29.078249 22542570456896 run_lib.py:146] step: 579100, eval_loss: 2.68288e-02
I0210 21:33:46.435117 22542570456896 run_lib.py:133] step: 579150, training_loss: 2.40972e-02
I0210 21:34:03.815186 22542570456896 run_lib.py:133] step: 579200, training_loss: 2.12563e-02
I0210 21:34:04.022540 22542570456896 run_lib.py:146] step: 579200, eval_loss: 2.95230e-02
I0210 21:34:21.636120 22542570456896 run_lib.py:133] step: 579250, training_loss: 3.38457e-02
I0210 21:34:39.123722 22542570456896 run_lib.py:133] step: 579300, training_loss: 2.96556e-02
I0210 21:34:39.277777 22542570456896 run_lib.py:146] step: 579300, eval_loss: 2.46777e-02
I0210 21:34:56.842127 22542570456896 run_lib.py:133] step: 579350, training_loss: 2.80664e-02
I0210 21:35:14.181375 22542570456896 run_lib.py:133] step: 579400, training_loss: 3.34918e-02
I0210 21:35:14.337165 22542570456896 run_lib.py:146] step: 579400, eval_loss: 3.13261e-02
I0210 21:35:31.889850 22542570456896 run_lib.py:133] step: 579450, training_loss: 2.97957e-02
I0210 21:35:49.301238 22542570456896 run_lib.py:133] step: 579500, training_loss: 2.70371e-02
I0210 21:35:49.462203 22542570456896 run_lib.py:146] step: 579500, eval_loss: 3.19033e-02
I0210 21:36:06.919139 22542570456896 run_lib.py:133] step: 579550, training_loss: 3.25509e-02
I0210 21:36:24.533712 22542570456896 run_lib.py:133] step: 579600, training_loss: 2.52342e-02
I0210 21:36:24.688290 22542570456896 run_lib.py:146] step: 579600, eval_loss: 3.20189e-02
I0210 21:36:42.084877 22542570456896 run_lib.py:133] step: 579650, training_loss: 3.13976e-02
I0210 21:36:59.617516 22542570456896 run_lib.py:133] step: 579700, training_loss: 2.58251e-02
I0210 21:36:59.776595 22542570456896 run_lib.py:146] step: 579700, eval_loss: 3.00451e-02
I0210 21:37:17.208715 22542570456896 run_lib.py:133] step: 579750, training_loss: 2.53810e-02
I0210 21:37:34.647039 22542570456896 run_lib.py:133] step: 579800, training_loss: 3.30848e-02
I0210 21:37:34.800569 22542570456896 run_lib.py:146] step: 579800, eval_loss: 2.42145e-02
I0210 21:37:52.386922 22542570456896 run_lib.py:133] step: 579850, training_loss: 2.57044e-02
I0210 21:38:09.842068 22542570456896 run_lib.py:133] step: 579900, training_loss: 2.95511e-02
I0210 21:38:10.005355 22542570456896 run_lib.py:146] step: 579900, eval_loss: 2.78331e-02
I0210 21:38:27.390969 22542570456896 run_lib.py:133] step: 579950, training_loss: 2.03913e-02
I0210 21:38:44.793090 22542570456896 run_lib.py:133] step: 580000, training_loss: 3.25914e-02
I0210 21:38:45.819129 22542570456896 run_lib.py:146] step: 580000, eval_loss: 2.70441e-02
I0210 21:39:06.031563 22542570456896 run_lib.py:133] step: 580050, training_loss: 2.74604e-02
I0210 21:39:23.632988 22542570456896 run_lib.py:133] step: 580100, training_loss: 2.28014e-02
I0210 21:39:23.787637 22542570456896 run_lib.py:146] step: 580100, eval_loss: 2.50569e-02
I0210 21:39:41.203392 22542570456896 run_lib.py:133] step: 580150, training_loss: 2.76142e-02
I0210 21:39:58.598508 22542570456896 run_lib.py:133] step: 580200, training_loss: 3.16314e-02
I0210 21:39:58.754379 22542570456896 run_lib.py:146] step: 580200, eval_loss: 3.09673e-02
I0210 21:40:16.295004 22542570456896 run_lib.py:133] step: 580250, training_loss: 2.38214e-02
I0210 21:40:33.698464 22542570456896 run_lib.py:133] step: 580300, training_loss: 2.71938e-02
I0210 21:40:33.870656 22542570456896 run_lib.py:146] step: 580300, eval_loss: 3.21850e-02
I0210 21:40:51.313961 22542570456896 run_lib.py:133] step: 580350, training_loss: 2.61507e-02
I0210 21:41:08.774395 22542570456896 run_lib.py:133] step: 580400, training_loss: 2.29010e-02
I0210 21:41:08.930085 22542570456896 run_lib.py:146] step: 580400, eval_loss: 3.47648e-02
I0210 21:41:26.551654 22542570456896 run_lib.py:133] step: 580450, training_loss: 2.97510e-02
I0210 21:41:43.961909 22542570456896 run_lib.py:133] step: 580500, training_loss: 2.59685e-02
I0210 21:41:44.116360 22542570456896 run_lib.py:146] step: 580500, eval_loss: 2.77847e-02
I0210 21:42:01.568472 22542570456896 run_lib.py:133] step: 580550, training_loss: 2.10791e-02
I0210 21:42:18.992566 22542570456896 run_lib.py:133] step: 580600, training_loss: 2.83774e-02
I0210 21:42:19.147643 22542570456896 run_lib.py:146] step: 580600, eval_loss: 2.79794e-02
I0210 21:42:36.601032 22542570456896 run_lib.py:133] step: 580650, training_loss: 2.45850e-02
I0210 21:42:54.051410 22542570456896 run_lib.py:133] step: 580700, training_loss: 3.02227e-02
I0210 21:42:54.224365 22542570456896 run_lib.py:146] step: 580700, eval_loss: 2.54211e-02
I0210 21:43:11.787044 22542570456896 run_lib.py:133] step: 580750, training_loss: 2.46315e-02
I0210 21:43:29.247097 22542570456896 run_lib.py:133] step: 580800, training_loss: 2.87804e-02
I0210 21:43:29.401479 22542570456896 run_lib.py:146] step: 580800, eval_loss: 2.37204e-02
I0210 21:43:46.837393 22542570456896 run_lib.py:133] step: 580850, training_loss: 3.61576e-02
I0210 21:44:04.242165 22542570456896 run_lib.py:133] step: 580900, training_loss: 3.41055e-02
I0210 21:44:04.413257 22542570456896 run_lib.py:146] step: 580900, eval_loss: 2.73670e-02
I0210 21:44:22.006585 22542570456896 run_lib.py:133] step: 580950, training_loss: 3.58263e-02
I0210 21:44:39.505832 22542570456896 run_lib.py:133] step: 581000, training_loss: 2.36984e-02
I0210 21:44:39.658118 22542570456896 run_lib.py:146] step: 581000, eval_loss: 2.95870e-02
I0210 21:44:57.267334 22542570456896 run_lib.py:133] step: 581050, training_loss: 2.89800e-02
I0210 21:45:14.692137 22542570456896 run_lib.py:133] step: 581100, training_loss: 2.72747e-02
I0210 21:45:14.847090 22542570456896 run_lib.py:146] step: 581100, eval_loss: 3.18912e-02
I0210 21:45:32.370258 22542570456896 run_lib.py:133] step: 581150, training_loss: 2.48290e-02
I0210 21:45:49.781325 22542570456896 run_lib.py:133] step: 581200, training_loss: 2.50089e-02
I0210 21:45:49.954438 22542570456896 run_lib.py:146] step: 581200, eval_loss: 2.94530e-02
I0210 21:46:07.606583 22542570456896 run_lib.py:133] step: 581250, training_loss: 2.62559e-02
I0210 21:46:25.013908 22542570456896 run_lib.py:133] step: 581300, training_loss: 2.54088e-02
I0210 21:46:25.169689 22542570456896 run_lib.py:146] step: 581300, eval_loss: 2.69431e-02
I0210 21:46:42.575729 22542570456896 run_lib.py:133] step: 581350, training_loss: 2.84696e-02
I0210 21:47:00.200019 22542570456896 run_lib.py:133] step: 581400, training_loss: 2.79143e-02
I0210 21:47:00.355316 22542570456896 run_lib.py:146] step: 581400, eval_loss: 2.55797e-02
I0210 21:47:17.784838 22542570456896 run_lib.py:133] step: 581450, training_loss: 2.47950e-02
I0210 21:47:35.223417 22542570456896 run_lib.py:133] step: 581500, training_loss: 2.96172e-02
I0210 21:47:35.376617 22542570456896 run_lib.py:146] step: 581500, eval_loss: 3.73406e-02
I0210 21:47:53.050336 22542570456896 run_lib.py:133] step: 581550, training_loss: 2.54935e-02
I0210 21:48:10.441954 22542570456896 run_lib.py:133] step: 581600, training_loss: 2.31317e-02
I0210 21:48:10.598356 22542570456896 run_lib.py:146] step: 581600, eval_loss: 3.26382e-02
I0210 21:48:28.137433 22542570456896 run_lib.py:133] step: 581650, training_loss: 1.94092e-02
I0210 21:48:45.625525 22542570456896 run_lib.py:133] step: 581700, training_loss: 2.61318e-02
I0210 21:48:45.797085 22542570456896 run_lib.py:146] step: 581700, eval_loss: 3.35135e-02
I0210 21:49:03.220742 22542570456896 run_lib.py:133] step: 581750, training_loss: 3.08526e-02
I0210 21:49:20.865321 22542570456896 run_lib.py:133] step: 581800, training_loss: 1.89043e-02
I0210 21:49:21.021567 22542570456896 run_lib.py:146] step: 581800, eval_loss: 2.28105e-02
I0210 21:49:38.464145 22542570456896 run_lib.py:133] step: 581850, training_loss: 2.40325e-02
I0210 21:49:55.814598 22542570456896 run_lib.py:133] step: 581900, training_loss: 2.47770e-02
I0210 21:49:55.971426 22542570456896 run_lib.py:146] step: 581900, eval_loss: 2.17512e-02
I0210 21:50:13.395059 22542570456896 run_lib.py:133] step: 581950, training_loss: 2.56656e-02
I0210 21:50:30.997370 22542570456896 run_lib.py:133] step: 582000, training_loss: 2.84442e-02
I0210 21:50:31.150762 22542570456896 run_lib.py:146] step: 582000, eval_loss: 2.85796e-02
I0210 21:50:48.602160 22542570456896 run_lib.py:133] step: 582050, training_loss: 2.61701e-02
I0210 21:51:06.120453 22542570456896 run_lib.py:133] step: 582100, training_loss: 2.69862e-02
I0210 21:51:06.277851 22542570456896 run_lib.py:146] step: 582100, eval_loss: 2.94916e-02
I0210 21:51:23.708508 22542570456896 run_lib.py:133] step: 582150, training_loss: 2.91763e-02
I0210 21:51:41.156838 22542570456896 run_lib.py:133] step: 582200, training_loss: 2.85364e-02
I0210 21:51:41.312473 22542570456896 run_lib.py:146] step: 582200, eval_loss: 3.10883e-02
I0210 21:51:58.895804 22542570456896 run_lib.py:133] step: 582250, training_loss: 2.69117e-02
I0210 21:52:16.390808 22542570456896 run_lib.py:133] step: 582300, training_loss: 2.79415e-02
I0210 21:52:16.550674 22542570456896 run_lib.py:146] step: 582300, eval_loss: 3.67499e-02
I0210 21:52:33.980464 22542570456896 run_lib.py:133] step: 582350, training_loss: 2.92870e-02
I0210 21:52:51.428402 22542570456896 run_lib.py:133] step: 582400, training_loss: 3.46254e-02
I0210 21:52:51.582101 22542570456896 run_lib.py:146] step: 582400, eval_loss: 2.58333e-02
I0210 21:53:09.181614 22542570456896 run_lib.py:133] step: 582450, training_loss: 3.11535e-02
I0210 21:53:26.568047 22542570456896 run_lib.py:133] step: 582500, training_loss: 2.32370e-02
I0210 21:53:26.720294 22542570456896 run_lib.py:146] step: 582500, eval_loss: 3.52578e-02
I0210 21:53:44.271103 22542570456896 run_lib.py:133] step: 582550, training_loss: 2.69668e-02
I0210 21:54:01.713533 22542570456896 run_lib.py:133] step: 582600, training_loss: 2.46532e-02
I0210 21:54:01.889332 22542570456896 run_lib.py:146] step: 582600, eval_loss: 2.63103e-02
I0210 21:54:19.490001 22542570456896 run_lib.py:133] step: 582650, training_loss: 2.53521e-02
I0210 21:54:37.001408 22542570456896 run_lib.py:133] step: 582700, training_loss: 2.54957e-02
I0210 21:54:37.156428 22542570456896 run_lib.py:146] step: 582700, eval_loss: 2.92324e-02
I0210 21:54:54.531419 22542570456896 run_lib.py:133] step: 582750, training_loss: 3.04488e-02
I0210 21:55:12.130161 22542570456896 run_lib.py:133] step: 582800, training_loss: 2.69402e-02
I0210 21:55:12.286077 22542570456896 run_lib.py:146] step: 582800, eval_loss: 2.30184e-02
I0210 21:55:29.748630 22542570456896 run_lib.py:133] step: 582850, training_loss: 2.79043e-02
I0210 21:55:47.313754 22542570456896 run_lib.py:133] step: 582900, training_loss: 2.87775e-02
I0210 21:55:47.466057 22542570456896 run_lib.py:146] step: 582900, eval_loss: 2.90386e-02
I0210 21:56:04.909412 22542570456896 run_lib.py:133] step: 582950, training_loss: 2.39236e-02
I0210 21:56:22.331652 22542570456896 run_lib.py:133] step: 583000, training_loss: 3.66640e-02
I0210 21:56:22.486184 22542570456896 run_lib.py:146] step: 583000, eval_loss: 3.28447e-02
I0210 21:56:40.067575 22542570456896 run_lib.py:133] step: 583050, training_loss: 3.22792e-02
I0210 21:56:57.466005 22542570456896 run_lib.py:133] step: 583100, training_loss: 2.49092e-02
I0210 21:56:57.634000 22542570456896 run_lib.py:146] step: 583100, eval_loss: 3.10669e-02
I0210 21:57:15.081029 22542570456896 run_lib.py:133] step: 583150, training_loss: 2.62008e-02
I0210 21:57:32.704807 22542570456896 run_lib.py:133] step: 583200, training_loss: 2.81465e-02
I0210 21:57:32.860471 22542570456896 run_lib.py:146] step: 583200, eval_loss: 3.25938e-02
I0210 21:57:50.290718 22542570456896 run_lib.py:133] step: 583250, training_loss: 2.80978e-02
I0210 21:58:07.668614 22542570456896 run_lib.py:133] step: 583300, training_loss: 2.46104e-02
I0210 21:58:08.008228 22542570456896 run_lib.py:146] step: 583300, eval_loss: 2.51248e-02
I0210 21:58:25.385051 22542570456896 run_lib.py:133] step: 583350, training_loss: 3.02688e-02
I0210 21:58:42.838766 22542570456896 run_lib.py:133] step: 583400, training_loss: 2.65702e-02
I0210 21:58:42.993302 22542570456896 run_lib.py:146] step: 583400, eval_loss: 2.77818e-02
I0210 21:59:00.462018 22542570456896 run_lib.py:133] step: 583450, training_loss: 2.75936e-02
I0210 21:59:17.852897 22542570456896 run_lib.py:133] step: 583500, training_loss: 3.08028e-02
I0210 21:59:18.009517 22542570456896 run_lib.py:146] step: 583500, eval_loss: 2.18806e-02
I0210 21:59:35.623974 22542570456896 run_lib.py:133] step: 583550, training_loss: 2.37434e-02
I0210 21:59:53.114200 22542570456896 run_lib.py:133] step: 583600, training_loss: 2.85397e-02
I0210 21:59:53.270675 22542570456896 run_lib.py:146] step: 583600, eval_loss: 3.48852e-02
I0210 22:00:10.852538 22542570456896 run_lib.py:133] step: 583650, training_loss: 2.50050e-02
I0210 22:00:28.244887 22542570456896 run_lib.py:133] step: 583700, training_loss: 2.95550e-02
I0210 22:00:28.404229 22542570456896 run_lib.py:146] step: 583700, eval_loss: 3.26497e-02
I0210 22:00:46.033846 22542570456896 run_lib.py:133] step: 583750, training_loss: 3.36291e-02
I0210 22:01:03.566115 22542570456896 run_lib.py:133] step: 583800, training_loss: 2.91685e-02
I0210 22:01:03.721551 22542570456896 run_lib.py:146] step: 583800, eval_loss: 3.43772e-02
I0210 22:01:21.156729 22542570456896 run_lib.py:133] step: 583850, training_loss: 2.89828e-02
I0210 22:01:38.580713 22542570456896 run_lib.py:133] step: 583900, training_loss: 3.13211e-02
I0210 22:01:38.733127 22542570456896 run_lib.py:146] step: 583900, eval_loss: 3.13620e-02
I0210 22:01:56.275103 22542570456896 run_lib.py:133] step: 583950, training_loss: 2.97973e-02
I0210 22:02:13.697997 22542570456896 run_lib.py:133] step: 584000, training_loss: 3.14165e-02
I0210 22:02:13.875329 22542570456896 run_lib.py:146] step: 584000, eval_loss: 3.02615e-02
I0210 22:02:31.499688 22542570456896 run_lib.py:133] step: 584050, training_loss: 2.83486e-02
I0210 22:02:48.937299 22542570456896 run_lib.py:133] step: 584100, training_loss: 3.56783e-02
I0210 22:02:49.095259 22542570456896 run_lib.py:146] step: 584100, eval_loss: 2.77862e-02
I0210 22:03:06.672616 22542570456896 run_lib.py:133] step: 584150, training_loss: 3.25645e-02
I0210 22:03:24.072713 22542570456896 run_lib.py:133] step: 584200, training_loss: 2.54510e-02
I0210 22:03:24.228152 22542570456896 run_lib.py:146] step: 584200, eval_loss: 2.54743e-02
I0210 22:03:41.664282 22542570456896 run_lib.py:133] step: 584250, training_loss: 2.77745e-02
I0210 22:03:59.266738 22542570456896 run_lib.py:133] step: 584300, training_loss: 2.37136e-02
I0210 22:03:59.422172 22542570456896 run_lib.py:146] step: 584300, eval_loss: 3.36052e-02
I0210 22:04:16.905719 22542570456896 run_lib.py:133] step: 584350, training_loss: 2.42995e-02
I0210 22:04:34.484114 22542570456896 run_lib.py:133] step: 584400, training_loss: 2.98064e-02
I0210 22:04:34.637372 22542570456896 run_lib.py:146] step: 584400, eval_loss: 3.18802e-02
I0210 22:04:52.036364 22542570456896 run_lib.py:133] step: 584450, training_loss: 3.08394e-02
I0210 22:05:09.426703 22542570456896 run_lib.py:133] step: 584500, training_loss: 3.04624e-02
I0210 22:05:09.584638 22542570456896 run_lib.py:146] step: 584500, eval_loss: 2.20527e-02
I0210 22:05:27.157459 22542570456896 run_lib.py:133] step: 584550, training_loss: 3.06074e-02
I0210 22:05:44.617670 22542570456896 run_lib.py:133] step: 584600, training_loss: 2.96544e-02
I0210 22:05:44.773568 22542570456896 run_lib.py:146] step: 584600, eval_loss: 2.96998e-02
I0210 22:06:02.244023 22542570456896 run_lib.py:133] step: 584650, training_loss: 3.15716e-02
I0210 22:06:19.666809 22542570456896 run_lib.py:133] step: 584700, training_loss: 2.78458e-02
I0210 22:06:19.820550 22542570456896 run_lib.py:146] step: 584700, eval_loss: 3.35735e-02
I0210 22:06:37.426705 22542570456896 run_lib.py:133] step: 584750, training_loss: 3.15849e-02
I0210 22:06:54.806059 22542570456896 run_lib.py:133] step: 584800, training_loss: 3.00707e-02
I0210 22:06:54.956350 22542570456896 run_lib.py:146] step: 584800, eval_loss: 2.58059e-02
I0210 22:07:12.433089 22542570456896 run_lib.py:133] step: 584850, training_loss: 2.94325e-02
I0210 22:07:29.861111 22542570456896 run_lib.py:133] step: 584900, training_loss: 3.00793e-02
I0210 22:07:30.029559 22542570456896 run_lib.py:146] step: 584900, eval_loss: 2.34040e-02
I0210 22:07:47.465074 22542570456896 run_lib.py:133] step: 584950, training_loss: 2.54050e-02
I0210 22:08:04.883516 22542570456896 run_lib.py:133] step: 585000, training_loss: 2.82478e-02
I0210 22:08:05.040489 22542570456896 run_lib.py:146] step: 585000, eval_loss: 2.88744e-02
I0210 22:08:22.607917 22542570456896 run_lib.py:133] step: 585050, training_loss: 2.41284e-02
I0210 22:08:40.113364 22542570456896 run_lib.py:133] step: 585100, training_loss: 2.80698e-02
I0210 22:08:40.292317 22542570456896 run_lib.py:146] step: 585100, eval_loss: 3.03695e-02
I0210 22:08:57.719894 22542570456896 run_lib.py:133] step: 585150, training_loss: 2.90733e-02
I0210 22:09:15.184429 22542570456896 run_lib.py:133] step: 585200, training_loss: 2.54929e-02
I0210 22:09:15.339144 22542570456896 run_lib.py:146] step: 585200, eval_loss: 3.07076e-02
I0210 22:09:32.949571 22542570456896 run_lib.py:133] step: 585250, training_loss: 2.67292e-02
I0210 22:09:50.366394 22542570456896 run_lib.py:133] step: 585300, training_loss: 2.72485e-02
I0210 22:09:50.517319 22542570456896 run_lib.py:146] step: 585300, eval_loss: 2.85556e-02
I0210 22:10:08.069233 22542570456896 run_lib.py:133] step: 585350, training_loss: 2.63075e-02
I0210 22:10:25.490508 22542570456896 run_lib.py:133] step: 585400, training_loss: 2.75439e-02
I0210 22:10:25.659681 22542570456896 run_lib.py:146] step: 585400, eval_loss: 2.07101e-02
I0210 22:10:43.282364 22542570456896 run_lib.py:133] step: 585450, training_loss: 2.22916e-02
I0210 22:11:00.732208 22542570456896 run_lib.py:133] step: 585500, training_loss: 2.31429e-02
I0210 22:11:00.889227 22542570456896 run_lib.py:146] step: 585500, eval_loss: 3.17299e-02
I0210 22:11:18.467255 22542570456896 run_lib.py:133] step: 585550, training_loss: 2.79371e-02
I0210 22:11:35.907229 22542570456896 run_lib.py:133] step: 585600, training_loss: 2.75061e-02
I0210 22:11:36.065385 22542570456896 run_lib.py:146] step: 585600, eval_loss: 2.01358e-02
I0210 22:11:53.537643 22542570456896 run_lib.py:133] step: 585650, training_loss: 2.99168e-02
I0210 22:12:11.132384 22542570456896 run_lib.py:133] step: 585700, training_loss: 3.76303e-02
I0210 22:12:11.286584 22542570456896 run_lib.py:146] step: 585700, eval_loss: 2.85303e-02
I0210 22:12:28.695123 22542570456896 run_lib.py:133] step: 585750, training_loss: 2.70166e-02
I0210 22:12:46.112200 22542570456896 run_lib.py:133] step: 585800, training_loss: 2.45184e-02
I0210 22:12:46.263241 22542570456896 run_lib.py:146] step: 585800, eval_loss: 2.91236e-02
I0210 22:13:03.838296 22542570456896 run_lib.py:133] step: 585850, training_loss: 3.30270e-02
I0210 22:13:21.431477 22542570456896 run_lib.py:133] step: 585900, training_loss: 2.55288e-02
I0210 22:13:21.589744 22542570456896 run_lib.py:146] step: 585900, eval_loss: 2.37076e-02
I0210 22:13:39.032492 22542570456896 run_lib.py:133] step: 585950, training_loss: 2.54760e-02
I0210 22:13:56.482785 22542570456896 run_lib.py:133] step: 586000, training_loss: 2.05773e-02
I0210 22:13:56.646385 22542570456896 run_lib.py:146] step: 586000, eval_loss: 3.16020e-02
I0210 22:14:14.081185 22542570456896 run_lib.py:133] step: 586050, training_loss: 2.94096e-02
I0210 22:14:31.673642 22542570456896 run_lib.py:133] step: 586100, training_loss: 2.76851e-02
I0210 22:14:31.829202 22542570456896 run_lib.py:146] step: 586100, eval_loss: 3.40232e-02
I0210 22:14:49.276652 22542570456896 run_lib.py:133] step: 586150, training_loss: 3.41484e-02
I0210 22:15:06.734608 22542570456896 run_lib.py:133] step: 586200, training_loss: 2.84159e-02
I0210 22:15:06.890616 22542570456896 run_lib.py:146] step: 586200, eval_loss: 2.45362e-02
I0210 22:15:24.381920 22542570456896 run_lib.py:133] step: 586250, training_loss: 2.75159e-02
I0210 22:15:42.044012 22542570456896 run_lib.py:133] step: 586300, training_loss: 2.89132e-02
I0210 22:15:42.198405 22542570456896 run_lib.py:146] step: 586300, eval_loss: 2.71978e-02
I0210 22:15:59.616319 22542570456896 run_lib.py:133] step: 586350, training_loss: 3.28796e-02
I0210 22:16:17.092194 22542570456896 run_lib.py:133] step: 586400, training_loss: 2.53840e-02
I0210 22:16:17.253597 22542570456896 run_lib.py:146] step: 586400, eval_loss: 2.88082e-02
I0210 22:16:34.682090 22542570456896 run_lib.py:133] step: 586450, training_loss: 2.92172e-02
I0210 22:16:52.144170 22542570456896 run_lib.py:133] step: 586500, training_loss: 2.57796e-02
I0210 22:16:52.300582 22542570456896 run_lib.py:146] step: 586500, eval_loss: 3.00673e-02
I0210 22:17:09.883110 22542570456896 run_lib.py:133] step: 586550, training_loss: 2.97498e-02
I0210 22:17:27.315053 22542570456896 run_lib.py:133] step: 586600, training_loss: 2.58078e-02
I0210 22:17:27.487491 22542570456896 run_lib.py:146] step: 586600, eval_loss: 3.27072e-02
I0210 22:17:44.871996 22542570456896 run_lib.py:133] step: 586650, training_loss: 2.56722e-02
I0210 22:18:02.323944 22542570456896 run_lib.py:133] step: 586700, training_loss: 2.65468e-02
I0210 22:18:02.475274 22542570456896 run_lib.py:146] step: 586700, eval_loss: 2.71313e-02
I0210 22:18:20.013116 22542570456896 run_lib.py:133] step: 586750, training_loss: 2.74645e-02
I0210 22:18:37.460462 22542570456896 run_lib.py:133] step: 586800, training_loss: 2.80936e-02
I0210 22:18:37.625521 22542570456896 run_lib.py:146] step: 586800, eval_loss: 3.03068e-02
I0210 22:18:55.326812 22542570456896 run_lib.py:133] step: 586850, training_loss: 2.67287e-02
I0210 22:19:12.786176 22542570456896 run_lib.py:133] step: 586900, training_loss: 3.09750e-02
I0210 22:19:12.942476 22542570456896 run_lib.py:146] step: 586900, eval_loss: 2.96570e-02
I0210 22:19:30.502426 22542570456896 run_lib.py:133] step: 586950, training_loss: 2.69038e-02
I0210 22:19:47.898420 22542570456896 run_lib.py:133] step: 587000, training_loss: 1.83022e-02
I0210 22:19:48.064283 22542570456896 run_lib.py:146] step: 587000, eval_loss: 2.36228e-02
I0210 22:20:05.472720 22542570456896 run_lib.py:133] step: 587050, training_loss: 2.64608e-02
I0210 22:20:23.135611 22542570456896 run_lib.py:133] step: 587100, training_loss: 3.00502e-02
I0210 22:20:23.291481 22542570456896 run_lib.py:146] step: 587100, eval_loss: 2.87589e-02
I0210 22:20:40.709778 22542570456896 run_lib.py:133] step: 587150, training_loss: 3.59755e-02
I0210 22:20:58.292010 22542570456896 run_lib.py:133] step: 587200, training_loss: 2.85429e-02
I0210 22:20:58.443657 22542570456896 run_lib.py:146] step: 587200, eval_loss: 2.95587e-02
I0210 22:21:15.825028 22542570456896 run_lib.py:133] step: 587250, training_loss: 2.79731e-02
I0210 22:21:33.209735 22542570456896 run_lib.py:133] step: 587300, training_loss: 2.81989e-02
I0210 22:21:33.379467 22542570456896 run_lib.py:146] step: 587300, eval_loss: 2.83456e-02
I0210 22:21:50.941246 22542570456896 run_lib.py:133] step: 587350, training_loss: 2.22747e-02
I0210 22:22:08.261839 22542570456896 run_lib.py:133] step: 587400, training_loss: 2.42563e-02
I0210 22:22:08.425932 22542570456896 run_lib.py:146] step: 587400, eval_loss: 2.54215e-02
I0210 22:22:25.723645 22542570456896 run_lib.py:133] step: 587450, training_loss: 2.13713e-02
I0210 22:22:43.262114 22542570456896 run_lib.py:133] step: 587500, training_loss: 2.88437e-02
I0210 22:22:43.420213 22542570456896 run_lib.py:146] step: 587500, eval_loss: 2.89641e-02
I0210 22:23:00.873090 22542570456896 run_lib.py:133] step: 587550, training_loss: 2.90675e-02
I0210 22:23:18.321763 22542570456896 run_lib.py:133] step: 587600, training_loss: 2.88598e-02
I0210 22:23:18.477525 22542570456896 run_lib.py:146] step: 587600, eval_loss: 2.64562e-02
I0210 22:23:36.017724 22542570456896 run_lib.py:133] step: 587650, training_loss: 3.34653e-02
I0210 22:23:53.477629 22542570456896 run_lib.py:133] step: 587700, training_loss: 2.86987e-02
I0210 22:23:53.629429 22542570456896 run_lib.py:146] step: 587700, eval_loss: 2.81310e-02
I0210 22:24:11.033794 22542570456896 run_lib.py:133] step: 587750, training_loss: 2.72809e-02
I0210 22:24:28.431946 22542570456896 run_lib.py:133] step: 587800, training_loss: 3.12909e-02
I0210 22:24:28.596292 22542570456896 run_lib.py:146] step: 587800, eval_loss: 2.94185e-02
I0210 22:24:46.229598 22542570456896 run_lib.py:133] step: 587850, training_loss: 3.61663e-02
I0210 22:25:03.764724 22542570456896 run_lib.py:133] step: 587900, training_loss: 2.38490e-02
I0210 22:25:03.919119 22542570456896 run_lib.py:146] step: 587900, eval_loss: 3.00036e-02
I0210 22:25:21.334923 22542570456896 run_lib.py:133] step: 587950, training_loss: 3.00313e-02
I0210 22:25:38.770974 22542570456896 run_lib.py:133] step: 588000, training_loss: 2.37184e-02
I0210 22:25:38.926418 22542570456896 run_lib.py:146] step: 588000, eval_loss: 2.86566e-02
I0210 22:25:56.506377 22542570456896 run_lib.py:133] step: 588050, training_loss: 2.59391e-02
I0210 22:26:14.022126 22542570456896 run_lib.py:133] step: 588100, training_loss: 2.33285e-02
I0210 22:26:14.184598 22542570456896 run_lib.py:146] step: 588100, eval_loss: 2.25581e-02
I0210 22:26:31.834473 22542570456896 run_lib.py:133] step: 588150, training_loss: 2.38573e-02
I0210 22:26:49.279574 22542570456896 run_lib.py:133] step: 588200, training_loss: 2.91537e-02
I0210 22:26:49.435347 22542570456896 run_lib.py:146] step: 588200, eval_loss: 2.42791e-02
I0210 22:27:07.075753 22542570456896 run_lib.py:133] step: 588250, training_loss: 2.61908e-02
I0210 22:27:24.502520 22542570456896 run_lib.py:133] step: 588300, training_loss: 2.42426e-02
I0210 22:27:24.660524 22542570456896 run_lib.py:146] step: 588300, eval_loss: 2.74497e-02
I0210 22:27:42.248960 22542570456896 run_lib.py:133] step: 588350, training_loss: 2.37343e-02
I0210 22:27:59.685135 22542570456896 run_lib.py:133] step: 588400, training_loss: 3.15508e-02
I0210 22:27:59.852539 22542570456896 run_lib.py:146] step: 588400, eval_loss: 2.70421e-02
I0210 22:28:17.431938 22542570456896 run_lib.py:133] step: 588450, training_loss: 2.48220e-02
I0210 22:28:35.015807 22542570456896 run_lib.py:133] step: 588500, training_loss: 2.81044e-02
I0210 22:28:35.179476 22542570456896 run_lib.py:146] step: 588500, eval_loss: 3.28479e-02
I0210 22:28:52.617187 22542570456896 run_lib.py:133] step: 588550, training_loss: 2.53300e-02
I0210 22:29:10.018636 22542570456896 run_lib.py:133] step: 588600, training_loss: 3.04086e-02
I0210 22:29:10.178153 22542570456896 run_lib.py:146] step: 588600, eval_loss: 3.44362e-02
I0210 22:29:27.812379 22542570456896 run_lib.py:133] step: 588650, training_loss: 3.10003e-02
I0210 22:29:45.256083 22542570456896 run_lib.py:133] step: 588700, training_loss: 2.74239e-02
I0210 22:29:45.415634 22542570456896 run_lib.py:146] step: 588700, eval_loss: 3.03044e-02
I0210 22:30:03.045773 22542570456896 run_lib.py:133] step: 588750, training_loss: 3.01044e-02
I0210 22:30:20.503810 22542570456896 run_lib.py:133] step: 588800, training_loss: 3.09566e-02
I0210 22:30:20.662620 22542570456896 run_lib.py:146] step: 588800, eval_loss: 2.62792e-02
I0210 22:30:38.122515 22542570456896 run_lib.py:133] step: 588850, training_loss: 3.00563e-02
I0210 22:30:55.681372 22542570456896 run_lib.py:133] step: 588900, training_loss: 3.01579e-02
I0210 22:30:55.850379 22542570456896 run_lib.py:146] step: 588900, eval_loss: 2.27336e-02
I0210 22:31:13.268147 22542570456896 run_lib.py:133] step: 588950, training_loss: 2.42888e-02
I0210 22:31:30.717004 22542570456896 run_lib.py:133] step: 589000, training_loss: 2.88785e-02
I0210 22:31:30.872576 22542570456896 run_lib.py:146] step: 589000, eval_loss: 3.52092e-02
I0210 22:31:48.358364 22542570456896 run_lib.py:133] step: 589050, training_loss: 3.17207e-02
I0210 22:32:05.967905 22542570456896 run_lib.py:133] step: 589100, training_loss: 2.76744e-02
I0210 22:32:06.119442 22542570456896 run_lib.py:146] step: 589100, eval_loss: 3.42235e-02
I0210 22:32:23.535871 22542570456896 run_lib.py:133] step: 589150, training_loss: 2.40049e-02
I0210 22:32:41.023125 22542570456896 run_lib.py:133] step: 589200, training_loss: 2.60822e-02
I0210 22:32:41.196578 22542570456896 run_lib.py:146] step: 589200, eval_loss: 2.16448e-02
I0210 22:32:58.703594 22542570456896 run_lib.py:133] step: 589250, training_loss: 2.68809e-02
I0210 22:33:16.120817 22542570456896 run_lib.py:133] step: 589300, training_loss: 2.48781e-02
I0210 22:33:16.279394 22542570456896 run_lib.py:146] step: 589300, eval_loss: 2.31876e-02
I0210 22:33:33.902337 22542570456896 run_lib.py:133] step: 589350, training_loss: 2.63072e-02
I0210 22:33:51.411867 22542570456896 run_lib.py:133] step: 589400, training_loss: 2.06764e-02
I0210 22:33:51.567754 22542570456896 run_lib.py:146] step: 589400, eval_loss: 2.80115e-02
I0210 22:34:08.954804 22542570456896 run_lib.py:133] step: 589450, training_loss: 2.78123e-02
I0210 22:34:26.407589 22542570456896 run_lib.py:133] step: 589500, training_loss: 2.71430e-02
I0210 22:34:26.567336 22542570456896 run_lib.py:146] step: 589500, eval_loss: 2.92407e-02
I0210 22:34:44.206833 22542570456896 run_lib.py:133] step: 589550, training_loss: 2.33519e-02
I0210 22:35:01.606707 22542570456896 run_lib.py:133] step: 589600, training_loss: 2.49988e-02
I0210 22:35:01.759225 22542570456896 run_lib.py:146] step: 589600, eval_loss: 2.73097e-02
I0210 22:35:19.329070 22542570456896 run_lib.py:133] step: 589650, training_loss: 2.46201e-02
I0210 22:35:36.737889 22542570456896 run_lib.py:133] step: 589700, training_loss: 3.03391e-02
I0210 22:35:36.896495 22542570456896 run_lib.py:146] step: 589700, eval_loss: 2.76315e-02
I0210 22:35:54.533015 22542570456896 run_lib.py:133] step: 589750, training_loss: 2.39442e-02
I0210 22:36:11.994941 22542570456896 run_lib.py:133] step: 589800, training_loss: 3.23945e-02
I0210 22:36:12.147429 22542570456896 run_lib.py:146] step: 589800, eval_loss: 3.08304e-02
I0210 22:36:29.563481 22542570456896 run_lib.py:133] step: 589850, training_loss: 2.50384e-02
I0210 22:36:47.160459 22542570456896 run_lib.py:133] step: 589900, training_loss: 2.36039e-02
I0210 22:36:47.316362 22542570456896 run_lib.py:146] step: 589900, eval_loss: 3.03467e-02
I0210 22:37:04.765478 22542570456896 run_lib.py:133] step: 589950, training_loss: 2.98451e-02
I0210 22:37:22.332845 22542570456896 run_lib.py:133] step: 590000, training_loss: 2.70277e-02
I0210 22:37:23.397006 22542570456896 run_lib.py:146] step: 590000, eval_loss: 3.14591e-02
I0210 22:37:43.937656 22542570456896 run_lib.py:133] step: 590050, training_loss: 3.34391e-02
I0210 22:38:01.325311 22542570456896 run_lib.py:133] step: 590100, training_loss: 2.77076e-02
I0210 22:38:01.480472 22542570456896 run_lib.py:146] step: 590100, eval_loss: 3.06146e-02
I0210 22:38:18.884546 22542570456896 run_lib.py:133] step: 590150, training_loss: 2.77330e-02
I0210 22:38:36.332556 22542570456896 run_lib.py:133] step: 590200, training_loss: 2.80207e-02
I0210 22:38:36.489562 22542570456896 run_lib.py:146] step: 590200, eval_loss: 2.41467e-02
I0210 22:38:54.036216 22542570456896 run_lib.py:133] step: 590250, training_loss: 3.50136e-02
I0210 22:39:11.571506 22542570456896 run_lib.py:133] step: 590300, training_loss: 2.35935e-02
I0210 22:39:11.729291 22542570456896 run_lib.py:146] step: 590300, eval_loss: 3.57234e-02
I0210 22:39:29.156724 22542570456896 run_lib.py:133] step: 590350, training_loss: 3.85825e-02
I0210 22:39:46.642342 22542570456896 run_lib.py:133] step: 590400, training_loss: 3.28498e-02
I0210 22:39:46.803345 22542570456896 run_lib.py:146] step: 590400, eval_loss: 3.42181e-02
I0210 22:40:04.419299 22542570456896 run_lib.py:133] step: 590450, training_loss: 3.46751e-02
I0210 22:40:21.795449 22542570456896 run_lib.py:133] step: 590500, training_loss: 2.26105e-02
I0210 22:40:21.955768 22542570456896 run_lib.py:146] step: 590500, eval_loss: 2.74853e-02
I0210 22:40:39.534128 22542570456896 run_lib.py:133] step: 590550, training_loss: 2.30759e-02
I0210 22:40:56.993584 22542570456896 run_lib.py:133] step: 590600, training_loss: 2.94240e-02
I0210 22:40:57.148645 22542570456896 run_lib.py:146] step: 590600, eval_loss: 2.70294e-02
I0210 22:41:14.745113 22542570456896 run_lib.py:133] step: 590650, training_loss: 2.39024e-02
I0210 22:41:32.191845 22542570456896 run_lib.py:133] step: 590700, training_loss: 2.35141e-02
I0210 22:41:32.350214 22542570456896 run_lib.py:146] step: 590700, eval_loss: 3.33816e-02
I0210 22:41:49.886916 22542570456896 run_lib.py:133] step: 590750, training_loss: 2.83606e-02
I0210 22:42:07.346452 22542570456896 run_lib.py:133] step: 590800, training_loss: 2.87344e-02
I0210 22:42:07.521380 22542570456896 run_lib.py:146] step: 590800, eval_loss: 2.57569e-02
I0210 22:42:24.941113 22542570456896 run_lib.py:133] step: 590850, training_loss: 2.57410e-02
I0210 22:42:42.514062 22542570456896 run_lib.py:133] step: 590900, training_loss: 3.32011e-02
I0210 22:42:42.670692 22542570456896 run_lib.py:146] step: 590900, eval_loss: 3.11201e-02
I0210 22:43:00.112223 22542570456896 run_lib.py:133] step: 590950, training_loss: 2.49815e-02
I0210 22:43:17.517046 22542570456896 run_lib.py:133] step: 591000, training_loss: 2.22252e-02
I0210 22:43:17.693390 22542570456896 run_lib.py:146] step: 591000, eval_loss: 2.98677e-02
I0210 22:43:35.243212 22542570456896 run_lib.py:133] step: 591050, training_loss: 2.87020e-02
I0210 22:43:52.845787 22542570456896 run_lib.py:133] step: 591100, training_loss: 3.38553e-02
I0210 22:43:53.000165 22542570456896 run_lib.py:146] step: 591100, eval_loss: 2.16923e-02
I0210 22:44:10.464932 22542570456896 run_lib.py:133] step: 591150, training_loss: 2.83018e-02
I0210 22:44:27.926378 22542570456896 run_lib.py:133] step: 591200, training_loss: 2.58201e-02
I0210 22:44:28.082325 22542570456896 run_lib.py:146] step: 591200, eval_loss: 2.87441e-02
I0210 22:44:45.518897 22542570456896 run_lib.py:133] step: 591250, training_loss: 2.97401e-02
I0210 22:45:03.081207 22542570456896 run_lib.py:133] step: 591300, training_loss: 3.26084e-02
I0210 22:45:03.236297 22542570456896 run_lib.py:146] step: 591300, eval_loss: 2.75945e-02
I0210 22:45:20.694277 22542570456896 run_lib.py:133] step: 591350, training_loss: 2.98808e-02
I0210 22:45:38.175696 22542570456896 run_lib.py:133] step: 591400, training_loss: 3.24798e-02
I0210 22:45:38.331830 22542570456896 run_lib.py:146] step: 591400, eval_loss: 3.02978e-02
I0210 22:45:55.753678 22542570456896 run_lib.py:133] step: 591450, training_loss: 2.45102e-02
I0210 22:46:13.348872 22542570456896 run_lib.py:133] step: 591500, training_loss: 2.75419e-02
I0210 22:46:13.500222 22542570456896 run_lib.py:146] step: 591500, eval_loss: 2.60369e-02
I0210 22:46:30.896577 22542570456896 run_lib.py:133] step: 591550, training_loss: 3.25269e-02
I0210 22:46:48.351237 22542570456896 run_lib.py:133] step: 591600, training_loss: 2.45933e-02
I0210 22:46:48.506514 22542570456896 run_lib.py:146] step: 591600, eval_loss: 3.02484e-02
I0210 22:47:05.924629 22542570456896 run_lib.py:133] step: 591650, training_loss: 2.93861e-02
I0210 22:47:23.395992 22542570456896 run_lib.py:133] step: 591700, training_loss: 2.70409e-02
I0210 22:47:23.553241 22542570456896 run_lib.py:146] step: 591700, eval_loss: 2.73466e-02
I0210 22:47:41.117788 22542570456896 run_lib.py:133] step: 591750, training_loss: 2.99634e-02
I0210 22:47:58.587512 22542570456896 run_lib.py:133] step: 591800, training_loss: 2.97975e-02
I0210 22:47:58.742293 22542570456896 run_lib.py:146] step: 591800, eval_loss: 2.88294e-02
I0210 22:48:16.183461 22542570456896 run_lib.py:133] step: 591850, training_loss: 3.21726e-02
I0210 22:48:33.598603 22542570456896 run_lib.py:133] step: 591900, training_loss: 2.25511e-02
I0210 22:48:33.759698 22542570456896 run_lib.py:146] step: 591900, eval_loss: 3.67998e-02
I0210 22:48:51.359942 22542570456896 run_lib.py:133] step: 591950, training_loss: 2.57478e-02
I0210 22:49:08.839135 22542570456896 run_lib.py:133] step: 592000, training_loss: 3.12983e-02
I0210 22:49:08.991465 22542570456896 run_lib.py:146] step: 592000, eval_loss: 2.88153e-02
I0210 22:49:26.561152 22542570456896 run_lib.py:133] step: 592050, training_loss: 2.42293e-02
I0210 22:49:44.054949 22542570456896 run_lib.py:133] step: 592100, training_loss: 2.61304e-02
I0210 22:49:44.211457 22542570456896 run_lib.py:146] step: 592100, eval_loss: 3.64008e-02
I0210 22:50:01.780205 22542570456896 run_lib.py:133] step: 592150, training_loss: 3.10174e-02
I0210 22:50:19.205260 22542570456896 run_lib.py:133] step: 592200, training_loss: 2.50229e-02
I0210 22:50:19.381398 22542570456896 run_lib.py:146] step: 592200, eval_loss: 2.34079e-02
I0210 22:50:36.954663 22542570456896 run_lib.py:133] step: 592250, training_loss: 3.19713e-02
I0210 22:50:54.523380 22542570456896 run_lib.py:133] step: 592300, training_loss: 2.20856e-02
I0210 22:50:54.686507 22542570456896 run_lib.py:146] step: 592300, eval_loss: 3.42107e-02
I0210 22:51:12.131738 22542570456896 run_lib.py:133] step: 592350, training_loss: 2.50530e-02
I0210 22:51:29.653425 22542570456896 run_lib.py:133] step: 592400, training_loss: 2.56538e-02
I0210 22:51:29.814413 22542570456896 run_lib.py:146] step: 592400, eval_loss: 2.69220e-02
I0210 22:51:47.248697 22542570456896 run_lib.py:133] step: 592450, training_loss: 3.53870e-02
I0210 22:52:04.689105 22542570456896 run_lib.py:133] step: 592500, training_loss: 2.72588e-02
I0210 22:52:04.843667 22542570456896 run_lib.py:146] step: 592500, eval_loss: 2.88192e-02
I0210 22:52:22.465191 22542570456896 run_lib.py:133] step: 592550, training_loss: 2.92787e-02
I0210 22:52:39.850092 22542570456896 run_lib.py:133] step: 592600, training_loss: 2.55354e-02
I0210 22:52:40.002441 22542570456896 run_lib.py:146] step: 592600, eval_loss: 2.45278e-02
I0210 22:52:57.403341 22542570456896 run_lib.py:133] step: 592650, training_loss: 3.11357e-02
I0210 22:53:14.951649 22542570456896 run_lib.py:133] step: 592700, training_loss: 3.02558e-02
I0210 22:53:15.109598 22542570456896 run_lib.py:146] step: 592700, eval_loss: 3.55196e-02
I0210 22:53:32.524482 22542570456896 run_lib.py:133] step: 592750, training_loss: 2.88915e-02
I0210 22:53:49.953493 22542570456896 run_lib.py:133] step: 592800, training_loss: 2.69514e-02
I0210 22:53:50.110792 22542570456896 run_lib.py:146] step: 592800, eval_loss: 2.82642e-02
I0210 22:54:07.625350 22542570456896 run_lib.py:133] step: 592850, training_loss: 2.52321e-02
I0210 22:54:24.961009 22542570456896 run_lib.py:133] step: 592900, training_loss: 2.62846e-02
I0210 22:54:25.117380 22542570456896 run_lib.py:146] step: 592900, eval_loss: 3.82897e-02
I0210 22:54:42.502148 22542570456896 run_lib.py:133] step: 592950, training_loss: 2.47097e-02
I0210 22:54:59.914840 22542570456896 run_lib.py:133] step: 593000, training_loss: 2.60447e-02
I0210 22:55:00.066273 22542570456896 run_lib.py:146] step: 593000, eval_loss: 2.40205e-02
I0210 22:55:17.649656 22542570456896 run_lib.py:133] step: 593050, training_loss: 2.40362e-02
I0210 22:55:35.155953 22542570456896 run_lib.py:133] step: 593100, training_loss: 3.04719e-02
I0210 22:55:35.332986 22542570456896 run_lib.py:146] step: 593100, eval_loss: 2.97743e-02
I0210 22:55:52.740850 22542570456896 run_lib.py:133] step: 593150, training_loss: 2.66742e-02
I0210 22:56:10.177805 22542570456896 run_lib.py:133] step: 593200, training_loss: 2.80291e-02
I0210 22:56:10.351416 22542570456896 run_lib.py:146] step: 593200, eval_loss: 2.77857e-02
I0210 22:56:27.908953 22542570456896 run_lib.py:133] step: 593250, training_loss: 2.39342e-02
I0210 22:56:45.302456 22542570456896 run_lib.py:133] step: 593300, training_loss: 2.16307e-02
I0210 22:56:45.461052 22542570456896 run_lib.py:146] step: 593300, eval_loss: 2.35830e-02
I0210 22:57:03.057723 22542570456896 run_lib.py:133] step: 593350, training_loss: 2.25563e-02
I0210 22:57:20.510296 22542570456896 run_lib.py:133] step: 593400, training_loss: 3.08315e-02
I0210 22:57:20.671295 22542570456896 run_lib.py:146] step: 593400, eval_loss: 2.59152e-02
I0210 22:57:38.315636 22542570456896 run_lib.py:133] step: 593450, training_loss: 2.71065e-02
I0210 22:57:55.722573 22542570456896 run_lib.py:133] step: 593500, training_loss: 2.90115e-02
I0210 22:57:55.878310 22542570456896 run_lib.py:146] step: 593500, eval_loss: 2.53654e-02
I0210 22:58:13.435619 22542570456896 run_lib.py:133] step: 593550, training_loss: 1.90699e-02
I0210 22:58:30.884256 22542570456896 run_lib.py:133] step: 593600, training_loss: 2.26826e-02
I0210 22:58:31.058314 22542570456896 run_lib.py:146] step: 593600, eval_loss: 3.09660e-02
I0210 22:58:48.505839 22542570456896 run_lib.py:133] step: 593650, training_loss: 1.91728e-02
I0210 22:59:06.127553 22542570456896 run_lib.py:133] step: 593700, training_loss: 2.08824e-02
I0210 22:59:06.282715 22542570456896 run_lib.py:146] step: 593700, eval_loss: 3.27991e-02
I0210 22:59:23.706252 22542570456896 run_lib.py:133] step: 593750, training_loss: 2.21683e-02
I0210 22:59:41.144406 22542570456896 run_lib.py:133] step: 593800, training_loss: 3.05372e-02
I0210 22:59:41.299281 22542570456896 run_lib.py:146] step: 593800, eval_loss: 2.71572e-02
I0210 22:59:58.883068 22542570456896 run_lib.py:133] step: 593850, training_loss: 3.30136e-02
I0210 23:00:16.334559 22542570456896 run_lib.py:133] step: 593900, training_loss: 3.36538e-02
I0210 23:00:16.488748 22542570456896 run_lib.py:146] step: 593900, eval_loss: 2.82630e-02
I0210 23:00:34.121668 22542570456896 run_lib.py:133] step: 593950, training_loss: 2.77433e-02
I0210 23:00:51.512022 22542570456896 run_lib.py:133] step: 594000, training_loss: 2.48591e-02
I0210 23:00:51.668158 22542570456896 run_lib.py:146] step: 594000, eval_loss: 2.75093e-02
I0210 23:01:09.069267 22542570456896 run_lib.py:133] step: 594050, training_loss: 3.15835e-02
I0210 23:01:26.637321 22542570456896 run_lib.py:133] step: 594100, training_loss: 2.30582e-02
I0210 23:01:26.795571 22542570456896 run_lib.py:146] step: 594100, eval_loss: 3.22867e-02
I0210 23:01:44.249981 22542570456896 run_lib.py:133] step: 594150, training_loss: 2.28873e-02
I0210 23:02:01.686585 22542570456896 run_lib.py:133] step: 594200, training_loss: 3.76656e-02
I0210 23:02:01.851302 22542570456896 run_lib.py:146] step: 594200, eval_loss: 2.64021e-02
I0210 23:02:19.259817 22542570456896 run_lib.py:133] step: 594250, training_loss: 2.38893e-02
I0210 23:02:36.844969 22542570456896 run_lib.py:133] step: 594300, training_loss: 2.41422e-02
I0210 23:02:37.000332 22542570456896 run_lib.py:146] step: 594300, eval_loss: 2.46485e-02
I0210 23:02:54.425974 22542570456896 run_lib.py:133] step: 594350, training_loss: 2.11438e-02
I0210 23:03:11.889588 22542570456896 run_lib.py:133] step: 594400, training_loss: 2.63957e-02
I0210 23:03:12.040400 22542570456896 run_lib.py:146] step: 594400, eval_loss: 2.68431e-02
I0210 23:03:29.519660 22542570456896 run_lib.py:133] step: 594450, training_loss: 2.71886e-02
I0210 23:03:46.998702 22542570456896 run_lib.py:133] step: 594500, training_loss: 3.34570e-02
I0210 23:03:47.162379 22542570456896 run_lib.py:146] step: 594500, eval_loss: 2.46106e-02
I0210 23:04:04.765095 22542570456896 run_lib.py:133] step: 594550, training_loss: 2.77230e-02
I0210 23:04:22.261768 22542570456896 run_lib.py:133] step: 594600, training_loss: 2.24889e-02
I0210 23:04:22.413713 22542570456896 run_lib.py:146] step: 594600, eval_loss: 2.45546e-02
I0210 23:04:39.805462 22542570456896 run_lib.py:133] step: 594650, training_loss: 3.22662e-02
I0210 23:04:57.196706 22542570456896 run_lib.py:133] step: 594700, training_loss: 2.96770e-02
I0210 23:04:57.358510 22542570456896 run_lib.py:146] step: 594700, eval_loss: 3.45442e-02
I0210 23:05:14.942714 22542570456896 run_lib.py:133] step: 594750, training_loss: 3.10417e-02
I0210 23:05:32.370540 22542570456896 run_lib.py:133] step: 594800, training_loss: 2.15667e-02
I0210 23:05:32.539197 22542570456896 run_lib.py:146] step: 594800, eval_loss: 2.79269e-02
I0210 23:05:50.120176 22542570456896 run_lib.py:133] step: 594850, training_loss: 2.75263e-02
I0210 23:06:07.542130 22542570456896 run_lib.py:133] step: 594900, training_loss: 2.59322e-02
I0210 23:06:07.695365 22542570456896 run_lib.py:146] step: 594900, eval_loss: 3.19087e-02
I0210 23:06:25.249545 22542570456896 run_lib.py:133] step: 594950, training_loss: 3.43770e-02
I0210 23:06:42.642322 22542570456896 run_lib.py:133] step: 595000, training_loss: 3.23979e-02
I0210 23:06:42.813315 22542570456896 run_lib.py:146] step: 595000, eval_loss: 3.74977e-02
I0210 23:07:00.246855 22542570456896 run_lib.py:133] step: 595050, training_loss: 2.56977e-02
I0210 23:07:17.877095 22542570456896 run_lib.py:133] step: 595100, training_loss: 3.16501e-02
I0210 23:07:18.033764 22542570456896 run_lib.py:146] step: 595100, eval_loss: 2.36975e-02
I0210 23:07:35.447850 22542570456896 run_lib.py:133] step: 595150, training_loss: 3.04246e-02
I0210 23:07:53.000106 22542570456896 run_lib.py:133] step: 595200, training_loss: 3.34935e-02
I0210 23:07:53.155215 22542570456896 run_lib.py:146] step: 595200, eval_loss: 3.59094e-02
I0210 23:08:10.595366 22542570456896 run_lib.py:133] step: 595250, training_loss: 2.58926e-02
I0210 23:08:28.049785 22542570456896 run_lib.py:133] step: 595300, training_loss: 2.09365e-02
I0210 23:08:28.209156 22542570456896 run_lib.py:146] step: 595300, eval_loss: 3.22696e-02
I0210 23:08:45.829471 22542570456896 run_lib.py:133] step: 595350, training_loss: 2.93574e-02
I0210 23:09:03.247841 22542570456896 run_lib.py:133] step: 595400, training_loss: 2.68806e-02
I0210 23:09:03.402337 22542570456896 run_lib.py:146] step: 595400, eval_loss: 2.39190e-02
I0210 23:09:20.808354 22542570456896 run_lib.py:133] step: 595450, training_loss: 2.81162e-02
I0210 23:09:38.399383 22542570456896 run_lib.py:133] step: 595500, training_loss: 2.85434e-02
I0210 23:09:38.556422 22542570456896 run_lib.py:146] step: 595500, eval_loss: 2.91448e-02
I0210 23:09:55.993452 22542570456896 run_lib.py:133] step: 595550, training_loss: 2.82492e-02
I0210 23:10:13.411341 22542570456896 run_lib.py:133] step: 595600, training_loss: 2.93677e-02
I0210 23:10:13.716279 22542570456896 run_lib.py:146] step: 595600, eval_loss: 2.70129e-02
I0210 23:10:31.123644 22542570456896 run_lib.py:133] step: 595650, training_loss: 2.87161e-02
I0210 23:10:48.566336 22542570456896 run_lib.py:133] step: 595700, training_loss: 2.75805e-02
I0210 23:10:48.722635 22542570456896 run_lib.py:146] step: 595700, eval_loss: 2.75299e-02
I0210 23:11:06.137515 22542570456896 run_lib.py:133] step: 595750, training_loss: 3.49407e-02
I0210 23:11:23.523768 22542570456896 run_lib.py:133] step: 595800, training_loss: 2.28115e-02
I0210 23:11:23.675302 22542570456896 run_lib.py:146] step: 595800, eval_loss: 2.26044e-02
I0210 23:11:41.228485 22542570456896 run_lib.py:133] step: 595850, training_loss: 2.04383e-02
I0210 23:11:58.684104 22542570456896 run_lib.py:133] step: 595900, training_loss: 2.65223e-02
I0210 23:11:58.851534 22542570456896 run_lib.py:146] step: 595900, eval_loss: 3.31741e-02
I0210 23:12:16.287593 22542570456896 run_lib.py:133] step: 595950, training_loss: 2.82743e-02
I0210 23:12:33.685395 22542570456896 run_lib.py:133] step: 596000, training_loss: 2.95060e-02
I0210 23:12:33.851201 22542570456896 run_lib.py:146] step: 596000, eval_loss: 2.73364e-02
I0210 23:12:51.428909 22542570456896 run_lib.py:133] step: 596050, training_loss: 2.64981e-02
I0210 23:13:08.858360 22542570456896 run_lib.py:133] step: 596100, training_loss: 2.24358e-02
I0210 23:13:09.013298 22542570456896 run_lib.py:146] step: 596100, eval_loss: 2.89133e-02
I0210 23:13:26.414701 22542570456896 run_lib.py:133] step: 596150, training_loss: 2.56233e-02
I0210 23:13:43.839709 22542570456896 run_lib.py:133] step: 596200, training_loss: 2.82915e-02
I0210 23:13:43.995639 22542570456896 run_lib.py:146] step: 596200, eval_loss: 2.62036e-02
I0210 23:14:01.621193 22542570456896 run_lib.py:133] step: 596250, training_loss: 3.03856e-02
I0210 23:14:18.985870 22542570456896 run_lib.py:133] step: 596300, training_loss: 3.06106e-02
I0210 23:14:19.139375 22542570456896 run_lib.py:146] step: 596300, eval_loss: 3.01070e-02
I0210 23:14:36.668351 22542570456896 run_lib.py:133] step: 596350, training_loss: 3.28399e-02
I0210 23:14:54.031004 22542570456896 run_lib.py:133] step: 596400, training_loss: 2.63333e-02
I0210 23:14:54.310460 22542570456896 run_lib.py:146] step: 596400, eval_loss: 2.89415e-02
I0210 23:15:11.912303 22542570456896 run_lib.py:133] step: 596450, training_loss: 2.20922e-02
I0210 23:15:29.307686 22542570456896 run_lib.py:133] step: 596500, training_loss: 2.95627e-02
I0210 23:15:29.466269 22542570456896 run_lib.py:146] step: 596500, eval_loss: 3.15471e-02
I0210 23:15:46.869704 22542570456896 run_lib.py:133] step: 596550, training_loss: 2.72017e-02
I0210 23:16:04.405707 22542570456896 run_lib.py:133] step: 596600, training_loss: 2.74938e-02
I0210 23:16:04.562041 22542570456896 run_lib.py:146] step: 596600, eval_loss: 2.59763e-02
I0210 23:16:21.958193 22542570456896 run_lib.py:133] step: 596650, training_loss: 2.63794e-02
I0210 23:16:39.457373 22542570456896 run_lib.py:133] step: 596700, training_loss: 3.00081e-02
I0210 23:16:39.609377 22542570456896 run_lib.py:146] step: 596700, eval_loss: 3.06525e-02
I0210 23:16:57.064756 22542570456896 run_lib.py:133] step: 596750, training_loss: 2.62393e-02
I0210 23:17:14.516849 22542570456896 run_lib.py:133] step: 596800, training_loss: 2.71472e-02
I0210 23:17:14.672564 22542570456896 run_lib.py:146] step: 596800, eval_loss: 3.64888e-02
I0210 23:17:32.242968 22542570456896 run_lib.py:133] step: 596850, training_loss: 2.65157e-02
I0210 23:17:49.626672 22542570456896 run_lib.py:133] step: 596900, training_loss: 2.31877e-02
I0210 23:17:49.796809 22542570456896 run_lib.py:146] step: 596900, eval_loss: 3.32203e-02
I0210 23:18:07.175313 22542570456896 run_lib.py:133] step: 596950, training_loss: 3.59329e-02
I0210 23:18:24.528877 22542570456896 run_lib.py:133] step: 597000, training_loss: 3.17434e-02
I0210 23:18:24.695951 22542570456896 run_lib.py:146] step: 597000, eval_loss: 3.16848e-02
I0210 23:18:42.309165 22542570456896 run_lib.py:133] step: 597050, training_loss: 2.96462e-02
I0210 23:18:59.731608 22542570456896 run_lib.py:133] step: 597100, training_loss: 2.95475e-02
I0210 23:18:59.887632 22542570456896 run_lib.py:146] step: 597100, eval_loss: 2.62994e-02
I0210 23:19:17.391119 22542570456896 run_lib.py:133] step: 597150, training_loss: 2.58110e-02
I0210 23:19:34.789451 22542570456896 run_lib.py:133] step: 597200, training_loss: 2.51384e-02
I0210 23:19:34.940378 22542570456896 run_lib.py:146] step: 597200, eval_loss: 2.35886e-02
I0210 23:19:52.360383 22542570456896 run_lib.py:133] step: 597250, training_loss: 2.11864e-02
I0210 23:20:09.809272 22542570456896 run_lib.py:133] step: 597300, training_loss: 3.31136e-02
I0210 23:20:09.981626 22542570456896 run_lib.py:146] step: 597300, eval_loss: 3.55622e-02
I0210 23:20:27.581246 22542570456896 run_lib.py:133] step: 597350, training_loss: 2.54954e-02
I0210 23:20:45.080061 22542570456896 run_lib.py:133] step: 597400, training_loss: 2.50130e-02
I0210 23:20:45.239333 22542570456896 run_lib.py:146] step: 597400, eval_loss: 2.83447e-02
I0210 23:21:02.574676 22542570456896 run_lib.py:133] step: 597450, training_loss: 2.26023e-02
I0210 23:21:19.965517 22542570456896 run_lib.py:133] step: 597500, training_loss: 2.68981e-02
I0210 23:21:20.120326 22542570456896 run_lib.py:146] step: 597500, eval_loss: 3.09129e-02
I0210 23:21:37.657675 22542570456896 run_lib.py:133] step: 597550, training_loss: 2.78763e-02
I0210 23:21:55.113633 22542570456896 run_lib.py:133] step: 597600, training_loss: 3.29443e-02
I0210 23:21:55.274539 22542570456896 run_lib.py:146] step: 597600, eval_loss: 2.97128e-02
I0210 23:22:12.890107 22542570456896 run_lib.py:133] step: 597650, training_loss: 2.81272e-02
I0210 23:22:30.259236 22542570456896 run_lib.py:133] step: 597700, training_loss: 2.40359e-02
I0210 23:22:30.411396 22542570456896 run_lib.py:146] step: 597700, eval_loss: 3.22613e-02
I0210 23:22:47.938599 22542570456896 run_lib.py:133] step: 597750, training_loss: 2.56255e-02
I0210 23:23:05.320606 22542570456896 run_lib.py:133] step: 597800, training_loss: 2.46538e-02
I0210 23:23:05.476494 22542570456896 run_lib.py:146] step: 597800, eval_loss: 3.43808e-02
I0210 23:23:23.023469 22542570456896 run_lib.py:133] step: 597850, training_loss: 2.14755e-02
I0210 23:23:40.474914 22542570456896 run_lib.py:133] step: 597900, training_loss: 2.53689e-02
I0210 23:23:40.633385 22542570456896 run_lib.py:146] step: 597900, eval_loss: 2.58214e-02
I0210 23:23:58.060619 22542570456896 run_lib.py:133] step: 597950, training_loss: 3.68804e-02
I0210 23:24:15.635721 22542570456896 run_lib.py:133] step: 598000, training_loss: 2.78514e-02
I0210 23:24:15.811530 22542570456896 run_lib.py:146] step: 598000, eval_loss: 3.33416e-02
I0210 23:24:33.213648 22542570456896 run_lib.py:133] step: 598050, training_loss: 3.63023e-02
I0210 23:24:50.598689 22542570456896 run_lib.py:133] step: 598100, training_loss: 3.09292e-02
I0210 23:24:50.760379 22542570456896 run_lib.py:146] step: 598100, eval_loss: 4.20626e-02
I0210 23:25:08.260778 22542570456896 run_lib.py:133] step: 598150, training_loss: 2.54685e-02
I0210 23:25:25.837751 22542570456896 run_lib.py:133] step: 598200, training_loss: 2.12953e-02
I0210 23:25:25.991476 22542570456896 run_lib.py:146] step: 598200, eval_loss: 2.26282e-02
I0210 23:25:43.419107 22542570456896 run_lib.py:133] step: 598250, training_loss: 3.05141e-02
I0210 23:26:00.834630 22542570456896 run_lib.py:133] step: 598300, training_loss: 2.81818e-02
I0210 23:26:00.992594 22542570456896 run_lib.py:146] step: 598300, eval_loss: 2.43650e-02
I0210 23:26:18.362689 22542570456896 run_lib.py:133] step: 598350, training_loss: 3.42421e-02
I0210 23:26:36.036050 22542570456896 run_lib.py:133] step: 598400, training_loss: 2.72917e-02
I0210 23:26:36.195359 22542570456896 run_lib.py:146] step: 598400, eval_loss: 2.97865e-02
I0210 23:26:53.588279 22542570456896 run_lib.py:133] step: 598450, training_loss: 3.21125e-02
I0210 23:27:11.031487 22542570456896 run_lib.py:133] step: 598500, training_loss: 2.61855e-02
I0210 23:27:11.186066 22542570456896 run_lib.py:146] step: 598500, eval_loss: 3.48133e-02
I0210 23:27:28.562823 22542570456896 run_lib.py:133] step: 598550, training_loss: 3.33395e-02
I0210 23:27:46.147557 22542570456896 run_lib.py:133] step: 598600, training_loss: 2.51654e-02
I0210 23:27:46.300219 22542570456896 run_lib.py:146] step: 598600, eval_loss: 2.72688e-02
I0210 23:28:03.711723 22542570456896 run_lib.py:133] step: 598650, training_loss: 2.59651e-02
I0210 23:28:21.197064 22542570456896 run_lib.py:133] step: 598700, training_loss: 2.99045e-02
I0210 23:28:21.351539 22542570456896 run_lib.py:146] step: 598700, eval_loss: 2.74484e-02
I0210 23:28:38.785315 22542570456896 run_lib.py:133] step: 598750, training_loss: 2.54217e-02
I0210 23:28:56.248441 22542570456896 run_lib.py:133] step: 598800, training_loss: 2.45690e-02
I0210 23:28:56.407453 22542570456896 run_lib.py:146] step: 598800, eval_loss: 2.97202e-02
I0210 23:29:13.981672 22542570456896 run_lib.py:133] step: 598850, training_loss: 2.75099e-02
I0210 23:29:31.391036 22542570456896 run_lib.py:133] step: 598900, training_loss: 2.70465e-02
I0210 23:29:31.546398 22542570456896 run_lib.py:146] step: 598900, eval_loss: 2.18082e-02
I0210 23:29:48.948054 22542570456896 run_lib.py:133] step: 598950, training_loss: 3.00876e-02
I0210 23:30:06.414603 22542570456896 run_lib.py:133] step: 599000, training_loss: 2.52393e-02
I0210 23:30:06.570907 22542570456896 run_lib.py:146] step: 599000, eval_loss: 3.33754e-02
I0210 23:30:24.131926 22542570456896 run_lib.py:133] step: 599050, training_loss: 2.72869e-02
I0210 23:30:41.420932 22542570456896 run_lib.py:133] step: 599100, training_loss: 2.32240e-02
I0210 23:30:41.568167 22542570456896 run_lib.py:146] step: 599100, eval_loss: 2.63475e-02
I0210 23:30:59.032959 22542570456896 run_lib.py:133] step: 599150, training_loss: 2.84545e-02
I0210 23:31:16.326918 22542570456896 run_lib.py:133] step: 599200, training_loss: 3.44872e-02
I0210 23:31:16.480067 22542570456896 run_lib.py:146] step: 599200, eval_loss: 3.24730e-02
I0210 23:31:34.048576 22542570456896 run_lib.py:133] step: 599250, training_loss: 2.44771e-02
I0210 23:31:51.517360 22542570456896 run_lib.py:133] step: 599300, training_loss: 3.23342e-02
I0210 23:31:51.689379 22542570456896 run_lib.py:146] step: 599300, eval_loss: 2.74285e-02
I0210 23:32:09.114418 22542570456896 run_lib.py:133] step: 599350, training_loss: 2.85575e-02
I0210 23:32:26.751512 22542570456896 run_lib.py:133] step: 599400, training_loss: 2.54934e-02
I0210 23:32:26.911579 22542570456896 run_lib.py:146] step: 599400, eval_loss: 2.75935e-02
I0210 23:32:44.320648 22542570456896 run_lib.py:133] step: 599450, training_loss: 3.26678e-02
I0210 23:33:01.835531 22542570456896 run_lib.py:133] step: 599500, training_loss: 2.77731e-02
I0210 23:33:01.987344 22542570456896 run_lib.py:146] step: 599500, eval_loss: 3.11659e-02
I0210 23:33:19.403746 22542570456896 run_lib.py:133] step: 599550, training_loss: 3.11716e-02
I0210 23:33:36.878850 22542570456896 run_lib.py:133] step: 599600, training_loss: 2.62959e-02
I0210 23:33:37.065531 22542570456896 run_lib.py:146] step: 599600, eval_loss: 2.80551e-02
I0210 23:33:54.690362 22542570456896 run_lib.py:133] step: 599650, training_loss: 2.55137e-02
I0210 23:34:12.121439 22542570456896 run_lib.py:133] step: 599700, training_loss: 2.79750e-02
I0210 23:34:12.276385 22542570456896 run_lib.py:146] step: 599700, eval_loss: 3.00926e-02
I0210 23:34:29.683783 22542570456896 run_lib.py:133] step: 599750, training_loss: 2.82474e-02
I0210 23:34:47.213554 22542570456896 run_lib.py:133] step: 599800, training_loss: 3.12457e-02
I0210 23:34:47.372461 22542570456896 run_lib.py:146] step: 599800, eval_loss: 2.94830e-02
I0210 23:35:04.870482 22542570456896 run_lib.py:133] step: 599850, training_loss: 3.09230e-02
I0210 23:35:22.350037 22542570456896 run_lib.py:133] step: 599900, training_loss: 1.77956e-02
I0210 23:35:22.506625 22542570456896 run_lib.py:146] step: 599900, eval_loss: 2.66040e-02
I0210 23:35:40.038325 22542570456896 run_lib.py:133] step: 599950, training_loss: 2.87619e-02
I0210 23:35:57.426858 22542570456896 run_lib.py:133] step: 600000, training_loss: 2.51030e-02
I0210 23:35:58.338253 22542570456896 run_lib.py:146] step: 600000, eval_loss: 3.49144e-02
I0210 23:36:18.746543 22542570456896 run_lib.py:133] step: 600050, training_loss: 2.66507e-02
I0210 23:36:36.144265 22542570456896 run_lib.py:133] step: 600100, training_loss: 2.42368e-02
I0210 23:36:36.298123 22542570456896 run_lib.py:146] step: 600100, eval_loss: 3.10772e-02
I0210 23:36:53.925674 22542570456896 run_lib.py:133] step: 600150, training_loss: 2.43914e-02
I0210 23:37:11.406384 22542570456896 run_lib.py:133] step: 600200, training_loss: 3.40639e-02
I0210 23:37:11.559262 22542570456896 run_lib.py:146] step: 600200, eval_loss: 2.91850e-02
I0210 23:37:29.058693 22542570456896 run_lib.py:133] step: 600250, training_loss: 3.77274e-02
I0210 23:37:46.491509 22542570456896 run_lib.py:133] step: 600300, training_loss: 2.74819e-02
I0210 23:37:46.651175 22542570456896 run_lib.py:146] step: 600300, eval_loss: 3.03392e-02
I0210 23:38:04.067142 22542570456896 run_lib.py:133] step: 600350, training_loss: 2.33064e-02
I0210 23:38:21.508792 22542570456896 run_lib.py:133] step: 600400, training_loss: 2.54266e-02
I0210 23:38:21.664388 22542570456896 run_lib.py:146] step: 600400, eval_loss: 2.28246e-02
I0210 23:38:39.269823 22542570456896 run_lib.py:133] step: 600450, training_loss: 3.21287e-02
I0210 23:38:56.737082 22542570456896 run_lib.py:133] step: 600500, training_loss: 2.86445e-02
I0210 23:38:56.893481 22542570456896 run_lib.py:146] step: 600500, eval_loss: 3.36898e-02
I0210 23:39:14.327886 22542570456896 run_lib.py:133] step: 600550, training_loss: 2.54091e-02
I0210 23:39:31.731447 22542570456896 run_lib.py:133] step: 600600, training_loss: 2.75781e-02
I0210 23:39:31.882685 22542570456896 run_lib.py:146] step: 600600, eval_loss: 2.38421e-02
I0210 23:39:49.433679 22542570456896 run_lib.py:133] step: 600650, training_loss: 2.39230e-02
I0210 23:40:06.888538 22542570456896 run_lib.py:133] step: 600700, training_loss: 2.81040e-02
I0210 23:40:07.058636 22542570456896 run_lib.py:146] step: 600700, eval_loss: 2.43472e-02
I0210 23:40:24.721125 22542570456896 run_lib.py:133] step: 600750, training_loss: 2.55348e-02
I0210 23:40:42.167002 22542570456896 run_lib.py:133] step: 600800, training_loss: 2.78360e-02
I0210 23:40:42.325547 22542570456896 run_lib.py:146] step: 600800, eval_loss: 3.08697e-02
I0210 23:40:59.870745 22542570456896 run_lib.py:133] step: 600850, training_loss: 2.89886e-02
I0210 23:41:17.291233 22542570456896 run_lib.py:133] step: 600900, training_loss: 2.17098e-02
I0210 23:41:17.446375 22542570456896 run_lib.py:146] step: 600900, eval_loss: 2.58527e-02
I0210 23:41:35.010004 22542570456896 run_lib.py:133] step: 600950, training_loss: 2.58910e-02
I0210 23:41:52.483519 22542570456896 run_lib.py:133] step: 601000, training_loss: 3.00300e-02
I0210 23:41:52.641551 22542570456896 run_lib.py:146] step: 601000, eval_loss: 2.80629e-02
I0210 23:42:10.087283 22542570456896 run_lib.py:133] step: 601050, training_loss: 2.48025e-02
I0210 23:42:27.680104 22542570456896 run_lib.py:133] step: 601100, training_loss: 3.07044e-02
I0210 23:42:27.833296 22542570456896 run_lib.py:146] step: 601100, eval_loss: 2.95729e-02
I0210 23:42:45.243907 22542570456896 run_lib.py:133] step: 601150, training_loss: 3.11187e-02
I0210 23:43:02.691670 22542570456896 run_lib.py:133] step: 601200, training_loss: 2.79526e-02
I0210 23:43:02.849582 22542570456896 run_lib.py:146] step: 601200, eval_loss: 2.82467e-02
I0210 23:43:20.466382 22542570456896 run_lib.py:133] step: 601250, training_loss: 3.01612e-02
I0210 23:43:37.914269 22542570456896 run_lib.py:133] step: 601300, training_loss: 3.62414e-02
I0210 23:43:38.073255 22542570456896 run_lib.py:146] step: 601300, eval_loss: 3.26737e-02
I0210 23:43:55.714992 22542570456896 run_lib.py:133] step: 601350, training_loss: 3.37578e-02
I0210 23:44:13.082679 22542570456896 run_lib.py:133] step: 601400, training_loss: 2.56330e-02
I0210 23:44:13.238477 22542570456896 run_lib.py:146] step: 601400, eval_loss: 2.98229e-02
I0210 23:44:30.659454 22542570456896 run_lib.py:133] step: 601450, training_loss: 2.92569e-02
I0210 23:44:48.222835 22542570456896 run_lib.py:133] step: 601500, training_loss: 3.48197e-02
I0210 23:44:48.379577 22542570456896 run_lib.py:146] step: 601500, eval_loss: 2.91058e-02
I0210 23:45:05.893554 22542570456896 run_lib.py:133] step: 601550, training_loss: 2.46294e-02
I0210 23:45:23.338484 22542570456896 run_lib.py:133] step: 601600, training_loss: 2.43433e-02
I0210 23:45:23.498337 22542570456896 run_lib.py:146] step: 601600, eval_loss: 2.45585e-02
I0210 23:45:40.877335 22542570456896 run_lib.py:133] step: 601650, training_loss: 3.28468e-02
I0210 23:45:58.485846 22542570456896 run_lib.py:133] step: 601700, training_loss: 2.55540e-02
I0210 23:45:58.645731 22542570456896 run_lib.py:146] step: 601700, eval_loss: 2.99972e-02
I0210 23:46:16.127251 22542570456896 run_lib.py:133] step: 601750, training_loss: 2.69845e-02
I0210 23:46:33.648257 22542570456896 run_lib.py:133] step: 601800, training_loss: 2.50101e-02
I0210 23:46:33.804635 22542570456896 run_lib.py:146] step: 601800, eval_loss: 3.15703e-02
I0210 23:46:51.223817 22542570456896 run_lib.py:133] step: 601850, training_loss: 2.70449e-02
I0210 23:47:08.647512 22542570456896 run_lib.py:133] step: 601900, training_loss: 2.91358e-02
I0210 23:47:08.803325 22542570456896 run_lib.py:146] step: 601900, eval_loss: 3.19711e-02
I0210 23:47:26.407577 22542570456896 run_lib.py:133] step: 601950, training_loss: 2.87296e-02
I0210 23:47:43.891591 22542570456896 run_lib.py:133] step: 602000, training_loss: 2.31758e-02
I0210 23:47:44.043000 22542570456896 run_lib.py:146] step: 602000, eval_loss: 2.62189e-02
I0210 23:48:01.420151 22542570456896 run_lib.py:133] step: 602050, training_loss: 2.86317e-02
I0210 23:48:18.860081 22542570456896 run_lib.py:133] step: 602100, training_loss: 2.53856e-02
I0210 23:48:19.023540 22542570456896 run_lib.py:146] step: 602100, eval_loss: 3.43967e-02
I0210 23:48:36.646234 22542570456896 run_lib.py:133] step: 602150, training_loss: 2.67723e-02
I0210 23:48:54.061525 22542570456896 run_lib.py:133] step: 602200, training_loss: 2.97069e-02
I0210 23:48:54.227116 22542570456896 run_lib.py:146] step: 602200, eval_loss: 2.87661e-02
I0210 23:49:11.769474 22542570456896 run_lib.py:133] step: 602250, training_loss: 2.95359e-02
I0210 23:49:29.182020 22542570456896 run_lib.py:133] step: 602300, training_loss: 3.25345e-02
I0210 23:49:29.336210 22542570456896 run_lib.py:146] step: 602300, eval_loss: 2.72073e-02
I0210 23:49:46.917330 22542570456896 run_lib.py:133] step: 602350, training_loss: 2.76305e-02
I0210 23:50:04.377961 22542570456896 run_lib.py:133] step: 602400, training_loss: 3.01814e-02
I0210 23:50:04.534735 22542570456896 run_lib.py:146] step: 602400, eval_loss: 3.95253e-02
I0210 23:50:21.964528 22542570456896 run_lib.py:133] step: 602450, training_loss: 2.41157e-02
I0210 23:50:39.555139 22542570456896 run_lib.py:133] step: 602500, training_loss: 2.34637e-02
I0210 23:50:39.712491 22542570456896 run_lib.py:146] step: 602500, eval_loss: 2.59871e-02
I0210 23:50:57.128818 22542570456896 run_lib.py:133] step: 602550, training_loss: 2.82235e-02
I0210 23:51:14.643796 22542570456896 run_lib.py:133] step: 602600, training_loss: 2.87964e-02
I0210 23:51:14.809648 22542570456896 run_lib.py:146] step: 602600, eval_loss: 2.82204e-02
I0210 23:51:32.255327 22542570456896 run_lib.py:133] step: 602650, training_loss: 2.77619e-02
I0210 23:51:49.716972 22542570456896 run_lib.py:133] step: 602700, training_loss: 2.36542e-02
I0210 23:51:49.875342 22542570456896 run_lib.py:146] step: 602700, eval_loss: 3.41229e-02
I0210 23:52:07.467339 22542570456896 run_lib.py:133] step: 602750, training_loss: 2.55203e-02
I0210 23:52:24.877147 22542570456896 run_lib.py:133] step: 602800, training_loss: 3.21790e-02
I0210 23:52:25.059424 22542570456896 run_lib.py:146] step: 602800, eval_loss: 2.99621e-02
I0210 23:52:42.479833 22542570456896 run_lib.py:133] step: 602850, training_loss: 2.74947e-02
I0210 23:53:00.042768 22542570456896 run_lib.py:133] step: 602900, training_loss: 2.59148e-02
I0210 23:53:00.197054 22542570456896 run_lib.py:146] step: 602900, eval_loss: 2.81281e-02
I0210 23:53:17.638276 22542570456896 run_lib.py:133] step: 602950, training_loss: 2.71829e-02
I0210 23:53:35.090970 22542570456896 run_lib.py:133] step: 603000, training_loss: 2.55238e-02
I0210 23:53:35.423188 22542570456896 run_lib.py:146] step: 603000, eval_loss: 2.76113e-02
I0210 23:53:52.803999 22542570456896 run_lib.py:133] step: 603050, training_loss: 2.89937e-02
I0210 23:54:10.233654 22542570456896 run_lib.py:133] step: 603100, training_loss: 2.95305e-02
I0210 23:54:10.389186 22542570456896 run_lib.py:146] step: 603100, eval_loss: 3.24093e-02
I0210 23:54:27.840425 22542570456896 run_lib.py:133] step: 603150, training_loss: 2.69781e-02
I0210 23:54:45.254365 22542570456896 run_lib.py:133] step: 603200, training_loss: 2.92563e-02
I0210 23:54:45.429942 22542570456896 run_lib.py:146] step: 603200, eval_loss: 3.16114e-02
I0210 23:55:02.998695 22542570456896 run_lib.py:133] step: 603250, training_loss: 2.42972e-02
I0210 23:55:20.530988 22542570456896 run_lib.py:133] step: 603300, training_loss: 3.20344e-02
I0210 23:55:20.686573 22542570456896 run_lib.py:146] step: 603300, eval_loss: 3.01248e-02
I0210 23:55:38.102238 22542570456896 run_lib.py:133] step: 603350, training_loss: 2.73581e-02
I0210 23:55:55.506221 22542570456896 run_lib.py:133] step: 603400, training_loss: 2.39573e-02
I0210 23:55:55.661277 22542570456896 run_lib.py:146] step: 603400, eval_loss: 2.86692e-02
I0210 23:56:13.207978 22542570456896 run_lib.py:133] step: 603450, training_loss: 2.30950e-02
I0210 23:56:30.789599 22542570456896 run_lib.py:133] step: 603500, training_loss: 2.53441e-02
I0210 23:56:30.941759 22542570456896 run_lib.py:146] step: 603500, eval_loss: 2.57364e-02
I0210 23:56:48.359953 22542570456896 run_lib.py:133] step: 603550, training_loss: 3.31437e-02
I0210 23:57:05.758290 22542570456896 run_lib.py:133] step: 603600, training_loss: 2.53702e-02
I0210 23:57:05.915952 22542570456896 run_lib.py:146] step: 603600, eval_loss: 2.93649e-02
I0210 23:57:23.485738 22542570456896 run_lib.py:133] step: 603650, training_loss: 2.41159e-02
I0210 23:57:40.883401 22542570456896 run_lib.py:133] step: 603700, training_loss: 2.53155e-02
I0210 23:57:41.039340 22542570456896 run_lib.py:146] step: 603700, eval_loss: 2.86068e-02
I0210 23:57:58.601086 22542570456896 run_lib.py:133] step: 603750, training_loss: 3.07609e-02
I0210 23:58:16.015681 22542570456896 run_lib.py:133] step: 603800, training_loss: 3.10389e-02
I0210 23:58:16.174243 22542570456896 run_lib.py:146] step: 603800, eval_loss: 2.74935e-02
I0210 23:58:33.781018 22542570456896 run_lib.py:133] step: 603850, training_loss: 3.16855e-02
I0210 23:58:51.218070 22542570456896 run_lib.py:133] step: 603900, training_loss: 2.25737e-02
I0210 23:58:51.369406 22542570456896 run_lib.py:146] step: 603900, eval_loss: 2.50385e-02
I0210 23:59:08.816293 22542570456896 run_lib.py:133] step: 603950, training_loss: 3.30975e-02
I0210 23:59:26.387826 22542570456896 run_lib.py:133] step: 604000, training_loss: 2.87660e-02
I0210 23:59:26.542277 22542570456896 run_lib.py:146] step: 604000, eval_loss: 2.40502e-02
I0210 23:59:43.940499 22542570456896 run_lib.py:133] step: 604050, training_loss: 2.48888e-02
I0211 00:00:01.570876 22542570456896 run_lib.py:133] step: 604100, training_loss: 2.33168e-02
I0211 00:00:01.737233 22542570456896 run_lib.py:146] step: 604100, eval_loss: 2.63047e-02
I0211 00:00:19.163733 22542570456896 run_lib.py:133] step: 604150, training_loss: 2.93042e-02
I0211 00:00:36.579152 22542570456896 run_lib.py:133] step: 604200, training_loss: 2.26960e-02
I0211 00:00:36.733473 22542570456896 run_lib.py:146] step: 604200, eval_loss: 3.39883e-02
I0211 00:00:54.303380 22542570456896 run_lib.py:133] step: 604250, training_loss: 2.50909e-02
I0211 00:01:11.704320 22542570456896 run_lib.py:133] step: 604300, training_loss: 2.29489e-02
I0211 00:01:11.870460 22542570456896 run_lib.py:146] step: 604300, eval_loss: 2.73050e-02
I0211 00:01:29.344008 22542570456896 run_lib.py:133] step: 604350, training_loss: 3.04878e-02
I0211 00:01:46.777476 22542570456896 run_lib.py:133] step: 604400, training_loss: 2.61582e-02
I0211 00:01:46.929644 22542570456896 run_lib.py:146] step: 604400, eval_loss: 2.51698e-02
I0211 00:02:04.560050 22542570456896 run_lib.py:133] step: 604450, training_loss: 3.50813e-02
I0211 00:02:21.955137 22542570456896 run_lib.py:133] step: 604500, training_loss: 2.23487e-02
I0211 00:02:22.118296 22542570456896 run_lib.py:146] step: 604500, eval_loss: 3.30155e-02
I0211 00:02:39.554749 22542570456896 run_lib.py:133] step: 604550, training_loss: 2.42025e-02
I0211 00:02:56.940613 22542570456896 run_lib.py:133] step: 604600, training_loss: 1.80723e-02
I0211 00:02:57.116274 22542570456896 run_lib.py:146] step: 604600, eval_loss: 2.66605e-02
I0211 00:03:14.595519 22542570456896 run_lib.py:133] step: 604650, training_loss: 2.80617e-02
I0211 00:03:31.997837 22542570456896 run_lib.py:133] step: 604700, training_loss: 2.59932e-02
I0211 00:03:32.160590 22542570456896 run_lib.py:146] step: 604700, eval_loss: 2.40268e-02
I0211 00:03:49.747945 22542570456896 run_lib.py:133] step: 604750, training_loss: 2.93290e-02
I0211 00:04:07.233942 22542570456896 run_lib.py:133] step: 604800, training_loss: 2.79571e-02
I0211 00:04:07.388394 22542570456896 run_lib.py:146] step: 604800, eval_loss: 3.44156e-02
I0211 00:04:24.855843 22542570456896 run_lib.py:133] step: 604850, training_loss: 3.12963e-02
I0211 00:04:42.288238 22542570456896 run_lib.py:133] step: 604900, training_loss: 3.28411e-02
I0211 00:04:42.442569 22542570456896 run_lib.py:146] step: 604900, eval_loss: 2.99195e-02
I0211 00:05:00.045132 22542570456896 run_lib.py:133] step: 604950, training_loss: 2.48188e-02
I0211 00:05:17.481688 22542570456896 run_lib.py:133] step: 605000, training_loss: 2.69808e-02
I0211 00:05:17.637312 22542570456896 run_lib.py:146] step: 605000, eval_loss: 3.09192e-02
I0211 00:05:35.165035 22542570456896 run_lib.py:133] step: 605050, training_loss: 2.26574e-02
I0211 00:05:52.575787 22542570456896 run_lib.py:133] step: 605100, training_loss: 2.88138e-02
I0211 00:05:52.735581 22542570456896 run_lib.py:146] step: 605100, eval_loss: 2.64442e-02
I0211 00:06:10.280266 22542570456896 run_lib.py:133] step: 605150, training_loss: 2.43700e-02
I0211 00:06:27.746077 22542570456896 run_lib.py:133] step: 605200, training_loss: 2.29372e-02
I0211 00:06:27.899445 22542570456896 run_lib.py:146] step: 605200, eval_loss: 3.02439e-02
I0211 00:06:45.511453 22542570456896 run_lib.py:133] step: 605250, training_loss: 2.94345e-02
I0211 00:07:02.872197 22542570456896 run_lib.py:133] step: 605300, training_loss: 2.69736e-02
I0211 00:07:03.026428 22542570456896 run_lib.py:146] step: 605300, eval_loss: 2.51098e-02
I0211 00:07:20.414983 22542570456896 run_lib.py:133] step: 605350, training_loss: 2.50976e-02
I0211 00:07:37.965363 22542570456896 run_lib.py:133] step: 605400, training_loss: 3.09116e-02
I0211 00:07:38.118353 22542570456896 run_lib.py:146] step: 605400, eval_loss: 3.41272e-02
I0211 00:07:55.554559 22542570456896 run_lib.py:133] step: 605450, training_loss: 2.75732e-02
I0211 00:08:12.966367 22542570456896 run_lib.py:133] step: 605500, training_loss: 3.11291e-02
I0211 00:08:13.125447 22542570456896 run_lib.py:146] step: 605500, eval_loss: 3.06781e-02
I0211 00:08:30.716355 22542570456896 run_lib.py:133] step: 605550, training_loss: 2.57295e-02
I0211 00:08:48.268367 22542570456896 run_lib.py:133] step: 605600, training_loss: 2.96580e-02
I0211 00:08:48.421640 22542570456896 run_lib.py:146] step: 605600, eval_loss: 3.18268e-02
I0211 00:09:05.856752 22542570456896 run_lib.py:133] step: 605650, training_loss: 2.69428e-02
I0211 00:09:23.242386 22542570456896 run_lib.py:133] step: 605700, training_loss: 3.07575e-02
I0211 00:09:23.396047 22542570456896 run_lib.py:146] step: 605700, eval_loss: 3.08170e-02
I0211 00:09:40.881048 22542570456896 run_lib.py:133] step: 605750, training_loss: 2.29930e-02
I0211 00:09:58.493171 22542570456896 run_lib.py:133] step: 605800, training_loss: 3.03948e-02
I0211 00:09:58.646967 22542570456896 run_lib.py:146] step: 605800, eval_loss: 2.60246e-02
I0211 00:10:16.069661 22542570456896 run_lib.py:133] step: 605850, training_loss: 2.65663e-02
I0211 00:10:33.483849 22542570456896 run_lib.py:133] step: 605900, training_loss: 3.06554e-02
I0211 00:10:33.639190 22542570456896 run_lib.py:146] step: 605900, eval_loss: 2.69180e-02
I0211 00:10:51.012296 22542570456896 run_lib.py:133] step: 605950, training_loss: 3.47443e-02
I0211 00:11:08.609073 22542570456896 run_lib.py:133] step: 606000, training_loss: 2.38332e-02
I0211 00:11:08.779430 22542570456896 run_lib.py:146] step: 606000, eval_loss: 2.50869e-02
I0211 00:11:26.202685 22542570456896 run_lib.py:133] step: 606050, training_loss: 2.62975e-02
I0211 00:11:43.703382 22542570456896 run_lib.py:133] step: 606100, training_loss: 2.63892e-02
I0211 00:11:43.856515 22542570456896 run_lib.py:146] step: 606100, eval_loss: 2.77286e-02
I0211 00:12:01.203016 22542570456896 run_lib.py:133] step: 606150, training_loss: 2.51287e-02
I0211 00:12:18.597487 22542570456896 run_lib.py:133] step: 606200, training_loss: 3.07134e-02
I0211 00:12:18.753952 22542570456896 run_lib.py:146] step: 606200, eval_loss: 3.21370e-02
I0211 00:12:36.302664 22542570456896 run_lib.py:133] step: 606250, training_loss: 2.68564e-02
I0211 00:12:53.756465 22542570456896 run_lib.py:133] step: 606300, training_loss: 2.89230e-02
I0211 00:12:53.911478 22542570456896 run_lib.py:146] step: 606300, eval_loss: 3.09866e-02
I0211 00:13:11.347555 22542570456896 run_lib.py:133] step: 606350, training_loss: 2.67658e-02
I0211 00:13:28.729102 22542570456896 run_lib.py:133] step: 606400, training_loss: 3.28379e-02
I0211 00:13:28.884305 22542570456896 run_lib.py:146] step: 606400, eval_loss: 3.87129e-02
I0211 00:13:46.477769 22542570456896 run_lib.py:133] step: 606450, training_loss: 2.64666e-02
I0211 00:14:03.902910 22542570456896 run_lib.py:133] step: 606500, training_loss: 2.49334e-02
I0211 00:14:04.061512 22542570456896 run_lib.py:146] step: 606500, eval_loss: 3.01666e-02
I0211 00:14:21.603945 22542570456896 run_lib.py:133] step: 606550, training_loss: 3.06877e-02
I0211 00:14:39.036609 22542570456896 run_lib.py:133] step: 606600, training_loss: 3.32284e-02
I0211 00:14:39.204202 22542570456896 run_lib.py:146] step: 606600, eval_loss: 2.77465e-02
I0211 00:14:56.784271 22542570456896 run_lib.py:133] step: 606650, training_loss: 2.16593e-02
I0211 00:15:14.209586 22542570456896 run_lib.py:133] step: 606700, training_loss: 2.86939e-02
I0211 00:15:14.364283 22542570456896 run_lib.py:146] step: 606700, eval_loss: 2.60290e-02
I0211 00:15:31.742249 22542570456896 run_lib.py:133] step: 606750, training_loss: 3.05213e-02
I0211 00:15:49.262706 22542570456896 run_lib.py:133] step: 606800, training_loss: 3.05087e-02
I0211 00:15:49.414383 22542570456896 run_lib.py:146] step: 606800, eval_loss: 3.17868e-02
I0211 00:16:06.811680 22542570456896 run_lib.py:133] step: 606850, training_loss: 3.06901e-02
I0211 00:16:24.361951 22542570456896 run_lib.py:133] step: 606900, training_loss: 2.63114e-02
I0211 00:16:24.532368 22542570456896 run_lib.py:146] step: 606900, eval_loss: 2.79278e-02
I0211 00:16:41.951340 22542570456896 run_lib.py:133] step: 606950, training_loss: 2.40369e-02
I0211 00:16:59.382878 22542570456896 run_lib.py:133] step: 607000, training_loss: 3.13417e-02
I0211 00:16:59.538571 22542570456896 run_lib.py:146] step: 607000, eval_loss: 3.11277e-02
I0211 00:17:17.140925 22542570456896 run_lib.py:133] step: 607050, training_loss: 3.40592e-02
I0211 00:17:34.488938 22542570456896 run_lib.py:133] step: 607100, training_loss: 2.81156e-02
I0211 00:17:34.644527 22542570456896 run_lib.py:146] step: 607100, eval_loss: 2.76912e-02
I0211 00:17:52.032782 22542570456896 run_lib.py:133] step: 607150, training_loss: 2.76470e-02
I0211 00:18:09.649899 22542570456896 run_lib.py:133] step: 607200, training_loss: 3.22198e-02
I0211 00:18:09.810653 22542570456896 run_lib.py:146] step: 607200, eval_loss: 2.94802e-02
I0211 00:18:27.246669 22542570456896 run_lib.py:133] step: 607250, training_loss: 3.31938e-02
I0211 00:18:44.601068 22542570456896 run_lib.py:133] step: 607300, training_loss: 2.73564e-02
I0211 00:18:44.752193 22542570456896 run_lib.py:146] step: 607300, eval_loss: 3.06848e-02
I0211 00:19:02.186043 22542570456896 run_lib.py:133] step: 607350, training_loss: 2.40999e-02
I0211 00:19:19.569352 22542570456896 run_lib.py:133] step: 607400, training_loss: 2.67839e-02
I0211 00:19:19.736422 22542570456896 run_lib.py:146] step: 607400, eval_loss: 3.24824e-02
I0211 00:19:37.126916 22542570456896 run_lib.py:133] step: 607450, training_loss: 2.69091e-02
I0211 00:19:54.608913 22542570456896 run_lib.py:133] step: 607500, training_loss: 2.88110e-02
I0211 00:19:54.764468 22542570456896 run_lib.py:146] step: 607500, eval_loss: 2.89783e-02
I0211 00:20:12.370145 22542570456896 run_lib.py:133] step: 607550, training_loss: 3.19263e-02
I0211 00:20:29.822375 22542570456896 run_lib.py:133] step: 607600, training_loss: 3.10074e-02
I0211 00:20:29.975970 22542570456896 run_lib.py:146] step: 607600, eval_loss: 2.93229e-02
I0211 00:20:47.358374 22542570456896 run_lib.py:133] step: 607650, training_loss: 2.69294e-02
I0211 00:21:04.773141 22542570456896 run_lib.py:133] step: 607700, training_loss: 2.40107e-02
I0211 00:21:04.930624 22542570456896 run_lib.py:146] step: 607700, eval_loss: 3.30107e-02
I0211 00:21:22.542110 22542570456896 run_lib.py:133] step: 607750, training_loss: 3.20801e-02
I0211 00:21:39.952115 22542570456896 run_lib.py:133] step: 607800, training_loss: 2.59444e-02
I0211 00:21:40.110718 22542570456896 run_lib.py:146] step: 607800, eval_loss: 2.86215e-02
I0211 00:21:57.660497 22542570456896 run_lib.py:133] step: 607850, training_loss: 2.82634e-02
I0211 00:22:14.996149 22542570456896 run_lib.py:133] step: 607900, training_loss: 2.58316e-02
I0211 00:22:15.153443 22542570456896 run_lib.py:146] step: 607900, eval_loss: 3.94985e-02
I0211 00:22:32.713582 22542570456896 run_lib.py:133] step: 607950, training_loss: 2.61295e-02
I0211 00:22:50.173848 22542570456896 run_lib.py:133] step: 608000, training_loss: 2.64648e-02
I0211 00:22:50.332457 22542570456896 run_lib.py:146] step: 608000, eval_loss: 2.29613e-02
I0211 00:23:07.891758 22542570456896 run_lib.py:133] step: 608050, training_loss: 2.64821e-02
I0211 00:23:25.279560 22542570456896 run_lib.py:133] step: 608100, training_loss: 2.69133e-02
I0211 00:23:25.435289 22542570456896 run_lib.py:146] step: 608100, eval_loss: 3.14392e-02
I0211 00:23:42.842750 22542570456896 run_lib.py:133] step: 608150, training_loss: 2.41237e-02
I0211 00:24:00.415189 22542570456896 run_lib.py:133] step: 608200, training_loss: 2.57883e-02
I0211 00:24:00.566312 22542570456896 run_lib.py:146] step: 608200, eval_loss: 2.78650e-02
I0211 00:24:18.010180 22542570456896 run_lib.py:133] step: 608250, training_loss: 2.95735e-02
I0211 00:24:35.450124 22542570456896 run_lib.py:133] step: 608300, training_loss: 3.97068e-02
I0211 00:24:35.614484 22542570456896 run_lib.py:146] step: 608300, eval_loss: 2.47957e-02
I0211 00:24:53.226646 22542570456896 run_lib.py:133] step: 608350, training_loss: 2.45590e-02
I0211 00:25:10.644775 22542570456896 run_lib.py:133] step: 608400, training_loss: 2.68963e-02
I0211 00:25:10.802688 22542570456896 run_lib.py:146] step: 608400, eval_loss: 2.24692e-02
I0211 00:25:28.333659 22542570456896 run_lib.py:133] step: 608450, training_loss: 2.58823e-02
I0211 00:25:45.723123 22542570456896 run_lib.py:133] step: 608500, training_loss: 2.80637e-02
I0211 00:25:45.887464 22542570456896 run_lib.py:146] step: 608500, eval_loss: 2.65614e-02
I0211 00:26:03.279222 22542570456896 run_lib.py:133] step: 608550, training_loss: 2.97261e-02
I0211 00:26:20.917024 22542570456896 run_lib.py:133] step: 608600, training_loss: 2.90201e-02
I0211 00:26:21.078650 22542570456896 run_lib.py:146] step: 608600, eval_loss: 2.60891e-02
I0211 00:26:38.490603 22542570456896 run_lib.py:133] step: 608650, training_loss: 2.77366e-02
I0211 00:26:55.904273 22542570456896 run_lib.py:133] step: 608700, training_loss: 3.00468e-02
I0211 00:26:56.070746 22542570456896 run_lib.py:146] step: 608700, eval_loss: 2.66495e-02
I0211 00:27:13.458117 22542570456896 run_lib.py:133] step: 608750, training_loss: 3.17394e-02
I0211 00:27:31.013319 22542570456896 run_lib.py:133] step: 608800, training_loss: 2.20357e-02
I0211 00:27:31.175545 22542570456896 run_lib.py:146] step: 608800, eval_loss: 3.08744e-02
I0211 00:27:48.607757 22542570456896 run_lib.py:133] step: 608850, training_loss: 2.98547e-02
I0211 00:28:06.113732 22542570456896 run_lib.py:133] step: 608900, training_loss: 2.82149e-02
I0211 00:28:06.270238 22542570456896 run_lib.py:146] step: 608900, eval_loss: 2.95570e-02
I0211 00:28:23.703474 22542570456896 run_lib.py:133] step: 608950, training_loss: 2.66497e-02
I0211 00:28:41.070933 22542570456896 run_lib.py:133] step: 609000, training_loss: 2.54742e-02
I0211 00:28:41.230045 22542570456896 run_lib.py:146] step: 609000, eval_loss: 2.60424e-02
I0211 00:28:58.778801 22542570456896 run_lib.py:133] step: 609050, training_loss: 3.53210e-02
I0211 00:29:16.200836 22542570456896 run_lib.py:133] step: 609100, training_loss: 2.22907e-02
I0211 00:29:16.355070 22542570456896 run_lib.py:146] step: 609100, eval_loss: 1.94675e-02
I0211 00:29:33.849581 22542570456896 run_lib.py:133] step: 609150, training_loss: 2.56263e-02
I0211 00:29:51.318712 22542570456896 run_lib.py:133] step: 609200, training_loss: 2.72737e-02
I0211 00:29:51.472561 22542570456896 run_lib.py:146] step: 609200, eval_loss: 3.05840e-02
I0211 00:30:09.068432 22542570456896 run_lib.py:133] step: 609250, training_loss: 2.55227e-02
I0211 00:30:26.462595 22542570456896 run_lib.py:133] step: 609300, training_loss: 2.46290e-02
I0211 00:30:26.627919 22542570456896 run_lib.py:146] step: 609300, eval_loss: 2.72497e-02
I0211 00:30:44.165385 22542570456896 run_lib.py:133] step: 609350, training_loss: 3.45720e-02
I0211 00:31:01.560940 22542570456896 run_lib.py:133] step: 609400, training_loss: 2.79021e-02
I0211 00:31:01.721263 22542570456896 run_lib.py:146] step: 609400, eval_loss: 3.16491e-02
I0211 00:31:19.348360 22542570456896 run_lib.py:133] step: 609450, training_loss: 3.03969e-02
I0211 00:31:36.763069 22542570456896 run_lib.py:133] step: 609500, training_loss: 2.91976e-02
I0211 00:31:36.918561 22542570456896 run_lib.py:146] step: 609500, eval_loss: 2.88519e-02
I0211 00:31:54.348260 22542570456896 run_lib.py:133] step: 609550, training_loss: 3.57903e-02
I0211 00:32:11.862484 22542570456896 run_lib.py:133] step: 609600, training_loss: 2.24568e-02
I0211 00:32:12.012243 22542570456896 run_lib.py:146] step: 609600, eval_loss: 2.51497e-02
I0211 00:32:29.423665 22542570456896 run_lib.py:133] step: 609650, training_loss: 2.26872e-02
I0211 00:32:47.031166 22542570456896 run_lib.py:133] step: 609700, training_loss: 3.19113e-02
I0211 00:32:47.198477 22542570456896 run_lib.py:146] step: 609700, eval_loss: 3.14829e-02
I0211 00:33:04.619284 22542570456896 run_lib.py:133] step: 609750, training_loss: 3.04611e-02
I0211 00:33:22.065768 22542570456896 run_lib.py:133] step: 609800, training_loss: 2.42466e-02
I0211 00:33:22.223526 22542570456896 run_lib.py:146] step: 609800, eval_loss: 2.42302e-02
I0211 00:33:39.821748 22542570456896 run_lib.py:133] step: 609850, training_loss: 2.10482e-02
I0211 00:33:57.216766 22542570456896 run_lib.py:133] step: 609900, training_loss: 3.11878e-02
I0211 00:33:57.371325 22542570456896 run_lib.py:146] step: 609900, eval_loss: 3.64550e-02
I0211 00:34:14.810830 22542570456896 run_lib.py:133] step: 609950, training_loss: 2.30448e-02
I0211 00:34:32.412654 22542570456896 run_lib.py:133] step: 610000, training_loss: 2.51073e-02
I0211 00:34:33.299412 22542570456896 run_lib.py:146] step: 610000, eval_loss: 3.03423e-02
I0211 00:34:53.334835 22542570456896 run_lib.py:133] step: 610050, training_loss: 3.39692e-02
I0211 00:35:10.750637 22542570456896 run_lib.py:133] step: 610100, training_loss: 3.08158e-02
I0211 00:35:10.911281 22542570456896 run_lib.py:146] step: 610100, eval_loss: 2.49428e-02
I0211 00:35:28.533861 22542570456896 run_lib.py:133] step: 610150, training_loss: 2.66972e-02
I0211 00:35:45.984010 22542570456896 run_lib.py:133] step: 610200, training_loss: 3.24394e-02
I0211 00:35:46.137578 22542570456896 run_lib.py:146] step: 610200, eval_loss: 2.86248e-02
I0211 00:36:03.606818 22542570456896 run_lib.py:133] step: 610250, training_loss: 2.35274e-02
I0211 00:36:21.047078 22542570456896 run_lib.py:133] step: 610300, training_loss: 3.71264e-02
I0211 00:36:21.205354 22542570456896 run_lib.py:146] step: 610300, eval_loss: 3.15188e-02
I0211 00:36:38.787900 22542570456896 run_lib.py:133] step: 610350, training_loss: 3.10383e-02
I0211 00:36:56.183596 22542570456896 run_lib.py:133] step: 610400, training_loss: 2.60322e-02
I0211 00:36:56.344731 22542570456896 run_lib.py:146] step: 610400, eval_loss: 3.01133e-02
I0211 00:37:13.816856 22542570456896 run_lib.py:133] step: 610450, training_loss: 2.63598e-02
I0211 00:37:31.245681 22542570456896 run_lib.py:133] step: 610500, training_loss: 2.23877e-02
I0211 00:37:31.401216 22542570456896 run_lib.py:146] step: 610500, eval_loss: 2.94134e-02
I0211 00:37:48.860456 22542570456896 run_lib.py:133] step: 610550, training_loss: 2.93800e-02
I0211 00:38:06.235628 22542570456896 run_lib.py:133] step: 610600, training_loss: 2.69038e-02
I0211 00:38:06.389168 22542570456896 run_lib.py:146] step: 610600, eval_loss: 3.11629e-02
I0211 00:38:23.930945 22542570456896 run_lib.py:133] step: 610650, training_loss: 2.65414e-02
I0211 00:38:41.405282 22542570456896 run_lib.py:133] step: 610700, training_loss: 2.21386e-02
I0211 00:38:41.557297 22542570456896 run_lib.py:146] step: 610700, eval_loss: 3.26072e-02
I0211 00:38:58.971995 22542570456896 run_lib.py:133] step: 610750, training_loss: 1.87402e-02
I0211 00:39:16.312736 22542570456896 run_lib.py:133] step: 610800, training_loss: 2.45093e-02
I0211 00:39:16.486231 22542570456896 run_lib.py:146] step: 610800, eval_loss: 3.18600e-02
I0211 00:39:33.987321 22542570456896 run_lib.py:133] step: 610850, training_loss: 2.68809e-02
I0211 00:39:51.347161 22542570456896 run_lib.py:133] step: 610900, training_loss: 2.18989e-02
I0211 00:39:51.504973 22542570456896 run_lib.py:146] step: 610900, eval_loss: 2.25151e-02
I0211 00:40:08.915602 22542570456896 run_lib.py:133] step: 610950, training_loss: 3.03075e-02
I0211 00:40:26.323980 22542570456896 run_lib.py:133] step: 611000, training_loss: 2.61352e-02
I0211 00:40:26.489476 22542570456896 run_lib.py:146] step: 611000, eval_loss: 2.56731e-02
I0211 00:40:44.041984 22542570456896 run_lib.py:133] step: 611050, training_loss: 2.16634e-02
I0211 00:41:01.492198 22542570456896 run_lib.py:133] step: 611100, training_loss: 2.19634e-02
I0211 00:41:01.645719 22542570456896 run_lib.py:146] step: 611100, eval_loss: 3.11267e-02
I0211 00:41:19.252118 22542570456896 run_lib.py:133] step: 611150, training_loss: 2.25330e-02
I0211 00:41:36.643618 22542570456896 run_lib.py:133] step: 611200, training_loss: 2.92310e-02
I0211 00:41:36.799436 22542570456896 run_lib.py:146] step: 611200, eval_loss: 2.74632e-02
I0211 00:41:54.203803 22542570456896 run_lib.py:133] step: 611250, training_loss: 2.53562e-02
I0211 00:42:11.779153 22542570456896 run_lib.py:133] step: 611300, training_loss: 1.81564e-02
I0211 00:42:11.956487 22542570456896 run_lib.py:146] step: 611300, eval_loss: 2.83655e-02
I0211 00:42:29.396906 22542570456896 run_lib.py:133] step: 611350, training_loss: 2.65849e-02
I0211 00:42:46.812190 22542570456896 run_lib.py:133] step: 611400, training_loss: 2.58848e-02
I0211 00:42:46.973561 22542570456896 run_lib.py:146] step: 611400, eval_loss: 2.53591e-02
I0211 00:43:04.599865 22542570456896 run_lib.py:133] step: 611450, training_loss: 2.96345e-02
I0211 00:43:22.156897 22542570456896 run_lib.py:133] step: 611500, training_loss: 2.64310e-02
I0211 00:43:22.311281 22542570456896 run_lib.py:146] step: 611500, eval_loss: 2.83283e-02
I0211 00:43:39.717554 22542570456896 run_lib.py:133] step: 611550, training_loss: 2.11542e-02
I0211 00:43:57.159840 22542570456896 run_lib.py:133] step: 611600, training_loss: 2.86647e-02
I0211 00:43:57.314580 22542570456896 run_lib.py:146] step: 611600, eval_loss: 2.77415e-02
I0211 00:44:14.956283 22542570456896 run_lib.py:133] step: 611650, training_loss: 2.43088e-02
I0211 00:44:32.562915 22542570456896 run_lib.py:133] step: 611700, training_loss: 3.18099e-02
I0211 00:44:32.725914 22542570456896 run_lib.py:146] step: 611700, eval_loss: 2.79907e-02
I0211 00:44:50.156135 22542570456896 run_lib.py:133] step: 611750, training_loss: 3.23743e-02
I0211 00:45:07.530554 22542570456896 run_lib.py:133] step: 611800, training_loss: 2.52421e-02
I0211 00:45:07.687624 22542570456896 run_lib.py:146] step: 611800, eval_loss: 2.53897e-02
I0211 00:45:25.136734 22542570456896 run_lib.py:133] step: 611850, training_loss: 2.73224e-02
I0211 00:45:42.790754 22542570456896 run_lib.py:133] step: 611900, training_loss: 3.27220e-02
I0211 00:45:42.955575 22542570456896 run_lib.py:146] step: 611900, eval_loss: 3.28244e-02
I0211 00:46:00.375828 22542570456896 run_lib.py:133] step: 611950, training_loss: 3.05566e-02
I0211 00:46:17.835893 22542570456896 run_lib.py:133] step: 612000, training_loss: 2.71106e-02
I0211 00:46:17.992294 22542570456896 run_lib.py:146] step: 612000, eval_loss: 2.93185e-02
I0211 00:46:35.410854 22542570456896 run_lib.py:133] step: 612050, training_loss: 2.76935e-02
I0211 00:46:52.825934 22542570456896 run_lib.py:133] step: 612100, training_loss: 2.35668e-02
I0211 00:46:52.977378 22542570456896 run_lib.py:146] step: 612100, eval_loss: 2.89335e-02
I0211 00:47:10.527594 22542570456896 run_lib.py:133] step: 612150, training_loss: 2.81185e-02
I0211 00:47:28.035053 22542570456896 run_lib.py:133] step: 612200, training_loss: 2.97978e-02
I0211 00:47:28.196316 22542570456896 run_lib.py:146] step: 612200, eval_loss: 2.53654e-02
I0211 00:47:45.662099 22542570456896 run_lib.py:133] step: 612250, training_loss: 2.31531e-02
I0211 00:48:03.101740 22542570456896 run_lib.py:133] step: 612300, training_loss: 3.43944e-02
I0211 00:48:03.260284 22542570456896 run_lib.py:146] step: 612300, eval_loss: 3.15582e-02
I0211 00:48:20.843938 22542570456896 run_lib.py:133] step: 612350, training_loss: 2.23336e-02
I0211 00:48:38.233596 22542570456896 run_lib.py:133] step: 612400, training_loss: 1.98571e-02
I0211 00:48:38.389486 22542570456896 run_lib.py:146] step: 612400, eval_loss: 3.15596e-02
I0211 00:48:55.932371 22542570456896 run_lib.py:133] step: 612450, training_loss: 2.97295e-02
I0211 00:49:13.454712 22542570456896 run_lib.py:133] step: 612500, training_loss: 2.99754e-02
I0211 00:49:13.608119 22542570456896 run_lib.py:146] step: 612500, eval_loss: 2.76614e-02
I0211 00:49:31.249458 22542570456896 run_lib.py:133] step: 612550, training_loss: 2.93590e-02
I0211 00:49:48.700908 22542570456896 run_lib.py:133] step: 612600, training_loss: 2.58454e-02
I0211 00:49:48.857447 22542570456896 run_lib.py:146] step: 612600, eval_loss: 2.30987e-02
I0211 00:50:06.251065 22542570456896 run_lib.py:133] step: 612650, training_loss: 2.73676e-02
I0211 00:50:23.851943 22542570456896 run_lib.py:133] step: 612700, training_loss: 2.84982e-02
I0211 00:50:24.015555 22542570456896 run_lib.py:146] step: 612700, eval_loss: 3.58435e-02
I0211 00:50:41.485279 22542570456896 run_lib.py:133] step: 612750, training_loss: 2.74810e-02
I0211 00:50:59.117827 22542570456896 run_lib.py:133] step: 612800, training_loss: 2.77313e-02
I0211 00:50:59.273530 22542570456896 run_lib.py:146] step: 612800, eval_loss: 2.91563e-02
I0211 00:51:16.733108 22542570456896 run_lib.py:133] step: 612850, training_loss: 2.88780e-02
I0211 00:51:34.119666 22542570456896 run_lib.py:133] step: 612900, training_loss: 2.50393e-02
I0211 00:51:34.279601 22542570456896 run_lib.py:146] step: 612900, eval_loss: 2.85817e-02
I0211 00:51:51.863848 22542570456896 run_lib.py:133] step: 612950, training_loss: 2.42944e-02
I0211 00:52:09.313443 22542570456896 run_lib.py:133] step: 613000, training_loss: 2.53636e-02
I0211 00:52:09.467085 22542570456896 run_lib.py:146] step: 613000, eval_loss: 2.49259e-02
I0211 00:52:26.998882 22542570456896 run_lib.py:133] step: 613050, training_loss: 2.96846e-02
I0211 00:52:44.627207 22542570456896 run_lib.py:133] step: 613100, training_loss: 2.87185e-02
I0211 00:52:44.816497 22542570456896 run_lib.py:146] step: 613100, eval_loss: 3.15181e-02
I0211 00:53:02.224437 22542570456896 run_lib.py:133] step: 613150, training_loss: 2.51047e-02
I0211 00:53:19.665783 22542570456896 run_lib.py:133] step: 613200, training_loss: 2.09672e-02
I0211 00:53:19.831135 22542570456896 run_lib.py:146] step: 613200, eval_loss: 2.88617e-02
I0211 00:53:37.341159 22542570456896 run_lib.py:133] step: 613250, training_loss: 2.58683e-02
I0211 00:53:54.796183 22542570456896 run_lib.py:133] step: 613300, training_loss: 2.84561e-02
I0211 00:53:54.954694 22542570456896 run_lib.py:146] step: 613300, eval_loss: 2.53272e-02
I0211 00:54:12.334502 22542570456896 run_lib.py:133] step: 613350, training_loss: 3.27897e-02
I0211 00:54:29.806654 22542570456896 run_lib.py:133] step: 613400, training_loss: 2.75599e-02
I0211 00:54:29.962387 22542570456896 run_lib.py:146] step: 613400, eval_loss: 4.06928e-02
I0211 00:54:47.590615 22542570456896 run_lib.py:133] step: 613450, training_loss: 3.53175e-02
I0211 00:55:05.075737 22542570456896 run_lib.py:133] step: 613500, training_loss: 2.73344e-02
I0211 00:55:05.228109 22542570456896 run_lib.py:146] step: 613500, eval_loss: 2.91536e-02
I0211 00:55:22.669152 22542570456896 run_lib.py:133] step: 613550, training_loss: 3.14863e-02
I0211 00:55:40.117979 22542570456896 run_lib.py:133] step: 613600, training_loss: 2.68203e-02
I0211 00:55:40.282868 22542570456896 run_lib.py:146] step: 613600, eval_loss: 3.08896e-02
I0211 00:55:57.899959 22542570456896 run_lib.py:133] step: 613650, training_loss: 3.39936e-02
I0211 00:56:15.317225 22542570456896 run_lib.py:133] step: 613700, training_loss: 2.97889e-02
I0211 00:56:15.481562 22542570456896 run_lib.py:146] step: 613700, eval_loss: 2.96434e-02
I0211 00:56:33.044272 22542570456896 run_lib.py:133] step: 613750, training_loss: 3.03488e-02
I0211 00:56:50.480111 22542570456896 run_lib.py:133] step: 613800, training_loss: 3.55329e-02
I0211 00:56:50.645063 22542570456896 run_lib.py:146] step: 613800, eval_loss: 2.94113e-02
I0211 00:57:08.281304 22542570456896 run_lib.py:133] step: 613850, training_loss: 3.21901e-02
I0211 00:57:25.687829 22542570456896 run_lib.py:133] step: 613900, training_loss: 2.38532e-02
I0211 00:57:25.845299 22542570456896 run_lib.py:146] step: 613900, eval_loss: 2.91019e-02
I0211 00:57:43.447918 22542570456896 run_lib.py:133] step: 613950, training_loss: 2.69330e-02
I0211 00:58:00.850944 22542570456896 run_lib.py:133] step: 614000, training_loss: 3.30914e-02
I0211 00:58:01.001272 22542570456896 run_lib.py:146] step: 614000, eval_loss: 2.52763e-02
I0211 00:58:18.401266 22542570456896 run_lib.py:133] step: 614050, training_loss: 3.10783e-02
I0211 00:58:36.035322 22542570456896 run_lib.py:133] step: 614100, training_loss: 2.72533e-02
I0211 00:58:36.212046 22542570456896 run_lib.py:146] step: 614100, eval_loss: 2.36340e-02
I0211 00:58:53.658660 22542570456896 run_lib.py:133] step: 614150, training_loss: 2.62443e-02
I0211 00:59:11.076427 22542570456896 run_lib.py:133] step: 614200, training_loss: 3.39092e-02
I0211 00:59:11.232353 22542570456896 run_lib.py:146] step: 614200, eval_loss: 3.41813e-02
I0211 00:59:28.859551 22542570456896 run_lib.py:133] step: 614250, training_loss: 2.70041e-02
I0211 00:59:46.271101 22542570456896 run_lib.py:133] step: 614300, training_loss: 2.69949e-02
I0211 00:59:46.426312 22542570456896 run_lib.py:146] step: 614300, eval_loss: 3.16044e-02
I0211 01:00:04.019670 22542570456896 run_lib.py:133] step: 614350, training_loss: 2.74132e-02
I0211 01:00:21.462606 22542570456896 run_lib.py:133] step: 614400, training_loss: 3.14297e-02
I0211 01:00:21.618155 22542570456896 run_lib.py:146] step: 614400, eval_loss: 2.64217e-02
I0211 01:00:39.068160 22542570456896 run_lib.py:133] step: 614450, training_loss: 2.59863e-02
I0211 01:00:56.695959 22542570456896 run_lib.py:133] step: 614500, training_loss: 3.09514e-02
I0211 01:00:56.851439 22542570456896 run_lib.py:146] step: 614500, eval_loss: 3.30721e-02
I0211 01:01:14.247104 22542570456896 run_lib.py:133] step: 614550, training_loss: 2.43820e-02
I0211 01:01:31.663494 22542570456896 run_lib.py:133] step: 614600, training_loss: 3.33466e-02
I0211 01:01:31.820293 22542570456896 run_lib.py:146] step: 614600, eval_loss: 2.72752e-02
I0211 01:01:49.265560 22542570456896 run_lib.py:133] step: 614650, training_loss: 2.59482e-02
I0211 01:02:06.903604 22542570456896 run_lib.py:133] step: 614700, training_loss: 2.53562e-02
I0211 01:02:07.059530 22542570456896 run_lib.py:146] step: 614700, eval_loss: 2.57198e-02
I0211 01:02:24.480854 22542570456896 run_lib.py:133] step: 614750, training_loss: 2.88074e-02
I0211 01:02:41.945976 22542570456896 run_lib.py:133] step: 614800, training_loss: 2.75624e-02
I0211 01:02:42.102489 22542570456896 run_lib.py:146] step: 614800, eval_loss: 2.86397e-02
I0211 01:02:59.534490 22542570456896 run_lib.py:133] step: 614850, training_loss: 2.91678e-02
I0211 01:03:17.017759 22542570456896 run_lib.py:133] step: 614900, training_loss: 3.06098e-02
I0211 01:03:17.170651 22542570456896 run_lib.py:146] step: 614900, eval_loss: 2.91830e-02
I0211 01:03:34.822175 22542570456896 run_lib.py:133] step: 614950, training_loss: 2.88005e-02
I0211 01:03:52.359182 22542570456896 run_lib.py:133] step: 615000, training_loss: 2.38220e-02
I0211 01:03:52.516302 22542570456896 run_lib.py:146] step: 615000, eval_loss: 2.36478e-02
I0211 01:04:09.904001 22542570456896 run_lib.py:133] step: 615050, training_loss: 2.54518e-02
I0211 01:04:27.329758 22542570456896 run_lib.py:133] step: 615100, training_loss: 2.56801e-02
I0211 01:04:27.487445 22542570456896 run_lib.py:146] step: 615100, eval_loss: 2.90400e-02
I0211 01:04:45.059050 22542570456896 run_lib.py:133] step: 615150, training_loss: 2.20469e-02
I0211 01:05:02.558715 22542570456896 run_lib.py:133] step: 615200, training_loss: 3.27466e-02
I0211 01:05:02.714662 22542570456896 run_lib.py:146] step: 615200, eval_loss: 3.07857e-02
I0211 01:05:20.290397 22542570456896 run_lib.py:133] step: 615250, training_loss: 3.01388e-02
I0211 01:05:37.650969 22542570456896 run_lib.py:133] step: 615300, training_loss: 3.25604e-02
I0211 01:05:37.806359 22542570456896 run_lib.py:146] step: 615300, eval_loss: 2.88523e-02
I0211 01:05:55.317092 22542570456896 run_lib.py:133] step: 615350, training_loss: 2.55746e-02
I0211 01:06:12.733717 22542570456896 run_lib.py:133] step: 615400, training_loss: 2.66465e-02
I0211 01:06:12.885282 22542570456896 run_lib.py:146] step: 615400, eval_loss: 2.94753e-02
I0211 01:06:30.254043 22542570456896 run_lib.py:133] step: 615450, training_loss: 2.41108e-02
I0211 01:06:47.827990 22542570456896 run_lib.py:133] step: 615500, training_loss: 2.61018e-02
I0211 01:06:47.997183 22542570456896 run_lib.py:146] step: 615500, eval_loss: 2.75688e-02
I0211 01:07:05.426267 22542570456896 run_lib.py:133] step: 615550, training_loss: 2.45190e-02
I0211 01:07:23.036128 22542570456896 run_lib.py:133] step: 615600, training_loss: 3.19720e-02
I0211 01:07:23.194559 22542570456896 run_lib.py:146] step: 615600, eval_loss: 3.00910e-02
I0211 01:07:40.560041 22542570456896 run_lib.py:133] step: 615650, training_loss: 2.90658e-02
I0211 01:07:57.946562 22542570456896 run_lib.py:133] step: 615700, training_loss: 2.78203e-02
I0211 01:07:58.115384 22542570456896 run_lib.py:146] step: 615700, eval_loss: 2.76149e-02
I0211 01:08:15.689530 22542570456896 run_lib.py:133] step: 615750, training_loss: 2.77319e-02
I0211 01:08:33.164582 22542570456896 run_lib.py:133] step: 615800, training_loss: 2.15071e-02
I0211 01:08:33.316403 22542570456896 run_lib.py:146] step: 615800, eval_loss: 2.32371e-02
I0211 01:08:50.694743 22542570456896 run_lib.py:133] step: 615850, training_loss: 2.40609e-02
I0211 01:09:08.293513 22542570456896 run_lib.py:133] step: 615900, training_loss: 2.97896e-02
I0211 01:09:08.445493 22542570456896 run_lib.py:146] step: 615900, eval_loss: 2.82559e-02
I0211 01:09:25.852393 22542570456896 run_lib.py:133] step: 615950, training_loss: 3.27445e-02
I0211 01:09:43.260139 22542570456896 run_lib.py:133] step: 616000, training_loss: 3.12553e-02
I0211 01:09:43.585161 22542570456896 run_lib.py:146] step: 616000, eval_loss: 2.98677e-02
I0211 01:10:01.038817 22542570456896 run_lib.py:133] step: 616050, training_loss: 3.08871e-02
I0211 01:10:18.480825 22542570456896 run_lib.py:133] step: 616100, training_loss: 2.33805e-02
I0211 01:10:18.636526 22542570456896 run_lib.py:146] step: 616100, eval_loss: 3.05671e-02
I0211 01:10:36.017042 22542570456896 run_lib.py:133] step: 616150, training_loss: 2.29045e-02
I0211 01:10:53.422309 22542570456896 run_lib.py:133] step: 616200, training_loss: 2.59791e-02
I0211 01:10:53.578073 22542570456896 run_lib.py:146] step: 616200, eval_loss: 2.78183e-02
I0211 01:11:11.187431 22542570456896 run_lib.py:133] step: 616250, training_loss: 2.84623e-02
I0211 01:11:28.721264 22542570456896 run_lib.py:133] step: 616300, training_loss: 2.63685e-02
I0211 01:11:28.875113 22542570456896 run_lib.py:146] step: 616300, eval_loss: 2.66799e-02
I0211 01:11:46.290437 22542570456896 run_lib.py:133] step: 616350, training_loss: 3.07316e-02
I0211 01:12:03.704250 22542570456896 run_lib.py:133] step: 616400, training_loss: 2.93477e-02
I0211 01:12:03.858246 22542570456896 run_lib.py:146] step: 616400, eval_loss: 3.18331e-02
I0211 01:12:21.387164 22542570456896 run_lib.py:133] step: 616450, training_loss: 2.99966e-02
I0211 01:12:38.838573 22542570456896 run_lib.py:133] step: 616500, training_loss: 2.64964e-02
I0211 01:12:39.003596 22542570456896 run_lib.py:146] step: 616500, eval_loss: 3.43645e-02
I0211 01:12:56.462079 22542570456896 run_lib.py:133] step: 616550, training_loss: 2.61436e-02
I0211 01:13:13.897744 22542570456896 run_lib.py:133] step: 616600, training_loss: 3.40431e-02
I0211 01:13:14.053545 22542570456896 run_lib.py:146] step: 616600, eval_loss: 2.67523e-02
I0211 01:13:31.640120 22542570456896 run_lib.py:133] step: 616650, training_loss: 2.79775e-02
I0211 01:13:49.045890 22542570456896 run_lib.py:133] step: 616700, training_loss: 3.12482e-02
I0211 01:13:49.204422 22542570456896 run_lib.py:146] step: 616700, eval_loss: 2.41447e-02
I0211 01:14:06.747864 22542570456896 run_lib.py:133] step: 616750, training_loss: 2.39399e-02
I0211 01:14:24.156029 22542570456896 run_lib.py:133] step: 616800, training_loss: 2.77761e-02
I0211 01:14:24.325916 22542570456896 run_lib.py:146] step: 616800, eval_loss: 2.71606e-02
I0211 01:14:41.926071 22542570456896 run_lib.py:133] step: 616850, training_loss: 3.20957e-02
I0211 01:14:59.306873 22542570456896 run_lib.py:133] step: 616900, training_loss: 2.24253e-02
I0211 01:14:59.465214 22542570456896 run_lib.py:146] step: 616900, eval_loss: 3.00226e-02
I0211 01:15:16.874645 22542570456896 run_lib.py:133] step: 616950, training_loss: 3.06727e-02
I0211 01:15:34.461598 22542570456896 run_lib.py:133] step: 617000, training_loss: 3.12917e-02
I0211 01:15:34.620576 22542570456896 run_lib.py:146] step: 617000, eval_loss: 3.05157e-02
I0211 01:15:52.018118 22542570456896 run_lib.py:133] step: 617050, training_loss: 2.14627e-02
I0211 01:16:09.538129 22542570456896 run_lib.py:133] step: 617100, training_loss: 3.22622e-02
I0211 01:16:09.707338 22542570456896 run_lib.py:146] step: 617100, eval_loss: 2.96705e-02
I0211 01:16:27.207061 22542570456896 run_lib.py:133] step: 617150, training_loss: 2.51154e-02
I0211 01:16:44.591406 22542570456896 run_lib.py:133] step: 617200, training_loss: 2.81012e-02
I0211 01:16:44.747553 22542570456896 run_lib.py:146] step: 617200, eval_loss: 3.59615e-02
I0211 01:17:02.363226 22542570456896 run_lib.py:133] step: 617250, training_loss: 2.81132e-02
I0211 01:17:19.746482 22542570456896 run_lib.py:133] step: 617300, training_loss: 2.54195e-02
I0211 01:17:19.899188 22542570456896 run_lib.py:146] step: 617300, eval_loss: 2.13323e-02
I0211 01:17:37.291952 22542570456896 run_lib.py:133] step: 617350, training_loss: 2.58492e-02
I0211 01:17:54.710806 22542570456896 run_lib.py:133] step: 617400, training_loss: 2.74673e-02
I0211 01:17:54.879259 22542570456896 run_lib.py:146] step: 617400, eval_loss: 3.31045e-02
I0211 01:18:12.473116 22542570456896 run_lib.py:133] step: 617450, training_loss: 2.78432e-02
I0211 01:18:29.936478 22542570456896 run_lib.py:133] step: 617500, training_loss: 3.43845e-02
I0211 01:18:30.096285 22542570456896 run_lib.py:146] step: 617500, eval_loss: 2.74141e-02
I0211 01:18:47.628855 22542570456896 run_lib.py:133] step: 617550, training_loss: 3.03673e-02
I0211 01:19:05.044114 22542570456896 run_lib.py:133] step: 617600, training_loss: 2.54618e-02
I0211 01:19:05.202401 22542570456896 run_lib.py:146] step: 617600, eval_loss: 2.95493e-02
I0211 01:19:22.597470 22542570456896 run_lib.py:133] step: 617650, training_loss: 3.42485e-02
I0211 01:19:40.045248 22542570456896 run_lib.py:133] step: 617700, training_loss: 2.56874e-02
I0211 01:19:40.201551 22542570456896 run_lib.py:146] step: 617700, eval_loss: 3.23449e-02
I0211 01:19:57.823118 22542570456896 run_lib.py:133] step: 617750, training_loss: 2.91022e-02
I0211 01:20:15.262930 22542570456896 run_lib.py:133] step: 617800, training_loss: 2.88231e-02
I0211 01:20:15.415745 22542570456896 run_lib.py:146] step: 617800, eval_loss: 3.14794e-02
I0211 01:20:32.814066 22542570456896 run_lib.py:133] step: 617850, training_loss: 2.75927e-02
I0211 01:20:50.226802 22542570456896 run_lib.py:133] step: 617900, training_loss: 2.79406e-02
I0211 01:20:50.399035 22542570456896 run_lib.py:146] step: 617900, eval_loss: 2.56718e-02
I0211 01:21:07.996920 22542570456896 run_lib.py:133] step: 617950, training_loss: 2.57481e-02
I0211 01:21:25.407903 22542570456896 run_lib.py:133] step: 618000, training_loss: 2.84948e-02
I0211 01:21:25.563503 22542570456896 run_lib.py:146] step: 618000, eval_loss: 2.89136e-02
I0211 01:21:43.142098 22542570456896 run_lib.py:133] step: 618050, training_loss: 2.68651e-02
I0211 01:22:00.590808 22542570456896 run_lib.py:133] step: 618100, training_loss: 3.44267e-02
I0211 01:22:00.745554 22542570456896 run_lib.py:146] step: 618100, eval_loss: 2.90521e-02
I0211 01:22:18.335541 22542570456896 run_lib.py:133] step: 618150, training_loss: 2.25827e-02
I0211 01:22:35.797144 22542570456896 run_lib.py:133] step: 618200, training_loss: 3.25061e-02
I0211 01:22:35.954144 22542570456896 run_lib.py:146] step: 618200, eval_loss: 2.78258e-02
I0211 01:22:53.601881 22542570456896 run_lib.py:133] step: 618250, training_loss: 2.65666e-02
I0211 01:23:10.998771 22542570456896 run_lib.py:133] step: 618300, training_loss: 3.39292e-02
I0211 01:23:11.154477 22542570456896 run_lib.py:146] step: 618300, eval_loss: 3.29904e-02
I0211 01:23:28.566300 22542570456896 run_lib.py:133] step: 618350, training_loss: 2.90710e-02
I0211 01:23:46.101053 22542570456896 run_lib.py:133] step: 618400, training_loss: 2.27952e-02
I0211 01:23:46.254717 22542570456896 run_lib.py:146] step: 618400, eval_loss: 3.40924e-02
I0211 01:24:03.672823 22542570456896 run_lib.py:133] step: 618450, training_loss: 2.90086e-02
I0211 01:24:21.085858 22542570456896 run_lib.py:133] step: 618500, training_loss: 3.17920e-02
I0211 01:24:21.253288 22542570456896 run_lib.py:146] step: 618500, eval_loss: 2.66776e-02
I0211 01:24:38.884879 22542570456896 run_lib.py:133] step: 618550, training_loss: 3.06173e-02
I0211 01:24:56.476507 22542570456896 run_lib.py:133] step: 618600, training_loss: 2.79967e-02
I0211 01:24:56.631491 22542570456896 run_lib.py:146] step: 618600, eval_loss: 3.98211e-02
I0211 01:25:14.039170 22542570456896 run_lib.py:133] step: 618650, training_loss: 2.42818e-02
I0211 01:25:31.404511 22542570456896 run_lib.py:133] step: 618700, training_loss: 3.43035e-02
I0211 01:25:31.621270 22542570456896 run_lib.py:146] step: 618700, eval_loss: 3.22038e-02
I0211 01:25:49.031634 22542570456896 run_lib.py:133] step: 618750, training_loss: 2.19082e-02
I0211 01:26:06.577351 22542570456896 run_lib.py:133] step: 618800, training_loss: 2.76779e-02
I0211 01:26:06.745579 22542570456896 run_lib.py:146] step: 618800, eval_loss: 2.67463e-02
I0211 01:26:24.199336 22542570456896 run_lib.py:133] step: 618850, training_loss: 2.69024e-02
I0211 01:26:41.620144 22542570456896 run_lib.py:133] step: 618900, training_loss: 2.18835e-02
I0211 01:26:41.783201 22542570456896 run_lib.py:146] step: 618900, eval_loss: 2.59228e-02
I0211 01:26:59.157487 22542570456896 run_lib.py:133] step: 618950, training_loss: 2.99268e-02
I0211 01:27:16.720312 22542570456896 run_lib.py:133] step: 619000, training_loss: 2.44514e-02
I0211 01:27:16.890197 22542570456896 run_lib.py:146] step: 619000, eval_loss: 3.05997e-02
I0211 01:27:34.324858 22542570456896 run_lib.py:133] step: 619050, training_loss: 2.26067e-02
I0211 01:27:51.849331 22542570456896 run_lib.py:133] step: 619100, training_loss: 3.47727e-02
I0211 01:27:52.005618 22542570456896 run_lib.py:146] step: 619100, eval_loss: 3.88493e-02
I0211 01:28:09.413774 22542570456896 run_lib.py:133] step: 619150, training_loss: 2.83056e-02
I0211 01:28:26.843750 22542570456896 run_lib.py:133] step: 619200, training_loss: 1.90745e-02
I0211 01:28:27.002396 22542570456896 run_lib.py:146] step: 619200, eval_loss: 2.70118e-02
I0211 01:28:44.552063 22542570456896 run_lib.py:133] step: 619250, training_loss: 2.64170e-02
I0211 01:29:02.065667 22542570456896 run_lib.py:133] step: 619300, training_loss: 2.66837e-02
I0211 01:29:02.241240 22542570456896 run_lib.py:146] step: 619300, eval_loss: 2.53993e-02
I0211 01:29:19.714280 22542570456896 run_lib.py:133] step: 619350, training_loss: 3.00662e-02
I0211 01:29:37.116322 22542570456896 run_lib.py:133] step: 619400, training_loss: 2.22569e-02
I0211 01:29:37.271263 22542570456896 run_lib.py:146] step: 619400, eval_loss: 2.95369e-02
I0211 01:29:54.880293 22542570456896 run_lib.py:133] step: 619450, training_loss: 2.51288e-02
I0211 01:30:12.278734 22542570456896 run_lib.py:133] step: 619500, training_loss: 3.43998e-02
I0211 01:30:12.433459 22542570456896 run_lib.py:146] step: 619500, eval_loss: 2.90508e-02
I0211 01:30:29.994695 22542570456896 run_lib.py:133] step: 619550, training_loss: 2.29128e-02
I0211 01:30:47.479877 22542570456896 run_lib.py:133] step: 619600, training_loss: 3.05759e-02
I0211 01:30:47.636696 22542570456896 run_lib.py:146] step: 619600, eval_loss: 2.34153e-02
I0211 01:31:05.327802 22542570456896 run_lib.py:133] step: 619650, training_loss: 2.88948e-02
I0211 01:31:22.780029 22542570456896 run_lib.py:133] step: 619700, training_loss: 3.30719e-02
I0211 01:31:22.932394 22542570456896 run_lib.py:146] step: 619700, eval_loss: 3.06071e-02
I0211 01:31:40.392897 22542570456896 run_lib.py:133] step: 619750, training_loss: 2.69523e-02
I0211 01:31:58.005211 22542570456896 run_lib.py:133] step: 619800, training_loss: 2.34374e-02
I0211 01:31:58.164632 22542570456896 run_lib.py:146] step: 619800, eval_loss: 2.46558e-02
I0211 01:32:15.683013 22542570456896 run_lib.py:133] step: 619850, training_loss: 2.72403e-02
I0211 01:32:33.353822 22542570456896 run_lib.py:133] step: 619900, training_loss: 3.05233e-02
I0211 01:32:33.508940 22542570456896 run_lib.py:146] step: 619900, eval_loss: 2.76411e-02
I0211 01:32:50.962796 22542570456896 run_lib.py:133] step: 619950, training_loss: 2.52080e-02
I0211 01:33:08.422002 22542570456896 run_lib.py:133] step: 620000, training_loss: 3.08267e-02
I0211 01:33:09.113935 22542570456896 run_lib.py:146] step: 620000, eval_loss: 3.21041e-02
I0211 01:33:29.248573 22542570456896 run_lib.py:133] step: 620050, training_loss: 3.19364e-02
I0211 01:33:46.888176 22542570456896 run_lib.py:133] step: 620100, training_loss: 2.42206e-02
I0211 01:33:47.044384 22542570456896 run_lib.py:146] step: 620100, eval_loss: 2.63117e-02
I0211 01:34:04.480874 22542570456896 run_lib.py:133] step: 620150, training_loss: 3.15345e-02
I0211 01:34:22.144839 22542570456896 run_lib.py:133] step: 620200, training_loss: 2.63585e-02
I0211 01:34:22.299805 22542570456896 run_lib.py:146] step: 620200, eval_loss: 2.66149e-02
I0211 01:34:39.837697 22542570456896 run_lib.py:133] step: 620250, training_loss: 2.67102e-02
I0211 01:34:57.331918 22542570456896 run_lib.py:133] step: 620300, training_loss: 3.91582e-02
I0211 01:34:57.496413 22542570456896 run_lib.py:146] step: 620300, eval_loss: 3.51950e-02
I0211 01:35:15.183670 22542570456896 run_lib.py:133] step: 620350, training_loss: 2.49635e-02
I0211 01:35:32.676436 22542570456896 run_lib.py:133] step: 620400, training_loss: 2.38462e-02
I0211 01:35:32.843729 22542570456896 run_lib.py:146] step: 620400, eval_loss: 3.06207e-02
I0211 01:35:50.485471 22542570456896 run_lib.py:133] step: 620450, training_loss: 2.62266e-02
I0211 01:36:08.056029 22542570456896 run_lib.py:133] step: 620500, training_loss: 2.88704e-02
I0211 01:36:08.212698 22542570456896 run_lib.py:146] step: 620500, eval_loss: 3.31978e-02
I0211 01:36:25.703895 22542570456896 run_lib.py:133] step: 620550, training_loss: 2.94357e-02
I0211 01:36:43.326041 22542570456896 run_lib.py:133] step: 620600, training_loss: 2.82431e-02
I0211 01:36:43.490404 22542570456896 run_lib.py:146] step: 620600, eval_loss: 3.10550e-02
I0211 01:37:00.949322 22542570456896 run_lib.py:133] step: 620650, training_loss: 3.00775e-02
I0211 01:37:18.452103 22542570456896 run_lib.py:133] step: 620700, training_loss: 3.18838e-02
I0211 01:37:18.613730 22542570456896 run_lib.py:146] step: 620700, eval_loss: 2.72676e-02
I0211 01:37:36.147346 22542570456896 run_lib.py:133] step: 620750, training_loss: 2.77383e-02
I0211 01:37:53.825113 22542570456896 run_lib.py:133] step: 620800, training_loss: 3.23598e-02
I0211 01:37:53.982837 22542570456896 run_lib.py:146] step: 620800, eval_loss: 3.06027e-02
I0211 01:38:11.428181 22542570456896 run_lib.py:133] step: 620850, training_loss: 2.12504e-02
I0211 01:38:28.967901 22542570456896 run_lib.py:133] step: 620900, training_loss: 2.37611e-02
I0211 01:38:29.131584 22542570456896 run_lib.py:146] step: 620900, eval_loss: 3.27562e-02
I0211 01:38:46.633246 22542570456896 run_lib.py:133] step: 620950, training_loss: 3.15233e-02
I0211 01:39:04.128052 22542570456896 run_lib.py:133] step: 621000, training_loss: 2.40130e-02
I0211 01:39:04.285218 22542570456896 run_lib.py:146] step: 621000, eval_loss: 3.45234e-02
I0211 01:39:21.964333 22542570456896 run_lib.py:133] step: 621050, training_loss: 3.07245e-02
I0211 01:39:39.503906 22542570456896 run_lib.py:133] step: 621100, training_loss: 3.55219e-02
I0211 01:39:39.659259 22542570456896 run_lib.py:146] step: 621100, eval_loss: 2.62895e-02
I0211 01:39:57.097510 22542570456896 run_lib.py:133] step: 621150, training_loss: 2.83188e-02
I0211 01:40:14.555122 22542570456896 run_lib.py:133] step: 621200, training_loss: 2.82776e-02
I0211 01:40:14.707300 22542570456896 run_lib.py:146] step: 621200, eval_loss: 3.40086e-02
I0211 01:40:32.310046 22542570456896 run_lib.py:133] step: 621250, training_loss: 2.14502e-02
I0211 01:40:49.823405 22542570456896 run_lib.py:133] step: 621300, training_loss: 3.17029e-02
I0211 01:40:49.995790 22542570456896 run_lib.py:146] step: 621300, eval_loss: 2.09440e-02
I0211 01:41:07.699383 22542570456896 run_lib.py:133] step: 621350, training_loss: 2.79235e-02
I0211 01:41:25.252015 22542570456896 run_lib.py:133] step: 621400, training_loss: 2.88911e-02
I0211 01:41:25.408368 22542570456896 run_lib.py:146] step: 621400, eval_loss: 2.83443e-02
I0211 01:41:43.037796 22542570456896 run_lib.py:133] step: 621450, training_loss: 2.91115e-02
I0211 01:42:00.502636 22542570456896 run_lib.py:133] step: 621500, training_loss: 2.88580e-02
I0211 01:42:00.662533 22542570456896 run_lib.py:146] step: 621500, eval_loss: 2.54743e-02
I0211 01:42:18.145415 22542570456896 run_lib.py:133] step: 621550, training_loss: 2.62395e-02
I0211 01:42:35.806849 22542570456896 run_lib.py:133] step: 621600, training_loss: 3.28443e-02
I0211 01:42:35.961050 22542570456896 run_lib.py:146] step: 621600, eval_loss: 3.45668e-02
I0211 01:42:53.482740 22542570456896 run_lib.py:133] step: 621650, training_loss: 3.00864e-02
I0211 01:43:11.082015 22542570456896 run_lib.py:133] step: 621700, training_loss: 3.16227e-02
I0211 01:43:11.239675 22542570456896 run_lib.py:146] step: 621700, eval_loss: 2.78980e-02
I0211 01:43:28.667756 22542570456896 run_lib.py:133] step: 621750, training_loss: 3.71976e-02
I0211 01:43:46.137392 22542570456896 run_lib.py:133] step: 621800, training_loss: 2.27464e-02
I0211 01:43:46.315712 22542570456896 run_lib.py:146] step: 621800, eval_loss: 2.50262e-02
I0211 01:44:04.038823 22542570456896 run_lib.py:133] step: 621850, training_loss: 2.54936e-02
I0211 01:44:21.519751 22542570456896 run_lib.py:133] step: 621900, training_loss: 2.14441e-02
I0211 01:44:21.691019 22542570456896 run_lib.py:146] step: 621900, eval_loss: 2.60820e-02
I0211 01:44:39.230705 22542570456896 run_lib.py:133] step: 621950, training_loss: 2.49537e-02
I0211 01:44:56.820679 22542570456896 run_lib.py:133] step: 622000, training_loss: 2.75987e-02
I0211 01:44:56.974337 22542570456896 run_lib.py:146] step: 622000, eval_loss: 1.99241e-02
I0211 01:45:14.475449 22542570456896 run_lib.py:133] step: 622050, training_loss: 2.88083e-02
I0211 01:45:32.029778 22542570456896 run_lib.py:133] step: 622100, training_loss: 2.27935e-02
I0211 01:45:32.189632 22542570456896 run_lib.py:146] step: 622100, eval_loss: 2.72007e-02
I0211 01:45:49.785908 22542570456896 run_lib.py:133] step: 622150, training_loss: 2.55134e-02
I0211 01:46:07.254351 22542570456896 run_lib.py:133] step: 622200, training_loss: 3.00715e-02
I0211 01:46:07.408203 22542570456896 run_lib.py:146] step: 622200, eval_loss: 2.62886e-02
I0211 01:46:24.868085 22542570456896 run_lib.py:133] step: 622250, training_loss: 2.77617e-02
I0211 01:46:42.352760 22542570456896 run_lib.py:133] step: 622300, training_loss: 3.45114e-02
I0211 01:46:42.513847 22542570456896 run_lib.py:146] step: 622300, eval_loss: 3.07076e-02
I0211 01:47:00.165481 22542570456896 run_lib.py:133] step: 622350, training_loss: 2.37724e-02
I0211 01:47:17.758504 22542570456896 run_lib.py:133] step: 622400, training_loss: 3.05766e-02
I0211 01:47:17.914538 22542570456896 run_lib.py:146] step: 622400, eval_loss: 2.66562e-02
I0211 01:47:35.407559 22542570456896 run_lib.py:133] step: 622450, training_loss: 2.71332e-02
I0211 01:47:52.852967 22542570456896 run_lib.py:133] step: 622500, training_loss: 2.45380e-02
I0211 01:47:53.007071 22542570456896 run_lib.py:146] step: 622500, eval_loss: 3.08855e-02
I0211 01:48:10.576003 22542570456896 run_lib.py:133] step: 622550, training_loss: 2.63147e-02
I0211 01:48:28.017355 22542570456896 run_lib.py:133] step: 622600, training_loss: 2.90497e-02
I0211 01:48:28.170776 22542570456896 run_lib.py:146] step: 622600, eval_loss: 3.11372e-02
I0211 01:48:45.794858 22542570456896 run_lib.py:133] step: 622650, training_loss: 2.48676e-02
I0211 01:49:03.171145 22542570456896 run_lib.py:133] step: 622700, training_loss: 2.71901e-02
I0211 01:49:03.327476 22542570456896 run_lib.py:146] step: 622700, eval_loss: 3.21746e-02
I0211 01:49:20.946917 22542570456896 run_lib.py:133] step: 622750, training_loss: 2.83713e-02
I0211 01:49:38.416555 22542570456896 run_lib.py:133] step: 622800, training_loss: 2.80055e-02
I0211 01:49:38.573712 22542570456896 run_lib.py:146] step: 622800, eval_loss: 2.69456e-02
I0211 01:49:56.261817 22542570456896 run_lib.py:133] step: 622850, training_loss: 3.08675e-02
I0211 01:50:13.733484 22542570456896 run_lib.py:133] step: 622900, training_loss: 3.22414e-02
I0211 01:50:13.911639 22542570456896 run_lib.py:146] step: 622900, eval_loss: 2.63438e-02
I0211 01:50:31.452290 22542570456896 run_lib.py:133] step: 622950, training_loss: 2.44311e-02
I0211 01:50:49.170241 22542570456896 run_lib.py:133] step: 623000, training_loss: 2.79727e-02
I0211 01:50:49.324120 22542570456896 run_lib.py:146] step: 623000, eval_loss: 3.45594e-02
I0211 01:51:06.823617 22542570456896 run_lib.py:133] step: 623050, training_loss: 3.30541e-02
I0211 01:51:24.298843 22542570456896 run_lib.py:133] step: 623100, training_loss: 2.13934e-02
I0211 01:51:24.453410 22542570456896 run_lib.py:146] step: 623100, eval_loss: 2.50172e-02
I0211 01:51:42.113488 22542570456896 run_lib.py:133] step: 623150, training_loss: 2.94712e-02
I0211 01:51:59.604008 22542570456896 run_lib.py:133] step: 623200, training_loss: 2.50426e-02
I0211 01:51:59.781387 22542570456896 run_lib.py:146] step: 623200, eval_loss: 2.67526e-02
I0211 01:52:17.442277 22542570456896 run_lib.py:133] step: 623250, training_loss: 2.69896e-02
I0211 01:52:34.916657 22542570456896 run_lib.py:133] step: 623300, training_loss: 3.04858e-02
I0211 01:52:35.072608 22542570456896 run_lib.py:146] step: 623300, eval_loss: 2.40822e-02
I0211 01:52:52.558588 22542570456896 run_lib.py:133] step: 623350, training_loss: 3.18424e-02
I0211 01:53:10.231363 22542570456896 run_lib.py:133] step: 623400, training_loss: 2.53840e-02
I0211 01:53:10.389568 22542570456896 run_lib.py:146] step: 623400, eval_loss: 3.20358e-02
I0211 01:53:27.936205 22542570456896 run_lib.py:133] step: 623450, training_loss: 2.37906e-02
I0211 01:53:45.489084 22542570456896 run_lib.py:133] step: 623500, training_loss: 2.24009e-02
I0211 01:53:45.656893 22542570456896 run_lib.py:146] step: 623500, eval_loss: 2.02120e-02
I0211 01:54:03.159037 22542570456896 run_lib.py:133] step: 623550, training_loss: 3.05582e-02
I0211 01:54:20.870569 22542570456896 run_lib.py:133] step: 623600, training_loss: 2.60935e-02
I0211 01:54:21.030529 22542570456896 run_lib.py:146] step: 623600, eval_loss: 2.73237e-02
I0211 01:54:38.501574 22542570456896 run_lib.py:133] step: 623650, training_loss: 3.45452e-02
I0211 01:54:56.060678 22542570456896 run_lib.py:133] step: 623700, training_loss: 2.78783e-02
I0211 01:54:56.223256 22542570456896 run_lib.py:146] step: 623700, eval_loss: 3.02442e-02
I0211 01:55:13.743191 22542570456896 run_lib.py:133] step: 623750, training_loss: 2.56111e-02
I0211 01:55:31.295035 22542570456896 run_lib.py:133] step: 623800, training_loss: 2.31370e-02
I0211 01:55:31.451567 22542570456896 run_lib.py:146] step: 623800, eval_loss: 2.85919e-02
I0211 01:55:49.115431 22542570456896 run_lib.py:133] step: 623850, training_loss: 2.21168e-02
I0211 01:56:06.672086 22542570456896 run_lib.py:133] step: 623900, training_loss: 2.40270e-02
I0211 01:56:06.828320 22542570456896 run_lib.py:146] step: 623900, eval_loss: 2.90300e-02
I0211 01:56:24.302719 22542570456896 run_lib.py:133] step: 623950, training_loss: 2.62174e-02
I0211 01:56:41.782461 22542570456896 run_lib.py:133] step: 624000, training_loss: 2.91304e-02
I0211 01:56:41.935466 22542570456896 run_lib.py:146] step: 624000, eval_loss: 3.06993e-02
I0211 01:56:59.525175 22542570456896 run_lib.py:133] step: 624050, training_loss: 3.51048e-02
I0211 01:57:17.038137 22542570456896 run_lib.py:133] step: 624100, training_loss: 2.91273e-02
I0211 01:57:17.213754 22542570456896 run_lib.py:146] step: 624100, eval_loss: 3.14345e-02
I0211 01:57:34.930986 22542570456896 run_lib.py:133] step: 624150, training_loss: 3.25229e-02
I0211 01:57:52.442703 22542570456896 run_lib.py:133] step: 624200, training_loss: 2.37367e-02
I0211 01:57:52.601958 22542570456896 run_lib.py:146] step: 624200, eval_loss: 3.04389e-02
I0211 01:58:10.220952 22542570456896 run_lib.py:133] step: 624250, training_loss: 2.74630e-02
I0211 01:58:27.714972 22542570456896 run_lib.py:133] step: 624300, training_loss: 2.90941e-02
I0211 01:58:27.882275 22542570456896 run_lib.py:146] step: 624300, eval_loss: 2.73825e-02
I0211 01:58:45.374423 22542570456896 run_lib.py:133] step: 624350, training_loss: 2.72722e-02
I0211 01:59:03.114563 22542570456896 run_lib.py:133] step: 624400, training_loss: 2.35517e-02
I0211 01:59:03.269359 22542570456896 run_lib.py:146] step: 624400, eval_loss: 3.32054e-02
I0211 01:59:20.773988 22542570456896 run_lib.py:133] step: 624450, training_loss: 3.06685e-02
I0211 01:59:38.386654 22542570456896 run_lib.py:133] step: 624500, training_loss: 2.86990e-02
I0211 01:59:38.538398 22542570456896 run_lib.py:146] step: 624500, eval_loss: 3.04928e-02
I0211 01:59:56.021734 22542570456896 run_lib.py:133] step: 624550, training_loss: 3.25389e-02
I0211 02:00:13.562451 22542570456896 run_lib.py:133] step: 624600, training_loss: 2.91632e-02
I0211 02:00:13.739447 22542570456896 run_lib.py:146] step: 624600, eval_loss: 2.34584e-02
I0211 02:00:31.403666 22542570456896 run_lib.py:133] step: 624650, training_loss: 2.16416e-02
I0211 02:00:48.854967 22542570456896 run_lib.py:133] step: 624700, training_loss: 2.78172e-02
I0211 02:00:49.081800 22542570456896 run_lib.py:146] step: 624700, eval_loss: 2.48233e-02
I0211 02:01:06.602633 22542570456896 run_lib.py:133] step: 624750, training_loss: 3.14407e-02
I0211 02:01:24.238900 22542570456896 run_lib.py:133] step: 624800, training_loss: 2.27613e-02
I0211 02:01:24.398627 22542570456896 run_lib.py:146] step: 624800, eval_loss: 2.91712e-02
I0211 02:01:41.871425 22542570456896 run_lib.py:133] step: 624850, training_loss: 2.52964e-02
I0211 02:01:59.394459 22542570456896 run_lib.py:133] step: 624900, training_loss: 2.73724e-02
I0211 02:01:59.750950 22542570456896 run_lib.py:146] step: 624900, eval_loss: 2.62273e-02
I0211 02:02:17.249230 22542570456896 run_lib.py:133] step: 624950, training_loss: 1.68739e-02
I0211 02:02:34.726061 22542570456896 run_lib.py:133] step: 625000, training_loss: 3.22402e-02
I0211 02:02:34.881514 22542570456896 run_lib.py:146] step: 625000, eval_loss: 2.96219e-02
I0211 02:02:52.372848 22542570456896 run_lib.py:133] step: 625050, training_loss: 2.63667e-02
I0211 02:03:09.881913 22542570456896 run_lib.py:133] step: 625100, training_loss: 3.08870e-02
I0211 02:03:10.099726 22542570456896 run_lib.py:146] step: 625100, eval_loss: 2.71650e-02
I0211 02:03:27.758686 22542570456896 run_lib.py:133] step: 625150, training_loss: 3.13290e-02
I0211 02:03:45.419772 22542570456896 run_lib.py:133] step: 625200, training_loss: 2.22166e-02
I0211 02:03:45.577280 22542570456896 run_lib.py:146] step: 625200, eval_loss: 2.93381e-02
I0211 02:04:03.080886 22542570456896 run_lib.py:133] step: 625250, training_loss: 2.14551e-02
I0211 02:04:20.540598 22542570456896 run_lib.py:133] step: 625300, training_loss: 2.90966e-02
I0211 02:04:20.696004 22542570456896 run_lib.py:146] step: 625300, eval_loss: 2.78722e-02
I0211 02:04:38.338319 22542570456896 run_lib.py:133] step: 625350, training_loss: 2.49036e-02
I0211 02:04:55.952403 22542570456896 run_lib.py:133] step: 625400, training_loss: 2.82093e-02
I0211 02:04:56.106322 22542570456896 run_lib.py:146] step: 625400, eval_loss: 3.16747e-02
I0211 02:05:13.674206 22542570456896 run_lib.py:133] step: 625450, training_loss: 2.77029e-02
I0211 02:05:31.168900 22542570456896 run_lib.py:133] step: 625500, training_loss: 2.13636e-02
I0211 02:05:31.326454 22542570456896 run_lib.py:146] step: 625500, eval_loss: 3.13560e-02
I0211 02:05:48.998396 22542570456896 run_lib.py:133] step: 625550, training_loss: 2.62509e-02
I0211 02:06:06.468981 22542570456896 run_lib.py:133] step: 625600, training_loss: 2.88230e-02
I0211 02:06:06.628682 22542570456896 run_lib.py:146] step: 625600, eval_loss: 2.55123e-02
I0211 02:06:24.266642 22542570456896 run_lib.py:133] step: 625650, training_loss: 2.96335e-02
I0211 02:06:41.840075 22542570456896 run_lib.py:133] step: 625700, training_loss: 2.51201e-02
I0211 02:06:41.998103 22542570456896 run_lib.py:146] step: 625700, eval_loss: 2.98977e-02
I0211 02:06:59.651792 22542570456896 run_lib.py:133] step: 625750, training_loss: 2.64233e-02
I0211 02:07:17.119426 22542570456896 run_lib.py:133] step: 625800, training_loss: 3.06135e-02
I0211 02:07:17.275649 22542570456896 run_lib.py:146] step: 625800, eval_loss: 2.93080e-02
I0211 02:07:34.757913 22542570456896 run_lib.py:133] step: 625850, training_loss: 2.52945e-02
I0211 02:07:52.405855 22542570456896 run_lib.py:133] step: 625900, training_loss: 3.20758e-02
I0211 02:07:52.556693 22542570456896 run_lib.py:146] step: 625900, eval_loss: 2.66212e-02
I0211 02:08:10.029969 22542570456896 run_lib.py:133] step: 625950, training_loss: 2.20483e-02
I0211 02:08:27.692584 22542570456896 run_lib.py:133] step: 626000, training_loss: 3.60023e-02
I0211 02:08:27.863120 22542570456896 run_lib.py:146] step: 626000, eval_loss: 2.89331e-02
I0211 02:08:45.416807 22542570456896 run_lib.py:133] step: 626050, training_loss: 2.99302e-02
I0211 02:09:02.918813 22542570456896 run_lib.py:133] step: 626100, training_loss: 2.52521e-02
I0211 02:09:03.087348 22542570456896 run_lib.py:146] step: 626100, eval_loss: 3.23291e-02
I0211 02:09:20.589836 22542570456896 run_lib.py:133] step: 626150, training_loss: 3.01952e-02
I0211 02:09:38.229584 22542570456896 run_lib.py:133] step: 626200, training_loss: 2.79774e-02
I0211 02:09:38.385372 22542570456896 run_lib.py:146] step: 626200, eval_loss: 3.00469e-02
I0211 02:09:55.852379 22542570456896 run_lib.py:133] step: 626250, training_loss: 2.79992e-02
I0211 02:10:13.367148 22542570456896 run_lib.py:133] step: 626300, training_loss: 2.92981e-02
I0211 02:10:13.523666 22542570456896 run_lib.py:146] step: 626300, eval_loss: 2.70545e-02
I0211 02:10:31.251688 22542570456896 run_lib.py:133] step: 626350, training_loss: 2.65193e-02
I0211 02:10:48.735674 22542570456896 run_lib.py:133] step: 626400, training_loss: 2.46752e-02
I0211 02:10:48.888312 22542570456896 run_lib.py:146] step: 626400, eval_loss: 2.76832e-02
I0211 02:11:06.412152 22542570456896 run_lib.py:133] step: 626450, training_loss: 2.44540e-02
I0211 02:11:23.892251 22542570456896 run_lib.py:133] step: 626500, training_loss: 2.73391e-02
I0211 02:11:24.063401 22542570456896 run_lib.py:146] step: 626500, eval_loss: 2.15099e-02
I0211 02:11:41.627948 22542570456896 run_lib.py:133] step: 626550, training_loss: 3.50265e-02
I0211 02:11:59.168712 22542570456896 run_lib.py:133] step: 626600, training_loss: 2.95883e-02
I0211 02:11:59.327585 22542570456896 run_lib.py:146] step: 626600, eval_loss: 2.60896e-02
I0211 02:12:16.999426 22542570456896 run_lib.py:133] step: 626650, training_loss: 2.69656e-02
I0211 02:12:34.560444 22542570456896 run_lib.py:133] step: 626700, training_loss: 2.21416e-02
I0211 02:12:34.736345 22542570456896 run_lib.py:146] step: 626700, eval_loss: 3.44863e-02
I0211 02:12:52.237514 22542570456896 run_lib.py:133] step: 626750, training_loss: 2.52321e-02
I0211 02:13:09.739642 22542570456896 run_lib.py:133] step: 626800, training_loss: 2.19145e-02
I0211 02:13:09.894196 22542570456896 run_lib.py:146] step: 626800, eval_loss: 2.41339e-02
I0211 02:13:27.614102 22542570456896 run_lib.py:133] step: 626850, training_loss: 2.88724e-02
I0211 02:13:45.069087 22542570456896 run_lib.py:133] step: 626900, training_loss: 2.94622e-02
I0211 02:13:45.225884 22542570456896 run_lib.py:146] step: 626900, eval_loss: 2.52185e-02
I0211 02:14:02.888838 22542570456896 run_lib.py:133] step: 626950, training_loss: 3.01068e-02
I0211 02:14:20.362907 22542570456896 run_lib.py:133] step: 627000, training_loss: 2.43666e-02
I0211 02:14:20.523339 22542570456896 run_lib.py:146] step: 627000, eval_loss: 2.86874e-02
I0211 02:14:38.165465 22542570456896 run_lib.py:133] step: 627050, training_loss: 3.05419e-02
I0211 02:14:55.721296 22542570456896 run_lib.py:133] step: 627100, training_loss: 3.08920e-02
I0211 02:14:55.877608 22542570456896 run_lib.py:146] step: 627100, eval_loss: 2.80398e-02
I0211 02:15:13.563194 22542570456896 run_lib.py:133] step: 627150, training_loss: 2.98378e-02
I0211 02:15:31.034036 22542570456896 run_lib.py:133] step: 627200, training_loss: 3.95635e-02
I0211 02:15:31.191628 22542570456896 run_lib.py:146] step: 627200, eval_loss: 3.12767e-02
I0211 02:15:48.655155 22542570456896 run_lib.py:133] step: 627250, training_loss: 3.41203e-02
I0211 02:16:06.321213 22542570456896 run_lib.py:133] step: 627300, training_loss: 2.97295e-02
I0211 02:16:06.480445 22542570456896 run_lib.py:146] step: 627300, eval_loss: 2.45317e-02
I0211 02:16:24.000199 22542570456896 run_lib.py:133] step: 627350, training_loss: 2.60400e-02
I0211 02:16:41.516442 22542570456896 run_lib.py:133] step: 627400, training_loss: 2.71467e-02
I0211 02:16:41.673629 22542570456896 run_lib.py:146] step: 627400, eval_loss: 3.36150e-02
I0211 02:16:59.361160 22542570456896 run_lib.py:133] step: 627450, training_loss: 2.84623e-02
I0211 02:17:17.007393 22542570456896 run_lib.py:133] step: 627500, training_loss: 2.34613e-02
I0211 02:17:17.167292 22542570456896 run_lib.py:146] step: 627500, eval_loss: 3.82607e-02
I0211 02:17:34.665211 22542570456896 run_lib.py:133] step: 627550, training_loss: 2.75064e-02
I0211 02:17:52.124491 22542570456896 run_lib.py:133] step: 627600, training_loss: 2.41955e-02
I0211 02:17:52.285440 22542570456896 run_lib.py:146] step: 627600, eval_loss: 3.08905e-02
I0211 02:18:09.777555 22542570456896 run_lib.py:133] step: 627650, training_loss: 2.41335e-02
I0211 02:18:27.485856 22542570456896 run_lib.py:133] step: 627700, training_loss: 2.82037e-02
I0211 02:18:27.641519 22542570456896 run_lib.py:146] step: 627700, eval_loss: 2.75095e-02
I0211 02:18:45.138726 22542570456896 run_lib.py:133] step: 627750, training_loss: 2.66474e-02
I0211 02:19:02.577369 22542570456896 run_lib.py:133] step: 627800, training_loss: 1.71690e-02
I0211 02:19:02.729309 22542570456896 run_lib.py:146] step: 627800, eval_loss: 2.86478e-02
I0211 02:19:20.203918 22542570456896 run_lib.py:133] step: 627850, training_loss: 2.56891e-02
I0211 02:19:37.850701 22542570456896 run_lib.py:133] step: 627900, training_loss: 2.78794e-02
I0211 02:19:38.022215 22542570456896 run_lib.py:146] step: 627900, eval_loss: 3.11573e-02
I0211 02:19:55.524141 22542570456896 run_lib.py:133] step: 627950, training_loss: 2.19636e-02
I0211 02:20:13.089018 22542570456896 run_lib.py:133] step: 628000, training_loss: 2.78588e-02
I0211 02:20:13.248233 22542570456896 run_lib.py:146] step: 628000, eval_loss: 3.19036e-02
I0211 02:20:30.695116 22542570456896 run_lib.py:133] step: 628050, training_loss: 2.42445e-02
I0211 02:20:48.161397 22542570456896 run_lib.py:133] step: 628100, training_loss: 2.07469e-02
I0211 02:20:48.317506 22542570456896 run_lib.py:146] step: 628100, eval_loss: 3.31162e-02
I0211 02:21:05.935920 22542570456896 run_lib.py:133] step: 628150, training_loss: 2.73500e-02
I0211 02:21:23.470137 22542570456896 run_lib.py:133] step: 628200, training_loss: 2.75726e-02
I0211 02:21:23.626607 22542570456896 run_lib.py:146] step: 628200, eval_loss: 3.26100e-02
I0211 02:21:41.169650 22542570456896 run_lib.py:133] step: 628250, training_loss: 1.87236e-02
I0211 02:21:58.648237 22542570456896 run_lib.py:133] step: 628300, training_loss: 2.97712e-02
I0211 02:21:58.802755 22542570456896 run_lib.py:146] step: 628300, eval_loss: 3.05156e-02
I0211 02:22:16.440204 22542570456896 run_lib.py:133] step: 628350, training_loss: 2.89235e-02
I0211 02:22:33.940449 22542570456896 run_lib.py:133] step: 628400, training_loss: 2.71153e-02
I0211 02:22:34.100626 22542570456896 run_lib.py:146] step: 628400, eval_loss: 3.16932e-02
I0211 02:22:51.709179 22542570456896 run_lib.py:133] step: 628450, training_loss: 2.81801e-02
I0211 02:23:09.265083 22542570456896 run_lib.py:133] step: 628500, training_loss: 2.36174e-02
I0211 02:23:09.421547 22542570456896 run_lib.py:146] step: 628500, eval_loss: 2.67518e-02
I0211 02:23:27.064599 22542570456896 run_lib.py:133] step: 628550, training_loss: 3.45158e-02
I0211 02:23:44.531564 22542570456896 run_lib.py:133] step: 628600, training_loss: 2.71077e-02
I0211 02:23:44.690076 22542570456896 run_lib.py:146] step: 628600, eval_loss: 2.91926e-02
I0211 02:24:02.160862 22542570456896 run_lib.py:133] step: 628650, training_loss: 3.51433e-02
I0211 02:24:19.826130 22542570456896 run_lib.py:133] step: 628700, training_loss: 2.45621e-02
I0211 02:24:19.981330 22542570456896 run_lib.py:146] step: 628700, eval_loss: 2.43287e-02
I0211 02:24:37.510144 22542570456896 run_lib.py:133] step: 628750, training_loss: 2.62284e-02
I0211 02:24:55.170106 22542570456896 run_lib.py:133] step: 628800, training_loss: 2.75521e-02
I0211 02:24:55.330707 22542570456896 run_lib.py:146] step: 628800, eval_loss: 3.06971e-02
I0211 02:25:12.799615 22542570456896 run_lib.py:133] step: 628850, training_loss: 2.40994e-02
I0211 02:25:30.273842 22542570456896 run_lib.py:133] step: 628900, training_loss: 2.46821e-02
I0211 02:25:30.428140 22542570456896 run_lib.py:146] step: 628900, eval_loss: 3.70485e-02
I0211 02:25:48.039862 22542570456896 run_lib.py:133] step: 628950, training_loss: 2.65106e-02
I0211 02:26:05.525669 22542570456896 run_lib.py:133] step: 629000, training_loss: 3.67357e-02
I0211 02:26:05.699712 22542570456896 run_lib.py:146] step: 629000, eval_loss: 2.68174e-02
I0211 02:26:23.206700 22542570456896 run_lib.py:133] step: 629050, training_loss: 3.42883e-02
I0211 02:26:40.883220 22542570456896 run_lib.py:133] step: 629100, training_loss: 2.62618e-02
I0211 02:26:41.043200 22542570456896 run_lib.py:146] step: 629100, eval_loss: 3.20552e-02
I0211 02:26:58.522183 22542570456896 run_lib.py:133] step: 629150, training_loss: 2.09870e-02
I0211 02:27:15.997822 22542570456896 run_lib.py:133] step: 629200, training_loss: 2.86724e-02
I0211 02:27:16.149883 22542570456896 run_lib.py:146] step: 629200, eval_loss: 3.26595e-02
I0211 02:27:33.682671 22542570456896 run_lib.py:133] step: 629250, training_loss: 3.04325e-02
I0211 02:27:51.192033 22542570456896 run_lib.py:133] step: 629300, training_loss: 3.03246e-02
I0211 02:27:51.389631 22542570456896 run_lib.py:146] step: 629300, eval_loss: 2.91671e-02
I0211 02:28:08.899492 22542570456896 run_lib.py:133] step: 629350, training_loss: 3.09659e-02
I0211 02:28:26.368732 22542570456896 run_lib.py:133] step: 629400, training_loss: 2.68423e-02
I0211 02:28:26.527480 22542570456896 run_lib.py:146] step: 629400, eval_loss: 2.64021e-02
I0211 02:28:44.193785 22542570456896 run_lib.py:133] step: 629450, training_loss: 2.24927e-02
I0211 02:29:01.698263 22542570456896 run_lib.py:133] step: 629500, training_loss: 3.02756e-02
I0211 02:29:01.853431 22542570456896 run_lib.py:146] step: 629500, eval_loss: 2.78414e-02
I0211 02:29:19.295068 22542570456896 run_lib.py:133] step: 629550, training_loss: 3.49380e-02
I0211 02:29:36.846373 22542570456896 run_lib.py:133] step: 629600, training_loss: 2.55972e-02
I0211 02:29:37.011982 22542570456896 run_lib.py:146] step: 629600, eval_loss: 3.62162e-02
I0211 02:29:54.726454 22542570456896 run_lib.py:133] step: 629650, training_loss: 2.31236e-02
I0211 02:30:12.156956 22542570456896 run_lib.py:133] step: 629700, training_loss: 2.51520e-02
I0211 02:30:12.307415 22542570456896 run_lib.py:146] step: 629700, eval_loss: 2.49150e-02
I0211 02:30:29.902869 22542570456896 run_lib.py:133] step: 629750, training_loss: 3.27700e-02
I0211 02:30:47.392304 22542570456896 run_lib.py:133] step: 629800, training_loss: 2.62563e-02
I0211 02:30:47.547087 22542570456896 run_lib.py:146] step: 629800, eval_loss: 2.74559e-02
I0211 02:31:05.222859 22542570456896 run_lib.py:133] step: 629850, training_loss: 2.56094e-02
I0211 02:31:22.736840 22542570456896 run_lib.py:133] step: 629900, training_loss: 2.88614e-02
I0211 02:31:22.897598 22542570456896 run_lib.py:146] step: 629900, eval_loss: 3.31099e-02
I0211 02:31:40.550873 22542570456896 run_lib.py:133] step: 629950, training_loss: 2.60185e-02
I0211 02:31:58.048909 22542570456896 run_lib.py:133] step: 630000, training_loss: 2.79387e-02
I0211 02:31:58.762171 22542570456896 run_lib.py:146] step: 630000, eval_loss: 2.62355e-02
I0211 02:32:18.869173 22542570456896 run_lib.py:133] step: 630050, training_loss: 3.17903e-02
I0211 02:32:36.468205 22542570456896 run_lib.py:133] step: 630100, training_loss: 3.04398e-02
I0211 02:32:36.641603 22542570456896 run_lib.py:146] step: 630100, eval_loss: 3.49797e-02
I0211 02:32:54.143650 22542570456896 run_lib.py:133] step: 630150, training_loss: 2.43244e-02
I0211 02:33:11.742912 22542570456896 run_lib.py:133] step: 630200, training_loss: 3.10509e-02
I0211 02:33:11.899187 22542570456896 run_lib.py:146] step: 630200, eval_loss: 2.28481e-02
I0211 02:33:29.453548 22542570456896 run_lib.py:133] step: 630250, training_loss: 2.57809e-02
I0211 02:33:46.966237 22542570456896 run_lib.py:133] step: 630300, training_loss: 3.42359e-02
I0211 02:33:47.122195 22542570456896 run_lib.py:146] step: 630300, eval_loss: 3.22967e-02
I0211 02:34:04.737048 22542570456896 run_lib.py:133] step: 630350, training_loss: 2.68087e-02
I0211 02:34:22.308954 22542570456896 run_lib.py:133] step: 630400, training_loss: 2.31814e-02
I0211 02:34:22.486334 22542570456896 run_lib.py:146] step: 630400, eval_loss: 2.33472e-02
I0211 02:34:39.999802 22542570456896 run_lib.py:133] step: 630450, training_loss: 2.99037e-02
I0211 02:34:57.491488 22542570456896 run_lib.py:133] step: 630500, training_loss: 2.51172e-02
I0211 02:34:57.647571 22542570456896 run_lib.py:146] step: 630500, eval_loss: 2.36244e-02
I0211 02:35:15.299378 22542570456896 run_lib.py:133] step: 630550, training_loss: 2.35371e-02
I0211 02:35:32.742644 22542570456896 run_lib.py:133] step: 630600, training_loss: 2.38838e-02
I0211 02:35:32.898724 22542570456896 run_lib.py:146] step: 630600, eval_loss: 3.05155e-02
I0211 02:35:50.531080 22542570456896 run_lib.py:133] step: 630650, training_loss: 3.11713e-02
I0211 02:36:08.051310 22542570456896 run_lib.py:133] step: 630700, training_loss: 2.83115e-02
I0211 02:36:08.206583 22542570456896 run_lib.py:146] step: 630700, eval_loss: 2.97599e-02
I0211 02:36:25.893192 22542570456896 run_lib.py:133] step: 630750, training_loss: 2.76512e-02
I0211 02:36:43.377538 22542570456896 run_lib.py:133] step: 630800, training_loss: 3.08306e-02
I0211 02:36:43.544414 22542570456896 run_lib.py:146] step: 630800, eval_loss: 2.50858e-02
I0211 02:37:01.042716 22542570456896 run_lib.py:133] step: 630850, training_loss: 2.47473e-02
I0211 02:37:18.669079 22542570456896 run_lib.py:133] step: 630900, training_loss: 2.65916e-02
I0211 02:37:18.841981 22542570456896 run_lib.py:146] step: 630900, eval_loss: 3.30647e-02
I0211 02:37:36.376908 22542570456896 run_lib.py:133] step: 630950, training_loss: 3.20304e-02
I0211 02:37:54.083493 22542570456896 run_lib.py:133] step: 631000, training_loss: 2.51469e-02
I0211 02:37:54.247752 22542570456896 run_lib.py:146] step: 631000, eval_loss: 3.44331e-02
I0211 02:38:11.741572 22542570456896 run_lib.py:133] step: 631050, training_loss: 2.39896e-02
I0211 02:38:29.234278 22542570456896 run_lib.py:133] step: 631100, training_loss: 3.33927e-02
I0211 02:38:29.389257 22542570456896 run_lib.py:146] step: 631100, eval_loss: 2.42432e-02
I0211 02:38:47.029134 22542570456896 run_lib.py:133] step: 631150, training_loss: 3.26903e-02
I0211 02:39:04.544259 22542570456896 run_lib.py:133] step: 631200, training_loss: 2.20576e-02
I0211 02:39:04.698796 22542570456896 run_lib.py:146] step: 631200, eval_loss: 2.71955e-02
I0211 02:39:22.297845 22542570456896 run_lib.py:133] step: 631250, training_loss: 2.40314e-02
I0211 02:39:39.993226 22542570456896 run_lib.py:133] step: 631300, training_loss: 3.16508e-02
I0211 02:39:40.158966 22542570456896 run_lib.py:146] step: 631300, eval_loss: 2.58893e-02
I0211 02:39:57.658058 22542570456896 run_lib.py:133] step: 631350, training_loss: 2.30221e-02
I0211 02:40:15.138403 22542570456896 run_lib.py:133] step: 631400, training_loss: 2.58908e-02
I0211 02:40:15.304083 22542570456896 run_lib.py:146] step: 631400, eval_loss: 3.16765e-02
I0211 02:40:32.893262 22542570456896 run_lib.py:133] step: 631450, training_loss: 2.22226e-02
I0211 02:40:50.460679 22542570456896 run_lib.py:133] step: 631500, training_loss: 2.41091e-02
I0211 02:40:50.621130 22542570456896 run_lib.py:146] step: 631500, eval_loss: 3.44485e-02
I0211 02:41:08.162117 22542570456896 run_lib.py:133] step: 631550, training_loss: 3.06367e-02
I0211 02:41:25.680129 22542570456896 run_lib.py:133] step: 631600, training_loss: 2.63489e-02
I0211 02:41:25.837082 22542570456896 run_lib.py:146] step: 631600, eval_loss: 3.37639e-02
I0211 02:41:43.490084 22542570456896 run_lib.py:133] step: 631650, training_loss: 2.74098e-02
I0211 02:42:01.039447 22542570456896 run_lib.py:133] step: 631700, training_loss: 2.34276e-02
I0211 02:42:01.195832 22542570456896 run_lib.py:146] step: 631700, eval_loss: 3.21831e-02
I0211 02:42:18.722754 22542570456896 run_lib.py:133] step: 631750, training_loss: 2.80162e-02
I0211 02:42:36.223144 22542570456896 run_lib.py:133] step: 631800, training_loss: 2.50623e-02
I0211 02:42:36.382775 22542570456896 run_lib.py:146] step: 631800, eval_loss: 3.63187e-02
I0211 02:42:54.052809 22542570456896 run_lib.py:133] step: 631850, training_loss: 2.87086e-02
I0211 02:43:11.487334 22542570456896 run_lib.py:133] step: 631900, training_loss: 2.86104e-02
I0211 02:43:11.644933 22542570456896 run_lib.py:146] step: 631900, eval_loss: 3.08241e-02
I0211 02:43:29.292540 22542570456896 run_lib.py:133] step: 631950, training_loss: 2.78343e-02
I0211 02:43:46.857752 22542570456896 run_lib.py:133] step: 632000, training_loss: 2.68165e-02
I0211 02:43:47.011129 22542570456896 run_lib.py:146] step: 632000, eval_loss: 2.72751e-02
I0211 02:44:04.702383 22542570456896 run_lib.py:133] step: 632050, training_loss: 2.60423e-02
I0211 02:44:22.187867 22542570456896 run_lib.py:133] step: 632100, training_loss: 2.08637e-02
I0211 02:44:22.340492 22542570456896 run_lib.py:146] step: 632100, eval_loss: 3.58740e-02
I0211 02:44:39.964871 22542570456896 run_lib.py:133] step: 632150, training_loss: 2.62425e-02
I0211 02:44:57.491518 22542570456896 run_lib.py:133] step: 632200, training_loss: 2.40986e-02
I0211 02:44:57.646462 22542570456896 run_lib.py:146] step: 632200, eval_loss: 2.87898e-02
I0211 02:45:15.118905 22542570456896 run_lib.py:133] step: 632250, training_loss: 3.02417e-02
I0211 02:45:32.791231 22542570456896 run_lib.py:133] step: 632300, training_loss: 2.60833e-02
I0211 02:45:32.971114 22542570456896 run_lib.py:146] step: 632300, eval_loss: 3.11510e-02
I0211 02:45:50.509242 22542570456896 run_lib.py:133] step: 632350, training_loss: 2.51913e-02
I0211 02:46:08.008235 22542570456896 run_lib.py:133] step: 632400, training_loss: 2.73505e-02
I0211 02:46:08.164800 22542570456896 run_lib.py:146] step: 632400, eval_loss: 2.66947e-02
I0211 02:46:25.833214 22542570456896 run_lib.py:133] step: 632450, training_loss: 2.61257e-02
I0211 02:46:43.299491 22542570456896 run_lib.py:133] step: 632500, training_loss: 2.77151e-02
I0211 02:46:43.458717 22542570456896 run_lib.py:146] step: 632500, eval_loss: 2.63467e-02
I0211 02:47:01.093883 22542570456896 run_lib.py:133] step: 632550, training_loss: 2.48236e-02
I0211 02:47:18.672098 22542570456896 run_lib.py:133] step: 632600, training_loss: 2.91872e-02
I0211 02:47:18.829358 22542570456896 run_lib.py:146] step: 632600, eval_loss: 2.52867e-02
I0211 02:47:36.315585 22542570456896 run_lib.py:133] step: 632650, training_loss: 2.60446e-02
I0211 02:47:54.028047 22542570456896 run_lib.py:133] step: 632700, training_loss: 3.07276e-02
I0211 02:47:54.184473 22542570456896 run_lib.py:146] step: 632700, eval_loss: 2.68290e-02
I0211 02:48:11.655475 22542570456896 run_lib.py:133] step: 632750, training_loss: 2.92076e-02
I0211 02:48:29.126251 22542570456896 run_lib.py:133] step: 632800, training_loss: 3.04019e-02
I0211 02:48:29.288534 22542570456896 run_lib.py:146] step: 632800, eval_loss: 2.69455e-02
I0211 02:48:46.786732 22542570456896 run_lib.py:133] step: 632850, training_loss: 3.10219e-02
I0211 02:49:04.465358 22542570456896 run_lib.py:133] step: 632900, training_loss: 3.26626e-02
I0211 02:49:04.622195 22542570456896 run_lib.py:146] step: 632900, eval_loss: 3.58040e-02
I0211 02:49:22.109056 22542570456896 run_lib.py:133] step: 632950, training_loss: 2.79696e-02
I0211 02:49:39.691500 22542570456896 run_lib.py:133] step: 633000, training_loss: 3.09421e-02
I0211 02:49:39.849148 22542570456896 run_lib.py:146] step: 633000, eval_loss: 3.25499e-02
I0211 02:49:57.331481 22542570456896 run_lib.py:133] step: 633050, training_loss: 2.84594e-02
I0211 02:50:14.936853 22542570456896 run_lib.py:133] step: 633100, training_loss: 2.35516e-02
I0211 02:50:15.091634 22542570456896 run_lib.py:146] step: 633100, eval_loss: 2.87261e-02
I0211 02:50:32.749307 22542570456896 run_lib.py:133] step: 633150, training_loss: 2.59691e-02
I0211 02:50:50.396347 22542570456896 run_lib.py:133] step: 633200, training_loss: 3.42367e-02
I0211 02:50:50.556499 22542570456896 run_lib.py:146] step: 633200, eval_loss: 2.63218e-02
I0211 02:51:08.006803 22542570456896 run_lib.py:133] step: 633250, training_loss: 2.98018e-02
I0211 02:51:25.470573 22542570456896 run_lib.py:133] step: 633300, training_loss: 2.36705e-02
I0211 02:51:25.629329 22542570456896 run_lib.py:146] step: 633300, eval_loss: 3.16801e-02
I0211 02:51:43.248842 22542570456896 run_lib.py:133] step: 633350, training_loss: 2.83934e-02
I0211 02:52:00.747488 22542570456896 run_lib.py:133] step: 633400, training_loss: 2.25681e-02
I0211 02:52:00.911169 22542570456896 run_lib.py:146] step: 633400, eval_loss: 2.77591e-02
I0211 02:52:18.586751 22542570456896 run_lib.py:133] step: 633450, training_loss: 2.53982e-02
I0211 02:52:36.081763 22542570456896 run_lib.py:133] step: 633500, training_loss: 2.76237e-02
I0211 02:52:36.236181 22542570456896 run_lib.py:146] step: 633500, eval_loss: 3.30028e-02
I0211 02:52:53.956156 22542570456896 run_lib.py:133] step: 633550, training_loss: 2.55294e-02
I0211 02:53:11.416816 22542570456896 run_lib.py:133] step: 633600, training_loss: 2.57422e-02
I0211 02:53:11.570461 22542570456896 run_lib.py:146] step: 633600, eval_loss: 2.69746e-02
I0211 02:53:29.028275 22542570456896 run_lib.py:133] step: 633650, training_loss: 2.83872e-02
I0211 02:53:46.700339 22542570456896 run_lib.py:133] step: 633700, training_loss: 2.66971e-02
I0211 02:53:46.883350 22542570456896 run_lib.py:146] step: 633700, eval_loss: 2.94858e-02
I0211 02:54:04.481751 22542570456896 run_lib.py:133] step: 633750, training_loss: 2.42203e-02
I0211 02:54:22.127696 22542570456896 run_lib.py:133] step: 633800, training_loss: 2.29665e-02
I0211 02:54:22.285351 22542570456896 run_lib.py:146] step: 633800, eval_loss: 3.34201e-02
I0211 02:54:39.768640 22542570456896 run_lib.py:133] step: 633850, training_loss: 3.53329e-02
I0211 02:54:57.252631 22542570456896 run_lib.py:133] step: 633900, training_loss: 2.55667e-02
I0211 02:54:57.409584 22542570456896 run_lib.py:146] step: 633900, eval_loss: 2.23383e-02
I0211 02:55:15.100659 22542570456896 run_lib.py:133] step: 633950, training_loss: 2.66680e-02
I0211 02:55:32.624043 22542570456896 run_lib.py:133] step: 634000, training_loss: 2.50361e-02
I0211 02:55:32.778450 22542570456896 run_lib.py:146] step: 634000, eval_loss: 2.52048e-02
I0211 02:55:50.304916 22542570456896 run_lib.py:133] step: 634050, training_loss: 2.45948e-02
I0211 02:56:07.988151 22542570456896 run_lib.py:133] step: 634100, training_loss: 3.25755e-02
I0211 02:56:08.143436 22542570456896 run_lib.py:146] step: 634100, eval_loss: 2.63650e-02
I0211 02:56:25.622092 22542570456896 run_lib.py:133] step: 634150, training_loss: 2.20325e-02
I0211 02:56:43.099130 22542570456896 run_lib.py:133] step: 634200, training_loss: 2.87421e-02
I0211 02:56:43.420328 22542570456896 run_lib.py:146] step: 634200, eval_loss: 2.85057e-02
I0211 02:57:00.948864 22542570456896 run_lib.py:133] step: 634250, training_loss: 3.07549e-02
I0211 02:57:18.517569 22542570456896 run_lib.py:133] step: 634300, training_loss: 2.83849e-02
I0211 02:57:18.675648 22542570456896 run_lib.py:146] step: 634300, eval_loss: 2.86652e-02
I0211 02:57:36.115061 22542570456896 run_lib.py:133] step: 634350, training_loss: 2.67428e-02
I0211 02:57:53.506898 22542570456896 run_lib.py:133] step: 634400, training_loss: 2.84209e-02
I0211 02:57:53.662318 22542570456896 run_lib.py:146] step: 634400, eval_loss: 3.55336e-02
I0211 02:58:11.223912 22542570456896 run_lib.py:133] step: 634450, training_loss: 2.68492e-02
I0211 02:58:28.643076 22542570456896 run_lib.py:133] step: 634500, training_loss: 2.51075e-02
I0211 02:58:28.795311 22542570456896 run_lib.py:146] step: 634500, eval_loss: 3.09695e-02
I0211 02:58:46.262793 22542570456896 run_lib.py:133] step: 634550, training_loss: 2.39783e-02
I0211 02:59:03.766693 22542570456896 run_lib.py:133] step: 634600, training_loss: 3.06618e-02
I0211 02:59:03.927666 22542570456896 run_lib.py:146] step: 634600, eval_loss: 2.79206e-02
I0211 02:59:21.612108 22542570456896 run_lib.py:133] step: 634650, training_loss: 2.83028e-02
I0211 02:59:39.184507 22542570456896 run_lib.py:133] step: 634700, training_loss: 3.26571e-02
I0211 02:59:39.351897 22542570456896 run_lib.py:146] step: 634700, eval_loss: 2.86261e-02
I0211 02:59:56.909755 22542570456896 run_lib.py:133] step: 634750, training_loss: 2.57156e-02
I0211 03:00:14.378492 22542570456896 run_lib.py:133] step: 634800, training_loss: 3.21354e-02
I0211 03:00:14.540794 22542570456896 run_lib.py:146] step: 634800, eval_loss: 2.58554e-02
I0211 03:00:32.149062 22542570456896 run_lib.py:133] step: 634850, training_loss: 2.49238e-02
I0211 03:00:49.737033 22542570456896 run_lib.py:133] step: 634900, training_loss: 2.86444e-02
I0211 03:00:49.894715 22542570456896 run_lib.py:146] step: 634900, eval_loss: 3.27156e-02
I0211 03:01:07.623524 22542570456896 run_lib.py:133] step: 634950, training_loss: 3.33397e-02
I0211 03:01:25.088603 22542570456896 run_lib.py:133] step: 635000, training_loss: 2.74634e-02
I0211 03:01:25.240938 22542570456896 run_lib.py:146] step: 635000, eval_loss: 3.18620e-02
I0211 03:01:42.851614 22542570456896 run_lib.py:133] step: 635050, training_loss: 3.20902e-02
I0211 03:02:00.316184 22542570456896 run_lib.py:133] step: 635100, training_loss: 2.78596e-02
I0211 03:02:00.474786 22542570456896 run_lib.py:146] step: 635100, eval_loss: 3.87996e-02
I0211 03:02:18.016086 22542570456896 run_lib.py:133] step: 635150, training_loss: 3.55730e-02
I0211 03:02:35.736449 22542570456896 run_lib.py:133] step: 635200, training_loss: 2.67557e-02
I0211 03:02:35.899160 22542570456896 run_lib.py:146] step: 635200, eval_loss: 2.76641e-02
I0211 03:02:53.345210 22542570456896 run_lib.py:133] step: 635250, training_loss: 2.64383e-02
I0211 03:03:10.968983 22542570456896 run_lib.py:133] step: 635300, training_loss: 2.92504e-02
I0211 03:03:11.124208 22542570456896 run_lib.py:146] step: 635300, eval_loss: 3.28387e-02
I0211 03:03:28.621209 22542570456896 run_lib.py:133] step: 635350, training_loss: 3.23722e-02
I0211 03:03:46.116057 22542570456896 run_lib.py:133] step: 635400, training_loss: 2.80411e-02
I0211 03:03:46.271299 22542570456896 run_lib.py:146] step: 635400, eval_loss: 2.41224e-02
I0211 03:04:04.007970 22542570456896 run_lib.py:133] step: 635450, training_loss: 2.42469e-02
I0211 03:04:21.505134 22542570456896 run_lib.py:133] step: 635500, training_loss: 2.47179e-02
I0211 03:04:21.658395 22542570456896 run_lib.py:146] step: 635500, eval_loss: 2.74804e-02
I0211 03:04:39.135053 22542570456896 run_lib.py:133] step: 635550, training_loss: 2.71495e-02
I0211 03:04:56.614290 22542570456896 run_lib.py:133] step: 635600, training_loss: 2.93092e-02
I0211 03:04:56.773602 22542570456896 run_lib.py:146] step: 635600, eval_loss: 2.92005e-02
I0211 03:05:14.387832 22542570456896 run_lib.py:133] step: 635650, training_loss: 3.31875e-02
I0211 03:05:31.901288 22542570456896 run_lib.py:133] step: 635700, training_loss: 2.96537e-02
I0211 03:05:32.074322 22542570456896 run_lib.py:146] step: 635700, eval_loss: 4.07570e-02
I0211 03:05:49.669675 22542570456896 run_lib.py:133] step: 635750, training_loss: 2.40407e-02
I0211 03:06:07.147687 22542570456896 run_lib.py:133] step: 635800, training_loss: 2.85915e-02
I0211 03:06:07.312806 22542570456896 run_lib.py:146] step: 635800, eval_loss: 4.12552e-02
I0211 03:06:24.795349 22542570456896 run_lib.py:133] step: 635850, training_loss: 2.54552e-02
I0211 03:06:42.258493 22542570456896 run_lib.py:133] step: 635900, training_loss: 2.97808e-02
I0211 03:06:42.408293 22542570456896 run_lib.py:146] step: 635900, eval_loss: 2.51528e-02
I0211 03:06:59.988126 22542570456896 run_lib.py:133] step: 635950, training_loss: 3.21082e-02
I0211 03:07:17.629121 22542570456896 run_lib.py:133] step: 636000, training_loss: 2.09581e-02
I0211 03:07:17.801032 22542570456896 run_lib.py:146] step: 636000, eval_loss: 2.37842e-02
I0211 03:07:35.317947 22542570456896 run_lib.py:133] step: 636050, training_loss: 3.27849e-02
I0211 03:07:52.830109 22542570456896 run_lib.py:133] step: 636100, training_loss: 2.16841e-02
I0211 03:07:52.990566 22542570456896 run_lib.py:146] step: 636100, eval_loss: 2.88187e-02
I0211 03:08:10.652370 22542570456896 run_lib.py:133] step: 636150, training_loss: 3.16306e-02
I0211 03:08:28.102620 22542570456896 run_lib.py:133] step: 636200, training_loss: 2.58136e-02
I0211 03:08:28.258507 22542570456896 run_lib.py:146] step: 636200, eval_loss: 2.85460e-02
I0211 03:08:45.893447 22542570456896 run_lib.py:133] step: 636250, training_loss: 3.43097e-02
I0211 03:09:03.485661 22542570456896 run_lib.py:133] step: 636300, training_loss: 2.65329e-02
I0211 03:09:03.646707 22542570456896 run_lib.py:146] step: 636300, eval_loss: 3.18117e-02
I0211 03:09:21.304394 22542570456896 run_lib.py:133] step: 636350, training_loss: 2.82108e-02
I0211 03:09:38.793825 22542570456896 run_lib.py:133] step: 636400, training_loss: 3.18504e-02
I0211 03:09:38.955367 22542570456896 run_lib.py:146] step: 636400, eval_loss: 2.75107e-02
I0211 03:09:56.597241 22542570456896 run_lib.py:133] step: 636450, training_loss: 3.29310e-02
I0211 03:10:14.136946 22542570456896 run_lib.py:133] step: 636500, training_loss: 2.52546e-02
I0211 03:10:14.306800 22542570456896 run_lib.py:146] step: 636500, eval_loss: 2.98809e-02
I0211 03:10:31.892917 22542570456896 run_lib.py:133] step: 636550, training_loss: 2.63016e-02
I0211 03:10:49.564154 22542570456896 run_lib.py:133] step: 636600, training_loss: 2.43870e-02
I0211 03:10:49.723513 22542570456896 run_lib.py:146] step: 636600, eval_loss: 2.84250e-02
I0211 03:11:07.203944 22542570456896 run_lib.py:133] step: 636650, training_loss: 2.78669e-02
I0211 03:11:24.705427 22542570456896 run_lib.py:133] step: 636700, training_loss: 2.36021e-02
I0211 03:11:24.861406 22542570456896 run_lib.py:146] step: 636700, eval_loss: 2.91059e-02
I0211 03:11:42.513788 22542570456896 run_lib.py:133] step: 636750, training_loss: 3.00561e-02
I0211 03:12:00.189007 22542570456896 run_lib.py:133] step: 636800, training_loss: 2.39456e-02
I0211 03:12:00.348094 22542570456896 run_lib.py:146] step: 636800, eval_loss: 2.96506e-02
I0211 03:12:17.870971 22542570456896 run_lib.py:133] step: 636850, training_loss: 2.89619e-02
I0211 03:12:35.323313 22542570456896 run_lib.py:133] step: 636900, training_loss: 2.70605e-02
I0211 03:12:35.475431 22542570456896 run_lib.py:146] step: 636900, eval_loss: 3.11047e-02
I0211 03:12:52.940314 22542570456896 run_lib.py:133] step: 636950, training_loss: 2.81780e-02
I0211 03:13:10.610334 22542570456896 run_lib.py:133] step: 637000, training_loss: 2.74139e-02
I0211 03:13:10.770367 22542570456896 run_lib.py:146] step: 637000, eval_loss: 3.23928e-02
I0211 03:13:28.228171 22542570456896 run_lib.py:133] step: 637050, training_loss: 2.78132e-02
I0211 03:13:45.784941 22542570456896 run_lib.py:133] step: 637100, training_loss: 2.72554e-02
I0211 03:13:45.941721 22542570456896 run_lib.py:146] step: 637100, eval_loss: 2.64156e-02
I0211 03:14:03.433599 22542570456896 run_lib.py:133] step: 637150, training_loss: 2.60551e-02
I0211 03:14:21.085016 22542570456896 run_lib.py:133] step: 637200, training_loss: 2.86580e-02
I0211 03:14:21.241629 22542570456896 run_lib.py:146] step: 637200, eval_loss: 2.65045e-02
I0211 03:14:38.731914 22542570456896 run_lib.py:133] step: 637250, training_loss: 2.20212e-02
I0211 03:14:56.285866 22542570456896 run_lib.py:133] step: 637300, training_loss: 2.84417e-02
I0211 03:14:56.438578 22542570456896 run_lib.py:146] step: 637300, eval_loss: 3.38398e-02
I0211 03:15:13.925363 22542570456896 run_lib.py:133] step: 637350, training_loss: 3.12892e-02
I0211 03:15:31.416538 22542570456896 run_lib.py:133] step: 637400, training_loss: 2.69824e-02
I0211 03:15:31.575993 22542570456896 run_lib.py:146] step: 637400, eval_loss: 2.62260e-02
I0211 03:15:49.330457 22542570456896 run_lib.py:133] step: 637450, training_loss: 2.35203e-02
I0211 03:16:06.957960 22542570456896 run_lib.py:133] step: 637500, training_loss: 2.48881e-02
I0211 03:16:07.125583 22542570456896 run_lib.py:146] step: 637500, eval_loss: 3.79027e-02
I0211 03:16:24.597887 22542570456896 run_lib.py:133] step: 637550, training_loss: 2.88622e-02
I0211 03:16:42.080209 22542570456896 run_lib.py:133] step: 637600, training_loss: 2.19214e-02
I0211 03:16:42.248551 22542570456896 run_lib.py:146] step: 637600, eval_loss: 2.80930e-02
I0211 03:16:59.880432 22542570456896 run_lib.py:133] step: 637650, training_loss: 2.83626e-02
I0211 03:17:17.424732 22542570456896 run_lib.py:133] step: 637700, training_loss: 2.64724e-02
I0211 03:17:17.582298 22542570456896 run_lib.py:146] step: 637700, eval_loss: 2.67773e-02
I0211 03:17:35.258211 22542570456896 run_lib.py:133] step: 637750, training_loss: 3.66188e-02
I0211 03:17:52.750481 22542570456896 run_lib.py:133] step: 637800, training_loss: 2.71688e-02
I0211 03:17:52.911103 22542570456896 run_lib.py:146] step: 637800, eval_loss: 2.30881e-02
I0211 03:18:10.547733 22542570456896 run_lib.py:133] step: 637850, training_loss: 3.25758e-02
I0211 03:18:28.036262 22542570456896 run_lib.py:133] step: 637900, training_loss: 2.62022e-02
I0211 03:18:28.204741 22542570456896 run_lib.py:146] step: 637900, eval_loss: 2.69840e-02
I0211 03:18:45.713606 22542570456896 run_lib.py:133] step: 637950, training_loss: 2.89051e-02
I0211 03:19:03.365972 22542570456896 run_lib.py:133] step: 638000, training_loss: 3.24759e-02
I0211 03:19:03.531417 22542570456896 run_lib.py:146] step: 638000, eval_loss: 2.65195e-02
I0211 03:19:20.993854 22542570456896 run_lib.py:133] step: 638050, training_loss: 2.11655e-02
I0211 03:19:38.579122 22542570456896 run_lib.py:133] step: 638100, training_loss: 3.22061e-02
I0211 03:19:38.741437 22542570456896 run_lib.py:146] step: 638100, eval_loss: 2.27386e-02
I0211 03:19:56.224019 22542570456896 run_lib.py:133] step: 638150, training_loss: 3.05144e-02
I0211 03:20:13.716116 22542570456896 run_lib.py:133] step: 638200, training_loss: 2.91422e-02
I0211 03:20:13.872775 22542570456896 run_lib.py:146] step: 638200, eval_loss: 2.71751e-02
I0211 03:20:31.540235 22542570456896 run_lib.py:133] step: 638250, training_loss: 2.33070e-02
I0211 03:20:49.032050 22542570456896 run_lib.py:133] step: 638300, training_loss: 2.65332e-02
I0211 03:20:49.185099 22542570456896 run_lib.py:146] step: 638300, eval_loss: 3.60521e-02
I0211 03:21:06.666046 22542570456896 run_lib.py:133] step: 638350, training_loss: 2.33801e-02
I0211 03:21:24.371083 22542570456896 run_lib.py:133] step: 638400, training_loss: 2.72069e-02
I0211 03:21:24.534458 22542570456896 run_lib.py:146] step: 638400, eval_loss: 3.33537e-02
I0211 03:21:42.026811 22542570456896 run_lib.py:133] step: 638450, training_loss: 2.68794e-02
I0211 03:21:59.535943 22542570456896 run_lib.py:133] step: 638500, training_loss: 3.83316e-02
I0211 03:21:59.700751 22542570456896 run_lib.py:146] step: 638500, eval_loss: 3.09559e-02
I0211 03:22:17.278793 22542570456896 run_lib.py:133] step: 638550, training_loss: 2.52598e-02
I0211 03:22:34.759477 22542570456896 run_lib.py:133] step: 638600, training_loss: 3.03648e-02
I0211 03:22:34.915096 22542570456896 run_lib.py:146] step: 638600, eval_loss: 2.83506e-02
I0211 03:22:52.370181 22542570456896 run_lib.py:133] step: 638650, training_loss: 2.91812e-02
I0211 03:23:09.817762 22542570456896 run_lib.py:133] step: 638700, training_loss: 2.49543e-02
I0211 03:23:09.972416 22542570456896 run_lib.py:146] step: 638700, eval_loss: 2.48324e-02
I0211 03:23:27.592388 22542570456896 run_lib.py:133] step: 638750, training_loss: 2.62290e-02
I0211 03:23:45.224130 22542570456896 run_lib.py:133] step: 638800, training_loss: 2.80367e-02
I0211 03:23:45.380726 22542570456896 run_lib.py:146] step: 638800, eval_loss: 2.26652e-02
I0211 03:24:02.879219 22542570456896 run_lib.py:133] step: 638850, training_loss: 2.73629e-02
I0211 03:24:20.353419 22542570456896 run_lib.py:133] step: 638900, training_loss: 3.10014e-02
I0211 03:24:20.515247 22542570456896 run_lib.py:146] step: 638900, eval_loss: 2.83831e-02
I0211 03:24:38.116582 22542570456896 run_lib.py:133] step: 638950, training_loss: 2.85807e-02
I0211 03:24:55.568207 22542570456896 run_lib.py:133] step: 639000, training_loss: 2.32075e-02
I0211 03:24:55.724426 22542570456896 run_lib.py:146] step: 639000, eval_loss: 3.62774e-02
I0211 03:25:13.340106 22542570456896 run_lib.py:133] step: 639050, training_loss: 2.77874e-02
I0211 03:25:30.899267 22542570456896 run_lib.py:133] step: 639100, training_loss: 2.07557e-02
I0211 03:25:31.062684 22542570456896 run_lib.py:146] step: 639100, eval_loss: 2.84774e-02
I0211 03:25:48.737747 22542570456896 run_lib.py:133] step: 639150, training_loss: 3.01886e-02
I0211 03:26:06.211072 22542570456896 run_lib.py:133] step: 639200, training_loss: 3.43169e-02
I0211 03:26:06.364126 22542570456896 run_lib.py:146] step: 639200, eval_loss: 2.69993e-02
I0211 03:26:24.024174 22542570456896 run_lib.py:133] step: 639250, training_loss: 3.34087e-02
I0211 03:26:41.512611 22542570456896 run_lib.py:133] step: 639300, training_loss: 3.24090e-02
I0211 03:26:41.675912 22542570456896 run_lib.py:146] step: 639300, eval_loss: 3.03350e-02
I0211 03:26:59.177096 22542570456896 run_lib.py:133] step: 639350, training_loss: 3.23635e-02
I0211 03:27:16.856679 22542570456896 run_lib.py:133] step: 639400, training_loss: 2.84011e-02
I0211 03:27:17.012398 22542570456896 run_lib.py:146] step: 639400, eval_loss: 3.54650e-02
I0211 03:27:34.483800 22542570456896 run_lib.py:133] step: 639450, training_loss: 2.87775e-02
I0211 03:27:51.966558 22542570456896 run_lib.py:133] step: 639500, training_loss: 1.99463e-02
I0211 03:27:52.120648 22542570456896 run_lib.py:146] step: 639500, eval_loss: 2.45631e-02
I0211 03:28:09.777717 22542570456896 run_lib.py:133] step: 639550, training_loss: 2.80422e-02
I0211 03:28:27.231504 22542570456896 run_lib.py:133] step: 639600, training_loss: 2.66736e-02
I0211 03:28:27.389089 22542570456896 run_lib.py:146] step: 639600, eval_loss: 3.05749e-02
I0211 03:28:45.177113 22542570456896 run_lib.py:133] step: 639650, training_loss: 3.71818e-02
I0211 03:29:02.680034 22542570456896 run_lib.py:133] step: 639700, training_loss: 3.71968e-02
I0211 03:29:02.833519 22542570456896 run_lib.py:146] step: 639700, eval_loss: 2.66558e-02
I0211 03:29:20.307034 22542570456896 run_lib.py:133] step: 639750, training_loss: 2.08891e-02
I0211 03:29:37.963909 22542570456896 run_lib.py:133] step: 639800, training_loss: 2.32217e-02
I0211 03:29:38.129604 22542570456896 run_lib.py:146] step: 639800, eval_loss: 2.76911e-02
I0211 03:29:55.598814 22542570456896 run_lib.py:133] step: 639850, training_loss: 2.79497e-02
I0211 03:30:13.121898 22542570456896 run_lib.py:133] step: 639900, training_loss: 2.76961e-02
I0211 03:30:13.297421 22542570456896 run_lib.py:146] step: 639900, eval_loss: 2.46772e-02
I0211 03:30:30.792407 22542570456896 run_lib.py:133] step: 639950, training_loss: 2.89424e-02
I0211 03:30:48.496012 22542570456896 run_lib.py:133] step: 640000, training_loss: 3.11536e-02
I0211 03:30:49.222091 22542570456896 run_lib.py:146] step: 640000, eval_loss: 3.02898e-02
I0211 03:31:09.341717 22542570456896 run_lib.py:133] step: 640050, training_loss: 3.04684e-02
I0211 03:31:26.932755 22542570456896 run_lib.py:133] step: 640100, training_loss: 2.77394e-02
I0211 03:31:27.090422 22542570456896 run_lib.py:146] step: 640100, eval_loss: 3.19522e-02
I0211 03:31:44.547660 22542570456896 run_lib.py:133] step: 640150, training_loss: 2.72514e-02
I0211 03:32:02.114894 22542570456896 run_lib.py:133] step: 640200, training_loss: 2.75888e-02
I0211 03:32:02.271132 22542570456896 run_lib.py:146] step: 640200, eval_loss: 3.04768e-02
I0211 03:32:19.762287 22542570456896 run_lib.py:133] step: 640250, training_loss: 3.38609e-02
I0211 03:32:37.454658 22542570456896 run_lib.py:133] step: 640300, training_loss: 2.73348e-02
I0211 03:32:37.613465 22542570456896 run_lib.py:146] step: 640300, eval_loss: 3.14750e-02
I0211 03:32:55.157801 22542570456896 run_lib.py:133] step: 640350, training_loss: 2.43555e-02
I0211 03:33:12.626261 22542570456896 run_lib.py:133] step: 640400, training_loss: 2.84856e-02
I0211 03:33:12.794486 22542570456896 run_lib.py:146] step: 640400, eval_loss: 2.99641e-02
I0211 03:33:30.326798 22542570456896 run_lib.py:133] step: 640450, training_loss: 2.25510e-02
I0211 03:33:47.809523 22542570456896 run_lib.py:133] step: 640500, training_loss: 2.10327e-02
I0211 03:33:47.972548 22542570456896 run_lib.py:146] step: 640500, eval_loss: 3.21403e-02
I0211 03:34:05.603239 22542570456896 run_lib.py:133] step: 640550, training_loss: 3.04447e-02
I0211 03:34:23.129643 22542570456896 run_lib.py:133] step: 640600, training_loss: 3.13680e-02
I0211 03:34:23.285058 22542570456896 run_lib.py:146] step: 640600, eval_loss: 2.97198e-02
I0211 03:34:40.744744 22542570456896 run_lib.py:133] step: 640650, training_loss: 2.34002e-02
I0211 03:34:58.239993 22542570456896 run_lib.py:133] step: 640700, training_loss: 2.98861e-02
I0211 03:34:58.394418 22542570456896 run_lib.py:146] step: 640700, eval_loss: 2.81517e-02
I0211 03:35:16.079907 22542570456896 run_lib.py:133] step: 640750, training_loss: 3.03530e-02
I0211 03:35:33.575030 22542570456896 run_lib.py:133] step: 640800, training_loss: 2.36504e-02
I0211 03:35:33.730372 22542570456896 run_lib.py:146] step: 640800, eval_loss: 2.51607e-02
I0211 03:35:51.348882 22542570456896 run_lib.py:133] step: 640850, training_loss: 3.22646e-02
I0211 03:36:08.819155 22542570456896 run_lib.py:133] step: 640900, training_loss: 2.53707e-02
I0211 03:36:08.983244 22542570456896 run_lib.py:146] step: 640900, eval_loss: 2.41309e-02
I0211 03:36:26.570535 22542570456896 run_lib.py:133] step: 640950, training_loss: 2.29926e-02
I0211 03:36:44.092344 22542570456896 run_lib.py:133] step: 641000, training_loss: 2.49810e-02
I0211 03:36:44.262691 22542570456896 run_lib.py:146] step: 641000, eval_loss: 2.64033e-02
I0211 03:37:01.783997 22542570456896 run_lib.py:133] step: 641050, training_loss: 2.39553e-02
I0211 03:37:19.464437 22542570456896 run_lib.py:133] step: 641100, training_loss: 3.57899e-02
I0211 03:37:19.633689 22542570456896 run_lib.py:146] step: 641100, eval_loss: 2.65995e-02
I0211 03:37:37.146471 22542570456896 run_lib.py:133] step: 641150, training_loss: 2.17618e-02
I0211 03:37:54.755986 22542570456896 run_lib.py:133] step: 641200, training_loss: 2.99554e-02
I0211 03:37:54.911753 22542570456896 run_lib.py:146] step: 641200, eval_loss: 3.12619e-02
I0211 03:38:12.358002 22542570456896 run_lib.py:133] step: 641250, training_loss: 2.57341e-02
I0211 03:38:29.872802 22542570456896 run_lib.py:133] step: 641300, training_loss: 3.24237e-02
I0211 03:38:30.043519 22542570456896 run_lib.py:146] step: 641300, eval_loss: 3.05546e-02
I0211 03:38:47.713048 22542570456896 run_lib.py:133] step: 641350, training_loss: 2.15247e-02
I0211 03:39:05.232677 22542570456896 run_lib.py:133] step: 641400, training_loss: 2.50394e-02
I0211 03:39:05.391670 22542570456896 run_lib.py:146] step: 641400, eval_loss: 2.89931e-02
I0211 03:39:22.832826 22542570456896 run_lib.py:133] step: 641450, training_loss: 2.55307e-02
I0211 03:39:40.444860 22542570456896 run_lib.py:133] step: 641500, training_loss: 3.09264e-02
I0211 03:39:40.601589 22542570456896 run_lib.py:146] step: 641500, eval_loss: 2.80027e-02
I0211 03:39:58.097385 22542570456896 run_lib.py:133] step: 641550, training_loss: 2.66329e-02
I0211 03:40:15.676243 22542570456896 run_lib.py:133] step: 641600, training_loss: 2.23372e-02
I0211 03:40:16.014425 22542570456896 run_lib.py:146] step: 641600, eval_loss: 2.33696e-02
I0211 03:40:33.515487 22542570456896 run_lib.py:133] step: 641650, training_loss: 2.38033e-02
I0211 03:40:50.998769 22542570456896 run_lib.py:133] step: 641700, training_loss: 2.87344e-02
I0211 03:40:51.147302 22542570456896 run_lib.py:146] step: 641700, eval_loss: 2.02281e-02
I0211 03:41:08.619295 22542570456896 run_lib.py:133] step: 641750, training_loss: 2.65207e-02
I0211 03:41:26.113182 22542570456896 run_lib.py:133] step: 641800, training_loss: 3.29215e-02
I0211 03:41:26.287766 22542570456896 run_lib.py:146] step: 641800, eval_loss: 2.58389e-02
I0211 03:41:43.936891 22542570456896 run_lib.py:133] step: 641850, training_loss: 3.08859e-02
I0211 03:42:01.561430 22542570456896 run_lib.py:133] step: 641900, training_loss: 2.48712e-02
I0211 03:42:01.719855 22542570456896 run_lib.py:146] step: 641900, eval_loss: 2.04704e-02
I0211 03:42:19.197217 22542570456896 run_lib.py:133] step: 641950, training_loss: 2.95193e-02
I0211 03:42:36.651893 22542570456896 run_lib.py:133] step: 642000, training_loss: 3.12856e-02
I0211 03:42:36.808131 22542570456896 run_lib.py:146] step: 642000, eval_loss: 2.55696e-02
I0211 03:42:54.439133 22542570456896 run_lib.py:133] step: 642050, training_loss: 2.20050e-02
I0211 03:43:12.020728 22542570456896 run_lib.py:133] step: 642100, training_loss: 3.18993e-02
I0211 03:43:12.175199 22542570456896 run_lib.py:146] step: 642100, eval_loss: 3.56042e-02
I0211 03:43:29.744030 22542570456896 run_lib.py:133] step: 642150, training_loss: 2.92084e-02
I0211 03:43:47.196216 22542570456896 run_lib.py:133] step: 642200, training_loss: 2.74591e-02
I0211 03:43:47.349894 22542570456896 run_lib.py:146] step: 642200, eval_loss: 2.83460e-02
I0211 03:44:04.997320 22542570456896 run_lib.py:133] step: 642250, training_loss: 3.29312e-02
I0211 03:44:22.452195 22542570456896 run_lib.py:133] step: 642300, training_loss: 2.48520e-02
I0211 03:44:22.610703 22542570456896 run_lib.py:146] step: 642300, eval_loss: 3.04083e-02
I0211 03:44:40.252190 22542570456896 run_lib.py:133] step: 642350, training_loss: 3.19259e-02
I0211 03:44:57.794533 22542570456896 run_lib.py:133] step: 642400, training_loss: 2.79865e-02
I0211 03:44:57.955406 22542570456896 run_lib.py:146] step: 642400, eval_loss: 3.01680e-02
I0211 03:45:15.599527 22542570456896 run_lib.py:133] step: 642450, training_loss: 2.88597e-02
I0211 03:45:33.059942 22542570456896 run_lib.py:133] step: 642500, training_loss: 2.59675e-02
I0211 03:45:33.215934 22542570456896 run_lib.py:146] step: 642500, eval_loss: 2.63922e-02
I0211 03:45:50.674210 22542570456896 run_lib.py:133] step: 642550, training_loss: 2.41036e-02
I0211 03:46:08.294864 22542570456896 run_lib.py:133] step: 642600, training_loss: 2.26086e-02
I0211 03:46:08.447757 22542570456896 run_lib.py:146] step: 642600, eval_loss: 2.45770e-02
I0211 03:46:25.977590 22542570456896 run_lib.py:133] step: 642650, training_loss: 2.74034e-02
I0211 03:46:43.624072 22542570456896 run_lib.py:133] step: 642700, training_loss: 2.76172e-02
I0211 03:46:43.788557 22542570456896 run_lib.py:146] step: 642700, eval_loss: 3.20625e-02
I0211 03:47:01.301133 22542570456896 run_lib.py:133] step: 642750, training_loss: 2.41850e-02
I0211 03:47:18.785173 22542570456896 run_lib.py:133] step: 642800, training_loss: 2.75549e-02
I0211 03:47:18.942064 22542570456896 run_lib.py:146] step: 642800, eval_loss: 3.04619e-02
I0211 03:47:36.534710 22542570456896 run_lib.py:133] step: 642850, training_loss: 3.45452e-02
I0211 03:47:54.002954 22542570456896 run_lib.py:133] step: 642900, training_loss: 3.12275e-02
I0211 03:47:54.169785 22542570456896 run_lib.py:146] step: 642900, eval_loss: 3.06932e-02
I0211 03:48:11.710885 22542570456896 run_lib.py:133] step: 642950, training_loss: 2.32955e-02
I0211 03:48:29.191548 22542570456896 run_lib.py:133] step: 643000, training_loss: 2.63240e-02
I0211 03:48:29.347226 22542570456896 run_lib.py:146] step: 643000, eval_loss: 3.26002e-02
I0211 03:48:47.076189 22542570456896 run_lib.py:133] step: 643050, training_loss: 2.77440e-02
I0211 03:49:04.586251 22542570456896 run_lib.py:133] step: 643100, training_loss: 3.29118e-02
I0211 03:49:04.739361 22542570456896 run_lib.py:146] step: 643100, eval_loss: 2.80526e-02
I0211 03:49:22.311882 22542570456896 run_lib.py:133] step: 643150, training_loss: 2.86301e-02
I0211 03:49:39.799270 22542570456896 run_lib.py:133] step: 643200, training_loss: 3.32982e-02
I0211 03:49:39.968611 22542570456896 run_lib.py:146] step: 643200, eval_loss: 3.12390e-02
I0211 03:49:57.491264 22542570456896 run_lib.py:133] step: 643250, training_loss: 2.87647e-02
I0211 03:50:14.993565 22542570456896 run_lib.py:133] step: 643300, training_loss: 2.30102e-02
I0211 03:50:15.156428 22542570456896 run_lib.py:146] step: 643300, eval_loss: 2.31894e-02
I0211 03:50:32.810544 22542570456896 run_lib.py:133] step: 643350, training_loss: 3.48306e-02
I0211 03:50:50.363935 22542570456896 run_lib.py:133] step: 643400, training_loss: 2.58755e-02
I0211 03:50:50.521689 22542570456896 run_lib.py:146] step: 643400, eval_loss: 3.31978e-02
I0211 03:51:08.039495 22542570456896 run_lib.py:133] step: 643450, training_loss: 2.30981e-02
I0211 03:51:25.566088 22542570456896 run_lib.py:133] step: 643500, training_loss: 3.20175e-02
I0211 03:51:25.722692 22542570456896 run_lib.py:146] step: 643500, eval_loss: 3.51762e-02
I0211 03:51:43.440392 22542570456896 run_lib.py:133] step: 643550, training_loss: 2.82905e-02
I0211 03:52:00.905588 22542570456896 run_lib.py:133] step: 643600, training_loss: 3.64114e-02
I0211 03:52:01.057475 22542570456896 run_lib.py:146] step: 643600, eval_loss: 2.43304e-02
I0211 03:52:18.710701 22542570456896 run_lib.py:133] step: 643650, training_loss: 2.66872e-02
I0211 03:52:36.177911 22542570456896 run_lib.py:133] step: 643700, training_loss: 3.04722e-02
I0211 03:52:36.334588 22542570456896 run_lib.py:146] step: 643700, eval_loss: 2.95691e-02
I0211 03:52:53.954555 22542570456896 run_lib.py:133] step: 643750, training_loss: 2.44655e-02
I0211 03:53:11.520180 22542570456896 run_lib.py:133] step: 643800, training_loss: 2.83119e-02
I0211 03:53:11.682382 22542570456896 run_lib.py:146] step: 643800, eval_loss: 2.86366e-02
I0211 03:53:29.386536 22542570456896 run_lib.py:133] step: 643850, training_loss: 2.12435e-02
I0211 03:53:46.892148 22542570456896 run_lib.py:133] step: 643900, training_loss: 2.99994e-02
I0211 03:53:47.047097 22542570456896 run_lib.py:146] step: 643900, eval_loss: 2.11247e-02
I0211 03:54:04.557257 22542570456896 run_lib.py:133] step: 643950, training_loss: 3.05453e-02
I0211 03:54:22.218839 22542570456896 run_lib.py:133] step: 644000, training_loss: 2.96156e-02
I0211 03:54:22.378698 22542570456896 run_lib.py:146] step: 644000, eval_loss: 2.75755e-02
I0211 03:54:39.985481 22542570456896 run_lib.py:133] step: 644050, training_loss: 2.70382e-02
I0211 03:54:57.467664 22542570456896 run_lib.py:133] step: 644100, training_loss: 2.47371e-02
I0211 03:54:57.620174 22542570456896 run_lib.py:146] step: 644100, eval_loss: 3.16479e-02
I0211 03:55:15.265087 22542570456896 run_lib.py:133] step: 644150, training_loss: 2.94954e-02
I0211 03:55:32.903129 22542570456896 run_lib.py:133] step: 644200, training_loss: 3.00363e-02
I0211 03:55:33.162562 22542570456896 run_lib.py:146] step: 644200, eval_loss: 2.37835e-02
I0211 03:55:50.639606 22542570456896 run_lib.py:133] step: 644250, training_loss: 3.22497e-02
I0211 03:56:08.113794 22542570456896 run_lib.py:133] step: 644300, training_loss: 2.21921e-02
I0211 03:56:08.273111 22542570456896 run_lib.py:146] step: 644300, eval_loss: 2.19851e-02
I0211 03:56:25.793330 22542570456896 run_lib.py:133] step: 644350, training_loss: 2.91201e-02
I0211 03:56:43.559264 22542570456896 run_lib.py:133] step: 644400, training_loss: 2.36729e-02
I0211 03:56:43.716079 22542570456896 run_lib.py:146] step: 644400, eval_loss: 2.55340e-02
I0211 03:57:01.216452 22542570456896 run_lib.py:133] step: 644450, training_loss: 2.87558e-02
I0211 03:57:18.725772 22542570456896 run_lib.py:133] step: 644500, training_loss: 3.07957e-02
I0211 03:57:18.875653 22542570456896 run_lib.py:146] step: 644500, eval_loss: 2.71136e-02
I0211 03:57:36.339742 22542570456896 run_lib.py:133] step: 644550, training_loss: 2.38111e-02
I0211 03:57:53.975761 22542570456896 run_lib.py:133] step: 644600, training_loss: 2.62512e-02
I0211 03:57:54.135831 22542570456896 run_lib.py:146] step: 644600, eval_loss: 2.62829e-02
I0211 03:58:11.669345 22542570456896 run_lib.py:133] step: 644650, training_loss: 2.42073e-02
I0211 03:58:29.304079 22542570456896 run_lib.py:133] step: 644700, training_loss: 2.92606e-02
I0211 03:58:29.463927 22542570456896 run_lib.py:146] step: 644700, eval_loss: 2.85770e-02
I0211 03:58:46.909537 22542570456896 run_lib.py:133] step: 644750, training_loss: 3.36680e-02
I0211 03:59:04.401830 22542570456896 run_lib.py:133] step: 644800, training_loss: 2.79899e-02
I0211 03:59:04.558494 22542570456896 run_lib.py:146] step: 644800, eval_loss: 2.92151e-02
I0211 03:59:22.167972 22542570456896 run_lib.py:133] step: 644850, training_loss: 2.48470e-02
I0211 03:59:39.751578 22542570456896 run_lib.py:133] step: 644900, training_loss: 2.75430e-02
I0211 03:59:39.911680 22542570456896 run_lib.py:146] step: 644900, eval_loss: 2.77078e-02
I0211 03:59:57.449398 22542570456896 run_lib.py:133] step: 644950, training_loss: 2.80538e-02
I0211 04:00:14.913717 22542570456896 run_lib.py:133] step: 645000, training_loss: 3.15406e-02
I0211 04:00:15.066760 22542570456896 run_lib.py:146] step: 645000, eval_loss: 3.40256e-02
I0211 04:00:32.724139 22542570456896 run_lib.py:133] step: 645050, training_loss: 1.99948e-02
I0211 04:00:50.216053 22542570456896 run_lib.py:133] step: 645100, training_loss: 2.07119e-02
I0211 04:00:50.371349 22542570456896 run_lib.py:146] step: 645100, eval_loss: 3.15615e-02
I0211 04:01:07.978150 22542570456896 run_lib.py:133] step: 645150, training_loss: 3.10055e-02
I0211 04:01:25.490561 22542570456896 run_lib.py:133] step: 645200, training_loss: 2.37778e-02
I0211 04:01:25.663388 22542570456896 run_lib.py:146] step: 645200, eval_loss: 3.75966e-02
I0211 04:01:43.389284 22542570456896 run_lib.py:133] step: 645250, training_loss: 2.57446e-02
I0211 04:02:00.913079 22542570456896 run_lib.py:133] step: 645300, training_loss: 3.43264e-02
I0211 04:02:01.068558 22542570456896 run_lib.py:146] step: 645300, eval_loss: 3.34746e-02
I0211 04:02:18.558902 22542570456896 run_lib.py:133] step: 645350, training_loss: 2.62310e-02
I0211 04:02:36.174093 22542570456896 run_lib.py:133] step: 645400, training_loss: 3.21953e-02
I0211 04:02:36.335689 22542570456896 run_lib.py:146] step: 645400, eval_loss: 2.65991e-02
I0211 04:02:53.797845 22542570456896 run_lib.py:133] step: 645450, training_loss: 2.79091e-02
I0211 04:03:11.515333 22542570456896 run_lib.py:133] step: 645500, training_loss: 2.42812e-02
I0211 04:03:11.667277 22542570456896 run_lib.py:146] step: 645500, eval_loss: 2.67126e-02
I0211 04:03:29.184914 22542570456896 run_lib.py:133] step: 645550, training_loss: 2.50710e-02
I0211 04:03:46.677490 22542570456896 run_lib.py:133] step: 645600, training_loss: 2.55306e-02
I0211 04:03:46.835618 22542570456896 run_lib.py:146] step: 645600, eval_loss: 3.03963e-02
I0211 04:04:04.493269 22542570456896 run_lib.py:133] step: 645650, training_loss: 2.54718e-02
I0211 04:04:21.962983 22542570456896 run_lib.py:133] step: 645700, training_loss: 1.49918e-02
I0211 04:04:22.122737 22542570456896 run_lib.py:146] step: 645700, eval_loss: 2.61761e-02
I0211 04:04:39.585377 22542570456896 run_lib.py:133] step: 645750, training_loss: 2.64319e-02
I0211 04:04:57.316335 22542570456896 run_lib.py:133] step: 645800, training_loss: 2.73174e-02
I0211 04:04:57.484330 22542570456896 run_lib.py:146] step: 645800, eval_loss: 3.56685e-02
I0211 04:05:14.983476 22542570456896 run_lib.py:133] step: 645850, training_loss: 2.92581e-02
I0211 04:05:32.470460 22542570456896 run_lib.py:133] step: 645900, training_loss: 2.13248e-02
I0211 04:05:32.624367 22542570456896 run_lib.py:146] step: 645900, eval_loss: 2.31026e-02
I0211 04:05:50.169121 22542570456896 run_lib.py:133] step: 645950, training_loss: 2.71056e-02
I0211 04:06:07.666439 22542570456896 run_lib.py:133] step: 646000, training_loss: 2.12303e-02
I0211 04:06:07.821401 22542570456896 run_lib.py:146] step: 646000, eval_loss: 3.09176e-02
I0211 04:06:25.339877 22542570456896 run_lib.py:133] step: 646050, training_loss: 2.16282e-02
I0211 04:06:42.835437 22542570456896 run_lib.py:133] step: 646100, training_loss: 2.53986e-02
I0211 04:06:42.993462 22542570456896 run_lib.py:146] step: 646100, eval_loss: 2.95656e-02
I0211 04:07:00.583346 22542570456896 run_lib.py:133] step: 646150, training_loss: 2.52967e-02
I0211 04:07:18.038900 22542570456896 run_lib.py:133] step: 646200, training_loss: 2.73971e-02
I0211 04:07:18.199330 22542570456896 run_lib.py:146] step: 646200, eval_loss: 2.61654e-02
I0211 04:07:35.609576 22542570456896 run_lib.py:133] step: 646250, training_loss: 2.60110e-02
I0211 04:07:52.983489 22542570456896 run_lib.py:133] step: 646300, training_loss: 2.83992e-02
I0211 04:07:53.141757 22542570456896 run_lib.py:146] step: 646300, eval_loss: 2.50127e-02
I0211 04:08:10.796856 22542570456896 run_lib.py:133] step: 646350, training_loss: 2.46027e-02
I0211 04:08:28.354986 22542570456896 run_lib.py:133] step: 646400, training_loss: 2.56546e-02
I0211 04:08:28.510117 22542570456896 run_lib.py:146] step: 646400, eval_loss: 2.68559e-02
I0211 04:08:46.227132 22542570456896 run_lib.py:133] step: 646450, training_loss: 2.85632e-02
I0211 04:09:03.732903 22542570456896 run_lib.py:133] step: 646500, training_loss: 2.83804e-02
I0211 04:09:03.888464 22542570456896 run_lib.py:146] step: 646500, eval_loss: 3.75718e-02
I0211 04:09:21.531498 22542570456896 run_lib.py:133] step: 646550, training_loss: 2.91824e-02
I0211 04:09:39.051933 22542570456896 run_lib.py:133] step: 646600, training_loss: 2.49387e-02
I0211 04:09:39.228428 22542570456896 run_lib.py:146] step: 646600, eval_loss: 2.58304e-02
I0211 04:09:57.001797 22542570456896 run_lib.py:133] step: 646650, training_loss: 2.46670e-02
I0211 04:10:14.488785 22542570456896 run_lib.py:133] step: 646700, training_loss: 2.48744e-02
I0211 04:10:14.647060 22542570456896 run_lib.py:146] step: 646700, eval_loss: 2.91334e-02
I0211 04:10:32.119713 22542570456896 run_lib.py:133] step: 646750, training_loss: 2.93738e-02
I0211 04:10:49.708734 22542570456896 run_lib.py:133] step: 646800, training_loss: 3.03851e-02
I0211 04:10:49.863513 22542570456896 run_lib.py:146] step: 646800, eval_loss: 2.85388e-02
I0211 04:11:07.376179 22542570456896 run_lib.py:133] step: 646850, training_loss: 3.01213e-02
I0211 04:11:24.874760 22542570456896 run_lib.py:133] step: 646900, training_loss: 2.64272e-02
I0211 04:11:25.032712 22542570456896 run_lib.py:146] step: 646900, eval_loss: 3.07880e-02
I0211 04:11:42.745154 22542570456896 run_lib.py:133] step: 646950, training_loss: 2.97817e-02
I0211 04:12:00.245403 22542570456896 run_lib.py:133] step: 647000, training_loss: 2.43531e-02
I0211 04:12:00.421476 22542570456896 run_lib.py:146] step: 647000, eval_loss: 2.50275e-02
I0211 04:12:18.046061 22542570456896 run_lib.py:133] step: 647050, training_loss: 2.79042e-02
I0211 04:12:35.553547 22542570456896 run_lib.py:133] step: 647100, training_loss: 3.41759e-02
I0211 04:12:35.729418 22542570456896 run_lib.py:146] step: 647100, eval_loss: 2.35135e-02
I0211 04:12:53.272358 22542570456896 run_lib.py:133] step: 647150, training_loss: 3.52602e-02
I0211 04:13:10.975705 22542570456896 run_lib.py:133] step: 647200, training_loss: 2.62988e-02
I0211 04:13:11.131545 22542570456896 run_lib.py:146] step: 647200, eval_loss: 2.46358e-02
I0211 04:13:28.648809 22542570456896 run_lib.py:133] step: 647250, training_loss: 2.41605e-02
I0211 04:13:46.125408 22542570456896 run_lib.py:133] step: 647300, training_loss: 3.07139e-02
I0211 04:13:46.280634 22542570456896 run_lib.py:146] step: 647300, eval_loss: 2.54757e-02
I0211 04:14:03.794635 22542570456896 run_lib.py:133] step: 647350, training_loss: 2.79120e-02
I0211 04:14:21.542869 22542570456896 run_lib.py:133] step: 647400, training_loss: 2.23913e-02
I0211 04:14:21.724809 22542570456896 run_lib.py:146] step: 647400, eval_loss: 2.80219e-02
I0211 04:14:39.306103 22542570456896 run_lib.py:133] step: 647450, training_loss: 2.62420e-02
I0211 04:14:56.926139 22542570456896 run_lib.py:133] step: 647500, training_loss: 2.75142e-02
I0211 04:14:57.086204 22542570456896 run_lib.py:146] step: 647500, eval_loss: 3.14357e-02
I0211 04:15:14.531769 22542570456896 run_lib.py:133] step: 647550, training_loss: 2.17550e-02
I0211 04:15:32.022190 22542570456896 run_lib.py:133] step: 647600, training_loss: 3.35321e-02
I0211 04:15:32.187128 22542570456896 run_lib.py:146] step: 647600, eval_loss: 3.14916e-02
I0211 04:15:49.896180 22542570456896 run_lib.py:133] step: 647650, training_loss: 2.68755e-02
I0211 04:16:07.519809 22542570456896 run_lib.py:133] step: 647700, training_loss: 2.79963e-02
I0211 04:16:07.675430 22542570456896 run_lib.py:146] step: 647700, eval_loss: 2.49189e-02
I0211 04:16:25.174079 22542570456896 run_lib.py:133] step: 647750, training_loss: 2.13786e-02
I0211 04:16:42.672381 22542570456896 run_lib.py:133] step: 647800, training_loss: 2.71712e-02
I0211 04:16:42.826462 22542570456896 run_lib.py:146] step: 647800, eval_loss: 2.65523e-02
I0211 04:17:00.435054 22542570456896 run_lib.py:133] step: 647850, training_loss: 2.97718e-02
I0211 04:17:17.967440 22542570456896 run_lib.py:133] step: 647900, training_loss: 2.77726e-02
I0211 04:17:18.121092 22542570456896 run_lib.py:146] step: 647900, eval_loss: 2.67386e-02
I0211 04:17:35.812739 22542570456896 run_lib.py:133] step: 647950, training_loss: 3.32035e-02
I0211 04:17:53.318330 22542570456896 run_lib.py:133] step: 648000, training_loss: 3.76786e-02
I0211 04:17:53.476805 22542570456896 run_lib.py:146] step: 648000, eval_loss: 3.28687e-02
I0211 04:18:11.094959 22542570456896 run_lib.py:133] step: 648050, training_loss: 3.03916e-02
I0211 04:18:28.581650 22542570456896 run_lib.py:133] step: 648100, training_loss: 2.95865e-02
I0211 04:18:28.741639 22542570456896 run_lib.py:146] step: 648100, eval_loss: 3.17141e-02
I0211 04:18:46.231247 22542570456896 run_lib.py:133] step: 648150, training_loss: 2.85231e-02
I0211 04:19:03.965114 22542570456896 run_lib.py:133] step: 648200, training_loss: 2.61799e-02
I0211 04:19:04.121686 22542570456896 run_lib.py:146] step: 648200, eval_loss: 2.58292e-02
I0211 04:19:21.631649 22542570456896 run_lib.py:133] step: 648250, training_loss: 3.08153e-02
I0211 04:19:39.277636 22542570456896 run_lib.py:133] step: 648300, training_loss: 2.56497e-02
I0211 04:19:39.436125 22542570456896 run_lib.py:146] step: 648300, eval_loss: 2.98021e-02
I0211 04:19:56.898887 22542570456896 run_lib.py:133] step: 648350, training_loss: 3.13101e-02
I0211 04:20:14.394541 22542570456896 run_lib.py:133] step: 648400, training_loss: 3.11484e-02
I0211 04:20:14.572243 22542570456896 run_lib.py:146] step: 648400, eval_loss: 3.01448e-02
I0211 04:20:32.268550 22542570456896 run_lib.py:133] step: 648450, training_loss: 3.24531e-02
I0211 04:20:49.844464 22542570456896 run_lib.py:133] step: 648500, training_loss: 2.45111e-02
I0211 04:20:50.003293 22542570456896 run_lib.py:146] step: 648500, eval_loss: 2.35484e-02
I0211 04:21:07.461239 22542570456896 run_lib.py:133] step: 648550, training_loss: 2.08773e-02
I0211 04:21:25.167674 22542570456896 run_lib.py:133] step: 648600, training_loss: 2.94024e-02
I0211 04:21:25.326193 22542570456896 run_lib.py:146] step: 648600, eval_loss: 2.68865e-02
I0211 04:21:42.815337 22542570456896 run_lib.py:133] step: 648650, training_loss: 2.81832e-02
I0211 04:22:00.291905 22542570456896 run_lib.py:133] step: 648700, training_loss: 2.34299e-02
I0211 04:22:00.591167 22542570456896 run_lib.py:146] step: 648700, eval_loss: 2.11312e-02
I0211 04:22:18.168226 22542570456896 run_lib.py:133] step: 648750, training_loss: 2.88302e-02
I0211 04:22:35.676828 22542570456896 run_lib.py:133] step: 648800, training_loss: 3.12243e-02
I0211 04:22:35.833464 22542570456896 run_lib.py:146] step: 648800, eval_loss: 2.78168e-02
I0211 04:22:53.308262 22542570456896 run_lib.py:133] step: 648850, training_loss: 3.15681e-02
I0211 04:23:10.777530 22542570456896 run_lib.py:133] step: 648900, training_loss: 2.23362e-02
I0211 04:23:10.940431 22542570456896 run_lib.py:146] step: 648900, eval_loss: 2.39995e-02
I0211 04:23:28.620029 22542570456896 run_lib.py:133] step: 648950, training_loss: 2.99092e-02
I0211 04:23:46.250482 22542570456896 run_lib.py:133] step: 649000, training_loss: 2.67697e-02
I0211 04:23:46.422668 22542570456896 run_lib.py:146] step: 649000, eval_loss: 3.05239e-02
I0211 04:24:03.861662 22542570456896 run_lib.py:133] step: 649050, training_loss: 2.91341e-02
I0211 04:24:21.372989 22542570456896 run_lib.py:133] step: 649100, training_loss: 2.28523e-02
I0211 04:24:21.529904 22542570456896 run_lib.py:146] step: 649100, eval_loss: 2.72734e-02
I0211 04:24:39.235330 22542570456896 run_lib.py:133] step: 649150, training_loss: 3.13998e-02
I0211 04:24:56.761366 22542570456896 run_lib.py:133] step: 649200, training_loss: 2.42841e-02
I0211 04:24:56.924575 22542570456896 run_lib.py:146] step: 649200, eval_loss: 3.34245e-02
I0211 04:25:14.430676 22542570456896 run_lib.py:133] step: 649250, training_loss: 2.83440e-02
I0211 04:25:31.970102 22542570456896 run_lib.py:133] step: 649300, training_loss: 3.11475e-02
I0211 04:25:32.125716 22542570456896 run_lib.py:146] step: 649300, eval_loss: 2.90524e-02
I0211 04:25:49.827972 22542570456896 run_lib.py:133] step: 649350, training_loss: 3.13646e-02
I0211 04:26:07.336584 22542570456896 run_lib.py:133] step: 649400, training_loss: 2.49898e-02
I0211 04:26:07.495696 22542570456896 run_lib.py:146] step: 649400, eval_loss: 3.09407e-02
I0211 04:26:25.101527 22542570456896 run_lib.py:133] step: 649450, training_loss: 2.71292e-02
I0211 04:26:42.542862 22542570456896 run_lib.py:133] step: 649500, training_loss: 2.56194e-02
I0211 04:26:42.704341 22542570456896 run_lib.py:146] step: 649500, eval_loss: 2.95400e-02
I0211 04:27:00.395947 22542570456896 run_lib.py:133] step: 649550, training_loss: 2.89997e-02
I0211 04:27:17.966666 22542570456896 run_lib.py:133] step: 649600, training_loss: 2.37620e-02
I0211 04:27:18.129575 22542570456896 run_lib.py:146] step: 649600, eval_loss: 3.13857e-02
I0211 04:27:35.606566 22542570456896 run_lib.py:133] step: 649650, training_loss: 2.78881e-02
I0211 04:27:53.213522 22542570456896 run_lib.py:133] step: 649700, training_loss: 3.45821e-02
I0211 04:27:53.366527 22542570456896 run_lib.py:146] step: 649700, eval_loss: 3.29903e-02
I0211 04:28:10.845308 22542570456896 run_lib.py:133] step: 649750, training_loss: 2.18417e-02
I0211 04:28:28.520643 22542570456896 run_lib.py:133] step: 649800, training_loss: 2.00054e-02
I0211 04:28:28.683963 22542570456896 run_lib.py:146] step: 649800, eval_loss: 2.82746e-02
I0211 04:28:46.211442 22542570456896 run_lib.py:133] step: 649850, training_loss: 2.72941e-02
I0211 04:29:03.683563 22542570456896 run_lib.py:133] step: 649900, training_loss: 3.11971e-02
I0211 04:29:03.842784 22542570456896 run_lib.py:146] step: 649900, eval_loss: 3.04343e-02
I0211 04:29:21.517199 22542570456896 run_lib.py:133] step: 649950, training_loss: 2.60114e-02
I0211 04:29:38.996767 22542570456896 run_lib.py:133] step: 650000, training_loss: 2.93130e-02
I0211 04:29:39.715478 22542570456896 run_lib.py:146] step: 650000, eval_loss: 3.23722e-02
I0211 04:29:59.998790 22542570456896 run_lib.py:133] step: 650050, training_loss: 2.88321e-02
I0211 04:30:17.652043 22542570456896 run_lib.py:133] step: 650100, training_loss: 2.89294e-02
I0211 04:30:17.817666 22542570456896 run_lib.py:146] step: 650100, eval_loss: 3.03459e-02
I0211 04:30:35.275084 22542570456896 run_lib.py:133] step: 650150, training_loss: 3.03935e-02
I0211 04:30:52.764892 22542570456896 run_lib.py:133] step: 650200, training_loss: 2.70412e-02
I0211 04:30:52.920230 22542570456896 run_lib.py:146] step: 650200, eval_loss: 3.46957e-02
I0211 04:31:10.566106 22542570456896 run_lib.py:133] step: 650250, training_loss: 2.98495e-02
I0211 04:31:28.121777 22542570456896 run_lib.py:133] step: 650300, training_loss: 3.04282e-02
I0211 04:31:28.277092 22542570456896 run_lib.py:146] step: 650300, eval_loss: 2.68278e-02
I0211 04:31:45.849996 22542570456896 run_lib.py:133] step: 650350, training_loss: 2.91796e-02
I0211 04:32:03.343497 22542570456896 run_lib.py:133] step: 650400, training_loss: 2.76448e-02
I0211 04:32:03.500468 22542570456896 run_lib.py:146] step: 650400, eval_loss: 2.89802e-02
I0211 04:32:21.131729 22542570456896 run_lib.py:133] step: 650450, training_loss: 2.13422e-02
I0211 04:32:38.619379 22542570456896 run_lib.py:133] step: 650500, training_loss: 2.82365e-02
I0211 04:32:38.777798 22542570456896 run_lib.py:146] step: 650500, eval_loss: 3.14783e-02
I0211 04:32:56.491125 22542570456896 run_lib.py:133] step: 650550, training_loss: 2.64688e-02
I0211 04:33:13.953217 22542570456896 run_lib.py:133] step: 650600, training_loss: 2.27997e-02
I0211 04:33:14.134302 22542570456896 run_lib.py:146] step: 650600, eval_loss: 3.01690e-02
I0211 04:33:31.851358 22542570456896 run_lib.py:133] step: 650650, training_loss: 2.67306e-02
I0211 04:33:49.350879 22542570456896 run_lib.py:133] step: 650700, training_loss: 2.83304e-02
I0211 04:33:49.504859 22542570456896 run_lib.py:146] step: 650700, eval_loss: 2.75631e-02
I0211 04:34:07.015272 22542570456896 run_lib.py:133] step: 650750, training_loss: 2.46972e-02
I0211 04:34:24.661972 22542570456896 run_lib.py:133] step: 650800, training_loss: 3.00544e-02
I0211 04:34:24.813477 22542570456896 run_lib.py:146] step: 650800, eval_loss: 2.51783e-02
I0211 04:34:42.289046 22542570456896 run_lib.py:133] step: 650850, training_loss: 3.04404e-02
I0211 04:34:59.896364 22542570456896 run_lib.py:133] step: 650900, training_loss: 2.88885e-02
I0211 04:35:00.071501 22542570456896 run_lib.py:146] step: 650900, eval_loss: 2.53180e-02
I0211 04:35:17.612255 22542570456896 run_lib.py:133] step: 650950, training_loss: 3.08137e-02
I0211 04:35:35.118563 22542570456896 run_lib.py:133] step: 651000, training_loss: 2.73363e-02
I0211 04:35:35.275514 22542570456896 run_lib.py:146] step: 651000, eval_loss: 4.03793e-02
I0211 04:35:52.973484 22542570456896 run_lib.py:133] step: 651050, training_loss: 2.86629e-02
I0211 04:36:10.399983 22542570456896 run_lib.py:133] step: 651100, training_loss: 2.90655e-02
I0211 04:36:10.556421 22542570456896 run_lib.py:146] step: 651100, eval_loss: 2.94156e-02
I0211 04:36:28.017938 22542570456896 run_lib.py:133] step: 651150, training_loss: 2.43629e-02
I0211 04:36:45.525134 22542570456896 run_lib.py:133] step: 651200, training_loss: 2.49628e-02
I0211 04:36:45.687518 22542570456896 run_lib.py:146] step: 651200, eval_loss: 2.53584e-02
I0211 04:37:03.394182 22542570456896 run_lib.py:133] step: 651250, training_loss: 3.34510e-02
I0211 04:37:20.839562 22542570456896 run_lib.py:133] step: 651300, training_loss: 2.81841e-02
I0211 04:37:20.991712 22542570456896 run_lib.py:146] step: 651300, eval_loss: 3.25096e-02
I0211 04:37:38.565712 22542570456896 run_lib.py:133] step: 651350, training_loss: 2.75056e-02
I0211 04:37:56.041640 22542570456896 run_lib.py:133] step: 651400, training_loss: 2.03368e-02
I0211 04:37:56.215841 22542570456896 run_lib.py:146] step: 651400, eval_loss: 2.52209e-02
I0211 04:38:13.696289 22542570456896 run_lib.py:133] step: 651450, training_loss: 2.89665e-02
I0211 04:38:31.217854 22542570456896 run_lib.py:133] step: 651500, training_loss: 2.47722e-02
I0211 04:38:31.374714 22542570456896 run_lib.py:146] step: 651500, eval_loss: 3.05087e-02
I0211 04:38:49.031103 22542570456896 run_lib.py:133] step: 651550, training_loss: 3.17126e-02
I0211 04:39:06.530475 22542570456896 run_lib.py:133] step: 651600, training_loss: 3.49578e-02
I0211 04:39:06.686601 22542570456896 run_lib.py:146] step: 651600, eval_loss: 2.84469e-02
I0211 04:39:24.155283 22542570456896 run_lib.py:133] step: 651650, training_loss: 2.82644e-02
I0211 04:39:41.576179 22542570456896 run_lib.py:133] step: 651700, training_loss: 3.11998e-02
I0211 04:39:41.735769 22542570456896 run_lib.py:146] step: 651700, eval_loss: 2.49765e-02
I0211 04:39:59.398205 22542570456896 run_lib.py:133] step: 651750, training_loss: 2.39255e-02
I0211 04:40:16.893643 22542570456896 run_lib.py:133] step: 651800, training_loss: 2.76468e-02
I0211 04:40:17.050574 22542570456896 run_lib.py:146] step: 651800, eval_loss: 2.32083e-02
I0211 04:40:34.717816 22542570456896 run_lib.py:133] step: 651850, training_loss: 2.84687e-02
I0211 04:40:52.199198 22542570456896 run_lib.py:133] step: 651900, training_loss: 2.21850e-02
I0211 04:40:52.359863 22542570456896 run_lib.py:146] step: 651900, eval_loss: 2.58961e-02
I0211 04:41:09.979575 22542570456896 run_lib.py:133] step: 651950, training_loss: 2.30268e-02
I0211 04:41:27.446873 22542570456896 run_lib.py:133] step: 652000, training_loss: 2.78457e-02
I0211 04:41:27.613255 22542570456896 run_lib.py:146] step: 652000, eval_loss: 2.84328e-02
I0211 04:41:45.277097 22542570456896 run_lib.py:133] step: 652050, training_loss: 2.88191e-02
I0211 04:42:02.763127 22542570456896 run_lib.py:133] step: 652100, training_loss: 2.55283e-02
I0211 04:42:02.919648 22542570456896 run_lib.py:146] step: 652100, eval_loss: 2.87503e-02
I0211 04:42:20.436949 22542570456896 run_lib.py:133] step: 652150, training_loss: 2.88104e-02
I0211 04:42:38.082957 22542570456896 run_lib.py:133] step: 652200, training_loss: 2.48556e-02
I0211 04:42:38.262535 22542570456896 run_lib.py:146] step: 652200, eval_loss: 2.83871e-02
I0211 04:42:55.753168 22542570456896 run_lib.py:133] step: 652250, training_loss: 2.61727e-02
I0211 04:43:13.212466 22542570456896 run_lib.py:133] step: 652300, training_loss: 2.69246e-02
I0211 04:43:13.381196 22542570456896 run_lib.py:146] step: 652300, eval_loss: 2.53112e-02
I0211 04:43:31.048466 22542570456896 run_lib.py:133] step: 652350, training_loss: 2.91001e-02
I0211 04:43:48.721423 22542570456896 run_lib.py:133] step: 652400, training_loss: 2.70006e-02
I0211 04:43:48.881455 22542570456896 run_lib.py:146] step: 652400, eval_loss: 2.65314e-02
I0211 04:44:06.320147 22542570456896 run_lib.py:133] step: 652450, training_loss: 2.63028e-02
I0211 04:44:23.804815 22542570456896 run_lib.py:133] step: 652500, training_loss: 2.22518e-02
I0211 04:44:23.960709 22542570456896 run_lib.py:146] step: 652500, eval_loss: 2.32117e-02
I0211 04:44:41.468090 22542570456896 run_lib.py:133] step: 652550, training_loss: 3.05959e-02
I0211 04:44:59.146646 22542570456896 run_lib.py:133] step: 652600, training_loss: 2.94915e-02
I0211 04:44:59.299555 22542570456896 run_lib.py:146] step: 652600, eval_loss: 2.59857e-02
I0211 04:45:16.837528 22542570456896 run_lib.py:133] step: 652650, training_loss: 2.66283e-02
I0211 04:45:34.334390 22542570456896 run_lib.py:133] step: 652700, training_loss: 2.62064e-02
I0211 04:45:34.486329 22542570456896 run_lib.py:146] step: 652700, eval_loss: 2.83114e-02
I0211 04:45:51.927230 22542570456896 run_lib.py:133] step: 652750, training_loss: 2.50144e-02
I0211 04:46:09.610690 22542570456896 run_lib.py:133] step: 652800, training_loss: 2.55811e-02
I0211 04:46:09.769557 22542570456896 run_lib.py:146] step: 652800, eval_loss: 2.93836e-02
I0211 04:46:27.236761 22542570456896 run_lib.py:133] step: 652850, training_loss: 2.33434e-02
I0211 04:46:44.884243 22542570456896 run_lib.py:133] step: 652900, training_loss: 3.33158e-02
I0211 04:46:45.057648 22542570456896 run_lib.py:146] step: 652900, eval_loss: 2.59045e-02
I0211 04:47:02.509259 22542570456896 run_lib.py:133] step: 652950, training_loss: 2.76864e-02
I0211 04:47:19.962736 22542570456896 run_lib.py:133] step: 653000, training_loss: 2.01364e-02
I0211 04:47:20.118208 22542570456896 run_lib.py:146] step: 653000, eval_loss: 2.84629e-02
I0211 04:47:37.746116 22542570456896 run_lib.py:133] step: 653050, training_loss: 2.64312e-02
I0211 04:47:55.274390 22542570456896 run_lib.py:133] step: 653100, training_loss: 2.86411e-02
I0211 04:47:55.428467 22542570456896 run_lib.py:146] step: 653100, eval_loss: 2.85178e-02
I0211 04:48:12.948806 22542570456896 run_lib.py:133] step: 653150, training_loss: 3.11658e-02
I0211 04:48:30.438018 22542570456896 run_lib.py:133] step: 653200, training_loss: 2.61605e-02
I0211 04:48:30.594995 22542570456896 run_lib.py:146] step: 653200, eval_loss: 2.92598e-02
I0211 04:48:48.259156 22542570456896 run_lib.py:133] step: 653250, training_loss: 2.68261e-02
I0211 04:49:05.749782 22542570456896 run_lib.py:133] step: 653300, training_loss: 2.20851e-02
I0211 04:49:05.911749 22542570456896 run_lib.py:146] step: 653300, eval_loss: 4.12101e-02
I0211 04:49:23.563800 22542570456896 run_lib.py:133] step: 653350, training_loss: 3.20846e-02
I0211 04:49:41.095767 22542570456896 run_lib.py:133] step: 653400, training_loss: 2.46920e-02
I0211 04:49:41.261481 22542570456896 run_lib.py:146] step: 653400, eval_loss: 2.50379e-02
I0211 04:49:58.914455 22542570456896 run_lib.py:133] step: 653450, training_loss: 2.65234e-02
I0211 04:50:16.358519 22542570456896 run_lib.py:133] step: 653500, training_loss: 2.90896e-02
I0211 04:50:16.513262 22542570456896 run_lib.py:146] step: 653500, eval_loss: 2.51435e-02
I0211 04:50:33.970006 22542570456896 run_lib.py:133] step: 653550, training_loss: 2.87416e-02
I0211 04:50:51.576579 22542570456896 run_lib.py:133] step: 653600, training_loss: 2.35763e-02
I0211 04:50:51.728492 22542570456896 run_lib.py:146] step: 653600, eval_loss: 2.31113e-02
I0211 04:51:09.205116 22542570456896 run_lib.py:133] step: 653650, training_loss: 2.80993e-02
I0211 04:51:26.874303 22542570456896 run_lib.py:133] step: 653700, training_loss: 2.62182e-02
I0211 04:51:27.038946 22542570456896 run_lib.py:146] step: 653700, eval_loss: 3.01201e-02
I0211 04:51:44.482398 22542570456896 run_lib.py:133] step: 653750, training_loss: 2.27775e-02
I0211 04:52:01.981945 22542570456896 run_lib.py:133] step: 653800, training_loss: 2.59405e-02
I0211 04:52:02.147469 22542570456896 run_lib.py:146] step: 653800, eval_loss: 2.62061e-02
I0211 04:52:19.769395 22542570456896 run_lib.py:133] step: 653850, training_loss: 2.82929e-02
I0211 04:52:37.254590 22542570456896 run_lib.py:133] step: 653900, training_loss: 2.85771e-02
I0211 04:52:37.417674 22542570456896 run_lib.py:146] step: 653900, eval_loss: 2.63100e-02
I0211 04:52:54.870113 22542570456896 run_lib.py:133] step: 653950, training_loss: 2.40756e-02
I0211 04:53:12.566008 22542570456896 run_lib.py:133] step: 654000, training_loss: 2.46363e-02
I0211 04:53:12.723691 22542570456896 run_lib.py:146] step: 654000, eval_loss: 2.47126e-02
I0211 04:53:30.249577 22542570456896 run_lib.py:133] step: 654050, training_loss: 2.48399e-02
I0211 04:53:47.719448 22542570456896 run_lib.py:133] step: 654100, training_loss: 3.53837e-02
I0211 04:53:47.872548 22542570456896 run_lib.py:146] step: 654100, eval_loss: 2.71073e-02
I0211 04:54:05.400975 22542570456896 run_lib.py:133] step: 654150, training_loss: 2.65152e-02
I0211 04:54:22.854401 22542570456896 run_lib.py:133] step: 654200, training_loss: 2.71801e-02
I0211 04:54:23.011573 22542570456896 run_lib.py:146] step: 654200, eval_loss: 2.80969e-02
I0211 04:54:40.523222 22542570456896 run_lib.py:133] step: 654250, training_loss: 2.63943e-02
I0211 04:54:58.088007 22542570456896 run_lib.py:133] step: 654300, training_loss: 2.10351e-02
I0211 04:54:58.247731 22542570456896 run_lib.py:146] step: 654300, eval_loss: 2.32083e-02
I0211 04:55:15.883566 22542570456896 run_lib.py:133] step: 654350, training_loss: 2.85128e-02
I0211 04:55:33.436063 22542570456896 run_lib.py:133] step: 654400, training_loss: 2.75175e-02
I0211 04:55:33.591287 22542570456896 run_lib.py:146] step: 654400, eval_loss: 3.68440e-02
I0211 04:55:51.083092 22542570456896 run_lib.py:133] step: 654450, training_loss: 2.95649e-02
I0211 04:56:08.566752 22542570456896 run_lib.py:133] step: 654500, training_loss: 2.55871e-02
I0211 04:56:08.719974 22542570456896 run_lib.py:146] step: 654500, eval_loss: 2.56386e-02
I0211 04:56:26.328018 22542570456896 run_lib.py:133] step: 654550, training_loss: 2.58574e-02
I0211 04:56:43.834998 22542570456896 run_lib.py:133] step: 654600, training_loss: 2.70764e-02
I0211 04:56:43.998361 22542570456896 run_lib.py:146] step: 654600, eval_loss: 2.63988e-02
I0211 04:57:01.737947 22542570456896 run_lib.py:133] step: 654650, training_loss: 3.51061e-02
I0211 04:57:19.227757 22542570456896 run_lib.py:133] step: 654700, training_loss: 2.83654e-02
I0211 04:57:19.384577 22542570456896 run_lib.py:146] step: 654700, eval_loss: 2.77711e-02
I0211 04:57:36.971313 22542570456896 run_lib.py:133] step: 654750, training_loss: 2.96824e-02
I0211 04:57:54.413723 22542570456896 run_lib.py:133] step: 654800, training_loss: 2.63761e-02
I0211 04:57:54.569860 22542570456896 run_lib.py:146] step: 654800, eval_loss: 2.51906e-02
I0211 04:58:12.204416 22542570456896 run_lib.py:133] step: 654850, training_loss: 3.53026e-02
I0211 04:58:29.745693 22542570456896 run_lib.py:133] step: 654900, training_loss: 2.47842e-02
I0211 04:58:29.899043 22542570456896 run_lib.py:146] step: 654900, eval_loss: 3.03574e-02
I0211 04:58:47.391191 22542570456896 run_lib.py:133] step: 654950, training_loss: 3.36718e-02
I0211 04:59:05.041366 22542570456896 run_lib.py:133] step: 655000, training_loss: 3.67630e-02
I0211 04:59:05.199160 22542570456896 run_lib.py:146] step: 655000, eval_loss: 2.82317e-02
I0211 04:59:22.690009 22542570456896 run_lib.py:133] step: 655050, training_loss: 2.42585e-02
I0211 04:59:40.194406 22542570456896 run_lib.py:133] step: 655100, training_loss: 2.53859e-02
I0211 04:59:40.361592 22542570456896 run_lib.py:146] step: 655100, eval_loss: 2.63567e-02
I0211 04:59:58.024824 22542570456896 run_lib.py:133] step: 655150, training_loss: 2.54211e-02
I0211 05:00:15.516469 22542570456896 run_lib.py:133] step: 655200, training_loss: 2.55319e-02
I0211 05:00:15.678427 22542570456896 run_lib.py:146] step: 655200, eval_loss: 2.47194e-02
I0211 05:00:33.354602 22542570456896 run_lib.py:133] step: 655250, training_loss: 2.31107e-02
I0211 05:00:50.824106 22542570456896 run_lib.py:133] step: 655300, training_loss: 2.51840e-02
I0211 05:00:50.981847 22542570456896 run_lib.py:146] step: 655300, eval_loss: 3.09659e-02
I0211 05:01:08.496606 22542570456896 run_lib.py:133] step: 655350, training_loss: 2.72804e-02
I0211 05:01:26.143723 22542570456896 run_lib.py:133] step: 655400, training_loss: 2.47111e-02
I0211 05:01:26.312606 22542570456896 run_lib.py:146] step: 655400, eval_loss: 2.96535e-02
I0211 05:01:43.864922 22542570456896 run_lib.py:133] step: 655450, training_loss: 2.38990e-02
I0211 05:02:01.385125 22542570456896 run_lib.py:133] step: 655500, training_loss: 2.97673e-02
I0211 05:02:01.539102 22542570456896 run_lib.py:146] step: 655500, eval_loss: 3.37421e-02
I0211 05:02:19.030255 22542570456896 run_lib.py:133] step: 655550, training_loss: 2.42247e-02
I0211 05:02:36.690088 22542570456896 run_lib.py:133] step: 655600, training_loss: 2.14317e-02
I0211 05:02:36.854566 22542570456896 run_lib.py:146] step: 655600, eval_loss: 2.81770e-02
I0211 05:02:54.330505 22542570456896 run_lib.py:133] step: 655650, training_loss: 2.96009e-02
I0211 05:03:11.910866 22542570456896 run_lib.py:133] step: 655700, training_loss: 2.59267e-02
I0211 05:03:12.068952 22542570456896 run_lib.py:146] step: 655700, eval_loss: 3.44084e-02
I0211 05:03:29.568645 22542570456896 run_lib.py:133] step: 655750, training_loss: 2.66464e-02
I0211 05:03:47.106580 22542570456896 run_lib.py:133] step: 655800, training_loss: 2.51062e-02
I0211 05:03:47.266569 22542570456896 run_lib.py:146] step: 655800, eval_loss: 2.50294e-02
I0211 05:04:04.967210 22542570456896 run_lib.py:133] step: 655850, training_loss: 3.08800e-02
I0211 05:04:22.510952 22542570456896 run_lib.py:133] step: 655900, training_loss: 3.10563e-02
I0211 05:04:22.669307 22542570456896 run_lib.py:146] step: 655900, eval_loss: 2.53946e-02
I0211 05:04:40.162285 22542570456896 run_lib.py:133] step: 655950, training_loss: 2.82895e-02
I0211 05:04:57.645859 22542570456896 run_lib.py:133] step: 656000, training_loss: 2.36885e-02
I0211 05:04:57.799575 22542570456896 run_lib.py:146] step: 656000, eval_loss: 3.18503e-02
I0211 05:05:15.489090 22542570456896 run_lib.py:133] step: 656050, training_loss: 1.76172e-02
I0211 05:05:32.971920 22542570456896 run_lib.py:133] step: 656100, training_loss: 2.41873e-02
I0211 05:05:33.134302 22542570456896 run_lib.py:146] step: 656100, eval_loss: 3.39593e-02
I0211 05:05:50.812722 22542570456896 run_lib.py:133] step: 656150, training_loss: 2.85987e-02
I0211 05:06:08.274392 22542570456896 run_lib.py:133] step: 656200, training_loss: 2.92241e-02
I0211 05:06:08.436326 22542570456896 run_lib.py:146] step: 656200, eval_loss: 1.98514e-02
I0211 05:06:26.085951 22542570456896 run_lib.py:133] step: 656250, training_loss: 2.92468e-02
I0211 05:06:43.621887 22542570456896 run_lib.py:133] step: 656300, training_loss: 2.70590e-02
I0211 05:06:43.785704 22542570456896 run_lib.py:146] step: 656300, eval_loss: 2.47934e-02
I0211 05:07:01.263728 22542570456896 run_lib.py:133] step: 656350, training_loss: 1.81504e-02
I0211 05:07:18.902479 22542570456896 run_lib.py:133] step: 656400, training_loss: 2.47008e-02
I0211 05:07:19.057399 22542570456896 run_lib.py:146] step: 656400, eval_loss: 3.75274e-02
I0211 05:07:36.561074 22542570456896 run_lib.py:133] step: 656450, training_loss: 2.17375e-02
I0211 05:07:54.227256 22542570456896 run_lib.py:133] step: 656500, training_loss: 2.74734e-02
I0211 05:07:54.380558 22542570456896 run_lib.py:146] step: 656500, eval_loss: 2.79100e-02
I0211 05:08:11.818955 22542570456896 run_lib.py:133] step: 656550, training_loss: 2.35214e-02
I0211 05:08:29.227678 22542570456896 run_lib.py:133] step: 656600, training_loss: 2.97955e-02
I0211 05:08:29.405235 22542570456896 run_lib.py:146] step: 656600, eval_loss: 2.97007e-02
I0211 05:08:47.012937 22542570456896 run_lib.py:133] step: 656650, training_loss: 2.89936e-02
I0211 05:09:04.464410 22542570456896 run_lib.py:133] step: 656700, training_loss: 2.86550e-02
I0211 05:09:04.620651 22542570456896 run_lib.py:146] step: 656700, eval_loss: 3.14831e-02
I0211 05:09:22.055882 22542570456896 run_lib.py:133] step: 656750, training_loss: 2.56938e-02
I0211 05:09:39.619903 22542570456896 run_lib.py:133] step: 656800, training_loss: 2.88949e-02
I0211 05:09:39.776097 22542570456896 run_lib.py:146] step: 656800, eval_loss: 3.82779e-02
I0211 05:09:57.195376 22542570456896 run_lib.py:133] step: 656850, training_loss: 2.69381e-02
I0211 05:10:14.613615 22542570456896 run_lib.py:133] step: 656900, training_loss: 3.52042e-02
I0211 05:10:14.916811 22542570456896 run_lib.py:146] step: 656900, eval_loss: 2.58430e-02
I0211 05:10:32.346817 22542570456896 run_lib.py:133] step: 656950, training_loss: 2.91942e-02
I0211 05:10:49.776400 22542570456896 run_lib.py:133] step: 657000, training_loss: 2.55069e-02
I0211 05:10:49.930437 22542570456896 run_lib.py:146] step: 657000, eval_loss: 2.46986e-02
I0211 05:11:07.327158 22542570456896 run_lib.py:133] step: 657050, training_loss: 2.11486e-02
I0211 05:11:24.702958 22542570456896 run_lib.py:133] step: 657100, training_loss: 2.74038e-02
I0211 05:11:24.861061 22542570456896 run_lib.py:146] step: 657100, eval_loss: 2.42419e-02
I0211 05:11:42.419709 22542570456896 run_lib.py:133] step: 657150, training_loss: 2.52423e-02
I0211 05:11:59.936685 22542570456896 run_lib.py:133] step: 657200, training_loss: 2.17803e-02
I0211 05:12:00.096502 22542570456896 run_lib.py:146] step: 657200, eval_loss: 2.93643e-02
I0211 05:12:17.511347 22542570456896 run_lib.py:133] step: 657250, training_loss: 2.80349e-02
I0211 05:12:34.893007 22542570456896 run_lib.py:133] step: 657300, training_loss: 3.11431e-02
I0211 05:12:35.057527 22542570456896 run_lib.py:146] step: 657300, eval_loss: 2.78218e-02
I0211 05:12:52.674155 22542570456896 run_lib.py:133] step: 657350, training_loss: 3.56332e-02
I0211 05:13:10.142608 22542570456896 run_lib.py:133] step: 657400, training_loss: 3.40311e-02
I0211 05:13:10.295070 22542570456896 run_lib.py:146] step: 657400, eval_loss: 2.69037e-02
I0211 05:13:27.696289 22542570456896 run_lib.py:133] step: 657450, training_loss: 3.06326e-02
I0211 05:13:45.120601 22542570456896 run_lib.py:133] step: 657500, training_loss: 3.27121e-02
I0211 05:13:45.297567 22542570456896 run_lib.py:146] step: 657500, eval_loss: 3.30681e-02
I0211 05:14:02.913244 22542570456896 run_lib.py:133] step: 657550, training_loss: 2.59395e-02
I0211 05:14:20.363082 22542570456896 run_lib.py:133] step: 657600, training_loss: 2.74718e-02
I0211 05:14:20.526415 22542570456896 run_lib.py:146] step: 657600, eval_loss: 2.87052e-02
I0211 05:14:38.055376 22542570456896 run_lib.py:133] step: 657650, training_loss: 2.67114e-02
I0211 05:14:55.435122 22542570456896 run_lib.py:133] step: 657700, training_loss: 3.15999e-02
I0211 05:14:55.592159 22542570456896 run_lib.py:146] step: 657700, eval_loss: 2.91252e-02
I0211 05:15:13.114100 22542570456896 run_lib.py:133] step: 657750, training_loss: 2.70534e-02
I0211 05:15:30.543588 22542570456896 run_lib.py:133] step: 657800, training_loss: 2.97552e-02
I0211 05:15:30.699601 22542570456896 run_lib.py:146] step: 657800, eval_loss: 3.60194e-02
I0211 05:15:48.166214 22542570456896 run_lib.py:133] step: 657850, training_loss: 2.63688e-02
I0211 05:16:05.709616 22542570456896 run_lib.py:133] step: 657900, training_loss: 2.84070e-02
I0211 05:16:05.860986 22542570456896 run_lib.py:146] step: 657900, eval_loss: 2.48951e-02
I0211 05:16:23.165734 22542570456896 run_lib.py:133] step: 657950, training_loss: 2.69442e-02
I0211 05:16:40.629446 22542570456896 run_lib.py:133] step: 658000, training_loss: 2.53932e-02
I0211 05:16:40.787421 22542570456896 run_lib.py:146] step: 658000, eval_loss: 2.64913e-02
I0211 05:16:58.037791 22542570456896 run_lib.py:133] step: 658050, training_loss: 3.28738e-02
I0211 05:17:15.380261 22542570456896 run_lib.py:133] step: 658100, training_loss: 3.03188e-02
I0211 05:17:15.549751 22542570456896 run_lib.py:146] step: 658100, eval_loss: 3.57017e-02
I0211 05:17:33.201573 22542570456896 run_lib.py:133] step: 658150, training_loss: 2.50651e-02
I0211 05:17:50.666941 22542570456896 run_lib.py:133] step: 658200, training_loss: 2.72106e-02
I0211 05:17:50.822221 22542570456896 run_lib.py:146] step: 658200, eval_loss: 3.01009e-02
I0211 05:18:08.230873 22542570456896 run_lib.py:133] step: 658250, training_loss: 2.87523e-02
I0211 05:18:25.654181 22542570456896 run_lib.py:133] step: 658300, training_loss: 3.61521e-02
I0211 05:18:25.807254 22542570456896 run_lib.py:146] step: 658300, eval_loss: 2.89875e-02
I0211 05:18:43.368640 22542570456896 run_lib.py:133] step: 658350, training_loss: 2.63005e-02
I0211 05:19:00.853448 22542570456896 run_lib.py:133] step: 658400, training_loss: 3.36471e-02
I0211 05:19:01.009554 22542570456896 run_lib.py:146] step: 658400, eval_loss: 2.75563e-02
I0211 05:19:18.558086 22542570456896 run_lib.py:133] step: 658450, training_loss: 2.94036e-02
I0211 05:19:35.960879 22542570456896 run_lib.py:133] step: 658500, training_loss: 2.62293e-02
I0211 05:19:36.118370 22542570456896 run_lib.py:146] step: 658500, eval_loss: 3.42827e-02
I0211 05:19:53.531381 22542570456896 run_lib.py:133] step: 658550, training_loss: 3.15473e-02
I0211 05:20:10.964235 22542570456896 run_lib.py:133] step: 658600, training_loss: 2.71139e-02
I0211 05:20:11.120437 22542570456896 run_lib.py:146] step: 658600, eval_loss: 3.52811e-02
I0211 05:20:28.706875 22542570456896 run_lib.py:133] step: 658650, training_loss: 3.29707e-02
I0211 05:20:46.231907 22542570456896 run_lib.py:133] step: 658700, training_loss: 2.56036e-02
I0211 05:20:46.389184 22542570456896 run_lib.py:146] step: 658700, eval_loss: 2.83071e-02
I0211 05:21:03.866213 22542570456896 run_lib.py:133] step: 658750, training_loss: 2.36420e-02
I0211 05:21:21.257761 22542570456896 run_lib.py:133] step: 658800, training_loss: 2.26946e-02
I0211 05:21:21.409012 22542570456896 run_lib.py:146] step: 658800, eval_loss: 2.82098e-02
I0211 05:21:38.998745 22542570456896 run_lib.py:133] step: 658850, training_loss: 2.75745e-02
I0211 05:21:56.436989 22542570456896 run_lib.py:133] step: 658900, training_loss: 2.26915e-02
I0211 05:21:56.591456 22542570456896 run_lib.py:146] step: 658900, eval_loss: 3.57873e-02
I0211 05:22:14.258406 22542570456896 run_lib.py:133] step: 658950, training_loss: 2.88159e-02
I0211 05:22:31.717765 22542570456896 run_lib.py:133] step: 659000, training_loss: 3.00770e-02
I0211 05:22:31.877265 22542570456896 run_lib.py:146] step: 659000, eval_loss: 2.37793e-02
I0211 05:22:49.460686 22542570456896 run_lib.py:133] step: 659050, training_loss: 2.35958e-02
I0211 05:23:06.851255 22542570456896 run_lib.py:133] step: 659100, training_loss: 3.56103e-02
I0211 05:23:07.006204 22542570456896 run_lib.py:146] step: 659100, eval_loss: 2.83422e-02
I0211 05:23:24.553284 22542570456896 run_lib.py:133] step: 659150, training_loss: 2.70037e-02
I0211 05:23:41.978163 22542570456896 run_lib.py:133] step: 659200, training_loss: 3.04664e-02
I0211 05:23:42.141596 22542570456896 run_lib.py:146] step: 659200, eval_loss: 3.07757e-02
I0211 05:23:59.609676 22542570456896 run_lib.py:133] step: 659250, training_loss: 2.46234e-02
I0211 05:24:17.181358 22542570456896 run_lib.py:133] step: 659300, training_loss: 2.43670e-02
I0211 05:24:17.332274 22542570456896 run_lib.py:146] step: 659300, eval_loss: 2.79965e-02
I0211 05:24:34.767661 22542570456896 run_lib.py:133] step: 659350, training_loss: 2.00440e-02
I0211 05:24:52.156601 22542570456896 run_lib.py:133] step: 659400, training_loss: 2.37112e-02
I0211 05:24:52.312258 22542570456896 run_lib.py:146] step: 659400, eval_loss: 2.79001e-02
I0211 05:25:09.861905 22542570456896 run_lib.py:133] step: 659450, training_loss: 2.70822e-02
I0211 05:25:27.414598 22542570456896 run_lib.py:133] step: 659500, training_loss: 3.43175e-02
I0211 05:25:27.581376 22542570456896 run_lib.py:146] step: 659500, eval_loss: 3.31340e-02
I0211 05:25:45.064071 22542570456896 run_lib.py:133] step: 659550, training_loss: 2.86263e-02
I0211 05:26:02.459497 22542570456896 run_lib.py:133] step: 659600, training_loss: 2.63091e-02
I0211 05:26:02.622646 22542570456896 run_lib.py:146] step: 659600, eval_loss: 2.67930e-02
I0211 05:26:20.081328 22542570456896 run_lib.py:133] step: 659650, training_loss: 1.93209e-02
I0211 05:26:37.694877 22542570456896 run_lib.py:133] step: 659700, training_loss: 2.89687e-02
I0211 05:26:37.848371 22542570456896 run_lib.py:146] step: 659700, eval_loss: 2.17148e-02
I0211 05:26:55.259018 22542570456896 run_lib.py:133] step: 659750, training_loss: 3.01606e-02
I0211 05:27:12.730717 22542570456896 run_lib.py:133] step: 659800, training_loss: 3.09627e-02
I0211 05:27:12.892550 22542570456896 run_lib.py:146] step: 659800, eval_loss: 2.55548e-02
I0211 05:27:30.327048 22542570456896 run_lib.py:133] step: 659850, training_loss: 2.44863e-02
I0211 05:27:47.922646 22542570456896 run_lib.py:133] step: 659900, training_loss: 3.51217e-02
I0211 05:27:48.080676 22542570456896 run_lib.py:146] step: 659900, eval_loss: 3.30000e-02
I0211 05:28:05.504707 22542570456896 run_lib.py:133] step: 659950, training_loss: 2.11747e-02
I0211 05:28:22.956335 22542570456896 run_lib.py:133] step: 660000, training_loss: 2.46736e-02
I0211 05:28:23.673805 22542570456896 run_lib.py:146] step: 660000, eval_loss: 2.45516e-02
I0211 05:28:43.830404 22542570456896 run_lib.py:133] step: 660050, training_loss: 2.11801e-02
I0211 05:29:01.251686 22542570456896 run_lib.py:133] step: 660100, training_loss: 2.75674e-02
I0211 05:29:01.407642 22542570456896 run_lib.py:146] step: 660100, eval_loss: 2.45802e-02
I0211 05:29:18.820847 22542570456896 run_lib.py:133] step: 660150, training_loss: 2.51468e-02
I0211 05:29:36.458654 22542570456896 run_lib.py:133] step: 660200, training_loss: 2.80478e-02
I0211 05:29:36.614586 22542570456896 run_lib.py:146] step: 660200, eval_loss: 3.25194e-02
I0211 05:29:54.001677 22542570456896 run_lib.py:133] step: 660250, training_loss: 2.09331e-02
I0211 05:30:11.614117 22542570456896 run_lib.py:133] step: 660300, training_loss: 2.77574e-02
I0211 05:30:11.771551 22542570456896 run_lib.py:146] step: 660300, eval_loss: 2.97788e-02
I0211 05:30:29.226129 22542570456896 run_lib.py:133] step: 660350, training_loss: 2.64797e-02
I0211 05:30:46.680912 22542570456896 run_lib.py:133] step: 660400, training_loss: 2.42217e-02
I0211 05:30:46.841343 22542570456896 run_lib.py:146] step: 660400, eval_loss: 2.91704e-02
I0211 05:31:04.413576 22542570456896 run_lib.py:133] step: 660450, training_loss: 2.77077e-02
I0211 05:31:21.869979 22542570456896 run_lib.py:133] step: 660500, training_loss: 2.35828e-02
I0211 05:31:22.031103 22542570456896 run_lib.py:146] step: 660500, eval_loss: 2.79354e-02
I0211 05:31:39.494036 22542570456896 run_lib.py:133] step: 660550, training_loss: 2.75152e-02
I0211 05:31:56.924226 22542570456896 run_lib.py:133] step: 660600, training_loss: 2.72425e-02
I0211 05:31:57.088454 22542570456896 run_lib.py:146] step: 660600, eval_loss: 2.67432e-02
I0211 05:32:14.681799 22542570456896 run_lib.py:133] step: 660650, training_loss: 3.34044e-02
I0211 05:32:32.100307 22542570456896 run_lib.py:133] step: 660700, training_loss: 2.68299e-02
I0211 05:32:32.259373 22542570456896 run_lib.py:146] step: 660700, eval_loss: 2.90115e-02
I0211 05:32:49.775648 22542570456896 run_lib.py:133] step: 660750, training_loss: 2.87533e-02
I0211 05:33:07.220416 22542570456896 run_lib.py:133] step: 660800, training_loss: 3.66422e-02
I0211 05:33:07.373514 22542570456896 run_lib.py:146] step: 660800, eval_loss: 2.44029e-02
I0211 05:33:24.943067 22542570456896 run_lib.py:133] step: 660850, training_loss: 3.04574e-02
I0211 05:33:42.377819 22542570456896 run_lib.py:133] step: 660900, training_loss: 2.16990e-02
I0211 05:33:42.534214 22542570456896 run_lib.py:146] step: 660900, eval_loss: 2.29838e-02
I0211 05:33:59.937458 22542570456896 run_lib.py:133] step: 660950, training_loss: 3.15143e-02
I0211 05:34:17.552115 22542570456896 run_lib.py:133] step: 661000, training_loss: 2.83245e-02
I0211 05:34:17.710582 22542570456896 run_lib.py:146] step: 661000, eval_loss: 2.30531e-02
I0211 05:34:35.118249 22542570456896 run_lib.py:133] step: 661050, training_loss: 2.91885e-02
I0211 05:34:52.659527 22542570456896 run_lib.py:133] step: 661100, training_loss: 2.42155e-02
I0211 05:34:52.815333 22542570456896 run_lib.py:146] step: 661100, eval_loss: 2.80003e-02
I0211 05:35:10.260049 22542570456896 run_lib.py:133] step: 661150, training_loss: 2.51007e-02
I0211 05:35:27.716366 22542570456896 run_lib.py:133] step: 661200, training_loss: 3.13567e-02
I0211 05:35:27.872580 22542570456896 run_lib.py:146] step: 661200, eval_loss: 4.10142e-02
I0211 05:35:45.511925 22542570456896 run_lib.py:133] step: 661250, training_loss: 2.88671e-02
I0211 05:36:02.935451 22542570456896 run_lib.py:133] step: 661300, training_loss: 2.54295e-02
I0211 05:36:03.088315 22542570456896 run_lib.py:146] step: 661300, eval_loss: 2.95246e-02
I0211 05:36:20.489915 22542570456896 run_lib.py:133] step: 661350, training_loss: 2.94778e-02
I0211 05:36:38.083229 22542570456896 run_lib.py:133] step: 661400, training_loss: 2.67364e-02
I0211 05:36:38.244369 22542570456896 run_lib.py:146] step: 661400, eval_loss: 2.80633e-02
I0211 05:36:55.699677 22542570456896 run_lib.py:133] step: 661450, training_loss: 2.48213e-02
I0211 05:37:13.160847 22542570456896 run_lib.py:133] step: 661500, training_loss: 3.25713e-02
I0211 05:37:13.315277 22542570456896 run_lib.py:146] step: 661500, eval_loss: 3.19682e-02
I0211 05:37:30.845130 22542570456896 run_lib.py:133] step: 661550, training_loss: 2.34837e-02
I0211 05:37:48.233549 22542570456896 run_lib.py:133] step: 661600, training_loss: 3.05604e-02
I0211 05:37:48.389438 22542570456896 run_lib.py:146] step: 661600, eval_loss: 2.62269e-02
I0211 05:38:05.802773 22542570456896 run_lib.py:133] step: 661650, training_loss: 2.76492e-02
I0211 05:38:23.251155 22542570456896 run_lib.py:133] step: 661700, training_loss: 2.74401e-02
I0211 05:38:23.412270 22542570456896 run_lib.py:146] step: 661700, eval_loss: 2.83643e-02
I0211 05:38:41.055124 22542570456896 run_lib.py:133] step: 661750, training_loss: 2.71547e-02
I0211 05:38:58.558170 22542570456896 run_lib.py:133] step: 661800, training_loss: 3.41411e-02
I0211 05:38:58.712365 22542570456896 run_lib.py:146] step: 661800, eval_loss: 3.21114e-02
I0211 05:39:16.080640 22542570456896 run_lib.py:133] step: 661850, training_loss: 2.61871e-02
I0211 05:39:33.490013 22542570456896 run_lib.py:133] step: 661900, training_loss: 2.38480e-02
I0211 05:39:33.645524 22542570456896 run_lib.py:146] step: 661900, eval_loss: 2.63502e-02
I0211 05:39:51.211263 22542570456896 run_lib.py:133] step: 661950, training_loss: 3.13091e-02
I0211 05:40:08.627813 22542570456896 run_lib.py:133] step: 662000, training_loss: 3.24761e-02
I0211 05:40:08.794259 22542570456896 run_lib.py:146] step: 662000, eval_loss: 2.84134e-02
I0211 05:40:26.372432 22542570456896 run_lib.py:133] step: 662050, training_loss: 2.24378e-02
I0211 05:40:43.816337 22542570456896 run_lib.py:133] step: 662100, training_loss: 2.36725e-02
I0211 05:40:43.971542 22542570456896 run_lib.py:146] step: 662100, eval_loss: 3.20196e-02
I0211 05:41:01.559221 22542570456896 run_lib.py:133] step: 662150, training_loss: 3.53257e-02
I0211 05:41:18.946573 22542570456896 run_lib.py:133] step: 662200, training_loss: 2.99055e-02
I0211 05:41:19.098142 22542570456896 run_lib.py:146] step: 662200, eval_loss: 2.73569e-02
I0211 05:41:36.674378 22542570456896 run_lib.py:133] step: 662250, training_loss: 2.94089e-02
I0211 05:41:54.125421 22542570456896 run_lib.py:133] step: 662300, training_loss: 2.16935e-02
I0211 05:41:54.294613 22542570456896 run_lib.py:146] step: 662300, eval_loss: 2.65457e-02
I0211 05:42:11.732349 22542570456896 run_lib.py:133] step: 662350, training_loss: 3.18446e-02
I0211 05:42:29.301836 22542570456896 run_lib.py:133] step: 662400, training_loss: 2.50736e-02
I0211 05:42:29.467562 22542570456896 run_lib.py:146] step: 662400, eval_loss: 2.95501e-02
I0211 05:42:46.861833 22542570456896 run_lib.py:133] step: 662450, training_loss: 3.45831e-02
I0211 05:43:04.294885 22542570456896 run_lib.py:133] step: 662500, training_loss: 3.60848e-02
I0211 05:43:04.457309 22542570456896 run_lib.py:146] step: 662500, eval_loss: 2.30562e-02
I0211 05:43:22.022326 22542570456896 run_lib.py:133] step: 662550, training_loss: 2.92422e-02
I0211 05:43:39.470827 22542570456896 run_lib.py:133] step: 662600, training_loss: 2.96903e-02
I0211 05:43:39.625143 22542570456896 run_lib.py:146] step: 662600, eval_loss: 2.99737e-02
I0211 05:43:57.202737 22542570456896 run_lib.py:133] step: 662650, training_loss: 2.70685e-02
I0211 05:44:14.612939 22542570456896 run_lib.py:133] step: 662700, training_loss: 2.77916e-02
I0211 05:44:14.772875 22542570456896 run_lib.py:146] step: 662700, eval_loss: 2.62180e-02
I0211 05:44:32.196418 22542570456896 run_lib.py:133] step: 662750, training_loss: 3.10042e-02
I0211 05:44:49.784260 22542570456896 run_lib.py:133] step: 662800, training_loss: 3.52009e-02
I0211 05:44:49.941228 22542570456896 run_lib.py:146] step: 662800, eval_loss: 3.19236e-02
I0211 05:45:07.330119 22542570456896 run_lib.py:133] step: 662850, training_loss: 2.74768e-02
I0211 05:45:24.782047 22542570456896 run_lib.py:133] step: 662900, training_loss: 3.06616e-02
I0211 05:45:24.941603 22542570456896 run_lib.py:146] step: 662900, eval_loss: 3.13940e-02
I0211 05:45:42.366358 22542570456896 run_lib.py:133] step: 662950, training_loss: 3.66781e-02
I0211 05:45:59.923737 22542570456896 run_lib.py:133] step: 663000, training_loss: 2.63132e-02
I0211 05:46:00.079237 22542570456896 run_lib.py:146] step: 663000, eval_loss: 2.78292e-02
I0211 05:46:17.505721 22542570456896 run_lib.py:133] step: 663050, training_loss: 3.27916e-02
I0211 05:46:34.945338 22542570456896 run_lib.py:133] step: 663100, training_loss: 3.10388e-02
I0211 05:46:35.098309 22542570456896 run_lib.py:146] step: 663100, eval_loss: 2.90010e-02
I0211 05:46:52.509913 22542570456896 run_lib.py:133] step: 663150, training_loss: 2.88772e-02
I0211 05:47:09.947475 22542570456896 run_lib.py:133] step: 663200, training_loss: 2.44330e-02
I0211 05:47:10.147501 22542570456896 run_lib.py:146] step: 663200, eval_loss: 2.96595e-02
I0211 05:47:27.757253 22542570456896 run_lib.py:133] step: 663250, training_loss: 3.35451e-02
I0211 05:47:45.239009 22542570456896 run_lib.py:133] step: 663300, training_loss: 2.76876e-02
I0211 05:47:45.397503 22542570456896 run_lib.py:146] step: 663300, eval_loss: 2.27845e-02
I0211 05:48:02.833278 22542570456896 run_lib.py:133] step: 663350, training_loss: 2.35458e-02
I0211 05:48:20.194485 22542570456896 run_lib.py:133] step: 663400, training_loss: 3.15484e-02
I0211 05:48:20.359473 22542570456896 run_lib.py:146] step: 663400, eval_loss: 3.30862e-02
I0211 05:48:37.930208 22542570456896 run_lib.py:133] step: 663450, training_loss: 3.24378e-02
I0211 05:48:55.314656 22542570456896 run_lib.py:133] step: 663500, training_loss: 2.96345e-02
I0211 05:48:55.470748 22542570456896 run_lib.py:146] step: 663500, eval_loss: 3.50402e-02
I0211 05:49:13.038898 22542570456896 run_lib.py:133] step: 663550, training_loss: 2.45255e-02
I0211 05:49:30.445441 22542570456896 run_lib.py:133] step: 663600, training_loss: 2.87604e-02
I0211 05:49:30.593595 22542570456896 run_lib.py:146] step: 663600, eval_loss: 2.86370e-02
I0211 05:49:48.126979 22542570456896 run_lib.py:133] step: 663650, training_loss: 3.03905e-02
I0211 05:50:05.513291 22542570456896 run_lib.py:133] step: 663700, training_loss: 2.51139e-02
I0211 05:50:05.680490 22542570456896 run_lib.py:146] step: 663700, eval_loss: 3.41534e-02
I0211 05:50:23.114401 22542570456896 run_lib.py:133] step: 663750, training_loss: 3.26426e-02
I0211 05:50:40.706026 22542570456896 run_lib.py:133] step: 663800, training_loss: 2.92093e-02
I0211 05:50:40.863627 22542570456896 run_lib.py:146] step: 663800, eval_loss: 2.66751e-02
I0211 05:50:58.309477 22542570456896 run_lib.py:133] step: 663850, training_loss: 2.74639e-02
I0211 05:51:15.834174 22542570456896 run_lib.py:133] step: 663900, training_loss: 2.76192e-02
I0211 05:51:15.988481 22542570456896 run_lib.py:146] step: 663900, eval_loss: 3.74906e-02
I0211 05:51:33.389201 22542570456896 run_lib.py:133] step: 663950, training_loss: 3.47140e-02
I0211 05:51:50.824264 22542570456896 run_lib.py:133] step: 664000, training_loss: 2.56664e-02
I0211 05:51:50.981723 22542570456896 run_lib.py:146] step: 664000, eval_loss: 3.44120e-02
I0211 05:52:08.610027 22542570456896 run_lib.py:133] step: 664050, training_loss: 3.39298e-02
I0211 05:52:25.981150 22542570456896 run_lib.py:133] step: 664100, training_loss: 2.91158e-02
I0211 05:52:26.131806 22542570456896 run_lib.py:146] step: 664100, eval_loss: 2.46576e-02
I0211 05:52:43.501953 22542570456896 run_lib.py:133] step: 664150, training_loss: 2.78277e-02
I0211 05:53:01.101965 22542570456896 run_lib.py:133] step: 664200, training_loss: 3.14502e-02
I0211 05:53:01.260747 22542570456896 run_lib.py:146] step: 664200, eval_loss: 2.80077e-02
I0211 05:53:18.759558 22542570456896 run_lib.py:133] step: 664250, training_loss: 2.42127e-02
I0211 05:53:36.216492 22542570456896 run_lib.py:133] step: 664300, training_loss: 2.31071e-02
I0211 05:53:36.556266 22542570456896 run_lib.py:146] step: 664300, eval_loss: 3.51012e-02
I0211 05:53:53.930435 22542570456896 run_lib.py:133] step: 664350, training_loss: 3.14623e-02
I0211 05:54:11.314669 22542570456896 run_lib.py:133] step: 664400, training_loss: 2.72293e-02
I0211 05:54:11.470458 22542570456896 run_lib.py:146] step: 664400, eval_loss: 3.37417e-02
I0211 05:54:28.875308 22542570456896 run_lib.py:133] step: 664450, training_loss: 2.57462e-02
I0211 05:54:46.299894 22542570456896 run_lib.py:133] step: 664500, training_loss: 2.78290e-02
I0211 05:54:46.459570 22542570456896 run_lib.py:146] step: 664500, eval_loss: 3.21255e-02
I0211 05:55:04.067509 22542570456896 run_lib.py:133] step: 664550, training_loss: 2.79511e-02
I0211 05:55:21.560414 22542570456896 run_lib.py:133] step: 664600, training_loss: 3.02151e-02
I0211 05:55:21.709369 22542570456896 run_lib.py:146] step: 664600, eval_loss: 2.90844e-02
I0211 05:55:39.161940 22542570456896 run_lib.py:133] step: 664650, training_loss: 2.49501e-02
I0211 05:55:56.582529 22542570456896 run_lib.py:133] step: 664700, training_loss: 2.53959e-02
I0211 05:55:56.744188 22542570456896 run_lib.py:146] step: 664700, eval_loss: 3.24898e-02
I0211 05:56:14.226137 22542570456896 run_lib.py:133] step: 664750, training_loss: 2.69396e-02
I0211 05:56:31.674774 22542570456896 run_lib.py:133] step: 664800, training_loss: 2.19910e-02
I0211 05:56:31.851271 22542570456896 run_lib.py:146] step: 664800, eval_loss: 2.50487e-02
I0211 05:56:49.279958 22542570456896 run_lib.py:133] step: 664850, training_loss: 2.48257e-02
I0211 05:57:06.691664 22542570456896 run_lib.py:133] step: 664900, training_loss: 2.16453e-02
I0211 05:57:06.847665 22542570456896 run_lib.py:146] step: 664900, eval_loss: 3.13809e-02
I0211 05:57:24.422077 22542570456896 run_lib.py:133] step: 664950, training_loss: 2.88587e-02
I0211 05:57:41.778263 22542570456896 run_lib.py:133] step: 665000, training_loss: 3.22426e-02
I0211 05:57:41.933347 22542570456896 run_lib.py:146] step: 665000, eval_loss: 2.71477e-02
I0211 05:57:59.446895 22542570456896 run_lib.py:133] step: 665050, training_loss: 2.63242e-02
I0211 05:58:16.818696 22542570456896 run_lib.py:133] step: 665100, training_loss: 2.97396e-02
I0211 05:58:16.972537 22542570456896 run_lib.py:146] step: 665100, eval_loss: 3.04506e-02
I0211 05:58:34.579927 22542570456896 run_lib.py:133] step: 665150, training_loss: 3.34464e-02
I0211 05:58:51.993794 22542570456896 run_lib.py:133] step: 665200, training_loss: 2.60914e-02
I0211 05:58:52.151249 22542570456896 run_lib.py:146] step: 665200, eval_loss: 2.37193e-02
I0211 05:59:09.512764 22542570456896 run_lib.py:133] step: 665250, training_loss: 2.71381e-02
I0211 05:59:27.017225 22542570456896 run_lib.py:133] step: 665300, training_loss: 2.97797e-02
I0211 05:59:27.172421 22542570456896 run_lib.py:146] step: 665300, eval_loss: 3.15332e-02
I0211 05:59:44.552232 22542570456896 run_lib.py:133] step: 665350, training_loss: 2.10055e-02
I0211 06:00:02.157479 22542570456896 run_lib.py:133] step: 665400, training_loss: 2.61767e-02
I0211 06:00:02.312658 22542570456896 run_lib.py:146] step: 665400, eval_loss: 3.26140e-02
I0211 06:00:19.701856 22542570456896 run_lib.py:133] step: 665450, training_loss: 3.01128e-02
I0211 06:00:37.039360 22542570456896 run_lib.py:133] step: 665500, training_loss: 2.26370e-02
I0211 06:00:37.194038 22542570456896 run_lib.py:146] step: 665500, eval_loss: 2.90048e-02
I0211 06:00:54.735991 22542570456896 run_lib.py:133] step: 665550, training_loss: 3.35292e-02
I0211 06:01:12.136717 22542570456896 run_lib.py:133] step: 665600, training_loss: 2.41190e-02
I0211 06:01:12.294250 22542570456896 run_lib.py:146] step: 665600, eval_loss: 3.05045e-02
I0211 06:01:29.706057 22542570456896 run_lib.py:133] step: 665650, training_loss: 2.81153e-02
I0211 06:01:47.122261 22542570456896 run_lib.py:133] step: 665700, training_loss: 2.73076e-02
I0211 06:01:47.289219 22542570456896 run_lib.py:146] step: 665700, eval_loss: 3.33918e-02
I0211 06:02:04.912795 22542570456896 run_lib.py:133] step: 665750, training_loss: 2.97950e-02
I0211 06:02:22.308916 22542570456896 run_lib.py:133] step: 665800, training_loss: 3.00607e-02
I0211 06:02:22.472432 22542570456896 run_lib.py:146] step: 665800, eval_loss: 3.57215e-02
I0211 06:02:39.910817 22542570456896 run_lib.py:133] step: 665850, training_loss: 2.88906e-02
I0211 06:02:57.374862 22542570456896 run_lib.py:133] step: 665900, training_loss: 3.30852e-02
I0211 06:02:57.541597 22542570456896 run_lib.py:146] step: 665900, eval_loss: 3.70079e-02
I0211 06:03:14.954031 22542570456896 run_lib.py:133] step: 665950, training_loss: 2.61982e-02
I0211 06:03:32.446461 22542570456896 run_lib.py:133] step: 666000, training_loss: 2.59975e-02
I0211 06:03:32.598496 22542570456896 run_lib.py:146] step: 666000, eval_loss: 3.22384e-02
I0211 06:03:50.184355 22542570456896 run_lib.py:133] step: 666050, training_loss: 3.14597e-02
I0211 06:04:07.696908 22542570456896 run_lib.py:133] step: 666100, training_loss: 2.86233e-02
I0211 06:04:07.852353 22542570456896 run_lib.py:146] step: 666100, eval_loss: 3.41611e-02
I0211 06:04:25.220297 22542570456896 run_lib.py:133] step: 666150, training_loss: 2.46449e-02
I0211 06:04:42.653864 22542570456896 run_lib.py:133] step: 666200, training_loss: 3.10419e-02
I0211 06:04:42.826280 22542570456896 run_lib.py:146] step: 666200, eval_loss: 2.49559e-02
I0211 06:05:00.383255 22542570456896 run_lib.py:133] step: 666250, training_loss: 2.81092e-02
I0211 06:05:17.774038 22542570456896 run_lib.py:133] step: 666300, training_loss: 3.14880e-02
I0211 06:05:17.933589 22542570456896 run_lib.py:146] step: 666300, eval_loss: 2.30543e-02
I0211 06:05:35.545716 22542570456896 run_lib.py:133] step: 666350, training_loss: 2.82393e-02
I0211 06:05:52.942570 22542570456896 run_lib.py:133] step: 666400, training_loss: 2.76935e-02
I0211 06:05:53.097308 22542570456896 run_lib.py:146] step: 666400, eval_loss: 2.89212e-02
I0211 06:06:10.625326 22542570456896 run_lib.py:133] step: 666450, training_loss: 2.18887e-02
I0211 06:06:28.091652 22542570456896 run_lib.py:133] step: 666500, training_loss: 2.40178e-02
I0211 06:06:28.246531 22542570456896 run_lib.py:146] step: 666500, eval_loss: 2.38204e-02
I0211 06:06:45.872430 22542570456896 run_lib.py:133] step: 666550, training_loss: 2.30904e-02
I0211 06:07:03.295450 22542570456896 run_lib.py:133] step: 666600, training_loss: 2.56116e-02
I0211 06:07:03.450456 22542570456896 run_lib.py:146] step: 666600, eval_loss: 3.16490e-02
I0211 06:07:20.802089 22542570456896 run_lib.py:133] step: 666650, training_loss: 2.89691e-02
I0211 06:07:38.280192 22542570456896 run_lib.py:133] step: 666700, training_loss: 2.74025e-02
I0211 06:07:38.437496 22542570456896 run_lib.py:146] step: 666700, eval_loss: 2.19423e-02
I0211 06:07:55.856007 22542570456896 run_lib.py:133] step: 666750, training_loss: 2.83155e-02
I0211 06:08:13.310636 22542570456896 run_lib.py:133] step: 666800, training_loss: 2.78076e-02
I0211 06:08:13.464925 22542570456896 run_lib.py:146] step: 666800, eval_loss: 3.26101e-02
I0211 06:08:31.043178 22542570456896 run_lib.py:133] step: 666850, training_loss: 2.91484e-02
I0211 06:08:48.600021 22542570456896 run_lib.py:133] step: 666900, training_loss: 3.18404e-02
I0211 06:08:48.763017 22542570456896 run_lib.py:146] step: 666900, eval_loss: 1.98455e-02
I0211 06:09:06.133072 22542570456896 run_lib.py:133] step: 666950, training_loss: 2.77030e-02
I0211 06:09:23.525239 22542570456896 run_lib.py:133] step: 667000, training_loss: 2.72687e-02
I0211 06:09:23.676069 22542570456896 run_lib.py:146] step: 667000, eval_loss: 2.50251e-02
I0211 06:09:41.162328 22542570456896 run_lib.py:133] step: 667050, training_loss: 2.77762e-02
I0211 06:09:58.755496 22542570456896 run_lib.py:133] step: 667100, training_loss: 2.74877e-02
I0211 06:09:58.919327 22542570456896 run_lib.py:146] step: 667100, eval_loss: 3.42242e-02
I0211 06:10:16.307753 22542570456896 run_lib.py:133] step: 667150, training_loss: 2.78535e-02
I0211 06:10:33.726860 22542570456896 run_lib.py:133] step: 667200, training_loss: 3.11333e-02
I0211 06:10:33.886317 22542570456896 run_lib.py:146] step: 667200, eval_loss: 2.67646e-02
I0211 06:10:51.285345 22542570456896 run_lib.py:133] step: 667250, training_loss: 2.91025e-02
I0211 06:11:08.836999 22542570456896 run_lib.py:133] step: 667300, training_loss: 2.50372e-02
I0211 06:11:08.994179 22542570456896 run_lib.py:146] step: 667300, eval_loss: 2.62238e-02
I0211 06:11:26.419889 22542570456896 run_lib.py:133] step: 667350, training_loss: 2.20437e-02
I0211 06:11:43.892529 22542570456896 run_lib.py:133] step: 667400, training_loss: 3.18769e-02
I0211 06:11:44.044185 22542570456896 run_lib.py:146] step: 667400, eval_loss: 2.54555e-02
I0211 06:12:01.450158 22542570456896 run_lib.py:133] step: 667450, training_loss: 2.44159e-02
I0211 06:12:18.827355 22542570456896 run_lib.py:133] step: 667500, training_loss: 2.72506e-02
I0211 06:12:18.980345 22542570456896 run_lib.py:146] step: 667500, eval_loss: 2.68337e-02
I0211 06:12:36.472179 22542570456896 run_lib.py:133] step: 667550, training_loss: 2.79819e-02
I0211 06:12:53.893332 22542570456896 run_lib.py:133] step: 667600, training_loss: 3.08003e-02
I0211 06:12:54.073999 22542570456896 run_lib.py:146] step: 667600, eval_loss: 3.09317e-02
I0211 06:13:11.512578 22542570456896 run_lib.py:133] step: 667650, training_loss: 3.18039e-02
I0211 06:13:28.921411 22542570456896 run_lib.py:133] step: 667700, training_loss: 3.05698e-02
I0211 06:13:29.076609 22542570456896 run_lib.py:146] step: 667700, eval_loss: 3.10167e-02
I0211 06:13:46.636968 22542570456896 run_lib.py:133] step: 667750, training_loss: 2.61705e-02
I0211 06:14:04.022448 22542570456896 run_lib.py:133] step: 667800, training_loss: 3.14014e-02
I0211 06:14:04.178401 22542570456896 run_lib.py:146] step: 667800, eval_loss: 2.68862e-02
I0211 06:14:21.697340 22542570456896 run_lib.py:133] step: 667850, training_loss: 2.44951e-02
I0211 06:14:39.115536 22542570456896 run_lib.py:133] step: 667900, training_loss: 2.58426e-02
I0211 06:14:39.277214 22542570456896 run_lib.py:146] step: 667900, eval_loss: 3.44784e-02
I0211 06:14:56.918939 22542570456896 run_lib.py:133] step: 667950, training_loss: 2.15731e-02
I0211 06:15:14.322901 22542570456896 run_lib.py:133] step: 668000, training_loss: 1.82675e-02
I0211 06:15:14.477222 22542570456896 run_lib.py:146] step: 668000, eval_loss: 2.57922e-02
I0211 06:15:31.851915 22542570456896 run_lib.py:133] step: 668050, training_loss: 3.09528e-02
I0211 06:15:49.415924 22542570456896 run_lib.py:133] step: 668100, training_loss: 2.80818e-02
I0211 06:15:49.581540 22542570456896 run_lib.py:146] step: 668100, eval_loss: 2.33337e-02
I0211 06:16:07.030706 22542570456896 run_lib.py:133] step: 668150, training_loss: 2.65950e-02
I0211 06:16:24.587399 22542570456896 run_lib.py:133] step: 668200, training_loss: 3.10681e-02
I0211 06:16:24.751945 22542570456896 run_lib.py:146] step: 668200, eval_loss: 2.95707e-02
I0211 06:16:42.207962 22542570456896 run_lib.py:133] step: 668250, training_loss: 2.52198e-02
I0211 06:16:59.553998 22542570456896 run_lib.py:133] step: 668300, training_loss: 2.97861e-02
I0211 06:16:59.711240 22542570456896 run_lib.py:146] step: 668300, eval_loss: 2.48749e-02
I0211 06:17:17.281064 22542570456896 run_lib.py:133] step: 668350, training_loss: 2.91184e-02
I0211 06:17:34.693932 22542570456896 run_lib.py:133] step: 668400, training_loss: 3.59280e-02
I0211 06:17:34.845297 22542570456896 run_lib.py:146] step: 668400, eval_loss: 2.32341e-02
I0211 06:17:52.212845 22542570456896 run_lib.py:133] step: 668450, training_loss: 2.38946e-02
I0211 06:18:09.813539 22542570456896 run_lib.py:133] step: 668500, training_loss: 3.00251e-02
I0211 06:18:09.986220 22542570456896 run_lib.py:146] step: 668500, eval_loss: 3.03353e-02
I0211 06:18:27.413722 22542570456896 run_lib.py:133] step: 668550, training_loss: 3.69113e-02
I0211 06:18:44.772444 22542570456896 run_lib.py:133] step: 668600, training_loss: 2.70892e-02
I0211 06:18:44.927433 22542570456896 run_lib.py:146] step: 668600, eval_loss: 2.84249e-02
I0211 06:19:02.373076 22542570456896 run_lib.py:133] step: 668650, training_loss: 2.37246e-02
I0211 06:19:19.763024 22542570456896 run_lib.py:133] step: 668700, training_loss: 2.60146e-02
I0211 06:19:19.918573 22542570456896 run_lib.py:146] step: 668700, eval_loss: 2.80410e-02
I0211 06:19:37.335342 22542570456896 run_lib.py:133] step: 668750, training_loss: 3.04237e-02
I0211 06:19:54.766739 22542570456896 run_lib.py:133] step: 668800, training_loss: 2.69369e-02
I0211 06:19:54.921516 22542570456896 run_lib.py:146] step: 668800, eval_loss: 2.83011e-02
I0211 06:20:12.480174 22542570456896 run_lib.py:133] step: 668850, training_loss: 2.82607e-02
I0211 06:20:29.900164 22542570456896 run_lib.py:133] step: 668900, training_loss: 2.84621e-02
I0211 06:20:30.051487 22542570456896 run_lib.py:146] step: 668900, eval_loss: 3.11081e-02
I0211 06:20:47.492169 22542570456896 run_lib.py:133] step: 668950, training_loss: 2.51626e-02
I0211 06:21:04.878069 22542570456896 run_lib.py:133] step: 669000, training_loss: 2.33970e-02
I0211 06:21:05.050273 22542570456896 run_lib.py:146] step: 669000, eval_loss: 2.85143e-02
I0211 06:21:22.672251 22542570456896 run_lib.py:133] step: 669050, training_loss: 3.08377e-02
I0211 06:21:40.134923 22542570456896 run_lib.py:133] step: 669100, training_loss: 3.10152e-02
I0211 06:21:40.302406 22542570456896 run_lib.py:146] step: 669100, eval_loss: 2.36089e-02
I0211 06:21:57.888611 22542570456896 run_lib.py:133] step: 669150, training_loss: 2.91945e-02
I0211 06:22:15.267728 22542570456896 run_lib.py:133] step: 669200, training_loss: 2.70713e-02
I0211 06:22:15.423084 22542570456896 run_lib.py:146] step: 669200, eval_loss: 2.73675e-02
I0211 06:22:32.980239 22542570456896 run_lib.py:133] step: 669250, training_loss: 2.67290e-02
I0211 06:22:50.394418 22542570456896 run_lib.py:133] step: 669300, training_loss: 2.43879e-02
I0211 06:22:50.547089 22542570456896 run_lib.py:146] step: 669300, eval_loss: 3.05339e-02
I0211 06:23:08.201222 22542570456896 run_lib.py:133] step: 669350, training_loss: 3.00932e-02
I0211 06:23:25.619415 22542570456896 run_lib.py:133] step: 669400, training_loss: 2.71921e-02
I0211 06:23:25.774401 22542570456896 run_lib.py:146] step: 669400, eval_loss: 3.84943e-02
I0211 06:23:43.181243 22542570456896 run_lib.py:133] step: 669450, training_loss: 2.81243e-02
I0211 06:24:00.750179 22542570456896 run_lib.py:133] step: 669500, training_loss: 2.88610e-02
I0211 06:24:00.915680 22542570456896 run_lib.py:146] step: 669500, eval_loss: 2.82006e-02
I0211 06:24:18.325112 22542570456896 run_lib.py:133] step: 669550, training_loss: 2.36156e-02
I0211 06:24:35.716354 22542570456896 run_lib.py:133] step: 669600, training_loss: 2.66702e-02
I0211 06:24:35.890105 22542570456896 run_lib.py:146] step: 669600, eval_loss: 3.06154e-02
I0211 06:24:53.444773 22542570456896 run_lib.py:133] step: 669650, training_loss: 3.03979e-02
I0211 06:25:10.773354 22542570456896 run_lib.py:133] step: 669700, training_loss: 2.46104e-02
I0211 06:25:11.040584 22542570456896 run_lib.py:146] step: 669700, eval_loss: 2.75696e-02
I0211 06:25:28.543762 22542570456896 run_lib.py:133] step: 669750, training_loss: 2.34744e-02
I0211 06:25:45.893559 22542570456896 run_lib.py:133] step: 669800, training_loss: 2.46736e-02
I0211 06:25:46.040648 22542570456896 run_lib.py:146] step: 669800, eval_loss: 2.96913e-02
I0211 06:26:03.476845 22542570456896 run_lib.py:133] step: 669850, training_loss: 3.20273e-02
I0211 06:26:21.061291 22542570456896 run_lib.py:133] step: 669900, training_loss: 2.98052e-02
I0211 06:26:21.236636 22542570456896 run_lib.py:146] step: 669900, eval_loss: 3.49470e-02
I0211 06:26:38.657168 22542570456896 run_lib.py:133] step: 669950, training_loss: 2.63166e-02
I0211 06:26:56.090522 22542570456896 run_lib.py:133] step: 670000, training_loss: 2.86863e-02
I0211 06:26:56.809297 22542570456896 run_lib.py:146] step: 670000, eval_loss: 2.98110e-02
I0211 06:27:17.020314 22542570456896 run_lib.py:133] step: 670050, training_loss: 2.70204e-02
I0211 06:27:34.449430 22542570456896 run_lib.py:133] step: 670100, training_loss: 2.94948e-02
I0211 06:27:34.608617 22542570456896 run_lib.py:146] step: 670100, eval_loss: 2.33570e-02
I0211 06:27:52.223888 22542570456896 run_lib.py:133] step: 670150, training_loss: 3.30221e-02
I0211 06:28:09.726304 22542570456896 run_lib.py:133] step: 670200, training_loss: 2.97706e-02
I0211 06:28:09.882159 22542570456896 run_lib.py:146] step: 670200, eval_loss: 3.10342e-02
I0211 06:28:27.439385 22542570456896 run_lib.py:133] step: 670250, training_loss: 3.06997e-02
I0211 06:28:44.895334 22542570456896 run_lib.py:133] step: 670300, training_loss: 2.82476e-02
I0211 06:28:45.049048 22542570456896 run_lib.py:146] step: 670300, eval_loss: 3.58217e-02
I0211 06:29:02.443958 22542570456896 run_lib.py:133] step: 670350, training_loss: 2.81712e-02
I0211 06:29:19.854603 22542570456896 run_lib.py:133] step: 670400, training_loss: 3.03811e-02
I0211 06:29:20.008591 22542570456896 run_lib.py:146] step: 670400, eval_loss: 2.88028e-02
I0211 06:29:37.596069 22542570456896 run_lib.py:133] step: 670450, training_loss: 2.17379e-02
I0211 06:29:55.182607 22542570456896 run_lib.py:133] step: 670500, training_loss: 2.94834e-02
I0211 06:29:55.340425 22542570456896 run_lib.py:146] step: 670500, eval_loss: 3.52258e-02
I0211 06:30:12.736515 22542570456896 run_lib.py:133] step: 670550, training_loss: 2.60271e-02
I0211 06:30:30.159700 22542570456896 run_lib.py:133] step: 670600, training_loss: 2.61102e-02
I0211 06:30:30.316257 22542570456896 run_lib.py:146] step: 670600, eval_loss: 3.33656e-02
I0211 06:30:47.906345 22542570456896 run_lib.py:133] step: 670650, training_loss: 3.01704e-02
I0211 06:31:05.324966 22542570456896 run_lib.py:133] step: 670700, training_loss: 2.63448e-02
I0211 06:31:05.493959 22542570456896 run_lib.py:146] step: 670700, eval_loss: 2.82861e-02
I0211 06:31:23.078476 22542570456896 run_lib.py:133] step: 670750, training_loss: 2.36325e-02
I0211 06:31:40.520663 22542570456896 run_lib.py:133] step: 670800, training_loss: 3.62955e-02
I0211 06:31:40.668628 22542570456896 run_lib.py:146] step: 670800, eval_loss: 3.14338e-02
I0211 06:31:58.308778 22542570456896 run_lib.py:133] step: 670850, training_loss: 2.49471e-02
I0211 06:32:15.722587 22542570456896 run_lib.py:133] step: 670900, training_loss: 2.97486e-02
I0211 06:32:15.875504 22542570456896 run_lib.py:146] step: 670900, eval_loss: 3.09397e-02
I0211 06:32:33.437541 22542570456896 run_lib.py:133] step: 670950, training_loss: 3.03964e-02
I0211 06:32:50.905133 22542570456896 run_lib.py:133] step: 671000, training_loss: 2.65314e-02
I0211 06:32:51.082306 22542570456896 run_lib.py:146] step: 671000, eval_loss: 2.80947e-02
I0211 06:33:08.586862 22542570456896 run_lib.py:133] step: 671050, training_loss: 3.17635e-02
I0211 06:33:26.200402 22542570456896 run_lib.py:133] step: 671100, training_loss: 2.83329e-02
I0211 06:33:26.355531 22542570456896 run_lib.py:146] step: 671100, eval_loss: 3.03135e-02
I0211 06:33:43.808972 22542570456896 run_lib.py:133] step: 671150, training_loss: 3.02458e-02
I0211 06:34:01.206030 22542570456896 run_lib.py:133] step: 671200, training_loss: 2.50239e-02
I0211 06:34:01.358492 22542570456896 run_lib.py:146] step: 671200, eval_loss: 3.30072e-02
I0211 06:34:18.921382 22542570456896 run_lib.py:133] step: 671250, training_loss: 2.80711e-02
I0211 06:34:36.537790 22542570456896 run_lib.py:133] step: 671300, training_loss: 3.01695e-02
I0211 06:34:36.746347 22542570456896 run_lib.py:146] step: 671300, eval_loss: 3.07396e-02
I0211 06:34:54.213909 22542570456896 run_lib.py:133] step: 671350, training_loss: 2.47140e-02
I0211 06:35:11.664039 22542570456896 run_lib.py:133] step: 671400, training_loss: 2.64070e-02
I0211 06:35:11.821401 22542570456896 run_lib.py:146] step: 671400, eval_loss: 2.63984e-02
I0211 06:35:29.224297 22542570456896 run_lib.py:133] step: 671450, training_loss: 2.97525e-02
I0211 06:35:46.795864 22542570456896 run_lib.py:133] step: 671500, training_loss: 2.43560e-02
I0211 06:35:46.962774 22542570456896 run_lib.py:146] step: 671500, eval_loss: 3.17405e-02
I0211 06:36:04.419810 22542570456896 run_lib.py:133] step: 671550, training_loss: 2.98999e-02
I0211 06:36:21.855976 22542570456896 run_lib.py:133] step: 671600, training_loss: 2.57907e-02
I0211 06:36:22.013138 22542570456896 run_lib.py:146] step: 671600, eval_loss: 2.61208e-02
I0211 06:36:39.456197 22542570456896 run_lib.py:133] step: 671650, training_loss: 2.71228e-02
I0211 06:36:57.046202 22542570456896 run_lib.py:133] step: 671700, training_loss: 3.19724e-02
I0211 06:36:57.202263 22542570456896 run_lib.py:146] step: 671700, eval_loss: 2.84449e-02
I0211 06:37:14.651545 22542570456896 run_lib.py:133] step: 671750, training_loss: 2.58726e-02
I0211 06:37:32.158274 22542570456896 run_lib.py:133] step: 671800, training_loss: 2.15075e-02
I0211 06:37:32.311546 22542570456896 run_lib.py:146] step: 671800, eval_loss: 3.22260e-02
I0211 06:37:49.801364 22542570456896 run_lib.py:133] step: 671850, training_loss: 2.75536e-02
I0211 06:38:07.196544 22542570456896 run_lib.py:133] step: 671900, training_loss: 2.76829e-02
I0211 06:38:07.358407 22542570456896 run_lib.py:146] step: 671900, eval_loss: 2.50504e-02
I0211 06:38:24.900702 22542570456896 run_lib.py:133] step: 671950, training_loss: 2.10285e-02
I0211 06:38:42.367247 22542570456896 run_lib.py:133] step: 672000, training_loss: 2.41619e-02
I0211 06:38:42.523720 22542570456896 run_lib.py:146] step: 672000, eval_loss: 2.63649e-02
I0211 06:38:59.975667 22542570456896 run_lib.py:133] step: 672050, training_loss: 2.19766e-02
I0211 06:39:17.374383 22542570456896 run_lib.py:133] step: 672100, training_loss: 3.20356e-02
I0211 06:39:17.529133 22542570456896 run_lib.py:146] step: 672100, eval_loss: 3.07042e-02
I0211 06:39:35.110461 22542570456896 run_lib.py:133] step: 672150, training_loss: 2.97094e-02
I0211 06:39:52.548856 22542570456896 run_lib.py:133] step: 672200, training_loss: 3.39446e-02
I0211 06:39:52.710187 22542570456896 run_lib.py:146] step: 672200, eval_loss: 3.22459e-02
I0211 06:40:10.362617 22542570456896 run_lib.py:133] step: 672250, training_loss: 2.09181e-02
I0211 06:40:27.751716 22542570456896 run_lib.py:133] step: 672300, training_loss: 2.61952e-02
I0211 06:40:27.912419 22542570456896 run_lib.py:146] step: 672300, eval_loss: 3.66721e-02
I0211 06:40:45.452500 22542570456896 run_lib.py:133] step: 672350, training_loss: 2.69730e-02
I0211 06:41:02.862674 22542570456896 run_lib.py:133] step: 672400, training_loss: 3.62383e-02
I0211 06:41:03.021540 22542570456896 run_lib.py:146] step: 672400, eval_loss: 2.26737e-02
I0211 06:41:20.466938 22542570456896 run_lib.py:133] step: 672450, training_loss: 2.52545e-02
I0211 06:41:38.087451 22542570456896 run_lib.py:133] step: 672500, training_loss: 2.81182e-02
I0211 06:41:38.245081 22542570456896 run_lib.py:146] step: 672500, eval_loss: 2.82389e-02
I0211 06:41:55.692503 22542570456896 run_lib.py:133] step: 672550, training_loss: 2.89825e-02
I0211 06:42:13.232784 22542570456896 run_lib.py:133] step: 672600, training_loss: 3.41390e-02
I0211 06:42:13.390665 22542570456896 run_lib.py:146] step: 672600, eval_loss: 2.97550e-02
I0211 06:42:30.801141 22542570456896 run_lib.py:133] step: 672650, training_loss: 2.39252e-02
I0211 06:42:48.245809 22542570456896 run_lib.py:133] step: 672700, training_loss: 2.82758e-02
I0211 06:42:48.404536 22542570456896 run_lib.py:146] step: 672700, eval_loss: 3.61900e-02
I0211 06:43:06.038224 22542570456896 run_lib.py:133] step: 672750, training_loss: 2.29155e-02
I0211 06:43:23.450311 22542570456896 run_lib.py:133] step: 672800, training_loss: 2.60161e-02
I0211 06:43:23.606358 22542570456896 run_lib.py:146] step: 672800, eval_loss: 2.94644e-02
I0211 06:43:41.008233 22542570456896 run_lib.py:133] step: 672850, training_loss: 3.17168e-02
I0211 06:43:58.582125 22542570456896 run_lib.py:133] step: 672900, training_loss: 2.23564e-02
I0211 06:43:58.752550 22542570456896 run_lib.py:146] step: 672900, eval_loss: 3.50122e-02
I0211 06:44:16.180561 22542570456896 run_lib.py:133] step: 672950, training_loss: 2.69712e-02
I0211 06:44:33.622414 22542570456896 run_lib.py:133] step: 673000, training_loss: 2.88204e-02
I0211 06:44:33.785523 22542570456896 run_lib.py:146] step: 673000, eval_loss: 3.02832e-02
I0211 06:44:51.282444 22542570456896 run_lib.py:133] step: 673050, training_loss: 2.98186e-02
I0211 06:45:08.699668 22542570456896 run_lib.py:133] step: 673100, training_loss: 2.53078e-02
I0211 06:45:08.857152 22542570456896 run_lib.py:146] step: 673100, eval_loss: 2.35212e-02
I0211 06:45:26.287854 22542570456896 run_lib.py:133] step: 673150, training_loss: 2.00392e-02
I0211 06:45:43.751313 22542570456896 run_lib.py:133] step: 673200, training_loss: 2.82449e-02
I0211 06:45:43.899308 22542570456896 run_lib.py:146] step: 673200, eval_loss: 3.18023e-02
I0211 06:46:01.462022 22542570456896 run_lib.py:133] step: 673250, training_loss: 3.22668e-02
I0211 06:46:18.949975 22542570456896 run_lib.py:133] step: 673300, training_loss: 2.41662e-02
I0211 06:46:19.119486 22542570456896 run_lib.py:146] step: 673300, eval_loss: 2.20723e-02
I0211 06:46:36.593117 22542570456896 run_lib.py:133] step: 673350, training_loss: 3.39685e-02
I0211 06:46:54.015661 22542570456896 run_lib.py:133] step: 673400, training_loss: 2.84026e-02
I0211 06:46:54.174312 22542570456896 run_lib.py:146] step: 673400, eval_loss: 3.34564e-02
I0211 06:47:11.763184 22542570456896 run_lib.py:133] step: 673450, training_loss: 2.90449e-02
I0211 06:47:29.158069 22542570456896 run_lib.py:133] step: 673500, training_loss: 3.17671e-02
I0211 06:47:29.326342 22542570456896 run_lib.py:146] step: 673500, eval_loss: 2.82166e-02
I0211 06:47:46.850116 22542570456896 run_lib.py:133] step: 673550, training_loss: 2.68851e-02
I0211 06:48:04.330851 22542570456896 run_lib.py:133] step: 673600, training_loss: 2.12978e-02
I0211 06:48:04.486505 22542570456896 run_lib.py:146] step: 673600, eval_loss: 2.86621e-02
I0211 06:48:22.073721 22542570456896 run_lib.py:133] step: 673650, training_loss: 2.86975e-02
I0211 06:48:39.490540 22542570456896 run_lib.py:133] step: 673700, training_loss: 2.04850e-02
I0211 06:48:39.643297 22542570456896 run_lib.py:146] step: 673700, eval_loss: 2.83530e-02
I0211 06:48:57.203178 22542570456896 run_lib.py:133] step: 673750, training_loss: 2.94218e-02
I0211 06:49:14.611908 22542570456896 run_lib.py:133] step: 673800, training_loss: 2.74938e-02
I0211 06:49:14.771507 22542570456896 run_lib.py:146] step: 673800, eval_loss: 2.91447e-02
I0211 06:49:32.191478 22542570456896 run_lib.py:133] step: 673850, training_loss: 2.08258e-02
I0211 06:49:49.774656 22542570456896 run_lib.py:133] step: 673900, training_loss: 2.15885e-02
I0211 06:49:49.929675 22542570456896 run_lib.py:146] step: 673900, eval_loss: 3.29047e-02
I0211 06:50:07.323031 22542570456896 run_lib.py:133] step: 673950, training_loss: 2.88168e-02
I0211 06:50:24.765141 22542570456896 run_lib.py:133] step: 674000, training_loss: 2.88694e-02
I0211 06:50:24.921438 22542570456896 run_lib.py:146] step: 674000, eval_loss: 3.04034e-02
I0211 06:50:42.482884 22542570456896 run_lib.py:133] step: 674050, training_loss: 3.48448e-02
I0211 06:50:59.853473 22542570456896 run_lib.py:133] step: 674100, training_loss: 3.15879e-02
I0211 06:51:00.007140 22542570456896 run_lib.py:146] step: 674100, eval_loss: 2.87713e-02
I0211 06:51:17.626599 22542570456896 run_lib.py:133] step: 674150, training_loss: 3.02087e-02
I0211 06:51:35.085702 22542570456896 run_lib.py:133] step: 674200, training_loss: 2.51927e-02
I0211 06:51:35.245183 22542570456896 run_lib.py:146] step: 674200, eval_loss: 2.69496e-02
I0211 06:51:52.659134 22542570456896 run_lib.py:133] step: 674250, training_loss: 3.05369e-02
I0211 06:52:10.263785 22542570456896 run_lib.py:133] step: 674300, training_loss: 3.11457e-02
I0211 06:52:10.422592 22542570456896 run_lib.py:146] step: 674300, eval_loss: 3.11716e-02
I0211 06:52:27.816612 22542570456896 run_lib.py:133] step: 674350, training_loss: 3.07689e-02
I0211 06:52:45.260588 22542570456896 run_lib.py:133] step: 674400, training_loss: 2.91012e-02
I0211 06:52:45.419213 22542570456896 run_lib.py:146] step: 674400, eval_loss: 2.55059e-02
I0211 06:53:02.857573 22542570456896 run_lib.py:133] step: 674450, training_loss: 2.35492e-02
I0211 06:53:20.508301 22542570456896 run_lib.py:133] step: 674500, training_loss: 2.06453e-02
I0211 06:53:20.684603 22542570456896 run_lib.py:146] step: 674500, eval_loss: 2.53676e-02
I0211 06:53:38.131537 22542570456896 run_lib.py:133] step: 674550, training_loss: 3.20790e-02
I0211 06:53:55.597676 22542570456896 run_lib.py:133] step: 674600, training_loss: 2.64005e-02
I0211 06:53:55.749192 22542570456896 run_lib.py:146] step: 674600, eval_loss: 2.27762e-02
I0211 06:54:13.155612 22542570456896 run_lib.py:133] step: 674650, training_loss: 3.08444e-02
I0211 06:54:30.565784 22542570456896 run_lib.py:133] step: 674700, training_loss: 2.35512e-02
I0211 06:54:30.746089 22542570456896 run_lib.py:146] step: 674700, eval_loss: 2.28180e-02
I0211 06:54:48.329387 22542570456896 run_lib.py:133] step: 674750, training_loss: 2.63342e-02
I0211 06:55:05.868416 22542570456896 run_lib.py:133] step: 674800, training_loss: 2.73822e-02
I0211 06:55:06.023297 22542570456896 run_lib.py:146] step: 674800, eval_loss: 2.95967e-02
I0211 06:55:23.427091 22542570456896 run_lib.py:133] step: 674850, training_loss: 2.46925e-02
I0211 06:55:40.847897 22542570456896 run_lib.py:133] step: 674900, training_loss: 2.97562e-02
I0211 06:55:41.003271 22542570456896 run_lib.py:146] step: 674900, eval_loss: 2.80369e-02
I0211 06:55:58.553658 22542570456896 run_lib.py:133] step: 674950, training_loss: 2.83193e-02
I0211 06:56:16.074289 22542570456896 run_lib.py:133] step: 675000, training_loss: 3.48432e-02
I0211 06:56:16.242677 22542570456896 run_lib.py:146] step: 675000, eval_loss: 2.36096e-02
I0211 06:56:33.882200 22542570456896 run_lib.py:133] step: 675050, training_loss: 2.60557e-02
I0211 06:56:51.281602 22542570456896 run_lib.py:133] step: 675100, training_loss: 3.56900e-02
I0211 06:56:51.432277 22542570456896 run_lib.py:146] step: 675100, eval_loss: 3.08386e-02
I0211 06:57:08.984317 22542570456896 run_lib.py:133] step: 675150, training_loss: 2.07364e-02
I0211 06:57:26.403321 22542570456896 run_lib.py:133] step: 675200, training_loss: 2.46021e-02
I0211 06:57:26.558379 22542570456896 run_lib.py:146] step: 675200, eval_loss: 2.97583e-02
I0211 06:57:43.948718 22542570456896 run_lib.py:133] step: 675250, training_loss: 3.45829e-02
I0211 06:58:01.580751 22542570456896 run_lib.py:133] step: 675300, training_loss: 3.08292e-02
I0211 06:58:01.738833 22542570456896 run_lib.py:146] step: 675300, eval_loss: 2.64029e-02
I0211 06:58:19.143557 22542570456896 run_lib.py:133] step: 675350, training_loss: 2.64691e-02
I0211 06:58:36.742082 22542570456896 run_lib.py:133] step: 675400, training_loss: 2.81680e-02
I0211 06:58:36.898942 22542570456896 run_lib.py:146] step: 675400, eval_loss: 2.85096e-02
I0211 06:58:54.307126 22542570456896 run_lib.py:133] step: 675450, training_loss: 3.33389e-02
I0211 06:59:11.711048 22542570456896 run_lib.py:133] step: 675500, training_loss: 2.57619e-02
I0211 06:59:11.865083 22542570456896 run_lib.py:146] step: 675500, eval_loss: 3.24152e-02
I0211 06:59:29.437358 22542570456896 run_lib.py:133] step: 675550, training_loss: 3.44600e-02
I0211 06:59:46.935525 22542570456896 run_lib.py:133] step: 675600, training_loss: 2.56723e-02
I0211 06:59:47.089525 22542570456896 run_lib.py:146] step: 675600, eval_loss: 2.38187e-02
I0211 07:00:04.510720 22542570456896 run_lib.py:133] step: 675650, training_loss: 2.36801e-02
I0211 07:00:22.164899 22542570456896 run_lib.py:133] step: 675700, training_loss: 2.67246e-02
I0211 07:00:22.322220 22542570456896 run_lib.py:146] step: 675700, eval_loss: 2.86660e-02
I0211 07:00:39.737170 22542570456896 run_lib.py:133] step: 675750, training_loss: 2.73197e-02
I0211 07:00:57.129561 22542570456896 run_lib.py:133] step: 675800, training_loss: 3.03402e-02
I0211 07:00:57.439277 22542570456896 run_lib.py:146] step: 675800, eval_loss: 2.98194e-02
I0211 07:01:14.915516 22542570456896 run_lib.py:133] step: 675850, training_loss: 2.92598e-02
I0211 07:01:32.371311 22542570456896 run_lib.py:133] step: 675900, training_loss: 3.19779e-02
I0211 07:01:32.527552 22542570456896 run_lib.py:146] step: 675900, eval_loss: 3.50270e-02
I0211 07:01:49.956416 22542570456896 run_lib.py:133] step: 675950, training_loss: 3.61872e-02
I0211 07:02:07.364122 22542570456896 run_lib.py:133] step: 676000, training_loss: 3.29031e-02
I0211 07:02:07.517140 22542570456896 run_lib.py:146] step: 676000, eval_loss: 3.45350e-02
I0211 07:02:25.140878 22542570456896 run_lib.py:133] step: 676050, training_loss: 3.14425e-02
I0211 07:02:42.677198 22542570456896 run_lib.py:133] step: 676100, training_loss: 2.77180e-02
I0211 07:02:42.841254 22542570456896 run_lib.py:146] step: 676100, eval_loss: 3.43570e-02
I0211 07:03:00.355977 22542570456896 run_lib.py:133] step: 676150, training_loss: 2.87986e-02
I0211 07:03:17.787630 22542570456896 run_lib.py:133] step: 676200, training_loss: 2.45126e-02
I0211 07:03:17.941673 22542570456896 run_lib.py:146] step: 676200, eval_loss: 2.89146e-02
I0211 07:03:35.515331 22542570456896 run_lib.py:133] step: 676250, training_loss: 2.95720e-02
I0211 07:03:52.972434 22542570456896 run_lib.py:133] step: 676300, training_loss: 2.92119e-02
I0211 07:03:53.127274 22542570456896 run_lib.py:146] step: 676300, eval_loss: 3.26427e-02
I0211 07:04:10.623472 22542570456896 run_lib.py:133] step: 676350, training_loss: 2.57565e-02
I0211 07:04:28.125702 22542570456896 run_lib.py:133] step: 676400, training_loss: 2.58570e-02
I0211 07:04:28.282847 22542570456896 run_lib.py:146] step: 676400, eval_loss: 4.02199e-02
I0211 07:04:45.896182 22542570456896 run_lib.py:133] step: 676450, training_loss: 2.57865e-02
I0211 07:05:03.323838 22542570456896 run_lib.py:133] step: 676500, training_loss: 3.04058e-02
I0211 07:05:03.476504 22542570456896 run_lib.py:146] step: 676500, eval_loss: 2.55001e-02
I0211 07:05:21.020898 22542570456896 run_lib.py:133] step: 676550, training_loss: 2.46691e-02
I0211 07:05:38.444077 22542570456896 run_lib.py:133] step: 676600, training_loss: 2.42118e-02
I0211 07:05:38.604452 22542570456896 run_lib.py:146] step: 676600, eval_loss: 3.34039e-02
I0211 07:05:56.163707 22542570456896 run_lib.py:133] step: 676650, training_loss: 2.80316e-02
I0211 07:06:13.618575 22542570456896 run_lib.py:133] step: 676700, training_loss: 2.21099e-02
I0211 07:06:13.776310 22542570456896 run_lib.py:146] step: 676700, eval_loss: 2.67493e-02
I0211 07:06:31.232242 22542570456896 run_lib.py:133] step: 676750, training_loss: 2.73287e-02
I0211 07:06:48.789456 22542570456896 run_lib.py:133] step: 676800, training_loss: 2.25241e-02
I0211 07:06:48.941566 22542570456896 run_lib.py:146] step: 676800, eval_loss: 2.78160e-02
I0211 07:07:06.420578 22542570456896 run_lib.py:133] step: 676850, training_loss: 2.33443e-02
I0211 07:07:24.023255 22542570456896 run_lib.py:133] step: 676900, training_loss: 2.90115e-02
I0211 07:07:24.186580 22542570456896 run_lib.py:146] step: 676900, eval_loss: 2.54291e-02
I0211 07:07:41.656174 22542570456896 run_lib.py:133] step: 676950, training_loss: 2.71930e-02
I0211 07:07:59.092364 22542570456896 run_lib.py:133] step: 677000, training_loss: 2.59235e-02
I0211 07:07:59.244420 22542570456896 run_lib.py:146] step: 677000, eval_loss: 3.01160e-02
I0211 07:08:16.863900 22542570456896 run_lib.py:133] step: 677050, training_loss: 2.55286e-02
I0211 07:08:34.303107 22542570456896 run_lib.py:133] step: 677100, training_loss: 2.40451e-02
I0211 07:08:34.458222 22542570456896 run_lib.py:146] step: 677100, eval_loss: 2.32957e-02
I0211 07:08:51.870796 22542570456896 run_lib.py:133] step: 677150, training_loss: 3.15696e-02
I0211 07:09:09.259549 22542570456896 run_lib.py:133] step: 677200, training_loss: 3.07400e-02
I0211 07:09:09.431391 22542570456896 run_lib.py:146] step: 677200, eval_loss: 3.85467e-02
I0211 07:09:27.061557 22542570456896 run_lib.py:133] step: 677250, training_loss: 3.04271e-02
I0211 07:09:44.487435 22542570456896 run_lib.py:133] step: 677300, training_loss: 2.54842e-02
I0211 07:09:44.646031 22542570456896 run_lib.py:146] step: 677300, eval_loss: 3.07790e-02
I0211 07:10:02.238817 22542570456896 run_lib.py:133] step: 677350, training_loss: 2.65322e-02
I0211 07:10:19.663987 22542570456896 run_lib.py:133] step: 677400, training_loss: 3.34602e-02
I0211 07:10:19.816170 22542570456896 run_lib.py:146] step: 677400, eval_loss: 2.49981e-02
I0211 07:10:37.225628 22542570456896 run_lib.py:133] step: 677450, training_loss: 3.64282e-02
I0211 07:10:54.683990 22542570456896 run_lib.py:133] step: 677500, training_loss: 3.01925e-02
I0211 07:10:54.846718 22542570456896 run_lib.py:146] step: 677500, eval_loss: 2.69912e-02
I0211 07:11:12.439371 22542570456896 run_lib.py:133] step: 677550, training_loss: 2.88170e-02
I0211 07:11:29.949441 22542570456896 run_lib.py:133] step: 677600, training_loss: 2.82322e-02
I0211 07:11:30.107228 22542570456896 run_lib.py:146] step: 677600, eval_loss: 2.60149e-02
I0211 07:11:47.535266 22542570456896 run_lib.py:133] step: 677650, training_loss: 2.90098e-02
I0211 07:12:04.915365 22542570456896 run_lib.py:133] step: 677700, training_loss: 2.40335e-02
I0211 07:12:05.087445 22542570456896 run_lib.py:146] step: 677700, eval_loss: 3.06470e-02
I0211 07:12:22.667676 22542570456896 run_lib.py:133] step: 677750, training_loss: 2.18317e-02
I0211 07:12:40.135756 22542570456896 run_lib.py:133] step: 677800, training_loss: 2.68851e-02
I0211 07:12:40.291118 22542570456896 run_lib.py:146] step: 677800, eval_loss: 2.61861e-02
I0211 07:12:57.928977 22542570456896 run_lib.py:133] step: 677850, training_loss: 2.38983e-02
I0211 07:13:15.329051 22542570456896 run_lib.py:133] step: 677900, training_loss: 2.78699e-02
I0211 07:13:15.481085 22542570456896 run_lib.py:146] step: 677900, eval_loss: 2.66799e-02
I0211 07:13:33.115113 22542570456896 run_lib.py:133] step: 677950, training_loss: 2.48268e-02
I0211 07:13:50.512530 22542570456896 run_lib.py:133] step: 678000, training_loss: 2.52295e-02
I0211 07:13:50.663831 22542570456896 run_lib.py:146] step: 678000, eval_loss: 3.57093e-02
I0211 07:14:08.272545 22542570456896 run_lib.py:133] step: 678050, training_loss: 2.55528e-02
I0211 07:14:25.737102 22542570456896 run_lib.py:133] step: 678100, training_loss: 3.00592e-02
I0211 07:14:25.898287 22542570456896 run_lib.py:146] step: 678100, eval_loss: 2.30422e-02
I0211 07:14:43.291489 22542570456896 run_lib.py:133] step: 678150, training_loss: 2.90424e-02
I0211 07:15:00.821780 22542570456896 run_lib.py:133] step: 678200, training_loss: 2.93905e-02
I0211 07:15:00.977267 22542570456896 run_lib.py:146] step: 678200, eval_loss: 3.25821e-02
I0211 07:15:18.386744 22542570456896 run_lib.py:133] step: 678250, training_loss: 2.47451e-02
I0211 07:15:35.853589 22542570456896 run_lib.py:133] step: 678300, training_loss: 2.54792e-02
I0211 07:15:36.009401 22542570456896 run_lib.py:146] step: 678300, eval_loss: 2.63788e-02
I0211 07:15:53.623878 22542570456896 run_lib.py:133] step: 678350, training_loss: 2.42818e-02
I0211 07:16:11.280869 22542570456896 run_lib.py:133] step: 678400, training_loss: 2.68708e-02
I0211 07:16:11.433581 22542570456896 run_lib.py:146] step: 678400, eval_loss: 2.54473e-02
I0211 07:16:28.885618 22542570456896 run_lib.py:133] step: 678450, training_loss: 2.49986e-02
I0211 07:16:46.361862 22542570456896 run_lib.py:133] step: 678500, training_loss: 3.27042e-02
I0211 07:16:46.517289 22542570456896 run_lib.py:146] step: 678500, eval_loss: 2.92052e-02
I0211 07:17:03.921175 22542570456896 run_lib.py:133] step: 678550, training_loss: 2.36262e-02
I0211 07:17:21.527286 22542570456896 run_lib.py:133] step: 678600, training_loss: 2.62763e-02
I0211 07:17:21.704394 22542570456896 run_lib.py:146] step: 678600, eval_loss: 2.77050e-02
I0211 07:17:39.169098 22542570456896 run_lib.py:133] step: 678650, training_loss: 3.63800e-02
I0211 07:17:56.575439 22542570456896 run_lib.py:133] step: 678700, training_loss: 1.83026e-02
I0211 07:17:56.738711 22542570456896 run_lib.py:146] step: 678700, eval_loss: 3.36915e-02
I0211 07:18:14.182620 22542570456896 run_lib.py:133] step: 678750, training_loss: 2.96442e-02
I0211 07:18:31.773586 22542570456896 run_lib.py:133] step: 678800, training_loss: 2.32139e-02
I0211 07:18:31.925612 22542570456896 run_lib.py:146] step: 678800, eval_loss: 3.28837e-02
I0211 07:18:49.350105 22542570456896 run_lib.py:133] step: 678850, training_loss: 2.42500e-02
I0211 07:19:06.891276 22542570456896 run_lib.py:133] step: 678900, training_loss: 2.56879e-02
I0211 07:19:07.051448 22542570456896 run_lib.py:146] step: 678900, eval_loss: 2.64567e-02
I0211 07:19:24.466114 22542570456896 run_lib.py:133] step: 678950, training_loss: 2.95057e-02
I0211 07:19:41.909708 22542570456896 run_lib.py:133] step: 679000, training_loss: 2.35869e-02
I0211 07:19:42.064574 22542570456896 run_lib.py:146] step: 679000, eval_loss: 3.15271e-02
I0211 07:19:59.706133 22542570456896 run_lib.py:133] step: 679050, training_loss: 2.78379e-02
I0211 07:20:17.244068 22542570456896 run_lib.py:133] step: 679100, training_loss: 2.70542e-02
I0211 07:20:17.416522 22542570456896 run_lib.py:146] step: 679100, eval_loss: 2.41627e-02
I0211 07:20:34.862660 22542570456896 run_lib.py:133] step: 679150, training_loss: 2.66036e-02
I0211 07:20:52.281038 22542570456896 run_lib.py:133] step: 679200, training_loss: 2.71516e-02
I0211 07:20:52.436190 22542570456896 run_lib.py:146] step: 679200, eval_loss: 2.57742e-02
I0211 07:21:10.035560 22542570456896 run_lib.py:133] step: 679250, training_loss: 2.60251e-02
I0211 07:21:27.449197 22542570456896 run_lib.py:133] step: 679300, training_loss: 2.23198e-02
I0211 07:21:27.605372 22542570456896 run_lib.py:146] step: 679300, eval_loss: 2.44663e-02
I0211 07:21:45.186180 22542570456896 run_lib.py:133] step: 679350, training_loss: 2.03603e-02
I0211 07:22:02.608469 22542570456896 run_lib.py:133] step: 679400, training_loss: 2.48152e-02
I0211 07:22:02.780311 22542570456896 run_lib.py:146] step: 679400, eval_loss: 2.90440e-02
I0211 07:22:20.428750 22542570456896 run_lib.py:133] step: 679450, training_loss: 3.63295e-02
I0211 07:22:37.875248 22542570456896 run_lib.py:133] step: 679500, training_loss: 2.44401e-02
I0211 07:22:38.032297 22542570456896 run_lib.py:146] step: 679500, eval_loss: 2.85401e-02
I0211 07:22:55.435052 22542570456896 run_lib.py:133] step: 679550, training_loss: 2.64626e-02
I0211 07:23:12.991041 22542570456896 run_lib.py:133] step: 679600, training_loss: 2.35860e-02
I0211 07:23:13.146277 22542570456896 run_lib.py:146] step: 679600, eval_loss: 3.25727e-02
I0211 07:23:30.573799 22542570456896 run_lib.py:133] step: 679650, training_loss: 2.58810e-02
I0211 07:23:48.157539 22542570456896 run_lib.py:133] step: 679700, training_loss: 2.35453e-02
I0211 07:23:48.312279 22542570456896 run_lib.py:146] step: 679700, eval_loss: 2.98528e-02
I0211 07:24:05.742596 22542570456896 run_lib.py:133] step: 679750, training_loss: 2.43600e-02
I0211 07:24:23.125791 22542570456896 run_lib.py:133] step: 679800, training_loss: 3.26402e-02
I0211 07:24:23.284272 22542570456896 run_lib.py:146] step: 679800, eval_loss: 2.64703e-02
I0211 07:24:40.921257 22542570456896 run_lib.py:133] step: 679850, training_loss: 2.40768e-02
I0211 07:24:58.334443 22542570456896 run_lib.py:133] step: 679900, training_loss: 2.61483e-02
I0211 07:24:58.489425 22542570456896 run_lib.py:146] step: 679900, eval_loss: 3.40007e-02
I0211 07:25:15.939614 22542570456896 run_lib.py:133] step: 679950, training_loss: 2.85383e-02
I0211 07:25:33.492592 22542570456896 run_lib.py:133] step: 680000, training_loss: 3.00372e-02
I0211 07:25:34.216278 22542570456896 run_lib.py:146] step: 680000, eval_loss: 2.59611e-02
I0211 07:25:54.316568 22542570456896 run_lib.py:133] step: 680050, training_loss: 2.68979e-02
I0211 07:26:11.691912 22542570456896 run_lib.py:133] step: 680100, training_loss: 2.47419e-02
I0211 07:26:11.849356 22542570456896 run_lib.py:146] step: 680100, eval_loss: 2.65897e-02
I0211 07:26:29.216518 22542570456896 run_lib.py:133] step: 680150, training_loss: 2.82527e-02
I0211 07:26:46.777349 22542570456896 run_lib.py:133] step: 680200, training_loss: 2.62320e-02
I0211 07:26:46.931331 22542570456896 run_lib.py:146] step: 680200, eval_loss: 3.26425e-02
I0211 07:27:04.364333 22542570456896 run_lib.py:133] step: 680250, training_loss: 3.21276e-02
I0211 07:27:21.799199 22542570456896 run_lib.py:133] step: 680300, training_loss: 2.73771e-02
I0211 07:27:21.954542 22542570456896 run_lib.py:146] step: 680300, eval_loss: 2.41335e-02
I0211 07:27:39.569746 22542570456896 run_lib.py:133] step: 680350, training_loss: 2.59079e-02
I0211 07:27:56.942246 22542570456896 run_lib.py:133] step: 680400, training_loss: 2.29987e-02
I0211 07:27:57.093453 22542570456896 run_lib.py:146] step: 680400, eval_loss: 2.57511e-02
I0211 07:28:14.597557 22542570456896 run_lib.py:133] step: 680450, training_loss: 2.48385e-02
I0211 07:28:31.996583 22542570456896 run_lib.py:133] step: 680500, training_loss: 2.67876e-02
I0211 07:28:32.152548 22542570456896 run_lib.py:146] step: 680500, eval_loss: 2.85458e-02
I0211 07:28:49.612403 22542570456896 run_lib.py:133] step: 680550, training_loss: 3.12962e-02
I0211 07:29:07.096300 22542570456896 run_lib.py:133] step: 680600, training_loss: 2.77712e-02
I0211 07:29:07.248816 22542570456896 run_lib.py:146] step: 680600, eval_loss: 3.26989e-02
I0211 07:29:24.838528 22542570456896 run_lib.py:133] step: 680650, training_loss: 2.64410e-02
I0211 07:29:42.296861 22542570456896 run_lib.py:133] step: 680700, training_loss: 3.06003e-02
I0211 07:29:42.451400 22542570456896 run_lib.py:146] step: 680700, eval_loss: 2.36531e-02
I0211 07:29:59.864264 22542570456896 run_lib.py:133] step: 680750, training_loss: 2.45509e-02
I0211 07:30:17.249331 22542570456896 run_lib.py:133] step: 680800, training_loss: 2.77928e-02
I0211 07:30:17.403470 22542570456896 run_lib.py:146] step: 680800, eval_loss: 2.71472e-02
I0211 07:30:34.952416 22542570456896 run_lib.py:133] step: 680850, training_loss: 2.35343e-02
I0211 07:30:52.433482 22542570456896 run_lib.py:133] step: 680900, training_loss: 2.24406e-02
I0211 07:30:52.590260 22542570456896 run_lib.py:146] step: 680900, eval_loss: 2.97305e-02
I0211 07:31:10.202760 22542570456896 run_lib.py:133] step: 680950, training_loss: 2.52326e-02
I0211 07:31:27.667845 22542570456896 run_lib.py:133] step: 681000, training_loss: 3.06790e-02
I0211 07:31:27.826592 22542570456896 run_lib.py:146] step: 681000, eval_loss: 2.67789e-02
I0211 07:31:45.368180 22542570456896 run_lib.py:133] step: 681050, training_loss: 2.19156e-02
I0211 07:32:02.750335 22542570456896 run_lib.py:133] step: 681100, training_loss: 2.20839e-02
I0211 07:32:02.911347 22542570456896 run_lib.py:146] step: 681100, eval_loss: 2.97675e-02
I0211 07:32:20.511995 22542570456896 run_lib.py:133] step: 681150, training_loss: 2.94300e-02
I0211 07:32:37.926012 22542570456896 run_lib.py:133] step: 681200, training_loss: 2.85554e-02
I0211 07:32:38.080662 22542570456896 run_lib.py:146] step: 681200, eval_loss: 2.31444e-02
I0211 07:32:55.502799 22542570456896 run_lib.py:133] step: 681250, training_loss: 2.36680e-02
I0211 07:33:13.117143 22542570456896 run_lib.py:133] step: 681300, training_loss: 2.76736e-02
I0211 07:33:13.264562 22542570456896 run_lib.py:146] step: 681300, eval_loss: 2.57434e-02
I0211 07:33:30.658956 22542570456896 run_lib.py:133] step: 681350, training_loss: 2.71601e-02
I0211 07:33:47.976861 22542570456896 run_lib.py:133] step: 681400, training_loss: 2.51786e-02
I0211 07:33:48.141387 22542570456896 run_lib.py:146] step: 681400, eval_loss: 3.16546e-02
I0211 07:34:05.700166 22542570456896 run_lib.py:133] step: 681450, training_loss: 2.14630e-02
I0211 07:34:23.056573 22542570456896 run_lib.py:133] step: 681500, training_loss: 2.95843e-02
I0211 07:34:23.213122 22542570456896 run_lib.py:146] step: 681500, eval_loss: 2.55448e-02
I0211 07:34:40.660391 22542570456896 run_lib.py:133] step: 681550, training_loss: 2.99680e-02
I0211 07:34:58.137358 22542570456896 run_lib.py:133] step: 681600, training_loss: 2.32755e-02
I0211 07:34:58.293458 22542570456896 run_lib.py:146] step: 681600, eval_loss: 3.49985e-02
I0211 07:35:15.720685 22542570456896 run_lib.py:133] step: 681650, training_loss: 2.60207e-02
I0211 07:35:33.302790 22542570456896 run_lib.py:133] step: 681700, training_loss: 3.23515e-02
I0211 07:35:33.469402 22542570456896 run_lib.py:146] step: 681700, eval_loss: 2.73895e-02
I0211 07:35:50.921669 22542570456896 run_lib.py:133] step: 681750, training_loss: 2.32615e-02
I0211 07:36:08.381733 22542570456896 run_lib.py:133] step: 681800, training_loss: 2.82526e-02
I0211 07:36:08.535659 22542570456896 run_lib.py:146] step: 681800, eval_loss: 2.71556e-02
I0211 07:36:25.952561 22542570456896 run_lib.py:133] step: 681850, training_loss: 2.25431e-02
I0211 07:36:43.560650 22542570456896 run_lib.py:133] step: 681900, training_loss: 2.61923e-02
I0211 07:36:43.714354 22542570456896 run_lib.py:146] step: 681900, eval_loss: 2.98330e-02
I0211 07:37:01.126489 22542570456896 run_lib.py:133] step: 681950, training_loss: 2.39261e-02
I0211 07:37:18.696045 22542570456896 run_lib.py:133] step: 682000, training_loss: 2.21305e-02
I0211 07:37:18.875271 22542570456896 run_lib.py:146] step: 682000, eval_loss: 2.81433e-02
I0211 07:37:36.301067 22542570456896 run_lib.py:133] step: 682050, training_loss: 2.69139e-02
I0211 07:37:53.759100 22542570456896 run_lib.py:133] step: 682100, training_loss: 2.40840e-02
I0211 07:37:53.914571 22542570456896 run_lib.py:146] step: 682100, eval_loss: 4.27746e-02
I0211 07:38:11.514785 22542570456896 run_lib.py:133] step: 682150, training_loss: 3.15957e-02
I0211 07:38:28.985395 22542570456896 run_lib.py:133] step: 682200, training_loss: 3.51330e-02
I0211 07:38:29.139380 22542570456896 run_lib.py:146] step: 682200, eval_loss: 2.72099e-02
I0211 07:38:46.546212 22542570456896 run_lib.py:133] step: 682250, training_loss: 2.80962e-02
I0211 07:39:03.987332 22542570456896 run_lib.py:133] step: 682300, training_loss: 2.67518e-02
I0211 07:39:04.142691 22542570456896 run_lib.py:146] step: 682300, eval_loss: 2.98041e-02
I0211 07:39:21.834696 22542570456896 run_lib.py:133] step: 682350, training_loss: 2.75853e-02
I0211 07:39:39.320237 22542570456896 run_lib.py:133] step: 682400, training_loss: 2.77108e-02
I0211 07:39:39.480516 22542570456896 run_lib.py:146] step: 682400, eval_loss: 2.59739e-02
I0211 07:39:57.021603 22542570456896 run_lib.py:133] step: 682450, training_loss: 3.15181e-02
I0211 07:40:14.422943 22542570456896 run_lib.py:133] step: 682500, training_loss: 2.98999e-02
I0211 07:40:14.581557 22542570456896 run_lib.py:146] step: 682500, eval_loss: 3.65275e-02
I0211 07:40:32.163838 22542570456896 run_lib.py:133] step: 682550, training_loss: 3.53257e-02
I0211 07:40:49.669949 22542570456896 run_lib.py:133] step: 682600, training_loss: 2.47220e-02
I0211 07:40:49.826826 22542570456896 run_lib.py:146] step: 682600, eval_loss: 3.56254e-02
I0211 07:41:07.258712 22542570456896 run_lib.py:133] step: 682650, training_loss: 2.67281e-02
I0211 07:41:24.834973 22542570456896 run_lib.py:133] step: 682700, training_loss: 2.96753e-02
I0211 07:41:24.989026 22542570456896 run_lib.py:146] step: 682700, eval_loss: 3.02713e-02
I0211 07:41:42.387714 22542570456896 run_lib.py:133] step: 682750, training_loss: 3.26030e-02
I0211 07:41:59.976865 22542570456896 run_lib.py:133] step: 682800, training_loss: 2.36887e-02
I0211 07:42:00.141388 22542570456896 run_lib.py:146] step: 682800, eval_loss: 2.73587e-02
I0211 07:42:17.601713 22542570456896 run_lib.py:133] step: 682850, training_loss: 2.26266e-02
I0211 07:42:34.996220 22542570456896 run_lib.py:133] step: 682900, training_loss: 2.49729e-02
I0211 07:42:35.153315 22542570456896 run_lib.py:146] step: 682900, eval_loss: 2.59821e-02
I0211 07:42:52.778574 22542570456896 run_lib.py:133] step: 682950, training_loss: 2.72262e-02
I0211 07:43:10.215237 22542570456896 run_lib.py:133] step: 683000, training_loss: 3.03588e-02
I0211 07:43:10.370357 22542570456896 run_lib.py:146] step: 683000, eval_loss: 1.98193e-02
I0211 07:43:27.791584 22542570456896 run_lib.py:133] step: 683050, training_loss: 2.34381e-02
I0211 07:43:45.378800 22542570456896 run_lib.py:133] step: 683100, training_loss: 3.40527e-02
I0211 07:43:45.536367 22542570456896 run_lib.py:146] step: 683100, eval_loss: 2.70649e-02
I0211 07:44:02.977867 22542570456896 run_lib.py:133] step: 683150, training_loss: 3.30803e-02
I0211 07:44:20.417398 22542570456896 run_lib.py:133] step: 683200, training_loss: 3.86737e-02
I0211 07:44:20.746930 22542570456896 run_lib.py:146] step: 683200, eval_loss: 3.21903e-02
I0211 07:44:38.156644 22542570456896 run_lib.py:133] step: 683250, training_loss: 3.28278e-02
I0211 07:44:55.562837 22542570456896 run_lib.py:133] step: 683300, training_loss: 2.83661e-02
I0211 07:44:55.717373 22542570456896 run_lib.py:146] step: 683300, eval_loss: 2.73742e-02
I0211 07:45:13.157261 22542570456896 run_lib.py:133] step: 683350, training_loss: 2.81402e-02
I0211 07:45:30.633778 22542570456896 run_lib.py:133] step: 683400, training_loss: 2.47034e-02
I0211 07:45:30.796343 22542570456896 run_lib.py:146] step: 683400, eval_loss: 3.15716e-02
I0211 07:45:48.418274 22542570456896 run_lib.py:133] step: 683450, training_loss: 3.08420e-02
I0211 07:46:05.910062 22542570456896 run_lib.py:133] step: 683500, training_loss: 2.70261e-02
I0211 07:46:06.065339 22542570456896 run_lib.py:146] step: 683500, eval_loss: 3.12867e-02
I0211 07:46:23.476276 22542570456896 run_lib.py:133] step: 683550, training_loss: 2.33830e-02
I0211 07:46:40.921695 22542570456896 run_lib.py:133] step: 683600, training_loss: 3.32182e-02
I0211 07:46:41.090311 22542570456896 run_lib.py:146] step: 683600, eval_loss: 2.71135e-02
I0211 07:46:58.648757 22542570456896 run_lib.py:133] step: 683650, training_loss: 2.87885e-02
I0211 07:47:16.183480 22542570456896 run_lib.py:133] step: 683700, training_loss: 2.02789e-02
I0211 07:47:16.341481 22542570456896 run_lib.py:146] step: 683700, eval_loss: 2.47836e-02
I0211 07:47:33.821760 22542570456896 run_lib.py:133] step: 683750, training_loss: 2.66579e-02
I0211 07:47:51.244095 22542570456896 run_lib.py:133] step: 683800, training_loss: 2.56645e-02
I0211 07:47:51.399287 22542570456896 run_lib.py:146] step: 683800, eval_loss: 3.07242e-02
I0211 07:48:08.935751 22542570456896 run_lib.py:133] step: 683850, training_loss: 2.52283e-02
I0211 07:48:26.311119 22542570456896 run_lib.py:133] step: 683900, training_loss: 3.06633e-02
I0211 07:48:26.487288 22542570456896 run_lib.py:146] step: 683900, eval_loss: 3.66428e-02
I0211 07:48:44.120923 22542570456896 run_lib.py:133] step: 683950, training_loss: 3.43180e-02
I0211 07:49:01.529610 22542570456896 run_lib.py:133] step: 684000, training_loss: 3.16295e-02
I0211 07:49:01.685423 22542570456896 run_lib.py:146] step: 684000, eval_loss: 3.72449e-02
I0211 07:49:19.283740 22542570456896 run_lib.py:133] step: 684050, training_loss: 2.57880e-02
I0211 07:49:36.671810 22542570456896 run_lib.py:133] step: 684100, training_loss: 2.67293e-02
I0211 07:49:36.826373 22542570456896 run_lib.py:146] step: 684100, eval_loss: 3.53677e-02
I0211 07:49:54.268084 22542570456896 run_lib.py:133] step: 684150, training_loss: 2.32279e-02
I0211 07:50:11.891858 22542570456896 run_lib.py:133] step: 684200, training_loss: 2.79132e-02
I0211 07:50:12.046637 22542570456896 run_lib.py:146] step: 684200, eval_loss: 3.70725e-02
I0211 07:50:29.486078 22542570456896 run_lib.py:133] step: 684250, training_loss: 2.70469e-02
I0211 07:50:47.077595 22542570456896 run_lib.py:133] step: 684300, training_loss: 2.81966e-02
I0211 07:50:47.237807 22542570456896 run_lib.py:146] step: 684300, eval_loss: 3.32920e-02
I0211 07:51:04.674986 22542570456896 run_lib.py:133] step: 684350, training_loss: 2.51738e-02
I0211 07:51:22.055712 22542570456896 run_lib.py:133] step: 684400, training_loss: 2.87049e-02
I0211 07:51:22.211464 22542570456896 run_lib.py:146] step: 684400, eval_loss: 2.96907e-02
I0211 07:51:39.739765 22542570456896 run_lib.py:133] step: 684450, training_loss: 2.15639e-02
I0211 07:51:57.193463 22542570456896 run_lib.py:133] step: 684500, training_loss: 3.46890e-02
I0211 07:51:57.348098 22542570456896 run_lib.py:146] step: 684500, eval_loss: 2.74531e-02
I0211 07:52:14.789033 22542570456896 run_lib.py:133] step: 684550, training_loss: 3.19258e-02
I0211 07:52:32.202391 22542570456896 run_lib.py:133] step: 684600, training_loss: 3.12548e-02
I0211 07:52:32.355436 22542570456896 run_lib.py:146] step: 684600, eval_loss: 2.99260e-02
I0211 07:52:49.936933 22542570456896 run_lib.py:133] step: 684650, training_loss: 2.58442e-02
I0211 07:53:07.366272 22542570456896 run_lib.py:133] step: 684700, training_loss: 3.01710e-02
I0211 07:53:07.519254 22542570456896 run_lib.py:146] step: 684700, eval_loss: 2.73242e-02
I0211 07:53:25.084882 22542570456896 run_lib.py:133] step: 684750, training_loss: 2.27853e-02
I0211 07:53:42.507639 22542570456896 run_lib.py:133] step: 684800, training_loss: 2.99357e-02
I0211 07:53:42.666245 22542570456896 run_lib.py:146] step: 684800, eval_loss: 3.20696e-02
I0211 07:54:00.082730 22542570456896 run_lib.py:133] step: 684850, training_loss: 2.85919e-02
I0211 07:54:17.465175 22542570456896 run_lib.py:133] step: 684900, training_loss: 3.75206e-02
I0211 07:54:17.621359 22542570456896 run_lib.py:146] step: 684900, eval_loss: 2.51656e-02
I0211 07:54:35.196528 22542570456896 run_lib.py:133] step: 684950, training_loss: 3.25781e-02
I0211 07:54:52.690114 22542570456896 run_lib.py:133] step: 685000, training_loss: 2.22741e-02
I0211 07:54:52.857425 22542570456896 run_lib.py:146] step: 685000, eval_loss: 2.37477e-02
I0211 07:55:10.314356 22542570456896 run_lib.py:133] step: 685050, training_loss: 2.88673e-02
I0211 07:55:27.729535 22542570456896 run_lib.py:133] step: 685100, training_loss: 2.91007e-02
I0211 07:55:27.881342 22542570456896 run_lib.py:146] step: 685100, eval_loss: 2.41702e-02
I0211 07:55:45.465906 22542570456896 run_lib.py:133] step: 685150, training_loss: 2.25736e-02
I0211 07:56:02.918023 22542570456896 run_lib.py:133] step: 685200, training_loss: 3.49113e-02
I0211 07:56:03.074232 22542570456896 run_lib.py:146] step: 685200, eval_loss: 2.48141e-02
I0211 07:56:20.556445 22542570456896 run_lib.py:133] step: 685250, training_loss: 2.11082e-02
I0211 07:56:37.996612 22542570456896 run_lib.py:133] step: 685300, training_loss: 3.12496e-02
I0211 07:56:38.183283 22542570456896 run_lib.py:146] step: 685300, eval_loss: 3.52275e-02
I0211 07:56:55.808844 22542570456896 run_lib.py:133] step: 685350, training_loss: 2.47040e-02
I0211 07:57:13.239536 22542570456896 run_lib.py:133] step: 685400, training_loss: 2.36185e-02
I0211 07:57:13.392575 22542570456896 run_lib.py:146] step: 685400, eval_loss: 2.71010e-02
I0211 07:57:30.976416 22542570456896 run_lib.py:133] step: 685450, training_loss: 2.25395e-02
I0211 07:57:48.381668 22542570456896 run_lib.py:133] step: 685500, training_loss: 3.26707e-02
I0211 07:57:48.539240 22542570456896 run_lib.py:146] step: 685500, eval_loss: 2.97258e-02
I0211 07:58:05.926052 22542570456896 run_lib.py:133] step: 685550, training_loss: 2.83695e-02
I0211 07:58:23.493179 22542570456896 run_lib.py:133] step: 685600, training_loss: 2.91774e-02
I0211 07:58:23.648529 22542570456896 run_lib.py:146] step: 685600, eval_loss: 2.93490e-02
I0211 07:58:41.079782 22542570456896 run_lib.py:133] step: 685650, training_loss: 2.13191e-02
I0211 07:58:58.501552 22542570456896 run_lib.py:133] step: 685700, training_loss: 2.93453e-02
I0211 07:58:58.657348 22542570456896 run_lib.py:146] step: 685700, eval_loss: 3.04792e-02
I0211 07:59:16.258109 22542570456896 run_lib.py:133] step: 685750, training_loss: 2.34151e-02
I0211 07:59:33.798525 22542570456896 run_lib.py:133] step: 685800, training_loss: 2.85612e-02
I0211 07:59:33.953366 22542570456896 run_lib.py:146] step: 685800, eval_loss: 3.09159e-02
I0211 07:59:51.365616 22542570456896 run_lib.py:133] step: 685850, training_loss: 2.76178e-02
I0211 08:00:08.847728 22542570456896 run_lib.py:133] step: 685900, training_loss: 2.80416e-02
I0211 08:00:09.002523 22542570456896 run_lib.py:146] step: 685900, eval_loss: 2.75531e-02
I0211 08:00:26.396336 22542570456896 run_lib.py:133] step: 685950, training_loss: 3.38293e-02
I0211 08:00:43.971841 22542570456896 run_lib.py:133] step: 686000, training_loss: 2.63665e-02
I0211 08:00:44.129230 22542570456896 run_lib.py:146] step: 686000, eval_loss: 2.88821e-02
I0211 08:01:01.545561 22542570456896 run_lib.py:133] step: 686050, training_loss: 2.71021e-02
I0211 08:01:18.933381 22542570456896 run_lib.py:133] step: 686100, training_loss: 2.84021e-02
I0211 08:01:19.085284 22542570456896 run_lib.py:146] step: 686100, eval_loss: 2.23780e-02
I0211 08:01:36.486533 22542570456896 run_lib.py:133] step: 686150, training_loss: 2.52839e-02
I0211 08:01:54.076267 22542570456896 run_lib.py:133] step: 686200, training_loss: 2.91300e-02
I0211 08:01:54.251269 22542570456896 run_lib.py:146] step: 686200, eval_loss: 3.48883e-02
I0211 08:02:11.676026 22542570456896 run_lib.py:133] step: 686250, training_loss: 2.44934e-02
I0211 08:02:29.200650 22542570456896 run_lib.py:133] step: 686300, training_loss: 3.39743e-02
I0211 08:02:29.355702 22542570456896 run_lib.py:146] step: 686300, eval_loss: 3.19222e-02
I0211 08:02:46.771168 22542570456896 run_lib.py:133] step: 686350, training_loss: 2.17065e-02
I0211 08:03:04.158674 22542570456896 run_lib.py:133] step: 686400, training_loss: 2.98419e-02
I0211 08:03:04.309751 22542570456896 run_lib.py:146] step: 686400, eval_loss: 2.67594e-02
I0211 08:03:21.880280 22542570456896 run_lib.py:133] step: 686450, training_loss: 3.31996e-02
I0211 08:03:39.443358 22542570456896 run_lib.py:133] step: 686500, training_loss: 2.88681e-02
I0211 08:03:39.597878 22542570456896 run_lib.py:146] step: 686500, eval_loss: 3.86897e-02
I0211 08:03:56.984924 22542570456896 run_lib.py:133] step: 686550, training_loss: 3.03413e-02
I0211 08:04:14.350298 22542570456896 run_lib.py:133] step: 686600, training_loss: 2.72664e-02
I0211 08:04:14.511806 22542570456896 run_lib.py:146] step: 686600, eval_loss: 3.07839e-02
I0211 08:04:32.120539 22542570456896 run_lib.py:133] step: 686650, training_loss: 2.08966e-02
I0211 08:04:49.534697 22542570456896 run_lib.py:133] step: 686700, training_loss: 3.45396e-02
I0211 08:04:49.710355 22542570456896 run_lib.py:146] step: 686700, eval_loss: 3.21008e-02
I0211 08:05:07.301713 22542570456896 run_lib.py:133] step: 686750, training_loss: 1.88809e-02
I0211 08:05:24.753565 22542570456896 run_lib.py:133] step: 686800, training_loss: 3.13065e-02
I0211 08:05:24.911558 22542570456896 run_lib.py:146] step: 686800, eval_loss: 3.83261e-02
I0211 08:05:42.508244 22542570456896 run_lib.py:133] step: 686850, training_loss: 2.67010e-02
I0211 08:05:59.882390 22542570456896 run_lib.py:133] step: 686900, training_loss: 2.83256e-02
I0211 08:06:00.040498 22542570456896 run_lib.py:146] step: 686900, eval_loss: 3.10732e-02
I0211 08:06:17.490455 22542570456896 run_lib.py:133] step: 686950, training_loss: 2.69229e-02
I0211 08:06:35.098870 22542570456896 run_lib.py:133] step: 687000, training_loss: 3.09061e-02
I0211 08:06:35.250159 22542570456896 run_lib.py:146] step: 687000, eval_loss: 2.96035e-02
I0211 08:06:52.689970 22542570456896 run_lib.py:133] step: 687050, training_loss: 2.89790e-02
I0211 08:07:10.259829 22542570456896 run_lib.py:133] step: 687100, training_loss: 2.68598e-02
I0211 08:07:10.414218 22542570456896 run_lib.py:146] step: 687100, eval_loss: 2.51712e-02
I0211 08:07:27.849133 22542570456896 run_lib.py:133] step: 687150, training_loss: 3.39411e-02
I0211 08:07:45.301051 22542570456896 run_lib.py:133] step: 687200, training_loss: 3.17099e-02
I0211 08:07:45.465327 22542570456896 run_lib.py:146] step: 687200, eval_loss: 3.19654e-02
I0211 08:08:03.060764 22542570456896 run_lib.py:133] step: 687250, training_loss: 2.79112e-02
I0211 08:08:20.530561 22542570456896 run_lib.py:133] step: 687300, training_loss: 2.56389e-02
I0211 08:08:20.685484 22542570456896 run_lib.py:146] step: 687300, eval_loss: 3.15596e-02
I0211 08:08:38.097281 22542570456896 run_lib.py:133] step: 687350, training_loss: 3.17637e-02
I0211 08:08:55.659082 22542570456896 run_lib.py:133] step: 687400, training_loss: 2.61694e-02
I0211 08:08:55.814336 22542570456896 run_lib.py:146] step: 687400, eval_loss: 2.22428e-02
I0211 08:09:13.231077 22542570456896 run_lib.py:133] step: 687450, training_loss: 2.29690e-02
I0211 08:09:30.671279 22542570456896 run_lib.py:133] step: 687500, training_loss: 2.85668e-02
I0211 08:09:30.824538 22542570456896 run_lib.py:146] step: 687500, eval_loss: 2.56898e-02
I0211 08:09:48.352838 22542570456896 run_lib.py:133] step: 687550, training_loss: 2.92900e-02
I0211 08:10:05.790834 22542570456896 run_lib.py:133] step: 687600, training_loss: 2.21555e-02
I0211 08:10:05.948194 22542570456896 run_lib.py:146] step: 687600, eval_loss: 2.42863e-02
I0211 08:10:23.343157 22542570456896 run_lib.py:133] step: 687650, training_loss: 2.87067e-02
I0211 08:10:40.771353 22542570456896 run_lib.py:133] step: 687700, training_loss: 3.35963e-02
I0211 08:10:40.934557 22542570456896 run_lib.py:146] step: 687700, eval_loss: 2.62599e-02
I0211 08:10:58.485386 22542570456896 run_lib.py:133] step: 687750, training_loss: 3.13442e-02
I0211 08:11:15.953289 22542570456896 run_lib.py:133] step: 687800, training_loss: 2.54111e-02
I0211 08:11:16.108038 22542570456896 run_lib.py:146] step: 687800, eval_loss: 3.45145e-02
I0211 08:11:33.560362 22542570456896 run_lib.py:133] step: 687850, training_loss: 2.65516e-02
I0211 08:11:50.939560 22542570456896 run_lib.py:133] step: 687900, training_loss: 2.19486e-02
I0211 08:11:51.094138 22542570456896 run_lib.py:146] step: 687900, eval_loss: 2.82509e-02
I0211 08:12:08.657773 22542570456896 run_lib.py:133] step: 687950, training_loss: 2.84792e-02
I0211 08:12:26.056371 22542570456896 run_lib.py:133] step: 688000, training_loss: 2.56059e-02
I0211 08:12:26.208266 22542570456896 run_lib.py:146] step: 688000, eval_loss: 2.84557e-02
I0211 08:12:43.765124 22542570456896 run_lib.py:133] step: 688050, training_loss: 3.02693e-02
I0211 08:13:01.179102 22542570456896 run_lib.py:133] step: 688100, training_loss: 2.81833e-02
I0211 08:13:01.341273 22542570456896 run_lib.py:146] step: 688100, eval_loss: 3.52839e-02
I0211 08:13:18.902136 22542570456896 run_lib.py:133] step: 688150, training_loss: 2.97750e-02
I0211 08:13:36.311580 22542570456896 run_lib.py:133] step: 688200, training_loss: 2.49395e-02
I0211 08:13:36.472027 22542570456896 run_lib.py:146] step: 688200, eval_loss: 2.52508e-02
I0211 08:13:54.101880 22542570456896 run_lib.py:133] step: 688250, training_loss: 2.41006e-02
I0211 08:14:11.475562 22542570456896 run_lib.py:133] step: 688300, training_loss: 2.67598e-02
I0211 08:14:11.630458 22542570456896 run_lib.py:146] step: 688300, eval_loss: 2.96173e-02
I0211 08:14:29.037001 22542570456896 run_lib.py:133] step: 688350, training_loss: 3.14824e-02
I0211 08:14:46.620935 22542570456896 run_lib.py:133] step: 688400, training_loss: 3.16276e-02
I0211 08:14:46.773080 22542570456896 run_lib.py:146] step: 688400, eval_loss: 3.44670e-02
I0211 08:15:04.197207 22542570456896 run_lib.py:133] step: 688450, training_loss: 2.99114e-02
I0211 08:15:21.636401 22542570456896 run_lib.py:133] step: 688500, training_loss: 3.14306e-02
I0211 08:15:21.790912 22542570456896 run_lib.py:146] step: 688500, eval_loss: 2.54932e-02
I0211 08:15:39.328002 22542570456896 run_lib.py:133] step: 688550, training_loss: 2.41891e-02
I0211 08:15:56.779775 22542570456896 run_lib.py:133] step: 688600, training_loss: 2.91146e-02
I0211 08:15:56.941280 22542570456896 run_lib.py:146] step: 688600, eval_loss: 3.13616e-02
I0211 08:16:14.520654 22542570456896 run_lib.py:133] step: 688650, training_loss: 2.24804e-02
I0211 08:16:31.957637 22542570456896 run_lib.py:133] step: 688700, training_loss: 2.97598e-02
I0211 08:16:32.112548 22542570456896 run_lib.py:146] step: 688700, eval_loss: 3.04514e-02
I0211 08:16:49.532439 22542570456896 run_lib.py:133] step: 688750, training_loss: 3.48164e-02
I0211 08:17:07.081317 22542570456896 run_lib.py:133] step: 688800, training_loss: 3.33511e-02
I0211 08:17:07.237492 22542570456896 run_lib.py:146] step: 688800, eval_loss: 2.60776e-02
I0211 08:17:24.672893 22542570456896 run_lib.py:133] step: 688850, training_loss: 2.48385e-02
I0211 08:17:42.096899 22542570456896 run_lib.py:133] step: 688900, training_loss: 2.29700e-02
I0211 08:17:42.249997 22542570456896 run_lib.py:146] step: 688900, eval_loss: 2.24581e-02
I0211 08:17:59.665291 22542570456896 run_lib.py:133] step: 688950, training_loss: 2.81539e-02
I0211 08:18:17.268915 22542570456896 run_lib.py:133] step: 689000, training_loss: 2.55554e-02
I0211 08:18:17.424607 22542570456896 run_lib.py:146] step: 689000, eval_loss: 2.65287e-02
I0211 08:18:34.862955 22542570456896 run_lib.py:133] step: 689050, training_loss: 2.35799e-02
I0211 08:18:52.308329 22542570456896 run_lib.py:133] step: 689100, training_loss: 3.56357e-02
I0211 08:18:52.467544 22542570456896 run_lib.py:146] step: 689100, eval_loss: 3.41825e-02
I0211 08:19:09.827917 22542570456896 run_lib.py:133] step: 689150, training_loss: 2.19512e-02
I0211 08:19:27.220140 22542570456896 run_lib.py:133] step: 689200, training_loss: 3.55106e-02
I0211 08:19:27.388357 22542570456896 run_lib.py:146] step: 689200, eval_loss: 2.90042e-02
I0211 08:19:44.970577 22542570456896 run_lib.py:133] step: 689250, training_loss: 3.11368e-02
I0211 08:20:02.435975 22542570456896 run_lib.py:133] step: 689300, training_loss: 3.15854e-02
I0211 08:20:02.591554 22542570456896 run_lib.py:146] step: 689300, eval_loss: 2.37367e-02
I0211 08:20:20.015290 22542570456896 run_lib.py:133] step: 689350, training_loss: 2.67067e-02
I0211 08:20:37.425734 22542570456896 run_lib.py:133] step: 689400, training_loss: 2.06990e-02
I0211 08:20:37.578340 22542570456896 run_lib.py:146] step: 689400, eval_loss: 3.11892e-02
I0211 08:20:55.091149 22542570456896 run_lib.py:133] step: 689450, training_loss: 2.41858e-02
I0211 08:21:12.462018 22542570456896 run_lib.py:133] step: 689500, training_loss: 2.04642e-02
I0211 08:21:12.630180 22542570456896 run_lib.py:146] step: 689500, eval_loss: 2.94642e-02
I0211 08:21:30.241482 22542570456896 run_lib.py:133] step: 689550, training_loss: 3.27945e-02
I0211 08:21:47.682702 22542570456896 run_lib.py:133] step: 689600, training_loss: 2.85699e-02
I0211 08:21:47.841318 22542570456896 run_lib.py:146] step: 689600, eval_loss: 2.97214e-02
I0211 08:22:05.438496 22542570456896 run_lib.py:133] step: 689650, training_loss: 2.79030e-02
I0211 08:22:22.809134 22542570456896 run_lib.py:133] step: 689700, training_loss: 2.42393e-02
I0211 08:22:22.972504 22542570456896 run_lib.py:146] step: 689700, eval_loss: 2.87449e-02
I0211 08:22:40.384178 22542570456896 run_lib.py:133] step: 689750, training_loss: 3.08787e-02
I0211 08:22:57.931131 22542570456896 run_lib.py:133] step: 689800, training_loss: 2.75855e-02
I0211 08:22:58.086475 22542570456896 run_lib.py:146] step: 689800, eval_loss: 2.78447e-02
I0211 08:23:15.523212 22542570456896 run_lib.py:133] step: 689850, training_loss: 2.17687e-02
I0211 08:23:33.030184 22542570456896 run_lib.py:133] step: 689900, training_loss: 2.63422e-02
I0211 08:23:33.182215 22542570456896 run_lib.py:146] step: 689900, eval_loss: 3.28437e-02
I0211 08:23:50.535920 22542570456896 run_lib.py:133] step: 689950, training_loss: 2.61138e-02
I0211 08:24:07.929246 22542570456896 run_lib.py:133] step: 690000, training_loss: 2.16077e-02
I0211 08:24:08.624313 22542570456896 run_lib.py:146] step: 690000, eval_loss: 3.16420e-02
I0211 08:24:28.780658 22542570456896 run_lib.py:133] step: 690050, training_loss: 2.79272e-02
I0211 08:24:46.245233 22542570456896 run_lib.py:133] step: 690100, training_loss: 2.06363e-02
I0211 08:24:46.405737 22542570456896 run_lib.py:146] step: 690100, eval_loss: 2.93352e-02
I0211 08:25:03.968967 22542570456896 run_lib.py:133] step: 690150, training_loss: 2.87052e-02
I0211 08:25:21.375026 22542570456896 run_lib.py:133] step: 690200, training_loss: 2.94432e-02
I0211 08:25:21.530456 22542570456896 run_lib.py:146] step: 690200, eval_loss: 3.05181e-02
I0211 08:25:38.897884 22542570456896 run_lib.py:133] step: 690250, training_loss: 2.81454e-02
I0211 08:25:56.460531 22542570456896 run_lib.py:133] step: 690300, training_loss: 2.66185e-02
I0211 08:25:56.622676 22542570456896 run_lib.py:146] step: 690300, eval_loss: 3.10843e-02
I0211 08:26:14.036996 22542570456896 run_lib.py:133] step: 690350, training_loss: 2.31338e-02
I0211 08:26:31.682957 22542570456896 run_lib.py:133] step: 690400, training_loss: 2.25041e-02
I0211 08:26:31.833500 22542570456896 run_lib.py:146] step: 690400, eval_loss: 2.58697e-02
I0211 08:26:49.233160 22542570456896 run_lib.py:133] step: 690450, training_loss: 3.45417e-02
I0211 08:27:06.656705 22542570456896 run_lib.py:133] step: 690500, training_loss: 2.70378e-02
I0211 08:27:06.810251 22542570456896 run_lib.py:146] step: 690500, eval_loss: 2.86379e-02
I0211 08:27:24.178789 22542570456896 run_lib.py:133] step: 690550, training_loss: 2.30412e-02
I0211 08:27:41.738194 22542570456896 run_lib.py:133] step: 690600, training_loss: 3.13853e-02
I0211 08:27:41.917573 22542570456896 run_lib.py:146] step: 690600, eval_loss: 2.90412e-02
I0211 08:27:59.354065 22542570456896 run_lib.py:133] step: 690650, training_loss: 2.54110e-02
I0211 08:28:16.763277 22542570456896 run_lib.py:133] step: 690700, training_loss: 2.99692e-02
I0211 08:28:16.918424 22542570456896 run_lib.py:146] step: 690700, eval_loss: 2.30378e-02
I0211 08:28:34.565685 22542570456896 run_lib.py:133] step: 690750, training_loss: 2.77393e-02
I0211 08:28:51.956747 22542570456896 run_lib.py:133] step: 690800, training_loss: 2.71294e-02
I0211 08:28:52.119170 22542570456896 run_lib.py:146] step: 690800, eval_loss: 2.81325e-02
I0211 08:29:09.534295 22542570456896 run_lib.py:133] step: 690850, training_loss: 3.64669e-02
I0211 08:29:26.935965 22542570456896 run_lib.py:133] step: 690900, training_loss: 2.19237e-02
I0211 08:29:27.088375 22542570456896 run_lib.py:146] step: 690900, eval_loss: 3.21330e-02
I0211 08:29:44.506325 22542570456896 run_lib.py:133] step: 690950, training_loss: 2.51185e-02
I0211 08:30:01.949119 22542570456896 run_lib.py:133] step: 691000, training_loss: 2.54117e-02
I0211 08:30:02.104214 22542570456896 run_lib.py:146] step: 691000, eval_loss: 2.88511e-02
I0211 08:30:19.688885 22542570456896 run_lib.py:133] step: 691050, training_loss: 3.58815e-02
I0211 08:30:37.118505 22542570456896 run_lib.py:133] step: 691100, training_loss: 2.49776e-02
I0211 08:30:37.278463 22542570456896 run_lib.py:146] step: 691100, eval_loss: 2.30039e-02
I0211 08:30:54.724380 22542570456896 run_lib.py:133] step: 691150, training_loss: 2.89007e-02
I0211 08:31:12.223832 22542570456896 run_lib.py:133] step: 691200, training_loss: 3.20079e-02
I0211 08:31:12.387223 22542570456896 run_lib.py:146] step: 691200, eval_loss: 2.75464e-02
I0211 08:31:29.950149 22542570456896 run_lib.py:133] step: 691250, training_loss: 3.16922e-02
I0211 08:31:47.334712 22542570456896 run_lib.py:133] step: 691300, training_loss: 2.81357e-02
I0211 08:31:47.489808 22542570456896 run_lib.py:146] step: 691300, eval_loss: 3.37234e-02
I0211 08:32:04.998935 22542570456896 run_lib.py:133] step: 691350, training_loss: 2.50390e-02
I0211 08:32:22.448331 22542570456896 run_lib.py:133] step: 691400, training_loss: 2.65356e-02
I0211 08:32:22.603284 22542570456896 run_lib.py:146] step: 691400, eval_loss: 3.05385e-02
I0211 08:32:40.178121 22542570456896 run_lib.py:133] step: 691450, training_loss: 3.15038e-02
I0211 08:32:57.601859 22542570456896 run_lib.py:133] step: 691500, training_loss: 2.96877e-02
I0211 08:32:57.761395 22542570456896 run_lib.py:146] step: 691500, eval_loss: 2.94911e-02
I0211 08:33:15.323204 22542570456896 run_lib.py:133] step: 691550, training_loss: 2.53611e-02
I0211 08:33:32.708120 22542570456896 run_lib.py:133] step: 691600, training_loss: 2.64463e-02
I0211 08:33:32.865549 22542570456896 run_lib.py:146] step: 691600, eval_loss: 2.57004e-02
I0211 08:33:50.279067 22542570456896 run_lib.py:133] step: 691650, training_loss: 2.60103e-02
I0211 08:34:07.851578 22542570456896 run_lib.py:133] step: 691700, training_loss: 2.49994e-02
I0211 08:34:08.007067 22542570456896 run_lib.py:146] step: 691700, eval_loss: 3.21979e-02
I0211 08:34:25.443222 22542570456896 run_lib.py:133] step: 691750, training_loss: 3.38352e-02
I0211 08:34:42.887266 22542570456896 run_lib.py:133] step: 691800, training_loss: 2.97070e-02
I0211 08:34:43.038055 22542570456896 run_lib.py:146] step: 691800, eval_loss: 3.97625e-02
I0211 08:35:00.603194 22542570456896 run_lib.py:133] step: 691850, training_loss: 3.21328e-02
I0211 08:35:18.039780 22542570456896 run_lib.py:133] step: 691900, training_loss: 2.68527e-02
I0211 08:35:18.200343 22542570456896 run_lib.py:146] step: 691900, eval_loss: 3.13018e-02
I0211 08:35:35.720726 22542570456896 run_lib.py:133] step: 691950, training_loss: 2.87809e-02
I0211 08:35:53.157707 22542570456896 run_lib.py:133] step: 692000, training_loss: 2.69283e-02
I0211 08:35:53.326303 22542570456896 run_lib.py:146] step: 692000, eval_loss: 2.95035e-02
I0211 08:36:10.787296 22542570456896 run_lib.py:133] step: 692050, training_loss: 2.28975e-02
I0211 08:36:28.362716 22542570456896 run_lib.py:133] step: 692100, training_loss: 2.54318e-02
I0211 08:36:28.526665 22542570456896 run_lib.py:146] step: 692100, eval_loss: 2.69911e-02
I0211 08:36:45.909825 22542570456896 run_lib.py:133] step: 692150, training_loss: 2.48733e-02
I0211 08:37:03.285491 22542570456896 run_lib.py:133] step: 692200, training_loss: 3.11288e-02
I0211 08:37:03.440999 22542570456896 run_lib.py:146] step: 692200, eval_loss: 2.90072e-02
I0211 08:37:20.910750 22542570456896 run_lib.py:133] step: 692250, training_loss: 2.60707e-02
I0211 08:37:38.555982 22542570456896 run_lib.py:133] step: 692300, training_loss: 2.46320e-02
I0211 08:37:38.709433 22542570456896 run_lib.py:146] step: 692300, eval_loss: 2.82649e-02
I0211 08:37:56.144108 22542570456896 run_lib.py:133] step: 692350, training_loss: 2.29020e-02
I0211 08:38:13.642642 22542570456896 run_lib.py:133] step: 692400, training_loss: 3.18257e-02
I0211 08:38:13.804311 22542570456896 run_lib.py:146] step: 692400, eval_loss: 3.32472e-02
I0211 08:38:31.222165 22542570456896 run_lib.py:133] step: 692450, training_loss: 2.62320e-02
I0211 08:38:48.611206 22542570456896 run_lib.py:133] step: 692500, training_loss: 2.88687e-02
I0211 08:38:48.769281 22542570456896 run_lib.py:146] step: 692500, eval_loss: 3.11861e-02
I0211 08:39:06.387850 22542570456896 run_lib.py:133] step: 692550, training_loss: 2.97053e-02
I0211 08:39:23.933278 22542570456896 run_lib.py:133] step: 692600, training_loss: 2.52539e-02
I0211 08:39:24.088413 22542570456896 run_lib.py:146] step: 692600, eval_loss: 2.94967e-02
I0211 08:39:41.469078 22542570456896 run_lib.py:133] step: 692650, training_loss: 2.49201e-02
I0211 08:39:58.865896 22542570456896 run_lib.py:133] step: 692700, training_loss: 2.77258e-02
I0211 08:39:59.020187 22542570456896 run_lib.py:146] step: 692700, eval_loss: 2.61034e-02
I0211 08:40:16.540407 22542570456896 run_lib.py:133] step: 692750, training_loss: 3.20903e-02
I0211 08:40:33.939134 22542570456896 run_lib.py:133] step: 692800, training_loss: 2.78267e-02
I0211 08:40:34.091399 22542570456896 run_lib.py:146] step: 692800, eval_loss: 3.05252e-02
I0211 08:40:51.694832 22542570456896 run_lib.py:133] step: 692850, training_loss: 2.08961e-02
I0211 08:41:09.101834 22542570456896 run_lib.py:133] step: 692900, training_loss: 2.60347e-02
I0211 08:41:09.257315 22542570456896 run_lib.py:146] step: 692900, eval_loss: 2.30033e-02
I0211 08:41:26.848980 22542570456896 run_lib.py:133] step: 692950, training_loss: 2.95366e-02
I0211 08:41:44.231797 22542570456896 run_lib.py:133] step: 693000, training_loss: 3.52016e-02
I0211 08:41:44.383708 22542570456896 run_lib.py:146] step: 693000, eval_loss: 3.37767e-02
I0211 08:42:01.791313 22542570456896 run_lib.py:133] step: 693050, training_loss: 2.68768e-02
I0211 08:42:19.331279 22542570456896 run_lib.py:133] step: 693100, training_loss: 2.48175e-02
I0211 08:42:19.488467 22542570456896 run_lib.py:146] step: 693100, eval_loss: 2.78095e-02
I0211 08:42:36.825649 22542570456896 run_lib.py:133] step: 693150, training_loss: 2.37989e-02
I0211 08:42:54.318285 22542570456896 run_lib.py:133] step: 693200, training_loss: 2.37720e-02
I0211 08:42:54.480845 22542570456896 run_lib.py:146] step: 693200, eval_loss: 3.10091e-02
I0211 08:43:11.800612 22542570456896 run_lib.py:133] step: 693250, training_loss: 2.41681e-02
I0211 08:43:29.077450 22542570456896 run_lib.py:133] step: 693300, training_loss: 2.72828e-02
I0211 08:43:29.230588 22542570456896 run_lib.py:146] step: 693300, eval_loss: 2.83252e-02
I0211 08:43:46.799010 22542570456896 run_lib.py:133] step: 693350, training_loss: 2.31342e-02
I0211 08:44:04.243190 22542570456896 run_lib.py:133] step: 693400, training_loss: 2.75648e-02
I0211 08:44:04.401614 22542570456896 run_lib.py:146] step: 693400, eval_loss: 2.56720e-02
I0211 08:44:21.872415 22542570456896 run_lib.py:133] step: 693450, training_loss: 2.09992e-02
I0211 08:44:39.492404 22542570456896 run_lib.py:133] step: 693500, training_loss: 2.79961e-02
I0211 08:44:39.649592 22542570456896 run_lib.py:146] step: 693500, eval_loss: 3.02105e-02
I0211 08:44:57.072392 22542570456896 run_lib.py:133] step: 693550, training_loss: 2.38614e-02
I0211 08:45:14.483993 22542570456896 run_lib.py:133] step: 693600, training_loss: 2.26139e-02
I0211 08:45:14.808998 22542570456896 run_lib.py:146] step: 693600, eval_loss: 3.65926e-02
I0211 08:45:32.243643 22542570456896 run_lib.py:133] step: 693650, training_loss: 3.04519e-02
I0211 08:45:49.663195 22542570456896 run_lib.py:133] step: 693700, training_loss: 3.21638e-02
I0211 08:45:49.817296 22542570456896 run_lib.py:146] step: 693700, eval_loss: 2.86027e-02
I0211 08:46:07.245404 22542570456896 run_lib.py:133] step: 693750, training_loss: 2.86270e-02
I0211 08:46:24.681500 22542570456896 run_lib.py:133] step: 693800, training_loss: 2.65428e-02
I0211 08:46:24.846602 22542570456896 run_lib.py:146] step: 693800, eval_loss: 3.02178e-02
I0211 08:46:42.436988 22542570456896 run_lib.py:133] step: 693850, training_loss: 3.59298e-02
I0211 08:46:59.921091 22542570456896 run_lib.py:133] step: 693900, training_loss: 2.52717e-02
I0211 08:47:00.080358 22542570456896 run_lib.py:146] step: 693900, eval_loss: 2.79878e-02
I0211 08:47:17.529449 22542570456896 run_lib.py:133] step: 693950, training_loss: 3.43560e-02
I0211 08:47:34.944822 22542570456896 run_lib.py:133] step: 694000, training_loss: 2.77974e-02
I0211 08:47:35.100003 22542570456896 run_lib.py:146] step: 694000, eval_loss: 2.57595e-02
I0211 08:47:52.663184 22542570456896 run_lib.py:133] step: 694050, training_loss: 2.40836e-02
I0211 08:48:10.235083 22542570456896 run_lib.py:133] step: 694100, training_loss: 2.40479e-02
I0211 08:48:10.399297 22542570456896 run_lib.py:146] step: 694100, eval_loss: 2.69171e-02
I0211 08:48:27.827665 22542570456896 run_lib.py:133] step: 694150, training_loss: 2.20355e-02
I0211 08:48:45.260010 22542570456896 run_lib.py:133] step: 694200, training_loss: 3.06109e-02
I0211 08:48:45.412359 22542570456896 run_lib.py:146] step: 694200, eval_loss: 2.52939e-02
I0211 08:49:02.968134 22542570456896 run_lib.py:133] step: 694250, training_loss: 2.53851e-02
I0211 08:49:20.514911 22542570456896 run_lib.py:133] step: 694300, training_loss: 2.47662e-02
I0211 08:49:20.685888 22542570456896 run_lib.py:146] step: 694300, eval_loss: 2.36609e-02
I0211 08:49:38.312014 22542570456896 run_lib.py:133] step: 694350, training_loss: 2.48435e-02
I0211 08:49:55.743563 22542570456896 run_lib.py:133] step: 694400, training_loss: 2.54736e-02
I0211 08:49:55.909555 22542570456896 run_lib.py:146] step: 694400, eval_loss: 2.66098e-02
I0211 08:50:13.504536 22542570456896 run_lib.py:133] step: 694450, training_loss: 2.81440e-02
I0211 08:50:30.901875 22542570456896 run_lib.py:133] step: 694500, training_loss: 2.51222e-02
I0211 08:50:31.057325 22542570456896 run_lib.py:146] step: 694500, eval_loss: 3.07288e-02
I0211 08:50:48.481410 22542570456896 run_lib.py:133] step: 694550, training_loss: 3.35282e-02
I0211 08:51:06.089224 22542570456896 run_lib.py:133] step: 694600, training_loss: 2.61333e-02
I0211 08:51:06.245635 22542570456896 run_lib.py:146] step: 694600, eval_loss: 3.00749e-02
I0211 08:51:23.687390 22542570456896 run_lib.py:133] step: 694650, training_loss: 2.38112e-02
I0211 08:51:41.257658 22542570456896 run_lib.py:133] step: 694700, training_loss: 3.03639e-02
I0211 08:51:41.409103 22542570456896 run_lib.py:146] step: 694700, eval_loss: 2.76892e-02
I0211 08:51:58.817025 22542570456896 run_lib.py:133] step: 694750, training_loss: 2.96764e-02
I0211 08:52:16.243944 22542570456896 run_lib.py:133] step: 694800, training_loss: 2.52997e-02
I0211 08:52:16.402329 22542570456896 run_lib.py:146] step: 694800, eval_loss: 2.33263e-02
I0211 08:52:34.005507 22542570456896 run_lib.py:133] step: 694850, training_loss: 3.21430e-02
I0211 08:52:51.461386 22542570456896 run_lib.py:133] step: 694900, training_loss: 2.96602e-02
I0211 08:52:51.619499 22542570456896 run_lib.py:146] step: 694900, eval_loss: 3.14824e-02
I0211 08:53:09.003254 22542570456896 run_lib.py:133] step: 694950, training_loss: 2.48319e-02
I0211 08:53:26.407585 22542570456896 run_lib.py:133] step: 695000, training_loss: 3.48072e-02
I0211 08:53:26.565093 22542570456896 run_lib.py:146] step: 695000, eval_loss: 3.28079e-02
I0211 08:53:44.173567 22542570456896 run_lib.py:133] step: 695050, training_loss: 2.27974e-02
I0211 08:54:01.621212 22542570456896 run_lib.py:133] step: 695100, training_loss: 2.64897e-02
I0211 08:54:01.776098 22542570456896 run_lib.py:146] step: 695100, eval_loss: 2.88776e-02
I0211 08:54:19.331274 22542570456896 run_lib.py:133] step: 695150, training_loss: 2.33580e-02
I0211 08:54:36.730538 22542570456896 run_lib.py:133] step: 695200, training_loss: 2.49295e-02
I0211 08:54:36.892362 22542570456896 run_lib.py:146] step: 695200, eval_loss: 2.96301e-02
I0211 08:54:54.307774 22542570456896 run_lib.py:133] step: 695250, training_loss: 3.23776e-02
I0211 08:55:11.736075 22542570456896 run_lib.py:133] step: 695300, training_loss: 3.01786e-02
I0211 08:55:11.899379 22542570456896 run_lib.py:146] step: 695300, eval_loss: 3.41457e-02
I0211 08:55:29.461402 22542570456896 run_lib.py:133] step: 695350, training_loss: 2.58469e-02
I0211 08:55:46.994505 22542570456896 run_lib.py:133] step: 695400, training_loss: 2.78074e-02
I0211 08:55:47.150518 22542570456896 run_lib.py:146] step: 695400, eval_loss: 3.22380e-02
I0211 08:56:04.546706 22542570456896 run_lib.py:133] step: 695450, training_loss: 3.03697e-02
I0211 08:56:21.958450 22542570456896 run_lib.py:133] step: 695500, training_loss: 2.51396e-02
I0211 08:56:22.113593 22542570456896 run_lib.py:146] step: 695500, eval_loss: 3.99585e-02
I0211 08:56:39.678698 22542570456896 run_lib.py:133] step: 695550, training_loss: 2.15242e-02
I0211 08:56:57.082755 22542570456896 run_lib.py:133] step: 695600, training_loss: 2.33753e-02
I0211 08:56:57.244053 22542570456896 run_lib.py:146] step: 695600, eval_loss: 2.96075e-02
I0211 08:57:14.769320 22542570456896 run_lib.py:133] step: 695650, training_loss: 2.72770e-02
I0211 08:57:32.243610 22542570456896 run_lib.py:133] step: 695700, training_loss: 3.07497e-02
I0211 08:57:32.411597 22542570456896 run_lib.py:146] step: 695700, eval_loss: 2.70915e-02
I0211 08:57:50.019352 22542570456896 run_lib.py:133] step: 695750, training_loss: 2.57139e-02
I0211 08:58:07.464774 22542570456896 run_lib.py:133] step: 695800, training_loss: 2.98068e-02
I0211 08:58:07.627655 22542570456896 run_lib.py:146] step: 695800, eval_loss: 2.95686e-02
I0211 08:58:25.178706 22542570456896 run_lib.py:133] step: 695850, training_loss: 2.40750e-02
I0211 08:58:42.598865 22542570456896 run_lib.py:133] step: 695900, training_loss: 2.20151e-02
I0211 08:58:42.767309 22542570456896 run_lib.py:146] step: 695900, eval_loss: 2.88308e-02
I0211 08:59:00.220103 22542570456896 run_lib.py:133] step: 695950, training_loss: 2.87661e-02
I0211 08:59:17.798701 22542570456896 run_lib.py:133] step: 696000, training_loss: 2.62311e-02
I0211 08:59:17.959522 22542570456896 run_lib.py:146] step: 696000, eval_loss: 2.72225e-02
I0211 08:59:35.402282 22542570456896 run_lib.py:133] step: 696050, training_loss: 1.91596e-02
I0211 08:59:52.796972 22542570456896 run_lib.py:133] step: 696100, training_loss: 2.35085e-02
I0211 08:59:52.954387 22542570456896 run_lib.py:146] step: 696100, eval_loss: 2.91169e-02
I0211 09:00:10.501059 22542570456896 run_lib.py:133] step: 696150, training_loss: 2.65067e-02
I0211 09:00:28.073904 22542570456896 run_lib.py:133] step: 696200, training_loss: 3.21669e-02
I0211 09:00:28.246512 22542570456896 run_lib.py:146] step: 696200, eval_loss: 2.83930e-02
I0211 09:00:45.713677 22542570456896 run_lib.py:133] step: 696250, training_loss: 3.05335e-02
I0211 09:01:03.113145 22542570456896 run_lib.py:133] step: 696300, training_loss: 2.85883e-02
I0211 09:01:03.270228 22542570456896 run_lib.py:146] step: 696300, eval_loss: 2.61139e-02
I0211 09:01:20.656216 22542570456896 run_lib.py:133] step: 696350, training_loss: 2.60356e-02
I0211 09:01:38.232872 22542570456896 run_lib.py:133] step: 696400, training_loss: 2.57015e-02
I0211 09:01:38.388283 22542570456896 run_lib.py:146] step: 696400, eval_loss: 2.53800e-02
I0211 09:01:55.787118 22542570456896 run_lib.py:133] step: 696450, training_loss: 3.04068e-02
I0211 09:02:13.264640 22542570456896 run_lib.py:133] step: 696500, training_loss: 2.68507e-02
I0211 09:02:13.421552 22542570456896 run_lib.py:146] step: 696500, eval_loss: 2.82462e-02
I0211 09:02:30.906351 22542570456896 run_lib.py:133] step: 696550, training_loss: 3.43527e-02
I0211 09:02:48.525899 22542570456896 run_lib.py:133] step: 696600, training_loss: 2.00722e-02
I0211 09:02:48.677302 22542570456896 run_lib.py:146] step: 696600, eval_loss: 2.69079e-02
I0211 09:03:06.135143 22542570456896 run_lib.py:133] step: 696650, training_loss: 2.41743e-02
I0211 09:03:23.624334 22542570456896 run_lib.py:133] step: 696700, training_loss: 3.16213e-02
I0211 09:03:23.783439 22542570456896 run_lib.py:146] step: 696700, eval_loss: 2.39153e-02
I0211 09:03:41.159932 22542570456896 run_lib.py:133] step: 696750, training_loss: 2.40294e-02
I0211 09:03:58.624669 22542570456896 run_lib.py:133] step: 696800, training_loss: 2.94494e-02
I0211 09:03:58.800392 22542570456896 run_lib.py:146] step: 696800, eval_loss: 2.90667e-02
I0211 09:04:16.434726 22542570456896 run_lib.py:133] step: 696850, training_loss: 2.72869e-02
I0211 09:04:33.906318 22542570456896 run_lib.py:133] step: 696900, training_loss: 3.33737e-02
I0211 09:04:34.065258 22542570456896 run_lib.py:146] step: 696900, eval_loss: 2.40432e-02
I0211 09:04:51.491225 22542570456896 run_lib.py:133] step: 696950, training_loss: 3.60046e-02
I0211 09:05:08.908586 22542570456896 run_lib.py:133] step: 697000, training_loss: 2.12801e-02
I0211 09:05:09.062420 22542570456896 run_lib.py:146] step: 697000, eval_loss: 3.58992e-02
I0211 09:05:26.619858 22542570456896 run_lib.py:133] step: 697050, training_loss: 2.90684e-02
I0211 09:05:44.034107 22542570456896 run_lib.py:133] step: 697100, training_loss: 2.84567e-02
I0211 09:05:44.207686 22542570456896 run_lib.py:146] step: 697100, eval_loss: 3.16899e-02
I0211 09:06:01.862522 22542570456896 run_lib.py:133] step: 697150, training_loss: 2.79627e-02
I0211 09:06:19.305412 22542570456896 run_lib.py:133] step: 697200, training_loss: 2.83168e-02
I0211 09:06:19.468500 22542570456896 run_lib.py:146] step: 697200, eval_loss: 3.06744e-02
I0211 09:06:37.022000 22542570456896 run_lib.py:133] step: 697250, training_loss: 2.95862e-02
I0211 09:06:54.408016 22542570456896 run_lib.py:133] step: 697300, training_loss: 3.31231e-02
I0211 09:06:54.562384 22542570456896 run_lib.py:146] step: 697300, eval_loss: 2.81356e-02
I0211 09:07:11.985057 22542570456896 run_lib.py:133] step: 697350, training_loss: 2.89963e-02
I0211 09:07:29.612950 22542570456896 run_lib.py:133] step: 697400, training_loss: 2.19349e-02
I0211 09:07:29.769699 22542570456896 run_lib.py:146] step: 697400, eval_loss: 3.05859e-02
I0211 09:07:47.176477 22542570456896 run_lib.py:133] step: 697450, training_loss: 3.04235e-02
I0211 09:08:04.701362 22542570456896 run_lib.py:133] step: 697500, training_loss: 2.92063e-02
I0211 09:08:04.858327 22542570456896 run_lib.py:146] step: 697500, eval_loss: 2.45024e-02
I0211 09:08:22.239049 22542570456896 run_lib.py:133] step: 697550, training_loss: 2.61453e-02
I0211 09:08:39.654178 22542570456896 run_lib.py:133] step: 697600, training_loss: 2.79449e-02
I0211 09:08:39.822485 22542570456896 run_lib.py:146] step: 697600, eval_loss: 3.19870e-02
I0211 09:08:57.447617 22542570456896 run_lib.py:133] step: 697650, training_loss: 2.46071e-02
I0211 09:09:14.916668 22542570456896 run_lib.py:133] step: 697700, training_loss: 2.34515e-02
I0211 09:09:15.073231 22542570456896 run_lib.py:146] step: 697700, eval_loss: 3.53385e-02
I0211 09:09:32.457406 22542570456896 run_lib.py:133] step: 697750, training_loss: 2.80397e-02
I0211 09:09:50.038448 22542570456896 run_lib.py:133] step: 697800, training_loss: 3.13707e-02
I0211 09:09:50.193450 22542570456896 run_lib.py:146] step: 697800, eval_loss: 3.17894e-02
I0211 09:10:07.590336 22542570456896 run_lib.py:133] step: 697850, training_loss: 2.65093e-02
I0211 09:10:25.040803 22542570456896 run_lib.py:133] step: 697900, training_loss: 3.17615e-02
I0211 09:10:25.197144 22542570456896 run_lib.py:146] step: 697900, eval_loss: 3.16821e-02
I0211 09:10:42.754606 22542570456896 run_lib.py:133] step: 697950, training_loss: 2.69092e-02
I0211 09:11:00.169538 22542570456896 run_lib.py:133] step: 698000, training_loss: 2.57212e-02
I0211 09:11:00.321261 22542570456896 run_lib.py:146] step: 698000, eval_loss: 2.46103e-02
I0211 09:11:17.713561 22542570456896 run_lib.py:133] step: 698050, training_loss: 2.37212e-02
I0211 09:11:35.159405 22542570456896 run_lib.py:133] step: 698100, training_loss: 2.29939e-02
I0211 09:11:35.315322 22542570456896 run_lib.py:146] step: 698100, eval_loss: 3.01912e-02
I0211 09:11:52.869074 22542570456896 run_lib.py:133] step: 698150, training_loss: 3.03705e-02
I0211 09:12:10.405818 22542570456896 run_lib.py:133] step: 698200, training_loss: 2.54201e-02
I0211 09:12:10.581331 22542570456896 run_lib.py:146] step: 698200, eval_loss: 3.01527e-02
I0211 09:12:28.048227 22542570456896 run_lib.py:133] step: 698250, training_loss: 2.48437e-02
I0211 09:12:45.506630 22542570456896 run_lib.py:133] step: 698300, training_loss: 2.22059e-02
I0211 09:12:45.662626 22542570456896 run_lib.py:146] step: 698300, eval_loss: 3.29244e-02
I0211 09:13:03.268488 22542570456896 run_lib.py:133] step: 698350, training_loss: 2.61993e-02
I0211 09:13:20.671367 22542570456896 run_lib.py:133] step: 698400, training_loss: 2.54187e-02
I0211 09:13:20.850194 22542570456896 run_lib.py:146] step: 698400, eval_loss: 2.93704e-02
I0211 09:13:38.432449 22542570456896 run_lib.py:133] step: 698450, training_loss: 2.86245e-02
I0211 09:13:55.834800 22542570456896 run_lib.py:133] step: 698500, training_loss: 2.90450e-02
I0211 09:13:55.990669 22542570456896 run_lib.py:146] step: 698500, eval_loss: 2.70358e-02
I0211 09:14:13.630607 22542570456896 run_lib.py:133] step: 698550, training_loss: 2.76752e-02
I0211 09:14:31.059388 22542570456896 run_lib.py:133] step: 698600, training_loss: 2.52726e-02
I0211 09:14:31.217306 22542570456896 run_lib.py:146] step: 698600, eval_loss: 2.91420e-02
I0211 09:14:48.812068 22542570456896 run_lib.py:133] step: 698650, training_loss: 2.94627e-02
I0211 09:15:06.214399 22542570456896 run_lib.py:133] step: 698700, training_loss: 3.00052e-02
I0211 09:15:06.369653 22542570456896 run_lib.py:146] step: 698700, eval_loss: 3.09892e-02
I0211 09:15:23.815050 22542570456896 run_lib.py:133] step: 698750, training_loss: 2.70653e-02
I0211 09:15:41.472418 22542570456896 run_lib.py:133] step: 698800, training_loss: 2.79705e-02
I0211 09:15:41.637504 22542570456896 run_lib.py:146] step: 698800, eval_loss: 2.74898e-02
I0211 09:15:59.029546 22542570456896 run_lib.py:133] step: 698850, training_loss: 2.37940e-02
I0211 09:16:16.441359 22542570456896 run_lib.py:133] step: 698900, training_loss: 3.31340e-02
I0211 09:16:16.596999 22542570456896 run_lib.py:146] step: 698900, eval_loss: 2.53439e-02
I0211 09:16:34.162271 22542570456896 run_lib.py:133] step: 698950, training_loss: 2.43625e-02
I0211 09:16:51.595675 22542570456896 run_lib.py:133] step: 699000, training_loss: 2.94880e-02
I0211 09:16:51.751523 22542570456896 run_lib.py:146] step: 699000, eval_loss: 2.52065e-02
I0211 09:17:09.361519 22542570456896 run_lib.py:133] step: 699050, training_loss: 2.53935e-02
I0211 09:17:26.787242 22542570456896 run_lib.py:133] step: 699100, training_loss: 2.82818e-02
I0211 09:17:26.948065 22542570456896 run_lib.py:146] step: 699100, eval_loss: 2.82115e-02
I0211 09:17:44.356565 22542570456896 run_lib.py:133] step: 699150, training_loss: 2.53034e-02
I0211 09:18:01.978744 22542570456896 run_lib.py:133] step: 699200, training_loss: 3.16083e-02
I0211 09:18:02.134350 22542570456896 run_lib.py:146] step: 699200, eval_loss: 2.86418e-02
I0211 09:18:19.542788 22542570456896 run_lib.py:133] step: 699250, training_loss: 2.74297e-02
I0211 09:18:36.932298 22542570456896 run_lib.py:133] step: 699300, training_loss: 3.36312e-02
I0211 09:18:37.100540 22542570456896 run_lib.py:146] step: 699300, eval_loss: 2.71299e-02
I0211 09:18:54.547900 22542570456896 run_lib.py:133] step: 699350, training_loss: 3.06397e-02
I0211 09:19:12.222386 22542570456896 run_lib.py:133] step: 699400, training_loss: 2.58693e-02
I0211 09:19:12.374280 22542570456896 run_lib.py:146] step: 699400, eval_loss: 2.89501e-02
I0211 09:19:29.820946 22542570456896 run_lib.py:133] step: 699450, training_loss: 3.07180e-02
I0211 09:19:47.320574 22542570456896 run_lib.py:133] step: 699500, training_loss: 2.50647e-02
I0211 09:19:47.476762 22542570456896 run_lib.py:146] step: 699500, eval_loss: 2.80568e-02
I0211 09:20:04.870059 22542570456896 run_lib.py:133] step: 699550, training_loss: 1.89003e-02
I0211 09:20:22.306566 22542570456896 run_lib.py:133] step: 699600, training_loss: 3.05289e-02
I0211 09:20:22.486287 22542570456896 run_lib.py:146] step: 699600, eval_loss: 2.61158e-02
I0211 09:20:40.096400 22542570456896 run_lib.py:133] step: 699650, training_loss: 2.31356e-02
I0211 09:20:57.564328 22542570456896 run_lib.py:133] step: 699700, training_loss: 2.86260e-02
I0211 09:20:57.720485 22542570456896 run_lib.py:146] step: 699700, eval_loss: 2.74829e-02
I0211 09:21:15.126230 22542570456896 run_lib.py:133] step: 699750, training_loss: 2.60643e-02
I0211 09:21:32.571521 22542570456896 run_lib.py:133] step: 699800, training_loss: 2.39407e-02
I0211 09:21:32.724390 22542570456896 run_lib.py:146] step: 699800, eval_loss: 2.94006e-02
I0211 09:21:50.258840 22542570456896 run_lib.py:133] step: 699850, training_loss: 3.13664e-02
I0211 09:22:07.712603 22542570456896 run_lib.py:133] step: 699900, training_loss: 2.79751e-02
I0211 09:22:07.868727 22542570456896 run_lib.py:146] step: 699900, eval_loss: 2.67577e-02
I0211 09:22:25.438701 22542570456896 run_lib.py:133] step: 699950, training_loss: 2.93207e-02
I0211 09:22:42.866619 22542570456896 run_lib.py:133] step: 700000, training_loss: 3.32866e-02
I0211 09:22:43.724269 22542570456896 run_lib.py:146] step: 700000, eval_loss: 2.41112e-02
I0211 09:23:03.936144 22542570456896 run_lib.py:133] step: 700050, training_loss: 2.81641e-02
I0211 09:23:21.381980 22542570456896 run_lib.py:133] step: 700100, training_loss: 3.35270e-02
I0211 09:23:21.541374 22542570456896 run_lib.py:146] step: 700100, eval_loss: 3.54952e-02
I0211 09:23:39.013454 22542570456896 run_lib.py:133] step: 700150, training_loss: 2.48923e-02
I0211 09:23:56.478204 22542570456896 run_lib.py:133] step: 700200, training_loss: 2.82799e-02
I0211 09:23:56.634484 22542570456896 run_lib.py:146] step: 700200, eval_loss: 3.22052e-02
I0211 09:24:14.017362 22542570456896 run_lib.py:133] step: 700250, training_loss: 2.75317e-02
I0211 09:24:31.393234 22542570456896 run_lib.py:133] step: 700300, training_loss: 2.24085e-02
I0211 09:24:31.549272 22542570456896 run_lib.py:146] step: 700300, eval_loss: 3.17807e-02
I0211 09:24:49.137543 22542570456896 run_lib.py:133] step: 700350, training_loss: 3.07980e-02
I0211 09:25:06.597283 22542570456896 run_lib.py:133] step: 700400, training_loss: 2.57521e-02
I0211 09:25:06.751101 22542570456896 run_lib.py:146] step: 700400, eval_loss: 2.52880e-02
I0211 09:25:24.193526 22542570456896 run_lib.py:133] step: 700450, training_loss: 2.17637e-02
I0211 09:25:41.622231 22542570456896 run_lib.py:133] step: 700500, training_loss: 2.75635e-02
I0211 09:25:41.777458 22542570456896 run_lib.py:146] step: 700500, eval_loss: 2.96976e-02
I0211 09:25:59.382939 22542570456896 run_lib.py:133] step: 700550, training_loss: 2.28029e-02
I0211 09:26:16.775466 22542570456896 run_lib.py:133] step: 700600, training_loss: 3.07541e-02
I0211 09:26:16.934619 22542570456896 run_lib.py:146] step: 700600, eval_loss: 2.53484e-02
I0211 09:26:34.459551 22542570456896 run_lib.py:133] step: 700650, training_loss: 2.74386e-02
I0211 09:26:51.854663 22542570456896 run_lib.py:133] step: 700700, training_loss: 2.96513e-02
I0211 09:26:52.021236 22542570456896 run_lib.py:146] step: 700700, eval_loss: 2.96339e-02
I0211 09:27:09.650181 22542570456896 run_lib.py:133] step: 700750, training_loss: 2.18080e-02
I0211 09:27:27.083972 22542570456896 run_lib.py:133] step: 700800, training_loss: 2.48232e-02
I0211 09:27:27.240768 22542570456896 run_lib.py:146] step: 700800, eval_loss: 2.62376e-02
I0211 09:27:44.661751 22542570456896 run_lib.py:133] step: 700850, training_loss: 2.61916e-02
I0211 09:28:02.230085 22542570456896 run_lib.py:133] step: 700900, training_loss: 2.83640e-02
I0211 09:28:02.388348 22542570456896 run_lib.py:146] step: 700900, eval_loss: 2.56781e-02
I0211 09:28:19.765578 22542570456896 run_lib.py:133] step: 700950, training_loss: 2.81820e-02
I0211 09:28:37.298043 22542570456896 run_lib.py:133] step: 701000, training_loss: 2.56590e-02
I0211 09:28:37.469872 22542570456896 run_lib.py:146] step: 701000, eval_loss: 2.99329e-02
I0211 09:28:54.898997 22542570456896 run_lib.py:133] step: 701050, training_loss: 2.40466e-02
I0211 09:29:12.310084 22542570456896 run_lib.py:133] step: 701100, training_loss: 2.59930e-02
I0211 09:29:12.467202 22542570456896 run_lib.py:146] step: 701100, eval_loss: 3.80042e-02
I0211 09:29:30.054375 22542570456896 run_lib.py:133] step: 701150, training_loss: 3.28695e-02
I0211 09:29:47.402334 22542570456896 run_lib.py:133] step: 701200, training_loss: 2.76104e-02
I0211 09:29:47.557384 22542570456896 run_lib.py:146] step: 701200, eval_loss: 2.40276e-02
I0211 09:30:04.956098 22542570456896 run_lib.py:133] step: 701250, training_loss: 2.99514e-02
I0211 09:30:22.525949 22542570456896 run_lib.py:133] step: 701300, training_loss: 2.40728e-02
I0211 09:30:22.683465 22542570456896 run_lib.py:146] step: 701300, eval_loss: 3.32351e-02
I0211 09:30:40.115532 22542570456896 run_lib.py:133] step: 701350, training_loss: 3.30674e-02
I0211 09:30:57.472566 22542570456896 run_lib.py:133] step: 701400, training_loss: 2.50212e-02
I0211 09:30:57.805180 22542570456896 run_lib.py:146] step: 701400, eval_loss: 3.05894e-02
I0211 09:31:15.218329 22542570456896 run_lib.py:133] step: 701450, training_loss: 3.53425e-02
I0211 09:31:32.612117 22542570456896 run_lib.py:133] step: 701500, training_loss: 2.72527e-02
I0211 09:31:32.776642 22542570456896 run_lib.py:146] step: 701500, eval_loss: 2.50945e-02
I0211 09:31:50.184929 22542570456896 run_lib.py:133] step: 701550, training_loss: 2.51549e-02
I0211 09:32:07.632714 22542570456896 run_lib.py:133] step: 701600, training_loss: 2.72675e-02
I0211 09:32:07.818821 22542570456896 run_lib.py:146] step: 701600, eval_loss: 3.15508e-02
I0211 09:32:25.392576 22542570456896 run_lib.py:133] step: 701650, training_loss: 3.11535e-02
I0211 09:32:42.855387 22542570456896 run_lib.py:133] step: 701700, training_loss: 2.50072e-02
I0211 09:32:43.016491 22542570456896 run_lib.py:146] step: 701700, eval_loss: 3.40534e-02
I0211 09:33:00.462961 22542570456896 run_lib.py:133] step: 701750, training_loss: 2.13647e-02
I0211 09:33:17.867813 22542570456896 run_lib.py:133] step: 701800, training_loss: 3.44804e-02
I0211 09:33:18.023312 22542570456896 run_lib.py:146] step: 701800, eval_loss: 2.69478e-02
I0211 09:33:35.579273 22542570456896 run_lib.py:133] step: 701850, training_loss: 2.30631e-02
I0211 09:33:53.100886 22542570456896 run_lib.py:133] step: 701900, training_loss: 2.59738e-02
I0211 09:33:53.254554 22542570456896 run_lib.py:146] step: 701900, eval_loss: 2.59294e-02
I0211 09:34:10.661307 22542570456896 run_lib.py:133] step: 701950, training_loss: 2.58828e-02
I0211 09:34:28.080121 22542570456896 run_lib.py:133] step: 702000, training_loss: 3.38355e-02
I0211 09:34:28.241525 22542570456896 run_lib.py:146] step: 702000, eval_loss: 2.75544e-02
I0211 09:34:45.737632 22542570456896 run_lib.py:133] step: 702050, training_loss: 3.26118e-02
I0211 09:35:03.117579 22542570456896 run_lib.py:133] step: 702100, training_loss: 2.82866e-02
I0211 09:35:03.274315 22542570456896 run_lib.py:146] step: 702100, eval_loss: 2.86347e-02
I0211 09:35:20.835668 22542570456896 run_lib.py:133] step: 702150, training_loss: 2.84326e-02
I0211 09:35:38.260280 22542570456896 run_lib.py:133] step: 702200, training_loss: 3.04668e-02
I0211 09:35:38.417795 22542570456896 run_lib.py:146] step: 702200, eval_loss: 3.33616e-02
I0211 09:35:56.036048 22542570456896 run_lib.py:133] step: 702250, training_loss: 2.80899e-02
I0211 09:36:13.439219 22542570456896 run_lib.py:133] step: 702300, training_loss: 2.80787e-02
I0211 09:36:13.590189 22542570456896 run_lib.py:146] step: 702300, eval_loss: 3.39766e-02
I0211 09:36:30.999674 22542570456896 run_lib.py:133] step: 702350, training_loss: 2.79318e-02
I0211 09:36:48.523493 22542570456896 run_lib.py:133] step: 702400, training_loss: 2.34801e-02
I0211 09:36:48.687682 22542570456896 run_lib.py:146] step: 702400, eval_loss: 2.67466e-02
I0211 09:37:06.157300 22542570456896 run_lib.py:133] step: 702450, training_loss: 2.90828e-02
I0211 09:37:23.788009 22542570456896 run_lib.py:133] step: 702500, training_loss: 2.60360e-02
I0211 09:37:23.941536 22542570456896 run_lib.py:146] step: 702500, eval_loss: 2.40106e-02
I0211 09:37:41.317030 22542570456896 run_lib.py:133] step: 702550, training_loss: 2.84580e-02
I0211 09:37:58.702010 22542570456896 run_lib.py:133] step: 702600, training_loss: 2.26459e-02
I0211 09:37:58.857308 22542570456896 run_lib.py:146] step: 702600, eval_loss: 2.76197e-02
I0211 09:38:16.441384 22542570456896 run_lib.py:133] step: 702650, training_loss: 2.55825e-02
I0211 09:38:33.912629 22542570456896 run_lib.py:133] step: 702700, training_loss: 3.17915e-02
I0211 09:38:34.069607 22542570456896 run_lib.py:146] step: 702700, eval_loss: 2.53931e-02
I0211 09:38:51.503405 22542570456896 run_lib.py:133] step: 702750, training_loss: 2.98602e-02
I0211 09:39:08.871586 22542570456896 run_lib.py:133] step: 702800, training_loss: 3.54867e-02
I0211 09:39:09.035318 22542570456896 run_lib.py:146] step: 702800, eval_loss: 2.70316e-02
I0211 09:39:26.629371 22542570456896 run_lib.py:133] step: 702850, training_loss: 2.91530e-02
I0211 09:39:44.143343 22542570456896 run_lib.py:133] step: 702900, training_loss: 2.57473e-02
I0211 09:39:44.299190 22542570456896 run_lib.py:146] step: 702900, eval_loss: 3.06319e-02
I0211 09:40:01.765307 22542570456896 run_lib.py:133] step: 702950, training_loss: 2.10864e-02
I0211 09:40:19.200029 22542570456896 run_lib.py:133] step: 703000, training_loss: 2.56183e-02
I0211 09:40:19.374312 22542570456896 run_lib.py:146] step: 703000, eval_loss: 2.62360e-02
I0211 09:40:36.832068 22542570456896 run_lib.py:133] step: 703050, training_loss: 2.46988e-02
I0211 09:40:54.243607 22542570456896 run_lib.py:133] step: 703100, training_loss: 3.30180e-02
I0211 09:40:54.405349 22542570456896 run_lib.py:146] step: 703100, eval_loss: 2.95862e-02
I0211 09:41:12.012510 22542570456896 run_lib.py:133] step: 703150, training_loss: 3.29362e-02
I0211 09:41:29.467860 22542570456896 run_lib.py:133] step: 703200, training_loss: 1.99960e-02
I0211 09:41:29.639027 22542570456896 run_lib.py:146] step: 703200, eval_loss: 2.76411e-02
I0211 09:41:47.064462 22542570456896 run_lib.py:133] step: 703250, training_loss: 2.47731e-02
I0211 09:42:04.527099 22542570456896 run_lib.py:133] step: 703300, training_loss: 3.17348e-02
I0211 09:42:04.681700 22542570456896 run_lib.py:146] step: 703300, eval_loss: 2.86936e-02
I0211 09:42:22.254618 22542570456896 run_lib.py:133] step: 703350, training_loss: 2.90505e-02
I0211 09:42:39.672381 22542570456896 run_lib.py:133] step: 703400, training_loss: 2.35285e-02
I0211 09:42:39.835464 22542570456896 run_lib.py:146] step: 703400, eval_loss: 3.09433e-02
I0211 09:42:57.412949 22542570456896 run_lib.py:133] step: 703450, training_loss: 2.93427e-02
I0211 09:43:14.793646 22542570456896 run_lib.py:133] step: 703500, training_loss: 2.62318e-02
I0211 09:43:14.956448 22542570456896 run_lib.py:146] step: 703500, eval_loss: 2.41716e-02
I0211 09:43:32.550488 22542570456896 run_lib.py:133] step: 703550, training_loss: 3.50697e-02
I0211 09:43:49.962322 22542570456896 run_lib.py:133] step: 703600, training_loss: 3.05630e-02
I0211 09:43:50.117071 22542570456896 run_lib.py:146] step: 703600, eval_loss: 3.02414e-02
I0211 09:44:07.697871 22542570456896 run_lib.py:133] step: 703650, training_loss: 3.65938e-02
I0211 09:44:25.098001 22542570456896 run_lib.py:133] step: 703700, training_loss: 3.00419e-02
I0211 09:44:25.253048 22542570456896 run_lib.py:146] step: 703700, eval_loss: 2.64044e-02
I0211 09:44:42.673712 22542570456896 run_lib.py:133] step: 703750, training_loss: 3.57588e-02
I0211 09:45:00.182290 22542570456896 run_lib.py:133] step: 703800, training_loss: 2.83558e-02
I0211 09:45:00.336458 22542570456896 run_lib.py:146] step: 703800, eval_loss: 2.72760e-02
I0211 09:45:17.790089 22542570456896 run_lib.py:133] step: 703850, training_loss: 2.34254e-02
I0211 09:45:35.197369 22542570456896 run_lib.py:133] step: 703900, training_loss: 2.90787e-02
I0211 09:45:35.362876 22542570456896 run_lib.py:146] step: 703900, eval_loss: 3.11801e-02
I0211 09:45:52.922687 22542570456896 run_lib.py:133] step: 703950, training_loss: 2.27363e-02
I0211 09:46:10.468387 22542570456896 run_lib.py:133] step: 704000, training_loss: 3.60691e-02
I0211 09:46:10.624390 22542570456896 run_lib.py:146] step: 704000, eval_loss: 3.48345e-02
I0211 09:46:28.000438 22542570456896 run_lib.py:133] step: 704050, training_loss: 2.69332e-02
I0211 09:46:45.384721 22542570456896 run_lib.py:133] step: 704100, training_loss: 2.45021e-02
I0211 09:46:45.544969 22542570456896 run_lib.py:146] step: 704100, eval_loss: 3.11209e-02
I0211 09:47:02.927125 22542570456896 run_lib.py:133] step: 704150, training_loss: 2.43207e-02
I0211 09:47:20.515674 22542570456896 run_lib.py:133] step: 704200, training_loss: 2.78766e-02
I0211 09:47:20.667454 22542570456896 run_lib.py:146] step: 704200, eval_loss: 2.84301e-02
I0211 09:47:38.094158 22542570456896 run_lib.py:133] step: 704250, training_loss: 2.30157e-02
I0211 09:47:55.502389 22542570456896 run_lib.py:133] step: 704300, training_loss: 3.51161e-02
I0211 09:47:55.656280 22542570456896 run_lib.py:146] step: 704300, eval_loss: 2.63172e-02
I0211 09:48:13.045237 22542570456896 run_lib.py:133] step: 704350, training_loss: 2.87870e-02
I0211 09:48:30.620069 22542570456896 run_lib.py:133] step: 704400, training_loss: 2.66107e-02
I0211 09:48:30.796296 22542570456896 run_lib.py:146] step: 704400, eval_loss: 2.67894e-02
I0211 09:48:48.288265 22542570456896 run_lib.py:133] step: 704450, training_loss: 2.37483e-02
I0211 09:49:05.823710 22542570456896 run_lib.py:133] step: 704500, training_loss: 2.60982e-02
I0211 09:49:05.979504 22542570456896 run_lib.py:146] step: 704500, eval_loss: 2.69274e-02
I0211 09:49:23.377321 22542570456896 run_lib.py:133] step: 704550, training_loss: 2.41544e-02
I0211 09:49:40.727348 22542570456896 run_lib.py:133] step: 704600, training_loss: 2.26775e-02
I0211 09:49:40.883450 22542570456896 run_lib.py:146] step: 704600, eval_loss: 2.81858e-02
I0211 09:49:58.403526 22542570456896 run_lib.py:133] step: 704650, training_loss: 2.33628e-02
I0211 09:50:15.912689 22542570456896 run_lib.py:133] step: 704700, training_loss: 2.58196e-02
I0211 09:50:16.062528 22542570456896 run_lib.py:146] step: 704700, eval_loss: 2.67540e-02
I0211 09:50:33.514226 22542570456896 run_lib.py:133] step: 704750, training_loss: 2.09274e-02
I0211 09:50:50.948847 22542570456896 run_lib.py:133] step: 704800, training_loss: 3.23964e-02
I0211 09:50:51.105283 22542570456896 run_lib.py:146] step: 704800, eval_loss: 2.94570e-02
I0211 09:51:08.700796 22542570456896 run_lib.py:133] step: 704850, training_loss: 2.12191e-02
I0211 09:51:26.018987 22542570456896 run_lib.py:133] step: 704900, training_loss: 2.83605e-02
I0211 09:51:26.174628 22542570456896 run_lib.py:146] step: 704900, eval_loss: 2.41180e-02
I0211 09:51:43.615104 22542570456896 run_lib.py:133] step: 704950, training_loss: 2.59274e-02
I0211 09:52:00.985950 22542570456896 run_lib.py:133] step: 705000, training_loss: 2.63187e-02
I0211 09:52:01.138351 22542570456896 run_lib.py:146] step: 705000, eval_loss: 3.08650e-02
I0211 09:52:18.692414 22542570456896 run_lib.py:133] step: 705050, training_loss: 2.79587e-02
I0211 09:52:36.114457 22542570456896 run_lib.py:133] step: 705100, training_loss: 1.94501e-02
I0211 09:52:36.269549 22542570456896 run_lib.py:146] step: 705100, eval_loss: 2.81336e-02
I0211 09:52:53.672663 22542570456896 run_lib.py:133] step: 705150, training_loss: 3.13090e-02
I0211 09:53:11.286692 22542570456896 run_lib.py:133] step: 705200, training_loss: 2.71374e-02
I0211 09:53:11.445528 22542570456896 run_lib.py:146] step: 705200, eval_loss: 3.39848e-02
I0211 09:53:28.865225 22542570456896 run_lib.py:133] step: 705250, training_loss: 2.75398e-02
I0211 09:53:46.465156 22542570456896 run_lib.py:133] step: 705300, training_loss: 1.91505e-02
I0211 09:53:46.621456 22542570456896 run_lib.py:146] step: 705300, eval_loss: 2.30051e-02
I0211 09:54:04.022430 22542570456896 run_lib.py:133] step: 705350, training_loss: 2.40903e-02
I0211 09:54:21.460018 22542570456896 run_lib.py:133] step: 705400, training_loss: 3.26757e-02
I0211 09:54:21.612647 22542570456896 run_lib.py:146] step: 705400, eval_loss: 3.13992e-02
I0211 09:54:39.222235 22542570456896 run_lib.py:133] step: 705450, training_loss: 3.03112e-02
I0211 09:54:56.626904 22542570456896 run_lib.py:133] step: 705500, training_loss: 2.67055e-02
I0211 09:54:56.782479 22542570456896 run_lib.py:146] step: 705500, eval_loss: 2.67251e-02
I0211 09:55:14.249440 22542570456896 run_lib.py:133] step: 705550, training_loss: 2.62515e-02
I0211 09:55:31.886938 22542570456896 run_lib.py:133] step: 705600, training_loss: 2.43909e-02
I0211 09:55:32.042527 22542570456896 run_lib.py:146] step: 705600, eval_loss: 2.51331e-02
I0211 09:55:49.472331 22542570456896 run_lib.py:133] step: 705650, training_loss: 2.50396e-02
I0211 09:56:06.878714 22542570456896 run_lib.py:133] step: 705700, training_loss: 3.01520e-02
I0211 09:56:07.031373 22542570456896 run_lib.py:146] step: 705700, eval_loss: 3.35969e-02
I0211 09:56:24.529227 22542570456896 run_lib.py:133] step: 705750, training_loss: 2.70025e-02
I0211 09:56:41.969603 22542570456896 run_lib.py:133] step: 705800, training_loss: 2.94586e-02
I0211 09:56:42.134497 22542570456896 run_lib.py:146] step: 705800, eval_loss: 2.77679e-02
I0211 09:56:59.606123 22542570456896 run_lib.py:133] step: 705850, training_loss: 2.86065e-02
I0211 09:57:17.065834 22542570456896 run_lib.py:133] step: 705900, training_loss: 3.10929e-02
I0211 09:57:17.222596 22542570456896 run_lib.py:146] step: 705900, eval_loss: 2.70381e-02
I0211 09:57:34.820325 22542570456896 run_lib.py:133] step: 705950, training_loss: 2.53471e-02
I0211 09:57:52.283312 22542570456896 run_lib.py:133] step: 706000, training_loss: 2.81377e-02
I0211 09:57:52.440265 22542570456896 run_lib.py:146] step: 706000, eval_loss: 2.21530e-02
I0211 09:58:09.865076 22542570456896 run_lib.py:133] step: 706050, training_loss: 2.76718e-02
I0211 09:58:27.313792 22542570456896 run_lib.py:133] step: 706100, training_loss: 3.07464e-02
I0211 09:58:27.468632 22542570456896 run_lib.py:146] step: 706100, eval_loss: 3.11892e-02
I0211 09:58:45.106018 22542570456896 run_lib.py:133] step: 706150, training_loss: 3.66070e-02
I0211 09:59:02.537003 22542570456896 run_lib.py:133] step: 706200, training_loss: 2.62578e-02
I0211 09:59:02.691236 22542570456896 run_lib.py:146] step: 706200, eval_loss: 3.30545e-02
I0211 09:59:20.258145 22542570456896 run_lib.py:133] step: 706250, training_loss: 2.58457e-02
I0211 09:59:37.647111 22542570456896 run_lib.py:133] step: 706300, training_loss: 3.34392e-02
I0211 09:59:37.815630 22542570456896 run_lib.py:146] step: 706300, eval_loss: 3.87374e-02
I0211 09:59:55.414607 22542570456896 run_lib.py:133] step: 706350, training_loss: 2.44994e-02
I0211 10:00:12.863502 22542570456896 run_lib.py:133] step: 706400, training_loss: 2.93028e-02
I0211 10:00:13.022516 22542570456896 run_lib.py:146] step: 706400, eval_loss: 2.17138e-02
I0211 10:00:30.666219 22542570456896 run_lib.py:133] step: 706450, training_loss: 2.95476e-02
I0211 10:00:48.067522 22542570456896 run_lib.py:133] step: 706500, training_loss: 2.76147e-02
I0211 10:00:48.223266 22542570456896 run_lib.py:146] step: 706500, eval_loss: 3.08388e-02
I0211 10:01:05.654128 22542570456896 run_lib.py:133] step: 706550, training_loss: 2.85239e-02
I0211 10:01:23.181581 22542570456896 run_lib.py:133] step: 706600, training_loss: 3.06314e-02
I0211 10:01:23.333333 22542570456896 run_lib.py:146] step: 706600, eval_loss: 3.11767e-02
I0211 10:01:40.764013 22542570456896 run_lib.py:133] step: 706650, training_loss: 3.08433e-02
I0211 10:01:58.214752 22542570456896 run_lib.py:133] step: 706700, training_loss: 3.38718e-02
I0211 10:01:58.386679 22542570456896 run_lib.py:146] step: 706700, eval_loss: 2.60359e-02
I0211 10:02:16.030422 22542570456896 run_lib.py:133] step: 706750, training_loss: 2.09458e-02
I0211 10:02:33.470333 22542570456896 run_lib.py:133] step: 706800, training_loss: 2.32110e-02
I0211 10:02:33.629580 22542570456896 run_lib.py:146] step: 706800, eval_loss: 2.32814e-02
I0211 10:02:51.199092 22542570456896 run_lib.py:133] step: 706850, training_loss: 2.96146e-02
I0211 10:03:08.576993 22542570456896 run_lib.py:133] step: 706900, training_loss: 2.03235e-02
I0211 10:03:08.745398 22542570456896 run_lib.py:146] step: 706900, eval_loss: 3.03397e-02
I0211 10:03:26.157238 22542570456896 run_lib.py:133] step: 706950, training_loss: 2.41890e-02
I0211 10:03:43.787672 22542570456896 run_lib.py:133] step: 707000, training_loss: 2.09004e-02
I0211 10:03:43.941846 22542570456896 run_lib.py:146] step: 707000, eval_loss: 2.84662e-02
I0211 10:04:01.385328 22542570456896 run_lib.py:133] step: 707050, training_loss: 2.98643e-02
I0211 10:04:18.772594 22542570456896 run_lib.py:133] step: 707100, training_loss: 2.73863e-02
I0211 10:04:18.924351 22542570456896 run_lib.py:146] step: 707100, eval_loss: 3.20971e-02
I0211 10:04:36.296683 22542570456896 run_lib.py:133] step: 707150, training_loss: 2.57529e-02
I0211 10:04:53.835523 22542570456896 run_lib.py:133] step: 707200, training_loss: 3.38114e-02
I0211 10:04:54.013277 22542570456896 run_lib.py:146] step: 707200, eval_loss: 2.43613e-02
I0211 10:05:11.446690 22542570456896 run_lib.py:133] step: 707250, training_loss: 2.59743e-02
I0211 10:05:28.978228 22542570456896 run_lib.py:133] step: 707300, training_loss: 2.55570e-02
I0211 10:05:29.135364 22542570456896 run_lib.py:146] step: 707300, eval_loss: 3.23088e-02
I0211 10:05:46.548594 22542570456896 run_lib.py:133] step: 707350, training_loss: 3.25091e-02
I0211 10:06:03.939606 22542570456896 run_lib.py:133] step: 707400, training_loss: 2.49256e-02
I0211 10:06:04.103098 22542570456896 run_lib.py:146] step: 707400, eval_loss: 3.05845e-02
I0211 10:06:21.645271 22542570456896 run_lib.py:133] step: 707450, training_loss: 2.42753e-02
I0211 10:06:39.198235 22542570456896 run_lib.py:133] step: 707500, training_loss: 2.52214e-02
I0211 10:06:39.351188 22542570456896 run_lib.py:146] step: 707500, eval_loss: 2.74840e-02
I0211 10:06:56.788153 22542570456896 run_lib.py:133] step: 707550, training_loss: 2.51506e-02
I0211 10:07:14.272287 22542570456896 run_lib.py:133] step: 707600, training_loss: 2.24239e-02
I0211 10:07:14.423314 22542570456896 run_lib.py:146] step: 707600, eval_loss: 3.00758e-02
I0211 10:07:31.976573 22542570456896 run_lib.py:133] step: 707650, training_loss: 2.73206e-02
I0211 10:07:49.384330 22542570456896 run_lib.py:133] step: 707700, training_loss: 2.54371e-02
I0211 10:07:49.543529 22542570456896 run_lib.py:146] step: 707700, eval_loss: 2.45754e-02
I0211 10:08:07.101870 22542570456896 run_lib.py:133] step: 707750, training_loss: 1.97717e-02
I0211 10:08:24.602037 22542570456896 run_lib.py:133] step: 707800, training_loss: 3.24811e-02
I0211 10:08:24.757652 22542570456896 run_lib.py:146] step: 707800, eval_loss: 3.05526e-02
I0211 10:08:42.384768 22542570456896 run_lib.py:133] step: 707850, training_loss: 2.87836e-02
I0211 10:08:59.783682 22542570456896 run_lib.py:133] step: 707900, training_loss: 2.83860e-02
I0211 10:08:59.938460 22542570456896 run_lib.py:146] step: 707900, eval_loss: 3.20958e-02
I0211 10:09:17.330607 22542570456896 run_lib.py:133] step: 707950, training_loss: 2.75636e-02
I0211 10:09:34.929679 22542570456896 run_lib.py:133] step: 708000, training_loss: 2.24962e-02
I0211 10:09:35.081564 22542570456896 run_lib.py:146] step: 708000, eval_loss: 2.39952e-02
I0211 10:09:52.572531 22542570456896 run_lib.py:133] step: 708050, training_loss: 3.27347e-02
I0211 10:10:10.162209 22542570456896 run_lib.py:133] step: 708100, training_loss: 2.60493e-02
I0211 10:10:10.317525 22542570456896 run_lib.py:146] step: 708100, eval_loss: 2.90218e-02
I0211 10:10:27.712018 22542570456896 run_lib.py:133] step: 708150, training_loss: 2.65081e-02
I0211 10:10:45.123048 22542570456896 run_lib.py:133] step: 708200, training_loss: 2.60583e-02
I0211 10:10:45.288594 22542570456896 run_lib.py:146] step: 708200, eval_loss: 3.13460e-02
I0211 10:11:02.862500 22542570456896 run_lib.py:133] step: 708250, training_loss: 3.62796e-02
I0211 10:11:20.292840 22542570456896 run_lib.py:133] step: 708300, training_loss: 3.05311e-02
I0211 10:11:20.453327 22542570456896 run_lib.py:146] step: 708300, eval_loss: 2.76981e-02
I0211 10:11:37.887868 22542570456896 run_lib.py:133] step: 708350, training_loss: 2.87622e-02
I0211 10:11:55.472335 22542570456896 run_lib.py:133] step: 708400, training_loss: 2.99312e-02
I0211 10:11:55.628571 22542570456896 run_lib.py:146] step: 708400, eval_loss: 2.80653e-02
I0211 10:12:13.083450 22542570456896 run_lib.py:133] step: 708450, training_loss: 2.79743e-02
I0211 10:12:30.518898 22542570456896 run_lib.py:133] step: 708500, training_loss: 2.58423e-02
I0211 10:12:30.812225 22542570456896 run_lib.py:146] step: 708500, eval_loss: 1.92843e-02
I0211 10:12:48.216593 22542570456896 run_lib.py:133] step: 708550, training_loss: 2.72892e-02
I0211 10:13:05.667833 22542570456896 run_lib.py:133] step: 708600, training_loss: 3.09427e-02
I0211 10:13:05.835220 22542570456896 run_lib.py:146] step: 708600, eval_loss: 2.96606e-02
I0211 10:13:23.314094 22542570456896 run_lib.py:133] step: 708650, training_loss: 2.68473e-02
I0211 10:13:40.762573 22542570456896 run_lib.py:133] step: 708700, training_loss: 2.98857e-02
I0211 10:13:40.924407 22542570456896 run_lib.py:146] step: 708700, eval_loss: 3.16670e-02
I0211 10:13:58.532532 22542570456896 run_lib.py:133] step: 708750, training_loss: 3.28281e-02
I0211 10:14:15.993535 22542570456896 run_lib.py:133] step: 708800, training_loss: 2.70883e-02
I0211 10:14:16.146614 22542570456896 run_lib.py:146] step: 708800, eval_loss: 2.88210e-02
I0211 10:14:33.657131 22542570456896 run_lib.py:133] step: 708850, training_loss: 2.70989e-02
I0211 10:14:51.115648 22542570456896 run_lib.py:133] step: 708900, training_loss: 2.90669e-02
I0211 10:14:51.278941 22542570456896 run_lib.py:146] step: 708900, eval_loss: 3.02776e-02
I0211 10:15:08.910200 22542570456896 run_lib.py:133] step: 708950, training_loss: 3.43866e-02
I0211 10:15:26.392722 22542570456896 run_lib.py:133] step: 709000, training_loss: 2.46316e-02
I0211 10:15:26.545321 22542570456896 run_lib.py:146] step: 709000, eval_loss: 2.95640e-02
I0211 10:15:43.982674 22542570456896 run_lib.py:133] step: 709050, training_loss: 2.79448e-02
I0211 10:16:01.443294 22542570456896 run_lib.py:133] step: 709100, training_loss: 2.26216e-02
I0211 10:16:01.605687 22542570456896 run_lib.py:146] step: 709100, eval_loss: 2.41704e-02
I0211 10:16:19.205130 22542570456896 run_lib.py:133] step: 709150, training_loss: 2.27649e-02
I0211 10:16:36.620823 22542570456896 run_lib.py:133] step: 709200, training_loss: 3.00950e-02
I0211 10:16:36.785343 22542570456896 run_lib.py:146] step: 709200, eval_loss: 2.77915e-02
I0211 10:16:54.365992 22542570456896 run_lib.py:133] step: 709250, training_loss: 2.69984e-02
I0211 10:17:11.821310 22542570456896 run_lib.py:133] step: 709300, training_loss: 2.50940e-02
I0211 10:17:11.985118 22542570456896 run_lib.py:146] step: 709300, eval_loss: 2.74427e-02
I0211 10:17:29.537277 22542570456896 run_lib.py:133] step: 709350, training_loss: 2.25366e-02
I0211 10:17:46.940364 22542570456896 run_lib.py:133] step: 709400, training_loss: 2.73578e-02
I0211 10:17:47.094191 22542570456896 run_lib.py:146] step: 709400, eval_loss: 3.13854e-02
I0211 10:18:04.578986 22542570456896 run_lib.py:133] step: 709450, training_loss: 2.61186e-02
I0211 10:18:22.160175 22542570456896 run_lib.py:133] step: 709500, training_loss: 2.68887e-02
I0211 10:18:22.312264 22542570456896 run_lib.py:146] step: 709500, eval_loss: 2.60094e-02
I0211 10:18:39.725442 22542570456896 run_lib.py:133] step: 709550, training_loss: 2.28554e-02
I0211 10:18:57.272223 22542570456896 run_lib.py:133] step: 709600, training_loss: 2.10133e-02
I0211 10:18:57.433539 22542570456896 run_lib.py:146] step: 709600, eval_loss: 3.23733e-02
I0211 10:19:14.854170 22542570456896 run_lib.py:133] step: 709650, training_loss: 2.09335e-02
I0211 10:19:32.287372 22542570456896 run_lib.py:133] step: 709700, training_loss: 2.56974e-02
I0211 10:19:32.450445 22542570456896 run_lib.py:146] step: 709700, eval_loss: 3.40743e-02
I0211 10:19:50.101732 22542570456896 run_lib.py:133] step: 709750, training_loss: 3.02010e-02
I0211 10:20:07.478458 22542570456896 run_lib.py:133] step: 709800, training_loss: 3.03493e-02
I0211 10:20:07.634520 22542570456896 run_lib.py:146] step: 709800, eval_loss: 2.83896e-02
I0211 10:20:25.094515 22542570456896 run_lib.py:133] step: 709850, training_loss: 3.23507e-02
I0211 10:20:42.488470 22542570456896 run_lib.py:133] step: 709900, training_loss: 2.97453e-02
I0211 10:20:42.636233 22542570456896 run_lib.py:146] step: 709900, eval_loss: 2.88550e-02
I0211 10:21:00.224800 22542570456896 run_lib.py:133] step: 709950, training_loss: 2.77751e-02
I0211 10:21:17.700473 22542570456896 run_lib.py:133] step: 710000, training_loss: 2.80445e-02
I0211 10:21:18.484155 22542570456896 run_lib.py:146] step: 710000, eval_loss: 2.08551e-02
I0211 10:21:38.969237 22542570456896 run_lib.py:133] step: 710050, training_loss: 3.38763e-02
I0211 10:21:56.385836 22542570456896 run_lib.py:133] step: 710100, training_loss: 2.88630e-02
I0211 10:21:56.540199 22542570456896 run_lib.py:146] step: 710100, eval_loss: 2.25474e-02
I0211 10:22:14.113874 22542570456896 run_lib.py:133] step: 710150, training_loss: 2.49771e-02
I0211 10:22:31.554094 22542570456896 run_lib.py:133] step: 710200, training_loss: 3.19083e-02
I0211 10:22:31.729468 22542570456896 run_lib.py:146] step: 710200, eval_loss: 2.99114e-02
I0211 10:22:49.184061 22542570456896 run_lib.py:133] step: 710250, training_loss: 3.02302e-02
I0211 10:23:06.747373 22542570456896 run_lib.py:133] step: 710300, training_loss: 2.76229e-02
I0211 10:23:06.899494 22542570456896 run_lib.py:146] step: 710300, eval_loss: 2.87008e-02
I0211 10:23:24.324046 22542570456896 run_lib.py:133] step: 710350, training_loss: 2.76005e-02
I0211 10:23:41.667860 22542570456896 run_lib.py:133] step: 710400, training_loss: 3.21950e-02
I0211 10:23:41.821336 22542570456896 run_lib.py:146] step: 710400, eval_loss: 2.53039e-02
I0211 10:23:59.219445 22542570456896 run_lib.py:133] step: 710450, training_loss: 2.68695e-02
I0211 10:24:16.818182 22542570456896 run_lib.py:133] step: 710500, training_loss: 2.61826e-02
I0211 10:24:16.972493 22542570456896 run_lib.py:146] step: 710500, eval_loss: 2.86395e-02
I0211 10:24:34.412381 22542570456896 run_lib.py:133] step: 710550, training_loss: 3.65735e-02
I0211 10:24:51.917530 22542570456896 run_lib.py:133] step: 710600, training_loss: 2.60786e-02
I0211 10:24:52.077534 22542570456896 run_lib.py:146] step: 710600, eval_loss: 3.14627e-02
I0211 10:25:09.450742 22542570456896 run_lib.py:133] step: 710650, training_loss: 2.44941e-02
I0211 10:25:26.863359 22542570456896 run_lib.py:133] step: 710700, training_loss: 2.98588e-02
I0211 10:25:27.023395 22542570456896 run_lib.py:146] step: 710700, eval_loss: 2.76819e-02
I0211 10:25:44.585438 22542570456896 run_lib.py:133] step: 710750, training_loss: 2.64061e-02
I0211 10:26:02.134175 22542570456896 run_lib.py:133] step: 710800, training_loss: 3.29491e-02
I0211 10:26:02.289994 22542570456896 run_lib.py:146] step: 710800, eval_loss: 3.34882e-02
I0211 10:26:19.705540 22542570456896 run_lib.py:133] step: 710850, training_loss: 2.77655e-02
I0211 10:26:37.128570 22542570456896 run_lib.py:133] step: 710900, training_loss: 2.32717e-02
I0211 10:26:37.281137 22542570456896 run_lib.py:146] step: 710900, eval_loss: 2.40516e-02
I0211 10:26:54.833549 22542570456896 run_lib.py:133] step: 710950, training_loss: 3.07289e-02
I0211 10:27:12.226503 22542570456896 run_lib.py:133] step: 711000, training_loss: 2.86980e-02
I0211 10:27:12.380869 22542570456896 run_lib.py:146] step: 711000, eval_loss: 3.00266e-02
I0211 10:27:29.943129 22542570456896 run_lib.py:133] step: 711050, training_loss: 2.84082e-02
I0211 10:27:47.401436 22542570456896 run_lib.py:133] step: 711100, training_loss: 3.29347e-02
I0211 10:27:47.565066 22542570456896 run_lib.py:146] step: 711100, eval_loss: 2.81119e-02
I0211 10:28:05.165825 22542570456896 run_lib.py:133] step: 711150, training_loss: 2.20675e-02
I0211 10:28:22.655140 22542570456896 run_lib.py:133] step: 711200, training_loss: 2.44835e-02
I0211 10:28:22.810257 22542570456896 run_lib.py:146] step: 711200, eval_loss: 3.31964e-02
I0211 10:28:40.193683 22542570456896 run_lib.py:133] step: 711250, training_loss: 2.95337e-02
I0211 10:28:57.761130 22542570456896 run_lib.py:133] step: 711300, training_loss: 2.71768e-02
I0211 10:28:57.917409 22542570456896 run_lib.py:146] step: 711300, eval_loss: 2.74760e-02
I0211 10:29:15.393315 22542570456896 run_lib.py:133] step: 711350, training_loss: 3.01924e-02
I0211 10:29:33.009290 22542570456896 run_lib.py:133] step: 711400, training_loss: 2.43879e-02
I0211 10:29:33.159990 22542570456896 run_lib.py:146] step: 711400, eval_loss: 2.75379e-02
I0211 10:29:50.601814 22542570456896 run_lib.py:133] step: 711450, training_loss: 3.25221e-02
I0211 10:30:08.049504 22542570456896 run_lib.py:133] step: 711500, training_loss: 2.58480e-02
I0211 10:30:08.204203 22542570456896 run_lib.py:146] step: 711500, eval_loss: 2.96716e-02
I0211 10:30:25.705960 22542570456896 run_lib.py:133] step: 711550, training_loss: 3.36968e-02
I0211 10:30:43.127065 22542570456896 run_lib.py:133] step: 711600, training_loss: 3.57713e-02
I0211 10:30:43.306251 22542570456896 run_lib.py:146] step: 711600, eval_loss: 2.94286e-02
I0211 10:31:00.713704 22542570456896 run_lib.py:133] step: 711650, training_loss: 2.77951e-02
I0211 10:31:18.143816 22542570456896 run_lib.py:133] step: 711700, training_loss: 3.06736e-02
I0211 10:31:18.299555 22542570456896 run_lib.py:146] step: 711700, eval_loss: 3.19867e-02
I0211 10:31:35.908253 22542570456896 run_lib.py:133] step: 711750, training_loss: 2.76530e-02
I0211 10:31:53.279029 22542570456896 run_lib.py:133] step: 711800, training_loss: 2.20214e-02
I0211 10:31:53.436473 22542570456896 run_lib.py:146] step: 711800, eval_loss: 2.57430e-02
I0211 10:32:10.903747 22542570456896 run_lib.py:133] step: 711850, training_loss: 2.79370e-02
I0211 10:32:28.363820 22542570456896 run_lib.py:133] step: 711900, training_loss: 3.18825e-02
I0211 10:32:28.525409 22542570456896 run_lib.py:146] step: 711900, eval_loss: 2.36334e-02
I0211 10:32:45.911728 22542570456896 run_lib.py:133] step: 711950, training_loss: 2.98654e-02
I0211 10:33:03.360265 22542570456896 run_lib.py:133] step: 712000, training_loss: 2.59989e-02
I0211 10:33:03.515375 22542570456896 run_lib.py:146] step: 712000, eval_loss: 3.06455e-02
I0211 10:33:21.093298 22542570456896 run_lib.py:133] step: 712050, training_loss: 2.41188e-02
I0211 10:33:38.596819 22542570456896 run_lib.py:133] step: 712100, training_loss: 2.94718e-02
I0211 10:33:38.755531 22542570456896 run_lib.py:146] step: 712100, eval_loss: 2.60075e-02
I0211 10:33:56.177360 22542570456896 run_lib.py:133] step: 712150, training_loss: 2.92292e-02
I0211 10:34:13.628952 22542570456896 run_lib.py:133] step: 712200, training_loss: 2.55647e-02
I0211 10:34:13.785077 22542570456896 run_lib.py:146] step: 712200, eval_loss: 3.24461e-02
I0211 10:34:31.407382 22542570456896 run_lib.py:133] step: 712250, training_loss: 2.12780e-02
I0211 10:34:48.808688 22542570456896 run_lib.py:133] step: 712300, training_loss: 2.82790e-02
I0211 10:34:48.964545 22542570456896 run_lib.py:146] step: 712300, eval_loss: 2.35766e-02
I0211 10:35:06.461261 22542570456896 run_lib.py:133] step: 712350, training_loss: 2.53703e-02
I0211 10:35:23.862056 22542570456896 run_lib.py:133] step: 712400, training_loss: 2.37352e-02
I0211 10:35:24.015733 22542570456896 run_lib.py:146] step: 712400, eval_loss: 2.68144e-02
I0211 10:35:41.621358 22542570456896 run_lib.py:133] step: 712450, training_loss: 2.96125e-02
I0211 10:35:59.080003 22542570456896 run_lib.py:133] step: 712500, training_loss: 2.59683e-02
I0211 10:35:59.238407 22542570456896 run_lib.py:146] step: 712500, eval_loss: 2.95956e-02
I0211 10:36:16.789670 22542570456896 run_lib.py:133] step: 712550, training_loss: 3.24725e-02
I0211 10:36:34.174953 22542570456896 run_lib.py:133] step: 712600, training_loss: 2.58427e-02
I0211 10:36:34.330292 22542570456896 run_lib.py:146] step: 712600, eval_loss: 2.39816e-02
I0211 10:36:51.705268 22542570456896 run_lib.py:133] step: 712650, training_loss: 2.55876e-02
I0211 10:37:09.293125 22542570456896 run_lib.py:133] step: 712700, training_loss: 2.81626e-02
I0211 10:37:09.444799 22542570456896 run_lib.py:146] step: 712700, eval_loss: 3.36464e-02
I0211 10:37:26.929059 22542570456896 run_lib.py:133] step: 712750, training_loss: 3.17912e-02
I0211 10:37:44.375219 22542570456896 run_lib.py:133] step: 712800, training_loss: 3.03719e-02
I0211 10:37:44.528861 22542570456896 run_lib.py:146] step: 712800, eval_loss: 2.84814e-02
I0211 10:38:02.144486 22542570456896 run_lib.py:133] step: 712850, training_loss: 2.48238e-02
I0211 10:38:19.676823 22542570456896 run_lib.py:133] step: 712900, training_loss: 2.60679e-02
I0211 10:38:19.833174 22542570456896 run_lib.py:146] step: 712900, eval_loss: 2.87103e-02
I0211 10:38:37.219469 22542570456896 run_lib.py:133] step: 712950, training_loss: 2.42700e-02
I0211 10:38:54.629073 22542570456896 run_lib.py:133] step: 713000, training_loss: 3.12761e-02
I0211 10:38:54.804322 22542570456896 run_lib.py:146] step: 713000, eval_loss: 2.81016e-02
I0211 10:39:12.286192 22542570456896 run_lib.py:133] step: 713050, training_loss: 2.31195e-02
I0211 10:39:29.897388 22542570456896 run_lib.py:133] step: 713100, training_loss: 3.10162e-02
I0211 10:39:30.052480 22542570456896 run_lib.py:146] step: 713100, eval_loss: 2.57200e-02
I0211 10:39:47.468560 22542570456896 run_lib.py:133] step: 713150, training_loss: 1.97096e-02
I0211 10:40:04.822761 22542570456896 run_lib.py:133] step: 713200, training_loss: 3.30504e-02
I0211 10:40:04.983401 22542570456896 run_lib.py:146] step: 713200, eval_loss: 2.67095e-02
I0211 10:40:22.396967 22542570456896 run_lib.py:133] step: 713250, training_loss: 2.38456e-02
I0211 10:40:39.978980 22542570456896 run_lib.py:133] step: 713300, training_loss: 2.56082e-02
I0211 10:40:40.144684 22542570456896 run_lib.py:146] step: 713300, eval_loss: 2.59031e-02
I0211 10:40:57.582902 22542570456896 run_lib.py:133] step: 713350, training_loss: 2.29667e-02
I0211 10:41:15.078088 22542570456896 run_lib.py:133] step: 713400, training_loss: 2.91761e-02
I0211 10:41:15.235251 22542570456896 run_lib.py:146] step: 713400, eval_loss: 2.65799e-02
I0211 10:41:32.639061 22542570456896 run_lib.py:133] step: 713450, training_loss: 3.01653e-02
I0211 10:41:50.042345 22542570456896 run_lib.py:133] step: 713500, training_loss: 2.83286e-02
I0211 10:41:50.204647 22542570456896 run_lib.py:146] step: 713500, eval_loss: 3.43800e-02
I0211 10:42:07.725181 22542570456896 run_lib.py:133] step: 713550, training_loss: 2.49049e-02
I0211 10:42:25.216676 22542570456896 run_lib.py:133] step: 713600, training_loss: 2.37516e-02
I0211 10:42:25.372703 22542570456896 run_lib.py:146] step: 713600, eval_loss: 3.07556e-02
I0211 10:42:42.802293 22542570456896 run_lib.py:133] step: 713650, training_loss: 2.54992e-02
I0211 10:43:00.215160 22542570456896 run_lib.py:133] step: 713700, training_loss: 3.19963e-02
I0211 10:43:00.370096 22542570456896 run_lib.py:146] step: 713700, eval_loss: 3.12040e-02
I0211 10:43:17.983654 22542570456896 run_lib.py:133] step: 713750, training_loss: 2.50554e-02
I0211 10:43:35.454821 22542570456896 run_lib.py:133] step: 713800, training_loss: 2.88878e-02
I0211 10:43:35.605865 22542570456896 run_lib.py:146] step: 713800, eval_loss: 2.79559e-02
I0211 10:43:53.138272 22542570456896 run_lib.py:133] step: 713850, training_loss: 3.04971e-02
I0211 10:44:10.565969 22542570456896 run_lib.py:133] step: 713900, training_loss: 2.65585e-02
I0211 10:44:10.734167 22542570456896 run_lib.py:146] step: 713900, eval_loss: 2.98001e-02
I0211 10:44:28.372639 22542570456896 run_lib.py:133] step: 713950, training_loss: 2.54378e-02
I0211 10:44:45.825442 22542570456896 run_lib.py:133] step: 714000, training_loss: 2.91086e-02
I0211 10:44:45.983500 22542570456896 run_lib.py:146] step: 714000, eval_loss: 3.14860e-02
I0211 10:45:03.460267 22542570456896 run_lib.py:133] step: 714050, training_loss: 3.06032e-02
I0211 10:45:21.014141 22542570456896 run_lib.py:133] step: 714100, training_loss: 2.79808e-02
I0211 10:45:21.172344 22542570456896 run_lib.py:146] step: 714100, eval_loss: 2.43596e-02
I0211 10:45:38.589350 22542570456896 run_lib.py:133] step: 714150, training_loss: 2.04151e-02
I0211 10:45:56.232309 22542570456896 run_lib.py:133] step: 714200, training_loss: 3.07992e-02
I0211 10:45:56.387542 22542570456896 run_lib.py:146] step: 714200, eval_loss: 3.21320e-02
I0211 10:46:13.852856 22542570456896 run_lib.py:133] step: 714250, training_loss: 2.72278e-02
I0211 10:46:31.241757 22542570456896 run_lib.py:133] step: 714300, training_loss: 2.69634e-02
I0211 10:46:31.399289 22542570456896 run_lib.py:146] step: 714300, eval_loss: 2.32594e-02
I0211 10:46:48.932530 22542570456896 run_lib.py:133] step: 714350, training_loss: 2.95164e-02
I0211 10:47:06.349083 22542570456896 run_lib.py:133] step: 714400, training_loss: 2.95930e-02
I0211 10:47:06.516864 22542570456896 run_lib.py:146] step: 714400, eval_loss: 3.10642e-02
I0211 10:47:23.915439 22542570456896 run_lib.py:133] step: 714450, training_loss: 3.62170e-02
I0211 10:47:41.556205 22542570456896 run_lib.py:133] step: 714500, training_loss: 2.64241e-02
I0211 10:47:41.714526 22542570456896 run_lib.py:146] step: 714500, eval_loss: 3.04204e-02
I0211 10:47:59.092960 22542570456896 run_lib.py:133] step: 714550, training_loss: 2.42733e-02
I0211 10:48:16.466686 22542570456896 run_lib.py:133] step: 714600, training_loss: 2.52311e-02
I0211 10:48:16.622148 22542570456896 run_lib.py:146] step: 714600, eval_loss: 3.03110e-02
I0211 10:48:34.099716 22542570456896 run_lib.py:133] step: 714650, training_loss: 2.71769e-02
I0211 10:48:51.549853 22542570456896 run_lib.py:133] step: 714700, training_loss: 2.58537e-02
I0211 10:48:51.710191 22542570456896 run_lib.py:146] step: 714700, eval_loss: 3.25584e-02
I0211 10:49:09.183327 22542570456896 run_lib.py:133] step: 714750, training_loss: 2.93941e-02
I0211 10:49:26.611982 22542570456896 run_lib.py:133] step: 714800, training_loss: 2.29590e-02
I0211 10:49:26.765278 22542570456896 run_lib.py:146] step: 714800, eval_loss: 2.64220e-02
I0211 10:49:44.332053 22542570456896 run_lib.py:133] step: 714850, training_loss: 2.42348e-02
I0211 10:50:01.844236 22542570456896 run_lib.py:133] step: 714900, training_loss: 2.46916e-02
I0211 10:50:02.002533 22542570456896 run_lib.py:146] step: 714900, eval_loss: 3.12684e-02
I0211 10:50:19.380964 22542570456896 run_lib.py:133] step: 714950, training_loss: 1.77780e-02
I0211 10:50:36.821878 22542570456896 run_lib.py:133] step: 715000, training_loss: 2.53237e-02
I0211 10:50:36.976984 22542570456896 run_lib.py:146] step: 715000, eval_loss: 2.89261e-02
I0211 10:50:54.541901 22542570456896 run_lib.py:133] step: 715050, training_loss: 2.89877e-02
I0211 10:51:11.875952 22542570456896 run_lib.py:133] step: 715100, training_loss: 3.16998e-02
I0211 10:51:12.031464 22542570456896 run_lib.py:146] step: 715100, eval_loss: 3.10620e-02
I0211 10:51:29.551867 22542570456896 run_lib.py:133] step: 715150, training_loss: 2.19898e-02
I0211 10:51:46.935939 22542570456896 run_lib.py:133] step: 715200, training_loss: 3.20750e-02
I0211 10:51:47.086334 22542570456896 run_lib.py:146] step: 715200, eval_loss: 3.12137e-02
I0211 10:52:04.621543 22542570456896 run_lib.py:133] step: 715250, training_loss: 2.60245e-02
I0211 10:52:22.034053 22542570456896 run_lib.py:133] step: 715300, training_loss: 2.77098e-02
I0211 10:52:22.204660 22542570456896 run_lib.py:146] step: 715300, eval_loss: 3.16061e-02
I0211 10:52:39.797534 22542570456896 run_lib.py:133] step: 715350, training_loss: 2.50587e-02
I0211 10:52:57.269516 22542570456896 run_lib.py:133] step: 715400, training_loss: 2.43397e-02
I0211 10:52:57.427617 22542570456896 run_lib.py:146] step: 715400, eval_loss: 3.54288e-02
I0211 10:53:14.827743 22542570456896 run_lib.py:133] step: 715450, training_loss: 2.56795e-02
I0211 10:53:32.340092 22542570456896 run_lib.py:133] step: 715500, training_loss: 3.05941e-02
I0211 10:53:32.506298 22542570456896 run_lib.py:146] step: 715500, eval_loss: 3.24933e-02
I0211 10:53:49.918285 22542570456896 run_lib.py:133] step: 715550, training_loss: 2.56971e-02
I0211 10:54:07.391988 22542570456896 run_lib.py:133] step: 715600, training_loss: 2.41951e-02
I0211 10:54:07.543675 22542570456896 run_lib.py:146] step: 715600, eval_loss: 2.93671e-02
I0211 10:54:25.072694 22542570456896 run_lib.py:133] step: 715650, training_loss: 2.34363e-02
I0211 10:54:42.468589 22542570456896 run_lib.py:133] step: 715700, training_loss: 2.87438e-02
I0211 10:54:42.627259 22542570456896 run_lib.py:146] step: 715700, eval_loss: 2.46530e-02
I0211 10:55:00.185142 22542570456896 run_lib.py:133] step: 715750, training_loss: 3.13519e-02
I0211 10:55:17.590050 22542570456896 run_lib.py:133] step: 715800, training_loss: 2.62746e-02
I0211 10:55:17.759901 22542570456896 run_lib.py:146] step: 715800, eval_loss: 2.69941e-02
I0211 10:55:35.137861 22542570456896 run_lib.py:133] step: 715850, training_loss: 2.94525e-02
I0211 10:55:52.726458 22542570456896 run_lib.py:133] step: 715900, training_loss: 2.89971e-02
I0211 10:55:52.891462 22542570456896 run_lib.py:146] step: 715900, eval_loss: 2.38639e-02
I0211 10:56:10.322761 22542570456896 run_lib.py:133] step: 715950, training_loss: 2.28549e-02
I0211 10:56:27.715703 22542570456896 run_lib.py:133] step: 716000, training_loss: 2.57276e-02
I0211 10:56:27.870153 22542570456896 run_lib.py:146] step: 716000, eval_loss: 2.98527e-02
I0211 10:56:45.258255 22542570456896 run_lib.py:133] step: 716050, training_loss: 2.06806e-02
I0211 10:57:02.862358 22542570456896 run_lib.py:133] step: 716100, training_loss: 2.68356e-02
I0211 10:57:03.025280 22542570456896 run_lib.py:146] step: 716100, eval_loss: 3.31031e-02
I0211 10:57:20.456427 22542570456896 run_lib.py:133] step: 716150, training_loss: 3.26603e-02
I0211 10:57:37.907737 22542570456896 run_lib.py:133] step: 716200, training_loss: 2.68556e-02
I0211 10:57:38.059404 22542570456896 run_lib.py:146] step: 716200, eval_loss: 3.04453e-02
I0211 10:57:55.441796 22542570456896 run_lib.py:133] step: 716250, training_loss: 2.08165e-02
I0211 10:58:12.801451 22542570456896 run_lib.py:133] step: 716300, training_loss: 2.41323e-02
I0211 10:58:12.966280 22542570456896 run_lib.py:146] step: 716300, eval_loss: 2.82140e-02
I0211 10:58:30.551629 22542570456896 run_lib.py:133] step: 716350, training_loss: 2.19831e-02
I0211 10:58:48.054113 22542570456896 run_lib.py:133] step: 716400, training_loss: 3.14841e-02
I0211 10:58:48.208584 22542570456896 run_lib.py:146] step: 716400, eval_loss: 3.57852e-02
I0211 10:59:05.544676 22542570456896 run_lib.py:133] step: 716450, training_loss: 2.92945e-02
I0211 10:59:22.911516 22542570456896 run_lib.py:133] step: 716500, training_loss: 2.44707e-02
I0211 10:59:23.066107 22542570456896 run_lib.py:146] step: 716500, eval_loss: 2.59414e-02
I0211 10:59:40.562297 22542570456896 run_lib.py:133] step: 716550, training_loss: 2.24229e-02
I0211 10:59:57.977928 22542570456896 run_lib.py:133] step: 716600, training_loss: 2.93116e-02
I0211 10:59:58.129903 22542570456896 run_lib.py:146] step: 716600, eval_loss: 2.61664e-02
I0211 11:00:15.635184 22542570456896 run_lib.py:133] step: 716650, training_loss: 3.29672e-02
I0211 11:00:32.921301 22542570456896 run_lib.py:133] step: 716700, training_loss: 2.93108e-02
I0211 11:00:33.076214 22542570456896 run_lib.py:146] step: 716700, eval_loss: 3.48394e-02
I0211 11:00:50.505450 22542570456896 run_lib.py:133] step: 716750, training_loss: 2.90457e-02
I0211 11:01:07.848783 22542570456896 run_lib.py:133] step: 716800, training_loss: 3.01881e-02
I0211 11:01:08.008575 22542570456896 run_lib.py:146] step: 716800, eval_loss: 3.19126e-02
I0211 11:01:25.457934 22542570456896 run_lib.py:133] step: 716850, training_loss: 2.29947e-02
I0211 11:01:43.098678 22542570456896 run_lib.py:133] step: 716900, training_loss: 2.12057e-02
I0211 11:01:43.255493 22542570456896 run_lib.py:146] step: 716900, eval_loss: 2.83030e-02
I0211 11:02:00.681033 22542570456896 run_lib.py:133] step: 716950, training_loss: 2.72676e-02
I0211 11:02:18.279502 22542570456896 run_lib.py:133] step: 717000, training_loss: 2.95763e-02
I0211 11:02:18.435462 22542570456896 run_lib.py:146] step: 717000, eval_loss: 2.55745e-02
I0211 11:02:35.865797 22542570456896 run_lib.py:133] step: 717050, training_loss: 2.42172e-02
I0211 11:02:53.292348 22542570456896 run_lib.py:133] step: 717100, training_loss: 2.88116e-02
I0211 11:02:53.446914 22542570456896 run_lib.py:146] step: 717100, eval_loss: 3.45588e-02
I0211 11:03:11.106791 22542570456896 run_lib.py:133] step: 717150, training_loss: 2.19323e-02
I0211 11:03:28.517704 22542570456896 run_lib.py:133] step: 717200, training_loss: 2.98574e-02
I0211 11:03:28.675325 22542570456896 run_lib.py:146] step: 717200, eval_loss: 3.83349e-02
I0211 11:03:46.083160 22542570456896 run_lib.py:133] step: 717250, training_loss: 2.79980e-02
I0211 11:04:03.644597 22542570456896 run_lib.py:133] step: 717300, training_loss: 2.37818e-02
I0211 11:04:03.803596 22542570456896 run_lib.py:146] step: 717300, eval_loss: 2.26333e-02
I0211 11:04:21.210480 22542570456896 run_lib.py:133] step: 717350, training_loss: 3.02630e-02
I0211 11:04:38.656777 22542570456896 run_lib.py:133] step: 717400, training_loss: 2.14146e-02
I0211 11:04:38.968980 22542570456896 run_lib.py:146] step: 717400, eval_loss: 2.45215e-02
I0211 11:04:56.421254 22542570456896 run_lib.py:133] step: 717450, training_loss: 2.16528e-02
I0211 11:05:13.884289 22542570456896 run_lib.py:133] step: 717500, training_loss: 2.35183e-02
I0211 11:05:14.048415 22542570456896 run_lib.py:146] step: 717500, eval_loss: 3.74561e-02
I0211 11:05:31.486541 22542570456896 run_lib.py:133] step: 717550, training_loss: 2.24287e-02
I0211 11:05:48.903132 22542570456896 run_lib.py:133] step: 717600, training_loss: 2.22926e-02
I0211 11:05:49.057005 22542570456896 run_lib.py:146] step: 717600, eval_loss: 2.80839e-02
I0211 11:06:06.608453 22542570456896 run_lib.py:133] step: 717650, training_loss: 2.85452e-02
I0211 11:06:24.126798 22542570456896 run_lib.py:133] step: 717700, training_loss: 2.73743e-02
I0211 11:06:24.317351 22542570456896 run_lib.py:146] step: 717700, eval_loss: 3.35480e-02
I0211 11:06:41.775067 22542570456896 run_lib.py:133] step: 717750, training_loss: 2.80904e-02
I0211 11:06:59.210401 22542570456896 run_lib.py:133] step: 717800, training_loss: 2.40050e-02
I0211 11:06:59.367618 22542570456896 run_lib.py:146] step: 717800, eval_loss: 2.89224e-02
I0211 11:07:16.976418 22542570456896 run_lib.py:133] step: 717850, training_loss: 2.96343e-02
I0211 11:07:34.471091 22542570456896 run_lib.py:133] step: 717900, training_loss: 2.50130e-02
I0211 11:07:34.626507 22542570456896 run_lib.py:146] step: 717900, eval_loss: 2.84091e-02
I0211 11:07:52.079182 22542570456896 run_lib.py:133] step: 717950, training_loss: 2.42606e-02
I0211 11:08:09.504936 22542570456896 run_lib.py:133] step: 718000, training_loss: 3.32473e-02
I0211 11:08:09.667286 22542570456896 run_lib.py:146] step: 718000, eval_loss: 3.08321e-02
I0211 11:08:27.341091 22542570456896 run_lib.py:133] step: 718050, training_loss: 3.12812e-02
I0211 11:08:44.779733 22542570456896 run_lib.py:133] step: 718100, training_loss: 2.56198e-02
I0211 11:08:44.931945 22542570456896 run_lib.py:146] step: 718100, eval_loss: 3.20288e-02
I0211 11:09:02.484750 22542570456896 run_lib.py:133] step: 718150, training_loss: 3.23531e-02
I0211 11:09:19.925534 22542570456896 run_lib.py:133] step: 718200, training_loss: 2.96705e-02
I0211 11:09:20.100270 22542570456896 run_lib.py:146] step: 718200, eval_loss: 2.70327e-02
I0211 11:09:37.679540 22542570456896 run_lib.py:133] step: 718250, training_loss: 2.89083e-02
I0211 11:09:55.094115 22542570456896 run_lib.py:133] step: 718300, training_loss: 2.59572e-02
I0211 11:09:55.249564 22542570456896 run_lib.py:146] step: 718300, eval_loss: 2.46716e-02
I0211 11:10:12.688575 22542570456896 run_lib.py:133] step: 718350, training_loss: 2.73329e-02
I0211 11:10:30.261735 22542570456896 run_lib.py:133] step: 718400, training_loss: 3.18820e-02
I0211 11:10:30.422245 22542570456896 run_lib.py:146] step: 718400, eval_loss: 2.99227e-02
I0211 11:10:47.834151 22542570456896 run_lib.py:133] step: 718450, training_loss: 2.22963e-02
I0211 11:11:05.385691 22542570456896 run_lib.py:133] step: 718500, training_loss: 3.85971e-02
I0211 11:11:05.539655 22542570456896 run_lib.py:146] step: 718500, eval_loss: 2.73901e-02
I0211 11:11:23.029225 22542570456896 run_lib.py:133] step: 718550, training_loss: 2.94171e-02
I0211 11:11:40.473313 22542570456896 run_lib.py:133] step: 718600, training_loss: 2.46004e-02
I0211 11:11:40.629355 22542570456896 run_lib.py:146] step: 718600, eval_loss: 2.78337e-02
I0211 11:11:58.288737 22542570456896 run_lib.py:133] step: 718650, training_loss: 2.39749e-02
I0211 11:12:15.697701 22542570456896 run_lib.py:133] step: 718700, training_loss: 3.09437e-02
I0211 11:12:15.852613 22542570456896 run_lib.py:146] step: 718700, eval_loss: 2.90671e-02
I0211 11:12:33.281732 22542570456896 run_lib.py:133] step: 718750, training_loss: 2.27382e-02
I0211 11:12:50.746645 22542570456896 run_lib.py:133] step: 718800, training_loss: 3.15640e-02
I0211 11:12:50.899416 22542570456896 run_lib.py:146] step: 718800, eval_loss: 2.55455e-02
I0211 11:13:08.537896 22542570456896 run_lib.py:133] step: 718850, training_loss: 2.42330e-02
I0211 11:13:25.935276 22542570456896 run_lib.py:133] step: 718900, training_loss: 2.81431e-02
I0211 11:13:26.092403 22542570456896 run_lib.py:146] step: 718900, eval_loss: 2.91346e-02
I0211 11:13:43.594247 22542570456896 run_lib.py:133] step: 718950, training_loss: 2.35262e-02
I0211 11:14:01.072955 22542570456896 run_lib.py:133] step: 719000, training_loss: 3.17276e-02
I0211 11:14:01.225506 22542570456896 run_lib.py:146] step: 719000, eval_loss: 2.50608e-02
I0211 11:14:18.720583 22542570456896 run_lib.py:133] step: 719050, training_loss: 2.70214e-02
I0211 11:14:36.178517 22542570456896 run_lib.py:133] step: 719100, training_loss: 2.45567e-02
I0211 11:14:36.334306 22542570456896 run_lib.py:146] step: 719100, eval_loss: 2.95301e-02
I0211 11:14:53.973976 22542570456896 run_lib.py:133] step: 719150, training_loss: 2.21523e-02
I0211 11:15:11.446828 22542570456896 run_lib.py:133] step: 719200, training_loss: 3.37470e-02
I0211 11:15:11.622638 22542570456896 run_lib.py:146] step: 719200, eval_loss: 2.49440e-02
I0211 11:15:29.061628 22542570456896 run_lib.py:133] step: 719250, training_loss: 3.18586e-02
I0211 11:15:46.467933 22542570456896 run_lib.py:133] step: 719300, training_loss: 2.82214e-02
I0211 11:15:46.634710 22542570456896 run_lib.py:146] step: 719300, eval_loss: 2.79016e-02
I0211 11:16:04.199733 22542570456896 run_lib.py:133] step: 719350, training_loss: 2.60911e-02
I0211 11:16:21.662107 22542570456896 run_lib.py:133] step: 719400, training_loss: 3.23849e-02
I0211 11:16:21.819574 22542570456896 run_lib.py:146] step: 719400, eval_loss: 3.02402e-02
I0211 11:16:39.439000 22542570456896 run_lib.py:133] step: 719450, training_loss: 3.21264e-02
I0211 11:16:56.873524 22542570456896 run_lib.py:133] step: 719500, training_loss: 2.63198e-02
I0211 11:16:57.026432 22542570456896 run_lib.py:146] step: 719500, eval_loss: 2.55085e-02
I0211 11:17:14.575103 22542570456896 run_lib.py:133] step: 719550, training_loss: 2.88613e-02
I0211 11:17:31.946241 22542570456896 run_lib.py:133] step: 719600, training_loss: 3.00415e-02
I0211 11:17:32.126976 22542570456896 run_lib.py:146] step: 719600, eval_loss: 3.09066e-02
I0211 11:17:49.778512 22542570456896 run_lib.py:133] step: 719650, training_loss: 3.87883e-02
I0211 11:18:07.258134 22542570456896 run_lib.py:133] step: 719700, training_loss: 3.39458e-02
I0211 11:18:07.416870 22542570456896 run_lib.py:146] step: 719700, eval_loss: 3.10487e-02
I0211 11:18:24.815943 22542570456896 run_lib.py:133] step: 719750, training_loss: 2.47844e-02
I0211 11:18:42.363195 22542570456896 run_lib.py:133] step: 719800, training_loss: 3.50404e-02
I0211 11:18:42.519096 22542570456896 run_lib.py:146] step: 719800, eval_loss: 3.14162e-02
I0211 11:18:59.911505 22542570456896 run_lib.py:133] step: 719850, training_loss: 3.40710e-02
I0211 11:19:17.342346 22542570456896 run_lib.py:133] step: 719900, training_loss: 2.65586e-02
I0211 11:19:17.505758 22542570456896 run_lib.py:146] step: 719900, eval_loss: 3.79044e-02
I0211 11:19:35.114489 22542570456896 run_lib.py:133] step: 719950, training_loss: 2.99856e-02
I0211 11:19:52.673913 22542570456896 run_lib.py:133] step: 720000, training_loss: 2.21231e-02
I0211 11:19:53.613200 22542570456896 run_lib.py:146] step: 720000, eval_loss: 2.88072e-02
I0211 11:20:13.639137 22542570456896 run_lib.py:133] step: 720050, training_loss: 3.17362e-02
I0211 11:20:31.123368 22542570456896 run_lib.py:133] step: 720100, training_loss: 2.49718e-02
I0211 11:20:31.279224 22542570456896 run_lib.py:146] step: 720100, eval_loss: 2.62929e-02
I0211 11:20:48.647803 22542570456896 run_lib.py:133] step: 720150, training_loss: 3.24692e-02
I0211 11:21:06.096942 22542570456896 run_lib.py:133] step: 720200, training_loss: 2.28746e-02
I0211 11:21:06.256424 22542570456896 run_lib.py:146] step: 720200, eval_loss: 3.21869e-02
I0211 11:21:23.835322 22542570456896 run_lib.py:133] step: 720250, training_loss: 2.94245e-02
I0211 11:21:41.274163 22542570456896 run_lib.py:133] step: 720300, training_loss: 2.62717e-02
I0211 11:21:41.430369 22542570456896 run_lib.py:146] step: 720300, eval_loss: 2.09902e-02
I0211 11:21:58.845883 22542570456896 run_lib.py:133] step: 720350, training_loss: 3.36445e-02
I0211 11:22:16.223094 22542570456896 run_lib.py:133] step: 720400, training_loss: 2.57255e-02
I0211 11:22:16.377321 22542570456896 run_lib.py:146] step: 720400, eval_loss: 2.50347e-02
I0211 11:22:33.971912 22542570456896 run_lib.py:133] step: 720450, training_loss: 2.77750e-02
I0211 11:22:51.444869 22542570456896 run_lib.py:133] step: 720500, training_loss: 2.63118e-02
I0211 11:22:51.598656 22542570456896 run_lib.py:146] step: 720500, eval_loss: 3.15600e-02
I0211 11:23:09.218532 22542570456896 run_lib.py:133] step: 720550, training_loss: 2.57103e-02
I0211 11:23:26.633065 22542570456896 run_lib.py:133] step: 720600, training_loss: 3.24565e-02
I0211 11:23:26.789480 22542570456896 run_lib.py:146] step: 720600, eval_loss: 3.29045e-02
I0211 11:23:44.301867 22542570456896 run_lib.py:133] step: 720650, training_loss: 2.06073e-02
I0211 11:24:01.728847 22542570456896 run_lib.py:133] step: 720700, training_loss: 2.50981e-02
I0211 11:24:01.913230 22542570456896 run_lib.py:146] step: 720700, eval_loss: 2.96429e-02
I0211 11:24:19.438507 22542570456896 run_lib.py:133] step: 720750, training_loss: 2.72943e-02
I0211 11:24:37.076439 22542570456896 run_lib.py:133] step: 720800, training_loss: 2.21447e-02
I0211 11:24:37.232475 22542570456896 run_lib.py:146] step: 720800, eval_loss: 2.62891e-02
I0211 11:24:54.646030 22542570456896 run_lib.py:133] step: 720850, training_loss: 2.95480e-02
I0211 11:25:12.232723 22542570456896 run_lib.py:133] step: 720900, training_loss: 2.96534e-02
I0211 11:25:12.386350 22542570456896 run_lib.py:146] step: 720900, eval_loss: 2.47772e-02
I0211 11:25:29.789260 22542570456896 run_lib.py:133] step: 720950, training_loss: 2.82351e-02
I0211 11:25:47.239952 22542570456896 run_lib.py:133] step: 721000, training_loss: 2.68714e-02
I0211 11:25:47.397898 22542570456896 run_lib.py:146] step: 721000, eval_loss: 3.12350e-02
I0211 11:26:05.046038 22542570456896 run_lib.py:133] step: 721050, training_loss: 2.92759e-02
I0211 11:26:22.473637 22542570456896 run_lib.py:133] step: 721100, training_loss: 2.81637e-02
I0211 11:26:22.632294 22542570456896 run_lib.py:146] step: 721100, eval_loss: 3.06036e-02
I0211 11:26:39.997704 22542570456896 run_lib.py:133] step: 721150, training_loss: 3.53722e-02
I0211 11:26:57.533247 22542570456896 run_lib.py:133] step: 721200, training_loss: 2.96506e-02
I0211 11:26:57.688527 22542570456896 run_lib.py:146] step: 721200, eval_loss: 2.80185e-02
I0211 11:27:15.123394 22542570456896 run_lib.py:133] step: 721250, training_loss: 3.04101e-02
I0211 11:27:32.587137 22542570456896 run_lib.py:133] step: 721300, training_loss: 3.62111e-02
I0211 11:27:32.744134 22542570456896 run_lib.py:146] step: 721300, eval_loss: 2.44319e-02
I0211 11:27:50.257099 22542570456896 run_lib.py:133] step: 721350, training_loss: 2.58343e-02
I0211 11:28:07.705376 22542570456896 run_lib.py:133] step: 721400, training_loss: 2.44568e-02
I0211 11:28:07.865133 22542570456896 run_lib.py:146] step: 721400, eval_loss: 2.61698e-02
I0211 11:28:25.298091 22542570456896 run_lib.py:133] step: 721450, training_loss: 2.68595e-02
I0211 11:28:42.720726 22542570456896 run_lib.py:133] step: 721500, training_loss: 3.22239e-02
I0211 11:28:42.871607 22542570456896 run_lib.py:146] step: 721500, eval_loss: 2.41311e-02
I0211 11:29:00.480973 22542570456896 run_lib.py:133] step: 721550, training_loss: 2.49981e-02
I0211 11:29:17.977417 22542570456896 run_lib.py:133] step: 721600, training_loss: 2.46052e-02
I0211 11:29:18.160368 22542570456896 run_lib.py:146] step: 721600, eval_loss: 3.14903e-02
I0211 11:29:35.644286 22542570456896 run_lib.py:133] step: 721650, training_loss: 3.20959e-02
I0211 11:29:53.012357 22542570456896 run_lib.py:133] step: 721700, training_loss: 2.31961e-02
I0211 11:29:53.167469 22542570456896 run_lib.py:146] step: 721700, eval_loss: 3.17054e-02
I0211 11:30:10.769371 22542570456896 run_lib.py:133] step: 721750, training_loss: 3.53619e-02
I0211 11:30:28.185310 22542570456896 run_lib.py:133] step: 721800, training_loss: 2.71640e-02
I0211 11:30:28.348407 22542570456896 run_lib.py:146] step: 721800, eval_loss: 3.07529e-02
I0211 11:30:46.021934 22542570456896 run_lib.py:133] step: 721850, training_loss: 2.48282e-02
I0211 11:31:03.449498 22542570456896 run_lib.py:133] step: 721900, training_loss: 3.01357e-02
I0211 11:31:03.605987 22542570456896 run_lib.py:146] step: 721900, eval_loss: 2.77590e-02
I0211 11:31:21.204046 22542570456896 run_lib.py:133] step: 721950, training_loss: 3.03941e-02
I0211 11:31:38.647805 22542570456896 run_lib.py:133] step: 722000, training_loss: 2.49109e-02
I0211 11:31:38.809302 22542570456896 run_lib.py:146] step: 722000, eval_loss: 2.87885e-02
I0211 11:31:56.366261 22542570456896 run_lib.py:133] step: 722050, training_loss: 2.90437e-02
I0211 11:32:13.754158 22542570456896 run_lib.py:133] step: 722100, training_loss: 2.96846e-02
I0211 11:32:13.931431 22542570456896 run_lib.py:146] step: 722100, eval_loss: 3.51000e-02
I0211 11:32:31.421433 22542570456896 run_lib.py:133] step: 722150, training_loss: 2.42991e-02
I0211 11:32:49.018944 22542570456896 run_lib.py:133] step: 722200, training_loss: 2.85575e-02
I0211 11:32:49.180604 22542570456896 run_lib.py:146] step: 722200, eval_loss: 2.81735e-02
I0211 11:33:06.634575 22542570456896 run_lib.py:133] step: 722250, training_loss: 2.62719e-02
I0211 11:33:24.051928 22542570456896 run_lib.py:133] step: 722300, training_loss: 3.05493e-02
I0211 11:33:24.222215 22542570456896 run_lib.py:146] step: 722300, eval_loss: 2.83869e-02
I0211 11:33:41.747353 22542570456896 run_lib.py:133] step: 722350, training_loss: 2.65422e-02
I0211 11:33:59.190711 22542570456896 run_lib.py:133] step: 722400, training_loss: 2.79174e-02
I0211 11:33:59.341993 22542570456896 run_lib.py:146] step: 722400, eval_loss: 2.39742e-02
I0211 11:34:16.948331 22542570456896 run_lib.py:133] step: 722450, training_loss: 2.91764e-02
I0211 11:34:34.329576 22542570456896 run_lib.py:133] step: 722500, training_loss: 2.73541e-02
I0211 11:34:34.484392 22542570456896 run_lib.py:146] step: 722500, eval_loss: 3.56919e-02
I0211 11:34:51.848451 22542570456896 run_lib.py:133] step: 722550, training_loss: 3.53166e-02
I0211 11:35:09.428830 22542570456896 run_lib.py:133] step: 722600, training_loss: 2.45965e-02
I0211 11:35:09.595738 22542570456896 run_lib.py:146] step: 722600, eval_loss: 2.97093e-02
I0211 11:35:27.030614 22542570456896 run_lib.py:133] step: 722650, training_loss: 2.73063e-02
I0211 11:35:44.522877 22542570456896 run_lib.py:133] step: 722700, training_loss: 2.67580e-02
I0211 11:35:44.681633 22542570456896 run_lib.py:146] step: 722700, eval_loss: 3.14080e-02
I0211 11:36:02.137088 22542570456896 run_lib.py:133] step: 722750, training_loss: 2.37019e-02
I0211 11:36:19.736632 22542570456896 run_lib.py:133] step: 722800, training_loss: 2.63853e-02
I0211 11:36:19.890240 22542570456896 run_lib.py:146] step: 722800, eval_loss: 2.69375e-02
I0211 11:36:37.322004 22542570456896 run_lib.py:133] step: 722850, training_loss: 2.57965e-02
I0211 11:36:54.811789 22542570456896 run_lib.py:133] step: 722900, training_loss: 3.07690e-02
I0211 11:36:54.960704 22542570456896 run_lib.py:146] step: 722900, eval_loss: 2.87073e-02
I0211 11:37:12.343176 22542570456896 run_lib.py:133] step: 722950, training_loss: 2.67664e-02
I0211 11:37:29.788142 22542570456896 run_lib.py:133] step: 723000, training_loss: 2.74445e-02
I0211 11:37:29.965293 22542570456896 run_lib.py:146] step: 723000, eval_loss: 2.70209e-02
I0211 11:37:47.556784 22542570456896 run_lib.py:133] step: 723050, training_loss: 2.78576e-02
I0211 11:38:05.015898 22542570456896 run_lib.py:133] step: 723100, training_loss: 3.32576e-02
I0211 11:38:05.170477 22542570456896 run_lib.py:146] step: 723100, eval_loss: 2.25129e-02
I0211 11:38:22.588897 22542570456896 run_lib.py:133] step: 723150, training_loss: 2.91843e-02
I0211 11:38:39.999309 22542570456896 run_lib.py:133] step: 723200, training_loss: 2.83389e-02
I0211 11:38:40.159435 22542570456896 run_lib.py:146] step: 723200, eval_loss: 3.14221e-02
I0211 11:38:57.650171 22542570456896 run_lib.py:133] step: 723250, training_loss: 2.60820e-02
I0211 11:39:15.101951 22542570456896 run_lib.py:133] step: 723300, training_loss: 2.48037e-02
I0211 11:39:15.255120 22542570456896 run_lib.py:146] step: 723300, eval_loss: 2.12008e-02
I0211 11:39:32.860384 22542570456896 run_lib.py:133] step: 723350, training_loss: 2.74395e-02
I0211 11:39:50.251467 22542570456896 run_lib.py:133] step: 723400, training_loss: 2.72653e-02
I0211 11:39:50.405403 22542570456896 run_lib.py:146] step: 723400, eval_loss: 3.17848e-02
I0211 11:40:07.902090 22542570456896 run_lib.py:133] step: 723450, training_loss: 2.52257e-02
I0211 11:40:25.294865 22542570456896 run_lib.py:133] step: 723500, training_loss: 3.16477e-02
I0211 11:40:25.460134 22542570456896 run_lib.py:146] step: 723500, eval_loss: 2.63892e-02
I0211 11:40:42.871362 22542570456896 run_lib.py:133] step: 723550, training_loss: 2.75741e-02
I0211 11:41:00.508776 22542570456896 run_lib.py:133] step: 723600, training_loss: 2.40592e-02
I0211 11:41:00.716475 22542570456896 run_lib.py:146] step: 723600, eval_loss: 2.57927e-02
I0211 11:41:18.134128 22542570456896 run_lib.py:133] step: 723650, training_loss: 2.19875e-02
I0211 11:41:35.690699 22542570456896 run_lib.py:133] step: 723700, training_loss: 3.02008e-02
I0211 11:41:35.846055 22542570456896 run_lib.py:146] step: 723700, eval_loss: 2.94332e-02
I0211 11:41:53.270734 22542570456896 run_lib.py:133] step: 723750, training_loss: 2.86583e-02
I0211 11:42:10.697076 22542570456896 run_lib.py:133] step: 723800, training_loss: 2.47302e-02
I0211 11:42:10.857385 22542570456896 run_lib.py:146] step: 723800, eval_loss: 3.49691e-02
I0211 11:42:28.469886 22542570456896 run_lib.py:133] step: 723850, training_loss: 2.58042e-02
I0211 11:42:45.886358 22542570456896 run_lib.py:133] step: 723900, training_loss: 3.23985e-02
I0211 11:42:46.130507 22542570456896 run_lib.py:146] step: 723900, eval_loss: 2.12154e-02
I0211 11:43:03.524889 22542570456896 run_lib.py:133] step: 723950, training_loss: 2.02600e-02
I0211 11:43:21.115087 22542570456896 run_lib.py:133] step: 724000, training_loss: 2.78984e-02
I0211 11:43:21.272522 22542570456896 run_lib.py:146] step: 724000, eval_loss: 2.57503e-02
I0211 11:43:38.651314 22542570456896 run_lib.py:133] step: 724050, training_loss: 2.49908e-02
I0211 11:43:56.040208 22542570456896 run_lib.py:133] step: 724100, training_loss: 2.31455e-02
I0211 11:43:56.345182 22542570456896 run_lib.py:146] step: 724100, eval_loss: 2.84051e-02
I0211 11:44:13.792067 22542570456896 run_lib.py:133] step: 724150, training_loss: 2.43779e-02
I0211 11:44:31.269472 22542570456896 run_lib.py:133] step: 724200, training_loss: 2.63680e-02
I0211 11:44:31.431620 22542570456896 run_lib.py:146] step: 724200, eval_loss: 2.90759e-02
I0211 11:44:48.901463 22542570456896 run_lib.py:133] step: 724250, training_loss: 2.42600e-02
I0211 11:45:06.281376 22542570456896 run_lib.py:133] step: 724300, training_loss: 2.72837e-02
I0211 11:45:06.440610 22542570456896 run_lib.py:146] step: 724300, eval_loss: 2.66640e-02
I0211 11:45:23.974596 22542570456896 run_lib.py:133] step: 724350, training_loss: 2.37190e-02
I0211 11:45:41.460102 22542570456896 run_lib.py:133] step: 724400, training_loss: 2.35721e-02
I0211 11:45:41.639138 22542570456896 run_lib.py:146] step: 724400, eval_loss: 3.54511e-02
I0211 11:45:59.084205 22542570456896 run_lib.py:133] step: 724450, training_loss: 2.61322e-02
I0211 11:46:16.503218 22542570456896 run_lib.py:133] step: 724500, training_loss: 2.45151e-02
I0211 11:46:16.661358 22542570456896 run_lib.py:146] step: 724500, eval_loss: 2.86300e-02
I0211 11:46:34.220659 22542570456896 run_lib.py:133] step: 724550, training_loss: 2.63546e-02
I0211 11:46:51.685098 22542570456896 run_lib.py:133] step: 724600, training_loss: 2.70298e-02
I0211 11:46:51.840045 22542570456896 run_lib.py:146] step: 724600, eval_loss: 2.85731e-02
I0211 11:47:09.278133 22542570456896 run_lib.py:133] step: 724650, training_loss: 2.86036e-02
I0211 11:47:26.776264 22542570456896 run_lib.py:133] step: 724700, training_loss: 2.97629e-02
I0211 11:47:26.931033 22542570456896 run_lib.py:146] step: 724700, eval_loss: 3.09963e-02
I0211 11:47:44.556057 22542570456896 run_lib.py:133] step: 724750, training_loss: 2.79307e-02
I0211 11:48:02.011533 22542570456896 run_lib.py:133] step: 724800, training_loss: 2.66925e-02
I0211 11:48:02.162263 22542570456896 run_lib.py:146] step: 724800, eval_loss: 2.83376e-02
I0211 11:48:19.734189 22542570456896 run_lib.py:133] step: 724850, training_loss: 2.48983e-02
I0211 11:48:37.155865 22542570456896 run_lib.py:133] step: 724900, training_loss: 2.47668e-02
I0211 11:48:37.313380 22542570456896 run_lib.py:146] step: 724900, eval_loss: 3.13204e-02
I0211 11:48:54.884756 22542570456896 run_lib.py:133] step: 724950, training_loss: 2.01878e-02
I0211 11:49:12.321536 22542570456896 run_lib.py:133] step: 725000, training_loss: 2.38563e-02
I0211 11:49:12.480002 22542570456896 run_lib.py:146] step: 725000, eval_loss: 2.78285e-02
I0211 11:49:29.850466 22542570456896 run_lib.py:133] step: 725050, training_loss: 3.02757e-02
I0211 11:49:47.450085 22542570456896 run_lib.py:133] step: 725100, training_loss: 3.17730e-02
I0211 11:49:47.605522 22542570456896 run_lib.py:146] step: 725100, eval_loss: 2.81793e-02
I0211 11:50:05.074560 22542570456896 run_lib.py:133] step: 725150, training_loss: 2.33596e-02
I0211 11:50:22.592577 22542570456896 run_lib.py:133] step: 725200, training_loss: 2.88686e-02
I0211 11:50:22.743427 22542570456896 run_lib.py:146] step: 725200, eval_loss: 2.64842e-02
I0211 11:50:40.243714 22542570456896 run_lib.py:133] step: 725250, training_loss: 2.47718e-02
I0211 11:50:57.668426 22542570456896 run_lib.py:133] step: 725300, training_loss: 2.59330e-02
I0211 11:50:57.818502 22542570456896 run_lib.py:146] step: 725300, eval_loss: 2.98075e-02
I0211 11:51:15.410727 22542570456896 run_lib.py:133] step: 725350, training_loss: 3.51106e-02
I0211 11:51:32.842273 22542570456896 run_lib.py:133] step: 725400, training_loss: 2.61828e-02
I0211 11:51:33.000572 22542570456896 run_lib.py:146] step: 725400, eval_loss: 3.39265e-02
I0211 11:51:50.365910 22542570456896 run_lib.py:133] step: 725450, training_loss: 2.88749e-02
I0211 11:52:07.717848 22542570456896 run_lib.py:133] step: 725500, training_loss: 3.01799e-02
I0211 11:52:07.905724 22542570456896 run_lib.py:146] step: 725500, eval_loss: 3.04579e-02
I0211 11:52:25.487277 22542570456896 run_lib.py:133] step: 725550, training_loss: 3.02587e-02
I0211 11:52:42.906865 22542570456896 run_lib.py:133] step: 725600, training_loss: 3.16861e-02
I0211 11:52:43.063701 22542570456896 run_lib.py:146] step: 725600, eval_loss: 3.34961e-02
I0211 11:53:00.603011 22542570456896 run_lib.py:133] step: 725650, training_loss: 2.92924e-02
I0211 11:53:17.995656 22542570456896 run_lib.py:133] step: 725700, training_loss: 2.54011e-02
I0211 11:53:18.146446 22542570456896 run_lib.py:146] step: 725700, eval_loss: 2.72465e-02
I0211 11:53:35.550994 22542570456896 run_lib.py:133] step: 725750, training_loss: 2.51644e-02
I0211 11:53:52.999909 22542570456896 run_lib.py:133] step: 725800, training_loss: 2.94416e-02
I0211 11:53:53.171171 22542570456896 run_lib.py:146] step: 725800, eval_loss: 2.69499e-02
I0211 11:54:10.783199 22542570456896 run_lib.py:133] step: 725850, training_loss: 2.32470e-02
I0211 11:54:28.258712 22542570456896 run_lib.py:133] step: 725900, training_loss: 2.66989e-02
I0211 11:54:28.417619 22542570456896 run_lib.py:146] step: 725900, eval_loss: 3.15204e-02
I0211 11:54:45.857343 22542570456896 run_lib.py:133] step: 725950, training_loss: 2.36606e-02
I0211 11:55:03.253155 22542570456896 run_lib.py:133] step: 726000, training_loss: 3.21235e-02
I0211 11:55:03.408377 22542570456896 run_lib.py:146] step: 726000, eval_loss: 2.42871e-02
I0211 11:55:20.952324 22542570456896 run_lib.py:133] step: 726050, training_loss: 3.31368e-02
I0211 11:55:38.416749 22542570456896 run_lib.py:133] step: 726100, training_loss: 2.70318e-02
I0211 11:55:38.571416 22542570456896 run_lib.py:146] step: 726100, eval_loss: 2.82606e-02
I0211 11:55:56.225219 22542570456896 run_lib.py:133] step: 726150, training_loss: 2.82564e-02
I0211 11:56:13.591564 22542570456896 run_lib.py:133] step: 726200, training_loss: 3.13736e-02
I0211 11:56:13.746225 22542570456896 run_lib.py:146] step: 726200, eval_loss: 4.07583e-02
I0211 11:56:31.272222 22542570456896 run_lib.py:133] step: 726250, training_loss: 2.88293e-02
I0211 11:56:48.727347 22542570456896 run_lib.py:133] step: 726300, training_loss: 2.34995e-02
I0211 11:56:48.893242 22542570456896 run_lib.py:146] step: 726300, eval_loss: 2.49338e-02
I0211 11:57:06.529771 22542570456896 run_lib.py:133] step: 726350, training_loss: 2.90831e-02
I0211 11:57:24.020440 22542570456896 run_lib.py:133] step: 726400, training_loss: 2.25643e-02
I0211 11:57:24.176727 22542570456896 run_lib.py:146] step: 726400, eval_loss: 2.99830e-02
I0211 11:57:41.549070 22542570456896 run_lib.py:133] step: 726450, training_loss: 3.07635e-02
I0211 11:57:59.081262 22542570456896 run_lib.py:133] step: 726500, training_loss: 3.12243e-02
I0211 11:57:59.236544 22542570456896 run_lib.py:146] step: 726500, eval_loss: 2.82379e-02
I0211 11:58:16.694473 22542570456896 run_lib.py:133] step: 726550, training_loss: 2.73006e-02
I0211 11:58:34.120011 22542570456896 run_lib.py:133] step: 726600, training_loss: 3.28198e-02
I0211 11:58:34.271497 22542570456896 run_lib.py:146] step: 726600, eval_loss: 2.79062e-02
I0211 11:58:51.924750 22542570456896 run_lib.py:133] step: 726650, training_loss: 3.91256e-02
I0211 11:59:09.566071 22542570456896 run_lib.py:133] step: 726700, training_loss: 2.35834e-02
I0211 11:59:09.718049 22542570456896 run_lib.py:146] step: 726700, eval_loss: 2.89850e-02
I0211 11:59:27.130361 22542570456896 run_lib.py:133] step: 726750, training_loss: 2.65923e-02
I0211 11:59:44.551077 22542570456896 run_lib.py:133] step: 726800, training_loss: 3.27422e-02
I0211 11:59:44.714827 22542570456896 run_lib.py:146] step: 726800, eval_loss: 2.50824e-02
I0211 12:00:02.180517 22542570456896 run_lib.py:133] step: 726850, training_loss: 3.12411e-02
I0211 12:00:19.762631 22542570456896 run_lib.py:133] step: 726900, training_loss: 2.65861e-02
I0211 12:00:19.922775 22542570456896 run_lib.py:146] step: 726900, eval_loss: 2.72326e-02
I0211 12:00:37.411578 22542570456896 run_lib.py:133] step: 726950, training_loss: 3.02705e-02
I0211 12:00:54.819520 22542570456896 run_lib.py:133] step: 727000, training_loss: 2.31451e-02
I0211 12:00:54.975147 22542570456896 run_lib.py:146] step: 727000, eval_loss: 3.08890e-02
I0211 12:01:12.462365 22542570456896 run_lib.py:133] step: 727050, training_loss: 3.04995e-02
I0211 12:01:30.034277 22542570456896 run_lib.py:133] step: 727100, training_loss: 2.94698e-02
I0211 12:01:30.208061 22542570456896 run_lib.py:146] step: 727100, eval_loss: 3.21845e-02
I0211 12:01:47.611709 22542570456896 run_lib.py:133] step: 727150, training_loss: 2.58111e-02
I0211 12:02:05.119940 22542570456896 run_lib.py:133] step: 727200, training_loss: 2.41054e-02
I0211 12:02:05.288155 22542570456896 run_lib.py:146] step: 727200, eval_loss: 3.14980e-02
I0211 12:02:22.715394 22542570456896 run_lib.py:133] step: 727250, training_loss: 2.68732e-02
I0211 12:02:40.127984 22542570456896 run_lib.py:133] step: 727300, training_loss: 2.79560e-02
I0211 12:02:40.286727 22542570456896 run_lib.py:146] step: 727300, eval_loss: 3.49875e-02
I0211 12:02:57.851113 22542570456896 run_lib.py:133] step: 727350, training_loss: 2.91903e-02
I0211 12:03:15.278117 22542570456896 run_lib.py:133] step: 727400, training_loss: 1.96257e-02
I0211 12:03:15.432238 22542570456896 run_lib.py:146] step: 727400, eval_loss: 2.82261e-02
I0211 12:03:32.813786 22542570456896 run_lib.py:133] step: 727450, training_loss: 2.06624e-02
I0211 12:03:50.289835 22542570456896 run_lib.py:133] step: 727500, training_loss: 2.67070e-02
I0211 12:03:50.447655 22542570456896 run_lib.py:146] step: 727500, eval_loss: 2.74714e-02
I0211 12:04:08.015787 22542570456896 run_lib.py:133] step: 727550, training_loss: 2.41447e-02
I0211 12:04:25.424039 22542570456896 run_lib.py:133] step: 727600, training_loss: 2.40226e-02
I0211 12:04:25.576331 22542570456896 run_lib.py:146] step: 727600, eval_loss: 3.82002e-02
I0211 12:04:43.077044 22542570456896 run_lib.py:133] step: 727650, training_loss: 2.29840e-02
I0211 12:05:00.491195 22542570456896 run_lib.py:133] step: 727700, training_loss: 3.04622e-02
I0211 12:05:00.651834 22542570456896 run_lib.py:146] step: 727700, eval_loss: 3.21128e-02
I0211 12:05:18.245562 22542570456896 run_lib.py:133] step: 727750, training_loss: 2.41466e-02
I0211 12:05:35.690446 22542570456896 run_lib.py:133] step: 727800, training_loss: 2.59460e-02
I0211 12:05:35.848292 22542570456896 run_lib.py:146] step: 727800, eval_loss: 2.64426e-02
I0211 12:05:53.290668 22542570456896 run_lib.py:133] step: 727850, training_loss: 3.32420e-02
I0211 12:06:10.923369 22542570456896 run_lib.py:133] step: 727900, training_loss: 2.46775e-02
I0211 12:06:11.078507 22542570456896 run_lib.py:146] step: 727900, eval_loss: 2.77497e-02
I0211 12:06:28.527532 22542570456896 run_lib.py:133] step: 727950, training_loss: 2.40553e-02
I0211 12:06:46.080830 22542570456896 run_lib.py:133] step: 728000, training_loss: 3.30439e-02
I0211 12:06:46.236617 22542570456896 run_lib.py:146] step: 728000, eval_loss: 2.75946e-02
I0211 12:07:03.725231 22542570456896 run_lib.py:133] step: 728050, training_loss: 2.94334e-02
I0211 12:07:21.157913 22542570456896 run_lib.py:133] step: 728100, training_loss: 2.54539e-02
I0211 12:07:21.309224 22542570456896 run_lib.py:146] step: 728100, eval_loss: 3.49949e-02
I0211 12:07:38.891030 22542570456896 run_lib.py:133] step: 728150, training_loss: 2.45912e-02
I0211 12:07:56.296222 22542570456896 run_lib.py:133] step: 728200, training_loss: 2.62935e-02
I0211 12:07:56.452685 22542570456896 run_lib.py:146] step: 728200, eval_loss: 2.74551e-02
I0211 12:08:13.889972 22542570456896 run_lib.py:133] step: 728250, training_loss: 2.41002e-02
I0211 12:08:31.525735 22542570456896 run_lib.py:133] step: 728300, training_loss: 2.74554e-02
I0211 12:08:31.684394 22542570456896 run_lib.py:146] step: 728300, eval_loss: 3.00865e-02
I0211 12:08:49.034446 22542570456896 run_lib.py:133] step: 728350, training_loss: 2.68384e-02
I0211 12:09:06.312067 22542570456896 run_lib.py:133] step: 728400, training_loss: 2.90756e-02
I0211 12:09:06.465908 22542570456896 run_lib.py:146] step: 728400, eval_loss: 2.48801e-02
I0211 12:09:23.833037 22542570456896 run_lib.py:133] step: 728450, training_loss: 3.59645e-02
I0211 12:09:41.118978 22542570456896 run_lib.py:133] step: 728500, training_loss: 2.50792e-02
I0211 12:09:41.275236 22542570456896 run_lib.py:146] step: 728500, eval_loss: 3.75492e-02
I0211 12:09:58.668078 22542570456896 run_lib.py:133] step: 728550, training_loss: 3.17560e-02
I0211 12:10:16.127331 22542570456896 run_lib.py:133] step: 728600, training_loss: 2.08410e-02
I0211 12:10:16.281554 22542570456896 run_lib.py:146] step: 728600, eval_loss: 2.76550e-02
I0211 12:10:33.885420 22542570456896 run_lib.py:133] step: 728650, training_loss: 3.11218e-02
I0211 12:10:51.412685 22542570456896 run_lib.py:133] step: 728700, training_loss: 2.66802e-02
I0211 12:10:51.579427 22542570456896 run_lib.py:146] step: 728700, eval_loss: 3.12037e-02
I0211 12:11:09.046441 22542570456896 run_lib.py:133] step: 728750, training_loss: 3.84743e-02
I0211 12:11:26.490464 22542570456896 run_lib.py:133] step: 728800, training_loss: 2.78047e-02
I0211 12:11:26.667430 22542570456896 run_lib.py:146] step: 728800, eval_loss: 2.63350e-02
I0211 12:11:44.282561 22542570456896 run_lib.py:133] step: 728850, training_loss: 3.38837e-02
I0211 12:12:01.742971 22542570456896 run_lib.py:133] step: 728900, training_loss: 2.63266e-02
I0211 12:12:01.907495 22542570456896 run_lib.py:146] step: 728900, eval_loss: 2.79322e-02
I0211 12:12:19.519385 22542570456896 run_lib.py:133] step: 728950, training_loss: 3.28527e-02
I0211 12:12:36.922994 22542570456896 run_lib.py:133] step: 729000, training_loss: 3.30590e-02
I0211 12:12:37.074090 22542570456896 run_lib.py:146] step: 729000, eval_loss: 2.84492e-02
I0211 12:12:54.683407 22542570456896 run_lib.py:133] step: 729050, training_loss: 3.05165e-02
I0211 12:13:12.131419 22542570456896 run_lib.py:133] step: 729100, training_loss: 2.66542e-02
I0211 12:13:12.305563 22542570456896 run_lib.py:146] step: 729100, eval_loss: 2.88489e-02
I0211 12:13:29.918465 22542570456896 run_lib.py:133] step: 729150, training_loss: 2.44311e-02
I0211 12:13:47.362787 22542570456896 run_lib.py:133] step: 729200, training_loss: 3.30591e-02
I0211 12:13:47.520338 22542570456896 run_lib.py:146] step: 729200, eval_loss: 3.25943e-02
I0211 12:14:04.943295 22542570456896 run_lib.py:133] step: 729250, training_loss: 2.99023e-02
I0211 12:14:22.495743 22542570456896 run_lib.py:133] step: 729300, training_loss: 2.62616e-02
I0211 12:14:22.653383 22542570456896 run_lib.py:146] step: 729300, eval_loss: 2.77495e-02
I0211 12:14:40.101646 22542570456896 run_lib.py:133] step: 729350, training_loss: 2.11605e-02
I0211 12:14:57.532395 22542570456896 run_lib.py:133] step: 729400, training_loss: 2.79941e-02
I0211 12:14:57.688523 22542570456896 run_lib.py:146] step: 729400, eval_loss: 3.21578e-02
I0211 12:15:15.314228 22542570456896 run_lib.py:133] step: 729450, training_loss: 2.84065e-02
I0211 12:15:32.726082 22542570456896 run_lib.py:133] step: 729500, training_loss: 2.69167e-02
I0211 12:15:32.885391 22542570456896 run_lib.py:146] step: 729500, eval_loss: 3.44648e-02
I0211 12:15:50.429198 22542570456896 run_lib.py:133] step: 729550, training_loss: 2.55612e-02
I0211 12:16:07.881455 22542570456896 run_lib.py:133] step: 729600, training_loss: 2.81807e-02
I0211 12:16:08.042377 22542570456896 run_lib.py:146] step: 729600, eval_loss: 2.74782e-02
I0211 12:16:25.496223 22542570456896 run_lib.py:133] step: 729650, training_loss: 2.70212e-02
I0211 12:16:43.157232 22542570456896 run_lib.py:133] step: 729700, training_loss: 2.41684e-02
I0211 12:16:43.315454 22542570456896 run_lib.py:146] step: 729700, eval_loss: 3.56415e-02
I0211 12:17:00.733806 22542570456896 run_lib.py:133] step: 729750, training_loss: 3.04580e-02
I0211 12:17:18.156787 22542570456896 run_lib.py:133] step: 729800, training_loss: 2.54654e-02
I0211 12:17:18.313311 22542570456896 run_lib.py:146] step: 729800, eval_loss: 2.78467e-02
I0211 12:17:35.738589 22542570456896 run_lib.py:133] step: 729850, training_loss: 3.19578e-02
I0211 12:17:53.304376 22542570456896 run_lib.py:133] step: 729900, training_loss: 2.82543e-02
I0211 12:17:53.462997 22542570456896 run_lib.py:146] step: 729900, eval_loss: 2.93316e-02
I0211 12:18:10.923084 22542570456896 run_lib.py:133] step: 729950, training_loss: 3.28696e-02
I0211 12:18:28.393323 22542570456896 run_lib.py:133] step: 730000, training_loss: 2.79826e-02
I0211 12:18:29.095478 22542570456896 run_lib.py:146] step: 730000, eval_loss: 2.43246e-02
I0211 12:18:49.160038 22542570456896 run_lib.py:133] step: 730050, training_loss: 2.77935e-02
I0211 12:19:06.552352 22542570456896 run_lib.py:133] step: 730100, training_loss: 3.03936e-02
I0211 12:19:06.708343 22542570456896 run_lib.py:146] step: 730100, eval_loss: 2.73632e-02
I0211 12:19:24.243740 22542570456896 run_lib.py:133] step: 730150, training_loss: 2.82134e-02
I0211 12:19:41.664097 22542570456896 run_lib.py:133] step: 730200, training_loss: 2.91464e-02
I0211 12:19:41.827905 22542570456896 run_lib.py:146] step: 730200, eval_loss: 2.50523e-02
I0211 12:19:59.348438 22542570456896 run_lib.py:133] step: 730250, training_loss: 2.39160e-02
I0211 12:20:16.823841 22542570456896 run_lib.py:133] step: 730300, training_loss: 2.97922e-02
I0211 12:20:16.979655 22542570456896 run_lib.py:146] step: 730300, eval_loss: 2.77695e-02
I0211 12:20:34.372179 22542570456896 run_lib.py:133] step: 730350, training_loss: 4.15654e-02
I0211 12:20:51.793741 22542570456896 run_lib.py:133] step: 730400, training_loss: 2.64563e-02
I0211 12:20:51.954053 22542570456896 run_lib.py:146] step: 730400, eval_loss: 2.37037e-02
I0211 12:21:09.548509 22542570456896 run_lib.py:133] step: 730450, training_loss: 2.77161e-02
I0211 12:21:27.011634 22542570456896 run_lib.py:133] step: 730500, training_loss: 2.29520e-02
I0211 12:21:27.166807 22542570456896 run_lib.py:146] step: 730500, eval_loss: 2.92467e-02
I0211 12:21:44.662351 22542570456896 run_lib.py:133] step: 730550, training_loss: 3.00245e-02
I0211 12:22:02.092162 22542570456896 run_lib.py:133] step: 730600, training_loss: 3.03098e-02
I0211 12:22:02.248687 22542570456896 run_lib.py:146] step: 730600, eval_loss: 2.31778e-02
I0211 12:22:19.836932 22542570456896 run_lib.py:133] step: 730650, training_loss: 2.63061e-02
I0211 12:22:37.246001 22542570456896 run_lib.py:133] step: 730700, training_loss: 2.72933e-02
I0211 12:22:37.402490 22542570456896 run_lib.py:146] step: 730700, eval_loss: 2.98718e-02
I0211 12:22:54.933040 22542570456896 run_lib.py:133] step: 730750, training_loss: 3.85267e-02
I0211 12:23:12.367764 22542570456896 run_lib.py:133] step: 730800, training_loss: 2.59437e-02
I0211 12:23:12.530033 22542570456896 run_lib.py:146] step: 730800, eval_loss: 3.26398e-02
I0211 12:23:30.156252 22542570456896 run_lib.py:133] step: 730850, training_loss: 1.85459e-02
I0211 12:23:47.593063 22542570456896 run_lib.py:133] step: 730900, training_loss: 2.74225e-02
I0211 12:23:47.748606 22542570456896 run_lib.py:146] step: 730900, eval_loss: 2.53170e-02
I0211 12:24:05.194729 22542570456896 run_lib.py:133] step: 730950, training_loss: 2.74506e-02
I0211 12:24:22.823991 22542570456896 run_lib.py:133] step: 731000, training_loss: 2.59929e-02
I0211 12:24:22.976324 22542570456896 run_lib.py:146] step: 731000, eval_loss: 3.21910e-02
I0211 12:24:40.391865 22542570456896 run_lib.py:133] step: 731050, training_loss: 2.81215e-02
I0211 12:24:57.970876 22542570456896 run_lib.py:133] step: 731100, training_loss: 2.93423e-02
I0211 12:24:58.139547 22542570456896 run_lib.py:146] step: 731100, eval_loss: 2.87003e-02
I0211 12:25:15.561496 22542570456896 run_lib.py:133] step: 731150, training_loss: 2.71175e-02
I0211 12:25:33.020478 22542570456896 run_lib.py:133] step: 731200, training_loss: 4.09909e-02
I0211 12:25:33.179326 22542570456896 run_lib.py:146] step: 731200, eval_loss: 2.73854e-02
I0211 12:25:50.811039 22542570456896 run_lib.py:133] step: 731250, training_loss: 2.65240e-02
I0211 12:26:08.223272 22542570456896 run_lib.py:133] step: 731300, training_loss: 3.21295e-02
I0211 12:26:08.382409 22542570456896 run_lib.py:146] step: 731300, eval_loss: 2.61161e-02
I0211 12:26:25.797144 22542570456896 run_lib.py:133] step: 731350, training_loss: 2.99357e-02
I0211 12:26:43.395812 22542570456896 run_lib.py:133] step: 731400, training_loss: 2.78411e-02
I0211 12:26:43.550537 22542570456896 run_lib.py:146] step: 731400, eval_loss: 3.03751e-02
I0211 12:27:00.973357 22542570456896 run_lib.py:133] step: 731450, training_loss: 2.19723e-02
I0211 12:27:18.461501 22542570456896 run_lib.py:133] step: 731500, training_loss: 2.35768e-02
I0211 12:27:18.799499 22542570456896 run_lib.py:146] step: 731500, eval_loss: 2.59152e-02
I0211 12:27:36.181340 22542570456896 run_lib.py:133] step: 731550, training_loss: 2.89807e-02
I0211 12:27:53.586817 22542570456896 run_lib.py:133] step: 731600, training_loss: 2.30668e-02
I0211 12:27:53.745239 22542570456896 run_lib.py:146] step: 731600, eval_loss: 3.14071e-02
I0211 12:28:11.129436 22542570456896 run_lib.py:133] step: 731650, training_loss: 2.95764e-02
I0211 12:28:28.589002 22542570456896 run_lib.py:133] step: 731700, training_loss: 3.04285e-02
I0211 12:28:28.748789 22542570456896 run_lib.py:146] step: 731700, eval_loss: 3.04856e-02
I0211 12:28:46.362453 22542570456896 run_lib.py:133] step: 731750, training_loss: 2.54025e-02
I0211 12:29:03.835512 22542570456896 run_lib.py:133] step: 731800, training_loss: 2.95808e-02
I0211 12:29:03.990058 22542570456896 run_lib.py:146] step: 731800, eval_loss: 2.39450e-02
I0211 12:29:21.409033 22542570456896 run_lib.py:133] step: 731850, training_loss: 2.60675e-02
I0211 12:29:38.840117 22542570456896 run_lib.py:133] step: 731900, training_loss: 2.66358e-02
I0211 12:29:38.994123 22542570456896 run_lib.py:146] step: 731900, eval_loss: 3.26364e-02
I0211 12:29:56.518705 22542570456896 run_lib.py:133] step: 731950, training_loss: 2.57595e-02
I0211 12:30:14.105303 22542570456896 run_lib.py:133] step: 732000, training_loss: 2.56850e-02
I0211 12:30:14.270534 22542570456896 run_lib.py:146] step: 732000, eval_loss: 3.40433e-02
I0211 12:30:31.690486 22542570456896 run_lib.py:133] step: 732050, training_loss: 2.69469e-02
I0211 12:30:49.124746 22542570456896 run_lib.py:133] step: 732100, training_loss: 2.85645e-02
I0211 12:30:49.282632 22542570456896 run_lib.py:146] step: 732100, eval_loss: 2.66782e-02
I0211 12:31:06.818486 22542570456896 run_lib.py:133] step: 732150, training_loss: 2.61995e-02
I0211 12:31:24.241463 22542570456896 run_lib.py:133] step: 732200, training_loss: 2.72117e-02
I0211 12:31:24.398352 22542570456896 run_lib.py:146] step: 732200, eval_loss: 3.10477e-02
I0211 12:31:41.947219 22542570456896 run_lib.py:133] step: 732250, training_loss: 2.88623e-02
I0211 12:31:59.390540 22542570456896 run_lib.py:133] step: 732300, training_loss: 3.23484e-02
I0211 12:31:59.543856 22542570456896 run_lib.py:146] step: 732300, eval_loss: 2.39874e-02
I0211 12:32:17.116367 22542570456896 run_lib.py:133] step: 732350, training_loss: 2.65429e-02
I0211 12:32:34.503931 22542570456896 run_lib.py:133] step: 732400, training_loss: 2.44018e-02
I0211 12:32:34.655091 22542570456896 run_lib.py:146] step: 732400, eval_loss: 2.97700e-02
I0211 12:32:52.088584 22542570456896 run_lib.py:133] step: 732450, training_loss: 2.48832e-02
I0211 12:33:09.623980 22542570456896 run_lib.py:133] step: 732500, training_loss: 3.30117e-02
I0211 12:33:09.782577 22542570456896 run_lib.py:146] step: 732500, eval_loss: 3.21760e-02
I0211 12:33:27.190585 22542570456896 run_lib.py:133] step: 732550, training_loss: 2.47904e-02
I0211 12:33:44.817571 22542570456896 run_lib.py:133] step: 732600, training_loss: 2.61543e-02
I0211 12:33:44.978318 22542570456896 run_lib.py:146] step: 732600, eval_loss: 2.54222e-02
I0211 12:34:02.375253 22542570456896 run_lib.py:133] step: 732650, training_loss: 2.11065e-02
I0211 12:34:19.739326 22542570456896 run_lib.py:133] step: 732700, training_loss: 2.91418e-02
I0211 12:34:19.895296 22542570456896 run_lib.py:146] step: 732700, eval_loss: 3.45095e-02
I0211 12:34:37.439251 22542570456896 run_lib.py:133] step: 732750, training_loss: 2.27967e-02
I0211 12:34:54.815922 22542570456896 run_lib.py:133] step: 732800, training_loss: 3.68109e-02
I0211 12:34:54.973139 22542570456896 run_lib.py:146] step: 732800, eval_loss: 2.56148e-02
I0211 12:35:12.391867 22542570456896 run_lib.py:133] step: 732850, training_loss: 2.95817e-02
I0211 12:35:29.835923 22542570456896 run_lib.py:133] step: 732900, training_loss: 2.99809e-02
I0211 12:35:29.990030 22542570456896 run_lib.py:146] step: 732900, eval_loss: 2.85490e-02
I0211 12:35:47.591485 22542570456896 run_lib.py:133] step: 732950, training_loss: 2.96050e-02
I0211 12:36:05.058485 22542570456896 run_lib.py:133] step: 733000, training_loss: 2.97951e-02
I0211 12:36:05.213375 22542570456896 run_lib.py:146] step: 733000, eval_loss: 2.56235e-02
I0211 12:36:22.627675 22542570456896 run_lib.py:133] step: 733050, training_loss: 2.47297e-02
I0211 12:36:40.014836 22542570456896 run_lib.py:133] step: 733100, training_loss: 2.77021e-02
I0211 12:36:40.192268 22542570456896 run_lib.py:146] step: 733100, eval_loss: 2.96793e-02
I0211 12:36:57.624651 22542570456896 run_lib.py:133] step: 733150, training_loss: 3.19825e-02
I0211 12:37:15.067327 22542570456896 run_lib.py:133] step: 733200, training_loss: 2.35813e-02
I0211 12:37:15.231688 22542570456896 run_lib.py:146] step: 733200, eval_loss: 2.66066e-02
I0211 12:37:32.851981 22542570456896 run_lib.py:133] step: 733250, training_loss: 2.75953e-02
I0211 12:37:50.311531 22542570456896 run_lib.py:133] step: 733300, training_loss: 2.76764e-02
I0211 12:37:50.466015 22542570456896 run_lib.py:146] step: 733300, eval_loss: 3.59719e-02
I0211 12:38:07.892698 22542570456896 run_lib.py:133] step: 733350, training_loss: 2.80590e-02
I0211 12:38:25.311502 22542570456896 run_lib.py:133] step: 733400, training_loss: 2.90578e-02
I0211 12:38:25.466706 22542570456896 run_lib.py:146] step: 733400, eval_loss: 2.46771e-02
I0211 12:38:43.137633 22542570456896 run_lib.py:133] step: 733450, training_loss: 2.38991e-02
I0211 12:39:00.549185 22542570456896 run_lib.py:133] step: 733500, training_loss: 2.69666e-02
I0211 12:39:00.707413 22542570456896 run_lib.py:146] step: 733500, eval_loss: 3.41440e-02
I0211 12:39:18.301212 22542570456896 run_lib.py:133] step: 733550, training_loss: 2.63705e-02
I0211 12:39:35.743664 22542570456896 run_lib.py:133] step: 733600, training_loss: 2.48843e-02
I0211 12:39:35.899409 22542570456896 run_lib.py:146] step: 733600, eval_loss: 3.04204e-02
I0211 12:39:53.468216 22542570456896 run_lib.py:133] step: 733650, training_loss: 2.81648e-02
I0211 12:40:10.919139 22542570456896 run_lib.py:133] step: 733700, training_loss: 2.62891e-02
I0211 12:40:11.075101 22542570456896 run_lib.py:146] step: 733700, eval_loss: 2.58926e-02
I0211 12:40:28.743754 22542570456896 run_lib.py:133] step: 733750, training_loss: 2.47215e-02
I0211 12:40:46.130167 22542570456896 run_lib.py:133] step: 733800, training_loss: 2.50715e-02
I0211 12:40:46.283004 22542570456896 run_lib.py:146] step: 733800, eval_loss: 3.35930e-02
I0211 12:41:03.659507 22542570456896 run_lib.py:133] step: 733850, training_loss: 2.29865e-02
I0211 12:41:21.206481 22542570456896 run_lib.py:133] step: 733900, training_loss: 2.90577e-02
I0211 12:41:21.359320 22542570456896 run_lib.py:146] step: 733900, eval_loss: 3.59763e-02
I0211 12:41:38.769268 22542570456896 run_lib.py:133] step: 733950, training_loss: 3.02279e-02
I0211 12:41:56.254524 22542570456896 run_lib.py:133] step: 734000, training_loss: 2.81768e-02
I0211 12:41:56.434233 22542570456896 run_lib.py:146] step: 734000, eval_loss: 2.80949e-02
I0211 12:42:14.055714 22542570456896 run_lib.py:133] step: 734050, training_loss: 2.26324e-02
I0211 12:42:31.620572 22542570456896 run_lib.py:133] step: 734100, training_loss: 2.55999e-02
I0211 12:42:31.776659 22542570456896 run_lib.py:146] step: 734100, eval_loss: 2.91372e-02
I0211 12:42:49.231956 22542570456896 run_lib.py:133] step: 734150, training_loss: 2.52650e-02
I0211 12:43:06.635869 22542570456896 run_lib.py:133] step: 734200, training_loss: 2.81108e-02
I0211 12:43:06.791480 22542570456896 run_lib.py:146] step: 734200, eval_loss: 3.20246e-02
I0211 12:43:24.199602 22542570456896 run_lib.py:133] step: 734250, training_loss: 2.69977e-02
I0211 12:43:41.789639 22542570456896 run_lib.py:133] step: 734300, training_loss: 2.20075e-02
I0211 12:43:41.941951 22542570456896 run_lib.py:146] step: 734300, eval_loss: 2.58901e-02
I0211 12:43:59.418176 22542570456896 run_lib.py:133] step: 734350, training_loss: 2.42563e-02
I0211 12:44:16.812426 22542570456896 run_lib.py:133] step: 734400, training_loss: 3.05352e-02
I0211 12:44:16.967265 22542570456896 run_lib.py:146] step: 734400, eval_loss: 3.55384e-02
I0211 12:44:34.349430 22542570456896 run_lib.py:133] step: 734450, training_loss: 2.63165e-02
I0211 12:44:51.919129 22542570456896 run_lib.py:133] step: 734500, training_loss: 2.69610e-02
I0211 12:44:52.077633 22542570456896 run_lib.py:146] step: 734500, eval_loss: 2.90501e-02
I0211 12:45:09.535193 22542570456896 run_lib.py:133] step: 734550, training_loss: 2.67488e-02
I0211 12:45:27.043706 22542570456896 run_lib.py:133] step: 734600, training_loss: 2.88249e-02
I0211 12:45:27.199599 22542570456896 run_lib.py:146] step: 734600, eval_loss: 2.77848e-02
I0211 12:45:44.575779 22542570456896 run_lib.py:133] step: 734650, training_loss: 2.33404e-02
I0211 12:46:01.955154 22542570456896 run_lib.py:133] step: 734700, training_loss: 3.00391e-02
I0211 12:46:02.110374 22542570456896 run_lib.py:146] step: 734700, eval_loss: 2.81439e-02
I0211 12:46:19.717715 22542570456896 run_lib.py:133] step: 734750, training_loss: 2.63862e-02
I0211 12:46:37.213692 22542570456896 run_lib.py:133] step: 734800, training_loss: 2.60656e-02
I0211 12:46:37.369630 22542570456896 run_lib.py:146] step: 734800, eval_loss: 2.72435e-02
I0211 12:46:54.834565 22542570456896 run_lib.py:133] step: 734850, training_loss: 2.78115e-02
I0211 12:47:12.218227 22542570456896 run_lib.py:133] step: 734900, training_loss: 3.00836e-02
I0211 12:47:12.373541 22542570456896 run_lib.py:146] step: 734900, eval_loss: 3.00304e-02
I0211 12:47:29.999600 22542570456896 run_lib.py:133] step: 734950, training_loss: 2.66947e-02
I0211 12:47:47.384650 22542570456896 run_lib.py:133] step: 735000, training_loss: 3.30984e-02
I0211 12:47:47.547581 22542570456896 run_lib.py:146] step: 735000, eval_loss: 3.04169e-02
I0211 12:48:05.085755 22542570456896 run_lib.py:133] step: 735050, training_loss: 3.27468e-02
I0211 12:48:22.483845 22542570456896 run_lib.py:133] step: 735100, training_loss: 2.24587e-02
I0211 12:48:22.661152 22542570456896 run_lib.py:146] step: 735100, eval_loss: 2.85101e-02
I0211 12:48:40.277878 22542570456896 run_lib.py:133] step: 735150, training_loss: 3.01071e-02
I0211 12:48:57.723100 22542570456896 run_lib.py:133] step: 735200, training_loss: 2.73118e-02
I0211 12:48:57.878065 22542570456896 run_lib.py:146] step: 735200, eval_loss: 2.83665e-02
I0211 12:49:15.301609 22542570456896 run_lib.py:133] step: 735250, training_loss: 2.79266e-02
I0211 12:49:32.834639 22542570456896 run_lib.py:133] step: 735300, training_loss: 2.28362e-02
I0211 12:49:32.990325 22542570456896 run_lib.py:146] step: 735300, eval_loss: 2.39952e-02
I0211 12:49:50.454791 22542570456896 run_lib.py:133] step: 735350, training_loss: 2.38767e-02
I0211 12:50:07.990875 22542570456896 run_lib.py:133] step: 735400, training_loss: 2.78608e-02
I0211 12:50:08.175331 22542570456896 run_lib.py:146] step: 735400, eval_loss: 2.40583e-02
I0211 12:50:25.626651 22542570456896 run_lib.py:133] step: 735450, training_loss: 2.89684e-02
I0211 12:50:43.046029 22542570456896 run_lib.py:133] step: 735500, training_loss: 3.24779e-02
I0211 12:50:43.202353 22542570456896 run_lib.py:146] step: 735500, eval_loss: 3.17543e-02
I0211 12:51:00.814424 22542570456896 run_lib.py:133] step: 735550, training_loss: 2.64382e-02
I0211 12:51:18.190950 22542570456896 run_lib.py:133] step: 735600, training_loss: 2.62661e-02
I0211 12:51:18.350424 22542570456896 run_lib.py:146] step: 735600, eval_loss: 2.50255e-02
I0211 12:51:35.759130 22542570456896 run_lib.py:133] step: 735650, training_loss: 2.80022e-02
I0211 12:51:53.360693 22542570456896 run_lib.py:133] step: 735700, training_loss: 2.52959e-02
I0211 12:51:53.515142 22542570456896 run_lib.py:146] step: 735700, eval_loss: 2.60048e-02
I0211 12:52:10.944245 22542570456896 run_lib.py:133] step: 735750, training_loss: 3.55748e-02
I0211 12:52:28.305487 22542570456896 run_lib.py:133] step: 735800, training_loss: 2.37884e-02
I0211 12:52:28.459288 22542570456896 run_lib.py:146] step: 735800, eval_loss: 3.38974e-02
I0211 12:52:45.945457 22542570456896 run_lib.py:133] step: 735850, training_loss: 2.92583e-02
I0211 12:53:03.375052 22542570456896 run_lib.py:133] step: 735900, training_loss: 2.42100e-02
I0211 12:53:03.532530 22542570456896 run_lib.py:146] step: 735900, eval_loss: 3.01506e-02
I0211 12:53:20.958956 22542570456896 run_lib.py:133] step: 735950, training_loss: 3.20469e-02
I0211 12:53:38.376477 22542570456896 run_lib.py:133] step: 736000, training_loss: 2.66828e-02
I0211 12:53:38.532648 22542570456896 run_lib.py:146] step: 736000, eval_loss: 2.78631e-02
I0211 12:53:56.131396 22542570456896 run_lib.py:133] step: 736050, training_loss: 2.90026e-02
I0211 12:54:13.613435 22542570456896 run_lib.py:133] step: 736100, training_loss: 2.76357e-02
I0211 12:54:13.777962 22542570456896 run_lib.py:146] step: 736100, eval_loss: 3.43035e-02
I0211 12:54:31.171449 22542570456896 run_lib.py:133] step: 736150, training_loss: 2.26911e-02
I0211 12:54:48.606925 22542570456896 run_lib.py:133] step: 736200, training_loss: 2.83368e-02
I0211 12:54:48.759073 22542570456896 run_lib.py:146] step: 736200, eval_loss: 3.42688e-02
I0211 12:55:06.405793 22542570456896 run_lib.py:133] step: 736250, training_loss: 2.27140e-02
I0211 12:55:23.876866 22542570456896 run_lib.py:133] step: 736300, training_loss: 2.87555e-02
I0211 12:55:24.037575 22542570456896 run_lib.py:146] step: 736300, eval_loss: 3.41549e-02
I0211 12:55:41.637463 22542570456896 run_lib.py:133] step: 736350, training_loss: 3.06088e-02
I0211 12:55:59.059947 22542570456896 run_lib.py:133] step: 736400, training_loss: 3.12494e-02
I0211 12:55:59.216550 22542570456896 run_lib.py:146] step: 736400, eval_loss: 2.87506e-02
I0211 12:56:16.804580 22542570456896 run_lib.py:133] step: 736450, training_loss: 2.28924e-02
I0211 12:56:34.215195 22542570456896 run_lib.py:133] step: 736500, training_loss: 3.18148e-02
I0211 12:56:34.373907 22542570456896 run_lib.py:146] step: 736500, eval_loss: 3.09489e-02
I0211 12:56:51.949046 22542570456896 run_lib.py:133] step: 736550, training_loss: 2.83751e-02
I0211 12:57:09.420123 22542570456896 run_lib.py:133] step: 736600, training_loss: 2.55156e-02
I0211 12:57:09.576233 22542570456896 run_lib.py:146] step: 736600, eval_loss: 2.78517e-02
I0211 12:57:27.002409 22542570456896 run_lib.py:133] step: 736650, training_loss: 3.02728e-02
I0211 12:57:44.763129 22542570456896 run_lib.py:133] step: 736700, training_loss: 2.71633e-02
I0211 12:57:44.916534 22542570456896 run_lib.py:146] step: 736700, eval_loss: 2.68663e-02
I0211 12:58:02.300694 22542570456896 run_lib.py:133] step: 736750, training_loss: 2.93643e-02
I0211 12:58:19.708206 22542570456896 run_lib.py:133] step: 736800, training_loss: 2.89376e-02
I0211 12:58:19.883913 22542570456896 run_lib.py:146] step: 736800, eval_loss: 3.46112e-02
I0211 12:58:37.509299 22542570456896 run_lib.py:133] step: 736850, training_loss: 1.89303e-02
I0211 12:58:54.968435 22542570456896 run_lib.py:133] step: 736900, training_loss: 2.34838e-02
I0211 12:58:55.129259 22542570456896 run_lib.py:146] step: 736900, eval_loss: 2.91628e-02
I0211 12:59:12.676768 22542570456896 run_lib.py:133] step: 736950, training_loss: 2.61701e-02
I0211 12:59:30.114045 22542570456896 run_lib.py:133] step: 737000, training_loss: 2.89092e-02
I0211 12:59:30.268130 22542570456896 run_lib.py:146] step: 737000, eval_loss: 3.17403e-02
I0211 12:59:47.732675 22542570456896 run_lib.py:133] step: 737050, training_loss: 2.45144e-02
I0211 13:00:05.338275 22542570456896 run_lib.py:133] step: 737100, training_loss: 2.64379e-02
I0211 13:00:05.490349 22542570456896 run_lib.py:146] step: 737100, eval_loss: 3.03757e-02
I0211 13:00:22.943935 22542570456896 run_lib.py:133] step: 737150, training_loss: 2.17752e-02
I0211 13:00:40.366446 22542570456896 run_lib.py:133] step: 737200, training_loss: 2.68506e-02
I0211 13:00:40.518345 22542570456896 run_lib.py:146] step: 737200, eval_loss: 3.52559e-02
I0211 13:00:57.935495 22542570456896 run_lib.py:133] step: 737250, training_loss: 2.49102e-02
I0211 13:01:15.560831 22542570456896 run_lib.py:133] step: 737300, training_loss: 2.89430e-02
I0211 13:01:15.719584 22542570456896 run_lib.py:146] step: 737300, eval_loss: 2.44272e-02
I0211 13:01:33.116829 22542570456896 run_lib.py:133] step: 737350, training_loss: 2.66566e-02
I0211 13:01:50.614417 22542570456896 run_lib.py:133] step: 737400, training_loss: 2.40293e-02
I0211 13:01:50.790343 22542570456896 run_lib.py:146] step: 737400, eval_loss: 2.92381e-02
I0211 13:02:08.247590 22542570456896 run_lib.py:133] step: 737450, training_loss: 2.59662e-02
I0211 13:02:25.728933 22542570456896 run_lib.py:133] step: 737500, training_loss: 3.41444e-02
I0211 13:02:25.884539 22542570456896 run_lib.py:146] step: 737500, eval_loss: 2.32911e-02
I0211 13:02:43.477196 22542570456896 run_lib.py:133] step: 737550, training_loss: 2.32527e-02
I0211 13:03:00.895891 22542570456896 run_lib.py:133] step: 737600, training_loss: 2.38424e-02
I0211 13:03:01.048084 22542570456896 run_lib.py:146] step: 737600, eval_loss: 2.33836e-02
I0211 13:03:18.387414 22542570456896 run_lib.py:133] step: 737650, training_loss: 2.27021e-02
I0211 13:03:35.818468 22542570456896 run_lib.py:133] step: 737700, training_loss: 3.86946e-02
I0211 13:03:35.981617 22542570456896 run_lib.py:146] step: 737700, eval_loss: 2.25538e-02
I0211 13:03:53.632466 22542570456896 run_lib.py:133] step: 737750, training_loss: 2.50445e-02
I0211 13:04:11.071008 22542570456896 run_lib.py:133] step: 737800, training_loss: 2.54400e-02
I0211 13:04:11.229973 22542570456896 run_lib.py:146] step: 737800, eval_loss: 3.38196e-02
I0211 13:04:28.769997 22542570456896 run_lib.py:133] step: 737850, training_loss: 2.93750e-02
I0211 13:04:46.167192 22542570456896 run_lib.py:133] step: 737900, training_loss: 3.10028e-02
I0211 13:04:46.327360 22542570456896 run_lib.py:146] step: 737900, eval_loss: 2.68084e-02
I0211 13:05:03.890917 22542570456896 run_lib.py:133] step: 737950, training_loss: 2.61893e-02
I0211 13:05:21.318883 22542570456896 run_lib.py:133] step: 738000, training_loss: 2.42581e-02
I0211 13:05:21.475930 22542570456896 run_lib.py:146] step: 738000, eval_loss: 2.52363e-02
I0211 13:05:38.949784 22542570456896 run_lib.py:133] step: 738050, training_loss: 2.30424e-02
I0211 13:05:56.503503 22542570456896 run_lib.py:133] step: 738100, training_loss: 2.23795e-02
I0211 13:05:56.660472 22542570456896 run_lib.py:146] step: 738100, eval_loss: 2.73457e-02
I0211 13:06:14.025245 22542570456896 run_lib.py:133] step: 738150, training_loss: 1.93440e-02
I0211 13:06:31.543391 22542570456896 run_lib.py:133] step: 738200, training_loss: 2.60523e-02
I0211 13:06:31.700421 22542570456896 run_lib.py:146] step: 738200, eval_loss: 2.89720e-02
I0211 13:06:49.078725 22542570456896 run_lib.py:133] step: 738250, training_loss: 2.45860e-02
I0211 13:07:06.461842 22542570456896 run_lib.py:133] step: 738300, training_loss: 2.77689e-02
I0211 13:07:06.633150 22542570456896 run_lib.py:146] step: 738300, eval_loss: 2.71143e-02
I0211 13:07:24.245281 22542570456896 run_lib.py:133] step: 738350, training_loss: 2.50234e-02
I0211 13:07:41.697178 22542570456896 run_lib.py:133] step: 738400, training_loss: 2.81157e-02
I0211 13:07:41.860864 22542570456896 run_lib.py:146] step: 738400, eval_loss: 2.57080e-02
I0211 13:07:59.274734 22542570456896 run_lib.py:133] step: 738450, training_loss: 3.27648e-02
I0211 13:08:16.812751 22542570456896 run_lib.py:133] step: 738500, training_loss: 2.59636e-02
I0211 13:08:16.969269 22542570456896 run_lib.py:146] step: 738500, eval_loss: 3.08690e-02
I0211 13:08:34.348178 22542570456896 run_lib.py:133] step: 738550, training_loss: 2.59682e-02
I0211 13:08:51.837491 22542570456896 run_lib.py:133] step: 738600, training_loss: 3.24448e-02
I0211 13:08:52.165374 22542570456896 run_lib.py:146] step: 738600, eval_loss: 3.05481e-02
I0211 13:09:09.642342 22542570456896 run_lib.py:133] step: 738650, training_loss: 2.21343e-02
I0211 13:09:27.063939 22542570456896 run_lib.py:133] step: 738700, training_loss: 2.96323e-02
I0211 13:09:27.219172 22542570456896 run_lib.py:146] step: 738700, eval_loss: 3.15098e-02
I0211 13:09:44.593231 22542570456896 run_lib.py:133] step: 738750, training_loss: 2.62304e-02
I0211 13:10:02.010211 22542570456896 run_lib.py:133] step: 738800, training_loss: 2.99317e-02
I0211 13:10:02.169567 22542570456896 run_lib.py:146] step: 738800, eval_loss: 2.88350e-02
I0211 13:10:19.753705 22542570456896 run_lib.py:133] step: 738850, training_loss: 2.52859e-02
I0211 13:10:37.233824 22542570456896 run_lib.py:133] step: 738900, training_loss: 2.12111e-02
I0211 13:10:37.394888 22542570456896 run_lib.py:146] step: 738900, eval_loss: 2.62402e-02
I0211 13:10:54.814742 22542570456896 run_lib.py:133] step: 738950, training_loss: 2.63072e-02
I0211 13:11:12.205042 22542570456896 run_lib.py:133] step: 739000, training_loss: 2.00555e-02
I0211 13:11:12.360282 22542570456896 run_lib.py:146] step: 739000, eval_loss: 2.92671e-02
I0211 13:11:29.941015 22542570456896 run_lib.py:133] step: 739050, training_loss: 2.77169e-02
I0211 13:11:47.381889 22542570456896 run_lib.py:133] step: 739100, training_loss: 3.31387e-02
I0211 13:11:47.533419 22542570456896 run_lib.py:146] step: 739100, eval_loss: 2.37632e-02
I0211 13:12:04.946249 22542570456896 run_lib.py:133] step: 739150, training_loss: 3.43391e-02
I0211 13:12:22.396102 22542570456896 run_lib.py:133] step: 739200, training_loss: 3.61027e-02
I0211 13:12:22.571382 22542570456896 run_lib.py:146] step: 739200, eval_loss: 2.79558e-02
I0211 13:12:40.167505 22542570456896 run_lib.py:133] step: 739250, training_loss: 2.99075e-02
I0211 13:12:57.579173 22542570456896 run_lib.py:133] step: 739300, training_loss: 2.97864e-02
I0211 13:12:57.734492 22542570456896 run_lib.py:146] step: 739300, eval_loss: 3.40327e-02
I0211 13:13:15.284569 22542570456896 run_lib.py:133] step: 739350, training_loss: 3.53169e-02
I0211 13:13:32.687020 22542570456896 run_lib.py:133] step: 739400, training_loss: 2.87974e-02
I0211 13:13:32.842103 22542570456896 run_lib.py:146] step: 739400, eval_loss: 2.81715e-02
I0211 13:13:50.406776 22542570456896 run_lib.py:133] step: 739450, training_loss: 2.01522e-02
I0211 13:14:07.897984 22542570456896 run_lib.py:133] step: 739500, training_loss: 2.86533e-02
I0211 13:14:08.051083 22542570456896 run_lib.py:146] step: 739500, eval_loss: 2.48012e-02
I0211 13:14:25.441663 22542570456896 run_lib.py:133] step: 739550, training_loss: 3.13264e-02
I0211 13:14:43.034919 22542570456896 run_lib.py:133] step: 739600, training_loss: 1.98587e-02
I0211 13:14:43.189358 22542570456896 run_lib.py:146] step: 739600, eval_loss: 3.26077e-02
I0211 13:15:00.640522 22542570456896 run_lib.py:133] step: 739650, training_loss: 2.43190e-02
I0211 13:15:18.192726 22542570456896 run_lib.py:133] step: 739700, training_loss: 2.70145e-02
I0211 13:15:18.374294 22542570456896 run_lib.py:146] step: 739700, eval_loss: 2.70550e-02
I0211 13:15:35.838850 22542570456896 run_lib.py:133] step: 739750, training_loss: 2.26575e-02
I0211 13:15:53.257332 22542570456896 run_lib.py:133] step: 739800, training_loss: 2.46212e-02
I0211 13:15:53.454543 22542570456896 run_lib.py:146] step: 739800, eval_loss: 2.72826e-02
I0211 13:16:11.058917 22542570456896 run_lib.py:133] step: 739850, training_loss: 2.62097e-02
I0211 13:16:28.422077 22542570456896 run_lib.py:133] step: 739900, training_loss: 2.88604e-02
I0211 13:16:28.577308 22542570456896 run_lib.py:146] step: 739900, eval_loss: 2.95766e-02
I0211 13:16:46.000195 22542570456896 run_lib.py:133] step: 739950, training_loss: 2.51364e-02
I0211 13:17:03.408035 22542570456896 run_lib.py:133] step: 740000, training_loss: 2.99168e-02
I0211 13:17:04.109402 22542570456896 run_lib.py:146] step: 740000, eval_loss: 3.35240e-02
I0211 13:17:24.284997 22542570456896 run_lib.py:133] step: 740050, training_loss: 2.34855e-02
I0211 13:17:41.758233 22542570456896 run_lib.py:133] step: 740100, training_loss: 2.73974e-02
I0211 13:17:41.911247 22542570456896 run_lib.py:146] step: 740100, eval_loss: 3.04626e-02
I0211 13:17:59.174075 22542570456896 run_lib.py:133] step: 740150, training_loss: 2.71756e-02
I0211 13:18:16.486187 22542570456896 run_lib.py:133] step: 740200, training_loss: 3.24760e-02
I0211 13:18:16.638392 22542570456896 run_lib.py:146] step: 740200, eval_loss: 2.88408e-02
I0211 13:18:34.050549 22542570456896 run_lib.py:133] step: 740250, training_loss: 3.10327e-02
I0211 13:18:51.509799 22542570456896 run_lib.py:133] step: 740300, training_loss: 2.66904e-02
I0211 13:18:51.675382 22542570456896 run_lib.py:146] step: 740300, eval_loss: 2.82362e-02
I0211 13:19:09.116783 22542570456896 run_lib.py:133] step: 740350, training_loss: 2.76126e-02
I0211 13:19:26.556618 22542570456896 run_lib.py:133] step: 740400, training_loss: 3.22774e-02
I0211 13:19:26.712086 22542570456896 run_lib.py:146] step: 740400, eval_loss: 2.39152e-02
I0211 13:19:44.342012 22542570456896 run_lib.py:133] step: 740450, training_loss: 2.76352e-02
I0211 13:20:01.757500 22542570456896 run_lib.py:133] step: 740500, training_loss: 3.31948e-02
I0211 13:20:01.912117 22542570456896 run_lib.py:146] step: 740500, eval_loss: 3.24058e-02
I0211 13:20:19.383521 22542570456896 run_lib.py:133] step: 740550, training_loss: 2.87341e-02
I0211 13:20:36.835593 22542570456896 run_lib.py:133] step: 740600, training_loss: 2.83543e-02
I0211 13:20:36.992666 22542570456896 run_lib.py:146] step: 740600, eval_loss: 2.09369e-02
I0211 13:20:54.428419 22542570456896 run_lib.py:133] step: 740650, training_loss: 3.00708e-02
I0211 13:21:11.863765 22542570456896 run_lib.py:133] step: 740700, training_loss: 2.15481e-02
I0211 13:21:12.022819 22542570456896 run_lib.py:146] step: 740700, eval_loss: 2.82597e-02
I0211 13:21:29.721231 22542570456896 run_lib.py:133] step: 740750, training_loss: 2.50338e-02
I0211 13:21:47.226051 22542570456896 run_lib.py:133] step: 740800, training_loss: 2.20742e-02
I0211 13:21:47.382564 22542570456896 run_lib.py:146] step: 740800, eval_loss: 3.08494e-02
I0211 13:22:04.869149 22542570456896 run_lib.py:133] step: 740850, training_loss: 3.24628e-02
I0211 13:22:22.436533 22542570456896 run_lib.py:133] step: 740900, training_loss: 3.10779e-02
I0211 13:22:22.593401 22542570456896 run_lib.py:146] step: 740900, eval_loss: 2.61270e-02
I0211 13:22:40.278646 22542570456896 run_lib.py:133] step: 740950, training_loss: 2.15503e-02
I0211 13:22:57.758433 22542570456896 run_lib.py:133] step: 741000, training_loss: 2.32693e-02
I0211 13:22:57.912542 22542570456896 run_lib.py:146] step: 741000, eval_loss: 3.36649e-02
I0211 13:23:15.488688 22542570456896 run_lib.py:133] step: 741050, training_loss: 3.01922e-02
I0211 13:23:32.943967 22542570456896 run_lib.py:133] step: 741100, training_loss: 2.37100e-02
I0211 13:23:33.098360 22542570456896 run_lib.py:146] step: 741100, eval_loss: 2.57078e-02
I0211 13:23:50.673302 22542570456896 run_lib.py:133] step: 741150, training_loss: 2.49540e-02
I0211 13:24:08.206037 22542570456896 run_lib.py:133] step: 741200, training_loss: 2.94825e-02
I0211 13:24:08.383508 22542570456896 run_lib.py:146] step: 741200, eval_loss: 3.03404e-02
I0211 13:24:26.079721 22542570456896 run_lib.py:133] step: 741250, training_loss: 2.13536e-02
I0211 13:24:43.540661 22542570456896 run_lib.py:133] step: 741300, training_loss: 3.36794e-02
I0211 13:24:43.713775 22542570456896 run_lib.py:146] step: 741300, eval_loss: 2.71593e-02
I0211 13:25:01.173506 22542570456896 run_lib.py:133] step: 741350, training_loss: 3.70323e-02
I0211 13:25:18.774028 22542570456896 run_lib.py:133] step: 741400, training_loss: 2.59724e-02
I0211 13:25:18.930375 22542570456896 run_lib.py:146] step: 741400, eval_loss: 2.99046e-02
I0211 13:25:36.440969 22542570456896 run_lib.py:133] step: 741450, training_loss: 2.24771e-02
I0211 13:25:53.978064 22542570456896 run_lib.py:133] step: 741500, training_loss: 2.98360e-02
I0211 13:25:54.133835 22542570456896 run_lib.py:146] step: 741500, eval_loss: 2.77016e-02
I0211 13:26:11.820665 22542570456896 run_lib.py:133] step: 741550, training_loss: 2.55766e-02
I0211 13:26:29.341989 22542570456896 run_lib.py:133] step: 741600, training_loss: 2.42618e-02
I0211 13:26:29.498551 22542570456896 run_lib.py:146] step: 741600, eval_loss: 2.40480e-02
I0211 13:26:47.113970 22542570456896 run_lib.py:133] step: 741650, training_loss: 2.30161e-02
I0211 13:27:04.614090 22542570456896 run_lib.py:133] step: 741700, training_loss: 2.89487e-02
I0211 13:27:04.773440 22542570456896 run_lib.py:146] step: 741700, eval_loss: 2.90896e-02
I0211 13:27:22.273407 22542570456896 run_lib.py:133] step: 741750, training_loss: 2.98676e-02
I0211 13:27:40.036353 22542570456896 run_lib.py:133] step: 741800, training_loss: 2.62979e-02
I0211 13:27:40.196285 22542570456896 run_lib.py:146] step: 741800, eval_loss: 2.68351e-02
I0211 13:27:57.711409 22542570456896 run_lib.py:133] step: 741850, training_loss: 2.73310e-02
I0211 13:28:15.165868 22542570456896 run_lib.py:133] step: 741900, training_loss: 3.35146e-02
I0211 13:28:15.321428 22542570456896 run_lib.py:146] step: 741900, eval_loss: 2.81089e-02
I0211 13:28:32.804446 22542570456896 run_lib.py:133] step: 741950, training_loss: 2.15181e-02
I0211 13:28:50.517586 22542570456896 run_lib.py:133] step: 742000, training_loss: 3.92889e-02
I0211 13:28:50.674603 22542570456896 run_lib.py:146] step: 742000, eval_loss: 2.38327e-02
I0211 13:29:08.236725 22542570456896 run_lib.py:133] step: 742050, training_loss: 3.53612e-02
I0211 13:29:25.821252 22542570456896 run_lib.py:133] step: 742100, training_loss: 3.14440e-02
I0211 13:29:25.978927 22542570456896 run_lib.py:146] step: 742100, eval_loss: 3.03474e-02
I0211 13:29:43.474802 22542570456896 run_lib.py:133] step: 742150, training_loss: 3.12926e-02
I0211 13:30:00.981678 22542570456896 run_lib.py:133] step: 742200, training_loss: 2.00485e-02
I0211 13:30:01.144566 22542570456896 run_lib.py:146] step: 742200, eval_loss: 2.48522e-02
I0211 13:30:18.750635 22542570456896 run_lib.py:133] step: 742250, training_loss: 3.38276e-02
I0211 13:30:36.389299 22542570456896 run_lib.py:133] step: 742300, training_loss: 2.28382e-02
I0211 13:30:36.553260 22542570456896 run_lib.py:146] step: 742300, eval_loss: 2.80997e-02
I0211 13:30:54.074923 22542570456896 run_lib.py:133] step: 742350, training_loss: 3.22411e-02
I0211 13:31:11.558616 22542570456896 run_lib.py:133] step: 742400, training_loss: 2.24172e-02
I0211 13:31:11.713410 22542570456896 run_lib.py:146] step: 742400, eval_loss: 3.28606e-02
I0211 13:31:29.363403 22542570456896 run_lib.py:133] step: 742450, training_loss: 2.78693e-02
I0211 13:31:46.864654 22542570456896 run_lib.py:133] step: 742500, training_loss: 2.25583e-02
I0211 13:31:47.019447 22542570456896 run_lib.py:146] step: 742500, eval_loss: 3.88885e-02
I0211 13:32:04.672234 22542570456896 run_lib.py:133] step: 742550, training_loss: 2.58450e-02
I0211 13:32:22.277038 22542570456896 run_lib.py:133] step: 742600, training_loss: 3.27684e-02
I0211 13:32:22.445660 22542570456896 run_lib.py:146] step: 742600, eval_loss: 2.61941e-02
I0211 13:32:40.171255 22542570456896 run_lib.py:133] step: 742650, training_loss: 2.47458e-02
I0211 13:32:57.666271 22542570456896 run_lib.py:133] step: 742700, training_loss: 2.54178e-02
I0211 13:32:57.822458 22542570456896 run_lib.py:146] step: 742700, eval_loss: 2.85028e-02
I0211 13:33:15.301675 22542570456896 run_lib.py:133] step: 742750, training_loss: 2.85224e-02
I0211 13:33:33.020411 22542570456896 run_lib.py:133] step: 742800, training_loss: 3.25292e-02
I0211 13:33:33.184172 22542570456896 run_lib.py:146] step: 742800, eval_loss: 2.60157e-02
I0211 13:33:50.715726 22542570456896 run_lib.py:133] step: 742850, training_loss: 2.48890e-02
I0211 13:34:08.367152 22542570456896 run_lib.py:133] step: 742900, training_loss: 2.46476e-02
I0211 13:34:08.521581 22542570456896 run_lib.py:146] step: 742900, eval_loss: 3.10816e-02
I0211 13:34:26.032056 22542570456896 run_lib.py:133] step: 742950, training_loss: 2.49155e-02
I0211 13:34:43.502899 22542570456896 run_lib.py:133] step: 743000, training_loss: 2.55463e-02
I0211 13:34:43.660363 22542570456896 run_lib.py:146] step: 743000, eval_loss: 2.63735e-02
I0211 13:35:01.292428 22542570456896 run_lib.py:133] step: 743050, training_loss: 2.89142e-02
I0211 13:35:18.772110 22542570456896 run_lib.py:133] step: 743100, training_loss: 2.00972e-02
I0211 13:35:18.930731 22542570456896 run_lib.py:146] step: 743100, eval_loss: 3.69748e-02
I0211 13:35:36.501658 22542570456896 run_lib.py:133] step: 743150, training_loss: 2.72213e-02
I0211 13:35:54.234772 22542570456896 run_lib.py:133] step: 743200, training_loss: 2.97264e-02
I0211 13:35:54.391253 22542570456896 run_lib.py:146] step: 743200, eval_loss: 3.64455e-02
I0211 13:36:11.875085 22542570456896 run_lib.py:133] step: 743250, training_loss: 2.13429e-02
I0211 13:36:29.365219 22542570456896 run_lib.py:133] step: 743300, training_loss: 3.51645e-02
I0211 13:36:29.696343 22542570456896 run_lib.py:146] step: 743300, eval_loss: 2.79888e-02
I0211 13:36:47.167273 22542570456896 run_lib.py:133] step: 743350, training_loss: 2.94389e-02
I0211 13:37:04.686795 22542570456896 run_lib.py:133] step: 743400, training_loss: 2.83124e-02
I0211 13:37:04.843493 22542570456896 run_lib.py:146] step: 743400, eval_loss: 2.79731e-02
I0211 13:37:22.365046 22542570456896 run_lib.py:133] step: 743450, training_loss: 2.82124e-02
I0211 13:37:39.840579 22542570456896 run_lib.py:133] step: 743500, training_loss: 2.41676e-02
I0211 13:37:39.996468 22542570456896 run_lib.py:146] step: 743500, eval_loss: 2.94436e-02
I0211 13:37:57.653822 22542570456896 run_lib.py:133] step: 743550, training_loss: 2.18460e-02
I0211 13:38:15.202872 22542570456896 run_lib.py:133] step: 743600, training_loss: 2.84788e-02
I0211 13:38:15.360691 22542570456896 run_lib.py:146] step: 743600, eval_loss: 2.57003e-02
I0211 13:38:32.878715 22542570456896 run_lib.py:133] step: 743650, training_loss: 2.84363e-02
I0211 13:38:50.400663 22542570456896 run_lib.py:133] step: 743700, training_loss: 2.09018e-02
I0211 13:38:50.565401 22542570456896 run_lib.py:146] step: 743700, eval_loss: 2.90896e-02
I0211 13:39:08.230421 22542570456896 run_lib.py:133] step: 743750, training_loss: 2.43738e-02
I0211 13:39:25.794873 22542570456896 run_lib.py:133] step: 743800, training_loss: 2.44298e-02
I0211 13:39:25.954731 22542570456896 run_lib.py:146] step: 743800, eval_loss: 3.40311e-02
I0211 13:39:43.417992 22542570456896 run_lib.py:133] step: 743850, training_loss: 3.13824e-02
I0211 13:40:00.943487 22542570456896 run_lib.py:133] step: 743900, training_loss: 2.31546e-02
I0211 13:40:01.107139 22542570456896 run_lib.py:146] step: 743900, eval_loss: 2.29956e-02
I0211 13:40:18.785857 22542570456896 run_lib.py:133] step: 743950, training_loss: 2.69151e-02
I0211 13:40:36.309506 22542570456896 run_lib.py:133] step: 744000, training_loss: 2.59074e-02
I0211 13:40:36.475783 22542570456896 run_lib.py:146] step: 744000, eval_loss: 2.86988e-02
I0211 13:40:54.198824 22542570456896 run_lib.py:133] step: 744050, training_loss: 3.00732e-02
I0211 13:41:11.722783 22542570456896 run_lib.py:133] step: 744100, training_loss: 2.66765e-02
I0211 13:41:11.879280 22542570456896 run_lib.py:146] step: 744100, eval_loss: 2.99896e-02
I0211 13:41:29.523051 22542570456896 run_lib.py:133] step: 744150, training_loss: 2.39978e-02
I0211 13:41:46.978379 22542570456896 run_lib.py:133] step: 744200, training_loss: 3.33044e-02
I0211 13:41:47.138751 22542570456896 run_lib.py:146] step: 744200, eval_loss: 2.65077e-02
I0211 13:42:04.748773 22542570456896 run_lib.py:133] step: 744250, training_loss: 2.48210e-02
I0211 13:42:22.523229 22542570456896 run_lib.py:133] step: 744300, training_loss: 2.35782e-02
I0211 13:42:22.676160 22542570456896 run_lib.py:146] step: 744300, eval_loss: 3.08674e-02
I0211 13:42:40.157930 22542570456896 run_lib.py:133] step: 744350, training_loss: 2.72376e-02
I0211 13:42:57.760218 22542570456896 run_lib.py:133] step: 744400, training_loss: 2.84967e-02
I0211 13:42:57.915502 22542570456896 run_lib.py:146] step: 744400, eval_loss: 2.78746e-02
I0211 13:43:15.372876 22542570456896 run_lib.py:133] step: 744450, training_loss: 2.52470e-02
I0211 13:43:32.875579 22542570456896 run_lib.py:133] step: 744500, training_loss: 3.60382e-02
I0211 13:43:33.038074 22542570456896 run_lib.py:146] step: 744500, eval_loss: 3.12782e-02
I0211 13:43:50.777437 22542570456896 run_lib.py:133] step: 744550, training_loss: 2.44250e-02
I0211 13:44:08.336606 22542570456896 run_lib.py:133] step: 744600, training_loss: 2.34435e-02
I0211 13:44:08.493657 22542570456896 run_lib.py:146] step: 744600, eval_loss: 2.70143e-02
I0211 13:44:25.982480 22542570456896 run_lib.py:133] step: 744650, training_loss: 2.73634e-02
I0211 13:44:43.472909 22542570456896 run_lib.py:133] step: 744700, training_loss: 2.66079e-02
I0211 13:44:43.629661 22542570456896 run_lib.py:146] step: 744700, eval_loss: 2.51387e-02
I0211 13:45:01.314591 22542570456896 run_lib.py:133] step: 744750, training_loss: 2.67005e-02
I0211 13:45:18.827052 22542570456896 run_lib.py:133] step: 744800, training_loss: 3.06401e-02
I0211 13:45:18.982695 22542570456896 run_lib.py:146] step: 744800, eval_loss: 2.67727e-02
I0211 13:45:36.624857 22542570456896 run_lib.py:133] step: 744850, training_loss: 3.37704e-02
I0211 13:45:54.123548 22542570456896 run_lib.py:133] step: 744900, training_loss: 2.71233e-02
I0211 13:45:54.279449 22542570456896 run_lib.py:146] step: 744900, eval_loss: 2.23644e-02
I0211 13:46:11.724499 22542570456896 run_lib.py:133] step: 744950, training_loss: 3.46917e-02
I0211 13:46:29.191312 22542570456896 run_lib.py:133] step: 745000, training_loss: 3.79853e-02
I0211 13:46:29.350764 22542570456896 run_lib.py:146] step: 745000, eval_loss: 3.60712e-02
I0211 13:46:47.049422 22542570456896 run_lib.py:133] step: 745050, training_loss: 2.66624e-02
I0211 13:47:04.689616 22542570456896 run_lib.py:133] step: 745100, training_loss: 2.80221e-02
I0211 13:47:04.848357 22542570456896 run_lib.py:146] step: 745100, eval_loss: 3.62950e-02
I0211 13:47:22.329429 22542570456896 run_lib.py:133] step: 745150, training_loss: 3.15834e-02
I0211 13:47:39.809098 22542570456896 run_lib.py:133] step: 745200, training_loss: 2.95218e-02
I0211 13:47:39.966470 22542570456896 run_lib.py:146] step: 745200, eval_loss: 3.05071e-02
I0211 13:47:57.652968 22542570456896 run_lib.py:133] step: 745250, training_loss: 2.71397e-02
I0211 13:48:15.140315 22542570456896 run_lib.py:133] step: 745300, training_loss: 2.21254e-02
I0211 13:48:15.294709 22542570456896 run_lib.py:146] step: 745300, eval_loss: 2.75854e-02
I0211 13:48:33.030477 22542570456896 run_lib.py:133] step: 745350, training_loss: 3.36294e-02
I0211 13:48:50.527421 22542570456896 run_lib.py:133] step: 745400, training_loss: 2.97984e-02
I0211 13:48:50.686651 22542570456896 run_lib.py:146] step: 745400, eval_loss: 2.65380e-02
I0211 13:49:08.357349 22542570456896 run_lib.py:133] step: 745450, training_loss: 2.73761e-02
I0211 13:49:25.853679 22542570456896 run_lib.py:133] step: 745500, training_loss: 2.64409e-02
I0211 13:49:26.012789 22542570456896 run_lib.py:146] step: 745500, eval_loss: 3.20193e-02
I0211 13:49:43.669076 22542570456896 run_lib.py:133] step: 745550, training_loss: 2.23823e-02
I0211 13:50:01.165678 22542570456896 run_lib.py:133] step: 745600, training_loss: 2.66752e-02
I0211 13:50:01.336675 22542570456896 run_lib.py:146] step: 745600, eval_loss: 3.12295e-02
I0211 13:50:18.853702 22542570456896 run_lib.py:133] step: 745650, training_loss: 3.27277e-02
I0211 13:50:36.561631 22542570456896 run_lib.py:133] step: 745700, training_loss: 3.53540e-02
I0211 13:50:36.732808 22542570456896 run_lib.py:146] step: 745700, eval_loss: 2.37247e-02
I0211 13:50:54.223447 22542570456896 run_lib.py:133] step: 745750, training_loss: 3.12073e-02
I0211 13:51:11.725013 22542570456896 run_lib.py:133] step: 745800, training_loss: 2.19804e-02
I0211 13:51:11.877377 22542570456896 run_lib.py:146] step: 745800, eval_loss: 3.18455e-02
I0211 13:51:29.510989 22542570456896 run_lib.py:133] step: 745850, training_loss: 1.82454e-02
I0211 13:51:47.131353 22542570456896 run_lib.py:133] step: 745900, training_loss: 2.66467e-02
I0211 13:51:47.306841 22542570456896 run_lib.py:146] step: 745900, eval_loss: 3.61075e-02
I0211 13:52:04.858671 22542570456896 run_lib.py:133] step: 745950, training_loss: 2.72585e-02
I0211 13:52:22.349166 22542570456896 run_lib.py:133] step: 746000, training_loss: 2.44608e-02
I0211 13:52:22.505038 22542570456896 run_lib.py:146] step: 746000, eval_loss: 2.88797e-02
I0211 13:52:39.952409 22542570456896 run_lib.py:133] step: 746050, training_loss: 2.59417e-02
I0211 13:52:57.626174 22542570456896 run_lib.py:133] step: 746100, training_loss: 2.52306e-02
I0211 13:52:57.787844 22542570456896 run_lib.py:146] step: 746100, eval_loss: 2.07997e-02
I0211 13:53:15.236677 22542570456896 run_lib.py:133] step: 746150, training_loss: 2.55543e-02
I0211 13:53:32.819944 22542570456896 run_lib.py:133] step: 746200, training_loss: 2.41873e-02
I0211 13:53:32.980949 22542570456896 run_lib.py:146] step: 746200, eval_loss: 2.97782e-02
I0211 13:53:50.557585 22542570456896 run_lib.py:133] step: 746250, training_loss: 2.83212e-02
I0211 13:54:08.207164 22542570456896 run_lib.py:133] step: 746300, training_loss: 3.11814e-02
I0211 13:54:08.360677 22542570456896 run_lib.py:146] step: 746300, eval_loss: 2.56679e-02
I0211 13:54:25.875446 22542570456896 run_lib.py:133] step: 746350, training_loss: 2.58641e-02
I0211 13:54:43.422708 22542570456896 run_lib.py:133] step: 746400, training_loss: 2.66230e-02
I0211 13:54:43.590472 22542570456896 run_lib.py:146] step: 746400, eval_loss: 3.53723e-02
I0211 13:55:01.074337 22542570456896 run_lib.py:133] step: 746450, training_loss: 2.44747e-02
I0211 13:55:18.548324 22542570456896 run_lib.py:133] step: 746500, training_loss: 2.85800e-02
I0211 13:55:18.719648 22542570456896 run_lib.py:146] step: 746500, eval_loss: 3.44977e-02
I0211 13:55:36.393904 22542570456896 run_lib.py:133] step: 746550, training_loss: 2.64967e-02
I0211 13:55:53.943001 22542570456896 run_lib.py:133] step: 746600, training_loss: 2.37260e-02
I0211 13:55:54.102603 22542570456896 run_lib.py:146] step: 746600, eval_loss: 3.18340e-02
I0211 13:56:11.616601 22542570456896 run_lib.py:133] step: 746650, training_loss: 2.72873e-02
I0211 13:56:29.072633 22542570456896 run_lib.py:133] step: 746700, training_loss: 3.54774e-02
I0211 13:56:29.224921 22542570456896 run_lib.py:146] step: 746700, eval_loss: 2.62841e-02
I0211 13:56:46.838916 22542570456896 run_lib.py:133] step: 746750, training_loss: 2.61702e-02
I0211 13:57:04.321620 22542570456896 run_lib.py:133] step: 746800, training_loss: 2.61291e-02
I0211 13:57:04.492585 22542570456896 run_lib.py:146] step: 746800, eval_loss: 2.82847e-02
I0211 13:57:22.157188 22542570456896 run_lib.py:133] step: 746850, training_loss: 3.58370e-02
I0211 13:57:39.675423 22542570456896 run_lib.py:133] step: 746900, training_loss: 2.33453e-02
I0211 13:57:39.834177 22542570456896 run_lib.py:146] step: 746900, eval_loss: 3.07298e-02
I0211 13:57:57.402620 22542570456896 run_lib.py:133] step: 746950, training_loss: 2.70716e-02
I0211 13:58:14.896355 22542570456896 run_lib.py:133] step: 747000, training_loss: 2.62570e-02
I0211 13:58:15.056501 22542570456896 run_lib.py:146] step: 747000, eval_loss: 2.13395e-02
I0211 13:58:32.602601 22542570456896 run_lib.py:133] step: 747050, training_loss: 2.75459e-02
I0211 13:58:50.265986 22542570456896 run_lib.py:133] step: 747100, training_loss: 3.56542e-02
I0211 13:58:50.421489 22542570456896 run_lib.py:146] step: 747100, eval_loss: 3.36908e-02
I0211 13:59:07.899765 22542570456896 run_lib.py:133] step: 747150, training_loss: 3.16585e-02
I0211 13:59:25.509660 22542570456896 run_lib.py:133] step: 747200, training_loss: 2.64092e-02
I0211 13:59:25.659971 22542570456896 run_lib.py:146] step: 747200, eval_loss: 2.09550e-02
I0211 13:59:43.164628 22542570456896 run_lib.py:133] step: 747250, training_loss: 3.12939e-02
I0211 14:00:00.676174 22542570456896 run_lib.py:133] step: 747300, training_loss: 2.37989e-02
I0211 14:00:00.842990 22542570456896 run_lib.py:146] step: 747300, eval_loss: 3.10675e-02
I0211 14:00:18.513296 22542570456896 run_lib.py:133] step: 747350, training_loss: 2.44260e-02
I0211 14:00:36.036882 22542570456896 run_lib.py:133] step: 747400, training_loss: 2.60203e-02
I0211 14:00:36.196918 22542570456896 run_lib.py:146] step: 747400, eval_loss: 2.93857e-02
I0211 14:00:53.685138 22542570456896 run_lib.py:133] step: 747450, training_loss: 2.40109e-02
I0211 14:01:11.299912 22542570456896 run_lib.py:133] step: 747500, training_loss: 2.79298e-02
I0211 14:01:11.456387 22542570456896 run_lib.py:146] step: 747500, eval_loss: 2.63073e-02
I0211 14:01:28.917759 22542570456896 run_lib.py:133] step: 747550, training_loss: 2.93525e-02
I0211 14:01:46.450088 22542570456896 run_lib.py:133] step: 747600, training_loss: 2.18717e-02
I0211 14:01:46.606719 22542570456896 run_lib.py:146] step: 747600, eval_loss: 2.75340e-02
I0211 14:02:04.242708 22542570456896 run_lib.py:133] step: 747650, training_loss: 3.80280e-02
I0211 14:02:21.698455 22542570456896 run_lib.py:133] step: 747700, training_loss: 2.52054e-02
I0211 14:02:21.851280 22542570456896 run_lib.py:146] step: 747700, eval_loss: 2.34246e-02
I0211 14:02:39.321228 22542570456896 run_lib.py:133] step: 747750, training_loss: 2.80655e-02
I0211 14:02:56.795774 22542570456896 run_lib.py:133] step: 747800, training_loss: 2.25501e-02
I0211 14:02:56.983441 22542570456896 run_lib.py:146] step: 747800, eval_loss: 2.88944e-02
I0211 14:03:14.646043 22542570456896 run_lib.py:133] step: 747850, training_loss: 2.94995e-02
I0211 14:03:32.286560 22542570456896 run_lib.py:133] step: 747900, training_loss: 2.73485e-02
I0211 14:03:32.446096 22542570456896 run_lib.py:146] step: 747900, eval_loss: 3.59217e-02
I0211 14:03:49.936516 22542570456896 run_lib.py:133] step: 747950, training_loss: 2.70537e-02
I0211 14:04:07.416059 22542570456896 run_lib.py:133] step: 748000, training_loss: 2.59584e-02
I0211 14:04:07.571479 22542570456896 run_lib.py:146] step: 748000, eval_loss: 2.87715e-02
I0211 14:04:25.190482 22542570456896 run_lib.py:133] step: 748050, training_loss: 2.37108e-02
I0211 14:04:42.665194 22542570456896 run_lib.py:133] step: 748100, training_loss: 2.56720e-02
I0211 14:04:42.824396 22542570456896 run_lib.py:146] step: 748100, eval_loss: 2.80876e-02
I0211 14:05:00.494778 22542570456896 run_lib.py:133] step: 748150, training_loss: 3.62889e-02
I0211 14:05:18.007140 22542570456896 run_lib.py:133] step: 748200, training_loss: 2.39240e-02
I0211 14:05:18.168479 22542570456896 run_lib.py:146] step: 748200, eval_loss: 2.24729e-02
I0211 14:05:35.801678 22542570456896 run_lib.py:133] step: 748250, training_loss: 2.65929e-02
I0211 14:05:53.274403 22542570456896 run_lib.py:133] step: 748300, training_loss: 2.73691e-02
I0211 14:05:53.440907 22542570456896 run_lib.py:146] step: 748300, eval_loss: 2.34357e-02
I0211 14:06:11.070512 22542570456896 run_lib.py:133] step: 748350, training_loss: 3.06816e-02
I0211 14:06:28.579022 22542570456896 run_lib.py:133] step: 748400, training_loss: 2.97686e-02
I0211 14:06:28.748362 22542570456896 run_lib.py:146] step: 748400, eval_loss: 2.96808e-02
I0211 14:06:46.264992 22542570456896 run_lib.py:133] step: 748450, training_loss: 2.37741e-02
I0211 14:07:03.971926 22542570456896 run_lib.py:133] step: 748500, training_loss: 2.75583e-02
I0211 14:07:04.130784 22542570456896 run_lib.py:146] step: 748500, eval_loss: 2.83161e-02
I0211 14:07:21.610119 22542570456896 run_lib.py:133] step: 748550, training_loss: 2.91895e-02
I0211 14:07:39.101603 22542570456896 run_lib.py:133] step: 748600, training_loss: 2.50409e-02
I0211 14:07:39.254229 22542570456896 run_lib.py:146] step: 748600, eval_loss: 2.69576e-02
I0211 14:07:56.885573 22542570456896 run_lib.py:133] step: 748650, training_loss: 2.94320e-02
I0211 14:08:14.450312 22542570456896 run_lib.py:133] step: 748700, training_loss: 2.15665e-02
I0211 14:08:14.618740 22542570456896 run_lib.py:146] step: 748700, eval_loss: 2.69657e-02
I0211 14:08:32.302547 22542570456896 run_lib.py:133] step: 748750, training_loss: 2.36398e-02
I0211 14:08:49.796092 22542570456896 run_lib.py:133] step: 748800, training_loss: 2.37025e-02
I0211 14:08:49.954694 22542570456896 run_lib.py:146] step: 748800, eval_loss: 2.42239e-02
I0211 14:09:07.451275 22542570456896 run_lib.py:133] step: 748850, training_loss: 2.60533e-02
I0211 14:09:25.061470 22542570456896 run_lib.py:133] step: 748900, training_loss: 2.96311e-02
I0211 14:09:25.218538 22542570456896 run_lib.py:146] step: 748900, eval_loss: 2.78171e-02
I0211 14:09:42.719405 22542570456896 run_lib.py:133] step: 748950, training_loss: 2.40731e-02
I0211 14:10:00.284317 22542570456896 run_lib.py:133] step: 749000, training_loss: 2.27088e-02
I0211 14:10:00.445859 22542570456896 run_lib.py:146] step: 749000, eval_loss: 3.11212e-02
I0211 14:10:17.941039 22542570456896 run_lib.py:133] step: 749050, training_loss: 2.59353e-02
I0211 14:10:35.613204 22542570456896 run_lib.py:133] step: 749100, training_loss: 3.32306e-02
I0211 14:10:35.766478 22542570456896 run_lib.py:146] step: 749100, eval_loss: 2.63325e-02
I0211 14:10:53.252254 22542570456896 run_lib.py:133] step: 749150, training_loss: 2.75167e-02
I0211 14:11:10.809702 22542570456896 run_lib.py:133] step: 749200, training_loss: 2.62779e-02
I0211 14:11:10.973670 22542570456896 run_lib.py:146] step: 749200, eval_loss: 2.73555e-02
I0211 14:11:28.470005 22542570456896 run_lib.py:133] step: 749250, training_loss: 2.86998e-02
I0211 14:11:45.967160 22542570456896 run_lib.py:133] step: 749300, training_loss: 2.69238e-02
I0211 14:11:46.125403 22542570456896 run_lib.py:146] step: 749300, eval_loss: 2.50419e-02
I0211 14:12:03.786672 22542570456896 run_lib.py:133] step: 749350, training_loss: 3.04625e-02
I0211 14:12:21.345057 22542570456896 run_lib.py:133] step: 749400, training_loss: 2.79741e-02
I0211 14:12:21.523072 22542570456896 run_lib.py:146] step: 749400, eval_loss: 3.27072e-02
I0211 14:12:38.985770 22542570456896 run_lib.py:133] step: 749450, training_loss: 2.43357e-02
I0211 14:12:56.441754 22542570456896 run_lib.py:133] step: 749500, training_loss: 3.03914e-02
I0211 14:12:56.600671 22542570456896 run_lib.py:146] step: 749500, eval_loss: 3.13514e-02
I0211 14:13:14.285853 22542570456896 run_lib.py:133] step: 749550, training_loss: 2.69944e-02
I0211 14:13:31.810844 22542570456896 run_lib.py:133] step: 749600, training_loss: 2.23076e-02
I0211 14:13:31.963496 22542570456896 run_lib.py:146] step: 749600, eval_loss: 2.51410e-02
I0211 14:13:49.635606 22542570456896 run_lib.py:133] step: 749650, training_loss: 2.25076e-02
I0211 14:14:07.169018 22542570456896 run_lib.py:133] step: 749700, training_loss: 2.88602e-02
I0211 14:14:07.325704 22542570456896 run_lib.py:146] step: 749700, eval_loss: 2.53995e-02
I0211 14:14:24.930597 22542570456896 run_lib.py:133] step: 749750, training_loss: 2.72737e-02
I0211 14:14:42.434160 22542570456896 run_lib.py:133] step: 749800, training_loss: 2.54564e-02
I0211 14:14:42.602864 22542570456896 run_lib.py:146] step: 749800, eval_loss: 3.02954e-02
I0211 14:15:00.088705 22542570456896 run_lib.py:133] step: 749850, training_loss: 2.46382e-02
I0211 14:15:17.762785 22542570456896 run_lib.py:133] step: 749900, training_loss: 2.22051e-02
I0211 14:15:17.924598 22542570456896 run_lib.py:146] step: 749900, eval_loss: 2.89825e-02
I0211 14:15:35.415426 22542570456896 run_lib.py:133] step: 749950, training_loss: 3.52817e-02
I0211 14:15:53.036617 22542570456896 run_lib.py:133] step: 750000, training_loss: 2.35471e-02
I0211 14:15:53.796156 22542570456896 run_lib.py:146] step: 750000, eval_loss: 3.19553e-02
I0211 14:16:14.025463 22542570456896 run_lib.py:133] step: 750050, training_loss: 2.92065e-02
I0211 14:16:31.550035 22542570456896 run_lib.py:133] step: 750100, training_loss: 3.26130e-02
I0211 14:16:31.713150 22542570456896 run_lib.py:146] step: 750100, eval_loss: 2.92119e-02
I0211 14:16:49.224633 22542570456896 run_lib.py:133] step: 750150, training_loss: 2.72786e-02
I0211 14:17:06.736189 22542570456896 run_lib.py:133] step: 750200, training_loss: 2.72245e-02
I0211 14:17:06.899252 22542570456896 run_lib.py:146] step: 750200, eval_loss: 2.73718e-02
I0211 14:17:24.544853 22542570456896 run_lib.py:133] step: 750250, training_loss: 2.58886e-02
I0211 14:17:42.088709 22542570456896 run_lib.py:133] step: 750300, training_loss: 2.99326e-02
I0211 14:17:42.249285 22542570456896 run_lib.py:146] step: 750300, eval_loss: 2.86161e-02
I0211 14:17:59.766156 22542570456896 run_lib.py:133] step: 750350, training_loss: 2.97511e-02
I0211 14:18:17.326081 22542570456896 run_lib.py:133] step: 750400, training_loss: 2.87885e-02
I0211 14:18:17.491436 22542570456896 run_lib.py:146] step: 750400, eval_loss: 2.98049e-02
I0211 14:18:35.141861 22542570456896 run_lib.py:133] step: 750450, training_loss: 2.05058e-02
I0211 14:18:52.663470 22542570456896 run_lib.py:133] step: 750500, training_loss: 2.11926e-02
I0211 14:18:52.818402 22542570456896 run_lib.py:146] step: 750500, eval_loss: 2.93219e-02
I0211 14:19:10.464998 22542570456896 run_lib.py:133] step: 750550, training_loss: 3.22507e-02
I0211 14:19:27.926560 22542570456896 run_lib.py:133] step: 750600, training_loss: 2.71722e-02
I0211 14:19:28.087966 22542570456896 run_lib.py:146] step: 750600, eval_loss: 2.32975e-02
I0211 14:19:45.713539 22542570456896 run_lib.py:133] step: 750650, training_loss: 3.81213e-02
I0211 14:20:03.236312 22542570456896 run_lib.py:133] step: 750700, training_loss: 2.56768e-02
I0211 14:20:03.394971 22542570456896 run_lib.py:146] step: 750700, eval_loss: 2.68295e-02
I0211 14:20:21.140481 22542570456896 run_lib.py:133] step: 750750, training_loss: 2.58892e-02
I0211 14:20:38.612357 22542570456896 run_lib.py:133] step: 750800, training_loss: 2.47585e-02
I0211 14:20:38.771637 22542570456896 run_lib.py:146] step: 750800, eval_loss: 3.15514e-02
I0211 14:20:56.231598 22542570456896 run_lib.py:133] step: 750850, training_loss: 2.39996e-02
I0211 14:21:13.863416 22542570456896 run_lib.py:133] step: 750900, training_loss: 2.26224e-02
I0211 14:21:14.030377 22542570456896 run_lib.py:146] step: 750900, eval_loss: 3.16187e-02
I0211 14:21:31.564723 22542570456896 run_lib.py:133] step: 750950, training_loss: 2.91766e-02
I0211 14:21:49.060540 22542570456896 run_lib.py:133] step: 751000, training_loss: 2.88758e-02
I0211 14:21:49.233641 22542570456896 run_lib.py:146] step: 751000, eval_loss: 3.10003e-02
I0211 14:22:06.921959 22542570456896 run_lib.py:133] step: 751050, training_loss: 2.27411e-02
I0211 14:22:24.564646 22542570456896 run_lib.py:133] step: 751100, training_loss: 2.34718e-02
I0211 14:22:24.716279 22542570456896 run_lib.py:146] step: 751100, eval_loss: 2.80272e-02
I0211 14:22:42.209072 22542570456896 run_lib.py:133] step: 751150, training_loss: 2.37151e-02
I0211 14:22:59.717347 22542570456896 run_lib.py:133] step: 751200, training_loss: 2.62543e-02
I0211 14:22:59.894392 22542570456896 run_lib.py:146] step: 751200, eval_loss: 2.29022e-02
I0211 14:23:17.412363 22542570456896 run_lib.py:133] step: 751250, training_loss: 2.33955e-02
I0211 14:23:35.136997 22542570456896 run_lib.py:133] step: 751300, training_loss: 2.49048e-02
I0211 14:23:35.291663 22542570456896 run_lib.py:146] step: 751300, eval_loss: 2.44929e-02
I0211 14:23:52.774072 22542570456896 run_lib.py:133] step: 751350, training_loss: 3.03644e-02
I0211 14:24:10.263034 22542570456896 run_lib.py:133] step: 751400, training_loss: 2.24224e-02
I0211 14:24:10.420482 22542570456896 run_lib.py:146] step: 751400, eval_loss: 2.49693e-02
I0211 14:24:27.921267 22542570456896 run_lib.py:133] step: 751450, training_loss: 2.99057e-02
I0211 14:24:45.602037 22542570456896 run_lib.py:133] step: 751500, training_loss: 2.72861e-02
I0211 14:24:45.762930 22542570456896 run_lib.py:146] step: 751500, eval_loss: 2.99152e-02
I0211 14:25:03.284253 22542570456896 run_lib.py:133] step: 751550, training_loss: 2.49982e-02
I0211 14:25:20.853147 22542570456896 run_lib.py:133] step: 751600, training_loss: 2.50052e-02
I0211 14:25:21.111456 22542570456896 run_lib.py:146] step: 751600, eval_loss: 2.69432e-02
I0211 14:25:38.574005 22542570456896 run_lib.py:133] step: 751650, training_loss: 2.92209e-02
I0211 14:25:56.047860 22542570456896 run_lib.py:133] step: 751700, training_loss: 2.87352e-02
I0211 14:25:56.206965 22542570456896 run_lib.py:146] step: 751700, eval_loss: 2.23080e-02
I0211 14:26:13.875975 22542570456896 run_lib.py:133] step: 751750, training_loss: 2.89492e-02
I0211 14:26:31.487679 22542570456896 run_lib.py:133] step: 751800, training_loss: 2.70797e-02
I0211 14:26:31.643563 22542570456896 run_lib.py:146] step: 751800, eval_loss: 2.53024e-02
I0211 14:26:49.134472 22542570456896 run_lib.py:133] step: 751850, training_loss: 2.64665e-02
I0211 14:27:06.523910 22542570456896 run_lib.py:133] step: 751900, training_loss: 2.43197e-02
I0211 14:27:06.680410 22542570456896 run_lib.py:146] step: 751900, eval_loss: 2.93237e-02
I0211 14:27:24.222368 22542570456896 run_lib.py:133] step: 751950, training_loss: 2.69503e-02
I0211 14:27:41.538842 22542570456896 run_lib.py:133] step: 752000, training_loss: 2.40911e-02
I0211 14:27:41.690360 22542570456896 run_lib.py:146] step: 752000, eval_loss: 2.87498e-02
I0211 14:27:59.230992 22542570456896 run_lib.py:133] step: 752050, training_loss: 2.44403e-02
I0211 14:28:16.811557 22542570456896 run_lib.py:133] step: 752100, training_loss: 2.56734e-02
I0211 14:28:16.980598 22542570456896 run_lib.py:146] step: 752100, eval_loss: 2.39270e-02
I0211 14:28:34.736948 22542570456896 run_lib.py:133] step: 752150, training_loss: 2.22728e-02
I0211 14:28:52.271649 22542570456896 run_lib.py:133] step: 752200, training_loss: 3.23228e-02
I0211 14:28:52.431720 22542570456896 run_lib.py:146] step: 752200, eval_loss: 2.99797e-02
I0211 14:29:09.885839 22542570456896 run_lib.py:133] step: 752250, training_loss: 2.62342e-02
I0211 14:29:27.487340 22542570456896 run_lib.py:133] step: 752300, training_loss: 2.71339e-02
I0211 14:29:27.643439 22542570456896 run_lib.py:146] step: 752300, eval_loss: 2.69228e-02
I0211 14:29:45.173588 22542570456896 run_lib.py:133] step: 752350, training_loss: 2.97934e-02
I0211 14:30:02.869842 22542570456896 run_lib.py:133] step: 752400, training_loss: 2.50585e-02
I0211 14:30:03.027732 22542570456896 run_lib.py:146] step: 752400, eval_loss: 2.39876e-02
I0211 14:30:20.562642 22542570456896 run_lib.py:133] step: 752450, training_loss: 2.72895e-02
I0211 14:30:38.020961 22542570456896 run_lib.py:133] step: 752500, training_loss: 2.51114e-02
I0211 14:30:38.173325 22542570456896 run_lib.py:146] step: 752500, eval_loss: 2.75998e-02
I0211 14:30:55.800050 22542570456896 run_lib.py:133] step: 752550, training_loss: 2.59591e-02
I0211 14:31:13.345762 22542570456896 run_lib.py:133] step: 752600, training_loss: 2.52795e-02
I0211 14:31:13.525494 22542570456896 run_lib.py:146] step: 752600, eval_loss: 2.93742e-02
I0211 14:31:31.043974 22542570456896 run_lib.py:133] step: 752650, training_loss: 2.47653e-02
I0211 14:31:48.761655 22542570456896 run_lib.py:133] step: 752700, training_loss: 2.51114e-02
I0211 14:31:48.919300 22542570456896 run_lib.py:146] step: 752700, eval_loss: 2.31758e-02
I0211 14:32:06.407773 22542570456896 run_lib.py:133] step: 752750, training_loss: 2.86096e-02
I0211 14:32:23.895564 22542570456896 run_lib.py:133] step: 752800, training_loss: 2.57135e-02
I0211 14:32:24.053197 22542570456896 run_lib.py:146] step: 752800, eval_loss: 3.56311e-02
I0211 14:32:41.619365 22542570456896 run_lib.py:133] step: 752850, training_loss: 3.16152e-02
I0211 14:32:59.161222 22542570456896 run_lib.py:133] step: 752900, training_loss: 2.37303e-02
I0211 14:32:59.317126 22542570456896 run_lib.py:146] step: 752900, eval_loss: 3.31944e-02
I0211 14:33:16.861743 22542570456896 run_lib.py:133] step: 752950, training_loss: 2.70993e-02
I0211 14:33:34.324253 22542570456896 run_lib.py:133] step: 753000, training_loss: 3.08603e-02
I0211 14:33:34.476385 22542570456896 run_lib.py:146] step: 753000, eval_loss: 3.25082e-02
I0211 14:33:52.160160 22542570456896 run_lib.py:133] step: 753050, training_loss: 2.70493e-02
I0211 14:34:09.850960 22542570456896 run_lib.py:133] step: 753100, training_loss: 3.11843e-02
I0211 14:34:10.011738 22542570456896 run_lib.py:146] step: 753100, eval_loss: 2.88735e-02
I0211 14:34:27.486790 22542570456896 run_lib.py:133] step: 753150, training_loss: 2.31734e-02
I0211 14:34:45.007934 22542570456896 run_lib.py:133] step: 753200, training_loss: 2.61719e-02
I0211 14:34:45.164688 22542570456896 run_lib.py:146] step: 753200, eval_loss: 3.05472e-02
I0211 14:35:02.851500 22542570456896 run_lib.py:133] step: 753250, training_loss: 2.93078e-02
I0211 14:35:20.320337 22542570456896 run_lib.py:133] step: 753300, training_loss: 2.90079e-02
I0211 14:35:20.477222 22542570456896 run_lib.py:146] step: 753300, eval_loss: 2.60109e-02
I0211 14:35:38.117500 22542570456896 run_lib.py:133] step: 753350, training_loss: 2.44769e-02
I0211 14:35:55.591765 22542570456896 run_lib.py:133] step: 753400, training_loss: 2.34782e-02
I0211 14:35:55.744127 22542570456896 run_lib.py:146] step: 753400, eval_loss: 2.49611e-02
I0211 14:36:13.375846 22542570456896 run_lib.py:133] step: 753450, training_loss: 2.40688e-02
I0211 14:36:30.896770 22542570456896 run_lib.py:133] step: 753500, training_loss: 3.61805e-02
I0211 14:36:31.065566 22542570456896 run_lib.py:146] step: 753500, eval_loss: 3.19689e-02
I0211 14:36:48.748425 22542570456896 run_lib.py:133] step: 753550, training_loss: 2.30987e-02
I0211 14:37:06.222365 22542570456896 run_lib.py:133] step: 753600, training_loss: 2.64242e-02
I0211 14:37:06.384611 22542570456896 run_lib.py:146] step: 753600, eval_loss: 2.05067e-02
I0211 14:37:23.816401 22542570456896 run_lib.py:133] step: 753650, training_loss: 2.83585e-02
I0211 14:37:41.408408 22542570456896 run_lib.py:133] step: 753700, training_loss: 2.36550e-02
I0211 14:37:41.564427 22542570456896 run_lib.py:146] step: 753700, eval_loss: 3.36566e-02
I0211 14:37:59.003004 22542570456896 run_lib.py:133] step: 753750, training_loss: 2.40875e-02
I0211 14:38:16.518460 22542570456896 run_lib.py:133] step: 753800, training_loss: 2.75012e-02
I0211 14:38:16.675675 22542570456896 run_lib.py:146] step: 753800, eval_loss: 2.62051e-02
I0211 14:38:34.338011 22542570456896 run_lib.py:133] step: 753850, training_loss: 2.46105e-02
I0211 14:38:51.799890 22542570456896 run_lib.py:133] step: 753900, training_loss: 2.91067e-02
I0211 14:38:51.955340 22542570456896 run_lib.py:146] step: 753900, eval_loss: 2.88448e-02
I0211 14:39:09.568582 22542570456896 run_lib.py:133] step: 753950, training_loss: 2.29944e-02
I0211 14:39:27.044516 22542570456896 run_lib.py:133] step: 754000, training_loss: 2.31785e-02
I0211 14:39:27.201587 22542570456896 run_lib.py:146] step: 754000, eval_loss: 3.74588e-02
I0211 14:39:44.711964 22542570456896 run_lib.py:133] step: 754050, training_loss: 3.08772e-02
I0211 14:40:02.433503 22542570456896 run_lib.py:133] step: 754100, training_loss: 2.95848e-02
I0211 14:40:02.598301 22542570456896 run_lib.py:146] step: 754100, eval_loss: 2.66002e-02
I0211 14:40:20.044975 22542570456896 run_lib.py:133] step: 754150, training_loss: 2.61315e-02
I0211 14:40:37.510668 22542570456896 run_lib.py:133] step: 754200, training_loss: 2.97681e-02
I0211 14:40:37.680475 22542570456896 run_lib.py:146] step: 754200, eval_loss: 3.04329e-02
I0211 14:40:55.120613 22542570456896 run_lib.py:133] step: 754250, training_loss: 2.73436e-02
I0211 14:41:12.721927 22542570456896 run_lib.py:133] step: 754300, training_loss: 2.93991e-02
I0211 14:41:12.880882 22542570456896 run_lib.py:146] step: 754300, eval_loss: 2.92211e-02
I0211 14:41:30.327997 22542570456896 run_lib.py:133] step: 754350, training_loss: 3.12633e-02
I0211 14:41:47.878365 22542570456896 run_lib.py:133] step: 754400, training_loss: 2.80990e-02
I0211 14:41:48.030687 22542570456896 run_lib.py:146] step: 754400, eval_loss: 2.75960e-02
I0211 14:42:05.585692 22542570456896 run_lib.py:133] step: 754450, training_loss: 3.38465e-02
I0211 14:42:23.065238 22542570456896 run_lib.py:133] step: 754500, training_loss: 3.08376e-02
I0211 14:42:23.223478 22542570456896 run_lib.py:146] step: 754500, eval_loss: 3.34124e-02
I0211 14:42:40.875458 22542570456896 run_lib.py:133] step: 754550, training_loss: 2.85150e-02
I0211 14:42:58.400964 22542570456896 run_lib.py:133] step: 754600, training_loss: 2.52373e-02
I0211 14:42:58.570413 22542570456896 run_lib.py:146] step: 754600, eval_loss: 2.80587e-02
I0211 14:43:16.089174 22542570456896 run_lib.py:133] step: 754650, training_loss: 3.14283e-02
I0211 14:43:33.546585 22542570456896 run_lib.py:133] step: 754700, training_loss: 2.27161e-02
I0211 14:43:33.703645 22542570456896 run_lib.py:146] step: 754700, eval_loss: 2.18468e-02
I0211 14:43:51.379317 22542570456896 run_lib.py:133] step: 754750, training_loss: 2.26364e-02
I0211 14:44:08.861037 22542570456896 run_lib.py:133] step: 754800, training_loss: 2.60244e-02
I0211 14:44:09.013925 22542570456896 run_lib.py:146] step: 754800, eval_loss: 3.06429e-02
I0211 14:44:26.629364 22542570456896 run_lib.py:133] step: 754850, training_loss: 3.42138e-02
I0211 14:44:44.121717 22542570456896 run_lib.py:133] step: 754900, training_loss: 2.93550e-02
I0211 14:44:44.287375 22542570456896 run_lib.py:146] step: 754900, eval_loss: 3.08372e-02
I0211 14:45:02.007643 22542570456896 run_lib.py:133] step: 754950, training_loss: 2.56258e-02
I0211 14:45:19.522991 22542570456896 run_lib.py:133] step: 755000, training_loss: 2.74152e-02
I0211 14:45:19.681399 22542570456896 run_lib.py:146] step: 755000, eval_loss: 2.17991e-02
I0211 14:45:37.169688 22542570456896 run_lib.py:133] step: 755050, training_loss: 2.89533e-02
I0211 14:45:54.760149 22542570456896 run_lib.py:133] step: 755100, training_loss: 2.61487e-02
I0211 14:45:54.915561 22542570456896 run_lib.py:146] step: 755100, eval_loss: 3.24228e-02
I0211 14:46:12.422682 22542570456896 run_lib.py:133] step: 755150, training_loss: 2.69890e-02
I0211 14:46:30.098605 22542570456896 run_lib.py:133] step: 755200, training_loss: 2.50988e-02
I0211 14:46:30.257206 22542570456896 run_lib.py:146] step: 755200, eval_loss: 2.13552e-02
I0211 14:46:47.775555 22542570456896 run_lib.py:133] step: 755250, training_loss: 2.83032e-02
I0211 14:47:05.240127 22542570456896 run_lib.py:133] step: 755300, training_loss: 2.28497e-02
I0211 14:47:05.393457 22542570456896 run_lib.py:146] step: 755300, eval_loss: 2.34586e-02
I0211 14:47:23.046614 22542570456896 run_lib.py:133] step: 755350, training_loss: 2.13757e-02
I0211 14:47:40.547116 22542570456896 run_lib.py:133] step: 755400, training_loss: 3.15912e-02
I0211 14:47:40.723533 22542570456896 run_lib.py:146] step: 755400, eval_loss: 3.10962e-02
I0211 14:47:58.282338 22542570456896 run_lib.py:133] step: 755450, training_loss: 2.57158e-02
I0211 14:48:15.989255 22542570456896 run_lib.py:133] step: 755500, training_loss: 3.14210e-02
I0211 14:48:16.148549 22542570456896 run_lib.py:146] step: 755500, eval_loss: 3.08125e-02
I0211 14:48:33.605576 22542570456896 run_lib.py:133] step: 755550, training_loss: 2.91387e-02
I0211 14:48:51.046401 22542570456896 run_lib.py:133] step: 755600, training_loss: 3.77615e-02
I0211 14:48:51.378848 22542570456896 run_lib.py:146] step: 755600, eval_loss: 2.76481e-02
I0211 14:49:08.890761 22542570456896 run_lib.py:133] step: 755650, training_loss: 2.95532e-02
I0211 14:49:26.389265 22542570456896 run_lib.py:133] step: 755700, training_loss: 2.66861e-02
I0211 14:49:26.544733 22542570456896 run_lib.py:146] step: 755700, eval_loss: 2.77571e-02
I0211 14:49:44.122417 22542570456896 run_lib.py:133] step: 755750, training_loss: 3.29818e-02
I0211 14:50:01.585891 22542570456896 run_lib.py:133] step: 755800, training_loss: 2.31243e-02
I0211 14:50:01.738380 22542570456896 run_lib.py:146] step: 755800, eval_loss: 2.87737e-02
I0211 14:50:19.424184 22542570456896 run_lib.py:133] step: 755850, training_loss: 3.00802e-02
I0211 14:50:37.030760 22542570456896 run_lib.py:133] step: 755900, training_loss: 2.44095e-02
I0211 14:50:37.187486 22542570456896 run_lib.py:146] step: 755900, eval_loss: 3.60385e-02
I0211 14:50:54.627130 22542570456896 run_lib.py:133] step: 755950, training_loss: 2.90443e-02
I0211 14:51:12.118387 22542570456896 run_lib.py:133] step: 756000, training_loss: 2.69604e-02
I0211 14:51:12.300477 22542570456896 run_lib.py:146] step: 756000, eval_loss: 3.81644e-02
I0211 14:51:29.995989 22542570456896 run_lib.py:133] step: 756050, training_loss: 2.63348e-02
I0211 14:51:47.547697 22542570456896 run_lib.py:133] step: 756100, training_loss: 2.73720e-02
I0211 14:51:47.703553 22542570456896 run_lib.py:146] step: 756100, eval_loss: 2.68695e-02
I0211 14:52:05.146261 22542570456896 run_lib.py:133] step: 756150, training_loss: 2.90462e-02
I0211 14:52:22.557399 22542570456896 run_lib.py:133] step: 756200, training_loss: 2.23471e-02
I0211 14:52:22.711385 22542570456896 run_lib.py:146] step: 756200, eval_loss: 2.86442e-02
I0211 14:52:40.319246 22542570456896 run_lib.py:133] step: 756250, training_loss: 2.43252e-02
I0211 14:52:57.822498 22542570456896 run_lib.py:133] step: 756300, training_loss: 2.77825e-02
I0211 14:52:57.980675 22542570456896 run_lib.py:146] step: 756300, eval_loss: 2.50299e-02
I0211 14:53:15.682486 22542570456896 run_lib.py:133] step: 756350, training_loss: 2.22648e-02
I0211 14:53:33.144561 22542570456896 run_lib.py:133] step: 756400, training_loss: 3.31125e-02
I0211 14:53:33.302574 22542570456896 run_lib.py:146] step: 756400, eval_loss: 2.64247e-02
I0211 14:53:50.926938 22542570456896 run_lib.py:133] step: 756450, training_loss: 2.31978e-02
I0211 14:54:08.390432 22542570456896 run_lib.py:133] step: 756500, training_loss: 2.06426e-02
I0211 14:54:08.560473 22542570456896 run_lib.py:146] step: 756500, eval_loss: 3.01502e-02
I0211 14:54:26.060484 22542570456896 run_lib.py:133] step: 756550, training_loss: 2.92833e-02
I0211 14:54:43.781358 22542570456896 run_lib.py:133] step: 756600, training_loss: 2.66476e-02
I0211 14:54:43.941539 22542570456896 run_lib.py:146] step: 756600, eval_loss: 3.81510e-02
I0211 14:55:01.413739 22542570456896 run_lib.py:133] step: 756650, training_loss: 2.63963e-02
I0211 14:55:19.018247 22542570456896 run_lib.py:133] step: 756700, training_loss: 2.91518e-02
I0211 14:55:19.173284 22542570456896 run_lib.py:146] step: 756700, eval_loss: 2.79506e-02
I0211 14:55:36.631498 22542570456896 run_lib.py:133] step: 756750, training_loss: 3.62019e-02
I0211 14:55:54.077444 22542570456896 run_lib.py:133] step: 756800, training_loss: 2.62573e-02
I0211 14:55:54.233757 22542570456896 run_lib.py:146] step: 756800, eval_loss: 3.72628e-02
I0211 14:56:11.908121 22542570456896 run_lib.py:133] step: 756850, training_loss: 2.42872e-02
I0211 14:56:29.464792 22542570456896 run_lib.py:133] step: 756900, training_loss: 2.29529e-02
I0211 14:56:29.624932 22542570456896 run_lib.py:146] step: 756900, eval_loss: 2.34887e-02
I0211 14:56:47.103474 22542570456896 run_lib.py:133] step: 756950, training_loss: 2.45281e-02
I0211 14:57:04.550349 22542570456896 run_lib.py:133] step: 757000, training_loss: 3.02968e-02
I0211 14:57:04.704371 22542570456896 run_lib.py:146] step: 757000, eval_loss: 3.54267e-02
I0211 14:57:22.362629 22542570456896 run_lib.py:133] step: 757050, training_loss: 2.82716e-02
I0211 14:57:39.835184 22542570456896 run_lib.py:133] step: 757100, training_loss: 2.76439e-02
I0211 14:57:39.992649 22542570456896 run_lib.py:146] step: 757100, eval_loss: 2.35593e-02
I0211 14:57:57.533813 22542570456896 run_lib.py:133] step: 757150, training_loss: 2.87095e-02
I0211 14:58:15.047644 22542570456896 run_lib.py:133] step: 757200, training_loss: 2.69227e-02
I0211 14:58:15.199335 22542570456896 run_lib.py:146] step: 757200, eval_loss: 2.43836e-02
I0211 14:58:32.659293 22542570456896 run_lib.py:133] step: 757250, training_loss: 3.01889e-02
I0211 14:58:50.206361 22542570456896 run_lib.py:133] step: 757300, training_loss: 2.33100e-02
I0211 14:58:50.361776 22542570456896 run_lib.py:146] step: 757300, eval_loss: 2.31370e-02
I0211 14:59:08.006725 22542570456896 run_lib.py:133] step: 757350, training_loss: 2.86820e-02
I0211 14:59:25.582546 22542570456896 run_lib.py:133] step: 757400, training_loss: 2.42580e-02
I0211 14:59:25.758639 22542570456896 run_lib.py:146] step: 757400, eval_loss: 2.76344e-02
I0211 14:59:43.335067 22542570456896 run_lib.py:133] step: 757450, training_loss: 2.12585e-02
I0211 15:00:00.862032 22542570456896 run_lib.py:133] step: 757500, training_loss: 2.71506e-02
I0211 15:00:01.020607 22542570456896 run_lib.py:146] step: 757500, eval_loss: 2.50473e-02
I0211 15:00:18.689148 22542570456896 run_lib.py:133] step: 757550, training_loss: 2.90568e-02
I0211 15:00:36.157854 22542570456896 run_lib.py:133] step: 757600, training_loss: 1.93150e-02
I0211 15:00:36.313117 22542570456896 run_lib.py:146] step: 757600, eval_loss: 3.03812e-02
I0211 15:00:53.952955 22542570456896 run_lib.py:133] step: 757650, training_loss: 2.48545e-02
I0211 15:01:11.443379 22542570456896 run_lib.py:133] step: 757700, training_loss: 2.70713e-02
I0211 15:01:11.597643 22542570456896 run_lib.py:146] step: 757700, eval_loss: 4.03336e-02
I0211 15:01:29.291991 22542570456896 run_lib.py:133] step: 757750, training_loss: 2.69269e-02
I0211 15:01:46.795088 22542570456896 run_lib.py:133] step: 757800, training_loss: 2.68027e-02
I0211 15:01:46.954568 22542570456896 run_lib.py:146] step: 757800, eval_loss: 2.22238e-02
I0211 15:02:04.538398 22542570456896 run_lib.py:133] step: 757850, training_loss: 2.86819e-02
I0211 15:02:22.020408 22542570456896 run_lib.py:133] step: 757900, training_loss: 2.55121e-02
I0211 15:02:22.189236 22542570456896 run_lib.py:146] step: 757900, eval_loss: 2.73070e-02
I0211 15:02:39.709512 22542570456896 run_lib.py:133] step: 757950, training_loss: 3.24077e-02
I0211 15:02:57.377711 22542570456896 run_lib.py:133] step: 758000, training_loss: 2.59123e-02
I0211 15:02:57.533503 22542570456896 run_lib.py:146] step: 758000, eval_loss: 3.30816e-02
I0211 15:03:15.010986 22542570456896 run_lib.py:133] step: 758050, training_loss: 2.51811e-02
I0211 15:03:32.468090 22542570456896 run_lib.py:133] step: 758100, training_loss: 3.29872e-02
I0211 15:03:32.622313 22542570456896 run_lib.py:146] step: 758100, eval_loss: 2.96186e-02
I0211 15:03:50.261195 22542570456896 run_lib.py:133] step: 758150, training_loss: 2.58862e-02
I0211 15:04:07.888598 22542570456896 run_lib.py:133] step: 758200, training_loss: 2.67550e-02
I0211 15:04:08.043709 22542570456896 run_lib.py:146] step: 758200, eval_loss: 2.83936e-02
I0211 15:04:25.562418 22542570456896 run_lib.py:133] step: 758250, training_loss: 3.10403e-02
I0211 15:04:43.036534 22542570456896 run_lib.py:133] step: 758300, training_loss: 3.28460e-02
I0211 15:04:43.195493 22542570456896 run_lib.py:146] step: 758300, eval_loss: 2.65577e-02
I0211 15:05:00.663676 22542570456896 run_lib.py:133] step: 758350, training_loss: 2.76130e-02
I0211 15:05:18.344817 22542570456896 run_lib.py:133] step: 758400, training_loss: 2.87777e-02
I0211 15:05:18.501570 22542570456896 run_lib.py:146] step: 758400, eval_loss: 3.11769e-02
I0211 15:05:36.006854 22542570456896 run_lib.py:133] step: 758450, training_loss: 2.48468e-02
I0211 15:05:53.487443 22542570456896 run_lib.py:133] step: 758500, training_loss: 2.49065e-02
I0211 15:05:53.654492 22542570456896 run_lib.py:146] step: 758500, eval_loss: 2.89375e-02
I0211 15:06:11.156183 22542570456896 run_lib.py:133] step: 758550, training_loss: 2.58371e-02
I0211 15:06:28.879884 22542570456896 run_lib.py:133] step: 758600, training_loss: 2.17710e-02
I0211 15:06:29.032139 22542570456896 run_lib.py:146] step: 758600, eval_loss: 2.50502e-02
I0211 15:06:46.511919 22542570456896 run_lib.py:133] step: 758650, training_loss: 2.89821e-02
I0211 15:07:04.032915 22542570456896 run_lib.py:133] step: 758700, training_loss: 2.03778e-02
I0211 15:07:04.185044 22542570456896 run_lib.py:146] step: 758700, eval_loss: 2.67780e-02
I0211 15:07:21.649411 22542570456896 run_lib.py:133] step: 758750, training_loss: 2.21574e-02
I0211 15:07:39.144067 22542570456896 run_lib.py:133] step: 758800, training_loss: 2.69716e-02
I0211 15:07:39.321645 22542570456896 run_lib.py:146] step: 758800, eval_loss: 3.17713e-02
I0211 15:07:57.027410 22542570456896 run_lib.py:133] step: 758850, training_loss: 2.06787e-02
I0211 15:08:14.552083 22542570456896 run_lib.py:133] step: 758900, training_loss: 2.98689e-02
I0211 15:08:14.715845 22542570456896 run_lib.py:146] step: 758900, eval_loss: 2.90439e-02
I0211 15:08:32.222033 22542570456896 run_lib.py:133] step: 758950, training_loss: 2.71274e-02
I0211 15:08:49.698956 22542570456896 run_lib.py:133] step: 759000, training_loss: 2.88152e-02
I0211 15:08:49.855156 22542570456896 run_lib.py:146] step: 759000, eval_loss: 3.04250e-02
I0211 15:09:07.446641 22542570456896 run_lib.py:133] step: 759050, training_loss: 2.57143e-02
I0211 15:09:24.922767 22542570456896 run_lib.py:133] step: 759100, training_loss: 2.88157e-02
I0211 15:09:25.076757 22542570456896 run_lib.py:146] step: 759100, eval_loss: 2.84334e-02
I0211 15:09:42.778024 22542570456896 run_lib.py:133] step: 759150, training_loss: 2.39899e-02
I0211 15:10:00.265262 22542570456896 run_lib.py:133] step: 759200, training_loss: 2.78452e-02
I0211 15:10:00.421357 22542570456896 run_lib.py:146] step: 759200, eval_loss: 2.81594e-02
I0211 15:10:18.057651 22542570456896 run_lib.py:133] step: 759250, training_loss: 2.49364e-02
I0211 15:10:35.503271 22542570456896 run_lib.py:133] step: 759300, training_loss: 2.65343e-02
I0211 15:10:35.666657 22542570456896 run_lib.py:146] step: 759300, eval_loss: 3.03777e-02
I0211 15:10:53.182311 22542570456896 run_lib.py:133] step: 759350, training_loss: 2.63272e-02
I0211 15:11:10.866916 22542570456896 run_lib.py:133] step: 759400, training_loss: 3.23019e-02
I0211 15:11:11.024378 22542570456896 run_lib.py:146] step: 759400, eval_loss: 2.70308e-02
I0211 15:11:28.478741 22542570456896 run_lib.py:133] step: 759450, training_loss: 2.58108e-02
I0211 15:11:46.133641 22542570456896 run_lib.py:133] step: 759500, training_loss: 2.90837e-02
I0211 15:11:46.290431 22542570456896 run_lib.py:146] step: 759500, eval_loss: 2.44026e-02
I0211 15:12:03.749659 22542570456896 run_lib.py:133] step: 759550, training_loss: 2.58542e-02
I0211 15:12:21.188981 22542570456896 run_lib.py:133] step: 759600, training_loss: 3.03807e-02
I0211 15:12:21.341601 22542570456896 run_lib.py:146] step: 759600, eval_loss: 2.85545e-02
I0211 15:12:38.984461 22542570456896 run_lib.py:133] step: 759650, training_loss: 2.85520e-02
I0211 15:12:56.472283 22542570456896 run_lib.py:133] step: 759700, training_loss: 2.15364e-02
I0211 15:12:56.635767 22542570456896 run_lib.py:146] step: 759700, eval_loss: 3.06545e-02
I0211 15:13:14.157232 22542570456896 run_lib.py:133] step: 759750, training_loss: 3.04840e-02
I0211 15:13:31.811610 22542570456896 run_lib.py:133] step: 759800, training_loss: 2.35009e-02
I0211 15:13:31.970551 22542570456896 run_lib.py:146] step: 759800, eval_loss: 2.70902e-02
I0211 15:13:49.460922 22542570456896 run_lib.py:133] step: 759850, training_loss: 2.43277e-02
I0211 15:14:06.922966 22542570456896 run_lib.py:133] step: 759900, training_loss: 2.53910e-02
I0211 15:14:07.084320 22542570456896 run_lib.py:146] step: 759900, eval_loss: 3.08248e-02
I0211 15:14:24.654209 22542570456896 run_lib.py:133] step: 759950, training_loss: 2.20695e-02
I0211 15:14:42.114140 22542570456896 run_lib.py:133] step: 760000, training_loss: 2.46509e-02
I0211 15:14:42.879102 22542570456896 run_lib.py:146] step: 760000, eval_loss: 3.82684e-02
I0211 15:15:03.146281 22542570456896 run_lib.py:133] step: 760050, training_loss: 2.40412e-02
I0211 15:15:20.597912 22542570456896 run_lib.py:133] step: 760100, training_loss: 2.80494e-02
I0211 15:15:20.755217 22542570456896 run_lib.py:146] step: 760100, eval_loss: 2.99066e-02
I0211 15:15:38.404211 22542570456896 run_lib.py:133] step: 760150, training_loss: 2.88783e-02
I0211 15:15:55.912488 22542570456896 run_lib.py:133] step: 760200, training_loss: 2.17794e-02
I0211 15:15:56.077668 22542570456896 run_lib.py:146] step: 760200, eval_loss: 2.96749e-02
I0211 15:16:13.728148 22542570456896 run_lib.py:133] step: 760250, training_loss: 2.45335e-02
I0211 15:16:31.215392 22542570456896 run_lib.py:133] step: 760300, training_loss: 2.52916e-02
I0211 15:16:31.373419 22542570456896 run_lib.py:146] step: 760300, eval_loss: 3.06255e-02
I0211 15:16:48.836195 22542570456896 run_lib.py:133] step: 760350, training_loss: 2.36500e-02
I0211 15:17:06.293517 22542570456896 run_lib.py:133] step: 760400, training_loss: 2.91119e-02
I0211 15:17:06.457129 22542570456896 run_lib.py:146] step: 760400, eval_loss: 3.93845e-02
I0211 15:17:24.061033 22542570456896 run_lib.py:133] step: 760450, training_loss: 2.13019e-02
I0211 15:17:41.676113 22542570456896 run_lib.py:133] step: 760500, training_loss: 2.81352e-02
I0211 15:17:41.834180 22542570456896 run_lib.py:146] step: 760500, eval_loss: 2.87243e-02
I0211 15:17:59.342894 22542570456896 run_lib.py:133] step: 760550, training_loss: 2.58189e-02
I0211 15:18:16.818868 22542570456896 run_lib.py:133] step: 760600, training_loss: 2.46900e-02
I0211 15:18:16.971597 22542570456896 run_lib.py:146] step: 760600, eval_loss: 2.42747e-02
I0211 15:18:34.608664 22542570456896 run_lib.py:133] step: 760650, training_loss: 2.45684e-02
I0211 15:18:52.139215 22542570456896 run_lib.py:133] step: 760700, training_loss: 2.12890e-02
I0211 15:18:52.308692 22542570456896 run_lib.py:146] step: 760700, eval_loss: 2.59093e-02
I0211 15:19:09.989280 22542570456896 run_lib.py:133] step: 760750, training_loss: 2.59884e-02
I0211 15:19:27.514880 22542570456896 run_lib.py:133] step: 760800, training_loss: 2.15188e-02
I0211 15:19:27.672290 22542570456896 run_lib.py:146] step: 760800, eval_loss: 3.10558e-02
I0211 15:19:45.322852 22542570456896 run_lib.py:133] step: 760850, training_loss: 3.18127e-02
I0211 15:20:02.822471 22542570456896 run_lib.py:133] step: 760900, training_loss: 2.65570e-02
I0211 15:20:02.979442 22542570456896 run_lib.py:146] step: 760900, eval_loss: 2.88192e-02
I0211 15:20:20.610269 22542570456896 run_lib.py:133] step: 760950, training_loss: 2.37300e-02
I0211 15:20:38.117049 22542570456896 run_lib.py:133] step: 761000, training_loss: 3.24367e-02
I0211 15:20:38.275726 22542570456896 run_lib.py:146] step: 761000, eval_loss: 2.65192e-02
I0211 15:20:55.768008 22542570456896 run_lib.py:133] step: 761050, training_loss: 2.83027e-02
I0211 15:21:13.415748 22542570456896 run_lib.py:133] step: 761100, training_loss: 2.62741e-02
I0211 15:21:13.568371 22542570456896 run_lib.py:146] step: 761100, eval_loss: 2.58848e-02
I0211 15:21:31.022615 22542570456896 run_lib.py:133] step: 761150, training_loss: 2.87455e-02
I0211 15:21:48.504755 22542570456896 run_lib.py:133] step: 761200, training_loss: 3.30853e-02
I0211 15:21:48.659442 22542570456896 run_lib.py:146] step: 761200, eval_loss: 2.91067e-02
I0211 15:22:06.292815 22542570456896 run_lib.py:133] step: 761250, training_loss: 3.07140e-02
I0211 15:22:23.910435 22542570456896 run_lib.py:133] step: 761300, training_loss: 3.14864e-02
I0211 15:22:24.077632 22542570456896 run_lib.py:146] step: 761300, eval_loss: 2.35310e-02
I0211 15:22:41.737392 22542570456896 run_lib.py:133] step: 761350, training_loss: 3.06343e-02
I0211 15:22:59.206324 22542570456896 run_lib.py:133] step: 761400, training_loss: 2.61459e-02
I0211 15:22:59.366200 22542570456896 run_lib.py:146] step: 761400, eval_loss: 2.93847e-02
I0211 15:23:16.831578 22542570456896 run_lib.py:133] step: 761450, training_loss: 3.01414e-02
I0211 15:23:34.465610 22542570456896 run_lib.py:133] step: 761500, training_loss: 2.56306e-02
I0211 15:23:34.622567 22542570456896 run_lib.py:146] step: 761500, eval_loss: 3.41400e-02
I0211 15:23:52.102470 22542570456896 run_lib.py:133] step: 761550, training_loss: 3.10544e-02
I0211 15:24:09.614685 22542570456896 run_lib.py:133] step: 761600, training_loss: 2.54536e-02
I0211 15:24:09.769459 22542570456896 run_lib.py:146] step: 761600, eval_loss: 2.50190e-02
I0211 15:24:27.266088 22542570456896 run_lib.py:133] step: 761650, training_loss: 2.25641e-02
I0211 15:24:44.915160 22542570456896 run_lib.py:133] step: 761700, training_loss: 3.17838e-02
I0211 15:24:45.075235 22542570456896 run_lib.py:146] step: 761700, eval_loss: 2.58866e-02
I0211 15:25:02.530709 22542570456896 run_lib.py:133] step: 761750, training_loss: 2.38977e-02
I0211 15:25:20.039362 22542570456896 run_lib.py:133] step: 761800, training_loss: 2.34066e-02
I0211 15:25:20.194383 22542570456896 run_lib.py:146] step: 761800, eval_loss: 2.48462e-02
I0211 15:25:37.692383 22542570456896 run_lib.py:133] step: 761850, training_loss: 2.54732e-02
I0211 15:25:55.245230 22542570456896 run_lib.py:133] step: 761900, training_loss: 2.77237e-02
I0211 15:25:55.401845 22542570456896 run_lib.py:146] step: 761900, eval_loss: 2.54403e-02
I0211 15:26:13.060428 22542570456896 run_lib.py:133] step: 761950, training_loss: 3.94181e-02
I0211 15:26:30.628512 22542570456896 run_lib.py:133] step: 762000, training_loss: 2.22580e-02
I0211 15:26:30.779397 22542570456896 run_lib.py:146] step: 762000, eval_loss: 2.61295e-02
I0211 15:26:48.247224 22542570456896 run_lib.py:133] step: 762050, training_loss: 3.06197e-02
I0211 15:27:05.732368 22542570456896 run_lib.py:133] step: 762100, training_loss: 3.01766e-02
I0211 15:27:05.896349 22542570456896 run_lib.py:146] step: 762100, eval_loss: 3.33827e-02
I0211 15:27:23.577866 22542570456896 run_lib.py:133] step: 762150, training_loss: 2.75151e-02
I0211 15:27:41.069982 22542570456896 run_lib.py:133] step: 762200, training_loss: 2.71598e-02
I0211 15:27:41.229935 22542570456896 run_lib.py:146] step: 762200, eval_loss: 2.82253e-02
I0211 15:27:58.878843 22542570456896 run_lib.py:133] step: 762250, training_loss: 2.53414e-02
I0211 15:28:16.327125 22542570456896 run_lib.py:133] step: 762300, training_loss: 2.33461e-02
I0211 15:28:16.484537 22542570456896 run_lib.py:146] step: 762300, eval_loss: 2.57674e-02
I0211 15:28:34.126459 22542570456896 run_lib.py:133] step: 762350, training_loss: 3.19552e-02
I0211 15:28:51.552891 22542570456896 run_lib.py:133] step: 762400, training_loss: 2.47526e-02
I0211 15:28:51.720567 22542570456896 run_lib.py:146] step: 762400, eval_loss: 2.72462e-02
I0211 15:29:09.249247 22542570456896 run_lib.py:133] step: 762450, training_loss: 2.52665e-02
I0211 15:29:26.959893 22542570456896 run_lib.py:133] step: 762500, training_loss: 2.43534e-02
I0211 15:29:27.112565 22542570456896 run_lib.py:146] step: 762500, eval_loss: 3.30160e-02
I0211 15:29:44.590616 22542570456896 run_lib.py:133] step: 762550, training_loss: 2.73298e-02
I0211 15:30:02.203023 22542570456896 run_lib.py:133] step: 762600, training_loss: 2.78941e-02
I0211 15:30:02.359386 22542570456896 run_lib.py:146] step: 762600, eval_loss: 2.62885e-02
I0211 15:30:19.803400 22542570456896 run_lib.py:133] step: 762650, training_loss: 2.51039e-02
I0211 15:30:37.318007 22542570456896 run_lib.py:133] step: 762700, training_loss: 2.24314e-02
I0211 15:30:37.496455 22542570456896 run_lib.py:146] step: 762700, eval_loss: 2.87953e-02
I0211 15:30:55.182482 22542570456896 run_lib.py:133] step: 762750, training_loss: 2.64816e-02
I0211 15:31:12.672946 22542570456896 run_lib.py:133] step: 762800, training_loss: 2.80616e-02
I0211 15:31:12.830011 22542570456896 run_lib.py:146] step: 762800, eval_loss: 2.44609e-02
I0211 15:31:30.370659 22542570456896 run_lib.py:133] step: 762850, training_loss: 2.82131e-02
I0211 15:31:48.020277 22542570456896 run_lib.py:133] step: 762900, training_loss: 2.70241e-02
I0211 15:31:48.176432 22542570456896 run_lib.py:146] step: 762900, eval_loss: 3.11153e-02
I0211 15:32:05.644489 22542570456896 run_lib.py:133] step: 762950, training_loss: 3.47712e-02
I0211 15:32:23.167774 22542570456896 run_lib.py:133] step: 763000, training_loss: 2.25016e-02
I0211 15:32:23.492588 22542570456896 run_lib.py:146] step: 763000, eval_loss: 3.25828e-02
I0211 15:32:41.010669 22542570456896 run_lib.py:133] step: 763050, training_loss: 2.47009e-02
I0211 15:32:58.511357 22542570456896 run_lib.py:133] step: 763100, training_loss: 2.57247e-02
I0211 15:32:58.676775 22542570456896 run_lib.py:146] step: 763100, eval_loss: 3.48344e-02
I0211 15:33:16.165707 22542570456896 run_lib.py:133] step: 763150, training_loss: 2.66552e-02
I0211 15:33:33.643719 22542570456896 run_lib.py:133] step: 763200, training_loss: 2.63784e-02
I0211 15:33:33.801911 22542570456896 run_lib.py:146] step: 763200, eval_loss: 3.03584e-02
I0211 15:33:51.495976 22542570456896 run_lib.py:133] step: 763250, training_loss: 2.58801e-02
I0211 15:34:09.117724 22542570456896 run_lib.py:133] step: 763300, training_loss: 2.44308e-02
I0211 15:34:09.271074 22542570456896 run_lib.py:146] step: 763300, eval_loss: 2.71892e-02
I0211 15:34:26.718100 22542570456896 run_lib.py:133] step: 763350, training_loss: 3.39832e-02
I0211 15:34:44.167901 22542570456896 run_lib.py:133] step: 763400, training_loss: 2.57237e-02
I0211 15:34:44.323061 22542570456896 run_lib.py:146] step: 763400, eval_loss: 3.07289e-02
I0211 15:35:01.952011 22542570456896 run_lib.py:133] step: 763450, training_loss: 2.77552e-02
I0211 15:35:19.486515 22542570456896 run_lib.py:133] step: 763500, training_loss: 3.26281e-02
I0211 15:35:19.641226 22542570456896 run_lib.py:146] step: 763500, eval_loss: 2.69781e-02
I0211 15:35:37.232330 22542570456896 run_lib.py:133] step: 763550, training_loss: 2.87225e-02
I0211 15:35:54.721362 22542570456896 run_lib.py:133] step: 763600, training_loss: 2.59582e-02
I0211 15:35:54.883521 22542570456896 run_lib.py:146] step: 763600, eval_loss: 3.33557e-02
I0211 15:36:12.485270 22542570456896 run_lib.py:133] step: 763650, training_loss: 2.99945e-02
I0211 15:36:29.883516 22542570456896 run_lib.py:133] step: 763700, training_loss: 2.71543e-02
I0211 15:36:30.039641 22542570456896 run_lib.py:146] step: 763700, eval_loss: 3.50257e-02
I0211 15:36:47.585197 22542570456896 run_lib.py:133] step: 763750, training_loss: 2.41414e-02
I0211 15:37:04.921944 22542570456896 run_lib.py:133] step: 763800, training_loss: 2.28893e-02
I0211 15:37:05.094996 22542570456896 run_lib.py:146] step: 763800, eval_loss: 2.49456e-02
I0211 15:37:22.802093 22542570456896 run_lib.py:133] step: 763850, training_loss: 3.06384e-02
I0211 15:37:40.335421 22542570456896 run_lib.py:133] step: 763900, training_loss: 2.79637e-02
I0211 15:37:40.488254 22542570456896 run_lib.py:146] step: 763900, eval_loss: 2.58176e-02
I0211 15:37:57.998184 22542570456896 run_lib.py:133] step: 763950, training_loss: 2.56299e-02
I0211 15:38:15.707684 22542570456896 run_lib.py:133] step: 764000, training_loss: 2.77269e-02
I0211 15:38:15.865355 22542570456896 run_lib.py:146] step: 764000, eval_loss: 2.83296e-02
I0211 15:38:33.358325 22542570456896 run_lib.py:133] step: 764050, training_loss: 2.53911e-02
I0211 15:38:51.012633 22542570456896 run_lib.py:133] step: 764100, training_loss: 2.85162e-02
I0211 15:38:51.192843 22542570456896 run_lib.py:146] step: 764100, eval_loss: 2.49841e-02
I0211 15:39:08.741888 22542570456896 run_lib.py:133] step: 764150, training_loss: 2.73927e-02
I0211 15:39:26.239090 22542570456896 run_lib.py:133] step: 764200, training_loss: 3.02238e-02
I0211 15:39:26.402301 22542570456896 run_lib.py:146] step: 764200, eval_loss: 2.48438e-02
I0211 15:39:44.097141 22542570456896 run_lib.py:133] step: 764250, training_loss: 2.59751e-02
I0211 15:40:01.611918 22542570456896 run_lib.py:133] step: 764300, training_loss: 2.43952e-02
I0211 15:40:01.766369 22542570456896 run_lib.py:146] step: 764300, eval_loss: 3.11841e-02
I0211 15:40:19.275027 22542570456896 run_lib.py:133] step: 764350, training_loss: 2.27222e-02
I0211 15:40:36.820841 22542570456896 run_lib.py:133] step: 764400, training_loss: 2.74038e-02
I0211 15:40:36.978719 22542570456896 run_lib.py:146] step: 764400, eval_loss: 2.92630e-02
I0211 15:40:54.740747 22542570456896 run_lib.py:133] step: 764450, training_loss: 2.89261e-02
I0211 15:41:12.238794 22542570456896 run_lib.py:133] step: 764500, training_loss: 2.50625e-02
I0211 15:41:12.395731 22542570456896 run_lib.py:146] step: 764500, eval_loss: 3.28031e-02
I0211 15:41:29.929504 22542570456896 run_lib.py:133] step: 764550, training_loss: 2.19603e-02
I0211 15:41:47.412045 22542570456896 run_lib.py:133] step: 764600, training_loss: 3.17643e-02
I0211 15:41:47.571692 22542570456896 run_lib.py:146] step: 764600, eval_loss: 3.73411e-02
I0211 15:42:05.085405 22542570456896 run_lib.py:133] step: 764650, training_loss: 3.09914e-02
I0211 15:42:22.626802 22542570456896 run_lib.py:133] step: 764700, training_loss: 3.12913e-02
I0211 15:42:22.786766 22542570456896 run_lib.py:146] step: 764700, eval_loss: 2.94014e-02
I0211 15:42:40.445871 22542570456896 run_lib.py:133] step: 764750, training_loss: 2.32885e-02
I0211 15:42:58.018077 22542570456896 run_lib.py:133] step: 764800, training_loss: 2.56583e-02
I0211 15:42:58.174428 22542570456896 run_lib.py:146] step: 764800, eval_loss: 2.76733e-02
I0211 15:43:15.650822 22542570456896 run_lib.py:133] step: 764850, training_loss: 2.64886e-02
I0211 15:43:33.120110 22542570456896 run_lib.py:133] step: 764900, training_loss: 3.33316e-02
I0211 15:43:33.272355 22542570456896 run_lib.py:146] step: 764900, eval_loss: 2.72584e-02
I0211 15:43:50.862588 22542570456896 run_lib.py:133] step: 764950, training_loss: 3.03252e-02
I0211 15:44:08.402734 22542570456896 run_lib.py:133] step: 765000, training_loss: 2.49231e-02
I0211 15:44:08.572352 22542570456896 run_lib.py:146] step: 765000, eval_loss: 3.13646e-02
I0211 15:44:26.254081 22542570456896 run_lib.py:133] step: 765050, training_loss: 2.55568e-02
I0211 15:44:43.769050 22542570456896 run_lib.py:133] step: 765100, training_loss: 2.53361e-02
I0211 15:44:43.927810 22542570456896 run_lib.py:146] step: 765100, eval_loss: 3.50290e-02
I0211 15:45:01.556526 22542570456896 run_lib.py:133] step: 765150, training_loss: 3.12036e-02
I0211 15:45:19.022802 22542570456896 run_lib.py:133] step: 765200, training_loss: 2.35729e-02
I0211 15:45:19.187145 22542570456896 run_lib.py:146] step: 765200, eval_loss: 2.96220e-02
I0211 15:45:36.901064 22542570456896 run_lib.py:133] step: 765250, training_loss: 2.41722e-02
I0211 15:45:54.425235 22542570456896 run_lib.py:133] step: 765300, training_loss: 3.00644e-02
I0211 15:45:54.583868 22542570456896 run_lib.py:146] step: 765300, eval_loss: 2.57768e-02
I0211 15:46:12.115046 22542570456896 run_lib.py:133] step: 765350, training_loss: 3.43149e-02
I0211 15:46:29.762086 22542570456896 run_lib.py:133] step: 765400, training_loss: 2.81143e-02
I0211 15:46:29.915445 22542570456896 run_lib.py:146] step: 765400, eval_loss: 2.56458e-02
I0211 15:46:47.361582 22542570456896 run_lib.py:133] step: 765450, training_loss: 2.45850e-02
I0211 15:47:04.869176 22542570456896 run_lib.py:133] step: 765500, training_loss: 3.37168e-02
I0211 15:47:05.046431 22542570456896 run_lib.py:146] step: 765500, eval_loss: 2.48986e-02
I0211 15:47:22.748044 22542570456896 run_lib.py:133] step: 765550, training_loss: 3.12541e-02
I0211 15:47:40.456393 22542570456896 run_lib.py:133] step: 765600, training_loss: 2.28897e-02
I0211 15:47:40.620530 22542570456896 run_lib.py:146] step: 765600, eval_loss: 3.26048e-02
I0211 15:47:58.086060 22542570456896 run_lib.py:133] step: 765650, training_loss: 2.74088e-02
I0211 15:48:15.538181 22542570456896 run_lib.py:133] step: 765700, training_loss: 2.79060e-02
I0211 15:48:15.695183 22542570456896 run_lib.py:146] step: 765700, eval_loss: 3.06345e-02
I0211 15:48:33.185640 22542570456896 run_lib.py:133] step: 765750, training_loss: 2.11500e-02
I0211 15:48:50.820146 22542570456896 run_lib.py:133] step: 765800, training_loss: 2.88864e-02
I0211 15:48:50.975287 22542570456896 run_lib.py:146] step: 765800, eval_loss: 2.46758e-02
I0211 15:49:08.514490 22542570456896 run_lib.py:133] step: 765850, training_loss: 2.50687e-02
I0211 15:49:25.982986 22542570456896 run_lib.py:133] step: 765900, training_loss: 2.78192e-02
I0211 15:49:26.137491 22542570456896 run_lib.py:146] step: 765900, eval_loss: 2.52690e-02
I0211 15:49:43.626338 22542570456896 run_lib.py:133] step: 765950, training_loss: 2.63002e-02
I0211 15:50:01.310192 22542570456896 run_lib.py:133] step: 766000, training_loss: 2.65146e-02
I0211 15:50:01.468739 22542570456896 run_lib.py:146] step: 766000, eval_loss: 3.74598e-02
I0211 15:50:18.924399 22542570456896 run_lib.py:133] step: 766050, training_loss: 2.81012e-02
I0211 15:50:36.554051 22542570456896 run_lib.py:133] step: 766100, training_loss: 2.81340e-02
I0211 15:50:36.711608 22542570456896 run_lib.py:146] step: 766100, eval_loss: 3.55391e-02
I0211 15:50:54.184782 22542570456896 run_lib.py:133] step: 766150, training_loss: 2.80035e-02
I0211 15:51:11.660881 22542570456896 run_lib.py:133] step: 766200, training_loss: 2.62914e-02
I0211 15:51:11.818459 22542570456896 run_lib.py:146] step: 766200, eval_loss: 3.46639e-02
I0211 15:51:29.465961 22542570456896 run_lib.py:133] step: 766250, training_loss: 2.81609e-02
I0211 15:51:47.018762 22542570456896 run_lib.py:133] step: 766300, training_loss: 2.57252e-02
I0211 15:51:47.170328 22542570456896 run_lib.py:146] step: 766300, eval_loss: 3.11210e-02
I0211 15:52:04.631958 22542570456896 run_lib.py:133] step: 766350, training_loss: 2.63466e-02
I0211 15:52:22.167761 22542570456896 run_lib.py:133] step: 766400, training_loss: 2.84663e-02
I0211 15:52:22.335233 22542570456896 run_lib.py:146] step: 766400, eval_loss: 2.55477e-02
I0211 15:52:40.034121 22542570456896 run_lib.py:133] step: 766450, training_loss: 2.49783e-02
I0211 15:52:57.518200 22542570456896 run_lib.py:133] step: 766500, training_loss: 2.56942e-02
I0211 15:52:57.672526 22542570456896 run_lib.py:146] step: 766500, eval_loss: 3.32337e-02
I0211 15:53:15.298654 22542570456896 run_lib.py:133] step: 766550, training_loss: 2.39670e-02
I0211 15:53:32.764606 22542570456896 run_lib.py:133] step: 766600, training_loss: 3.04495e-02
I0211 15:53:32.924510 22542570456896 run_lib.py:146] step: 766600, eval_loss: 2.79850e-02
I0211 15:53:50.599579 22542570456896 run_lib.py:133] step: 766650, training_loss: 2.98819e-02
I0211 15:54:08.115872 22542570456896 run_lib.py:133] step: 766700, training_loss: 1.78990e-02
I0211 15:54:08.276620 22542570456896 run_lib.py:146] step: 766700, eval_loss: 2.57325e-02
I0211 15:54:25.765364 22542570456896 run_lib.py:133] step: 766750, training_loss: 2.13410e-02
I0211 15:54:43.462368 22542570456896 run_lib.py:133] step: 766800, training_loss: 2.58485e-02
I0211 15:54:43.614463 22542570456896 run_lib.py:146] step: 766800, eval_loss: 2.78102e-02
I0211 15:55:01.072662 22542570456896 run_lib.py:133] step: 766850, training_loss: 2.39146e-02
I0211 15:55:18.705385 22542570456896 run_lib.py:133] step: 766900, training_loss: 2.82327e-02
I0211 15:55:18.869206 22542570456896 run_lib.py:146] step: 766900, eval_loss: 2.70960e-02
I0211 15:55:36.437173 22542570456896 run_lib.py:133] step: 766950, training_loss: 3.18311e-02
I0211 15:55:53.922051 22542570456896 run_lib.py:133] step: 767000, training_loss: 2.55264e-02
I0211 15:55:54.078360 22542570456896 run_lib.py:146] step: 767000, eval_loss: 3.02047e-02
I0211 15:56:11.737341 22542570456896 run_lib.py:133] step: 767050, training_loss: 2.04411e-02
I0211 15:56:29.212826 22542570456896 run_lib.py:133] step: 767100, training_loss: 2.83388e-02
I0211 15:56:29.369987 22542570456896 run_lib.py:146] step: 767100, eval_loss: 3.25816e-02
I0211 15:56:46.863151 22542570456896 run_lib.py:133] step: 767150, training_loss: 3.48096e-02
I0211 15:57:04.529264 22542570456896 run_lib.py:133] step: 767200, training_loss: 3.06438e-02
I0211 15:57:04.684248 22542570456896 run_lib.py:146] step: 767200, eval_loss: 3.20414e-02
I0211 15:57:22.225221 22542570456896 run_lib.py:133] step: 767250, training_loss: 2.47513e-02
I0211 15:57:39.689594 22542570456896 run_lib.py:133] step: 767300, training_loss: 2.80696e-02
I0211 15:57:39.841303 22542570456896 run_lib.py:146] step: 767300, eval_loss: 3.33949e-02
I0211 15:57:57.410879 22542570456896 run_lib.py:133] step: 767350, training_loss: 2.87605e-02
I0211 15:58:14.880970 22542570456896 run_lib.py:133] step: 767400, training_loss: 2.12986e-02
I0211 15:58:15.039673 22542570456896 run_lib.py:146] step: 767400, eval_loss: 3.33598e-02
I0211 15:58:32.523486 22542570456896 run_lib.py:133] step: 767450, training_loss: 2.37822e-02
I0211 15:58:49.998753 22542570456896 run_lib.py:133] step: 767500, training_loss: 2.45356e-02
I0211 15:58:50.168847 22542570456896 run_lib.py:146] step: 767500, eval_loss: 2.89060e-02
I0211 15:59:07.872144 22542570456896 run_lib.py:133] step: 767550, training_loss: 2.48275e-02
I0211 15:59:25.414505 22542570456896 run_lib.py:133] step: 767600, training_loss: 3.23515e-02
I0211 15:59:25.571438 22542570456896 run_lib.py:146] step: 767600, eval_loss: 2.83641e-02
I0211 15:59:43.051935 22542570456896 run_lib.py:133] step: 767650, training_loss: 3.00017e-02
I0211 16:00:00.511711 22542570456896 run_lib.py:133] step: 767700, training_loss: 2.17931e-02
I0211 16:00:00.673745 22542570456896 run_lib.py:146] step: 767700, eval_loss: 1.98423e-02
I0211 16:00:18.306962 22542570456896 run_lib.py:133] step: 767750, training_loss: 2.67162e-02
I0211 16:00:35.796504 22542570456896 run_lib.py:133] step: 767800, training_loss: 2.22709e-02
I0211 16:00:35.967400 22542570456896 run_lib.py:146] step: 767800, eval_loss: 2.68984e-02
I0211 16:00:53.658438 22542570456896 run_lib.py:133] step: 767850, training_loss: 2.48364e-02
I0211 16:01:11.172645 22542570456896 run_lib.py:133] step: 767900, training_loss: 2.09915e-02
I0211 16:01:11.329599 22542570456896 run_lib.py:146] step: 767900, eval_loss: 2.96816e-02
I0211 16:01:28.947216 22542570456896 run_lib.py:133] step: 767950, training_loss: 3.58171e-02
I0211 16:01:46.407677 22542570456896 run_lib.py:133] step: 768000, training_loss: 2.99079e-02
I0211 16:01:46.563441 22542570456896 run_lib.py:146] step: 768000, eval_loss: 2.54194e-02
I0211 16:02:04.194774 22542570456896 run_lib.py:133] step: 768050, training_loss: 3.23295e-02
I0211 16:02:21.712860 22542570456896 run_lib.py:133] step: 768100, training_loss: 3.31059e-02
I0211 16:02:21.870642 22542570456896 run_lib.py:146] step: 768100, eval_loss: 2.45090e-02
I0211 16:02:39.412547 22542570456896 run_lib.py:133] step: 768150, training_loss: 2.77538e-02
I0211 16:02:57.045042 22542570456896 run_lib.py:133] step: 768200, training_loss: 2.71400e-02
I0211 16:02:57.198344 22542570456896 run_lib.py:146] step: 768200, eval_loss: 3.37481e-02
I0211 16:03:14.652188 22542570456896 run_lib.py:133] step: 768250, training_loss: 2.32952e-02
I0211 16:03:32.185009 22542570456896 run_lib.py:133] step: 768300, training_loss: 2.87734e-02
I0211 16:03:32.346610 22542570456896 run_lib.py:146] step: 768300, eval_loss: 3.16764e-02
I0211 16:03:50.021339 22542570456896 run_lib.py:133] step: 768350, training_loss: 2.47315e-02
I0211 16:04:07.576588 22542570456896 run_lib.py:133] step: 768400, training_loss: 3.00816e-02
I0211 16:04:07.736394 22542570456896 run_lib.py:146] step: 768400, eval_loss: 2.85123e-02
I0211 16:04:25.407504 22542570456896 run_lib.py:133] step: 768450, training_loss: 2.23365e-02
I0211 16:04:42.885797 22542570456896 run_lib.py:133] step: 768500, training_loss: 2.65341e-02
I0211 16:04:43.040376 22542570456896 run_lib.py:146] step: 768500, eval_loss: 3.18468e-02
I0211 16:05:00.557395 22542570456896 run_lib.py:133] step: 768550, training_loss: 3.11151e-02
I0211 16:05:18.174959 22542570456896 run_lib.py:133] step: 768600, training_loss: 3.45539e-02
I0211 16:05:18.334753 22542570456896 run_lib.py:146] step: 768600, eval_loss: 2.32410e-02
I0211 16:05:35.831354 22542570456896 run_lib.py:133] step: 768650, training_loss: 2.64479e-02
I0211 16:05:53.354912 22542570456896 run_lib.py:133] step: 768700, training_loss: 2.70673e-02
I0211 16:05:53.516613 22542570456896 run_lib.py:146] step: 768700, eval_loss: 3.37123e-02
I0211 16:06:11.016371 22542570456896 run_lib.py:133] step: 768750, training_loss: 2.77736e-02
I0211 16:06:28.701951 22542570456896 run_lib.py:133] step: 768800, training_loss: 2.26925e-02
I0211 16:06:28.860231 22542570456896 run_lib.py:146] step: 768800, eval_loss: 3.79115e-02
I0211 16:06:46.301292 22542570456896 run_lib.py:133] step: 768850, training_loss: 3.06374e-02
I0211 16:07:03.866406 22542570456896 run_lib.py:133] step: 768900, training_loss: 3.73136e-02
I0211 16:07:04.039519 22542570456896 run_lib.py:146] step: 768900, eval_loss: 3.39046e-02
I0211 16:07:21.558939 22542570456896 run_lib.py:133] step: 768950, training_loss: 2.28125e-02
I0211 16:07:39.040492 22542570456896 run_lib.py:133] step: 769000, training_loss: 3.62956e-02
I0211 16:07:39.196202 22542570456896 run_lib.py:146] step: 769000, eval_loss: 2.60055e-02
I0211 16:07:56.892873 22542570456896 run_lib.py:133] step: 769050, training_loss: 2.60883e-02
I0211 16:08:14.424114 22542570456896 run_lib.py:133] step: 769100, training_loss: 2.49445e-02
I0211 16:08:14.577127 22542570456896 run_lib.py:146] step: 769100, eval_loss: 2.91954e-02
I0211 16:08:32.044504 22542570456896 run_lib.py:133] step: 769150, training_loss: 1.99199e-02
I0211 16:08:49.571835 22542570456896 run_lib.py:133] step: 769200, training_loss: 2.70729e-02
I0211 16:08:49.744562 22542570456896 run_lib.py:146] step: 769200, eval_loss: 2.56485e-02
I0211 16:09:07.410079 22542570456896 run_lib.py:133] step: 769250, training_loss: 2.22547e-02
I0211 16:09:24.918142 22542570456896 run_lib.py:133] step: 769300, training_loss: 2.77643e-02
I0211 16:09:25.076661 22542570456896 run_lib.py:146] step: 769300, eval_loss: 2.99103e-02
I0211 16:09:42.698612 22542570456896 run_lib.py:133] step: 769350, training_loss: 2.75646e-02
I0211 16:10:00.156103 22542570456896 run_lib.py:133] step: 769400, training_loss: 2.38659e-02
I0211 16:10:00.326444 22542570456896 run_lib.py:146] step: 769400, eval_loss: 3.24653e-02
I0211 16:10:17.986949 22542570456896 run_lib.py:133] step: 769450, training_loss: 2.27762e-02
I0211 16:10:35.515491 22542570456896 run_lib.py:133] step: 769500, training_loss: 2.61203e-02
I0211 16:10:35.671692 22542570456896 run_lib.py:146] step: 769500, eval_loss: 3.77337e-02
I0211 16:10:53.157457 22542570456896 run_lib.py:133] step: 769550, training_loss: 2.66380e-02
I0211 16:11:10.786854 22542570456896 run_lib.py:133] step: 769600, training_loss: 2.95209e-02
I0211 16:11:10.938433 22542570456896 run_lib.py:146] step: 769600, eval_loss: 3.08610e-02
I0211 16:11:28.412939 22542570456896 run_lib.py:133] step: 769650, training_loss: 2.65271e-02
I0211 16:11:46.094490 22542570456896 run_lib.py:133] step: 769700, training_loss: 3.08037e-02
I0211 16:11:46.266637 22542570456896 run_lib.py:146] step: 769700, eval_loss: 2.92444e-02
I0211 16:12:03.738878 22542570456896 run_lib.py:133] step: 769750, training_loss: 2.18200e-02
I0211 16:12:21.223987 22542570456896 run_lib.py:133] step: 769800, training_loss: 2.71412e-02
I0211 16:12:21.390400 22542570456896 run_lib.py:146] step: 769800, eval_loss: 2.96795e-02
I0211 16:12:39.018857 22542570456896 run_lib.py:133] step: 769850, training_loss: 3.17531e-02
I0211 16:12:56.489826 22542570456896 run_lib.py:133] step: 769900, training_loss: 2.50065e-02
I0211 16:12:56.654104 22542570456896 run_lib.py:146] step: 769900, eval_loss: 3.07369e-02
I0211 16:13:14.129286 22542570456896 run_lib.py:133] step: 769950, training_loss: 3.02994e-02
I0211 16:13:31.796176 22542570456896 run_lib.py:133] step: 770000, training_loss: 2.62084e-02
I0211 16:13:32.556390 22542570456896 run_lib.py:146] step: 770000, eval_loss: 2.61445e-02
I0211 16:13:52.738159 22542570456896 run_lib.py:133] step: 770050, training_loss: 2.87494e-02
I0211 16:14:10.219598 22542570456896 run_lib.py:133] step: 770100, training_loss: 3.19292e-02
I0211 16:14:10.375470 22542570456896 run_lib.py:146] step: 770100, eval_loss: 2.78275e-02
I0211 16:14:28.102373 22542570456896 run_lib.py:133] step: 770150, training_loss: 3.10167e-02
I0211 16:14:45.575037 22542570456896 run_lib.py:133] step: 770200, training_loss: 2.57824e-02
I0211 16:14:45.726449 22542570456896 run_lib.py:146] step: 770200, eval_loss: 3.59242e-02
I0211 16:15:03.250724 22542570456896 run_lib.py:133] step: 770250, training_loss: 2.27340e-02
I0211 16:15:20.792064 22542570456896 run_lib.py:133] step: 770300, training_loss: 2.81182e-02
I0211 16:15:20.955282 22542570456896 run_lib.py:146] step: 770300, eval_loss: 2.74165e-02
I0211 16:15:38.615546 22542570456896 run_lib.py:133] step: 770350, training_loss: 2.18880e-02
I0211 16:15:56.075618 22542570456896 run_lib.py:133] step: 770400, training_loss: 3.23167e-02
I0211 16:15:56.233688 22542570456896 run_lib.py:146] step: 770400, eval_loss: 2.93372e-02
I0211 16:16:13.766239 22542570456896 run_lib.py:133] step: 770450, training_loss: 2.92073e-02
I0211 16:16:31.251328 22542570456896 run_lib.py:133] step: 770500, training_loss: 2.29275e-02
I0211 16:16:31.419123 22542570456896 run_lib.py:146] step: 770500, eval_loss: 2.74946e-02
I0211 16:16:48.919431 22542570456896 run_lib.py:133] step: 770550, training_loss: 2.75061e-02
I0211 16:17:06.437990 22542570456896 run_lib.py:133] step: 770600, training_loss: 3.41699e-02
I0211 16:17:06.591469 22542570456896 run_lib.py:146] step: 770600, eval_loss: 2.76677e-02
I0211 16:17:24.216127 22542570456896 run_lib.py:133] step: 770650, training_loss: 3.05948e-02
I0211 16:17:41.786030 22542570456896 run_lib.py:133] step: 770700, training_loss: 2.96224e-02
I0211 16:17:41.939526 22542570456896 run_lib.py:146] step: 770700, eval_loss: 2.51454e-02
I0211 16:17:59.381177 22542570456896 run_lib.py:133] step: 770750, training_loss: 2.82805e-02
I0211 16:18:16.836391 22542570456896 run_lib.py:133] step: 770800, training_loss: 2.78539e-02
I0211 16:18:17.012674 22542570456896 run_lib.py:146] step: 770800, eval_loss: 2.70690e-02
I0211 16:18:34.674151 22542570456896 run_lib.py:133] step: 770850, training_loss: 2.57630e-02
I0211 16:18:52.172034 22542570456896 run_lib.py:133] step: 770900, training_loss: 2.43048e-02
I0211 16:18:52.328678 22542570456896 run_lib.py:146] step: 770900, eval_loss: 2.87535e-02
I0211 16:19:09.963785 22542570456896 run_lib.py:133] step: 770950, training_loss: 3.06152e-02
I0211 16:19:27.427004 22542570456896 run_lib.py:133] step: 771000, training_loss: 2.86182e-02
I0211 16:19:27.582447 22542570456896 run_lib.py:146] step: 771000, eval_loss: 3.27411e-02
I0211 16:19:45.201501 22542570456896 run_lib.py:133] step: 771050, training_loss: 2.45570e-02
I0211 16:20:02.730061 22542570456896 run_lib.py:133] step: 771100, training_loss: 2.50369e-02
I0211 16:20:02.883684 22542570456896 run_lib.py:146] step: 771100, eval_loss: 3.20120e-02
I0211 16:20:20.585546 22542570456896 run_lib.py:133] step: 771150, training_loss: 3.01167e-02
I0211 16:20:38.074296 22542570456896 run_lib.py:133] step: 771200, training_loss: 2.06142e-02
I0211 16:20:38.230342 22542570456896 run_lib.py:146] step: 771200, eval_loss: 3.03943e-02
I0211 16:20:55.693927 22542570456896 run_lib.py:133] step: 771250, training_loss: 2.07826e-02
I0211 16:21:13.294985 22542570456896 run_lib.py:133] step: 771300, training_loss: 2.17237e-02
I0211 16:21:13.458679 22542570456896 run_lib.py:146] step: 771300, eval_loss: 2.84506e-02
I0211 16:21:30.977439 22542570456896 run_lib.py:133] step: 771350, training_loss: 3.35165e-02
I0211 16:21:48.477497 22542570456896 run_lib.py:133] step: 771400, training_loss: 2.50726e-02
I0211 16:21:48.633616 22542570456896 run_lib.py:146] step: 771400, eval_loss: 2.44303e-02
I0211 16:22:06.314874 22542570456896 run_lib.py:133] step: 771450, training_loss: 3.24801e-02
I0211 16:22:23.909930 22542570456896 run_lib.py:133] step: 771500, training_loss: 2.93755e-02
I0211 16:22:24.065450 22542570456896 run_lib.py:146] step: 771500, eval_loss: 3.48663e-02
I0211 16:22:41.569253 22542570456896 run_lib.py:133] step: 771550, training_loss: 2.62482e-02
I0211 16:22:59.079305 22542570456896 run_lib.py:133] step: 771600, training_loss: 3.13410e-02
I0211 16:22:59.233537 22542570456896 run_lib.py:146] step: 771600, eval_loss: 3.04073e-02
I0211 16:23:16.780241 22542570456896 run_lib.py:133] step: 771650, training_loss: 2.62569e-02
I0211 16:23:34.422028 22542570456896 run_lib.py:133] step: 771700, training_loss: 2.75181e-02
I0211 16:23:34.596383 22542570456896 run_lib.py:146] step: 771700, eval_loss: 2.44184e-02
I0211 16:23:52.044115 22542570456896 run_lib.py:133] step: 771750, training_loss: 2.99943e-02
I0211 16:24:09.506673 22542570456896 run_lib.py:133] step: 771800, training_loss: 2.45432e-02
I0211 16:24:09.665636 22542570456896 run_lib.py:146] step: 771800, eval_loss: 3.02426e-02
I0211 16:24:27.164583 22542570456896 run_lib.py:133] step: 771850, training_loss: 2.84564e-02
I0211 16:24:44.819378 22542570456896 run_lib.py:133] step: 771900, training_loss: 2.88528e-02
I0211 16:24:44.981426 22542570456896 run_lib.py:146] step: 771900, eval_loss: 2.36241e-02
I0211 16:25:02.456720 22542570456896 run_lib.py:133] step: 771950, training_loss: 2.47335e-02
I0211 16:25:20.149483 22542570456896 run_lib.py:133] step: 772000, training_loss: 2.88481e-02
I0211 16:25:20.303375 22542570456896 run_lib.py:146] step: 772000, eval_loss: 3.25167e-02
I0211 16:25:37.781265 22542570456896 run_lib.py:133] step: 772050, training_loss: 2.94485e-02
I0211 16:25:55.290958 22542570456896 run_lib.py:133] step: 772100, training_loss: 2.97978e-02
I0211 16:25:55.451476 22542570456896 run_lib.py:146] step: 772100, eval_loss: 3.45745e-02
I0211 16:26:13.072966 22542570456896 run_lib.py:133] step: 772150, training_loss: 2.57681e-02
I0211 16:26:30.673425 22542570456896 run_lib.py:133] step: 772200, training_loss: 2.72356e-02
I0211 16:26:30.859845 22542570456896 run_lib.py:146] step: 772200, eval_loss: 2.95849e-02
I0211 16:26:48.381907 22542570456896 run_lib.py:133] step: 772250, training_loss: 3.19359e-02
I0211 16:27:05.857828 22542570456896 run_lib.py:133] step: 772300, training_loss: 2.41002e-02
I0211 16:27:06.013669 22542570456896 run_lib.py:146] step: 772300, eval_loss: 3.57829e-02
I0211 16:27:23.611931 22542570456896 run_lib.py:133] step: 772350, training_loss: 2.56811e-02
I0211 16:27:41.058666 22542570456896 run_lib.py:133] step: 772400, training_loss: 2.90411e-02
I0211 16:27:41.218421 22542570456896 run_lib.py:146] step: 772400, eval_loss: 2.72400e-02
I0211 16:27:58.763902 22542570456896 run_lib.py:133] step: 772450, training_loss: 2.81828e-02
I0211 16:28:16.265139 22542570456896 run_lib.py:133] step: 772500, training_loss: 2.67723e-02
I0211 16:28:16.420019 22542570456896 run_lib.py:146] step: 772500, eval_loss: 2.73065e-02
I0211 16:28:34.036174 22542570456896 run_lib.py:133] step: 772550, training_loss: 2.44343e-02
I0211 16:28:51.449629 22542570456896 run_lib.py:133] step: 772600, training_loss: 3.09189e-02
I0211 16:28:51.607361 22542570456896 run_lib.py:146] step: 772600, eval_loss: 2.70929e-02
I0211 16:29:08.984858 22542570456896 run_lib.py:133] step: 772650, training_loss: 3.24387e-02
I0211 16:29:26.528949 22542570456896 run_lib.py:133] step: 772700, training_loss: 2.36387e-02
I0211 16:29:26.708644 22542570456896 run_lib.py:146] step: 772700, eval_loss: 3.45318e-02
I0211 16:29:44.176928 22542570456896 run_lib.py:133] step: 772750, training_loss: 2.52046e-02
I0211 16:30:01.801877 22542570456896 run_lib.py:133] step: 772800, training_loss: 2.70150e-02
I0211 16:30:01.957650 22542570456896 run_lib.py:146] step: 772800, eval_loss: 2.87258e-02
I0211 16:30:19.367506 22542570456896 run_lib.py:133] step: 772850, training_loss: 3.03256e-02
I0211 16:30:36.785513 22542570456896 run_lib.py:133] step: 772900, training_loss: 2.84702e-02
I0211 16:30:36.941774 22542570456896 run_lib.py:146] step: 772900, eval_loss: 2.43057e-02
I0211 16:30:54.571598 22542570456896 run_lib.py:133] step: 772950, training_loss: 2.38726e-02
I0211 16:31:12.032853 22542570456896 run_lib.py:133] step: 773000, training_loss: 1.87879e-02
I0211 16:31:12.195918 22542570456896 run_lib.py:146] step: 773000, eval_loss: 3.43248e-02
I0211 16:31:29.684364 22542570456896 run_lib.py:133] step: 773050, training_loss: 2.82765e-02
I0211 16:31:47.322234 22542570456896 run_lib.py:133] step: 773100, training_loss: 2.93599e-02
I0211 16:31:47.480170 22542570456896 run_lib.py:146] step: 773100, eval_loss: 2.76313e-02
I0211 16:32:04.866210 22542570456896 run_lib.py:133] step: 773150, training_loss: 2.66652e-02
I0211 16:32:22.284647 22542570456896 run_lib.py:133] step: 773200, training_loss: 2.62030e-02
I0211 16:32:22.441872 22542570456896 run_lib.py:146] step: 773200, eval_loss: 3.09198e-02
I0211 16:32:39.969213 22542570456896 run_lib.py:133] step: 773250, training_loss: 2.94072e-02
I0211 16:32:57.407921 22542570456896 run_lib.py:133] step: 773300, training_loss: 2.00252e-02
I0211 16:32:57.583560 22542570456896 run_lib.py:146] step: 773300, eval_loss: 2.86031e-02
I0211 16:33:15.010315 22542570456896 run_lib.py:133] step: 773350, training_loss: 3.04181e-02
I0211 16:33:32.427159 22542570456896 run_lib.py:133] step: 773400, training_loss: 2.52826e-02
I0211 16:33:32.582391 22542570456896 run_lib.py:146] step: 773400, eval_loss: 2.80364e-02
I0211 16:33:50.197505 22542570456896 run_lib.py:133] step: 773450, training_loss: 2.44717e-02
I0211 16:34:07.630779 22542570456896 run_lib.py:133] step: 773500, training_loss: 3.27958e-02
I0211 16:34:07.782291 22542570456896 run_lib.py:146] step: 773500, eval_loss: 3.60642e-02
I0211 16:34:25.182768 22542570456896 run_lib.py:133] step: 773550, training_loss: 2.18288e-02
I0211 16:34:42.619203 22542570456896 run_lib.py:133] step: 773600, training_loss: 2.90943e-02
I0211 16:34:42.783480 22542570456896 run_lib.py:146] step: 773600, eval_loss: 3.06278e-02
I0211 16:35:00.358546 22542570456896 run_lib.py:133] step: 773650, training_loss: 2.97360e-02
I0211 16:35:17.803336 22542570456896 run_lib.py:133] step: 773700, training_loss: 3.09193e-02
I0211 16:35:17.961530 22542570456896 run_lib.py:146] step: 773700, eval_loss: 2.68246e-02
I0211 16:35:35.513901 22542570456896 run_lib.py:133] step: 773750, training_loss: 2.71086e-02
I0211 16:35:52.883732 22542570456896 run_lib.py:133] step: 773800, training_loss: 2.64652e-02
I0211 16:35:53.044166 22542570456896 run_lib.py:146] step: 773800, eval_loss: 2.90619e-02
I0211 16:36:10.603270 22542570456896 run_lib.py:133] step: 773850, training_loss: 2.68475e-02
I0211 16:36:28.073173 22542570456896 run_lib.py:133] step: 773900, training_loss: 2.82032e-02
I0211 16:36:28.228498 22542570456896 run_lib.py:146] step: 773900, eval_loss: 2.84442e-02
I0211 16:36:45.859400 22542570456896 run_lib.py:133] step: 773950, training_loss: 2.34127e-02
I0211 16:37:03.315845 22542570456896 run_lib.py:133] step: 774000, training_loss: 2.29135e-02
I0211 16:37:03.468775 22542570456896 run_lib.py:146] step: 774000, eval_loss: 2.62728e-02
I0211 16:37:20.903616 22542570456896 run_lib.py:133] step: 774050, training_loss: 2.88220e-02
I0211 16:37:38.523550 22542570456896 run_lib.py:133] step: 774100, training_loss: 2.68644e-02
I0211 16:37:38.698895 22542570456896 run_lib.py:146] step: 774100, eval_loss: 2.70923e-02
I0211 16:37:56.139775 22542570456896 run_lib.py:133] step: 774150, training_loss: 2.76366e-02
I0211 16:38:13.561038 22542570456896 run_lib.py:133] step: 774200, training_loss: 2.79012e-02
I0211 16:38:13.717558 22542570456896 run_lib.py:146] step: 774200, eval_loss: 2.84702e-02
I0211 16:38:31.341013 22542570456896 run_lib.py:133] step: 774250, training_loss: 3.21217e-02
I0211 16:38:48.805684 22542570456896 run_lib.py:133] step: 774300, training_loss: 2.06337e-02
I0211 16:38:48.971081 22542570456896 run_lib.py:146] step: 774300, eval_loss: 3.58904e-02
I0211 16:39:06.548495 22542570456896 run_lib.py:133] step: 774350, training_loss: 2.98210e-02
I0211 16:39:24.038467 22542570456896 run_lib.py:133] step: 774400, training_loss: 3.49235e-02
I0211 16:39:24.194125 22542570456896 run_lib.py:146] step: 774400, eval_loss: 2.96284e-02
I0211 16:39:41.610047 22542570456896 run_lib.py:133] step: 774450, training_loss: 2.59252e-02
I0211 16:39:59.244380 22542570456896 run_lib.py:133] step: 774500, training_loss: 3.12588e-02
I0211 16:39:59.398363 22542570456896 run_lib.py:146] step: 774500, eval_loss: 2.91547e-02
I0211 16:40:16.831959 22542570456896 run_lib.py:133] step: 774550, training_loss: 2.69353e-02
I0211 16:40:34.263821 22542570456896 run_lib.py:133] step: 774600, training_loss: 2.59563e-02
I0211 16:40:34.419695 22542570456896 run_lib.py:146] step: 774600, eval_loss: 2.82862e-02
I0211 16:40:51.879853 22542570456896 run_lib.py:133] step: 774650, training_loss: 2.65695e-02
I0211 16:41:09.506464 22542570456896 run_lib.py:133] step: 774700, training_loss: 2.52945e-02
I0211 16:41:09.668649 22542570456896 run_lib.py:146] step: 774700, eval_loss: 2.69721e-02
I0211 16:41:27.092118 22542570456896 run_lib.py:133] step: 774750, training_loss: 2.89491e-02
I0211 16:41:44.612564 22542570456896 run_lib.py:133] step: 774800, training_loss: 2.34186e-02
I0211 16:41:44.773772 22542570456896 run_lib.py:146] step: 774800, eval_loss: 2.77511e-02
I0211 16:42:02.223351 22542570456896 run_lib.py:133] step: 774850, training_loss: 2.31734e-02
I0211 16:42:19.680258 22542570456896 run_lib.py:133] step: 774900, training_loss: 2.59741e-02
I0211 16:42:19.849926 22542570456896 run_lib.py:146] step: 774900, eval_loss: 2.57240e-02
I0211 16:42:37.467849 22542570456896 run_lib.py:133] step: 774950, training_loss: 3.01232e-02
I0211 16:42:54.992281 22542570456896 run_lib.py:133] step: 775000, training_loss: 3.02177e-02
I0211 16:42:55.156399 22542570456896 run_lib.py:146] step: 775000, eval_loss: 2.46708e-02
I0211 16:43:12.555413 22542570456896 run_lib.py:133] step: 775050, training_loss: 2.47202e-02
I0211 16:43:29.976355 22542570456896 run_lib.py:133] step: 775100, training_loss: 2.21449e-02
I0211 16:43:30.134673 22542570456896 run_lib.py:146] step: 775100, eval_loss: 2.99896e-02
I0211 16:43:47.671423 22542570456896 run_lib.py:133] step: 775150, training_loss: 1.82637e-02
I0211 16:44:05.064407 22542570456896 run_lib.py:133] step: 775200, training_loss: 2.87483e-02
I0211 16:44:05.237335 22542570456896 run_lib.py:146] step: 775200, eval_loss: 3.19415e-02
I0211 16:44:22.809660 22542570456896 run_lib.py:133] step: 775250, training_loss: 2.66830e-02
I0211 16:44:40.229739 22542570456896 run_lib.py:133] step: 775300, training_loss: 2.71497e-02
I0211 16:44:40.386689 22542570456896 run_lib.py:146] step: 775300, eval_loss: 3.52720e-02
I0211 16:44:58.014387 22542570456896 run_lib.py:133] step: 775350, training_loss: 3.06077e-02
I0211 16:45:15.396465 22542570456896 run_lib.py:133] step: 775400, training_loss: 2.66889e-02
I0211 16:45:15.546215 22542570456896 run_lib.py:146] step: 775400, eval_loss: 2.55233e-02
I0211 16:45:32.812566 22542570456896 run_lib.py:133] step: 775450, training_loss: 2.73417e-02
I0211 16:45:50.283970 22542570456896 run_lib.py:133] step: 775500, training_loss: 2.81157e-02
I0211 16:45:50.452180 22542570456896 run_lib.py:146] step: 775500, eval_loss: 2.97693e-02
I0211 16:46:07.851235 22542570456896 run_lib.py:133] step: 775550, training_loss: 2.08807e-02
I0211 16:46:25.401902 22542570456896 run_lib.py:133] step: 775600, training_loss: 3.15552e-02
I0211 16:46:25.562505 22542570456896 run_lib.py:146] step: 775600, eval_loss: 3.25327e-02
I0211 16:46:43.012257 22542570456896 run_lib.py:133] step: 775650, training_loss: 2.75096e-02
I0211 16:47:00.451454 22542570456896 run_lib.py:133] step: 775700, training_loss: 2.83357e-02
I0211 16:47:00.606442 22542570456896 run_lib.py:146] step: 775700, eval_loss: 2.98219e-02
I0211 16:47:18.207875 22542570456896 run_lib.py:133] step: 775750, training_loss: 1.87723e-02
I0211 16:47:35.700606 22542570456896 run_lib.py:133] step: 775800, training_loss: 2.62366e-02
I0211 16:47:35.853968 22542570456896 run_lib.py:146] step: 775800, eval_loss: 2.54682e-02
I0211 16:47:53.328522 22542570456896 run_lib.py:133] step: 775850, training_loss: 2.95944e-02
I0211 16:48:10.950055 22542570456896 run_lib.py:133] step: 775900, training_loss: 2.92577e-02
I0211 16:48:11.100700 22542570456896 run_lib.py:146] step: 775900, eval_loss: 3.20398e-02
I0211 16:48:28.521919 22542570456896 run_lib.py:133] step: 775950, training_loss: 3.13422e-02
I0211 16:48:45.954782 22542570456896 run_lib.py:133] step: 776000, training_loss: 3.10633e-02
I0211 16:48:46.265539 22542570456896 run_lib.py:146] step: 776000, eval_loss: 3.17679e-02
I0211 16:49:03.711910 22542570456896 run_lib.py:133] step: 776050, training_loss: 2.57600e-02
I0211 16:49:21.159429 22542570456896 run_lib.py:133] step: 776100, training_loss: 2.65827e-02
I0211 16:49:21.314805 22542570456896 run_lib.py:146] step: 776100, eval_loss: 2.92445e-02
I0211 16:49:38.727294 22542570456896 run_lib.py:133] step: 776150, training_loss: 2.63282e-02
I0211 16:49:56.157148 22542570456896 run_lib.py:133] step: 776200, training_loss: 2.81601e-02
I0211 16:49:56.317066 22542570456896 run_lib.py:146] step: 776200, eval_loss: 3.89405e-02
I0211 16:50:13.929322 22542570456896 run_lib.py:133] step: 776250, training_loss: 3.35093e-02
I0211 16:50:31.415390 22542570456896 run_lib.py:133] step: 776300, training_loss: 3.27020e-02
I0211 16:50:31.569074 22542570456896 run_lib.py:146] step: 776300, eval_loss: 2.49015e-02
I0211 16:50:49.037259 22542570456896 run_lib.py:133] step: 776350, training_loss: 3.02826e-02
I0211 16:51:06.447839 22542570456896 run_lib.py:133] step: 776400, training_loss: 2.92464e-02
I0211 16:51:06.606072 22542570456896 run_lib.py:146] step: 776400, eval_loss: 3.09649e-02
I0211 16:51:24.198456 22542570456896 run_lib.py:133] step: 776450, training_loss: 2.29240e-02
I0211 16:51:41.706914 22542570456896 run_lib.py:133] step: 776500, training_loss: 2.35079e-02
I0211 16:51:41.882595 22542570456896 run_lib.py:146] step: 776500, eval_loss: 2.50292e-02
I0211 16:51:59.302651 22542570456896 run_lib.py:133] step: 776550, training_loss: 2.47061e-02
I0211 16:52:16.733567 22542570456896 run_lib.py:133] step: 776600, training_loss: 2.55708e-02
I0211 16:52:16.911875 22542570456896 run_lib.py:146] step: 776600, eval_loss: 2.46961e-02
I0211 16:52:34.566651 22542570456896 run_lib.py:133] step: 776650, training_loss: 2.21095e-02
I0211 16:52:52.046782 22542570456896 run_lib.py:133] step: 776700, training_loss: 2.61966e-02
I0211 16:52:52.203681 22542570456896 run_lib.py:146] step: 776700, eval_loss: 2.84411e-02
I0211 16:53:09.822466 22542570456896 run_lib.py:133] step: 776750, training_loss: 2.50609e-02
I0211 16:53:27.244240 22542570456896 run_lib.py:133] step: 776800, training_loss: 2.58142e-02
I0211 16:53:27.395373 22542570456896 run_lib.py:146] step: 776800, eval_loss: 2.82739e-02
I0211 16:53:44.976195 22542570456896 run_lib.py:133] step: 776850, training_loss: 2.65408e-02
I0211 16:54:02.442850 22542570456896 run_lib.py:133] step: 776900, training_loss: 2.59691e-02
I0211 16:54:02.610669 22542570456896 run_lib.py:146] step: 776900, eval_loss: 4.37286e-02
I0211 16:54:20.115881 22542570456896 run_lib.py:133] step: 776950, training_loss: 2.37170e-02
I0211 16:54:37.742496 22542570456896 run_lib.py:133] step: 777000, training_loss: 2.39483e-02
I0211 16:54:37.911603 22542570456896 run_lib.py:146] step: 777000, eval_loss: 3.24733e-02
I0211 16:54:55.308024 22542570456896 run_lib.py:133] step: 777050, training_loss: 2.62834e-02
I0211 16:55:12.855766 22542570456896 run_lib.py:133] step: 777100, training_loss: 3.03006e-02
I0211 16:55:13.013510 22542570456896 run_lib.py:146] step: 777100, eval_loss: 2.95109e-02
I0211 16:55:30.430697 22542570456896 run_lib.py:133] step: 777150, training_loss: 3.39238e-02
I0211 16:55:47.918793 22542570456896 run_lib.py:133] step: 777200, training_loss: 2.73702e-02
I0211 16:55:48.075725 22542570456896 run_lib.py:146] step: 777200, eval_loss: 3.33745e-02
I0211 16:56:05.746349 22542570456896 run_lib.py:133] step: 777250, training_loss: 2.89786e-02
I0211 16:56:23.156488 22542570456896 run_lib.py:133] step: 777300, training_loss: 3.12273e-02
I0211 16:56:23.305166 22542570456896 run_lib.py:146] step: 777300, eval_loss: 2.29298e-02
I0211 16:56:40.764134 22542570456896 run_lib.py:133] step: 777350, training_loss: 2.70005e-02
I0211 16:56:58.179164 22542570456896 run_lib.py:133] step: 777400, training_loss: 2.53304e-02
I0211 16:56:58.334576 22542570456896 run_lib.py:146] step: 777400, eval_loss: 3.17490e-02
I0211 16:57:15.918587 22542570456896 run_lib.py:133] step: 777450, training_loss: 2.75859e-02
I0211 16:57:33.422764 22542570456896 run_lib.py:133] step: 777500, training_loss: 2.35034e-02
I0211 16:57:33.581995 22542570456896 run_lib.py:146] step: 777500, eval_loss: 2.88907e-02
I0211 16:57:51.081124 22542570456896 run_lib.py:133] step: 777550, training_loss: 2.17327e-02
I0211 16:58:08.505196 22542570456896 run_lib.py:133] step: 777600, training_loss: 2.98621e-02
I0211 16:58:08.661478 22542570456896 run_lib.py:146] step: 777600, eval_loss: 2.74574e-02
I0211 16:58:26.069505 22542570456896 run_lib.py:133] step: 777650, training_loss: 2.80070e-02
I0211 16:58:43.519187 22542570456896 run_lib.py:133] step: 777700, training_loss: 2.51598e-02
I0211 16:58:43.679149 22542570456896 run_lib.py:146] step: 777700, eval_loss: 2.42476e-02
I0211 16:59:01.315721 22542570456896 run_lib.py:133] step: 777750, training_loss: 3.17053e-02
I0211 16:59:18.903161 22542570456896 run_lib.py:133] step: 777800, training_loss: 2.22815e-02
I0211 16:59:19.056648 22542570456896 run_lib.py:146] step: 777800, eval_loss: 2.94671e-02
I0211 16:59:36.529736 22542570456896 run_lib.py:133] step: 777850, training_loss: 2.58418e-02
I0211 16:59:54.004658 22542570456896 run_lib.py:133] step: 777900, training_loss: 2.77519e-02
I0211 16:59:54.164726 22542570456896 run_lib.py:146] step: 777900, eval_loss: 2.54454e-02
I0211 17:00:11.729726 22542570456896 run_lib.py:133] step: 777950, training_loss: 2.33145e-02
I0211 17:00:29.151016 22542570456896 run_lib.py:133] step: 778000, training_loss: 1.96273e-02
I0211 17:00:29.319352 22542570456896 run_lib.py:146] step: 778000, eval_loss: 2.89325e-02
I0211 17:00:46.913105 22542570456896 run_lib.py:133] step: 778050, training_loss: 2.39180e-02
I0211 17:01:04.383279 22542570456896 run_lib.py:133] step: 778100, training_loss: 2.24271e-02
I0211 17:01:04.557306 22542570456896 run_lib.py:146] step: 778100, eval_loss: 3.77456e-02
I0211 17:01:22.208468 22542570456896 run_lib.py:133] step: 778150, training_loss: 2.18990e-02
I0211 17:01:39.594848 22542570456896 run_lib.py:133] step: 778200, training_loss: 2.19464e-02
I0211 17:01:39.744220 22542570456896 run_lib.py:146] step: 778200, eval_loss: 2.51404e-02
I0211 17:01:57.320605 22542570456896 run_lib.py:133] step: 778250, training_loss: 2.43998e-02
I0211 17:02:14.782696 22542570456896 run_lib.py:133] step: 778300, training_loss: 3.31978e-02
I0211 17:02:14.954634 22542570456896 run_lib.py:146] step: 778300, eval_loss: 2.62249e-02
I0211 17:02:32.399275 22542570456896 run_lib.py:133] step: 778350, training_loss: 2.65073e-02
I0211 17:02:50.031734 22542570456896 run_lib.py:133] step: 778400, training_loss: 2.80451e-02
I0211 17:02:50.189358 22542570456896 run_lib.py:146] step: 778400, eval_loss: 2.79604e-02
I0211 17:03:07.607945 22542570456896 run_lib.py:133] step: 778450, training_loss: 3.49258e-02
I0211 17:03:25.001205 22542570456896 run_lib.py:133] step: 778500, training_loss: 2.53212e-02
I0211 17:03:25.156448 22542570456896 run_lib.py:146] step: 778500, eval_loss: 2.83422e-02
I0211 17:03:42.740802 22542570456896 run_lib.py:133] step: 778550, training_loss: 2.59257e-02
I0211 17:04:00.398926 22542570456896 run_lib.py:133] step: 778600, training_loss: 2.61373e-02
I0211 17:04:00.554619 22542570456896 run_lib.py:146] step: 778600, eval_loss: 2.67513e-02
I0211 17:04:18.010592 22542570456896 run_lib.py:133] step: 778650, training_loss: 2.51477e-02
I0211 17:04:35.447895 22542570456896 run_lib.py:133] step: 778700, training_loss: 2.75214e-02
I0211 17:04:35.599369 22542570456896 run_lib.py:146] step: 778700, eval_loss: 2.76254e-02
I0211 17:04:53.021994 22542570456896 run_lib.py:133] step: 778750, training_loss: 2.82385e-02
I0211 17:05:10.615946 22542570456896 run_lib.py:133] step: 778800, training_loss: 2.43086e-02
I0211 17:05:10.771644 22542570456896 run_lib.py:146] step: 778800, eval_loss: 2.93197e-02
I0211 17:05:28.257229 22542570456896 run_lib.py:133] step: 778850, training_loss: 2.45672e-02
I0211 17:05:45.766563 22542570456896 run_lib.py:133] step: 778900, training_loss: 2.42215e-02
I0211 17:05:45.924604 22542570456896 run_lib.py:146] step: 778900, eval_loss: 2.69467e-02
I0211 17:06:03.338279 22542570456896 run_lib.py:133] step: 778950, training_loss: 2.47799e-02
I0211 17:06:20.944179 22542570456896 run_lib.py:133] step: 779000, training_loss: 2.89917e-02
I0211 17:06:21.101512 22542570456896 run_lib.py:146] step: 779000, eval_loss: 2.96587e-02
I0211 17:06:38.524230 22542570456896 run_lib.py:133] step: 779050, training_loss: 2.81788e-02
I0211 17:06:56.036274 22542570456896 run_lib.py:133] step: 779100, training_loss: 3.31870e-02
I0211 17:06:56.199636 22542570456896 run_lib.py:146] step: 779100, eval_loss: 2.73161e-02
I0211 17:07:13.650170 22542570456896 run_lib.py:133] step: 779150, training_loss: 2.86143e-02
I0211 17:07:31.116326 22542570456896 run_lib.py:133] step: 779200, training_loss: 3.15541e-02
I0211 17:07:31.269698 22542570456896 run_lib.py:146] step: 779200, eval_loss: 3.36295e-02
I0211 17:07:48.886417 22542570456896 run_lib.py:133] step: 779250, training_loss: 2.74401e-02
I0211 17:08:06.397114 22542570456896 run_lib.py:133] step: 779300, training_loss: 3.76972e-02
I0211 17:08:06.553572 22542570456896 run_lib.py:146] step: 779300, eval_loss: 3.16258e-02
I0211 17:08:23.931275 22542570456896 run_lib.py:133] step: 779350, training_loss: 3.08084e-02
I0211 17:08:41.382662 22542570456896 run_lib.py:133] step: 779400, training_loss: 3.29773e-02
I0211 17:08:41.553482 22542570456896 run_lib.py:146] step: 779400, eval_loss: 3.04987e-02
I0211 17:08:59.211089 22542570456896 run_lib.py:133] step: 779450, training_loss: 2.46937e-02
I0211 17:09:16.658378 22542570456896 run_lib.py:133] step: 779500, training_loss: 2.96505e-02
I0211 17:09:16.813638 22542570456896 run_lib.py:146] step: 779500, eval_loss: 2.90587e-02
I0211 17:09:34.365487 22542570456896 run_lib.py:133] step: 779550, training_loss: 2.76459e-02
I0211 17:09:51.768932 22542570456896 run_lib.py:133] step: 779600, training_loss: 2.55618e-02
I0211 17:09:51.920352 22542570456896 run_lib.py:146] step: 779600, eval_loss: 3.29733e-02
I0211 17:10:09.473145 22542570456896 run_lib.py:133] step: 779650, training_loss: 2.54860e-02
I0211 17:10:26.912065 22542570456896 run_lib.py:133] step: 779700, training_loss: 2.57024e-02
I0211 17:10:27.085471 22542570456896 run_lib.py:146] step: 779700, eval_loss: 2.76949e-02
I0211 17:10:44.493090 22542570456896 run_lib.py:133] step: 779750, training_loss: 2.61684e-02
I0211 17:11:02.101589 22542570456896 run_lib.py:133] step: 779800, training_loss: 2.87530e-02
I0211 17:11:02.260647 22542570456896 run_lib.py:146] step: 779800, eval_loss: 2.55895e-02
I0211 17:11:19.683280 22542570456896 run_lib.py:133] step: 779850, training_loss: 2.65625e-02
I0211 17:11:37.231984 22542570456896 run_lib.py:133] step: 779900, training_loss: 2.63947e-02
I0211 17:11:37.401470 22542570456896 run_lib.py:146] step: 779900, eval_loss: 2.87483e-02
I0211 17:11:54.869583 22542570456896 run_lib.py:133] step: 779950, training_loss: 2.72168e-02
I0211 17:12:12.309258 22542570456896 run_lib.py:133] step: 780000, training_loss: 2.58921e-02
I0211 17:12:13.059031 22542570456896 run_lib.py:146] step: 780000, eval_loss: 3.05448e-02
I0211 17:12:33.280287 22542570456896 run_lib.py:133] step: 780050, training_loss: 2.22237e-02
I0211 17:12:50.875463 22542570456896 run_lib.py:133] step: 780100, training_loss: 2.13229e-02
I0211 17:12:51.030384 22542570456896 run_lib.py:146] step: 780100, eval_loss: 2.65489e-02
I0211 17:13:08.448526 22542570456896 run_lib.py:133] step: 780150, training_loss: 2.66718e-02
I0211 17:13:26.032181 22542570456896 run_lib.py:133] step: 780200, training_loss: 2.76198e-02
I0211 17:13:26.186635 22542570456896 run_lib.py:146] step: 780200, eval_loss: 2.94943e-02
I0211 17:13:43.676310 22542570456896 run_lib.py:133] step: 780250, training_loss: 2.65516e-02
I0211 17:14:01.086324 22542570456896 run_lib.py:133] step: 780300, training_loss: 2.29771e-02
I0211 17:14:01.242422 22542570456896 run_lib.py:146] step: 780300, eval_loss: 2.53317e-02
I0211 17:14:18.815481 22542570456896 run_lib.py:133] step: 780350, training_loss: 3.31791e-02
I0211 17:14:36.255261 22542570456896 run_lib.py:133] step: 780400, training_loss: 3.62640e-02
I0211 17:14:36.412549 22542570456896 run_lib.py:146] step: 780400, eval_loss: 2.79233e-02
I0211 17:14:53.994753 22542570456896 run_lib.py:133] step: 780450, training_loss: 2.27300e-02
I0211 17:15:11.463131 22542570456896 run_lib.py:133] step: 780500, training_loss: 3.53847e-02
I0211 17:15:11.620583 22542570456896 run_lib.py:146] step: 780500, eval_loss: 2.92636e-02
I0211 17:15:29.071677 22542570456896 run_lib.py:133] step: 780550, training_loss: 2.88796e-02
I0211 17:15:46.702755 22542570456896 run_lib.py:133] step: 780600, training_loss: 3.02023e-02
I0211 17:15:46.857440 22542570456896 run_lib.py:146] step: 780600, eval_loss: 2.72627e-02
I0211 17:16:04.293385 22542570456896 run_lib.py:133] step: 780650, training_loss: 3.57541e-02
I0211 17:16:21.744163 22542570456896 run_lib.py:133] step: 780700, training_loss: 3.68587e-02
I0211 17:16:21.898753 22542570456896 run_lib.py:146] step: 780700, eval_loss: 2.87254e-02
I0211 17:16:39.329725 22542570456896 run_lib.py:133] step: 780750, training_loss: 2.99669e-02
I0211 17:16:56.966442 22542570456896 run_lib.py:133] step: 780800, training_loss: 2.50440e-02
I0211 17:16:57.125036 22542570456896 run_lib.py:146] step: 780800, eval_loss: 2.90257e-02
I0211 17:17:14.555143 22542570456896 run_lib.py:133] step: 780850, training_loss: 3.34247e-02
I0211 17:17:32.063988 22542570456896 run_lib.py:133] step: 780900, training_loss: 2.63464e-02
I0211 17:17:32.226698 22542570456896 run_lib.py:146] step: 780900, eval_loss: 3.10095e-02
I0211 17:17:49.667094 22542570456896 run_lib.py:133] step: 780950, training_loss: 2.50129e-02
I0211 17:18:07.062595 22542570456896 run_lib.py:133] step: 781000, training_loss: 2.45547e-02
I0211 17:18:07.222873 22542570456896 run_lib.py:146] step: 781000, eval_loss: 3.66610e-02
I0211 17:18:24.809484 22542570456896 run_lib.py:133] step: 781050, training_loss: 2.51694e-02
I0211 17:18:42.403517 22542570456896 run_lib.py:133] step: 781100, training_loss: 2.49663e-02
I0211 17:18:42.557070 22542570456896 run_lib.py:146] step: 781100, eval_loss: 2.66478e-02
I0211 17:18:59.997993 22542570456896 run_lib.py:133] step: 781150, training_loss: 3.15676e-02
I0211 17:19:17.429912 22542570456896 run_lib.py:133] step: 781200, training_loss: 2.37742e-02
I0211 17:19:17.586338 22542570456896 run_lib.py:146] step: 781200, eval_loss: 3.16814e-02
I0211 17:19:35.142355 22542570456896 run_lib.py:133] step: 781250, training_loss: 2.28164e-02
I0211 17:19:52.571678 22542570456896 run_lib.py:133] step: 781300, training_loss: 2.62487e-02
I0211 17:19:52.741149 22542570456896 run_lib.py:146] step: 781300, eval_loss: 2.74763e-02
I0211 17:20:10.338386 22542570456896 run_lib.py:133] step: 781350, training_loss: 3.08464e-02
I0211 17:20:27.793110 22542570456896 run_lib.py:133] step: 781400, training_loss: 2.81861e-02
I0211 17:20:27.954562 22542570456896 run_lib.py:146] step: 781400, eval_loss: 3.89911e-02
I0211 17:20:45.582402 22542570456896 run_lib.py:133] step: 781450, training_loss: 2.40524e-02
I0211 17:21:02.987880 22542570456896 run_lib.py:133] step: 781500, training_loss: 2.54200e-02
I0211 17:21:03.147506 22542570456896 run_lib.py:146] step: 781500, eval_loss: 2.31935e-02
I0211 17:21:20.544368 22542570456896 run_lib.py:133] step: 781550, training_loss: 2.87037e-02
I0211 17:21:38.190924 22542570456896 run_lib.py:133] step: 781600, training_loss: 2.11397e-02
I0211 17:21:38.341197 22542570456896 run_lib.py:146] step: 781600, eval_loss: 2.63890e-02
I0211 17:21:55.799991 22542570456896 run_lib.py:133] step: 781650, training_loss: 3.15262e-02
I0211 17:22:13.383389 22542570456896 run_lib.py:133] step: 781700, training_loss: 3.19407e-02
I0211 17:22:13.538964 22542570456896 run_lib.py:146] step: 781700, eval_loss: 2.48489e-02
I0211 17:22:30.911276 22542570456896 run_lib.py:133] step: 781750, training_loss: 2.56252e-02
I0211 17:22:48.401428 22542570456896 run_lib.py:133] step: 781800, training_loss: 2.04362e-02
I0211 17:22:48.559767 22542570456896 run_lib.py:146] step: 781800, eval_loss: 2.74626e-02
I0211 17:23:06.123806 22542570456896 run_lib.py:133] step: 781850, training_loss: 2.79988e-02
I0211 17:23:23.586565 22542570456896 run_lib.py:133] step: 781900, training_loss: 2.90560e-02
I0211 17:23:23.744599 22542570456896 run_lib.py:146] step: 781900, eval_loss: 2.55995e-02
I0211 17:23:41.144638 22542570456896 run_lib.py:133] step: 781950, training_loss: 2.61839e-02
I0211 17:23:58.765048 22542570456896 run_lib.py:133] step: 782000, training_loss: 2.20997e-02
I0211 17:23:58.921370 22542570456896 run_lib.py:146] step: 782000, eval_loss: 2.83008e-02
I0211 17:24:16.394507 22542570456896 run_lib.py:133] step: 782050, training_loss: 3.17538e-02
I0211 17:24:33.816515 22542570456896 run_lib.py:133] step: 782100, training_loss: 2.43745e-02
I0211 17:24:33.968449 22542570456896 run_lib.py:146] step: 782100, eval_loss: 3.24021e-02
I0211 17:24:51.440096 22542570456896 run_lib.py:133] step: 782150, training_loss: 2.66676e-02
I0211 17:25:08.921447 22542570456896 run_lib.py:133] step: 782200, training_loss: 3.24492e-02
I0211 17:25:09.085768 22542570456896 run_lib.py:146] step: 782200, eval_loss: 2.73899e-02
I0211 17:25:26.504889 22542570456896 run_lib.py:133] step: 782250, training_loss: 2.87832e-02
I0211 17:25:43.924657 22542570456896 run_lib.py:133] step: 782300, training_loss: 2.97294e-02
I0211 17:25:44.082678 22542570456896 run_lib.py:146] step: 782300, eval_loss: 2.86726e-02
I0211 17:26:01.652664 22542570456896 run_lib.py:133] step: 782350, training_loss: 3.27321e-02
I0211 17:26:19.093657 22542570456896 run_lib.py:133] step: 782400, training_loss: 2.16863e-02
I0211 17:26:19.249393 22542570456896 run_lib.py:146] step: 782400, eval_loss: 2.71804e-02
I0211 17:26:36.631221 22542570456896 run_lib.py:133] step: 782450, training_loss: 2.67941e-02
I0211 17:26:54.083345 22542570456896 run_lib.py:133] step: 782500, training_loss: 3.15826e-02
I0211 17:26:54.246702 22542570456896 run_lib.py:146] step: 782500, eval_loss: 2.59099e-02
I0211 17:27:11.869074 22542570456896 run_lib.py:133] step: 782550, training_loss: 2.99220e-02
I0211 17:27:29.274823 22542570456896 run_lib.py:133] step: 782600, training_loss: 2.98235e-02
I0211 17:27:29.427335 22542570456896 run_lib.py:146] step: 782600, eval_loss: 2.75768e-02
I0211 17:27:46.956169 22542570456896 run_lib.py:133] step: 782650, training_loss: 3.14685e-02
I0211 17:28:04.367918 22542570456896 run_lib.py:133] step: 782700, training_loss: 2.85733e-02
I0211 17:28:04.529781 22542570456896 run_lib.py:146] step: 782700, eval_loss: 2.99694e-02
I0211 17:28:22.094022 22542570456896 run_lib.py:133] step: 782750, training_loss: 2.29521e-02
I0211 17:28:39.531616 22542570456896 run_lib.py:133] step: 782800, training_loss: 2.02083e-02
I0211 17:28:39.686296 22542570456896 run_lib.py:146] step: 782800, eval_loss: 2.33930e-02
I0211 17:28:57.242138 22542570456896 run_lib.py:133] step: 782850, training_loss: 2.57358e-02
I0211 17:29:14.661708 22542570456896 run_lib.py:133] step: 782900, training_loss: 3.45404e-02
I0211 17:29:14.825145 22542570456896 run_lib.py:146] step: 782900, eval_loss: 2.79477e-02
I0211 17:29:32.268674 22542570456896 run_lib.py:133] step: 782950, training_loss: 2.36875e-02
I0211 17:29:49.838648 22542570456896 run_lib.py:133] step: 783000, training_loss: 2.25041e-02
I0211 17:29:50.001164 22542570456896 run_lib.py:146] step: 783000, eval_loss: 2.93221e-02
I0211 17:30:07.480490 22542570456896 run_lib.py:133] step: 783050, training_loss: 2.78968e-02
I0211 17:30:24.901309 22542570456896 run_lib.py:133] step: 783100, training_loss: 2.29391e-02
I0211 17:30:25.054523 22542570456896 run_lib.py:146] step: 783100, eval_loss: 2.85083e-02
I0211 17:30:42.656080 22542570456896 run_lib.py:133] step: 783150, training_loss: 2.66318e-02
I0211 17:31:00.087085 22542570456896 run_lib.py:133] step: 783200, training_loss: 3.48668e-02
I0211 17:31:00.244518 22542570456896 run_lib.py:146] step: 783200, eval_loss: 3.01127e-02
I0211 17:31:17.808136 22542570456896 run_lib.py:133] step: 783250, training_loss: 2.59879e-02
I0211 17:31:35.262715 22542570456896 run_lib.py:133] step: 783300, training_loss: 2.18469e-02
I0211 17:31:35.423583 22542570456896 run_lib.py:146] step: 783300, eval_loss: 2.85019e-02
I0211 17:31:52.846468 22542570456896 run_lib.py:133] step: 783350, training_loss: 2.34098e-02
I0211 17:32:10.445162 22542570456896 run_lib.py:133] step: 783400, training_loss: 2.67390e-02
I0211 17:32:10.599730 22542570456896 run_lib.py:146] step: 783400, eval_loss: 2.85443e-02
I0211 17:32:27.991490 22542570456896 run_lib.py:133] step: 783450, training_loss: 1.83073e-02
I0211 17:32:45.384793 22542570456896 run_lib.py:133] step: 783500, training_loss: 2.41285e-02
I0211 17:32:45.537391 22542570456896 run_lib.py:146] step: 783500, eval_loss: 2.84088e-02
I0211 17:33:02.917019 22542570456896 run_lib.py:133] step: 783550, training_loss: 2.68030e-02
I0211 17:33:20.498671 22542570456896 run_lib.py:133] step: 783600, training_loss: 2.98428e-02
I0211 17:33:20.668675 22542570456896 run_lib.py:146] step: 783600, eval_loss: 3.01787e-02
I0211 17:33:38.102245 22542570456896 run_lib.py:133] step: 783650, training_loss: 2.79294e-02
I0211 17:33:55.593055 22542570456896 run_lib.py:133] step: 783700, training_loss: 2.11812e-02
I0211 17:33:55.751559 22542570456896 run_lib.py:146] step: 783700, eval_loss: 2.46235e-02
I0211 17:34:13.161064 22542570456896 run_lib.py:133] step: 783750, training_loss: 3.44439e-02
I0211 17:34:30.510522 22542570456896 run_lib.py:133] step: 783800, training_loss: 2.44918e-02
I0211 17:34:30.665367 22542570456896 run_lib.py:146] step: 783800, eval_loss: 2.99718e-02
I0211 17:34:48.203067 22542570456896 run_lib.py:133] step: 783850, training_loss: 2.64863e-02
I0211 17:35:05.753251 22542570456896 run_lib.py:133] step: 783900, training_loss: 2.35552e-02
I0211 17:35:05.911532 22542570456896 run_lib.py:146] step: 783900, eval_loss: 2.60000e-02
I0211 17:35:23.352828 22542570456896 run_lib.py:133] step: 783950, training_loss: 2.38251e-02
I0211 17:35:40.719269 22542570456896 run_lib.py:133] step: 784000, training_loss: 2.72028e-02
I0211 17:35:40.869276 22542570456896 run_lib.py:146] step: 784000, eval_loss: 2.49278e-02
I0211 17:35:58.341573 22542570456896 run_lib.py:133] step: 784050, training_loss: 2.65466e-02
I0211 17:36:15.699481 22542570456896 run_lib.py:133] step: 784100, training_loss: 2.40921e-02
I0211 17:36:15.869554 22542570456896 run_lib.py:146] step: 784100, eval_loss: 3.54644e-02
I0211 17:36:33.443315 22542570456896 run_lib.py:133] step: 784150, training_loss: 2.58434e-02
I0211 17:36:50.826460 22542570456896 run_lib.py:133] step: 784200, training_loss: 3.08367e-02
I0211 17:36:50.984323 22542570456896 run_lib.py:146] step: 784200, eval_loss: 2.63695e-02
I0211 17:37:08.549804 22542570456896 run_lib.py:133] step: 784250, training_loss: 2.69497e-02
I0211 17:37:25.932540 22542570456896 run_lib.py:133] step: 784300, training_loss: 2.37495e-02
I0211 17:37:26.095364 22542570456896 run_lib.py:146] step: 784300, eval_loss: 3.00117e-02
I0211 17:37:43.490797 22542570456896 run_lib.py:133] step: 784350, training_loss: 2.44649e-02
I0211 17:38:01.085677 22542570456896 run_lib.py:133] step: 784400, training_loss: 3.11688e-02
I0211 17:38:01.240544 22542570456896 run_lib.py:146] step: 784400, eval_loss: 3.46723e-02
I0211 17:38:18.662489 22542570456896 run_lib.py:133] step: 784450, training_loss: 2.31167e-02
I0211 17:38:36.297830 22542570456896 run_lib.py:133] step: 784500, training_loss: 2.39591e-02
I0211 17:38:36.449480 22542570456896 run_lib.py:146] step: 784500, eval_loss: 4.27545e-02
I0211 17:38:53.832106 22542570456896 run_lib.py:133] step: 784550, training_loss: 2.41550e-02
I0211 17:39:11.238479 22542570456896 run_lib.py:133] step: 784600, training_loss: 3.15723e-02
I0211 17:39:11.397918 22542570456896 run_lib.py:146] step: 784600, eval_loss: 3.02333e-02
I0211 17:39:28.927705 22542570456896 run_lib.py:133] step: 784650, training_loss: 3.22491e-02
I0211 17:39:46.378160 22542570456896 run_lib.py:133] step: 784700, training_loss: 2.51455e-02
I0211 17:39:46.535479 22542570456896 run_lib.py:146] step: 784700, eval_loss: 3.43120e-02
I0211 17:40:03.932186 22542570456896 run_lib.py:133] step: 784750, training_loss: 2.27285e-02
I0211 17:40:21.492724 22542570456896 run_lib.py:133] step: 784800, training_loss: 3.39575e-02
I0211 17:40:21.650409 22542570456896 run_lib.py:146] step: 784800, eval_loss: 3.58777e-02
I0211 17:40:39.046661 22542570456896 run_lib.py:133] step: 784850, training_loss: 2.94000e-02
I0211 17:40:56.419885 22542570456896 run_lib.py:133] step: 784900, training_loss: 2.87344e-02
I0211 17:40:56.718993 22542570456896 run_lib.py:146] step: 784900, eval_loss: 3.16834e-02
I0211 17:41:14.113259 22542570456896 run_lib.py:133] step: 784950, training_loss: 2.35712e-02
I0211 17:41:31.528573 22542570456896 run_lib.py:133] step: 785000, training_loss: 3.39352e-02
I0211 17:41:31.686843 22542570456896 run_lib.py:146] step: 785000, eval_loss: 3.10741e-02
I0211 17:41:49.116737 22542570456896 run_lib.py:133] step: 785050, training_loss: 2.61178e-02
I0211 17:42:06.536297 22542570456896 run_lib.py:133] step: 785100, training_loss: 2.42239e-02
I0211 17:42:06.696386 22542570456896 run_lib.py:146] step: 785100, eval_loss: 2.66686e-02
I0211 17:42:24.248202 22542570456896 run_lib.py:133] step: 785150, training_loss: 2.40117e-02
I0211 17:42:41.749089 22542570456896 run_lib.py:133] step: 785200, training_loss: 3.05842e-02
I0211 17:42:41.911545 22542570456896 run_lib.py:146] step: 785200, eval_loss: 2.76737e-02
I0211 17:42:59.319883 22542570456896 run_lib.py:133] step: 785250, training_loss: 2.54082e-02
I0211 17:43:16.713324 22542570456896 run_lib.py:133] step: 785300, training_loss: 2.32449e-02
I0211 17:43:16.867537 22542570456896 run_lib.py:146] step: 785300, eval_loss: 3.25476e-02
I0211 17:43:34.469165 22542570456896 run_lib.py:133] step: 785350, training_loss: 2.93333e-02
I0211 17:43:51.908068 22542570456896 run_lib.py:133] step: 785400, training_loss: 2.35901e-02
I0211 17:43:52.059033 22542570456896 run_lib.py:146] step: 785400, eval_loss: 2.83871e-02
I0211 17:44:09.503298 22542570456896 run_lib.py:133] step: 785450, training_loss: 3.20887e-02
I0211 17:44:26.897480 22542570456896 run_lib.py:133] step: 785500, training_loss: 2.96776e-02
I0211 17:44:27.062607 22542570456896 run_lib.py:146] step: 785500, eval_loss: 2.64617e-02
I0211 17:44:44.664272 22542570456896 run_lib.py:133] step: 785550, training_loss: 2.81745e-02
I0211 17:45:02.038714 22542570456896 run_lib.py:133] step: 785600, training_loss: 2.41369e-02
I0211 17:45:02.204047 22542570456896 run_lib.py:146] step: 785600, eval_loss: 2.67758e-02
I0211 17:45:19.702596 22542570456896 run_lib.py:133] step: 785650, training_loss: 2.30612e-02
I0211 17:45:37.078925 22542570456896 run_lib.py:133] step: 785700, training_loss: 3.07183e-02
I0211 17:45:37.248262 22542570456896 run_lib.py:146] step: 785700, eval_loss: 2.79988e-02
I0211 17:45:54.820253 22542570456896 run_lib.py:133] step: 785750, training_loss: 3.40135e-02
I0211 17:46:12.283912 22542570456896 run_lib.py:133] step: 785800, training_loss: 2.98158e-02
I0211 17:46:12.442669 22542570456896 run_lib.py:146] step: 785800, eval_loss: 2.79115e-02
I0211 17:46:29.867434 22542570456896 run_lib.py:133] step: 785850, training_loss: 2.58659e-02
I0211 17:46:47.389917 22542570456896 run_lib.py:133] step: 785900, training_loss: 3.47990e-02
I0211 17:46:47.545357 22542570456896 run_lib.py:146] step: 785900, eval_loss: 3.01284e-02
I0211 17:47:04.944340 22542570456896 run_lib.py:133] step: 785950, training_loss: 2.35029e-02
I0211 17:47:22.487017 22542570456896 run_lib.py:133] step: 786000, training_loss: 2.42233e-02
I0211 17:47:22.656518 22542570456896 run_lib.py:146] step: 786000, eval_loss: 3.21847e-02
I0211 17:47:40.117874 22542570456896 run_lib.py:133] step: 786050, training_loss: 2.75245e-02
I0211 17:47:57.576998 22542570456896 run_lib.py:133] step: 786100, training_loss: 3.00245e-02
I0211 17:47:57.735108 22542570456896 run_lib.py:146] step: 786100, eval_loss: 2.65679e-02
I0211 17:48:15.315573 22542570456896 run_lib.py:133] step: 786150, training_loss: 2.44145e-02
I0211 17:48:32.743226 22542570456896 run_lib.py:133] step: 786200, training_loss: 2.68059e-02
I0211 17:48:32.899038 22542570456896 run_lib.py:146] step: 786200, eval_loss: 2.70492e-02
I0211 17:48:50.298829 22542570456896 run_lib.py:133] step: 786250, training_loss: 2.37394e-02
I0211 17:49:07.790282 22542570456896 run_lib.py:133] step: 786300, training_loss: 2.82723e-02
I0211 17:49:07.954405 22542570456896 run_lib.py:146] step: 786300, eval_loss: 2.76983e-02
I0211 17:49:25.533721 22542570456896 run_lib.py:133] step: 786350, training_loss: 2.72221e-02
I0211 17:49:42.923609 22542570456896 run_lib.py:133] step: 786400, training_loss: 3.14718e-02
I0211 17:49:43.075211 22542570456896 run_lib.py:146] step: 786400, eval_loss: 3.59599e-02
I0211 17:50:00.490481 22542570456896 run_lib.py:133] step: 786450, training_loss: 2.53828e-02
I0211 17:50:17.849620 22542570456896 run_lib.py:133] step: 786500, training_loss: 3.05042e-02
I0211 17:50:18.013191 22542570456896 run_lib.py:146] step: 786500, eval_loss: 2.81423e-02
I0211 17:50:35.423993 22542570456896 run_lib.py:133] step: 786550, training_loss: 2.64718e-02
I0211 17:50:52.851483 22542570456896 run_lib.py:133] step: 786600, training_loss: 2.14205e-02
I0211 17:50:53.006483 22542570456896 run_lib.py:146] step: 786600, eval_loss: 2.90060e-02
I0211 17:51:10.550947 22542570456896 run_lib.py:133] step: 786650, training_loss: 2.77985e-02
I0211 17:51:27.998444 22542570456896 run_lib.py:133] step: 786700, training_loss: 3.45607e-02
I0211 17:51:28.152146 22542570456896 run_lib.py:146] step: 786700, eval_loss: 3.07073e-02
I0211 17:51:45.573980 22542570456896 run_lib.py:133] step: 786750, training_loss: 3.12502e-02
I0211 17:52:02.961078 22542570456896 run_lib.py:133] step: 786800, training_loss: 3.19549e-02
I0211 17:52:03.114127 22542570456896 run_lib.py:146] step: 786800, eval_loss: 3.30937e-02
I0211 17:52:20.711261 22542570456896 run_lib.py:133] step: 786850, training_loss: 2.80607e-02
I0211 17:52:38.112939 22542570456896 run_lib.py:133] step: 786900, training_loss: 2.67468e-02
I0211 17:52:38.265227 22542570456896 run_lib.py:146] step: 786900, eval_loss: 2.53987e-02
I0211 17:52:55.812492 22542570456896 run_lib.py:133] step: 786950, training_loss: 3.04873e-02
I0211 17:53:13.187834 22542570456896 run_lib.py:133] step: 787000, training_loss: 2.81051e-02
I0211 17:53:13.343695 22542570456896 run_lib.py:146] step: 787000, eval_loss: 2.45069e-02
I0211 17:53:30.858813 22542570456896 run_lib.py:133] step: 787050, training_loss: 2.97858e-02
I0211 17:53:48.280097 22542570456896 run_lib.py:133] step: 787100, training_loss: 2.63815e-02
I0211 17:53:48.449287 22542570456896 run_lib.py:146] step: 787100, eval_loss: 3.00856e-02
I0211 17:54:06.031446 22542570456896 run_lib.py:133] step: 787150, training_loss: 2.13860e-02
I0211 17:54:23.367787 22542570456896 run_lib.py:133] step: 787200, training_loss: 2.87303e-02
I0211 17:54:23.522701 22542570456896 run_lib.py:146] step: 787200, eval_loss: 2.95874e-02
I0211 17:54:40.832528 22542570456896 run_lib.py:133] step: 787250, training_loss: 2.22307e-02
I0211 17:54:58.265449 22542570456896 run_lib.py:133] step: 787300, training_loss: 2.76069e-02
I0211 17:54:58.414288 22542570456896 run_lib.py:146] step: 787300, eval_loss: 3.60051e-02
I0211 17:55:15.793968 22542570456896 run_lib.py:133] step: 787350, training_loss: 2.95842e-02
I0211 17:55:33.230065 22542570456896 run_lib.py:133] step: 787400, training_loss: 2.82485e-02
I0211 17:55:33.401359 22542570456896 run_lib.py:146] step: 787400, eval_loss: 2.90395e-02
I0211 17:55:51.016083 22542570456896 run_lib.py:133] step: 787450, training_loss: 2.78845e-02
I0211 17:56:08.650365 22542570456896 run_lib.py:133] step: 787500, training_loss: 2.55520e-02
I0211 17:56:08.809400 22542570456896 run_lib.py:146] step: 787500, eval_loss: 2.79135e-02
I0211 17:56:26.206515 22542570456896 run_lib.py:133] step: 787550, training_loss: 2.95842e-02
I0211 17:56:43.591386 22542570456896 run_lib.py:133] step: 787600, training_loss: 2.06695e-02
I0211 17:56:43.747411 22542570456896 run_lib.py:146] step: 787600, eval_loss: 3.00195e-02
I0211 17:57:01.150090 22542570456896 run_lib.py:133] step: 787650, training_loss: 3.81944e-02
I0211 17:57:18.788712 22542570456896 run_lib.py:133] step: 787700, training_loss: 2.38337e-02
I0211 17:57:18.941844 22542570456896 run_lib.py:146] step: 787700, eval_loss: 2.84471e-02
I0211 17:57:36.415007 22542570456896 run_lib.py:133] step: 787750, training_loss: 2.76720e-02
I0211 17:57:53.814644 22542570456896 run_lib.py:133] step: 787800, training_loss: 3.23034e-02
I0211 17:57:53.965654 22542570456896 run_lib.py:146] step: 787800, eval_loss: 2.83386e-02
I0211 17:58:11.377547 22542570456896 run_lib.py:133] step: 787850, training_loss: 2.74881e-02
I0211 17:58:29.003273 22542570456896 run_lib.py:133] step: 787900, training_loss: 3.33513e-02
I0211 17:58:29.158212 22542570456896 run_lib.py:146] step: 787900, eval_loss: 2.83621e-02
I0211 17:58:46.565639 22542570456896 run_lib.py:133] step: 787950, training_loss: 2.54257e-02
I0211 17:59:04.084091 22542570456896 run_lib.py:133] step: 788000, training_loss: 2.29510e-02
I0211 17:59:04.243389 22542570456896 run_lib.py:146] step: 788000, eval_loss: 2.66962e-02
I0211 17:59:21.647750 22542570456896 run_lib.py:133] step: 788050, training_loss: 2.96670e-02
I0211 17:59:39.061065 22542570456896 run_lib.py:133] step: 788100, training_loss: 2.93038e-02
I0211 17:59:39.223458 22542570456896 run_lib.py:146] step: 788100, eval_loss: 2.40913e-02
I0211 17:59:56.808781 22542570456896 run_lib.py:133] step: 788150, training_loss: 2.73288e-02
I0211 18:00:14.267374 22542570456896 run_lib.py:133] step: 788200, training_loss: 3.75229e-02
I0211 18:00:14.419991 22542570456896 run_lib.py:146] step: 788200, eval_loss: 2.30727e-02
I0211 18:00:31.924574 22542570456896 run_lib.py:133] step: 788250, training_loss: 2.37104e-02
I0211 18:00:49.381689 22542570456896 run_lib.py:133] step: 788300, training_loss: 2.14769e-02
I0211 18:00:49.544610 22542570456896 run_lib.py:146] step: 788300, eval_loss: 3.14147e-02
I0211 18:01:07.168041 22542570456896 run_lib.py:133] step: 788350, training_loss: 2.14911e-02
I0211 18:01:24.590476 22542570456896 run_lib.py:133] step: 788400, training_loss: 2.82079e-02
I0211 18:01:24.755514 22542570456896 run_lib.py:146] step: 788400, eval_loss: 2.94468e-02
I0211 18:01:42.300398 22542570456896 run_lib.py:133] step: 788450, training_loss: 2.83495e-02
I0211 18:01:59.703133 22542570456896 run_lib.py:133] step: 788500, training_loss: 4.18895e-02
I0211 18:01:59.869375 22542570456896 run_lib.py:146] step: 788500, eval_loss: 2.67522e-02
I0211 18:02:17.513558 22542570456896 run_lib.py:133] step: 788550, training_loss: 2.12486e-02
I0211 18:02:34.946580 22542570456896 run_lib.py:133] step: 788600, training_loss: 3.07348e-02
I0211 18:02:35.107131 22542570456896 run_lib.py:146] step: 788600, eval_loss: 2.27154e-02
I0211 18:02:52.592464 22542570456896 run_lib.py:133] step: 788650, training_loss: 2.67987e-02
I0211 18:03:10.138144 22542570456896 run_lib.py:133] step: 788700, training_loss: 2.49100e-02
I0211 18:03:10.293047 22542570456896 run_lib.py:146] step: 788700, eval_loss: 2.77036e-02
I0211 18:03:27.687118 22542570456896 run_lib.py:133] step: 788750, training_loss: 2.83850e-02
I0211 18:03:45.255160 22542570456896 run_lib.py:133] step: 788800, training_loss: 2.93211e-02
I0211 18:03:45.418455 22542570456896 run_lib.py:146] step: 788800, eval_loss: 3.56206e-02
I0211 18:04:02.880435 22542570456896 run_lib.py:133] step: 788850, training_loss: 2.11985e-02
I0211 18:04:20.340633 22542570456896 run_lib.py:133] step: 788900, training_loss: 2.98833e-02
I0211 18:04:20.498003 22542570456896 run_lib.py:146] step: 788900, eval_loss: 2.57876e-02
I0211 18:04:38.081526 22542570456896 run_lib.py:133] step: 788950, training_loss: 2.24113e-02
I0211 18:04:55.461220 22542570456896 run_lib.py:133] step: 789000, training_loss: 2.97510e-02
I0211 18:04:55.616323 22542570456896 run_lib.py:146] step: 789000, eval_loss: 3.34580e-02
I0211 18:05:13.060654 22542570456896 run_lib.py:133] step: 789050, training_loss: 3.04360e-02
I0211 18:05:30.621493 22542570456896 run_lib.py:133] step: 789100, training_loss: 2.17086e-02
I0211 18:05:30.776468 22542570456896 run_lib.py:146] step: 789100, eval_loss: 2.53194e-02
I0211 18:05:48.216720 22542570456896 run_lib.py:133] step: 789150, training_loss: 3.25990e-02
I0211 18:06:05.649281 22542570456896 run_lib.py:133] step: 789200, training_loss: 2.41960e-02
I0211 18:06:05.804296 22542570456896 run_lib.py:146] step: 789200, eval_loss: 3.03943e-02
I0211 18:06:23.363739 22542570456896 run_lib.py:133] step: 789250, training_loss: 3.04157e-02
I0211 18:06:40.819072 22542570456896 run_lib.py:133] step: 789300, training_loss: 2.63902e-02
I0211 18:06:40.976305 22542570456896 run_lib.py:146] step: 789300, eval_loss: 2.67402e-02
I0211 18:06:58.377823 22542570456896 run_lib.py:133] step: 789350, training_loss: 2.84190e-02
I0211 18:07:15.798610 22542570456896 run_lib.py:133] step: 789400, training_loss: 2.65430e-02
I0211 18:07:15.972387 22542570456896 run_lib.py:146] step: 789400, eval_loss: 3.40612e-02
I0211 18:07:33.571882 22542570456896 run_lib.py:133] step: 789450, training_loss: 2.72504e-02
I0211 18:07:51.101560 22542570456896 run_lib.py:133] step: 789500, training_loss: 1.86508e-02
I0211 18:07:51.257602 22542570456896 run_lib.py:146] step: 789500, eval_loss: 3.29242e-02
I0211 18:08:08.642588 22542570456896 run_lib.py:133] step: 789550, training_loss: 3.33857e-02
I0211 18:08:26.053009 22542570456896 run_lib.py:133] step: 789600, training_loss: 3.00119e-02
I0211 18:08:26.207474 22542570456896 run_lib.py:146] step: 789600, eval_loss: 3.98785e-02
I0211 18:08:43.766784 22542570456896 run_lib.py:133] step: 789650, training_loss: 2.40371e-02
I0211 18:09:01.217514 22542570456896 run_lib.py:133] step: 789700, training_loss: 2.78186e-02
I0211 18:09:01.380686 22542570456896 run_lib.py:146] step: 789700, eval_loss: 2.63935e-02
I0211 18:09:18.958483 22542570456896 run_lib.py:133] step: 789750, training_loss: 2.57561e-02
I0211 18:09:36.375511 22542570456896 run_lib.py:133] step: 789800, training_loss: 2.55750e-02
I0211 18:09:36.531295 22542570456896 run_lib.py:146] step: 789800, eval_loss: 3.61533e-02
I0211 18:09:54.143552 22542570456896 run_lib.py:133] step: 789850, training_loss: 2.57265e-02
I0211 18:10:11.525130 22542570456896 run_lib.py:133] step: 789900, training_loss: 2.17772e-02
I0211 18:10:11.682499 22542570456896 run_lib.py:146] step: 789900, eval_loss: 3.20813e-02
I0211 18:10:29.235071 22542570456896 run_lib.py:133] step: 789950, training_loss: 2.88187e-02
I0211 18:10:46.706148 22542570456896 run_lib.py:133] step: 790000, training_loss: 3.34373e-02
I0211 18:10:47.406008 22542570456896 run_lib.py:146] step: 790000, eval_loss: 3.06394e-02
I0211 18:11:07.504263 22542570456896 run_lib.py:133] step: 790050, training_loss: 2.36932e-02
I0211 18:11:25.060931 22542570456896 run_lib.py:133] step: 790100, training_loss: 3.41531e-02
I0211 18:11:25.216196 22542570456896 run_lib.py:146] step: 790100, eval_loss: 2.86172e-02
I0211 18:11:42.622440 22542570456896 run_lib.py:133] step: 790150, training_loss: 2.41373e-02
I0211 18:12:00.086881 22542570456896 run_lib.py:133] step: 790200, training_loss: 2.15730e-02
I0211 18:12:00.241173 22542570456896 run_lib.py:146] step: 790200, eval_loss: 2.89576e-02
I0211 18:12:17.666855 22542570456896 run_lib.py:133] step: 790250, training_loss: 2.77965e-02
I0211 18:12:35.072199 22542570456896 run_lib.py:133] step: 790300, training_loss: 2.11079e-02
I0211 18:12:35.227567 22542570456896 run_lib.py:146] step: 790300, eval_loss: 3.21753e-02
I0211 18:12:52.840994 22542570456896 run_lib.py:133] step: 790350, training_loss: 3.66228e-02
I0211 18:13:10.305456 22542570456896 run_lib.py:133] step: 790400, training_loss: 2.80827e-02
I0211 18:13:10.472467 22542570456896 run_lib.py:146] step: 790400, eval_loss: 3.05360e-02
I0211 18:13:27.870790 22542570456896 run_lib.py:133] step: 790450, training_loss: 2.42703e-02
I0211 18:13:45.259936 22542570456896 run_lib.py:133] step: 790500, training_loss: 2.26772e-02
I0211 18:13:45.424233 22542570456896 run_lib.py:146] step: 790500, eval_loss: 2.67754e-02
I0211 18:14:03.012527 22542570456896 run_lib.py:133] step: 790550, training_loss: 2.84352e-02
I0211 18:14:20.459680 22542570456896 run_lib.py:133] step: 790600, training_loss: 3.19336e-02
I0211 18:14:20.613898 22542570456896 run_lib.py:146] step: 790600, eval_loss: 2.85768e-02
I0211 18:14:38.258607 22542570456896 run_lib.py:133] step: 790650, training_loss: 2.32008e-02
I0211 18:14:55.677774 22542570456896 run_lib.py:133] step: 790700, training_loss: 2.42918e-02
I0211 18:14:55.828366 22542570456896 run_lib.py:146] step: 790700, eval_loss: 2.80719e-02
I0211 18:15:13.358734 22542570456896 run_lib.py:133] step: 790750, training_loss: 3.41040e-02
I0211 18:15:30.809813 22542570456896 run_lib.py:133] step: 790800, training_loss: 3.02818e-02
I0211 18:15:30.978613 22542570456896 run_lib.py:146] step: 790800, eval_loss: 2.14675e-02
I0211 18:15:48.436639 22542570456896 run_lib.py:133] step: 790850, training_loss: 2.79189e-02
I0211 18:16:06.038672 22542570456896 run_lib.py:133] step: 790900, training_loss: 2.81867e-02
I0211 18:16:06.195545 22542570456896 run_lib.py:146] step: 790900, eval_loss: 2.94690e-02
I0211 18:16:23.623390 22542570456896 run_lib.py:133] step: 790950, training_loss: 2.98073e-02
I0211 18:16:41.187851 22542570456896 run_lib.py:133] step: 791000, training_loss: 2.55309e-02
I0211 18:16:41.344255 22542570456896 run_lib.py:146] step: 791000, eval_loss: 2.39131e-02
I0211 18:16:58.693897 22542570456896 run_lib.py:133] step: 791050, training_loss: 3.13791e-02
I0211 18:17:16.124420 22542570456896 run_lib.py:133] step: 791100, training_loss: 2.46795e-02
I0211 18:17:16.281096 22542570456896 run_lib.py:146] step: 791100, eval_loss: 3.05511e-02
I0211 18:17:33.914942 22542570456896 run_lib.py:133] step: 791150, training_loss: 3.17621e-02
I0211 18:17:51.356649 22542570456896 run_lib.py:133] step: 791200, training_loss: 3.14275e-02
I0211 18:17:51.518204 22542570456896 run_lib.py:146] step: 791200, eval_loss: 3.53168e-02
I0211 18:18:08.926499 22542570456896 run_lib.py:133] step: 791250, training_loss: 2.92209e-02
I0211 18:18:26.525005 22542570456896 run_lib.py:133] step: 791300, training_loss: 2.49232e-02
I0211 18:18:26.693350 22542570456896 run_lib.py:146] step: 791300, eval_loss: 3.57532e-02
I0211 18:18:44.143846 22542570456896 run_lib.py:133] step: 791350, training_loss: 2.34173e-02
I0211 18:19:01.589837 22542570456896 run_lib.py:133] step: 791400, training_loss: 2.00101e-02
I0211 18:19:01.746459 22542570456896 run_lib.py:146] step: 791400, eval_loss: 2.82898e-02
I0211 18:19:19.209339 22542570456896 run_lib.py:133] step: 791450, training_loss: 2.46222e-02
I0211 18:19:36.609057 22542570456896 run_lib.py:133] step: 791500, training_loss: 2.59844e-02
I0211 18:19:36.763512 22542570456896 run_lib.py:146] step: 791500, eval_loss: 2.48845e-02
I0211 18:19:54.185129 22542570456896 run_lib.py:133] step: 791550, training_loss: 2.66817e-02
I0211 18:20:11.612897 22542570456896 run_lib.py:133] step: 791600, training_loss: 2.50952e-02
I0211 18:20:11.767433 22542570456896 run_lib.py:146] step: 791600, eval_loss: 2.76706e-02
I0211 18:20:29.371885 22542570456896 run_lib.py:133] step: 791650, training_loss: 2.62742e-02
I0211 18:20:46.882490 22542570456896 run_lib.py:133] step: 791700, training_loss: 2.53909e-02
I0211 18:20:47.044636 22542570456896 run_lib.py:146] step: 791700, eval_loss: 3.11562e-02
I0211 18:21:04.505943 22542570456896 run_lib.py:133] step: 791750, training_loss: 3.10789e-02
I0211 18:21:21.969987 22542570456896 run_lib.py:133] step: 791800, training_loss: 2.46499e-02
I0211 18:21:22.133608 22542570456896 run_lib.py:146] step: 791800, eval_loss: 2.83342e-02
I0211 18:21:39.637469 22542570456896 run_lib.py:133] step: 791850, training_loss: 2.67721e-02
I0211 18:21:57.019186 22542570456896 run_lib.py:133] step: 791900, training_loss: 2.32721e-02
I0211 18:21:57.196336 22542570456896 run_lib.py:146] step: 791900, eval_loss: 3.62360e-02
I0211 18:22:14.834537 22542570456896 run_lib.py:133] step: 791950, training_loss: 2.41231e-02
I0211 18:22:32.224895 22542570456896 run_lib.py:133] step: 792000, training_loss: 2.68597e-02
I0211 18:22:32.380271 22542570456896 run_lib.py:146] step: 792000, eval_loss: 2.60791e-02
I0211 18:22:49.948673 22542570456896 run_lib.py:133] step: 792050, training_loss: 2.85817e-02
I0211 18:23:07.316442 22542570456896 run_lib.py:133] step: 792100, training_loss: 2.84704e-02
I0211 18:23:07.464547 22542570456896 run_lib.py:146] step: 792100, eval_loss: 2.93529e-02
I0211 18:23:25.010231 22542570456896 run_lib.py:133] step: 792150, training_loss: 3.31778e-02
I0211 18:23:42.447049 22542570456896 run_lib.py:133] step: 792200, training_loss: 3.40312e-02
I0211 18:23:42.613530 22542570456896 run_lib.py:146] step: 792200, eval_loss: 2.74340e-02
I0211 18:24:00.047864 22542570456896 run_lib.py:133] step: 792250, training_loss: 2.20811e-02
I0211 18:24:17.670998 22542570456896 run_lib.py:133] step: 792300, training_loss: 2.88372e-02
I0211 18:24:17.828277 22542570456896 run_lib.py:146] step: 792300, eval_loss: 3.10528e-02
I0211 18:24:35.204360 22542570456896 run_lib.py:133] step: 792350, training_loss: 2.84094e-02
I0211 18:24:52.632554 22542570456896 run_lib.py:133] step: 792400, training_loss: 2.61697e-02
I0211 18:24:52.787239 22542570456896 run_lib.py:146] step: 792400, eval_loss: 2.38911e-02
I0211 18:25:10.361579 22542570456896 run_lib.py:133] step: 792450, training_loss: 2.41108e-02
I0211 18:25:27.780238 22542570456896 run_lib.py:133] step: 792500, training_loss: 3.33626e-02
I0211 18:25:27.942242 22542570456896 run_lib.py:146] step: 792500, eval_loss: 2.18629e-02
I0211 18:25:45.568018 22542570456896 run_lib.py:133] step: 792550, training_loss: 2.87593e-02
I0211 18:26:02.977518 22542570456896 run_lib.py:133] step: 792600, training_loss: 3.18382e-02
I0211 18:26:03.141658 22542570456896 run_lib.py:146] step: 792600, eval_loss: 3.46583e-02
I0211 18:26:20.504017 22542570456896 run_lib.py:133] step: 792650, training_loss: 2.47031e-02
I0211 18:26:38.123014 22542570456896 run_lib.py:133] step: 792700, training_loss: 2.42144e-02
I0211 18:26:38.284706 22542570456896 run_lib.py:146] step: 792700, eval_loss: 3.15517e-02
I0211 18:26:55.733145 22542570456896 run_lib.py:133] step: 792750, training_loss: 2.70968e-02
I0211 18:27:13.157077 22542570456896 run_lib.py:133] step: 792800, training_loss: 2.31904e-02
I0211 18:27:13.314355 22542570456896 run_lib.py:146] step: 792800, eval_loss: 2.45294e-02
I0211 18:27:30.709644 22542570456896 run_lib.py:133] step: 792850, training_loss: 2.64506e-02
I0211 18:27:48.303228 22542570456896 run_lib.py:133] step: 792900, training_loss: 2.56216e-02
I0211 18:27:48.458314 22542570456896 run_lib.py:146] step: 792900, eval_loss: 3.53033e-02
I0211 18:28:05.871839 22542570456896 run_lib.py:133] step: 792950, training_loss: 3.41808e-02
I0211 18:28:23.327690 22542570456896 run_lib.py:133] step: 793000, training_loss: 2.58970e-02
I0211 18:28:23.482855 22542570456896 run_lib.py:146] step: 793000, eval_loss: 3.90782e-02
I0211 18:28:40.943896 22542570456896 run_lib.py:133] step: 793050, training_loss: 2.63432e-02
I0211 18:28:58.398487 22542570456896 run_lib.py:133] step: 793100, training_loss: 2.80862e-02
I0211 18:28:58.551540 22542570456896 run_lib.py:146] step: 793100, eval_loss: 2.79470e-02
I0211 18:29:16.159491 22542570456896 run_lib.py:133] step: 793150, training_loss: 2.79498e-02
I0211 18:29:33.640996 22542570456896 run_lib.py:133] step: 793200, training_loss: 2.45038e-02
I0211 18:29:33.799540 22542570456896 run_lib.py:146] step: 793200, eval_loss: 3.49272e-02
I0211 18:29:51.179414 22542570456896 run_lib.py:133] step: 793250, training_loss: 3.45174e-02
I0211 18:30:08.591393 22542570456896 run_lib.py:133] step: 793300, training_loss: 3.65041e-02
I0211 18:30:08.777084 22542570456896 run_lib.py:146] step: 793300, eval_loss: 2.73886e-02
I0211 18:30:26.433650 22542570456896 run_lib.py:133] step: 793350, training_loss: 2.59441e-02
I0211 18:30:43.889194 22542570456896 run_lib.py:133] step: 793400, training_loss: 3.08095e-02
I0211 18:30:44.044245 22542570456896 run_lib.py:146] step: 793400, eval_loss: 2.97119e-02
I0211 18:31:01.626934 22542570456896 run_lib.py:133] step: 793450, training_loss: 2.91866e-02
I0211 18:31:19.043472 22542570456896 run_lib.py:133] step: 793500, training_loss: 2.51630e-02
I0211 18:31:19.199140 22542570456896 run_lib.py:146] step: 793500, eval_loss: 2.55717e-02
I0211 18:31:36.786703 22542570456896 run_lib.py:133] step: 793550, training_loss: 2.68871e-02
I0211 18:31:54.239745 22542570456896 run_lib.py:133] step: 793600, training_loss: 3.19109e-02
I0211 18:31:54.398842 22542570456896 run_lib.py:146] step: 793600, eval_loss: 3.35908e-02
I0211 18:32:11.844200 22542570456896 run_lib.py:133] step: 793650, training_loss: 3.16060e-02
I0211 18:32:29.434247 22542570456896 run_lib.py:133] step: 793700, training_loss: 2.29974e-02
I0211 18:32:29.589395 22542570456896 run_lib.py:146] step: 793700, eval_loss: 2.93843e-02
I0211 18:32:46.952149 22542570456896 run_lib.py:133] step: 793750, training_loss: 2.68680e-02
I0211 18:33:04.465422 22542570456896 run_lib.py:133] step: 793800, training_loss: 3.11716e-02
I0211 18:33:04.620453 22542570456896 run_lib.py:146] step: 793800, eval_loss: 2.90061e-02
I0211 18:33:22.074170 22542570456896 run_lib.py:133] step: 793850, training_loss: 2.67700e-02
I0211 18:33:39.541213 22542570456896 run_lib.py:133] step: 793900, training_loss: 3.18218e-02
I0211 18:33:39.697192 22542570456896 run_lib.py:146] step: 793900, eval_loss: 3.06729e-02
I0211 18:33:57.301568 22542570456896 run_lib.py:133] step: 793950, training_loss: 2.22738e-02
I0211 18:34:14.667678 22542570456896 run_lib.py:133] step: 794000, training_loss: 3.01164e-02
I0211 18:34:14.819343 22542570456896 run_lib.py:146] step: 794000, eval_loss: 2.59720e-02
I0211 18:34:32.213688 22542570456896 run_lib.py:133] step: 794050, training_loss: 2.49541e-02
I0211 18:34:49.754280 22542570456896 run_lib.py:133] step: 794100, training_loss: 2.84043e-02
I0211 18:34:49.911638 22542570456896 run_lib.py:146] step: 794100, eval_loss: 2.98236e-02
I0211 18:35:07.365031 22542570456896 run_lib.py:133] step: 794150, training_loss: 2.66029e-02
I0211 18:35:24.854801 22542570456896 run_lib.py:133] step: 794200, training_loss: 2.30080e-02
I0211 18:35:25.200352 22542570456896 run_lib.py:146] step: 794200, eval_loss: 3.51688e-02
I0211 18:35:42.614727 22542570456896 run_lib.py:133] step: 794250, training_loss: 2.78047e-02
I0211 18:36:00.000944 22542570456896 run_lib.py:133] step: 794300, training_loss: 2.73098e-02
I0211 18:36:00.156208 22542570456896 run_lib.py:146] step: 794300, eval_loss: 2.71095e-02
I0211 18:36:17.514741 22542570456896 run_lib.py:133] step: 794350, training_loss: 2.45740e-02
I0211 18:36:34.915491 22542570456896 run_lib.py:133] step: 794400, training_loss: 3.77331e-02
I0211 18:36:35.070523 22542570456896 run_lib.py:146] step: 794400, eval_loss: 2.47866e-02
I0211 18:36:52.629185 22542570456896 run_lib.py:133] step: 794450, training_loss: 3.23800e-02
I0211 18:37:10.187768 22542570456896 run_lib.py:133] step: 794500, training_loss: 2.59478e-02
I0211 18:37:10.341551 22542570456896 run_lib.py:146] step: 794500, eval_loss: 2.54276e-02
I0211 18:37:27.759965 22542570456896 run_lib.py:133] step: 794550, training_loss: 2.31621e-02
I0211 18:37:45.167598 22542570456896 run_lib.py:133] step: 794600, training_loss: 2.93813e-02
I0211 18:37:45.325480 22542570456896 run_lib.py:146] step: 794600, eval_loss: 2.53825e-02
I0211 18:38:02.818543 22542570456896 run_lib.py:133] step: 794650, training_loss: 2.73560e-02
I0211 18:38:20.277816 22542570456896 run_lib.py:133] step: 794700, training_loss: 2.96093e-02
I0211 18:38:20.439210 22542570456896 run_lib.py:146] step: 794700, eval_loss: 2.91043e-02
I0211 18:38:37.834304 22542570456896 run_lib.py:133] step: 794750, training_loss: 2.79452e-02
I0211 18:38:55.293440 22542570456896 run_lib.py:133] step: 794800, training_loss: 2.74499e-02
I0211 18:38:55.449557 22542570456896 run_lib.py:146] step: 794800, eval_loss: 2.66755e-02
I0211 18:39:13.008325 22542570456896 run_lib.py:133] step: 794850, training_loss: 2.26566e-02
I0211 18:39:30.418774 22542570456896 run_lib.py:133] step: 794900, training_loss: 3.27272e-02
I0211 18:39:30.573279 22542570456896 run_lib.py:146] step: 794900, eval_loss: 2.36037e-02
I0211 18:39:48.087736 22542570456896 run_lib.py:133] step: 794950, training_loss: 3.82354e-02
I0211 18:40:05.479217 22542570456896 run_lib.py:133] step: 795000, training_loss: 3.03975e-02
I0211 18:40:05.633576 22542570456896 run_lib.py:146] step: 795000, eval_loss: 3.09452e-02
I0211 18:40:23.287125 22542570456896 run_lib.py:133] step: 795050, training_loss: 2.23368e-02
I0211 18:40:40.665216 22542570456896 run_lib.py:133] step: 795100, training_loss: 3.13778e-02
I0211 18:40:40.825453 22542570456896 run_lib.py:146] step: 795100, eval_loss: 2.87331e-02
I0211 18:40:58.198107 22542570456896 run_lib.py:133] step: 795150, training_loss: 2.86744e-02
I0211 18:41:15.704958 22542570456896 run_lib.py:133] step: 795200, training_loss: 3.27374e-02
I0211 18:41:15.865529 22542570456896 run_lib.py:146] step: 795200, eval_loss: 3.26480e-02
I0211 18:41:33.259238 22542570456896 run_lib.py:133] step: 795250, training_loss: 2.99392e-02
I0211 18:41:50.888679 22542570456896 run_lib.py:133] step: 795300, training_loss: 2.45303e-02
I0211 18:41:51.044054 22542570456896 run_lib.py:146] step: 795300, eval_loss: 3.13477e-02
I0211 18:42:08.444894 22542570456896 run_lib.py:133] step: 795350, training_loss: 2.61709e-02
I0211 18:42:25.844738 22542570456896 run_lib.py:133] step: 795400, training_loss: 2.71580e-02
I0211 18:42:26.000732 22542570456896 run_lib.py:146] step: 795400, eval_loss: 3.12157e-02
I0211 18:42:43.560328 22542570456896 run_lib.py:133] step: 795450, training_loss: 2.57015e-02
I0211 18:43:00.969132 22542570456896 run_lib.py:133] step: 795500, training_loss: 2.77659e-02
I0211 18:43:01.121304 22542570456896 run_lib.py:146] step: 795500, eval_loss: 2.58168e-02
I0211 18:43:18.466401 22542570456896 run_lib.py:133] step: 795550, training_loss: 2.96366e-02
I0211 18:43:35.909825 22542570456896 run_lib.py:133] step: 795600, training_loss: 2.68357e-02
I0211 18:43:36.088322 22542570456896 run_lib.py:146] step: 795600, eval_loss: 2.80170e-02
I0211 18:43:53.807965 22542570456896 run_lib.py:133] step: 795650, training_loss: 2.61138e-02
I0211 18:44:11.258275 22542570456896 run_lib.py:133] step: 795700, training_loss: 2.81708e-02
I0211 18:44:11.413507 22542570456896 run_lib.py:146] step: 795700, eval_loss: 2.40151e-02
I0211 18:44:28.959355 22542570456896 run_lib.py:133] step: 795750, training_loss: 3.24192e-02
I0211 18:44:46.315458 22542570456896 run_lib.py:133] step: 795800, training_loss: 2.25780e-02
I0211 18:44:46.478632 22542570456896 run_lib.py:146] step: 795800, eval_loss: 3.07879e-02
I0211 18:45:03.861250 22542570456896 run_lib.py:133] step: 795850, training_loss: 3.77698e-02
I0211 18:45:21.346615 22542570456896 run_lib.py:133] step: 795900, training_loss: 3.32002e-02
I0211 18:45:21.499485 22542570456896 run_lib.py:146] step: 795900, eval_loss: 3.11765e-02
I0211 18:45:39.114298 22542570456896 run_lib.py:133] step: 795950, training_loss: 2.47828e-02
I0211 18:45:56.590188 22542570456896 run_lib.py:133] step: 796000, training_loss: 2.09666e-02
I0211 18:45:56.744858 22542570456896 run_lib.py:146] step: 796000, eval_loss: 3.15123e-02
I0211 18:46:14.138087 22542570456896 run_lib.py:133] step: 796050, training_loss: 2.69360e-02
I0211 18:46:31.563297 22542570456896 run_lib.py:133] step: 796100, training_loss: 2.12908e-02
I0211 18:46:31.722985 22542570456896 run_lib.py:146] step: 796100, eval_loss: 2.36018e-02
I0211 18:46:49.274854 22542570456896 run_lib.py:133] step: 796150, training_loss: 2.33371e-02
I0211 18:47:06.750697 22542570456896 run_lib.py:133] step: 796200, training_loss: 2.34653e-02
I0211 18:47:06.911550 22542570456896 run_lib.py:146] step: 796200, eval_loss: 2.51718e-02
I0211 18:47:24.510582 22542570456896 run_lib.py:133] step: 796250, training_loss: 3.14993e-02
I0211 18:47:41.874933 22542570456896 run_lib.py:133] step: 796300, training_loss: 2.74865e-02
I0211 18:47:42.030175 22542570456896 run_lib.py:146] step: 796300, eval_loss: 2.37310e-02
I0211 18:47:59.532886 22542570456896 run_lib.py:133] step: 796350, training_loss: 2.71135e-02
I0211 18:48:16.934745 22542570456896 run_lib.py:133] step: 796400, training_loss: 2.30483e-02
I0211 18:48:17.087472 22542570456896 run_lib.py:146] step: 796400, eval_loss: 2.77387e-02
I0211 18:48:34.669334 22542570456896 run_lib.py:133] step: 796450, training_loss: 2.49857e-02
I0211 18:48:52.068761 22542570456896 run_lib.py:133] step: 796500, training_loss: 2.06739e-02
I0211 18:48:52.233654 22542570456896 run_lib.py:146] step: 796500, eval_loss: 2.70274e-02
I0211 18:49:09.680940 22542570456896 run_lib.py:133] step: 796550, training_loss: 3.61471e-02
I0211 18:49:27.267310 22542570456896 run_lib.py:133] step: 796600, training_loss: 2.68778e-02
I0211 18:49:27.425473 22542570456896 run_lib.py:146] step: 796600, eval_loss: 2.48608e-02
I0211 18:49:44.869876 22542570456896 run_lib.py:133] step: 796650, training_loss: 2.61984e-02
I0211 18:50:02.275376 22542570456896 run_lib.py:133] step: 796700, training_loss: 2.87213e-02
I0211 18:50:02.447782 22542570456896 run_lib.py:146] step: 796700, eval_loss: 3.28320e-02
I0211 18:50:20.052235 22542570456896 run_lib.py:133] step: 796750, training_loss: 3.25769e-02
I0211 18:50:37.680778 22542570456896 run_lib.py:133] step: 796800, training_loss: 2.79907e-02
I0211 18:50:37.835161 22542570456896 run_lib.py:146] step: 796800, eval_loss: 2.25867e-02
I0211 18:50:55.270411 22542570456896 run_lib.py:133] step: 796850, training_loss: 2.16873e-02
I0211 18:51:12.685312 22542570456896 run_lib.py:133] step: 796900, training_loss: 2.53398e-02
I0211 18:51:12.838479 22542570456896 run_lib.py:146] step: 796900, eval_loss: 3.21209e-02
I0211 18:51:30.233807 22542570456896 run_lib.py:133] step: 796950, training_loss: 2.39094e-02
I0211 18:51:47.781216 22542570456896 run_lib.py:133] step: 797000, training_loss: 2.80201e-02
I0211 18:51:47.955276 22542570456896 run_lib.py:146] step: 797000, eval_loss: 2.58365e-02
I0211 18:52:05.396270 22542570456896 run_lib.py:133] step: 797050, training_loss: 2.95341e-02
I0211 18:52:22.815746 22542570456896 run_lib.py:133] step: 797100, training_loss: 2.59298e-02
I0211 18:52:22.970307 22542570456896 run_lib.py:146] step: 797100, eval_loss: 2.50160e-02
I0211 18:52:40.420174 22542570456896 run_lib.py:133] step: 797150, training_loss: 2.55550e-02
I0211 18:52:58.002183 22542570456896 run_lib.py:133] step: 797200, training_loss: 2.36820e-02
I0211 18:52:58.160401 22542570456896 run_lib.py:146] step: 797200, eval_loss: 2.90290e-02
I0211 18:53:15.570500 22542570456896 run_lib.py:133] step: 797250, training_loss: 3.20831e-02
I0211 18:53:33.081187 22542570456896 run_lib.py:133] step: 797300, training_loss: 2.98403e-02
I0211 18:53:33.233066 22542570456896 run_lib.py:146] step: 797300, eval_loss: 3.30959e-02
I0211 18:53:50.671710 22542570456896 run_lib.py:133] step: 797350, training_loss: 2.44323e-02
I0211 18:54:08.054594 22542570456896 run_lib.py:133] step: 797400, training_loss: 3.03026e-02
I0211 18:54:08.212351 22542570456896 run_lib.py:146] step: 797400, eval_loss: 2.99066e-02
I0211 18:54:25.802857 22542570456896 run_lib.py:133] step: 797450, training_loss: 1.99570e-02
I0211 18:54:43.263156 22542570456896 run_lib.py:133] step: 797500, training_loss: 3.31052e-02
I0211 18:54:43.425704 22542570456896 run_lib.py:146] step: 797500, eval_loss: 2.77236e-02
I0211 18:55:00.858496 22542570456896 run_lib.py:133] step: 797550, training_loss: 3.34703e-02
I0211 18:55:18.319146 22542570456896 run_lib.py:133] step: 797600, training_loss: 2.97570e-02
I0211 18:55:18.480574 22542570456896 run_lib.py:146] step: 797600, eval_loss: 2.42095e-02
I0211 18:55:36.028683 22542570456896 run_lib.py:133] step: 797650, training_loss: 3.03607e-02
I0211 18:55:53.442976 22542570456896 run_lib.py:133] step: 797700, training_loss: 2.90928e-02
I0211 18:55:53.603471 22542570456896 run_lib.py:146] step: 797700, eval_loss: 3.15888e-02
I0211 18:56:11.132243 22542570456896 run_lib.py:133] step: 797750, training_loss: 2.95818e-02
I0211 18:56:28.524355 22542570456896 run_lib.py:133] step: 797800, training_loss: 2.96078e-02
I0211 18:56:28.677151 22542570456896 run_lib.py:146] step: 797800, eval_loss: 3.15235e-02
I0211 18:56:46.301254 22542570456896 run_lib.py:133] step: 797850, training_loss: 2.57803e-02
I0211 18:57:03.682410 22542570456896 run_lib.py:133] step: 797900, training_loss: 2.94507e-02
I0211 18:57:03.837406 22542570456896 run_lib.py:146] step: 797900, eval_loss: 2.25660e-02
I0211 18:57:21.219020 22542570456896 run_lib.py:133] step: 797950, training_loss: 2.91172e-02
I0211 18:57:38.809125 22542570456896 run_lib.py:133] step: 798000, training_loss: 3.02210e-02
I0211 18:57:38.967574 22542570456896 run_lib.py:146] step: 798000, eval_loss: 2.21550e-02
I0211 18:57:56.387322 22542570456896 run_lib.py:133] step: 798050, training_loss: 3.65664e-02
I0211 18:58:13.917112 22542570456896 run_lib.py:133] step: 798100, training_loss: 2.73113e-02
I0211 18:58:14.086235 22542570456896 run_lib.py:146] step: 798100, eval_loss: 3.42450e-02
I0211 18:58:31.521186 22542570456896 run_lib.py:133] step: 798150, training_loss: 3.20587e-02
I0211 18:58:48.984990 22542570456896 run_lib.py:133] step: 798200, training_loss: 2.90404e-02
I0211 18:58:49.143689 22542570456896 run_lib.py:146] step: 798200, eval_loss: 2.70899e-02
I0211 18:59:06.743163 22542570456896 run_lib.py:133] step: 798250, training_loss: 2.66397e-02
I0211 18:59:24.114491 22542570456896 run_lib.py:133] step: 798300, training_loss: 2.13593e-02
I0211 18:59:24.265319 22542570456896 run_lib.py:146] step: 798300, eval_loss: 3.38516e-02
I0211 18:59:41.628514 22542570456896 run_lib.py:133] step: 798350, training_loss: 3.11375e-02
I0211 18:59:59.193861 22542570456896 run_lib.py:133] step: 798400, training_loss: 2.47260e-02
I0211 18:59:59.371039 22542570456896 run_lib.py:146] step: 798400, eval_loss: 2.77585e-02
I0211 19:00:16.813321 22542570456896 run_lib.py:133] step: 798450, training_loss: 2.91199e-02
I0211 19:00:34.220432 22542570456896 run_lib.py:133] step: 798500, training_loss: 2.98771e-02
I0211 19:00:34.379258 22542570456896 run_lib.py:146] step: 798500, eval_loss: 3.67967e-02
I0211 19:00:51.851576 22542570456896 run_lib.py:133] step: 798550, training_loss: 3.15719e-02
I0211 19:01:09.226600 22542570456896 run_lib.py:133] step: 798600, training_loss: 2.83460e-02
I0211 19:01:09.389805 22542570456896 run_lib.py:146] step: 798600, eval_loss: 2.47950e-02
I0211 19:01:26.784055 22542570456896 run_lib.py:133] step: 798650, training_loss: 3.06050e-02
I0211 19:01:44.197178 22542570456896 run_lib.py:133] step: 798700, training_loss: 3.12812e-02
I0211 19:01:44.350452 22542570456896 run_lib.py:146] step: 798700, eval_loss: 2.88023e-02
I0211 19:02:01.902250 22542570456896 run_lib.py:133] step: 798750, training_loss: 2.37755e-02
I0211 19:02:19.371044 22542570456896 run_lib.py:133] step: 798800, training_loss: 2.64155e-02
I0211 19:02:19.543097 22542570456896 run_lib.py:146] step: 798800, eval_loss: 3.28017e-02
I0211 19:02:36.901147 22542570456896 run_lib.py:133] step: 798850, training_loss: 3.02520e-02
I0211 19:02:54.245954 22542570456896 run_lib.py:133] step: 798900, training_loss: 3.44693e-02
I0211 19:02:54.402514 22542570456896 run_lib.py:146] step: 798900, eval_loss: 3.28780e-02
I0211 19:03:11.846783 22542570456896 run_lib.py:133] step: 798950, training_loss: 2.91882e-02
I0211 19:03:29.253896 22542570456896 run_lib.py:133] step: 799000, training_loss: 2.50093e-02
I0211 19:03:29.408427 22542570456896 run_lib.py:146] step: 799000, eval_loss: 2.76526e-02
I0211 19:03:46.854235 22542570456896 run_lib.py:133] step: 799050, training_loss: 2.42762e-02
I0211 19:04:04.234986 22542570456896 run_lib.py:133] step: 799100, training_loss: 2.55150e-02
I0211 19:04:04.391512 22542570456896 run_lib.py:146] step: 799100, eval_loss: 3.15872e-02
I0211 19:04:21.941184 22542570456896 run_lib.py:133] step: 799150, training_loss: 3.07606e-02
I0211 19:04:39.335161 22542570456896 run_lib.py:133] step: 799200, training_loss: 2.89711e-02
I0211 19:04:39.486001 22542570456896 run_lib.py:146] step: 799200, eval_loss: 2.16326e-02
I0211 19:04:57.003746 22542570456896 run_lib.py:133] step: 799250, training_loss: 3.42055e-02
I0211 19:05:14.452080 22542570456896 run_lib.py:133] step: 799300, training_loss: 3.25885e-02
I0211 19:05:14.614641 22542570456896 run_lib.py:146] step: 799300, eval_loss: 2.68490e-02
I0211 19:05:32.058391 22542570456896 run_lib.py:133] step: 799350, training_loss: 3.41282e-02
I0211 19:05:49.672218 22542570456896 run_lib.py:133] step: 799400, training_loss: 2.49577e-02
I0211 19:05:49.830735 22542570456896 run_lib.py:146] step: 799400, eval_loss: 2.99318e-02
I0211 19:06:07.268388 22542570456896 run_lib.py:133] step: 799450, training_loss: 3.20571e-02
I0211 19:06:24.644278 22542570456896 run_lib.py:133] step: 799500, training_loss: 2.53196e-02
I0211 19:06:24.807362 22542570456896 run_lib.py:146] step: 799500, eval_loss: 2.61551e-02
I0211 19:06:42.404821 22542570456896 run_lib.py:133] step: 799550, training_loss: 2.98489e-02
I0211 19:06:59.881422 22542570456896 run_lib.py:133] step: 799600, training_loss: 2.61426e-02
I0211 19:07:00.038596 22542570456896 run_lib.py:146] step: 799600, eval_loss: 3.36072e-02
I0211 19:07:17.635294 22542570456896 run_lib.py:133] step: 799650, training_loss: 2.76388e-02
I0211 19:07:35.070312 22542570456896 run_lib.py:133] step: 799700, training_loss: 3.41842e-02
I0211 19:07:35.223455 22542570456896 run_lib.py:146] step: 799700, eval_loss: 2.83153e-02
I0211 19:07:52.605205 22542570456896 run_lib.py:133] step: 799750, training_loss: 3.11134e-02
I0211 19:08:10.187375 22542570456896 run_lib.py:133] step: 799800, training_loss: 2.56044e-02
I0211 19:08:10.364371 22542570456896 run_lib.py:146] step: 799800, eval_loss: 3.28067e-02
I0211 19:08:27.797173 22542570456896 run_lib.py:133] step: 799850, training_loss: 2.77139e-02
I0211 19:08:45.252679 22542570456896 run_lib.py:133] step: 799900, training_loss: 2.92390e-02
I0211 19:08:45.418280 22542570456896 run_lib.py:146] step: 799900, eval_loss: 2.52251e-02
I0211 19:09:02.790860 22542570456896 run_lib.py:133] step: 799950, training_loss: 2.90528e-02
I0211 19:09:20.390746 22542570456896 run_lib.py:133] step: 800000, training_loss: 2.71038e-02
I0211 19:09:21.102246 22542570456896 run_lib.py:146] step: 800000, eval_loss: 3.25774e-02
I0211 19:09:41.326201 22542570456896 run_lib.py:133] step: 800050, training_loss: 3.67869e-02
I0211 19:09:58.936523 22542570456896 run_lib.py:133] step: 800100, training_loss: 2.57170e-02
I0211 19:09:59.098808 22542570456896 run_lib.py:146] step: 800100, eval_loss: 2.92221e-02
I0211 19:10:16.528776 22542570456896 run_lib.py:133] step: 800150, training_loss: 1.96794e-02
I0211 19:10:33.928780 22542570456896 run_lib.py:133] step: 800200, training_loss: 2.79166e-02
I0211 19:10:34.085319 22542570456896 run_lib.py:146] step: 800200, eval_loss: 3.63279e-02
I0211 19:10:51.514055 22542570456896 run_lib.py:133] step: 800250, training_loss: 3.13365e-02
I0211 19:11:09.117300 22542570456896 run_lib.py:133] step: 800300, training_loss: 2.38118e-02
I0211 19:11:09.276320 22542570456896 run_lib.py:146] step: 800300, eval_loss: 2.74544e-02
I0211 19:11:26.767066 22542570456896 run_lib.py:133] step: 800350, training_loss: 2.77091e-02
I0211 19:11:44.200167 22542570456896 run_lib.py:133] step: 800400, training_loss: 2.24719e-02
I0211 19:11:44.398420 22542570456896 run_lib.py:146] step: 800400, eval_loss: 3.05316e-02
I0211 19:12:01.839243 22542570456896 run_lib.py:133] step: 800450, training_loss: 2.33180e-02
I0211 19:12:19.259909 22542570456896 run_lib.py:133] step: 800500, training_loss: 2.62326e-02
I0211 19:12:19.414276 22542570456896 run_lib.py:146] step: 800500, eval_loss: 3.19581e-02
I0211 19:12:37.005299 22542570456896 run_lib.py:133] step: 800550, training_loss: 2.58636e-02
I0211 19:12:54.455188 22542570456896 run_lib.py:133] step: 800600, training_loss: 2.82842e-02
I0211 19:12:54.618092 22542570456896 run_lib.py:146] step: 800600, eval_loss: 3.82768e-02
I0211 19:13:12.029177 22542570456896 run_lib.py:133] step: 800650, training_loss: 2.82022e-02
I0211 19:13:29.467547 22542570456896 run_lib.py:133] step: 800700, training_loss: 2.66839e-02
I0211 19:13:29.621152 22542570456896 run_lib.py:146] step: 800700, eval_loss: 3.25957e-02
I0211 19:13:47.254663 22542570456896 run_lib.py:133] step: 800750, training_loss: 2.99971e-02
I0211 19:14:04.671053 22542570456896 run_lib.py:133] step: 800800, training_loss: 2.53042e-02
I0211 19:14:04.834408 22542570456896 run_lib.py:146] step: 800800, eval_loss: 2.65377e-02
I0211 19:14:22.387629 22542570456896 run_lib.py:133] step: 800850, training_loss: 2.56257e-02
I0211 19:14:39.805244 22542570456896 run_lib.py:133] step: 800900, training_loss: 3.51258e-02
I0211 19:14:39.976633 22542570456896 run_lib.py:146] step: 800900, eval_loss: 2.26469e-02
I0211 19:14:57.572856 22542570456896 run_lib.py:133] step: 800950, training_loss: 2.91905e-02
I0211 19:15:14.966801 22542570456896 run_lib.py:133] step: 801000, training_loss: 3.00087e-02
I0211 19:15:15.121443 22542570456896 run_lib.py:146] step: 801000, eval_loss: 2.97813e-02
I0211 19:15:32.524324 22542570456896 run_lib.py:133] step: 801050, training_loss: 2.97172e-02
I0211 19:15:50.042428 22542570456896 run_lib.py:133] step: 801100, training_loss: 2.38887e-02
I0211 19:15:50.198026 22542570456896 run_lib.py:146] step: 801100, eval_loss: 3.14830e-02
I0211 19:16:07.665375 22542570456896 run_lib.py:133] step: 801150, training_loss: 3.37287e-02
I0211 19:16:25.254831 22542570456896 run_lib.py:133] step: 801200, training_loss: 2.56167e-02
I0211 19:16:25.417641 22542570456896 run_lib.py:146] step: 801200, eval_loss: 2.19332e-02
I0211 19:16:42.833833 22542570456896 run_lib.py:133] step: 801250, training_loss: 2.97232e-02
I0211 19:17:00.246930 22542570456896 run_lib.py:133] step: 801300, training_loss: 2.35453e-02
I0211 19:17:00.398377 22542570456896 run_lib.py:146] step: 801300, eval_loss: 2.18627e-02
I0211 19:17:17.986642 22542570456896 run_lib.py:133] step: 801350, training_loss: 2.16749e-02
I0211 19:17:35.375006 22542570456896 run_lib.py:133] step: 801400, training_loss: 2.88002e-02
I0211 19:17:35.536364 22542570456896 run_lib.py:146] step: 801400, eval_loss: 2.90607e-02
I0211 19:17:52.979985 22542570456896 run_lib.py:133] step: 801450, training_loss: 2.45447e-02
I0211 19:18:10.639826 22542570456896 run_lib.py:133] step: 801500, training_loss: 1.95956e-02
I0211 19:18:10.796639 22542570456896 run_lib.py:146] step: 801500, eval_loss: 2.87052e-02
I0211 19:18:28.214722 22542570456896 run_lib.py:133] step: 801550, training_loss: 2.28177e-02
I0211 19:18:45.625874 22542570456896 run_lib.py:133] step: 801600, training_loss: 2.36963e-02
I0211 19:18:45.941507 22542570456896 run_lib.py:146] step: 801600, eval_loss: 2.94089e-02
I0211 19:19:03.344551 22542570456896 run_lib.py:133] step: 801650, training_loss: 2.24711e-02
I0211 19:19:20.708855 22542570456896 run_lib.py:133] step: 801700, training_loss: 2.73696e-02
I0211 19:19:20.859385 22542570456896 run_lib.py:146] step: 801700, eval_loss: 3.15066e-02
I0211 19:19:38.349984 22542570456896 run_lib.py:133] step: 801750, training_loss: 2.52861e-02
I0211 19:19:55.721954 22542570456896 run_lib.py:133] step: 801800, training_loss: 2.23246e-02
I0211 19:19:55.877223 22542570456896 run_lib.py:146] step: 801800, eval_loss: 2.77426e-02
I0211 19:20:13.511714 22542570456896 run_lib.py:133] step: 801850, training_loss: 2.67635e-02
I0211 19:20:30.985172 22542570456896 run_lib.py:133] step: 801900, training_loss: 2.80998e-02
I0211 19:20:31.142544 22542570456896 run_lib.py:146] step: 801900, eval_loss: 2.90410e-02
I0211 19:20:48.556917 22542570456896 run_lib.py:133] step: 801950, training_loss: 2.53141e-02
I0211 19:21:05.969408 22542570456896 run_lib.py:133] step: 802000, training_loss: 3.23261e-02
I0211 19:21:06.160018 22542570456896 run_lib.py:146] step: 802000, eval_loss: 3.23403e-02
I0211 19:21:23.761178 22542570456896 run_lib.py:133] step: 802050, training_loss: 3.12726e-02
I0211 19:21:41.277004 22542570456896 run_lib.py:133] step: 802100, training_loss: 2.00683e-02
I0211 19:21:41.431697 22542570456896 run_lib.py:146] step: 802100, eval_loss: 3.13533e-02
I0211 19:21:58.850813 22542570456896 run_lib.py:133] step: 802150, training_loss: 2.64045e-02
I0211 19:22:16.250323 22542570456896 run_lib.py:133] step: 802200, training_loss: 2.15593e-02
I0211 19:22:16.401471 22542570456896 run_lib.py:146] step: 802200, eval_loss: 2.53636e-02
I0211 19:22:33.938041 22542570456896 run_lib.py:133] step: 802250, training_loss: 2.20197e-02
I0211 19:22:51.356835 22542570456896 run_lib.py:133] step: 802300, training_loss: 2.61667e-02
I0211 19:22:51.533048 22542570456896 run_lib.py:146] step: 802300, eval_loss: 3.75051e-02
I0211 19:23:09.157107 22542570456896 run_lib.py:133] step: 802350, training_loss: 2.83048e-02
I0211 19:23:26.572868 22542570456896 run_lib.py:133] step: 802400, training_loss: 3.27316e-02
I0211 19:23:26.737236 22542570456896 run_lib.py:146] step: 802400, eval_loss: 2.99693e-02
I0211 19:23:44.272653 22542570456896 run_lib.py:133] step: 802450, training_loss: 2.95504e-02
I0211 19:24:01.693096 22542570456896 run_lib.py:133] step: 802500, training_loss: 2.75941e-02
I0211 19:24:01.845231 22542570456896 run_lib.py:146] step: 802500, eval_loss: 2.80049e-02
I0211 19:24:19.256053 22542570456896 run_lib.py:133] step: 802550, training_loss: 3.38763e-02
I0211 19:24:36.852639 22542570456896 run_lib.py:133] step: 802600, training_loss: 2.28856e-02
I0211 19:24:37.005038 22542570456896 run_lib.py:146] step: 802600, eval_loss: 3.02025e-02
I0211 19:24:54.426419 22542570456896 run_lib.py:133] step: 802650, training_loss: 3.08146e-02
I0211 19:25:11.969161 22542570456896 run_lib.py:133] step: 802700, training_loss: 2.61859e-02
I0211 19:25:12.133268 22542570456896 run_lib.py:146] step: 802700, eval_loss: 3.05913e-02
I0211 19:25:29.473029 22542570456896 run_lib.py:133] step: 802750, training_loss: 3.44991e-02
I0211 19:25:46.882458 22542570456896 run_lib.py:133] step: 802800, training_loss: 2.95563e-02
I0211 19:25:47.040642 22542570456896 run_lib.py:146] step: 802800, eval_loss: 3.06355e-02
I0211 19:26:04.616852 22542570456896 run_lib.py:133] step: 802850, training_loss: 2.57291e-02
I0211 19:26:22.058457 22542570456896 run_lib.py:133] step: 802900, training_loss: 2.32769e-02
I0211 19:26:22.215618 22542570456896 run_lib.py:146] step: 802900, eval_loss: 3.01023e-02
I0211 19:26:39.576721 22542570456896 run_lib.py:133] step: 802950, training_loss: 2.63328e-02
I0211 19:26:56.961966 22542570456896 run_lib.py:133] step: 803000, training_loss: 2.70586e-02
I0211 19:26:57.117367 22542570456896 run_lib.py:146] step: 803000, eval_loss: 2.68378e-02
I0211 19:27:14.690065 22542570456896 run_lib.py:133] step: 803050, training_loss: 2.53895e-02
I0211 19:27:32.095918 22542570456896 run_lib.py:133] step: 803100, training_loss: 2.16795e-02
I0211 19:27:32.249447 22542570456896 run_lib.py:146] step: 803100, eval_loss: 4.08514e-02
I0211 19:27:49.733375 22542570456896 run_lib.py:133] step: 803150, training_loss: 2.44400e-02
I0211 19:28:07.137818 22542570456896 run_lib.py:133] step: 803200, training_loss: 2.30325e-02
I0211 19:28:07.294597 22542570456896 run_lib.py:146] step: 803200, eval_loss: 2.49022e-02
I0211 19:28:24.681450 22542570456896 run_lib.py:133] step: 803250, training_loss: 2.85372e-02
I0211 19:28:42.113205 22542570456896 run_lib.py:133] step: 803300, training_loss: 3.36817e-02
I0211 19:28:42.270489 22542570456896 run_lib.py:146] step: 803300, eval_loss: 3.17914e-02
I0211 19:28:59.822861 22542570456896 run_lib.py:133] step: 803350, training_loss: 2.65047e-02
I0211 19:29:17.327716 22542570456896 run_lib.py:133] step: 803400, training_loss: 2.37164e-02
I0211 19:29:17.483502 22542570456896 run_lib.py:146] step: 803400, eval_loss: 2.63838e-02
I0211 19:29:34.883887 22542570456896 run_lib.py:133] step: 803450, training_loss: 2.08344e-02
I0211 19:29:52.288461 22542570456896 run_lib.py:133] step: 803500, training_loss: 2.90238e-02
I0211 19:29:52.449101 22542570456896 run_lib.py:146] step: 803500, eval_loss: 2.73364e-02
I0211 19:30:09.986563 22542570456896 run_lib.py:133] step: 803550, training_loss: 2.08425e-02
I0211 19:30:27.358111 22542570456896 run_lib.py:133] step: 803600, training_loss: 2.56940e-02
I0211 19:30:27.595273 22542570456896 run_lib.py:146] step: 803600, eval_loss: 2.19836e-02
I0211 19:30:45.145675 22542570456896 run_lib.py:133] step: 803650, training_loss: 2.96533e-02
I0211 19:31:02.575644 22542570456896 run_lib.py:133] step: 803700, training_loss: 2.68435e-02
I0211 19:31:02.742363 22542570456896 run_lib.py:146] step: 803700, eval_loss: 3.47117e-02
I0211 19:31:20.342473 22542570456896 run_lib.py:133] step: 803750, training_loss: 2.65731e-02
I0211 19:31:37.741097 22542570456896 run_lib.py:133] step: 803800, training_loss: 2.40133e-02
I0211 19:31:37.897701 22542570456896 run_lib.py:146] step: 803800, eval_loss: 3.18756e-02
I0211 19:31:55.461724 22542570456896 run_lib.py:133] step: 803850, training_loss: 3.15784e-02
I0211 19:32:12.851071 22542570456896 run_lib.py:133] step: 803900, training_loss: 2.77465e-02
I0211 19:32:13.005377 22542570456896 run_lib.py:146] step: 803900, eval_loss: 2.74064e-02
I0211 19:32:30.385447 22542570456896 run_lib.py:133] step: 803950, training_loss: 2.38186e-02
I0211 19:32:47.982874 22542570456896 run_lib.py:133] step: 804000, training_loss: 2.50903e-02
I0211 19:32:48.137603 22542570456896 run_lib.py:146] step: 804000, eval_loss: 2.85429e-02
I0211 19:33:05.559863 22542570456896 run_lib.py:133] step: 804050, training_loss: 2.82962e-02
I0211 19:33:22.988950 22542570456896 run_lib.py:133] step: 804100, training_loss: 2.82958e-02
I0211 19:33:23.142347 22542570456896 run_lib.py:146] step: 804100, eval_loss: 3.37480e-02
I0211 19:33:40.697893 22542570456896 run_lib.py:133] step: 804150, training_loss: 2.48330e-02
I0211 19:33:58.254270 22542570456896 run_lib.py:133] step: 804200, training_loss: 3.53703e-02
I0211 19:33:58.417469 22542570456896 run_lib.py:146] step: 804200, eval_loss: 3.45849e-02
I0211 19:34:15.898801 22542570456896 run_lib.py:133] step: 804250, training_loss: 2.54416e-02
I0211 19:34:33.332000 22542570456896 run_lib.py:133] step: 804300, training_loss: 3.02210e-02
I0211 19:34:33.494575 22542570456896 run_lib.py:146] step: 804300, eval_loss: 2.85129e-02
I0211 19:34:50.861240 22542570456896 run_lib.py:133] step: 804350, training_loss: 2.13363e-02
I0211 19:35:08.436035 22542570456896 run_lib.py:133] step: 804400, training_loss: 2.72523e-02
I0211 19:35:08.593240 22542570456896 run_lib.py:146] step: 804400, eval_loss: 2.58983e-02
I0211 19:35:25.997226 22542570456896 run_lib.py:133] step: 804450, training_loss: 2.47263e-02
I0211 19:35:43.406453 22542570456896 run_lib.py:133] step: 804500, training_loss: 3.03349e-02
I0211 19:35:43.559649 22542570456896 run_lib.py:146] step: 804500, eval_loss: 3.03782e-02
I0211 19:36:01.014170 22542570456896 run_lib.py:133] step: 804550, training_loss: 2.42318e-02
I0211 19:36:18.570821 22542570456896 run_lib.py:133] step: 804600, training_loss: 2.56592e-02
I0211 19:36:18.725271 22542570456896 run_lib.py:146] step: 804600, eval_loss: 3.87485e-02
I0211 19:36:36.116839 22542570456896 run_lib.py:133] step: 804650, training_loss: 2.49246e-02
I0211 19:36:53.588818 22542570456896 run_lib.py:133] step: 804700, training_loss: 2.33809e-02
I0211 19:36:53.754884 22542570456896 run_lib.py:146] step: 804700, eval_loss: 2.59766e-02
I0211 19:37:11.096908 22542570456896 run_lib.py:133] step: 804750, training_loss: 2.40127e-02
I0211 19:37:28.479585 22542570456896 run_lib.py:133] step: 804800, training_loss: 3.09647e-02
I0211 19:37:28.642457 22542570456896 run_lib.py:146] step: 804800, eval_loss: 3.38131e-02
I0211 19:37:46.225239 22542570456896 run_lib.py:133] step: 804850, training_loss: 2.44624e-02
I0211 19:38:03.767965 22542570456896 run_lib.py:133] step: 804900, training_loss: 3.05832e-02
I0211 19:38:03.923191 22542570456896 run_lib.py:146] step: 804900, eval_loss: 3.50116e-02
I0211 19:38:21.331702 22542570456896 run_lib.py:133] step: 804950, training_loss: 3.47250e-02
I0211 19:38:38.710951 22542570456896 run_lib.py:133] step: 805000, training_loss: 3.35875e-02
I0211 19:38:38.862397 22542570456896 run_lib.py:146] step: 805000, eval_loss: 2.48674e-02
I0211 19:38:56.386493 22542570456896 run_lib.py:133] step: 805050, training_loss: 2.92098e-02
I0211 19:39:13.790499 22542570456896 run_lib.py:133] step: 805100, training_loss: 2.87368e-02
I0211 19:39:13.957654 22542570456896 run_lib.py:146] step: 805100, eval_loss: 3.23436e-02
I0211 19:39:31.557253 22542570456896 run_lib.py:133] step: 805150, training_loss: 2.95566e-02
I0211 19:39:48.992751 22542570456896 run_lib.py:133] step: 805200, training_loss: 1.88043e-02
I0211 19:39:49.163393 22542570456896 run_lib.py:146] step: 805200, eval_loss: 2.83844e-02
I0211 19:40:06.767877 22542570456896 run_lib.py:133] step: 805250, training_loss: 2.38493e-02
I0211 19:40:24.142099 22542570456896 run_lib.py:133] step: 805300, training_loss: 2.52822e-02
I0211 19:40:24.305181 22542570456896 run_lib.py:146] step: 805300, eval_loss: 3.66413e-02
I0211 19:40:41.666160 22542570456896 run_lib.py:133] step: 805350, training_loss: 3.56720e-02
I0211 19:40:59.287513 22542570456896 run_lib.py:133] step: 805400, training_loss: 3.03854e-02
I0211 19:40:59.440617 22542570456896 run_lib.py:146] step: 805400, eval_loss: 3.08515e-02
I0211 19:41:16.917374 22542570456896 run_lib.py:133] step: 805450, training_loss: 2.57801e-02
I0211 19:41:34.480681 22542570456896 run_lib.py:133] step: 805500, training_loss: 2.29248e-02
I0211 19:41:34.632353 22542570456896 run_lib.py:146] step: 805500, eval_loss: 4.00118e-02
I0211 19:41:52.047332 22542570456896 run_lib.py:133] step: 805550, training_loss: 3.25698e-02
I0211 19:42:09.469494 22542570456896 run_lib.py:133] step: 805600, training_loss: 2.88055e-02
I0211 19:42:09.626629 22542570456896 run_lib.py:146] step: 805600, eval_loss: 3.60309e-02
I0211 19:42:27.182533 22542570456896 run_lib.py:133] step: 805650, training_loss: 2.86227e-02
I0211 19:42:44.636862 22542570456896 run_lib.py:133] step: 805700, training_loss: 3.46416e-02
I0211 19:42:44.799400 22542570456896 run_lib.py:146] step: 805700, eval_loss: 2.72478e-02
I0211 19:43:02.200725 22542570456896 run_lib.py:133] step: 805750, training_loss: 2.95157e-02
I0211 19:43:19.763368 22542570456896 run_lib.py:133] step: 805800, training_loss: 3.17938e-02
I0211 19:43:19.919085 22542570456896 run_lib.py:146] step: 805800, eval_loss: 2.68465e-02
I0211 19:43:37.323053 22542570456896 run_lib.py:133] step: 805850, training_loss: 2.58214e-02
I0211 19:43:54.717170 22542570456896 run_lib.py:133] step: 805900, training_loss: 2.87208e-02
I0211 19:43:54.875234 22542570456896 run_lib.py:146] step: 805900, eval_loss: 3.02344e-02
I0211 19:44:12.340990 22542570456896 run_lib.py:133] step: 805950, training_loss: 2.56244e-02
I0211 19:44:29.752878 22542570456896 run_lib.py:133] step: 806000, training_loss: 3.65307e-02
I0211 19:44:29.904514 22542570456896 run_lib.py:146] step: 806000, eval_loss: 3.01352e-02
I0211 19:44:47.334423 22542570456896 run_lib.py:133] step: 806050, training_loss: 2.15205e-02
I0211 19:45:04.739634 22542570456896 run_lib.py:133] step: 806100, training_loss: 2.66072e-02
I0211 19:45:04.898703 22542570456896 run_lib.py:146] step: 806100, eval_loss: 2.52423e-02
I0211 19:45:22.481261 22542570456896 run_lib.py:133] step: 806150, training_loss: 2.82246e-02
I0211 19:45:39.925646 22542570456896 run_lib.py:133] step: 806200, training_loss: 2.74749e-02
I0211 19:45:40.080337 22542570456896 run_lib.py:146] step: 806200, eval_loss: 2.37776e-02
I0211 19:45:57.478089 22542570456896 run_lib.py:133] step: 806250, training_loss: 2.81365e-02
I0211 19:46:14.924069 22542570456896 run_lib.py:133] step: 806300, training_loss: 3.67202e-02
I0211 19:46:15.080855 22542570456896 run_lib.py:146] step: 806300, eval_loss: 2.44241e-02
I0211 19:46:32.676421 22542570456896 run_lib.py:133] step: 806350, training_loss: 2.24287e-02
I0211 19:46:50.068257 22542570456896 run_lib.py:133] step: 806400, training_loss: 2.77807e-02
I0211 19:46:50.219008 22542570456896 run_lib.py:146] step: 806400, eval_loss: 3.34314e-02
I0211 19:47:07.758109 22542570456896 run_lib.py:133] step: 806450, training_loss: 2.44790e-02
I0211 19:47:25.128723 22542570456896 run_lib.py:133] step: 806500, training_loss: 2.86722e-02
I0211 19:47:25.298506 22542570456896 run_lib.py:146] step: 806500, eval_loss: 2.89368e-02
I0211 19:47:42.896492 22542570456896 run_lib.py:133] step: 806550, training_loss: 2.63005e-02
I0211 19:48:00.338424 22542570456896 run_lib.py:133] step: 806600, training_loss: 2.28972e-02
I0211 19:48:00.496348 22542570456896 run_lib.py:146] step: 806600, eval_loss: 2.69329e-02
I0211 19:48:18.051857 22542570456896 run_lib.py:133] step: 806650, training_loss: 2.74407e-02
I0211 19:48:35.432739 22542570456896 run_lib.py:133] step: 806700, training_loss: 1.98126e-02
I0211 19:48:35.588339 22542570456896 run_lib.py:146] step: 806700, eval_loss: 3.25684e-02
I0211 19:48:52.967923 22542570456896 run_lib.py:133] step: 806750, training_loss: 3.06695e-02
I0211 19:49:10.598713 22542570456896 run_lib.py:133] step: 806800, training_loss: 2.97206e-02
I0211 19:49:10.758535 22542570456896 run_lib.py:146] step: 806800, eval_loss: 2.77427e-02
I0211 19:49:28.182682 22542570456896 run_lib.py:133] step: 806850, training_loss: 1.80575e-02
I0211 19:49:45.550505 22542570456896 run_lib.py:133] step: 806900, training_loss: 2.55927e-02
I0211 19:49:45.710821 22542570456896 run_lib.py:146] step: 806900, eval_loss: 2.79070e-02
I0211 19:50:03.277504 22542570456896 run_lib.py:133] step: 806950, training_loss: 2.47679e-02
I0211 19:50:20.702525 22542570456896 run_lib.py:133] step: 807000, training_loss: 3.07433e-02
I0211 19:50:20.858449 22542570456896 run_lib.py:146] step: 807000, eval_loss: 3.13435e-02
I0211 19:50:38.382670 22542570456896 run_lib.py:133] step: 807050, training_loss: 2.60187e-02
I0211 19:50:55.819452 22542570456896 run_lib.py:133] step: 807100, training_loss: 2.80729e-02
I0211 19:50:55.976298 22542570456896 run_lib.py:146] step: 807100, eval_loss: 2.78389e-02
I0211 19:51:13.343462 22542570456896 run_lib.py:133] step: 807150, training_loss: 2.98338e-02
I0211 19:51:30.921485 22542570456896 run_lib.py:133] step: 807200, training_loss: 3.16496e-02
I0211 19:51:31.076974 22542570456896 run_lib.py:146] step: 807200, eval_loss: 2.59739e-02
I0211 19:51:48.459835 22542570456896 run_lib.py:133] step: 807250, training_loss: 2.90155e-02
I0211 19:52:05.855131 22542570456896 run_lib.py:133] step: 807300, training_loss: 3.04875e-02
I0211 19:52:06.020575 22542570456896 run_lib.py:146] step: 807300, eval_loss: 3.88721e-02
I0211 19:52:23.444758 22542570456896 run_lib.py:133] step: 807350, training_loss: 2.51361e-02
I0211 19:52:41.065808 22542570456896 run_lib.py:133] step: 807400, training_loss: 2.74192e-02
I0211 19:52:41.216067 22542570456896 run_lib.py:146] step: 807400, eval_loss: 2.88260e-02
I0211 19:52:58.644337 22542570456896 run_lib.py:133] step: 807450, training_loss: 3.41742e-02
I0211 19:53:16.137614 22542570456896 run_lib.py:133] step: 807500, training_loss: 3.06782e-02
I0211 19:53:16.296871 22542570456896 run_lib.py:146] step: 807500, eval_loss: 3.21114e-02
I0211 19:53:33.681060 22542570456896 run_lib.py:133] step: 807550, training_loss: 2.61358e-02
I0211 19:53:51.132049 22542570456896 run_lib.py:133] step: 807600, training_loss: 3.25147e-02
I0211 19:53:51.302407 22542570456896 run_lib.py:146] step: 807600, eval_loss: 3.25120e-02
I0211 19:54:08.903490 22542570456896 run_lib.py:133] step: 807650, training_loss: 3.49963e-02
I0211 19:54:26.436272 22542570456896 run_lib.py:133] step: 807700, training_loss: 2.74649e-02
I0211 19:54:26.591733 22542570456896 run_lib.py:146] step: 807700, eval_loss: 3.29776e-02
I0211 19:54:44.022019 22542570456896 run_lib.py:133] step: 807750, training_loss: 3.25238e-02
I0211 19:55:01.415405 22542570456896 run_lib.py:133] step: 807800, training_loss: 2.74636e-02
I0211 19:55:01.567010 22542570456896 run_lib.py:146] step: 807800, eval_loss: 2.35833e-02
I0211 19:55:19.061877 22542570456896 run_lib.py:133] step: 807850, training_loss: 2.77466e-02
I0211 19:55:36.471940 22542570456896 run_lib.py:133] step: 807900, training_loss: 3.12872e-02
I0211 19:55:36.638552 22542570456896 run_lib.py:146] step: 807900, eval_loss: 3.11701e-02
I0211 19:55:54.222212 22542570456896 run_lib.py:133] step: 807950, training_loss: 2.46552e-02
I0211 19:56:11.625441 22542570456896 run_lib.py:133] step: 808000, training_loss: 2.65993e-02
I0211 19:56:11.781983 22542570456896 run_lib.py:146] step: 808000, eval_loss: 3.11206e-02
I0211 19:56:29.328969 22542570456896 run_lib.py:133] step: 808050, training_loss: 2.13725e-02
I0211 19:56:46.686058 22542570456896 run_lib.py:133] step: 808100, training_loss: 2.55708e-02
I0211 19:56:46.842274 22542570456896 run_lib.py:146] step: 808100, eval_loss: 2.71836e-02
I0211 19:57:04.268162 22542570456896 run_lib.py:133] step: 808150, training_loss: 2.19879e-02
I0211 19:57:21.909610 22542570456896 run_lib.py:133] step: 808200, training_loss: 2.81889e-02
I0211 19:57:22.078266 22542570456896 run_lib.py:146] step: 808200, eval_loss: 2.89702e-02
I0211 19:57:39.491276 22542570456896 run_lib.py:133] step: 808250, training_loss: 3.20167e-02
I0211 19:57:57.001731 22542570456896 run_lib.py:133] step: 808300, training_loss: 2.55189e-02
I0211 19:57:57.153280 22542570456896 run_lib.py:146] step: 808300, eval_loss: 2.50313e-02
I0211 19:58:14.512418 22542570456896 run_lib.py:133] step: 808350, training_loss: 2.60082e-02
I0211 19:58:31.909077 22542570456896 run_lib.py:133] step: 808400, training_loss: 2.79064e-02
I0211 19:58:32.075599 22542570456896 run_lib.py:146] step: 808400, eval_loss: 3.46030e-02
I0211 19:58:49.651954 22542570456896 run_lib.py:133] step: 808450, training_loss: 2.44026e-02
I0211 19:59:07.103002 22542570456896 run_lib.py:133] step: 808500, training_loss: 2.35080e-02
I0211 19:59:07.260956 22542570456896 run_lib.py:146] step: 808500, eval_loss: 3.20489e-02
I0211 19:59:24.651397 22542570456896 run_lib.py:133] step: 808550, training_loss: 2.97849e-02
I0211 19:59:42.249516 22542570456896 run_lib.py:133] step: 808600, training_loss: 2.71374e-02
I0211 19:59:42.409542 22542570456896 run_lib.py:146] step: 808600, eval_loss: 2.87823e-02
I0211 19:59:59.808054 22542570456896 run_lib.py:133] step: 808650, training_loss: 2.46497e-02
I0211 20:00:17.221905 22542570456896 run_lib.py:133] step: 808700, training_loss: 2.57872e-02
I0211 20:00:17.523633 22542570456896 run_lib.py:146] step: 808700, eval_loss: 2.97408e-02
I0211 20:00:34.982951 22542570456896 run_lib.py:133] step: 808750, training_loss: 2.53857e-02
I0211 20:00:52.411366 22542570456896 run_lib.py:133] step: 808800, training_loss: 3.28902e-02
I0211 20:00:52.560153 22542570456896 run_lib.py:146] step: 808800, eval_loss: 3.43222e-02
I0211 20:01:09.999197 22542570456896 run_lib.py:133] step: 808850, training_loss: 2.22196e-02
I0211 20:01:27.389703 22542570456896 run_lib.py:133] step: 808900, training_loss: 3.21668e-02
I0211 20:01:27.544391 22542570456896 run_lib.py:146] step: 808900, eval_loss: 2.73133e-02
I0211 20:01:45.174875 22542570456896 run_lib.py:133] step: 808950, training_loss: 2.97617e-02
I0211 20:02:02.658489 22542570456896 run_lib.py:133] step: 809000, training_loss: 2.51845e-02
I0211 20:02:02.825403 22542570456896 run_lib.py:146] step: 809000, eval_loss: 2.99156e-02
I0211 20:02:20.241993 22542570456896 run_lib.py:133] step: 809050, training_loss: 2.77009e-02
I0211 20:02:37.642019 22542570456896 run_lib.py:133] step: 809100, training_loss: 2.37615e-02
I0211 20:02:37.795540 22542570456896 run_lib.py:146] step: 809100, eval_loss: 2.84639e-02
I0211 20:02:55.444715 22542570456896 run_lib.py:133] step: 809150, training_loss: 2.12705e-02
I0211 20:03:12.879182 22542570456896 run_lib.py:133] step: 809200, training_loss: 2.13941e-02
I0211 20:03:13.036347 22542570456896 run_lib.py:146] step: 809200, eval_loss: 3.55904e-02
I0211 20:03:30.474967 22542570456896 run_lib.py:133] step: 809250, training_loss: 2.63081e-02
I0211 20:03:47.896110 22542570456896 run_lib.py:133] step: 809300, training_loss: 2.36938e-02
I0211 20:03:48.052489 22542570456896 run_lib.py:146] step: 809300, eval_loss: 2.61655e-02
I0211 20:04:05.646235 22542570456896 run_lib.py:133] step: 809350, training_loss: 3.73885e-02
I0211 20:04:23.073981 22542570456896 run_lib.py:133] step: 809400, training_loss: 2.67298e-02
I0211 20:04:23.232529 22542570456896 run_lib.py:146] step: 809400, eval_loss: 2.79479e-02
I0211 20:04:40.754240 22542570456896 run_lib.py:133] step: 809450, training_loss: 2.55917e-02
I0211 20:04:58.156557 22542570456896 run_lib.py:133] step: 809500, training_loss: 2.40622e-02
I0211 20:04:58.314276 22542570456896 run_lib.py:146] step: 809500, eval_loss: 3.46052e-02
I0211 20:05:15.951561 22542570456896 run_lib.py:133] step: 809550, training_loss: 3.05081e-02
I0211 20:05:33.360674 22542570456896 run_lib.py:133] step: 809600, training_loss: 3.33981e-02
I0211 20:05:33.516612 22542570456896 run_lib.py:146] step: 809600, eval_loss: 2.49919e-02
I0211 20:05:50.931099 22542570456896 run_lib.py:133] step: 809650, training_loss: 2.48337e-02
I0211 20:06:08.480550 22542570456896 run_lib.py:133] step: 809700, training_loss: 2.76557e-02
I0211 20:06:08.633090 22542570456896 run_lib.py:146] step: 809700, eval_loss: 2.87602e-02
I0211 20:06:26.097373 22542570456896 run_lib.py:133] step: 809750, training_loss: 2.61888e-02
I0211 20:06:43.656242 22542570456896 run_lib.py:133] step: 809800, training_loss: 2.82518e-02
I0211 20:06:43.814595 22542570456896 run_lib.py:146] step: 809800, eval_loss: 2.39669e-02
I0211 20:07:01.311290 22542570456896 run_lib.py:133] step: 809850, training_loss: 2.62726e-02
I0211 20:07:18.746684 22542570456896 run_lib.py:133] step: 809900, training_loss: 3.15801e-02
I0211 20:07:18.911383 22542570456896 run_lib.py:146] step: 809900, eval_loss: 2.97598e-02
I0211 20:07:36.511894 22542570456896 run_lib.py:133] step: 809950, training_loss: 2.65659e-02
I0211 20:07:53.915300 22542570456896 run_lib.py:133] step: 810000, training_loss: 2.91460e-02
I0211 20:07:54.625829 22542570456896 run_lib.py:146] step: 810000, eval_loss: 2.75009e-02
I0211 20:08:14.857287 22542570456896 run_lib.py:133] step: 810050, training_loss: 3.68220e-02
I0211 20:08:32.384144 22542570456896 run_lib.py:133] step: 810100, training_loss: 2.97309e-02
I0211 20:08:32.539548 22542570456896 run_lib.py:146] step: 810100, eval_loss: 3.41460e-02
I0211 20:08:49.986066 22542570456896 run_lib.py:133] step: 810150, training_loss: 2.53586e-02
I0211 20:09:07.344511 22542570456896 run_lib.py:133] step: 810200, training_loss: 2.47285e-02
I0211 20:09:07.497382 22542570456896 run_lib.py:146] step: 810200, eval_loss: 3.21700e-02
I0211 20:09:25.078259 22542570456896 run_lib.py:133] step: 810250, training_loss: 2.44838e-02
I0211 20:09:42.566702 22542570456896 run_lib.py:133] step: 810300, training_loss: 3.45676e-02
I0211 20:09:42.720269 22542570456896 run_lib.py:146] step: 810300, eval_loss: 3.51455e-02
I0211 20:10:00.142218 22542570456896 run_lib.py:133] step: 810350, training_loss: 2.67915e-02
I0211 20:10:17.551914 22542570456896 run_lib.py:133] step: 810400, training_loss: 2.98477e-02
I0211 20:10:17.720608 22542570456896 run_lib.py:146] step: 810400, eval_loss: 2.88353e-02
I0211 20:10:35.338173 22542570456896 run_lib.py:133] step: 810450, training_loss: 2.47044e-02
I0211 20:10:52.751639 22542570456896 run_lib.py:133] step: 810500, training_loss: 3.04380e-02
I0211 20:10:52.911237 22542570456896 run_lib.py:146] step: 810500, eval_loss: 2.63426e-02
I0211 20:11:10.476885 22542570456896 run_lib.py:133] step: 810550, training_loss: 3.40898e-02
I0211 20:11:27.875701 22542570456896 run_lib.py:133] step: 810600, training_loss: 3.35540e-02
I0211 20:11:28.030980 22542570456896 run_lib.py:146] step: 810600, eval_loss: 2.46428e-02
I0211 20:11:45.512357 22542570456896 run_lib.py:133] step: 810650, training_loss: 2.61493e-02
I0211 20:12:02.987691 22542570456896 run_lib.py:133] step: 810700, training_loss: 2.49553e-02
I0211 20:12:03.148499 22542570456896 run_lib.py:146] step: 810700, eval_loss: 2.56806e-02
I0211 20:12:20.464102 22542570456896 run_lib.py:133] step: 810750, training_loss: 2.09108e-02
I0211 20:12:37.965180 22542570456896 run_lib.py:133] step: 810800, training_loss: 3.66437e-02
I0211 20:12:38.116204 22542570456896 run_lib.py:146] step: 810800, eval_loss: 2.89053e-02
I0211 20:12:55.482048 22542570456896 run_lib.py:133] step: 810850, training_loss: 3.38093e-02
I0211 20:13:13.101602 22542570456896 run_lib.py:133] step: 810900, training_loss: 2.99335e-02
I0211 20:13:13.272260 22542570456896 run_lib.py:146] step: 810900, eval_loss: 3.34232e-02
I0211 20:13:30.741827 22542570456896 run_lib.py:133] step: 810950, training_loss: 2.77620e-02
I0211 20:13:48.202520 22542570456896 run_lib.py:133] step: 811000, training_loss: 2.61405e-02
I0211 20:13:48.360768 22542570456896 run_lib.py:146] step: 811000, eval_loss: 2.75672e-02
I0211 20:14:05.943136 22542570456896 run_lib.py:133] step: 811050, training_loss: 2.71047e-02
I0211 20:14:23.377283 22542570456896 run_lib.py:133] step: 811100, training_loss: 2.49855e-02
I0211 20:14:23.534454 22542570456896 run_lib.py:146] step: 811100, eval_loss: 3.12836e-02
I0211 20:14:40.960834 22542570456896 run_lib.py:133] step: 811150, training_loss: 2.22780e-02
I0211 20:14:58.365386 22542570456896 run_lib.py:133] step: 811200, training_loss: 2.52105e-02
I0211 20:14:58.520139 22542570456896 run_lib.py:146] step: 811200, eval_loss: 2.44460e-02
I0211 20:15:16.118731 22542570456896 run_lib.py:133] step: 811250, training_loss: 3.71669e-02
I0211 20:15:33.572160 22542570456896 run_lib.py:133] step: 811300, training_loss: 2.32906e-02
I0211 20:15:33.722530 22542570456896 run_lib.py:146] step: 811300, eval_loss: 3.18409e-02
I0211 20:15:51.200025 22542570456896 run_lib.py:133] step: 811350, training_loss: 2.27826e-02
I0211 20:16:08.656387 22542570456896 run_lib.py:133] step: 811400, training_loss: 3.07589e-02
I0211 20:16:08.812549 22542570456896 run_lib.py:146] step: 811400, eval_loss: 2.58205e-02
I0211 20:16:26.186899 22542570456896 run_lib.py:133] step: 811450, training_loss: 2.94507e-02
I0211 20:16:43.639997 22542570456896 run_lib.py:133] step: 811500, training_loss: 2.02970e-02
I0211 20:16:43.810483 22542570456896 run_lib.py:146] step: 811500, eval_loss: 3.35798e-02
I0211 20:17:01.385657 22542570456896 run_lib.py:133] step: 811550, training_loss: 3.00801e-02
I0211 20:17:18.894884 22542570456896 run_lib.py:133] step: 811600, training_loss: 2.49338e-02
I0211 20:17:19.051349 22542570456896 run_lib.py:146] step: 811600, eval_loss: 2.91414e-02
I0211 20:17:36.462163 22542570456896 run_lib.py:133] step: 811650, training_loss: 3.27940e-02
I0211 20:17:53.859070 22542570456896 run_lib.py:133] step: 811700, training_loss: 3.47562e-02
I0211 20:17:54.010413 22542570456896 run_lib.py:146] step: 811700, eval_loss: 2.83810e-02
I0211 20:18:11.559144 22542570456896 run_lib.py:133] step: 811750, training_loss: 2.52936e-02
I0211 20:18:28.983010 22542570456896 run_lib.py:133] step: 811800, training_loss: 2.73369e-02
I0211 20:18:29.150498 22542570456896 run_lib.py:146] step: 811800, eval_loss: 2.02026e-02
I0211 20:18:46.726658 22542570456896 run_lib.py:133] step: 811850, training_loss: 2.78170e-02
I0211 20:19:04.159926 22542570456896 run_lib.py:133] step: 811900, training_loss: 2.20729e-02
I0211 20:19:04.326443 22542570456896 run_lib.py:146] step: 811900, eval_loss: 2.61007e-02
I0211 20:19:21.892910 22542570456896 run_lib.py:133] step: 811950, training_loss: 2.52331e-02
I0211 20:19:39.278491 22542570456896 run_lib.py:133] step: 812000, training_loss: 3.19690e-02
I0211 20:19:39.434411 22542570456896 run_lib.py:146] step: 812000, eval_loss: 2.85930e-02
I0211 20:19:56.992837 22542570456896 run_lib.py:133] step: 812050, training_loss: 2.13644e-02
I0211 20:20:14.434983 22542570456896 run_lib.py:133] step: 812100, training_loss: 2.38185e-02
I0211 20:20:14.589442 22542570456896 run_lib.py:146] step: 812100, eval_loss: 3.38220e-02
I0211 20:20:32.005412 22542570456896 run_lib.py:133] step: 812150, training_loss: 2.78942e-02
I0211 20:20:49.617503 22542570456896 run_lib.py:133] step: 812200, training_loss: 2.49727e-02
I0211 20:20:49.773371 22542570456896 run_lib.py:146] step: 812200, eval_loss: 3.07337e-02
I0211 20:21:07.189595 22542570456896 run_lib.py:133] step: 812250, training_loss: 3.03129e-02
I0211 20:21:24.631060 22542570456896 run_lib.py:133] step: 812300, training_loss: 2.21458e-02
I0211 20:21:24.798198 22542570456896 run_lib.py:146] step: 812300, eval_loss: 2.72776e-02
I0211 20:21:42.418077 22542570456896 run_lib.py:133] step: 812350, training_loss: 3.24712e-02
I0211 20:22:00.017468 22542570456896 run_lib.py:133] step: 812400, training_loss: 2.08904e-02
I0211 20:22:00.175257 22542570456896 run_lib.py:146] step: 812400, eval_loss: 2.97922e-02
I0211 20:22:17.548311 22542570456896 run_lib.py:133] step: 812450, training_loss: 2.79781e-02
I0211 20:22:34.956277 22542570456896 run_lib.py:133] step: 812500, training_loss: 3.01987e-02
I0211 20:22:35.112092 22542570456896 run_lib.py:146] step: 812500, eval_loss: 2.96985e-02
I0211 20:22:52.486597 22542570456896 run_lib.py:133] step: 812550, training_loss: 2.60565e-02
I0211 20:23:10.117897 22542570456896 run_lib.py:133] step: 812600, training_loss: 2.72520e-02
I0211 20:23:10.270080 22542570456896 run_lib.py:146] step: 812600, eval_loss: 2.48252e-02
I0211 20:23:27.697793 22542570456896 run_lib.py:133] step: 812650, training_loss: 2.20850e-02
I0211 20:23:45.085598 22542570456896 run_lib.py:133] step: 812700, training_loss: 2.44673e-02
I0211 20:23:45.238505 22542570456896 run_lib.py:146] step: 812700, eval_loss: 2.98265e-02
I0211 20:24:02.654323 22542570456896 run_lib.py:133] step: 812750, training_loss: 2.09372e-02
I0211 20:24:20.258635 22542570456896 run_lib.py:133] step: 812800, training_loss: 2.75802e-02
I0211 20:24:20.417561 22542570456896 run_lib.py:146] step: 812800, eval_loss: 3.13292e-02
I0211 20:24:37.859256 22542570456896 run_lib.py:133] step: 812850, training_loss: 2.76124e-02
I0211 20:24:55.362909 22542570456896 run_lib.py:133] step: 812900, training_loss: 2.94288e-02
I0211 20:24:55.521568 22542570456896 run_lib.py:146] step: 812900, eval_loss: 2.99404e-02
I0211 20:25:12.940044 22542570456896 run_lib.py:133] step: 812950, training_loss: 2.09509e-02
I0211 20:25:30.350705 22542570456896 run_lib.py:133] step: 813000, training_loss: 2.39562e-02
I0211 20:25:30.506156 22542570456896 run_lib.py:146] step: 813000, eval_loss: 3.57572e-02
I0211 20:25:48.084668 22542570456896 run_lib.py:133] step: 813050, training_loss: 3.13860e-02
I0211 20:26:05.567894 22542570456896 run_lib.py:133] step: 813100, training_loss: 2.28760e-02
I0211 20:26:05.721120 22542570456896 run_lib.py:146] step: 813100, eval_loss: 2.89082e-02
I0211 20:26:23.136325 22542570456896 run_lib.py:133] step: 813150, training_loss: 2.66814e-02
I0211 20:26:40.595704 22542570456896 run_lib.py:133] step: 813200, training_loss: 2.90455e-02
I0211 20:26:40.761685 22542570456896 run_lib.py:146] step: 813200, eval_loss: 2.96675e-02
I0211 20:26:58.364619 22542570456896 run_lib.py:133] step: 813250, training_loss: 3.53026e-02
I0211 20:27:15.775998 22542570456896 run_lib.py:133] step: 813300, training_loss: 2.22984e-02
I0211 20:27:15.941778 22542570456896 run_lib.py:146] step: 813300, eval_loss: 2.92459e-02
I0211 20:27:33.490189 22542570456896 run_lib.py:133] step: 813350, training_loss: 2.31735e-02
I0211 20:27:50.846378 22542570456896 run_lib.py:133] step: 813400, training_loss: 2.58514e-02
I0211 20:27:51.005332 22542570456896 run_lib.py:146] step: 813400, eval_loss: 2.75382e-02
I0211 20:28:08.603076 22542570456896 run_lib.py:133] step: 813450, training_loss: 2.69502e-02
I0211 20:28:25.972689 22542570456896 run_lib.py:133] step: 813500, training_loss: 2.22223e-02
I0211 20:28:26.127869 22542570456896 run_lib.py:146] step: 813500, eval_loss: 3.66188e-02
I0211 20:28:43.564077 22542570456896 run_lib.py:133] step: 813550, training_loss: 2.76178e-02
I0211 20:29:01.098067 22542570456896 run_lib.py:133] step: 813600, training_loss: 3.32086e-02
I0211 20:29:01.249943 22542570456896 run_lib.py:146] step: 813600, eval_loss: 3.79755e-02
I0211 20:29:18.687082 22542570456896 run_lib.py:133] step: 813650, training_loss: 3.43291e-02
I0211 20:29:36.246336 22542570456896 run_lib.py:133] step: 813700, training_loss: 2.49829e-02
I0211 20:29:36.412687 22542570456896 run_lib.py:146] step: 813700, eval_loss: 3.82711e-02
I0211 20:29:53.832456 22542570456896 run_lib.py:133] step: 813750, training_loss: 2.38696e-02
I0211 20:30:11.248642 22542570456896 run_lib.py:133] step: 813800, training_loss: 3.27919e-02
I0211 20:30:11.409249 22542570456896 run_lib.py:146] step: 813800, eval_loss: 2.71429e-02
I0211 20:30:29.029424 22542570456896 run_lib.py:133] step: 813850, training_loss: 2.62065e-02
I0211 20:30:46.412787 22542570456896 run_lib.py:133] step: 813900, training_loss: 2.26968e-02
I0211 20:30:46.569305 22542570456896 run_lib.py:146] step: 813900, eval_loss: 2.71579e-02
I0211 20:31:03.956053 22542570456896 run_lib.py:133] step: 813950, training_loss: 2.58240e-02
I0211 20:31:21.511032 22542570456896 run_lib.py:133] step: 814000, training_loss: 3.15753e-02
I0211 20:31:21.674464 22542570456896 run_lib.py:146] step: 814000, eval_loss: 2.68810e-02
I0211 20:31:39.125483 22542570456896 run_lib.py:133] step: 814050, training_loss: 3.18514e-02
I0211 20:31:56.559120 22542570456896 run_lib.py:133] step: 814100, training_loss: 2.44122e-02
I0211 20:31:56.711296 22542570456896 run_lib.py:146] step: 814100, eval_loss: 2.65160e-02
I0211 20:32:14.181298 22542570456896 run_lib.py:133] step: 814150, training_loss: 3.23053e-02
I0211 20:32:31.635777 22542570456896 run_lib.py:133] step: 814200, training_loss: 3.02672e-02
I0211 20:32:31.791537 22542570456896 run_lib.py:146] step: 814200, eval_loss: 2.64050e-02
I0211 20:32:49.228879 22542570456896 run_lib.py:133] step: 814250, training_loss: 2.10280e-02
I0211 20:33:06.605040 22542570456896 run_lib.py:133] step: 814300, training_loss: 2.62985e-02
I0211 20:33:06.781310 22542570456896 run_lib.py:146] step: 814300, eval_loss: 3.20715e-02
I0211 20:33:24.370639 22542570456896 run_lib.py:133] step: 814350, training_loss: 2.86016e-02
I0211 20:33:41.880358 22542570456896 run_lib.py:133] step: 814400, training_loss: 3.18354e-02
I0211 20:33:42.034997 22542570456896 run_lib.py:146] step: 814400, eval_loss: 2.33658e-02
I0211 20:33:59.421612 22542570456896 run_lib.py:133] step: 814450, training_loss: 2.38341e-02
I0211 20:34:16.761140 22542570456896 run_lib.py:133] step: 814500, training_loss: 1.98146e-02
I0211 20:34:16.915355 22542570456896 run_lib.py:146] step: 814500, eval_loss: 3.19032e-02
I0211 20:34:34.437685 22542570456896 run_lib.py:133] step: 814550, training_loss: 2.56328e-02
I0211 20:34:51.850325 22542570456896 run_lib.py:133] step: 814600, training_loss: 2.48393e-02
I0211 20:34:52.006565 22542570456896 run_lib.py:146] step: 814600, eval_loss: 2.55843e-02
I0211 20:35:09.599933 22542570456896 run_lib.py:133] step: 814650, training_loss: 2.94243e-02
I0211 20:35:26.957108 22542570456896 run_lib.py:133] step: 814700, training_loss: 2.63107e-02
I0211 20:35:27.114273 22542570456896 run_lib.py:146] step: 814700, eval_loss: 2.22827e-02
I0211 20:35:44.632186 22542570456896 run_lib.py:133] step: 814750, training_loss: 2.36691e-02
I0211 20:36:01.992934 22542570456896 run_lib.py:133] step: 814800, training_loss: 2.61847e-02
I0211 20:36:02.147276 22542570456896 run_lib.py:146] step: 814800, eval_loss: 2.98871e-02
I0211 20:36:19.669865 22542570456896 run_lib.py:133] step: 814850, training_loss: 2.48195e-02
I0211 20:36:37.100292 22542570456896 run_lib.py:133] step: 814900, training_loss: 3.41595e-02
I0211 20:36:37.256152 22542570456896 run_lib.py:146] step: 814900, eval_loss: 2.58713e-02
I0211 20:36:54.662963 22542570456896 run_lib.py:133] step: 814950, training_loss: 2.58628e-02
I0211 20:37:12.247116 22542570456896 run_lib.py:133] step: 815000, training_loss: 2.41543e-02
I0211 20:37:12.402075 22542570456896 run_lib.py:146] step: 815000, eval_loss: 3.86092e-02
I0211 20:37:29.783432 22542570456896 run_lib.py:133] step: 815050, training_loss: 3.17657e-02
I0211 20:37:47.184952 22542570456896 run_lib.py:133] step: 815100, training_loss: 2.20117e-02
I0211 20:37:47.339637 22542570456896 run_lib.py:146] step: 815100, eval_loss: 2.88182e-02
I0211 20:38:04.888569 22542570456896 run_lib.py:133] step: 815150, training_loss: 2.76562e-02
I0211 20:38:22.350385 22542570456896 run_lib.py:133] step: 815200, training_loss: 2.56426e-02
I0211 20:38:22.508257 22542570456896 run_lib.py:146] step: 815200, eval_loss: 3.24127e-02
I0211 20:38:40.112697 22542570456896 run_lib.py:133] step: 815250, training_loss: 3.05114e-02
I0211 20:38:57.490800 22542570456896 run_lib.py:133] step: 815300, training_loss: 2.86270e-02
I0211 20:38:57.652885 22542570456896 run_lib.py:146] step: 815300, eval_loss: 3.01688e-02
I0211 20:39:15.036418 22542570456896 run_lib.py:133] step: 815350, training_loss: 2.60267e-02
I0211 20:39:32.571959 22542570456896 run_lib.py:133] step: 815400, training_loss: 2.24396e-02
I0211 20:39:32.743001 22542570456896 run_lib.py:146] step: 815400, eval_loss: 2.71684e-02
I0211 20:39:50.186076 22542570456896 run_lib.py:133] step: 815450, training_loss: 2.53167e-02
I0211 20:40:07.584810 22542570456896 run_lib.py:133] step: 815500, training_loss: 2.99475e-02
I0211 20:40:07.742481 22542570456896 run_lib.py:146] step: 815500, eval_loss: 2.67415e-02
I0211 20:40:25.159265 22542570456896 run_lib.py:133] step: 815550, training_loss: 2.60956e-02
I0211 20:40:42.746121 22542570456896 run_lib.py:133] step: 815600, training_loss: 2.26990e-02
I0211 20:40:42.899867 22542570456896 run_lib.py:146] step: 815600, eval_loss: 3.72765e-02
I0211 20:41:00.300006 22542570456896 run_lib.py:133] step: 815650, training_loss: 2.51267e-02
I0211 20:41:17.765211 22542570456896 run_lib.py:133] step: 815700, training_loss: 2.55704e-02
I0211 20:41:17.940834 22542570456896 run_lib.py:146] step: 815700, eval_loss: 3.16570e-02
I0211 20:41:35.391088 22542570456896 run_lib.py:133] step: 815750, training_loss: 2.73375e-02
I0211 20:41:52.830320 22542570456896 run_lib.py:133] step: 815800, training_loss: 2.45474e-02
I0211 20:41:52.986492 22542570456896 run_lib.py:146] step: 815800, eval_loss: 2.68130e-02
I0211 20:42:10.587707 22542570456896 run_lib.py:133] step: 815850, training_loss: 2.88809e-02
I0211 20:42:28.008945 22542570456896 run_lib.py:133] step: 815900, training_loss: 3.29614e-02
I0211 20:42:28.163151 22542570456896 run_lib.py:146] step: 815900, eval_loss: 2.60737e-02
I0211 20:42:45.604567 22542570456896 run_lib.py:133] step: 815950, training_loss: 2.37196e-02
I0211 20:43:03.051452 22542570456896 run_lib.py:133] step: 816000, training_loss: 2.93861e-02
I0211 20:43:03.203406 22542570456896 run_lib.py:146] step: 816000, eval_loss: 3.05979e-02
I0211 20:43:20.823285 22542570456896 run_lib.py:133] step: 816050, training_loss: 2.33897e-02
I0211 20:43:38.261837 22542570456896 run_lib.py:133] step: 816100, training_loss: 2.85246e-02
I0211 20:43:38.420352 22542570456896 run_lib.py:146] step: 816100, eval_loss: 2.73901e-02
I0211 20:43:55.957136 22542570456896 run_lib.py:133] step: 816150, training_loss: 2.33807e-02
I0211 20:44:13.406477 22542570456896 run_lib.py:133] step: 816200, training_loss: 3.88483e-02
I0211 20:44:13.561489 22542570456896 run_lib.py:146] step: 816200, eval_loss: 3.20086e-02
I0211 20:44:31.100480 22542570456896 run_lib.py:133] step: 816250, training_loss: 2.93487e-02
I0211 20:44:48.519378 22542570456896 run_lib.py:133] step: 816300, training_loss: 2.53836e-02
I0211 20:44:48.675121 22542570456896 run_lib.py:146] step: 816300, eval_loss: 2.81709e-02
I0211 20:45:06.076060 22542570456896 run_lib.py:133] step: 816350, training_loss: 2.57998e-02
I0211 20:45:23.687523 22542570456896 run_lib.py:133] step: 816400, training_loss: 3.70441e-02
I0211 20:45:23.841474 22542570456896 run_lib.py:146] step: 816400, eval_loss: 2.95162e-02
I0211 20:45:41.223399 22542570456896 run_lib.py:133] step: 816450, training_loss: 2.92969e-02
I0211 20:45:58.772556 22542570456896 run_lib.py:133] step: 816500, training_loss: 2.76062e-02
I0211 20:45:58.928250 22542570456896 run_lib.py:146] step: 816500, eval_loss: 3.01205e-02
I0211 20:46:16.361830 22542570456896 run_lib.py:133] step: 816550, training_loss: 3.27430e-02
I0211 20:46:33.821547 22542570456896 run_lib.py:133] step: 816600, training_loss: 3.10892e-02
I0211 20:46:34.006268 22542570456896 run_lib.py:146] step: 816600, eval_loss: 2.44607e-02
I0211 20:46:51.650349 22542570456896 run_lib.py:133] step: 816650, training_loss: 2.96469e-02
I0211 20:47:09.073189 22542570456896 run_lib.py:133] step: 816700, training_loss: 3.19859e-02
I0211 20:47:09.236963 22542570456896 run_lib.py:146] step: 816700, eval_loss: 3.33427e-02
I0211 20:47:26.635056 22542570456896 run_lib.py:133] step: 816750, training_loss: 3.04995e-02
I0211 20:47:44.157962 22542570456896 run_lib.py:133] step: 816800, training_loss: 3.07017e-02
I0211 20:47:44.311992 22542570456896 run_lib.py:146] step: 816800, eval_loss: 3.23786e-02
I0211 20:48:01.672297 22542570456896 run_lib.py:133] step: 816850, training_loss: 3.03442e-02
I0211 20:48:19.126477 22542570456896 run_lib.py:133] step: 816900, training_loss: 2.48469e-02
I0211 20:48:19.459597 22542570456896 run_lib.py:146] step: 816900, eval_loss: 3.23338e-02
I0211 20:48:36.886822 22542570456896 run_lib.py:133] step: 816950, training_loss: 3.43376e-02
I0211 20:48:54.260275 22542570456896 run_lib.py:133] step: 817000, training_loss: 4.09775e-02
I0211 20:48:54.415105 22542570456896 run_lib.py:146] step: 817000, eval_loss: 2.85154e-02
I0211 20:49:11.761104 22542570456896 run_lib.py:133] step: 817050, training_loss: 2.43012e-02
I0211 20:49:29.176167 22542570456896 run_lib.py:133] step: 817100, training_loss: 1.91559e-02
I0211 20:49:29.334688 22542570456896 run_lib.py:146] step: 817100, eval_loss: 3.10151e-02
I0211 20:49:46.932075 22542570456896 run_lib.py:133] step: 817150, training_loss: 2.99690e-02
I0211 20:50:04.431828 22542570456896 run_lib.py:133] step: 817200, training_loss: 3.18322e-02
I0211 20:50:04.596092 22542570456896 run_lib.py:146] step: 817200, eval_loss: 3.63141e-02
I0211 20:50:21.968315 22542570456896 run_lib.py:133] step: 817250, training_loss: 3.67670e-02
I0211 20:50:39.347794 22542570456896 run_lib.py:133] step: 817300, training_loss: 3.04409e-02
I0211 20:50:39.502305 22542570456896 run_lib.py:146] step: 817300, eval_loss: 3.41074e-02
I0211 20:50:57.054792 22542570456896 run_lib.py:133] step: 817350, training_loss: 2.93892e-02
I0211 20:51:14.551018 22542570456896 run_lib.py:133] step: 817400, training_loss: 2.90943e-02
I0211 20:51:14.705558 22542570456896 run_lib.py:146] step: 817400, eval_loss: 3.27475e-02
I0211 20:51:32.187302 22542570456896 run_lib.py:133] step: 817450, training_loss: 3.59994e-02
I0211 20:51:49.571026 22542570456896 run_lib.py:133] step: 817500, training_loss: 3.22098e-02
I0211 20:51:49.726252 22542570456896 run_lib.py:146] step: 817500, eval_loss: 2.59387e-02
I0211 20:52:07.292668 22542570456896 run_lib.py:133] step: 817550, training_loss: 3.09053e-02
I0211 20:52:24.685420 22542570456896 run_lib.py:133] step: 817600, training_loss: 3.42343e-02
I0211 20:52:24.841583 22542570456896 run_lib.py:146] step: 817600, eval_loss: 3.32938e-02
I0211 20:52:42.379440 22542570456896 run_lib.py:133] step: 817650, training_loss: 2.81157e-02
I0211 20:52:59.736562 22542570456896 run_lib.py:133] step: 817700, training_loss: 2.82370e-02
I0211 20:52:59.897392 22542570456896 run_lib.py:146] step: 817700, eval_loss: 2.90093e-02
I0211 20:53:17.512482 22542570456896 run_lib.py:133] step: 817750, training_loss: 3.68801e-02
I0211 20:53:34.953775 22542570456896 run_lib.py:133] step: 817800, training_loss: 2.58110e-02
I0211 20:53:35.108374 22542570456896 run_lib.py:146] step: 817800, eval_loss: 3.66946e-02
I0211 20:53:52.518222 22542570456896 run_lib.py:133] step: 817850, training_loss: 2.92196e-02
I0211 20:54:10.065736 22542570456896 run_lib.py:133] step: 817900, training_loss: 3.13927e-02
I0211 20:54:10.217335 22542570456896 run_lib.py:146] step: 817900, eval_loss: 2.27014e-02
I0211 20:54:27.590803 22542570456896 run_lib.py:133] step: 817950, training_loss: 2.41001e-02
I0211 20:54:45.170771 22542570456896 run_lib.py:133] step: 818000, training_loss: 2.77780e-02
I0211 20:54:45.348251 22542570456896 run_lib.py:146] step: 818000, eval_loss: 2.41619e-02
I0211 20:55:02.735842 22542570456896 run_lib.py:133] step: 818050, training_loss: 2.38943e-02
I0211 20:55:20.136267 22542570456896 run_lib.py:133] step: 818100, training_loss: 2.73504e-02
I0211 20:55:20.293355 22542570456896 run_lib.py:146] step: 818100, eval_loss: 2.66936e-02
I0211 20:55:37.891474 22542570456896 run_lib.py:133] step: 818150, training_loss: 3.17228e-02
I0211 20:55:55.265796 22542570456896 run_lib.py:133] step: 818200, training_loss: 2.27102e-02
I0211 20:55:55.419106 22542570456896 run_lib.py:146] step: 818200, eval_loss: 3.27107e-02
I0211 20:56:12.823751 22542570456896 run_lib.py:133] step: 818250, training_loss: 2.53488e-02
I0211 20:56:30.299074 22542570456896 run_lib.py:133] step: 818300, training_loss: 3.09781e-02
I0211 20:56:30.452187 22542570456896 run_lib.py:146] step: 818300, eval_loss: 2.87570e-02
I0211 20:56:48.041828 22542570456896 run_lib.py:133] step: 818350, training_loss: 2.57742e-02
I0211 20:57:05.374106 22542570456896 run_lib.py:133] step: 818400, training_loss: 2.32578e-02
I0211 20:57:05.527287 22542570456896 run_lib.py:146] step: 818400, eval_loss: 2.46688e-02
I0211 20:57:22.983887 22542570456896 run_lib.py:133] step: 818450, training_loss: 3.94940e-02
I0211 20:57:40.390479 22542570456896 run_lib.py:133] step: 818500, training_loss: 3.02038e-02
I0211 20:57:40.556308 22542570456896 run_lib.py:146] step: 818500, eval_loss: 2.49524e-02
I0211 20:57:58.024259 22542570456896 run_lib.py:133] step: 818550, training_loss: 2.90939e-02
I0211 20:58:15.478815 22542570456896 run_lib.py:133] step: 818600, training_loss: 2.53259e-02
I0211 20:58:15.635566 22542570456896 run_lib.py:146] step: 818600, eval_loss: 2.37899e-02
I0211 20:58:33.206316 22542570456896 run_lib.py:133] step: 818650, training_loss: 3.18032e-02
I0211 20:58:50.620764 22542570456896 run_lib.py:133] step: 818700, training_loss: 2.34827e-02
I0211 20:58:50.776562 22542570456896 run_lib.py:146] step: 818700, eval_loss: 2.44474e-02
I0211 20:59:08.167335 22542570456896 run_lib.py:133] step: 818750, training_loss: 2.65061e-02
I0211 20:59:25.555910 22542570456896 run_lib.py:133] step: 818800, training_loss: 3.06918e-02
I0211 20:59:25.717101 22542570456896 run_lib.py:146] step: 818800, eval_loss: 2.54986e-02
I0211 20:59:43.337773 22542570456896 run_lib.py:133] step: 818850, training_loss: 2.77375e-02
I0211 21:00:00.722948 22542570456896 run_lib.py:133] step: 818900, training_loss: 2.90440e-02
I0211 21:00:00.878362 22542570456896 run_lib.py:146] step: 818900, eval_loss: 2.72256e-02
I0211 21:00:18.483267 22542570456896 run_lib.py:133] step: 818950, training_loss: 2.75415e-02
I0211 21:00:35.880620 22542570456896 run_lib.py:133] step: 819000, training_loss: 2.54659e-02
I0211 21:00:36.038843 22542570456896 run_lib.py:146] step: 819000, eval_loss: 2.67450e-02
I0211 21:00:53.585488 22542570456896 run_lib.py:133] step: 819050, training_loss: 2.69229e-02
I0211 21:01:11.056302 22542570456896 run_lib.py:133] step: 819100, training_loss: 2.45098e-02
I0211 21:01:11.220605 22542570456896 run_lib.py:146] step: 819100, eval_loss: 3.15326e-02
I0211 21:01:28.827603 22542570456896 run_lib.py:133] step: 819150, training_loss: 2.31714e-02
I0211 21:01:46.265014 22542570456896 run_lib.py:133] step: 819200, training_loss: 2.77248e-02
I0211 21:01:46.424357 22542570456896 run_lib.py:146] step: 819200, eval_loss: 3.76859e-02
I0211 21:02:03.864741 22542570456896 run_lib.py:133] step: 819250, training_loss: 3.18820e-02
I0211 21:02:21.407479 22542570456896 run_lib.py:133] step: 819300, training_loss: 2.99473e-02
I0211 21:02:21.559308 22542570456896 run_lib.py:146] step: 819300, eval_loss: 2.37261e-02
I0211 21:02:38.929602 22542570456896 run_lib.py:133] step: 819350, training_loss: 2.98757e-02
I0211 21:02:56.356989 22542570456896 run_lib.py:133] step: 819400, training_loss: 2.41184e-02
I0211 21:02:56.528491 22542570456896 run_lib.py:146] step: 819400, eval_loss: 2.83191e-02
I0211 21:03:14.126064 22542570456896 run_lib.py:133] step: 819450, training_loss: 2.78574e-02
I0211 21:03:31.707460 22542570456896 run_lib.py:133] step: 819500, training_loss: 2.45479e-02
I0211 21:03:31.864569 22542570456896 run_lib.py:146] step: 819500, eval_loss: 3.36417e-02
I0211 21:03:49.279210 22542570456896 run_lib.py:133] step: 819550, training_loss: 2.51702e-02
I0211 21:04:06.724103 22542570456896 run_lib.py:133] step: 819600, training_loss: 3.56024e-02
I0211 21:04:06.881419 22542570456896 run_lib.py:146] step: 819600, eval_loss: 3.57858e-02
I0211 21:04:24.320164 22542570456896 run_lib.py:133] step: 819650, training_loss: 2.84799e-02
I0211 21:04:41.945147 22542570456896 run_lib.py:133] step: 819700, training_loss: 2.78799e-02
I0211 21:04:42.099949 22542570456896 run_lib.py:146] step: 819700, eval_loss: 3.01278e-02
I0211 21:04:59.475466 22542570456896 run_lib.py:133] step: 819750, training_loss: 2.55491e-02
I0211 21:05:16.906951 22542570456896 run_lib.py:133] step: 819800, training_loss: 2.91819e-02
I0211 21:05:17.058306 22542570456896 run_lib.py:146] step: 819800, eval_loss: 2.60310e-02
I0211 21:05:34.490451 22542570456896 run_lib.py:133] step: 819850, training_loss: 3.65505e-02
I0211 21:05:52.078787 22542570456896 run_lib.py:133] step: 819900, training_loss: 2.53304e-02
I0211 21:05:52.253199 22542570456896 run_lib.py:146] step: 819900, eval_loss: 3.32547e-02
I0211 21:06:09.694198 22542570456896 run_lib.py:133] step: 819950, training_loss: 2.78412e-02
I0211 21:06:27.200316 22542570456896 run_lib.py:133] step: 820000, training_loss: 2.13376e-02
I0211 21:06:27.899443 22542570456896 run_lib.py:146] step: 820000, eval_loss: 2.62623e-02
I0211 21:06:47.921712 22542570456896 run_lib.py:133] step: 820050, training_loss: 3.14063e-02
I0211 21:07:05.293271 22542570456896 run_lib.py:133] step: 820100, training_loss: 2.81407e-02
I0211 21:07:05.448242 22542570456896 run_lib.py:146] step: 820100, eval_loss: 2.99776e-02
I0211 21:07:22.830241 22542570456896 run_lib.py:133] step: 820150, training_loss: 3.57164e-02
I0211 21:07:40.405148 22542570456896 run_lib.py:133] step: 820200, training_loss: 2.52216e-02
I0211 21:07:40.562211 22542570456896 run_lib.py:146] step: 820200, eval_loss: 3.13788e-02
I0211 21:07:58.005798 22542570456896 run_lib.py:133] step: 820250, training_loss: 3.12641e-02
I0211 21:08:15.536020 22542570456896 run_lib.py:133] step: 820300, training_loss: 2.60106e-02
I0211 21:08:15.686357 22542570456896 run_lib.py:146] step: 820300, eval_loss: 2.46415e-02
I0211 21:08:33.100821 22542570456896 run_lib.py:133] step: 820350, training_loss: 2.31683e-02
I0211 21:08:50.483157 22542570456896 run_lib.py:133] step: 820400, training_loss: 2.27445e-02
I0211 21:08:50.637321 22542570456896 run_lib.py:146] step: 820400, eval_loss: 2.55734e-02
I0211 21:09:08.190702 22542570456896 run_lib.py:133] step: 820450, training_loss: 3.02661e-02
I0211 21:09:25.748653 22542570456896 run_lib.py:133] step: 820500, training_loss: 3.32161e-02
I0211 21:09:25.911303 22542570456896 run_lib.py:146] step: 820500, eval_loss: 2.49706e-02
I0211 21:09:43.348576 22542570456896 run_lib.py:133] step: 820550, training_loss: 2.61953e-02
I0211 21:10:00.722035 22542570456896 run_lib.py:133] step: 820600, training_loss: 3.53405e-02
I0211 21:10:00.876314 22542570456896 run_lib.py:146] step: 820600, eval_loss: 3.11012e-02
I0211 21:10:18.378344 22542570456896 run_lib.py:133] step: 820650, training_loss: 2.72499e-02
I0211 21:10:35.819399 22542570456896 run_lib.py:133] step: 820700, training_loss: 2.87474e-02
I0211 21:10:35.979312 22542570456896 run_lib.py:146] step: 820700, eval_loss: 2.96220e-02
I0211 21:10:53.551185 22542570456896 run_lib.py:133] step: 820750, training_loss: 2.51630e-02
I0211 21:11:10.974716 22542570456896 run_lib.py:133] step: 820800, training_loss: 2.47081e-02
I0211 21:11:11.128570 22542570456896 run_lib.py:146] step: 820800, eval_loss: 2.82333e-02
I0211 21:11:28.750155 22542570456896 run_lib.py:133] step: 820850, training_loss: 2.48110e-02
I0211 21:11:46.156463 22542570456896 run_lib.py:133] step: 820900, training_loss: 2.74818e-02
I0211 21:11:46.312340 22542570456896 run_lib.py:146] step: 820900, eval_loss: 2.71533e-02
I0211 21:12:03.682863 22542570456896 run_lib.py:133] step: 820950, training_loss: 3.17228e-02
I0211 21:12:21.254737 22542570456896 run_lib.py:133] step: 821000, training_loss: 3.26447e-02
I0211 21:12:21.418233 22542570456896 run_lib.py:146] step: 821000, eval_loss: 3.42245e-02
I0211 21:12:38.855807 22542570456896 run_lib.py:133] step: 821050, training_loss: 2.56425e-02
I0211 21:12:56.484892 22542570456896 run_lib.py:133] step: 821100, training_loss: 2.89909e-02
I0211 21:12:56.640577 22542570456896 run_lib.py:146] step: 821100, eval_loss: 3.10581e-02
I0211 21:13:14.012541 22542570456896 run_lib.py:133] step: 821150, training_loss: 2.71452e-02
I0211 21:13:31.428108 22542570456896 run_lib.py:133] step: 821200, training_loss: 2.27791e-02
I0211 21:13:31.583262 22542570456896 run_lib.py:146] step: 821200, eval_loss: 2.65798e-02
I0211 21:13:49.101740 22542570456896 run_lib.py:133] step: 821250, training_loss: 2.83467e-02
I0211 21:14:06.589393 22542570456896 run_lib.py:133] step: 821300, training_loss: 2.53479e-02
I0211 21:14:06.750757 22542570456896 run_lib.py:146] step: 821300, eval_loss: 3.00152e-02
I0211 21:14:24.165724 22542570456896 run_lib.py:133] step: 821350, training_loss: 2.85580e-02
I0211 21:14:41.730137 22542570456896 run_lib.py:133] step: 821400, training_loss: 2.69518e-02
I0211 21:14:41.887507 22542570456896 run_lib.py:146] step: 821400, eval_loss: 2.28224e-02
I0211 21:14:59.263718 22542570456896 run_lib.py:133] step: 821450, training_loss: 2.90094e-02
I0211 21:15:16.681831 22542570456896 run_lib.py:133] step: 821500, training_loss: 2.95606e-02
I0211 21:15:16.841478 22542570456896 run_lib.py:146] step: 821500, eval_loss: 3.23108e-02
I0211 21:15:34.313133 22542570456896 run_lib.py:133] step: 821550, training_loss: 2.98625e-02
I0211 21:15:51.738451 22542570456896 run_lib.py:133] step: 821600, training_loss: 2.36923e-02
I0211 21:15:51.893945 22542570456896 run_lib.py:146] step: 821600, eval_loss: 2.61208e-02
I0211 21:16:09.336851 22542570456896 run_lib.py:133] step: 821650, training_loss: 2.68010e-02
I0211 21:16:26.696863 22542570456896 run_lib.py:133] step: 821700, training_loss: 2.51135e-02
I0211 21:16:26.850310 22542570456896 run_lib.py:146] step: 821700, eval_loss: 2.56546e-02
I0211 21:16:44.413464 22542570456896 run_lib.py:133] step: 821750, training_loss: 2.59333e-02
I0211 21:17:01.923108 22542570456896 run_lib.py:133] step: 821800, training_loss: 2.60515e-02
I0211 21:17:02.081617 22542570456896 run_lib.py:146] step: 821800, eval_loss: 2.92188e-02
I0211 21:17:19.583619 22542570456896 run_lib.py:133] step: 821850, training_loss: 2.24052e-02
I0211 21:17:37.032595 22542570456896 run_lib.py:133] step: 821900, training_loss: 2.49795e-02
I0211 21:17:37.189320 22542570456896 run_lib.py:146] step: 821900, eval_loss: 3.29975e-02
I0211 21:17:54.747252 22542570456896 run_lib.py:133] step: 821950, training_loss: 3.04378e-02
I0211 21:18:12.156744 22542570456896 run_lib.py:133] step: 822000, training_loss: 2.96497e-02
I0211 21:18:12.308485 22542570456896 run_lib.py:146] step: 822000, eval_loss: 3.13559e-02
I0211 21:18:29.872329 22542570456896 run_lib.py:133] step: 822050, training_loss: 2.96076e-02
I0211 21:18:47.317441 22542570456896 run_lib.py:133] step: 822100, training_loss: 2.78240e-02
I0211 21:18:47.474320 22542570456896 run_lib.py:146] step: 822100, eval_loss: 2.79169e-02
I0211 21:19:05.113068 22542570456896 run_lib.py:133] step: 822150, training_loss: 2.61835e-02
I0211 21:19:22.503493 22542570456896 run_lib.py:133] step: 822200, training_loss: 3.04779e-02
I0211 21:19:22.655127 22542570456896 run_lib.py:146] step: 822200, eval_loss: 3.40622e-02
I0211 21:19:40.185847 22542570456896 run_lib.py:133] step: 822250, training_loss: 2.64596e-02
I0211 21:19:57.586648 22542570456896 run_lib.py:133] step: 822300, training_loss: 2.64702e-02
I0211 21:19:57.741251 22542570456896 run_lib.py:146] step: 822300, eval_loss: 2.84951e-02
I0211 21:20:15.143893 22542570456896 run_lib.py:133] step: 822350, training_loss: 2.24782e-02
I0211 21:20:32.645542 22542570456896 run_lib.py:133] step: 822400, training_loss: 3.16146e-02
I0211 21:20:32.827446 22542570456896 run_lib.py:146] step: 822400, eval_loss: 3.09876e-02
I0211 21:20:50.209927 22542570456896 run_lib.py:133] step: 822450, training_loss: 2.04635e-02
I0211 21:21:07.525883 22542570456896 run_lib.py:133] step: 822500, training_loss: 2.60871e-02
I0211 21:21:07.680347 22542570456896 run_lib.py:146] step: 822500, eval_loss: 2.68232e-02
I0211 21:21:25.130698 22542570456896 run_lib.py:133] step: 822550, training_loss: 2.35906e-02
I0211 21:21:42.489561 22542570456896 run_lib.py:133] step: 822600, training_loss: 3.00623e-02
I0211 21:21:42.644288 22542570456896 run_lib.py:146] step: 822600, eval_loss: 3.13536e-02
I0211 21:22:00.189071 22542570456896 run_lib.py:133] step: 822650, training_loss: 2.76399e-02
I0211 21:22:17.633049 22542570456896 run_lib.py:133] step: 822700, training_loss: 2.25596e-02
I0211 21:22:17.787495 22542570456896 run_lib.py:146] step: 822700, eval_loss: 2.63583e-02
I0211 21:22:35.248142 22542570456896 run_lib.py:133] step: 822750, training_loss: 2.94916e-02
I0211 21:22:52.874414 22542570456896 run_lib.py:133] step: 822800, training_loss: 2.25000e-02
I0211 21:22:53.030392 22542570456896 run_lib.py:146] step: 822800, eval_loss: 3.22143e-02
I0211 21:23:10.419299 22542570456896 run_lib.py:133] step: 822850, training_loss: 3.16088e-02
I0211 21:23:27.872042 22542570456896 run_lib.py:133] step: 822900, training_loss: 2.74414e-02
I0211 21:23:28.047187 22542570456896 run_lib.py:146] step: 822900, eval_loss: 2.74351e-02
I0211 21:23:45.483269 22542570456896 run_lib.py:133] step: 822950, training_loss: 2.85137e-02
I0211 21:24:03.135287 22542570456896 run_lib.py:133] step: 823000, training_loss: 3.26791e-02
I0211 21:24:03.290137 22542570456896 run_lib.py:146] step: 823000, eval_loss: 3.35194e-02
I0211 21:24:20.757162 22542570456896 run_lib.py:133] step: 823050, training_loss: 1.69198e-02
I0211 21:24:38.241760 22542570456896 run_lib.py:133] step: 823100, training_loss: 2.76000e-02
I0211 21:24:38.396388 22542570456896 run_lib.py:146] step: 823100, eval_loss: 3.20596e-02
I0211 21:24:55.818944 22542570456896 run_lib.py:133] step: 823150, training_loss: 2.56364e-02
I0211 21:25:13.272472 22542570456896 run_lib.py:133] step: 823200, training_loss: 2.63599e-02
I0211 21:25:13.435404 22542570456896 run_lib.py:146] step: 823200, eval_loss: 2.70705e-02
I0211 21:25:31.024982 22542570456896 run_lib.py:133] step: 823250, training_loss: 2.36262e-02
I0211 21:25:48.560020 22542570456896 run_lib.py:133] step: 823300, training_loss: 2.69617e-02
I0211 21:25:48.718356 22542570456896 run_lib.py:146] step: 823300, eval_loss: 3.20057e-02
I0211 21:26:06.138342 22542570456896 run_lib.py:133] step: 823350, training_loss: 2.27769e-02
I0211 21:26:23.586829 22542570456896 run_lib.py:133] step: 823400, training_loss: 2.25844e-02
I0211 21:26:23.741372 22542570456896 run_lib.py:146] step: 823400, eval_loss: 2.85086e-02
I0211 21:26:41.304322 22542570456896 run_lib.py:133] step: 823450, training_loss: 2.95043e-02
I0211 21:26:58.736708 22542570456896 run_lib.py:133] step: 823500, training_loss: 2.03258e-02
I0211 21:26:58.896716 22542570456896 run_lib.py:146] step: 823500, eval_loss: 2.95676e-02
I0211 21:27:16.481037 22542570456896 run_lib.py:133] step: 823550, training_loss: 2.61548e-02
I0211 21:27:33.926756 22542570456896 run_lib.py:133] step: 823600, training_loss: 2.48790e-02
I0211 21:27:34.080455 22542570456896 run_lib.py:146] step: 823600, eval_loss: 3.06948e-02
I0211 21:27:51.652165 22542570456896 run_lib.py:133] step: 823650, training_loss: 3.35591e-02
I0211 21:28:09.053868 22542570456896 run_lib.py:133] step: 823700, training_loss: 3.30177e-02
I0211 21:28:09.207424 22542570456896 run_lib.py:146] step: 823700, eval_loss: 3.54726e-02
I0211 21:28:26.634131 22542570456896 run_lib.py:133] step: 823750, training_loss: 2.54563e-02
I0211 21:28:44.257297 22542570456896 run_lib.py:133] step: 823800, training_loss: 2.81925e-02
I0211 21:28:44.438476 22542570456896 run_lib.py:146] step: 823800, eval_loss: 3.01929e-02
I0211 21:29:01.903677 22542570456896 run_lib.py:133] step: 823850, training_loss: 2.69806e-02
I0211 21:29:19.479831 22542570456896 run_lib.py:133] step: 823900, training_loss: 2.16743e-02
I0211 21:29:19.638516 22542570456896 run_lib.py:146] step: 823900, eval_loss: 3.45470e-02
I0211 21:29:37.058200 22542570456896 run_lib.py:133] step: 823950, training_loss: 2.61218e-02
I0211 21:29:54.486941 22542570456896 run_lib.py:133] step: 824000, training_loss: 2.62591e-02
I0211 21:29:54.641453 22542570456896 run_lib.py:146] step: 824000, eval_loss: 2.08750e-02
I0211 21:30:12.226854 22542570456896 run_lib.py:133] step: 824050, training_loss: 2.21005e-02
I0211 21:30:29.658386 22542570456896 run_lib.py:133] step: 824100, training_loss: 3.19563e-02
I0211 21:30:29.817066 22542570456896 run_lib.py:146] step: 824100, eval_loss: 3.64553e-02
I0211 21:30:47.296445 22542570456896 run_lib.py:133] step: 824150, training_loss: 2.75024e-02
I0211 21:31:04.906920 22542570456896 run_lib.py:133] step: 824200, training_loss: 2.54794e-02
I0211 21:31:05.062396 22542570456896 run_lib.py:146] step: 824200, eval_loss: 3.37348e-02
I0211 21:31:22.503416 22542570456896 run_lib.py:133] step: 824250, training_loss: 2.91533e-02
I0211 21:31:39.931046 22542570456896 run_lib.py:133] step: 824300, training_loss: 2.15895e-02
I0211 21:31:40.233229 22542570456896 run_lib.py:146] step: 824300, eval_loss: 2.54502e-02
I0211 21:31:57.651224 22542570456896 run_lib.py:133] step: 824350, training_loss: 2.54844e-02
I0211 21:32:15.109281 22542570456896 run_lib.py:133] step: 824400, training_loss: 3.15887e-02
I0211 21:32:15.265576 22542570456896 run_lib.py:146] step: 824400, eval_loss: 3.12837e-02
I0211 21:32:32.662391 22542570456896 run_lib.py:133] step: 824450, training_loss: 3.47974e-02
I0211 21:32:50.048969 22542570456896 run_lib.py:133] step: 824500, training_loss: 2.27908e-02
I0211 21:32:50.204354 22542570456896 run_lib.py:146] step: 824500, eval_loss: 3.11450e-02
I0211 21:33:07.805619 22542570456896 run_lib.py:133] step: 824550, training_loss: 2.63652e-02
I0211 21:33:25.287629 22542570456896 run_lib.py:133] step: 824600, training_loss: 2.52048e-02
I0211 21:33:25.440346 22542570456896 run_lib.py:146] step: 824600, eval_loss: 3.48522e-02
I0211 21:33:42.891602 22542570456896 run_lib.py:133] step: 824650, training_loss: 3.15568e-02
I0211 21:34:00.327980 22542570456896 run_lib.py:133] step: 824700, training_loss: 1.90889e-02
I0211 21:34:00.493169 22542570456896 run_lib.py:146] step: 824700, eval_loss: 3.80975e-02
I0211 21:34:18.111558 22542570456896 run_lib.py:133] step: 824750, training_loss: 3.12204e-02
I0211 21:34:35.609467 22542570456896 run_lib.py:133] step: 824800, training_loss: 2.85170e-02
I0211 21:34:35.767688 22542570456896 run_lib.py:146] step: 824800, eval_loss: 3.01066e-02
I0211 21:34:53.197070 22542570456896 run_lib.py:133] step: 824850, training_loss: 1.94742e-02
I0211 21:35:10.573760 22542570456896 run_lib.py:133] step: 824900, training_loss: 2.22943e-02
I0211 21:35:10.732502 22542570456896 run_lib.py:146] step: 824900, eval_loss: 3.47439e-02
I0211 21:35:28.299838 22542570456896 run_lib.py:133] step: 824950, training_loss: 2.44497e-02
I0211 21:35:45.777327 22542570456896 run_lib.py:133] step: 825000, training_loss: 2.93913e-02
I0211 21:35:45.933529 22542570456896 run_lib.py:146] step: 825000, eval_loss: 2.67764e-02
I0211 21:36:03.533442 22542570456896 run_lib.py:133] step: 825050, training_loss: 2.93963e-02
I0211 21:36:20.973605 22542570456896 run_lib.py:133] step: 825100, training_loss: 3.14082e-02
I0211 21:36:21.127296 22542570456896 run_lib.py:146] step: 825100, eval_loss: 2.70400e-02
I0211 21:36:38.668903 22542570456896 run_lib.py:133] step: 825150, training_loss: 2.02519e-02
I0211 21:36:56.117758 22542570456896 run_lib.py:133] step: 825200, training_loss: 2.98407e-02
I0211 21:36:56.275301 22542570456896 run_lib.py:146] step: 825200, eval_loss: 3.10546e-02
I0211 21:37:13.667263 22542570456896 run_lib.py:133] step: 825250, training_loss: 2.25839e-02
I0211 21:37:31.313652 22542570456896 run_lib.py:133] step: 825300, training_loss: 2.56406e-02
I0211 21:37:31.469494 22542570456896 run_lib.py:146] step: 825300, eval_loss: 2.96963e-02
I0211 21:37:48.869482 22542570456896 run_lib.py:133] step: 825350, training_loss: 3.33804e-02
I0211 21:38:06.457482 22542570456896 run_lib.py:133] step: 825400, training_loss: 3.47809e-02
I0211 21:38:06.612134 22542570456896 run_lib.py:146] step: 825400, eval_loss: 3.15298e-02
I0211 21:38:23.989219 22542570456896 run_lib.py:133] step: 825450, training_loss: 2.49016e-02
I0211 21:38:41.392394 22542570456896 run_lib.py:133] step: 825500, training_loss: 2.93949e-02
I0211 21:38:41.545121 22542570456896 run_lib.py:146] step: 825500, eval_loss: 3.20337e-02
I0211 21:38:59.213175 22542570456896 run_lib.py:133] step: 825550, training_loss: 2.62382e-02
I0211 21:39:16.588885 22542570456896 run_lib.py:133] step: 825600, training_loss: 2.64835e-02
I0211 21:39:16.743583 22542570456896 run_lib.py:146] step: 825600, eval_loss: 3.02346e-02
I0211 21:39:34.132675 22542570456896 run_lib.py:133] step: 825650, training_loss: 2.33530e-02
I0211 21:39:51.542220 22542570456896 run_lib.py:133] step: 825700, training_loss: 2.47609e-02
I0211 21:39:51.700553 22542570456896 run_lib.py:146] step: 825700, eval_loss: 2.51106e-02
I0211 21:40:09.253909 22542570456896 run_lib.py:133] step: 825750, training_loss: 2.57293e-02
I0211 21:40:26.650738 22542570456896 run_lib.py:133] step: 825800, training_loss: 3.29944e-02
I0211 21:40:26.819382 22542570456896 run_lib.py:146] step: 825800, eval_loss: 2.70770e-02
I0211 21:40:44.302640 22542570456896 run_lib.py:133] step: 825850, training_loss: 2.00942e-02
I0211 21:41:01.760203 22542570456896 run_lib.py:133] step: 825900, training_loss: 2.54665e-02
I0211 21:41:01.915037 22542570456896 run_lib.py:146] step: 825900, eval_loss: 4.09470e-02
I0211 21:41:19.361772 22542570456896 run_lib.py:133] step: 825950, training_loss: 3.08824e-02
I0211 21:41:36.769872 22542570456896 run_lib.py:133] step: 826000, training_loss: 2.75597e-02
I0211 21:41:36.920348 22542570456896 run_lib.py:146] step: 826000, eval_loss: 2.80206e-02
I0211 21:41:54.466614 22542570456896 run_lib.py:133] step: 826050, training_loss: 2.60674e-02
I0211 21:42:11.907393 22542570456896 run_lib.py:133] step: 826100, training_loss: 2.75579e-02
I0211 21:42:12.076693 22542570456896 run_lib.py:146] step: 826100, eval_loss: 3.46966e-02
I0211 21:42:29.565931 22542570456896 run_lib.py:133] step: 826150, training_loss: 2.42252e-02
I0211 21:42:46.992655 22542570456896 run_lib.py:133] step: 826200, training_loss: 2.37746e-02
I0211 21:42:47.150249 22542570456896 run_lib.py:146] step: 826200, eval_loss: 2.31163e-02
I0211 21:43:04.742082 22542570456896 run_lib.py:133] step: 826250, training_loss: 3.07666e-02
I0211 21:43:22.126739 22542570456896 run_lib.py:133] step: 826300, training_loss: 2.66948e-02
I0211 21:43:22.279102 22542570456896 run_lib.py:146] step: 826300, eval_loss: 2.64475e-02
I0211 21:43:39.814541 22542570456896 run_lib.py:133] step: 826350, training_loss: 2.84552e-02
I0211 21:43:57.258112 22542570456896 run_lib.py:133] step: 826400, training_loss: 2.74604e-02
I0211 21:43:57.413437 22542570456896 run_lib.py:146] step: 826400, eval_loss: 2.96824e-02
I0211 21:44:15.043385 22542570456896 run_lib.py:133] step: 826450, training_loss: 3.32102e-02
I0211 21:44:32.414134 22542570456896 run_lib.py:133] step: 826500, training_loss: 2.91625e-02
I0211 21:44:32.566780 22542570456896 run_lib.py:146] step: 826500, eval_loss: 3.56837e-02
I0211 21:44:50.098805 22542570456896 run_lib.py:133] step: 826550, training_loss: 3.43578e-02
I0211 21:45:07.476914 22542570456896 run_lib.py:133] step: 826600, training_loss: 2.65571e-02
I0211 21:45:07.640331 22542570456896 run_lib.py:146] step: 826600, eval_loss: 2.99503e-02
I0211 21:45:25.079880 22542570456896 run_lib.py:133] step: 826650, training_loss: 3.04667e-02
I0211 21:45:42.654164 22542570456896 run_lib.py:133] step: 826700, training_loss: 2.68938e-02
I0211 21:45:42.813371 22542570456896 run_lib.py:146] step: 826700, eval_loss: 3.11803e-02
I0211 21:46:00.218648 22542570456896 run_lib.py:133] step: 826750, training_loss: 2.32000e-02
I0211 21:46:17.604431 22542570456896 run_lib.py:133] step: 826800, training_loss: 2.80821e-02
I0211 21:46:17.758973 22542570456896 run_lib.py:146] step: 826800, eval_loss: 2.96848e-02
I0211 21:46:35.360662 22542570456896 run_lib.py:133] step: 826850, training_loss: 2.92399e-02
I0211 21:46:52.864137 22542570456896 run_lib.py:133] step: 826900, training_loss: 2.86399e-02
I0211 21:46:53.017162 22542570456896 run_lib.py:146] step: 826900, eval_loss: 3.08857e-02
I0211 21:47:10.443449 22542570456896 run_lib.py:133] step: 826950, training_loss: 2.82613e-02
I0211 21:47:27.869302 22542570456896 run_lib.py:133] step: 827000, training_loss: 2.21196e-02
I0211 21:47:28.023975 22542570456896 run_lib.py:146] step: 827000, eval_loss: 2.74947e-02
I0211 21:47:45.462462 22542570456896 run_lib.py:133] step: 827050, training_loss: 2.76542e-02
I0211 21:48:03.060617 22542570456896 run_lib.py:133] step: 827100, training_loss: 2.74116e-02
I0211 21:48:03.219497 22542570456896 run_lib.py:146] step: 827100, eval_loss: 2.72910e-02
I0211 21:48:20.657145 22542570456896 run_lib.py:133] step: 827150, training_loss: 3.18693e-02
I0211 21:48:38.095500 22542570456896 run_lib.py:133] step: 827200, training_loss: 2.56254e-02
I0211 21:48:38.252309 22542570456896 run_lib.py:146] step: 827200, eval_loss: 3.43468e-02
I0211 21:48:55.686703 22542570456896 run_lib.py:133] step: 827250, training_loss: 3.04392e-02
I0211 21:49:13.310880 22542570456896 run_lib.py:133] step: 827300, training_loss: 2.24386e-02
I0211 21:49:13.466172 22542570456896 run_lib.py:146] step: 827300, eval_loss: 2.86292e-02
I0211 21:49:30.902811 22542570456896 run_lib.py:133] step: 827350, training_loss: 2.98449e-02
I0211 21:49:48.414137 22542570456896 run_lib.py:133] step: 827400, training_loss: 2.89888e-02
I0211 21:49:48.571385 22542570456896 run_lib.py:146] step: 827400, eval_loss: 2.75344e-02
I0211 21:50:05.974830 22542570456896 run_lib.py:133] step: 827450, training_loss: 2.37831e-02
I0211 21:50:23.426895 22542570456896 run_lib.py:133] step: 827500, training_loss: 2.48929e-02
I0211 21:50:23.590457 22542570456896 run_lib.py:146] step: 827500, eval_loss: 2.47986e-02
I0211 21:50:41.163044 22542570456896 run_lib.py:133] step: 827550, training_loss: 2.66187e-02
I0211 21:50:58.749661 22542570456896 run_lib.py:133] step: 827600, training_loss: 2.82810e-02
I0211 21:50:58.911287 22542570456896 run_lib.py:146] step: 827600, eval_loss: 2.68200e-02
I0211 21:51:16.363987 22542570456896 run_lib.py:133] step: 827650, training_loss: 2.91759e-02
I0211 21:51:33.751787 22542570456896 run_lib.py:133] step: 827700, training_loss: 2.82764e-02
I0211 21:51:33.905664 22542570456896 run_lib.py:146] step: 827700, eval_loss: 3.53579e-02
I0211 21:51:51.466985 22542570456896 run_lib.py:133] step: 827750, training_loss: 3.23461e-02
I0211 21:52:08.915288 22542570456896 run_lib.py:133] step: 827800, training_loss: 3.12216e-02
I0211 21:52:09.075509 22542570456896 run_lib.py:146] step: 827800, eval_loss: 2.93797e-02
I0211 21:52:26.696957 22542570456896 run_lib.py:133] step: 827850, training_loss: 3.24896e-02
I0211 21:52:44.156314 22542570456896 run_lib.py:133] step: 827900, training_loss: 2.80248e-02
I0211 21:52:44.306819 22542570456896 run_lib.py:146] step: 827900, eval_loss: 2.68379e-02
I0211 21:53:01.884869 22542570456896 run_lib.py:133] step: 827950, training_loss: 3.31943e-02
I0211 21:53:19.269268 22542570456896 run_lib.py:133] step: 828000, training_loss: 2.52647e-02
I0211 21:53:19.424351 22542570456896 run_lib.py:146] step: 828000, eval_loss: 3.73153e-02
I0211 21:53:36.806303 22542570456896 run_lib.py:133] step: 828050, training_loss: 3.38612e-02
I0211 21:53:54.420143 22542570456896 run_lib.py:133] step: 828100, training_loss: 2.63556e-02
I0211 21:53:54.599729 22542570456896 run_lib.py:146] step: 828100, eval_loss: 2.28563e-02
I0211 21:54:12.094836 22542570456896 run_lib.py:133] step: 828150, training_loss: 2.87573e-02
I0211 21:54:29.663319 22542570456896 run_lib.py:133] step: 828200, training_loss: 3.17998e-02
I0211 21:54:29.819534 22542570456896 run_lib.py:146] step: 828200, eval_loss: 2.33771e-02
I0211 21:54:47.206068 22542570456896 run_lib.py:133] step: 828250, training_loss: 2.12401e-02
I0211 21:55:04.621715 22542570456896 run_lib.py:133] step: 828300, training_loss: 2.86520e-02
I0211 21:55:04.776377 22542570456896 run_lib.py:146] step: 828300, eval_loss: 2.88123e-02
I0211 21:55:22.319640 22542570456896 run_lib.py:133] step: 828350, training_loss: 2.49612e-02
I0211 21:55:39.737188 22542570456896 run_lib.py:133] step: 828400, training_loss: 2.51495e-02
I0211 21:55:39.893550 22542570456896 run_lib.py:146] step: 828400, eval_loss: 2.66857e-02
I0211 21:55:57.317097 22542570456896 run_lib.py:133] step: 828450, training_loss: 2.61267e-02
I0211 21:56:14.947411 22542570456896 run_lib.py:133] step: 828500, training_loss: 2.79289e-02
I0211 21:56:15.104586 22542570456896 run_lib.py:146] step: 828500, eval_loss: 2.20922e-02
I0211 21:56:32.538944 22542570456896 run_lib.py:133] step: 828550, training_loss: 2.32969e-02
I0211 21:56:49.901081 22542570456896 run_lib.py:133] step: 828600, training_loss: 2.58831e-02
I0211 21:56:50.057571 22542570456896 run_lib.py:146] step: 828600, eval_loss: 3.52658e-02
I0211 21:57:07.521101 22542570456896 run_lib.py:133] step: 828650, training_loss: 2.44347e-02
I0211 21:57:25.004172 22542570456896 run_lib.py:133] step: 828700, training_loss: 3.11111e-02
I0211 21:57:25.160568 22542570456896 run_lib.py:146] step: 828700, eval_loss: 2.57559e-02
I0211 21:57:42.603328 22542570456896 run_lib.py:133] step: 828750, training_loss: 3.01564e-02
I0211 21:57:59.990176 22542570456896 run_lib.py:133] step: 828800, training_loss: 2.67920e-02
I0211 21:58:00.145374 22542570456896 run_lib.py:146] step: 828800, eval_loss: 2.72386e-02
I0211 21:58:17.746196 22542570456896 run_lib.py:133] step: 828850, training_loss: 2.83231e-02
I0211 21:58:35.283673 22542570456896 run_lib.py:133] step: 828900, training_loss: 2.56353e-02
I0211 21:58:35.436477 22542570456896 run_lib.py:146] step: 828900, eval_loss: 2.83484e-02
I0211 21:58:52.844732 22542570456896 run_lib.py:133] step: 828950, training_loss: 3.68045e-02
I0211 21:59:10.298038 22542570456896 run_lib.py:133] step: 829000, training_loss: 2.51742e-02
I0211 21:59:10.457411 22542570456896 run_lib.py:146] step: 829000, eval_loss: 3.61018e-02
I0211 21:59:28.088663 22542570456896 run_lib.py:133] step: 829050, training_loss: 2.93864e-02
I0211 21:59:45.479784 22542570456896 run_lib.py:133] step: 829100, training_loss: 3.28338e-02
I0211 21:59:45.632534 22542570456896 run_lib.py:146] step: 829100, eval_loss: 2.35639e-02
I0211 22:00:03.184430 22542570456896 run_lib.py:133] step: 829150, training_loss: 2.37348e-02
I0211 22:00:20.603543 22542570456896 run_lib.py:133] step: 829200, training_loss: 2.74675e-02
I0211 22:00:20.760123 22542570456896 run_lib.py:146] step: 829200, eval_loss: 2.61062e-02
I0211 22:00:38.349403 22542570456896 run_lib.py:133] step: 829250, training_loss: 3.80166e-02
I0211 22:00:55.821866 22542570456896 run_lib.py:133] step: 829300, training_loss: 2.43922e-02
I0211 22:00:55.973270 22542570456896 run_lib.py:146] step: 829300, eval_loss: 3.18755e-02
I0211 22:01:13.531932 22542570456896 run_lib.py:133] step: 829350, training_loss: 2.40235e-02
I0211 22:01:30.909386 22542570456896 run_lib.py:133] step: 829400, training_loss: 2.87062e-02
I0211 22:01:31.066362 22542570456896 run_lib.py:146] step: 829400, eval_loss: 3.40002e-02
I0211 22:01:48.472825 22542570456896 run_lib.py:133] step: 829450, training_loss: 2.04700e-02
I0211 22:02:06.003216 22542570456896 run_lib.py:133] step: 829500, training_loss: 2.42055e-02
I0211 22:02:06.183860 22542570456896 run_lib.py:146] step: 829500, eval_loss: 2.74236e-02
I0211 22:02:23.620840 22542570456896 run_lib.py:133] step: 829550, training_loss: 3.00538e-02
I0211 22:02:41.010500 22542570456896 run_lib.py:133] step: 829600, training_loss: 3.14618e-02
I0211 22:02:41.170485 22542570456896 run_lib.py:146] step: 829600, eval_loss: 3.15422e-02
I0211 22:02:58.776661 22542570456896 run_lib.py:133] step: 829650, training_loss: 3.01115e-02
I0211 22:03:16.154714 22542570456896 run_lib.py:133] step: 829700, training_loss: 3.04637e-02
I0211 22:03:16.312317 22542570456896 run_lib.py:146] step: 829700, eval_loss: 2.32554e-02
I0211 22:03:33.828906 22542570456896 run_lib.py:133] step: 829750, training_loss: 2.76417e-02
I0211 22:03:51.323103 22542570456896 run_lib.py:133] step: 829800, training_loss: 2.82653e-02
I0211 22:03:51.476771 22542570456896 run_lib.py:146] step: 829800, eval_loss: 2.61351e-02
I0211 22:04:08.928282 22542570456896 run_lib.py:133] step: 829850, training_loss: 2.46755e-02
I0211 22:04:26.518278 22542570456896 run_lib.py:133] step: 829900, training_loss: 2.27276e-02
I0211 22:04:26.674335 22542570456896 run_lib.py:146] step: 829900, eval_loss: 3.28268e-02
I0211 22:04:44.058024 22542570456896 run_lib.py:133] step: 829950, training_loss: 2.54884e-02
I0211 22:05:01.474851 22542570456896 run_lib.py:133] step: 830000, training_loss: 2.63429e-02
I0211 22:05:02.219373 22542570456896 run_lib.py:146] step: 830000, eval_loss: 2.79042e-02
I0211 22:05:22.560412 22542570456896 run_lib.py:133] step: 830050, training_loss: 3.06723e-02
I0211 22:05:40.000433 22542570456896 run_lib.py:133] step: 830100, training_loss: 2.60520e-02
I0211 22:05:40.158424 22542570456896 run_lib.py:146] step: 830100, eval_loss: 2.61168e-02
I0211 22:05:57.726813 22542570456896 run_lib.py:133] step: 830150, training_loss: 2.82148e-02
I0211 22:06:15.113854 22542570456896 run_lib.py:133] step: 830200, training_loss: 2.64406e-02
I0211 22:06:15.269077 22542570456896 run_lib.py:146] step: 830200, eval_loss: 2.41932e-02
I0211 22:06:32.762655 22542570456896 run_lib.py:133] step: 830250, training_loss: 2.81148e-02
I0211 22:06:50.177045 22542570456896 run_lib.py:133] step: 830300, training_loss: 3.30060e-02
I0211 22:06:50.331104 22542570456896 run_lib.py:146] step: 830300, eval_loss: 3.40157e-02
I0211 22:07:07.800391 22542570456896 run_lib.py:133] step: 830350, training_loss: 3.01470e-02
I0211 22:07:25.217609 22542570456896 run_lib.py:133] step: 830400, training_loss: 3.05091e-02
I0211 22:07:25.370372 22542570456896 run_lib.py:146] step: 830400, eval_loss: 2.82378e-02
I0211 22:07:42.963054 22542570456896 run_lib.py:133] step: 830450, training_loss: 2.37599e-02
I0211 22:08:00.414738 22542570456896 run_lib.py:133] step: 830500, training_loss: 3.01604e-02
I0211 22:08:00.572646 22542570456896 run_lib.py:146] step: 830500, eval_loss: 2.25880e-02
I0211 22:08:17.995475 22542570456896 run_lib.py:133] step: 830550, training_loss: 3.35022e-02
I0211 22:08:35.404537 22542570456896 run_lib.py:133] step: 830600, training_loss: 2.62755e-02
I0211 22:08:35.574285 22542570456896 run_lib.py:146] step: 830600, eval_loss: 2.71661e-02
I0211 22:08:53.184507 22542570456896 run_lib.py:133] step: 830650, training_loss: 2.74065e-02
I0211 22:09:10.623341 22542570456896 run_lib.py:133] step: 830700, training_loss: 2.58317e-02
I0211 22:09:10.779667 22542570456896 run_lib.py:146] step: 830700, eval_loss: 2.81029e-02
I0211 22:09:28.375046 22542570456896 run_lib.py:133] step: 830750, training_loss: 3.33423e-02
I0211 22:09:45.777108 22542570456896 run_lib.py:133] step: 830800, training_loss: 3.33150e-02
I0211 22:09:45.928010 22542570456896 run_lib.py:146] step: 830800, eval_loss: 3.36545e-02
I0211 22:10:03.460153 22542570456896 run_lib.py:133] step: 830850, training_loss: 2.65385e-02
I0211 22:10:20.913846 22542570456896 run_lib.py:133] step: 830900, training_loss: 2.69765e-02
I0211 22:10:21.081495 22542570456896 run_lib.py:146] step: 830900, eval_loss: 2.58279e-02
I0211 22:10:38.713584 22542570456896 run_lib.py:133] step: 830950, training_loss: 2.58818e-02
I0211 22:10:56.156134 22542570456896 run_lib.py:133] step: 831000, training_loss: 2.98260e-02
I0211 22:10:56.313406 22542570456896 run_lib.py:146] step: 831000, eval_loss: 2.66513e-02
I0211 22:11:13.728256 22542570456896 run_lib.py:133] step: 831050, training_loss: 2.81387e-02
I0211 22:11:31.255407 22542570456896 run_lib.py:133] step: 831100, training_loss: 2.35066e-02
I0211 22:11:31.410285 22542570456896 run_lib.py:146] step: 831100, eval_loss: 3.25847e-02
I0211 22:11:48.797742 22542570456896 run_lib.py:133] step: 831150, training_loss: 2.58485e-02
I0211 22:12:06.284770 22542570456896 run_lib.py:133] step: 831200, training_loss: 3.54058e-02
I0211 22:12:06.441572 22542570456896 run_lib.py:146] step: 831200, eval_loss: 2.76199e-02
I0211 22:12:24.095344 22542570456896 run_lib.py:133] step: 831250, training_loss: 2.58148e-02
I0211 22:12:41.669347 22542570456896 run_lib.py:133] step: 831300, training_loss: 3.22532e-02
I0211 22:12:41.821256 22542570456896 run_lib.py:146] step: 831300, eval_loss: 2.46872e-02
I0211 22:12:59.217490 22542570456896 run_lib.py:133] step: 831350, training_loss: 2.81890e-02
I0211 22:13:16.593132 22542570456896 run_lib.py:133] step: 831400, training_loss: 1.98944e-02
I0211 22:13:16.748264 22542570456896 run_lib.py:146] step: 831400, eval_loss: 3.12627e-02
I0211 22:13:34.193364 22542570456896 run_lib.py:133] step: 831450, training_loss: 2.76065e-02
I0211 22:13:51.797654 22542570456896 run_lib.py:133] step: 831500, training_loss: 2.17183e-02
I0211 22:13:51.960446 22542570456896 run_lib.py:146] step: 831500, eval_loss: 2.98909e-02
I0211 22:14:09.379696 22542570456896 run_lib.py:133] step: 831550, training_loss: 2.63687e-02
I0211 22:14:26.810166 22542570456896 run_lib.py:133] step: 831600, training_loss: 3.21643e-02
I0211 22:14:26.966350 22542570456896 run_lib.py:146] step: 831600, eval_loss: 3.15462e-02
I0211 22:14:44.369925 22542570456896 run_lib.py:133] step: 831650, training_loss: 2.61781e-02
I0211 22:15:01.923696 22542570456896 run_lib.py:133] step: 831700, training_loss: 2.40827e-02
I0211 22:15:02.085560 22542570456896 run_lib.py:146] step: 831700, eval_loss: 2.72822e-02
I0211 22:15:19.556760 22542570456896 run_lib.py:133] step: 831750, training_loss: 2.19835e-02
I0211 22:15:37.123677 22542570456896 run_lib.py:133] step: 831800, training_loss: 2.53689e-02
I0211 22:15:37.276615 22542570456896 run_lib.py:146] step: 831800, eval_loss: 2.75574e-02
I0211 22:15:54.686417 22542570456896 run_lib.py:133] step: 831850, training_loss: 3.05038e-02
I0211 22:16:12.077072 22542570456896 run_lib.py:133] step: 831900, training_loss: 3.10643e-02
I0211 22:16:12.236719 22542570456896 run_lib.py:146] step: 831900, eval_loss: 3.21991e-02
I0211 22:16:29.755621 22542570456896 run_lib.py:133] step: 831950, training_loss: 2.16835e-02
I0211 22:16:47.244694 22542570456896 run_lib.py:133] step: 832000, training_loss: 2.45326e-02
I0211 22:16:47.412891 22542570456896 run_lib.py:146] step: 832000, eval_loss: 2.72331e-02
I0211 22:17:04.828531 22542570456896 run_lib.py:133] step: 832050, training_loss: 2.65360e-02
I0211 22:17:22.275392 22542570456896 run_lib.py:133] step: 832100, training_loss: 2.32538e-02
I0211 22:17:22.431189 22542570456896 run_lib.py:146] step: 832100, eval_loss: 3.00885e-02
I0211 22:17:40.022641 22542570456896 run_lib.py:133] step: 832150, training_loss: 3.13053e-02
I0211 22:17:57.420231 22542570456896 run_lib.py:133] step: 832200, training_loss: 2.69455e-02
I0211 22:17:57.572469 22542570456896 run_lib.py:146] step: 832200, eval_loss: 2.92602e-02
I0211 22:18:15.113355 22542570456896 run_lib.py:133] step: 832250, training_loss: 2.67740e-02
I0211 22:18:32.552471 22542570456896 run_lib.py:133] step: 832300, training_loss: 2.57429e-02
I0211 22:18:32.709480 22542570456896 run_lib.py:146] step: 832300, eval_loss: 2.55204e-02
I0211 22:18:50.296566 22542570456896 run_lib.py:133] step: 832350, training_loss: 2.66331e-02
I0211 22:19:07.752215 22542570456896 run_lib.py:133] step: 832400, training_loss: 2.69927e-02
I0211 22:19:07.912137 22542570456896 run_lib.py:146] step: 832400, eval_loss: 3.43942e-02
I0211 22:19:25.303275 22542570456896 run_lib.py:133] step: 832450, training_loss: 2.67688e-02
I0211 22:19:42.839456 22542570456896 run_lib.py:133] step: 832500, training_loss: 2.34839e-02
I0211 22:19:42.996581 22542570456896 run_lib.py:146] step: 832500, eval_loss: 2.99417e-02
I0211 22:20:00.457859 22542570456896 run_lib.py:133] step: 832550, training_loss: 2.23646e-02
I0211 22:20:18.066580 22542570456896 run_lib.py:133] step: 832600, training_loss: 2.29675e-02
I0211 22:20:18.222680 22542570456896 run_lib.py:146] step: 832600, eval_loss: 2.98564e-02
I0211 22:20:35.668305 22542570456896 run_lib.py:133] step: 832650, training_loss: 3.20986e-02
I0211 22:20:53.098648 22542570456896 run_lib.py:133] step: 832700, training_loss: 2.78852e-02
I0211 22:20:53.250262 22542570456896 run_lib.py:146] step: 832700, eval_loss: 2.76135e-02
I0211 22:21:10.780435 22542570456896 run_lib.py:133] step: 832750, training_loss: 2.56366e-02
I0211 22:21:28.218619 22542570456896 run_lib.py:133] step: 832800, training_loss: 2.46122e-02
I0211 22:21:28.388538 22542570456896 run_lib.py:146] step: 832800, eval_loss: 2.75705e-02
I0211 22:21:45.853726 22542570456896 run_lib.py:133] step: 832850, training_loss: 2.62747e-02
I0211 22:22:03.297512 22542570456896 run_lib.py:133] step: 832900, training_loss: 2.63093e-02
I0211 22:22:03.453186 22542570456896 run_lib.py:146] step: 832900, eval_loss: 3.27207e-02
I0211 22:22:20.688003 22542570456896 run_lib.py:133] step: 832950, training_loss: 2.56255e-02
I0211 22:22:37.907755 22542570456896 run_lib.py:133] step: 833000, training_loss: 2.62804e-02
I0211 22:22:38.061177 22542570456896 run_lib.py:146] step: 833000, eval_loss: 2.73976e-02
I0211 22:22:55.357568 22542570456896 run_lib.py:133] step: 833050, training_loss: 2.96314e-02
I0211 22:23:12.602737 22542570456896 run_lib.py:133] step: 833100, training_loss: 3.20939e-02
I0211 22:23:12.760356 22542570456896 run_lib.py:146] step: 833100, eval_loss: 3.18928e-02
I0211 22:23:30.076760 22542570456896 run_lib.py:133] step: 833150, training_loss: 3.17676e-02
I0211 22:23:47.348496 22542570456896 run_lib.py:133] step: 833200, training_loss: 2.68130e-02
I0211 22:23:47.499327 22542570456896 run_lib.py:146] step: 833200, eval_loss: 3.35834e-02
I0211 22:24:04.910999 22542570456896 run_lib.py:133] step: 833250, training_loss: 3.16182e-02
I0211 22:24:22.212824 22542570456896 run_lib.py:133] step: 833300, training_loss: 2.99114e-02
I0211 22:24:22.367239 22542570456896 run_lib.py:146] step: 833300, eval_loss: 4.21153e-02
I0211 22:24:39.591384 22542570456896 run_lib.py:133] step: 833350, training_loss: 2.89692e-02
I0211 22:24:56.833563 22542570456896 run_lib.py:133] step: 833400, training_loss: 2.77627e-02
I0211 22:24:57.006269 22542570456896 run_lib.py:146] step: 833400, eval_loss: 3.00509e-02
I0211 22:25:14.428646 22542570456896 run_lib.py:133] step: 833450, training_loss: 3.02156e-02
I0211 22:25:31.679973 22542570456896 run_lib.py:133] step: 833500, training_loss: 2.77923e-02
I0211 22:25:31.838472 22542570456896 run_lib.py:146] step: 833500, eval_loss: 2.84045e-02
I0211 22:25:49.274350 22542570456896 run_lib.py:133] step: 833550, training_loss: 2.78466e-02
I0211 22:26:06.533968 22542570456896 run_lib.py:133] step: 833600, training_loss: 2.57397e-02
I0211 22:26:06.687225 22542570456896 run_lib.py:146] step: 833600, eval_loss: 3.94715e-02
I0211 22:26:24.040855 22542570456896 run_lib.py:133] step: 833650, training_loss: 2.91141e-02
I0211 22:26:41.275115 22542570456896 run_lib.py:133] step: 833700, training_loss: 2.52574e-02
I0211 22:26:41.432440 22542570456896 run_lib.py:146] step: 833700, eval_loss: 2.65711e-02
I0211 22:26:58.972601 22542570456896 run_lib.py:133] step: 833750, training_loss: 3.02951e-02
I0211 22:27:16.216765 22542570456896 run_lib.py:133] step: 833800, training_loss: 3.15164e-02
I0211 22:27:16.373296 22542570456896 run_lib.py:146] step: 833800, eval_loss: 3.01152e-02
I0211 22:27:33.612760 22542570456896 run_lib.py:133] step: 833850, training_loss: 2.18094e-02
I0211 22:27:50.981813 22542570456896 run_lib.py:133] step: 833900, training_loss: 2.17330e-02
I0211 22:27:51.139425 22542570456896 run_lib.py:146] step: 833900, eval_loss: 3.01555e-02
I0211 22:28:08.433303 22542570456896 run_lib.py:133] step: 833950, training_loss: 2.41917e-02
I0211 22:28:25.759037 22542570456896 run_lib.py:133] step: 834000, training_loss: 3.09514e-02
I0211 22:28:25.913943 22542570456896 run_lib.py:146] step: 834000, eval_loss: 2.68454e-02
I0211 22:28:43.321258 22542570456896 run_lib.py:133] step: 834050, training_loss: 3.73350e-02
I0211 22:29:00.569492 22542570456896 run_lib.py:133] step: 834100, training_loss: 2.69800e-02
I0211 22:29:00.720993 22542570456896 run_lib.py:146] step: 834100, eval_loss: 2.51977e-02
I0211 22:29:18.141722 22542570456896 run_lib.py:133] step: 834150, training_loss: 2.79552e-02
I0211 22:29:35.389928 22542570456896 run_lib.py:133] step: 834200, training_loss: 2.67916e-02
I0211 22:29:35.546157 22542570456896 run_lib.py:146] step: 834200, eval_loss: 3.10117e-02
I0211 22:29:52.771112 22542570456896 run_lib.py:133] step: 834250, training_loss: 3.08743e-02
I0211 22:30:10.221701 22542570456896 run_lib.py:133] step: 834300, training_loss: 2.60776e-02
I0211 22:30:10.386232 22542570456896 run_lib.py:146] step: 834300, eval_loss: 3.41864e-02
I0211 22:30:27.652663 22542570456896 run_lib.py:133] step: 834350, training_loss: 2.42473e-02
I0211 22:30:44.894962 22542570456896 run_lib.py:133] step: 834400, training_loss: 2.40402e-02
I0211 22:30:45.048276 22542570456896 run_lib.py:146] step: 834400, eval_loss: 2.42909e-02
I0211 22:31:02.330537 22542570456896 run_lib.py:133] step: 834450, training_loss: 2.67115e-02
I0211 22:31:19.741904 22542570456896 run_lib.py:133] step: 834500, training_loss: 2.79570e-02
I0211 22:31:19.895416 22542570456896 run_lib.py:146] step: 834500, eval_loss: 2.93567e-02
I0211 22:31:37.169463 22542570456896 run_lib.py:133] step: 834550, training_loss: 2.99193e-02
I0211 22:31:54.511125 22542570456896 run_lib.py:133] step: 834600, training_loss: 2.20781e-02
I0211 22:31:54.663026 22542570456896 run_lib.py:146] step: 834600, eval_loss: 2.56137e-02
I0211 22:32:11.930440 22542570456896 run_lib.py:133] step: 834650, training_loss: 2.64217e-02
I0211 22:32:29.191123 22542570456896 run_lib.py:133] step: 834700, training_loss: 2.93436e-02
I0211 22:32:29.344278 22542570456896 run_lib.py:146] step: 834700, eval_loss: 2.72907e-02
I0211 22:32:46.765154 22542570456896 run_lib.py:133] step: 834750, training_loss: 3.45881e-02
I0211 22:33:04.053338 22542570456896 run_lib.py:133] step: 834800, training_loss: 2.46744e-02
I0211 22:33:04.223360 22542570456896 run_lib.py:146] step: 834800, eval_loss: 3.06562e-02
I0211 22:33:21.488033 22542570456896 run_lib.py:133] step: 834850, training_loss: 2.27576e-02
I0211 22:33:38.739296 22542570456896 run_lib.py:133] step: 834900, training_loss: 2.03124e-02
I0211 22:33:38.893464 22542570456896 run_lib.py:146] step: 834900, eval_loss: 1.95404e-02
I0211 22:33:56.319191 22542570456896 run_lib.py:133] step: 834950, training_loss: 2.21767e-02
I0211 22:34:13.536758 22542570456896 run_lib.py:133] step: 835000, training_loss: 2.38748e-02
I0211 22:34:13.690260 22542570456896 run_lib.py:146] step: 835000, eval_loss: 2.44902e-02
I0211 22:34:31.063634 22542570456896 run_lib.py:133] step: 835050, training_loss: 2.61826e-02
I0211 22:34:48.332181 22542570456896 run_lib.py:133] step: 835100, training_loss: 3.07431e-02
I0211 22:34:48.493275 22542570456896 run_lib.py:146] step: 835100, eval_loss: 3.22108e-02
I0211 22:35:06.000196 22542570456896 run_lib.py:133] step: 835150, training_loss: 4.05828e-02
I0211 22:35:23.233312 22542570456896 run_lib.py:133] step: 835200, training_loss: 2.81811e-02
I0211 22:35:23.386214 22542570456896 run_lib.py:146] step: 835200, eval_loss: 2.34783e-02
I0211 22:35:40.596699 22542570456896 run_lib.py:133] step: 835250, training_loss: 2.33792e-02
I0211 22:35:57.969064 22542570456896 run_lib.py:133] step: 835300, training_loss: 2.61923e-02
I0211 22:35:58.125402 22542570456896 run_lib.py:146] step: 835300, eval_loss: 2.82366e-02
I0211 22:36:15.407955 22542570456896 run_lib.py:133] step: 835350, training_loss: 2.20487e-02
I0211 22:36:32.867989 22542570456896 run_lib.py:133] step: 835400, training_loss: 2.12731e-02
I0211 22:36:33.021995 22542570456896 run_lib.py:146] step: 835400, eval_loss: 2.19964e-02
I0211 22:36:50.285297 22542570456896 run_lib.py:133] step: 835450, training_loss: 2.79821e-02
I0211 22:37:07.518002 22542570456896 run_lib.py:133] step: 835500, training_loss: 2.66619e-02
I0211 22:37:07.671250 22542570456896 run_lib.py:146] step: 835500, eval_loss: 2.85472e-02
I0211 22:37:25.069025 22542570456896 run_lib.py:133] step: 835550, training_loss: 3.00404e-02
I0211 22:37:42.344826 22542570456896 run_lib.py:133] step: 835600, training_loss: 2.71015e-02
I0211 22:37:42.508536 22542570456896 run_lib.py:146] step: 835600, eval_loss: 3.35093e-02
I0211 22:37:59.803306 22542570456896 run_lib.py:133] step: 835650, training_loss: 2.65186e-02
I0211 22:38:17.274837 22542570456896 run_lib.py:133] step: 835700, training_loss: 2.35903e-02
I0211 22:38:17.430222 22542570456896 run_lib.py:146] step: 835700, eval_loss: 2.77762e-02
I0211 22:38:34.690540 22542570456896 run_lib.py:133] step: 835750, training_loss: 2.43621e-02
I0211 22:38:51.910117 22542570456896 run_lib.py:133] step: 835800, training_loss: 3.16337e-02
I0211 22:38:52.219278 22542570456896 run_lib.py:146] step: 835800, eval_loss: 2.57357e-02
I0211 22:39:09.440575 22542570456896 run_lib.py:133] step: 835850, training_loss: 2.93389e-02
I0211 22:39:26.687587 22542570456896 run_lib.py:133] step: 835900, training_loss: 2.87975e-02
I0211 22:39:26.845293 22542570456896 run_lib.py:146] step: 835900, eval_loss: 3.33173e-02
I0211 22:39:44.087167 22542570456896 run_lib.py:133] step: 835950, training_loss: 2.89476e-02
I0211 22:40:01.420455 22542570456896 run_lib.py:133] step: 836000, training_loss: 3.81074e-02
I0211 22:40:01.572967 22542570456896 run_lib.py:146] step: 836000, eval_loss: 3.01861e-02
I0211 22:40:19.025248 22542570456896 run_lib.py:133] step: 836050, training_loss: 2.57783e-02
I0211 22:40:36.335954 22542570456896 run_lib.py:133] step: 836100, training_loss: 2.99818e-02
I0211 22:40:36.488286 22542570456896 run_lib.py:146] step: 836100, eval_loss: 3.72657e-02
I0211 22:40:53.725235 22542570456896 run_lib.py:133] step: 836150, training_loss: 2.12097e-02
I0211 22:41:10.989435 22542570456896 run_lib.py:133] step: 836200, training_loss: 2.47274e-02
I0211 22:41:11.169195 22542570456896 run_lib.py:146] step: 836200, eval_loss: 3.26754e-02
I0211 22:41:28.603731 22542570456896 run_lib.py:133] step: 836250, training_loss: 2.72682e-02
I0211 22:41:45.958149 22542570456896 run_lib.py:133] step: 836300, training_loss: 2.24019e-02
I0211 22:41:46.112468 22542570456896 run_lib.py:146] step: 836300, eval_loss: 2.84794e-02
I0211 22:42:03.342065 22542570456896 run_lib.py:133] step: 836350, training_loss: 1.52900e-02
I0211 22:42:20.564055 22542570456896 run_lib.py:133] step: 836400, training_loss: 2.10164e-02
I0211 22:42:20.718451 22542570456896 run_lib.py:146] step: 836400, eval_loss: 3.19172e-02
I0211 22:42:38.071226 22542570456896 run_lib.py:133] step: 836450, training_loss: 2.66200e-02
I0211 22:42:55.372616 22542570456896 run_lib.py:133] step: 836500, training_loss: 3.03239e-02
I0211 22:42:55.527497 22542570456896 run_lib.py:146] step: 836500, eval_loss: 2.66231e-02
I0211 22:43:12.948276 22542570456896 run_lib.py:133] step: 836550, training_loss: 2.47021e-02
I0211 22:43:30.223208 22542570456896 run_lib.py:133] step: 836600, training_loss: 2.09858e-02
I0211 22:43:30.377227 22542570456896 run_lib.py:146] step: 836600, eval_loss: 2.93183e-02
I0211 22:43:47.776108 22542570456896 run_lib.py:133] step: 836650, training_loss: 3.40261e-02
I0211 22:44:05.066819 22542570456896 run_lib.py:133] step: 836700, training_loss: 3.16475e-02
I0211 22:44:05.223375 22542570456896 run_lib.py:146] step: 836700, eval_loss: 3.29795e-02
I0211 22:44:22.489934 22542570456896 run_lib.py:133] step: 836750, training_loss: 3.46067e-02
I0211 22:44:39.914777 22542570456896 run_lib.py:133] step: 836800, training_loss: 2.34632e-02
I0211 22:44:40.068429 22542570456896 run_lib.py:146] step: 836800, eval_loss: 3.40527e-02
I0211 22:44:57.349022 22542570456896 run_lib.py:133] step: 836850, training_loss: 2.43188e-02
I0211 22:45:14.767450 22542570456896 run_lib.py:133] step: 836900, training_loss: 2.76228e-02
I0211 22:45:14.920213 22542570456896 run_lib.py:146] step: 836900, eval_loss: 3.45195e-02
I0211 22:45:32.129209 22542570456896 run_lib.py:133] step: 836950, training_loss: 2.09468e-02
I0211 22:45:49.333094 22542570456896 run_lib.py:133] step: 837000, training_loss: 2.82000e-02
I0211 22:45:49.484271 22542570456896 run_lib.py:146] step: 837000, eval_loss: 3.04944e-02
I0211 22:46:06.823374 22542570456896 run_lib.py:133] step: 837050, training_loss: 2.25702e-02
I0211 22:46:24.156396 22542570456896 run_lib.py:133] step: 837100, training_loss: 3.38162e-02
I0211 22:46:24.323071 22542570456896 run_lib.py:146] step: 837100, eval_loss: 2.74854e-02
I0211 22:46:41.607793 22542570456896 run_lib.py:133] step: 837150, training_loss: 3.00260e-02
I0211 22:46:58.902878 22542570456896 run_lib.py:133] step: 837200, training_loss: 3.00601e-02
I0211 22:46:59.060349 22542570456896 run_lib.py:146] step: 837200, eval_loss: 2.70352e-02
I0211 22:47:16.468887 22542570456896 run_lib.py:133] step: 837250, training_loss: 2.07281e-02
I0211 22:47:33.697663 22542570456896 run_lib.py:133] step: 837300, training_loss: 2.74941e-02
I0211 22:47:33.863356 22542570456896 run_lib.py:146] step: 837300, eval_loss: 3.28868e-02
I0211 22:47:51.182172 22542570456896 run_lib.py:133] step: 837350, training_loss: 2.89317e-02
I0211 22:48:08.445081 22542570456896 run_lib.py:133] step: 837400, training_loss: 2.41944e-02
I0211 22:48:08.597988 22542570456896 run_lib.py:146] step: 837400, eval_loss: 3.21986e-02
I0211 22:48:25.898706 22542570456896 run_lib.py:133] step: 837450, training_loss: 3.10315e-02
I0211 22:48:43.142480 22542570456896 run_lib.py:133] step: 837500, training_loss: 2.28305e-02
I0211 22:48:43.293266 22542570456896 run_lib.py:146] step: 837500, eval_loss: 3.01521e-02
I0211 22:49:00.700178 22542570456896 run_lib.py:133] step: 837550, training_loss: 2.73728e-02
I0211 22:49:17.992338 22542570456896 run_lib.py:133] step: 837600, training_loss: 2.28508e-02
I0211 22:49:18.161663 22542570456896 run_lib.py:146] step: 837600, eval_loss: 2.48003e-02
I0211 22:49:35.420047 22542570456896 run_lib.py:133] step: 837650, training_loss: 2.36704e-02
I0211 22:49:52.719369 22542570456896 run_lib.py:133] step: 837700, training_loss: 3.46410e-02
I0211 22:49:52.877462 22542570456896 run_lib.py:146] step: 837700, eval_loss: 3.24257e-02
I0211 22:50:10.274934 22542570456896 run_lib.py:133] step: 837750, training_loss: 2.47619e-02
I0211 22:50:27.476038 22542570456896 run_lib.py:133] step: 837800, training_loss: 2.61704e-02
I0211 22:50:27.631895 22542570456896 run_lib.py:146] step: 837800, eval_loss: 2.86702e-02
I0211 22:50:45.071115 22542570456896 run_lib.py:133] step: 837850, training_loss: 2.18412e-02
I0211 22:51:02.332872 22542570456896 run_lib.py:133] step: 837900, training_loss: 3.41302e-02
I0211 22:51:02.481974 22542570456896 run_lib.py:146] step: 837900, eval_loss: 2.73782e-02
I0211 22:51:19.863461 22542570456896 run_lib.py:133] step: 837950, training_loss: 2.49633e-02
I0211 22:51:37.143165 22542570456896 run_lib.py:133] step: 838000, training_loss: 2.78757e-02
I0211 22:51:37.310341 22542570456896 run_lib.py:146] step: 838000, eval_loss: 3.37262e-02
I0211 22:51:54.775368 22542570456896 run_lib.py:133] step: 838050, training_loss: 2.47360e-02
I0211 22:52:12.020411 22542570456896 run_lib.py:133] step: 838100, training_loss: 2.92706e-02
I0211 22:52:12.177457 22542570456896 run_lib.py:146] step: 838100, eval_loss: 3.38523e-02
I0211 22:52:29.394157 22542570456896 run_lib.py:133] step: 838150, training_loss: 3.06302e-02
I0211 22:52:46.737504 22542570456896 run_lib.py:133] step: 838200, training_loss: 2.61838e-02
I0211 22:52:46.899123 22542570456896 run_lib.py:146] step: 838200, eval_loss: 2.85550e-02
I0211 22:53:04.225381 22542570456896 run_lib.py:133] step: 838250, training_loss: 2.47717e-02
I0211 22:53:21.486759 22542570456896 run_lib.py:133] step: 838300, training_loss: 2.49031e-02
I0211 22:53:21.647461 22542570456896 run_lib.py:146] step: 838300, eval_loss: 2.87024e-02
I0211 22:53:39.123760 22542570456896 run_lib.py:133] step: 838350, training_loss: 3.27510e-02
I0211 22:53:56.489228 22542570456896 run_lib.py:133] step: 838400, training_loss: 2.98100e-02
I0211 22:53:56.638264 22542570456896 run_lib.py:146] step: 838400, eval_loss: 3.78093e-02
I0211 22:54:13.891825 22542570456896 run_lib.py:133] step: 838450, training_loss: 2.60917e-02
I0211 22:54:31.133484 22542570456896 run_lib.py:133] step: 838500, training_loss: 2.67869e-02
I0211 22:54:31.304463 22542570456896 run_lib.py:146] step: 838500, eval_loss: 3.27083e-02
I0211 22:54:48.647360 22542570456896 run_lib.py:133] step: 838550, training_loss: 2.09557e-02
I0211 22:55:06.112454 22542570456896 run_lib.py:133] step: 838600, training_loss: 2.94723e-02
I0211 22:55:06.268258 22542570456896 run_lib.py:146] step: 838600, eval_loss: 2.57412e-02
I0211 22:55:23.499119 22542570456896 run_lib.py:133] step: 838650, training_loss: 2.69517e-02
I0211 22:55:40.739097 22542570456896 run_lib.py:133] step: 838700, training_loss: 2.77829e-02
I0211 22:55:40.892316 22542570456896 run_lib.py:146] step: 838700, eval_loss: 2.75304e-02
I0211 22:55:58.169300 22542570456896 run_lib.py:133] step: 838750, training_loss: 2.83865e-02
I0211 22:56:15.653627 22542570456896 run_lib.py:133] step: 838800, training_loss: 2.30336e-02
I0211 22:56:15.808465 22542570456896 run_lib.py:146] step: 838800, eval_loss: 2.26076e-02
I0211 22:56:33.112281 22542570456896 run_lib.py:133] step: 838850, training_loss: 2.42877e-02
I0211 22:56:50.441795 22542570456896 run_lib.py:133] step: 838900, training_loss: 2.66110e-02
I0211 22:56:50.592201 22542570456896 run_lib.py:146] step: 838900, eval_loss: 2.84767e-02
I0211 22:57:07.801361 22542570456896 run_lib.py:133] step: 838950, training_loss: 2.75191e-02
I0211 22:57:25.058483 22542570456896 run_lib.py:133] step: 839000, training_loss: 2.42809e-02
I0211 22:57:25.212474 22542570456896 run_lib.py:146] step: 839000, eval_loss: 3.16319e-02
I0211 22:57:42.570787 22542570456896 run_lib.py:133] step: 839050, training_loss: 2.83085e-02
I0211 22:57:59.932145 22542570456896 run_lib.py:133] step: 839100, training_loss: 2.35485e-02
I0211 22:58:00.092205 22542570456896 run_lib.py:146] step: 839100, eval_loss: 2.92472e-02
I0211 22:58:17.387762 22542570456896 run_lib.py:133] step: 839150, training_loss: 3.25789e-02
I0211 22:58:34.659403 22542570456896 run_lib.py:133] step: 839200, training_loss: 2.61218e-02
I0211 22:58:34.814065 22542570456896 run_lib.py:146] step: 839200, eval_loss: 3.09420e-02
I0211 22:58:52.270705 22542570456896 run_lib.py:133] step: 839250, training_loss: 2.61546e-02
I0211 22:59:09.512703 22542570456896 run_lib.py:133] step: 839300, training_loss: 2.69875e-02
I0211 22:59:09.665262 22542570456896 run_lib.py:146] step: 839300, eval_loss: 3.23109e-02
I0211 22:59:27.073603 22542570456896 run_lib.py:133] step: 839350, training_loss: 2.59043e-02
I0211 22:59:44.372123 22542570456896 run_lib.py:133] step: 839400, training_loss: 3.04708e-02
I0211 22:59:44.525465 22542570456896 run_lib.py:146] step: 839400, eval_loss: 2.40487e-02
I0211 23:00:01.977569 22542570456896 run_lib.py:133] step: 839450, training_loss: 3.01045e-02
I0211 23:00:19.248564 22542570456896 run_lib.py:133] step: 839500, training_loss: 3.75375e-02
I0211 23:00:19.408437 22542570456896 run_lib.py:146] step: 839500, eval_loss: 2.53830e-02
I0211 23:00:36.641911 22542570456896 run_lib.py:133] step: 839550, training_loss: 2.61294e-02
I0211 23:00:54.018471 22542570456896 run_lib.py:133] step: 839600, training_loss: 3.01643e-02
I0211 23:00:54.175258 22542570456896 run_lib.py:146] step: 839600, eval_loss: 2.56076e-02
I0211 23:01:11.510847 22542570456896 run_lib.py:133] step: 839650, training_loss: 2.03175e-02
I0211 23:01:28.995645 22542570456896 run_lib.py:133] step: 839700, training_loss: 2.92073e-02
I0211 23:01:29.149079 22542570456896 run_lib.py:146] step: 839700, eval_loss: 3.20529e-02
I0211 23:01:46.444374 22542570456896 run_lib.py:133] step: 839750, training_loss: 2.64176e-02
I0211 23:02:03.724310 22542570456896 run_lib.py:133] step: 839800, training_loss: 3.01001e-02
I0211 23:02:03.874031 22542570456896 run_lib.py:146] step: 839800, eval_loss: 2.47015e-02
I0211 23:02:21.272546 22542570456896 run_lib.py:133] step: 839850, training_loss: 2.25999e-02
I0211 23:02:38.576372 22542570456896 run_lib.py:133] step: 839900, training_loss: 2.45881e-02
I0211 23:02:38.745567 22542570456896 run_lib.py:146] step: 839900, eval_loss: 3.08476e-02
I0211 23:02:56.125675 22542570456896 run_lib.py:133] step: 839950, training_loss: 3.04972e-02
I0211 23:03:13.595163 22542570456896 run_lib.py:133] step: 840000, training_loss: 2.82336e-02
I0211 23:03:14.337163 22542570456896 run_lib.py:146] step: 840000, eval_loss: 3.55616e-02
I0211 23:03:34.174376 22542570456896 run_lib.py:133] step: 840050, training_loss: 2.31356e-02
I0211 23:03:51.396414 22542570456896 run_lib.py:133] step: 840100, training_loss: 3.00542e-02
I0211 23:03:51.551440 22542570456896 run_lib.py:146] step: 840100, eval_loss: 2.82136e-02
I0211 23:04:08.757496 22542570456896 run_lib.py:133] step: 840150, training_loss: 3.47922e-02
I0211 23:04:26.232185 22542570456896 run_lib.py:133] step: 840200, training_loss: 3.10118e-02
I0211 23:04:26.389240 22542570456896 run_lib.py:146] step: 840200, eval_loss: 2.76357e-02
I0211 23:04:43.647825 22542570456896 run_lib.py:133] step: 840250, training_loss: 3.57485e-02
I0211 23:05:00.925162 22542570456896 run_lib.py:133] step: 840300, training_loss: 2.39061e-02
I0211 23:05:01.077199 22542570456896 run_lib.py:146] step: 840300, eval_loss: 2.86842e-02
I0211 23:05:18.495537 22542570456896 run_lib.py:133] step: 840350, training_loss: 1.91985e-02
I0211 23:05:35.770856 22542570456896 run_lib.py:133] step: 840400, training_loss: 2.61792e-02
I0211 23:05:35.921289 22542570456896 run_lib.py:146] step: 840400, eval_loss: 3.07401e-02
I0211 23:05:53.280945 22542570456896 run_lib.py:133] step: 840450, training_loss: 2.28900e-02
I0211 23:06:10.567905 22542570456896 run_lib.py:133] step: 840500, training_loss: 2.99178e-02
I0211 23:06:10.723181 22542570456896 run_lib.py:146] step: 840500, eval_loss: 2.89591e-02
I0211 23:06:28.005226 22542570456896 run_lib.py:133] step: 840550, training_loss: 3.42538e-02
I0211 23:06:45.228085 22542570456896 run_lib.py:133] step: 840600, training_loss: 3.43515e-02
I0211 23:06:45.382555 22542570456896 run_lib.py:146] step: 840600, eval_loss: 3.06844e-02
I0211 23:07:02.799582 22542570456896 run_lib.py:133] step: 840650, training_loss: 2.65841e-02
I0211 23:07:20.105464 22542570456896 run_lib.py:133] step: 840700, training_loss: 2.58927e-02
I0211 23:07:20.266364 22542570456896 run_lib.py:146] step: 840700, eval_loss: 2.46406e-02
I0211 23:07:37.573437 22542570456896 run_lib.py:133] step: 840750, training_loss: 2.88368e-02
I0211 23:07:54.879436 22542570456896 run_lib.py:133] step: 840800, training_loss: 2.19925e-02
I0211 23:07:55.032593 22542570456896 run_lib.py:146] step: 840800, eval_loss: 2.70269e-02
I0211 23:08:12.505315 22542570456896 run_lib.py:133] step: 840850, training_loss: 2.38437e-02
I0211 23:08:29.750414 22542570456896 run_lib.py:133] step: 840900, training_loss: 2.37456e-02
I0211 23:08:29.899213 22542570456896 run_lib.py:146] step: 840900, eval_loss: 3.57541e-02
I0211 23:08:47.267016 22542570456896 run_lib.py:133] step: 840950, training_loss: 3.30355e-02
I0211 23:09:04.603268 22542570456896 run_lib.py:133] step: 841000, training_loss: 2.50698e-02
I0211 23:09:04.781284 22542570456896 run_lib.py:146] step: 841000, eval_loss: 3.89296e-02
I0211 23:09:22.265916 22542570456896 run_lib.py:133] step: 841050, training_loss: 3.41723e-02
I0211 23:09:39.499785 22542570456896 run_lib.py:133] step: 841100, training_loss: 2.15660e-02
I0211 23:09:39.653533 22542570456896 run_lib.py:146] step: 841100, eval_loss: 3.19803e-02
I0211 23:09:57.027824 22542570456896 run_lib.py:133] step: 841150, training_loss: 2.58409e-02
I0211 23:10:14.263660 22542570456896 run_lib.py:133] step: 841200, training_loss: 2.49476e-02
I0211 23:10:14.417124 22542570456896 run_lib.py:146] step: 841200, eval_loss: 2.67155e-02
I0211 23:10:31.712312 22542570456896 run_lib.py:133] step: 841250, training_loss: 2.30493e-02
I0211 23:10:49.169367 22542570456896 run_lib.py:133] step: 841300, training_loss: 2.59141e-02
I0211 23:10:49.321511 22542570456896 run_lib.py:146] step: 841300, eval_loss: 3.17996e-02
I0211 23:11:06.647088 22542570456896 run_lib.py:133] step: 841350, training_loss: 2.61024e-02
I0211 23:11:23.906649 22542570456896 run_lib.py:133] step: 841400, training_loss: 1.98107e-02
I0211 23:11:24.060294 22542570456896 run_lib.py:146] step: 841400, eval_loss: 2.87804e-02
I0211 23:11:41.486828 22542570456896 run_lib.py:133] step: 841450, training_loss: 3.12349e-02
I0211 23:11:58.801418 22542570456896 run_lib.py:133] step: 841500, training_loss: 3.03476e-02
I0211 23:11:58.955445 22542570456896 run_lib.py:146] step: 841500, eval_loss: 2.12220e-02
I0211 23:12:16.338925 22542570456896 run_lib.py:133] step: 841550, training_loss: 3.42984e-02
I0211 23:12:33.635298 22542570456896 run_lib.py:133] step: 841600, training_loss: 2.40500e-02
I0211 23:12:33.792489 22542570456896 run_lib.py:146] step: 841600, eval_loss: 2.95614e-02
I0211 23:12:51.018504 22542570456896 run_lib.py:133] step: 841650, training_loss: 2.68807e-02
I0211 23:13:08.401299 22542570456896 run_lib.py:133] step: 841700, training_loss: 3.47756e-02
I0211 23:13:08.554201 22542570456896 run_lib.py:146] step: 841700, eval_loss: 3.82208e-02
I0211 23:13:25.810201 22542570456896 run_lib.py:133] step: 841750, training_loss: 3.11987e-02
I0211 23:13:43.143005 22542570456896 run_lib.py:133] step: 841800, training_loss: 3.18605e-02
I0211 23:13:43.294370 22542570456896 run_lib.py:146] step: 841800, eval_loss: 3.03288e-02
I0211 23:14:00.650475 22542570456896 run_lib.py:133] step: 841850, training_loss: 2.39196e-02
I0211 23:14:18.070309 22542570456896 run_lib.py:133] step: 841900, training_loss: 2.72259e-02
I0211 23:14:18.224182 22542570456896 run_lib.py:146] step: 841900, eval_loss: 2.52086e-02
I0211 23:14:35.483088 22542570456896 run_lib.py:133] step: 841950, training_loss: 2.44326e-02
I0211 23:14:52.755681 22542570456896 run_lib.py:133] step: 842000, training_loss: 3.07778e-02
I0211 23:14:52.911539 22542570456896 run_lib.py:146] step: 842000, eval_loss: 2.65533e-02
I0211 23:15:10.153245 22542570456896 run_lib.py:133] step: 842050, training_loss: 2.58750e-02
I0211 23:15:27.382779 22542570456896 run_lib.py:133] step: 842100, training_loss: 3.02554e-02
I0211 23:15:27.542325 22542570456896 run_lib.py:146] step: 842100, eval_loss: 2.96273e-02
I0211 23:15:44.978603 22542570456896 run_lib.py:133] step: 842150, training_loss: 2.79979e-02
I0211 23:16:02.348644 22542570456896 run_lib.py:133] step: 842200, training_loss: 2.38453e-02
I0211 23:16:02.502445 22542570456896 run_lib.py:146] step: 842200, eval_loss: 2.85265e-02
I0211 23:16:19.786051 22542570456896 run_lib.py:133] step: 842250, training_loss: 2.56204e-02
I0211 23:16:37.040300 22542570456896 run_lib.py:133] step: 842300, training_loss: 2.86740e-02
I0211 23:16:37.193253 22542570456896 run_lib.py:146] step: 842300, eval_loss: 3.47494e-02
I0211 23:16:54.580598 22542570456896 run_lib.py:133] step: 842350, training_loss: 2.61261e-02
I0211 23:17:11.832645 22542570456896 run_lib.py:133] step: 842400, training_loss: 2.90825e-02
I0211 23:17:12.014302 22542570456896 run_lib.py:146] step: 842400, eval_loss: 3.40115e-02
I0211 23:17:29.440691 22542570456896 run_lib.py:133] step: 842450, training_loss: 2.03471e-02
I0211 23:17:46.716776 22542570456896 run_lib.py:133] step: 842500, training_loss: 2.38899e-02
I0211 23:17:46.872351 22542570456896 run_lib.py:146] step: 842500, eval_loss: 2.63015e-02
I0211 23:18:04.304352 22542570456896 run_lib.py:133] step: 842550, training_loss: 2.66107e-02
I0211 23:18:21.583855 22542570456896 run_lib.py:133] step: 842600, training_loss: 2.58245e-02
I0211 23:18:21.737036 22542570456896 run_lib.py:146] step: 842600, eval_loss: 2.96314e-02
I0211 23:18:38.981774 22542570456896 run_lib.py:133] step: 842650, training_loss: 2.54038e-02
I0211 23:18:56.440329 22542570456896 run_lib.py:133] step: 842700, training_loss: 2.98854e-02
I0211 23:18:56.599078 22542570456896 run_lib.py:146] step: 842700, eval_loss: 2.70859e-02
I0211 23:19:13.927509 22542570456896 run_lib.py:133] step: 842750, training_loss: 3.11127e-02
I0211 23:19:31.361968 22542570456896 run_lib.py:133] step: 842800, training_loss: 2.81313e-02
I0211 23:19:31.513283 22542570456896 run_lib.py:146] step: 842800, eval_loss: 2.23941e-02
I0211 23:19:48.776721 22542570456896 run_lib.py:133] step: 842850, training_loss: 3.06533e-02
I0211 23:20:06.030024 22542570456896 run_lib.py:133] step: 842900, training_loss: 2.67536e-02
I0211 23:20:06.186537 22542570456896 run_lib.py:146] step: 842900, eval_loss: 2.67942e-02
I0211 23:20:23.642047 22542570456896 run_lib.py:133] step: 842950, training_loss: 2.79694e-02
I0211 23:20:40.904560 22542570456896 run_lib.py:133] step: 843000, training_loss: 2.84292e-02
I0211 23:20:41.069452 22542570456896 run_lib.py:146] step: 843000, eval_loss: 2.93905e-02
I0211 23:20:58.361722 22542570456896 run_lib.py:133] step: 843050, training_loss: 2.65350e-02
I0211 23:21:15.792949 22542570456896 run_lib.py:133] step: 843100, training_loss: 2.38721e-02
I0211 23:21:15.954500 22542570456896 run_lib.py:146] step: 843100, eval_loss: 2.95345e-02
I0211 23:21:33.247568 22542570456896 run_lib.py:133] step: 843150, training_loss: 2.35706e-02
I0211 23:21:50.487702 22542570456896 run_lib.py:133] step: 843200, training_loss: 3.10686e-02
I0211 23:21:50.781041 22542570456896 run_lib.py:146] step: 843200, eval_loss: 3.00762e-02
I0211 23:22:08.041469 22542570456896 run_lib.py:133] step: 843250, training_loss: 2.48982e-02
I0211 23:22:25.327683 22542570456896 run_lib.py:133] step: 843300, training_loss: 2.91280e-02
I0211 23:22:25.493524 22542570456896 run_lib.py:146] step: 843300, eval_loss: 3.59004e-02
I0211 23:22:42.846135 22542570456896 run_lib.py:133] step: 843350, training_loss: 2.76867e-02
I0211 23:23:00.164364 22542570456896 run_lib.py:133] step: 843400, training_loss: 2.29593e-02
I0211 23:23:00.333325 22542570456896 run_lib.py:146] step: 843400, eval_loss: 3.01348e-02
I0211 23:23:17.817784 22542570456896 run_lib.py:133] step: 843450, training_loss: 2.37864e-02
I0211 23:23:35.261518 22542570456896 run_lib.py:133] step: 843500, training_loss: 2.66343e-02
I0211 23:23:35.421674 22542570456896 run_lib.py:146] step: 843500, eval_loss: 3.02715e-02
I0211 23:23:52.849371 22542570456896 run_lib.py:133] step: 843550, training_loss: 2.51379e-02
I0211 23:24:10.323197 22542570456896 run_lib.py:133] step: 843600, training_loss: 2.66788e-02
I0211 23:24:10.479681 22542570456896 run_lib.py:146] step: 843600, eval_loss: 3.56736e-02
I0211 23:24:28.120475 22542570456896 run_lib.py:133] step: 843650, training_loss: 2.53658e-02
I0211 23:24:45.588210 22542570456896 run_lib.py:133] step: 843700, training_loss: 2.77098e-02
I0211 23:24:45.741548 22542570456896 run_lib.py:146] step: 843700, eval_loss: 2.95662e-02
I0211 23:25:03.158572 22542570456896 run_lib.py:133] step: 843750, training_loss: 2.54794e-02
I0211 23:25:20.616690 22542570456896 run_lib.py:133] step: 843800, training_loss: 2.23111e-02
I0211 23:25:20.770538 22542570456896 run_lib.py:146] step: 843800, eval_loss: 3.32941e-02
I0211 23:25:38.385370 22542570456896 run_lib.py:133] step: 843850, training_loss: 2.95191e-02
I0211 23:25:55.867855 22542570456896 run_lib.py:133] step: 843900, training_loss: 3.07333e-02
I0211 23:25:56.027193 22542570456896 run_lib.py:146] step: 843900, eval_loss: 2.69506e-02
I0211 23:26:13.620488 22542570456896 run_lib.py:133] step: 843950, training_loss: 3.15015e-02
I0211 23:26:31.005527 22542570456896 run_lib.py:133] step: 844000, training_loss: 2.83111e-02
I0211 23:26:31.161427 22542570456896 run_lib.py:146] step: 844000, eval_loss: 2.53188e-02
I0211 23:26:48.762817 22542570456896 run_lib.py:133] step: 844050, training_loss: 3.01373e-02
I0211 23:27:06.225151 22542570456896 run_lib.py:133] step: 844100, training_loss: 2.52776e-02
I0211 23:27:06.388511 22542570456896 run_lib.py:146] step: 844100, eval_loss: 2.78259e-02
I0211 23:27:23.911088 22542570456896 run_lib.py:133] step: 844150, training_loss: 2.32738e-02
I0211 23:27:41.637218 22542570456896 run_lib.py:133] step: 844200, training_loss: 2.71443e-02
I0211 23:27:41.794865 22542570456896 run_lib.py:146] step: 844200, eval_loss: 3.04360e-02
I0211 23:27:59.344843 22542570456896 run_lib.py:133] step: 844250, training_loss: 2.88677e-02
I0211 23:28:17.063380 22542570456896 run_lib.py:133] step: 844300, training_loss: 2.52774e-02
I0211 23:28:17.225036 22542570456896 run_lib.py:146] step: 844300, eval_loss: 3.10650e-02
I0211 23:28:34.727831 22542570456896 run_lib.py:133] step: 844350, training_loss: 3.75651e-02
I0211 23:28:52.249180 22542570456896 run_lib.py:133] step: 844400, training_loss: 3.13087e-02
I0211 23:28:52.407509 22542570456896 run_lib.py:146] step: 844400, eval_loss: 3.09577e-02
I0211 23:29:10.092436 22542570456896 run_lib.py:133] step: 844450, training_loss: 2.58612e-02
I0211 23:29:27.694171 22542570456896 run_lib.py:133] step: 844500, training_loss: 3.26343e-02
I0211 23:29:27.849967 22542570456896 run_lib.py:146] step: 844500, eval_loss: 3.65446e-02
I0211 23:29:45.365441 22542570456896 run_lib.py:133] step: 844550, training_loss: 2.41749e-02
I0211 23:30:02.841983 22542570456896 run_lib.py:133] step: 844600, training_loss: 3.13881e-02
I0211 23:30:02.997236 22542570456896 run_lib.py:146] step: 844600, eval_loss: 2.43471e-02
I0211 23:30:20.690483 22542570456896 run_lib.py:133] step: 844650, training_loss: 2.56719e-02
I0211 23:30:38.220811 22542570456896 run_lib.py:133] step: 844700, training_loss: 2.34935e-02
I0211 23:30:38.380767 22542570456896 run_lib.py:146] step: 844700, eval_loss: 3.20334e-02
I0211 23:30:56.032339 22542570456896 run_lib.py:133] step: 844750, training_loss: 2.82489e-02
I0211 23:31:13.589859 22542570456896 run_lib.py:133] step: 844800, training_loss: 2.34688e-02
I0211 23:31:13.750263 22542570456896 run_lib.py:146] step: 844800, eval_loss: 3.27617e-02
I0211 23:31:31.282067 22542570456896 run_lib.py:133] step: 844850, training_loss: 2.50989e-02
I0211 23:31:48.778373 22542570456896 run_lib.py:133] step: 844900, training_loss: 2.53571e-02
I0211 23:31:48.936520 22542570456896 run_lib.py:146] step: 844900, eval_loss: 2.81657e-02
I0211 23:32:06.574890 22542570456896 run_lib.py:133] step: 844950, training_loss: 2.39065e-02
I0211 23:32:24.181220 22542570456896 run_lib.py:133] step: 845000, training_loss: 2.35179e-02
I0211 23:32:24.340340 22542570456896 run_lib.py:146] step: 845000, eval_loss: 2.53695e-02
I0211 23:32:41.875554 22542570456896 run_lib.py:133] step: 845050, training_loss: 2.93674e-02
I0211 23:32:59.384546 22542570456896 run_lib.py:133] step: 845100, training_loss: 2.73629e-02
I0211 23:32:59.537503 22542570456896 run_lib.py:146] step: 845100, eval_loss: 3.04452e-02
I0211 23:33:17.244753 22542570456896 run_lib.py:133] step: 845150, training_loss: 3.00785e-02
I0211 23:33:34.749151 22542570456896 run_lib.py:133] step: 845200, training_loss: 2.28496e-02
I0211 23:33:34.911503 22542570456896 run_lib.py:146] step: 845200, eval_loss: 2.81512e-02
I0211 23:33:52.528911 22542570456896 run_lib.py:133] step: 845250, training_loss: 2.21154e-02
I0211 23:34:10.039572 22542570456896 run_lib.py:133] step: 845300, training_loss: 2.29215e-02
I0211 23:34:10.217509 22542570456896 run_lib.py:146] step: 845300, eval_loss: 2.61184e-02
I0211 23:34:27.955596 22542570456896 run_lib.py:133] step: 845350, training_loss: 3.51514e-02
I0211 23:34:45.475317 22542570456896 run_lib.py:133] step: 845400, training_loss: 3.51229e-02
I0211 23:34:45.633684 22542570456896 run_lib.py:146] step: 845400, eval_loss: 2.92665e-02
I0211 23:35:03.315979 22542570456896 run_lib.py:133] step: 845450, training_loss: 2.60503e-02
I0211 23:35:20.798714 22542570456896 run_lib.py:133] step: 845500, training_loss: 3.08769e-02
I0211 23:35:20.955578 22542570456896 run_lib.py:146] step: 845500, eval_loss: 3.25603e-02
I0211 23:35:38.476144 22542570456896 run_lib.py:133] step: 845550, training_loss: 3.05830e-02
I0211 23:35:56.179527 22542570456896 run_lib.py:133] step: 845600, training_loss: 3.03001e-02
I0211 23:35:56.341690 22542570456896 run_lib.py:146] step: 845600, eval_loss: 2.56720e-02
I0211 23:36:13.884718 22542570456896 run_lib.py:133] step: 845650, training_loss: 2.81132e-02
I0211 23:36:31.411196 22542570456896 run_lib.py:133] step: 845700, training_loss: 3.03093e-02
I0211 23:36:31.569522 22542570456896 run_lib.py:146] step: 845700, eval_loss: 3.42118e-02
I0211 23:36:49.221512 22542570456896 run_lib.py:133] step: 845750, training_loss: 2.82289e-02
I0211 23:37:06.868379 22542570456896 run_lib.py:133] step: 845800, training_loss: 1.95548e-02
I0211 23:37:07.029773 22542570456896 run_lib.py:146] step: 845800, eval_loss: 2.66236e-02
I0211 23:37:24.569197 22542570456896 run_lib.py:133] step: 845850, training_loss: 2.48020e-02
I0211 23:37:42.115936 22542570456896 run_lib.py:133] step: 845900, training_loss: 2.56387e-02
I0211 23:37:42.272245 22542570456896 run_lib.py:146] step: 845900, eval_loss: 3.06591e-02
I0211 23:37:59.772827 22542570456896 run_lib.py:133] step: 845950, training_loss: 2.57545e-02
I0211 23:38:17.447145 22542570456896 run_lib.py:133] step: 846000, training_loss: 2.33200e-02
I0211 23:38:17.604527 22542570456896 run_lib.py:146] step: 846000, eval_loss: 2.76172e-02
I0211 23:38:35.122948 22542570456896 run_lib.py:133] step: 846050, training_loss: 2.75782e-02
I0211 23:38:52.672800 22542570456896 run_lib.py:133] step: 846100, training_loss: 3.28376e-02
I0211 23:38:52.827789 22542570456896 run_lib.py:146] step: 846100, eval_loss: 2.73168e-02
I0211 23:39:10.376992 22542570456896 run_lib.py:133] step: 846150, training_loss: 2.59058e-02
I0211 23:39:28.073113 22542570456896 run_lib.py:133] step: 846200, training_loss: 2.75614e-02
I0211 23:39:28.233567 22542570456896 run_lib.py:146] step: 846200, eval_loss: 3.27161e-02
I0211 23:39:45.757207 22542570456896 run_lib.py:133] step: 846250, training_loss: 1.92471e-02
I0211 23:40:03.310548 22542570456896 run_lib.py:133] step: 846300, training_loss: 2.91485e-02
I0211 23:40:03.467750 22542570456896 run_lib.py:146] step: 846300, eval_loss: 2.99819e-02
I0211 23:40:20.940918 22542570456896 run_lib.py:133] step: 846350, training_loss: 2.83760e-02
I0211 23:40:38.467675 22542570456896 run_lib.py:133] step: 846400, training_loss: 2.29755e-02
I0211 23:40:38.627570 22542570456896 run_lib.py:146] step: 846400, eval_loss: 3.24888e-02
I0211 23:40:56.320908 22542570456896 run_lib.py:133] step: 846450, training_loss: 2.37843e-02
I0211 23:41:13.924289 22542570456896 run_lib.py:133] step: 846500, training_loss: 2.73561e-02
I0211 23:41:14.078227 22542570456896 run_lib.py:146] step: 846500, eval_loss: 3.31723e-02
I0211 23:41:31.579818 22542570456896 run_lib.py:133] step: 846550, training_loss: 2.96361e-02
I0211 23:41:49.074196 22542570456896 run_lib.py:133] step: 846600, training_loss: 3.00075e-02
I0211 23:41:49.237477 22542570456896 run_lib.py:146] step: 846600, eval_loss: 2.91407e-02
I0211 23:42:06.881124 22542570456896 run_lib.py:133] step: 846650, training_loss: 3.24299e-02
I0211 23:42:24.387412 22542570456896 run_lib.py:133] step: 846700, training_loss: 2.70438e-02
I0211 23:42:24.566516 22542570456896 run_lib.py:146] step: 846700, eval_loss: 2.62907e-02
I0211 23:42:42.303316 22542570456896 run_lib.py:133] step: 846750, training_loss: 2.26217e-02
I0211 23:42:59.807203 22542570456896 run_lib.py:133] step: 846800, training_loss: 3.18745e-02
I0211 23:42:59.972700 22542570456896 run_lib.py:146] step: 846800, eval_loss: 2.49257e-02
I0211 23:43:17.646964 22542570456896 run_lib.py:133] step: 846850, training_loss: 2.76903e-02
I0211 23:43:35.134425 22542570456896 run_lib.py:133] step: 846900, training_loss: 2.92219e-02
I0211 23:43:35.293735 22542570456896 run_lib.py:146] step: 846900, eval_loss: 2.31027e-02
I0211 23:43:52.765850 22542570456896 run_lib.py:133] step: 846950, training_loss: 2.98224e-02
I0211 23:44:10.495883 22542570456896 run_lib.py:133] step: 847000, training_loss: 2.90474e-02
I0211 23:44:10.652254 22542570456896 run_lib.py:146] step: 847000, eval_loss: 3.69721e-02
I0211 23:44:28.193805 22542570456896 run_lib.py:133] step: 847050, training_loss: 2.53969e-02
I0211 23:44:45.882327 22542570456896 run_lib.py:133] step: 847100, training_loss: 2.74487e-02
I0211 23:44:46.040469 22542570456896 run_lib.py:146] step: 847100, eval_loss: 2.18700e-02
I0211 23:45:03.489643 22542570456896 run_lib.py:133] step: 847150, training_loss: 1.88735e-02
I0211 23:45:21.005100 22542570456896 run_lib.py:133] step: 847200, training_loss: 2.51748e-02
I0211 23:45:21.176738 22542570456896 run_lib.py:146] step: 847200, eval_loss: 3.55651e-02
I0211 23:45:38.898592 22542570456896 run_lib.py:133] step: 847250, training_loss: 2.53209e-02
I0211 23:45:56.421679 22542570456896 run_lib.py:133] step: 847300, training_loss: 3.15492e-02
I0211 23:45:56.591642 22542570456896 run_lib.py:146] step: 847300, eval_loss: 2.23886e-02
I0211 23:46:14.135540 22542570456896 run_lib.py:133] step: 847350, training_loss: 2.55352e-02
I0211 23:46:31.838818 22542570456896 run_lib.py:133] step: 847400, training_loss: 2.37782e-02
I0211 23:46:31.996250 22542570456896 run_lib.py:146] step: 847400, eval_loss: 3.41914e-02
I0211 23:46:49.492362 22542570456896 run_lib.py:133] step: 847450, training_loss: 1.98509e-02
I0211 23:47:06.983081 22542570456896 run_lib.py:133] step: 847500, training_loss: 3.25743e-02
I0211 23:47:07.138695 22542570456896 run_lib.py:146] step: 847500, eval_loss: 3.71854e-02
I0211 23:47:24.757701 22542570456896 run_lib.py:133] step: 847550, training_loss: 2.99715e-02
I0211 23:47:42.252237 22542570456896 run_lib.py:133] step: 847600, training_loss: 2.76884e-02
I0211 23:47:42.408758 22542570456896 run_lib.py:146] step: 847600, eval_loss: 2.63103e-02
I0211 23:47:59.870817 22542570456896 run_lib.py:133] step: 847650, training_loss: 2.33166e-02
I0211 23:48:17.349905 22542570456896 run_lib.py:133] step: 847700, training_loss: 2.03153e-02
I0211 23:48:17.510714 22542570456896 run_lib.py:146] step: 847700, eval_loss: 2.91098e-02
I0211 23:48:35.157921 22542570456896 run_lib.py:133] step: 847750, training_loss: 3.08514e-02
I0211 23:48:52.749032 22542570456896 run_lib.py:133] step: 847800, training_loss: 2.40509e-02
I0211 23:48:52.913153 22542570456896 run_lib.py:146] step: 847800, eval_loss: 2.81553e-02
I0211 23:49:10.466673 22542570456896 run_lib.py:133] step: 847850, training_loss: 2.78189e-02
I0211 23:49:27.979123 22542570456896 run_lib.py:133] step: 847900, training_loss: 2.53214e-02
I0211 23:49:28.137794 22542570456896 run_lib.py:146] step: 847900, eval_loss: 2.86196e-02
I0211 23:49:45.834353 22542570456896 run_lib.py:133] step: 847950, training_loss: 2.15091e-02
I0211 23:50:03.311007 22542570456896 run_lib.py:133] step: 848000, training_loss: 3.50900e-02
I0211 23:50:03.463599 22542570456896 run_lib.py:146] step: 848000, eval_loss: 3.21766e-02
I0211 23:50:21.090884 22542570456896 run_lib.py:133] step: 848050, training_loss: 2.28605e-02
I0211 23:50:38.522041 22542570456896 run_lib.py:133] step: 848100, training_loss: 3.10160e-02
I0211 23:50:38.701412 22542570456896 run_lib.py:146] step: 848100, eval_loss: 3.47757e-02
I0211 23:50:56.370748 22542570456896 run_lib.py:133] step: 848150, training_loss: 3.12838e-02
I0211 23:51:13.861890 22542570456896 run_lib.py:133] step: 848200, training_loss: 2.72268e-02
I0211 23:51:14.020143 22542570456896 run_lib.py:146] step: 848200, eval_loss: 3.32070e-02
I0211 23:51:31.596470 22542570456896 run_lib.py:133] step: 848250, training_loss: 1.90166e-02
I0211 23:51:48.985105 22542570456896 run_lib.py:133] step: 848300, training_loss: 2.71518e-02
I0211 23:51:49.141504 22542570456896 run_lib.py:146] step: 848300, eval_loss: 3.48689e-02
I0211 23:52:06.534451 22542570456896 run_lib.py:133] step: 848350, training_loss: 2.40276e-02
I0211 23:52:24.240044 22542570456896 run_lib.py:133] step: 848400, training_loss: 3.21439e-02
I0211 23:52:24.390800 22542570456896 run_lib.py:146] step: 848400, eval_loss: 3.05928e-02
I0211 23:52:41.908394 22542570456896 run_lib.py:133] step: 848450, training_loss: 2.73709e-02
I0211 23:52:59.408880 22542570456896 run_lib.py:133] step: 848500, training_loss: 2.34668e-02
I0211 23:52:59.565604 22542570456896 run_lib.py:146] step: 848500, eval_loss: 2.89916e-02
I0211 23:53:17.267314 22542570456896 run_lib.py:133] step: 848550, training_loss: 2.67761e-02
I0211 23:53:34.779373 22542570456896 run_lib.py:133] step: 848600, training_loss: 2.76826e-02
I0211 23:53:34.959573 22542570456896 run_lib.py:146] step: 848600, eval_loss: 2.46247e-02
I0211 23:53:52.648087 22542570456896 run_lib.py:133] step: 848650, training_loss: 2.55165e-02
I0211 23:54:10.165836 22542570456896 run_lib.py:133] step: 848700, training_loss: 3.20236e-02
I0211 23:54:10.323686 22542570456896 run_lib.py:146] step: 848700, eval_loss: 2.97853e-02
I0211 23:54:27.823258 22542570456896 run_lib.py:133] step: 848750, training_loss: 2.61094e-02
I0211 23:54:45.512235 22542570456896 run_lib.py:133] step: 848800, training_loss: 2.86853e-02
I0211 23:54:45.670655 22542570456896 run_lib.py:146] step: 848800, eval_loss: 2.92091e-02
I0211 23:55:03.172988 22542570456896 run_lib.py:133] step: 848850, training_loss: 2.91942e-02
I0211 23:55:20.711880 22542570456896 run_lib.py:133] step: 848900, training_loss: 2.61852e-02
I0211 23:55:20.867868 22542570456896 run_lib.py:146] step: 848900, eval_loss: 2.85104e-02
I0211 23:55:38.402794 22542570456896 run_lib.py:133] step: 848950, training_loss: 3.13378e-02
I0211 23:55:56.126995 22542570456896 run_lib.py:133] step: 849000, training_loss: 2.87086e-02
I0211 23:55:56.284730 22542570456896 run_lib.py:146] step: 849000, eval_loss: 2.42722e-02
I0211 23:56:13.778219 22542570456896 run_lib.py:133] step: 849050, training_loss: 2.75178e-02
I0211 23:56:31.363641 22542570456896 run_lib.py:133] step: 849100, training_loss: 2.25411e-02
I0211 23:56:31.524887 22542570456896 run_lib.py:146] step: 849100, eval_loss: 3.16596e-02
I0211 23:56:49.032605 22542570456896 run_lib.py:133] step: 849150, training_loss: 3.12076e-02
I0211 23:57:06.604033 22542570456896 run_lib.py:133] step: 849200, training_loss: 3.34977e-02
I0211 23:57:06.769718 22542570456896 run_lib.py:146] step: 849200, eval_loss: 2.48991e-02
I0211 23:57:24.464454 22542570456896 run_lib.py:133] step: 849250, training_loss: 3.23840e-02
I0211 23:57:42.067708 22542570456896 run_lib.py:133] step: 849300, training_loss: 2.15179e-02
I0211 23:57:42.224499 22542570456896 run_lib.py:146] step: 849300, eval_loss: 3.46382e-02
I0211 23:57:59.711114 22542570456896 run_lib.py:133] step: 849350, training_loss: 2.82193e-02
I0211 23:58:17.213594 22542570456896 run_lib.py:133] step: 849400, training_loss: 2.97541e-02
I0211 23:58:17.366475 22542570456896 run_lib.py:146] step: 849400, eval_loss: 3.12784e-02
I0211 23:58:35.011838 22542570456896 run_lib.py:133] step: 849450, training_loss: 2.58081e-02
I0211 23:58:52.541788 22542570456896 run_lib.py:133] step: 849500, training_loss: 2.74090e-02
I0211 23:58:52.719329 22542570456896 run_lib.py:146] step: 849500, eval_loss: 3.16049e-02
I0211 23:59:10.471823 22542570456896 run_lib.py:133] step: 849550, training_loss: 2.76441e-02
I0211 23:59:28.022279 22542570456896 run_lib.py:133] step: 849600, training_loss: 2.96882e-02
I0211 23:59:28.182735 22542570456896 run_lib.py:146] step: 849600, eval_loss: 2.57630e-02
I0211 23:59:45.832578 22542570456896 run_lib.py:133] step: 849650, training_loss: 2.39208e-02
I0212 00:00:03.361080 22542570456896 run_lib.py:133] step: 849700, training_loss: 2.58788e-02
I0212 00:00:03.518693 22542570456896 run_lib.py:146] step: 849700, eval_loss: 2.97996e-02
I0212 00:00:21.022092 22542570456896 run_lib.py:133] step: 849750, training_loss: 2.75349e-02
I0212 00:00:38.727910 22542570456896 run_lib.py:133] step: 849800, training_loss: 2.78403e-02
I0212 00:00:38.886734 22542570456896 run_lib.py:146] step: 849800, eval_loss: 2.56481e-02
I0212 00:00:56.418198 22542570456896 run_lib.py:133] step: 849850, training_loss: 1.98204e-02
I0212 00:01:14.123044 22542570456896 run_lib.py:133] step: 849900, training_loss: 2.92619e-02
I0212 00:01:14.277559 22542570456896 run_lib.py:146] step: 849900, eval_loss: 3.44992e-02
I0212 00:01:31.763504 22542570456896 run_lib.py:133] step: 849950, training_loss: 2.37946e-02
I0212 00:01:49.280847 22542570456896 run_lib.py:133] step: 850000, training_loss: 2.95587e-02
I0212 00:01:50.084598 22542570456896 run_lib.py:146] step: 850000, eval_loss: 2.88268e-02
I0212 00:02:10.484028 22542570456896 run_lib.py:133] step: 850050, training_loss: 2.68014e-02
I0212 00:02:28.002403 22542570456896 run_lib.py:133] step: 850100, training_loss: 3.11988e-02
I0212 00:02:28.163452 22542570456896 run_lib.py:146] step: 850100, eval_loss: 2.41885e-02
I0212 00:02:45.858137 22542570456896 run_lib.py:133] step: 850150, training_loss: 3.21377e-02
I0212 00:03:03.421585 22542570456896 run_lib.py:133] step: 850200, training_loss: 3.60363e-02
I0212 00:03:03.578503 22542570456896 run_lib.py:146] step: 850200, eval_loss: 2.87510e-02
I0212 00:03:21.082387 22542570456896 run_lib.py:133] step: 850250, training_loss: 2.42911e-02
I0212 00:03:38.729430 22542570456896 run_lib.py:133] step: 850300, training_loss: 2.81294e-02
I0212 00:03:38.899502 22542570456896 run_lib.py:146] step: 850300, eval_loss: 3.11846e-02
I0212 00:03:56.447363 22542570456896 run_lib.py:133] step: 850350, training_loss: 2.93817e-02
I0212 00:04:14.196054 22542570456896 run_lib.py:133] step: 850400, training_loss: 3.54601e-02
I0212 00:04:14.349728 22542570456896 run_lib.py:146] step: 850400, eval_loss: 3.10633e-02
I0212 00:04:31.842974 22542570456896 run_lib.py:133] step: 850450, training_loss: 3.25927e-02
I0212 00:04:49.345149 22542570456896 run_lib.py:133] step: 850500, training_loss: 2.42253e-02
I0212 00:04:49.502500 22542570456896 run_lib.py:146] step: 850500, eval_loss: 2.53980e-02
I0212 00:05:06.989456 22542570456896 run_lib.py:133] step: 850550, training_loss: 3.33159e-02
I0212 00:05:24.658479 22542570456896 run_lib.py:133] step: 850600, training_loss: 2.74975e-02
I0212 00:05:24.839619 22542570456896 run_lib.py:146] step: 850600, eval_loss: 3.06605e-02
I0212 00:05:42.404488 22542570456896 run_lib.py:133] step: 850650, training_loss: 2.44629e-02
I0212 00:05:59.926912 22542570456896 run_lib.py:133] step: 850700, training_loss: 2.80914e-02
I0212 00:06:00.089707 22542570456896 run_lib.py:146] step: 850700, eval_loss: 3.19553e-02
I0212 00:06:17.828310 22542570456896 run_lib.py:133] step: 850750, training_loss: 3.24177e-02
I0212 00:06:35.314411 22542570456896 run_lib.py:133] step: 850800, training_loss: 2.65829e-02
I0212 00:06:35.472824 22542570456896 run_lib.py:146] step: 850800, eval_loss: 3.14046e-02
I0212 00:06:53.029536 22542570456896 run_lib.py:133] step: 850850, training_loss: 2.92538e-02
I0212 00:07:10.583883 22542570456896 run_lib.py:133] step: 850900, training_loss: 2.80306e-02
I0212 00:07:10.739728 22542570456896 run_lib.py:146] step: 850900, eval_loss: 2.88381e-02
I0212 00:07:28.304270 22542570456896 run_lib.py:133] step: 850950, training_loss: 2.79205e-02
I0212 00:07:45.819234 22542570456896 run_lib.py:133] step: 851000, training_loss: 2.61966e-02
I0212 00:07:45.978692 22542570456896 run_lib.py:146] step: 851000, eval_loss: 3.49264e-02
I0212 00:08:03.646507 22542570456896 run_lib.py:133] step: 851050, training_loss: 2.59502e-02
I0212 00:08:21.252701 22542570456896 run_lib.py:133] step: 851100, training_loss: 2.91196e-02
I0212 00:08:21.412725 22542570456896 run_lib.py:146] step: 851100, eval_loss: 3.41848e-02
I0212 00:08:38.931789 22542570456896 run_lib.py:133] step: 851150, training_loss: 3.04821e-02
I0212 00:08:56.487805 22542570456896 run_lib.py:133] step: 851200, training_loss: 2.44352e-02
I0212 00:08:56.650265 22542570456896 run_lib.py:146] step: 851200, eval_loss: 2.78888e-02
I0212 00:09:14.350431 22542570456896 run_lib.py:133] step: 851250, training_loss: 2.27106e-02
I0212 00:09:31.851462 22542570456896 run_lib.py:133] step: 851300, training_loss: 2.30226e-02
I0212 00:09:32.007586 22542570456896 run_lib.py:146] step: 851300, eval_loss: 3.29503e-02
I0212 00:09:49.656218 22542570456896 run_lib.py:133] step: 851350, training_loss: 2.75546e-02
I0212 00:10:07.139760 22542570456896 run_lib.py:133] step: 851400, training_loss: 3.00311e-02
I0212 00:10:07.293447 22542570456896 run_lib.py:146] step: 851400, eval_loss: 2.51934e-02
I0212 00:10:24.936754 22542570456896 run_lib.py:133] step: 851450, training_loss: 2.39380e-02
I0212 00:10:42.435723 22542570456896 run_lib.py:133] step: 851500, training_loss: 2.46763e-02
I0212 00:10:42.601409 22542570456896 run_lib.py:146] step: 851500, eval_loss: 2.59511e-02
I0212 00:11:00.300989 22542570456896 run_lib.py:133] step: 851550, training_loss: 3.15924e-02
I0212 00:11:17.783333 22542570456896 run_lib.py:133] step: 851600, training_loss: 2.17316e-02
I0212 00:11:17.940572 22542570456896 run_lib.py:146] step: 851600, eval_loss: 2.74317e-02
I0212 00:11:35.431355 22542570456896 run_lib.py:133] step: 851650, training_loss: 2.31497e-02
I0212 00:11:53.064812 22542570456896 run_lib.py:133] step: 851700, training_loss: 2.67750e-02
I0212 00:11:53.234282 22542570456896 run_lib.py:146] step: 851700, eval_loss: 2.67213e-02
I0212 00:12:10.733689 22542570456896 run_lib.py:133] step: 851750, training_loss: 2.79970e-02
I0212 00:12:28.264842 22542570456896 run_lib.py:133] step: 851800, training_loss: 2.68858e-02
I0212 00:12:28.419354 22542570456896 run_lib.py:146] step: 851800, eval_loss: 3.59809e-02
I0212 00:12:46.124580 22542570456896 run_lib.py:133] step: 851850, training_loss: 2.62256e-02
I0212 00:13:03.579395 22542570456896 run_lib.py:133] step: 851900, training_loss: 2.15184e-02
I0212 00:13:03.735511 22542570456896 run_lib.py:146] step: 851900, eval_loss: 4.23505e-02
I0212 00:13:21.306809 22542570456896 run_lib.py:133] step: 851950, training_loss: 3.90137e-02
I0212 00:13:38.718255 22542570456896 run_lib.py:133] step: 852000, training_loss: 2.82356e-02
I0212 00:13:38.882646 22542570456896 run_lib.py:146] step: 852000, eval_loss: 3.12599e-02
I0212 00:13:56.358172 22542570456896 run_lib.py:133] step: 852050, training_loss: 2.94085e-02
I0212 00:14:13.976615 22542570456896 run_lib.py:133] step: 852100, training_loss: 2.49898e-02
I0212 00:14:14.133642 22542570456896 run_lib.py:146] step: 852100, eval_loss: 2.79314e-02
I0212 00:14:31.548997 22542570456896 run_lib.py:133] step: 852150, training_loss: 2.11206e-02
I0212 00:14:48.982852 22542570456896 run_lib.py:133] step: 852200, training_loss: 2.56923e-02
I0212 00:14:49.139455 22542570456896 run_lib.py:146] step: 852200, eval_loss: 2.92385e-02
I0212 00:15:06.575092 22542570456896 run_lib.py:133] step: 852250, training_loss: 2.55885e-02
I0212 00:15:24.232259 22542570456896 run_lib.py:133] step: 852300, training_loss: 3.04730e-02
I0212 00:15:24.386739 22542570456896 run_lib.py:146] step: 852300, eval_loss: 3.48414e-02
I0212 00:15:41.933668 22542570456896 run_lib.py:133] step: 852350, training_loss: 2.98247e-02
I0212 00:15:59.537171 22542570456896 run_lib.py:133] step: 852400, training_loss: 2.41489e-02
I0212 00:15:59.694748 22542570456896 run_lib.py:146] step: 852400, eval_loss: 2.58972e-02
I0212 00:16:17.176344 22542570456896 run_lib.py:133] step: 852450, training_loss: 2.12153e-02
I0212 00:16:34.698180 22542570456896 run_lib.py:133] step: 852500, training_loss: 2.52112e-02
I0212 00:16:34.859687 22542570456896 run_lib.py:146] step: 852500, eval_loss: 3.60134e-02
I0212 00:16:52.510303 22542570456896 run_lib.py:133] step: 852550, training_loss: 2.67490e-02
I0212 00:17:10.090174 22542570456896 run_lib.py:133] step: 852600, training_loss: 3.20745e-02
I0212 00:17:10.259551 22542570456896 run_lib.py:146] step: 852600, eval_loss: 2.80180e-02
I0212 00:17:27.795177 22542570456896 run_lib.py:133] step: 852650, training_loss: 2.94978e-02
I0212 00:17:45.362367 22542570456896 run_lib.py:133] step: 852700, training_loss: 2.92236e-02
I0212 00:17:45.518326 22542570456896 run_lib.py:146] step: 852700, eval_loss: 3.18284e-02
I0212 00:18:03.236054 22542570456896 run_lib.py:133] step: 852750, training_loss: 3.33578e-02
I0212 00:18:20.742845 22542570456896 run_lib.py:133] step: 852800, training_loss: 3.46799e-02
I0212 00:18:20.896344 22542570456896 run_lib.py:146] step: 852800, eval_loss: 4.03826e-02
I0212 00:18:38.559190 22542570456896 run_lib.py:133] step: 852850, training_loss: 2.89102e-02
I0212 00:18:56.071119 22542570456896 run_lib.py:133] step: 852900, training_loss: 3.08083e-02
I0212 00:18:56.246404 22542570456896 run_lib.py:146] step: 852900, eval_loss: 3.01209e-02
I0212 00:19:13.987402 22542570456896 run_lib.py:133] step: 852950, training_loss: 2.08624e-02
I0212 00:19:31.513402 22542570456896 run_lib.py:133] step: 853000, training_loss: 2.74475e-02
I0212 00:19:31.671582 22542570456896 run_lib.py:146] step: 853000, eval_loss: 2.45754e-02
I0212 00:19:49.164180 22542570456896 run_lib.py:133] step: 853050, training_loss: 2.75296e-02
I0212 00:20:06.820718 22542570456896 run_lib.py:133] step: 853100, training_loss: 2.89267e-02
I0212 00:20:06.979641 22542570456896 run_lib.py:146] step: 853100, eval_loss: 2.48363e-02
I0212 00:20:24.495770 22542570456896 run_lib.py:133] step: 853150, training_loss: 2.85018e-02
I0212 00:20:42.213486 22542570456896 run_lib.py:133] step: 853200, training_loss: 2.61609e-02
I0212 00:20:42.368614 22542570456896 run_lib.py:146] step: 853200, eval_loss: 2.91318e-02
I0212 00:20:59.945878 22542570456896 run_lib.py:133] step: 853250, training_loss: 2.42276e-02
I0212 00:21:17.463959 22542570456896 run_lib.py:133] step: 853300, training_loss: 3.17115e-02
I0212 00:21:17.617570 22542570456896 run_lib.py:146] step: 853300, eval_loss: 2.91944e-02
I0212 00:21:35.294249 22542570456896 run_lib.py:133] step: 853350, training_loss: 2.37188e-02
I0212 00:21:52.817253 22542570456896 run_lib.py:133] step: 853400, training_loss: 2.65851e-02
I0212 00:21:52.991391 22542570456896 run_lib.py:146] step: 853400, eval_loss: 3.01754e-02
I0212 00:22:10.526167 22542570456896 run_lib.py:133] step: 853450, training_loss: 2.88428e-02
I0212 00:22:28.269599 22542570456896 run_lib.py:133] step: 853500, training_loss: 2.46260e-02
I0212 00:22:28.436602 22542570456896 run_lib.py:146] step: 853500, eval_loss: 3.48737e-02
I0212 00:22:45.949867 22542570456896 run_lib.py:133] step: 853550, training_loss: 3.22719e-02
I0212 00:23:03.447941 22542570456896 run_lib.py:133] step: 853600, training_loss: 3.04612e-02
I0212 00:23:03.786096 22542570456896 run_lib.py:146] step: 853600, eval_loss: 2.53378e-02
I0212 00:23:21.301363 22542570456896 run_lib.py:133] step: 853650, training_loss: 2.61077e-02
I0212 00:23:38.839668 22542570456896 run_lib.py:133] step: 853700, training_loss: 2.86962e-02
I0212 00:23:38.995234 22542570456896 run_lib.py:146] step: 853700, eval_loss: 3.24008e-02
I0212 00:23:56.536205 22542570456896 run_lib.py:133] step: 853750, training_loss: 2.67198e-02
I0212 00:24:14.029942 22542570456896 run_lib.py:133] step: 853800, training_loss: 2.83268e-02
I0212 00:24:14.190394 22542570456896 run_lib.py:146] step: 853800, eval_loss: 2.40463e-02
I0212 00:24:31.859760 22542570456896 run_lib.py:133] step: 853850, training_loss: 2.50593e-02
I0212 00:24:49.473118 22542570456896 run_lib.py:133] step: 853900, training_loss: 2.30189e-02
I0212 00:24:49.633696 22542570456896 run_lib.py:146] step: 853900, eval_loss: 2.61583e-02
I0212 00:25:07.145281 22542570456896 run_lib.py:133] step: 853950, training_loss: 2.40190e-02
I0212 00:25:24.674952 22542570456896 run_lib.py:133] step: 854000, training_loss: 2.38728e-02
I0212 00:25:24.844476 22542570456896 run_lib.py:146] step: 854000, eval_loss: 3.14576e-02
I0212 00:25:42.556295 22542570456896 run_lib.py:133] step: 854050, training_loss: 1.85415e-02
I0212 00:26:00.167429 22542570456896 run_lib.py:133] step: 854100, training_loss: 1.77709e-02
I0212 00:26:00.330792 22542570456896 run_lib.py:146] step: 854100, eval_loss: 3.38334e-02
I0212 00:26:17.827007 22542570456896 run_lib.py:133] step: 854150, training_loss: 3.25028e-02
I0212 00:26:35.348067 22542570456896 run_lib.py:133] step: 854200, training_loss: 2.58849e-02
I0212 00:26:35.503410 22542570456896 run_lib.py:146] step: 854200, eval_loss: 3.49199e-02
I0212 00:26:53.142397 22542570456896 run_lib.py:133] step: 854250, training_loss: 3.03780e-02
I0212 00:27:10.714993 22542570456896 run_lib.py:133] step: 854300, training_loss: 2.35833e-02
I0212 00:27:10.886682 22542570456896 run_lib.py:146] step: 854300, eval_loss: 2.85283e-02
I0212 00:27:28.632606 22542570456896 run_lib.py:133] step: 854350, training_loss: 1.89843e-02
I0212 00:27:46.144855 22542570456896 run_lib.py:133] step: 854400, training_loss: 2.38499e-02
I0212 00:27:46.304820 22542570456896 run_lib.py:146] step: 854400, eval_loss: 2.59619e-02
I0212 00:28:03.989414 22542570456896 run_lib.py:133] step: 854450, training_loss: 2.86989e-02
I0212 00:28:21.487639 22542570456896 run_lib.py:133] step: 854500, training_loss: 2.50797e-02
I0212 00:28:21.644483 22542570456896 run_lib.py:146] step: 854500, eval_loss: 3.79865e-02
I0212 00:28:39.161844 22542570456896 run_lib.py:133] step: 854550, training_loss: 3.32383e-02
I0212 00:28:56.859246 22542570456896 run_lib.py:133] step: 854600, training_loss: 2.47491e-02
I0212 00:28:57.014782 22542570456896 run_lib.py:146] step: 854600, eval_loss: 2.26148e-02
I0212 00:29:14.539070 22542570456896 run_lib.py:133] step: 854650, training_loss: 2.44400e-02
I0212 00:29:32.218407 22542570456896 run_lib.py:133] step: 854700, training_loss: 2.77190e-02
I0212 00:29:32.372537 22542570456896 run_lib.py:146] step: 854700, eval_loss: 2.68700e-02
I0212 00:29:49.877321 22542570456896 run_lib.py:133] step: 854750, training_loss: 2.75068e-02
I0212 00:30:07.375422 22542570456896 run_lib.py:133] step: 854800, training_loss: 2.42899e-02
I0212 00:30:07.535608 22542570456896 run_lib.py:146] step: 854800, eval_loss: 2.52542e-02
I0212 00:30:25.028402 22542570456896 run_lib.py:133] step: 854850, training_loss: 2.37277e-02
I0212 00:30:42.740685 22542570456896 run_lib.py:133] step: 854900, training_loss: 2.32439e-02
I0212 00:30:42.899553 22542570456896 run_lib.py:146] step: 854900, eval_loss: 2.41713e-02
I0212 00:31:00.414045 22542570456896 run_lib.py:133] step: 854950, training_loss: 2.61448e-02
I0212 00:31:17.940782 22542570456896 run_lib.py:133] step: 855000, training_loss: 2.16106e-02
I0212 00:31:18.098414 22542570456896 run_lib.py:146] step: 855000, eval_loss: 3.24139e-02
I0212 00:31:35.845791 22542570456896 run_lib.py:133] step: 855050, training_loss: 2.72661e-02
I0212 00:31:53.333156 22542570456896 run_lib.py:133] step: 855100, training_loss: 2.40725e-02
I0212 00:31:53.492253 22542570456896 run_lib.py:146] step: 855100, eval_loss: 3.38860e-02
I0212 00:32:11.114575 22542570456896 run_lib.py:133] step: 855150, training_loss: 3.29651e-02
I0212 00:32:28.633356 22542570456896 run_lib.py:133] step: 855200, training_loss: 3.01345e-02
I0212 00:32:28.790768 22542570456896 run_lib.py:146] step: 855200, eval_loss: 2.90887e-02
I0212 00:32:46.309698 22542570456896 run_lib.py:133] step: 855250, training_loss: 2.70364e-02
I0212 00:33:03.796375 22542570456896 run_lib.py:133] step: 855300, training_loss: 3.07641e-02
I0212 00:33:03.956732 22542570456896 run_lib.py:146] step: 855300, eval_loss: 2.83320e-02
I0212 00:33:21.622264 22542570456896 run_lib.py:133] step: 855350, training_loss: 2.75985e-02
I0212 00:33:39.191962 22542570456896 run_lib.py:133] step: 855400, training_loss: 2.32449e-02
I0212 00:33:39.354544 22542570456896 run_lib.py:146] step: 855400, eval_loss: 2.98716e-02
I0212 00:33:56.862815 22542570456896 run_lib.py:133] step: 855450, training_loss: 2.65591e-02
I0212 00:34:14.384325 22542570456896 run_lib.py:133] step: 855500, training_loss: 2.62042e-02
I0212 00:34:14.543029 22542570456896 run_lib.py:146] step: 855500, eval_loss: 3.21208e-02
I0212 00:34:32.227746 22542570456896 run_lib.py:133] step: 855550, training_loss: 2.94656e-02
I0212 00:34:49.712283 22542570456896 run_lib.py:133] step: 855600, training_loss: 3.10271e-02
I0212 00:34:49.866281 22542570456896 run_lib.py:146] step: 855600, eval_loss: 2.88694e-02
I0212 00:35:07.510069 22542570456896 run_lib.py:133] step: 855650, training_loss: 2.91711e-02
I0212 00:35:24.958669 22542570456896 run_lib.py:133] step: 855700, training_loss: 2.89208e-02
I0212 00:35:25.114457 22542570456896 run_lib.py:146] step: 855700, eval_loss: 2.62047e-02
I0212 00:35:42.740941 22542570456896 run_lib.py:133] step: 855750, training_loss: 2.23339e-02
I0212 00:36:00.205510 22542570456896 run_lib.py:133] step: 855800, training_loss: 2.51236e-02
I0212 00:36:00.369374 22542570456896 run_lib.py:146] step: 855800, eval_loss: 2.75612e-02
I0212 00:36:18.025568 22542570456896 run_lib.py:133] step: 855850, training_loss: 3.07111e-02
I0212 00:36:35.432746 22542570456896 run_lib.py:133] step: 855900, training_loss: 3.51236e-02
I0212 00:36:35.596769 22542570456896 run_lib.py:146] step: 855900, eval_loss: 3.02847e-02
I0212 00:36:53.003867 22542570456896 run_lib.py:133] step: 855950, training_loss: 2.61903e-02
I0212 00:37:10.553441 22542570456896 run_lib.py:133] step: 856000, training_loss: 2.22964e-02
I0212 00:37:10.722384 22542570456896 run_lib.py:146] step: 856000, eval_loss: 2.63295e-02
I0212 00:37:28.222569 22542570456896 run_lib.py:133] step: 856050, training_loss: 2.88282e-02
I0212 00:37:45.708772 22542570456896 run_lib.py:133] step: 856100, training_loss: 3.34767e-02
I0212 00:37:45.862687 22542570456896 run_lib.py:146] step: 856100, eval_loss: 2.81555e-02
I0212 00:38:03.543055 22542570456896 run_lib.py:133] step: 856150, training_loss: 2.27175e-02
I0212 00:38:21.222222 22542570456896 run_lib.py:133] step: 856200, training_loss: 2.26191e-02
I0212 00:38:21.379618 22542570456896 run_lib.py:146] step: 856200, eval_loss: 3.00265e-02
I0212 00:38:38.861890 22542570456896 run_lib.py:133] step: 856250, training_loss: 3.08131e-02
I0212 00:38:56.388415 22542570456896 run_lib.py:133] step: 856300, training_loss: 2.67783e-02
I0212 00:38:56.569602 22542570456896 run_lib.py:146] step: 856300, eval_loss: 3.73265e-02
I0212 00:39:14.086807 22542570456896 run_lib.py:133] step: 856350, training_loss: 2.71109e-02
I0212 00:39:31.792073 22542570456896 run_lib.py:133] step: 856400, training_loss: 2.72363e-02
I0212 00:39:31.949553 22542570456896 run_lib.py:146] step: 856400, eval_loss: 3.20379e-02
I0212 00:39:49.468551 22542570456896 run_lib.py:133] step: 856450, training_loss: 2.74717e-02
I0212 00:40:06.949228 22542570456896 run_lib.py:133] step: 856500, training_loss: 2.51809e-02
I0212 00:40:07.106215 22542570456896 run_lib.py:146] step: 856500, eval_loss: 2.86012e-02
I0212 00:40:24.614078 22542570456896 run_lib.py:133] step: 856550, training_loss: 2.71064e-02
I0212 00:40:42.350614 22542570456896 run_lib.py:133] step: 856600, training_loss: 2.96580e-02
I0212 00:40:42.508741 22542570456896 run_lib.py:146] step: 856600, eval_loss: 3.45927e-02
I0212 00:41:00.018758 22542570456896 run_lib.py:133] step: 856650, training_loss: 3.47745e-02
I0212 00:41:17.643593 22542570456896 run_lib.py:133] step: 856700, training_loss: 2.46907e-02
I0212 00:41:17.804443 22542570456896 run_lib.py:146] step: 856700, eval_loss: 2.76794e-02
I0212 00:41:35.292577 22542570456896 run_lib.py:133] step: 856750, training_loss: 2.24381e-02
I0212 00:41:52.811660 22542570456896 run_lib.py:133] step: 856800, training_loss: 2.27910e-02
I0212 00:41:52.978684 22542570456896 run_lib.py:146] step: 856800, eval_loss: 3.10664e-02
I0212 00:42:10.675596 22542570456896 run_lib.py:133] step: 856850, training_loss: 3.13438e-02
I0212 00:42:28.353574 22542570456896 run_lib.py:133] step: 856900, training_loss: 3.10900e-02
I0212 00:42:28.511413 22542570456896 run_lib.py:146] step: 856900, eval_loss: 3.06483e-02
I0212 00:42:46.051156 22542570456896 run_lib.py:133] step: 856950, training_loss: 2.12675e-02
I0212 00:43:03.587109 22542570456896 run_lib.py:133] step: 857000, training_loss: 2.86189e-02
I0212 00:43:03.740449 22542570456896 run_lib.py:146] step: 857000, eval_loss: 2.87374e-02
I0212 00:43:21.378364 22542570456896 run_lib.py:133] step: 857050, training_loss: 2.46244e-02
I0212 00:43:38.927324 22542570456896 run_lib.py:133] step: 857100, training_loss: 2.91738e-02
I0212 00:43:39.091730 22542570456896 run_lib.py:146] step: 857100, eval_loss: 2.47437e-02
I0212 00:43:56.802262 22542570456896 run_lib.py:133] step: 857150, training_loss: 2.67840e-02
I0212 00:44:14.368861 22542570456896 run_lib.py:133] step: 857200, training_loss: 2.60848e-02
I0212 00:44:14.530530 22542570456896 run_lib.py:146] step: 857200, eval_loss: 2.90946e-02
I0212 00:44:32.206756 22542570456896 run_lib.py:133] step: 857250, training_loss: 1.82881e-02
I0212 00:44:49.679128 22542570456896 run_lib.py:133] step: 857300, training_loss: 3.30288e-02
I0212 00:44:49.836580 22542570456896 run_lib.py:146] step: 857300, eval_loss: 2.89756e-02
I0212 00:45:07.326267 22542570456896 run_lib.py:133] step: 857350, training_loss: 2.69373e-02
I0212 00:45:24.981361 22542570456896 run_lib.py:133] step: 857400, training_loss: 3.20897e-02
I0212 00:45:25.150627 22542570456896 run_lib.py:146] step: 857400, eval_loss: 3.00932e-02
I0212 00:45:42.689813 22542570456896 run_lib.py:133] step: 857450, training_loss: 3.23029e-02
I0212 00:46:00.485688 22542570456896 run_lib.py:133] step: 857500, training_loss: 2.42821e-02
I0212 00:46:00.639730 22542570456896 run_lib.py:146] step: 857500, eval_loss: 2.78650e-02
I0212 00:46:18.157399 22542570456896 run_lib.py:133] step: 857550, training_loss: 2.59681e-02
I0212 00:46:35.666326 22542570456896 run_lib.py:133] step: 857600, training_loss: 2.95820e-02
I0212 00:46:35.820767 22542570456896 run_lib.py:146] step: 857600, eval_loss: 3.22094e-02
I0212 00:46:53.457387 22542570456896 run_lib.py:133] step: 857650, training_loss: 1.98236e-02
I0212 00:47:10.956124 22542570456896 run_lib.py:133] step: 857700, training_loss: 2.86924e-02
I0212 00:47:11.130482 22542570456896 run_lib.py:146] step: 857700, eval_loss: 2.42884e-02
I0212 00:47:28.715322 22542570456896 run_lib.py:133] step: 857750, training_loss: 2.84015e-02
I0212 00:47:46.463510 22542570456896 run_lib.py:133] step: 857800, training_loss: 3.08152e-02
I0212 00:47:46.621660 22542570456896 run_lib.py:146] step: 857800, eval_loss: 3.24531e-02
I0212 00:48:04.115996 22542570456896 run_lib.py:133] step: 857850, training_loss: 2.56712e-02
I0212 00:48:21.602257 22542570456896 run_lib.py:133] step: 857900, training_loss: 2.02313e-02
I0212 00:48:21.759596 22542570456896 run_lib.py:146] step: 857900, eval_loss: 2.99303e-02
I0212 00:48:39.317132 22542570456896 run_lib.py:133] step: 857950, training_loss: 2.63224e-02
I0212 00:48:56.899715 22542570456896 run_lib.py:133] step: 858000, training_loss: 2.71323e-02
I0212 00:48:57.055781 22542570456896 run_lib.py:146] step: 858000, eval_loss: 2.50342e-02
I0212 00:49:14.575307 22542570456896 run_lib.py:133] step: 858050, training_loss: 3.02062e-02
I0212 00:49:32.062749 22542570456896 run_lib.py:133] step: 858100, training_loss: 2.81411e-02
I0212 00:49:32.220499 22542570456896 run_lib.py:146] step: 858100, eval_loss: 2.99798e-02
I0212 00:49:49.908676 22542570456896 run_lib.py:133] step: 858150, training_loss: 2.82925e-02
I0212 00:50:07.490658 22542570456896 run_lib.py:133] step: 858200, training_loss: 2.75425e-02
I0212 00:50:07.650636 22542570456896 run_lib.py:146] step: 858200, eval_loss: 2.65262e-02
I0212 00:50:25.125178 22542570456896 run_lib.py:133] step: 858250, training_loss: 2.55840e-02
I0212 00:50:42.636539 22542570456896 run_lib.py:133] step: 858300, training_loss: 2.74988e-02
I0212 00:50:42.794532 22542570456896 run_lib.py:146] step: 858300, eval_loss: 2.88745e-02
I0212 00:51:00.540342 22542570456896 run_lib.py:133] step: 858350, training_loss: 2.66284e-02
I0212 00:51:18.060491 22542570456896 run_lib.py:133] step: 858400, training_loss: 3.20942e-02
I0212 00:51:18.218399 22542570456896 run_lib.py:146] step: 858400, eval_loss: 2.96663e-02
I0212 00:51:35.872676 22542570456896 run_lib.py:133] step: 858450, training_loss: 2.80590e-02
I0212 00:51:53.386961 22542570456896 run_lib.py:133] step: 858500, training_loss: 2.63437e-02
I0212 00:51:53.540541 22542570456896 run_lib.py:146] step: 858500, eval_loss: 3.65319e-02
I0212 00:52:11.178060 22542570456896 run_lib.py:133] step: 858550, training_loss: 2.99497e-02
I0212 00:52:28.701756 22542570456896 run_lib.py:133] step: 858600, training_loss: 2.55208e-02
I0212 00:52:28.880650 22542570456896 run_lib.py:146] step: 858600, eval_loss: 2.54517e-02
I0212 00:52:46.644926 22542570456896 run_lib.py:133] step: 858650, training_loss: 3.18642e-02
I0212 00:53:04.164523 22542570456896 run_lib.py:133] step: 858700, training_loss: 2.90038e-02
I0212 00:53:04.322733 22542570456896 run_lib.py:146] step: 858700, eval_loss: 3.43545e-02
I0212 00:53:21.827796 22542570456896 run_lib.py:133] step: 858750, training_loss: 3.13376e-02
I0212 00:53:39.468381 22542570456896 run_lib.py:133] step: 858800, training_loss: 2.80888e-02
I0212 00:53:39.625661 22542570456896 run_lib.py:146] step: 858800, eval_loss: 2.65059e-02
I0212 00:53:57.118565 22542570456896 run_lib.py:133] step: 858850, training_loss: 2.81587e-02
I0212 00:54:14.688938 22542570456896 run_lib.py:133] step: 858900, training_loss: 3.03228e-02
I0212 00:54:14.844279 22542570456896 run_lib.py:146] step: 858900, eval_loss: 2.61384e-02
I0212 00:54:32.570594 22542570456896 run_lib.py:133] step: 858950, training_loss: 2.60611e-02
I0212 00:54:50.051601 22542570456896 run_lib.py:133] step: 859000, training_loss: 1.98209e-02
I0212 00:54:50.211539 22542570456896 run_lib.py:146] step: 859000, eval_loss: 2.80810e-02
I0212 00:55:07.917202 22542570456896 run_lib.py:133] step: 859050, training_loss: 2.59776e-02
I0212 00:55:25.435874 22542570456896 run_lib.py:133] step: 859100, training_loss: 2.69870e-02
I0212 00:55:25.595876 22542570456896 run_lib.py:146] step: 859100, eval_loss: 3.05351e-02
I0212 00:55:43.081444 22542570456896 run_lib.py:133] step: 859150, training_loss: 1.61505e-02
I0212 00:56:00.756855 22542570456896 run_lib.py:133] step: 859200, training_loss: 2.86811e-02
I0212 00:56:00.922605 22542570456896 run_lib.py:146] step: 859200, eval_loss: 2.87089e-02
I0212 00:56:18.450551 22542570456896 run_lib.py:133] step: 859250, training_loss: 2.73928e-02
I0212 00:56:35.944580 22542570456896 run_lib.py:133] step: 859300, training_loss: 3.13032e-02
I0212 00:56:36.108716 22542570456896 run_lib.py:146] step: 859300, eval_loss: 3.04967e-02
I0212 00:56:53.597182 22542570456896 run_lib.py:133] step: 859350, training_loss: 2.64939e-02
I0212 00:57:11.260602 22542570456896 run_lib.py:133] step: 859400, training_loss: 2.66615e-02
I0212 00:57:11.413200 22542570456896 run_lib.py:146] step: 859400, eval_loss: 3.89521e-02
I0212 00:57:28.884557 22542570456896 run_lib.py:133] step: 859450, training_loss: 3.42702e-02
I0212 00:57:46.463794 22542570456896 run_lib.py:133] step: 859500, training_loss: 2.93084e-02
I0212 00:57:46.636740 22542570456896 run_lib.py:146] step: 859500, eval_loss: 2.89312e-02
I0212 00:58:04.216657 22542570456896 run_lib.py:133] step: 859550, training_loss: 2.47536e-02
I0212 00:58:21.705991 22542570456896 run_lib.py:133] step: 859600, training_loss: 2.93878e-02
I0212 00:58:21.870443 22542570456896 run_lib.py:146] step: 859600, eval_loss: 3.73119e-02
I0212 00:58:39.504696 22542570456896 run_lib.py:133] step: 859650, training_loss: 2.67453e-02
I0212 00:58:56.978415 22542570456896 run_lib.py:133] step: 859700, training_loss: 2.77574e-02
I0212 00:58:57.134462 22542570456896 run_lib.py:146] step: 859700, eval_loss: 2.84213e-02
I0212 00:59:14.561970 22542570456896 run_lib.py:133] step: 859750, training_loss: 2.87437e-02
I0212 00:59:32.021767 22542570456896 run_lib.py:133] step: 859800, training_loss: 2.60820e-02
I0212 00:59:32.177764 22542570456896 run_lib.py:146] step: 859800, eval_loss: 2.54653e-02
I0212 00:59:49.819561 22542570456896 run_lib.py:133] step: 859850, training_loss: 2.90882e-02
I0212 01:00:07.261721 22542570456896 run_lib.py:133] step: 859900, training_loss: 2.95262e-02
I0212 01:00:07.418435 22542570456896 run_lib.py:146] step: 859900, eval_loss: 3.18898e-02
I0212 01:00:25.004007 22542570456896 run_lib.py:133] step: 859950, training_loss: 3.09595e-02
I0212 01:00:42.475425 22542570456896 run_lib.py:133] step: 860000, training_loss: 2.73902e-02
I0212 01:00:43.207355 22542570456896 run_lib.py:146] step: 860000, eval_loss: 3.16993e-02
I0212 01:01:03.515085 22542570456896 run_lib.py:133] step: 860050, training_loss: 2.47349e-02
I0212 01:01:21.015286 22542570456896 run_lib.py:133] step: 860100, training_loss: 2.61317e-02
I0212 01:01:21.179600 22542570456896 run_lib.py:146] step: 860100, eval_loss: 3.14791e-02
I0212 01:01:38.819223 22542570456896 run_lib.py:133] step: 860150, training_loss: 2.23706e-02
I0212 01:01:56.321102 22542570456896 run_lib.py:133] step: 860200, training_loss: 2.46691e-02
I0212 01:01:56.478382 22542570456896 run_lib.py:146] step: 860200, eval_loss: 3.64827e-02
I0212 01:02:13.997697 22542570456896 run_lib.py:133] step: 860250, training_loss: 3.09737e-02
I0212 01:02:31.477094 22542570456896 run_lib.py:133] step: 860300, training_loss: 2.12558e-02
I0212 01:02:31.642513 22542570456896 run_lib.py:146] step: 860300, eval_loss: 2.93165e-02
I0212 01:02:49.301159 22542570456896 run_lib.py:133] step: 860350, training_loss: 2.96711e-02
I0212 01:03:06.976058 22542570456896 run_lib.py:133] step: 860400, training_loss: 3.36253e-02
I0212 01:03:07.132365 22542570456896 run_lib.py:146] step: 860400, eval_loss: 3.11048e-02
I0212 01:03:24.652931 22542570456896 run_lib.py:133] step: 860450, training_loss: 3.04702e-02
I0212 01:03:42.161282 22542570456896 run_lib.py:133] step: 860500, training_loss: 2.85307e-02
I0212 01:03:42.318512 22542570456896 run_lib.py:146] step: 860500, eval_loss: 3.01817e-02
I0212 01:03:59.986792 22542570456896 run_lib.py:133] step: 860550, training_loss: 2.30077e-02
I0212 01:04:17.493334 22542570456896 run_lib.py:133] step: 860600, training_loss: 3.01454e-02
I0212 01:04:17.654468 22542570456896 run_lib.py:146] step: 860600, eval_loss: 2.83157e-02
I0212 01:04:35.331779 22542570456896 run_lib.py:133] step: 860650, training_loss: 3.20964e-02
I0212 01:04:52.875659 22542570456896 run_lib.py:133] step: 860700, training_loss: 2.53668e-02
I0212 01:04:53.034822 22542570456896 run_lib.py:146] step: 860700, eval_loss: 2.84716e-02
I0212 01:05:10.717168 22542570456896 run_lib.py:133] step: 860750, training_loss: 2.89562e-02
I0212 01:05:28.197202 22542570456896 run_lib.py:133] step: 860800, training_loss: 2.82537e-02
I0212 01:05:28.362720 22542570456896 run_lib.py:146] step: 860800, eval_loss: 2.83016e-02
I0212 01:05:45.827961 22542570456896 run_lib.py:133] step: 860850, training_loss: 2.51385e-02
I0212 01:06:03.507171 22542570456896 run_lib.py:133] step: 860900, training_loss: 2.43428e-02
I0212 01:06:03.661969 22542570456896 run_lib.py:146] step: 860900, eval_loss: 2.57031e-02
I0212 01:06:21.200976 22542570456896 run_lib.py:133] step: 860950, training_loss: 2.38411e-02
I0212 01:06:38.927066 22542570456896 run_lib.py:133] step: 861000, training_loss: 2.54772e-02
I0212 01:06:39.094746 22542570456896 run_lib.py:146] step: 861000, eval_loss: 2.89761e-02
I0212 01:06:56.583803 22542570456896 run_lib.py:133] step: 861050, training_loss: 2.86673e-02
I0212 01:07:14.125785 22542570456896 run_lib.py:133] step: 861100, training_loss: 2.29860e-02
I0212 01:07:14.296525 22542570456896 run_lib.py:146] step: 861100, eval_loss: 3.00534e-02
I0212 01:07:31.943651 22542570456896 run_lib.py:133] step: 861150, training_loss: 2.36689e-02
I0212 01:07:49.419799 22542570456896 run_lib.py:133] step: 861200, training_loss: 2.15908e-02
I0212 01:07:49.589585 22542570456896 run_lib.py:146] step: 861200, eval_loss: 2.35664e-02
I0212 01:08:07.114790 22542570456896 run_lib.py:133] step: 861250, training_loss: 3.18529e-02
I0212 01:08:24.833456 22542570456896 run_lib.py:133] step: 861300, training_loss: 2.89613e-02
I0212 01:08:24.990514 22542570456896 run_lib.py:146] step: 861300, eval_loss: 3.24157e-02
I0212 01:08:42.512314 22542570456896 run_lib.py:133] step: 861350, training_loss: 2.70708e-02
I0212 01:09:00.012398 22542570456896 run_lib.py:133] step: 861400, training_loss: 2.52690e-02
I0212 01:09:00.324512 22542570456896 run_lib.py:146] step: 861400, eval_loss: 3.34766e-02
I0212 01:09:17.815456 22542570456896 run_lib.py:133] step: 861450, training_loss: 2.89588e-02
I0212 01:09:35.346384 22542570456896 run_lib.py:133] step: 861500, training_loss: 2.06469e-02
I0212 01:09:35.519376 22542570456896 run_lib.py:146] step: 861500, eval_loss: 2.30344e-02
I0212 01:09:53.059977 22542570456896 run_lib.py:133] step: 861550, training_loss: 2.57129e-02
I0212 01:10:10.600907 22542570456896 run_lib.py:133] step: 861600, training_loss: 2.59195e-02
I0212 01:10:10.761586 22542570456896 run_lib.py:146] step: 861600, eval_loss: 3.10082e-02
I0212 01:10:28.470750 22542570456896 run_lib.py:133] step: 861650, training_loss: 3.25058e-02
I0212 01:10:46.045026 22542570456896 run_lib.py:133] step: 861700, training_loss: 2.86192e-02
I0212 01:10:46.202651 22542570456896 run_lib.py:146] step: 861700, eval_loss: 3.50075e-02
I0212 01:11:03.714365 22542570456896 run_lib.py:133] step: 861750, training_loss: 2.83937e-02
I0212 01:11:21.233021 22542570456896 run_lib.py:133] step: 861800, training_loss: 2.70230e-02
I0212 01:11:21.390823 22542570456896 run_lib.py:146] step: 861800, eval_loss: 3.01692e-02
I0212 01:11:39.114078 22542570456896 run_lib.py:133] step: 861850, training_loss: 3.21863e-02
I0212 01:11:56.701441 22542570456896 run_lib.py:133] step: 861900, training_loss: 3.32410e-02
I0212 01:11:56.857472 22542570456896 run_lib.py:146] step: 861900, eval_loss: 3.07165e-02
I0212 01:12:14.363291 22542570456896 run_lib.py:133] step: 861950, training_loss: 3.24075e-02
I0212 01:12:31.857911 22542570456896 run_lib.py:133] step: 862000, training_loss: 3.20931e-02
I0212 01:12:32.027499 22542570456896 run_lib.py:146] step: 862000, eval_loss: 2.84863e-02
I0212 01:12:49.661757 22542570456896 run_lib.py:133] step: 862050, training_loss: 2.87756e-02
I0212 01:13:07.221260 22542570456896 run_lib.py:133] step: 862100, training_loss: 3.75156e-02
I0212 01:13:07.382756 22542570456896 run_lib.py:146] step: 862100, eval_loss: 2.73238e-02
I0212 01:13:25.073502 22542570456896 run_lib.py:133] step: 862150, training_loss: 2.91308e-02
I0212 01:13:42.587565 22542570456896 run_lib.py:133] step: 862200, training_loss: 2.72147e-02
I0212 01:13:42.753638 22542570456896 run_lib.py:146] step: 862200, eval_loss: 3.19426e-02
I0212 01:14:00.444530 22542570456896 run_lib.py:133] step: 862250, training_loss: 2.66347e-02
I0212 01:14:17.966355 22542570456896 run_lib.py:133] step: 862300, training_loss: 2.21495e-02
I0212 01:14:18.119336 22542570456896 run_lib.py:146] step: 862300, eval_loss: 3.16892e-02
I0212 01:14:35.626421 22542570456896 run_lib.py:133] step: 862350, training_loss: 3.47089e-02
I0212 01:14:53.368900 22542570456896 run_lib.py:133] step: 862400, training_loss: 2.44433e-02
I0212 01:14:53.534588 22542570456896 run_lib.py:146] step: 862400, eval_loss: 3.85707e-02
I0212 01:15:11.077888 22542570456896 run_lib.py:133] step: 862450, training_loss: 3.23321e-02
I0212 01:15:28.828177 22542570456896 run_lib.py:133] step: 862500, training_loss: 3.43825e-02
I0212 01:15:28.988768 22542570456896 run_lib.py:146] step: 862500, eval_loss: 2.89788e-02
I0212 01:15:46.483466 22542570456896 run_lib.py:133] step: 862550, training_loss: 2.80701e-02
I0212 01:16:03.967224 22542570456896 run_lib.py:133] step: 862600, training_loss: 2.20013e-02
I0212 01:16:04.136478 22542570456896 run_lib.py:146] step: 862600, eval_loss: 2.70318e-02
I0212 01:16:21.816732 22542570456896 run_lib.py:133] step: 862650, training_loss: 3.02095e-02
I0212 01:16:39.394509 22542570456896 run_lib.py:133] step: 862700, training_loss: 2.99821e-02
I0212 01:16:39.550605 22542570456896 run_lib.py:146] step: 862700, eval_loss: 2.63161e-02
I0212 01:16:57.054011 22542570456896 run_lib.py:133] step: 862750, training_loss: 2.84167e-02
I0212 01:17:14.551715 22542570456896 run_lib.py:133] step: 862800, training_loss: 2.94072e-02
I0212 01:17:14.705516 22542570456896 run_lib.py:146] step: 862800, eval_loss: 2.93071e-02
I0212 01:17:32.443202 22542570456896 run_lib.py:133] step: 862850, training_loss: 2.87809e-02
I0212 01:17:49.962106 22542570456896 run_lib.py:133] step: 862900, training_loss: 2.72012e-02
I0212 01:17:50.134681 22542570456896 run_lib.py:146] step: 862900, eval_loss: 3.35001e-02
I0212 01:18:07.796284 22542570456896 run_lib.py:133] step: 862950, training_loss: 2.65746e-02
I0212 01:18:25.321587 22542570456896 run_lib.py:133] step: 863000, training_loss: 3.34320e-02
I0212 01:18:25.479461 22542570456896 run_lib.py:146] step: 863000, eval_loss: 3.08770e-02
I0212 01:18:42.965756 22542570456896 run_lib.py:133] step: 863050, training_loss: 2.72642e-02
I0212 01:19:00.402157 22542570456896 run_lib.py:133] step: 863100, training_loss: 2.50183e-02
I0212 01:19:00.559351 22542570456896 run_lib.py:146] step: 863100, eval_loss: 2.78879e-02
I0212 01:19:18.256213 22542570456896 run_lib.py:133] step: 863150, training_loss: 1.97294e-02
I0212 01:19:35.852795 22542570456896 run_lib.py:133] step: 863200, training_loss: 3.30312e-02
I0212 01:19:36.009648 22542570456896 run_lib.py:146] step: 863200, eval_loss: 3.17016e-02
I0212 01:19:53.551050 22542570456896 run_lib.py:133] step: 863250, training_loss: 2.24154e-02
I0212 01:20:10.998584 22542570456896 run_lib.py:133] step: 863300, training_loss: 2.21603e-02
I0212 01:20:11.157456 22542570456896 run_lib.py:146] step: 863300, eval_loss: 3.21873e-02
I0212 01:20:28.788777 22542570456896 run_lib.py:133] step: 863350, training_loss: 2.52228e-02
I0212 01:20:46.248790 22542570456896 run_lib.py:133] step: 863400, training_loss: 2.40939e-02
I0212 01:20:46.405611 22542570456896 run_lib.py:146] step: 863400, eval_loss: 2.79689e-02
I0212 01:21:04.011203 22542570456896 run_lib.py:133] step: 863450, training_loss: 2.37237e-02
I0212 01:21:21.449440 22542570456896 run_lib.py:133] step: 863500, training_loss: 3.08003e-02
I0212 01:21:21.626299 22542570456896 run_lib.py:146] step: 863500, eval_loss: 2.49984e-02
I0212 01:21:39.216751 22542570456896 run_lib.py:133] step: 863550, training_loss: 2.25618e-02
I0212 01:21:56.611786 22542570456896 run_lib.py:133] step: 863600, training_loss: 2.69405e-02
I0212 01:21:56.775152 22542570456896 run_lib.py:146] step: 863600, eval_loss: 3.24918e-02
I0212 01:22:14.361599 22542570456896 run_lib.py:133] step: 863650, training_loss: 2.95270e-02
I0212 01:22:31.717844 22542570456896 run_lib.py:133] step: 863700, training_loss: 2.70379e-02
I0212 01:22:31.871316 22542570456896 run_lib.py:146] step: 863700, eval_loss: 2.57765e-02
I0212 01:22:49.217009 22542570456896 run_lib.py:133] step: 863750, training_loss: 3.59036e-02
I0212 01:23:06.760570 22542570456896 run_lib.py:133] step: 863800, training_loss: 2.36678e-02
I0212 01:23:06.914558 22542570456896 run_lib.py:146] step: 863800, eval_loss: 2.69632e-02
I0212 01:23:24.368545 22542570456896 run_lib.py:133] step: 863850, training_loss: 2.67619e-02
I0212 01:23:41.773315 22542570456896 run_lib.py:133] step: 863900, training_loss: 2.77649e-02
I0212 01:23:41.934973 22542570456896 run_lib.py:146] step: 863900, eval_loss: 3.25858e-02
I0212 01:23:59.344063 22542570456896 run_lib.py:133] step: 863950, training_loss: 3.04166e-02
I0212 01:24:16.737043 22542570456896 run_lib.py:133] step: 864000, training_loss: 3.31658e-02
I0212 01:24:16.890238 22542570456896 run_lib.py:146] step: 864000, eval_loss: 2.59997e-02
I0212 01:24:34.155474 22542570456896 run_lib.py:133] step: 864050, training_loss: 2.51410e-02
I0212 01:24:51.445295 22542570456896 run_lib.py:133] step: 864100, training_loss: 2.34709e-02
I0212 01:24:51.599048 22542570456896 run_lib.py:146] step: 864100, eval_loss: 2.63568e-02
I0212 01:25:08.843882 22542570456896 run_lib.py:133] step: 864150, training_loss: 3.15030e-02
I0212 01:25:26.248676 22542570456896 run_lib.py:133] step: 864200, training_loss: 3.28761e-02
I0212 01:25:26.398269 22542570456896 run_lib.py:146] step: 864200, eval_loss: 2.84401e-02
I0212 01:25:43.638043 22542570456896 run_lib.py:133] step: 864250, training_loss: 2.88426e-02
I0212 01:26:00.880456 22542570456896 run_lib.py:133] step: 864300, training_loss: 3.17706e-02
I0212 01:26:01.038445 22542570456896 run_lib.py:146] step: 864300, eval_loss: 3.32244e-02
I0212 01:26:18.313844 22542570456896 run_lib.py:133] step: 864350, training_loss: 2.57280e-02
I0212 01:26:35.762684 22542570456896 run_lib.py:133] step: 864400, training_loss: 3.07910e-02
I0212 01:26:35.918160 22542570456896 run_lib.py:146] step: 864400, eval_loss: 2.96708e-02
I0212 01:26:53.154876 22542570456896 run_lib.py:133] step: 864450, training_loss: 2.70070e-02
I0212 01:27:10.427181 22542570456896 run_lib.py:133] step: 864500, training_loss: 3.26140e-02
I0212 01:27:10.585220 22542570456896 run_lib.py:146] step: 864500, eval_loss: 3.06637e-02
I0212 01:27:27.820520 22542570456896 run_lib.py:133] step: 864550, training_loss: 2.63246e-02
I0212 01:27:45.069090 22542570456896 run_lib.py:133] step: 864600, training_loss: 2.41115e-02
I0212 01:27:45.224226 22542570456896 run_lib.py:146] step: 864600, eval_loss: 3.21666e-02
I0212 01:28:02.607220 22542570456896 run_lib.py:133] step: 864650, training_loss: 2.13550e-02
I0212 01:28:19.979451 22542570456896 run_lib.py:133] step: 864700, training_loss: 3.00371e-02
I0212 01:28:20.130368 22542570456896 run_lib.py:146] step: 864700, eval_loss: 2.53476e-02
I0212 01:28:37.382126 22542570456896 run_lib.py:133] step: 864750, training_loss: 2.78153e-02
I0212 01:28:54.657233 22542570456896 run_lib.py:133] step: 864800, training_loss: 2.80002e-02
I0212 01:28:54.810294 22542570456896 run_lib.py:146] step: 864800, eval_loss: 3.05115e-02
I0212 01:29:12.178941 22542570456896 run_lib.py:133] step: 864850, training_loss: 2.95034e-02
I0212 01:29:29.444667 22542570456896 run_lib.py:133] step: 864900, training_loss: 2.54426e-02
I0212 01:29:29.618360 22542570456896 run_lib.py:146] step: 864900, eval_loss: 2.67321e-02
I0212 01:29:47.071961 22542570456896 run_lib.py:133] step: 864950, training_loss: 2.77739e-02
I0212 01:30:04.361227 22542570456896 run_lib.py:133] step: 865000, training_loss: 3.15155e-02
I0212 01:30:04.523117 22542570456896 run_lib.py:146] step: 865000, eval_loss: 2.27723e-02
I0212 01:30:21.979468 22542570456896 run_lib.py:133] step: 865050, training_loss: 2.84589e-02
I0212 01:30:39.247297 22542570456896 run_lib.py:133] step: 865100, training_loss: 3.01326e-02
I0212 01:30:39.400321 22542570456896 run_lib.py:146] step: 865100, eval_loss: 3.08715e-02
I0212 01:30:56.666129 22542570456896 run_lib.py:133] step: 865150, training_loss: 2.48411e-02
I0212 01:31:14.130835 22542570456896 run_lib.py:133] step: 865200, training_loss: 2.35014e-02
I0212 01:31:14.283574 22542570456896 run_lib.py:146] step: 865200, eval_loss: 2.76746e-02
I0212 01:31:31.609537 22542570456896 run_lib.py:133] step: 865250, training_loss: 2.38956e-02
I0212 01:31:49.067456 22542570456896 run_lib.py:133] step: 865300, training_loss: 3.23462e-02
I0212 01:31:49.224292 22542570456896 run_lib.py:146] step: 865300, eval_loss: 3.43174e-02
I0212 01:32:06.465034 22542570456896 run_lib.py:133] step: 865350, training_loss: 2.97177e-02
I0212 01:32:23.712716 22542570456896 run_lib.py:133] step: 865400, training_loss: 2.88607e-02
I0212 01:32:23.866513 22542570456896 run_lib.py:146] step: 865400, eval_loss: 2.98113e-02
I0212 01:32:41.268433 22542570456896 run_lib.py:133] step: 865450, training_loss: 2.93873e-02
I0212 01:32:58.577805 22542570456896 run_lib.py:133] step: 865500, training_loss: 3.16702e-02
I0212 01:32:58.736430 22542570456896 run_lib.py:146] step: 865500, eval_loss: 2.45276e-02
I0212 01:33:16.034603 22542570456896 run_lib.py:133] step: 865550, training_loss: 2.67566e-02
I0212 01:33:33.477008 22542570456896 run_lib.py:133] step: 865600, training_loss: 3.14715e-02
I0212 01:33:33.629287 22542570456896 run_lib.py:146] step: 865600, eval_loss: 2.71019e-02
I0212 01:33:50.888073 22542570456896 run_lib.py:133] step: 865650, training_loss: 2.15435e-02
I0212 01:34:08.192180 22542570456896 run_lib.py:133] step: 865700, training_loss: 2.00562e-02
I0212 01:34:08.344128 22542570456896 run_lib.py:146] step: 865700, eval_loss: 2.73358e-02
I0212 01:34:25.693514 22542570456896 run_lib.py:133] step: 865750, training_loss: 3.03439e-02
I0212 01:34:43.010751 22542570456896 run_lib.py:133] step: 865800, training_loss: 2.75747e-02
I0212 01:34:43.177358 22542570456896 run_lib.py:146] step: 865800, eval_loss: 2.68758e-02
I0212 01:35:00.456513 22542570456896 run_lib.py:133] step: 865850, training_loss: 2.25732e-02
I0212 01:35:17.787838 22542570456896 run_lib.py:133] step: 865900, training_loss: 3.02156e-02
I0212 01:35:17.950232 22542570456896 run_lib.py:146] step: 865900, eval_loss: 3.42230e-02
I0212 01:35:35.405798 22542570456896 run_lib.py:133] step: 865950, training_loss: 2.66802e-02
I0212 01:35:52.718995 22542570456896 run_lib.py:133] step: 866000, training_loss: 3.33991e-02
I0212 01:35:52.871973 22542570456896 run_lib.py:146] step: 866000, eval_loss: 3.05927e-02
I0212 01:36:10.155472 22542570456896 run_lib.py:133] step: 866050, training_loss: 2.61251e-02
I0212 01:36:27.526495 22542570456896 run_lib.py:133] step: 866100, training_loss: 3.10688e-02
I0212 01:36:27.678715 22542570456896 run_lib.py:146] step: 866100, eval_loss: 2.42123e-02
I0212 01:36:45.134722 22542570456896 run_lib.py:133] step: 866150, training_loss: 2.79374e-02
I0212 01:37:02.399374 22542570456896 run_lib.py:133] step: 866200, training_loss: 2.34468e-02
I0212 01:37:02.552335 22542570456896 run_lib.py:146] step: 866200, eval_loss: 3.09371e-02
I0212 01:37:19.952026 22542570456896 run_lib.py:133] step: 866250, training_loss: 3.37467e-02
I0212 01:37:37.209703 22542570456896 run_lib.py:133] step: 866300, training_loss: 2.93813e-02
I0212 01:37:37.378276 22542570456896 run_lib.py:146] step: 866300, eval_loss: 2.90208e-02
I0212 01:37:54.789754 22542570456896 run_lib.py:133] step: 866350, training_loss: 3.62711e-02
I0212 01:38:12.091187 22542570456896 run_lib.py:133] step: 866400, training_loss: 2.46603e-02
I0212 01:38:12.245395 22542570456896 run_lib.py:146] step: 866400, eval_loss: 3.37977e-02
I0212 01:38:29.668502 22542570456896 run_lib.py:133] step: 866450, training_loss: 3.64304e-02
I0212 01:38:46.907572 22542570456896 run_lib.py:133] step: 866500, training_loss: 3.25802e-02
I0212 01:38:47.061321 22542570456896 run_lib.py:146] step: 866500, eval_loss: 2.55334e-02
I0212 01:39:04.307689 22542570456896 run_lib.py:133] step: 866550, training_loss: 3.02617e-02
I0212 01:39:21.714790 22542570456896 run_lib.py:133] step: 866600, training_loss: 2.70882e-02
I0212 01:39:21.866528 22542570456896 run_lib.py:146] step: 866600, eval_loss: 2.67532e-02
I0212 01:39:39.196670 22542570456896 run_lib.py:133] step: 866650, training_loss: 2.56977e-02
I0212 01:39:56.469236 22542570456896 run_lib.py:133] step: 866700, training_loss: 2.84713e-02
I0212 01:39:56.624310 22542570456896 run_lib.py:146] step: 866700, eval_loss: 2.90801e-02
I0212 01:40:14.053500 22542570456896 run_lib.py:133] step: 866750, training_loss: 2.30857e-02
I0212 01:40:31.312150 22542570456896 run_lib.py:133] step: 866800, training_loss: 3.07559e-02
I0212 01:40:31.487708 22542570456896 run_lib.py:146] step: 866800, eval_loss: 3.09074e-02
I0212 01:40:48.888981 22542570456896 run_lib.py:133] step: 866850, training_loss: 2.88805e-02
I0212 01:41:06.156136 22542570456896 run_lib.py:133] step: 866900, training_loss: 2.52091e-02
I0212 01:41:06.309347 22542570456896 run_lib.py:146] step: 866900, eval_loss: 3.39401e-02
I0212 01:41:23.621503 22542570456896 run_lib.py:133] step: 866950, training_loss: 3.21551e-02
I0212 01:41:41.063876 22542570456896 run_lib.py:133] step: 867000, training_loss: 3.19628e-02
I0212 01:41:41.217302 22542570456896 run_lib.py:146] step: 867000, eval_loss: 2.84141e-02
I0212 01:41:58.478805 22542570456896 run_lib.py:133] step: 867050, training_loss: 2.67128e-02
I0212 01:42:15.745457 22542570456896 run_lib.py:133] step: 867100, training_loss: 2.30025e-02
I0212 01:42:15.895313 22542570456896 run_lib.py:146] step: 867100, eval_loss: 3.14830e-02
I0212 01:42:33.172770 22542570456896 run_lib.py:133] step: 867150, training_loss: 2.37790e-02
I0212 01:42:50.611975 22542570456896 run_lib.py:133] step: 867200, training_loss: 3.58309e-02
I0212 01:42:50.792363 22542570456896 run_lib.py:146] step: 867200, eval_loss: 3.45003e-02
I0212 01:43:08.095404 22542570456896 run_lib.py:133] step: 867250, training_loss: 2.36675e-02
I0212 01:43:25.471230 22542570456896 run_lib.py:133] step: 867300, training_loss: 2.42741e-02
I0212 01:43:25.626228 22542570456896 run_lib.py:146] step: 867300, eval_loss: 3.53253e-02
I0212 01:43:42.879628 22542570456896 run_lib.py:133] step: 867350, training_loss: 2.32303e-02
I0212 01:44:00.124017 22542570456896 run_lib.py:133] step: 867400, training_loss: 2.63455e-02
I0212 01:44:00.277090 22542570456896 run_lib.py:146] step: 867400, eval_loss: 3.10635e-02
I0212 01:44:17.684638 22542570456896 run_lib.py:133] step: 867450, training_loss: 3.12271e-02
I0212 01:44:35.019950 22542570456896 run_lib.py:133] step: 867500, training_loss: 2.24082e-02
I0212 01:44:35.178103 22542570456896 run_lib.py:146] step: 867500, eval_loss: 2.57773e-02
I0212 01:44:52.561345 22542570456896 run_lib.py:133] step: 867550, training_loss: 2.58066e-02
I0212 01:45:09.827999 22542570456896 run_lib.py:133] step: 867600, training_loss: 3.05934e-02
I0212 01:45:09.979245 22542570456896 run_lib.py:146] step: 867600, eval_loss: 2.65483e-02
I0212 01:45:27.393404 22542570456896 run_lib.py:133] step: 867650, training_loss: 2.60666e-02
I0212 01:45:44.679372 22542570456896 run_lib.py:133] step: 867700, training_loss: 2.17585e-02
I0212 01:45:44.836551 22542570456896 run_lib.py:146] step: 867700, eval_loss: 3.10181e-02
I0212 01:46:02.252989 22542570456896 run_lib.py:133] step: 867750, training_loss: 2.76644e-02
I0212 01:46:19.571940 22542570456896 run_lib.py:133] step: 867800, training_loss: 2.92152e-02
I0212 01:46:19.728475 22542570456896 run_lib.py:146] step: 867800, eval_loss: 3.36343e-02
I0212 01:46:37.160530 22542570456896 run_lib.py:133] step: 867850, training_loss: 2.51577e-02
I0212 01:46:54.431105 22542570456896 run_lib.py:133] step: 867900, training_loss: 2.68832e-02
I0212 01:46:54.584481 22542570456896 run_lib.py:146] step: 867900, eval_loss: 2.32236e-02
I0212 01:47:11.862370 22542570456896 run_lib.py:133] step: 867950, training_loss: 3.01407e-02
I0212 01:47:29.290809 22542570456896 run_lib.py:133] step: 868000, training_loss: 2.83159e-02
I0212 01:47:29.446019 22542570456896 run_lib.py:146] step: 868000, eval_loss: 3.08863e-02
I0212 01:47:46.700781 22542570456896 run_lib.py:133] step: 868050, training_loss: 2.76686e-02
I0212 01:48:04.137737 22542570456896 run_lib.py:133] step: 868100, training_loss: 3.07967e-02
I0212 01:48:04.310583 22542570456896 run_lib.py:146] step: 868100, eval_loss: 2.83417e-02
I0212 01:48:21.629343 22542570456896 run_lib.py:133] step: 868150, training_loss: 2.57033e-02
I0212 01:48:38.919013 22542570456896 run_lib.py:133] step: 868200, training_loss: 2.43271e-02
I0212 01:48:39.075595 22542570456896 run_lib.py:146] step: 868200, eval_loss: 2.89260e-02
I0212 01:48:56.548125 22542570456896 run_lib.py:133] step: 868250, training_loss: 2.75362e-02
I0212 01:49:13.774284 22542570456896 run_lib.py:133] step: 868300, training_loss: 2.98498e-02
I0212 01:49:13.933318 22542570456896 run_lib.py:146] step: 868300, eval_loss: 2.63484e-02
I0212 01:49:31.192819 22542570456896 run_lib.py:133] step: 868350, training_loss: 3.47962e-02
I0212 01:49:48.655112 22542570456896 run_lib.py:133] step: 868400, training_loss: 2.53872e-02
I0212 01:49:48.809545 22542570456896 run_lib.py:146] step: 868400, eval_loss: 3.54158e-02
I0212 01:50:06.118930 22542570456896 run_lib.py:133] step: 868450, training_loss: 2.58523e-02
I0212 01:50:23.414376 22542570456896 run_lib.py:133] step: 868500, training_loss: 3.36313e-02
I0212 01:50:23.717292 22542570456896 run_lib.py:146] step: 868500, eval_loss: 3.22864e-02
I0212 01:50:40.941882 22542570456896 run_lib.py:133] step: 868550, training_loss: 2.77578e-02
I0212 01:50:58.175359 22542570456896 run_lib.py:133] step: 868600, training_loss: 2.43801e-02
I0212 01:50:58.340436 22542570456896 run_lib.py:146] step: 868600, eval_loss: 3.33880e-02
I0212 01:51:15.637339 22542570456896 run_lib.py:133] step: 868650, training_loss: 2.61366e-02
I0212 01:51:32.888451 22542570456896 run_lib.py:133] step: 868700, training_loss: 2.80087e-02
I0212 01:51:33.045215 22542570456896 run_lib.py:146] step: 868700, eval_loss: 2.62774e-02
I0212 01:51:50.486507 22542570456896 run_lib.py:133] step: 868750, training_loss: 2.89622e-02
I0212 01:52:07.779108 22542570456896 run_lib.py:133] step: 868800, training_loss: 3.10222e-02
I0212 01:52:07.933252 22542570456896 run_lib.py:146] step: 868800, eval_loss: 2.79370e-02
I0212 01:52:25.155282 22542570456896 run_lib.py:133] step: 868850, training_loss: 2.84793e-02
I0212 01:52:42.412801 22542570456896 run_lib.py:133] step: 868900, training_loss: 2.80594e-02
I0212 01:52:42.569550 22542570456896 run_lib.py:146] step: 868900, eval_loss: 2.68541e-02
I0212 01:53:00.088149 22542570456896 run_lib.py:133] step: 868950, training_loss: 3.15045e-02
I0212 01:53:17.471107 22542570456896 run_lib.py:133] step: 869000, training_loss: 2.49222e-02
I0212 01:53:17.618793 22542570456896 run_lib.py:146] step: 869000, eval_loss: 2.77867e-02
I0212 01:53:34.869889 22542570456896 run_lib.py:133] step: 869050, training_loss: 2.93252e-02
I0212 01:53:52.182030 22542570456896 run_lib.py:133] step: 869100, training_loss: 2.93478e-02
I0212 01:53:52.343731 22542570456896 run_lib.py:146] step: 869100, eval_loss: 3.14931e-02
I0212 01:54:09.713441 22542570456896 run_lib.py:133] step: 869150, training_loss: 2.77091e-02
I0212 01:54:26.978556 22542570456896 run_lib.py:133] step: 869200, training_loss: 2.66348e-02
I0212 01:54:27.147389 22542570456896 run_lib.py:146] step: 869200, eval_loss: 3.15887e-02
I0212 01:54:44.660247 22542570456896 run_lib.py:133] step: 869250, training_loss: 2.75723e-02
I0212 01:55:01.975356 22542570456896 run_lib.py:133] step: 869300, training_loss: 3.29144e-02
I0212 01:55:02.130071 22542570456896 run_lib.py:146] step: 869300, eval_loss: 2.88393e-02
I0212 01:55:19.531541 22542570456896 run_lib.py:133] step: 869350, training_loss: 2.86152e-02
I0212 01:55:36.768334 22542570456896 run_lib.py:133] step: 869400, training_loss: 2.95324e-02
I0212 01:55:36.920019 22542570456896 run_lib.py:146] step: 869400, eval_loss: 2.86988e-02
I0212 01:55:54.168262 22542570456896 run_lib.py:133] step: 869450, training_loss: 2.38312e-02
I0212 01:56:11.644636 22542570456896 run_lib.py:133] step: 869500, training_loss: 2.64326e-02
I0212 01:56:11.799992 22542570456896 run_lib.py:146] step: 869500, eval_loss: 3.26918e-02
I0212 01:56:29.109589 22542570456896 run_lib.py:133] step: 869550, training_loss: 2.31481e-02
I0212 01:56:46.541026 22542570456896 run_lib.py:133] step: 869600, training_loss: 3.11784e-02
I0212 01:56:46.698504 22542570456896 run_lib.py:146] step: 869600, eval_loss: 2.87682e-02
I0212 01:57:03.954267 22542570456896 run_lib.py:133] step: 869650, training_loss: 3.26969e-02
I0212 01:57:21.223416 22542570456896 run_lib.py:133] step: 869700, training_loss: 2.28015e-02
I0212 01:57:21.377253 22542570456896 run_lib.py:146] step: 869700, eval_loss: 2.80899e-02
I0212 01:57:38.792574 22542570456896 run_lib.py:133] step: 869750, training_loss: 2.94771e-02
I0212 01:57:56.116022 22542570456896 run_lib.py:133] step: 869800, training_loss: 3.61526e-02
I0212 01:57:56.270682 22542570456896 run_lib.py:146] step: 869800, eval_loss: 2.98476e-02
I0212 01:58:13.541246 22542570456896 run_lib.py:133] step: 869850, training_loss: 2.93846e-02
I0212 01:58:30.815666 22542570456896 run_lib.py:133] step: 869900, training_loss: 2.78853e-02
I0212 01:58:30.965353 22542570456896 run_lib.py:146] step: 869900, eval_loss: 2.76741e-02
I0212 01:58:48.404999 22542570456896 run_lib.py:133] step: 869950, training_loss: 2.35871e-02
I0212 01:59:05.684607 22542570456896 run_lib.py:133] step: 870000, training_loss: 2.58089e-02
I0212 01:59:06.399332 22542570456896 run_lib.py:146] step: 870000, eval_loss: 3.20510e-02
I0212 01:59:26.421756 22542570456896 run_lib.py:133] step: 870050, training_loss: 2.93485e-02
I0212 01:59:43.695426 22542570456896 run_lib.py:133] step: 870100, training_loss: 2.94301e-02
I0212 01:59:43.849264 22542570456896 run_lib.py:146] step: 870100, eval_loss: 2.92322e-02
I0212 02:00:01.239903 22542570456896 run_lib.py:133] step: 870150, training_loss: 2.64718e-02
I0212 02:00:18.509942 22542570456896 run_lib.py:133] step: 870200, training_loss: 2.55158e-02
I0212 02:00:18.666547 22542570456896 run_lib.py:146] step: 870200, eval_loss: 2.27148e-02
I0212 02:00:35.943426 22542570456896 run_lib.py:133] step: 870250, training_loss: 3.04052e-02
I0212 02:00:53.370423 22542570456896 run_lib.py:133] step: 870300, training_loss: 2.59540e-02
I0212 02:00:53.539317 22542570456896 run_lib.py:146] step: 870300, eval_loss: 2.85875e-02
I0212 02:01:10.838096 22542570456896 run_lib.py:133] step: 870350, training_loss: 3.07674e-02
I0212 02:01:28.098700 22542570456896 run_lib.py:133] step: 870400, training_loss: 3.22870e-02
I0212 02:01:28.251078 22542570456896 run_lib.py:146] step: 870400, eval_loss: 2.33551e-02
I0212 02:01:45.537767 22542570456896 run_lib.py:133] step: 870450, training_loss: 2.69500e-02
I0212 02:02:02.962612 22542570456896 run_lib.py:133] step: 870500, training_loss: 2.92841e-02
I0212 02:02:03.112421 22542570456896 run_lib.py:146] step: 870500, eval_loss: 3.40858e-02
I0212 02:02:20.401790 22542570456896 run_lib.py:133] step: 870550, training_loss: 3.57799e-02
I0212 02:02:37.718598 22542570456896 run_lib.py:133] step: 870600, training_loss: 2.29150e-02
I0212 02:02:37.893377 22542570456896 run_lib.py:146] step: 870600, eval_loss: 2.58771e-02
I0212 02:02:55.188440 22542570456896 run_lib.py:133] step: 870650, training_loss: 2.34866e-02
I0212 02:03:12.473573 22542570456896 run_lib.py:133] step: 870700, training_loss: 2.53072e-02
I0212 02:03:12.628407 22542570456896 run_lib.py:146] step: 870700, eval_loss: 3.09417e-02
I0212 02:03:30.065147 22542570456896 run_lib.py:133] step: 870750, training_loss: 2.51515e-02
I0212 02:03:47.326817 22542570456896 run_lib.py:133] step: 870800, training_loss: 2.71238e-02
I0212 02:03:47.480422 22542570456896 run_lib.py:146] step: 870800, eval_loss: 2.58021e-02
I0212 02:04:04.767002 22542570456896 run_lib.py:133] step: 870850, training_loss: 2.27010e-02
I0212 02:04:22.113712 22542570456896 run_lib.py:133] step: 870900, training_loss: 2.23523e-02
I0212 02:04:22.265116 22542570456896 run_lib.py:146] step: 870900, eval_loss: 3.22899e-02
I0212 02:04:39.738500 22542570456896 run_lib.py:133] step: 870950, training_loss: 3.13683e-02
I0212 02:04:56.992507 22542570456896 run_lib.py:133] step: 871000, training_loss: 2.45509e-02
I0212 02:04:57.145278 22542570456896 run_lib.py:146] step: 871000, eval_loss: 2.67680e-02
I0212 02:05:14.523972 22542570456896 run_lib.py:133] step: 871050, training_loss: 1.80595e-02
I0212 02:05:31.798828 22542570456896 run_lib.py:133] step: 871100, training_loss: 2.56196e-02
I0212 02:05:31.954474 22542570456896 run_lib.py:146] step: 871100, eval_loss: 3.78372e-02
I0212 02:05:49.387486 22542570456896 run_lib.py:133] step: 871150, training_loss: 2.54630e-02
I0212 02:06:06.691659 22542570456896 run_lib.py:133] step: 871200, training_loss: 2.18983e-02
I0212 02:06:06.846549 22542570456896 run_lib.py:146] step: 871200, eval_loss: 2.29940e-02
I0212 02:06:24.134570 22542570456896 run_lib.py:133] step: 871250, training_loss: 3.15198e-02
I0212 02:06:41.545006 22542570456896 run_lib.py:133] step: 871300, training_loss: 3.33365e-02
I0212 02:06:41.698527 22542570456896 run_lib.py:146] step: 871300, eval_loss: 3.20293e-02
I0212 02:06:58.997545 22542570456896 run_lib.py:133] step: 871350, training_loss: 2.91504e-02
I0212 02:07:16.365374 22542570456896 run_lib.py:133] step: 871400, training_loss: 2.63679e-02
I0212 02:07:16.517106 22542570456896 run_lib.py:146] step: 871400, eval_loss: 2.46831e-02
I0212 02:07:33.881800 22542570456896 run_lib.py:133] step: 871450, training_loss: 2.63561e-02
I0212 02:07:51.113277 22542570456896 run_lib.py:133] step: 871500, training_loss: 2.43167e-02
I0212 02:07:51.267627 22542570456896 run_lib.py:146] step: 871500, eval_loss: 2.53013e-02
I0212 02:08:08.692071 22542570456896 run_lib.py:133] step: 871550, training_loss: 2.60855e-02
I0212 02:08:25.965557 22542570456896 run_lib.py:133] step: 871600, training_loss: 2.37889e-02
I0212 02:08:26.122548 22542570456896 run_lib.py:146] step: 871600, eval_loss: 2.37804e-02
I0212 02:08:43.336803 22542570456896 run_lib.py:133] step: 871650, training_loss: 2.73488e-02
I0212 02:09:00.578717 22542570456896 run_lib.py:133] step: 871700, training_loss: 2.83989e-02
I0212 02:09:00.748264 22542570456896 run_lib.py:146] step: 871700, eval_loss: 2.98516e-02
I0212 02:09:18.155955 22542570456896 run_lib.py:133] step: 871750, training_loss: 2.55866e-02
I0212 02:09:35.438090 22542570456896 run_lib.py:133] step: 871800, training_loss: 3.01352e-02
I0212 02:09:35.591506 22542570456896 run_lib.py:146] step: 871800, eval_loss: 2.60550e-02
I0212 02:09:53.014572 22542570456896 run_lib.py:133] step: 871850, training_loss: 2.07848e-02
I0212 02:10:10.287949 22542570456896 run_lib.py:133] step: 871900, training_loss: 2.58654e-02
I0212 02:10:10.437255 22542570456896 run_lib.py:146] step: 871900, eval_loss: 2.48917e-02
I0212 02:10:27.667649 22542570456896 run_lib.py:133] step: 871950, training_loss: 2.74664e-02
I0212 02:10:44.949933 22542570456896 run_lib.py:133] step: 872000, training_loss: 2.83677e-02
I0212 02:10:45.113314 22542570456896 run_lib.py:146] step: 872000, eval_loss: 2.95002e-02
I0212 02:11:02.608350 22542570456896 run_lib.py:133] step: 872050, training_loss: 3.43468e-02
I0212 02:11:19.945146 22542570456896 run_lib.py:133] step: 872100, training_loss: 2.67008e-02
I0212 02:11:20.101608 22542570456896 run_lib.py:146] step: 872100, eval_loss: 2.38164e-02
I0212 02:11:37.375578 22542570456896 run_lib.py:133] step: 872150, training_loss: 3.61586e-02
I0212 02:11:54.613515 22542570456896 run_lib.py:133] step: 872200, training_loss: 2.72253e-02
I0212 02:11:54.767037 22542570456896 run_lib.py:146] step: 872200, eval_loss: 2.93745e-02
I0212 02:12:12.133007 22542570456896 run_lib.py:133] step: 872250, training_loss: 2.30007e-02
I0212 02:12:29.430737 22542570456896 run_lib.py:133] step: 872300, training_loss: 2.43064e-02
I0212 02:12:29.584069 22542570456896 run_lib.py:146] step: 872300, eval_loss: 3.43147e-02
I0212 02:12:47.042904 22542570456896 run_lib.py:133] step: 872350, training_loss: 2.48619e-02
I0212 02:13:04.291246 22542570456896 run_lib.py:133] step: 872400, training_loss: 1.91101e-02
I0212 02:13:04.449268 22542570456896 run_lib.py:146] step: 872400, eval_loss: 2.32348e-02
I0212 02:13:21.841485 22542570456896 run_lib.py:133] step: 872450, training_loss: 2.98992e-02
I0212 02:13:39.182417 22542570456896 run_lib.py:133] step: 872500, training_loss: 2.09901e-02
I0212 02:13:39.344352 22542570456896 run_lib.py:146] step: 872500, eval_loss: 3.08065e-02
I0212 02:13:56.787501 22542570456896 run_lib.py:133] step: 872550, training_loss: 2.60103e-02
I0212 02:14:14.121944 22542570456896 run_lib.py:133] step: 872600, training_loss: 2.52374e-02
I0212 02:14:14.276570 22542570456896 run_lib.py:146] step: 872600, eval_loss: 3.06943e-02
I0212 02:14:31.530603 22542570456896 run_lib.py:133] step: 872650, training_loss: 2.39859e-02
I0212 02:14:48.947370 22542570456896 run_lib.py:133] step: 872700, training_loss: 2.67318e-02
I0212 02:14:49.101271 22542570456896 run_lib.py:146] step: 872700, eval_loss: 2.54016e-02
I0212 02:15:06.378940 22542570456896 run_lib.py:133] step: 872750, training_loss: 2.63109e-02
I0212 02:15:23.634845 22542570456896 run_lib.py:133] step: 872800, training_loss: 2.46234e-02
I0212 02:15:23.793091 22542570456896 run_lib.py:146] step: 872800, eval_loss: 2.51347e-02
I0212 02:15:41.304311 22542570456896 run_lib.py:133] step: 872850, training_loss: 3.02045e-02
I0212 02:15:58.748543 22542570456896 run_lib.py:133] step: 872900, training_loss: 2.67890e-02
I0212 02:15:58.902925 22542570456896 run_lib.py:146] step: 872900, eval_loss: 2.80322e-02
I0212 02:16:16.161891 22542570456896 run_lib.py:133] step: 872950, training_loss: 2.49211e-02
I0212 02:16:33.456239 22542570456896 run_lib.py:133] step: 873000, training_loss: 2.21574e-02
I0212 02:16:33.613560 22542570456896 run_lib.py:146] step: 873000, eval_loss: 3.40961e-02
I0212 02:16:50.881842 22542570456896 run_lib.py:133] step: 873050, training_loss: 3.00576e-02
I0212 02:17:08.289368 22542570456896 run_lib.py:133] step: 873100, training_loss: 2.43563e-02
I0212 02:17:08.456338 22542570456896 run_lib.py:146] step: 873100, eval_loss: 2.69015e-02
I0212 02:17:25.733570 22542570456896 run_lib.py:133] step: 873150, training_loss: 2.15378e-02
I0212 02:17:43.022358 22542570456896 run_lib.py:133] step: 873200, training_loss: 2.43498e-02
I0212 02:17:43.184263 22542570456896 run_lib.py:146] step: 873200, eval_loss: 2.49878e-02
I0212 02:18:00.457109 22542570456896 run_lib.py:133] step: 873250, training_loss: 2.38059e-02
I0212 02:18:17.881009 22542570456896 run_lib.py:133] step: 873300, training_loss: 2.79811e-02
I0212 02:18:18.030401 22542570456896 run_lib.py:146] step: 873300, eval_loss: 3.03970e-02
I0212 02:18:35.280611 22542570456896 run_lib.py:133] step: 873350, training_loss: 2.57468e-02
I0212 02:18:52.637678 22542570456896 run_lib.py:133] step: 873400, training_loss: 2.89979e-02
I0212 02:18:52.804483 22542570456896 run_lib.py:146] step: 873400, eval_loss: 2.52102e-02
I0212 02:19:10.101202 22542570456896 run_lib.py:133] step: 873450, training_loss: 2.43135e-02
I0212 02:19:27.410068 22542570456896 run_lib.py:133] step: 873500, training_loss: 2.98073e-02
I0212 02:19:27.566549 22542570456896 run_lib.py:146] step: 873500, eval_loss: 2.61654e-02
I0212 02:19:45.003512 22542570456896 run_lib.py:133] step: 873550, training_loss: 2.30980e-02
I0212 02:20:02.314593 22542570456896 run_lib.py:133] step: 873600, training_loss: 2.50397e-02
I0212 02:20:02.468363 22542570456896 run_lib.py:146] step: 873600, eval_loss: 3.43073e-02
I0212 02:20:19.708957 22542570456896 run_lib.py:133] step: 873650, training_loss: 2.47004e-02
I0212 02:20:37.069442 22542570456896 run_lib.py:133] step: 873700, training_loss: 3.41896e-02
I0212 02:20:37.228523 22542570456896 run_lib.py:146] step: 873700, eval_loss: 2.88461e-02
I0212 02:20:54.680768 22542570456896 run_lib.py:133] step: 873750, training_loss: 2.65190e-02
I0212 02:21:11.948467 22542570456896 run_lib.py:133] step: 873800, training_loss: 2.48469e-02
I0212 02:21:12.099260 22542570456896 run_lib.py:146] step: 873800, eval_loss: 2.18523e-02
I0212 02:21:29.476713 22542570456896 run_lib.py:133] step: 873850, training_loss: 2.51645e-02
I0212 02:21:46.781772 22542570456896 run_lib.py:133] step: 873900, training_loss: 2.38036e-02
I0212 02:21:46.935218 22542570456896 run_lib.py:146] step: 873900, eval_loss: 2.91021e-02
I0212 02:22:04.400035 22542570456896 run_lib.py:133] step: 873950, training_loss: 2.82290e-02
I0212 02:22:21.717208 22542570456896 run_lib.py:133] step: 874000, training_loss: 2.23792e-02
I0212 02:22:21.874212 22542570456896 run_lib.py:146] step: 874000, eval_loss: 2.45130e-02
I0212 02:22:39.122425 22542570456896 run_lib.py:133] step: 874050, training_loss: 2.33888e-02
I0212 02:22:56.532366 22542570456896 run_lib.py:133] step: 874100, training_loss: 2.99562e-02
I0212 02:22:56.681798 22542570456896 run_lib.py:146] step: 874100, eval_loss: 3.27177e-02
I0212 02:23:13.920691 22542570456896 run_lib.py:133] step: 874150, training_loss: 1.83142e-02
I0212 02:23:31.403436 22542570456896 run_lib.py:133] step: 874200, training_loss: 2.02955e-02
I0212 02:23:31.558364 22542570456896 run_lib.py:146] step: 874200, eval_loss: 2.33318e-02
I0212 02:23:48.930465 22542570456896 run_lib.py:133] step: 874250, training_loss: 1.91160e-02
I0212 02:24:06.307558 22542570456896 run_lib.py:133] step: 874300, training_loss: 2.61724e-02
I0212 02:24:06.460556 22542570456896 run_lib.py:146] step: 874300, eval_loss: 2.52998e-02
I0212 02:24:23.911702 22542570456896 run_lib.py:133] step: 874350, training_loss: 3.38273e-02
I0212 02:24:41.191214 22542570456896 run_lib.py:133] step: 874400, training_loss: 2.42168e-02
I0212 02:24:41.348518 22542570456896 run_lib.py:146] step: 874400, eval_loss: 3.62283e-02
I0212 02:24:58.620719 22542570456896 run_lib.py:133] step: 874450, training_loss: 2.23863e-02
I0212 02:25:16.031640 22542570456896 run_lib.py:133] step: 874500, training_loss: 2.40669e-02
I0212 02:25:16.204305 22542570456896 run_lib.py:146] step: 874500, eval_loss: 3.28823e-02
I0212 02:25:33.584820 22542570456896 run_lib.py:133] step: 874550, training_loss: 3.79631e-02
I0212 02:25:50.944913 22542570456896 run_lib.py:133] step: 874600, training_loss: 2.51982e-02
I0212 02:25:51.105106 22542570456896 run_lib.py:146] step: 874600, eval_loss: 2.58834e-02
I0212 02:26:08.514576 22542570456896 run_lib.py:133] step: 874650, training_loss: 2.66428e-02
I0212 02:26:25.775228 22542570456896 run_lib.py:133] step: 874700, training_loss: 2.21474e-02
I0212 02:26:25.932436 22542570456896 run_lib.py:146] step: 874700, eval_loss: 3.35081e-02
I0212 02:26:43.197173 22542570456896 run_lib.py:133] step: 874750, training_loss: 3.20440e-02
I0212 02:27:00.471421 22542570456896 run_lib.py:133] step: 874800, training_loss: 2.18552e-02
I0212 02:27:00.636659 22542570456896 run_lib.py:146] step: 874800, eval_loss: 3.84891e-02
I0212 02:27:18.124065 22542570456896 run_lib.py:133] step: 874850, training_loss: 2.60476e-02
I0212 02:27:35.499989 22542570456896 run_lib.py:133] step: 874900, training_loss: 2.67930e-02
I0212 02:27:35.653277 22542570456896 run_lib.py:146] step: 874900, eval_loss: 3.41687e-02
I0212 02:27:52.894348 22542570456896 run_lib.py:133] step: 874950, training_loss: 2.73347e-02
I0212 02:28:10.155431 22542570456896 run_lib.py:133] step: 875000, training_loss: 2.40921e-02
I0212 02:28:10.311325 22542570456896 run_lib.py:146] step: 875000, eval_loss: 3.27929e-02
I0212 02:28:27.740984 22542570456896 run_lib.py:133] step: 875050, training_loss: 3.43464e-02
I0212 02:28:45.037903 22542570456896 run_lib.py:133] step: 875100, training_loss: 2.04756e-02
I0212 02:28:45.192491 22542570456896 run_lib.py:146] step: 875100, eval_loss: 2.73461e-02
I0212 02:29:02.702665 22542570456896 run_lib.py:133] step: 875150, training_loss: 2.44450e-02
I0212 02:29:20.043088 22542570456896 run_lib.py:133] step: 875200, training_loss: 2.38926e-02
I0212 02:29:20.193444 22542570456896 run_lib.py:146] step: 875200, eval_loss: 2.85970e-02
I0212 02:29:37.695373 22542570456896 run_lib.py:133] step: 875250, training_loss: 2.96464e-02
I0212 02:29:55.159498 22542570456896 run_lib.py:133] step: 875300, training_loss: 2.66751e-02
I0212 02:29:55.317600 22542570456896 run_lib.py:146] step: 875300, eval_loss: 3.18701e-02
I0212 02:30:12.957983 22542570456896 run_lib.py:133] step: 875350, training_loss: 3.31842e-02
I0212 02:30:30.507893 22542570456896 run_lib.py:133] step: 875400, training_loss: 3.60980e-02
I0212 02:30:30.673585 22542570456896 run_lib.py:146] step: 875400, eval_loss: 3.64071e-02
I0212 02:30:48.209169 22542570456896 run_lib.py:133] step: 875450, training_loss: 2.28441e-02
I0212 02:31:05.908220 22542570456896 run_lib.py:133] step: 875500, training_loss: 2.30431e-02
I0212 02:31:06.065895 22542570456896 run_lib.py:146] step: 875500, eval_loss: 3.65924e-02
I0212 02:31:23.581970 22542570456896 run_lib.py:133] step: 875550, training_loss: 2.76295e-02
I0212 02:31:41.055182 22542570456896 run_lib.py:133] step: 875600, training_loss: 2.57485e-02
I0212 02:31:41.220517 22542570456896 run_lib.py:146] step: 875600, eval_loss: 2.69950e-02
I0212 02:31:58.889037 22542570456896 run_lib.py:133] step: 875650, training_loss: 3.06751e-02
I0212 02:32:16.374062 22542570456896 run_lib.py:133] step: 875700, training_loss: 2.55163e-02
I0212 02:32:16.528769 22542570456896 run_lib.py:146] step: 875700, eval_loss: 2.42657e-02
I0212 02:32:34.228381 22542570456896 run_lib.py:133] step: 875750, training_loss: 2.70540e-02
I0212 02:32:51.707611 22542570456896 run_lib.py:133] step: 875800, training_loss: 3.12209e-02
I0212 02:32:51.864401 22542570456896 run_lib.py:146] step: 875800, eval_loss: 2.82675e-02
I0212 02:33:09.311261 22542570456896 run_lib.py:133] step: 875850, training_loss: 2.42143e-02
I0212 02:33:27.000710 22542570456896 run_lib.py:133] step: 875900, training_loss: 3.00810e-02
I0212 02:33:27.157613 22542570456896 run_lib.py:146] step: 875900, eval_loss: 3.38264e-02
I0212 02:33:44.672139 22542570456896 run_lib.py:133] step: 875950, training_loss: 2.99717e-02
I0212 02:34:02.215702 22542570456896 run_lib.py:133] step: 876000, training_loss: 2.33922e-02
I0212 02:34:02.382245 22542570456896 run_lib.py:146] step: 876000, eval_loss: 2.57903e-02
I0212 02:34:19.887334 22542570456896 run_lib.py:133] step: 876050, training_loss: 2.69934e-02
I0212 02:34:37.535964 22542570456896 run_lib.py:133] step: 876100, training_loss: 2.46477e-02
I0212 02:34:37.693509 22542570456896 run_lib.py:146] step: 876100, eval_loss: 2.90011e-02
I0212 02:34:55.179230 22542570456896 run_lib.py:133] step: 876150, training_loss: 2.75248e-02
I0212 02:35:12.695867 22542570456896 run_lib.py:133] step: 876200, training_loss: 2.87548e-02
I0212 02:35:12.852357 22542570456896 run_lib.py:146] step: 876200, eval_loss: 2.86045e-02
I0212 02:35:30.326438 22542570456896 run_lib.py:133] step: 876250, training_loss: 2.29158e-02
I0212 02:35:47.816875 22542570456896 run_lib.py:133] step: 876300, training_loss: 3.07609e-02
I0212 02:35:47.993294 22542570456896 run_lib.py:146] step: 876300, eval_loss: 3.06332e-02
I0212 02:36:05.682292 22542570456896 run_lib.py:133] step: 876350, training_loss: 3.48745e-02
I0212 02:36:23.250471 22542570456896 run_lib.py:133] step: 876400, training_loss: 2.73258e-02
I0212 02:36:23.407839 22542570456896 run_lib.py:146] step: 876400, eval_loss: 3.13902e-02
I0212 02:36:40.881974 22542570456896 run_lib.py:133] step: 876450, training_loss: 2.76669e-02
I0212 02:36:58.338630 22542570456896 run_lib.py:133] step: 876500, training_loss: 3.56861e-02
I0212 02:36:58.495255 22542570456896 run_lib.py:146] step: 876500, eval_loss: 2.94678e-02
I0212 02:37:16.141977 22542570456896 run_lib.py:133] step: 876550, training_loss: 2.91200e-02
I0212 02:37:33.698539 22542570456896 run_lib.py:133] step: 876600, training_loss: 3.62032e-02
I0212 02:37:33.853210 22542570456896 run_lib.py:146] step: 876600, eval_loss: 3.18880e-02
I0212 02:37:51.581440 22542570456896 run_lib.py:133] step: 876650, training_loss: 2.80130e-02
I0212 02:38:09.066088 22542570456896 run_lib.py:133] step: 876700, training_loss: 3.24258e-02
I0212 02:38:09.222372 22542570456896 run_lib.py:146] step: 876700, eval_loss: 3.27731e-02
I0212 02:38:26.871777 22542570456896 run_lib.py:133] step: 876750, training_loss: 2.13505e-02
I0212 02:38:44.352893 22542570456896 run_lib.py:133] step: 876800, training_loss: 2.73115e-02
I0212 02:38:44.525534 22542570456896 run_lib.py:146] step: 876800, eval_loss: 2.32349e-02
I0212 02:39:02.039041 22542570456896 run_lib.py:133] step: 876850, training_loss: 3.10027e-02
I0212 02:39:19.753879 22542570456896 run_lib.py:133] step: 876900, training_loss: 2.54105e-02
I0212 02:39:19.920509 22542570456896 run_lib.py:146] step: 876900, eval_loss: 2.85510e-02
I0212 02:39:37.403257 22542570456896 run_lib.py:133] step: 876950, training_loss: 2.63199e-02
I0212 02:39:55.012812 22542570456896 run_lib.py:133] step: 877000, training_loss: 2.36018e-02
I0212 02:39:55.169546 22542570456896 run_lib.py:146] step: 877000, eval_loss: 2.99734e-02
I0212 02:40:12.602818 22542570456896 run_lib.py:133] step: 877050, training_loss: 2.25137e-02
I0212 02:40:30.117398 22542570456896 run_lib.py:133] step: 877100, training_loss: 2.46873e-02
I0212 02:40:30.273645 22542570456896 run_lib.py:146] step: 877100, eval_loss: 2.70798e-02
I0212 02:40:47.983614 22542570456896 run_lib.py:133] step: 877150, training_loss: 2.37055e-02
I0212 02:41:05.456754 22542570456896 run_lib.py:133] step: 877200, training_loss: 2.46656e-02
I0212 02:41:05.623920 22542570456896 run_lib.py:146] step: 877200, eval_loss: 2.75320e-02
I0212 02:41:23.116173 22542570456896 run_lib.py:133] step: 877250, training_loss: 2.88147e-02
I0212 02:41:40.820740 22542570456896 run_lib.py:133] step: 877300, training_loss: 2.25426e-02
I0212 02:41:40.983695 22542570456896 run_lib.py:146] step: 877300, eval_loss: 2.40777e-02
I0212 02:41:58.501193 22542570456896 run_lib.py:133] step: 877350, training_loss: 2.88202e-02
I0212 02:42:16.006103 22542570456896 run_lib.py:133] step: 877400, training_loss: 3.21253e-02
I0212 02:42:16.321616 22542570456896 run_lib.py:146] step: 877400, eval_loss: 2.84409e-02
I0212 02:42:33.791097 22542570456896 run_lib.py:133] step: 877450, training_loss: 2.19541e-02
I0212 02:42:51.246325 22542570456896 run_lib.py:133] step: 877500, training_loss: 2.14373e-02
I0212 02:42:51.403551 22542570456896 run_lib.py:146] step: 877500, eval_loss: 2.07164e-02
I0212 02:43:08.862310 22542570456896 run_lib.py:133] step: 877550, training_loss: 2.80268e-02
I0212 02:43:26.346334 22542570456896 run_lib.py:133] step: 877600, training_loss: 2.66693e-02
I0212 02:43:26.499213 22542570456896 run_lib.py:146] step: 877600, eval_loss: 3.45312e-02
I0212 02:43:44.143852 22542570456896 run_lib.py:133] step: 877650, training_loss: 3.00732e-02
I0212 02:44:01.758457 22542570456896 run_lib.py:133] step: 877700, training_loss: 2.21431e-02
I0212 02:44:01.932539 22542570456896 run_lib.py:146] step: 877700, eval_loss: 2.78522e-02
I0212 02:44:19.427374 22542570456896 run_lib.py:133] step: 877750, training_loss: 2.43762e-02
I0212 02:44:36.883028 22542570456896 run_lib.py:133] step: 877800, training_loss: 2.44729e-02
I0212 02:44:37.041699 22542570456896 run_lib.py:146] step: 877800, eval_loss: 2.72053e-02
I0212 02:44:54.716601 22542570456896 run_lib.py:133] step: 877850, training_loss: 2.80310e-02
I0212 02:45:12.240179 22542570456896 run_lib.py:133] step: 877900, training_loss: 2.16023e-02
I0212 02:45:12.407525 22542570456896 run_lib.py:146] step: 877900, eval_loss: 2.80574e-02
I0212 02:45:29.948889 22542570456896 run_lib.py:133] step: 877950, training_loss: 2.42237e-02
I0212 02:45:47.434037 22542570456896 run_lib.py:133] step: 878000, training_loss: 3.11407e-02
I0212 02:45:47.590650 22542570456896 run_lib.py:146] step: 878000, eval_loss: 2.60985e-02
I0212 02:46:05.259262 22542570456896 run_lib.py:133] step: 878050, training_loss: 2.90208e-02
I0212 02:46:22.743304 22542570456896 run_lib.py:133] step: 878100, training_loss: 2.41892e-02
I0212 02:46:22.898583 22542570456896 run_lib.py:146] step: 878100, eval_loss: 3.03049e-02
I0212 02:46:40.497038 22542570456896 run_lib.py:133] step: 878150, training_loss: 3.16693e-02
I0212 02:46:58.010160 22542570456896 run_lib.py:133] step: 878200, training_loss: 2.87718e-02
I0212 02:46:58.187446 22542570456896 run_lib.py:146] step: 878200, eval_loss: 3.21426e-02
I0212 02:47:15.883741 22542570456896 run_lib.py:133] step: 878250, training_loss: 2.84169e-02
I0212 02:47:33.417208 22542570456896 run_lib.py:133] step: 878300, training_loss: 2.51845e-02
I0212 02:47:33.574743 22542570456896 run_lib.py:146] step: 878300, eval_loss: 2.96393e-02
I0212 02:47:51.001326 22542570456896 run_lib.py:133] step: 878350, training_loss: 2.56685e-02
I0212 02:48:08.605984 22542570456896 run_lib.py:133] step: 878400, training_loss: 2.77686e-02
I0212 02:48:08.763599 22542570456896 run_lib.py:146] step: 878400, eval_loss: 2.70258e-02
I0212 02:48:26.241179 22542570456896 run_lib.py:133] step: 878450, training_loss: 2.50207e-02
I0212 02:48:43.913930 22542570456896 run_lib.py:133] step: 878500, training_loss: 2.75667e-02
I0212 02:48:44.076245 22542570456896 run_lib.py:146] step: 878500, eval_loss: 2.87090e-02
I0212 02:49:01.601398 22542570456896 run_lib.py:133] step: 878550, training_loss: 2.35631e-02
I0212 02:49:19.054297 22542570456896 run_lib.py:133] step: 878600, training_loss: 3.18980e-02
I0212 02:49:19.213471 22542570456896 run_lib.py:146] step: 878600, eval_loss: 3.43723e-02
I0212 02:49:36.855310 22542570456896 run_lib.py:133] step: 878650, training_loss: 3.48505e-02
I0212 02:49:54.381468 22542570456896 run_lib.py:133] step: 878700, training_loss: 2.68449e-02
I0212 02:49:54.556078 22542570456896 run_lib.py:146] step: 878700, eval_loss: 3.09873e-02
I0212 02:50:12.071831 22542570456896 run_lib.py:133] step: 878750, training_loss: 3.23271e-02
I0212 02:50:29.576113 22542570456896 run_lib.py:133] step: 878800, training_loss: 2.59548e-02
I0212 02:50:29.734653 22542570456896 run_lib.py:146] step: 878800, eval_loss: 3.16411e-02
I0212 02:50:47.415426 22542570456896 run_lib.py:133] step: 878850, training_loss: 3.85221e-02
I0212 02:51:04.882977 22542570456896 run_lib.py:133] step: 878900, training_loss: 2.73368e-02
I0212 02:51:05.040466 22542570456896 run_lib.py:146] step: 878900, eval_loss: 2.68227e-02
I0212 02:51:22.617036 22542570456896 run_lib.py:133] step: 878950, training_loss: 2.37873e-02
I0212 02:51:40.099924 22542570456896 run_lib.py:133] step: 879000, training_loss: 2.23121e-02
I0212 02:51:40.254566 22542570456896 run_lib.py:146] step: 879000, eval_loss: 3.00198e-02
I0212 02:51:57.765735 22542570456896 run_lib.py:133] step: 879050, training_loss: 3.18485e-02
I0212 02:52:15.251448 22542570456896 run_lib.py:133] step: 879100, training_loss: 2.47223e-02
I0212 02:52:15.407511 22542570456896 run_lib.py:146] step: 879100, eval_loss: 2.38652e-02
I0212 02:52:33.073370 22542570456896 run_lib.py:133] step: 879150, training_loss: 2.57712e-02
I0212 02:52:50.600741 22542570456896 run_lib.py:133] step: 879200, training_loss: 2.26582e-02
I0212 02:52:50.760750 22542570456896 run_lib.py:146] step: 879200, eval_loss: 3.27440e-02
I0212 02:53:08.232265 22542570456896 run_lib.py:133] step: 879250, training_loss: 2.99059e-02
I0212 02:53:25.750602 22542570456896 run_lib.py:133] step: 879300, training_loss: 2.97142e-02
I0212 02:53:25.911685 22542570456896 run_lib.py:146] step: 879300, eval_loss: 2.92650e-02
I0212 02:53:43.561810 22542570456896 run_lib.py:133] step: 879350, training_loss: 2.40150e-02
I0212 02:54:01.004185 22542570456896 run_lib.py:133] step: 879400, training_loss: 3.26459e-02
I0212 02:54:01.166483 22542570456896 run_lib.py:146] step: 879400, eval_loss: 3.19735e-02
I0212 02:54:18.790767 22542570456896 run_lib.py:133] step: 879450, training_loss: 3.69614e-02
I0212 02:54:36.246073 22542570456896 run_lib.py:133] step: 879500, training_loss: 3.06833e-02
I0212 02:54:36.398394 22542570456896 run_lib.py:146] step: 879500, eval_loss: 3.37066e-02
I0212 02:54:54.033047 22542570456896 run_lib.py:133] step: 879550, training_loss: 2.66475e-02
I0212 02:55:11.514282 22542570456896 run_lib.py:133] step: 879600, training_loss: 2.64953e-02
I0212 02:55:11.693499 22542570456896 run_lib.py:146] step: 879600, eval_loss: 2.31678e-02
I0212 02:55:29.391344 22542570456896 run_lib.py:133] step: 879650, training_loss: 3.30632e-02
I0212 02:55:46.884024 22542570456896 run_lib.py:133] step: 879700, training_loss: 3.13120e-02
I0212 02:55:47.051516 22542570456896 run_lib.py:146] step: 879700, eval_loss: 2.67026e-02
I0212 02:56:04.523439 22542570456896 run_lib.py:133] step: 879750, training_loss: 3.07397e-02
I0212 02:56:22.169351 22542570456896 run_lib.py:133] step: 879800, training_loss: 3.29089e-02
I0212 02:56:22.329178 22542570456896 run_lib.py:146] step: 879800, eval_loss: 3.14894e-02
I0212 02:56:39.832354 22542570456896 run_lib.py:133] step: 879850, training_loss: 3.20579e-02
I0212 02:56:57.272695 22542570456896 run_lib.py:133] step: 879900, training_loss: 2.99057e-02
I0212 02:56:57.426093 22542570456896 run_lib.py:146] step: 879900, eval_loss: 3.21188e-02
I0212 02:57:15.113952 22542570456896 run_lib.py:133] step: 879950, training_loss: 2.71624e-02
I0212 02:57:32.711680 22542570456896 run_lib.py:133] step: 880000, training_loss: 2.01187e-02
I0212 02:57:33.461220 22542570456896 run_lib.py:146] step: 880000, eval_loss: 3.19220e-02
I0212 02:57:53.579285 22542570456896 run_lib.py:133] step: 880050, training_loss: 3.20344e-02
I0212 02:58:11.162957 22542570456896 run_lib.py:133] step: 880100, training_loss: 3.11293e-02
I0212 02:58:11.332641 22542570456896 run_lib.py:146] step: 880100, eval_loss: 2.57353e-02
I0212 02:58:28.822173 22542570456896 run_lib.py:133] step: 880150, training_loss: 2.87955e-02
I0212 02:58:46.306787 22542570456896 run_lib.py:133] step: 880200, training_loss: 2.53561e-02
I0212 02:58:46.463572 22542570456896 run_lib.py:146] step: 880200, eval_loss: 3.15283e-02
I0212 02:59:04.119381 22542570456896 run_lib.py:133] step: 880250, training_loss: 2.78554e-02
I0212 02:59:21.567511 22542570456896 run_lib.py:133] step: 880300, training_loss: 2.91132e-02
I0212 02:59:21.722392 22542570456896 run_lib.py:146] step: 880300, eval_loss: 2.45435e-02
I0212 02:59:39.076458 22542570456896 run_lib.py:133] step: 880350, training_loss: 2.68826e-02
I0212 02:59:56.496067 22542570456896 run_lib.py:133] step: 880400, training_loss: 2.64319e-02
I0212 02:59:56.653495 22542570456896 run_lib.py:146] step: 880400, eval_loss: 2.52661e-02
I0212 03:00:14.241063 22542570456896 run_lib.py:133] step: 880450, training_loss: 2.54575e-02
I0212 03:00:31.629567 22542570456896 run_lib.py:133] step: 880500, training_loss: 2.52669e-02
I0212 03:00:31.784260 22542570456896 run_lib.py:146] step: 880500, eval_loss: 3.46191e-02
I0212 03:00:49.246844 22542570456896 run_lib.py:133] step: 880550, training_loss: 2.86398e-02
I0212 03:01:06.614364 22542570456896 run_lib.py:133] step: 880600, training_loss: 2.99629e-02
I0212 03:01:06.783485 22542570456896 run_lib.py:146] step: 880600, eval_loss: 2.79413e-02
I0212 03:01:24.437177 22542570456896 run_lib.py:133] step: 880650, training_loss: 2.28019e-02
I0212 03:01:41.818669 22542570456896 run_lib.py:133] step: 880700, training_loss: 3.03535e-02
I0212 03:01:41.976379 22542570456896 run_lib.py:146] step: 880700, eval_loss: 2.92371e-02
I0212 03:01:59.444663 22542570456896 run_lib.py:133] step: 880750, training_loss: 2.53732e-02
I0212 03:02:17.071973 22542570456896 run_lib.py:133] step: 880800, training_loss: 2.73496e-02
I0212 03:02:17.229522 22542570456896 run_lib.py:146] step: 880800, eval_loss: 3.20021e-02
I0212 03:02:34.721852 22542570456896 run_lib.py:133] step: 880850, training_loss: 2.67518e-02
I0212 03:02:52.369594 22542570456896 run_lib.py:133] step: 880900, training_loss: 2.92779e-02
I0212 03:02:52.524537 22542570456896 run_lib.py:146] step: 880900, eval_loss: 3.66015e-02
I0212 03:03:10.060551 22542570456896 run_lib.py:133] step: 880950, training_loss: 2.78104e-02
I0212 03:03:27.523786 22542570456896 run_lib.py:133] step: 881000, training_loss: 2.95018e-02
I0212 03:03:27.677548 22542570456896 run_lib.py:146] step: 881000, eval_loss: 2.80889e-02
I0212 03:03:45.365406 22542570456896 run_lib.py:133] step: 881050, training_loss: 2.42096e-02
I0212 03:04:02.829891 22542570456896 run_lib.py:133] step: 881100, training_loss: 2.88878e-02
I0212 03:04:02.996323 22542570456896 run_lib.py:146] step: 881100, eval_loss: 3.00875e-02
I0212 03:04:20.409078 22542570456896 run_lib.py:133] step: 881150, training_loss: 2.62832e-02
I0212 03:04:38.078824 22542570456896 run_lib.py:133] step: 881200, training_loss: 2.86145e-02
I0212 03:04:38.242370 22542570456896 run_lib.py:146] step: 881200, eval_loss: 2.70924e-02
I0212 03:04:55.761539 22542570456896 run_lib.py:133] step: 881250, training_loss: 2.63889e-02
I0212 03:05:13.291402 22542570456896 run_lib.py:133] step: 881300, training_loss: 2.30170e-02
I0212 03:05:13.448184 22542570456896 run_lib.py:146] step: 881300, eval_loss: 2.64834e-02
I0212 03:05:31.062250 22542570456896 run_lib.py:133] step: 881350, training_loss: 2.54824e-02
I0212 03:05:48.539147 22542570456896 run_lib.py:133] step: 881400, training_loss: 3.33409e-02
I0212 03:05:48.694404 22542570456896 run_lib.py:146] step: 881400, eval_loss: 3.32325e-02
I0212 03:06:06.218958 22542570456896 run_lib.py:133] step: 881450, training_loss: 2.92437e-02
I0212 03:06:23.744334 22542570456896 run_lib.py:133] step: 881500, training_loss: 2.39861e-02
I0212 03:06:23.899597 22542570456896 run_lib.py:146] step: 881500, eval_loss: 3.14359e-02
I0212 03:06:41.598199 22542570456896 run_lib.py:133] step: 881550, training_loss: 2.91883e-02
I0212 03:06:59.183124 22542570456896 run_lib.py:133] step: 881600, training_loss: 2.71324e-02
I0212 03:06:59.349634 22542570456896 run_lib.py:146] step: 881600, eval_loss: 2.11267e-02
I0212 03:07:16.808873 22542570456896 run_lib.py:133] step: 881650, training_loss: 2.46267e-02
I0212 03:07:34.269199 22542570456896 run_lib.py:133] step: 881700, training_loss: 2.48625e-02
I0212 03:07:34.433460 22542570456896 run_lib.py:146] step: 881700, eval_loss: 3.69887e-02
I0212 03:07:52.095263 22542570456896 run_lib.py:133] step: 881750, training_loss: 2.78543e-02
I0212 03:08:09.591112 22542570456896 run_lib.py:133] step: 881800, training_loss: 2.37404e-02
I0212 03:08:09.752646 22542570456896 run_lib.py:146] step: 881800, eval_loss: 3.32228e-02
I0212 03:08:27.451300 22542570456896 run_lib.py:133] step: 881850, training_loss: 2.58156e-02
I0212 03:08:44.940225 22542570456896 run_lib.py:133] step: 881900, training_loss: 2.67086e-02
I0212 03:08:45.094473 22542570456896 run_lib.py:146] step: 881900, eval_loss: 3.22039e-02
I0212 03:09:02.710772 22542570456896 run_lib.py:133] step: 881950, training_loss: 2.56386e-02
I0212 03:09:20.243367 22542570456896 run_lib.py:133] step: 882000, training_loss: 3.10204e-02
I0212 03:09:20.414618 22542570456896 run_lib.py:146] step: 882000, eval_loss: 3.55777e-02
I0212 03:09:38.101426 22542570456896 run_lib.py:133] step: 882050, training_loss: 2.68809e-02
I0212 03:09:55.573555 22542570456896 run_lib.py:133] step: 882100, training_loss: 3.04975e-02
I0212 03:09:55.732448 22542570456896 run_lib.py:146] step: 882100, eval_loss: 3.23047e-02
I0212 03:10:13.168803 22542570456896 run_lib.py:133] step: 882150, training_loss: 1.95124e-02
I0212 03:10:30.764929 22542570456896 run_lib.py:133] step: 882200, training_loss: 2.55330e-02
I0212 03:10:30.923541 22542570456896 run_lib.py:146] step: 882200, eval_loss: 2.83196e-02
I0212 03:10:48.411270 22542570456896 run_lib.py:133] step: 882250, training_loss: 2.35832e-02
I0212 03:11:05.893696 22542570456896 run_lib.py:133] step: 882300, training_loss: 2.90006e-02
I0212 03:11:06.057687 22542570456896 run_lib.py:146] step: 882300, eval_loss: 3.40937e-02
I0212 03:11:23.728779 22542570456896 run_lib.py:133] step: 882350, training_loss: 2.62375e-02
I0212 03:11:41.203813 22542570456896 run_lib.py:133] step: 882400, training_loss: 2.26768e-02
I0212 03:11:41.357475 22542570456896 run_lib.py:146] step: 882400, eval_loss: 3.43428e-02
I0212 03:11:59.017271 22542570456896 run_lib.py:133] step: 882450, training_loss: 2.62696e-02
I0212 03:12:16.507190 22542570456896 run_lib.py:133] step: 882500, training_loss: 2.50203e-02
I0212 03:12:16.667412 22542570456896 run_lib.py:146] step: 882500, eval_loss: 2.97820e-02
I0212 03:12:34.143637 22542570456896 run_lib.py:133] step: 882550, training_loss: 3.10215e-02
I0212 03:12:51.837293 22542570456896 run_lib.py:133] step: 882600, training_loss: 2.35410e-02
I0212 03:12:52.015583 22542570456896 run_lib.py:146] step: 882600, eval_loss: 3.39462e-02
I0212 03:13:09.509650 22542570456896 run_lib.py:133] step: 882650, training_loss: 2.20049e-02
I0212 03:13:26.999498 22542570456896 run_lib.py:133] step: 882700, training_loss: 2.90256e-02
I0212 03:13:27.156723 22542570456896 run_lib.py:146] step: 882700, eval_loss: 2.73497e-02
I0212 03:13:44.672659 22542570456896 run_lib.py:133] step: 882750, training_loss: 3.00415e-02
I0212 03:14:02.345323 22542570456896 run_lib.py:133] step: 882800, training_loss: 2.60673e-02
I0212 03:14:02.509089 22542570456896 run_lib.py:146] step: 882800, eval_loss: 2.79830e-02
I0212 03:14:19.981171 22542570456896 run_lib.py:133] step: 882850, training_loss: 2.85472e-02
I0212 03:14:37.578090 22542570456896 run_lib.py:133] step: 882900, training_loss: 3.02945e-02
I0212 03:14:37.733757 22542570456896 run_lib.py:146] step: 882900, eval_loss: 3.01833e-02
I0212 03:14:55.228005 22542570456896 run_lib.py:133] step: 882950, training_loss: 3.27471e-02
I0212 03:15:12.717857 22542570456896 run_lib.py:133] step: 883000, training_loss: 2.96633e-02
I0212 03:15:12.884681 22542570456896 run_lib.py:146] step: 883000, eval_loss: 3.23676e-02
I0212 03:15:30.538540 22542570456896 run_lib.py:133] step: 883050, training_loss: 2.45771e-02
I0212 03:15:48.056419 22542570456896 run_lib.py:133] step: 883100, training_loss: 3.02917e-02
I0212 03:15:48.215556 22542570456896 run_lib.py:146] step: 883100, eval_loss: 2.64106e-02
I0212 03:16:05.670480 22542570456896 run_lib.py:133] step: 883150, training_loss: 2.75809e-02
I0212 03:16:23.232776 22542570456896 run_lib.py:133] step: 883200, training_loss: 2.46375e-02
I0212 03:16:23.393775 22542570456896 run_lib.py:146] step: 883200, eval_loss: 3.00708e-02
I0212 03:16:41.073714 22542570456896 run_lib.py:133] step: 883250, training_loss: 3.00896e-02
I0212 03:16:58.528394 22542570456896 run_lib.py:133] step: 883300, training_loss: 2.73662e-02
I0212 03:16:58.685667 22542570456896 run_lib.py:146] step: 883300, eval_loss: 2.88840e-02
I0212 03:17:16.292726 22542570456896 run_lib.py:133] step: 883350, training_loss: 2.95787e-02
I0212 03:17:33.786905 22542570456896 run_lib.py:133] step: 883400, training_loss: 2.42727e-02
I0212 03:17:33.941773 22542570456896 run_lib.py:146] step: 883400, eval_loss: 2.21485e-02
I0212 03:17:51.578912 22542570456896 run_lib.py:133] step: 883450, training_loss: 2.85715e-02
I0212 03:18:09.079491 22542570456896 run_lib.py:133] step: 883500, training_loss: 2.59594e-02
I0212 03:18:09.242315 22542570456896 run_lib.py:146] step: 883500, eval_loss: 3.36846e-02
I0212 03:18:26.731384 22542570456896 run_lib.py:133] step: 883550, training_loss: 3.07602e-02
I0212 03:18:44.409767 22542570456896 run_lib.py:133] step: 883600, training_loss: 2.85409e-02
I0212 03:18:44.568443 22542570456896 run_lib.py:146] step: 883600, eval_loss: 3.75423e-02
I0212 03:19:02.039052 22542570456896 run_lib.py:133] step: 883650, training_loss: 2.43206e-02
I0212 03:19:19.693500 22542570456896 run_lib.py:133] step: 883700, training_loss: 2.34764e-02
I0212 03:19:19.850273 22542570456896 run_lib.py:146] step: 883700, eval_loss: 3.07012e-02
I0212 03:19:37.375063 22542570456896 run_lib.py:133] step: 883750, training_loss: 2.71122e-02
I0212 03:19:54.823600 22542570456896 run_lib.py:133] step: 883800, training_loss: 3.17751e-02
I0212 03:19:54.976150 22542570456896 run_lib.py:146] step: 883800, eval_loss: 3.42156e-02
I0212 03:20:12.624837 22542570456896 run_lib.py:133] step: 883850, training_loss: 2.90553e-02
I0212 03:20:30.133038 22542570456896 run_lib.py:133] step: 883900, training_loss: 2.68744e-02
I0212 03:20:30.291287 22542570456896 run_lib.py:146] step: 883900, eval_loss: 2.87878e-02
I0212 03:20:47.804610 22542570456896 run_lib.py:133] step: 883950, training_loss: 2.58303e-02
I0212 03:21:05.484770 22542570456896 run_lib.py:133] step: 884000, training_loss: 2.65029e-02
I0212 03:21:05.643161 22542570456896 run_lib.py:146] step: 884000, eval_loss: 3.39768e-02
I0212 03:21:23.102146 22542570456896 run_lib.py:133] step: 884050, training_loss: 2.58248e-02
I0212 03:21:40.573761 22542570456896 run_lib.py:133] step: 884100, training_loss: 3.01572e-02
I0212 03:21:40.920311 22542570456896 run_lib.py:146] step: 884100, eval_loss: 2.68978e-02
I0212 03:21:58.414044 22542570456896 run_lib.py:133] step: 884150, training_loss: 2.85322e-02
I0212 03:22:15.872332 22542570456896 run_lib.py:133] step: 884200, training_loss: 2.22884e-02
I0212 03:22:16.029453 22542570456896 run_lib.py:146] step: 884200, eval_loss: 2.91172e-02
I0212 03:22:33.531956 22542570456896 run_lib.py:133] step: 884250, training_loss: 2.57945e-02
I0212 03:22:51.061681 22542570456896 run_lib.py:133] step: 884300, training_loss: 2.49095e-02
I0212 03:22:51.219657 22542570456896 run_lib.py:146] step: 884300, eval_loss: 2.89216e-02
I0212 03:23:08.915568 22542570456896 run_lib.py:133] step: 884350, training_loss: 3.48604e-02
I0212 03:23:26.505341 22542570456896 run_lib.py:133] step: 884400, training_loss: 2.85334e-02
I0212 03:23:26.664406 22542570456896 run_lib.py:146] step: 884400, eval_loss: 3.29914e-02
I0212 03:23:44.112956 22542570456896 run_lib.py:133] step: 884450, training_loss: 2.78528e-02
I0212 03:24:01.573398 22542570456896 run_lib.py:133] step: 884500, training_loss: 2.51203e-02
I0212 03:24:01.752464 22542570456896 run_lib.py:146] step: 884500, eval_loss: 2.20615e-02
I0212 03:24:19.452365 22542570456896 run_lib.py:133] step: 884550, training_loss: 2.87141e-02
I0212 03:24:37.011305 22542570456896 run_lib.py:133] step: 884600, training_loss: 2.14135e-02
I0212 03:24:37.168134 22542570456896 run_lib.py:146] step: 884600, eval_loss: 3.15561e-02
I0212 03:24:54.640470 22542570456896 run_lib.py:133] step: 884650, training_loss: 2.25968e-02
I0212 03:25:12.074567 22542570456896 run_lib.py:133] step: 884700, training_loss: 2.87967e-02
I0212 03:25:12.231395 22542570456896 run_lib.py:146] step: 884700, eval_loss: 2.48850e-02
I0212 03:25:29.858710 22542570456896 run_lib.py:133] step: 884750, training_loss: 2.80245e-02
I0212 03:25:47.342018 22542570456896 run_lib.py:133] step: 884800, training_loss: 3.03817e-02
I0212 03:25:47.497563 22542570456896 run_lib.py:146] step: 884800, eval_loss: 3.69476e-02
I0212 03:26:05.183696 22542570456896 run_lib.py:133] step: 884850, training_loss: 2.94418e-02
I0212 03:26:22.672355 22542570456896 run_lib.py:133] step: 884900, training_loss: 2.31218e-02
I0212 03:26:22.828757 22542570456896 run_lib.py:146] step: 884900, eval_loss: 2.01808e-02
I0212 03:26:40.463879 22542570456896 run_lib.py:133] step: 884950, training_loss: 2.49860e-02
I0212 03:26:57.965671 22542570456896 run_lib.py:133] step: 885000, training_loss: 2.89116e-02
I0212 03:26:58.122494 22542570456896 run_lib.py:146] step: 885000, eval_loss: 3.01762e-02
I0212 03:27:15.612555 22542570456896 run_lib.py:133] step: 885050, training_loss: 2.26470e-02
I0212 03:27:33.267004 22542570456896 run_lib.py:133] step: 885100, training_loss: 2.22957e-02
I0212 03:27:33.425775 22542570456896 run_lib.py:146] step: 885100, eval_loss: 2.39611e-02
I0212 03:27:50.976404 22542570456896 run_lib.py:133] step: 885150, training_loss: 2.71806e-02
I0212 03:28:08.645791 22542570456896 run_lib.py:133] step: 885200, training_loss: 3.28371e-02
I0212 03:28:08.799156 22542570456896 run_lib.py:146] step: 885200, eval_loss: 2.59006e-02
I0212 03:28:26.260965 22542570456896 run_lib.py:133] step: 885250, training_loss: 2.15491e-02
I0212 03:28:43.740729 22542570456896 run_lib.py:133] step: 885300, training_loss: 2.36373e-02
I0212 03:28:43.897405 22542570456896 run_lib.py:146] step: 885300, eval_loss: 2.56162e-02
I0212 03:29:01.517705 22542570456896 run_lib.py:133] step: 885350, training_loss: 2.70580e-02
I0212 03:29:19.005756 22542570456896 run_lib.py:133] step: 885400, training_loss: 2.61447e-02
I0212 03:29:19.183361 22542570456896 run_lib.py:146] step: 885400, eval_loss: 3.10130e-02
I0212 03:29:36.664292 22542570456896 run_lib.py:133] step: 885450, training_loss: 2.70734e-02
I0212 03:29:54.054878 22542570456896 run_lib.py:133] step: 885500, training_loss: 2.68860e-02
I0212 03:29:54.212490 22542570456896 run_lib.py:146] step: 885500, eval_loss: 3.24538e-02
I0212 03:30:11.769512 22542570456896 run_lib.py:133] step: 885550, training_loss: 2.65335e-02
I0212 03:30:29.122672 22542570456896 run_lib.py:133] step: 885600, training_loss: 3.02593e-02
I0212 03:30:29.278407 22542570456896 run_lib.py:146] step: 885600, eval_loss: 3.16730e-02
I0212 03:30:46.712991 22542570456896 run_lib.py:133] step: 885650, training_loss: 3.29925e-02
I0212 03:31:04.149173 22542570456896 run_lib.py:133] step: 885700, training_loss: 2.31227e-02
I0212 03:31:04.309654 22542570456896 run_lib.py:146] step: 885700, eval_loss: 2.47811e-02
I0212 03:31:21.707205 22542570456896 run_lib.py:133] step: 885750, training_loss: 2.10048e-02
I0212 03:31:39.100831 22542570456896 run_lib.py:133] step: 885800, training_loss: 2.58037e-02
I0212 03:31:39.256394 22542570456896 run_lib.py:146] step: 885800, eval_loss: 2.58941e-02
I0212 03:31:56.793734 22542570456896 run_lib.py:133] step: 885850, training_loss: 2.68714e-02
I0212 03:32:14.208075 22542570456896 run_lib.py:133] step: 885900, training_loss: 2.40188e-02
I0212 03:32:14.396500 22542570456896 run_lib.py:146] step: 885900, eval_loss: 2.77785e-02
I0212 03:32:31.920507 22542570456896 run_lib.py:133] step: 885950, training_loss: 2.22053e-02
I0212 03:32:49.422042 22542570456896 run_lib.py:133] step: 886000, training_loss: 2.74702e-02
I0212 03:32:49.588544 22542570456896 run_lib.py:146] step: 886000, eval_loss: 3.71088e-02
I0212 03:33:07.267991 22542570456896 run_lib.py:133] step: 886050, training_loss: 2.33795e-02
I0212 03:33:24.769708 22542570456896 run_lib.py:133] step: 886100, training_loss: 1.99437e-02
I0212 03:33:24.934928 22542570456896 run_lib.py:146] step: 886100, eval_loss: 3.00715e-02
I0212 03:33:42.576138 22542570456896 run_lib.py:133] step: 886150, training_loss: 3.14504e-02
I0212 03:34:00.092579 22542570456896 run_lib.py:133] step: 886200, training_loss: 2.43554e-02
I0212 03:34:00.249723 22542570456896 run_lib.py:146] step: 886200, eval_loss: 2.68353e-02
I0212 03:34:18.019631 22542570456896 run_lib.py:133] step: 886250, training_loss: 2.44983e-02
I0212 03:34:35.511035 22542570456896 run_lib.py:133] step: 886300, training_loss: 2.96207e-02
I0212 03:34:35.668235 22542570456896 run_lib.py:146] step: 886300, eval_loss: 2.21500e-02
I0212 03:34:53.252510 22542570456896 run_lib.py:133] step: 886350, training_loss: 2.44369e-02
I0212 03:35:10.712580 22542570456896 run_lib.py:133] step: 886400, training_loss: 2.86115e-02
I0212 03:35:10.875575 22542570456896 run_lib.py:146] step: 886400, eval_loss: 2.99736e-02
I0212 03:35:28.364762 22542570456896 run_lib.py:133] step: 886450, training_loss: 2.71786e-02
I0212 03:35:46.114650 22542570456896 run_lib.py:133] step: 886500, training_loss: 2.85704e-02
I0212 03:35:46.272918 22542570456896 run_lib.py:146] step: 886500, eval_loss: 2.82741e-02
I0212 03:36:03.752725 22542570456896 run_lib.py:133] step: 886550, training_loss: 2.71490e-02
I0212 03:36:21.208599 22542570456896 run_lib.py:133] step: 886600, training_loss: 3.00414e-02
I0212 03:36:21.364409 22542570456896 run_lib.py:146] step: 886600, eval_loss: 3.63303e-02
I0212 03:36:39.025388 22542570456896 run_lib.py:133] step: 886650, training_loss: 2.53863e-02
I0212 03:36:56.645604 22542570456896 run_lib.py:133] step: 886700, training_loss: 2.57507e-02
I0212 03:36:56.800658 22542570456896 run_lib.py:146] step: 886700, eval_loss: 3.36242e-02
I0212 03:37:14.314738 22542570456896 run_lib.py:133] step: 886750, training_loss: 2.34965e-02
I0212 03:37:31.799031 22542570456896 run_lib.py:133] step: 886800, training_loss: 2.18712e-02
I0212 03:37:31.961535 22542570456896 run_lib.py:146] step: 886800, eval_loss: 2.89745e-02
I0212 03:37:49.433444 22542570456896 run_lib.py:133] step: 886850, training_loss: 2.24943e-02
I0212 03:38:07.101103 22542570456896 run_lib.py:133] step: 886900, training_loss: 2.28256e-02
I0212 03:38:07.258424 22542570456896 run_lib.py:146] step: 886900, eval_loss: 2.75375e-02
I0212 03:38:24.719336 22542570456896 run_lib.py:133] step: 886950, training_loss: 2.58532e-02
I0212 03:38:42.212360 22542570456896 run_lib.py:133] step: 887000, training_loss: 3.44321e-02
I0212 03:38:42.371350 22542570456896 run_lib.py:146] step: 887000, eval_loss: 2.63789e-02
I0212 03:38:59.895523 22542570456896 run_lib.py:133] step: 887050, training_loss: 3.36658e-02
I0212 03:39:17.583167 22542570456896 run_lib.py:133] step: 887100, training_loss: 2.88160e-02
I0212 03:39:17.735143 22542570456896 run_lib.py:146] step: 887100, eval_loss: 3.12341e-02
I0212 03:39:35.186340 22542570456896 run_lib.py:133] step: 887150, training_loss: 2.57769e-02
I0212 03:39:52.748321 22542570456896 run_lib.py:133] step: 887200, training_loss: 2.48525e-02
I0212 03:39:52.902273 22542570456896 run_lib.py:146] step: 887200, eval_loss: 2.82440e-02
I0212 03:40:10.389906 22542570456896 run_lib.py:133] step: 887250, training_loss: 2.63639e-02
I0212 03:40:27.930264 22542570456896 run_lib.py:133] step: 887300, training_loss: 2.41931e-02
I0212 03:40:28.095496 22542570456896 run_lib.py:146] step: 887300, eval_loss: 2.71372e-02
I0212 03:40:45.743715 22542570456896 run_lib.py:133] step: 887350, training_loss: 2.73027e-02
I0212 03:41:03.274818 22542570456896 run_lib.py:133] step: 887400, training_loss: 2.29361e-02
I0212 03:41:03.431528 22542570456896 run_lib.py:146] step: 887400, eval_loss: 3.13678e-02
I0212 03:41:20.906820 22542570456896 run_lib.py:133] step: 887450, training_loss: 2.49628e-02
I0212 03:41:38.388898 22542570456896 run_lib.py:133] step: 887500, training_loss: 2.79382e-02
I0212 03:41:38.562447 22542570456896 run_lib.py:146] step: 887500, eval_loss: 2.04765e-02
I0212 03:41:56.227099 22542570456896 run_lib.py:133] step: 887550, training_loss: 2.87356e-02
I0212 03:42:13.697218 22542570456896 run_lib.py:133] step: 887600, training_loss: 2.57794e-02
I0212 03:42:13.849636 22542570456896 run_lib.py:146] step: 887600, eval_loss: 3.41109e-02
I0212 03:42:31.521567 22542570456896 run_lib.py:133] step: 887650, training_loss: 3.38379e-02
I0212 03:42:49.007235 22542570456896 run_lib.py:133] step: 887700, training_loss: 2.30644e-02
I0212 03:42:49.164433 22542570456896 run_lib.py:146] step: 887700, eval_loss: 3.44212e-02
I0212 03:43:06.748826 22542570456896 run_lib.py:133] step: 887750, training_loss: 2.65708e-02
I0212 03:43:24.207352 22542570456896 run_lib.py:133] step: 887800, training_loss: 2.74208e-02
I0212 03:43:24.386437 22542570456896 run_lib.py:146] step: 887800, eval_loss: 2.82585e-02
I0212 03:43:41.914070 22542570456896 run_lib.py:133] step: 887850, training_loss: 2.77396e-02
I0212 03:43:59.561068 22542570456896 run_lib.py:133] step: 887900, training_loss: 3.09349e-02
I0212 03:43:59.718537 22542570456896 run_lib.py:146] step: 887900, eval_loss: 2.74884e-02
I0212 03:44:17.164496 22542570456896 run_lib.py:133] step: 887950, training_loss: 2.33536e-02
I0212 03:44:34.759668 22542570456896 run_lib.py:133] step: 888000, training_loss: 2.53404e-02
I0212 03:44:34.917448 22542570456896 run_lib.py:146] step: 888000, eval_loss: 3.21216e-02
I0212 03:44:52.363695 22542570456896 run_lib.py:133] step: 888050, training_loss: 2.86182e-02
I0212 03:45:09.881164 22542570456896 run_lib.py:133] step: 888100, training_loss: 2.56460e-02
I0212 03:45:10.043682 22542570456896 run_lib.py:146] step: 888100, eval_loss: 3.47763e-02
I0212 03:45:27.784553 22542570456896 run_lib.py:133] step: 888150, training_loss: 2.36755e-02
I0212 03:45:45.261782 22542570456896 run_lib.py:133] step: 888200, training_loss: 2.17829e-02
I0212 03:45:45.419710 22542570456896 run_lib.py:146] step: 888200, eval_loss: 3.33065e-02
I0212 03:46:02.884487 22542570456896 run_lib.py:133] step: 888250, training_loss: 2.59131e-02
I0212 03:46:20.493761 22542570456896 run_lib.py:133] step: 888300, training_loss: 2.65579e-02
I0212 03:46:20.653635 22542570456896 run_lib.py:146] step: 888300, eval_loss: 2.71408e-02
I0212 03:46:38.136323 22542570456896 run_lib.py:133] step: 888350, training_loss: 2.92933e-02
I0212 03:46:55.651849 22542570456896 run_lib.py:133] step: 888400, training_loss: 2.83299e-02
I0212 03:46:55.810181 22542570456896 run_lib.py:146] step: 888400, eval_loss: 2.64577e-02
I0212 03:47:13.391887 22542570456896 run_lib.py:133] step: 888450, training_loss: 2.39641e-02
I0212 03:47:30.805110 22542570456896 run_lib.py:133] step: 888500, training_loss: 2.76730e-02
I0212 03:47:30.965343 22542570456896 run_lib.py:146] step: 888500, eval_loss: 2.87123e-02
I0212 03:47:48.418462 22542570456896 run_lib.py:133] step: 888550, training_loss: 2.57097e-02
I0212 03:48:05.888513 22542570456896 run_lib.py:133] step: 888600, training_loss: 3.00318e-02
I0212 03:48:06.049453 22542570456896 run_lib.py:146] step: 888600, eval_loss: 3.00730e-02
I0212 03:48:23.673183 22542570456896 run_lib.py:133] step: 888650, training_loss: 2.34449e-02
I0212 03:48:41.205630 22542570456896 run_lib.py:133] step: 888700, training_loss: 3.20692e-02
I0212 03:48:41.383458 22542570456896 run_lib.py:146] step: 888700, eval_loss: 2.87783e-02
I0212 03:48:58.877252 22542570456896 run_lib.py:133] step: 888750, training_loss: 2.74889e-02
I0212 03:49:16.364011 22542570456896 run_lib.py:133] step: 888800, training_loss: 3.11608e-02
I0212 03:49:16.522803 22542570456896 run_lib.py:146] step: 888800, eval_loss: 3.04838e-02
I0212 03:49:34.206017 22542570456896 run_lib.py:133] step: 888850, training_loss: 2.25674e-02
I0212 03:49:51.639581 22542570456896 run_lib.py:133] step: 888900, training_loss: 3.36405e-02
I0212 03:49:51.796176 22542570456896 run_lib.py:146] step: 888900, eval_loss: 3.61398e-02
I0212 03:50:09.403675 22542570456896 run_lib.py:133] step: 888950, training_loss: 2.28617e-02
I0212 03:50:26.925813 22542570456896 run_lib.py:133] step: 889000, training_loss: 2.92739e-02
I0212 03:50:27.082233 22542570456896 run_lib.py:146] step: 889000, eval_loss: 2.49166e-02
I0212 03:50:44.808866 22542570456896 run_lib.py:133] step: 889050, training_loss: 1.95032e-02
I0212 03:51:02.296264 22542570456896 run_lib.py:133] step: 889100, training_loss: 2.64503e-02
I0212 03:51:02.451421 22542570456896 run_lib.py:146] step: 889100, eval_loss: 3.47190e-02
I0212 03:51:20.053939 22542570456896 run_lib.py:133] step: 889150, training_loss: 2.57882e-02
I0212 03:51:37.538564 22542570456896 run_lib.py:133] step: 889200, training_loss: 2.08241e-02
I0212 03:51:37.708900 22542570456896 run_lib.py:146] step: 889200, eval_loss: 2.80091e-02
I0212 03:51:55.257112 22542570456896 run_lib.py:133] step: 889250, training_loss: 3.07498e-02
I0212 03:52:12.953431 22542570456896 run_lib.py:133] step: 889300, training_loss: 3.04512e-02
I0212 03:52:13.106585 22542570456896 run_lib.py:146] step: 889300, eval_loss: 2.99183e-02
I0212 03:52:30.595463 22542570456896 run_lib.py:133] step: 889350, training_loss: 2.27114e-02
I0212 03:52:48.038732 22542570456896 run_lib.py:133] step: 889400, training_loss: 2.97161e-02
I0212 03:52:48.195448 22542570456896 run_lib.py:146] step: 889400, eval_loss: 2.29940e-02
I0212 03:53:05.880606 22542570456896 run_lib.py:133] step: 889450, training_loss: 3.08584e-02
I0212 03:53:23.342664 22542570456896 run_lib.py:133] step: 889500, training_loss: 3.63829e-02
I0212 03:53:23.495435 22542570456896 run_lib.py:146] step: 889500, eval_loss: 2.65346e-02
I0212 03:53:41.102160 22542570456896 run_lib.py:133] step: 889550, training_loss: 2.42282e-02
I0212 03:53:58.617348 22542570456896 run_lib.py:133] step: 889600, training_loss: 3.40621e-02
I0212 03:53:58.786618 22542570456896 run_lib.py:146] step: 889600, eval_loss: 3.11679e-02
I0212 03:54:16.317269 22542570456896 run_lib.py:133] step: 889650, training_loss: 2.33392e-02
I0212 03:54:34.004283 22542570456896 run_lib.py:133] step: 889700, training_loss: 2.39234e-02
I0212 03:54:34.163650 22542570456896 run_lib.py:146] step: 889700, eval_loss: 2.85565e-02
I0212 03:54:51.632184 22542570456896 run_lib.py:133] step: 889750, training_loss: 2.65764e-02
I0212 03:55:09.092540 22542570456896 run_lib.py:133] step: 889800, training_loss: 2.46398e-02
I0212 03:55:09.250372 22542570456896 run_lib.py:146] step: 889800, eval_loss: 2.85147e-02
I0212 03:55:26.723755 22542570456896 run_lib.py:133] step: 889850, training_loss: 3.33880e-02
I0212 03:55:44.393697 22542570456896 run_lib.py:133] step: 889900, training_loss: 2.12894e-02
I0212 03:55:44.550740 22542570456896 run_lib.py:146] step: 889900, eval_loss: 2.75691e-02
I0212 03:56:02.052139 22542570456896 run_lib.py:133] step: 889950, training_loss: 2.24051e-02
I0212 03:56:19.622395 22542570456896 run_lib.py:133] step: 890000, training_loss: 2.59935e-02
I0212 03:56:20.366013 22542570456896 run_lib.py:146] step: 890000, eval_loss: 2.90892e-02
I0212 03:56:40.465613 22542570456896 run_lib.py:133] step: 890050, training_loss: 2.98988e-02
I0212 03:56:57.949756 22542570456896 run_lib.py:133] step: 890100, training_loss: 1.99766e-02
I0212 03:56:58.104668 22542570456896 run_lib.py:146] step: 890100, eval_loss: 2.67678e-02
I0212 03:57:15.780475 22542570456896 run_lib.py:133] step: 890150, training_loss: 2.27835e-02
I0212 03:57:33.300217 22542570456896 run_lib.py:133] step: 890200, training_loss: 2.91621e-02
I0212 03:57:33.463448 22542570456896 run_lib.py:146] step: 890200, eval_loss: 2.97839e-02
I0212 03:57:51.037873 22542570456896 run_lib.py:133] step: 890250, training_loss: 2.92223e-02
I0212 03:58:08.462037 22542570456896 run_lib.py:133] step: 890300, training_loss: 2.55682e-02
I0212 03:58:08.622387 22542570456896 run_lib.py:146] step: 890300, eval_loss: 3.02212e-02
I0212 03:58:26.065209 22542570456896 run_lib.py:133] step: 890350, training_loss: 3.37338e-02
I0212 03:58:43.512245 22542570456896 run_lib.py:133] step: 890400, training_loss: 3.04349e-02
I0212 03:58:43.680153 22542570456896 run_lib.py:146] step: 890400, eval_loss: 2.59007e-02
I0212 03:59:01.346905 22542570456896 run_lib.py:133] step: 890450, training_loss: 3.07136e-02
I0212 03:59:18.933097 22542570456896 run_lib.py:133] step: 890500, training_loss: 2.72173e-02
I0212 03:59:19.085729 22542570456896 run_lib.py:146] step: 890500, eval_loss: 2.79021e-02
I0212 03:59:36.523386 22542570456896 run_lib.py:133] step: 890550, training_loss: 2.69027e-02
I0212 03:59:54.003193 22542570456896 run_lib.py:133] step: 890600, training_loss: 2.32815e-02
I0212 03:59:54.160466 22542570456896 run_lib.py:146] step: 890600, eval_loss: 2.93379e-02
I0212 04:00:11.753840 22542570456896 run_lib.py:133] step: 890650, training_loss: 2.84010e-02
I0212 04:00:29.170149 22542570456896 run_lib.py:133] step: 890700, training_loss: 2.67546e-02
I0212 04:00:29.343286 22542570456896 run_lib.py:146] step: 890700, eval_loss: 3.12332e-02
I0212 04:00:46.935082 22542570456896 run_lib.py:133] step: 890750, training_loss: 3.36615e-02
I0212 04:01:04.321827 22542570456896 run_lib.py:133] step: 890800, training_loss: 2.50412e-02
I0212 04:01:04.478624 22542570456896 run_lib.py:146] step: 890800, eval_loss: 2.68797e-02
I0212 04:01:21.943279 22542570456896 run_lib.py:133] step: 890850, training_loss: 2.27407e-02
I0212 04:01:39.269629 22542570456896 run_lib.py:133] step: 890900, training_loss: 2.74723e-02
I0212 04:01:39.424334 22542570456896 run_lib.py:146] step: 890900, eval_loss: 3.43147e-02
I0212 04:01:56.797335 22542570456896 run_lib.py:133] step: 890950, training_loss: 2.15539e-02
I0212 04:02:14.428043 22542570456896 run_lib.py:133] step: 891000, training_loss: 3.34233e-02
I0212 04:02:14.589484 22542570456896 run_lib.py:146] step: 891000, eval_loss: 3.33767e-02
I0212 04:02:32.008100 22542570456896 run_lib.py:133] step: 891050, training_loss: 2.22888e-02
I0212 04:02:49.570020 22542570456896 run_lib.py:133] step: 891100, training_loss: 2.78422e-02
I0212 04:02:49.727508 22542570456896 run_lib.py:146] step: 891100, eval_loss: 3.02302e-02
I0212 04:03:07.201321 22542570456896 run_lib.py:133] step: 891150, training_loss: 3.22973e-02
I0212 04:03:24.668095 22542570456896 run_lib.py:133] step: 891200, training_loss: 2.54187e-02
I0212 04:03:24.828383 22542570456896 run_lib.py:146] step: 891200, eval_loss: 2.72548e-02
I0212 04:03:42.497783 22542570456896 run_lib.py:133] step: 891250, training_loss: 2.71146e-02
I0212 04:04:00.031853 22542570456896 run_lib.py:133] step: 891300, training_loss: 2.25287e-02
I0212 04:04:00.188699 22542570456896 run_lib.py:146] step: 891300, eval_loss: 3.04707e-02
I0212 04:04:17.654883 22542570456896 run_lib.py:133] step: 891350, training_loss: 2.78890e-02
I0212 04:04:35.323072 22542570456896 run_lib.py:133] step: 891400, training_loss: 2.20061e-02
I0212 04:04:35.479420 22542570456896 run_lib.py:146] step: 891400, eval_loss: 2.35479e-02
I0212 04:04:52.966562 22542570456896 run_lib.py:133] step: 891450, training_loss: 3.40164e-02
I0212 04:05:10.448920 22542570456896 run_lib.py:133] step: 891500, training_loss: 2.30104e-02
I0212 04:05:10.761384 22542570456896 run_lib.py:146] step: 891500, eval_loss: 3.19072e-02
I0212 04:05:28.215598 22542570456896 run_lib.py:133] step: 891550, training_loss: 3.01293e-02
I0212 04:05:45.735869 22542570456896 run_lib.py:133] step: 891600, training_loss: 2.55414e-02
I0212 04:05:45.909184 22542570456896 run_lib.py:146] step: 891600, eval_loss: 2.63889e-02
I0212 04:06:03.409298 22542570456896 run_lib.py:133] step: 891650, training_loss: 3.15634e-02
I0212 04:06:20.884103 22542570456896 run_lib.py:133] step: 891700, training_loss: 3.02106e-02
I0212 04:06:21.042374 22542570456896 run_lib.py:146] step: 891700, eval_loss: 2.78149e-02
I0212 04:06:38.705347 22542570456896 run_lib.py:133] step: 891750, training_loss: 2.20548e-02
I0212 04:06:56.223515 22542570456896 run_lib.py:133] step: 891800, training_loss: 2.49346e-02
I0212 04:06:56.381548 22542570456896 run_lib.py:146] step: 891800, eval_loss: 2.33477e-02
I0212 04:07:13.843069 22542570456896 run_lib.py:133] step: 891850, training_loss: 2.50164e-02
I0212 04:07:31.358887 22542570456896 run_lib.py:133] step: 891900, training_loss: 3.04163e-02
I0212 04:07:31.514049 22542570456896 run_lib.py:146] step: 891900, eval_loss: 3.47971e-02
I0212 04:07:49.219686 22542570456896 run_lib.py:133] step: 891950, training_loss: 2.83492e-02
I0212 04:08:06.719029 22542570456896 run_lib.py:133] step: 892000, training_loss: 3.39803e-02
I0212 04:08:06.873421 22542570456896 run_lib.py:146] step: 892000, eval_loss: 3.72920e-02
I0212 04:08:24.329941 22542570456896 run_lib.py:133] step: 892050, training_loss: 2.77419e-02
I0212 04:08:41.809823 22542570456896 run_lib.py:133] step: 892100, training_loss: 2.71484e-02
I0212 04:08:41.970720 22542570456896 run_lib.py:146] step: 892100, eval_loss: 3.36611e-02
I0212 04:08:59.613167 22542570456896 run_lib.py:133] step: 892150, training_loss: 2.49351e-02
I0212 04:09:17.123280 22542570456896 run_lib.py:133] step: 892200, training_loss: 2.50978e-02
I0212 04:09:17.281579 22542570456896 run_lib.py:146] step: 892200, eval_loss: 2.79390e-02
I0212 04:09:34.944972 22542570456896 run_lib.py:133] step: 892250, training_loss: 2.73188e-02
I0212 04:09:52.394662 22542570456896 run_lib.py:133] step: 892300, training_loss: 3.15470e-02
I0212 04:09:52.551788 22542570456896 run_lib.py:146] step: 892300, eval_loss: 3.00937e-02
I0212 04:10:10.204237 22542570456896 run_lib.py:133] step: 892350, training_loss: 3.24950e-02
I0212 04:10:27.659559 22542570456896 run_lib.py:133] step: 892400, training_loss: 2.82166e-02
I0212 04:10:27.813285 22542570456896 run_lib.py:146] step: 892400, eval_loss: 2.81184e-02
I0212 04:10:45.301403 22542570456896 run_lib.py:133] step: 892450, training_loss: 2.79548e-02
I0212 04:11:02.985961 22542570456896 run_lib.py:133] step: 892500, training_loss: 2.86464e-02
I0212 04:11:03.150583 22542570456896 run_lib.py:146] step: 892500, eval_loss: 3.14356e-02
I0212 04:11:20.641414 22542570456896 run_lib.py:133] step: 892550, training_loss: 2.40514e-02
I0212 04:11:38.306644 22542570456896 run_lib.py:133] step: 892600, training_loss: 3.04236e-02
I0212 04:11:38.464322 22542570456896 run_lib.py:146] step: 892600, eval_loss: 2.90483e-02
I0212 04:11:55.932680 22542570456896 run_lib.py:133] step: 892650, training_loss: 2.51581e-02
I0212 04:12:13.394776 22542570456896 run_lib.py:133] step: 892700, training_loss: 2.10046e-02
I0212 04:12:13.556369 22542570456896 run_lib.py:146] step: 892700, eval_loss: 2.56734e-02
I0212 04:12:31.255156 22542570456896 run_lib.py:133] step: 892750, training_loss: 2.47710e-02
I0212 04:12:48.726491 22542570456896 run_lib.py:133] step: 892800, training_loss: 2.49022e-02
I0212 04:12:48.884709 22542570456896 run_lib.py:146] step: 892800, eval_loss: 2.30273e-02
I0212 04:13:06.362649 22542570456896 run_lib.py:133] step: 892850, training_loss: 2.63889e-02
I0212 04:13:23.823415 22542570456896 run_lib.py:133] step: 892900, training_loss: 3.13512e-02
I0212 04:13:23.984367 22542570456896 run_lib.py:146] step: 892900, eval_loss: 3.52208e-02
I0212 04:13:41.619109 22542570456896 run_lib.py:133] step: 892950, training_loss: 2.50071e-02
I0212 04:13:59.091991 22542570456896 run_lib.py:133] step: 893000, training_loss: 3.89437e-02
I0212 04:13:59.264663 22542570456896 run_lib.py:146] step: 893000, eval_loss: 2.79460e-02
I0212 04:14:16.887931 22542570456896 run_lib.py:133] step: 893050, training_loss: 2.63965e-02
I0212 04:14:34.370136 22542570456896 run_lib.py:133] step: 893100, training_loss: 2.75771e-02
I0212 04:14:34.530480 22542570456896 run_lib.py:146] step: 893100, eval_loss: 3.02941e-02
I0212 04:14:51.973412 22542570456896 run_lib.py:133] step: 893150, training_loss: 2.69496e-02
I0212 04:15:09.427752 22542570456896 run_lib.py:133] step: 893200, training_loss: 3.08916e-02
I0212 04:15:09.585481 22542570456896 run_lib.py:146] step: 893200, eval_loss: 2.53684e-02
I0212 04:15:27.206541 22542570456896 run_lib.py:133] step: 893250, training_loss: 2.70448e-02
I0212 04:15:44.827358 22542570456896 run_lib.py:133] step: 893300, training_loss: 2.77510e-02
I0212 04:15:44.991686 22542570456896 run_lib.py:146] step: 893300, eval_loss: 2.33815e-02
I0212 04:16:02.520933 22542570456896 run_lib.py:133] step: 893350, training_loss: 2.81195e-02
I0212 04:16:19.953073 22542570456896 run_lib.py:133] step: 893400, training_loss: 3.21598e-02
I0212 04:16:20.106583 22542570456896 run_lib.py:146] step: 893400, eval_loss: 3.02636e-02
I0212 04:16:37.759084 22542570456896 run_lib.py:133] step: 893450, training_loss: 2.74178e-02
I0212 04:16:55.243774 22542570456896 run_lib.py:133] step: 893500, training_loss: 2.65775e-02
I0212 04:16:55.403944 22542570456896 run_lib.py:146] step: 893500, eval_loss: 3.51119e-02
I0212 04:17:13.006782 22542570456896 run_lib.py:133] step: 893550, training_loss: 2.26336e-02
I0212 04:17:30.469802 22542570456896 run_lib.py:133] step: 893600, training_loss: 1.93618e-02
I0212 04:17:30.641442 22542570456896 run_lib.py:146] step: 893600, eval_loss: 3.89323e-02
I0212 04:17:48.330141 22542570456896 run_lib.py:133] step: 893650, training_loss: 2.61312e-02
I0212 04:18:05.815695 22542570456896 run_lib.py:133] step: 893700, training_loss: 2.63307e-02
I0212 04:18:05.971444 22542570456896 run_lib.py:146] step: 893700, eval_loss: 3.50409e-02
I0212 04:18:23.634573 22542570456896 run_lib.py:133] step: 893750, training_loss: 2.14735e-02
I0212 04:18:41.090286 22542570456896 run_lib.py:133] step: 893800, training_loss: 2.58998e-02
I0212 04:18:41.243112 22542570456896 run_lib.py:146] step: 893800, eval_loss: 2.90053e-02
I0212 04:18:58.696769 22542570456896 run_lib.py:133] step: 893850, training_loss: 2.82805e-02
I0212 04:19:16.360128 22542570456896 run_lib.py:133] step: 893900, training_loss: 3.12708e-02
I0212 04:19:16.517833 22542570456896 run_lib.py:146] step: 893900, eval_loss: 2.99964e-02
I0212 04:19:34.020698 22542570456896 run_lib.py:133] step: 893950, training_loss: 2.42056e-02
I0212 04:19:51.481608 22542570456896 run_lib.py:133] step: 894000, training_loss: 2.11042e-02
I0212 04:19:51.641239 22542570456896 run_lib.py:146] step: 894000, eval_loss: 2.70726e-02
I0212 04:20:09.293291 22542570456896 run_lib.py:133] step: 894050, training_loss: 2.91180e-02
I0212 04:20:26.893400 22542570456896 run_lib.py:133] step: 894100, training_loss: 3.30381e-02
I0212 04:20:27.051440 22542570456896 run_lib.py:146] step: 894100, eval_loss: 2.76106e-02
I0212 04:20:44.558091 22542570456896 run_lib.py:133] step: 894150, training_loss: 2.19679e-02
I0212 04:21:02.057695 22542570456896 run_lib.py:133] step: 894200, training_loss: 2.22664e-02
I0212 04:21:02.227843 22542570456896 run_lib.py:146] step: 894200, eval_loss: 3.07252e-02
I0212 04:21:19.709656 22542570456896 run_lib.py:133] step: 894250, training_loss: 2.24296e-02
I0212 04:21:37.380434 22542570456896 run_lib.py:133] step: 894300, training_loss: 2.96025e-02
I0212 04:21:37.534484 22542570456896 run_lib.py:146] step: 894300, eval_loss: 3.16649e-02
I0212 04:21:54.981110 22542570456896 run_lib.py:133] step: 894350, training_loss: 3.20745e-02
I0212 04:22:12.421303 22542570456896 run_lib.py:133] step: 894400, training_loss: 3.70118e-02
I0212 04:22:12.583628 22542570456896 run_lib.py:146] step: 894400, eval_loss: 2.87249e-02
I0212 04:22:30.038329 22542570456896 run_lib.py:133] step: 894450, training_loss: 3.01846e-02
I0212 04:22:47.778903 22542570456896 run_lib.py:133] step: 894500, training_loss: 2.16162e-02
I0212 04:22:47.940225 22542570456896 run_lib.py:146] step: 894500, eval_loss: 2.51800e-02
I0212 04:23:05.376216 22542570456896 run_lib.py:133] step: 894550, training_loss: 2.75520e-02
I0212 04:23:22.899688 22542570456896 run_lib.py:133] step: 894600, training_loss: 2.18792e-02
I0212 04:23:23.057482 22542570456896 run_lib.py:146] step: 894600, eval_loss: 3.47829e-02
I0212 04:23:40.517518 22542570456896 run_lib.py:133] step: 894650, training_loss: 1.93167e-02
I0212 04:23:58.055541 22542570456896 run_lib.py:133] step: 894700, training_loss: 2.53869e-02
I0212 04:23:58.213612 22542570456896 run_lib.py:146] step: 894700, eval_loss: 2.49349e-02
I0212 04:24:15.916192 22542570456896 run_lib.py:133] step: 894750, training_loss: 3.30243e-02
I0212 04:24:33.448743 22542570456896 run_lib.py:133] step: 894800, training_loss: 2.79818e-02
I0212 04:24:33.601389 22542570456896 run_lib.py:146] step: 894800, eval_loss: 3.92182e-02
I0212 04:24:51.044491 22542570456896 run_lib.py:133] step: 894850, training_loss: 3.22769e-02
I0212 04:25:08.515224 22542570456896 run_lib.py:133] step: 894900, training_loss: 2.49486e-02
I0212 04:25:08.673494 22542570456896 run_lib.py:146] step: 894900, eval_loss: 3.50813e-02
I0212 04:25:26.258769 22542570456896 run_lib.py:133] step: 894950, training_loss: 2.39833e-02
I0212 04:25:43.782110 22542570456896 run_lib.py:133] step: 895000, training_loss: 3.73128e-02
I0212 04:25:43.954436 22542570456896 run_lib.py:146] step: 895000, eval_loss: 3.35243e-02
I0212 04:26:01.651490 22542570456896 run_lib.py:133] step: 895050, training_loss: 3.07191e-02
I0212 04:26:19.140141 22542570456896 run_lib.py:133] step: 895100, training_loss: 2.26745e-02
I0212 04:26:19.294773 22542570456896 run_lib.py:146] step: 895100, eval_loss: 3.18647e-02
I0212 04:26:36.909678 22542570456896 run_lib.py:133] step: 895150, training_loss: 2.72245e-02
I0212 04:26:54.322384 22542570456896 run_lib.py:133] step: 895200, training_loss: 2.81272e-02
I0212 04:26:54.480450 22542570456896 run_lib.py:146] step: 895200, eval_loss: 3.22630e-02
I0212 04:27:11.930655 22542570456896 run_lib.py:133] step: 895250, training_loss: 2.99788e-02
I0212 04:27:29.613555 22542570456896 run_lib.py:133] step: 895300, training_loss: 2.27803e-02
I0212 04:27:29.777414 22542570456896 run_lib.py:146] step: 895300, eval_loss: 3.33716e-02
I0212 04:27:47.245502 22542570456896 run_lib.py:133] step: 895350, training_loss: 2.78134e-02
I0212 04:28:04.907714 22542570456896 run_lib.py:133] step: 895400, training_loss: 2.09749e-02
I0212 04:28:05.076426 22542570456896 run_lib.py:146] step: 895400, eval_loss: 3.30940e-02
I0212 04:28:22.551348 22542570456896 run_lib.py:133] step: 895450, training_loss: 2.40309e-02
I0212 04:28:40.022764 22542570456896 run_lib.py:133] step: 895500, training_loss: 2.55997e-02
I0212 04:28:40.181857 22542570456896 run_lib.py:146] step: 895500, eval_loss: 2.90831e-02
I0212 04:28:57.855657 22542570456896 run_lib.py:133] step: 895550, training_loss: 2.60770e-02
I0212 04:29:15.395327 22542570456896 run_lib.py:133] step: 895600, training_loss: 2.96996e-02
I0212 04:29:15.554952 22542570456896 run_lib.py:146] step: 895600, eval_loss: 2.78345e-02
I0212 04:29:33.066487 22542570456896 run_lib.py:133] step: 895650, training_loss: 3.11120e-02
I0212 04:29:50.711004 22542570456896 run_lib.py:133] step: 895700, training_loss: 2.47305e-02
I0212 04:29:50.872879 22542570456896 run_lib.py:146] step: 895700, eval_loss: 2.90482e-02
I0212 04:30:08.328685 22542570456896 run_lib.py:133] step: 895750, training_loss: 2.47400e-02
I0212 04:30:25.799207 22542570456896 run_lib.py:133] step: 895800, training_loss: 2.61519e-02
I0212 04:30:25.959447 22542570456896 run_lib.py:146] step: 895800, eval_loss: 2.73022e-02
I0212 04:30:43.470635 22542570456896 run_lib.py:133] step: 895850, training_loss: 2.90790e-02
I0212 04:31:00.851430 22542570456896 run_lib.py:133] step: 895900, training_loss: 2.52197e-02
I0212 04:31:01.010311 22542570456896 run_lib.py:146] step: 895900, eval_loss: 2.46584e-02
I0212 04:31:18.348344 22542570456896 run_lib.py:133] step: 895950, training_loss: 2.64356e-02
I0212 04:31:35.685100 22542570456896 run_lib.py:133] step: 896000, training_loss: 2.54372e-02
I0212 04:31:35.840322 22542570456896 run_lib.py:146] step: 896000, eval_loss: 3.78192e-02
I0212 04:31:53.360182 22542570456896 run_lib.py:133] step: 896050, training_loss: 2.08152e-02
I0212 04:32:10.784580 22542570456896 run_lib.py:133] step: 896100, training_loss: 2.54983e-02
I0212 04:32:10.941707 22542570456896 run_lib.py:146] step: 896100, eval_loss: 2.62469e-02
I0212 04:32:28.342017 22542570456896 run_lib.py:133] step: 896150, training_loss: 2.67202e-02
I0212 04:32:45.761451 22542570456896 run_lib.py:133] step: 896200, training_loss: 2.67753e-02
I0212 04:32:45.918772 22542570456896 run_lib.py:146] step: 896200, eval_loss: 3.00096e-02
I0212 04:33:03.512831 22542570456896 run_lib.py:133] step: 896250, training_loss: 3.08192e-02
I0212 04:33:20.927218 22542570456896 run_lib.py:133] step: 896300, training_loss: 2.53569e-02
I0212 04:33:21.083459 22542570456896 run_lib.py:146] step: 896300, eval_loss: 2.82944e-02
I0212 04:33:38.693908 22542570456896 run_lib.py:133] step: 896350, training_loss: 2.59867e-02
I0212 04:33:56.199293 22542570456896 run_lib.py:133] step: 896400, training_loss: 2.34125e-02
I0212 04:33:56.359739 22542570456896 run_lib.py:146] step: 896400, eval_loss: 2.41312e-02
I0212 04:34:14.003394 22542570456896 run_lib.py:133] step: 896450, training_loss: 2.83179e-02
I0212 04:34:31.527643 22542570456896 run_lib.py:133] step: 896500, training_loss: 2.76517e-02
I0212 04:34:31.689633 22542570456896 run_lib.py:146] step: 896500, eval_loss: 3.00772e-02
I0212 04:34:49.364880 22542570456896 run_lib.py:133] step: 896550, training_loss: 2.91196e-02
I0212 04:35:06.866529 22542570456896 run_lib.py:133] step: 896600, training_loss: 3.08414e-02
I0212 04:35:07.023449 22542570456896 run_lib.py:146] step: 896600, eval_loss: 2.71435e-02
I0212 04:35:24.532099 22542570456896 run_lib.py:133] step: 896650, training_loss: 3.02093e-02
I0212 04:35:42.145396 22542570456896 run_lib.py:133] step: 896700, training_loss: 2.87940e-02
I0212 04:35:42.305672 22542570456896 run_lib.py:146] step: 896700, eval_loss: 3.37542e-02
I0212 04:35:59.830083 22542570456896 run_lib.py:133] step: 896750, training_loss: 3.20014e-02
I0212 04:36:17.331161 22542570456896 run_lib.py:133] step: 896800, training_loss: 2.79736e-02
I0212 04:36:17.495499 22542570456896 run_lib.py:146] step: 896800, eval_loss: 2.70125e-02
I0212 04:36:35.174339 22542570456896 run_lib.py:133] step: 896850, training_loss: 2.90483e-02
I0212 04:36:52.657337 22542570456896 run_lib.py:133] step: 896900, training_loss: 2.84903e-02
I0212 04:36:52.818818 22542570456896 run_lib.py:146] step: 896900, eval_loss: 2.78152e-02
I0212 04:37:10.426766 22542570456896 run_lib.py:133] step: 896950, training_loss: 2.17648e-02
I0212 04:37:27.896561 22542570456896 run_lib.py:133] step: 897000, training_loss: 2.51609e-02
I0212 04:37:28.071100 22542570456896 run_lib.py:146] step: 897000, eval_loss: 3.02095e-02
I0212 04:37:45.629613 22542570456896 run_lib.py:133] step: 897050, training_loss: 3.22619e-02
I0212 04:38:03.310594 22542570456896 run_lib.py:133] step: 897100, training_loss: 2.37105e-02
I0212 04:38:03.465945 22542570456896 run_lib.py:146] step: 897100, eval_loss: 2.47949e-02
I0212 04:38:20.943860 22542570456896 run_lib.py:133] step: 897150, training_loss: 3.05450e-02
I0212 04:38:38.408124 22542570456896 run_lib.py:133] step: 897200, training_loss: 3.03025e-02
I0212 04:38:38.559577 22542570456896 run_lib.py:146] step: 897200, eval_loss: 2.72096e-02
I0212 04:38:56.020356 22542570456896 run_lib.py:133] step: 897250, training_loss: 2.06130e-02
I0212 04:39:13.682838 22542570456896 run_lib.py:133] step: 897300, training_loss: 2.64436e-02
I0212 04:39:13.862338 22542570456896 run_lib.py:146] step: 897300, eval_loss: 3.33671e-02
I0212 04:39:31.346719 22542570456896 run_lib.py:133] step: 897350, training_loss: 2.89432e-02
I0212 04:39:48.964985 22542570456896 run_lib.py:133] step: 897400, training_loss: 2.80363e-02
I0212 04:39:49.128264 22542570456896 run_lib.py:146] step: 897400, eval_loss: 2.84872e-02
I0212 04:40:06.588114 22542570456896 run_lib.py:133] step: 897450, training_loss: 2.83240e-02
I0212 04:40:24.045816 22542570456896 run_lib.py:133] step: 897500, training_loss: 2.74220e-02
I0212 04:40:24.206522 22542570456896 run_lib.py:146] step: 897500, eval_loss: 2.91013e-02
I0212 04:40:41.855588 22542570456896 run_lib.py:133] step: 897550, training_loss: 2.79222e-02
I0212 04:40:59.451416 22542570456896 run_lib.py:133] step: 897600, training_loss: 2.45473e-02
I0212 04:40:59.612190 22542570456896 run_lib.py:146] step: 897600, eval_loss: 2.23596e-02
I0212 04:41:17.096752 22542570456896 run_lib.py:133] step: 897650, training_loss: 2.38607e-02
I0212 04:41:34.545796 22542570456896 run_lib.py:133] step: 897700, training_loss: 2.47821e-02
I0212 04:41:34.702476 22542570456896 run_lib.py:146] step: 897700, eval_loss: 3.43964e-02
I0212 04:41:52.276711 22542570456896 run_lib.py:133] step: 897750, training_loss: 2.87057e-02
I0212 04:42:09.733136 22542570456896 run_lib.py:133] step: 897800, training_loss: 3.41505e-02
I0212 04:42:09.911262 22542570456896 run_lib.py:146] step: 897800, eval_loss: 2.85585e-02
I0212 04:42:27.603068 22542570456896 run_lib.py:133] step: 897850, training_loss: 2.66327e-02
I0212 04:42:45.073879 22542570456896 run_lib.py:133] step: 897900, training_loss: 2.84356e-02
I0212 04:42:45.228294 22542570456896 run_lib.py:146] step: 897900, eval_loss: 3.21558e-02
I0212 04:43:02.856443 22542570456896 run_lib.py:133] step: 897950, training_loss: 2.87493e-02
I0212 04:43:20.293983 22542570456896 run_lib.py:133] step: 898000, training_loss: 2.77741e-02
I0212 04:43:20.451639 22542570456896 run_lib.py:146] step: 898000, eval_loss: 3.30121e-02
I0212 04:43:37.950150 22542570456896 run_lib.py:133] step: 898050, training_loss: 1.97175e-02
I0212 04:43:55.578225 22542570456896 run_lib.py:133] step: 898100, training_loss: 2.68851e-02
I0212 04:43:55.738829 22542570456896 run_lib.py:146] step: 898100, eval_loss: 2.37152e-02
I0212 04:44:13.281271 22542570456896 run_lib.py:133] step: 898150, training_loss: 2.88483e-02
I0212 04:44:30.933584 22542570456896 run_lib.py:133] step: 898200, training_loss: 3.30158e-02
I0212 04:44:31.090475 22542570456896 run_lib.py:146] step: 898200, eval_loss: 2.78043e-02
I0212 04:44:48.531020 22542570456896 run_lib.py:133] step: 898250, training_loss: 2.63781e-02
I0212 04:45:05.992567 22542570456896 run_lib.py:133] step: 898300, training_loss: 2.66256e-02
I0212 04:45:06.160699 22542570456896 run_lib.py:146] step: 898300, eval_loss: 2.78560e-02
I0212 04:45:23.775058 22542570456896 run_lib.py:133] step: 898350, training_loss: 2.65088e-02
I0212 04:45:41.272427 22542570456896 run_lib.py:133] step: 898400, training_loss: 2.72579e-02
I0212 04:45:41.436464 22542570456896 run_lib.py:146] step: 898400, eval_loss: 3.37242e-02
I0212 04:45:58.906709 22542570456896 run_lib.py:133] step: 898450, training_loss: 2.45458e-02
I0212 04:46:16.609427 22542570456896 run_lib.py:133] step: 898500, training_loss: 2.98285e-02
I0212 04:46:16.763511 22542570456896 run_lib.py:146] step: 898500, eval_loss: 2.50568e-02
I0212 04:46:34.262052 22542570456896 run_lib.py:133] step: 898550, training_loss: 2.83307e-02
I0212 04:46:51.741460 22542570456896 run_lib.py:133] step: 898600, training_loss: 2.89618e-02
I0212 04:46:52.056393 22542570456896 run_lib.py:146] step: 898600, eval_loss: 2.71199e-02
I0212 04:47:09.509015 22542570456896 run_lib.py:133] step: 898650, training_loss: 3.40433e-02
I0212 04:47:26.970429 22542570456896 run_lib.py:133] step: 898700, training_loss: 3.17500e-02
I0212 04:47:27.142241 22542570456896 run_lib.py:146] step: 898700, eval_loss: 3.15748e-02
I0212 04:47:44.620510 22542570456896 run_lib.py:133] step: 898750, training_loss: 2.34320e-02
I0212 04:48:02.101734 22542570456896 run_lib.py:133] step: 898800, training_loss: 2.40161e-02
I0212 04:48:02.259829 22542570456896 run_lib.py:146] step: 898800, eval_loss: 3.59164e-02
I0212 04:48:19.904094 22542570456896 run_lib.py:133] step: 898850, training_loss: 2.27734e-02
I0212 04:48:37.413919 22542570456896 run_lib.py:133] step: 898900, training_loss: 3.19878e-02
I0212 04:48:37.572589 22542570456896 run_lib.py:146] step: 898900, eval_loss: 3.55463e-02
I0212 04:48:55.011493 22542570456896 run_lib.py:133] step: 898950, training_loss: 2.67957e-02
I0212 04:49:12.549022 22542570456896 run_lib.py:133] step: 899000, training_loss: 3.21698e-02
I0212 04:49:12.704566 22542570456896 run_lib.py:146] step: 899000, eval_loss: 2.68171e-02
I0212 04:49:30.384979 22542570456896 run_lib.py:133] step: 899050, training_loss: 2.34335e-02
I0212 04:49:47.913412 22542570456896 run_lib.py:133] step: 899100, training_loss: 2.51880e-02
I0212 04:49:48.068444 22542570456896 run_lib.py:146] step: 899100, eval_loss: 2.98381e-02
I0212 04:50:05.509570 22542570456896 run_lib.py:133] step: 899150, training_loss: 2.89710e-02
I0212 04:50:22.958863 22542570456896 run_lib.py:133] step: 899200, training_loss: 3.07607e-02
I0212 04:50:23.136471 22542570456896 run_lib.py:146] step: 899200, eval_loss: 2.67865e-02
I0212 04:50:40.787618 22542570456896 run_lib.py:133] step: 899250, training_loss: 2.46745e-02
I0212 04:50:58.268759 22542570456896 run_lib.py:133] step: 899300, training_loss: 2.71712e-02
I0212 04:50:58.434501 22542570456896 run_lib.py:146] step: 899300, eval_loss: 2.46124e-02
I0212 04:51:16.118351 22542570456896 run_lib.py:133] step: 899350, training_loss: 3.17692e-02
I0212 04:51:33.566561 22542570456896 run_lib.py:133] step: 899400, training_loss: 2.39334e-02
I0212 04:51:33.724256 22542570456896 run_lib.py:146] step: 899400, eval_loss: 3.48957e-02
I0212 04:51:51.344369 22542570456896 run_lib.py:133] step: 899450, training_loss: 2.04182e-02
I0212 04:52:08.850516 22542570456896 run_lib.py:133] step: 899500, training_loss: 2.93505e-02
I0212 04:52:09.006329 22542570456896 run_lib.py:146] step: 899500, eval_loss: 2.68833e-02
I0212 04:52:26.526464 22542570456896 run_lib.py:133] step: 899550, training_loss: 2.75302e-02
I0212 04:52:44.189001 22542570456896 run_lib.py:133] step: 899600, training_loss: 3.07055e-02
I0212 04:52:44.345477 22542570456896 run_lib.py:146] step: 899600, eval_loss: 3.36027e-02
I0212 04:53:01.784248 22542570456896 run_lib.py:133] step: 899650, training_loss: 2.06024e-02
I0212 04:53:19.405341 22542570456896 run_lib.py:133] step: 899700, training_loss: 2.95695e-02
I0212 04:53:19.563218 22542570456896 run_lib.py:146] step: 899700, eval_loss: 2.79238e-02
I0212 04:53:37.005239 22542570456896 run_lib.py:133] step: 899750, training_loss: 2.97355e-02
I0212 04:53:54.500358 22542570456896 run_lib.py:133] step: 899800, training_loss: 2.18502e-02
I0212 04:53:54.668392 22542570456896 run_lib.py:146] step: 899800, eval_loss: 2.40222e-02
I0212 04:54:12.384860 22542570456896 run_lib.py:133] step: 899850, training_loss: 2.41463e-02
I0212 04:54:29.872584 22542570456896 run_lib.py:133] step: 899900, training_loss: 2.13136e-02
I0212 04:54:30.039423 22542570456896 run_lib.py:146] step: 899900, eval_loss: 2.64294e-02
I0212 04:54:47.509555 22542570456896 run_lib.py:133] step: 899950, training_loss: 2.93656e-02
I0212 04:55:04.971755 22542570456896 run_lib.py:133] step: 900000, training_loss: 2.66337e-02
I0212 04:55:05.696208 22542570456896 run_lib.py:146] step: 900000, eval_loss: 2.42558e-02
I0212 04:55:25.960040 22542570456896 run_lib.py:133] step: 900050, training_loss: 2.62421e-02
I0212 04:55:43.657803 22542570456896 run_lib.py:133] step: 900100, training_loss: 3.29807e-02
I0212 04:55:43.813706 22542570456896 run_lib.py:146] step: 900100, eval_loss: 3.25815e-02
I0212 04:56:01.284255 22542570456896 run_lib.py:133] step: 900150, training_loss: 2.59466e-02
I0212 04:56:18.750064 22542570456896 run_lib.py:133] step: 900200, training_loss: 3.00130e-02
I0212 04:56:18.911593 22542570456896 run_lib.py:146] step: 900200, eval_loss: 2.49241e-02
I0212 04:56:36.505962 22542570456896 run_lib.py:133] step: 900250, training_loss: 2.57344e-02
I0212 04:56:54.012059 22542570456896 run_lib.py:133] step: 900300, training_loss: 2.93372e-02
I0212 04:56:54.178553 22542570456896 run_lib.py:146] step: 900300, eval_loss: 2.31933e-02
I0212 04:57:11.717672 22542570456896 run_lib.py:133] step: 900350, training_loss: 3.06736e-02
I0212 04:57:29.204167 22542570456896 run_lib.py:133] step: 900400, training_loss: 3.24926e-02
I0212 04:57:29.360231 22542570456896 run_lib.py:146] step: 900400, eval_loss: 2.49933e-02
I0212 04:57:47.011678 22542570456896 run_lib.py:133] step: 900450, training_loss: 2.77829e-02
I0212 04:58:04.455657 22542570456896 run_lib.py:133] step: 900500, training_loss: 2.95920e-02
I0212 04:58:04.611508 22542570456896 run_lib.py:146] step: 900500, eval_loss: 2.95625e-02
I0212 04:58:22.186017 22542570456896 run_lib.py:133] step: 900550, training_loss: 2.67181e-02
I0212 04:58:39.687832 22542570456896 run_lib.py:133] step: 900600, training_loss: 3.31720e-02
I0212 04:58:39.842659 22542570456896 run_lib.py:146] step: 900600, eval_loss: 3.61367e-02
I0212 04:58:57.375069 22542570456896 run_lib.py:133] step: 900650, training_loss: 2.94633e-02
I0212 04:59:14.876929 22542570456896 run_lib.py:133] step: 900700, training_loss: 2.22565e-02
I0212 04:59:15.039478 22542570456896 run_lib.py:146] step: 900700, eval_loss: 2.13557e-02
I0212 04:59:32.692241 22542570456896 run_lib.py:133] step: 900750, training_loss: 2.30552e-02
I0212 04:59:50.233239 22542570456896 run_lib.py:133] step: 900800, training_loss: 1.86649e-02
I0212 04:59:50.390630 22542570456896 run_lib.py:146] step: 900800, eval_loss: 3.15042e-02
I0212 05:00:07.862816 22542570456896 run_lib.py:133] step: 900850, training_loss: 2.58217e-02
I0212 05:00:25.328382 22542570456896 run_lib.py:133] step: 900900, training_loss: 2.44072e-02
I0212 05:00:25.490164 22542570456896 run_lib.py:146] step: 900900, eval_loss: 2.90247e-02
I0212 05:00:43.172973 22542570456896 run_lib.py:133] step: 900950, training_loss: 2.61174e-02
I0212 05:01:00.647553 22542570456896 run_lib.py:133] step: 901000, training_loss: 2.52000e-02
I0212 05:01:00.798538 22542570456896 run_lib.py:146] step: 901000, eval_loss: 2.29545e-02
I0212 05:01:18.412843 22542570456896 run_lib.py:133] step: 901050, training_loss: 2.66625e-02
I0212 05:01:35.805073 22542570456896 run_lib.py:133] step: 901100, training_loss: 2.86849e-02
I0212 05:01:35.958266 22542570456896 run_lib.py:146] step: 901100, eval_loss: 3.01251e-02
I0212 05:01:53.473380 22542570456896 run_lib.py:133] step: 901150, training_loss: 2.85700e-02
I0212 05:02:10.884616 22542570456896 run_lib.py:133] step: 901200, training_loss: 3.33229e-02
I0212 05:02:11.059276 22542570456896 run_lib.py:146] step: 901200, eval_loss: 2.90677e-02
I0212 05:02:28.673596 22542570456896 run_lib.py:133] step: 901250, training_loss: 3.30157e-02
I0212 05:02:46.072178 22542570456896 run_lib.py:133] step: 901300, training_loss: 2.57213e-02
I0212 05:02:46.233566 22542570456896 run_lib.py:146] step: 901300, eval_loss: 2.72189e-02
I0212 05:03:03.620650 22542570456896 run_lib.py:133] step: 901350, training_loss: 2.05741e-02
I0212 05:03:21.080718 22542570456896 run_lib.py:133] step: 901400, training_loss: 2.77764e-02
I0212 05:03:21.247249 22542570456896 run_lib.py:146] step: 901400, eval_loss: 2.38303e-02
I0212 05:03:38.605662 22542570456896 run_lib.py:133] step: 901450, training_loss: 2.60757e-02
I0212 05:03:56.049110 22542570456896 run_lib.py:133] step: 901500, training_loss: 2.69788e-02
I0212 05:03:56.204747 22542570456896 run_lib.py:146] step: 901500, eval_loss: 2.78824e-02
I0212 05:04:13.945583 22542570456896 run_lib.py:133] step: 901550, training_loss: 2.69870e-02
I0212 05:04:31.422735 22542570456896 run_lib.py:133] step: 901600, training_loss: 2.29665e-02
I0212 05:04:31.582442 22542570456896 run_lib.py:146] step: 901600, eval_loss: 2.84571e-02
I0212 05:04:49.190583 22542570456896 run_lib.py:133] step: 901650, training_loss: 2.46323e-02
I0212 05:05:06.672930 22542570456896 run_lib.py:133] step: 901700, training_loss: 2.98688e-02
I0212 05:05:06.853479 22542570456896 run_lib.py:146] step: 901700, eval_loss: 3.50025e-02
I0212 05:05:24.393635 22542570456896 run_lib.py:133] step: 901750, training_loss: 2.80042e-02
I0212 05:05:42.066545 22542570456896 run_lib.py:133] step: 901800, training_loss: 3.04938e-02
I0212 05:05:42.224778 22542570456896 run_lib.py:146] step: 901800, eval_loss: 3.11939e-02
I0212 05:05:59.696771 22542570456896 run_lib.py:133] step: 901850, training_loss: 2.59926e-02
I0212 05:06:17.144017 22542570456896 run_lib.py:133] step: 901900, training_loss: 2.72546e-02
I0212 05:06:17.301559 22542570456896 run_lib.py:146] step: 901900, eval_loss: 2.24927e-02
I0212 05:06:34.819590 22542570456896 run_lib.py:133] step: 901950, training_loss: 2.60084e-02
I0212 05:06:52.465638 22542570456896 run_lib.py:133] step: 902000, training_loss: 2.15480e-02
I0212 05:06:52.629613 22542570456896 run_lib.py:146] step: 902000, eval_loss: 3.67368e-02
I0212 05:07:10.131750 22542570456896 run_lib.py:133] step: 902050, training_loss: 2.70957e-02
I0212 05:07:27.740447 22542570456896 run_lib.py:133] step: 902100, training_loss: 2.20989e-02
I0212 05:07:27.894973 22542570456896 run_lib.py:146] step: 902100, eval_loss: 2.99579e-02
I0212 05:07:45.389543 22542570456896 run_lib.py:133] step: 902150, training_loss: 2.85237e-02
I0212 05:08:02.842251 22542570456896 run_lib.py:133] step: 902200, training_loss: 3.49845e-02
I0212 05:08:03.000644 22542570456896 run_lib.py:146] step: 902200, eval_loss: 3.34476e-02
I0212 05:08:20.662135 22542570456896 run_lib.py:133] step: 902250, training_loss: 3.24493e-02
I0212 05:08:38.282635 22542570456896 run_lib.py:133] step: 902300, training_loss: 2.82588e-02
I0212 05:08:38.439949 22542570456896 run_lib.py:146] step: 902300, eval_loss: 2.45209e-02
I0212 05:08:55.950980 22542570456896 run_lib.py:133] step: 902350, training_loss: 2.84894e-02
I0212 05:09:13.381719 22542570456896 run_lib.py:133] step: 902400, training_loss: 2.31538e-02
I0212 05:09:13.538365 22542570456896 run_lib.py:146] step: 902400, eval_loss: 3.09517e-02
I0212 05:09:31.116782 22542570456896 run_lib.py:133] step: 902450, training_loss: 3.31833e-02
I0212 05:09:48.606288 22542570456896 run_lib.py:133] step: 902500, training_loss: 3.08483e-02
I0212 05:09:48.760628 22542570456896 run_lib.py:146] step: 902500, eval_loss: 2.89387e-02
I0212 05:10:06.405601 22542570456896 run_lib.py:133] step: 902550, training_loss: 2.65246e-02
I0212 05:10:23.908805 22542570456896 run_lib.py:133] step: 902600, training_loss: 2.31423e-02
I0212 05:10:24.070500 22542570456896 run_lib.py:146] step: 902600, eval_loss: 3.01776e-02
I0212 05:10:41.725007 22542570456896 run_lib.py:133] step: 902650, training_loss: 2.99458e-02
I0212 05:10:59.184870 22542570456896 run_lib.py:133] step: 902700, training_loss: 2.74760e-02
I0212 05:10:59.342447 22542570456896 run_lib.py:146] step: 902700, eval_loss: 2.88519e-02
I0212 05:11:16.816817 22542570456896 run_lib.py:133] step: 902750, training_loss: 2.35416e-02
I0212 05:11:34.408955 22542570456896 run_lib.py:133] step: 902800, training_loss: 2.84499e-02
I0212 05:11:34.570182 22542570456896 run_lib.py:146] step: 902800, eval_loss: 4.08441e-02
I0212 05:11:52.054781 22542570456896 run_lib.py:133] step: 902850, training_loss: 2.17752e-02
I0212 05:12:09.840120 22542570456896 run_lib.py:133] step: 902900, training_loss: 2.80164e-02
I0212 05:12:09.993189 22542570456896 run_lib.py:146] step: 902900, eval_loss: 2.95527e-02
I0212 05:12:27.519606 22542570456896 run_lib.py:133] step: 902950, training_loss: 3.40209e-02
I0212 05:12:45.017918 22542570456896 run_lib.py:133] step: 903000, training_loss: 2.98665e-02
I0212 05:12:45.179481 22542570456896 run_lib.py:146] step: 903000, eval_loss: 3.47205e-02
I0212 05:13:02.789137 22542570456896 run_lib.py:133] step: 903050, training_loss: 2.09025e-02
I0212 05:13:20.269279 22542570456896 run_lib.py:133] step: 903100, training_loss: 2.62677e-02
I0212 05:13:20.442299 22542570456896 run_lib.py:146] step: 903100, eval_loss: 3.07435e-02
I0212 05:13:37.930574 22542570456896 run_lib.py:133] step: 903150, training_loss: 2.70335e-02
I0212 05:13:55.612424 22542570456896 run_lib.py:133] step: 903200, training_loss: 2.97359e-02
I0212 05:13:55.770629 22542570456896 run_lib.py:146] step: 903200, eval_loss: 2.86981e-02
I0212 05:14:13.256143 22542570456896 run_lib.py:133] step: 903250, training_loss: 2.30866e-02
I0212 05:14:30.715510 22542570456896 run_lib.py:133] step: 903300, training_loss: 3.08330e-02
I0212 05:14:31.028174 22542570456896 run_lib.py:146] step: 903300, eval_loss: 2.89144e-02
I0212 05:14:48.515449 22542570456896 run_lib.py:133] step: 903350, training_loss: 2.87528e-02
I0212 05:15:05.977243 22542570456896 run_lib.py:133] step: 903400, training_loss: 3.31636e-02
I0212 05:15:06.131615 22542570456896 run_lib.py:146] step: 903400, eval_loss: 3.48128e-02
I0212 05:15:23.656840 22542570456896 run_lib.py:133] step: 903450, training_loss: 2.39365e-02
I0212 05:15:41.158097 22542570456896 run_lib.py:133] step: 903500, training_loss: 2.68673e-02
I0212 05:15:41.322292 22542570456896 run_lib.py:146] step: 903500, eval_loss: 3.14333e-02
I0212 05:15:58.962440 22542570456896 run_lib.py:133] step: 903550, training_loss: 2.36920e-02
I0212 05:16:16.478945 22542570456896 run_lib.py:133] step: 903600, training_loss: 3.27573e-02
I0212 05:16:16.640678 22542570456896 run_lib.py:146] step: 903600, eval_loss: 2.57212e-02
I0212 05:16:34.092366 22542570456896 run_lib.py:133] step: 903650, training_loss: 2.79120e-02
I0212 05:16:51.560860 22542570456896 run_lib.py:133] step: 903700, training_loss: 2.68989e-02
I0212 05:16:51.732477 22542570456896 run_lib.py:146] step: 903700, eval_loss: 3.14062e-02
I0212 05:17:09.357279 22542570456896 run_lib.py:133] step: 903750, training_loss: 2.45981e-02
I0212 05:17:26.969383 22542570456896 run_lib.py:133] step: 903800, training_loss: 3.81973e-02
I0212 05:17:27.125636 22542570456896 run_lib.py:146] step: 903800, eval_loss: 2.80974e-02
I0212 05:17:44.633960 22542570456896 run_lib.py:133] step: 903850, training_loss: 1.80851e-02
I0212 05:18:02.101134 22542570456896 run_lib.py:133] step: 903900, training_loss: 2.95016e-02
I0212 05:18:02.256423 22542570456896 run_lib.py:146] step: 903900, eval_loss: 2.56396e-02
I0212 05:18:19.881717 22542570456896 run_lib.py:133] step: 903950, training_loss: 2.50631e-02
I0212 05:18:37.330842 22542570456896 run_lib.py:133] step: 904000, training_loss: 2.28846e-02
I0212 05:18:37.518267 22542570456896 run_lib.py:146] step: 904000, eval_loss: 3.42963e-02
I0212 05:18:55.207482 22542570456896 run_lib.py:133] step: 904050, training_loss: 2.72208e-02
I0212 05:19:12.700843 22542570456896 run_lib.py:133] step: 904100, training_loss: 2.49372e-02
I0212 05:19:12.859570 22542570456896 run_lib.py:146] step: 904100, eval_loss: 2.33846e-02
I0212 05:19:30.479064 22542570456896 run_lib.py:133] step: 904150, training_loss: 3.28445e-02
I0212 05:19:47.917089 22542570456896 run_lib.py:133] step: 904200, training_loss: 2.63570e-02
I0212 05:19:48.075195 22542570456896 run_lib.py:146] step: 904200, eval_loss: 2.52464e-02
I0212 05:20:05.531425 22542570456896 run_lib.py:133] step: 904250, training_loss: 2.50347e-02
I0212 05:20:23.254439 22542570456896 run_lib.py:133] step: 904300, training_loss: 2.26839e-02
I0212 05:20:23.410225 22542570456896 run_lib.py:146] step: 904300, eval_loss: 3.01551e-02
I0212 05:20:40.899044 22542570456896 run_lib.py:133] step: 904350, training_loss: 3.19429e-02
I0212 05:20:58.552037 22542570456896 run_lib.py:133] step: 904400, training_loss: 2.82822e-02
I0212 05:20:58.715384 22542570456896 run_lib.py:146] step: 904400, eval_loss: 3.03314e-02
I0212 05:21:16.180975 22542570456896 run_lib.py:133] step: 904450, training_loss: 2.73431e-02
I0212 05:21:33.665531 22542570456896 run_lib.py:133] step: 904500, training_loss: 2.58539e-02
I0212 05:21:33.832309 22542570456896 run_lib.py:146] step: 904500, eval_loss: 2.15001e-02
I0212 05:21:51.510493 22542570456896 run_lib.py:133] step: 904550, training_loss: 2.99906e-02
I0212 05:22:09.028195 22542570456896 run_lib.py:133] step: 904600, training_loss: 2.59111e-02
I0212 05:22:09.185756 22542570456896 run_lib.py:146] step: 904600, eval_loss: 2.94504e-02
I0212 05:22:26.676859 22542570456896 run_lib.py:133] step: 904650, training_loss: 2.89777e-02
I0212 05:22:44.132992 22542570456896 run_lib.py:133] step: 904700, training_loss: 2.64814e-02
I0212 05:22:44.289545 22542570456896 run_lib.py:146] step: 904700, eval_loss: 2.67623e-02
I0212 05:23:01.926444 22542570456896 run_lib.py:133] step: 904750, training_loss: 2.57490e-02
I0212 05:23:19.395699 22542570456896 run_lib.py:133] step: 904800, training_loss: 2.78168e-02
I0212 05:23:19.552269 22542570456896 run_lib.py:146] step: 904800, eval_loss: 3.16901e-02
I0212 05:23:37.209385 22542570456896 run_lib.py:133] step: 904850, training_loss: 2.50805e-02
I0212 05:23:54.671596 22542570456896 run_lib.py:133] step: 904900, training_loss: 3.40011e-02
I0212 05:23:54.828430 22542570456896 run_lib.py:146] step: 904900, eval_loss: 3.25715e-02
I0212 05:24:12.277300 22542570456896 run_lib.py:133] step: 904950, training_loss: 2.52255e-02
I0212 05:24:29.742676 22542570456896 run_lib.py:133] step: 905000, training_loss: 2.36456e-02
I0212 05:24:29.899523 22542570456896 run_lib.py:146] step: 905000, eval_loss: 2.50991e-02
I0212 05:24:47.556355 22542570456896 run_lib.py:133] step: 905050, training_loss: 2.11916e-02
I0212 05:25:05.113537 22542570456896 run_lib.py:133] step: 905100, training_loss: 2.71803e-02
I0212 05:25:05.284481 22542570456896 run_lib.py:146] step: 905100, eval_loss: 3.04554e-02
I0212 05:25:22.797246 22542570456896 run_lib.py:133] step: 905150, training_loss: 3.56586e-02
I0212 05:25:40.299753 22542570456896 run_lib.py:133] step: 905200, training_loss: 2.76829e-02
I0212 05:25:40.458208 22542570456896 run_lib.py:146] step: 905200, eval_loss: 2.77538e-02
I0212 05:25:58.184052 22542570456896 run_lib.py:133] step: 905250, training_loss: 2.32755e-02
I0212 05:26:15.615078 22542570456896 run_lib.py:133] step: 905300, training_loss: 2.76136e-02
I0212 05:26:15.768488 22542570456896 run_lib.py:146] step: 905300, eval_loss: 2.56046e-02
I0212 05:26:33.396434 22542570456896 run_lib.py:133] step: 905350, training_loss: 2.68058e-02
I0212 05:26:50.874847 22542570456896 run_lib.py:133] step: 905400, training_loss: 2.61501e-02
I0212 05:26:51.045703 22542570456896 run_lib.py:146] step: 905400, eval_loss: 3.47821e-02
I0212 05:27:08.754312 22542570456896 run_lib.py:133] step: 905450, training_loss: 2.40954e-02
I0212 05:27:26.260381 22542570456896 run_lib.py:133] step: 905500, training_loss: 2.95181e-02
I0212 05:27:26.427824 22542570456896 run_lib.py:146] step: 905500, eval_loss: 3.05249e-02
I0212 05:27:44.025384 22542570456896 run_lib.py:133] step: 905550, training_loss: 2.66470e-02
I0212 05:28:01.459179 22542570456896 run_lib.py:133] step: 905600, training_loss: 2.83215e-02
I0212 05:28:01.621446 22542570456896 run_lib.py:146] step: 905600, eval_loss: 2.83748e-02
I0212 05:28:19.102500 22542570456896 run_lib.py:133] step: 905650, training_loss: 4.10019e-02
I0212 05:28:36.756955 22542570456896 run_lib.py:133] step: 905700, training_loss: 3.09501e-02
I0212 05:28:36.913689 22542570456896 run_lib.py:146] step: 905700, eval_loss: 2.97286e-02
I0212 05:28:54.418417 22542570456896 run_lib.py:133] step: 905750, training_loss: 2.51146e-02
I0212 05:29:11.871981 22542570456896 run_lib.py:133] step: 905800, training_loss: 2.40730e-02
I0212 05:29:12.026451 22542570456896 run_lib.py:146] step: 905800, eval_loss: 3.35974e-02
I0212 05:29:29.676618 22542570456896 run_lib.py:133] step: 905850, training_loss: 3.08999e-02
I0212 05:29:47.275041 22542570456896 run_lib.py:133] step: 905900, training_loss: 2.93621e-02
I0212 05:29:47.452468 22542570456896 run_lib.py:146] step: 905900, eval_loss: 2.96611e-02
I0212 05:30:04.960230 22542570456896 run_lib.py:133] step: 905950, training_loss: 2.69986e-02
I0212 05:30:22.472721 22542570456896 run_lib.py:133] step: 906000, training_loss: 2.01795e-02
I0212 05:30:22.630475 22542570456896 run_lib.py:146] step: 906000, eval_loss: 3.64921e-02
I0212 05:30:40.119018 22542570456896 run_lib.py:133] step: 906050, training_loss: 2.79019e-02
I0212 05:30:57.790278 22542570456896 run_lib.py:133] step: 906100, training_loss: 2.77010e-02
I0212 05:30:57.954166 22542570456896 run_lib.py:146] step: 906100, eval_loss: 2.85150e-02
I0212 05:31:15.424183 22542570456896 run_lib.py:133] step: 906150, training_loss: 3.20286e-02
I0212 05:31:32.896888 22542570456896 run_lib.py:133] step: 906200, training_loss: 2.75668e-02
I0212 05:31:33.059229 22542570456896 run_lib.py:146] step: 906200, eval_loss: 2.80606e-02
I0212 05:31:50.559829 22542570456896 run_lib.py:133] step: 906250, training_loss: 3.24173e-02
I0212 05:32:08.100017 22542570456896 run_lib.py:133] step: 906300, training_loss: 3.04778e-02
I0212 05:32:08.253209 22542570456896 run_lib.py:146] step: 906300, eval_loss: 2.82413e-02
I0212 05:32:25.592799 22542570456896 run_lib.py:133] step: 906350, training_loss: 2.17753e-02
I0212 05:32:43.028182 22542570456896 run_lib.py:133] step: 906400, training_loss: 2.82275e-02
I0212 05:32:43.193329 22542570456896 run_lib.py:146] step: 906400, eval_loss: 2.68179e-02
I0212 05:33:00.594645 22542570456896 run_lib.py:133] step: 906450, training_loss: 2.12722e-02
I0212 05:33:17.999929 22542570456896 run_lib.py:133] step: 906500, training_loss: 2.21281e-02
I0212 05:33:18.160569 22542570456896 run_lib.py:146] step: 906500, eval_loss: 2.80934e-02
I0212 05:33:35.705060 22542570456896 run_lib.py:133] step: 906550, training_loss: 3.00459e-02
I0212 05:33:53.166946 22542570456896 run_lib.py:133] step: 906600, training_loss: 2.60698e-02
I0212 05:33:53.322601 22542570456896 run_lib.py:146] step: 906600, eval_loss: 2.31747e-02
I0212 05:34:10.685018 22542570456896 run_lib.py:133] step: 906650, training_loss: 2.58913e-02
I0212 05:34:28.143369 22542570456896 run_lib.py:133] step: 906700, training_loss: 2.97744e-02
I0212 05:34:28.298534 22542570456896 run_lib.py:146] step: 906700, eval_loss: 2.81028e-02
I0212 05:34:45.923776 22542570456896 run_lib.py:133] step: 906750, training_loss: 2.91979e-02
I0212 05:35:03.462806 22542570456896 run_lib.py:133] step: 906800, training_loss: 2.93895e-02
I0212 05:35:03.632640 22542570456896 run_lib.py:146] step: 906800, eval_loss: 3.51240e-02
I0212 05:35:21.311011 22542570456896 run_lib.py:133] step: 906850, training_loss: 2.90386e-02
I0212 05:35:38.815585 22542570456896 run_lib.py:133] step: 906900, training_loss: 2.80838e-02
I0212 05:35:38.976686 22542570456896 run_lib.py:146] step: 906900, eval_loss: 2.49859e-02
I0212 05:35:56.607163 22542570456896 run_lib.py:133] step: 906950, training_loss: 2.60840e-02
I0212 05:36:14.061620 22542570456896 run_lib.py:133] step: 907000, training_loss: 3.38177e-02
I0212 05:36:14.222496 22542570456896 run_lib.py:146] step: 907000, eval_loss: 3.36663e-02
I0212 05:36:31.696195 22542570456896 run_lib.py:133] step: 907050, training_loss: 2.92086e-02
I0212 05:36:49.419226 22542570456896 run_lib.py:133] step: 907100, training_loss: 2.89616e-02
I0212 05:36:49.574640 22542570456896 run_lib.py:146] step: 907100, eval_loss: 2.60650e-02
I0212 05:37:07.061903 22542570456896 run_lib.py:133] step: 907150, training_loss: 2.61769e-02
I0212 05:37:24.674530 22542570456896 run_lib.py:133] step: 907200, training_loss: 2.64578e-02
I0212 05:37:24.827255 22542570456896 run_lib.py:146] step: 907200, eval_loss: 2.79098e-02
I0212 05:37:42.285701 22542570456896 run_lib.py:133] step: 907250, training_loss: 2.37525e-02
I0212 05:37:59.755768 22542570456896 run_lib.py:133] step: 907300, training_loss: 3.37897e-02
I0212 05:37:59.918714 22542570456896 run_lib.py:146] step: 907300, eval_loss: 2.36502e-02
I0212 05:38:17.574434 22542570456896 run_lib.py:133] step: 907350, training_loss: 2.64244e-02
I0212 05:38:35.073296 22542570456896 run_lib.py:133] step: 907400, training_loss: 2.28238e-02
I0212 05:38:35.232279 22542570456896 run_lib.py:146] step: 907400, eval_loss: 2.74974e-02
I0212 05:38:52.671584 22542570456896 run_lib.py:133] step: 907450, training_loss: 2.32636e-02
I0212 05:39:10.372428 22542570456896 run_lib.py:133] step: 907500, training_loss: 3.09618e-02
I0212 05:39:10.526808 22542570456896 run_lib.py:146] step: 907500, eval_loss: 2.39650e-02
I0212 05:39:27.981801 22542570456896 run_lib.py:133] step: 907550, training_loss: 2.29340e-02
I0212 05:39:45.451169 22542570456896 run_lib.py:133] step: 907600, training_loss: 2.82927e-02
I0212 05:39:45.610386 22542570456896 run_lib.py:146] step: 907600, eval_loss: 2.67384e-02
I0212 05:40:03.132390 22542570456896 run_lib.py:133] step: 907650, training_loss: 2.39172e-02
I0212 05:40:20.641854 22542570456896 run_lib.py:133] step: 907700, training_loss: 2.81135e-02
I0212 05:40:20.798714 22542570456896 run_lib.py:146] step: 907700, eval_loss: 2.80795e-02
I0212 05:40:38.311104 22542570456896 run_lib.py:133] step: 907750, training_loss: 3.09264e-02
I0212 05:40:55.811711 22542570456896 run_lib.py:133] step: 907800, training_loss: 2.87044e-02
I0212 05:40:55.971697 22542570456896 run_lib.py:146] step: 907800, eval_loss: 2.51198e-02
I0212 05:41:13.602097 22542570456896 run_lib.py:133] step: 907850, training_loss: 3.00501e-02
I0212 05:41:31.124579 22542570456896 run_lib.py:133] step: 907900, training_loss: 3.26174e-02
I0212 05:41:31.281443 22542570456896 run_lib.py:146] step: 907900, eval_loss: 2.89344e-02
I0212 05:41:48.768782 22542570456896 run_lib.py:133] step: 907950, training_loss: 3.46904e-02
I0212 05:42:06.313911 22542570456896 run_lib.py:133] step: 908000, training_loss: 2.76703e-02
I0212 05:42:06.471753 22542570456896 run_lib.py:146] step: 908000, eval_loss: 3.08747e-02
I0212 05:42:24.131694 22542570456896 run_lib.py:133] step: 908050, training_loss: 2.11508e-02
I0212 05:42:41.591671 22542570456896 run_lib.py:133] step: 908100, training_loss: 3.37314e-02
I0212 05:42:41.746148 22542570456896 run_lib.py:146] step: 908100, eval_loss: 3.42948e-02
I0212 05:42:59.347064 22542570456896 run_lib.py:133] step: 908150, training_loss: 2.87771e-02
I0212 05:43:16.854541 22542570456896 run_lib.py:133] step: 908200, training_loss: 2.69621e-02
I0212 05:43:17.011714 22542570456896 run_lib.py:146] step: 908200, eval_loss: 3.20562e-02
I0212 05:43:34.721030 22542570456896 run_lib.py:133] step: 908250, training_loss: 2.38247e-02
I0212 05:43:52.215092 22542570456896 run_lib.py:133] step: 908300, training_loss: 2.56869e-02
I0212 05:43:52.376477 22542570456896 run_lib.py:146] step: 908300, eval_loss: 3.10913e-02
I0212 05:44:10.000802 22542570456896 run_lib.py:133] step: 908350, training_loss: 3.26549e-02
I0212 05:44:27.459535 22542570456896 run_lib.py:133] step: 908400, training_loss: 2.46297e-02
I0212 05:44:27.623410 22542570456896 run_lib.py:146] step: 908400, eval_loss: 2.64973e-02
I0212 05:44:45.101717 22542570456896 run_lib.py:133] step: 908450, training_loss: 2.83385e-02
I0212 05:45:02.777069 22542570456896 run_lib.py:133] step: 908500, training_loss: 2.30515e-02
I0212 05:45:02.935709 22542570456896 run_lib.py:146] step: 908500, eval_loss: 3.07364e-02
I0212 05:45:20.477490 22542570456896 run_lib.py:133] step: 908550, training_loss: 2.74324e-02
I0212 05:45:37.950307 22542570456896 run_lib.py:133] step: 908600, training_loss: 3.19845e-02
I0212 05:45:38.103198 22542570456896 run_lib.py:146] step: 908600, eval_loss: 2.73610e-02
I0212 05:45:55.768577 22542570456896 run_lib.py:133] step: 908650, training_loss: 3.60351e-02
I0212 05:46:13.223454 22542570456896 run_lib.py:133] step: 908700, training_loss: 2.42408e-02
I0212 05:46:13.380435 22542570456896 run_lib.py:146] step: 908700, eval_loss: 2.63671e-02
I0212 05:46:30.999753 22542570456896 run_lib.py:133] step: 908750, training_loss: 3.38413e-02
I0212 05:46:48.491024 22542570456896 run_lib.py:133] step: 908800, training_loss: 2.30722e-02
I0212 05:46:48.675333 22542570456896 run_lib.py:146] step: 908800, eval_loss: 2.82365e-02
I0212 05:47:06.156841 22542570456896 run_lib.py:133] step: 908850, training_loss: 2.49908e-02
I0212 05:47:23.844504 22542570456896 run_lib.py:133] step: 908900, training_loss: 3.11261e-02
I0212 05:47:24.009687 22542570456896 run_lib.py:146] step: 908900, eval_loss: 3.17439e-02
I0212 05:47:41.493138 22542570456896 run_lib.py:133] step: 908950, training_loss: 2.50641e-02
I0212 05:47:58.928235 22542570456896 run_lib.py:133] step: 909000, training_loss: 2.52620e-02
I0212 05:47:59.086590 22542570456896 run_lib.py:146] step: 909000, eval_loss: 3.03947e-02
I0212 05:48:16.586925 22542570456896 run_lib.py:133] step: 909050, training_loss: 3.41803e-02
I0212 05:48:34.308620 22542570456896 run_lib.py:133] step: 909100, training_loss: 2.48785e-02
I0212 05:48:34.463666 22542570456896 run_lib.py:146] step: 909100, eval_loss: 3.69347e-02
I0212 05:48:51.972203 22542570456896 run_lib.py:133] step: 909150, training_loss: 3.27510e-02
I0212 05:49:09.575395 22542570456896 run_lib.py:133] step: 909200, training_loss: 3.17962e-02
I0212 05:49:09.732466 22542570456896 run_lib.py:146] step: 909200, eval_loss: 2.83891e-02
I0212 05:49:27.200259 22542570456896 run_lib.py:133] step: 909250, training_loss: 3.80436e-02
I0212 05:49:44.657974 22542570456896 run_lib.py:133] step: 909300, training_loss: 2.68912e-02
I0212 05:49:44.826665 22542570456896 run_lib.py:146] step: 909300, eval_loss: 3.20921e-02
I0212 05:50:02.514093 22542570456896 run_lib.py:133] step: 909350, training_loss: 2.51846e-02
I0212 05:50:20.086697 22542570456896 run_lib.py:133] step: 909400, training_loss: 2.50776e-02
I0212 05:50:20.244240 22542570456896 run_lib.py:146] step: 909400, eval_loss: 3.39451e-02
I0212 05:50:37.741547 22542570456896 run_lib.py:133] step: 909450, training_loss: 2.85818e-02
I0212 05:50:55.225901 22542570456896 run_lib.py:133] step: 909500, training_loss: 2.96584e-02
I0212 05:50:55.389384 22542570456896 run_lib.py:146] step: 909500, eval_loss: 2.41925e-02
I0212 05:51:12.991716 22542570456896 run_lib.py:133] step: 909550, training_loss: 2.86785e-02
I0212 05:51:30.464009 22542570456896 run_lib.py:133] step: 909600, training_loss: 2.75418e-02
I0212 05:51:30.620638 22542570456896 run_lib.py:146] step: 909600, eval_loss: 2.84495e-02
I0212 05:51:48.325178 22542570456896 run_lib.py:133] step: 909650, training_loss: 2.70750e-02
I0212 05:52:05.813303 22542570456896 run_lib.py:133] step: 909700, training_loss: 2.88248e-02
I0212 05:52:05.982553 22542570456896 run_lib.py:146] step: 909700, eval_loss: 2.93687e-02
I0212 05:52:23.618983 22542570456896 run_lib.py:133] step: 909750, training_loss: 2.69364e-02
I0212 05:52:41.091167 22542570456896 run_lib.py:133] step: 909800, training_loss: 2.52330e-02
I0212 05:52:41.257440 22542570456896 run_lib.py:146] step: 909800, eval_loss: 2.75965e-02
I0212 05:52:58.758830 22542570456896 run_lib.py:133] step: 909850, training_loss: 2.94945e-02
I0212 05:53:16.439336 22542570456896 run_lib.py:133] step: 909900, training_loss: 2.41739e-02
I0212 05:53:16.596691 22542570456896 run_lib.py:146] step: 909900, eval_loss: 2.67624e-02
I0212 05:53:34.113228 22542570456896 run_lib.py:133] step: 909950, training_loss: 2.82352e-02
I0212 05:53:51.717612 22542570456896 run_lib.py:133] step: 910000, training_loss: 2.37223e-02
I0212 05:53:52.449988 22542570456896 run_lib.py:146] step: 910000, eval_loss: 2.97561e-02
I0212 05:54:12.663900 22542570456896 run_lib.py:133] step: 910050, training_loss: 2.35380e-02
I0212 05:54:30.115522 22542570456896 run_lib.py:133] step: 910100, training_loss: 3.11626e-02
I0212 05:54:30.271952 22542570456896 run_lib.py:146] step: 910100, eval_loss: 3.09375e-02
I0212 05:54:47.789235 22542570456896 run_lib.py:133] step: 910150, training_loss: 2.60650e-02
I0212 05:55:05.277347 22542570456896 run_lib.py:133] step: 910200, training_loss: 3.04877e-02
I0212 05:55:05.435104 22542570456896 run_lib.py:146] step: 910200, eval_loss: 3.12717e-02
I0212 05:55:23.097733 22542570456896 run_lib.py:133] step: 910250, training_loss: 2.90931e-02
I0212 05:55:40.623204 22542570456896 run_lib.py:133] step: 910300, training_loss: 2.47795e-02
I0212 05:55:40.783610 22542570456896 run_lib.py:146] step: 910300, eval_loss: 3.55383e-02
I0212 05:55:58.262030 22542570456896 run_lib.py:133] step: 910350, training_loss: 2.73562e-02
I0212 05:56:15.699685 22542570456896 run_lib.py:133] step: 910400, training_loss: 2.19158e-02
I0212 05:56:15.874465 22542570456896 run_lib.py:146] step: 910400, eval_loss: 3.25751e-02
I0212 05:56:33.508202 22542570456896 run_lib.py:133] step: 910450, training_loss: 2.29756e-02
I0212 05:56:51.026409 22542570456896 run_lib.py:133] step: 910500, training_loss: 3.38715e-02
I0212 05:56:51.189653 22542570456896 run_lib.py:146] step: 910500, eval_loss: 2.62691e-02
I0212 05:57:08.882801 22542570456896 run_lib.py:133] step: 910550, training_loss: 3.78289e-02
I0212 05:57:26.320630 22542570456896 run_lib.py:133] step: 910600, training_loss: 2.64370e-02
I0212 05:57:26.473444 22542570456896 run_lib.py:146] step: 910600, eval_loss: 3.22628e-02
I0212 05:57:44.096679 22542570456896 run_lib.py:133] step: 910650, training_loss: 2.75883e-02
I0212 05:58:01.643208 22542570456896 run_lib.py:133] step: 910700, training_loss: 2.21093e-02
I0212 05:58:01.812299 22542570456896 run_lib.py:146] step: 910700, eval_loss: 2.82252e-02
I0212 05:58:19.469908 22542570456896 run_lib.py:133] step: 910750, training_loss: 2.59548e-02
I0212 05:58:36.944712 22542570456896 run_lib.py:133] step: 910800, training_loss: 2.11848e-02
I0212 05:58:37.103374 22542570456896 run_lib.py:146] step: 910800, eval_loss: 2.77148e-02
I0212 05:58:54.555593 22542570456896 run_lib.py:133] step: 910850, training_loss: 2.48882e-02
I0212 05:59:12.160654 22542570456896 run_lib.py:133] step: 910900, training_loss: 2.95531e-02
I0212 05:59:12.324496 22542570456896 run_lib.py:146] step: 910900, eval_loss: 2.72147e-02
I0212 05:59:29.780848 22542570456896 run_lib.py:133] step: 910950, training_loss: 3.24595e-02
I0212 05:59:47.280726 22542570456896 run_lib.py:133] step: 911000, training_loss: 2.99318e-02
I0212 05:59:47.436868 22542570456896 run_lib.py:146] step: 911000, eval_loss: 3.24051e-02
I0212 06:00:05.105615 22542570456896 run_lib.py:133] step: 911050, training_loss: 3.26485e-02
I0212 06:00:22.751460 22542570456896 run_lib.py:133] step: 911100, training_loss: 3.18340e-02
I0212 06:00:22.911552 22542570456896 run_lib.py:146] step: 911100, eval_loss: 2.36849e-02
I0212 06:00:40.355190 22542570456896 run_lib.py:133] step: 911150, training_loss: 3.37491e-02
I0212 06:00:57.815597 22542570456896 run_lib.py:133] step: 911200, training_loss: 2.48600e-02
I0212 06:00:57.978760 22542570456896 run_lib.py:146] step: 911200, eval_loss: 3.28892e-02
I0212 06:01:15.419216 22542570456896 run_lib.py:133] step: 911250, training_loss: 3.10269e-02
I0212 06:01:33.114690 22542570456896 run_lib.py:133] step: 911300, training_loss: 3.35124e-02
I0212 06:01:33.271672 22542570456896 run_lib.py:146] step: 911300, eval_loss: 3.38254e-02
I0212 06:01:50.723762 22542570456896 run_lib.py:133] step: 911350, training_loss: 3.06400e-02
I0212 06:02:08.178295 22542570456896 run_lib.py:133] step: 911400, training_loss: 2.91722e-02
I0212 06:02:08.336199 22542570456896 run_lib.py:146] step: 911400, eval_loss: 2.77527e-02
I0212 06:02:25.669389 22542570456896 run_lib.py:133] step: 911450, training_loss: 3.33160e-02
I0212 06:02:43.200759 22542570456896 run_lib.py:133] step: 911500, training_loss: 3.08373e-02
I0212 06:02:43.353025 22542570456896 run_lib.py:146] step: 911500, eval_loss: 3.31666e-02
I0212 06:03:00.722063 22542570456896 run_lib.py:133] step: 911550, training_loss: 2.87831e-02
I0212 06:03:18.195609 22542570456896 run_lib.py:133] step: 911600, training_loss: 2.95470e-02
I0212 06:03:18.350600 22542570456896 run_lib.py:146] step: 911600, eval_loss: 3.00407e-02
I0212 06:03:35.700218 22542570456896 run_lib.py:133] step: 911650, training_loss: 2.03147e-02
I0212 06:03:53.052293 22542570456896 run_lib.py:133] step: 911700, training_loss: 2.70842e-02
I0212 06:03:53.210469 22542570456896 run_lib.py:146] step: 911700, eval_loss: 3.17589e-02
I0212 06:04:10.747730 22542570456896 run_lib.py:133] step: 911750, training_loss: 2.00283e-02
I0212 06:04:28.224394 22542570456896 run_lib.py:133] step: 911800, training_loss: 2.45540e-02
I0212 06:04:28.388557 22542570456896 run_lib.py:146] step: 911800, eval_loss: 2.43974e-02
I0212 06:04:45.817864 22542570456896 run_lib.py:133] step: 911850, training_loss: 2.42326e-02
I0212 06:05:03.303724 22542570456896 run_lib.py:133] step: 911900, training_loss: 2.92282e-02
I0212 06:05:03.461246 22542570456896 run_lib.py:146] step: 911900, eval_loss: 2.91707e-02
I0212 06:05:21.153072 22542570456896 run_lib.py:133] step: 911950, training_loss: 3.25141e-02
I0212 06:05:38.594983 22542570456896 run_lib.py:133] step: 912000, training_loss: 2.53506e-02
I0212 06:05:38.753493 22542570456896 run_lib.py:146] step: 912000, eval_loss: 3.48682e-02
I0212 06:05:56.420125 22542570456896 run_lib.py:133] step: 912050, training_loss: 2.34289e-02
I0212 06:06:13.930679 22542570456896 run_lib.py:133] step: 912100, training_loss: 2.39381e-02
I0212 06:06:14.102726 22542570456896 run_lib.py:146] step: 912100, eval_loss: 3.18735e-02
I0212 06:06:31.795638 22542570456896 run_lib.py:133] step: 912150, training_loss: 3.55566e-02
I0212 06:06:49.292151 22542570456896 run_lib.py:133] step: 912200, training_loss: 2.37788e-02
I0212 06:06:49.451675 22542570456896 run_lib.py:146] step: 912200, eval_loss: 2.33445e-02
I0212 06:07:06.908428 22542570456896 run_lib.py:133] step: 912250, training_loss: 2.37398e-02
I0212 06:07:24.542466 22542570456896 run_lib.py:133] step: 912300, training_loss: 3.15374e-02
I0212 06:07:24.707536 22542570456896 run_lib.py:146] step: 912300, eval_loss: 3.46513e-02
I0212 06:07:42.155575 22542570456896 run_lib.py:133] step: 912350, training_loss: 3.07774e-02
I0212 06:07:59.842497 22542570456896 run_lib.py:133] step: 912400, training_loss: 2.20332e-02
I0212 06:07:59.998612 22542570456896 run_lib.py:146] step: 912400, eval_loss: 2.96751e-02
I0212 06:08:17.469065 22542570456896 run_lib.py:133] step: 912450, training_loss: 2.16774e-02
I0212 06:08:34.909226 22542570456896 run_lib.py:133] step: 912500, training_loss: 3.06126e-02
I0212 06:08:35.062448 22542570456896 run_lib.py:146] step: 912500, eval_loss: 3.48233e-02
I0212 06:08:52.713746 22542570456896 run_lib.py:133] step: 912550, training_loss: 2.91379e-02
I0212 06:09:10.195855 22542570456896 run_lib.py:133] step: 912600, training_loss: 2.75173e-02
I0212 06:09:10.365472 22542570456896 run_lib.py:146] step: 912600, eval_loss: 2.04730e-02
I0212 06:09:27.863338 22542570456896 run_lib.py:133] step: 912650, training_loss: 2.60819e-02
I0212 06:09:45.605403 22542570456896 run_lib.py:133] step: 912700, training_loss: 2.65158e-02
I0212 06:09:45.765497 22542570456896 run_lib.py:146] step: 912700, eval_loss: 2.41943e-02
I0212 06:10:03.211384 22542570456896 run_lib.py:133] step: 912750, training_loss: 2.68647e-02
I0212 06:10:20.650820 22542570456896 run_lib.py:133] step: 912800, training_loss: 2.47485e-02
I0212 06:10:20.809204 22542570456896 run_lib.py:146] step: 912800, eval_loss: 2.90274e-02
I0212 06:10:38.343924 22542570456896 run_lib.py:133] step: 912850, training_loss: 2.27836e-02
I0212 06:10:55.830885 22542570456896 run_lib.py:133] step: 912900, training_loss: 3.20806e-02
I0212 06:10:55.992648 22542570456896 run_lib.py:146] step: 912900, eval_loss: 3.23140e-02
I0212 06:11:13.534986 22542570456896 run_lib.py:133] step: 912950, training_loss: 2.26419e-02
I0212 06:11:31.011738 22542570456896 run_lib.py:133] step: 913000, training_loss: 3.43486e-02
I0212 06:11:31.164489 22542570456896 run_lib.py:146] step: 913000, eval_loss: 2.48545e-02
I0212 06:11:48.854964 22542570456896 run_lib.py:133] step: 913050, training_loss: 2.13778e-02
I0212 06:12:06.390325 22542570456896 run_lib.py:133] step: 913100, training_loss: 3.30723e-02
I0212 06:12:06.559880 22542570456896 run_lib.py:146] step: 913100, eval_loss: 3.26930e-02
I0212 06:12:24.006414 22542570456896 run_lib.py:133] step: 913150, training_loss: 3.02321e-02
I0212 06:12:41.503883 22542570456896 run_lib.py:133] step: 913200, training_loss: 2.70567e-02
I0212 06:12:41.671329 22542570456896 run_lib.py:146] step: 913200, eval_loss: 2.74180e-02
I0212 06:12:59.400282 22542570456896 run_lib.py:133] step: 913250, training_loss: 2.06343e-02
I0212 06:13:16.877928 22542570456896 run_lib.py:133] step: 913300, training_loss: 2.60286e-02
I0212 06:13:17.034765 22542570456896 run_lib.py:146] step: 913300, eval_loss: 2.66202e-02
I0212 06:13:34.636006 22542570456896 run_lib.py:133] step: 913350, training_loss: 2.64763e-02
I0212 06:13:52.088510 22542570456896 run_lib.py:133] step: 913400, training_loss: 3.00380e-02
I0212 06:13:52.241201 22542570456896 run_lib.py:146] step: 913400, eval_loss: 2.84048e-02
I0212 06:14:09.917925 22542570456896 run_lib.py:133] step: 913450, training_loss: 2.37265e-02
I0212 06:14:27.383007 22542570456896 run_lib.py:133] step: 913500, training_loss: 2.40021e-02
I0212 06:14:27.550811 22542570456896 run_lib.py:146] step: 913500, eval_loss: 2.58632e-02
I0212 06:14:45.207298 22542570456896 run_lib.py:133] step: 913550, training_loss: 3.63483e-02
I0212 06:15:02.725332 22542570456896 run_lib.py:133] step: 913600, training_loss: 2.59876e-02
I0212 06:15:02.885696 22542570456896 run_lib.py:146] step: 913600, eval_loss: 2.98616e-02
I0212 06:15:20.385854 22542570456896 run_lib.py:133] step: 913650, training_loss: 2.54565e-02
I0212 06:15:37.997400 22542570456896 run_lib.py:133] step: 913700, training_loss: 2.65511e-02
I0212 06:15:38.172378 22542570456896 run_lib.py:146] step: 913700, eval_loss: 3.06766e-02
I0212 06:15:55.666402 22542570456896 run_lib.py:133] step: 913750, training_loss: 2.78440e-02
I0212 06:16:13.159613 22542570456896 run_lib.py:133] step: 913800, training_loss: 2.22394e-02
I0212 06:16:13.325397 22542570456896 run_lib.py:146] step: 913800, eval_loss: 3.66859e-02
I0212 06:16:30.995328 22542570456896 run_lib.py:133] step: 913850, training_loss: 1.99564e-02
I0212 06:16:48.464956 22542570456896 run_lib.py:133] step: 913900, training_loss: 2.80973e-02
I0212 06:16:48.616478 22542570456896 run_lib.py:146] step: 913900, eval_loss: 2.59028e-02
I0212 06:17:06.234229 22542570456896 run_lib.py:133] step: 913950, training_loss: 3.31896e-02
I0212 06:17:23.717959 22542570456896 run_lib.py:133] step: 914000, training_loss: 2.92596e-02
I0212 06:17:23.888689 22542570456896 run_lib.py:146] step: 914000, eval_loss: 2.63126e-02
I0212 06:17:41.418135 22542570456896 run_lib.py:133] step: 914050, training_loss: 2.82564e-02
I0212 06:17:59.111387 22542570456896 run_lib.py:133] step: 914100, training_loss: 2.44498e-02
I0212 06:17:59.272229 22542570456896 run_lib.py:146] step: 914100, eval_loss: 2.65489e-02
I0212 06:18:16.770528 22542570456896 run_lib.py:133] step: 914150, training_loss: 3.76211e-02
I0212 06:18:34.228389 22542570456896 run_lib.py:133] step: 914200, training_loss: 3.11941e-02
I0212 06:18:34.384428 22542570456896 run_lib.py:146] step: 914200, eval_loss: 3.22581e-02
I0212 06:18:51.879059 22542570456896 run_lib.py:133] step: 914250, training_loss: 2.79930e-02
I0212 06:19:09.573096 22542570456896 run_lib.py:133] step: 914300, training_loss: 2.60802e-02
I0212 06:19:09.731630 22542570456896 run_lib.py:146] step: 914300, eval_loss: 2.69402e-02
I0212 06:19:27.226356 22542570456896 run_lib.py:133] step: 914350, training_loss: 2.95414e-02
I0212 06:19:44.752048 22542570456896 run_lib.py:133] step: 914400, training_loss: 2.41270e-02
I0212 06:19:44.910985 22542570456896 run_lib.py:146] step: 914400, eval_loss: 2.93935e-02
I0212 06:20:02.371183 22542570456896 run_lib.py:133] step: 914450, training_loss: 2.02573e-02
I0212 06:20:19.823307 22542570456896 run_lib.py:133] step: 914500, training_loss: 3.15814e-02
I0212 06:20:19.985719 22542570456896 run_lib.py:146] step: 914500, eval_loss: 2.60284e-02
I0212 06:20:37.637431 22542570456896 run_lib.py:133] step: 914550, training_loss: 2.60674e-02
I0212 06:20:55.251810 22542570456896 run_lib.py:133] step: 914600, training_loss: 2.35267e-02
I0212 06:20:55.408587 22542570456896 run_lib.py:146] step: 914600, eval_loss: 3.33616e-02
I0212 06:21:12.857366 22542570456896 run_lib.py:133] step: 914650, training_loss: 2.60821e-02
I0212 06:21:30.318617 22542570456896 run_lib.py:133] step: 914700, training_loss: 2.90169e-02
I0212 06:21:30.475573 22542570456896 run_lib.py:146] step: 914700, eval_loss: 2.13875e-02
I0212 06:21:48.087305 22542570456896 run_lib.py:133] step: 914750, training_loss: 2.99975e-02
I0212 06:22:05.557880 22542570456896 run_lib.py:133] step: 914800, training_loss: 2.63700e-02
I0212 06:22:05.715704 22542570456896 run_lib.py:146] step: 914800, eval_loss: 3.01075e-02
I0212 06:22:23.417714 22542570456896 run_lib.py:133] step: 914850, training_loss: 3.34505e-02
I0212 06:22:40.892713 22542570456896 run_lib.py:133] step: 914900, training_loss: 2.44630e-02
I0212 06:22:41.047823 22542570456896 run_lib.py:146] step: 914900, eval_loss: 3.28738e-02
I0212 06:22:58.709429 22542570456896 run_lib.py:133] step: 914950, training_loss: 3.56651e-02
I0212 06:23:16.214720 22542570456896 run_lib.py:133] step: 915000, training_loss: 2.37560e-02
I0212 06:23:16.374647 22542570456896 run_lib.py:146] step: 915000, eval_loss: 3.06054e-02
I0212 06:23:33.810016 22542570456896 run_lib.py:133] step: 915050, training_loss: 2.76787e-02
I0212 06:23:51.464961 22542570456896 run_lib.py:133] step: 915100, training_loss: 2.64637e-02
I0212 06:23:51.626441 22542570456896 run_lib.py:146] step: 915100, eval_loss: 3.87462e-02
I0212 06:24:09.119144 22542570456896 run_lib.py:133] step: 915150, training_loss: 2.51396e-02
I0212 06:24:26.826317 22542570456896 run_lib.py:133] step: 915200, training_loss: 2.29128e-02
I0212 06:24:26.983697 22542570456896 run_lib.py:146] step: 915200, eval_loss: 3.67465e-02
I0212 06:24:44.463030 22542570456896 run_lib.py:133] step: 915250, training_loss: 2.99089e-02
I0212 06:25:01.896456 22542570456896 run_lib.py:133] step: 915300, training_loss: 2.55585e-02
I0212 06:25:02.057875 22542570456896 run_lib.py:146] step: 915300, eval_loss: 3.10095e-02
I0212 06:25:19.662062 22542570456896 run_lib.py:133] step: 915350, training_loss: 2.89196e-02
I0212 06:25:37.214358 22542570456896 run_lib.py:133] step: 915400, training_loss: 2.36333e-02
I0212 06:25:37.381734 22542570456896 run_lib.py:146] step: 915400, eval_loss: 2.69765e-02
I0212 06:25:54.890995 22542570456896 run_lib.py:133] step: 915450, training_loss: 2.52703e-02
I0212 06:26:12.578308 22542570456896 run_lib.py:133] step: 915500, training_loss: 3.27044e-02
I0212 06:26:12.737381 22542570456896 run_lib.py:146] step: 915500, eval_loss: 3.17438e-02
I0212 06:26:30.220542 22542570456896 run_lib.py:133] step: 915550, training_loss: 2.77300e-02
I0212 06:26:47.697521 22542570456896 run_lib.py:133] step: 915600, training_loss: 3.07394e-02
I0212 06:26:48.008321 22542570456896 run_lib.py:146] step: 915600, eval_loss: 2.20109e-02
I0212 06:27:05.449719 22542570456896 run_lib.py:133] step: 915650, training_loss: 2.41277e-02
I0212 06:27:22.946157 22542570456896 run_lib.py:133] step: 915700, training_loss: 2.74129e-02
I0212 06:27:23.104311 22542570456896 run_lib.py:146] step: 915700, eval_loss: 2.43471e-02
I0212 06:27:40.607881 22542570456896 run_lib.py:133] step: 915750, training_loss: 2.72081e-02
I0212 06:27:58.092908 22542570456896 run_lib.py:133] step: 915800, training_loss: 2.74689e-02
I0212 06:27:58.246505 22542570456896 run_lib.py:146] step: 915800, eval_loss: 3.15953e-02
I0212 06:28:15.902796 22542570456896 run_lib.py:133] step: 915850, training_loss: 3.50914e-02
I0212 06:28:33.449238 22542570456896 run_lib.py:133] step: 915900, training_loss: 2.90705e-02
I0212 06:28:33.623647 22542570456896 run_lib.py:146] step: 915900, eval_loss: 3.19089e-02
I0212 06:28:51.114075 22542570456896 run_lib.py:133] step: 915950, training_loss: 2.87525e-02
I0212 06:29:08.627386 22542570456896 run_lib.py:133] step: 916000, training_loss: 3.03131e-02
I0212 06:29:08.788434 22542570456896 run_lib.py:146] step: 916000, eval_loss: 2.50527e-02
I0212 06:29:26.384012 22542570456896 run_lib.py:133] step: 916050, training_loss: 2.23369e-02
I0212 06:29:43.897874 22542570456896 run_lib.py:133] step: 916100, training_loss: 2.39674e-02
I0212 06:29:44.054428 22542570456896 run_lib.py:146] step: 916100, eval_loss: 2.71646e-02
I0212 06:30:01.489672 22542570456896 run_lib.py:133] step: 916150, training_loss: 2.03145e-02
I0212 06:30:19.015471 22542570456896 run_lib.py:133] step: 916200, training_loss: 2.46665e-02
I0212 06:30:19.173784 22542570456896 run_lib.py:146] step: 916200, eval_loss: 2.92292e-02
I0212 06:30:36.864383 22542570456896 run_lib.py:133] step: 916250, training_loss: 3.84249e-02
I0212 06:30:54.317160 22542570456896 run_lib.py:133] step: 916300, training_loss: 3.01417e-02
I0212 06:30:54.471425 22542570456896 run_lib.py:146] step: 916300, eval_loss: 2.52879e-02
I0212 06:31:12.068223 22542570456896 run_lib.py:133] step: 916350, training_loss: 2.34836e-02
I0212 06:31:29.529576 22542570456896 run_lib.py:133] step: 916400, training_loss: 2.39241e-02
I0212 06:31:29.693662 22542570456896 run_lib.py:146] step: 916400, eval_loss: 3.52963e-02
I0212 06:31:47.286866 22542570456896 run_lib.py:133] step: 916450, training_loss: 2.58724e-02
I0212 06:32:04.768958 22542570456896 run_lib.py:133] step: 916500, training_loss: 2.87575e-02
I0212 06:32:04.941869 22542570456896 run_lib.py:146] step: 916500, eval_loss: 3.23120e-02
I0212 06:32:22.425044 22542570456896 run_lib.py:133] step: 916550, training_loss: 2.41716e-02
I0212 06:32:40.100606 22542570456896 run_lib.py:133] step: 916600, training_loss: 2.86752e-02
I0212 06:32:40.255011 22542570456896 run_lib.py:146] step: 916600, eval_loss: 2.66989e-02
I0212 06:32:57.654828 22542570456896 run_lib.py:133] step: 916650, training_loss: 3.01930e-02
I0212 06:33:15.169178 22542570456896 run_lib.py:133] step: 916700, training_loss: 2.32648e-02
I0212 06:33:15.321987 22542570456896 run_lib.py:146] step: 916700, eval_loss: 2.96895e-02
I0212 06:33:32.683510 22542570456896 run_lib.py:133] step: 916750, training_loss: 2.75815e-02
I0212 06:33:50.067551 22542570456896 run_lib.py:133] step: 916800, training_loss: 2.47200e-02
I0212 06:33:50.223557 22542570456896 run_lib.py:146] step: 916800, eval_loss: 3.43199e-02
I0212 06:34:07.809680 22542570456896 run_lib.py:133] step: 916850, training_loss: 3.32353e-02
I0212 06:34:25.173338 22542570456896 run_lib.py:133] step: 916900, training_loss: 2.54754e-02
I0212 06:34:25.331323 22542570456896 run_lib.py:146] step: 916900, eval_loss: 2.97746e-02
I0212 06:34:42.740999 22542570456896 run_lib.py:133] step: 916950, training_loss: 2.16250e-02
I0212 06:35:00.092921 22542570456896 run_lib.py:133] step: 917000, training_loss: 2.38421e-02
I0212 06:35:00.245626 22542570456896 run_lib.py:146] step: 917000, eval_loss: 2.70965e-02
I0212 06:35:17.812191 22542570456896 run_lib.py:133] step: 917050, training_loss: 2.74720e-02
I0212 06:35:35.337586 22542570456896 run_lib.py:133] step: 917100, training_loss: 2.58298e-02
I0212 06:35:35.502319 22542570456896 run_lib.py:146] step: 917100, eval_loss: 2.75822e-02
I0212 06:35:53.159005 22542570456896 run_lib.py:133] step: 917150, training_loss: 2.61200e-02
I0212 06:36:10.597818 22542570456896 run_lib.py:133] step: 917200, training_loss: 3.00111e-02
I0212 06:36:10.752271 22542570456896 run_lib.py:146] step: 917200, eval_loss: 3.46361e-02
I0212 06:36:28.206665 22542570456896 run_lib.py:133] step: 917250, training_loss: 2.92389e-02
I0212 06:36:45.688994 22542570456896 run_lib.py:133] step: 917300, training_loss: 3.16378e-02
I0212 06:36:45.845644 22542570456896 run_lib.py:146] step: 917300, eval_loss: 2.69862e-02
I0212 06:37:03.492019 22542570456896 run_lib.py:133] step: 917350, training_loss: 2.49172e-02
I0212 06:37:21.085441 22542570456896 run_lib.py:133] step: 917400, training_loss: 2.13891e-02
I0212 06:37:21.251519 22542570456896 run_lib.py:146] step: 917400, eval_loss: 2.81988e-02
I0212 06:37:38.778589 22542570456896 run_lib.py:133] step: 917450, training_loss: 1.80972e-02
I0212 06:37:56.287524 22542570456896 run_lib.py:133] step: 917500, training_loss: 2.95085e-02
I0212 06:37:56.445603 22542570456896 run_lib.py:146] step: 917500, eval_loss: 2.84717e-02
I0212 06:38:14.123746 22542570456896 run_lib.py:133] step: 917550, training_loss: 2.79727e-02
I0212 06:38:31.609144 22542570456896 run_lib.py:133] step: 917600, training_loss: 2.38239e-02
I0212 06:38:31.772511 22542570456896 run_lib.py:146] step: 917600, eval_loss: 3.71080e-02
I0212 06:38:49.438075 22542570456896 run_lib.py:133] step: 917650, training_loss: 2.09989e-02
I0212 06:39:06.935961 22542570456896 run_lib.py:133] step: 917700, training_loss: 2.55098e-02
I0212 06:39:07.088533 22542570456896 run_lib.py:146] step: 917700, eval_loss: 2.95923e-02
I0212 06:39:24.783506 22542570456896 run_lib.py:133] step: 917750, training_loss: 2.61962e-02
I0212 06:39:42.215937 22542570456896 run_lib.py:133] step: 917800, training_loss: 2.92010e-02
I0212 06:39:42.369959 22542570456896 run_lib.py:146] step: 917800, eval_loss: 3.19301e-02
I0212 06:39:59.931292 22542570456896 run_lib.py:133] step: 917850, training_loss: 1.73509e-02
I0212 06:40:17.420651 22542570456896 run_lib.py:133] step: 917900, training_loss: 2.85191e-02
I0212 06:40:17.598489 22542570456896 run_lib.py:146] step: 917900, eval_loss: 2.58197e-02
I0212 06:40:35.101617 22542570456896 run_lib.py:133] step: 917950, training_loss: 2.64956e-02
I0212 06:40:52.764207 22542570456896 run_lib.py:133] step: 918000, training_loss: 2.87872e-02
I0212 06:40:52.920432 22542570456896 run_lib.py:146] step: 918000, eval_loss: 2.74185e-02
I0212 06:41:10.393944 22542570456896 run_lib.py:133] step: 918050, training_loss: 3.21071e-02
I0212 06:41:27.812690 22542570456896 run_lib.py:133] step: 918100, training_loss: 3.11275e-02
I0212 06:41:27.978418 22542570456896 run_lib.py:146] step: 918100, eval_loss: 2.66247e-02
I0212 06:41:45.608113 22542570456896 run_lib.py:133] step: 918150, training_loss: 2.77014e-02
I0212 06:42:03.282710 22542570456896 run_lib.py:133] step: 918200, training_loss: 2.84081e-02
I0212 06:42:03.440608 22542570456896 run_lib.py:146] step: 918200, eval_loss: 2.60572e-02
I0212 06:42:20.971886 22542570456896 run_lib.py:133] step: 918250, training_loss: 2.64272e-02
I0212 06:42:38.434275 22542570456896 run_lib.py:133] step: 918300, training_loss: 3.22926e-02
I0212 06:42:38.594478 22542570456896 run_lib.py:146] step: 918300, eval_loss: 2.56644e-02
I0212 06:42:56.083479 22542570456896 run_lib.py:133] step: 918350, training_loss: 2.86528e-02
I0212 06:43:13.713320 22542570456896 run_lib.py:133] step: 918400, training_loss: 2.59041e-02
I0212 06:43:13.869082 22542570456896 run_lib.py:146] step: 918400, eval_loss: 2.76323e-02
I0212 06:43:31.362055 22542570456896 run_lib.py:133] step: 918450, training_loss: 3.04638e-02
I0212 06:43:48.898748 22542570456896 run_lib.py:133] step: 918500, training_loss: 3.27791e-02
I0212 06:43:49.058200 22542570456896 run_lib.py:146] step: 918500, eval_loss: 3.11303e-02
I0212 06:44:06.531772 22542570456896 run_lib.py:133] step: 918550, training_loss: 3.00255e-02
I0212 06:44:24.181333 22542570456896 run_lib.py:133] step: 918600, training_loss: 2.32534e-02
I0212 06:44:24.336463 22542570456896 run_lib.py:146] step: 918600, eval_loss: 3.22116e-02
I0212 06:44:41.812467 22542570456896 run_lib.py:133] step: 918650, training_loss: 2.75962e-02
I0212 06:44:59.376464 22542570456896 run_lib.py:133] step: 918700, training_loss: 2.62378e-02
I0212 06:44:59.535705 22542570456896 run_lib.py:146] step: 918700, eval_loss: 2.76974e-02
I0212 06:45:17.083955 22542570456896 run_lib.py:133] step: 918750, training_loss: 2.89553e-02
I0212 06:45:34.539506 22542570456896 run_lib.py:133] step: 918800, training_loss: 3.75522e-02
I0212 06:45:34.699414 22542570456896 run_lib.py:146] step: 918800, eval_loss: 2.55763e-02
I0212 06:45:52.347941 22542570456896 run_lib.py:133] step: 918850, training_loss: 2.80876e-02
I0212 06:46:09.902447 22542570456896 run_lib.py:133] step: 918900, training_loss: 2.10227e-02
I0212 06:46:10.059400 22542570456896 run_lib.py:146] step: 918900, eval_loss: 2.91232e-02
I0212 06:46:27.596272 22542570456896 run_lib.py:133] step: 918950, training_loss: 2.61087e-02
I0212 06:46:45.114073 22542570456896 run_lib.py:133] step: 919000, training_loss: 2.08251e-02
I0212 06:46:45.272035 22542570456896 run_lib.py:146] step: 919000, eval_loss: 2.58262e-02
I0212 06:47:02.982411 22542570456896 run_lib.py:133] step: 919050, training_loss: 2.18358e-02
I0212 06:47:20.484763 22542570456896 run_lib.py:133] step: 919100, training_loss: 2.52119e-02
I0212 06:47:20.646477 22542570456896 run_lib.py:146] step: 919100, eval_loss: 2.09325e-02
I0212 06:47:38.268983 22542570456896 run_lib.py:133] step: 919150, training_loss: 3.33663e-02
I0212 06:47:55.734032 22542570456896 run_lib.py:133] step: 919200, training_loss: 2.47957e-02
I0212 06:47:55.896664 22542570456896 run_lib.py:146] step: 919200, eval_loss: 3.06800e-02
I0212 06:48:13.541655 22542570456896 run_lib.py:133] step: 919250, training_loss: 2.79318e-02
I0212 06:48:31.074998 22542570456896 run_lib.py:133] step: 919300, training_loss: 2.50058e-02
I0212 06:48:31.237460 22542570456896 run_lib.py:146] step: 919300, eval_loss: 2.70232e-02
I0212 06:48:48.699629 22542570456896 run_lib.py:133] step: 919350, training_loss: 2.33592e-02
I0212 06:49:06.341753 22542570456896 run_lib.py:133] step: 919400, training_loss: 2.91527e-02
I0212 06:49:06.498422 22542570456896 run_lib.py:146] step: 919400, eval_loss: 3.97913e-02
I0212 06:49:23.986971 22542570456896 run_lib.py:133] step: 919450, training_loss: 2.95521e-02
I0212 06:49:41.636852 22542570456896 run_lib.py:133] step: 919500, training_loss: 2.95318e-02
I0212 06:49:41.792419 22542570456896 run_lib.py:146] step: 919500, eval_loss: 2.35167e-02
I0212 06:49:59.258876 22542570456896 run_lib.py:133] step: 919550, training_loss: 2.42381e-02
I0212 06:50:16.719092 22542570456896 run_lib.py:133] step: 919600, training_loss: 2.92393e-02
I0212 06:50:16.883471 22542570456896 run_lib.py:146] step: 919600, eval_loss: 3.41092e-02
I0212 06:50:34.611999 22542570456896 run_lib.py:133] step: 919650, training_loss: 2.88279e-02
I0212 06:50:52.144609 22542570456896 run_lib.py:133] step: 919700, training_loss: 3.22252e-02
I0212 06:50:52.298453 22542570456896 run_lib.py:146] step: 919700, eval_loss: 3.68427e-02
I0212 06:51:09.739651 22542570456896 run_lib.py:133] step: 919750, training_loss: 2.90384e-02
I0212 06:51:27.362553 22542570456896 run_lib.py:133] step: 919800, training_loss: 2.56437e-02
I0212 06:51:27.543512 22542570456896 run_lib.py:146] step: 919800, eval_loss: 2.44241e-02
I0212 06:51:45.074896 22542570456896 run_lib.py:133] step: 919850, training_loss: 3.66797e-02
I0212 06:52:02.542854 22542570456896 run_lib.py:133] step: 919900, training_loss: 3.06070e-02
I0212 06:52:02.701706 22542570456896 run_lib.py:146] step: 919900, eval_loss: 2.82856e-02
I0212 06:52:20.304071 22542570456896 run_lib.py:133] step: 919950, training_loss: 2.82297e-02
I0212 06:52:37.755831 22542570456896 run_lib.py:133] step: 920000, training_loss: 3.85479e-02
I0212 06:52:38.503283 22542570456896 run_lib.py:146] step: 920000, eval_loss: 2.70355e-02
I0212 06:52:58.654419 22542570456896 run_lib.py:133] step: 920050, training_loss: 2.86815e-02
I0212 06:53:16.139251 22542570456896 run_lib.py:133] step: 920100, training_loss: 2.60324e-02
I0212 06:53:16.294337 22542570456896 run_lib.py:146] step: 920100, eval_loss: 3.52987e-02
I0212 06:53:33.979939 22542570456896 run_lib.py:133] step: 920150, training_loss: 3.48713e-02
I0212 06:53:51.420808 22542570456896 run_lib.py:133] step: 920200, training_loss: 3.50219e-02
I0212 06:53:51.578184 22542570456896 run_lib.py:146] step: 920200, eval_loss: 2.54326e-02
I0212 06:54:09.074891 22542570456896 run_lib.py:133] step: 920250, training_loss: 2.65905e-02
I0212 06:54:26.557083 22542570456896 run_lib.py:133] step: 920300, training_loss: 2.64581e-02
I0212 06:54:26.713137 22542570456896 run_lib.py:146] step: 920300, eval_loss: 3.21738e-02
I0212 06:54:44.167933 22542570456896 run_lib.py:133] step: 920350, training_loss: 1.58574e-02
I0212 06:55:01.716456 22542570456896 run_lib.py:133] step: 920400, training_loss: 2.10268e-02
I0212 06:55:01.870439 22542570456896 run_lib.py:146] step: 920400, eval_loss: 3.58664e-02
I0212 06:55:19.539853 22542570456896 run_lib.py:133] step: 920450, training_loss: 2.45320e-02
I0212 06:55:37.082631 22542570456896 run_lib.py:133] step: 920500, training_loss: 2.52758e-02
I0212 06:55:37.239751 22542570456896 run_lib.py:146] step: 920500, eval_loss: 2.56553e-02
I0212 06:55:54.707063 22542570456896 run_lib.py:133] step: 920550, training_loss: 2.54843e-02
I0212 06:56:12.183274 22542570456896 run_lib.py:133] step: 920600, training_loss: 2.26177e-02
I0212 06:56:12.337366 22542570456896 run_lib.py:146] step: 920600, eval_loss: 2.88173e-02
I0212 06:56:30.020960 22542570456896 run_lib.py:133] step: 920650, training_loss: 2.62199e-02
I0212 06:56:47.510166 22542570456896 run_lib.py:133] step: 920700, training_loss: 2.81309e-02
I0212 06:56:47.667886 22542570456896 run_lib.py:146] step: 920700, eval_loss: 2.75483e-02
I0212 06:57:05.359464 22542570456896 run_lib.py:133] step: 920750, training_loss: 2.76283e-02
I0212 06:57:22.830879 22542570456896 run_lib.py:133] step: 920800, training_loss: 3.12081e-02
I0212 06:57:22.990693 22542570456896 run_lib.py:146] step: 920800, eval_loss: 2.40757e-02
I0212 06:57:40.595846 22542570456896 run_lib.py:133] step: 920850, training_loss: 2.31145e-02
I0212 06:57:58.101149 22542570456896 run_lib.py:133] step: 920900, training_loss: 2.14866e-02
I0212 06:57:58.268457 22542570456896 run_lib.py:146] step: 920900, eval_loss: 3.10300e-02
I0212 06:58:15.935589 22542570456896 run_lib.py:133] step: 920950, training_loss: 2.85358e-02
I0212 06:58:33.440684 22542570456896 run_lib.py:133] step: 921000, training_loss: 2.70068e-02
I0212 06:58:33.599673 22542570456896 run_lib.py:146] step: 921000, eval_loss: 2.45837e-02
I0212 06:58:51.097746 22542570456896 run_lib.py:133] step: 921050, training_loss: 2.64942e-02
I0212 06:59:08.731188 22542570456896 run_lib.py:133] step: 921100, training_loss: 2.86675e-02
I0212 06:59:08.884417 22542570456896 run_lib.py:146] step: 921100, eval_loss: 3.45149e-02
I0212 06:59:26.321648 22542570456896 run_lib.py:133] step: 921150, training_loss: 3.10515e-02
I0212 06:59:43.817801 22542570456896 run_lib.py:133] step: 921200, training_loss: 2.69307e-02
I0212 06:59:43.987022 22542570456896 run_lib.py:146] step: 921200, eval_loss: 2.35161e-02
I0212 07:00:01.694321 22542570456896 run_lib.py:133] step: 921250, training_loss: 2.43244e-02
I0212 07:00:19.172461 22542570456896 run_lib.py:133] step: 921300, training_loss: 3.08133e-02
I0212 07:00:19.330378 22542570456896 run_lib.py:146] step: 921300, eval_loss: 3.16159e-02
I0212 07:00:36.947647 22542570456896 run_lib.py:133] step: 921350, training_loss: 2.88805e-02
I0212 07:00:54.393197 22542570456896 run_lib.py:133] step: 921400, training_loss: 2.06116e-02
I0212 07:00:54.550330 22542570456896 run_lib.py:146] step: 921400, eval_loss: 3.06495e-02
I0212 07:01:12.020531 22542570456896 run_lib.py:133] step: 921450, training_loss: 2.58188e-02
I0212 07:01:29.729204 22542570456896 run_lib.py:133] step: 921500, training_loss: 2.41216e-02
I0212 07:01:29.894729 22542570456896 run_lib.py:146] step: 921500, eval_loss: 3.36826e-02
I0212 07:01:47.431513 22542570456896 run_lib.py:133] step: 921550, training_loss: 2.49673e-02
I0212 07:02:04.905544 22542570456896 run_lib.py:133] step: 921600, training_loss: 2.19870e-02
I0212 07:02:05.059363 22542570456896 run_lib.py:146] step: 921600, eval_loss: 2.74072e-02
I0212 07:02:22.529944 22542570456896 run_lib.py:133] step: 921650, training_loss: 2.89398e-02
I0212 07:02:40.215462 22542570456896 run_lib.py:133] step: 921700, training_loss: 3.48649e-02
I0212 07:02:40.377666 22542570456896 run_lib.py:146] step: 921700, eval_loss: 3.30579e-02
I0212 07:02:57.858169 22542570456896 run_lib.py:133] step: 921750, training_loss: 3.05424e-02
I0212 07:03:15.412517 22542570456896 run_lib.py:133] step: 921800, training_loss: 2.62784e-02
I0212 07:03:15.569569 22542570456896 run_lib.py:146] step: 921800, eval_loss: 2.78365e-02
I0212 07:03:33.014725 22542570456896 run_lib.py:133] step: 921850, training_loss: 3.40950e-02
I0212 07:03:50.366851 22542570456896 run_lib.py:133] step: 921900, training_loss: 3.09978e-02
I0212 07:03:50.523362 22542570456896 run_lib.py:146] step: 921900, eval_loss: 3.18935e-02
I0212 07:04:08.099509 22542570456896 run_lib.py:133] step: 921950, training_loss: 2.69839e-02
I0212 07:04:25.482115 22542570456896 run_lib.py:133] step: 922000, training_loss: 2.83117e-02
I0212 07:04:25.634011 22542570456896 run_lib.py:146] step: 922000, eval_loss: 2.95894e-02
I0212 07:04:43.036746 22542570456896 run_lib.py:133] step: 922050, training_loss: 2.84799e-02
I0212 07:05:00.433240 22542570456896 run_lib.py:133] step: 922100, training_loss: 3.89620e-02
I0212 07:05:00.603943 22542570456896 run_lib.py:146] step: 922100, eval_loss: 3.25572e-02
I0212 07:05:18.220534 22542570456896 run_lib.py:133] step: 922150, training_loss: 2.41047e-02
I0212 07:05:35.590369 22542570456896 run_lib.py:133] step: 922200, training_loss: 2.75713e-02
I0212 07:05:35.754259 22542570456896 run_lib.py:146] step: 922200, eval_loss: 2.73146e-02
I0212 07:05:53.342522 22542570456896 run_lib.py:133] step: 922250, training_loss: 3.04977e-02
I0212 07:06:10.786838 22542570456896 run_lib.py:133] step: 922300, training_loss: 2.56974e-02
I0212 07:06:10.941711 22542570456896 run_lib.py:146] step: 922300, eval_loss: 2.97963e-02
I0212 07:06:28.563659 22542570456896 run_lib.py:133] step: 922350, training_loss: 2.98924e-02
I0212 07:06:46.076936 22542570456896 run_lib.py:133] step: 922400, training_loss: 2.88617e-02
I0212 07:06:46.235828 22542570456896 run_lib.py:146] step: 922400, eval_loss: 3.22534e-02
I0212 07:07:03.761915 22542570456896 run_lib.py:133] step: 922450, training_loss: 2.50959e-02
I0212 07:07:21.410606 22542570456896 run_lib.py:133] step: 922500, training_loss: 2.92337e-02
I0212 07:07:21.563490 22542570456896 run_lib.py:146] step: 922500, eval_loss: 3.01932e-02
I0212 07:07:39.041642 22542570456896 run_lib.py:133] step: 922550, training_loss: 3.19942e-02
I0212 07:07:56.644167 22542570456896 run_lib.py:133] step: 922600, training_loss: 3.01117e-02
I0212 07:07:56.805443 22542570456896 run_lib.py:146] step: 922600, eval_loss: 2.70144e-02
I0212 07:08:14.333562 22542570456896 run_lib.py:133] step: 922650, training_loss: 3.08893e-02
I0212 07:08:31.864927 22542570456896 run_lib.py:133] step: 922700, training_loss: 2.81511e-02
I0212 07:08:32.024488 22542570456896 run_lib.py:146] step: 922700, eval_loss: 2.80783e-02
I0212 07:08:49.710379 22542570456896 run_lib.py:133] step: 922750, training_loss: 2.98440e-02
I0212 07:09:07.173942 22542570456896 run_lib.py:133] step: 922800, training_loss: 2.87585e-02
I0212 07:09:07.332457 22542570456896 run_lib.py:146] step: 922800, eval_loss: 3.16410e-02
I0212 07:09:24.812124 22542570456896 run_lib.py:133] step: 922850, training_loss: 2.27569e-02
I0212 07:09:42.440605 22542570456896 run_lib.py:133] step: 922900, training_loss: 2.84014e-02
I0212 07:09:42.603685 22542570456896 run_lib.py:146] step: 922900, eval_loss: 3.10904e-02
I0212 07:10:00.099349 22542570456896 run_lib.py:133] step: 922950, training_loss: 3.02240e-02
I0212 07:10:17.588443 22542570456896 run_lib.py:133] step: 923000, training_loss: 2.23043e-02
I0212 07:10:17.931602 22542570456896 run_lib.py:146] step: 923000, eval_loss: 3.04324e-02
I0212 07:10:35.463185 22542570456896 run_lib.py:133] step: 923050, training_loss: 2.45931e-02
I0212 07:10:52.924164 22542570456896 run_lib.py:133] step: 923100, training_loss: 3.84545e-02
I0212 07:10:53.079685 22542570456896 run_lib.py:146] step: 923100, eval_loss: 3.42219e-02
I0212 07:11:10.545849 22542570456896 run_lib.py:133] step: 923150, training_loss: 2.89946e-02
I0212 07:11:27.992381 22542570456896 run_lib.py:133] step: 923200, training_loss: 3.09989e-02
I0212 07:11:28.166400 22542570456896 run_lib.py:146] step: 923200, eval_loss: 2.21266e-02
I0212 07:11:45.822648 22542570456896 run_lib.py:133] step: 923250, training_loss: 2.54537e-02
I0212 07:12:03.436535 22542570456896 run_lib.py:133] step: 923300, training_loss: 2.98877e-02
I0212 07:12:03.593698 22542570456896 run_lib.py:146] step: 923300, eval_loss: 2.93850e-02
I0212 07:12:21.090254 22542570456896 run_lib.py:133] step: 923350, training_loss: 2.79929e-02
I0212 07:12:38.534560 22542570456896 run_lib.py:133] step: 923400, training_loss: 2.61984e-02
I0212 07:12:38.690406 22542570456896 run_lib.py:146] step: 923400, eval_loss: 2.82325e-02
I0212 07:12:56.310222 22542570456896 run_lib.py:133] step: 923450, training_loss: 2.25786e-02
I0212 07:13:13.925364 22542570456896 run_lib.py:133] step: 923500, training_loss: 2.28640e-02
I0212 07:13:14.079613 22542570456896 run_lib.py:146] step: 923500, eval_loss: 2.50207e-02
I0212 07:13:31.579714 22542570456896 run_lib.py:133] step: 923550, training_loss: 2.69523e-02
I0212 07:13:49.067296 22542570456896 run_lib.py:133] step: 923600, training_loss: 2.93134e-02
I0212 07:13:49.227689 22542570456896 run_lib.py:146] step: 923600, eval_loss: 2.81560e-02
I0212 07:14:06.845166 22542570456896 run_lib.py:133] step: 923650, training_loss: 2.58666e-02
I0212 07:14:24.306577 22542570456896 run_lib.py:133] step: 923700, training_loss: 2.83732e-02
I0212 07:14:24.467437 22542570456896 run_lib.py:146] step: 923700, eval_loss: 3.22280e-02
I0212 07:14:42.128133 22542570456896 run_lib.py:133] step: 923750, training_loss: 2.97243e-02
I0212 07:14:59.635388 22542570456896 run_lib.py:133] step: 923800, training_loss: 2.69043e-02
I0212 07:14:59.793218 22542570456896 run_lib.py:146] step: 923800, eval_loss: 2.41250e-02
I0212 07:15:17.461646 22542570456896 run_lib.py:133] step: 923850, training_loss: 3.04418e-02
I0212 07:15:34.903898 22542570456896 run_lib.py:133] step: 923900, training_loss: 2.66426e-02
I0212 07:15:35.057249 22542570456896 run_lib.py:146] step: 923900, eval_loss: 3.47113e-02
I0212 07:15:52.508213 22542570456896 run_lib.py:133] step: 923950, training_loss: 2.05173e-02
I0212 07:16:10.122559 22542570456896 run_lib.py:133] step: 924000, training_loss: 2.66858e-02
I0212 07:16:10.290943 22542570456896 run_lib.py:146] step: 924000, eval_loss: 3.17197e-02
I0212 07:16:27.803769 22542570456896 run_lib.py:133] step: 924050, training_loss: 2.67154e-02
I0212 07:16:45.485037 22542570456896 run_lib.py:133] step: 924100, training_loss: 2.59656e-02
I0212 07:16:45.646428 22542570456896 run_lib.py:146] step: 924100, eval_loss: 2.42617e-02
I0212 07:17:03.086998 22542570456896 run_lib.py:133] step: 924150, training_loss: 2.88848e-02
I0212 07:17:20.548368 22542570456896 run_lib.py:133] step: 924200, training_loss: 2.66409e-02
I0212 07:17:20.706394 22542570456896 run_lib.py:146] step: 924200, eval_loss: 3.23392e-02
I0212 07:17:38.330363 22542570456896 run_lib.py:133] step: 924250, training_loss: 3.13414e-02
I0212 07:17:55.814215 22542570456896 run_lib.py:133] step: 924300, training_loss: 2.71982e-02
I0212 07:17:55.970671 22542570456896 run_lib.py:146] step: 924300, eval_loss: 2.75441e-02
I0212 07:18:13.475452 22542570456896 run_lib.py:133] step: 924350, training_loss: 2.05976e-02
I0212 07:18:30.957494 22542570456896 run_lib.py:133] step: 924400, training_loss: 2.41803e-02
I0212 07:18:31.111091 22542570456896 run_lib.py:146] step: 924400, eval_loss: 2.34801e-02
I0212 07:18:48.745755 22542570456896 run_lib.py:133] step: 924450, training_loss: 2.37003e-02
I0212 07:19:06.213103 22542570456896 run_lib.py:133] step: 924500, training_loss: 2.08292e-02
I0212 07:19:06.370458 22542570456896 run_lib.py:146] step: 924500, eval_loss: 2.79306e-02
I0212 07:19:23.887112 22542570456896 run_lib.py:133] step: 924550, training_loss: 2.62566e-02
I0212 07:19:41.394907 22542570456896 run_lib.py:133] step: 924600, training_loss: 3.27461e-02
I0212 07:19:41.561378 22542570456896 run_lib.py:146] step: 924600, eval_loss: 3.64950e-02
I0212 07:19:59.046432 22542570456896 run_lib.py:133] step: 924650, training_loss: 2.90254e-02
I0212 07:20:16.508838 22542570456896 run_lib.py:133] step: 924700, training_loss: 2.11806e-02
I0212 07:20:16.666435 22542570456896 run_lib.py:146] step: 924700, eval_loss: 3.14598e-02
I0212 07:20:34.307136 22542570456896 run_lib.py:133] step: 924750, training_loss: 2.79365e-02
I0212 07:20:51.859109 22542570456896 run_lib.py:133] step: 924800, training_loss: 2.28426e-02
I0212 07:20:52.014601 22542570456896 run_lib.py:146] step: 924800, eval_loss: 2.59516e-02
I0212 07:21:09.523823 22542570456896 run_lib.py:133] step: 924850, training_loss: 2.98694e-02
I0212 07:21:27.029147 22542570456896 run_lib.py:133] step: 924900, training_loss: 2.99723e-02
I0212 07:21:27.185626 22542570456896 run_lib.py:146] step: 924900, eval_loss: 3.25393e-02
I0212 07:21:44.862096 22542570456896 run_lib.py:133] step: 924950, training_loss: 2.56524e-02
I0212 07:22:02.388165 22542570456896 run_lib.py:133] step: 925000, training_loss: 2.87927e-02
I0212 07:22:02.545718 22542570456896 run_lib.py:146] step: 925000, eval_loss: 2.54734e-02
I0212 07:22:20.141857 22542570456896 run_lib.py:133] step: 925050, training_loss: 2.69622e-02
I0212 07:22:37.617161 22542570456896 run_lib.py:133] step: 925100, training_loss: 2.94208e-02
I0212 07:22:37.795421 22542570456896 run_lib.py:146] step: 925100, eval_loss: 3.06675e-02
I0212 07:22:55.478685 22542570456896 run_lib.py:133] step: 925150, training_loss: 3.16517e-02
I0212 07:23:12.980027 22542570456896 run_lib.py:133] step: 925200, training_loss: 2.93188e-02
I0212 07:23:13.137205 22542570456896 run_lib.py:146] step: 925200, eval_loss: 2.94178e-02
I0212 07:23:30.741799 22542570456896 run_lib.py:133] step: 925250, training_loss: 2.95664e-02
I0212 07:23:48.159327 22542570456896 run_lib.py:133] step: 925300, training_loss: 2.88046e-02
I0212 07:23:48.314397 22542570456896 run_lib.py:146] step: 925300, eval_loss: 3.16651e-02
I0212 07:24:05.794976 22542570456896 run_lib.py:133] step: 925350, training_loss: 2.71894e-02
I0212 07:24:23.425093 22542570456896 run_lib.py:133] step: 925400, training_loss: 2.86700e-02
I0212 07:24:23.589646 22542570456896 run_lib.py:146] step: 925400, eval_loss: 2.50418e-02
I0212 07:24:41.095357 22542570456896 run_lib.py:133] step: 925450, training_loss: 2.59219e-02
I0212 07:24:58.578564 22542570456896 run_lib.py:133] step: 925500, training_loss: 3.46863e-02
I0212 07:24:58.739638 22542570456896 run_lib.py:146] step: 925500, eval_loss: 3.56951e-02
I0212 07:25:16.426418 22542570456896 run_lib.py:133] step: 925550, training_loss: 2.09990e-02
I0212 07:25:34.055257 22542570456896 run_lib.py:133] step: 925600, training_loss: 2.54702e-02
I0212 07:25:34.223572 22542570456896 run_lib.py:146] step: 925600, eval_loss: 2.79048e-02
I0212 07:25:51.742039 22542570456896 run_lib.py:133] step: 925650, training_loss: 2.89065e-02
I0212 07:26:09.230715 22542570456896 run_lib.py:133] step: 925700, training_loss: 2.83738e-02
I0212 07:26:09.386216 22542570456896 run_lib.py:146] step: 925700, eval_loss: 2.80673e-02
I0212 07:26:26.869078 22542570456896 run_lib.py:133] step: 925750, training_loss: 2.92754e-02
I0212 07:26:44.536256 22542570456896 run_lib.py:133] step: 925800, training_loss: 2.82683e-02
I0212 07:26:44.691526 22542570456896 run_lib.py:146] step: 925800, eval_loss: 3.07736e-02
I0212 07:27:02.178306 22542570456896 run_lib.py:133] step: 925850, training_loss: 2.97241e-02
I0212 07:27:19.682762 22542570456896 run_lib.py:133] step: 925900, training_loss: 2.56796e-02
I0212 07:27:19.850198 22542570456896 run_lib.py:146] step: 925900, eval_loss: 2.58364e-02
I0212 07:27:37.354465 22542570456896 run_lib.py:133] step: 925950, training_loss: 3.15995e-02
I0212 07:27:55.049156 22542570456896 run_lib.py:133] step: 926000, training_loss: 2.27697e-02
I0212 07:27:55.207648 22542570456896 run_lib.py:146] step: 926000, eval_loss: 3.35592e-02
I0212 07:28:12.674121 22542570456896 run_lib.py:133] step: 926050, training_loss: 2.52446e-02
I0212 07:28:30.218341 22542570456896 run_lib.py:133] step: 926100, training_loss: 2.46413e-02
I0212 07:28:30.380441 22542570456896 run_lib.py:146] step: 926100, eval_loss: 3.47231e-02
I0212 07:28:47.884367 22542570456896 run_lib.py:133] step: 926150, training_loss: 2.85602e-02
I0212 07:29:05.375210 22542570456896 run_lib.py:133] step: 926200, training_loss: 3.26571e-02
I0212 07:29:05.533107 22542570456896 run_lib.py:146] step: 926200, eval_loss: 3.98344e-02
I0212 07:29:23.177669 22542570456896 run_lib.py:133] step: 926250, training_loss: 2.88181e-02
I0212 07:29:40.697309 22542570456896 run_lib.py:133] step: 926300, training_loss: 2.11919e-02
I0212 07:29:40.857574 22542570456896 run_lib.py:146] step: 926300, eval_loss: 2.44980e-02
I0212 07:29:58.306303 22542570456896 run_lib.py:133] step: 926350, training_loss: 2.81314e-02
I0212 07:30:15.742935 22542570456896 run_lib.py:133] step: 926400, training_loss: 2.77935e-02
I0212 07:30:15.909142 22542570456896 run_lib.py:146] step: 926400, eval_loss: 3.15714e-02
I0212 07:30:33.578912 22542570456896 run_lib.py:133] step: 926450, training_loss: 2.99916e-02
I0212 07:30:51.059071 22542570456896 run_lib.py:133] step: 926500, training_loss: 3.11989e-02
I0212 07:30:51.219391 22542570456896 run_lib.py:146] step: 926500, eval_loss: 2.87632e-02
I0212 07:31:08.869122 22542570456896 run_lib.py:133] step: 926550, training_loss: 2.67051e-02
I0212 07:31:26.322884 22542570456896 run_lib.py:133] step: 926600, training_loss: 3.50862e-02
I0212 07:31:26.480443 22542570456896 run_lib.py:146] step: 926600, eval_loss: 2.58268e-02
I0212 07:31:44.088756 22542570456896 run_lib.py:133] step: 926650, training_loss: 2.67342e-02
I0212 07:32:01.551106 22542570456896 run_lib.py:133] step: 926700, training_loss: 2.96397e-02
I0212 07:32:01.708457 22542570456896 run_lib.py:146] step: 926700, eval_loss: 3.09179e-02
I0212 07:32:19.213645 22542570456896 run_lib.py:133] step: 926750, training_loss: 3.46075e-02
I0212 07:32:36.902531 22542570456896 run_lib.py:133] step: 926800, training_loss: 2.89106e-02
I0212 07:32:37.059954 22542570456896 run_lib.py:146] step: 926800, eval_loss: 3.17104e-02
I0212 07:32:54.567996 22542570456896 run_lib.py:133] step: 926850, training_loss: 2.62818e-02
I0212 07:33:12.195874 22542570456896 run_lib.py:133] step: 926900, training_loss: 2.66360e-02
I0212 07:33:12.355646 22542570456896 run_lib.py:146] step: 926900, eval_loss: 2.62658e-02
I0212 07:33:29.792456 22542570456896 run_lib.py:133] step: 926950, training_loss: 3.21074e-02
I0212 07:33:47.249349 22542570456896 run_lib.py:133] step: 927000, training_loss: 3.40642e-02
I0212 07:33:47.419802 22542570456896 run_lib.py:146] step: 927000, eval_loss: 2.98607e-02
I0212 07:34:04.966415 22542570456896 run_lib.py:133] step: 927050, training_loss: 3.37022e-02
I0212 07:34:22.414534 22542570456896 run_lib.py:133] step: 927100, training_loss: 1.92733e-02
I0212 07:34:22.569550 22542570456896 run_lib.py:146] step: 927100, eval_loss: 2.96069e-02
I0212 07:34:39.960663 22542570456896 run_lib.py:133] step: 927150, training_loss: 3.66170e-02
I0212 07:34:57.425040 22542570456896 run_lib.py:133] step: 927200, training_loss: 2.79250e-02
I0212 07:34:57.577369 22542570456896 run_lib.py:146] step: 927200, eval_loss: 2.84381e-02
I0212 07:35:14.982794 22542570456896 run_lib.py:133] step: 927250, training_loss: 3.03864e-02
I0212 07:35:32.404875 22542570456896 run_lib.py:133] step: 927300, training_loss: 2.65356e-02
I0212 07:35:32.560872 22542570456896 run_lib.py:146] step: 927300, eval_loss: 2.68180e-02
I0212 07:35:50.049483 22542570456896 run_lib.py:133] step: 927350, training_loss: 2.56861e-02
I0212 07:36:07.417187 22542570456896 run_lib.py:133] step: 927400, training_loss: 2.80192e-02
I0212 07:36:07.580518 22542570456896 run_lib.py:146] step: 927400, eval_loss: 2.37938e-02
I0212 07:36:25.014438 22542570456896 run_lib.py:133] step: 927450, training_loss: 2.84748e-02
I0212 07:36:42.490092 22542570456896 run_lib.py:133] step: 927500, training_loss: 2.94920e-02
I0212 07:36:42.656432 22542570456896 run_lib.py:146] step: 927500, eval_loss: 2.94075e-02
I0212 07:37:00.291234 22542570456896 run_lib.py:133] step: 927550, training_loss: 2.81288e-02
I0212 07:37:17.905420 22542570456896 run_lib.py:133] step: 927600, training_loss: 2.41797e-02
I0212 07:37:18.062257 22542570456896 run_lib.py:146] step: 927600, eval_loss: 3.07955e-02
I0212 07:37:35.571451 22542570456896 run_lib.py:133] step: 927650, training_loss: 2.49245e-02
I0212 07:37:53.059834 22542570456896 run_lib.py:133] step: 927700, training_loss: 2.93675e-02
I0212 07:37:53.212170 22542570456896 run_lib.py:146] step: 927700, eval_loss: 2.87531e-02
I0212 07:38:10.824296 22542570456896 run_lib.py:133] step: 927750, training_loss: 2.49498e-02
I0212 07:38:28.288341 22542570456896 run_lib.py:133] step: 927800, training_loss: 2.88777e-02
I0212 07:38:28.457741 22542570456896 run_lib.py:146] step: 927800, eval_loss: 3.43062e-02
I0212 07:38:46.144785 22542570456896 run_lib.py:133] step: 927850, training_loss: 2.69402e-02
I0212 07:39:03.648798 22542570456896 run_lib.py:133] step: 927900, training_loss: 3.18115e-02
I0212 07:39:03.809438 22542570456896 run_lib.py:146] step: 927900, eval_loss: 2.83591e-02
I0212 07:39:21.433053 22542570456896 run_lib.py:133] step: 927950, training_loss: 2.91875e-02
I0212 07:39:38.923452 22542570456896 run_lib.py:133] step: 928000, training_loss: 3.11495e-02
I0212 07:39:39.082516 22542570456896 run_lib.py:146] step: 928000, eval_loss: 2.64678e-02
I0212 07:39:56.718010 22542570456896 run_lib.py:133] step: 928050, training_loss: 2.75335e-02
I0212 07:40:14.246369 22542570456896 run_lib.py:133] step: 928100, training_loss: 2.97625e-02
I0212 07:40:14.401941 22542570456896 run_lib.py:146] step: 928100, eval_loss: 3.02174e-02
I0212 07:40:31.899891 22542570456896 run_lib.py:133] step: 928150, training_loss: 3.00572e-02
I0212 07:40:49.520565 22542570456896 run_lib.py:133] step: 928200, training_loss: 2.83724e-02
I0212 07:40:49.671673 22542570456896 run_lib.py:146] step: 928200, eval_loss: 2.27448e-02
I0212 07:41:07.101674 22542570456896 run_lib.py:133] step: 928250, training_loss: 2.17270e-02
I0212 07:41:24.562327 22542570456896 run_lib.py:133] step: 928300, training_loss: 2.50712e-02
I0212 07:41:24.720644 22542570456896 run_lib.py:146] step: 928300, eval_loss: 2.72250e-02
I0212 07:41:42.379775 22542570456896 run_lib.py:133] step: 928350, training_loss: 2.76106e-02
I0212 07:41:59.906379 22542570456896 run_lib.py:133] step: 928400, training_loss: 2.61608e-02
I0212 07:42:00.066323 22542570456896 run_lib.py:146] step: 928400, eval_loss: 2.86956e-02
I0212 07:42:17.730716 22542570456896 run_lib.py:133] step: 928450, training_loss: 2.88003e-02
I0212 07:42:35.216772 22542570456896 run_lib.py:133] step: 928500, training_loss: 2.43192e-02
I0212 07:42:35.374347 22542570456896 run_lib.py:146] step: 928500, eval_loss: 2.89393e-02
I0212 07:42:52.814180 22542570456896 run_lib.py:133] step: 928550, training_loss: 2.44859e-02
I0212 07:43:10.465109 22542570456896 run_lib.py:133] step: 928600, training_loss: 2.82434e-02
I0212 07:43:10.622619 22542570456896 run_lib.py:146] step: 928600, eval_loss: 2.91764e-02
I0212 07:43:28.119231 22542570456896 run_lib.py:133] step: 928650, training_loss: 2.06602e-02
I0212 07:43:45.563025 22542570456896 run_lib.py:133] step: 928700, training_loss: 2.88353e-02
I0212 07:43:45.715458 22542570456896 run_lib.py:146] step: 928700, eval_loss: 2.67875e-02
I0212 07:44:03.153632 22542570456896 run_lib.py:133] step: 928750, training_loss: 2.50715e-02
I0212 07:44:20.820528 22542570456896 run_lib.py:133] step: 928800, training_loss: 2.72618e-02
I0212 07:44:20.980647 22542570456896 run_lib.py:146] step: 928800, eval_loss: 2.78261e-02
I0212 07:44:38.432874 22542570456896 run_lib.py:133] step: 928850, training_loss: 3.02309e-02
I0212 07:44:56.005369 22542570456896 run_lib.py:133] step: 928900, training_loss: 2.96797e-02
I0212 07:44:56.182396 22542570456896 run_lib.py:146] step: 928900, eval_loss: 2.95113e-02
I0212 07:45:13.664648 22542570456896 run_lib.py:133] step: 928950, training_loss: 2.35336e-02
I0212 07:45:31.175425 22542570456896 run_lib.py:133] step: 929000, training_loss: 3.24398e-02
I0212 07:45:31.332207 22542570456896 run_lib.py:146] step: 929000, eval_loss: 3.57179e-02
I0212 07:45:49.025508 22542570456896 run_lib.py:133] step: 929050, training_loss: 2.47744e-02
I0212 07:46:06.557853 22542570456896 run_lib.py:133] step: 929100, training_loss: 2.82682e-02
I0212 07:46:06.713202 22542570456896 run_lib.py:146] step: 929100, eval_loss: 2.37773e-02
I0212 07:46:24.156555 22542570456896 run_lib.py:133] step: 929150, training_loss: 2.72134e-02
I0212 07:46:41.657389 22542570456896 run_lib.py:133] step: 929200, training_loss: 2.70638e-02
I0212 07:46:41.817665 22542570456896 run_lib.py:146] step: 929200, eval_loss: 2.84089e-02
I0212 07:46:59.493888 22542570456896 run_lib.py:133] step: 929250, training_loss: 2.40037e-02
I0212 07:47:17.001668 22542570456896 run_lib.py:133] step: 929300, training_loss: 2.94220e-02
I0212 07:47:17.166641 22542570456896 run_lib.py:146] step: 929300, eval_loss: 3.33988e-02
I0212 07:47:34.753182 22542570456896 run_lib.py:133] step: 929350, training_loss: 2.73823e-02
I0212 07:47:52.215964 22542570456896 run_lib.py:133] step: 929400, training_loss: 2.40002e-02
I0212 07:47:52.386436 22542570456896 run_lib.py:146] step: 929400, eval_loss: 3.14678e-02
I0212 07:48:10.054031 22542570456896 run_lib.py:133] step: 929450, training_loss: 2.14989e-02
I0212 07:48:27.506461 22542570456896 run_lib.py:133] step: 929500, training_loss: 3.14317e-02
I0212 07:48:27.667674 22542570456896 run_lib.py:146] step: 929500, eval_loss: 2.74705e-02
I0212 07:48:45.137321 22542570456896 run_lib.py:133] step: 929550, training_loss: 2.63685e-02
I0212 07:49:02.750380 22542570456896 run_lib.py:133] step: 929600, training_loss: 2.58090e-02
I0212 07:49:02.899199 22542570456896 run_lib.py:146] step: 929600, eval_loss: 3.22133e-02
I0212 07:49:20.376763 22542570456896 run_lib.py:133] step: 929650, training_loss: 2.60070e-02
I0212 07:49:37.989125 22542570456896 run_lib.py:133] step: 929700, training_loss: 3.21110e-02
I0212 07:49:38.147687 22542570456896 run_lib.py:146] step: 929700, eval_loss: 2.77845e-02
I0212 07:49:55.637452 22542570456896 run_lib.py:133] step: 929750, training_loss: 2.27225e-02
I0212 07:50:13.172444 22542570456896 run_lib.py:133] step: 929800, training_loss: 2.74106e-02
I0212 07:50:13.334477 22542570456896 run_lib.py:146] step: 929800, eval_loss: 3.18056e-02
I0212 07:50:30.992151 22542570456896 run_lib.py:133] step: 929850, training_loss: 2.68708e-02
I0212 07:50:48.439328 22542570456896 run_lib.py:133] step: 929900, training_loss: 2.29693e-02
I0212 07:50:48.595438 22542570456896 run_lib.py:146] step: 929900, eval_loss: 3.09928e-02
I0212 07:51:06.035455 22542570456896 run_lib.py:133] step: 929950, training_loss: 2.93932e-02
I0212 07:51:23.627187 22542570456896 run_lib.py:133] step: 930000, training_loss: 2.23517e-02
I0212 07:51:24.365261 22542570456896 run_lib.py:146] step: 930000, eval_loss: 2.84060e-02
I0212 07:51:44.518499 22542570456896 run_lib.py:133] step: 930050, training_loss: 3.10429e-02
I0212 07:52:02.004430 22542570456896 run_lib.py:133] step: 930100, training_loss: 2.89224e-02
I0212 07:52:02.162169 22542570456896 run_lib.py:146] step: 930100, eval_loss: 3.82941e-02
I0212 07:52:19.810407 22542570456896 run_lib.py:133] step: 930150, training_loss: 2.25854e-02
I0212 07:52:37.272047 22542570456896 run_lib.py:133] step: 930200, training_loss: 2.96647e-02
I0212 07:52:37.433221 22542570456896 run_lib.py:146] step: 930200, eval_loss: 2.48007e-02
I0212 07:52:54.887855 22542570456896 run_lib.py:133] step: 930250, training_loss: 2.52207e-02
I0212 07:53:12.423716 22542570456896 run_lib.py:133] step: 930300, training_loss: 3.25154e-02
I0212 07:53:12.601523 22542570456896 run_lib.py:146] step: 930300, eval_loss: 2.07631e-02
I0212 07:53:30.268030 22542570456896 run_lib.py:133] step: 930350, training_loss: 2.61477e-02
I0212 07:53:47.762555 22542570456896 run_lib.py:133] step: 930400, training_loss: 2.58899e-02
I0212 07:53:47.925717 22542570456896 run_lib.py:146] step: 930400, eval_loss: 3.11865e-02
I0212 07:54:05.478048 22542570456896 run_lib.py:133] step: 930450, training_loss: 2.43959e-02
I0212 07:54:22.956030 22542570456896 run_lib.py:133] step: 930500, training_loss: 2.66394e-02
I0212 07:54:23.113181 22542570456896 run_lib.py:146] step: 930500, eval_loss: 2.48319e-02
I0212 07:54:40.590054 22542570456896 run_lib.py:133] step: 930550, training_loss: 2.37231e-02
I0212 07:54:58.076418 22542570456896 run_lib.py:133] step: 930600, training_loss: 2.17517e-02
I0212 07:54:58.231216 22542570456896 run_lib.py:146] step: 930600, eval_loss: 2.87590e-02
I0212 07:55:15.944553 22542570456896 run_lib.py:133] step: 930650, training_loss: 3.11515e-02
I0212 07:55:33.477501 22542570456896 run_lib.py:133] step: 930700, training_loss: 2.10629e-02
I0212 07:55:33.631349 22542570456896 run_lib.py:146] step: 930700, eval_loss: 3.07914e-02
I0212 07:55:51.067794 22542570456896 run_lib.py:133] step: 930750, training_loss: 3.05026e-02
I0212 07:56:08.529666 22542570456896 run_lib.py:133] step: 930800, training_loss: 2.94626e-02
I0212 07:56:08.699180 22542570456896 run_lib.py:146] step: 930800, eval_loss: 2.98142e-02
I0212 07:56:26.380207 22542570456896 run_lib.py:133] step: 930850, training_loss: 3.07353e-02
I0212 07:56:43.890161 22542570456896 run_lib.py:133] step: 930900, training_loss: 2.75017e-02
I0212 07:56:44.047543 22542570456896 run_lib.py:146] step: 930900, eval_loss: 2.74286e-02
I0212 07:57:01.715830 22542570456896 run_lib.py:133] step: 930950, training_loss: 2.28207e-02
I0212 07:57:19.167442 22542570456896 run_lib.py:133] step: 931000, training_loss: 3.05014e-02
I0212 07:57:19.324572 22542570456896 run_lib.py:146] step: 931000, eval_loss: 3.16865e-02
I0212 07:57:36.928352 22542570456896 run_lib.py:133] step: 931050, training_loss: 3.11986e-02
I0212 07:57:54.416664 22542570456896 run_lib.py:133] step: 931100, training_loss: 2.57844e-02
I0212 07:57:54.571620 22542570456896 run_lib.py:146] step: 931100, eval_loss: 2.68571e-02
I0212 07:58:12.270408 22542570456896 run_lib.py:133] step: 931150, training_loss: 2.47998e-02
I0212 07:58:29.748066 22542570456896 run_lib.py:133] step: 931200, training_loss: 2.47193e-02
I0212 07:58:29.911663 22542570456896 run_lib.py:146] step: 931200, eval_loss: 3.17850e-02
I0212 07:58:47.376478 22542570456896 run_lib.py:133] step: 931250, training_loss: 2.59788e-02
I0212 07:59:05.013112 22542570456896 run_lib.py:133] step: 931300, training_loss: 2.57317e-02
I0212 07:59:05.175870 22542570456896 run_lib.py:146] step: 931300, eval_loss: 2.48352e-02
I0212 07:59:22.626513 22542570456896 run_lib.py:133] step: 931350, training_loss: 2.69339e-02
I0212 07:59:40.066205 22542570456896 run_lib.py:133] step: 931400, training_loss: 3.15003e-02
I0212 07:59:40.234433 22542570456896 run_lib.py:146] step: 931400, eval_loss: 3.45266e-02
I0212 07:59:57.925716 22542570456896 run_lib.py:133] step: 931450, training_loss: 2.38731e-02
I0212 08:00:15.622872 22542570456896 run_lib.py:133] step: 931500, training_loss: 2.31956e-02
I0212 08:00:15.783644 22542570456896 run_lib.py:146] step: 931500, eval_loss: 2.70096e-02
I0212 08:00:33.302796 22542570456896 run_lib.py:133] step: 931550, training_loss: 2.53584e-02
I0212 08:00:50.751999 22542570456896 run_lib.py:133] step: 931600, training_loss: 1.98543e-02
I0212 08:00:50.911335 22542570456896 run_lib.py:146] step: 931600, eval_loss: 2.91177e-02
I0212 08:01:08.364033 22542570456896 run_lib.py:133] step: 931650, training_loss: 2.30176e-02
I0212 08:01:25.978767 22542570456896 run_lib.py:133] step: 931700, training_loss: 2.96687e-02
I0212 08:01:26.140584 22542570456896 run_lib.py:146] step: 931700, eval_loss: 2.47378e-02
I0212 08:01:43.644892 22542570456896 run_lib.py:133] step: 931750, training_loss: 3.21568e-02
I0212 08:02:01.202800 22542570456896 run_lib.py:133] step: 931800, training_loss: 3.24568e-02
I0212 08:02:01.364535 22542570456896 run_lib.py:146] step: 931800, eval_loss: 3.30691e-02
I0212 08:02:18.782272 22542570456896 run_lib.py:133] step: 931850, training_loss: 3.33562e-02
I0212 08:02:36.416242 22542570456896 run_lib.py:133] step: 931900, training_loss: 2.74386e-02
I0212 08:02:36.578362 22542570456896 run_lib.py:146] step: 931900, eval_loss: 3.49964e-02
I0212 08:02:54.067436 22542570456896 run_lib.py:133] step: 931950, training_loss: 2.80765e-02
I0212 08:03:11.583545 22542570456896 run_lib.py:133] step: 932000, training_loss: 3.05990e-02
I0212 08:03:11.741386 22542570456896 run_lib.py:146] step: 932000, eval_loss: 3.73418e-02
I0212 08:03:29.267289 22542570456896 run_lib.py:133] step: 932050, training_loss: 3.56865e-02
I0212 08:03:46.749893 22542570456896 run_lib.py:133] step: 932100, training_loss: 3.24288e-02
I0212 08:03:46.911657 22542570456896 run_lib.py:146] step: 932100, eval_loss: 2.50435e-02
I0212 08:04:04.569695 22542570456896 run_lib.py:133] step: 932150, training_loss: 2.45267e-02
I0212 08:04:22.040329 22542570456896 run_lib.py:133] step: 932200, training_loss: 2.97142e-02
I0212 08:04:22.203593 22542570456896 run_lib.py:146] step: 932200, eval_loss: 2.71724e-02
I0212 08:04:39.547834 22542570456896 run_lib.py:133] step: 932250, training_loss: 2.63259e-02
I0212 08:04:56.938617 22542570456896 run_lib.py:133] step: 932300, training_loss: 2.80827e-02
I0212 08:04:57.109333 22542570456896 run_lib.py:146] step: 932300, eval_loss: 3.38454e-02
I0212 08:05:14.689996 22542570456896 run_lib.py:133] step: 932350, training_loss: 2.56877e-02
I0212 08:05:32.119803 22542570456896 run_lib.py:133] step: 932400, training_loss: 2.48753e-02
I0212 08:05:32.274507 22542570456896 run_lib.py:146] step: 932400, eval_loss: 2.75802e-02
I0212 08:05:49.835678 22542570456896 run_lib.py:133] step: 932450, training_loss: 2.38578e-02
I0212 08:06:07.191909 22542570456896 run_lib.py:133] step: 932500, training_loss: 2.46414e-02
I0212 08:06:07.344069 22542570456896 run_lib.py:146] step: 932500, eval_loss: 2.83846e-02
I0212 08:06:24.855985 22542570456896 run_lib.py:133] step: 932550, training_loss: 2.55558e-02
I0212 08:06:42.304339 22542570456896 run_lib.py:133] step: 932600, training_loss: 2.25415e-02
I0212 08:06:42.469708 22542570456896 run_lib.py:146] step: 932600, eval_loss: 2.57242e-02
I0212 08:06:59.954518 22542570456896 run_lib.py:133] step: 932650, training_loss: 2.31976e-02
I0212 08:07:17.628017 22542570456896 run_lib.py:133] step: 932700, training_loss: 2.58344e-02
I0212 08:07:17.790689 22542570456896 run_lib.py:146] step: 932700, eval_loss: 2.51905e-02
I0212 08:07:35.241343 22542570456896 run_lib.py:133] step: 932750, training_loss: 2.91586e-02
I0212 08:07:52.857398 22542570456896 run_lib.py:133] step: 932800, training_loss: 2.79455e-02
I0212 08:07:53.015460 22542570456896 run_lib.py:146] step: 932800, eval_loss: 2.20683e-02
I0212 08:08:10.466248 22542570456896 run_lib.py:133] step: 932850, training_loss: 2.75961e-02
I0212 08:08:27.927689 22542570456896 run_lib.py:133] step: 932900, training_loss: 3.27222e-02
I0212 08:08:28.089405 22542570456896 run_lib.py:146] step: 932900, eval_loss: 2.71705e-02
I0212 08:08:45.815690 22542570456896 run_lib.py:133] step: 932950, training_loss: 2.39729e-02
I0212 08:09:03.316896 22542570456896 run_lib.py:133] step: 933000, training_loss: 2.46291e-02
I0212 08:09:03.470282 22542570456896 run_lib.py:146] step: 933000, eval_loss: 2.96679e-02
I0212 08:09:20.914551 22542570456896 run_lib.py:133] step: 933050, training_loss: 2.17129e-02
I0212 08:09:38.529561 22542570456896 run_lib.py:133] step: 933100, training_loss: 3.09059e-02
I0212 08:09:38.693466 22542570456896 run_lib.py:146] step: 933100, eval_loss: 2.46942e-02
I0212 08:09:56.144352 22542570456896 run_lib.py:133] step: 933150, training_loss: 2.78430e-02
I0212 08:10:13.667051 22542570456896 run_lib.py:133] step: 933200, training_loss: 2.45290e-02
I0212 08:10:13.851412 22542570456896 run_lib.py:146] step: 933200, eval_loss: 2.64768e-02
I0212 08:10:31.424745 22542570456896 run_lib.py:133] step: 933250, training_loss: 2.48443e-02
I0212 08:10:48.888465 22542570456896 run_lib.py:133] step: 933300, training_loss: 2.94399e-02
I0212 08:10:49.053614 22542570456896 run_lib.py:146] step: 933300, eval_loss: 2.91702e-02
I0212 08:11:06.524311 22542570456896 run_lib.py:133] step: 933350, training_loss: 2.80030e-02
I0212 08:11:23.992771 22542570456896 run_lib.py:133] step: 933400, training_loss: 3.03581e-02
I0212 08:11:24.149185 22542570456896 run_lib.py:146] step: 933400, eval_loss: 2.99605e-02
I0212 08:11:41.772904 22542570456896 run_lib.py:133] step: 933450, training_loss: 2.27417e-02
I0212 08:11:59.363224 22542570456896 run_lib.py:133] step: 933500, training_loss: 2.29528e-02
I0212 08:11:59.518572 22542570456896 run_lib.py:146] step: 933500, eval_loss: 3.00187e-02
I0212 08:12:17.028391 22542570456896 run_lib.py:133] step: 933550, training_loss: 2.14226e-02
I0212 08:12:34.545955 22542570456896 run_lib.py:133] step: 933600, training_loss: 3.23032e-02
I0212 08:12:34.711462 22542570456896 run_lib.py:146] step: 933600, eval_loss: 2.59837e-02
I0212 08:12:52.361887 22542570456896 run_lib.py:133] step: 933650, training_loss: 2.95422e-02
I0212 08:13:09.839601 22542570456896 run_lib.py:133] step: 933700, training_loss: 2.30044e-02
I0212 08:13:10.008589 22542570456896 run_lib.py:146] step: 933700, eval_loss: 2.78989e-02
I0212 08:13:27.685613 22542570456896 run_lib.py:133] step: 933750, training_loss: 2.53729e-02
I0212 08:13:45.178935 22542570456896 run_lib.py:133] step: 933800, training_loss: 2.73240e-02
I0212 08:13:45.343184 22542570456896 run_lib.py:146] step: 933800, eval_loss: 3.33140e-02
I0212 08:14:02.999671 22542570456896 run_lib.py:133] step: 933850, training_loss: 2.85849e-02
I0212 08:14:20.424755 22542570456896 run_lib.py:133] step: 933900, training_loss: 2.85013e-02
I0212 08:14:20.582512 22542570456896 run_lib.py:146] step: 933900, eval_loss: 2.91018e-02
I0212 08:14:38.189677 22542570456896 run_lib.py:133] step: 933950, training_loss: 2.42705e-02
I0212 08:14:55.664571 22542570456896 run_lib.py:133] step: 934000, training_loss: 2.69926e-02
I0212 08:14:55.818710 22542570456896 run_lib.py:146] step: 934000, eval_loss: 2.62213e-02
I0212 08:15:13.332969 22542570456896 run_lib.py:133] step: 934050, training_loss: 2.55569e-02
I0212 08:15:30.998034 22542570456896 run_lib.py:133] step: 934100, training_loss: 3.03967e-02
I0212 08:15:31.158502 22542570456896 run_lib.py:146] step: 934100, eval_loss: 2.85220e-02
I0212 08:15:48.628865 22542570456896 run_lib.py:133] step: 934150, training_loss: 2.12772e-02
I0212 08:16:06.084517 22542570456896 run_lib.py:133] step: 934200, training_loss: 2.43437e-02
I0212 08:16:06.241416 22542570456896 run_lib.py:146] step: 934200, eval_loss: 2.95790e-02
I0212 08:16:23.854187 22542570456896 run_lib.py:133] step: 934250, training_loss: 2.34966e-02
I0212 08:16:41.334289 22542570456896 run_lib.py:133] step: 934300, training_loss: 2.39217e-02
I0212 08:16:41.499840 22542570456896 run_lib.py:146] step: 934300, eval_loss: 3.08799e-02
I0212 08:16:59.172415 22542570456896 run_lib.py:133] step: 934350, training_loss: 2.23292e-02
I0212 08:17:16.640457 22542570456896 run_lib.py:133] step: 934400, training_loss: 2.53962e-02
I0212 08:17:16.794162 22542570456896 run_lib.py:146] step: 934400, eval_loss: 2.52041e-02
I0212 08:17:34.279620 22542570456896 run_lib.py:133] step: 934450, training_loss: 3.86489e-02
I0212 08:17:51.925566 22542570456896 run_lib.py:133] step: 934500, training_loss: 2.05599e-02
I0212 08:17:52.082511 22542570456896 run_lib.py:146] step: 934500, eval_loss: 2.99277e-02
I0212 08:18:09.532453 22542570456896 run_lib.py:133] step: 934550, training_loss: 2.42067e-02
I0212 08:18:27.023384 22542570456896 run_lib.py:133] step: 934600, training_loss: 2.66117e-02
I0212 08:18:27.199632 22542570456896 run_lib.py:146] step: 934600, eval_loss: 3.37353e-02
I0212 08:18:44.686402 22542570456896 run_lib.py:133] step: 934650, training_loss: 2.53415e-02
I0212 08:19:02.362798 22542570456896 run_lib.py:133] step: 934700, training_loss: 2.91067e-02
I0212 08:19:02.521493 22542570456896 run_lib.py:146] step: 934700, eval_loss: 3.00214e-02
I0212 08:19:20.003354 22542570456896 run_lib.py:133] step: 934750, training_loss: 2.70211e-02
I0212 08:19:37.539367 22542570456896 run_lib.py:133] step: 934800, training_loss: 2.21763e-02
I0212 08:19:37.696631 22542570456896 run_lib.py:146] step: 934800, eval_loss: 3.14508e-02
I0212 08:19:55.181701 22542570456896 run_lib.py:133] step: 934850, training_loss: 2.25721e-02
I0212 08:20:12.679580 22542570456896 run_lib.py:133] step: 934900, training_loss: 2.60780e-02
I0212 08:20:12.838730 22542570456896 run_lib.py:146] step: 934900, eval_loss: 2.79166e-02
I0212 08:20:30.588644 22542570456896 run_lib.py:133] step: 934950, training_loss: 2.18250e-02
I0212 08:20:48.114340 22542570456896 run_lib.py:133] step: 935000, training_loss: 2.20773e-02
I0212 08:20:48.270406 22542570456896 run_lib.py:146] step: 935000, eval_loss: 4.01597e-02
I0212 08:21:05.728698 22542570456896 run_lib.py:133] step: 935050, training_loss: 3.03422e-02
I0212 08:21:23.183462 22542570456896 run_lib.py:133] step: 935100, training_loss: 2.97360e-02
I0212 08:21:23.350417 22542570456896 run_lib.py:146] step: 935100, eval_loss: 2.70081e-02
I0212 08:21:40.990987 22542570456896 run_lib.py:133] step: 935150, training_loss: 2.30466e-02
I0212 08:21:58.491672 22542570456896 run_lib.py:133] step: 935200, training_loss: 2.47788e-02
I0212 08:21:58.645632 22542570456896 run_lib.py:146] step: 935200, eval_loss: 3.34802e-02
I0212 08:22:16.317126 22542570456896 run_lib.py:133] step: 935250, training_loss: 3.73608e-02
I0212 08:22:33.773319 22542570456896 run_lib.py:133] step: 935300, training_loss: 2.49353e-02
I0212 08:22:33.926558 22542570456896 run_lib.py:146] step: 935300, eval_loss: 2.49599e-02
I0212 08:22:51.537701 22542570456896 run_lib.py:133] step: 935350, training_loss: 2.36306e-02
I0212 08:23:09.024516 22542570456896 run_lib.py:133] step: 935400, training_loss: 3.13125e-02
I0212 08:23:09.187781 22542570456896 run_lib.py:146] step: 935400, eval_loss: 3.61512e-02
I0212 08:23:26.762518 22542570456896 run_lib.py:133] step: 935450, training_loss: 2.98709e-02
I0212 08:23:44.444965 22542570456896 run_lib.py:133] step: 935500, training_loss: 2.64684e-02
I0212 08:23:44.608130 22542570456896 run_lib.py:146] step: 935500, eval_loss: 2.72643e-02
I0212 08:24:02.110938 22542570456896 run_lib.py:133] step: 935550, training_loss: 2.62892e-02
I0212 08:24:19.710015 22542570456896 run_lib.py:133] step: 935600, training_loss: 2.71257e-02
I0212 08:24:19.869631 22542570456896 run_lib.py:146] step: 935600, eval_loss: 2.58452e-02
I0212 08:24:37.380343 22542570456896 run_lib.py:133] step: 935650, training_loss: 2.92162e-02
I0212 08:24:54.915155 22542570456896 run_lib.py:133] step: 935700, training_loss: 2.92140e-02
I0212 08:24:55.071707 22542570456896 run_lib.py:146] step: 935700, eval_loss: 2.73409e-02
I0212 08:25:12.737601 22542570456896 run_lib.py:133] step: 935750, training_loss: 2.48453e-02
I0212 08:25:30.177451 22542570456896 run_lib.py:133] step: 935800, training_loss: 2.83862e-02
I0212 08:25:30.333404 22542570456896 run_lib.py:146] step: 935800, eval_loss: 3.14961e-02
I0212 08:25:47.790761 22542570456896 run_lib.py:133] step: 935850, training_loss: 3.24691e-02
I0212 08:26:05.461515 22542570456896 run_lib.py:133] step: 935900, training_loss: 2.65895e-02
I0212 08:26:05.619490 22542570456896 run_lib.py:146] step: 935900, eval_loss: 3.19107e-02
I0212 08:26:23.061521 22542570456896 run_lib.py:133] step: 935950, training_loss: 2.55619e-02
I0212 08:26:40.587586 22542570456896 run_lib.py:133] step: 936000, training_loss: 2.45605e-02
I0212 08:26:40.940580 22542570456896 run_lib.py:146] step: 936000, eval_loss: 3.04122e-02
I0212 08:26:58.439717 22542570456896 run_lib.py:133] step: 936050, training_loss: 2.41343e-02
I0212 08:27:15.973051 22542570456896 run_lib.py:133] step: 936100, training_loss: 2.86371e-02
I0212 08:27:16.138806 22542570456896 run_lib.py:146] step: 936100, eval_loss: 2.90840e-02
I0212 08:27:33.629742 22542570456896 run_lib.py:133] step: 936150, training_loss: 2.70697e-02
I0212 08:27:51.076132 22542570456896 run_lib.py:133] step: 936200, training_loss: 2.51627e-02
I0212 08:27:51.245121 22542570456896 run_lib.py:146] step: 936200, eval_loss: 3.12825e-02
I0212 08:28:08.897743 22542570456896 run_lib.py:133] step: 936250, training_loss: 2.85593e-02
I0212 08:28:26.537385 22542570456896 run_lib.py:133] step: 936300, training_loss: 3.40246e-02
I0212 08:28:26.690226 22542570456896 run_lib.py:146] step: 936300, eval_loss: 3.17025e-02
I0212 08:28:44.218796 22542570456896 run_lib.py:133] step: 936350, training_loss: 2.35185e-02
I0212 08:29:01.708968 22542570456896 run_lib.py:133] step: 936400, training_loss: 2.76306e-02
I0212 08:29:01.865416 22542570456896 run_lib.py:146] step: 936400, eval_loss: 2.87066e-02
I0212 08:29:19.463834 22542570456896 run_lib.py:133] step: 936450, training_loss: 3.07711e-02
I0212 08:29:37.005126 22542570456896 run_lib.py:133] step: 936500, training_loss: 2.34092e-02
I0212 08:29:37.184441 22542570456896 run_lib.py:146] step: 936500, eval_loss: 3.24643e-02
I0212 08:29:54.685760 22542570456896 run_lib.py:133] step: 936550, training_loss: 2.35836e-02
I0212 08:30:12.177309 22542570456896 run_lib.py:133] step: 936600, training_loss: 2.21202e-02
I0212 08:30:12.333695 22542570456896 run_lib.py:146] step: 936600, eval_loss: 2.90632e-02
I0212 08:30:30.038495 22542570456896 run_lib.py:133] step: 936650, training_loss: 2.77693e-02
I0212 08:30:47.504200 22542570456896 run_lib.py:133] step: 936700, training_loss: 2.49240e-02
I0212 08:30:47.661738 22542570456896 run_lib.py:146] step: 936700, eval_loss: 3.11283e-02
I0212 08:31:05.271290 22542570456896 run_lib.py:133] step: 936750, training_loss: 2.62686e-02
I0212 08:31:22.778134 22542570456896 run_lib.py:133] step: 936800, training_loss: 2.73869e-02
I0212 08:31:22.938022 22542570456896 run_lib.py:146] step: 936800, eval_loss: 2.79486e-02
I0212 08:31:40.629498 22542570456896 run_lib.py:133] step: 936850, training_loss: 2.72269e-02
I0212 08:31:58.102160 22542570456896 run_lib.py:133] step: 936900, training_loss: 3.66371e-02
I0212 08:31:58.258859 22542570456896 run_lib.py:146] step: 936900, eval_loss: 2.83650e-02
I0212 08:32:15.692534 22542570456896 run_lib.py:133] step: 936950, training_loss: 2.41678e-02
I0212 08:32:33.333158 22542570456896 run_lib.py:133] step: 937000, training_loss: 2.81211e-02
I0212 08:32:33.498551 22542570456896 run_lib.py:146] step: 937000, eval_loss: 3.78467e-02
I0212 08:32:51.032421 22542570456896 run_lib.py:133] step: 937050, training_loss: 2.54993e-02
I0212 08:33:08.746587 22542570456896 run_lib.py:133] step: 937100, training_loss: 2.92924e-02
I0212 08:33:08.911842 22542570456896 run_lib.py:146] step: 937100, eval_loss: 2.85562e-02
I0212 08:33:26.367975 22542570456896 run_lib.py:133] step: 937150, training_loss: 2.47129e-02
I0212 08:33:43.827156 22542570456896 run_lib.py:133] step: 937200, training_loss: 2.57844e-02
I0212 08:33:43.986457 22542570456896 run_lib.py:146] step: 937200, eval_loss: 3.57793e-02
I0212 08:34:01.598204 22542570456896 run_lib.py:133] step: 937250, training_loss: 3.00597e-02
I0212 08:34:19.126530 22542570456896 run_lib.py:133] step: 937300, training_loss: 2.47756e-02
I0212 08:34:19.287722 22542570456896 run_lib.py:146] step: 937300, eval_loss: 2.88879e-02
I0212 08:34:36.789560 22542570456896 run_lib.py:133] step: 937350, training_loss: 2.52928e-02
I0212 08:34:54.155770 22542570456896 run_lib.py:133] step: 937400, training_loss: 2.42504e-02
I0212 08:34:54.311291 22542570456896 run_lib.py:146] step: 937400, eval_loss: 2.68334e-02
I0212 08:35:11.894444 22542570456896 run_lib.py:133] step: 937450, training_loss: 2.14743e-02
I0212 08:35:29.322854 22542570456896 run_lib.py:133] step: 937500, training_loss: 3.22043e-02
I0212 08:35:29.489301 22542570456896 run_lib.py:146] step: 937500, eval_loss: 3.00653e-02
I0212 08:35:46.940562 22542570456896 run_lib.py:133] step: 937550, training_loss: 2.36481e-02
I0212 08:36:04.354691 22542570456896 run_lib.py:133] step: 937600, training_loss: 2.58197e-02
I0212 08:36:04.518080 22542570456896 run_lib.py:146] step: 937600, eval_loss: 3.21506e-02
I0212 08:36:21.892722 22542570456896 run_lib.py:133] step: 937650, training_loss: 2.95570e-02
I0212 08:36:39.287645 22542570456896 run_lib.py:133] step: 937700, training_loss: 3.21537e-02
I0212 08:36:39.442007 22542570456896 run_lib.py:146] step: 937700, eval_loss: 2.69413e-02
I0212 08:36:56.970814 22542570456896 run_lib.py:133] step: 937750, training_loss: 2.71446e-02
I0212 08:37:14.491816 22542570456896 run_lib.py:133] step: 937800, training_loss: 3.04473e-02
I0212 08:37:14.648632 22542570456896 run_lib.py:146] step: 937800, eval_loss: 2.40436e-02
I0212 08:37:32.114184 22542570456896 run_lib.py:133] step: 937850, training_loss: 2.64861e-02
I0212 08:37:49.656652 22542570456896 run_lib.py:133] step: 937900, training_loss: 2.54140e-02
I0212 08:37:49.835505 22542570456896 run_lib.py:146] step: 937900, eval_loss: 3.54514e-02
I0212 08:38:07.514269 22542570456896 run_lib.py:133] step: 937950, training_loss: 2.91569e-02
I0212 08:38:24.994696 22542570456896 run_lib.py:133] step: 938000, training_loss: 2.39586e-02
I0212 08:38:25.153374 22542570456896 run_lib.py:146] step: 938000, eval_loss: 2.58208e-02
I0212 08:38:42.828919 22542570456896 run_lib.py:133] step: 938050, training_loss: 2.51744e-02
I0212 08:39:00.281912 22542570456896 run_lib.py:133] step: 938100, training_loss: 2.65178e-02
I0212 08:39:00.438088 22542570456896 run_lib.py:146] step: 938100, eval_loss: 3.15515e-02
I0212 08:39:18.053131 22542570456896 run_lib.py:133] step: 938150, training_loss: 2.59953e-02
I0212 08:39:35.559758 22542570456896 run_lib.py:133] step: 938200, training_loss: 2.97350e-02
I0212 08:39:35.720283 22542570456896 run_lib.py:146] step: 938200, eval_loss: 2.62954e-02
I0212 08:39:53.447746 22542570456896 run_lib.py:133] step: 938250, training_loss: 3.05060e-02
I0212 08:40:10.909194 22542570456896 run_lib.py:133] step: 938300, training_loss: 3.09548e-02
I0212 08:40:11.073898 22542570456896 run_lib.py:146] step: 938300, eval_loss: 3.49015e-02
I0212 08:40:28.517979 22542570456896 run_lib.py:133] step: 938350, training_loss: 2.89839e-02
I0212 08:40:46.165132 22542570456896 run_lib.py:133] step: 938400, training_loss: 2.37940e-02
I0212 08:40:46.326741 22542570456896 run_lib.py:146] step: 938400, eval_loss: 2.91647e-02
I0212 08:41:03.822311 22542570456896 run_lib.py:133] step: 938450, training_loss: 2.85413e-02
I0212 08:41:21.342672 22542570456896 run_lib.py:133] step: 938500, training_loss: 2.47603e-02
I0212 08:41:21.500986 22542570456896 run_lib.py:146] step: 938500, eval_loss: 2.89272e-02
I0212 08:41:39.183406 22542570456896 run_lib.py:133] step: 938550, training_loss: 2.89133e-02
I0212 08:41:56.810004 22542570456896 run_lib.py:133] step: 938600, training_loss: 3.19170e-02
I0212 08:41:56.966470 22542570456896 run_lib.py:146] step: 938600, eval_loss: 2.84939e-02
I0212 08:42:14.461379 22542570456896 run_lib.py:133] step: 938650, training_loss: 2.68618e-02
I0212 08:42:31.928603 22542570456896 run_lib.py:133] step: 938700, training_loss: 3.15530e-02
I0212 08:42:32.081478 22542570456896 run_lib.py:146] step: 938700, eval_loss: 3.12542e-02
I0212 08:42:49.562495 22542570456896 run_lib.py:133] step: 938750, training_loss: 2.26584e-02
I0212 08:43:07.257437 22542570456896 run_lib.py:133] step: 938800, training_loss: 2.72989e-02
I0212 08:43:07.431639 22542570456896 run_lib.py:146] step: 938800, eval_loss: 3.02219e-02
I0212 08:43:24.968040 22542570456896 run_lib.py:133] step: 938850, training_loss: 3.33432e-02
I0212 08:43:42.495279 22542570456896 run_lib.py:133] step: 938900, training_loss: 2.71065e-02
I0212 08:43:42.659737 22542570456896 run_lib.py:146] step: 938900, eval_loss: 3.27398e-02
I0212 08:44:00.139274 22542570456896 run_lib.py:133] step: 938950, training_loss: 2.62324e-02
I0212 08:44:17.813108 22542570456896 run_lib.py:133] step: 939000, training_loss: 2.37683e-02
I0212 08:44:17.983486 22542570456896 run_lib.py:146] step: 939000, eval_loss: 2.99258e-02
I0212 08:44:35.519495 22542570456896 run_lib.py:133] step: 939050, training_loss: 2.50505e-02
I0212 08:44:53.153259 22542570456896 run_lib.py:133] step: 939100, training_loss: 2.44225e-02
I0212 08:44:53.315615 22542570456896 run_lib.py:146] step: 939100, eval_loss: 2.92228e-02
I0212 08:45:10.812090 22542570456896 run_lib.py:133] step: 939150, training_loss: 3.26315e-02
I0212 08:45:28.279038 22542570456896 run_lib.py:133] step: 939200, training_loss: 2.40649e-02
I0212 08:45:28.432380 22542570456896 run_lib.py:146] step: 939200, eval_loss: 3.05446e-02
I0212 08:45:46.078943 22542570456896 run_lib.py:133] step: 939250, training_loss: 3.27993e-02
I0212 08:46:03.645321 22542570456896 run_lib.py:133] step: 939300, training_loss: 2.72091e-02
I0212 08:46:03.818464 22542570456896 run_lib.py:146] step: 939300, eval_loss: 2.73715e-02
I0212 08:46:21.317943 22542570456896 run_lib.py:133] step: 939350, training_loss: 2.43309e-02
I0212 08:46:38.829226 22542570456896 run_lib.py:133] step: 939400, training_loss: 2.72121e-02
I0212 08:46:38.987492 22542570456896 run_lib.py:146] step: 939400, eval_loss: 3.05017e-02
I0212 08:46:56.677484 22542570456896 run_lib.py:133] step: 939450, training_loss: 2.96336e-02
I0212 08:47:14.157363 22542570456896 run_lib.py:133] step: 939500, training_loss: 3.02580e-02
I0212 08:47:14.315619 22542570456896 run_lib.py:146] step: 939500, eval_loss: 2.64856e-02
I0212 08:47:31.951938 22542570456896 run_lib.py:133] step: 939550, training_loss: 2.84740e-02
I0212 08:47:49.499066 22542570456896 run_lib.py:133] step: 939600, training_loss: 3.68636e-02
I0212 08:47:49.661689 22542570456896 run_lib.py:146] step: 939600, eval_loss: 3.25972e-02
I0212 08:48:07.449401 22542570456896 run_lib.py:133] step: 939650, training_loss: 2.60295e-02
I0212 08:48:24.935390 22542570456896 run_lib.py:133] step: 939700, training_loss: 3.29580e-02
I0212 08:48:25.098870 22542570456896 run_lib.py:146] step: 939700, eval_loss: 3.24869e-02
I0212 08:48:42.558534 22542570456896 run_lib.py:133] step: 939750, training_loss: 2.83649e-02
I0212 08:49:00.192305 22542570456896 run_lib.py:133] step: 939800, training_loss: 3.19645e-02
I0212 08:49:00.352658 22542570456896 run_lib.py:146] step: 939800, eval_loss: 2.33918e-02
I0212 08:49:17.858599 22542570456896 run_lib.py:133] step: 939850, training_loss: 3.39141e-02
I0212 08:49:35.562587 22542570456896 run_lib.py:133] step: 939900, training_loss: 2.11529e-02
I0212 08:49:35.720680 22542570456896 run_lib.py:146] step: 939900, eval_loss: 3.14443e-02
I0212 08:49:53.181584 22542570456896 run_lib.py:133] step: 939950, training_loss: 2.96498e-02
I0212 08:50:10.676990 22542570456896 run_lib.py:133] step: 940000, training_loss: 2.43949e-02
I0212 08:50:11.392089 22542570456896 run_lib.py:146] step: 940000, eval_loss: 2.45067e-02
I0212 08:50:31.526616 22542570456896 run_lib.py:133] step: 940050, training_loss: 2.49904e-02
I0212 08:50:49.187416 22542570456896 run_lib.py:133] step: 940100, training_loss: 2.69636e-02
I0212 08:50:49.341133 22542570456896 run_lib.py:146] step: 940100, eval_loss: 3.11537e-02
I0212 08:51:06.855128 22542570456896 run_lib.py:133] step: 940150, training_loss: 2.76867e-02
I0212 08:51:24.513635 22542570456896 run_lib.py:133] step: 940200, training_loss: 3.05706e-02
I0212 08:51:24.666376 22542570456896 run_lib.py:146] step: 940200, eval_loss: 2.62158e-02
I0212 08:51:42.130200 22542570456896 run_lib.py:133] step: 940250, training_loss: 3.23361e-02
I0212 08:51:59.585947 22542570456896 run_lib.py:133] step: 940300, training_loss: 2.83486e-02
I0212 08:51:59.742353 22542570456896 run_lib.py:146] step: 940300, eval_loss: 3.17936e-02
I0212 08:52:17.349387 22542570456896 run_lib.py:133] step: 940350, training_loss: 2.89329e-02
I0212 08:52:34.925087 22542570456896 run_lib.py:133] step: 940400, training_loss: 3.35258e-02
I0212 08:52:35.094412 22542570456896 run_lib.py:146] step: 940400, eval_loss: 2.95733e-02
I0212 08:52:52.762910 22542570456896 run_lib.py:133] step: 940450, training_loss: 3.58269e-02
I0212 08:53:10.260805 22542570456896 run_lib.py:133] step: 940500, training_loss: 3.31641e-02
I0212 08:53:10.418470 22542570456896 run_lib.py:146] step: 940500, eval_loss: 3.21013e-02
I0212 08:53:27.904163 22542570456896 run_lib.py:133] step: 940550, training_loss: 1.90278e-02
I0212 08:53:45.573777 22542570456896 run_lib.py:133] step: 940600, training_loss: 2.70864e-02
I0212 08:53:45.730637 22542570456896 run_lib.py:146] step: 940600, eval_loss: 2.86291e-02
I0212 08:54:03.237888 22542570456896 run_lib.py:133] step: 940650, training_loss: 2.77900e-02
I0212 08:54:20.735108 22542570456896 run_lib.py:133] step: 940700, training_loss: 2.67777e-02
I0212 08:54:20.888652 22542570456896 run_lib.py:146] step: 940700, eval_loss: 2.56507e-02
I0212 08:54:38.368567 22542570456896 run_lib.py:133] step: 940750, training_loss: 1.92513e-02
I0212 08:54:56.043836 22542570456896 run_lib.py:133] step: 940800, training_loss: 2.30671e-02
I0212 08:54:56.203762 22542570456896 run_lib.py:146] step: 940800, eval_loss: 2.83264e-02
I0212 08:55:13.645722 22542570456896 run_lib.py:133] step: 940850, training_loss: 2.77166e-02
I0212 08:55:31.166854 22542570456896 run_lib.py:133] step: 940900, training_loss: 2.75327e-02
I0212 08:55:31.346386 22542570456896 run_lib.py:146] step: 940900, eval_loss: 3.46653e-02
I0212 08:55:48.885886 22542570456896 run_lib.py:133] step: 940950, training_loss: 2.55660e-02
I0212 08:56:06.380168 22542570456896 run_lib.py:133] step: 941000, training_loss: 2.81842e-02
I0212 08:56:06.538167 22542570456896 run_lib.py:146] step: 941000, eval_loss: 2.76537e-02
I0212 08:56:24.235847 22542570456896 run_lib.py:133] step: 941050, training_loss: 2.58020e-02
I0212 08:56:41.766720 22542570456896 run_lib.py:133] step: 941100, training_loss: 2.55620e-02
I0212 08:56:41.926081 22542570456896 run_lib.py:146] step: 941100, eval_loss: 3.63397e-02
I0212 08:56:59.412870 22542570456896 run_lib.py:133] step: 941150, training_loss: 1.94891e-02
I0212 08:57:16.909251 22542570456896 run_lib.py:133] step: 941200, training_loss: 3.09021e-02
I0212 08:57:17.068612 22542570456896 run_lib.py:146] step: 941200, eval_loss: 2.87702e-02
I0212 08:57:34.774656 22542570456896 run_lib.py:133] step: 941250, training_loss: 2.94797e-02
I0212 08:57:52.260524 22542570456896 run_lib.py:133] step: 941300, training_loss: 3.01661e-02
I0212 08:57:52.421446 22542570456896 run_lib.py:146] step: 941300, eval_loss: 3.02992e-02
I0212 08:58:10.012553 22542570456896 run_lib.py:133] step: 941350, training_loss: 2.62340e-02
I0212 08:58:27.481833 22542570456896 run_lib.py:133] step: 941400, training_loss: 2.35806e-02
I0212 08:58:27.637402 22542570456896 run_lib.py:146] step: 941400, eval_loss: 3.33672e-02
I0212 08:58:45.243755 22542570456896 run_lib.py:133] step: 941450, training_loss: 2.91410e-02
I0212 08:59:02.774354 22542570456896 run_lib.py:133] step: 941500, training_loss: 2.17795e-02
I0212 08:59:02.940215 22542570456896 run_lib.py:146] step: 941500, eval_loss: 2.69419e-02
I0212 08:59:20.462318 22542570456896 run_lib.py:133] step: 941550, training_loss: 2.85587e-02
I0212 08:59:38.138244 22542570456896 run_lib.py:133] step: 941600, training_loss: 2.61265e-02
I0212 08:59:38.292484 22542570456896 run_lib.py:146] step: 941600, eval_loss: 3.63108e-02
I0212 08:59:55.764689 22542570456896 run_lib.py:133] step: 941650, training_loss: 2.83555e-02
I0212 09:00:13.417074 22542570456896 run_lib.py:133] step: 941700, training_loss: 2.68122e-02
I0212 09:00:13.575671 22542570456896 run_lib.py:146] step: 941700, eval_loss: 3.70658e-02
I0212 09:00:31.069545 22542570456896 run_lib.py:133] step: 941750, training_loss: 2.04180e-02
I0212 09:00:48.583275 22542570456896 run_lib.py:133] step: 941800, training_loss: 3.23029e-02
I0212 09:00:48.744492 22542570456896 run_lib.py:146] step: 941800, eval_loss: 2.35297e-02
I0212 09:01:06.376731 22542570456896 run_lib.py:133] step: 941850, training_loss: 3.70621e-02
I0212 09:01:23.858831 22542570456896 run_lib.py:133] step: 941900, training_loss: 2.56624e-02
I0212 09:01:24.017566 22542570456896 run_lib.py:146] step: 941900, eval_loss: 2.82723e-02
I0212 09:01:41.518510 22542570456896 run_lib.py:133] step: 941950, training_loss: 2.83529e-02
I0212 09:01:59.127536 22542570456896 run_lib.py:133] step: 942000, training_loss: 2.38140e-02
I0212 09:01:59.291476 22542570456896 run_lib.py:146] step: 942000, eval_loss: 3.45388e-02
I0212 09:02:16.791234 22542570456896 run_lib.py:133] step: 942050, training_loss: 3.10913e-02
I0212 09:02:34.314781 22542570456896 run_lib.py:133] step: 942100, training_loss: 3.19136e-02
I0212 09:02:34.470690 22542570456896 run_lib.py:146] step: 942100, eval_loss: 2.95782e-02
I0212 09:02:52.075924 22542570456896 run_lib.py:133] step: 942150, training_loss: 2.95290e-02
I0212 09:03:09.518675 22542570456896 run_lib.py:133] step: 942200, training_loss: 2.70231e-02
I0212 09:03:09.682351 22542570456896 run_lib.py:146] step: 942200, eval_loss: 3.22937e-02
I0212 09:03:27.113043 22542570456896 run_lib.py:133] step: 942250, training_loss: 3.31938e-02
I0212 09:03:44.586809 22542570456896 run_lib.py:133] step: 942300, training_loss: 2.86137e-02
I0212 09:03:44.767464 22542570456896 run_lib.py:146] step: 942300, eval_loss: 2.34840e-02
I0212 09:04:02.424215 22542570456896 run_lib.py:133] step: 942350, training_loss: 2.61856e-02
I0212 09:04:20.008401 22542570456896 run_lib.py:133] step: 942400, training_loss: 2.94503e-02
I0212 09:04:20.173534 22542570456896 run_lib.py:146] step: 942400, eval_loss: 3.06222e-02
I0212 09:04:37.633811 22542570456896 run_lib.py:133] step: 942450, training_loss: 3.20866e-02
I0212 09:04:55.069407 22542570456896 run_lib.py:133] step: 942500, training_loss: 2.36245e-02
I0212 09:04:55.232250 22542570456896 run_lib.py:146] step: 942500, eval_loss: 2.81104e-02
I0212 09:05:12.806945 22542570456896 run_lib.py:133] step: 942550, training_loss: 2.70271e-02
I0212 09:05:30.214084 22542570456896 run_lib.py:133] step: 942600, training_loss: 2.89035e-02
I0212 09:05:30.368990 22542570456896 run_lib.py:146] step: 942600, eval_loss: 2.79566e-02
I0212 09:05:47.903522 22542570456896 run_lib.py:133] step: 942650, training_loss: 3.17361e-02
I0212 09:06:05.281645 22542570456896 run_lib.py:133] step: 942700, training_loss: 2.54453e-02
I0212 09:06:05.439375 22542570456896 run_lib.py:146] step: 942700, eval_loss: 2.86684e-02
I0212 09:06:22.978554 22542570456896 run_lib.py:133] step: 942750, training_loss: 2.33659e-02
I0212 09:06:40.352934 22542570456896 run_lib.py:133] step: 942800, training_loss: 2.73665e-02
I0212 09:06:40.516642 22542570456896 run_lib.py:146] step: 942800, eval_loss: 2.67778e-02
I0212 09:06:58.056196 22542570456896 run_lib.py:133] step: 942850, training_loss: 2.61448e-02
I0212 09:07:15.479815 22542570456896 run_lib.py:133] step: 942900, training_loss: 2.63578e-02
I0212 09:07:15.635131 22542570456896 run_lib.py:146] step: 942900, eval_loss: 2.27811e-02
I0212 09:07:33.016778 22542570456896 run_lib.py:133] step: 942950, training_loss: 3.18525e-02
I0212 09:07:50.617295 22542570456896 run_lib.py:133] step: 943000, training_loss: 2.62677e-02
I0212 09:07:50.773222 22542570456896 run_lib.py:146] step: 943000, eval_loss: 2.56096e-02
I0212 09:08:08.230636 22542570456896 run_lib.py:133] step: 943050, training_loss: 3.13326e-02
I0212 09:08:25.716240 22542570456896 run_lib.py:133] step: 943100, training_loss: 2.67800e-02
I0212 09:08:25.874489 22542570456896 run_lib.py:146] step: 943100, eval_loss: 2.54438e-02
I0212 09:08:43.522708 22542570456896 run_lib.py:133] step: 943150, training_loss: 2.73518e-02
I0212 09:09:01.039152 22542570456896 run_lib.py:133] step: 943200, training_loss: 2.97704e-02
I0212 09:09:01.200470 22542570456896 run_lib.py:146] step: 943200, eval_loss: 3.05433e-02
I0212 09:09:18.871507 22542570456896 run_lib.py:133] step: 943250, training_loss: 2.84424e-02
I0212 09:09:36.360448 22542570456896 run_lib.py:133] step: 943300, training_loss: 3.20551e-02
I0212 09:09:36.516353 22542570456896 run_lib.py:146] step: 943300, eval_loss: 2.76807e-02
I0212 09:09:54.006842 22542570456896 run_lib.py:133] step: 943350, training_loss: 2.74054e-02
I0212 09:10:11.684223 22542570456896 run_lib.py:133] step: 943400, training_loss: 2.25642e-02
I0212 09:10:11.846265 22542570456896 run_lib.py:146] step: 943400, eval_loss: 2.78954e-02
I0212 09:10:29.343904 22542570456896 run_lib.py:133] step: 943450, training_loss: 2.86272e-02
I0212 09:10:46.883686 22542570456896 run_lib.py:133] step: 943500, training_loss: 3.39694e-02
I0212 09:10:47.036457 22542570456896 run_lib.py:146] step: 943500, eval_loss: 2.65479e-02
I0212 09:11:04.516108 22542570456896 run_lib.py:133] step: 943550, training_loss: 2.86195e-02
I0212 09:11:22.234743 22542570456896 run_lib.py:133] step: 943600, training_loss: 2.88778e-02
I0212 09:11:22.391944 22542570456896 run_lib.py:146] step: 943600, eval_loss: 2.56406e-02
I0212 09:11:39.873577 22542570456896 run_lib.py:133] step: 943650, training_loss: 2.98155e-02
I0212 09:11:57.450749 22542570456896 run_lib.py:133] step: 943700, training_loss: 2.79496e-02
I0212 09:11:57.621966 22542570456896 run_lib.py:146] step: 943700, eval_loss: 3.06950e-02
I0212 09:12:15.139002 22542570456896 run_lib.py:133] step: 943750, training_loss: 3.38099e-02
I0212 09:12:32.611815 22542570456896 run_lib.py:133] step: 943800, training_loss: 2.78227e-02
I0212 09:12:32.768695 22542570456896 run_lib.py:146] step: 943800, eval_loss: 2.40097e-02
I0212 09:12:50.480247 22542570456896 run_lib.py:133] step: 943850, training_loss: 2.31869e-02
I0212 09:13:08.002753 22542570456896 run_lib.py:133] step: 943900, training_loss: 2.69229e-02
I0212 09:13:08.159322 22542570456896 run_lib.py:146] step: 943900, eval_loss: 3.40864e-02
I0212 09:13:25.655935 22542570456896 run_lib.py:133] step: 943950, training_loss: 2.30481e-02
I0212 09:13:43.160857 22542570456896 run_lib.py:133] step: 944000, training_loss: 3.47932e-02
I0212 09:13:43.321619 22542570456896 run_lib.py:146] step: 944000, eval_loss: 3.25799e-02
I0212 09:14:01.057749 22542570456896 run_lib.py:133] step: 944050, training_loss: 3.13657e-02
I0212 09:14:18.545564 22542570456896 run_lib.py:133] step: 944100, training_loss: 3.40264e-02
I0212 09:14:18.704493 22542570456896 run_lib.py:146] step: 944100, eval_loss: 3.90578e-02
I0212 09:14:36.306821 22542570456896 run_lib.py:133] step: 944150, training_loss: 3.47839e-02
I0212 09:14:53.781756 22542570456896 run_lib.py:133] step: 944200, training_loss: 2.77860e-02
I0212 09:14:53.942115 22542570456896 run_lib.py:146] step: 944200, eval_loss: 3.29186e-02
I0212 09:15:11.603506 22542570456896 run_lib.py:133] step: 944250, training_loss: 2.87554e-02
I0212 09:15:29.175811 22542570456896 run_lib.py:133] step: 944300, training_loss: 2.43821e-02
I0212 09:15:29.333577 22542570456896 run_lib.py:146] step: 944300, eval_loss: 2.82076e-02
I0212 09:15:46.812357 22542570456896 run_lib.py:133] step: 944350, training_loss: 2.53021e-02
I0212 09:16:04.505561 22542570456896 run_lib.py:133] step: 944400, training_loss: 2.34196e-02
I0212 09:16:04.662183 22542570456896 run_lib.py:146] step: 944400, eval_loss: 2.73187e-02
I0212 09:16:22.113745 22542570456896 run_lib.py:133] step: 944450, training_loss: 1.86305e-02
I0212 09:16:39.730811 22542570456896 run_lib.py:133] step: 944500, training_loss: 2.34519e-02
I0212 09:16:39.884421 22542570456896 run_lib.py:146] step: 944500, eval_loss: 2.96267e-02
I0212 09:16:57.351375 22542570456896 run_lib.py:133] step: 944550, training_loss: 2.84329e-02
I0212 09:17:14.863473 22542570456896 run_lib.py:133] step: 944600, training_loss: 3.05263e-02
I0212 09:17:15.037380 22542570456896 run_lib.py:146] step: 944600, eval_loss: 2.91048e-02
I0212 09:17:32.779262 22542570456896 run_lib.py:133] step: 944650, training_loss: 2.16444e-02
I0212 09:17:50.303835 22542570456896 run_lib.py:133] step: 944700, training_loss: 1.99690e-02
I0212 09:17:50.461925 22542570456896 run_lib.py:146] step: 944700, eval_loss: 2.70052e-02
I0212 09:18:07.913406 22542570456896 run_lib.py:133] step: 944750, training_loss: 3.18101e-02
I0212 09:18:25.491858 22542570456896 run_lib.py:133] step: 944800, training_loss: 2.29883e-02
I0212 09:18:25.649599 22542570456896 run_lib.py:146] step: 944800, eval_loss: 3.18027e-02
I0212 09:18:43.119254 22542570456896 run_lib.py:133] step: 944850, training_loss: 2.99781e-02
I0212 09:19:00.697391 22542570456896 run_lib.py:133] step: 944900, training_loss: 2.83227e-02
I0212 09:19:01.051160 22542570456896 run_lib.py:146] step: 944900, eval_loss: 2.77599e-02
I0212 09:19:18.561966 22542570456896 run_lib.py:133] step: 944950, training_loss: 1.95859e-02
I0212 09:19:36.012686 22542570456896 run_lib.py:133] step: 945000, training_loss: 2.75106e-02
I0212 09:19:36.171345 22542570456896 run_lib.py:146] step: 945000, eval_loss: 2.99541e-02
I0212 09:19:53.653817 22542570456896 run_lib.py:133] step: 945050, training_loss: 2.90335e-02
I0212 09:20:11.144978 22542570456896 run_lib.py:133] step: 945100, training_loss: 2.43513e-02
I0212 09:20:11.306422 22542570456896 run_lib.py:146] step: 945100, eval_loss: 2.86521e-02
I0212 09:20:28.946403 22542570456896 run_lib.py:133] step: 945150, training_loss: 2.89767e-02
I0212 09:20:46.550168 22542570456896 run_lib.py:133] step: 945200, training_loss: 3.38967e-02
I0212 09:20:46.713661 22542570456896 run_lib.py:146] step: 945200, eval_loss: 2.38110e-02
I0212 09:21:04.188877 22542570456896 run_lib.py:133] step: 945250, training_loss: 2.90123e-02
I0212 09:21:21.645416 22542570456896 run_lib.py:133] step: 945300, training_loss: 3.24160e-02
I0212 09:21:21.801604 22542570456896 run_lib.py:146] step: 945300, eval_loss: 3.65012e-02
I0212 09:21:39.475547 22542570456896 run_lib.py:133] step: 945350, training_loss: 3.47786e-02
I0212 09:21:57.052427 22542570456896 run_lib.py:133] step: 945400, training_loss: 2.44746e-02
I0212 09:21:57.203784 22542570456896 run_lib.py:146] step: 945400, eval_loss: 3.04605e-02
I0212 09:22:14.736285 22542570456896 run_lib.py:133] step: 945450, training_loss: 2.97448e-02
I0212 09:22:32.224147 22542570456896 run_lib.py:133] step: 945500, training_loss: 3.05078e-02
I0212 09:22:32.380366 22542570456896 run_lib.py:146] step: 945500, eval_loss: 3.34031e-02
I0212 09:22:50.031680 22542570456896 run_lib.py:133] step: 945550, training_loss: 2.74447e-02
I0212 09:23:07.494903 22542570456896 run_lib.py:133] step: 945600, training_loss: 3.29716e-02
I0212 09:23:07.655649 22542570456896 run_lib.py:146] step: 945600, eval_loss: 3.64160e-02
I0212 09:23:25.266496 22542570456896 run_lib.py:133] step: 945650, training_loss: 2.87980e-02
I0212 09:23:42.743462 22542570456896 run_lib.py:133] step: 945700, training_loss: 2.70969e-02
I0212 09:23:42.908063 22542570456896 run_lib.py:146] step: 945700, eval_loss: 2.61487e-02
I0212 09:24:00.591470 22542570456896 run_lib.py:133] step: 945750, training_loss: 2.35065e-02
I0212 09:24:18.060239 22542570456896 run_lib.py:133] step: 945800, training_loss: 2.74572e-02
I0212 09:24:18.216144 22542570456896 run_lib.py:146] step: 945800, eval_loss: 2.83815e-02
I0212 09:24:35.732649 22542570456896 run_lib.py:133] step: 945850, training_loss: 2.96909e-02
I0212 09:24:53.347886 22542570456896 run_lib.py:133] step: 945900, training_loss: 2.75888e-02
I0212 09:24:53.500412 22542570456896 run_lib.py:146] step: 945900, eval_loss: 3.59413e-02
I0212 09:25:10.966885 22542570456896 run_lib.py:133] step: 945950, training_loss: 2.46545e-02
I0212 09:25:28.589807 22542570456896 run_lib.py:133] step: 946000, training_loss: 2.14499e-02
I0212 09:25:28.765831 22542570456896 run_lib.py:146] step: 946000, eval_loss: 2.77551e-02
I0212 09:25:46.333419 22542570456896 run_lib.py:133] step: 946050, training_loss: 2.98994e-02
I0212 09:26:03.844509 22542570456896 run_lib.py:133] step: 946100, training_loss: 2.20290e-02
I0212 09:26:04.003757 22542570456896 run_lib.py:146] step: 946100, eval_loss: 3.34334e-02
I0212 09:26:21.674400 22542570456896 run_lib.py:133] step: 946150, training_loss: 2.41560e-02
I0212 09:26:39.126665 22542570456896 run_lib.py:133] step: 946200, training_loss: 2.58877e-02
I0212 09:26:39.281348 22542570456896 run_lib.py:146] step: 946200, eval_loss: 3.11187e-02
I0212 09:26:56.736304 22542570456896 run_lib.py:133] step: 946250, training_loss: 2.71139e-02
I0212 09:27:14.226041 22542570456896 run_lib.py:133] step: 946300, training_loss: 2.39276e-02
I0212 09:27:14.383661 22542570456896 run_lib.py:146] step: 946300, eval_loss: 3.32525e-02
I0212 09:27:32.060976 22542570456896 run_lib.py:133] step: 946350, training_loss: 3.09389e-02
I0212 09:27:49.535383 22542570456896 run_lib.py:133] step: 946400, training_loss: 2.27810e-02
I0212 09:27:49.689769 22542570456896 run_lib.py:146] step: 946400, eval_loss: 2.86649e-02
I0212 09:28:07.235097 22542570456896 run_lib.py:133] step: 946450, training_loss: 2.75618e-02
I0212 09:28:24.714790 22542570456896 run_lib.py:133] step: 946500, training_loss: 3.96352e-02
I0212 09:28:24.883528 22542570456896 run_lib.py:146] step: 946500, eval_loss: 2.77495e-02
I0212 09:28:42.360917 22542570456896 run_lib.py:133] step: 946550, training_loss: 2.64525e-02
I0212 09:28:59.890826 22542570456896 run_lib.py:133] step: 946600, training_loss: 2.30938e-02
I0212 09:29:00.056447 22542570456896 run_lib.py:146] step: 946600, eval_loss: 2.84088e-02
I0212 09:29:17.706979 22542570456896 run_lib.py:133] step: 946650, training_loss: 2.82693e-02
I0212 09:29:35.236732 22542570456896 run_lib.py:133] step: 946700, training_loss: 1.95222e-02
I0212 09:29:35.394499 22542570456896 run_lib.py:146] step: 946700, eval_loss: 2.66777e-02
I0212 09:29:52.856133 22542570456896 run_lib.py:133] step: 946750, training_loss: 2.34952e-02
I0212 09:30:10.309401 22542570456896 run_lib.py:133] step: 946800, training_loss: 2.93656e-02
I0212 09:30:10.463197 22542570456896 run_lib.py:146] step: 946800, eval_loss: 2.84617e-02
I0212 09:30:28.094002 22542570456896 run_lib.py:133] step: 946850, training_loss: 2.48760e-02
I0212 09:30:45.582447 22542570456896 run_lib.py:133] step: 946900, training_loss: 2.64932e-02
I0212 09:30:45.747092 22542570456896 run_lib.py:146] step: 946900, eval_loss: 3.51486e-02
I0212 09:31:03.441327 22542570456896 run_lib.py:133] step: 946950, training_loss: 2.23947e-02
I0212 09:31:20.928101 22542570456896 run_lib.py:133] step: 947000, training_loss: 3.11150e-02
I0212 09:31:21.089807 22542570456896 run_lib.py:146] step: 947000, eval_loss: 3.04811e-02
I0212 09:31:38.755805 22542570456896 run_lib.py:133] step: 947050, training_loss: 2.18528e-02
I0212 09:31:56.208615 22542570456896 run_lib.py:133] step: 947100, training_loss: 2.56249e-02
I0212 09:31:56.372450 22542570456896 run_lib.py:146] step: 947100, eval_loss: 3.02791e-02
I0212 09:32:14.042092 22542570456896 run_lib.py:133] step: 947150, training_loss: 3.05468e-02
I0212 09:32:31.569028 22542570456896 run_lib.py:133] step: 947200, training_loss: 2.38504e-02
I0212 09:32:31.730759 22542570456896 run_lib.py:146] step: 947200, eval_loss: 3.80775e-02
I0212 09:32:49.231124 22542570456896 run_lib.py:133] step: 947250, training_loss: 2.87322e-02
I0212 09:33:06.884486 22542570456896 run_lib.py:133] step: 947300, training_loss: 3.03560e-02
I0212 09:33:07.038500 22542570456896 run_lib.py:146] step: 947300, eval_loss: 2.38207e-02
I0212 09:33:24.504466 22542570456896 run_lib.py:133] step: 947350, training_loss: 3.13502e-02
I0212 09:33:41.970415 22542570456896 run_lib.py:133] step: 947400, training_loss: 2.67817e-02
I0212 09:33:42.128690 22542570456896 run_lib.py:146] step: 947400, eval_loss: 3.11171e-02
I0212 09:33:59.772473 22542570456896 run_lib.py:133] step: 947450, training_loss: 2.32018e-02
I0212 09:34:17.492603 22542570456896 run_lib.py:133] step: 947500, training_loss: 2.78386e-02
I0212 09:34:17.661919 22542570456896 run_lib.py:146] step: 947500, eval_loss: 2.12494e-02
I0212 09:34:35.118257 22542570456896 run_lib.py:133] step: 947550, training_loss: 2.00106e-02
I0212 09:34:52.565847 22542570456896 run_lib.py:133] step: 947600, training_loss: 2.62995e-02
I0212 09:34:52.722543 22542570456896 run_lib.py:146] step: 947600, eval_loss: 2.64534e-02
I0212 09:35:10.209368 22542570456896 run_lib.py:133] step: 947650, training_loss: 2.63963e-02
I0212 09:35:27.831767 22542570456896 run_lib.py:133] step: 947700, training_loss: 2.34048e-02
I0212 09:35:27.989421 22542570456896 run_lib.py:146] step: 947700, eval_loss: 2.57317e-02
I0212 09:35:45.469893 22542570456896 run_lib.py:133] step: 947750, training_loss: 3.08765e-02
I0212 09:36:02.852133 22542570456896 run_lib.py:133] step: 947800, training_loss: 2.58828e-02
I0212 09:36:03.010540 22542570456896 run_lib.py:146] step: 947800, eval_loss: 2.71177e-02
I0212 09:36:20.398878 22542570456896 run_lib.py:133] step: 947850, training_loss: 2.27298e-02
I0212 09:36:38.031949 22542570456896 run_lib.py:133] step: 947900, training_loss: 3.19973e-02
I0212 09:36:38.187256 22542570456896 run_lib.py:146] step: 947900, eval_loss: 2.79670e-02
I0212 09:36:55.552436 22542570456896 run_lib.py:133] step: 947950, training_loss: 2.35561e-02
I0212 09:37:12.999540 22542570456896 run_lib.py:133] step: 948000, training_loss: 2.99115e-02
I0212 09:37:13.160196 22542570456896 run_lib.py:146] step: 948000, eval_loss: 3.53197e-02
I0212 09:37:30.574271 22542570456896 run_lib.py:133] step: 948050, training_loss: 3.04521e-02
I0212 09:37:47.994982 22542570456896 run_lib.py:133] step: 948100, training_loss: 3.15556e-02
I0212 09:37:48.150707 22542570456896 run_lib.py:146] step: 948100, eval_loss: 2.77072e-02
I0212 09:38:05.715349 22542570456896 run_lib.py:133] step: 948150, training_loss: 2.16303e-02
I0212 09:38:23.224533 22542570456896 run_lib.py:133] step: 948200, training_loss: 2.01425e-02
I0212 09:38:23.379386 22542570456896 run_lib.py:146] step: 948200, eval_loss: 3.32141e-02
I0212 09:38:40.844182 22542570456896 run_lib.py:133] step: 948250, training_loss: 2.65142e-02
I0212 09:38:58.309808 22542570456896 run_lib.py:133] step: 948300, training_loss: 2.39173e-02
I0212 09:38:58.464692 22542570456896 run_lib.py:146] step: 948300, eval_loss: 3.24684e-02
I0212 09:39:16.184520 22542570456896 run_lib.py:133] step: 948350, training_loss: 2.73983e-02
I0212 09:39:33.679540 22542570456896 run_lib.py:133] step: 948400, training_loss: 2.68049e-02
I0212 09:39:33.837837 22542570456896 run_lib.py:146] step: 948400, eval_loss: 3.75449e-02
I0212 09:39:51.491839 22542570456896 run_lib.py:133] step: 948450, training_loss: 3.00091e-02
I0212 09:40:08.964589 22542570456896 run_lib.py:133] step: 948500, training_loss: 2.65038e-02
I0212 09:40:09.120375 22542570456896 run_lib.py:146] step: 948500, eval_loss: 3.37897e-02
I0212 09:40:26.763845 22542570456896 run_lib.py:133] step: 948550, training_loss: 3.02347e-02
I0212 09:40:44.234294 22542570456896 run_lib.py:133] step: 948600, training_loss: 2.49804e-02
I0212 09:40:44.394192 22542570456896 run_lib.py:146] step: 948600, eval_loss: 2.65188e-02
I0212 09:41:01.867758 22542570456896 run_lib.py:133] step: 948650, training_loss: 3.46483e-02
I0212 09:41:19.591475 22542570456896 run_lib.py:133] step: 948700, training_loss: 3.23411e-02
I0212 09:41:19.747119 22542570456896 run_lib.py:146] step: 948700, eval_loss: 2.84688e-02
I0212 09:41:37.240793 22542570456896 run_lib.py:133] step: 948750, training_loss: 2.53952e-02
I0212 09:41:54.901618 22542570456896 run_lib.py:133] step: 948800, training_loss: 2.88175e-02
I0212 09:41:55.058495 22542570456896 run_lib.py:146] step: 948800, eval_loss: 3.44016e-02
I0212 09:42:12.492069 22542570456896 run_lib.py:133] step: 948850, training_loss: 2.51395e-02
I0212 09:42:29.969632 22542570456896 run_lib.py:133] step: 948900, training_loss: 2.29285e-02
I0212 09:42:30.145416 22542570456896 run_lib.py:146] step: 948900, eval_loss: 2.66471e-02
I0212 09:42:47.813435 22542570456896 run_lib.py:133] step: 948950, training_loss: 2.47505e-02
I0212 09:43:05.333577 22542570456896 run_lib.py:133] step: 949000, training_loss: 4.24501e-02
I0212 09:43:05.500455 22542570456896 run_lib.py:146] step: 949000, eval_loss: 2.88618e-02
I0212 09:43:23.014838 22542570456896 run_lib.py:133] step: 949050, training_loss: 2.74788e-02
I0212 09:43:40.654489 22542570456896 run_lib.py:133] step: 949100, training_loss: 2.53898e-02
I0212 09:43:40.817469 22542570456896 run_lib.py:146] step: 949100, eval_loss: 2.60253e-02
I0212 09:43:58.325656 22542570456896 run_lib.py:133] step: 949150, training_loss: 2.88406e-02
I0212 09:44:15.861425 22542570456896 run_lib.py:133] step: 949200, training_loss: 3.55339e-02
I0212 09:44:16.016629 22542570456896 run_lib.py:146] step: 949200, eval_loss: 3.12565e-02
I0212 09:44:33.656398 22542570456896 run_lib.py:133] step: 949250, training_loss: 3.82765e-02
I0212 09:44:51.128719 22542570456896 run_lib.py:133] step: 949300, training_loss: 2.80754e-02
I0212 09:44:51.289359 22542570456896 run_lib.py:146] step: 949300, eval_loss: 2.49350e-02
I0212 09:45:08.746723 22542570456896 run_lib.py:133] step: 949350, training_loss: 2.33228e-02
I0212 09:45:26.223602 22542570456896 run_lib.py:133] step: 949400, training_loss: 3.00295e-02
I0212 09:45:26.382640 22542570456896 run_lib.py:146] step: 949400, eval_loss: 2.86551e-02
I0212 09:45:44.042828 22542570456896 run_lib.py:133] step: 949450, training_loss: 2.65219e-02
I0212 09:46:01.578492 22542570456896 run_lib.py:133] step: 949500, training_loss: 3.33439e-02
I0212 09:46:01.748479 22542570456896 run_lib.py:146] step: 949500, eval_loss: 3.07354e-02
I0212 09:46:19.265523 22542570456896 run_lib.py:133] step: 949550, training_loss: 2.99710e-02
I0212 09:46:36.795699 22542570456896 run_lib.py:133] step: 949600, training_loss: 2.66037e-02
I0212 09:46:36.954770 22542570456896 run_lib.py:146] step: 949600, eval_loss: 3.35660e-02
I0212 09:46:54.660665 22542570456896 run_lib.py:133] step: 949650, training_loss: 3.42299e-02
I0212 09:47:12.144804 22542570456896 run_lib.py:133] step: 949700, training_loss: 3.29594e-02
I0212 09:47:12.296592 22542570456896 run_lib.py:146] step: 949700, eval_loss: 2.64516e-02
I0212 09:47:29.892160 22542570456896 run_lib.py:133] step: 949750, training_loss: 2.71584e-02
I0212 09:47:47.359769 22542570456896 run_lib.py:133] step: 949800, training_loss: 3.03861e-02
I0212 09:47:47.528522 22542570456896 run_lib.py:146] step: 949800, eval_loss: 3.45799e-02
I0212 09:48:05.229867 22542570456896 run_lib.py:133] step: 949850, training_loss: 2.55121e-02
I0212 09:48:22.726184 22542570456896 run_lib.py:133] step: 949900, training_loss: 2.36738e-02
I0212 09:48:22.885490 22542570456896 run_lib.py:146] step: 949900, eval_loss: 2.98831e-02
I0212 09:48:40.518202 22542570456896 run_lib.py:133] step: 949950, training_loss: 2.84231e-02
I0212 09:48:57.981342 22542570456896 run_lib.py:133] step: 950000, training_loss: 3.28072e-02
I0212 09:48:58.730020 22542570456896 run_lib.py:146] step: 950000, eval_loss: 2.97466e-02
I0212 09:49:19.179500 22542570456896 run_lib.py:133] step: 950050, training_loss: 2.29958e-02
I0212 09:49:36.828458 22542570456896 run_lib.py:133] step: 950100, training_loss: 2.37791e-02
I0212 09:49:36.985185 22542570456896 run_lib.py:146] step: 950100, eval_loss: 2.69978e-02
I0212 09:49:54.447169 22542570456896 run_lib.py:133] step: 950150, training_loss: 3.06110e-02
I0212 09:50:12.039077 22542570456896 run_lib.py:133] step: 950200, training_loss: 2.37196e-02
I0212 09:50:12.201198 22542570456896 run_lib.py:146] step: 950200, eval_loss: 3.27147e-02
I0212 09:50:29.647027 22542570456896 run_lib.py:133] step: 950250, training_loss: 2.61018e-02
I0212 09:50:47.108756 22542570456896 run_lib.py:133] step: 950300, training_loss: 2.58927e-02
I0212 09:50:47.264413 22542570456896 run_lib.py:146] step: 950300, eval_loss: 2.85556e-02
I0212 09:51:04.926759 22542570456896 run_lib.py:133] step: 950350, training_loss: 2.80965e-02
I0212 09:51:22.510915 22542570456896 run_lib.py:133] step: 950400, training_loss: 2.80273e-02
I0212 09:51:22.678493 22542570456896 run_lib.py:146] step: 950400, eval_loss: 2.44520e-02
I0212 09:51:40.167708 22542570456896 run_lib.py:133] step: 950450, training_loss: 2.51511e-02
I0212 09:51:57.645187 22542570456896 run_lib.py:133] step: 950500, training_loss: 2.65016e-02
I0212 09:51:57.801606 22542570456896 run_lib.py:146] step: 950500, eval_loss: 2.70585e-02
I0212 09:52:15.445229 22542570456896 run_lib.py:133] step: 950550, training_loss: 3.03332e-02
I0212 09:52:32.910124 22542570456896 run_lib.py:133] step: 950600, training_loss: 3.21955e-02
I0212 09:52:33.076642 22542570456896 run_lib.py:146] step: 950600, eval_loss: 3.04863e-02
I0212 09:52:50.758346 22542570456896 run_lib.py:133] step: 950650, training_loss: 3.05697e-02
I0212 09:53:08.233182 22542570456896 run_lib.py:133] step: 950700, training_loss: 3.00432e-02
I0212 09:53:08.386665 22542570456896 run_lib.py:146] step: 950700, eval_loss: 3.09850e-02
I0212 09:53:26.066064 22542570456896 run_lib.py:133] step: 950750, training_loss: 2.58304e-02
I0212 09:53:43.552228 22542570456896 run_lib.py:133] step: 950800, training_loss: 2.76913e-02
I0212 09:53:43.709406 22542570456896 run_lib.py:146] step: 950800, eval_loss: 3.12484e-02
I0212 09:54:01.181014 22542570456896 run_lib.py:133] step: 950850, training_loss: 2.46383e-02
I0212 09:54:18.859188 22542570456896 run_lib.py:133] step: 950900, training_loss: 2.90260e-02
I0212 09:54:19.039335 22542570456896 run_lib.py:146] step: 950900, eval_loss: 1.88315e-02
I0212 09:54:36.578306 22542570456896 run_lib.py:133] step: 950950, training_loss: 3.61284e-02
I0212 09:54:54.250207 22542570456896 run_lib.py:133] step: 951000, training_loss: 2.04646e-02
I0212 09:54:54.408694 22542570456896 run_lib.py:146] step: 951000, eval_loss: 3.74976e-02
I0212 09:55:11.874286 22542570456896 run_lib.py:133] step: 951050, training_loss: 2.77143e-02
I0212 09:55:29.307836 22542570456896 run_lib.py:133] step: 951100, training_loss: 2.44535e-02
I0212 09:55:29.463480 22542570456896 run_lib.py:146] step: 951100, eval_loss: 2.71264e-02
I0212 09:55:47.067134 22542570456896 run_lib.py:133] step: 951150, training_loss: 2.85410e-02
I0212 09:56:04.550982 22542570456896 run_lib.py:133] step: 951200, training_loss: 2.44289e-02
I0212 09:56:04.705548 22542570456896 run_lib.py:146] step: 951200, eval_loss: 3.13955e-02
I0212 09:56:22.216320 22542570456896 run_lib.py:133] step: 951250, training_loss: 2.78526e-02
I0212 09:56:39.884288 22542570456896 run_lib.py:133] step: 951300, training_loss: 2.33865e-02
I0212 09:56:40.046458 22542570456896 run_lib.py:146] step: 951300, eval_loss: 2.69895e-02
I0212 09:56:57.545829 22542570456896 run_lib.py:133] step: 951350, training_loss: 2.11246e-02
I0212 09:57:15.011680 22542570456896 run_lib.py:133] step: 951400, training_loss: 2.72905e-02
I0212 09:57:15.168651 22542570456896 run_lib.py:146] step: 951400, eval_loss: 2.53257e-02
I0212 09:57:32.738843 22542570456896 run_lib.py:133] step: 951450, training_loss: 2.58971e-02
I0212 09:57:50.281358 22542570456896 run_lib.py:133] step: 951500, training_loss: 2.27874e-02
I0212 09:57:50.437969 22542570456896 run_lib.py:146] step: 951500, eval_loss: 2.51116e-02
I0212 09:58:07.920425 22542570456896 run_lib.py:133] step: 951550, training_loss: 2.66781e-02
I0212 09:58:25.352527 22542570456896 run_lib.py:133] step: 951600, training_loss: 3.37851e-02
I0212 09:58:25.508237 22542570456896 run_lib.py:146] step: 951600, eval_loss: 3.48871e-02
I0212 09:58:43.161430 22542570456896 run_lib.py:133] step: 951650, training_loss: 2.46741e-02
I0212 09:59:00.701943 22542570456896 run_lib.py:133] step: 951700, training_loss: 2.56937e-02
I0212 09:59:00.857707 22542570456896 run_lib.py:146] step: 951700, eval_loss: 2.69032e-02
I0212 09:59:18.382370 22542570456896 run_lib.py:133] step: 951750, training_loss: 2.73949e-02
I0212 09:59:35.862859 22542570456896 run_lib.py:133] step: 951800, training_loss: 2.88156e-02
I0212 09:59:36.027522 22542570456896 run_lib.py:146] step: 951800, eval_loss: 3.87745e-02
I0212 09:59:53.668512 22542570456896 run_lib.py:133] step: 951850, training_loss: 2.49669e-02
I0212 10:00:11.120834 22542570456896 run_lib.py:133] step: 951900, training_loss: 3.26651e-02
I0212 10:00:11.278399 22542570456896 run_lib.py:146] step: 951900, eval_loss: 2.64146e-02
I0212 10:00:28.888783 22542570456896 run_lib.py:133] step: 951950, training_loss: 3.05170e-02
I0212 10:00:46.342108 22542570456896 run_lib.py:133] step: 952000, training_loss: 2.95776e-02
I0212 10:00:46.509175 22542570456896 run_lib.py:146] step: 952000, eval_loss: 2.96111e-02
I0212 10:01:04.165303 22542570456896 run_lib.py:133] step: 952050, training_loss: 2.39487e-02
I0212 10:01:21.681920 22542570456896 run_lib.py:133] step: 952100, training_loss: 2.90940e-02
I0212 10:01:21.834133 22542570456896 run_lib.py:146] step: 952100, eval_loss: 3.28344e-02
I0212 10:01:39.520114 22542570456896 run_lib.py:133] step: 952150, training_loss: 2.87903e-02
I0212 10:01:56.994560 22542570456896 run_lib.py:133] step: 952200, training_loss: 2.89695e-02
I0212 10:01:57.151408 22542570456896 run_lib.py:146] step: 952200, eval_loss: 2.44555e-02
I0212 10:02:14.600313 22542570456896 run_lib.py:133] step: 952250, training_loss: 2.49831e-02
I0212 10:02:32.203125 22542570456896 run_lib.py:133] step: 952300, training_loss: 2.86348e-02
I0212 10:02:32.375358 22542570456896 run_lib.py:146] step: 952300, eval_loss: 3.33965e-02
I0212 10:02:49.880953 22542570456896 run_lib.py:133] step: 952350, training_loss: 2.24419e-02
I0212 10:03:07.369162 22542570456896 run_lib.py:133] step: 952400, training_loss: 2.64908e-02
I0212 10:03:07.525462 22542570456896 run_lib.py:146] step: 952400, eval_loss: 3.04759e-02
I0212 10:03:25.212639 22542570456896 run_lib.py:133] step: 952450, training_loss: 1.73842e-02
I0212 10:03:42.666714 22542570456896 run_lib.py:133] step: 952500, training_loss: 2.17314e-02
I0212 10:03:42.822256 22542570456896 run_lib.py:146] step: 952500, eval_loss: 3.04534e-02
I0212 10:04:00.415412 22542570456896 run_lib.py:133] step: 952550, training_loss: 2.45846e-02
I0212 10:04:17.885157 22542570456896 run_lib.py:133] step: 952600, training_loss: 2.20915e-02
I0212 10:04:18.041132 22542570456896 run_lib.py:146] step: 952600, eval_loss: 2.45903e-02
I0212 10:04:35.557286 22542570456896 run_lib.py:133] step: 952650, training_loss: 2.39415e-02
I0212 10:04:53.237514 22542570456896 run_lib.py:133] step: 952700, training_loss: 2.55643e-02
I0212 10:04:53.394397 22542570456896 run_lib.py:146] step: 952700, eval_loss: 3.17340e-02
I0212 10:05:10.830303 22542570456896 run_lib.py:133] step: 952750, training_loss: 2.82456e-02
I0212 10:05:28.278842 22542570456896 run_lib.py:133] step: 952800, training_loss: 2.73210e-02
I0212 10:05:28.442624 22542570456896 run_lib.py:146] step: 952800, eval_loss: 2.52854e-02
I0212 10:05:45.905035 22542570456896 run_lib.py:133] step: 952850, training_loss: 2.94403e-02
I0212 10:06:03.632113 22542570456896 run_lib.py:133] step: 952900, training_loss: 2.75477e-02
I0212 10:06:03.788751 22542570456896 run_lib.py:146] step: 952900, eval_loss: 2.99065e-02
I0212 10:06:21.237585 22542570456896 run_lib.py:133] step: 952950, training_loss: 3.75311e-02
I0212 10:06:38.694687 22542570456896 run_lib.py:133] step: 953000, training_loss: 2.62643e-02
I0212 10:06:38.849448 22542570456896 run_lib.py:146] step: 953000, eval_loss: 2.38931e-02
I0212 10:06:56.196515 22542570456896 run_lib.py:133] step: 953050, training_loss: 2.55081e-02
I0212 10:07:13.609487 22542570456896 run_lib.py:133] step: 953100, training_loss: 2.37637e-02
I0212 10:07:13.766441 22542570456896 run_lib.py:146] step: 953100, eval_loss: 2.96203e-02
I0212 10:07:31.283165 22542570456896 run_lib.py:133] step: 953150, training_loss: 3.59910e-02
I0212 10:07:48.780824 22542570456896 run_lib.py:133] step: 953200, training_loss: 2.61031e-02
I0212 10:07:48.957413 22542570456896 run_lib.py:146] step: 953200, eval_loss: 2.73471e-02
I0212 10:08:06.378736 22542570456896 run_lib.py:133] step: 953250, training_loss: 2.33917e-02
I0212 10:08:23.770415 22542570456896 run_lib.py:133] step: 953300, training_loss: 3.38315e-02
I0212 10:08:23.928471 22542570456896 run_lib.py:146] step: 953300, eval_loss: 2.74129e-02
I0212 10:08:41.462436 22542570456896 run_lib.py:133] step: 953350, training_loss: 2.74260e-02
I0212 10:08:58.935647 22542570456896 run_lib.py:133] step: 953400, training_loss: 2.53483e-02
I0212 10:08:59.093240 22542570456896 run_lib.py:146] step: 953400, eval_loss: 2.51094e-02
I0212 10:09:16.713231 22542570456896 run_lib.py:133] step: 953450, training_loss: 2.39043e-02
I0212 10:09:34.266051 22542570456896 run_lib.py:133] step: 953500, training_loss: 2.72433e-02
I0212 10:09:34.421311 22542570456896 run_lib.py:146] step: 953500, eval_loss: 2.67016e-02
I0212 10:09:52.116176 22542570456896 run_lib.py:133] step: 953550, training_loss: 3.89239e-02
I0212 10:10:09.571206 22542570456896 run_lib.py:133] step: 953600, training_loss: 2.42349e-02
I0212 10:10:09.732431 22542570456896 run_lib.py:146] step: 953600, eval_loss: 2.34270e-02
I0212 10:10:27.184664 22542570456896 run_lib.py:133] step: 953650, training_loss: 2.03212e-02
I0212 10:10:44.814389 22542570456896 run_lib.py:133] step: 953700, training_loss: 2.58526e-02
I0212 10:10:44.978662 22542570456896 run_lib.py:146] step: 953700, eval_loss: 3.04941e-02
I0212 10:11:02.471382 22542570456896 run_lib.py:133] step: 953750, training_loss: 2.64226e-02
I0212 10:11:20.140029 22542570456896 run_lib.py:133] step: 953800, training_loss: 2.83607e-02
I0212 10:11:20.298551 22542570456896 run_lib.py:146] step: 953800, eval_loss: 2.91093e-02
I0212 10:11:37.785178 22542570456896 run_lib.py:133] step: 953850, training_loss: 2.58201e-02
I0212 10:11:55.256442 22542570456896 run_lib.py:133] step: 953900, training_loss: 2.55189e-02
I0212 10:11:55.413780 22542570456896 run_lib.py:146] step: 953900, eval_loss: 2.34842e-02
I0212 10:12:13.118889 22542570456896 run_lib.py:133] step: 953950, training_loss: 3.13126e-02
I0212 10:12:30.606909 22542570456896 run_lib.py:133] step: 954000, training_loss: 2.71538e-02
I0212 10:12:30.761996 22542570456896 run_lib.py:146] step: 954000, eval_loss: 3.29654e-02
I0212 10:12:48.257202 22542570456896 run_lib.py:133] step: 954050, training_loss: 2.93630e-02
I0212 10:13:05.930754 22542570456896 run_lib.py:133] step: 954100, training_loss: 2.50783e-02
I0212 10:13:06.090967 22542570456896 run_lib.py:146] step: 954100, eval_loss: 2.78191e-02
I0212 10:13:23.551389 22542570456896 run_lib.py:133] step: 954150, training_loss: 2.79861e-02
I0212 10:13:41.060853 22542570456896 run_lib.py:133] step: 954200, training_loss: 2.68758e-02
I0212 10:13:41.398583 22542570456896 run_lib.py:146] step: 954200, eval_loss: 2.80138e-02
I0212 10:13:58.858643 22542570456896 run_lib.py:133] step: 954250, training_loss: 2.51686e-02
I0212 10:14:16.362397 22542570456896 run_lib.py:133] step: 954300, training_loss: 3.33376e-02
I0212 10:14:16.535386 22542570456896 run_lib.py:146] step: 954300, eval_loss: 2.11406e-02
I0212 10:14:34.032390 22542570456896 run_lib.py:133] step: 954350, training_loss: 2.84675e-02
I0212 10:14:51.516746 22542570456896 run_lib.py:133] step: 954400, training_loss: 2.81715e-02
I0212 10:14:51.675685 22542570456896 run_lib.py:146] step: 954400, eval_loss: 3.36929e-02
I0212 10:15:09.367896 22542570456896 run_lib.py:133] step: 954450, training_loss: 2.50387e-02
I0212 10:15:26.872173 22542570456896 run_lib.py:133] step: 954500, training_loss: 2.80201e-02
I0212 10:15:27.024671 22542570456896 run_lib.py:146] step: 954500, eval_loss: 3.31261e-02
I0212 10:15:44.468889 22542570456896 run_lib.py:133] step: 954550, training_loss: 2.31440e-02
I0212 10:16:01.957046 22542570456896 run_lib.py:133] step: 954600, training_loss: 2.58674e-02
I0212 10:16:02.128607 22542570456896 run_lib.py:146] step: 954600, eval_loss: 3.27819e-02
I0212 10:16:19.844261 22542570456896 run_lib.py:133] step: 954650, training_loss: 2.89550e-02
I0212 10:16:37.423730 22542570456896 run_lib.py:133] step: 954700, training_loss: 2.56015e-02
I0212 10:16:37.593918 22542570456896 run_lib.py:146] step: 954700, eval_loss: 2.88758e-02
I0212 10:16:55.049187 22542570456896 run_lib.py:133] step: 954750, training_loss: 2.84000e-02
I0212 10:17:12.490851 22542570456896 run_lib.py:133] step: 954800, training_loss: 2.71824e-02
I0212 10:17:12.651348 22542570456896 run_lib.py:146] step: 954800, eval_loss: 3.07184e-02
I0212 10:17:30.338120 22542570456896 run_lib.py:133] step: 954850, training_loss: 2.55894e-02
I0212 10:17:47.862099 22542570456896 run_lib.py:133] step: 954900, training_loss: 1.96092e-02
I0212 10:17:48.019784 22542570456896 run_lib.py:146] step: 954900, eval_loss: 3.14262e-02
I0212 10:18:05.725884 22542570456896 run_lib.py:133] step: 954950, training_loss: 3.05362e-02
I0212 10:18:23.197931 22542570456896 run_lib.py:133] step: 955000, training_loss: 2.70325e-02
I0212 10:18:23.350450 22542570456896 run_lib.py:146] step: 955000, eval_loss: 2.95220e-02
I0212 10:18:40.969925 22542570456896 run_lib.py:133] step: 955050, training_loss: 2.44997e-02
I0212 10:18:58.447217 22542570456896 run_lib.py:133] step: 955100, training_loss: 3.40255e-02
I0212 10:18:58.607598 22542570456896 run_lib.py:146] step: 955100, eval_loss: 2.56280e-02
I0212 10:19:16.113898 22542570456896 run_lib.py:133] step: 955150, training_loss: 2.26712e-02
I0212 10:19:33.835260 22542570456896 run_lib.py:133] step: 955200, training_loss: 2.34680e-02
I0212 10:19:33.991516 22542570456896 run_lib.py:146] step: 955200, eval_loss: 2.76989e-02
I0212 10:19:51.477597 22542570456896 run_lib.py:133] step: 955250, training_loss: 2.60684e-02
I0212 10:20:09.113919 22542570456896 run_lib.py:133] step: 955300, training_loss: 2.48930e-02
I0212 10:20:09.271200 22542570456896 run_lib.py:146] step: 955300, eval_loss: 2.83801e-02
I0212 10:20:26.724693 22542570456896 run_lib.py:133] step: 955350, training_loss: 2.60373e-02
I0212 10:20:44.191402 22542570456896 run_lib.py:133] step: 955400, training_loss: 3.52932e-02
I0212 10:20:44.348227 22542570456896 run_lib.py:146] step: 955400, eval_loss: 2.73590e-02
I0212 10:21:02.063002 22542570456896 run_lib.py:133] step: 955450, training_loss: 3.28053e-02
I0212 10:21:19.556069 22542570456896 run_lib.py:133] step: 955500, training_loss: 2.62961e-02
I0212 10:21:19.711627 22542570456896 run_lib.py:146] step: 955500, eval_loss: 3.41493e-02
I0212 10:21:37.191432 22542570456896 run_lib.py:133] step: 955550, training_loss: 2.37296e-02
I0212 10:21:54.664858 22542570456896 run_lib.py:133] step: 955600, training_loss: 2.20776e-02
I0212 10:21:54.832464 22542570456896 run_lib.py:146] step: 955600, eval_loss: 2.81989e-02
I0212 10:22:12.475507 22542570456896 run_lib.py:133] step: 955650, training_loss: 2.89672e-02
I0212 10:22:29.974321 22542570456896 run_lib.py:133] step: 955700, training_loss: 2.77303e-02
I0212 10:22:30.142432 22542570456896 run_lib.py:146] step: 955700, eval_loss: 2.87137e-02
I0212 10:22:47.699406 22542570456896 run_lib.py:133] step: 955750, training_loss: 3.22558e-02
I0212 10:23:05.203954 22542570456896 run_lib.py:133] step: 955800, training_loss: 2.63289e-02
I0212 10:23:05.362042 22542570456896 run_lib.py:146] step: 955800, eval_loss: 2.64521e-02
I0212 10:23:22.868715 22542570456896 run_lib.py:133] step: 955850, training_loss: 2.28384e-02
I0212 10:23:40.336955 22542570456896 run_lib.py:133] step: 955900, training_loss: 3.19270e-02
I0212 10:23:40.488379 22542570456896 run_lib.py:146] step: 955900, eval_loss: 2.93358e-02
I0212 10:23:58.144108 22542570456896 run_lib.py:133] step: 955950, training_loss: 2.70189e-02
I0212 10:24:15.719351 22542570456896 run_lib.py:133] step: 956000, training_loss: 2.15967e-02
I0212 10:24:15.893767 22542570456896 run_lib.py:146] step: 956000, eval_loss: 3.50010e-02
I0212 10:24:33.418148 22542570456896 run_lib.py:133] step: 956050, training_loss: 2.41751e-02
I0212 10:24:50.900328 22542570456896 run_lib.py:133] step: 956100, training_loss: 2.54686e-02
I0212 10:24:51.061706 22542570456896 run_lib.py:146] step: 956100, eval_loss: 3.28460e-02
I0212 10:25:08.705085 22542570456896 run_lib.py:133] step: 956150, training_loss: 3.72790e-02
I0212 10:25:26.184956 22542570456896 run_lib.py:133] step: 956200, training_loss: 3.00595e-02
I0212 10:25:26.341360 22542570456896 run_lib.py:146] step: 956200, eval_loss: 2.47791e-02
I0212 10:25:43.988522 22542570456896 run_lib.py:133] step: 956250, training_loss: 2.94233e-02
I0212 10:26:01.556238 22542570456896 run_lib.py:133] step: 956300, training_loss: 2.96327e-02
I0212 10:26:01.715304 22542570456896 run_lib.py:146] step: 956300, eval_loss: 3.66245e-02
I0212 10:26:19.433395 22542570456896 run_lib.py:133] step: 956350, training_loss: 3.05490e-02
I0212 10:26:36.911239 22542570456896 run_lib.py:133] step: 956400, training_loss: 3.30290e-02
I0212 10:26:37.065465 22542570456896 run_lib.py:146] step: 956400, eval_loss: 2.68102e-02
I0212 10:26:54.696811 22542570456896 run_lib.py:133] step: 956450, training_loss: 2.37520e-02
I0212 10:27:12.158447 22542570456896 run_lib.py:133] step: 956500, training_loss: 2.71506e-02
I0212 10:27:12.315713 22542570456896 run_lib.py:146] step: 956500, eval_loss: 2.46072e-02
I0212 10:27:29.823670 22542570456896 run_lib.py:133] step: 956550, training_loss: 3.72882e-02
I0212 10:27:47.529969 22542570456896 run_lib.py:133] step: 956600, training_loss: 2.58619e-02
I0212 10:27:47.690374 22542570456896 run_lib.py:146] step: 956600, eval_loss: 2.74753e-02
I0212 10:28:05.125115 22542570456896 run_lib.py:133] step: 956650, training_loss: 2.19397e-02
I0212 10:28:22.575027 22542570456896 run_lib.py:133] step: 956700, training_loss: 2.57967e-02
I0212 10:28:22.735439 22542570456896 run_lib.py:146] step: 956700, eval_loss: 3.99322e-02
I0212 10:28:40.413188 22542570456896 run_lib.py:133] step: 956750, training_loss: 2.83267e-02
I0212 10:28:58.035705 22542570456896 run_lib.py:133] step: 956800, training_loss: 3.14145e-02
I0212 10:28:58.191445 22542570456896 run_lib.py:146] step: 956800, eval_loss: 2.76465e-02
I0212 10:29:15.668063 22542570456896 run_lib.py:133] step: 956850, training_loss: 2.79927e-02
I0212 10:29:33.175302 22542570456896 run_lib.py:133] step: 956900, training_loss: 2.30448e-02
I0212 10:29:33.331030 22542570456896 run_lib.py:146] step: 956900, eval_loss: 3.43773e-02
I0212 10:29:50.824922 22542570456896 run_lib.py:133] step: 956950, training_loss: 3.15176e-02
I0212 10:30:08.522428 22542570456896 run_lib.py:133] step: 957000, training_loss: 2.93763e-02
I0212 10:30:08.683598 22542570456896 run_lib.py:146] step: 957000, eval_loss: 3.24373e-02
I0212 10:30:26.114849 22542570456896 run_lib.py:133] step: 957050, training_loss: 2.53631e-02
I0212 10:30:43.593591 22542570456896 run_lib.py:133] step: 957100, training_loss: 2.80847e-02
I0212 10:30:43.749387 22542570456896 run_lib.py:146] step: 957100, eval_loss: 3.22347e-02
I0212 10:31:01.208519 22542570456896 run_lib.py:133] step: 957150, training_loss: 2.77360e-02
I0212 10:31:18.933822 22542570456896 run_lib.py:133] step: 957200, training_loss: 2.74437e-02
I0212 10:31:19.092718 22542570456896 run_lib.py:146] step: 957200, eval_loss: 2.68691e-02
I0212 10:31:36.569918 22542570456896 run_lib.py:133] step: 957250, training_loss: 3.40051e-02
I0212 10:31:54.082147 22542570456896 run_lib.py:133] step: 957300, training_loss: 2.64006e-02
I0212 10:31:54.235188 22542570456896 run_lib.py:146] step: 957300, eval_loss: 3.16380e-02
I0212 10:32:11.720073 22542570456896 run_lib.py:133] step: 957350, training_loss: 2.34843e-02
I0212 10:32:29.196406 22542570456896 run_lib.py:133] step: 957400, training_loss: 2.21856e-02
I0212 10:32:29.359681 22542570456896 run_lib.py:146] step: 957400, eval_loss: 2.91974e-02
I0212 10:32:47.043744 22542570456896 run_lib.py:133] step: 957450, training_loss: 2.70895e-02
I0212 10:33:04.627227 22542570456896 run_lib.py:133] step: 957500, training_loss: 2.61344e-02
I0212 10:33:04.789585 22542570456896 run_lib.py:146] step: 957500, eval_loss: 2.61003e-02
I0212 10:33:22.256569 22542570456896 run_lib.py:133] step: 957550, training_loss: 2.59115e-02
I0212 10:33:39.700650 22542570456896 run_lib.py:133] step: 957600, training_loss: 3.03494e-02
I0212 10:33:39.857487 22542570456896 run_lib.py:146] step: 957600, eval_loss: 2.51985e-02
I0212 10:33:57.467473 22542570456896 run_lib.py:133] step: 957650, training_loss: 2.50404e-02
I0212 10:34:14.930249 22542570456896 run_lib.py:133] step: 957700, training_loss: 2.75568e-02
I0212 10:34:15.087568 22542570456896 run_lib.py:146] step: 957700, eval_loss: 2.66238e-02
I0212 10:34:32.736495 22542570456896 run_lib.py:133] step: 957750, training_loss: 3.01669e-02
I0212 10:34:50.251508 22542570456896 run_lib.py:133] step: 957800, training_loss: 2.73678e-02
I0212 10:34:50.405219 22542570456896 run_lib.py:146] step: 957800, eval_loss: 3.43660e-02
I0212 10:35:08.049059 22542570456896 run_lib.py:133] step: 957850, training_loss: 2.89265e-02
I0212 10:35:25.505189 22542570456896 run_lib.py:133] step: 957900, training_loss: 2.47897e-02
I0212 10:35:25.662383 22542570456896 run_lib.py:146] step: 957900, eval_loss: 2.11417e-02
I0212 10:35:43.114681 22542570456896 run_lib.py:133] step: 957950, training_loss: 3.18529e-02
I0212 10:36:00.793726 22542570456896 run_lib.py:133] step: 958000, training_loss: 2.45992e-02
I0212 10:36:00.973432 22542570456896 run_lib.py:146] step: 958000, eval_loss: 2.91284e-02
I0212 10:36:18.464294 22542570456896 run_lib.py:133] step: 958050, training_loss: 3.13834e-02
I0212 10:36:36.130956 22542570456896 run_lib.py:133] step: 958100, training_loss: 2.42693e-02
I0212 10:36:36.286498 22542570456896 run_lib.py:146] step: 958100, eval_loss: 3.09595e-02
I0212 10:36:53.667329 22542570456896 run_lib.py:133] step: 958150, training_loss: 3.38367e-02
I0212 10:37:10.995922 22542570456896 run_lib.py:133] step: 958200, training_loss: 2.43744e-02
I0212 10:37:11.157001 22542570456896 run_lib.py:146] step: 958200, eval_loss: 3.00164e-02
I0212 10:37:28.647611 22542570456896 run_lib.py:133] step: 958250, training_loss: 3.01492e-02
I0212 10:37:46.073753 22542570456896 run_lib.py:133] step: 958300, training_loss: 2.53519e-02
I0212 10:37:46.229554 22542570456896 run_lib.py:146] step: 958300, eval_loss: 2.91545e-02
I0212 10:38:03.635155 22542570456896 run_lib.py:133] step: 958350, training_loss: 2.61561e-02
I0212 10:38:21.181016 22542570456896 run_lib.py:133] step: 958400, training_loss: 2.32970e-02
I0212 10:38:21.336294 22542570456896 run_lib.py:146] step: 958400, eval_loss: 3.36003e-02
I0212 10:38:38.708073 22542570456896 run_lib.py:133] step: 958450, training_loss: 2.38812e-02
I0212 10:38:56.072294 22542570456896 run_lib.py:133] step: 958500, training_loss: 2.17528e-02
I0212 10:38:56.235633 22542570456896 run_lib.py:146] step: 958500, eval_loss: 3.59613e-02
I0212 10:39:13.692472 22542570456896 run_lib.py:133] step: 958550, training_loss: 3.07678e-02
I0212 10:39:31.242690 22542570456896 run_lib.py:133] step: 958600, training_loss: 1.79963e-02
I0212 10:39:31.400299 22542570456896 run_lib.py:146] step: 958600, eval_loss: 2.99896e-02
I0212 10:39:48.904432 22542570456896 run_lib.py:133] step: 958650, training_loss: 2.97581e-02
I0212 10:40:06.366976 22542570456896 run_lib.py:133] step: 958700, training_loss: 2.85534e-02
I0212 10:40:06.527189 22542570456896 run_lib.py:146] step: 958700, eval_loss: 2.97339e-02
I0212 10:40:24.245277 22542570456896 run_lib.py:133] step: 958750, training_loss: 2.62481e-02
I0212 10:40:41.799729 22542570456896 run_lib.py:133] step: 958800, training_loss: 2.86736e-02
I0212 10:40:41.954676 22542570456896 run_lib.py:146] step: 958800, eval_loss: 2.57969e-02
I0212 10:40:59.466090 22542570456896 run_lib.py:133] step: 958850, training_loss: 2.57462e-02
I0212 10:41:17.038655 22542570456896 run_lib.py:133] step: 958900, training_loss: 2.73359e-02
I0212 10:41:17.199487 22542570456896 run_lib.py:146] step: 958900, eval_loss: 3.03613e-02
I0212 10:41:34.854494 22542570456896 run_lib.py:133] step: 958950, training_loss: 2.36640e-02
I0212 10:41:52.316670 22542570456896 run_lib.py:133] step: 959000, training_loss: 2.66725e-02
I0212 10:41:52.473494 22542570456896 run_lib.py:146] step: 959000, eval_loss: 3.59383e-02
I0212 10:42:10.073685 22542570456896 run_lib.py:133] step: 959050, training_loss: 2.96188e-02
I0212 10:42:27.508025 22542570456896 run_lib.py:133] step: 959100, training_loss: 3.42140e-02
I0212 10:42:27.676821 22542570456896 run_lib.py:146] step: 959100, eval_loss: 3.12808e-02
I0212 10:42:45.393563 22542570456896 run_lib.py:133] step: 959150, training_loss: 3.42506e-02
I0212 10:43:02.903768 22542570456896 run_lib.py:133] step: 959200, training_loss: 2.85395e-02
I0212 10:43:03.058250 22542570456896 run_lib.py:146] step: 959200, eval_loss: 2.99633e-02
I0212 10:43:20.708922 22542570456896 run_lib.py:133] step: 959250, training_loss: 3.37252e-02
I0212 10:43:38.175735 22542570456896 run_lib.py:133] step: 959300, training_loss: 3.05384e-02
I0212 10:43:38.332483 22542570456896 run_lib.py:146] step: 959300, eval_loss: 3.05349e-02
I0212 10:43:55.791442 22542570456896 run_lib.py:133] step: 959350, training_loss: 2.31922e-02
I0212 10:44:13.435050 22542570456896 run_lib.py:133] step: 959400, training_loss: 2.70028e-02
I0212 10:44:13.620363 22542570456896 run_lib.py:146] step: 959400, eval_loss: 2.42209e-02
I0212 10:44:31.138348 22542570456896 run_lib.py:133] step: 959450, training_loss: 3.27373e-02
I0212 10:44:48.622590 22542570456896 run_lib.py:133] step: 959500, training_loss: 2.70594e-02
I0212 10:44:48.780592 22542570456896 run_lib.py:146] step: 959500, eval_loss: 3.61632e-02
I0212 10:45:06.466438 22542570456896 run_lib.py:133] step: 959550, training_loss: 3.83580e-02
I0212 10:45:23.919740 22542570456896 run_lib.py:133] step: 959600, training_loss: 2.67937e-02
I0212 10:45:24.079196 22542570456896 run_lib.py:146] step: 959600, eval_loss: 2.51957e-02
I0212 10:45:41.704240 22542570456896 run_lib.py:133] step: 959650, training_loss: 2.25865e-02
I0212 10:45:59.211675 22542570456896 run_lib.py:133] step: 959700, training_loss: 2.34268e-02
I0212 10:45:59.366701 22542570456896 run_lib.py:146] step: 959700, eval_loss: 2.72526e-02
I0212 10:46:16.865857 22542570456896 run_lib.py:133] step: 959750, training_loss: 2.57592e-02
I0212 10:46:34.531898 22542570456896 run_lib.py:133] step: 959800, training_loss: 2.83222e-02
I0212 10:46:34.689372 22542570456896 run_lib.py:146] step: 959800, eval_loss: 2.96863e-02
I0212 10:46:52.122299 22542570456896 run_lib.py:133] step: 959850, training_loss: 2.83972e-02
I0212 10:47:09.588763 22542570456896 run_lib.py:133] step: 959900, training_loss: 2.84440e-02
I0212 10:47:09.764662 22542570456896 run_lib.py:146] step: 959900, eval_loss: 2.55431e-02
I0212 10:47:27.274673 22542570456896 run_lib.py:133] step: 959950, training_loss: 2.47460e-02
I0212 10:47:44.979176 22542570456896 run_lib.py:133] step: 960000, training_loss: 2.29144e-02
I0212 10:47:45.710495 22542570456896 run_lib.py:146] step: 960000, eval_loss: 2.83430e-02
I0212 10:48:05.798959 22542570456896 run_lib.py:133] step: 960050, training_loss: 3.41927e-02
I0212 10:48:23.416845 22542570456896 run_lib.py:133] step: 960100, training_loss: 2.93949e-02
I0212 10:48:23.572530 22542570456896 run_lib.py:146] step: 960100, eval_loss: 2.99562e-02
I0212 10:48:41.059677 22542570456896 run_lib.py:133] step: 960150, training_loss: 3.06986e-02
I0212 10:48:58.539522 22542570456896 run_lib.py:133] step: 960200, training_loss: 2.84632e-02
I0212 10:48:58.695559 22542570456896 run_lib.py:146] step: 960200, eval_loss: 2.67365e-02
I0212 10:49:16.200281 22542570456896 run_lib.py:133] step: 960250, training_loss: 2.53217e-02
I0212 10:49:33.858875 22542570456896 run_lib.py:133] step: 960300, training_loss: 2.19383e-02
I0212 10:49:34.012477 22542570456896 run_lib.py:146] step: 960300, eval_loss: 2.60167e-02
I0212 10:49:51.551666 22542570456896 run_lib.py:133] step: 960350, training_loss: 2.91017e-02
I0212 10:50:09.028097 22542570456896 run_lib.py:133] step: 960400, training_loss: 2.84657e-02
I0212 10:50:09.187735 22542570456896 run_lib.py:146] step: 960400, eval_loss: 3.41089e-02
I0212 10:50:26.642244 22542570456896 run_lib.py:133] step: 960450, training_loss: 2.27644e-02
I0212 10:50:44.114868 22542570456896 run_lib.py:133] step: 960500, training_loss: 2.40266e-02
I0212 10:50:44.284705 22542570456896 run_lib.py:146] step: 960500, eval_loss: 2.93983e-02
I0212 10:51:01.962935 22542570456896 run_lib.py:133] step: 960550, training_loss: 2.61435e-02
I0212 10:51:19.511684 22542570456896 run_lib.py:133] step: 960600, training_loss: 2.59946e-02
I0212 10:51:19.673248 22542570456896 run_lib.py:146] step: 960600, eval_loss: 3.58177e-02
I0212 10:51:37.165541 22542570456896 run_lib.py:133] step: 960650, training_loss: 3.13285e-02
I0212 10:51:54.638975 22542570456896 run_lib.py:133] step: 960700, training_loss: 2.66496e-02
I0212 10:51:54.796236 22542570456896 run_lib.py:146] step: 960700, eval_loss: 2.05243e-02
I0212 10:52:12.427009 22542570456896 run_lib.py:133] step: 960750, training_loss: 2.93682e-02
I0212 10:52:29.912438 22542570456896 run_lib.py:133] step: 960800, training_loss: 2.28412e-02
I0212 10:52:30.071644 22542570456896 run_lib.py:146] step: 960800, eval_loss: 2.90548e-02
I0212 10:52:47.761619 22542570456896 run_lib.py:133] step: 960850, training_loss: 2.33334e-02
I0212 10:53:05.247709 22542570456896 run_lib.py:133] step: 960900, training_loss: 2.57601e-02
I0212 10:53:05.406116 22542570456896 run_lib.py:146] step: 960900, eval_loss: 2.73743e-02
I0212 10:53:23.014604 22542570456896 run_lib.py:133] step: 960950, training_loss: 2.67811e-02
I0212 10:53:40.485811 22542570456896 run_lib.py:133] step: 961000, training_loss: 2.26033e-02
I0212 10:53:40.654453 22542570456896 run_lib.py:146] step: 961000, eval_loss: 3.42671e-02
I0212 10:53:58.157816 22542570456896 run_lib.py:133] step: 961050, training_loss: 2.73086e-02
I0212 10:54:15.862089 22542570456896 run_lib.py:133] step: 961100, training_loss: 2.87302e-02
I0212 10:54:16.018463 22542570456896 run_lib.py:146] step: 961100, eval_loss: 2.51535e-02
I0212 10:54:33.512588 22542570456896 run_lib.py:133] step: 961150, training_loss: 2.87239e-02
I0212 10:54:51.113895 22542570456896 run_lib.py:133] step: 961200, training_loss: 3.20612e-02
I0212 10:54:51.267440 22542570456896 run_lib.py:146] step: 961200, eval_loss: 2.58295e-02
I0212 10:55:08.714558 22542570456896 run_lib.py:133] step: 961250, training_loss: 3.20493e-02
I0212 10:55:26.211477 22542570456896 run_lib.py:133] step: 961300, training_loss: 3.03604e-02
I0212 10:55:26.379620 22542570456896 run_lib.py:146] step: 961300, eval_loss: 2.61403e-02
I0212 10:55:44.100023 22542570456896 run_lib.py:133] step: 961350, training_loss: 2.46586e-02
I0212 10:56:01.637206 22542570456896 run_lib.py:133] step: 961400, training_loss: 3.16068e-02
I0212 10:56:01.797341 22542570456896 run_lib.py:146] step: 961400, eval_loss: 2.94653e-02
I0212 10:56:19.232597 22542570456896 run_lib.py:133] step: 961450, training_loss: 2.54052e-02
I0212 10:56:36.887089 22542570456896 run_lib.py:133] step: 961500, training_loss: 2.65681e-02
I0212 10:56:37.045491 22542570456896 run_lib.py:146] step: 961500, eval_loss: 2.97347e-02
I0212 10:56:54.529924 22542570456896 run_lib.py:133] step: 961550, training_loss: 2.93377e-02
I0212 10:57:12.032278 22542570456896 run_lib.py:133] step: 961600, training_loss: 2.40045e-02
I0212 10:57:12.344112 22542570456896 run_lib.py:146] step: 961600, eval_loss: 3.40081e-02
I0212 10:57:29.859606 22542570456896 run_lib.py:133] step: 961650, training_loss: 2.21829e-02
I0212 10:57:47.317064 22542570456896 run_lib.py:133] step: 961700, training_loss: 2.77348e-02
I0212 10:57:47.474362 22542570456896 run_lib.py:146] step: 961700, eval_loss: 2.59535e-02
I0212 10:58:04.923894 22542570456896 run_lib.py:133] step: 961750, training_loss: 2.52394e-02
I0212 10:58:22.379153 22542570456896 run_lib.py:133] step: 961800, training_loss: 2.68463e-02
I0212 10:58:22.536405 22542570456896 run_lib.py:146] step: 961800, eval_loss: 2.35601e-02
I0212 10:58:40.169074 22542570456896 run_lib.py:133] step: 961850, training_loss: 2.53428e-02
I0212 10:58:57.757442 22542570456896 run_lib.py:133] step: 961900, training_loss: 3.13512e-02
I0212 10:58:57.935410 22542570456896 run_lib.py:146] step: 961900, eval_loss: 3.04445e-02
I0212 10:59:15.435418 22542570456896 run_lib.py:133] step: 961950, training_loss: 3.02694e-02
I0212 10:59:32.916002 22542570456896 run_lib.py:133] step: 962000, training_loss: 2.76765e-02
I0212 10:59:33.079242 22542570456896 run_lib.py:146] step: 962000, eval_loss: 2.44228e-02
I0212 10:59:50.762307 22542570456896 run_lib.py:133] step: 962050, training_loss: 2.97327e-02
I0212 11:00:08.304928 22542570456896 run_lib.py:133] step: 962100, training_loss: 2.44392e-02
I0212 11:00:08.460969 22542570456896 run_lib.py:146] step: 962100, eval_loss: 2.46622e-02
I0212 11:00:25.943542 22542570456896 run_lib.py:133] step: 962150, training_loss: 2.92853e-02
I0212 11:00:43.501765 22542570456896 run_lib.py:133] step: 962200, training_loss: 2.89451e-02
I0212 11:00:43.663656 22542570456896 run_lib.py:146] step: 962200, eval_loss: 2.91374e-02
I0212 11:01:01.361914 22542570456896 run_lib.py:133] step: 962250, training_loss: 3.19044e-02
I0212 11:01:18.870511 22542570456896 run_lib.py:133] step: 962300, training_loss: 2.50710e-02
I0212 11:01:19.035661 22542570456896 run_lib.py:146] step: 962300, eval_loss: 2.81765e-02
I0212 11:01:36.621105 22542570456896 run_lib.py:133] step: 962350, training_loss: 2.85338e-02
I0212 11:01:54.113280 22542570456896 run_lib.py:133] step: 962400, training_loss: 2.18303e-02
I0212 11:01:54.270393 22542570456896 run_lib.py:146] step: 962400, eval_loss: 2.52279e-02
I0212 11:02:11.915827 22542570456896 run_lib.py:133] step: 962450, training_loss: 2.85352e-02
I0212 11:02:29.449485 22542570456896 run_lib.py:133] step: 962500, training_loss: 2.57874e-02
I0212 11:02:29.615801 22542570456896 run_lib.py:146] step: 962500, eval_loss: 3.50195e-02
I0212 11:02:47.119580 22542570456896 run_lib.py:133] step: 962550, training_loss: 2.80419e-02
I0212 11:03:04.757651 22542570456896 run_lib.py:133] step: 962600, training_loss: 2.29393e-02
I0212 11:03:04.911191 22542570456896 run_lib.py:146] step: 962600, eval_loss: 2.72140e-02
I0212 11:03:22.387280 22542570456896 run_lib.py:133] step: 962650, training_loss: 2.15337e-02
I0212 11:03:39.992767 22542570456896 run_lib.py:133] step: 962700, training_loss: 2.56699e-02
I0212 11:03:40.148522 22542570456896 run_lib.py:146] step: 962700, eval_loss: 2.71124e-02
I0212 11:03:57.656146 22542570456896 run_lib.py:133] step: 962750, training_loss: 2.71385e-02
I0212 11:04:15.161564 22542570456896 run_lib.py:133] step: 962800, training_loss: 3.07508e-02
I0212 11:04:15.328460 22542570456896 run_lib.py:146] step: 962800, eval_loss: 2.84217e-02
I0212 11:04:33.047714 22542570456896 run_lib.py:133] step: 962850, training_loss: 3.42940e-02
I0212 11:04:50.513121 22542570456896 run_lib.py:133] step: 962900, training_loss: 3.24275e-02
I0212 11:04:50.669476 22542570456896 run_lib.py:146] step: 962900, eval_loss: 2.69673e-02
I0212 11:05:08.115620 22542570456896 run_lib.py:133] step: 962950, training_loss: 2.48268e-02
I0212 11:05:25.568648 22542570456896 run_lib.py:133] step: 963000, training_loss: 3.29920e-02
I0212 11:05:25.725374 22542570456896 run_lib.py:146] step: 963000, eval_loss: 3.53075e-02
I0212 11:05:43.381230 22542570456896 run_lib.py:133] step: 963050, training_loss: 2.17348e-02
I0212 11:06:00.889059 22542570456896 run_lib.py:133] step: 963100, training_loss: 3.13174e-02
I0212 11:06:01.047638 22542570456896 run_lib.py:146] step: 963100, eval_loss: 2.84444e-02
I0212 11:06:18.662241 22542570456896 run_lib.py:133] step: 963150, training_loss: 2.42062e-02
I0212 11:06:36.158106 22542570456896 run_lib.py:133] step: 963200, training_loss: 3.26963e-02
I0212 11:06:36.316478 22542570456896 run_lib.py:146] step: 963200, eval_loss: 3.07860e-02
I0212 11:06:53.774811 22542570456896 run_lib.py:133] step: 963250, training_loss: 2.78927e-02
I0212 11:07:11.250024 22542570456896 run_lib.py:133] step: 963300, training_loss: 3.83987e-02
I0212 11:07:11.416409 22542570456896 run_lib.py:146] step: 963300, eval_loss: 3.61335e-02
I0212 11:07:28.943705 22542570456896 run_lib.py:133] step: 963350, training_loss: 2.59481e-02
I0212 11:07:46.439970 22542570456896 run_lib.py:133] step: 963400, training_loss: 3.10242e-02
I0212 11:07:46.595683 22542570456896 run_lib.py:146] step: 963400, eval_loss: 3.09277e-02
I0212 11:08:04.008878 22542570456896 run_lib.py:133] step: 963450, training_loss: 2.85280e-02
I0212 11:08:21.323476 22542570456896 run_lib.py:133] step: 963500, training_loss: 2.64349e-02
I0212 11:08:21.477291 22542570456896 run_lib.py:146] step: 963500, eval_loss: 3.60509e-02
I0212 11:08:38.977779 22542570456896 run_lib.py:133] step: 963550, training_loss: 2.15131e-02
I0212 11:08:56.371023 22542570456896 run_lib.py:133] step: 963600, training_loss: 2.72520e-02
I0212 11:08:56.524552 22542570456896 run_lib.py:146] step: 963600, eval_loss: 3.26547e-02
I0212 11:09:14.114264 22542570456896 run_lib.py:133] step: 963650, training_loss: 2.50830e-02
I0212 11:09:31.481117 22542570456896 run_lib.py:133] step: 963700, training_loss: 2.67734e-02
I0212 11:09:31.638375 22542570456896 run_lib.py:146] step: 963700, eval_loss: 2.85783e-02
I0212 11:09:49.210593 22542570456896 run_lib.py:133] step: 963750, training_loss: 2.51685e-02
I0212 11:10:06.668886 22542570456896 run_lib.py:133] step: 963800, training_loss: 2.55183e-02
I0212 11:10:06.826682 22542570456896 run_lib.py:146] step: 963800, eval_loss: 2.78973e-02
I0212 11:10:24.468956 22542570456896 run_lib.py:133] step: 963850, training_loss: 2.95519e-02
I0212 11:10:41.925982 22542570456896 run_lib.py:133] step: 963900, training_loss: 2.53200e-02
I0212 11:10:42.091497 22542570456896 run_lib.py:146] step: 963900, eval_loss: 2.46311e-02
I0212 11:10:59.567628 22542570456896 run_lib.py:133] step: 963950, training_loss: 2.54700e-02
I0212 11:11:17.257149 22542570456896 run_lib.py:133] step: 964000, training_loss: 2.49116e-02
I0212 11:11:17.414187 22542570456896 run_lib.py:146] step: 964000, eval_loss: 3.16239e-02
I0212 11:11:34.903707 22542570456896 run_lib.py:133] step: 964050, training_loss: 2.19466e-02
I0212 11:11:52.374956 22542570456896 run_lib.py:133] step: 964100, training_loss: 2.35512e-02
I0212 11:11:52.527406 22542570456896 run_lib.py:146] step: 964100, eval_loss: 2.59463e-02
I0212 11:12:10.154665 22542570456896 run_lib.py:133] step: 964150, training_loss: 2.81151e-02
I0212 11:12:27.760164 22542570456896 run_lib.py:133] step: 964200, training_loss: 2.99289e-02
I0212 11:12:27.933961 22542570456896 run_lib.py:146] step: 964200, eval_loss: 2.49327e-02
I0212 11:12:45.426914 22542570456896 run_lib.py:133] step: 964250, training_loss: 2.97382e-02
I0212 11:13:02.918895 22542570456896 run_lib.py:133] step: 964300, training_loss: 2.68959e-02
I0212 11:13:03.076682 22542570456896 run_lib.py:146] step: 964300, eval_loss: 3.54419e-02
I0212 11:13:20.555264 22542570456896 run_lib.py:133] step: 964350, training_loss: 2.64464e-02
I0212 11:13:38.186049 22542570456896 run_lib.py:133] step: 964400, training_loss: 2.54084e-02
I0212 11:13:38.344266 22542570456896 run_lib.py:146] step: 964400, eval_loss: 2.88827e-02
I0212 11:13:55.795174 22542570456896 run_lib.py:133] step: 964450, training_loss: 2.91102e-02
I0212 11:14:13.260386 22542570456896 run_lib.py:133] step: 964500, training_loss: 2.48728e-02
I0212 11:14:13.420335 22542570456896 run_lib.py:146] step: 964500, eval_loss: 3.10567e-02
I0212 11:14:30.926981 22542570456896 run_lib.py:133] step: 964550, training_loss: 3.11667e-02
I0212 11:14:48.632903 22542570456896 run_lib.py:133] step: 964600, training_loss: 2.53534e-02
I0212 11:14:48.790709 22542570456896 run_lib.py:146] step: 964600, eval_loss: 2.83035e-02
I0212 11:15:06.260873 22542570456896 run_lib.py:133] step: 964650, training_loss: 2.77713e-02
I0212 11:15:23.798546 22542570456896 run_lib.py:133] step: 964700, training_loss: 2.59391e-02
I0212 11:15:23.956630 22542570456896 run_lib.py:146] step: 964700, eval_loss: 3.38744e-02
I0212 11:15:41.408154 22542570456896 run_lib.py:133] step: 964750, training_loss: 1.81338e-02
I0212 11:15:58.884829 22542570456896 run_lib.py:133] step: 964800, training_loss: 2.65227e-02
I0212 11:15:59.050021 22542570456896 run_lib.py:146] step: 964800, eval_loss: 3.00284e-02
I0212 11:16:16.703282 22542570456896 run_lib.py:133] step: 964850, training_loss: 2.93633e-02
I0212 11:16:34.294877 22542570456896 run_lib.py:133] step: 964900, training_loss: 3.07562e-02
I0212 11:16:34.451667 22542570456896 run_lib.py:146] step: 964900, eval_loss: 2.63244e-02
I0212 11:16:51.953053 22542570456896 run_lib.py:133] step: 964950, training_loss: 2.68331e-02
I0212 11:17:09.416910 22542570456896 run_lib.py:133] step: 965000, training_loss: 2.67799e-02
I0212 11:17:09.569386 22542570456896 run_lib.py:146] step: 965000, eval_loss: 3.03313e-02
I0212 11:17:27.183289 22542570456896 run_lib.py:133] step: 965050, training_loss: 2.33099e-02
I0212 11:17:44.649463 22542570456896 run_lib.py:133] step: 965100, training_loss: 2.45602e-02
I0212 11:17:44.825605 22542570456896 run_lib.py:146] step: 965100, eval_loss: 3.36369e-02
I0212 11:18:02.485465 22542570456896 run_lib.py:133] step: 965150, training_loss: 2.48196e-02
I0212 11:18:19.979949 22542570456896 run_lib.py:133] step: 965200, training_loss: 2.48441e-02
I0212 11:18:20.140406 22542570456896 run_lib.py:146] step: 965200, eval_loss: 2.76296e-02
I0212 11:18:37.773316 22542570456896 run_lib.py:133] step: 965250, training_loss: 3.47541e-02
I0212 11:18:55.244585 22542570456896 run_lib.py:133] step: 965300, training_loss: 2.40669e-02
I0212 11:18:55.402365 22542570456896 run_lib.py:146] step: 965300, eval_loss: 2.77900e-02
I0212 11:19:12.881824 22542570456896 run_lib.py:133] step: 965350, training_loss: 2.73794e-02
I0212 11:19:30.580966 22542570456896 run_lib.py:133] step: 965400, training_loss: 2.86077e-02
I0212 11:19:30.738667 22542570456896 run_lib.py:146] step: 965400, eval_loss: 2.69113e-02
I0212 11:19:48.247613 22542570456896 run_lib.py:133] step: 965450, training_loss: 2.69593e-02
I0212 11:20:05.940815 22542570456896 run_lib.py:133] step: 965500, training_loss: 3.17648e-02
I0212 11:20:06.096812 22542570456896 run_lib.py:146] step: 965500, eval_loss: 2.82150e-02
I0212 11:20:23.562797 22542570456896 run_lib.py:133] step: 965550, training_loss: 2.96563e-02
I0212 11:20:41.048606 22542570456896 run_lib.py:133] step: 965600, training_loss: 2.96899e-02
I0212 11:20:41.209641 22542570456896 run_lib.py:146] step: 965600, eval_loss: 3.20735e-02
I0212 11:20:58.844086 22542570456896 run_lib.py:133] step: 965650, training_loss: 2.66210e-02
I0212 11:21:16.384718 22542570456896 run_lib.py:133] step: 965700, training_loss: 2.55134e-02
I0212 11:21:16.544595 22542570456896 run_lib.py:146] step: 965700, eval_loss: 3.89488e-02
I0212 11:21:34.022143 22542570456896 run_lib.py:133] step: 965750, training_loss: 3.22694e-02
I0212 11:21:51.710567 22542570456896 run_lib.py:133] step: 965800, training_loss: 3.39475e-02
I0212 11:21:51.868197 22542570456896 run_lib.py:146] step: 965800, eval_loss: 2.79216e-02
I0212 11:22:09.343161 22542570456896 run_lib.py:133] step: 965850, training_loss: 2.96067e-02
I0212 11:22:26.794378 22542570456896 run_lib.py:133] step: 965900, training_loss: 2.97349e-02
I0212 11:22:26.954230 22542570456896 run_lib.py:146] step: 965900, eval_loss: 3.01775e-02
I0212 11:22:44.591140 22542570456896 run_lib.py:133] step: 965950, training_loss: 2.90760e-02
I0212 11:23:02.087121 22542570456896 run_lib.py:133] step: 966000, training_loss: 3.21776e-02
I0212 11:23:02.241692 22542570456896 run_lib.py:146] step: 966000, eval_loss: 3.14250e-02
I0212 11:23:19.670488 22542570456896 run_lib.py:133] step: 966050, training_loss: 2.73480e-02
I0212 11:23:37.139011 22542570456896 run_lib.py:133] step: 966100, training_loss: 2.53260e-02
I0212 11:23:37.300817 22542570456896 run_lib.py:146] step: 966100, eval_loss: 3.06186e-02
I0212 11:23:54.934785 22542570456896 run_lib.py:133] step: 966150, training_loss: 2.95683e-02
I0212 11:24:12.554345 22542570456896 run_lib.py:133] step: 966200, training_loss: 3.29070e-02
I0212 11:24:12.721544 22542570456896 run_lib.py:146] step: 966200, eval_loss: 3.10827e-02
I0212 11:24:30.206604 22542570456896 run_lib.py:133] step: 966250, training_loss: 2.34307e-02
I0212 11:24:47.662531 22542570456896 run_lib.py:133] step: 966300, training_loss: 2.56862e-02
I0212 11:24:47.821750 22542570456896 run_lib.py:146] step: 966300, eval_loss: 3.07620e-02
I0212 11:25:05.492316 22542570456896 run_lib.py:133] step: 966350, training_loss: 2.44963e-02
I0212 11:25:22.944550 22542570456896 run_lib.py:133] step: 966400, training_loss: 2.42773e-02
I0212 11:25:23.097097 22542570456896 run_lib.py:146] step: 966400, eval_loss: 2.95874e-02
I0212 11:25:40.727454 22542570456896 run_lib.py:133] step: 966450, training_loss: 3.35582e-02
I0212 11:25:58.217525 22542570456896 run_lib.py:133] step: 966500, training_loss: 2.89495e-02
I0212 11:25:58.387698 22542570456896 run_lib.py:146] step: 966500, eval_loss: 2.76493e-02
I0212 11:26:16.113660 22542570456896 run_lib.py:133] step: 966550, training_loss: 3.13740e-02
I0212 11:26:33.654072 22542570456896 run_lib.py:133] step: 966600, training_loss: 2.52909e-02
I0212 11:26:33.813612 22542570456896 run_lib.py:146] step: 966600, eval_loss: 3.06344e-02
I0212 11:26:51.427445 22542570456896 run_lib.py:133] step: 966650, training_loss: 2.34709e-02
I0212 11:27:08.896106 22542570456896 run_lib.py:133] step: 966700, training_loss: 2.41993e-02
I0212 11:27:09.053436 22542570456896 run_lib.py:146] step: 966700, eval_loss: 3.06932e-02
I0212 11:27:26.508803 22542570456896 run_lib.py:133] step: 966750, training_loss: 2.70276e-02
I0212 11:27:44.157259 22542570456896 run_lib.py:133] step: 966800, training_loss: 3.05643e-02
I0212 11:27:44.321639 22542570456896 run_lib.py:146] step: 966800, eval_loss: 2.86884e-02
I0212 11:28:01.840179 22542570456896 run_lib.py:133] step: 966850, training_loss: 3.07244e-02
I0212 11:28:19.286327 22542570456896 run_lib.py:133] step: 966900, training_loss: 2.42569e-02
I0212 11:28:19.447432 22542570456896 run_lib.py:146] step: 966900, eval_loss: 3.16843e-02
I0212 11:28:37.118293 22542570456896 run_lib.py:133] step: 966950, training_loss: 2.73303e-02
I0212 11:28:54.569468 22542570456896 run_lib.py:133] step: 967000, training_loss: 2.87323e-02
I0212 11:28:54.726442 22542570456896 run_lib.py:146] step: 967000, eval_loss: 2.63472e-02
I0212 11:29:12.333197 22542570456896 run_lib.py:133] step: 967050, training_loss: 2.60432e-02
I0212 11:29:29.867166 22542570456896 run_lib.py:133] step: 967100, training_loss: 2.40983e-02
I0212 11:29:30.027449 22542570456896 run_lib.py:146] step: 967100, eval_loss: 2.86412e-02
I0212 11:29:47.526739 22542570456896 run_lib.py:133] step: 967150, training_loss: 2.39601e-02
I0212 11:30:05.178480 22542570456896 run_lib.py:133] step: 967200, training_loss: 2.21963e-02
I0212 11:30:05.336403 22542570456896 run_lib.py:146] step: 967200, eval_loss: 2.83966e-02
I0212 11:30:22.816504 22542570456896 run_lib.py:133] step: 967250, training_loss: 2.40955e-02
I0212 11:30:40.314643 22542570456896 run_lib.py:133] step: 967300, training_loss: 2.77044e-02
I0212 11:30:40.472680 22542570456896 run_lib.py:146] step: 967300, eval_loss: 2.31844e-02
I0212 11:30:57.986470 22542570456896 run_lib.py:133] step: 967350, training_loss: 2.19488e-02
I0212 11:31:15.627470 22542570456896 run_lib.py:133] step: 967400, training_loss: 2.24078e-02
I0212 11:31:15.781468 22542570456896 run_lib.py:146] step: 967400, eval_loss: 2.43843e-02
I0212 11:31:33.231935 22542570456896 run_lib.py:133] step: 967450, training_loss: 2.54730e-02
I0212 11:31:50.775246 22542570456896 run_lib.py:133] step: 967500, training_loss: 3.65079e-02
I0212 11:31:50.935820 22542570456896 run_lib.py:146] step: 967500, eval_loss: 2.76357e-02
I0212 11:32:08.383141 22542570456896 run_lib.py:133] step: 967550, training_loss: 3.02799e-02
I0212 11:32:25.842166 22542570456896 run_lib.py:133] step: 967600, training_loss: 2.57973e-02
I0212 11:32:26.015522 22542570456896 run_lib.py:146] step: 967600, eval_loss: 3.17334e-02
I0212 11:32:43.698567 22542570456896 run_lib.py:133] step: 967650, training_loss: 3.05650e-02
I0212 11:33:01.336740 22542570456896 run_lib.py:133] step: 967700, training_loss: 2.51656e-02
I0212 11:33:01.493244 22542570456896 run_lib.py:146] step: 967700, eval_loss: 2.44876e-02
I0212 11:33:19.000931 22542570456896 run_lib.py:133] step: 967750, training_loss: 2.68132e-02
I0212 11:33:36.471518 22542570456896 run_lib.py:133] step: 967800, training_loss: 3.25362e-02
I0212 11:33:36.624651 22542570456896 run_lib.py:146] step: 967800, eval_loss: 2.79368e-02
I0212 11:33:54.256088 22542570456896 run_lib.py:133] step: 967850, training_loss: 2.72964e-02
I0212 11:34:11.711473 22542570456896 run_lib.py:133] step: 967900, training_loss: 2.76875e-02
I0212 11:34:11.869636 22542570456896 run_lib.py:146] step: 967900, eval_loss: 2.98266e-02
I0212 11:34:29.576630 22542570456896 run_lib.py:133] step: 967950, training_loss: 2.89403e-02
I0212 11:34:47.060204 22542570456896 run_lib.py:133] step: 968000, training_loss: 2.67654e-02
I0212 11:34:47.225561 22542570456896 run_lib.py:146] step: 968000, eval_loss: 3.11322e-02
I0212 11:35:04.825617 22542570456896 run_lib.py:133] step: 968050, training_loss: 2.70715e-02
I0212 11:35:22.260263 22542570456896 run_lib.py:133] step: 968100, training_loss: 3.03558e-02
I0212 11:35:22.416398 22542570456896 run_lib.py:146] step: 968100, eval_loss: 2.57796e-02
I0212 11:35:39.890162 22542570456896 run_lib.py:133] step: 968150, training_loss: 2.33375e-02
I0212 11:35:57.563865 22542570456896 run_lib.py:133] step: 968200, training_loss: 2.70604e-02
I0212 11:35:57.724336 22542570456896 run_lib.py:146] step: 968200, eval_loss: 3.39368e-02
I0212 11:36:15.199210 22542570456896 run_lib.py:133] step: 968250, training_loss: 2.94122e-02
I0212 11:36:32.840027 22542570456896 run_lib.py:133] step: 968300, training_loss: 2.52914e-02
I0212 11:36:32.994489 22542570456896 run_lib.py:146] step: 968300, eval_loss: 2.37045e-02
I0212 11:36:50.449853 22542570456896 run_lib.py:133] step: 968350, training_loss: 3.07868e-02
I0212 11:37:07.911649 22542570456896 run_lib.py:133] step: 968400, training_loss: 3.33705e-02
I0212 11:37:08.077618 22542570456896 run_lib.py:146] step: 968400, eval_loss: 2.79815e-02
I0212 11:37:25.761715 22542570456896 run_lib.py:133] step: 968450, training_loss: 3.03351e-02
I0212 11:37:43.232458 22542570456896 run_lib.py:133] step: 968500, training_loss: 3.06209e-02
I0212 11:37:43.391355 22542570456896 run_lib.py:146] step: 968500, eval_loss: 3.01050e-02
I0212 11:38:00.743093 22542570456896 run_lib.py:133] step: 968550, training_loss: 2.70462e-02
I0212 11:38:18.260665 22542570456896 run_lib.py:133] step: 968600, training_loss: 2.92763e-02
I0212 11:38:18.416285 22542570456896 run_lib.py:146] step: 968600, eval_loss: 2.95535e-02
I0212 11:38:35.790531 22542570456896 run_lib.py:133] step: 968650, training_loss: 2.28425e-02
I0212 11:38:53.155942 22542570456896 run_lib.py:133] step: 968700, training_loss: 3.20434e-02
I0212 11:38:53.454520 22542570456896 run_lib.py:146] step: 968700, eval_loss: 3.02419e-02
I0212 11:39:10.898485 22542570456896 run_lib.py:133] step: 968750, training_loss: 2.68221e-02
I0212 11:39:28.319026 22542570456896 run_lib.py:133] step: 968800, training_loss: 2.70859e-02
I0212 11:39:28.470575 22542570456896 run_lib.py:146] step: 968800, eval_loss: 2.93575e-02
I0212 11:39:45.854171 22542570456896 run_lib.py:133] step: 968850, training_loss: 2.74849e-02
I0212 11:40:03.224366 22542570456896 run_lib.py:133] step: 968900, training_loss: 2.38172e-02
I0212 11:40:03.378259 22542570456896 run_lib.py:146] step: 968900, eval_loss: 2.95726e-02
I0212 11:40:20.988754 22542570456896 run_lib.py:133] step: 968950, training_loss: 2.47140e-02
I0212 11:40:38.576547 22542570456896 run_lib.py:133] step: 969000, training_loss: 3.69867e-02
I0212 11:40:38.743431 22542570456896 run_lib.py:146] step: 969000, eval_loss: 2.43892e-02
I0212 11:40:56.230682 22542570456896 run_lib.py:133] step: 969050, training_loss: 3.20829e-02
I0212 11:41:13.731495 22542570456896 run_lib.py:133] step: 969100, training_loss: 1.99446e-02
I0212 11:41:13.888609 22542570456896 run_lib.py:146] step: 969100, eval_loss: 3.34562e-02
I0212 11:41:31.552501 22542570456896 run_lib.py:133] step: 969150, training_loss: 3.10112e-02
I0212 11:41:49.095426 22542570456896 run_lib.py:133] step: 969200, training_loss: 2.85846e-02
I0212 11:41:49.253517 22542570456896 run_lib.py:146] step: 969200, eval_loss: 3.15450e-02
I0212 11:42:06.747395 22542570456896 run_lib.py:133] step: 969250, training_loss: 2.33867e-02
I0212 11:42:24.262239 22542570456896 run_lib.py:133] step: 969300, training_loss: 2.60572e-02
I0212 11:42:24.426392 22542570456896 run_lib.py:146] step: 969300, eval_loss: 2.62567e-02
I0212 11:42:42.058146 22542570456896 run_lib.py:133] step: 969350, training_loss: 2.51326e-02
I0212 11:42:59.535838 22542570456896 run_lib.py:133] step: 969400, training_loss: 2.83765e-02
I0212 11:42:59.694282 22542570456896 run_lib.py:146] step: 969400, eval_loss: 3.32521e-02
I0212 11:43:17.266369 22542570456896 run_lib.py:133] step: 969450, training_loss: 2.78718e-02
I0212 11:43:34.726203 22542570456896 run_lib.py:133] step: 969500, training_loss: 2.61870e-02
I0212 11:43:34.897391 22542570456896 run_lib.py:146] step: 969500, eval_loss: 2.98199e-02
I0212 11:43:52.619817 22542570456896 run_lib.py:133] step: 969550, training_loss: 2.68595e-02
I0212 11:44:10.137921 22542570456896 run_lib.py:133] step: 969600, training_loss: 2.58344e-02
I0212 11:44:10.293800 22542570456896 run_lib.py:146] step: 969600, eval_loss: 2.82073e-02
I0212 11:44:27.778276 22542570456896 run_lib.py:133] step: 969650, training_loss: 2.71102e-02
I0212 11:44:45.364757 22542570456896 run_lib.py:133] step: 969700, training_loss: 3.07278e-02
I0212 11:44:45.518131 22542570456896 run_lib.py:146] step: 969700, eval_loss: 2.26613e-02
I0212 11:45:02.970930 22542570456896 run_lib.py:133] step: 969750, training_loss: 2.67736e-02
I0212 11:45:20.615892 22542570456896 run_lib.py:133] step: 969800, training_loss: 2.28357e-02
I0212 11:45:20.780763 22542570456896 run_lib.py:146] step: 969800, eval_loss: 3.20204e-02
I0212 11:45:38.276267 22542570456896 run_lib.py:133] step: 969850, training_loss: 3.01187e-02
I0212 11:45:55.800029 22542570456896 run_lib.py:133] step: 969900, training_loss: 2.55634e-02
I0212 11:45:55.959742 22542570456896 run_lib.py:146] step: 969900, eval_loss: 2.56350e-02
I0212 11:46:13.633746 22542570456896 run_lib.py:133] step: 969950, training_loss: 2.76149e-02
I0212 11:46:31.126168 22542570456896 run_lib.py:133] step: 970000, training_loss: 2.88650e-02
I0212 11:46:31.871304 22542570456896 run_lib.py:146] step: 970000, eval_loss: 3.01601e-02
I0212 11:46:52.157232 22542570456896 run_lib.py:133] step: 970050, training_loss: 2.94531e-02
I0212 11:47:09.818666 22542570456896 run_lib.py:133] step: 970100, training_loss: 2.29484e-02
I0212 11:47:09.977944 22542570456896 run_lib.py:146] step: 970100, eval_loss: 2.99230e-02
I0212 11:47:27.432495 22542570456896 run_lib.py:133] step: 970150, training_loss: 3.41772e-02
I0212 11:47:44.857972 22542570456896 run_lib.py:133] step: 970200, training_loss: 2.79174e-02
I0212 11:47:45.015461 22542570456896 run_lib.py:146] step: 970200, eval_loss: 3.06145e-02
I0212 11:48:02.622445 22542570456896 run_lib.py:133] step: 970250, training_loss: 2.69725e-02
I0212 11:48:20.241475 22542570456896 run_lib.py:133] step: 970300, training_loss: 2.59794e-02
I0212 11:48:20.395653 22542570456896 run_lib.py:146] step: 970300, eval_loss: 3.33925e-02
I0212 11:48:37.904221 22542570456896 run_lib.py:133] step: 970350, training_loss: 2.42733e-02
I0212 11:48:55.349046 22542570456896 run_lib.py:133] step: 970400, training_loss: 2.11756e-02
I0212 11:48:55.513403 22542570456896 run_lib.py:146] step: 970400, eval_loss: 2.68202e-02
I0212 11:49:13.161514 22542570456896 run_lib.py:133] step: 970450, training_loss: 2.36416e-02
I0212 11:49:30.647977 22542570456896 run_lib.py:133] step: 970500, training_loss: 2.65889e-02
I0212 11:49:30.816809 22542570456896 run_lib.py:146] step: 970500, eval_loss: 2.91984e-02
I0212 11:49:48.455111 22542570456896 run_lib.py:133] step: 970550, training_loss: 2.94230e-02
I0212 11:50:05.981476 22542570456896 run_lib.py:133] step: 970600, training_loss: 2.64751e-02
I0212 11:50:06.143185 22542570456896 run_lib.py:146] step: 970600, eval_loss: 3.09938e-02
I0212 11:50:23.834493 22542570456896 run_lib.py:133] step: 970650, training_loss: 2.71189e-02
I0212 11:50:41.292200 22542570456896 run_lib.py:133] step: 970700, training_loss: 2.61450e-02
I0212 11:50:41.448367 22542570456896 run_lib.py:146] step: 970700, eval_loss: 3.42422e-02
I0212 11:50:58.940589 22542570456896 run_lib.py:133] step: 970750, training_loss: 3.13542e-02
I0212 11:51:16.576279 22542570456896 run_lib.py:133] step: 970800, training_loss: 2.91673e-02
I0212 11:51:16.730399 22542570456896 run_lib.py:146] step: 970800, eval_loss: 2.78577e-02
I0212 11:51:34.178278 22542570456896 run_lib.py:133] step: 970850, training_loss: 3.03099e-02
I0212 11:51:51.843451 22542570456896 run_lib.py:133] step: 970900, training_loss: 2.89391e-02
I0212 11:51:52.022440 22542570456896 run_lib.py:146] step: 970900, eval_loss: 3.37863e-02
I0212 11:52:09.515632 22542570456896 run_lib.py:133] step: 970950, training_loss: 2.11705e-02
I0212 11:52:26.999325 22542570456896 run_lib.py:133] step: 971000, training_loss: 2.88308e-02
I0212 11:52:27.156695 22542570456896 run_lib.py:146] step: 971000, eval_loss: 3.11589e-02
I0212 11:52:44.818100 22542570456896 run_lib.py:133] step: 971050, training_loss: 2.80795e-02
I0212 11:53:02.279169 22542570456896 run_lib.py:133] step: 971100, training_loss: 2.61215e-02
I0212 11:53:02.435469 22542570456896 run_lib.py:146] step: 971100, eval_loss: 2.75627e-02
I0212 11:53:19.909651 22542570456896 run_lib.py:133] step: 971150, training_loss: 2.80899e-02
I0212 11:53:37.437922 22542570456896 run_lib.py:133] step: 971200, training_loss: 2.98932e-02
I0212 11:53:37.594276 22542570456896 run_lib.py:146] step: 971200, eval_loss: 3.00751e-02
I0212 11:53:55.311618 22542570456896 run_lib.py:133] step: 971250, training_loss: 2.42512e-02
I0212 11:54:12.777709 22542570456896 run_lib.py:133] step: 971300, training_loss: 2.56130e-02
I0212 11:54:12.934398 22542570456896 run_lib.py:146] step: 971300, eval_loss: 3.32335e-02
I0212 11:54:30.450342 22542570456896 run_lib.py:133] step: 971350, training_loss: 3.30541e-02
I0212 11:54:47.904501 22542570456896 run_lib.py:133] step: 971400, training_loss: 3.29692e-02
I0212 11:54:48.074419 22542570456896 run_lib.py:146] step: 971400, eval_loss: 3.31110e-02
I0212 11:55:05.600706 22542570456896 run_lib.py:133] step: 971450, training_loss: 3.04883e-02
I0212 11:55:23.096318 22542570456896 run_lib.py:133] step: 971500, training_loss: 2.81223e-02
I0212 11:55:23.255628 22542570456896 run_lib.py:146] step: 971500, eval_loss: 2.61983e-02
I0212 11:55:40.918959 22542570456896 run_lib.py:133] step: 971550, training_loss: 2.52991e-02
I0212 11:55:58.423705 22542570456896 run_lib.py:133] step: 971600, training_loss: 2.43237e-02
I0212 11:55:58.581812 22542570456896 run_lib.py:146] step: 971600, eval_loss: 3.21523e-02
I0212 11:56:16.090088 22542570456896 run_lib.py:133] step: 971650, training_loss: 3.52668e-02
I0212 11:56:33.595575 22542570456896 run_lib.py:133] step: 971700, training_loss: 2.29855e-02
I0212 11:56:33.750667 22542570456896 run_lib.py:146] step: 971700, eval_loss: 2.83279e-02
I0212 11:56:51.491842 22542570456896 run_lib.py:133] step: 971750, training_loss: 2.95895e-02
I0212 11:57:08.959851 22542570456896 run_lib.py:133] step: 971800, training_loss: 2.79650e-02
I0212 11:57:09.118459 22542570456896 run_lib.py:146] step: 971800, eval_loss: 3.59875e-02
I0212 11:57:26.774196 22542570456896 run_lib.py:133] step: 971850, training_loss: 2.51998e-02
I0212 11:57:44.255799 22542570456896 run_lib.py:133] step: 971900, training_loss: 3.16479e-02
I0212 11:57:44.417577 22542570456896 run_lib.py:146] step: 971900, eval_loss: 2.39000e-02
I0212 11:58:02.039388 22542570456896 run_lib.py:133] step: 971950, training_loss: 2.72329e-02
I0212 11:58:19.551991 22542570456896 run_lib.py:133] step: 972000, training_loss: 2.93828e-02
I0212 11:58:19.710730 22542570456896 run_lib.py:146] step: 972000, eval_loss: 3.17390e-02
I0212 11:58:37.411140 22542570456896 run_lib.py:133] step: 972050, training_loss: 2.95011e-02
I0212 11:58:54.860952 22542570456896 run_lib.py:133] step: 972100, training_loss: 3.00950e-02
I0212 11:58:55.018424 22542570456896 run_lib.py:146] step: 972100, eval_loss: 3.22567e-02
I0212 11:59:12.502288 22542570456896 run_lib.py:133] step: 972150, training_loss: 2.91226e-02
I0212 11:59:30.101641 22542570456896 run_lib.py:133] step: 972200, training_loss: 3.02312e-02
I0212 11:59:30.254417 22542570456896 run_lib.py:146] step: 972200, eval_loss: 2.73242e-02
I0212 11:59:47.778899 22542570456896 run_lib.py:133] step: 972250, training_loss: 2.78799e-02
I0212 12:00:05.258083 22542570456896 run_lib.py:133] step: 972300, training_loss: 3.09613e-02
I0212 12:00:05.420296 22542570456896 run_lib.py:146] step: 972300, eval_loss: 2.67318e-02
I0212 12:00:23.104497 22542570456896 run_lib.py:133] step: 972350, training_loss: 2.65353e-02
I0212 12:00:40.727242 22542570456896 run_lib.py:133] step: 972400, training_loss: 2.07783e-02
I0212 12:00:40.887681 22542570456896 run_lib.py:146] step: 972400, eval_loss: 2.99638e-02
I0212 12:00:58.350496 22542570456896 run_lib.py:133] step: 972450, training_loss: 2.02644e-02
I0212 12:01:15.831003 22542570456896 run_lib.py:133] step: 972500, training_loss: 2.73908e-02
I0212 12:01:15.989594 22542570456896 run_lib.py:146] step: 972500, eval_loss: 2.74216e-02
I0212 12:01:33.476781 22542570456896 run_lib.py:133] step: 972550, training_loss: 2.39742e-02
I0212 12:01:51.166709 22542570456896 run_lib.py:133] step: 972600, training_loss: 2.78498e-02
I0212 12:01:51.324594 22542570456896 run_lib.py:146] step: 972600, eval_loss: 2.81025e-02
I0212 12:02:08.827382 22542570456896 run_lib.py:133] step: 972650, training_loss: 2.67484e-02
I0212 12:02:26.270080 22542570456896 run_lib.py:133] step: 972700, training_loss: 2.54973e-02
I0212 12:02:26.423504 22542570456896 run_lib.py:146] step: 972700, eval_loss: 2.66144e-02
I0212 12:02:43.859635 22542570456896 run_lib.py:133] step: 972750, training_loss: 3.25769e-02
I0212 12:03:01.490978 22542570456896 run_lib.py:133] step: 972800, training_loss: 2.35826e-02
I0212 12:03:01.669382 22542570456896 run_lib.py:146] step: 972800, eval_loss: 2.38986e-02
I0212 12:03:19.180558 22542570456896 run_lib.py:133] step: 972850, training_loss: 2.58888e-02
I0212 12:03:36.740511 22542570456896 run_lib.py:133] step: 972900, training_loss: 3.17805e-02
I0212 12:03:36.899658 22542570456896 run_lib.py:146] step: 972900, eval_loss: 2.51078e-02
I0212 12:03:54.345532 22542570456896 run_lib.py:133] step: 972950, training_loss: 2.17083e-02
I0212 12:04:11.784512 22542570456896 run_lib.py:133] step: 973000, training_loss: 2.82340e-02
I0212 12:04:11.940211 22542570456896 run_lib.py:146] step: 973000, eval_loss: 3.65491e-02
I0212 12:04:29.534777 22542570456896 run_lib.py:133] step: 973050, training_loss: 2.38737e-02
I0212 12:04:47.101988 22542570456896 run_lib.py:133] step: 973100, training_loss: 2.49676e-02
I0212 12:04:47.256413 22542570456896 run_lib.py:146] step: 973100, eval_loss: 2.50692e-02
I0212 12:05:04.766737 22542570456896 run_lib.py:133] step: 973150, training_loss: 3.15927e-02
I0212 12:05:22.219503 22542570456896 run_lib.py:133] step: 973200, training_loss: 2.36725e-02
I0212 12:05:22.376469 22542570456896 run_lib.py:146] step: 973200, eval_loss: 3.29842e-02
I0212 12:05:39.977535 22542570456896 run_lib.py:133] step: 973250, training_loss: 2.01481e-02
I0212 12:05:57.443565 22542570456896 run_lib.py:133] step: 973300, training_loss: 2.40118e-02
I0212 12:05:57.602938 22542570456896 run_lib.py:146] step: 973300, eval_loss: 2.96286e-02
I0212 12:06:15.250854 22542570456896 run_lib.py:133] step: 973350, training_loss: 2.89197e-02
I0212 12:06:32.796096 22542570456896 run_lib.py:133] step: 973400, training_loss: 2.43941e-02
I0212 12:06:32.955681 22542570456896 run_lib.py:146] step: 973400, eval_loss: 3.46315e-02
I0212 12:06:50.605598 22542570456896 run_lib.py:133] step: 973450, training_loss: 3.20134e-02
I0212 12:07:08.036251 22542570456896 run_lib.py:133] step: 973500, training_loss: 2.31975e-02
I0212 12:07:08.199382 22542570456896 run_lib.py:146] step: 973500, eval_loss: 3.18964e-02
I0212 12:07:25.681701 22542570456896 run_lib.py:133] step: 973550, training_loss: 2.72498e-02
I0212 12:07:43.320583 22542570456896 run_lib.py:133] step: 973600, training_loss: 2.84190e-02
I0212 12:07:43.475722 22542570456896 run_lib.py:146] step: 973600, eval_loss: 2.52227e-02
I0212 12:08:00.969859 22542570456896 run_lib.py:133] step: 973650, training_loss: 2.79999e-02
I0212 12:08:18.561204 22542570456896 run_lib.py:133] step: 973700, training_loss: 3.66588e-02
I0212 12:08:18.717550 22542570456896 run_lib.py:146] step: 973700, eval_loss: 2.94442e-02
I0212 12:08:36.085323 22542570456896 run_lib.py:133] step: 973750, training_loss: 2.70195e-02
I0212 12:08:53.465675 22542570456896 run_lib.py:133] step: 973800, training_loss: 2.10556e-02
I0212 12:08:53.624432 22542570456896 run_lib.py:146] step: 973800, eval_loss: 2.92213e-02
I0212 12:09:11.156398 22542570456896 run_lib.py:133] step: 973850, training_loss: 2.66636e-02
I0212 12:09:28.509480 22542570456896 run_lib.py:133] step: 973900, training_loss: 2.23604e-02
I0212 12:09:28.678263 22542570456896 run_lib.py:146] step: 973900, eval_loss: 2.59595e-02
I0212 12:09:46.143780 22542570456896 run_lib.py:133] step: 973950, training_loss: 2.24190e-02
I0212 12:10:03.734720 22542570456896 run_lib.py:133] step: 974000, training_loss: 2.42807e-02
I0212 12:10:03.889530 22542570456896 run_lib.py:146] step: 974000, eval_loss: 2.77001e-02
I0212 12:10:21.363427 22542570456896 run_lib.py:133] step: 974050, training_loss: 2.62605e-02
I0212 12:10:38.727483 22542570456896 run_lib.py:133] step: 974100, training_loss: 2.97744e-02
I0212 12:10:38.880434 22542570456896 run_lib.py:146] step: 974100, eval_loss: 2.94803e-02
I0212 12:10:56.381426 22542570456896 run_lib.py:133] step: 974150, training_loss: 2.34005e-02
I0212 12:11:13.867640 22542570456896 run_lib.py:133] step: 974200, training_loss: 2.68940e-02
I0212 12:11:14.047642 22542570456896 run_lib.py:146] step: 974200, eval_loss: 2.72015e-02
I0212 12:11:31.570917 22542570456896 run_lib.py:133] step: 974250, training_loss: 2.54317e-02
I0212 12:11:49.083010 22542570456896 run_lib.py:133] step: 974300, training_loss: 2.23818e-02
I0212 12:11:49.243674 22542570456896 run_lib.py:146] step: 974300, eval_loss: 3.13044e-02
I0212 12:12:06.893596 22542570456896 run_lib.py:133] step: 974350, training_loss: 2.22848e-02
I0212 12:12:24.427223 22542570456896 run_lib.py:133] step: 974400, training_loss: 3.21122e-02
I0212 12:12:24.584236 22542570456896 run_lib.py:146] step: 974400, eval_loss: 3.20375e-02
I0212 12:12:42.052581 22542570456896 run_lib.py:133] step: 974450, training_loss: 2.57580e-02
I0212 12:12:59.565868 22542570456896 run_lib.py:133] step: 974500, training_loss: 2.61385e-02
I0212 12:12:59.722210 22542570456896 run_lib.py:146] step: 974500, eval_loss: 3.49221e-02
I0212 12:13:17.428963 22542570456896 run_lib.py:133] step: 974550, training_loss: 2.48767e-02
I0212 12:13:34.877205 22542570456896 run_lib.py:133] step: 974600, training_loss: 2.62390e-02
I0212 12:13:35.031451 22542570456896 run_lib.py:146] step: 974600, eval_loss: 3.01552e-02
I0212 12:13:52.659489 22542570456896 run_lib.py:133] step: 974650, training_loss: 2.62551e-02
I0212 12:14:10.164537 22542570456896 run_lib.py:133] step: 974700, training_loss: 2.13799e-02
I0212 12:14:10.325578 22542570456896 run_lib.py:146] step: 974700, eval_loss: 2.91196e-02
I0212 12:14:27.979577 22542570456896 run_lib.py:133] step: 974750, training_loss: 3.00730e-02
I0212 12:14:45.508547 22542570456896 run_lib.py:133] step: 974800, training_loss: 3.34682e-02
I0212 12:14:45.665651 22542570456896 run_lib.py:146] step: 974800, eval_loss: 2.75718e-02
I0212 12:15:03.320437 22542570456896 run_lib.py:133] step: 974850, training_loss: 2.15652e-02
I0212 12:15:20.766530 22542570456896 run_lib.py:133] step: 974900, training_loss: 2.86806e-02
I0212 12:15:20.921525 22542570456896 run_lib.py:146] step: 974900, eval_loss: 3.03157e-02
I0212 12:15:38.381803 22542570456896 run_lib.py:133] step: 974950, training_loss: 2.62297e-02
I0212 12:15:55.996497 22542570456896 run_lib.py:133] step: 975000, training_loss: 2.85791e-02
I0212 12:15:56.150233 22542570456896 run_lib.py:146] step: 975000, eval_loss: 2.96421e-02
I0212 12:16:13.669663 22542570456896 run_lib.py:133] step: 975050, training_loss: 2.51843e-02
I0212 12:16:31.133522 22542570456896 run_lib.py:133] step: 975100, training_loss: 2.12636e-02
I0212 12:16:31.294677 22542570456896 run_lib.py:146] step: 975100, eval_loss: 2.48804e-02
I0212 12:16:48.998181 22542570456896 run_lib.py:133] step: 975150, training_loss: 2.50799e-02
I0212 12:17:06.485177 22542570456896 run_lib.py:133] step: 975200, training_loss: 2.53367e-02
I0212 12:17:06.646826 22542570456896 run_lib.py:146] step: 975200, eval_loss: 2.95389e-02
I0212 12:17:24.258416 22542570456896 run_lib.py:133] step: 975250, training_loss: 2.25018e-02
I0212 12:17:41.723586 22542570456896 run_lib.py:133] step: 975300, training_loss: 2.92245e-02
I0212 12:17:41.893448 22542570456896 run_lib.py:146] step: 975300, eval_loss: 3.40977e-02
I0212 12:17:59.436952 22542570456896 run_lib.py:133] step: 975350, training_loss: 2.47196e-02
I0212 12:18:17.116114 22542570456896 run_lib.py:133] step: 975400, training_loss: 1.92427e-02
I0212 12:18:17.272938 22542570456896 run_lib.py:146] step: 975400, eval_loss: 2.86164e-02
I0212 12:18:34.750964 22542570456896 run_lib.py:133] step: 975450, training_loss: 2.57319e-02
I0212 12:18:52.224363 22542570456896 run_lib.py:133] step: 975500, training_loss: 2.74756e-02
I0212 12:18:52.377520 22542570456896 run_lib.py:146] step: 975500, eval_loss: 3.09693e-02
I0212 12:19:09.875668 22542570456896 run_lib.py:133] step: 975550, training_loss: 2.18648e-02
I0212 12:19:27.523497 22542570456896 run_lib.py:133] step: 975600, training_loss: 2.82253e-02
I0212 12:19:27.693648 22542570456896 run_lib.py:146] step: 975600, eval_loss: 2.81704e-02
I0212 12:19:45.203354 22542570456896 run_lib.py:133] step: 975650, training_loss: 2.17433e-02
I0212 12:20:02.841838 22542570456896 run_lib.py:133] step: 975700, training_loss: 2.17504e-02
I0212 12:20:03.001177 22542570456896 run_lib.py:146] step: 975700, eval_loss: 2.43382e-02
I0212 12:20:20.469847 22542570456896 run_lib.py:133] step: 975750, training_loss: 2.76045e-02
I0212 12:20:37.924522 22542570456896 run_lib.py:133] step: 975800, training_loss: 2.73052e-02
I0212 12:20:38.086384 22542570456896 run_lib.py:146] step: 975800, eval_loss: 2.44605e-02
I0212 12:20:55.694240 22542570456896 run_lib.py:133] step: 975850, training_loss: 2.67028e-02
I0212 12:21:13.256412 22542570456896 run_lib.py:133] step: 975900, training_loss: 3.09249e-02
I0212 12:21:13.415629 22542570456896 run_lib.py:146] step: 975900, eval_loss: 2.35644e-02
I0212 12:21:30.965847 22542570456896 run_lib.py:133] step: 975950, training_loss: 2.68148e-02
I0212 12:21:48.409184 22542570456896 run_lib.py:133] step: 976000, training_loss: 3.24616e-02
I0212 12:21:48.560652 22542570456896 run_lib.py:146] step: 976000, eval_loss: 3.11607e-02
I0212 12:22:06.215116 22542570456896 run_lib.py:133] step: 976050, training_loss: 2.63649e-02
I0212 12:22:23.696226 22542570456896 run_lib.py:133] step: 976100, training_loss: 2.96859e-02
I0212 12:22:23.852774 22542570456896 run_lib.py:146] step: 976100, eval_loss: 2.99440e-02
I0212 12:22:41.512705 22542570456896 run_lib.py:133] step: 976150, training_loss: 2.95015e-02
I0212 12:22:58.990409 22542570456896 run_lib.py:133] step: 976200, training_loss: 2.52081e-02
I0212 12:22:59.156454 22542570456896 run_lib.py:146] step: 976200, eval_loss: 3.22669e-02
I0212 12:23:16.854735 22542570456896 run_lib.py:133] step: 976250, training_loss: 3.83809e-02
I0212 12:23:34.340186 22542570456896 run_lib.py:133] step: 976300, training_loss: 3.59765e-02
I0212 12:23:34.494234 22542570456896 run_lib.py:146] step: 976300, eval_loss: 2.87786e-02
I0212 12:23:51.974886 22542570456896 run_lib.py:133] step: 976350, training_loss: 2.83217e-02
I0212 12:24:09.591285 22542570456896 run_lib.py:133] step: 976400, training_loss: 3.24435e-02
I0212 12:24:09.746139 22542570456896 run_lib.py:146] step: 976400, eval_loss: 3.28402e-02
I0212 12:24:27.182631 22542570456896 run_lib.py:133] step: 976450, training_loss: 2.87907e-02
I0212 12:24:44.821388 22542570456896 run_lib.py:133] step: 976500, training_loss: 3.32568e-02
I0212 12:24:44.975730 22542570456896 run_lib.py:146] step: 976500, eval_loss: 3.15918e-02
I0212 12:25:02.515861 22542570456896 run_lib.py:133] step: 976550, training_loss: 3.23827e-02
I0212 12:25:19.982264 22542570456896 run_lib.py:133] step: 976600, training_loss: 2.63200e-02
I0212 12:25:20.143472 22542570456896 run_lib.py:146] step: 976600, eval_loss: 2.82930e-02
I0212 12:25:37.809581 22542570456896 run_lib.py:133] step: 976650, training_loss: 3.15214e-02
I0212 12:25:55.271480 22542570456896 run_lib.py:133] step: 976700, training_loss: 2.38219e-02
I0212 12:25:55.429573 22542570456896 run_lib.py:146] step: 976700, eval_loss: 3.27957e-02
I0212 12:26:12.928367 22542570456896 run_lib.py:133] step: 976750, training_loss: 2.46480e-02
I0212 12:26:30.575642 22542570456896 run_lib.py:133] step: 976800, training_loss: 2.60749e-02
I0212 12:26:30.732278 22542570456896 run_lib.py:146] step: 976800, eval_loss: 3.19951e-02
I0212 12:26:48.251179 22542570456896 run_lib.py:133] step: 976850, training_loss: 2.61548e-02
I0212 12:27:05.691009 22542570456896 run_lib.py:133] step: 976900, training_loss: 3.13995e-02
I0212 12:27:06.043074 22542570456896 run_lib.py:146] step: 976900, eval_loss: 2.41594e-02
I0212 12:27:23.523528 22542570456896 run_lib.py:133] step: 976950, training_loss: 3.20731e-02
I0212 12:27:40.977120 22542570456896 run_lib.py:133] step: 977000, training_loss: 2.62260e-02
I0212 12:27:41.132444 22542570456896 run_lib.py:146] step: 977000, eval_loss: 2.84277e-02
I0212 12:27:58.582401 22542570456896 run_lib.py:133] step: 977050, training_loss: 2.56380e-02
I0212 12:28:16.037192 22542570456896 run_lib.py:133] step: 977100, training_loss: 2.41983e-02
I0212 12:28:16.215565 22542570456896 run_lib.py:146] step: 977100, eval_loss: 3.47009e-02
I0212 12:28:33.872634 22542570456896 run_lib.py:133] step: 977150, training_loss: 2.62124e-02
I0212 12:28:51.488399 22542570456896 run_lib.py:133] step: 977200, training_loss: 2.89630e-02
I0212 12:28:51.646606 22542570456896 run_lib.py:146] step: 977200, eval_loss: 3.10755e-02
I0212 12:29:09.115722 22542570456896 run_lib.py:133] step: 977250, training_loss: 2.35774e-02
I0212 12:29:26.568903 22542570456896 run_lib.py:133] step: 977300, training_loss: 2.43546e-02
I0212 12:29:26.724426 22542570456896 run_lib.py:146] step: 977300, eval_loss: 2.64038e-02
I0212 12:29:44.336292 22542570456896 run_lib.py:133] step: 977350, training_loss: 2.50782e-02
I0212 12:30:01.943508 22542570456896 run_lib.py:133] step: 977400, training_loss: 2.51602e-02
I0212 12:30:02.098674 22542570456896 run_lib.py:146] step: 977400, eval_loss: 3.02835e-02
I0212 12:30:19.586915 22542570456896 run_lib.py:133] step: 977450, training_loss: 2.73932e-02
I0212 12:30:37.065796 22542570456896 run_lib.py:133] step: 977500, training_loss: 2.66065e-02
I0212 12:30:37.230343 22542570456896 run_lib.py:146] step: 977500, eval_loss: 2.51720e-02
I0212 12:30:54.836325 22542570456896 run_lib.py:133] step: 977550, training_loss: 2.78200e-02
I0212 12:31:12.327094 22542570456896 run_lib.py:133] step: 977600, training_loss: 3.06059e-02
I0212 12:31:12.502469 22542570456896 run_lib.py:146] step: 977600, eval_loss: 3.08053e-02
I0212 12:31:30.167072 22542570456896 run_lib.py:133] step: 977650, training_loss: 2.66048e-02
I0212 12:31:47.660822 22542570456896 run_lib.py:133] step: 977700, training_loss: 2.74393e-02
I0212 12:31:47.817766 22542570456896 run_lib.py:146] step: 977700, eval_loss: 2.61162e-02
I0212 12:32:05.461523 22542570456896 run_lib.py:133] step: 977750, training_loss: 2.56030e-02
I0212 12:32:22.927923 22542570456896 run_lib.py:133] step: 977800, training_loss: 2.42437e-02
I0212 12:32:23.083510 22542570456896 run_lib.py:146] step: 977800, eval_loss: 2.94928e-02
I0212 12:32:40.550273 22542570456896 run_lib.py:133] step: 977850, training_loss: 2.97000e-02
I0212 12:32:58.178968 22542570456896 run_lib.py:133] step: 977900, training_loss: 3.27066e-02
I0212 12:32:58.333700 22542570456896 run_lib.py:146] step: 977900, eval_loss: 2.93129e-02
I0212 12:33:15.836254 22542570456896 run_lib.py:133] step: 977950, training_loss: 2.31273e-02
I0212 12:33:33.509189 22542570456896 run_lib.py:133] step: 978000, training_loss: 2.34931e-02
I0212 12:33:33.669316 22542570456896 run_lib.py:146] step: 978000, eval_loss: 2.76979e-02
I0212 12:33:51.135721 22542570456896 run_lib.py:133] step: 978050, training_loss: 2.82935e-02
I0212 12:34:08.628418 22542570456896 run_lib.py:133] step: 978100, training_loss: 2.41041e-02
I0212 12:34:08.788723 22542570456896 run_lib.py:146] step: 978100, eval_loss: 3.04841e-02
I0212 12:34:26.426617 22542570456896 run_lib.py:133] step: 978150, training_loss: 3.07343e-02
I0212 12:34:43.896629 22542570456896 run_lib.py:133] step: 978200, training_loss: 2.30521e-02
I0212 12:34:44.052258 22542570456896 run_lib.py:146] step: 978200, eval_loss: 3.10718e-02
I0212 12:35:01.528143 22542570456896 run_lib.py:133] step: 978250, training_loss: 3.05535e-02
I0212 12:35:19.084569 22542570456896 run_lib.py:133] step: 978300, training_loss: 2.66761e-02
I0212 12:35:19.239283 22542570456896 run_lib.py:146] step: 978300, eval_loss: 3.07882e-02
I0212 12:35:36.928653 22542570456896 run_lib.py:133] step: 978350, training_loss: 2.59606e-02
I0212 12:35:54.430727 22542570456896 run_lib.py:133] step: 978400, training_loss: 2.53105e-02
I0212 12:35:54.585438 22542570456896 run_lib.py:146] step: 978400, eval_loss: 2.35150e-02
I0212 12:36:12.113439 22542570456896 run_lib.py:133] step: 978450, training_loss: 3.24062e-02
I0212 12:36:29.600909 22542570456896 run_lib.py:133] step: 978500, training_loss: 2.59128e-02
I0212 12:36:29.775481 22542570456896 run_lib.py:146] step: 978500, eval_loss: 2.73133e-02
I0212 12:36:47.303561 22542570456896 run_lib.py:133] step: 978550, training_loss: 2.91503e-02
I0212 12:37:04.820165 22542570456896 run_lib.py:133] step: 978600, training_loss: 2.85759e-02
I0212 12:37:04.978956 22542570456896 run_lib.py:146] step: 978600, eval_loss: 3.61850e-02
I0212 12:37:22.627240 22542570456896 run_lib.py:133] step: 978650, training_loss: 2.58952e-02
I0212 12:37:40.160040 22542570456896 run_lib.py:133] step: 978700, training_loss: 2.65761e-02
I0212 12:37:40.317769 22542570456896 run_lib.py:146] step: 978700, eval_loss: 3.04575e-02
I0212 12:37:57.786788 22542570456896 run_lib.py:133] step: 978750, training_loss: 2.78004e-02
I0212 12:38:15.291355 22542570456896 run_lib.py:133] step: 978800, training_loss: 2.63255e-02
I0212 12:38:15.448891 22542570456896 run_lib.py:146] step: 978800, eval_loss: 3.73013e-02
I0212 12:38:33.163245 22542570456896 run_lib.py:133] step: 978850, training_loss: 2.76142e-02
I0212 12:38:50.624341 22542570456896 run_lib.py:133] step: 978900, training_loss: 3.40820e-02
I0212 12:38:50.779315 22542570456896 run_lib.py:146] step: 978900, eval_loss: 2.95887e-02
I0212 12:39:08.281228 22542570456896 run_lib.py:133] step: 978950, training_loss: 2.99313e-02
I0212 12:39:25.676856 22542570456896 run_lib.py:133] step: 979000, training_loss: 2.56478e-02
I0212 12:39:25.835467 22542570456896 run_lib.py:146] step: 979000, eval_loss: 2.97954e-02
I0212 12:39:43.313317 22542570456896 run_lib.py:133] step: 979050, training_loss: 2.98173e-02
I0212 12:40:00.767928 22542570456896 run_lib.py:133] step: 979100, training_loss: 2.47305e-02
I0212 12:40:00.924558 22542570456896 run_lib.py:146] step: 979100, eval_loss: 2.95454e-02
I0212 12:40:18.468792 22542570456896 run_lib.py:133] step: 979150, training_loss: 2.57763e-02
I0212 12:40:35.822384 22542570456896 run_lib.py:133] step: 979200, training_loss: 2.17443e-02
I0212 12:40:35.977315 22542570456896 run_lib.py:146] step: 979200, eval_loss: 3.16924e-02
I0212 12:40:53.359814 22542570456896 run_lib.py:133] step: 979250, training_loss: 2.72471e-02
I0212 12:41:10.857907 22542570456896 run_lib.py:133] step: 979300, training_loss: 2.71267e-02
I0212 12:41:11.008859 22542570456896 run_lib.py:146] step: 979300, eval_loss: 3.15565e-02
I0212 12:41:28.445928 22542570456896 run_lib.py:133] step: 979350, training_loss: 3.18601e-02
I0212 12:41:45.935967 22542570456896 run_lib.py:133] step: 979400, training_loss: 2.51630e-02
I0212 12:41:46.106693 22542570456896 run_lib.py:146] step: 979400, eval_loss: 2.53657e-02
I0212 12:42:03.845607 22542570456896 run_lib.py:133] step: 979450, training_loss: 2.67254e-02
I0212 12:42:21.519333 22542570456896 run_lib.py:133] step: 979500, training_loss: 3.09936e-02
I0212 12:42:21.678596 22542570456896 run_lib.py:146] step: 979500, eval_loss: 2.71324e-02
I0212 12:42:39.156527 22542570456896 run_lib.py:133] step: 979550, training_loss: 2.30255e-02
I0212 12:42:56.611139 22542570456896 run_lib.py:133] step: 979600, training_loss: 2.58580e-02
I0212 12:42:56.782533 22542570456896 run_lib.py:146] step: 979600, eval_loss: 2.72634e-02
I0212 12:43:14.335469 22542570456896 run_lib.py:133] step: 979650, training_loss: 2.89220e-02
I0212 12:43:32.033373 22542570456896 run_lib.py:133] step: 979700, training_loss: 2.37074e-02
I0212 12:43:32.189666 22542570456896 run_lib.py:146] step: 979700, eval_loss: 3.28797e-02
I0212 12:43:49.670359 22542570456896 run_lib.py:133] step: 979750, training_loss: 2.93096e-02
I0212 12:44:07.130784 22542570456896 run_lib.py:133] step: 979800, training_loss: 2.79521e-02
I0212 12:44:07.283358 22542570456896 run_lib.py:146] step: 979800, eval_loss: 3.49740e-02
I0212 12:44:24.776883 22542570456896 run_lib.py:133] step: 979850, training_loss: 2.56802e-02
I0212 12:44:42.407155 22542570456896 run_lib.py:133] step: 979900, training_loss: 3.44008e-02
I0212 12:44:42.577492 22542570456896 run_lib.py:146] step: 979900, eval_loss: 2.98286e-02
I0212 12:45:00.045784 22542570456896 run_lib.py:133] step: 979950, training_loss: 3.04744e-02
I0212 12:45:17.603439 22542570456896 run_lib.py:133] step: 980000, training_loss: 2.26626e-02
I0212 12:45:18.342707 22542570456896 run_lib.py:146] step: 980000, eval_loss: 2.75881e-02
I0212 12:45:38.531225 22542570456896 run_lib.py:133] step: 980050, training_loss: 2.60291e-02
I0212 12:45:56.025696 22542570456896 run_lib.py:133] step: 980100, training_loss: 2.58255e-02
I0212 12:45:56.187441 22542570456896 run_lib.py:146] step: 980100, eval_loss: 2.76780e-02
I0212 12:46:13.612746 22542570456896 run_lib.py:133] step: 980150, training_loss: 2.54244e-02
I0212 12:46:31.319433 22542570456896 run_lib.py:133] step: 980200, training_loss: 3.49889e-02
I0212 12:46:31.477719 22542570456896 run_lib.py:146] step: 980200, eval_loss: 2.99738e-02
I0212 12:46:48.989602 22542570456896 run_lib.py:133] step: 980250, training_loss: 2.49364e-02
I0212 12:47:06.572280 22542570456896 run_lib.py:133] step: 980300, training_loss: 3.36070e-02
I0212 12:47:06.724278 22542570456896 run_lib.py:146] step: 980300, eval_loss: 3.05527e-02
I0212 12:47:24.214289 22542570456896 run_lib.py:133] step: 980350, training_loss: 2.92452e-02
I0212 12:47:41.676426 22542570456896 run_lib.py:133] step: 980400, training_loss: 2.57958e-02
I0212 12:47:41.836626 22542570456896 run_lib.py:146] step: 980400, eval_loss: 2.39125e-02
I0212 12:47:59.504550 22542570456896 run_lib.py:133] step: 980450, training_loss: 3.28501e-02
I0212 12:48:17.099807 22542570456896 run_lib.py:133] step: 980500, training_loss: 2.85465e-02
I0212 12:48:17.262077 22542570456896 run_lib.py:146] step: 980500, eval_loss: 3.18001e-02
I0212 12:48:34.798875 22542570456896 run_lib.py:133] step: 980550, training_loss: 3.35313e-02
I0212 12:48:52.306037 22542570456896 run_lib.py:133] step: 980600, training_loss: 2.15122e-02
I0212 12:48:52.463667 22542570456896 run_lib.py:146] step: 980600, eval_loss: 2.78150e-02
I0212 12:49:10.144419 22542570456896 run_lib.py:133] step: 980650, training_loss: 3.23254e-02
I0212 12:49:27.601237 22542570456896 run_lib.py:133] step: 980700, training_loss: 3.20627e-02
I0212 12:49:27.754795 22542570456896 run_lib.py:146] step: 980700, eval_loss: 2.24311e-02
I0212 12:49:45.402494 22542570456896 run_lib.py:133] step: 980750, training_loss: 2.35967e-02
I0212 12:50:02.924545 22542570456896 run_lib.py:133] step: 980800, training_loss: 2.96612e-02
I0212 12:50:03.080672 22542570456896 run_lib.py:146] step: 980800, eval_loss: 2.86152e-02
I0212 12:50:20.782895 22542570456896 run_lib.py:133] step: 980850, training_loss: 2.78287e-02
I0212 12:50:38.223393 22542570456896 run_lib.py:133] step: 980900, training_loss: 3.18079e-02
I0212 12:50:38.380421 22542570456896 run_lib.py:146] step: 980900, eval_loss: 3.15039e-02
I0212 12:50:55.779493 22542570456896 run_lib.py:133] step: 980950, training_loss: 4.07823e-02
I0212 12:51:13.379376 22542570456896 run_lib.py:133] step: 981000, training_loss: 2.11500e-02
I0212 12:51:13.539457 22542570456896 run_lib.py:146] step: 981000, eval_loss: 2.99878e-02
I0212 12:51:31.015787 22542570456896 run_lib.py:133] step: 981050, training_loss: 2.53067e-02
I0212 12:51:48.692048 22542570456896 run_lib.py:133] step: 981100, training_loss: 3.38820e-02
I0212 12:51:48.857669 22542570456896 run_lib.py:146] step: 981100, eval_loss: 3.52407e-02
I0212 12:52:06.342749 22542570456896 run_lib.py:133] step: 981150, training_loss: 2.31012e-02
I0212 12:52:23.810528 22542570456896 run_lib.py:133] step: 981200, training_loss: 2.52185e-02
I0212 12:52:23.970025 22542570456896 run_lib.py:146] step: 981200, eval_loss: 3.23728e-02
I0212 12:52:41.623295 22542570456896 run_lib.py:133] step: 981250, training_loss: 2.52762e-02
I0212 12:52:59.137674 22542570456896 run_lib.py:133] step: 981300, training_loss: 2.55678e-02
I0212 12:52:59.292766 22542570456896 run_lib.py:146] step: 981300, eval_loss: 3.34598e-02
I0212 12:53:16.816821 22542570456896 run_lib.py:133] step: 981350, training_loss: 3.10308e-02
I0212 12:53:34.486167 22542570456896 run_lib.py:133] step: 981400, training_loss: 3.35475e-02
I0212 12:53:34.646399 22542570456896 run_lib.py:146] step: 981400, eval_loss: 3.16721e-02
I0212 12:53:52.101090 22542570456896 run_lib.py:133] step: 981450, training_loss: 2.80657e-02
I0212 12:54:09.576371 22542570456896 run_lib.py:133] step: 981500, training_loss: 2.41382e-02
I0212 12:54:09.733663 22542570456896 run_lib.py:146] step: 981500, eval_loss: 3.08186e-02
I0212 12:54:27.273395 22542570456896 run_lib.py:133] step: 981550, training_loss: 2.55340e-02
I0212 12:54:44.800202 22542570456896 run_lib.py:133] step: 981600, training_loss: 2.80894e-02
I0212 12:54:44.963785 22542570456896 run_lib.py:146] step: 981600, eval_loss: 3.34140e-02
I0212 12:55:02.448894 22542570456896 run_lib.py:133] step: 981650, training_loss: 2.51413e-02
I0212 12:55:19.946002 22542570456896 run_lib.py:133] step: 981700, training_loss: 2.99076e-02
I0212 12:55:20.100172 22542570456896 run_lib.py:146] step: 981700, eval_loss: 2.89031e-02
I0212 12:55:37.741560 22542570456896 run_lib.py:133] step: 981750, training_loss: 2.94807e-02
I0212 12:55:55.270125 22542570456896 run_lib.py:133] step: 981800, training_loss: 2.19687e-02
I0212 12:55:55.423439 22542570456896 run_lib.py:146] step: 981800, eval_loss: 2.53392e-02
I0212 12:56:12.885063 22542570456896 run_lib.py:133] step: 981850, training_loss: 3.49592e-02
I0212 12:56:30.368228 22542570456896 run_lib.py:133] step: 981900, training_loss: 2.62485e-02
I0212 12:56:30.547403 22542570456896 run_lib.py:146] step: 981900, eval_loss: 2.85853e-02
I0212 12:56:48.273761 22542570456896 run_lib.py:133] step: 981950, training_loss: 3.45652e-02
I0212 12:57:05.764889 22542570456896 run_lib.py:133] step: 982000, training_loss: 2.82709e-02
I0212 12:57:05.922717 22542570456896 run_lib.py:146] step: 982000, eval_loss: 2.95658e-02
I0212 12:57:23.547860 22542570456896 run_lib.py:133] step: 982050, training_loss: 2.32217e-02
I0212 12:57:40.973485 22542570456896 run_lib.py:133] step: 982100, training_loss: 2.79671e-02
I0212 12:57:41.132584 22542570456896 run_lib.py:146] step: 982100, eval_loss: 2.79615e-02
I0212 12:57:58.742173 22542570456896 run_lib.py:133] step: 982150, training_loss: 2.55429e-02
I0212 12:58:16.271753 22542570456896 run_lib.py:133] step: 982200, training_loss: 3.03626e-02
I0212 12:58:16.428367 22542570456896 run_lib.py:146] step: 982200, eval_loss: 2.79323e-02
I0212 12:58:34.122950 22542570456896 run_lib.py:133] step: 982250, training_loss: 3.37583e-02
I0212 12:58:51.603636 22542570456896 run_lib.py:133] step: 982300, training_loss: 2.87561e-02
I0212 12:58:51.760416 22542570456896 run_lib.py:146] step: 982300, eval_loss: 2.79330e-02
I0212 12:59:09.207952 22542570456896 run_lib.py:133] step: 982350, training_loss: 2.42666e-02
I0212 12:59:26.840153 22542570456896 run_lib.py:133] step: 982400, training_loss: 2.49931e-02
I0212 12:59:27.012363 22542570456896 run_lib.py:146] step: 982400, eval_loss: 2.86281e-02
I0212 12:59:44.513568 22542570456896 run_lib.py:133] step: 982450, training_loss: 3.01520e-02
I0212 13:00:02.016280 22542570456896 run_lib.py:133] step: 982500, training_loss: 2.89412e-02
I0212 13:00:02.174779 22542570456896 run_lib.py:146] step: 982500, eval_loss: 3.41062e-02
I0212 13:00:19.841455 22542570456896 run_lib.py:133] step: 982550, training_loss: 2.92004e-02
I0212 13:00:37.298519 22542570456896 run_lib.py:133] step: 982600, training_loss: 2.09056e-02
I0212 13:00:37.455068 22542570456896 run_lib.py:146] step: 982600, eval_loss: 2.74274e-02
I0212 13:00:55.063270 22542570456896 run_lib.py:133] step: 982650, training_loss: 2.58253e-02
I0212 13:01:12.570153 22542570456896 run_lib.py:133] step: 982700, training_loss: 3.39279e-02
I0212 13:01:12.732928 22542570456896 run_lib.py:146] step: 982700, eval_loss: 2.90406e-02
I0212 13:01:30.273767 22542570456896 run_lib.py:133] step: 982750, training_loss: 2.78909e-02
I0212 13:01:47.947176 22542570456896 run_lib.py:133] step: 982800, training_loss: 2.59466e-02
I0212 13:01:48.104380 22542570456896 run_lib.py:146] step: 982800, eval_loss: 2.87763e-02
I0212 13:02:05.537125 22542570456896 run_lib.py:133] step: 982850, training_loss: 2.81107e-02
I0212 13:02:23.005366 22542570456896 run_lib.py:133] step: 982900, training_loss: 2.50490e-02
I0212 13:02:23.173509 22542570456896 run_lib.py:146] step: 982900, eval_loss: 2.64407e-02
I0212 13:02:40.654463 22542570456896 run_lib.py:133] step: 982950, training_loss: 2.65231e-02
I0212 13:02:58.374617 22542570456896 run_lib.py:133] step: 983000, training_loss: 2.75759e-02
I0212 13:02:58.532207 22542570456896 run_lib.py:146] step: 983000, eval_loss: 2.84222e-02
I0212 13:03:16.008027 22542570456896 run_lib.py:133] step: 983050, training_loss: 2.87598e-02
I0212 13:03:33.559037 22542570456896 run_lib.py:133] step: 983100, training_loss: 3.21574e-02
I0212 13:03:33.715444 22542570456896 run_lib.py:146] step: 983100, eval_loss: 2.72824e-02
I0212 13:03:51.170608 22542570456896 run_lib.py:133] step: 983150, training_loss: 2.72202e-02
I0212 13:04:08.667288 22542570456896 run_lib.py:133] step: 983200, training_loss: 2.95953e-02
I0212 13:04:08.825167 22542570456896 run_lib.py:146] step: 983200, eval_loss: 2.82031e-02
I0212 13:04:26.484560 22542570456896 run_lib.py:133] step: 983250, training_loss: 2.90642e-02
I0212 13:04:44.091636 22542570456896 run_lib.py:133] step: 983300, training_loss: 2.37069e-02
I0212 13:04:44.253861 22542570456896 run_lib.py:146] step: 983300, eval_loss: 3.70299e-02
I0212 13:05:01.736606 22542570456896 run_lib.py:133] step: 983350, training_loss: 2.10982e-02
I0212 13:05:19.205194 22542570456896 run_lib.py:133] step: 983400, training_loss: 2.32521e-02
I0212 13:05:19.361412 22542570456896 run_lib.py:146] step: 983400, eval_loss: 3.33462e-02
I0212 13:05:36.972304 22542570456896 run_lib.py:133] step: 983450, training_loss: 2.57174e-02
I0212 13:05:54.424931 22542570456896 run_lib.py:133] step: 983500, training_loss: 2.36811e-02
I0212 13:05:54.594558 22542570456896 run_lib.py:146] step: 983500, eval_loss: 2.70942e-02
I0212 13:06:12.260566 22542570456896 run_lib.py:133] step: 983550, training_loss: 3.61141e-02
I0212 13:06:29.783493 22542570456896 run_lib.py:133] step: 983600, training_loss: 2.69979e-02
I0212 13:06:29.937153 22542570456896 run_lib.py:146] step: 983600, eval_loss: 2.80842e-02
I0212 13:06:47.614177 22542570456896 run_lib.py:133] step: 983650, training_loss: 2.88974e-02
I0212 13:07:05.085969 22542570456896 run_lib.py:133] step: 983700, training_loss: 2.92107e-02
I0212 13:07:05.241335 22542570456896 run_lib.py:146] step: 983700, eval_loss: 3.15936e-02
I0212 13:07:22.680515 22542570456896 run_lib.py:133] step: 983750, training_loss: 2.75050e-02
I0212 13:07:40.301281 22542570456896 run_lib.py:133] step: 983800, training_loss: 2.31581e-02
I0212 13:07:40.473347 22542570456896 run_lib.py:146] step: 983800, eval_loss: 2.79379e-02
I0212 13:07:57.970795 22542570456896 run_lib.py:133] step: 983850, training_loss: 2.79282e-02
I0212 13:08:15.631863 22542570456896 run_lib.py:133] step: 983900, training_loss: 2.30003e-02
I0212 13:08:15.789721 22542570456896 run_lib.py:146] step: 983900, eval_loss: 2.37978e-02
I0212 13:08:33.271877 22542570456896 run_lib.py:133] step: 983950, training_loss: 1.89355e-02
I0212 13:08:50.721850 22542570456896 run_lib.py:133] step: 984000, training_loss: 3.25252e-02
I0212 13:08:50.880405 22542570456896 run_lib.py:146] step: 984000, eval_loss: 3.25698e-02
I0212 13:09:08.503094 22542570456896 run_lib.py:133] step: 984050, training_loss: 3.10861e-02
I0212 13:09:25.897454 22542570456896 run_lib.py:133] step: 984100, training_loss: 2.81449e-02
I0212 13:09:26.058006 22542570456896 run_lib.py:146] step: 984100, eval_loss: 2.80223e-02
I0212 13:09:43.486749 22542570456896 run_lib.py:133] step: 984150, training_loss: 2.92574e-02
I0212 13:10:01.013841 22542570456896 run_lib.py:133] step: 984200, training_loss: 2.94200e-02
I0212 13:10:01.168238 22542570456896 run_lib.py:146] step: 984200, eval_loss: 2.88928e-02
I0212 13:10:18.609795 22542570456896 run_lib.py:133] step: 984250, training_loss: 2.88437e-02
I0212 13:10:35.989933 22542570456896 run_lib.py:133] step: 984300, training_loss: 2.71771e-02
I0212 13:10:36.291561 22542570456896 run_lib.py:146] step: 984300, eval_loss: 2.70934e-02
I0212 13:10:53.623925 22542570456896 run_lib.py:133] step: 984350, training_loss: 2.35969e-02
I0212 13:11:10.950838 22542570456896 run_lib.py:133] step: 984400, training_loss: 2.83154e-02
I0212 13:11:11.125359 22542570456896 run_lib.py:146] step: 984400, eval_loss: 2.47879e-02
I0212 13:11:28.523777 22542570456896 run_lib.py:133] step: 984450, training_loss: 3.92373e-02
I0212 13:11:45.883558 22542570456896 run_lib.py:133] step: 984500, training_loss: 2.98855e-02
I0212 13:11:46.049503 22542570456896 run_lib.py:146] step: 984500, eval_loss: 3.04778e-02
I0212 13:12:03.767252 22542570456896 run_lib.py:133] step: 984550, training_loss: 3.28612e-02
I0212 13:12:21.315411 22542570456896 run_lib.py:133] step: 984600, training_loss: 3.33075e-02
I0212 13:12:21.468515 22542570456896 run_lib.py:146] step: 984600, eval_loss: 3.00844e-02
I0212 13:12:38.959099 22542570456896 run_lib.py:133] step: 984650, training_loss: 2.44559e-02
I0212 13:12:56.417270 22542570456896 run_lib.py:133] step: 984700, training_loss: 2.45623e-02
I0212 13:12:56.593187 22542570456896 run_lib.py:146] step: 984700, eval_loss: 3.46117e-02
I0212 13:13:14.291027 22542570456896 run_lib.py:133] step: 984750, training_loss: 2.68971e-02
I0212 13:13:31.895672 22542570456896 run_lib.py:133] step: 984800, training_loss: 3.48931e-02
I0212 13:13:32.054462 22542570456896 run_lib.py:146] step: 984800, eval_loss: 2.79394e-02
I0212 13:13:49.519941 22542570456896 run_lib.py:133] step: 984850, training_loss: 2.60218e-02
I0212 13:14:06.955957 22542570456896 run_lib.py:133] step: 984900, training_loss: 2.82129e-02
I0212 13:14:07.113495 22542570456896 run_lib.py:146] step: 984900, eval_loss: 2.72784e-02
I0212 13:14:24.780654 22542570456896 run_lib.py:133] step: 984950, training_loss: 3.09308e-02
I0212 13:14:42.274667 22542570456896 run_lib.py:133] step: 985000, training_loss: 2.87961e-02
I0212 13:14:42.432733 22542570456896 run_lib.py:146] step: 985000, eval_loss: 3.09461e-02
I0212 13:15:00.107892 22542570456896 run_lib.py:133] step: 985050, training_loss: 3.49120e-02
I0212 13:15:17.553307 22542570456896 run_lib.py:133] step: 985100, training_loss: 2.64648e-02
I0212 13:15:17.707341 22542570456896 run_lib.py:146] step: 985100, eval_loss: 2.65408e-02
I0212 13:15:35.329569 22542570456896 run_lib.py:133] step: 985150, training_loss: 2.72138e-02
I0212 13:15:52.796771 22542570456896 run_lib.py:133] step: 985200, training_loss: 2.66477e-02
I0212 13:15:52.974518 22542570456896 run_lib.py:146] step: 985200, eval_loss: 2.98612e-02
I0212 13:16:10.501925 22542570456896 run_lib.py:133] step: 985250, training_loss: 2.78006e-02
I0212 13:16:28.208106 22542570456896 run_lib.py:133] step: 985300, training_loss: 2.10721e-02
I0212 13:16:28.365729 22542570456896 run_lib.py:146] step: 985300, eval_loss: 2.51683e-02
I0212 13:16:45.824563 22542570456896 run_lib.py:133] step: 985350, training_loss: 3.77374e-02
I0212 13:17:03.426076 22542570456896 run_lib.py:133] step: 985400, training_loss: 2.57771e-02
I0212 13:17:03.582212 22542570456896 run_lib.py:146] step: 985400, eval_loss: 3.58020e-02
I0212 13:17:21.072785 22542570456896 run_lib.py:133] step: 985450, training_loss: 3.16454e-02
I0212 13:17:38.567444 22542570456896 run_lib.py:133] step: 985500, training_loss: 2.11507e-02
I0212 13:17:38.723185 22542570456896 run_lib.py:146] step: 985500, eval_loss: 2.82107e-02
I0212 13:17:56.462052 22542570456896 run_lib.py:133] step: 985550, training_loss: 3.80851e-02
I0212 13:18:13.937000 22542570456896 run_lib.py:133] step: 985600, training_loss: 2.71765e-02
I0212 13:18:14.093458 22542570456896 run_lib.py:146] step: 985600, eval_loss: 3.15279e-02
I0212 13:18:31.557915 22542570456896 run_lib.py:133] step: 985650, training_loss: 2.54665e-02
I0212 13:18:49.048588 22542570456896 run_lib.py:133] step: 985700, training_loss: 2.99489e-02
I0212 13:18:49.209781 22542570456896 run_lib.py:146] step: 985700, eval_loss: 2.71245e-02
I0212 13:19:06.821496 22542570456896 run_lib.py:133] step: 985750, training_loss: 2.46478e-02
I0212 13:19:24.283941 22542570456896 run_lib.py:133] step: 985800, training_loss: 2.22025e-02
I0212 13:19:24.453825 22542570456896 run_lib.py:146] step: 985800, eval_loss: 3.19800e-02
I0212 13:19:42.047002 22542570456896 run_lib.py:133] step: 985850, training_loss: 2.56366e-02
I0212 13:19:59.556575 22542570456896 run_lib.py:133] step: 985900, training_loss: 2.18968e-02
I0212 13:19:59.714672 22542570456896 run_lib.py:146] step: 985900, eval_loss: 2.89301e-02
I0212 13:20:17.191413 22542570456896 run_lib.py:133] step: 985950, training_loss: 2.18518e-02
I0212 13:20:34.647807 22542570456896 run_lib.py:133] step: 986000, training_loss: 2.34130e-02
I0212 13:20:34.809437 22542570456896 run_lib.py:146] step: 986000, eval_loss: 4.31035e-02
I0212 13:20:52.440645 22542570456896 run_lib.py:133] step: 986050, training_loss: 2.47946e-02
I0212 13:21:10.020172 22542570456896 run_lib.py:133] step: 986100, training_loss: 3.21468e-02
I0212 13:21:10.189759 22542570456896 run_lib.py:146] step: 986100, eval_loss: 2.79893e-02
I0212 13:21:27.713401 22542570456896 run_lib.py:133] step: 986150, training_loss: 2.61678e-02
I0212 13:21:45.200681 22542570456896 run_lib.py:133] step: 986200, training_loss: 2.41550e-02
I0212 13:21:45.367382 22542570456896 run_lib.py:146] step: 986200, eval_loss: 2.62390e-02
I0212 13:22:03.018740 22542570456896 run_lib.py:133] step: 986250, training_loss: 2.68202e-02
I0212 13:22:20.472018 22542570456896 run_lib.py:133] step: 986300, training_loss: 3.75720e-02
I0212 13:22:20.628543 22542570456896 run_lib.py:146] step: 986300, eval_loss: 2.47553e-02
I0212 13:22:38.240869 22542570456896 run_lib.py:133] step: 986350, training_loss: 3.15287e-02
I0212 13:22:55.730782 22542570456896 run_lib.py:133] step: 986400, training_loss: 2.33526e-02
I0212 13:22:55.886758 22542570456896 run_lib.py:146] step: 986400, eval_loss: 3.60638e-02
I0212 13:23:13.579332 22542570456896 run_lib.py:133] step: 986450, training_loss: 2.66848e-02
I0212 13:23:31.053452 22542570456896 run_lib.py:133] step: 986500, training_loss: 2.44754e-02
I0212 13:23:31.202701 22542570456896 run_lib.py:146] step: 986500, eval_loss: 2.87146e-02
I0212 13:23:48.854056 22542570456896 run_lib.py:133] step: 986550, training_loss: 2.72944e-02
I0212 13:24:06.346898 22542570456896 run_lib.py:133] step: 986600, training_loss: 2.20654e-02
I0212 13:24:06.503725 22542570456896 run_lib.py:146] step: 986600, eval_loss: 3.11594e-02
I0212 13:24:23.959054 22542570456896 run_lib.py:133] step: 986650, training_loss: 2.35034e-02
I0212 13:24:41.585670 22542570456896 run_lib.py:133] step: 986700, training_loss: 2.34663e-02
I0212 13:24:41.760416 22542570456896 run_lib.py:146] step: 986700, eval_loss: 2.81863e-02
I0212 13:24:59.250208 22542570456896 run_lib.py:133] step: 986750, training_loss: 2.63379e-02
I0212 13:25:16.738963 22542570456896 run_lib.py:133] step: 986800, training_loss: 2.37958e-02
I0212 13:25:16.899103 22542570456896 run_lib.py:146] step: 986800, eval_loss: 2.64183e-02
I0212 13:25:34.596104 22542570456896 run_lib.py:133] step: 986850, training_loss: 2.57495e-02
I0212 13:25:52.203205 22542570456896 run_lib.py:133] step: 986900, training_loss: 3.10007e-02
I0212 13:25:52.360571 22542570456896 run_lib.py:146] step: 986900, eval_loss: 2.28737e-02
I0212 13:26:09.809473 22542570456896 run_lib.py:133] step: 986950, training_loss: 2.83777e-02
I0212 13:26:27.314498 22542570456896 run_lib.py:133] step: 987000, training_loss: 3.14488e-02
I0212 13:26:27.471747 22542570456896 run_lib.py:146] step: 987000, eval_loss: 3.16617e-02
I0212 13:26:44.984178 22542570456896 run_lib.py:133] step: 987050, training_loss: 2.32664e-02
I0212 13:27:02.677846 22542570456896 run_lib.py:133] step: 987100, training_loss: 3.55610e-02
I0212 13:27:02.838461 22542570456896 run_lib.py:146] step: 987100, eval_loss: 3.26099e-02
I0212 13:27:20.299785 22542570456896 run_lib.py:133] step: 987150, training_loss: 3.21682e-02
I0212 13:27:37.749327 22542570456896 run_lib.py:133] step: 987200, training_loss: 2.44929e-02
I0212 13:27:37.911454 22542570456896 run_lib.py:146] step: 987200, eval_loss: 3.46874e-02
I0212 13:27:55.384648 22542570456896 run_lib.py:133] step: 987250, training_loss: 2.78552e-02
I0212 13:28:13.088078 22542570456896 run_lib.py:133] step: 987300, training_loss: 2.58668e-02
I0212 13:28:13.250179 22542570456896 run_lib.py:146] step: 987300, eval_loss: 2.51396e-02
I0212 13:28:30.747009 22542570456896 run_lib.py:133] step: 987350, training_loss: 2.67253e-02
I0212 13:28:48.294971 22542570456896 run_lib.py:133] step: 987400, training_loss: 2.51431e-02
I0212 13:28:48.449117 22542570456896 run_lib.py:146] step: 987400, eval_loss: 2.42426e-02
I0212 13:29:05.926763 22542570456896 run_lib.py:133] step: 987450, training_loss: 2.93213e-02
I0212 13:29:23.435336 22542570456896 run_lib.py:133] step: 987500, training_loss: 2.71532e-02
I0212 13:29:23.593646 22542570456896 run_lib.py:146] step: 987500, eval_loss: 2.99229e-02
I0212 13:29:41.263839 22542570456896 run_lib.py:133] step: 987550, training_loss: 2.98235e-02
I0212 13:29:58.885107 22542570456896 run_lib.py:133] step: 987600, training_loss: 2.91175e-02
I0212 13:29:59.043249 22542570456896 run_lib.py:146] step: 987600, eval_loss: 2.81943e-02
I0212 13:30:16.506914 22542570456896 run_lib.py:133] step: 987650, training_loss: 2.85626e-02
I0212 13:30:33.948668 22542570456896 run_lib.py:133] step: 987700, training_loss: 2.18836e-02
I0212 13:30:34.115381 22542570456896 run_lib.py:146] step: 987700, eval_loss: 3.22485e-02
I0212 13:30:51.737000 22542570456896 run_lib.py:133] step: 987750, training_loss: 3.06735e-02
I0212 13:31:09.179280 22542570456896 run_lib.py:133] step: 987800, training_loss: 2.42156e-02
I0212 13:31:09.335375 22542570456896 run_lib.py:146] step: 987800, eval_loss: 3.05651e-02
I0212 13:31:26.996865 22542570456896 run_lib.py:133] step: 987850, training_loss: 2.30973e-02
I0212 13:31:44.486607 22542570456896 run_lib.py:133] step: 987900, training_loss: 2.19873e-02
I0212 13:31:44.648601 22542570456896 run_lib.py:146] step: 987900, eval_loss: 3.30274e-02
I0212 13:32:02.333282 22542570456896 run_lib.py:133] step: 987950, training_loss: 2.24089e-02
I0212 13:32:19.816980 22542570456896 run_lib.py:133] step: 988000, training_loss: 2.98820e-02
I0212 13:32:19.979923 22542570456896 run_lib.py:146] step: 988000, eval_loss: 2.61362e-02
I0212 13:32:37.449399 22542570456896 run_lib.py:133] step: 988050, training_loss: 2.84298e-02
I0212 13:32:55.061235 22542570456896 run_lib.py:133] step: 988100, training_loss: 2.97360e-02
I0212 13:32:55.229416 22542570456896 run_lib.py:146] step: 988100, eval_loss: 3.16463e-02
I0212 13:33:12.714221 22542570456896 run_lib.py:133] step: 988150, training_loss: 2.74460e-02
I0212 13:33:30.429921 22542570456896 run_lib.py:133] step: 988200, training_loss: 4.06442e-02
I0212 13:33:30.587737 22542570456896 run_lib.py:146] step: 988200, eval_loss: 2.94409e-02
I0212 13:33:48.087324 22542570456896 run_lib.py:133] step: 988250, training_loss: 2.80593e-02
I0212 13:34:05.565435 22542570456896 run_lib.py:133] step: 988300, training_loss: 2.92522e-02
I0212 13:34:05.724423 22542570456896 run_lib.py:146] step: 988300, eval_loss: 2.91327e-02
I0212 13:34:23.317585 22542570456896 run_lib.py:133] step: 988350, training_loss: 2.63155e-02
I0212 13:34:40.803942 22542570456896 run_lib.py:133] step: 988400, training_loss: 2.84581e-02
I0212 13:34:40.957619 22542570456896 run_lib.py:146] step: 988400, eval_loss: 3.71207e-02
I0212 13:34:58.538377 22542570456896 run_lib.py:133] step: 988450, training_loss: 3.02441e-02
I0212 13:35:16.206900 22542570456896 run_lib.py:133] step: 988500, training_loss: 2.94407e-02
I0212 13:35:16.364497 22542570456896 run_lib.py:146] step: 988500, eval_loss: 3.11411e-02
I0212 13:35:33.809518 22542570456896 run_lib.py:133] step: 988550, training_loss: 2.93516e-02
I0212 13:35:51.270650 22542570456896 run_lib.py:133] step: 988600, training_loss: 2.37877e-02
I0212 13:35:51.428687 22542570456896 run_lib.py:146] step: 988600, eval_loss: 4.09932e-02
I0212 13:36:09.005446 22542570456896 run_lib.py:133] step: 988650, training_loss: 2.12871e-02
I0212 13:36:26.526759 22542570456896 run_lib.py:133] step: 988700, training_loss: 2.69901e-02
I0212 13:36:26.684176 22542570456896 run_lib.py:146] step: 988700, eval_loss: 3.34990e-02
I0212 13:36:44.167391 22542570456896 run_lib.py:133] step: 988750, training_loss: 2.82760e-02
I0212 13:37:01.620245 22542570456896 run_lib.py:133] step: 988800, training_loss: 2.98080e-02
I0212 13:37:01.776502 22542570456896 run_lib.py:146] step: 988800, eval_loss: 3.41668e-02
I0212 13:37:19.433722 22542570456896 run_lib.py:133] step: 988850, training_loss: 2.49179e-02
I0212 13:37:36.972123 22542570456896 run_lib.py:133] step: 988900, training_loss: 2.74910e-02
I0212 13:37:37.122737 22542570456896 run_lib.py:146] step: 988900, eval_loss: 3.15921e-02
I0212 13:37:54.560355 22542570456896 run_lib.py:133] step: 988950, training_loss: 2.76504e-02
I0212 13:38:12.070729 22542570456896 run_lib.py:133] step: 989000, training_loss: 2.52538e-02
I0212 13:38:12.251505 22542570456896 run_lib.py:146] step: 989000, eval_loss: 3.41112e-02
I0212 13:38:29.977774 22542570456896 run_lib.py:133] step: 989050, training_loss: 3.15249e-02
I0212 13:38:47.445062 22542570456896 run_lib.py:133] step: 989100, training_loss: 2.09780e-02
I0212 13:38:47.608328 22542570456896 run_lib.py:146] step: 989100, eval_loss: 2.64540e-02
I0212 13:39:05.214859 22542570456896 run_lib.py:133] step: 989150, training_loss: 2.79883e-02
I0212 13:39:22.626910 22542570456896 run_lib.py:133] step: 989200, training_loss: 2.86930e-02
I0212 13:39:22.784112 22542570456896 run_lib.py:146] step: 989200, eval_loss: 3.35313e-02
I0212 13:39:40.415143 22542570456896 run_lib.py:133] step: 989250, training_loss: 3.21442e-02
I0212 13:39:57.911255 22542570456896 run_lib.py:133] step: 989300, training_loss: 2.19356e-02
I0212 13:39:58.072311 22542570456896 run_lib.py:146] step: 989300, eval_loss: 2.93154e-02
I0212 13:40:15.668701 22542570456896 run_lib.py:133] step: 989350, training_loss: 2.71536e-02
I0212 13:40:33.004732 22542570456896 run_lib.py:133] step: 989400, training_loss: 2.87207e-02
I0212 13:40:33.158631 22542570456896 run_lib.py:146] step: 989400, eval_loss: 2.24414e-02
I0212 13:40:50.516334 22542570456896 run_lib.py:133] step: 989450, training_loss: 2.98558e-02
I0212 13:41:07.975999 22542570456896 run_lib.py:133] step: 989500, training_loss: 2.33977e-02
I0212 13:41:08.138362 22542570456896 run_lib.py:146] step: 989500, eval_loss: 3.53066e-02
I0212 13:41:25.504138 22542570456896 run_lib.py:133] step: 989550, training_loss: 2.56103e-02
I0212 13:41:42.891881 22542570456896 run_lib.py:133] step: 989600, training_loss: 2.54685e-02
I0212 13:41:43.049640 22542570456896 run_lib.py:146] step: 989600, eval_loss: 2.80211e-02
I0212 13:42:00.598770 22542570456896 run_lib.py:133] step: 989650, training_loss: 2.55939e-02
I0212 13:42:17.916646 22542570456896 run_lib.py:133] step: 989700, training_loss: 2.83384e-02
I0212 13:42:18.072865 22542570456896 run_lib.py:146] step: 989700, eval_loss: 3.40531e-02
I0212 13:42:35.694877 22542570456896 run_lib.py:133] step: 989750, training_loss: 2.76729e-02
I0212 13:42:53.177186 22542570456896 run_lib.py:133] step: 989800, training_loss: 2.17604e-02
I0212 13:42:53.332726 22542570456896 run_lib.py:146] step: 989800, eval_loss: 2.90752e-02
I0212 13:43:10.890592 22542570456896 run_lib.py:133] step: 989850, training_loss: 3.08340e-02
I0212 13:43:28.570600 22542570456896 run_lib.py:133] step: 989900, training_loss: 3.09753e-02
I0212 13:43:28.727205 22542570456896 run_lib.py:146] step: 989900, eval_loss: 2.30826e-02
I0212 13:43:46.186790 22542570456896 run_lib.py:133] step: 989950, training_loss: 2.85375e-02
I0212 13:44:03.691144 22542570456896 run_lib.py:133] step: 990000, training_loss: 2.98971e-02
I0212 13:44:04.490513 22542570456896 run_lib.py:146] step: 990000, eval_loss: 2.34849e-02
I0212 13:44:24.578468 22542570456896 run_lib.py:133] step: 990050, training_loss: 2.29379e-02
I0212 13:44:42.065214 22542570456896 run_lib.py:133] step: 990100, training_loss: 2.27438e-02
I0212 13:44:42.238511 22542570456896 run_lib.py:146] step: 990100, eval_loss: 3.00560e-02
I0212 13:44:59.925171 22542570456896 run_lib.py:133] step: 990150, training_loss: 3.22730e-02
I0212 13:45:17.439570 22542570456896 run_lib.py:133] step: 990200, training_loss: 2.98609e-02
I0212 13:45:17.596465 22542570456896 run_lib.py:146] step: 990200, eval_loss: 3.31084e-02
I0212 13:45:35.190615 22542570456896 run_lib.py:133] step: 990250, training_loss: 2.04169e-02
I0212 13:45:52.627260 22542570456896 run_lib.py:133] step: 990300, training_loss: 2.36200e-02
I0212 13:45:52.782129 22542570456896 run_lib.py:146] step: 990300, eval_loss: 2.79828e-02
I0212 13:46:10.235703 22542570456896 run_lib.py:133] step: 990350, training_loss: 2.72811e-02
I0212 13:46:27.769035 22542570456896 run_lib.py:133] step: 990400, training_loss: 2.11376e-02
I0212 13:46:27.937947 22542570456896 run_lib.py:146] step: 990400, eval_loss: 3.19713e-02
I0212 13:46:45.638061 22542570456896 run_lib.py:133] step: 990450, training_loss: 2.69538e-02
I0212 13:47:03.253414 22542570456896 run_lib.py:133] step: 990500, training_loss: 2.80629e-02
I0212 13:47:03.421584 22542570456896 run_lib.py:146] step: 990500, eval_loss: 2.42059e-02
I0212 13:47:20.857138 22542570456896 run_lib.py:133] step: 990550, training_loss: 3.27739e-02
I0212 13:47:38.349790 22542570456896 run_lib.py:133] step: 990600, training_loss: 2.27635e-02
I0212 13:47:38.508507 22542570456896 run_lib.py:146] step: 990600, eval_loss: 3.12814e-02
I0212 13:47:56.169873 22542570456896 run_lib.py:133] step: 990650, training_loss: 3.59927e-02
I0212 13:48:13.709171 22542570456896 run_lib.py:133] step: 990700, training_loss: 3.13957e-02
I0212 13:48:13.873576 22542570456896 run_lib.py:146] step: 990700, eval_loss: 2.97607e-02
I0212 13:48:31.567890 22542570456896 run_lib.py:133] step: 990750, training_loss: 3.01333e-02
I0212 13:48:49.038400 22542570456896 run_lib.py:133] step: 990800, training_loss: 2.98472e-02
I0212 13:48:49.191535 22542570456896 run_lib.py:146] step: 990800, eval_loss: 2.73039e-02
I0212 13:49:06.798074 22542570456896 run_lib.py:133] step: 990850, training_loss: 2.40680e-02
I0212 13:49:24.266551 22542570456896 run_lib.py:133] step: 990900, training_loss: 2.42443e-02
I0212 13:49:24.433789 22542570456896 run_lib.py:146] step: 990900, eval_loss: 2.59612e-02
I0212 13:49:42.097631 22542570456896 run_lib.py:133] step: 990950, training_loss: 3.61830e-02
I0212 13:49:59.647938 22542570456896 run_lib.py:133] step: 991000, training_loss: 2.34720e-02
I0212 13:49:59.807429 22542570456896 run_lib.py:146] step: 991000, eval_loss: 3.06541e-02
I0212 13:50:17.257292 22542570456896 run_lib.py:133] step: 991050, training_loss: 3.83191e-02
I0212 13:50:34.906768 22542570456896 run_lib.py:133] step: 991100, training_loss: 2.09998e-02
I0212 13:50:35.063428 22542570456896 run_lib.py:146] step: 991100, eval_loss: 2.66169e-02
I0212 13:50:52.549803 22542570456896 run_lib.py:133] step: 991150, training_loss: 2.89251e-02
I0212 13:51:10.040320 22542570456896 run_lib.py:133] step: 991200, training_loss: 2.67350e-02
I0212 13:51:10.195667 22542570456896 run_lib.py:146] step: 991200, eval_loss: 3.26240e-02
I0212 13:51:27.881945 22542570456896 run_lib.py:133] step: 991250, training_loss: 3.41258e-02
I0212 13:51:45.554774 22542570456896 run_lib.py:133] step: 991300, training_loss: 2.40615e-02
I0212 13:51:45.716486 22542570456896 run_lib.py:146] step: 991300, eval_loss: 3.11541e-02
I0212 13:52:03.176134 22542570456896 run_lib.py:133] step: 991350, training_loss: 2.89042e-02
I0212 13:52:20.681359 22542570456896 run_lib.py:133] step: 991400, training_loss: 3.37836e-02
I0212 13:52:20.838238 22542570456896 run_lib.py:146] step: 991400, eval_loss: 3.03427e-02
I0212 13:52:38.303754 22542570456896 run_lib.py:133] step: 991450, training_loss: 3.28266e-02
I0212 13:52:55.997509 22542570456896 run_lib.py:133] step: 991500, training_loss: 2.47693e-02
I0212 13:52:56.174543 22542570456896 run_lib.py:146] step: 991500, eval_loss: 3.12295e-02
I0212 13:53:13.671123 22542570456896 run_lib.py:133] step: 991550, training_loss: 2.42734e-02
I0212 13:53:31.155542 22542570456896 run_lib.py:133] step: 991600, training_loss: 2.43469e-02
I0212 13:53:31.318867 22542570456896 run_lib.py:146] step: 991600, eval_loss: 3.25727e-02
I0212 13:53:48.826449 22542570456896 run_lib.py:133] step: 991650, training_loss: 2.40625e-02
I0212 13:54:06.482568 22542570456896 run_lib.py:133] step: 991700, training_loss: 2.56567e-02
I0212 13:54:06.639599 22542570456896 run_lib.py:146] step: 991700, eval_loss: 2.47120e-02
I0212 13:54:24.126921 22542570456896 run_lib.py:133] step: 991750, training_loss: 2.56459e-02
I0212 13:54:41.734311 22542570456896 run_lib.py:133] step: 991800, training_loss: 2.76437e-02
I0212 13:54:41.899637 22542570456896 run_lib.py:146] step: 991800, eval_loss: 2.40770e-02
I0212 13:54:59.411934 22542570456896 run_lib.py:133] step: 991850, training_loss: 2.59770e-02
I0212 13:55:16.903974 22542570456896 run_lib.py:133] step: 991900, training_loss: 2.57641e-02
I0212 13:55:17.065960 22542570456896 run_lib.py:146] step: 991900, eval_loss: 2.98994e-02
I0212 13:55:34.672245 22542570456896 run_lib.py:133] step: 991950, training_loss: 3.20070e-02
I0212 13:55:52.230753 22542570456896 run_lib.py:133] step: 992000, training_loss: 2.37289e-02
I0212 13:55:52.388538 22542570456896 run_lib.py:146] step: 992000, eval_loss: 2.96527e-02
I0212 13:56:09.881457 22542570456896 run_lib.py:133] step: 992050, training_loss: 2.32038e-02
I0212 13:56:27.460215 22542570456896 run_lib.py:133] step: 992100, training_loss: 2.63344e-02
I0212 13:56:27.626241 22542570456896 run_lib.py:146] step: 992100, eval_loss: 3.33585e-02
I0212 13:56:45.328971 22542570456896 run_lib.py:133] step: 992150, training_loss: 1.84727e-02
I0212 13:57:02.776169 22542570456896 run_lib.py:133] step: 992200, training_loss: 2.14506e-02
I0212 13:57:02.931436 22542570456896 run_lib.py:146] step: 992200, eval_loss: 3.01379e-02
I0212 13:57:20.533671 22542570456896 run_lib.py:133] step: 992250, training_loss: 3.05052e-02
I0212 13:57:38.000115 22542570456896 run_lib.py:133] step: 992300, training_loss: 2.79465e-02
I0212 13:57:38.165704 22542570456896 run_lib.py:146] step: 992300, eval_loss: 2.72627e-02
I0212 13:57:55.908135 22542570456896 run_lib.py:133] step: 992350, training_loss: 3.32954e-02
I0212 13:58:13.405575 22542570456896 run_lib.py:133] step: 992400, training_loss: 2.92914e-02
I0212 13:58:13.564754 22542570456896 run_lib.py:146] step: 992400, eval_loss: 3.46055e-02
I0212 13:58:31.029265 22542570456896 run_lib.py:133] step: 992450, training_loss: 3.39523e-02
I0212 13:58:48.661771 22542570456896 run_lib.py:133] step: 992500, training_loss: 2.84090e-02
I0212 13:58:48.825500 22542570456896 run_lib.py:146] step: 992500, eval_loss: 3.38561e-02
I0212 13:59:06.379621 22542570456896 run_lib.py:133] step: 992550, training_loss: 2.72698e-02
I0212 13:59:24.048519 22542570456896 run_lib.py:133] step: 992600, training_loss: 2.32086e-02
I0212 13:59:24.213311 22542570456896 run_lib.py:146] step: 992600, eval_loss: 3.34689e-02
I0212 13:59:41.722373 22542570456896 run_lib.py:133] step: 992650, training_loss: 2.60469e-02
I0212 13:59:59.189881 22542570456896 run_lib.py:133] step: 992700, training_loss: 2.80164e-02
I0212 13:59:59.344465 22542570456896 run_lib.py:146] step: 992700, eval_loss: 2.16817e-02
I0212 14:00:17.030085 22542570456896 run_lib.py:133] step: 992750, training_loss: 2.57995e-02
I0212 14:00:34.492270 22542570456896 run_lib.py:133] step: 992800, training_loss: 2.55330e-02
I0212 14:00:34.646796 22542570456896 run_lib.py:146] step: 992800, eval_loss: 3.07668e-02
I0212 14:00:52.114205 22542570456896 run_lib.py:133] step: 992850, training_loss: 3.44129e-02
I0212 14:01:09.797546 22542570456896 run_lib.py:133] step: 992900, training_loss: 2.91866e-02
I0212 14:01:09.973450 22542570456896 run_lib.py:146] step: 992900, eval_loss: 2.79482e-02
I0212 14:01:27.499332 22542570456896 run_lib.py:133] step: 992950, training_loss: 1.93447e-02
I0212 14:01:44.955822 22542570456896 run_lib.py:133] step: 993000, training_loss: 2.87223e-02
I0212 14:01:45.113749 22542570456896 run_lib.py:146] step: 993000, eval_loss: 3.29490e-02
I0212 14:02:02.677826 22542570456896 run_lib.py:133] step: 993050, training_loss: 2.41782e-02
I0212 14:02:20.137990 22542570456896 run_lib.py:133] step: 993100, training_loss: 2.63569e-02
I0212 14:02:20.298449 22542570456896 run_lib.py:146] step: 993100, eval_loss: 2.83724e-02
I0212 14:02:37.770130 22542570456896 run_lib.py:133] step: 993150, training_loss: 2.83574e-02
I0212 14:02:55.297930 22542570456896 run_lib.py:133] step: 993200, training_loss: 2.58275e-02
I0212 14:02:55.455639 22542570456896 run_lib.py:146] step: 993200, eval_loss: 2.66107e-02
I0212 14:03:13.143691 22542570456896 run_lib.py:133] step: 993250, training_loss: 2.43473e-02
I0212 14:03:30.692236 22542570456896 run_lib.py:133] step: 993300, training_loss: 2.82211e-02
I0212 14:03:30.849439 22542570456896 run_lib.py:146] step: 993300, eval_loss: 3.27255e-02
I0212 14:03:48.312923 22542570456896 run_lib.py:133] step: 993350, training_loss: 2.78710e-02
I0212 14:04:05.786730 22542570456896 run_lib.py:133] step: 993400, training_loss: 2.36444e-02
I0212 14:04:05.954405 22542570456896 run_lib.py:146] step: 993400, eval_loss: 2.66489e-02
I0212 14:04:23.611849 22542570456896 run_lib.py:133] step: 993450, training_loss: 2.29956e-02
I0212 14:04:41.116231 22542570456896 run_lib.py:133] step: 993500, training_loss: 2.08068e-02
I0212 14:04:41.273796 22542570456896 run_lib.py:146] step: 993500, eval_loss: 2.45456e-02
I0212 14:04:58.951110 22542570456896 run_lib.py:133] step: 993550, training_loss: 2.65669e-02
I0212 14:05:16.406985 22542570456896 run_lib.py:133] step: 993600, training_loss: 2.51708e-02
I0212 14:05:16.561199 22542570456896 run_lib.py:146] step: 993600, eval_loss: 2.86694e-02
I0212 14:05:34.169235 22542570456896 run_lib.py:133] step: 993650, training_loss: 2.57184e-02
I0212 14:05:51.665329 22542570456896 run_lib.py:133] step: 993700, training_loss: 3.04463e-02
I0212 14:05:51.821722 22542570456896 run_lib.py:146] step: 993700, eval_loss: 2.54317e-02
I0212 14:06:09.577538 22542570456896 run_lib.py:133] step: 993750, training_loss: 3.27490e-02
I0212 14:06:27.088634 22542570456896 run_lib.py:133] step: 993800, training_loss: 2.99781e-02
I0212 14:06:27.249906 22542570456896 run_lib.py:146] step: 993800, eval_loss: 2.65801e-02
I0212 14:06:44.698782 22542570456896 run_lib.py:133] step: 993850, training_loss: 3.68300e-02
I0212 14:07:02.302803 22542570456896 run_lib.py:133] step: 993900, training_loss: 2.78743e-02
I0212 14:07:02.459702 22542570456896 run_lib.py:146] step: 993900, eval_loss: 3.53787e-02
I0212 14:07:19.931970 22542570456896 run_lib.py:133] step: 993950, training_loss: 2.36115e-02
I0212 14:07:37.440191 22542570456896 run_lib.py:133] step: 994000, training_loss: 2.55229e-02
I0212 14:07:37.594570 22542570456896 run_lib.py:146] step: 994000, eval_loss: 2.99653e-02
I0212 14:07:55.281058 22542570456896 run_lib.py:133] step: 994050, training_loss: 2.38302e-02
I0212 14:08:12.777246 22542570456896 run_lib.py:133] step: 994100, training_loss: 2.83885e-02
I0212 14:08:12.931637 22542570456896 run_lib.py:146] step: 994100, eval_loss: 2.99524e-02
I0212 14:08:30.579980 22542570456896 run_lib.py:133] step: 994150, training_loss: 2.61347e-02
I0212 14:08:48.073516 22542570456896 run_lib.py:133] step: 994200, training_loss: 2.38610e-02
I0212 14:08:48.228467 22542570456896 run_lib.py:146] step: 994200, eval_loss: 2.88388e-02
I0212 14:09:05.674829 22542570456896 run_lib.py:133] step: 994250, training_loss: 2.58064e-02
I0212 14:09:23.347086 22542570456896 run_lib.py:133] step: 994300, training_loss: 2.65476e-02
I0212 14:09:23.528486 22542570456896 run_lib.py:146] step: 994300, eval_loss: 3.18126e-02
I0212 14:09:41.023884 22542570456896 run_lib.py:133] step: 994350, training_loss: 2.46875e-02
I0212 14:09:58.509974 22542570456896 run_lib.py:133] step: 994400, training_loss: 2.46745e-02
I0212 14:09:58.667700 22542570456896 run_lib.py:146] step: 994400, eval_loss: 3.02237e-02
I0212 14:10:16.159483 22542570456896 run_lib.py:133] step: 994450, training_loss: 3.00374e-02
I0212 14:10:33.726452 22542570456896 run_lib.py:133] step: 994500, training_loss: 2.95366e-02
I0212 14:10:33.888648 22542570456896 run_lib.py:146] step: 994500, eval_loss: 2.37431e-02
I0212 14:10:51.248531 22542570456896 run_lib.py:133] step: 994550, training_loss: 2.35799e-02
I0212 14:11:08.715991 22542570456896 run_lib.py:133] step: 994600, training_loss: 2.64845e-02
I0212 14:11:08.870217 22542570456896 run_lib.py:146] step: 994600, eval_loss: 2.83433e-02
I0212 14:11:26.274754 22542570456896 run_lib.py:133] step: 994650, training_loss: 2.88259e-02
I0212 14:11:43.739777 22542570456896 run_lib.py:133] step: 994700, training_loss: 2.91066e-02
I0212 14:11:43.895505 22542570456896 run_lib.py:146] step: 994700, eval_loss: 2.47571e-02
I0212 14:12:01.459496 22542570456896 run_lib.py:133] step: 994750, training_loss: 2.61929e-02
I0212 14:12:18.939375 22542570456896 run_lib.py:133] step: 994800, training_loss: 3.08146e-02
I0212 14:12:19.103378 22542570456896 run_lib.py:146] step: 994800, eval_loss: 2.75224e-02
I0212 14:12:36.527717 22542570456896 run_lib.py:133] step: 994850, training_loss: 2.76650e-02
I0212 14:12:53.985240 22542570456896 run_lib.py:133] step: 994900, training_loss: 2.78096e-02
I0212 14:12:54.143729 22542570456896 run_lib.py:146] step: 994900, eval_loss: 1.97498e-02
I0212 14:13:11.822562 22542570456896 run_lib.py:133] step: 994950, training_loss: 2.89716e-02
I0212 14:13:29.250603 22542570456896 run_lib.py:133] step: 995000, training_loss: 3.22092e-02
I0212 14:13:29.409541 22542570456896 run_lib.py:146] step: 995000, eval_loss: 3.36794e-02
I0212 14:13:47.047585 22542570456896 run_lib.py:133] step: 995050, training_loss: 2.33885e-02
I0212 14:14:04.578594 22542570456896 run_lib.py:133] step: 995100, training_loss: 2.49596e-02
I0212 14:14:04.734694 22542570456896 run_lib.py:146] step: 995100, eval_loss: 2.67621e-02
I0212 14:14:22.417933 22542570456896 run_lib.py:133] step: 995150, training_loss: 2.41065e-02
I0212 14:14:39.906663 22542570456896 run_lib.py:133] step: 995200, training_loss: 2.76459e-02
I0212 14:14:40.064785 22542570456896 run_lib.py:146] step: 995200, eval_loss: 3.36225e-02
I0212 14:14:57.533902 22542570456896 run_lib.py:133] step: 995250, training_loss: 3.10340e-02
I0212 14:15:15.191199 22542570456896 run_lib.py:133] step: 995300, training_loss: 2.31171e-02
I0212 14:15:15.350665 22542570456896 run_lib.py:146] step: 995300, eval_loss: 2.88195e-02
I0212 14:15:32.812863 22542570456896 run_lib.py:133] step: 995350, training_loss: 2.91529e-02
I0212 14:15:50.443584 22542570456896 run_lib.py:133] step: 995400, training_loss: 2.59927e-02
I0212 14:15:50.609229 22542570456896 run_lib.py:146] step: 995400, eval_loss: 3.41972e-02
I0212 14:16:08.096145 22542570456896 run_lib.py:133] step: 995450, training_loss: 2.74571e-02
I0212 14:16:25.583809 22542570456896 run_lib.py:133] step: 995500, training_loss: 2.99578e-02
I0212 14:16:25.738372 22542570456896 run_lib.py:146] step: 995500, eval_loss: 3.15120e-02
I0212 14:16:43.398470 22542570456896 run_lib.py:133] step: 995550, training_loss: 2.38723e-02
I0212 14:17:00.908374 22542570456896 run_lib.py:133] step: 995600, training_loss: 2.97639e-02
I0212 14:17:01.062636 22542570456896 run_lib.py:146] step: 995600, eval_loss: 2.72112e-02
I0212 14:17:18.549134 22542570456896 run_lib.py:133] step: 995650, training_loss: 2.46111e-02
I0212 14:17:36.192761 22542570456896 run_lib.py:133] step: 995700, training_loss: 3.07960e-02
I0212 14:17:36.374469 22542570456896 run_lib.py:146] step: 995700, eval_loss: 3.09280e-02
I0212 14:17:53.889300 22542570456896 run_lib.py:133] step: 995750, training_loss: 2.98650e-02
I0212 14:18:11.360745 22542570456896 run_lib.py:133] step: 995800, training_loss: 2.62534e-02
I0212 14:18:11.718573 22542570456896 run_lib.py:146] step: 995800, eval_loss: 2.59148e-02
I0212 14:18:29.195494 22542570456896 run_lib.py:133] step: 995850, training_loss: 2.55581e-02
I0212 14:18:46.648550 22542570456896 run_lib.py:133] step: 995900, training_loss: 3.13176e-02
I0212 14:18:46.807537 22542570456896 run_lib.py:146] step: 995900, eval_loss: 2.72781e-02
I0212 14:19:04.255109 22542570456896 run_lib.py:133] step: 995950, training_loss: 3.21610e-02
I0212 14:19:21.814857 22542570456896 run_lib.py:133] step: 996000, training_loss: 2.84462e-02
I0212 14:19:21.968411 22542570456896 run_lib.py:146] step: 996000, eval_loss: 3.06139e-02
I0212 14:19:39.637347 22542570456896 run_lib.py:133] step: 996050, training_loss: 2.60409e-02
I0212 14:19:57.202126 22542570456896 run_lib.py:133] step: 996100, training_loss: 2.60420e-02
I0212 14:19:57.359511 22542570456896 run_lib.py:146] step: 996100, eval_loss: 3.17563e-02
I0212 14:20:14.812364 22542570456896 run_lib.py:133] step: 996150, training_loss: 2.67460e-02
I0212 14:20:32.304523 22542570456896 run_lib.py:133] step: 996200, training_loss: 2.78669e-02
I0212 14:20:32.472632 22542570456896 run_lib.py:146] step: 996200, eval_loss: 2.32639e-02
I0212 14:20:50.169771 22542570456896 run_lib.py:133] step: 996250, training_loss: 2.66693e-02
I0212 14:21:07.779756 22542570456896 run_lib.py:133] step: 996300, training_loss: 2.10295e-02
I0212 14:21:07.935699 22542570456896 run_lib.py:146] step: 996300, eval_loss: 3.52425e-02
I0212 14:21:25.367566 22542570456896 run_lib.py:133] step: 996350, training_loss: 2.35364e-02
I0212 14:21:42.823640 22542570456896 run_lib.py:133] step: 996400, training_loss: 2.79565e-02
I0212 14:21:42.980511 22542570456896 run_lib.py:146] step: 996400, eval_loss: 2.51493e-02
I0212 14:22:00.606343 22542570456896 run_lib.py:133] step: 996450, training_loss: 2.84276e-02
I0212 14:22:18.066164 22542570456896 run_lib.py:133] step: 996500, training_loss: 3.12372e-02
I0212 14:22:18.219582 22542570456896 run_lib.py:146] step: 996500, eval_loss: 2.62507e-02
I0212 14:22:35.833194 22542570456896 run_lib.py:133] step: 996550, training_loss: 2.57438e-02
I0212 14:22:53.322430 22542570456896 run_lib.py:133] step: 996600, training_loss: 2.69220e-02
I0212 14:22:53.489641 22542570456896 run_lib.py:146] step: 996600, eval_loss: 3.10175e-02
I0212 14:23:11.234214 22542570456896 run_lib.py:133] step: 996650, training_loss: 2.98288e-02
I0212 14:23:28.722501 22542570456896 run_lib.py:133] step: 996700, training_loss: 2.63202e-02
I0212 14:23:28.889733 22542570456896 run_lib.py:146] step: 996700, eval_loss: 2.93703e-02
I0212 14:23:46.377676 22542570456896 run_lib.py:133] step: 996750, training_loss: 2.74578e-02
I0212 14:24:03.993004 22542570456896 run_lib.py:133] step: 996800, training_loss: 3.55232e-02
I0212 14:24:04.150465 22542570456896 run_lib.py:146] step: 996800, eval_loss: 2.16304e-02
I0212 14:24:21.681489 22542570456896 run_lib.py:133] step: 996850, training_loss: 2.87059e-02
I0212 14:24:39.363122 22542570456896 run_lib.py:133] step: 996900, training_loss: 2.35654e-02
I0212 14:24:39.523748 22542570456896 run_lib.py:146] step: 996900, eval_loss: 2.52369e-02
I0212 14:24:57.004326 22542570456896 run_lib.py:133] step: 996950, training_loss: 2.42614e-02
I0212 14:25:14.456747 22542570456896 run_lib.py:133] step: 997000, training_loss: 2.84691e-02
I0212 14:25:14.609344 22542570456896 run_lib.py:146] step: 997000, eval_loss: 2.65209e-02
I0212 14:25:32.263131 22542570456896 run_lib.py:133] step: 997050, training_loss: 2.42597e-02
I0212 14:25:49.763561 22542570456896 run_lib.py:133] step: 997100, training_loss: 3.10804e-02
I0212 14:25:49.941234 22542570456896 run_lib.py:146] step: 997100, eval_loss: 3.68222e-02
I0212 14:26:07.468372 22542570456896 run_lib.py:133] step: 997150, training_loss: 2.52713e-02
I0212 14:26:24.970384 22542570456896 run_lib.py:133] step: 997200, training_loss: 2.48946e-02
I0212 14:26:25.128733 22542570456896 run_lib.py:146] step: 997200, eval_loss: 3.22222e-02
I0212 14:26:42.813110 22542570456896 run_lib.py:133] step: 997250, training_loss: 3.06604e-02
I0212 14:27:00.279593 22542570456896 run_lib.py:133] step: 997300, training_loss: 2.41130e-02
I0212 14:27:00.436539 22542570456896 run_lib.py:146] step: 997300, eval_loss: 2.74913e-02
I0212 14:27:17.967299 22542570456896 run_lib.py:133] step: 997350, training_loss: 3.09058e-02
I0212 14:27:35.494265 22542570456896 run_lib.py:133] step: 997400, training_loss: 2.45801e-02
I0212 14:27:35.651722 22542570456896 run_lib.py:146] step: 997400, eval_loss: 2.54577e-02
I0212 14:27:53.217628 22542570456896 run_lib.py:133] step: 997450, training_loss: 2.65966e-02
I0212 14:28:10.693445 22542570456896 run_lib.py:133] step: 997500, training_loss: 2.57937e-02
I0212 14:28:10.846553 22542570456896 run_lib.py:146] step: 997500, eval_loss: 2.47661e-02
I0212 14:28:28.483135 22542570456896 run_lib.py:133] step: 997550, training_loss: 2.66366e-02
I0212 14:28:46.019881 22542570456896 run_lib.py:133] step: 997600, training_loss: 2.89151e-02
I0212 14:28:46.180880 22542570456896 run_lib.py:146] step: 997600, eval_loss: 3.42195e-02
I0212 14:29:03.683536 22542570456896 run_lib.py:133] step: 997650, training_loss: 2.79781e-02
I0212 14:29:21.280106 22542570456896 run_lib.py:133] step: 997700, training_loss: 3.52862e-02
I0212 14:29:21.437709 22542570456896 run_lib.py:146] step: 997700, eval_loss: 2.90866e-02
I0212 14:29:39.118334 22542570456896 run_lib.py:133] step: 997750, training_loss: 2.75580e-02
I0212 14:29:56.593048 22542570456896 run_lib.py:133] step: 997800, training_loss: 2.49748e-02
I0212 14:29:56.751207 22542570456896 run_lib.py:146] step: 997800, eval_loss: 2.61586e-02
I0212 14:30:14.393322 22542570456896 run_lib.py:133] step: 997850, training_loss: 2.05787e-02
I0212 14:30:31.863347 22542570456896 run_lib.py:133] step: 997900, training_loss: 3.40136e-02
I0212 14:30:32.016372 22542570456896 run_lib.py:146] step: 997900, eval_loss: 2.60042e-02
I0212 14:30:49.692257 22542570456896 run_lib.py:133] step: 997950, training_loss: 2.88271e-02
I0212 14:31:07.201947 22542570456896 run_lib.py:133] step: 998000, training_loss: 2.91173e-02
I0212 14:31:07.361675 22542570456896 run_lib.py:146] step: 998000, eval_loss: 2.92984e-02
I0212 14:31:25.035296 22542570456896 run_lib.py:133] step: 998050, training_loss: 2.79253e-02
I0212 14:31:42.526793 22542570456896 run_lib.py:133] step: 998100, training_loss: 2.77642e-02
I0212 14:31:42.686748 22542570456896 run_lib.py:146] step: 998100, eval_loss: 3.13409e-02
I0212 14:32:00.156475 22542570456896 run_lib.py:133] step: 998150, training_loss: 2.52509e-02
I0212 14:32:17.767789 22542570456896 run_lib.py:133] step: 998200, training_loss: 2.73710e-02
I0212 14:32:17.934313 22542570456896 run_lib.py:146] step: 998200, eval_loss: 3.74316e-02
I0212 14:32:35.435328 22542570456896 run_lib.py:133] step: 998250, training_loss: 2.37386e-02
I0212 14:32:52.926510 22542570456896 run_lib.py:133] step: 998300, training_loss: 2.79846e-02
I0212 14:32:53.083714 22542570456896 run_lib.py:146] step: 998300, eval_loss: 2.77622e-02
I0212 14:33:10.801170 22542570456896 run_lib.py:133] step: 998350, training_loss: 2.53973e-02
I0212 14:33:28.436044 22542570456896 run_lib.py:133] step: 998400, training_loss: 2.83395e-02
I0212 14:33:28.590571 22542570456896 run_lib.py:146] step: 998400, eval_loss: 3.19462e-02
I0212 14:33:46.052919 22542570456896 run_lib.py:133] step: 998450, training_loss: 2.72647e-02
I0212 14:34:03.508740 22542570456896 run_lib.py:133] step: 998500, training_loss: 2.57987e-02
I0212 14:34:03.676631 22542570456896 run_lib.py:146] step: 998500, eval_loss: 2.89003e-02
I0212 14:34:21.173274 22542570456896 run_lib.py:133] step: 998550, training_loss: 3.23260e-02
I0212 14:34:38.882706 22542570456896 run_lib.py:133] step: 998600, training_loss: 2.19027e-02
I0212 14:34:39.051468 22542570456896 run_lib.py:146] step: 998600, eval_loss: 2.69543e-02
I0212 14:34:56.532590 22542570456896 run_lib.py:133] step: 998650, training_loss: 2.58052e-02
I0212 14:35:14.016050 22542570456896 run_lib.py:133] step: 998700, training_loss: 2.60671e-02
I0212 14:35:14.172435 22542570456896 run_lib.py:146] step: 998700, eval_loss: 2.50646e-02
I0212 14:35:31.641965 22542570456896 run_lib.py:133] step: 998750, training_loss: 3.79404e-02
I0212 14:35:49.322155 22542570456896 run_lib.py:133] step: 998800, training_loss: 2.58033e-02
I0212 14:35:49.479089 22542570456896 run_lib.py:146] step: 998800, eval_loss: 3.57187e-02
I0212 14:36:06.959661 22542570456896 run_lib.py:133] step: 998850, training_loss: 3.14816e-02
I0212 14:36:24.527195 22542570456896 run_lib.py:133] step: 998900, training_loss: 2.64096e-02
I0212 14:36:24.680504 22542570456896 run_lib.py:146] step: 998900, eval_loss: 2.76324e-02
I0212 14:36:42.161218 22542570456896 run_lib.py:133] step: 998950, training_loss: 3.33085e-02
I0212 14:36:59.655130 22542570456896 run_lib.py:133] step: 999000, training_loss: 2.68854e-02
I0212 14:36:59.813642 22542570456896 run_lib.py:146] step: 999000, eval_loss: 3.35270e-02
I0212 14:37:17.443512 22542570456896 run_lib.py:133] step: 999050, training_loss: 2.65237e-02
I0212 14:37:35.069330 22542570456896 run_lib.py:133] step: 999100, training_loss: 1.86386e-02
I0212 14:37:35.232537 22542570456896 run_lib.py:146] step: 999100, eval_loss: 2.75097e-02
I0212 14:37:52.711306 22542570456896 run_lib.py:133] step: 999150, training_loss: 2.99790e-02
I0212 14:38:10.212745 22542570456896 run_lib.py:133] step: 999200, training_loss: 2.56654e-02
I0212 14:38:10.369732 22542570456896 run_lib.py:146] step: 999200, eval_loss: 2.87950e-02
I0212 14:38:28.015983 22542570456896 run_lib.py:133] step: 999250, training_loss: 2.62114e-02
I0212 14:38:45.465846 22542570456896 run_lib.py:133] step: 999300, training_loss: 2.25801e-02
I0212 14:38:45.621448 22542570456896 run_lib.py:146] step: 999300, eval_loss: 2.34262e-02
I0212 14:39:03.256972 22542570456896 run_lib.py:133] step: 999350, training_loss: 2.42344e-02
I0212 14:39:20.761727 22542570456896 run_lib.py:133] step: 999400, training_loss: 3.42316e-02
I0212 14:39:20.918627 22542570456896 run_lib.py:146] step: 999400, eval_loss: 2.19453e-02
I0212 14:39:38.592844 22542570456896 run_lib.py:133] step: 999450, training_loss: 3.29545e-02
I0212 14:39:56.077217 22542570456896 run_lib.py:133] step: 999500, training_loss: 2.58232e-02
I0212 14:39:56.242016 22542570456896 run_lib.py:146] step: 999500, eval_loss: 2.90857e-02
I0212 14:40:13.689530 22542570456896 run_lib.py:133] step: 999550, training_loss: 3.56407e-02
I0212 14:40:31.313802 22542570456896 run_lib.py:133] step: 999600, training_loss: 2.60284e-02
I0212 14:40:31.475627 22542570456896 run_lib.py:146] step: 999600, eval_loss: 2.42824e-02
I0212 14:40:48.960276 22542570456896 run_lib.py:133] step: 999650, training_loss: 2.36198e-02
I0212 14:41:06.547975 22542570456896 run_lib.py:133] step: 999700, training_loss: 2.56652e-02
I0212 14:41:06.704317 22542570456896 run_lib.py:146] step: 999700, eval_loss: 3.25597e-02
I0212 14:41:24.080217 22542570456896 run_lib.py:133] step: 999750, training_loss: 3.29860e-02
I0212 14:41:41.418337 22542570456896 run_lib.py:133] step: 999800, training_loss: 2.70989e-02
I0212 14:41:41.571402 22542570456896 run_lib.py:146] step: 999800, eval_loss: 3.59049e-02
I0212 14:41:59.089881 22542570456896 run_lib.py:133] step: 999850, training_loss: 2.15593e-02
I0212 14:42:16.437137 22542570456896 run_lib.py:133] step: 999900, training_loss: 2.94201e-02
I0212 14:42:16.593376 22542570456896 run_lib.py:146] step: 999900, eval_loss: 2.79102e-02
I0212 14:42:33.950661 22542570456896 run_lib.py:133] step: 999950, training_loss: 2.23159e-02
I0212 14:42:51.514685 22542570456896 run_lib.py:133] step: 1000000, training_loss: 2.90582e-02
I0212 14:42:52.204278 22542570456896 run_lib.py:146] step: 1000000, eval_loss: 2.77435e-02
I0212 14:43:12.192375 22542570456896 run_lib.py:133] step: 1000050, training_loss: 2.09025e-02
I0212 14:43:29.609104 22542570456896 run_lib.py:133] step: 1000100, training_loss: 2.73783e-02
I0212 14:43:29.768845 22542570456896 run_lib.py:146] step: 1000100, eval_loss: 3.18046e-02
I0212 14:43:47.229859 22542570456896 run_lib.py:133] step: 1000150, training_loss: 2.53006e-02
I0212 14:44:04.879284 22542570456896 run_lib.py:133] step: 1000200, training_loss: 2.82953e-02
I0212 14:44:05.051461 22542570456896 run_lib.py:146] step: 1000200, eval_loss: 3.33408e-02
I0212 14:44:22.542333 22542570456896 run_lib.py:133] step: 1000250, training_loss: 2.81021e-02
I0212 14:44:40.068760 22542570456896 run_lib.py:133] step: 1000300, training_loss: 2.25263e-02
I0212 14:44:40.226695 22542570456896 run_lib.py:146] step: 1000300, eval_loss: 2.81287e-02
I0212 14:44:57.903189 22542570456896 run_lib.py:133] step: 1000350, training_loss: 2.56503e-02
I0212 14:45:15.362011 22542570456896 run_lib.py:133] step: 1000400, training_loss: 3.32135e-02
I0212 14:45:15.515501 22542570456896 run_lib.py:146] step: 1000400, eval_loss: 3.16163e-02
I0212 14:45:33.016978 22542570456896 run_lib.py:133] step: 1000450, training_loss: 2.47374e-02
I0212 14:45:50.480871 22542570456896 run_lib.py:133] step: 1000500, training_loss: 2.22790e-02
I0212 14:45:50.654448 22542570456896 run_lib.py:146] step: 1000500, eval_loss: 3.48862e-02
I0212 14:46:08.157361 22542570456896 run_lib.py:133] step: 1000550, training_loss: 2.51272e-02
I0212 14:46:25.650899 22542570456896 run_lib.py:133] step: 1000600, training_loss: 2.82695e-02
I0212 14:46:25.818509 22542570456896 run_lib.py:146] step: 1000600, eval_loss: 2.45034e-02
I0212 14:46:43.486648 22542570456896 run_lib.py:133] step: 1000650, training_loss: 3.02458e-02
I0212 14:47:01.004385 22542570456896 run_lib.py:133] step: 1000700, training_loss: 2.84789e-02
I0212 14:47:01.162624 22542570456896 run_lib.py:146] step: 1000700, eval_loss: 3.21641e-02
I0212 14:47:18.636078 22542570456896 run_lib.py:133] step: 1000750, training_loss: 3.08723e-02
I0212 14:47:36.143758 22542570456896 run_lib.py:133] step: 1000800, training_loss: 2.64929e-02
I0212 14:47:36.300709 22542570456896 run_lib.py:146] step: 1000800, eval_loss: 2.50679e-02
I0212 14:47:53.987392 22542570456896 run_lib.py:133] step: 1000850, training_loss: 3.29280e-02
I0212 14:48:11.429881 22542570456896 run_lib.py:133] step: 1000900, training_loss: 2.61649e-02
I0212 14:48:11.585402 22542570456896 run_lib.py:146] step: 1000900, eval_loss: 2.69745e-02
I0212 14:48:29.224853 22542570456896 run_lib.py:133] step: 1000950, training_loss: 2.91989e-02
I0212 14:48:46.688185 22542570456896 run_lib.py:133] step: 1001000, training_loss: 2.60336e-02
I0212 14:48:46.848420 22542570456896 run_lib.py:146] step: 1001000, eval_loss: 2.36874e-02
I0212 14:49:04.464904 22542570456896 run_lib.py:133] step: 1001050, training_loss: 2.04283e-02
I0212 14:49:21.978574 22542570456896 run_lib.py:133] step: 1001100, training_loss: 3.86786e-02
I0212 14:49:22.145406 22542570456896 run_lib.py:146] step: 1001100, eval_loss: 2.75155e-02
I0212 14:49:39.827809 22542570456896 run_lib.py:133] step: 1001150, training_loss: 2.46012e-02
I0212 14:49:57.252611 22542570456896 run_lib.py:133] step: 1001200, training_loss: 2.70363e-02
I0212 14:49:57.411155 22542570456896 run_lib.py:146] step: 1001200, eval_loss: 2.99053e-02
I0212 14:50:14.874880 22542570456896 run_lib.py:133] step: 1001250, training_loss: 3.04388e-02
I0212 14:50:32.465047 22542570456896 run_lib.py:133] step: 1001300, training_loss: 2.68098e-02
I0212 14:50:32.617488 22542570456896 run_lib.py:146] step: 1001300, eval_loss: 3.69526e-02
I0212 14:50:50.113837 22542570456896 run_lib.py:133] step: 1001350, training_loss: 2.45363e-02
I0212 14:51:07.611125 22542570456896 run_lib.py:133] step: 1001400, training_loss: 3.11963e-02
I0212 14:51:07.779696 22542570456896 run_lib.py:146] step: 1001400, eval_loss: 3.14026e-02
I0212 14:51:25.450502 22542570456896 run_lib.py:133] step: 1001450, training_loss: 3.18978e-02
I0212 14:51:42.972455 22542570456896 run_lib.py:133] step: 1001500, training_loss: 2.81022e-02
I0212 14:51:43.133818 22542570456896 run_lib.py:146] step: 1001500, eval_loss: 2.59029e-02
I0212 14:52:00.751374 22542570456896 run_lib.py:133] step: 1001550, training_loss: 2.53442e-02
I0212 14:52:18.208727 22542570456896 run_lib.py:133] step: 1001600, training_loss: 2.82282e-02
I0212 14:52:18.368638 22542570456896 run_lib.py:146] step: 1001600, eval_loss: 3.15176e-02
I0212 14:52:35.832113 22542570456896 run_lib.py:133] step: 1001650, training_loss: 2.83260e-02
I0212 14:52:53.539634 22542570456896 run_lib.py:133] step: 1001700, training_loss: 2.68596e-02
I0212 14:52:53.697818 22542570456896 run_lib.py:146] step: 1001700, eval_loss: 2.15599e-02
I0212 14:53:11.203158 22542570456896 run_lib.py:133] step: 1001750, training_loss: 2.89865e-02
I0212 14:53:28.664445 22542570456896 run_lib.py:133] step: 1001800, training_loss: 2.43429e-02
I0212 14:53:28.825568 22542570456896 run_lib.py:146] step: 1001800, eval_loss: 2.83254e-02
I0212 14:53:46.302745 22542570456896 run_lib.py:133] step: 1001850, training_loss: 2.75585e-02
I0212 14:54:03.926270 22542570456896 run_lib.py:133] step: 1001900, training_loss: 2.34033e-02
I0212 14:54:04.096669 22542570456896 run_lib.py:146] step: 1001900, eval_loss: 3.14666e-02
I0212 14:54:21.644289 22542570456896 run_lib.py:133] step: 1001950, training_loss: 2.58791e-02
I0212 14:54:39.208778 22542570456896 run_lib.py:133] step: 1002000, training_loss: 2.69405e-02
I0212 14:54:39.368598 22542570456896 run_lib.py:146] step: 1002000, eval_loss: 2.73925e-02
I0212 14:54:56.815942 22542570456896 run_lib.py:133] step: 1002050, training_loss: 2.50784e-02
I0212 14:55:14.270060 22542570456896 run_lib.py:133] step: 1002100, training_loss: 2.85365e-02
I0212 14:55:14.427548 22542570456896 run_lib.py:146] step: 1002100, eval_loss: 2.53730e-02
I0212 14:55:32.058940 22542570456896 run_lib.py:133] step: 1002150, training_loss: 2.56800e-02
I0212 14:55:49.646201 22542570456896 run_lib.py:133] step: 1002200, training_loss: 3.56391e-02
I0212 14:55:49.804698 22542570456896 run_lib.py:146] step: 1002200, eval_loss: 2.82547e-02
I0212 14:56:07.317077 22542570456896 run_lib.py:133] step: 1002250, training_loss: 2.92857e-02
I0212 14:56:24.765813 22542570456896 run_lib.py:133] step: 1002300, training_loss: 2.89918e-02
I0212 14:56:24.919521 22542570456896 run_lib.py:146] step: 1002300, eval_loss: 2.56600e-02
I0212 14:56:42.543078 22542570456896 run_lib.py:133] step: 1002350, training_loss: 2.96286e-02
I0212 14:57:00.006345 22542570456896 run_lib.py:133] step: 1002400, training_loss: 1.95436e-02
I0212 14:57:00.171699 22542570456896 run_lib.py:146] step: 1002400, eval_loss: 2.67320e-02
I0212 14:57:17.813039 22542570456896 run_lib.py:133] step: 1002450, training_loss: 2.29551e-02
I0212 14:57:35.343113 22542570456896 run_lib.py:133] step: 1002500, training_loss: 2.85528e-02
I0212 14:57:35.506485 22542570456896 run_lib.py:146] step: 1002500, eval_loss: 2.52715e-02
I0212 14:57:53.179531 22542570456896 run_lib.py:133] step: 1002550, training_loss: 2.52118e-02
I0212 14:58:10.638344 22542570456896 run_lib.py:133] step: 1002600, training_loss: 2.51096e-02
I0212 14:58:10.796369 22542570456896 run_lib.py:146] step: 1002600, eval_loss: 2.90017e-02
I0212 14:58:28.280981 22542570456896 run_lib.py:133] step: 1002650, training_loss: 2.69734e-02
I0212 14:58:45.901099 22542570456896 run_lib.py:133] step: 1002700, training_loss: 2.29477e-02
I0212 14:58:46.056172 22542570456896 run_lib.py:146] step: 1002700, eval_loss: 2.44813e-02
I0212 14:59:03.537805 22542570456896 run_lib.py:133] step: 1002750, training_loss: 3.02473e-02
I0212 14:59:21.163841 22542570456896 run_lib.py:133] step: 1002800, training_loss: 2.28150e-02
I0212 14:59:21.322759 22542570456896 run_lib.py:146] step: 1002800, eval_loss: 2.85246e-02
I0212 14:59:38.824703 22542570456896 run_lib.py:133] step: 1002850, training_loss: 2.35132e-02
I0212 14:59:56.314618 22542570456896 run_lib.py:133] step: 1002900, training_loss: 2.49232e-02
I0212 14:59:56.474528 22542570456896 run_lib.py:146] step: 1002900, eval_loss: 2.40652e-02
I0212 15:00:14.137873 22542570456896 run_lib.py:133] step: 1002950, training_loss: 2.50813e-02
I0212 15:00:31.595109 22542570456896 run_lib.py:133] step: 1003000, training_loss: 2.76907e-02
I0212 15:00:31.752441 22542570456896 run_lib.py:146] step: 1003000, eval_loss: 3.04493e-02
I0212 15:00:49.232681 22542570456896 run_lib.py:133] step: 1003050, training_loss: 2.79971e-02
I0212 15:01:06.962767 22542570456896 run_lib.py:133] step: 1003100, training_loss: 2.46952e-02
I0212 15:01:07.121074 22542570456896 run_lib.py:146] step: 1003100, eval_loss: 2.69276e-02
I0212 15:01:24.606059 22542570456896 run_lib.py:133] step: 1003150, training_loss: 3.17329e-02
I0212 15:01:42.068450 22542570456896 run_lib.py:133] step: 1003200, training_loss: 3.02230e-02
I0212 15:01:42.410480 22542570456896 run_lib.py:146] step: 1003200, eval_loss: 2.91661e-02
I0212 15:01:59.857496 22542570456896 run_lib.py:133] step: 1003250, training_loss: 2.38645e-02
I0212 15:02:17.312865 22542570456896 run_lib.py:133] step: 1003300, training_loss: 2.27725e-02
I0212 15:02:17.479458 22542570456896 run_lib.py:146] step: 1003300, eval_loss: 3.56578e-02
I0212 15:02:34.952851 22542570456896 run_lib.py:133] step: 1003350, training_loss: 2.84320e-02
I0212 15:02:52.495764 22542570456896 run_lib.py:133] step: 1003400, training_loss: 2.55604e-02
I0212 15:02:52.661404 22542570456896 run_lib.py:146] step: 1003400, eval_loss: 3.10097e-02
I0212 15:03:10.315249 22542570456896 run_lib.py:133] step: 1003450, training_loss: 2.67057e-02
I0212 15:03:27.859478 22542570456896 run_lib.py:133] step: 1003500, training_loss: 3.44233e-02
I0212 15:03:28.017410 22542570456896 run_lib.py:146] step: 1003500, eval_loss: 3.27402e-02
I0212 15:03:45.462304 22542570456896 run_lib.py:133] step: 1003550, training_loss: 2.76740e-02
I0212 15:04:02.914381 22542570456896 run_lib.py:133] step: 1003600, training_loss: 2.53333e-02
I0212 15:04:03.083158 22542570456896 run_lib.py:146] step: 1003600, eval_loss: 2.68699e-02
I0212 15:04:20.744030 22542570456896 run_lib.py:133] step: 1003650, training_loss: 2.96011e-02
I0212 15:04:38.361236 22542570456896 run_lib.py:133] step: 1003700, training_loss: 2.73188e-02
I0212 15:04:38.514697 22542570456896 run_lib.py:146] step: 1003700, eval_loss: 3.44164e-02
I0212 15:04:55.966412 22542570456896 run_lib.py:133] step: 1003750, training_loss: 2.86794e-02
I0212 15:05:13.426343 22542570456896 run_lib.py:133] step: 1003800, training_loss: 3.02747e-02
I0212 15:05:13.586536 22542570456896 run_lib.py:146] step: 1003800, eval_loss: 2.68175e-02
I0212 15:05:31.201177 22542570456896 run_lib.py:133] step: 1003850, training_loss: 2.82580e-02
I0212 15:05:48.701859 22542570456896 run_lib.py:133] step: 1003900, training_loss: 2.56719e-02
I0212 15:05:48.871465 22542570456896 run_lib.py:146] step: 1003900, eval_loss: 2.64788e-02
I0212 15:06:06.572841 22542570456896 run_lib.py:133] step: 1003950, training_loss: 2.27155e-02
I0212 15:06:24.067998 22542570456896 run_lib.py:133] step: 1004000, training_loss: 2.21066e-02
I0212 15:06:24.224592 22542570456896 run_lib.py:146] step: 1004000, eval_loss: 2.62945e-02
I0212 15:06:41.875321 22542570456896 run_lib.py:133] step: 1004050, training_loss: 2.70858e-02
I0212 15:06:59.375146 22542570456896 run_lib.py:133] step: 1004100, training_loss: 2.80348e-02
I0212 15:06:59.539610 22542570456896 run_lib.py:146] step: 1004100, eval_loss: 3.27490e-02
I0212 15:07:17.002329 22542570456896 run_lib.py:133] step: 1004150, training_loss: 2.83322e-02
I0212 15:07:34.709495 22542570456896 run_lib.py:133] step: 1004200, training_loss: 2.57996e-02
I0212 15:07:34.865669 22542570456896 run_lib.py:146] step: 1004200, eval_loss: 2.83784e-02
I0212 15:07:52.396315 22542570456896 run_lib.py:133] step: 1004250, training_loss: 2.46272e-02
I0212 15:08:10.113791 22542570456896 run_lib.py:133] step: 1004300, training_loss: 3.04927e-02
I0212 15:08:10.269696 22542570456896 run_lib.py:146] step: 1004300, eval_loss: 2.61250e-02
I0212 15:08:27.692613 22542570456896 run_lib.py:133] step: 1004350, training_loss: 2.71748e-02
I0212 15:08:45.160297 22542570456896 run_lib.py:133] step: 1004400, training_loss: 2.05821e-02
I0212 15:08:45.318753 22542570456896 run_lib.py:146] step: 1004400, eval_loss: 3.54732e-02
I0212 15:09:03.043830 22542570456896 run_lib.py:133] step: 1004450, training_loss: 2.72853e-02
I0212 15:09:20.536477 22542570456896 run_lib.py:133] step: 1004500, training_loss: 2.55521e-02
I0212 15:09:20.693167 22542570456896 run_lib.py:146] step: 1004500, eval_loss: 2.84561e-02
I0212 15:09:38.128002 22542570456896 run_lib.py:133] step: 1004550, training_loss: 2.35629e-02
I0212 15:09:55.558477 22542570456896 run_lib.py:133] step: 1004600, training_loss: 2.86373e-02
I0212 15:09:55.713383 22542570456896 run_lib.py:146] step: 1004600, eval_loss: 3.01848e-02
I0212 15:10:13.409892 22542570456896 run_lib.py:133] step: 1004650, training_loss: 2.78685e-02
I0212 15:10:30.871852 22542570456896 run_lib.py:133] step: 1004700, training_loss: 2.19337e-02
I0212 15:10:31.034614 22542570456896 run_lib.py:146] step: 1004700, eval_loss: 3.07513e-02
I0212 15:10:48.619495 22542570456896 run_lib.py:133] step: 1004750, training_loss: 3.30560e-02
I0212 15:11:06.134509 22542570456896 run_lib.py:133] step: 1004800, training_loss: 3.16399e-02
I0212 15:11:06.294411 22542570456896 run_lib.py:146] step: 1004800, eval_loss: 2.61843e-02
I0212 15:11:23.769404 22542570456896 run_lib.py:133] step: 1004850, training_loss: 2.76987e-02
I0212 15:11:41.119815 22542570456896 run_lib.py:133] step: 1004900, training_loss: 2.38401e-02
I0212 15:11:41.275191 22542570456896 run_lib.py:146] step: 1004900, eval_loss: 3.33868e-02
I0212 15:11:58.815304 22542570456896 run_lib.py:133] step: 1004950, training_loss: 2.70599e-02
I0212 15:12:16.239675 22542570456896 run_lib.py:133] step: 1005000, training_loss: 3.03653e-02
I0212 15:12:16.408185 22542570456896 run_lib.py:146] step: 1005000, eval_loss: 2.33562e-02
I0212 15:12:33.849559 22542570456896 run_lib.py:133] step: 1005050, training_loss: 2.96132e-02
I0212 15:12:51.230992 22542570456896 run_lib.py:133] step: 1005100, training_loss: 3.22114e-02
I0212 15:12:51.382636 22542570456896 run_lib.py:146] step: 1005100, eval_loss: 3.27984e-02
I0212 15:13:08.915386 22542570456896 run_lib.py:133] step: 1005150, training_loss: 2.36775e-02
I0212 15:13:26.346514 22542570456896 run_lib.py:133] step: 1005200, training_loss: 2.50180e-02
I0212 15:13:26.501426 22542570456896 run_lib.py:146] step: 1005200, eval_loss: 3.56423e-02
I0212 15:13:44.021137 22542570456896 run_lib.py:133] step: 1005250, training_loss: 2.58298e-02
I0212 15:14:01.470303 22542570456896 run_lib.py:133] step: 1005300, training_loss: 2.19724e-02
I0212 15:14:01.649468 22542570456896 run_lib.py:146] step: 1005300, eval_loss: 3.00782e-02
I0212 15:14:19.361561 22542570456896 run_lib.py:133] step: 1005350, training_loss: 2.15678e-02
I0212 15:14:36.849290 22542570456896 run_lib.py:133] step: 1005400, training_loss: 2.88965e-02
I0212 15:14:37.008738 22542570456896 run_lib.py:146] step: 1005400, eval_loss: 3.02823e-02
I0212 15:14:54.693991 22542570456896 run_lib.py:133] step: 1005450, training_loss: 3.08723e-02
I0212 15:15:12.166246 22542570456896 run_lib.py:133] step: 1005500, training_loss: 2.84115e-02
I0212 15:15:12.323467 22542570456896 run_lib.py:146] step: 1005500, eval_loss: 3.37112e-02
I0212 15:15:29.829496 22542570456896 run_lib.py:133] step: 1005550, training_loss: 2.36534e-02
I0212 15:15:47.493906 22542570456896 run_lib.py:133] step: 1005600, training_loss: 3.00049e-02
I0212 15:15:47.650626 22542570456896 run_lib.py:146] step: 1005600, eval_loss: 2.51257e-02
I0212 15:16:05.133787 22542570456896 run_lib.py:133] step: 1005650, training_loss: 2.89674e-02
I0212 15:16:22.606073 22542570456896 run_lib.py:133] step: 1005700, training_loss: 2.19120e-02
I0212 15:16:22.762508 22542570456896 run_lib.py:146] step: 1005700, eval_loss: 2.88170e-02
I0212 15:16:40.417458 22542570456896 run_lib.py:133] step: 1005750, training_loss: 2.79407e-02
I0212 15:16:58.053175 22542570456896 run_lib.py:133] step: 1005800, training_loss: 2.59791e-02
I0212 15:16:58.212692 22542570456896 run_lib.py:146] step: 1005800, eval_loss: 3.49357e-02
I0212 15:17:15.716592 22542570456896 run_lib.py:133] step: 1005850, training_loss: 2.51842e-02
I0212 15:17:33.242503 22542570456896 run_lib.py:133] step: 1005900, training_loss: 2.56862e-02
I0212 15:17:33.400584 22542570456896 run_lib.py:146] step: 1005900, eval_loss: 3.28892e-02
I0212 15:17:50.885133 22542570456896 run_lib.py:133] step: 1005950, training_loss: 2.63851e-02
I0212 15:18:08.530272 22542570456896 run_lib.py:133] step: 1006000, training_loss: 2.54103e-02
I0212 15:18:08.685447 22542570456896 run_lib.py:146] step: 1006000, eval_loss: 2.55825e-02
I0212 15:18:26.144129 22542570456896 run_lib.py:133] step: 1006050, training_loss: 2.91162e-02
I0212 15:18:43.624154 22542570456896 run_lib.py:133] step: 1006100, training_loss: 2.82048e-02
I0212 15:18:43.781759 22542570456896 run_lib.py:146] step: 1006100, eval_loss: 2.47708e-02
I0212 15:19:01.302002 22542570456896 run_lib.py:133] step: 1006150, training_loss: 2.43787e-02
I0212 15:19:18.975883 22542570456896 run_lib.py:133] step: 1006200, training_loss: 2.34058e-02
I0212 15:19:19.135310 22542570456896 run_lib.py:146] step: 1006200, eval_loss: 2.83274e-02
I0212 15:19:36.596667 22542570456896 run_lib.py:133] step: 1006250, training_loss: 3.72669e-02
I0212 15:19:54.159519 22542570456896 run_lib.py:133] step: 1006300, training_loss: 2.93240e-02
I0212 15:19:54.317724 22542570456896 run_lib.py:146] step: 1006300, eval_loss: 3.30923e-02
I0212 15:20:11.774879 22542570456896 run_lib.py:133] step: 1006350, training_loss: 2.71154e-02
I0212 15:20:29.240762 22542570456896 run_lib.py:133] step: 1006400, training_loss: 2.51358e-02
I0212 15:20:29.406697 22542570456896 run_lib.py:146] step: 1006400, eval_loss: 2.76204e-02
I0212 15:20:47.121578 22542570456896 run_lib.py:133] step: 1006450, training_loss: 2.36441e-02
I0212 15:21:04.726125 22542570456896 run_lib.py:133] step: 1006500, training_loss: 2.92802e-02
I0212 15:21:04.883143 22542570456896 run_lib.py:146] step: 1006500, eval_loss: 3.21098e-02
I0212 15:21:22.374165 22542570456896 run_lib.py:133] step: 1006550, training_loss: 2.72222e-02
I0212 15:21:39.840467 22542570456896 run_lib.py:133] step: 1006600, training_loss: 2.89948e-02
I0212 15:21:39.996567 22542570456896 run_lib.py:146] step: 1006600, eval_loss: 3.25463e-02
I0212 15:21:57.625617 22542570456896 run_lib.py:133] step: 1006650, training_loss: 2.13298e-02
I0212 15:22:15.113907 22542570456896 run_lib.py:133] step: 1006700, training_loss: 2.34297e-02
I0212 15:22:15.291514 22542570456896 run_lib.py:146] step: 1006700, eval_loss: 2.63696e-02
I0212 15:22:32.980679 22542570456896 run_lib.py:133] step: 1006750, training_loss: 2.78621e-02
I0212 15:22:50.487584 22542570456896 run_lib.py:133] step: 1006800, training_loss: 3.02397e-02
I0212 15:22:50.656549 22542570456896 run_lib.py:146] step: 1006800, eval_loss: 3.10377e-02
I0212 15:23:08.302689 22542570456896 run_lib.py:133] step: 1006850, training_loss: 2.70621e-02
I0212 15:23:25.755470 22542570456896 run_lib.py:133] step: 1006900, training_loss: 2.40886e-02
I0212 15:23:25.912708 22542570456896 run_lib.py:146] step: 1006900, eval_loss: 3.25118e-02
I0212 15:23:43.373734 22542570456896 run_lib.py:133] step: 1006950, training_loss: 2.10709e-02
I0212 15:24:01.094410 22542570456896 run_lib.py:133] step: 1007000, training_loss: 2.88926e-02
I0212 15:24:01.249316 22542570456896 run_lib.py:146] step: 1007000, eval_loss: 3.32924e-02
I0212 15:24:18.756188 22542570456896 run_lib.py:133] step: 1007050, training_loss: 2.53706e-02
I0212 15:24:36.389516 22542570456896 run_lib.py:133] step: 1007100, training_loss: 3.12924e-02
I0212 15:24:36.548507 22542570456896 run_lib.py:146] step: 1007100, eval_loss: 2.80375e-02
I0212 15:24:54.000334 22542570456896 run_lib.py:133] step: 1007150, training_loss: 2.26748e-02
I0212 15:25:11.466097 22542570456896 run_lib.py:133] step: 1007200, training_loss: 2.78221e-02
I0212 15:25:11.645501 22542570456896 run_lib.py:146] step: 1007200, eval_loss: 2.76609e-02
I0212 15:25:29.285598 22542570456896 run_lib.py:133] step: 1007250, training_loss: 2.61370e-02
I0212 15:25:46.776068 22542570456896 run_lib.py:133] step: 1007300, training_loss: 2.56882e-02
I0212 15:25:46.935730 22542570456896 run_lib.py:146] step: 1007300, eval_loss: 2.74824e-02
I0212 15:26:04.409058 22542570456896 run_lib.py:133] step: 1007350, training_loss: 2.42172e-02
I0212 15:26:22.076497 22542570456896 run_lib.py:133] step: 1007400, training_loss: 3.05089e-02
I0212 15:26:22.240565 22542570456896 run_lib.py:146] step: 1007400, eval_loss: 3.25516e-02
I0212 15:26:39.719814 22542570456896 run_lib.py:133] step: 1007450, training_loss: 2.35093e-02
I0212 15:26:57.226057 22542570456896 run_lib.py:133] step: 1007500, training_loss: 2.52116e-02
I0212 15:26:57.392649 22542570456896 run_lib.py:146] step: 1007500, eval_loss: 3.00636e-02
I0212 15:27:15.014966 22542570456896 run_lib.py:133] step: 1007550, training_loss: 2.47986e-02
I0212 15:27:32.504694 22542570456896 run_lib.py:133] step: 1007600, training_loss: 2.40822e-02
I0212 15:27:32.661396 22542570456896 run_lib.py:146] step: 1007600, eval_loss: 3.69688e-02
I0212 15:27:50.118463 22542570456896 run_lib.py:133] step: 1007650, training_loss: 2.74743e-02
I0212 15:28:07.612114 22542570456896 run_lib.py:133] step: 1007700, training_loss: 2.43924e-02
I0212 15:28:07.780567 22542570456896 run_lib.py:146] step: 1007700, eval_loss: 2.70919e-02
I0212 15:28:25.489345 22542570456896 run_lib.py:133] step: 1007750, training_loss: 2.87744e-02
I0212 15:28:43.093354 22542570456896 run_lib.py:133] step: 1007800, training_loss: 3.11756e-02
I0212 15:28:43.251367 22542570456896 run_lib.py:146] step: 1007800, eval_loss: 2.88008e-02
I0212 15:29:00.763411 22542570456896 run_lib.py:133] step: 1007850, training_loss: 2.63222e-02
I0212 15:29:18.250682 22542570456896 run_lib.py:133] step: 1007900, training_loss: 2.36033e-02
I0212 15:29:18.408478 22542570456896 run_lib.py:146] step: 1007900, eval_loss: 3.43823e-02
I0212 15:29:36.068318 22542570456896 run_lib.py:133] step: 1007950, training_loss: 2.58506e-02
I0212 15:29:53.562992 22542570456896 run_lib.py:133] step: 1008000, training_loss: 2.65795e-02
I0212 15:29:53.715261 22542570456896 run_lib.py:146] step: 1008000, eval_loss: 3.10968e-02
I0212 15:30:11.377908 22542570456896 run_lib.py:133] step: 1008050, training_loss: 2.95581e-02
I0212 15:30:28.870089 22542570456896 run_lib.py:133] step: 1008100, training_loss: 2.74446e-02
I0212 15:30:29.035435 22542570456896 run_lib.py:146] step: 1008100, eval_loss: 3.02938e-02
I0212 15:30:46.670897 22542570456896 run_lib.py:133] step: 1008150, training_loss: 2.87365e-02
I0212 15:31:04.145093 22542570456896 run_lib.py:133] step: 1008200, training_loss: 2.39947e-02
I0212 15:31:04.302501 22542570456896 run_lib.py:146] step: 1008200, eval_loss: 2.52144e-02
I0212 15:31:21.900097 22542570456896 run_lib.py:133] step: 1008250, training_loss: 3.40859e-02
I0212 15:31:39.346372 22542570456896 run_lib.py:133] step: 1008300, training_loss: 3.06599e-02
I0212 15:31:39.506591 22542570456896 run_lib.py:146] step: 1008300, eval_loss: 2.32628e-02
I0212 15:31:57.028000 22542570456896 run_lib.py:133] step: 1008350, training_loss: 2.63168e-02
I0212 15:32:14.720646 22542570456896 run_lib.py:133] step: 1008400, training_loss: 2.27396e-02
I0212 15:32:14.874176 22542570456896 run_lib.py:146] step: 1008400, eval_loss: 3.50098e-02
I0212 15:32:32.366295 22542570456896 run_lib.py:133] step: 1008450, training_loss: 2.93154e-02
I0212 15:32:49.833618 22542570456896 run_lib.py:133] step: 1008500, training_loss: 3.25928e-02
I0212 15:32:49.989452 22542570456896 run_lib.py:146] step: 1008500, eval_loss: 3.68660e-02
I0212 15:33:07.623132 22542570456896 run_lib.py:133] step: 1008550, training_loss: 2.73375e-02
I0212 15:33:25.133858 22542570456896 run_lib.py:133] step: 1008600, training_loss: 2.55258e-02
I0212 15:33:25.320498 22542570456896 run_lib.py:146] step: 1008600, eval_loss: 2.30333e-02
I0212 15:33:43.006897 22542570456896 run_lib.py:133] step: 1008650, training_loss: 2.94363e-02
I0212 15:34:00.469030 22542570456896 run_lib.py:133] step: 1008700, training_loss: 2.40667e-02
I0212 15:34:00.626482 22542570456896 run_lib.py:146] step: 1008700, eval_loss: 2.64620e-02
I0212 15:34:18.101028 22542570456896 run_lib.py:133] step: 1008750, training_loss: 2.15814e-02
I0212 15:34:35.715468 22542570456896 run_lib.py:133] step: 1008800, training_loss: 2.98937e-02
I0212 15:34:35.873633 22542570456896 run_lib.py:146] step: 1008800, eval_loss: 2.97292e-02
I0212 15:34:53.358434 22542570456896 run_lib.py:133] step: 1008850, training_loss: 3.24172e-02
I0212 15:35:10.859667 22542570456896 run_lib.py:133] step: 1008900, training_loss: 2.74796e-02
I0212 15:35:11.023693 22542570456896 run_lib.py:146] step: 1008900, eval_loss: 3.71964e-02
I0212 15:35:28.569194 22542570456896 run_lib.py:133] step: 1008950, training_loss: 2.93296e-02
I0212 15:35:46.232097 22542570456896 run_lib.py:133] step: 1009000, training_loss: 3.01772e-02
I0212 15:35:46.391489 22542570456896 run_lib.py:146] step: 1009000, eval_loss: 2.52299e-02
I0212 15:36:03.831789 22542570456896 run_lib.py:133] step: 1009050, training_loss: 2.48435e-02
I0212 15:36:21.378266 22542570456896 run_lib.py:133] step: 1009100, training_loss: 2.69768e-02
I0212 15:36:21.553554 22542570456896 run_lib.py:146] step: 1009100, eval_loss: 2.43043e-02
I0212 15:36:39.081383 22542570456896 run_lib.py:133] step: 1009150, training_loss: 2.83146e-02
I0212 15:36:56.546728 22542570456896 run_lib.py:133] step: 1009200, training_loss: 2.34829e-02
I0212 15:36:56.703662 22542570456896 run_lib.py:146] step: 1009200, eval_loss: 2.68262e-02
I0212 15:37:14.363054 22542570456896 run_lib.py:133] step: 1009250, training_loss: 2.76157e-02
I0212 15:37:31.899442 22542570456896 run_lib.py:133] step: 1009300, training_loss: 3.05263e-02
I0212 15:37:32.056526 22542570456896 run_lib.py:146] step: 1009300, eval_loss: 2.85522e-02
I0212 15:37:49.538812 22542570456896 run_lib.py:133] step: 1009350, training_loss: 2.89616e-02
I0212 15:38:07.015743 22542570456896 run_lib.py:133] step: 1009400, training_loss: 2.58330e-02
I0212 15:38:07.172698 22542570456896 run_lib.py:146] step: 1009400, eval_loss: 2.67426e-02
I0212 15:38:24.879058 22542570456896 run_lib.py:133] step: 1009450, training_loss: 2.35973e-02
I0212 15:38:42.362510 22542570456896 run_lib.py:133] step: 1009500, training_loss: 2.73695e-02
I0212 15:38:42.519199 22542570456896 run_lib.py:146] step: 1009500, eval_loss: 2.71436e-02
I0212 15:39:00.121665 22542570456896 run_lib.py:133] step: 1009550, training_loss: 2.59516e-02
I0212 15:39:17.564276 22542570456896 run_lib.py:133] step: 1009600, training_loss: 2.61983e-02
I0212 15:39:17.733769 22542570456896 run_lib.py:146] step: 1009600, eval_loss: 2.79921e-02
I0212 15:39:35.374132 22542570456896 run_lib.py:133] step: 1009650, training_loss: 2.63420e-02
I0212 15:39:52.869941 22542570456896 run_lib.py:133] step: 1009700, training_loss: 2.69661e-02
I0212 15:39:53.028952 22542570456896 run_lib.py:146] step: 1009700, eval_loss: 2.88995e-02
I0212 15:40:10.535456 22542570456896 run_lib.py:133] step: 1009750, training_loss: 2.93982e-02
I0212 15:40:28.187402 22542570456896 run_lib.py:133] step: 1009800, training_loss: 2.44516e-02
I0212 15:40:28.343185 22542570456896 run_lib.py:146] step: 1009800, eval_loss: 2.89371e-02
I0212 15:40:45.785701 22542570456896 run_lib.py:133] step: 1009850, training_loss: 2.71944e-02
I0212 15:41:03.415865 22542570456896 run_lib.py:133] step: 1009900, training_loss: 2.97181e-02
I0212 15:41:03.578343 22542570456896 run_lib.py:146] step: 1009900, eval_loss: 2.73625e-02
I0212 15:41:21.114069 22542570456896 run_lib.py:133] step: 1009950, training_loss: 2.50963e-02
I0212 15:41:38.626306 22542570456896 run_lib.py:133] step: 1010000, training_loss: 2.64191e-02
I0212 15:41:39.357364 22542570456896 run_lib.py:146] step: 1010000, eval_loss: 3.37098e-02
I0212 15:41:59.585813 22542570456896 run_lib.py:133] step: 1010050, training_loss: 2.27312e-02
I0212 15:42:16.914659 22542570456896 run_lib.py:133] step: 1010100, training_loss: 2.61803e-02
I0212 15:42:17.071593 22542570456896 run_lib.py:146] step: 1010100, eval_loss: 3.01155e-02
I0212 15:42:34.639589 22542570456896 run_lib.py:133] step: 1010150, training_loss: 3.08139e-02
I0212 15:42:52.019858 22542570456896 run_lib.py:133] step: 1010200, training_loss: 3.46421e-02
I0212 15:42:52.178297 22542570456896 run_lib.py:146] step: 1010200, eval_loss: 2.68796e-02
I0212 15:43:09.537062 22542570456896 run_lib.py:133] step: 1010250, training_loss: 2.13154e-02
I0212 15:43:27.117431 22542570456896 run_lib.py:133] step: 1010300, training_loss: 2.91947e-02
I0212 15:43:27.272584 22542570456896 run_lib.py:146] step: 1010300, eval_loss: 3.33761e-02
I0212 15:43:44.677955 22542570456896 run_lib.py:133] step: 1010350, training_loss: 2.93997e-02
I0212 15:44:02.238866 22542570456896 run_lib.py:133] step: 1010400, training_loss: 3.19048e-02
I0212 15:44:02.390362 22542570456896 run_lib.py:146] step: 1010400, eval_loss: 2.37376e-02
I0212 15:44:19.790894 22542570456896 run_lib.py:133] step: 1010450, training_loss: 2.73676e-02
I0212 15:44:37.255295 22542570456896 run_lib.py:133] step: 1010500, training_loss: 2.63871e-02
I0212 15:44:37.434356 22542570456896 run_lib.py:146] step: 1010500, eval_loss: 2.92286e-02
I0212 15:44:54.976673 22542570456896 run_lib.py:133] step: 1010550, training_loss: 2.67100e-02
I0212 15:45:12.718674 22542570456896 run_lib.py:133] step: 1010600, training_loss: 3.19970e-02
I0212 15:45:12.878533 22542570456896 run_lib.py:146] step: 1010600, eval_loss: 2.09672e-02
I0212 15:45:30.345022 22542570456896 run_lib.py:133] step: 1010650, training_loss: 2.90728e-02
I0212 15:45:47.819712 22542570456896 run_lib.py:133] step: 1010700, training_loss: 2.29231e-02
I0212 15:45:47.977504 22542570456896 run_lib.py:146] step: 1010700, eval_loss: 2.80586e-02
I0212 15:46:05.634210 22542570456896 run_lib.py:133] step: 1010750, training_loss: 2.42553e-02
I0212 15:46:23.144493 22542570456896 run_lib.py:133] step: 1010800, training_loss: 2.62035e-02
I0212 15:46:23.301723 22542570456896 run_lib.py:146] step: 1010800, eval_loss: 2.38283e-02
I0212 15:46:40.901639 22542570456896 run_lib.py:133] step: 1010850, training_loss: 2.81183e-02
I0212 15:46:58.401580 22542570456896 run_lib.py:133] step: 1010900, training_loss: 2.16576e-02
I0212 15:46:58.552587 22542570456896 run_lib.py:146] step: 1010900, eval_loss: 2.50383e-02
I0212 15:47:16.035540 22542570456896 run_lib.py:133] step: 1010950, training_loss: 2.29944e-02
I0212 15:47:33.481132 22542570456896 run_lib.py:133] step: 1011000, training_loss: 3.03169e-02
I0212 15:47:33.651414 22542570456896 run_lib.py:146] step: 1011000, eval_loss: 3.79770e-02
I0212 15:47:51.297988 22542570456896 run_lib.py:133] step: 1011050, training_loss: 2.72577e-02
I0212 15:48:08.951865 22542570456896 run_lib.py:133] step: 1011100, training_loss: 2.80328e-02
I0212 15:48:09.113499 22542570456896 run_lib.py:146] step: 1011100, eval_loss: 2.89174e-02
I0212 15:48:26.561601 22542570456896 run_lib.py:133] step: 1011150, training_loss: 2.59028e-02
I0212 15:48:44.012979 22542570456896 run_lib.py:133] step: 1011200, training_loss: 3.07969e-02
I0212 15:48:44.169164 22542570456896 run_lib.py:146] step: 1011200, eval_loss: 3.25744e-02
I0212 15:49:01.781323 22542570456896 run_lib.py:133] step: 1011250, training_loss: 2.97510e-02
I0212 15:49:19.289985 22542570456896 run_lib.py:133] step: 1011300, training_loss: 2.90136e-02
I0212 15:49:19.447192 22542570456896 run_lib.py:146] step: 1011300, eval_loss: 2.86272e-02
I0212 15:49:37.127996 22542570456896 run_lib.py:133] step: 1011350, training_loss: 2.66725e-02
I0212 15:49:54.629611 22542570456896 run_lib.py:133] step: 1011400, training_loss: 2.69180e-02
I0212 15:49:54.787486 22542570456896 run_lib.py:146] step: 1011400, eval_loss: 3.01459e-02
I0212 15:50:12.426276 22542570456896 run_lib.py:133] step: 1011450, training_loss: 2.84876e-02
I0212 15:50:29.894966 22542570456896 run_lib.py:133] step: 1011500, training_loss: 2.83660e-02
I0212 15:50:30.056777 22542570456896 run_lib.py:146] step: 1011500, eval_loss: 2.87989e-02
I0212 15:50:47.661724 22542570456896 run_lib.py:133] step: 1011550, training_loss: 2.53887e-02
I0212 15:51:05.219062 22542570456896 run_lib.py:133] step: 1011600, training_loss: 2.59810e-02
I0212 15:51:05.377797 22542570456896 run_lib.py:146] step: 1011600, eval_loss: 2.31458e-02
I0212 15:51:22.838886 22542570456896 run_lib.py:133] step: 1011650, training_loss: 2.74269e-02
I0212 15:51:40.476935 22542570456896 run_lib.py:133] step: 1011700, training_loss: 2.60405e-02
I0212 15:51:40.633261 22542570456896 run_lib.py:146] step: 1011700, eval_loss: 2.78506e-02
I0212 15:51:58.101705 22542570456896 run_lib.py:133] step: 1011750, training_loss: 3.53982e-02
I0212 15:52:15.563379 22542570456896 run_lib.py:133] step: 1011800, training_loss: 3.47771e-02
I0212 15:52:15.715043 22542570456896 run_lib.py:146] step: 1011800, eval_loss: 2.07125e-02
I0212 15:52:33.367416 22542570456896 run_lib.py:133] step: 1011850, training_loss: 2.89444e-02
I0212 15:52:50.889942 22542570456896 run_lib.py:133] step: 1011900, training_loss: 2.51334e-02
I0212 15:52:51.056829 22542570456896 run_lib.py:146] step: 1011900, eval_loss: 2.88400e-02
I0212 15:53:08.710439 22542570456896 run_lib.py:133] step: 1011950, training_loss: 2.32964e-02
I0212 15:53:26.206530 22542570456896 run_lib.py:133] step: 1012000, training_loss: 3.63499e-02
I0212 15:53:26.365727 22542570456896 run_lib.py:146] step: 1012000, eval_loss: 3.03689e-02
I0212 15:53:43.819852 22542570456896 run_lib.py:133] step: 1012050, training_loss: 2.42295e-02
I0212 15:54:01.443223 22542570456896 run_lib.py:133] step: 1012100, training_loss: 2.77881e-02
I0212 15:54:01.611431 22542570456896 run_lib.py:146] step: 1012100, eval_loss: 3.01212e-02
I0212 15:54:19.121105 22542570456896 run_lib.py:133] step: 1012150, training_loss: 3.05962e-02
I0212 15:54:36.617723 22542570456896 run_lib.py:133] step: 1012200, training_loss: 2.44318e-02
I0212 15:54:36.775213 22542570456896 run_lib.py:146] step: 1012200, eval_loss: 3.01052e-02
I0212 15:54:54.280314 22542570456896 run_lib.py:133] step: 1012250, training_loss: 3.68523e-02
I0212 15:55:11.938531 22542570456896 run_lib.py:133] step: 1012300, training_loss: 3.08760e-02
I0212 15:55:12.092565 22542570456896 run_lib.py:146] step: 1012300, eval_loss: 3.05040e-02
I0212 15:55:29.534945 22542570456896 run_lib.py:133] step: 1012350, training_loss: 3.17775e-02
I0212 15:55:47.076710 22542570456896 run_lib.py:133] step: 1012400, training_loss: 2.56858e-02
I0212 15:55:47.245713 22542570456896 run_lib.py:146] step: 1012400, eval_loss: 3.48853e-02
I0212 15:56:04.768163 22542570456896 run_lib.py:133] step: 1012450, training_loss: 2.19079e-02
I0212 15:56:22.298187 22542570456896 run_lib.py:133] step: 1012500, training_loss: 2.09070e-02
I0212 15:56:22.458475 22542570456896 run_lib.py:146] step: 1012500, eval_loss: 2.62451e-02
I0212 15:56:40.067671 22542570456896 run_lib.py:133] step: 1012550, training_loss: 3.31129e-02
I0212 15:56:57.619566 22542570456896 run_lib.py:133] step: 1012600, training_loss: 2.92377e-02
I0212 15:56:57.778521 22542570456896 run_lib.py:146] step: 1012600, eval_loss: 3.73927e-02
I0212 15:57:15.242476 22542570456896 run_lib.py:133] step: 1012650, training_loss: 2.71278e-02
I0212 15:57:32.733448 22542570456896 run_lib.py:133] step: 1012700, training_loss: 3.04457e-02
I0212 15:57:32.891738 22542570456896 run_lib.py:146] step: 1012700, eval_loss: 2.89724e-02
I0212 15:57:50.557088 22542570456896 run_lib.py:133] step: 1012750, training_loss: 2.20419e-02
I0212 15:58:08.025342 22542570456896 run_lib.py:133] step: 1012800, training_loss: 3.29556e-02
I0212 15:58:08.184356 22542570456896 run_lib.py:146] step: 1012800, eval_loss: 2.42217e-02
I0212 15:58:25.898816 22542570456896 run_lib.py:133] step: 1012850, training_loss: 3.00010e-02
I0212 15:58:43.403411 22542570456896 run_lib.py:133] step: 1012900, training_loss: 3.35233e-02
I0212 15:58:43.559324 22542570456896 run_lib.py:146] step: 1012900, eval_loss: 2.49952e-02
I0212 15:59:01.159891 22542570456896 run_lib.py:133] step: 1012950, training_loss: 2.28693e-02
I0212 15:59:18.620977 22542570456896 run_lib.py:133] step: 1013000, training_loss: 2.36090e-02
I0212 15:59:18.792557 22542570456896 run_lib.py:146] step: 1013000, eval_loss: 3.32650e-02
I0212 15:59:36.305956 22542570456896 run_lib.py:133] step: 1013050, training_loss: 3.26491e-02
I0212 15:59:53.956095 22542570456896 run_lib.py:133] step: 1013100, training_loss: 2.50866e-02
I0212 15:59:54.112730 22542570456896 run_lib.py:146] step: 1013100, eval_loss: 2.74993e-02
I0212 16:00:11.606662 22542570456896 run_lib.py:133] step: 1013150, training_loss: 2.87746e-02
I0212 16:00:29.229470 22542570456896 run_lib.py:133] step: 1013200, training_loss: 2.59123e-02
I0212 16:00:29.384501 22542570456896 run_lib.py:146] step: 1013200, eval_loss: 3.19004e-02
I0212 16:00:46.854512 22542570456896 run_lib.py:133] step: 1013250, training_loss: 2.99629e-02
I0212 16:01:04.313024 22542570456896 run_lib.py:133] step: 1013300, training_loss: 2.43332e-02
I0212 16:01:04.477428 22542570456896 run_lib.py:146] step: 1013300, eval_loss: 2.79812e-02
I0212 16:01:22.170496 22542570456896 run_lib.py:133] step: 1013350, training_loss: 3.35253e-02
I0212 16:01:39.665080 22542570456896 run_lib.py:133] step: 1013400, training_loss: 2.62786e-02
I0212 16:01:39.833472 22542570456896 run_lib.py:146] step: 1013400, eval_loss: 2.60442e-02
I0212 16:01:57.300196 22542570456896 run_lib.py:133] step: 1013450, training_loss: 2.61906e-02
I0212 16:02:14.957497 22542570456896 run_lib.py:133] step: 1013500, training_loss: 2.60446e-02
I0212 16:02:15.115536 22542570456896 run_lib.py:146] step: 1013500, eval_loss: 2.88196e-02
I0212 16:02:32.616783 22542570456896 run_lib.py:133] step: 1013550, training_loss: 2.32453e-02
I0212 16:02:50.127556 22542570456896 run_lib.py:133] step: 1013600, training_loss: 3.59456e-02
I0212 16:02:50.450327 22542570456896 run_lib.py:146] step: 1013600, eval_loss: 2.90447e-02
I0212 16:03:07.970265 22542570456896 run_lib.py:133] step: 1013650, training_loss: 2.66125e-02
I0212 16:03:25.432684 22542570456896 run_lib.py:133] step: 1013700, training_loss: 2.88052e-02
I0212 16:03:25.585550 22542570456896 run_lib.py:146] step: 1013700, eval_loss: 3.16446e-02
I0212 16:03:43.073218 22542570456896 run_lib.py:133] step: 1013750, training_loss: 2.78276e-02
I0212 16:04:00.564105 22542570456896 run_lib.py:133] step: 1013800, training_loss: 2.63093e-02
I0212 16:04:00.722475 22542570456896 run_lib.py:146] step: 1013800, eval_loss: 2.97878e-02
I0212 16:04:18.428778 22542570456896 run_lib.py:133] step: 1013850, training_loss: 2.93615e-02
I0212 16:04:36.007357 22542570456896 run_lib.py:133] step: 1013900, training_loss: 2.49203e-02
I0212 16:04:36.185497 22542570456896 run_lib.py:146] step: 1013900, eval_loss: 3.75170e-02
I0212 16:04:53.670772 22542570456896 run_lib.py:133] step: 1013950, training_loss: 2.22586e-02
I0212 16:05:11.169312 22542570456896 run_lib.py:133] step: 1014000, training_loss: 2.00830e-02
I0212 16:05:11.328704 22542570456896 run_lib.py:146] step: 1014000, eval_loss: 3.26590e-02
I0212 16:05:29.000441 22542570456896 run_lib.py:133] step: 1014050, training_loss: 2.54337e-02
I0212 16:05:46.519345 22542570456896 run_lib.py:133] step: 1014100, training_loss: 2.76755e-02
I0212 16:05:46.677532 22542570456896 run_lib.py:146] step: 1014100, eval_loss: 2.90777e-02
I0212 16:06:04.158998 22542570456896 run_lib.py:133] step: 1014150, training_loss: 2.40135e-02
I0212 16:06:21.666412 22542570456896 run_lib.py:133] step: 1014200, training_loss: 2.87736e-02
I0212 16:06:21.830574 22542570456896 run_lib.py:146] step: 1014200, eval_loss: 3.49243e-02
I0212 16:06:39.557590 22542570456896 run_lib.py:133] step: 1014250, training_loss: 2.27016e-02
I0212 16:06:57.027358 22542570456896 run_lib.py:133] step: 1014300, training_loss: 2.74062e-02
I0212 16:06:57.184591 22542570456896 run_lib.py:146] step: 1014300, eval_loss: 2.57703e-02
I0212 16:07:14.779580 22542570456896 run_lib.py:133] step: 1014350, training_loss: 3.05420e-02
I0212 16:07:32.249538 22542570456896 run_lib.py:133] step: 1014400, training_loss: 2.81524e-02
I0212 16:07:32.412715 22542570456896 run_lib.py:146] step: 1014400, eval_loss: 2.70430e-02
I0212 16:07:50.058213 22542570456896 run_lib.py:133] step: 1014450, training_loss: 2.67619e-02
I0212 16:08:07.577925 22542570456896 run_lib.py:133] step: 1014500, training_loss: 2.60759e-02
I0212 16:08:07.736931 22542570456896 run_lib.py:146] step: 1014500, eval_loss: 3.37475e-02
I0212 16:08:25.241380 22542570456896 run_lib.py:133] step: 1014550, training_loss: 3.10112e-02
I0212 16:08:42.894765 22542570456896 run_lib.py:133] step: 1014600, training_loss: 2.74309e-02
I0212 16:08:43.050487 22542570456896 run_lib.py:146] step: 1014600, eval_loss: 2.56262e-02
I0212 16:09:00.550533 22542570456896 run_lib.py:133] step: 1014650, training_loss: 2.61316e-02
I0212 16:09:18.162454 22542570456896 run_lib.py:133] step: 1014700, training_loss: 2.72273e-02
I0212 16:09:18.318673 22542570456896 run_lib.py:146] step: 1014700, eval_loss: 2.50251e-02
I0212 16:09:35.840095 22542570456896 run_lib.py:133] step: 1014750, training_loss: 2.68215e-02
I0212 16:09:53.317708 22542570456896 run_lib.py:133] step: 1014800, training_loss: 2.52344e-02
I0212 16:09:53.477461 22542570456896 run_lib.py:146] step: 1014800, eval_loss: 2.24124e-02
I0212 16:10:11.129450 22542570456896 run_lib.py:133] step: 1014850, training_loss: 2.10518e-02
I0212 16:10:28.591171 22542570456896 run_lib.py:133] step: 1014900, training_loss: 2.14077e-02
I0212 16:10:28.750620 22542570456896 run_lib.py:146] step: 1014900, eval_loss: 3.29394e-02
I0212 16:10:46.251073 22542570456896 run_lib.py:133] step: 1014950, training_loss: 2.98408e-02
I0212 16:11:03.792927 22542570456896 run_lib.py:133] step: 1015000, training_loss: 2.40783e-02
I0212 16:11:03.954253 22542570456896 run_lib.py:146] step: 1015000, eval_loss: 3.02169e-02
I0212 16:11:21.617933 22542570456896 run_lib.py:133] step: 1015050, training_loss: 2.75011e-02
I0212 16:11:39.058078 22542570456896 run_lib.py:133] step: 1015100, training_loss: 3.02682e-02
I0212 16:11:39.213237 22542570456896 run_lib.py:146] step: 1015100, eval_loss: 2.96698e-02
I0212 16:11:56.739496 22542570456896 run_lib.py:133] step: 1015150, training_loss: 2.03885e-02
I0212 16:12:14.217210 22542570456896 run_lib.py:133] step: 1015200, training_loss: 2.64809e-02
I0212 16:12:14.374435 22542570456896 run_lib.py:146] step: 1015200, eval_loss: 2.37354e-02
I0212 16:12:31.778208 22542570456896 run_lib.py:133] step: 1015250, training_loss: 2.22725e-02
I0212 16:12:49.170145 22542570456896 run_lib.py:133] step: 1015300, training_loss: 2.62924e-02
I0212 16:12:49.333400 22542570456896 run_lib.py:146] step: 1015300, eval_loss: 2.41335e-02
I0212 16:13:06.927608 22542570456896 run_lib.py:133] step: 1015350, training_loss: 2.86860e-02
I0212 16:13:24.336760 22542570456896 run_lib.py:133] step: 1015400, training_loss: 2.67811e-02
I0212 16:13:24.491271 22542570456896 run_lib.py:146] step: 1015400, eval_loss: 3.33270e-02
I0212 16:13:41.880613 22542570456896 run_lib.py:133] step: 1015450, training_loss: 3.05184e-02
I0212 16:13:59.254525 22542570456896 run_lib.py:133] step: 1015500, training_loss: 2.74315e-02
I0212 16:13:59.423566 22542570456896 run_lib.py:146] step: 1015500, eval_loss: 2.72540e-02
I0212 16:14:16.949106 22542570456896 run_lib.py:133] step: 1015550, training_loss: 3.02819e-02
I0212 16:14:34.395173 22542570456896 run_lib.py:133] step: 1015600, training_loss: 3.69729e-02
I0212 16:14:34.550110 22542570456896 run_lib.py:146] step: 1015600, eval_loss: 3.35510e-02
I0212 16:14:52.113775 22542570456896 run_lib.py:133] step: 1015650, training_loss: 2.51150e-02
I0212 16:15:09.565751 22542570456896 run_lib.py:133] step: 1015700, training_loss: 3.33459e-02
I0212 16:15:09.723577 22542570456896 run_lib.py:146] step: 1015700, eval_loss: 3.00594e-02
I0212 16:15:27.322968 22542570456896 run_lib.py:133] step: 1015750, training_loss: 2.69275e-02
I0212 16:15:44.798654 22542570456896 run_lib.py:133] step: 1015800, training_loss: 2.01639e-02
I0212 16:15:44.976346 22542570456896 run_lib.py:146] step: 1015800, eval_loss: 2.28178e-02
I0212 16:16:02.676265 22542570456896 run_lib.py:133] step: 1015850, training_loss: 2.49792e-02
I0212 16:16:20.168632 22542570456896 run_lib.py:133] step: 1015900, training_loss: 3.26332e-02
I0212 16:16:20.327724 22542570456896 run_lib.py:146] step: 1015900, eval_loss: 2.61583e-02
I0212 16:16:37.799568 22542570456896 run_lib.py:133] step: 1015950, training_loss: 2.99510e-02
I0212 16:16:55.395001 22542570456896 run_lib.py:133] step: 1016000, training_loss: 2.77710e-02
I0212 16:16:55.550157 22542570456896 run_lib.py:146] step: 1016000, eval_loss: 3.10925e-02
I0212 16:17:13.028339 22542570456896 run_lib.py:133] step: 1016050, training_loss: 3.17939e-02
I0212 16:17:30.525971 22542570456896 run_lib.py:133] step: 1016100, training_loss: 2.68088e-02
I0212 16:17:30.681760 22542570456896 run_lib.py:146] step: 1016100, eval_loss: 2.95547e-02
I0212 16:17:48.376497 22542570456896 run_lib.py:133] step: 1016150, training_loss: 2.62096e-02
I0212 16:18:06.056476 22542570456896 run_lib.py:133] step: 1016200, training_loss: 2.17938e-02
I0212 16:18:06.213533 22542570456896 run_lib.py:146] step: 1016200, eval_loss: 2.84336e-02
I0212 16:18:23.666423 22542570456896 run_lib.py:133] step: 1016250, training_loss: 2.29928e-02
I0212 16:18:41.141589 22542570456896 run_lib.py:133] step: 1016300, training_loss: 2.50432e-02
I0212 16:18:41.303612 22542570456896 run_lib.py:146] step: 1016300, eval_loss: 2.59407e-02
I0212 16:18:58.829472 22542570456896 run_lib.py:133] step: 1016350, training_loss: 2.99725e-02
I0212 16:19:16.547828 22542570456896 run_lib.py:133] step: 1016400, training_loss: 3.11788e-02
I0212 16:19:16.707824 22542570456896 run_lib.py:146] step: 1016400, eval_loss: 2.55042e-02
I0212 16:19:34.208423 22542570456896 run_lib.py:133] step: 1016450, training_loss: 3.35869e-02
I0212 16:19:51.665879 22542570456896 run_lib.py:133] step: 1016500, training_loss: 2.94007e-02
I0212 16:19:51.824488 22542570456896 run_lib.py:146] step: 1016500, eval_loss: 2.41403e-02
I0212 16:20:09.306099 22542570456896 run_lib.py:133] step: 1016550, training_loss: 2.36299e-02
I0212 16:20:26.963117 22542570456896 run_lib.py:133] step: 1016600, training_loss: 2.67262e-02
I0212 16:20:27.117542 22542570456896 run_lib.py:146] step: 1016600, eval_loss: 3.01797e-02
I0212 16:20:44.588309 22542570456896 run_lib.py:133] step: 1016650, training_loss: 2.41361e-02
I0212 16:21:02.163081 22542570456896 run_lib.py:133] step: 1016700, training_loss: 3.29036e-02
I0212 16:21:02.338568 22542570456896 run_lib.py:146] step: 1016700, eval_loss: 3.86586e-02
I0212 16:21:19.834109 22542570456896 run_lib.py:133] step: 1016750, training_loss: 3.24401e-02
I0212 16:21:37.303700 22542570456896 run_lib.py:133] step: 1016800, training_loss: 2.49000e-02
I0212 16:21:37.460551 22542570456896 run_lib.py:146] step: 1016800, eval_loss: 3.24319e-02
I0212 16:21:55.128825 22542570456896 run_lib.py:133] step: 1016850, training_loss: 3.00554e-02
I0212 16:22:12.659472 22542570456896 run_lib.py:133] step: 1016900, training_loss: 2.97891e-02
I0212 16:22:12.821204 22542570456896 run_lib.py:146] step: 1016900, eval_loss: 2.48434e-02
I0212 16:22:30.371562 22542570456896 run_lib.py:133] step: 1016950, training_loss: 2.30450e-02
I0212 16:22:47.889651 22542570456896 run_lib.py:133] step: 1017000, training_loss: 2.24656e-02
I0212 16:22:48.044521 22542570456896 run_lib.py:146] step: 1017000, eval_loss: 3.88854e-02
I0212 16:23:05.726003 22542570456896 run_lib.py:133] step: 1017050, training_loss: 2.70160e-02
I0212 16:23:23.162789 22542570456896 run_lib.py:133] step: 1017100, training_loss: 2.99039e-02
I0212 16:23:23.317970 22542570456896 run_lib.py:146] step: 1017100, eval_loss: 2.81262e-02
I0212 16:23:40.929437 22542570456896 run_lib.py:133] step: 1017150, training_loss: 2.44703e-02
I0212 16:23:58.413064 22542570456896 run_lib.py:133] step: 1017200, training_loss: 2.43280e-02
I0212 16:23:58.573609 22542570456896 run_lib.py:146] step: 1017200, eval_loss: 3.03391e-02
I0212 16:24:16.184986 22542570456896 run_lib.py:133] step: 1017250, training_loss: 3.02237e-02
I0212 16:24:33.697715 22542570456896 run_lib.py:133] step: 1017300, training_loss: 2.23345e-02
I0212 16:24:33.856725 22542570456896 run_lib.py:146] step: 1017300, eval_loss: 3.32888e-02
I0212 16:24:51.325067 22542570456896 run_lib.py:133] step: 1017350, training_loss: 2.76887e-02
I0212 16:25:08.949467 22542570456896 run_lib.py:133] step: 1017400, training_loss: 2.65011e-02
I0212 16:25:09.107634 22542570456896 run_lib.py:146] step: 1017400, eval_loss: 2.18997e-02
I0212 16:25:26.598360 22542570456896 run_lib.py:133] step: 1017450, training_loss: 2.71944e-02
I0212 16:25:44.248538 22542570456896 run_lib.py:133] step: 1017500, training_loss: 2.11408e-02
I0212 16:25:44.403627 22542570456896 run_lib.py:146] step: 1017500, eval_loss: 2.66477e-02
I0212 16:26:01.952098 22542570456896 run_lib.py:133] step: 1017550, training_loss: 2.22524e-02
I0212 16:26:19.413320 22542570456896 run_lib.py:133] step: 1017600, training_loss: 2.42984e-02
I0212 16:26:19.571496 22542570456896 run_lib.py:146] step: 1017600, eval_loss: 2.58407e-02
I0212 16:26:37.205555 22542570456896 run_lib.py:133] step: 1017650, training_loss: 2.75827e-02
I0212 16:26:54.683926 22542570456896 run_lib.py:133] step: 1017700, training_loss: 2.76810e-02
I0212 16:26:54.843811 22542570456896 run_lib.py:146] step: 1017700, eval_loss: 2.90140e-02
I0212 16:27:12.345603 22542570456896 run_lib.py:133] step: 1017750, training_loss: 2.29699e-02
I0212 16:27:29.964372 22542570456896 run_lib.py:133] step: 1017800, training_loss: 2.54924e-02
I0212 16:27:30.126585 22542570456896 run_lib.py:146] step: 1017800, eval_loss: 2.71008e-02
I0212 16:27:47.626229 22542570456896 run_lib.py:133] step: 1017850, training_loss: 2.58431e-02
I0212 16:28:05.127904 22542570456896 run_lib.py:133] step: 1017900, training_loss: 2.84788e-02
I0212 16:28:05.284254 22542570456896 run_lib.py:146] step: 1017900, eval_loss: 2.63626e-02
I0212 16:28:22.905433 22542570456896 run_lib.py:133] step: 1017950, training_loss: 2.85743e-02
I0212 16:28:40.374020 22542570456896 run_lib.py:133] step: 1018000, training_loss: 2.31366e-02
I0212 16:28:40.526388 22542570456896 run_lib.py:146] step: 1018000, eval_loss: 2.52230e-02
I0212 16:28:58.016403 22542570456896 run_lib.py:133] step: 1018050, training_loss: 2.31089e-02
I0212 16:29:15.464239 22542570456896 run_lib.py:133] step: 1018100, training_loss: 2.67907e-02
I0212 16:29:15.634918 22542570456896 run_lib.py:146] step: 1018100, eval_loss: 2.61278e-02
I0212 16:29:33.339071 22542570456896 run_lib.py:133] step: 1018150, training_loss: 2.28061e-02
I0212 16:29:50.901660 22542570456896 run_lib.py:133] step: 1018200, training_loss: 2.20470e-02
I0212 16:29:51.061516 22542570456896 run_lib.py:146] step: 1018200, eval_loss: 3.26367e-02
I0212 16:30:08.509539 22542570456896 run_lib.py:133] step: 1018250, training_loss: 2.69986e-02
I0212 16:30:25.956485 22542570456896 run_lib.py:133] step: 1018300, training_loss: 2.68078e-02
I0212 16:30:26.114433 22542570456896 run_lib.py:146] step: 1018300, eval_loss: 3.08789e-02
I0212 16:30:43.743978 22542570456896 run_lib.py:133] step: 1018350, training_loss: 3.21834e-02
I0212 16:31:01.253499 22542570456896 run_lib.py:133] step: 1018400, training_loss: 2.34269e-02
I0212 16:31:01.409647 22542570456896 run_lib.py:146] step: 1018400, eval_loss: 2.46522e-02
I0212 16:31:19.069319 22542570456896 run_lib.py:133] step: 1018450, training_loss: 3.28434e-02
I0212 16:31:36.533974 22542570456896 run_lib.py:133] step: 1018500, training_loss: 3.05846e-02
I0212 16:31:36.694360 22542570456896 run_lib.py:146] step: 1018500, eval_loss: 3.03045e-02
I0212 16:31:54.328722 22542570456896 run_lib.py:133] step: 1018550, training_loss: 3.10826e-02
I0212 16:32:11.789927 22542570456896 run_lib.py:133] step: 1018600, training_loss: 2.34995e-02
I0212 16:32:11.954673 22542570456896 run_lib.py:146] step: 1018600, eval_loss: 2.71669e-02
I0212 16:32:29.593310 22542570456896 run_lib.py:133] step: 1018650, training_loss: 2.20752e-02
I0212 16:32:47.116210 22542570456896 run_lib.py:133] step: 1018700, training_loss: 3.37365e-02
I0212 16:32:47.274868 22542570456896 run_lib.py:146] step: 1018700, eval_loss: 2.96040e-02
I0212 16:33:04.794103 22542570456896 run_lib.py:133] step: 1018750, training_loss: 2.94554e-02
I0212 16:33:22.430095 22542570456896 run_lib.py:133] step: 1018800, training_loss: 2.41871e-02
I0212 16:33:22.587604 22542570456896 run_lib.py:146] step: 1018800, eval_loss: 3.16371e-02
I0212 16:33:40.047424 22542570456896 run_lib.py:133] step: 1018850, training_loss: 2.13139e-02
I0212 16:33:57.496300 22542570456896 run_lib.py:133] step: 1018900, training_loss: 2.89954e-02
I0212 16:33:57.650237 22542570456896 run_lib.py:146] step: 1018900, eval_loss: 3.42670e-02
I0212 16:34:15.305072 22542570456896 run_lib.py:133] step: 1018950, training_loss: 2.54024e-02
I0212 16:34:32.822231 22542570456896 run_lib.py:133] step: 1019000, training_loss: 2.42149e-02
I0212 16:34:32.984724 22542570456896 run_lib.py:146] step: 1019000, eval_loss: 2.46445e-02
I0212 16:34:50.685145 22542570456896 run_lib.py:133] step: 1019050, training_loss: 3.03257e-02
I0212 16:35:08.191130 22542570456896 run_lib.py:133] step: 1019100, training_loss: 2.75041e-02
I0212 16:35:08.357599 22542570456896 run_lib.py:146] step: 1019100, eval_loss: 2.76539e-02
I0212 16:35:25.838618 22542570456896 run_lib.py:133] step: 1019150, training_loss: 2.57812e-02
I0212 16:35:43.445575 22542570456896 run_lib.py:133] step: 1019200, training_loss: 2.26243e-02
I0212 16:35:43.618515 22542570456896 run_lib.py:146] step: 1019200, eval_loss: 2.73265e-02
I0212 16:36:01.119785 22542570456896 run_lib.py:133] step: 1019250, training_loss: 3.25670e-02
I0212 16:36:18.633618 22542570456896 run_lib.py:133] step: 1019300, training_loss: 2.58273e-02
I0212 16:36:18.792039 22542570456896 run_lib.py:146] step: 1019300, eval_loss: 3.22398e-02
I0212 16:36:36.250895 22542570456896 run_lib.py:133] step: 1019350, training_loss: 2.61551e-02
I0212 16:36:53.902936 22542570456896 run_lib.py:133] step: 1019400, training_loss: 3.70989e-02
I0212 16:36:54.055469 22542570456896 run_lib.py:146] step: 1019400, eval_loss: 2.69842e-02
I0212 16:37:11.509300 22542570456896 run_lib.py:133] step: 1019450, training_loss: 2.18978e-02
I0212 16:37:29.084456 22542570456896 run_lib.py:133] step: 1019500, training_loss: 2.67229e-02
I0212 16:37:29.251776 22542570456896 run_lib.py:146] step: 1019500, eval_loss: 2.55814e-02
I0212 16:37:46.752937 22542570456896 run_lib.py:133] step: 1019550, training_loss: 2.08909e-02
I0212 16:38:04.251575 22542570456896 run_lib.py:133] step: 1019600, training_loss: 3.19143e-02
I0212 16:38:04.410394 22542570456896 run_lib.py:146] step: 1019600, eval_loss: 2.80475e-02
I0212 16:38:22.053558 22542570456896 run_lib.py:133] step: 1019650, training_loss: 3.08562e-02
I0212 16:38:39.562983 22542570456896 run_lib.py:133] step: 1019700, training_loss: 2.68409e-02
I0212 16:38:39.724431 22542570456896 run_lib.py:146] step: 1019700, eval_loss: 2.30243e-02
I0212 16:38:57.179092 22542570456896 run_lib.py:133] step: 1019750, training_loss: 2.77882e-02
I0212 16:39:14.692533 22542570456896 run_lib.py:133] step: 1019800, training_loss: 2.32259e-02
I0212 16:39:14.859874 22542570456896 run_lib.py:146] step: 1019800, eval_loss: 2.93035e-02
I0212 16:39:32.574190 22542570456896 run_lib.py:133] step: 1019850, training_loss: 2.91957e-02
I0212 16:39:50.041404 22542570456896 run_lib.py:133] step: 1019900, training_loss: 2.66614e-02
I0212 16:39:50.194391 22542570456896 run_lib.py:146] step: 1019900, eval_loss: 2.85523e-02
I0212 16:40:07.789476 22542570456896 run_lib.py:133] step: 1019950, training_loss: 3.50448e-02
I0212 16:40:25.262783 22542570456896 run_lib.py:133] step: 1020000, training_loss: 2.15138e-02
I0212 16:40:26.001285 22542570456896 run_lib.py:146] step: 1020000, eval_loss: 3.50064e-02
I0212 16:40:46.285874 22542570456896 run_lib.py:133] step: 1020050, training_loss: 2.30369e-02
I0212 16:41:03.772359 22542570456896 run_lib.py:133] step: 1020100, training_loss: 2.97197e-02
I0212 16:41:03.954452 22542570456896 run_lib.py:146] step: 1020100, eval_loss: 3.33775e-02
I0212 16:41:21.509848 22542570456896 run_lib.py:133] step: 1020150, training_loss: 2.70631e-02
I0212 16:41:38.991151 22542570456896 run_lib.py:133] step: 1020200, training_loss: 2.68263e-02
I0212 16:41:39.148771 22542570456896 run_lib.py:146] step: 1020200, eval_loss: 2.14956e-02
I0212 16:41:56.642560 22542570456896 run_lib.py:133] step: 1020250, training_loss: 3.35841e-02
I0212 16:42:14.098901 22542570456896 run_lib.py:133] step: 1020300, training_loss: 3.23725e-02
I0212 16:42:14.256493 22542570456896 run_lib.py:146] step: 1020300, eval_loss: 3.50841e-02
I0212 16:42:31.869882 22542570456896 run_lib.py:133] step: 1020350, training_loss: 2.41404e-02
I0212 16:42:49.495077 22542570456896 run_lib.py:133] step: 1020400, training_loss: 3.18797e-02
I0212 16:42:49.648749 22542570456896 run_lib.py:146] step: 1020400, eval_loss: 2.97406e-02
I0212 16:43:07.015570 22542570456896 run_lib.py:133] step: 1020450, training_loss: 2.82307e-02
I0212 16:43:24.399587 22542570456896 run_lib.py:133] step: 1020500, training_loss: 2.75265e-02
I0212 16:43:24.553317 22542570456896 run_lib.py:146] step: 1020500, eval_loss: 2.77662e-02
I0212 16:43:42.019258 22542570456896 run_lib.py:133] step: 1020550, training_loss: 2.57260e-02
I0212 16:43:59.365246 22542570456896 run_lib.py:133] step: 1020600, training_loss: 2.68804e-02
I0212 16:43:59.529274 22542570456896 run_lib.py:146] step: 1020600, eval_loss: 3.00999e-02
I0212 16:44:17.056009 22542570456896 run_lib.py:133] step: 1020650, training_loss: 2.36330e-02
I0212 16:44:34.459087 22542570456896 run_lib.py:133] step: 1020700, training_loss: 3.30688e-02
I0212 16:44:34.623133 22542570456896 run_lib.py:146] step: 1020700, eval_loss: 2.36157e-02
I0212 16:44:52.179443 22542570456896 run_lib.py:133] step: 1020750, training_loss: 2.44309e-02
I0212 16:45:09.544681 22542570456896 run_lib.py:133] step: 1020800, training_loss: 2.63734e-02
I0212 16:45:09.698115 22542570456896 run_lib.py:146] step: 1020800, eval_loss: 3.18281e-02
I0212 16:45:27.124045 22542570456896 run_lib.py:133] step: 1020850, training_loss: 3.09007e-02
I0212 16:45:44.782812 22542570456896 run_lib.py:133] step: 1020900, training_loss: 2.68759e-02
I0212 16:45:44.937741 22542570456896 run_lib.py:146] step: 1020900, eval_loss: 3.36239e-02
I0212 16:46:02.471608 22542570456896 run_lib.py:133] step: 1020950, training_loss: 2.19530e-02
I0212 16:46:20.144653 22542570456896 run_lib.py:133] step: 1021000, training_loss: 2.93509e-02
I0212 16:46:20.303467 22542570456896 run_lib.py:146] step: 1021000, eval_loss: 2.97769e-02
I0212 16:46:37.783641 22542570456896 run_lib.py:133] step: 1021050, training_loss: 1.79782e-02
I0212 16:46:55.267214 22542570456896 run_lib.py:133] step: 1021100, training_loss: 3.55442e-02
I0212 16:46:55.433597 22542570456896 run_lib.py:146] step: 1021100, eval_loss: 2.54523e-02
I0212 16:47:13.102579 22542570456896 run_lib.py:133] step: 1021150, training_loss: 2.98288e-02
I0212 16:47:30.674478 22542570456896 run_lib.py:133] step: 1021200, training_loss: 2.38166e-02
I0212 16:47:30.833659 22542570456896 run_lib.py:146] step: 1021200, eval_loss: 2.64340e-02
I0212 16:47:48.328895 22542570456896 run_lib.py:133] step: 1021250, training_loss: 2.85399e-02
I0212 16:48:05.969536 22542570456896 run_lib.py:133] step: 1021300, training_loss: 2.48441e-02
I0212 16:48:06.134447 22542570456896 run_lib.py:146] step: 1021300, eval_loss: 2.86542e-02
I0212 16:48:23.607157 22542570456896 run_lib.py:133] step: 1021350, training_loss: 2.39055e-02
I0212 16:48:41.103587 22542570456896 run_lib.py:133] step: 1021400, training_loss: 2.77609e-02
I0212 16:48:41.423119 22542570456896 run_lib.py:146] step: 1021400, eval_loss: 3.17803e-02
I0212 16:48:58.971135 22542570456896 run_lib.py:133] step: 1021450, training_loss: 3.02282e-02
I0212 16:49:16.438697 22542570456896 run_lib.py:133] step: 1021500, training_loss: 2.80716e-02
I0212 16:49:16.596250 22542570456896 run_lib.py:146] step: 1021500, eval_loss: 3.16571e-02
I0212 16:49:34.077683 22542570456896 run_lib.py:133] step: 1021550, training_loss: 2.50530e-02
I0212 16:49:51.566304 22542570456896 run_lib.py:133] step: 1021600, training_loss: 2.17577e-02
I0212 16:49:51.726594 22542570456896 run_lib.py:146] step: 1021600, eval_loss: 2.35366e-02
I0212 16:50:09.397549 22542570456896 run_lib.py:133] step: 1021650, training_loss: 2.81880e-02
I0212 16:50:26.930757 22542570456896 run_lib.py:133] step: 1021700, training_loss: 3.08411e-02
I0212 16:50:27.093556 22542570456896 run_lib.py:146] step: 1021700, eval_loss: 2.54951e-02
I0212 16:50:44.581822 22542570456896 run_lib.py:133] step: 1021750, training_loss: 2.32010e-02
I0212 16:51:02.064388 22542570456896 run_lib.py:133] step: 1021800, training_loss: 2.63780e-02
I0212 16:51:02.220798 22542570456896 run_lib.py:146] step: 1021800, eval_loss: 2.14403e-02
I0212 16:51:19.893388 22542570456896 run_lib.py:133] step: 1021850, training_loss: 3.06565e-02
I0212 16:51:37.414076 22542570456896 run_lib.py:133] step: 1021900, training_loss: 2.62999e-02
I0212 16:51:37.569547 22542570456896 run_lib.py:146] step: 1021900, eval_loss: 2.40313e-02
I0212 16:51:55.033215 22542570456896 run_lib.py:133] step: 1021950, training_loss: 2.97157e-02
I0212 16:52:12.523897 22542570456896 run_lib.py:133] step: 1022000, training_loss: 2.77039e-02
I0212 16:52:12.703394 22542570456896 run_lib.py:146] step: 1022000, eval_loss: 2.65275e-02
I0212 16:52:30.423317 22542570456896 run_lib.py:133] step: 1022050, training_loss: 2.43229e-02
I0212 16:52:47.913002 22542570456896 run_lib.py:133] step: 1022100, training_loss: 2.54006e-02
I0212 16:52:48.078770 22542570456896 run_lib.py:146] step: 1022100, eval_loss: 2.75069e-02
I0212 16:53:05.731887 22542570456896 run_lib.py:133] step: 1022150, training_loss: 1.94969e-02
I0212 16:53:23.156403 22542570456896 run_lib.py:133] step: 1022200, training_loss: 3.47927e-02
I0212 16:53:23.313092 22542570456896 run_lib.py:146] step: 1022200, eval_loss: 2.89890e-02
I0212 16:53:40.933502 22542570456896 run_lib.py:133] step: 1022250, training_loss: 2.55685e-02
I0212 16:53:58.466448 22542570456896 run_lib.py:133] step: 1022300, training_loss: 3.16054e-02
I0212 16:53:58.622239 22542570456896 run_lib.py:146] step: 1022300, eval_loss: 2.68715e-02
I0212 16:54:16.096878 22542570456896 run_lib.py:133] step: 1022350, training_loss: 2.38841e-02
I0212 16:54:33.772698 22542570456896 run_lib.py:133] step: 1022400, training_loss: 2.30945e-02
I0212 16:54:33.929475 22542570456896 run_lib.py:146] step: 1022400, eval_loss: 2.85346e-02
I0212 16:54:51.422308 22542570456896 run_lib.py:133] step: 1022450, training_loss: 2.08743e-02
I0212 16:55:09.020370 22542570456896 run_lib.py:133] step: 1022500, training_loss: 3.46327e-02
I0212 16:55:09.200451 22542570456896 run_lib.py:146] step: 1022500, eval_loss: 2.81899e-02
I0212 16:55:26.693896 22542570456896 run_lib.py:133] step: 1022550, training_loss: 2.18441e-02
I0212 16:55:44.198342 22542570456896 run_lib.py:133] step: 1022600, training_loss: 2.51002e-02
I0212 16:55:44.358769 22542570456896 run_lib.py:146] step: 1022600, eval_loss: 3.15769e-02
I0212 16:56:02.003498 22542570456896 run_lib.py:133] step: 1022650, training_loss: 2.92064e-02
I0212 16:56:19.433245 22542570456896 run_lib.py:133] step: 1022700, training_loss: 2.93732e-02
I0212 16:56:19.597220 22542570456896 run_lib.py:146] step: 1022700, eval_loss: 2.82711e-02
I0212 16:56:37.040523 22542570456896 run_lib.py:133] step: 1022750, training_loss: 2.72042e-02
I0212 16:56:54.521751 22542570456896 run_lib.py:133] step: 1022800, training_loss: 2.34044e-02
I0212 16:56:54.676669 22542570456896 run_lib.py:146] step: 1022800, eval_loss: 2.91439e-02
I0212 16:57:12.395909 22542570456896 run_lib.py:133] step: 1022850, training_loss: 2.74632e-02
I0212 16:57:29.836769 22542570456896 run_lib.py:133] step: 1022900, training_loss: 2.79981e-02
I0212 16:57:29.994407 22542570456896 run_lib.py:146] step: 1022900, eval_loss: 3.12314e-02
I0212 16:57:47.541368 22542570456896 run_lib.py:133] step: 1022950, training_loss: 2.80194e-02
I0212 16:58:04.999776 22542570456896 run_lib.py:133] step: 1023000, training_loss: 2.10574e-02
I0212 16:58:05.159734 22542570456896 run_lib.py:146] step: 1023000, eval_loss: 3.13630e-02
I0212 16:58:22.641728 22542570456896 run_lib.py:133] step: 1023050, training_loss: 2.48620e-02
I0212 16:58:40.119103 22542570456896 run_lib.py:133] step: 1023100, training_loss: 2.67766e-02
I0212 16:58:40.284504 22542570456896 run_lib.py:146] step: 1023100, eval_loss: 2.89506e-02
I0212 16:58:57.904984 22542570456896 run_lib.py:133] step: 1023150, training_loss: 2.48777e-02
I0212 16:59:15.503582 22542570456896 run_lib.py:133] step: 1023200, training_loss: 2.52121e-02
I0212 16:59:15.664535 22542570456896 run_lib.py:146] step: 1023200, eval_loss: 2.45279e-02
I0212 16:59:33.157078 22542570456896 run_lib.py:133] step: 1023250, training_loss: 2.78019e-02
I0212 16:59:50.610114 22542570456896 run_lib.py:133] step: 1023300, training_loss: 2.55776e-02
I0212 16:59:50.762510 22542570456896 run_lib.py:146] step: 1023300, eval_loss: 3.03246e-02
I0212 17:00:08.376867 22542570456896 run_lib.py:133] step: 1023350, training_loss: 2.14463e-02
I0212 17:00:25.895318 22542570456896 run_lib.py:133] step: 1023400, training_loss: 2.45312e-02
I0212 17:00:26.067368 22542570456896 run_lib.py:146] step: 1023400, eval_loss: 2.48093e-02
I0212 17:00:43.717062 22542570456896 run_lib.py:133] step: 1023450, training_loss: 2.70382e-02
I0212 17:01:01.190518 22542570456896 run_lib.py:133] step: 1023500, training_loss: 2.28702e-02
I0212 17:01:01.350480 22542570456896 run_lib.py:146] step: 1023500, eval_loss: 2.72223e-02
I0212 17:01:18.972044 22542570456896 run_lib.py:133] step: 1023550, training_loss: 2.49656e-02
I0212 17:01:36.441595 22542570456896 run_lib.py:133] step: 1023600, training_loss: 2.51205e-02
I0212 17:01:36.604227 22542570456896 run_lib.py:146] step: 1023600, eval_loss: 2.89657e-02
I0212 17:01:54.214589 22542570456896 run_lib.py:133] step: 1023650, training_loss: 2.30265e-02
I0212 17:02:11.721035 22542570456896 run_lib.py:133] step: 1023700, training_loss: 2.79973e-02
I0212 17:02:11.878675 22542570456896 run_lib.py:146] step: 1023700, eval_loss: 3.26420e-02
I0212 17:02:29.368371 22542570456896 run_lib.py:133] step: 1023750, training_loss: 2.43518e-02
I0212 17:02:47.002678 22542570456896 run_lib.py:133] step: 1023800, training_loss: 2.72805e-02
I0212 17:02:47.156383 22542570456896 run_lib.py:146] step: 1023800, eval_loss: 2.93013e-02
I0212 17:03:04.601874 22542570456896 run_lib.py:133] step: 1023850, training_loss: 2.75127e-02
I0212 17:03:22.060149 22542570456896 run_lib.py:133] step: 1023900, training_loss: 2.69774e-02
I0212 17:03:22.222702 22542570456896 run_lib.py:146] step: 1023900, eval_loss: 2.95906e-02
I0212 17:03:39.848006 22542570456896 run_lib.py:133] step: 1023950, training_loss: 2.73393e-02
I0212 17:03:57.597604 22542570456896 run_lib.py:133] step: 1024000, training_loss: 2.56671e-02
I0212 17:03:57.755700 22542570456896 run_lib.py:146] step: 1024000, eval_loss: 2.52714e-02
I0212 17:04:15.189030 22542570456896 run_lib.py:133] step: 1024050, training_loss: 2.41018e-02
I0212 17:04:32.645968 22542570456896 run_lib.py:133] step: 1024100, training_loss: 2.49295e-02
I0212 17:04:32.803199 22542570456896 run_lib.py:146] step: 1024100, eval_loss: 2.92821e-02
I0212 17:04:50.271823 22542570456896 run_lib.py:133] step: 1024150, training_loss: 3.29380e-02
I0212 17:05:07.872753 22542570456896 run_lib.py:133] step: 1024200, training_loss: 2.64542e-02
I0212 17:05:08.027209 22542570456896 run_lib.py:146] step: 1024200, eval_loss: 2.05835e-02
I0212 17:05:25.479330 22542570456896 run_lib.py:133] step: 1024250, training_loss: 2.38985e-02
I0212 17:05:42.959032 22542570456896 run_lib.py:133] step: 1024300, training_loss: 2.67810e-02
I0212 17:05:43.127667 22542570456896 run_lib.py:146] step: 1024300, eval_loss: 2.95265e-02
I0212 17:06:00.626685 22542570456896 run_lib.py:133] step: 1024350, training_loss: 3.05542e-02
I0212 17:06:18.326529 22542570456896 run_lib.py:133] step: 1024400, training_loss: 2.74367e-02
I0212 17:06:18.497474 22542570456896 run_lib.py:146] step: 1024400, eval_loss: 2.70907e-02
I0212 17:06:35.958252 22542570456896 run_lib.py:133] step: 1024450, training_loss: 2.81182e-02
I0212 17:06:53.489334 22542570456896 run_lib.py:133] step: 1024500, training_loss: 2.51201e-02
I0212 17:06:53.666491 22542570456896 run_lib.py:146] step: 1024500, eval_loss: 2.75921e-02
I0212 17:07:11.169127 22542570456896 run_lib.py:133] step: 1024550, training_loss: 2.43907e-02
I0212 17:07:28.652200 22542570456896 run_lib.py:133] step: 1024600, training_loss: 2.70600e-02
I0212 17:07:28.805837 22542570456896 run_lib.py:146] step: 1024600, eval_loss: 3.09350e-02
I0212 17:07:46.503714 22542570456896 run_lib.py:133] step: 1024650, training_loss: 2.27912e-02
I0212 17:08:04.069369 22542570456896 run_lib.py:133] step: 1024700, training_loss: 2.75410e-02
I0212 17:08:04.222159 22542570456896 run_lib.py:146] step: 1024700, eval_loss: 2.86740e-02
I0212 17:08:21.701663 22542570456896 run_lib.py:133] step: 1024750, training_loss: 2.58726e-02
I0212 17:08:39.169995 22542570456896 run_lib.py:133] step: 1024800, training_loss: 2.79842e-02
I0212 17:08:39.341632 22542570456896 run_lib.py:146] step: 1024800, eval_loss: 2.99139e-02
I0212 17:08:57.036888 22542570456896 run_lib.py:133] step: 1024850, training_loss: 2.35928e-02
I0212 17:09:14.568978 22542570456896 run_lib.py:133] step: 1024900, training_loss: 2.48499e-02
I0212 17:09:14.729373 22542570456896 run_lib.py:146] step: 1024900, eval_loss: 2.29901e-02
I0212 17:09:32.326571 22542570456896 run_lib.py:133] step: 1024950, training_loss: 3.24891e-02
I0212 17:09:49.828503 22542570456896 run_lib.py:133] step: 1025000, training_loss: 2.48807e-02
I0212 17:09:49.984479 22542570456896 run_lib.py:146] step: 1025000, eval_loss: 2.78588e-02
I0212 17:10:07.604391 22542570456896 run_lib.py:133] step: 1025050, training_loss: 2.54105e-02
I0212 17:10:25.101710 22542570456896 run_lib.py:133] step: 1025100, training_loss: 3.00593e-02
I0212 17:10:25.257710 22542570456896 run_lib.py:146] step: 1025100, eval_loss: 2.49491e-02
I0212 17:10:42.768125 22542570456896 run_lib.py:133] step: 1025150, training_loss: 2.99154e-02
I0212 17:11:00.445438 22542570456896 run_lib.py:133] step: 1025200, training_loss: 2.85139e-02
I0212 17:11:00.599427 22542570456896 run_lib.py:146] step: 1025200, eval_loss: 3.44475e-02
I0212 17:11:18.075945 22542570456896 run_lib.py:133] step: 1025250, training_loss: 2.65354e-02
I0212 17:11:35.701280 22542570456896 run_lib.py:133] step: 1025300, training_loss: 2.35981e-02
I0212 17:11:35.867500 22542570456896 run_lib.py:146] step: 1025300, eval_loss: 2.38652e-02
I0212 17:11:53.336219 22542570456896 run_lib.py:133] step: 1025350, training_loss: 2.23002e-02
I0212 17:12:10.826220 22542570456896 run_lib.py:133] step: 1025400, training_loss: 2.21816e-02
I0212 17:12:10.984511 22542570456896 run_lib.py:146] step: 1025400, eval_loss: 3.29590e-02
I0212 17:12:28.671105 22542570456896 run_lib.py:133] step: 1025450, training_loss: 2.72598e-02
I0212 17:12:46.120785 22542570456896 run_lib.py:133] step: 1025500, training_loss: 2.20476e-02
I0212 17:12:46.278587 22542570456896 run_lib.py:146] step: 1025500, eval_loss: 3.78436e-02
I0212 17:13:03.747955 22542570456896 run_lib.py:133] step: 1025550, training_loss: 2.43948e-02
I0212 17:13:21.322986 22542570456896 run_lib.py:133] step: 1025600, training_loss: 2.67656e-02
I0212 17:13:21.479322 22542570456896 run_lib.py:146] step: 1025600, eval_loss: 3.14794e-02
I0212 17:13:38.859092 22542570456896 run_lib.py:133] step: 1025650, training_loss: 2.52568e-02
I0212 17:13:56.263741 22542570456896 run_lib.py:133] step: 1025700, training_loss: 3.05284e-02
I0212 17:13:56.427068 22542570456896 run_lib.py:146] step: 1025700, eval_loss: 2.98722e-02
I0212 17:14:13.927245 22542570456896 run_lib.py:133] step: 1025750, training_loss: 2.40324e-02
I0212 17:14:31.325857 22542570456896 run_lib.py:133] step: 1025800, training_loss: 3.01519e-02
I0212 17:14:31.491537 22542570456896 run_lib.py:146] step: 1025800, eval_loss: 3.25176e-02
I0212 17:14:48.869426 22542570456896 run_lib.py:133] step: 1025850, training_loss: 2.17341e-02
I0212 17:15:06.203195 22542570456896 run_lib.py:133] step: 1025900, training_loss: 3.03870e-02
I0212 17:15:06.371242 22542570456896 run_lib.py:146] step: 1025900, eval_loss: 2.76187e-02
I0212 17:15:23.914428 22542570456896 run_lib.py:133] step: 1025950, training_loss: 2.24353e-02
I0212 17:15:41.419258 22542570456896 run_lib.py:133] step: 1026000, training_loss: 3.16786e-02
I0212 17:15:41.574041 22542570456896 run_lib.py:146] step: 1026000, eval_loss: 2.75550e-02
I0212 17:15:58.991991 22542570456896 run_lib.py:133] step: 1026050, training_loss: 2.68886e-02
I0212 17:16:16.462356 22542570456896 run_lib.py:133] step: 1026100, training_loss: 2.44963e-02
I0212 17:16:16.614449 22542570456896 run_lib.py:146] step: 1026100, eval_loss: 2.87155e-02
I0212 17:16:34.257634 22542570456896 run_lib.py:133] step: 1026150, training_loss: 2.65269e-02
I0212 17:16:51.765817 22542570456896 run_lib.py:133] step: 1026200, training_loss: 2.54738e-02
I0212 17:16:51.934654 22542570456896 run_lib.py:146] step: 1026200, eval_loss: 3.06542e-02
I0212 17:17:09.632213 22542570456896 run_lib.py:133] step: 1026250, training_loss: 2.89769e-02
I0212 17:17:27.123699 22542570456896 run_lib.py:133] step: 1026300, training_loss: 2.47365e-02
I0212 17:17:27.284498 22542570456896 run_lib.py:146] step: 1026300, eval_loss: 3.40633e-02
I0212 17:17:44.909109 22542570456896 run_lib.py:133] step: 1026350, training_loss: 2.41578e-02
I0212 17:18:02.339758 22542570456896 run_lib.py:133] step: 1026400, training_loss: 2.37690e-02
I0212 17:18:02.497525 22542570456896 run_lib.py:146] step: 1026400, eval_loss: 3.21001e-02
I0212 17:18:20.144357 22542570456896 run_lib.py:133] step: 1026450, training_loss: 3.00939e-02
I0212 17:18:37.680786 22542570456896 run_lib.py:133] step: 1026500, training_loss: 2.82484e-02
I0212 17:18:37.836881 22542570456896 run_lib.py:146] step: 1026500, eval_loss: 3.38856e-02
I0212 17:18:55.343283 22542570456896 run_lib.py:133] step: 1026550, training_loss: 2.51864e-02
I0212 17:19:12.963537 22542570456896 run_lib.py:133] step: 1026600, training_loss: 2.90451e-02
I0212 17:19:13.117464 22542570456896 run_lib.py:146] step: 1026600, eval_loss: 3.23422e-02
I0212 17:19:30.592634 22542570456896 run_lib.py:133] step: 1026650, training_loss: 2.44030e-02
I0212 17:19:48.035581 22542570456896 run_lib.py:133] step: 1026700, training_loss: 2.57056e-02
I0212 17:19:48.193447 22542570456896 run_lib.py:146] step: 1026700, eval_loss: 2.88762e-02
I0212 17:20:05.827901 22542570456896 run_lib.py:133] step: 1026750, training_loss: 2.99398e-02
I0212 17:20:23.367919 22542570456896 run_lib.py:133] step: 1026800, training_loss: 2.64323e-02
I0212 17:20:23.530854 22542570456896 run_lib.py:146] step: 1026800, eval_loss: 2.94518e-02
I0212 17:20:41.168909 22542570456896 run_lib.py:133] step: 1026850, training_loss: 2.35613e-02
I0212 17:20:58.605165 22542570456896 run_lib.py:133] step: 1026900, training_loss: 2.82286e-02
I0212 17:20:58.762463 22542570456896 run_lib.py:146] step: 1026900, eval_loss: 3.39258e-02
I0212 17:21:16.258631 22542570456896 run_lib.py:133] step: 1026950, training_loss: 2.63095e-02
I0212 17:21:33.855081 22542570456896 run_lib.py:133] step: 1027000, training_loss: 2.77057e-02
I0212 17:21:34.021604 22542570456896 run_lib.py:146] step: 1027000, eval_loss: 2.23817e-02
I0212 17:21:51.480662 22542570456896 run_lib.py:133] step: 1027050, training_loss: 2.49429e-02
I0212 17:22:08.962121 22542570456896 run_lib.py:133] step: 1027100, training_loss: 2.51207e-02
I0212 17:22:09.116759 22542570456896 run_lib.py:146] step: 1027100, eval_loss: 3.09472e-02
I0212 17:22:26.610466 22542570456896 run_lib.py:133] step: 1027150, training_loss: 2.86035e-02
I0212 17:22:44.296996 22542570456896 run_lib.py:133] step: 1027200, training_loss: 2.92346e-02
I0212 17:22:44.455656 22542570456896 run_lib.py:146] step: 1027200, eval_loss: 2.69930e-02
I0212 17:23:01.885347 22542570456896 run_lib.py:133] step: 1027250, training_loss: 2.96468e-02
I0212 17:23:19.463865 22542570456896 run_lib.py:133] step: 1027300, training_loss: 2.43435e-02
I0212 17:23:19.627530 22542570456896 run_lib.py:146] step: 1027300, eval_loss: 3.01268e-02
I0212 17:23:37.115287 22542570456896 run_lib.py:133] step: 1027350, training_loss: 3.31467e-02
I0212 17:23:54.545498 22542570456896 run_lib.py:133] step: 1027400, training_loss: 2.73025e-02
I0212 17:23:54.705275 22542570456896 run_lib.py:146] step: 1027400, eval_loss: 3.01465e-02
I0212 17:24:12.339653 22542570456896 run_lib.py:133] step: 1027450, training_loss: 3.25170e-02
I0212 17:24:29.883806 22542570456896 run_lib.py:133] step: 1027500, training_loss: 2.65819e-02
I0212 17:24:30.039283 22542570456896 run_lib.py:146] step: 1027500, eval_loss: 3.37355e-02
I0212 17:24:47.495260 22542570456896 run_lib.py:133] step: 1027550, training_loss: 2.49418e-02
I0212 17:25:04.982662 22542570456896 run_lib.py:133] step: 1027600, training_loss: 2.65951e-02
I0212 17:25:05.146874 22542570456896 run_lib.py:146] step: 1027600, eval_loss: 2.88554e-02
I0212 17:25:22.863324 22542570456896 run_lib.py:133] step: 1027650, training_loss: 2.98935e-02
I0212 17:25:40.358320 22542570456896 run_lib.py:133] step: 1027700, training_loss: 2.86486e-02
I0212 17:25:40.519718 22542570456896 run_lib.py:146] step: 1027700, eval_loss: 3.04916e-02
I0212 17:25:58.100303 22542570456896 run_lib.py:133] step: 1027750, training_loss: 2.78860e-02
I0212 17:26:15.525086 22542570456896 run_lib.py:133] step: 1027800, training_loss: 2.27550e-02
I0212 17:26:15.689425 22542570456896 run_lib.py:146] step: 1027800, eval_loss: 2.42651e-02
I0212 17:26:33.303910 22542570456896 run_lib.py:133] step: 1027850, training_loss: 2.99842e-02
I0212 17:26:50.828461 22542570456896 run_lib.py:133] step: 1027900, training_loss: 2.79161e-02
I0212 17:26:50.984659 22542570456896 run_lib.py:146] step: 1027900, eval_loss: 2.64443e-02
I0212 17:27:08.462064 22542570456896 run_lib.py:133] step: 1027950, training_loss: 2.68833e-02
I0212 17:27:26.094734 22542570456896 run_lib.py:133] step: 1028000, training_loss: 2.74728e-02
I0212 17:27:26.248616 22542570456896 run_lib.py:146] step: 1028000, eval_loss: 3.01915e-02
I0212 17:27:43.689401 22542570456896 run_lib.py:133] step: 1028050, training_loss: 2.61207e-02
I0212 17:28:01.304959 22542570456896 run_lib.py:133] step: 1028100, training_loss: 2.18864e-02
I0212 17:28:01.471630 22542570456896 run_lib.py:146] step: 1028100, eval_loss: 3.13539e-02
I0212 17:28:18.998705 22542570456896 run_lib.py:133] step: 1028150, training_loss: 2.83158e-02
I0212 17:28:36.485027 22542570456896 run_lib.py:133] step: 1028200, training_loss: 2.27458e-02
I0212 17:28:36.645341 22542570456896 run_lib.py:146] step: 1028200, eval_loss: 2.95921e-02
I0212 17:28:54.295153 22542570456896 run_lib.py:133] step: 1028250, training_loss: 2.62088e-02
I0212 17:29:11.741585 22542570456896 run_lib.py:133] step: 1028300, training_loss: 2.33840e-02
I0212 17:29:11.898418 22542570456896 run_lib.py:146] step: 1028300, eval_loss: 2.74056e-02
I0212 17:29:29.348268 22542570456896 run_lib.py:133] step: 1028350, training_loss: 2.65075e-02
I0212 17:29:46.950881 22542570456896 run_lib.py:133] step: 1028400, training_loss: 3.29942e-02
I0212 17:29:47.107667 22542570456896 run_lib.py:146] step: 1028400, eval_loss: 2.97362e-02
I0212 17:30:04.609789 22542570456896 run_lib.py:133] step: 1028450, training_loss: 2.68836e-02
I0212 17:30:22.074770 22542570456896 run_lib.py:133] step: 1028500, training_loss: 3.28370e-02
I0212 17:30:22.431366 22542570456896 run_lib.py:146] step: 1028500, eval_loss: 3.47568e-02
I0212 17:30:39.889091 22542570456896 run_lib.py:133] step: 1028550, training_loss: 3.29464e-02
I0212 17:30:57.331183 22542570456896 run_lib.py:133] step: 1028600, training_loss: 3.08655e-02
I0212 17:30:57.488443 22542570456896 run_lib.py:146] step: 1028600, eval_loss: 2.86909e-02
I0212 17:31:14.904609 22542570456896 run_lib.py:133] step: 1028650, training_loss: 2.83615e-02
I0212 17:31:32.400907 22542570456896 run_lib.py:133] step: 1028700, training_loss: 2.20195e-02
I0212 17:31:32.578404 22542570456896 run_lib.py:146] step: 1028700, eval_loss: 2.98067e-02
I0212 17:31:50.270336 22542570456896 run_lib.py:133] step: 1028750, training_loss: 2.92510e-02
I0212 17:32:07.835758 22542570456896 run_lib.py:133] step: 1028800, training_loss: 3.00237e-02
I0212 17:32:07.993783 22542570456896 run_lib.py:146] step: 1028800, eval_loss: 3.07461e-02
I0212 17:32:25.470835 22542570456896 run_lib.py:133] step: 1028850, training_loss: 2.37769e-02
I0212 17:32:42.937522 22542570456896 run_lib.py:133] step: 1028900, training_loss: 2.57772e-02
I0212 17:32:43.093472 22542570456896 run_lib.py:146] step: 1028900, eval_loss: 2.80087e-02
I0212 17:33:00.697353 22542570456896 run_lib.py:133] step: 1028950, training_loss: 2.77406e-02
I0212 17:33:18.309702 22542570456896 run_lib.py:133] step: 1029000, training_loss: 2.87442e-02
I0212 17:33:18.470764 22542570456896 run_lib.py:146] step: 1029000, eval_loss: 2.75714e-02
I0212 17:33:35.976422 22542570456896 run_lib.py:133] step: 1029050, training_loss: 2.23927e-02
I0212 17:33:53.466347 22542570456896 run_lib.py:133] step: 1029100, training_loss: 2.16752e-02
I0212 17:33:53.631862 22542570456896 run_lib.py:146] step: 1029100, eval_loss: 3.41666e-02
I0212 17:34:11.234729 22542570456896 run_lib.py:133] step: 1029150, training_loss: 2.77439e-02
I0212 17:34:28.669712 22542570456896 run_lib.py:133] step: 1029200, training_loss: 2.74052e-02
I0212 17:34:28.826603 22542570456896 run_lib.py:146] step: 1029200, eval_loss: 3.34458e-02
I0212 17:34:46.471694 22542570456896 run_lib.py:133] step: 1029250, training_loss: 2.55810e-02
I0212 17:35:03.992801 22542570456896 run_lib.py:133] step: 1029300, training_loss: 2.51516e-02
I0212 17:35:04.151312 22542570456896 run_lib.py:146] step: 1029300, eval_loss: 2.77731e-02
I0212 17:35:21.814680 22542570456896 run_lib.py:133] step: 1029350, training_loss: 2.89839e-02
I0212 17:35:39.255945 22542570456896 run_lib.py:133] step: 1029400, training_loss: 2.31955e-02
I0212 17:35:39.409217 22542570456896 run_lib.py:146] step: 1029400, eval_loss: 2.83842e-02
I0212 17:35:56.897251 22542570456896 run_lib.py:133] step: 1029450, training_loss: 2.70157e-02
I0212 17:36:14.530925 22542570456896 run_lib.py:133] step: 1029500, training_loss: 3.08905e-02
I0212 17:36:14.691667 22542570456896 run_lib.py:146] step: 1029500, eval_loss: 3.09131e-02
I0212 17:36:32.208059 22542570456896 run_lib.py:133] step: 1029550, training_loss: 2.86467e-02
I0212 17:36:49.905375 22542570456896 run_lib.py:133] step: 1029600, training_loss: 2.21329e-02
I0212 17:36:50.065495 22542570456896 run_lib.py:146] step: 1029600, eval_loss: 3.11785e-02
I0212 17:37:07.521526 22542570456896 run_lib.py:133] step: 1029650, training_loss: 2.17811e-02
I0212 17:37:24.987764 22542570456896 run_lib.py:133] step: 1029700, training_loss: 3.03536e-02
I0212 17:37:25.154483 22542570456896 run_lib.py:146] step: 1029700, eval_loss: 3.06596e-02
I0212 17:37:42.809984 22542570456896 run_lib.py:133] step: 1029750, training_loss: 2.50992e-02
I0212 17:38:00.348864 22542570456896 run_lib.py:133] step: 1029800, training_loss: 2.25080e-02
I0212 17:38:00.507596 22542570456896 run_lib.py:146] step: 1029800, eval_loss: 2.77369e-02
I0212 17:38:18.020500 22542570456896 run_lib.py:133] step: 1029850, training_loss: 3.17254e-02
I0212 17:38:35.490736 22542570456896 run_lib.py:133] step: 1029900, training_loss: 2.65647e-02
I0212 17:38:35.652396 22542570456896 run_lib.py:146] step: 1029900, eval_loss: 2.53332e-02
I0212 17:38:53.310967 22542570456896 run_lib.py:133] step: 1029950, training_loss: 2.82117e-02
I0212 17:39:10.772849 22542570456896 run_lib.py:133] step: 1030000, training_loss: 3.03057e-02
I0212 17:39:11.496489 22542570456896 run_lib.py:146] step: 1030000, eval_loss: 3.52011e-02
I0212 17:39:31.754150 22542570456896 run_lib.py:133] step: 1030050, training_loss: 2.53706e-02
I0212 17:39:49.235524 22542570456896 run_lib.py:133] step: 1030100, training_loss: 2.11434e-02
I0212 17:39:49.408952 22542570456896 run_lib.py:146] step: 1030100, eval_loss: 3.29609e-02
I0212 17:40:07.065857 22542570456896 run_lib.py:133] step: 1030150, training_loss: 2.78253e-02
I0212 17:40:24.611903 22542570456896 run_lib.py:133] step: 1030200, training_loss: 2.99780e-02
I0212 17:40:24.771212 22542570456896 run_lib.py:146] step: 1030200, eval_loss: 3.10569e-02
I0212 17:40:42.244482 22542570456896 run_lib.py:133] step: 1030250, training_loss: 2.72069e-02
I0212 17:40:59.858475 22542570456896 run_lib.py:133] step: 1030300, training_loss: 2.89614e-02
I0212 17:41:00.015773 22542570456896 run_lib.py:146] step: 1030300, eval_loss: 3.61928e-02
I0212 17:41:17.471277 22542570456896 run_lib.py:133] step: 1030350, training_loss: 3.04678e-02
I0212 17:41:34.969231 22542570456896 run_lib.py:133] step: 1030400, training_loss: 2.38495e-02
I0212 17:41:35.123798 22542570456896 run_lib.py:146] step: 1030400, eval_loss: 2.94429e-02
I0212 17:41:52.607265 22542570456896 run_lib.py:133] step: 1030450, training_loss: 3.29359e-02
I0212 17:42:10.249156 22542570456896 run_lib.py:133] step: 1030500, training_loss: 3.00780e-02
I0212 17:42:10.402782 22542570456896 run_lib.py:146] step: 1030500, eval_loss: 3.02275e-02
I0212 17:42:27.848262 22542570456896 run_lib.py:133] step: 1030550, training_loss: 2.51887e-02
I0212 17:42:45.396420 22542570456896 run_lib.py:133] step: 1030600, training_loss: 2.71497e-02
I0212 17:42:45.570397 22542570456896 run_lib.py:146] step: 1030600, eval_loss: 3.16851e-02
I0212 17:43:03.097207 22542570456896 run_lib.py:133] step: 1030650, training_loss: 3.47888e-02
I0212 17:43:20.557522 22542570456896 run_lib.py:133] step: 1030700, training_loss: 2.76586e-02
I0212 17:43:20.715436 22542570456896 run_lib.py:146] step: 1030700, eval_loss: 2.96376e-02
I0212 17:43:38.379678 22542570456896 run_lib.py:133] step: 1030750, training_loss: 3.08516e-02
I0212 17:43:55.905538 22542570456896 run_lib.py:133] step: 1030800, training_loss: 2.54506e-02
I0212 17:43:56.062569 22542570456896 run_lib.py:146] step: 1030800, eval_loss: 2.93512e-02
I0212 17:44:13.474665 22542570456896 run_lib.py:133] step: 1030850, training_loss: 2.50279e-02
I0212 17:44:30.848526 22542570456896 run_lib.py:133] step: 1030900, training_loss: 2.72753e-02
I0212 17:44:31.004173 22542570456896 run_lib.py:146] step: 1030900, eval_loss: 2.42691e-02
I0212 17:44:48.543985 22542570456896 run_lib.py:133] step: 1030950, training_loss: 2.52265e-02
I0212 17:45:05.924473 22542570456896 run_lib.py:133] step: 1031000, training_loss: 2.31770e-02
I0212 17:45:06.078298 22542570456896 run_lib.py:146] step: 1031000, eval_loss: 2.13208e-02
I0212 17:45:23.608442 22542570456896 run_lib.py:133] step: 1031050, training_loss: 2.39168e-02
I0212 17:45:41.007966 22542570456896 run_lib.py:133] step: 1031100, training_loss: 2.69913e-02
I0212 17:45:41.166755 22542570456896 run_lib.py:146] step: 1031100, eval_loss: 3.35019e-02
I0212 17:45:58.672170 22542570456896 run_lib.py:133] step: 1031150, training_loss: 2.78338e-02
I0212 17:46:16.072007 22542570456896 run_lib.py:133] step: 1031200, training_loss: 2.39338e-02
I0212 17:46:16.244257 22542570456896 run_lib.py:146] step: 1031200, eval_loss: 2.40672e-02
I0212 17:46:33.725590 22542570456896 run_lib.py:133] step: 1031250, training_loss: 2.90133e-02
I0212 17:46:51.402615 22542570456896 run_lib.py:133] step: 1031300, training_loss: 2.50117e-02
I0212 17:46:51.558711 22542570456896 run_lib.py:146] step: 1031300, eval_loss: 2.47591e-02
I0212 17:47:09.061558 22542570456896 run_lib.py:133] step: 1031350, training_loss: 2.56240e-02
I0212 17:47:26.680315 22542570456896 run_lib.py:133] step: 1031400, training_loss: 3.13368e-02
I0212 17:47:26.841216 22542570456896 run_lib.py:146] step: 1031400, eval_loss: 2.97078e-02
I0212 17:47:44.309056 22542570456896 run_lib.py:133] step: 1031450, training_loss: 2.77053e-02
I0212 17:48:01.804822 22542570456896 run_lib.py:133] step: 1031500, training_loss: 2.42959e-02
I0212 17:48:01.975572 22542570456896 run_lib.py:146] step: 1031500, eval_loss: 2.48734e-02
I0212 17:48:19.668490 22542570456896 run_lib.py:133] step: 1031550, training_loss: 3.04340e-02
I0212 17:48:37.182136 22542570456896 run_lib.py:133] step: 1031600, training_loss: 2.74036e-02
I0212 17:48:37.344464 22542570456896 run_lib.py:146] step: 1031600, eval_loss: 3.49196e-02
I0212 17:48:54.826545 22542570456896 run_lib.py:133] step: 1031650, training_loss: 2.48598e-02
I0212 17:49:12.275219 22542570456896 run_lib.py:133] step: 1031700, training_loss: 2.47589e-02
I0212 17:49:12.432413 22542570456896 run_lib.py:146] step: 1031700, eval_loss: 2.29030e-02
I0212 17:49:30.038800 22542570456896 run_lib.py:133] step: 1031750, training_loss: 2.32812e-02
I0212 17:49:47.591578 22542570456896 run_lib.py:133] step: 1031800, training_loss: 2.45351e-02
I0212 17:49:47.749589 22542570456896 run_lib.py:146] step: 1031800, eval_loss: 3.36960e-02
I0212 17:50:05.327104 22542570456896 run_lib.py:133] step: 1031850, training_loss: 2.24454e-02
I0212 17:50:22.759076 22542570456896 run_lib.py:133] step: 1031900, training_loss: 2.38232e-02
I0212 17:50:22.912439 22542570456896 run_lib.py:146] step: 1031900, eval_loss: 2.76635e-02
I0212 17:50:40.360081 22542570456896 run_lib.py:133] step: 1031950, training_loss: 2.35658e-02
I0212 17:50:57.862270 22542570456896 run_lib.py:133] step: 1032000, training_loss: 2.97852e-02
I0212 17:50:58.029586 22542570456896 run_lib.py:146] step: 1032000, eval_loss: 2.91063e-02
I0212 17:51:15.680606 22542570456896 run_lib.py:133] step: 1032050, training_loss: 2.45105e-02
I0212 17:51:33.277711 22542570456896 run_lib.py:133] step: 1032100, training_loss: 2.50337e-02
I0212 17:51:33.438494 22542570456896 run_lib.py:146] step: 1032100, eval_loss: 2.59942e-02
I0212 17:51:50.904587 22542570456896 run_lib.py:133] step: 1032150, training_loss: 2.04277e-02
I0212 17:52:08.354099 22542570456896 run_lib.py:133] step: 1032200, training_loss: 3.36281e-02
I0212 17:52:08.511234 22542570456896 run_lib.py:146] step: 1032200, eval_loss: 2.63611e-02
I0212 17:52:26.115547 22542570456896 run_lib.py:133] step: 1032250, training_loss: 2.57083e-02
I0212 17:52:43.559834 22542570456896 run_lib.py:133] step: 1032300, training_loss: 3.11269e-02
I0212 17:52:43.718703 22542570456896 run_lib.py:146] step: 1032300, eval_loss: 2.66978e-02
I0212 17:53:01.366777 22542570456896 run_lib.py:133] step: 1032350, training_loss: 3.05548e-02
I0212 17:53:18.893334 22542570456896 run_lib.py:133] step: 1032400, training_loss: 2.92520e-02
I0212 17:53:19.047670 22542570456896 run_lib.py:146] step: 1032400, eval_loss: 2.58879e-02
I0212 17:53:36.669033 22542570456896 run_lib.py:133] step: 1032450, training_loss: 2.92544e-02
I0212 17:53:54.133125 22542570456896 run_lib.py:133] step: 1032500, training_loss: 2.31030e-02
I0212 17:53:54.293499 22542570456896 run_lib.py:146] step: 1032500, eval_loss: 3.18018e-02
I0212 17:54:11.887540 22542570456896 run_lib.py:133] step: 1032550, training_loss: 2.57301e-02
I0212 17:54:29.362431 22542570456896 run_lib.py:133] step: 1032600, training_loss: 2.91404e-02
I0212 17:54:29.525370 22542570456896 run_lib.py:146] step: 1032600, eval_loss: 2.63291e-02
I0212 17:54:47.012637 22542570456896 run_lib.py:133] step: 1032650, training_loss: 2.93847e-02
I0212 17:55:04.700477 22542570456896 run_lib.py:133] step: 1032700, training_loss: 2.55739e-02
I0212 17:55:04.857683 22542570456896 run_lib.py:146] step: 1032700, eval_loss: 3.08516e-02
I0212 17:55:22.350248 22542570456896 run_lib.py:133] step: 1032750, training_loss: 2.39122e-02
I0212 17:55:39.819766 22542570456896 run_lib.py:133] step: 1032800, training_loss: 2.74867e-02
I0212 17:55:39.973241 22542570456896 run_lib.py:146] step: 1032800, eval_loss: 2.27329e-02
I0212 17:55:57.590313 22542570456896 run_lib.py:133] step: 1032850, training_loss: 2.64472e-02
I0212 17:56:15.280531 22542570456896 run_lib.py:133] step: 1032900, training_loss: 2.69702e-02
I0212 17:56:15.445556 22542570456896 run_lib.py:146] step: 1032900, eval_loss: 2.77069e-02
I0212 17:56:32.952322 22542570456896 run_lib.py:133] step: 1032950, training_loss: 2.51118e-02
I0212 17:56:50.439123 22542570456896 run_lib.py:133] step: 1033000, training_loss: 2.65172e-02
I0212 17:56:50.607640 22542570456896 run_lib.py:146] step: 1033000, eval_loss: 3.00325e-02
I0212 17:57:08.056123 22542570456896 run_lib.py:133] step: 1033050, training_loss: 3.13627e-02
I0212 17:57:25.674852 22542570456896 run_lib.py:133] step: 1033100, training_loss: 2.66838e-02
I0212 17:57:25.832368 22542570456896 run_lib.py:146] step: 1033100, eval_loss: 2.71688e-02
I0212 17:57:43.287680 22542570456896 run_lib.py:133] step: 1033150, training_loss: 3.11058e-02
I0212 17:58:00.809904 22542570456896 run_lib.py:133] step: 1033200, training_loss: 2.88199e-02
I0212 17:58:00.968798 22542570456896 run_lib.py:146] step: 1033200, eval_loss: 2.76115e-02
I0212 17:58:18.471765 22542570456896 run_lib.py:133] step: 1033250, training_loss: 3.56040e-02
I0212 17:58:36.112270 22542570456896 run_lib.py:133] step: 1033300, training_loss: 2.84658e-02
I0212 17:58:36.264444 22542570456896 run_lib.py:146] step: 1033300, eval_loss: 2.43484e-02
I0212 17:58:53.701877 22542570456896 run_lib.py:133] step: 1033350, training_loss: 2.45782e-02
I0212 17:59:11.258397 22542570456896 run_lib.py:133] step: 1033400, training_loss: 2.84418e-02
I0212 17:59:11.439915 22542570456896 run_lib.py:146] step: 1033400, eval_loss: 3.29118e-02
I0212 17:59:28.957508 22542570456896 run_lib.py:133] step: 1033450, training_loss: 2.77069e-02
I0212 17:59:46.462915 22542570456896 run_lib.py:133] step: 1033500, training_loss: 2.78713e-02
I0212 17:59:46.622473 22542570456896 run_lib.py:146] step: 1033500, eval_loss: 2.81780e-02
I0212 18:00:04.293344 22542570456896 run_lib.py:133] step: 1033550, training_loss: 2.21413e-02
I0212 18:00:21.846303 22542570456896 run_lib.py:133] step: 1033600, training_loss: 2.31844e-02
I0212 18:00:22.003444 22542570456896 run_lib.py:146] step: 1033600, eval_loss: 2.97284e-02
I0212 18:00:39.457247 22542570456896 run_lib.py:133] step: 1033650, training_loss: 2.30215e-02
I0212 18:00:56.960529 22542570456896 run_lib.py:133] step: 1033700, training_loss: 2.36542e-02
I0212 18:00:57.118116 22542570456896 run_lib.py:146] step: 1033700, eval_loss: 3.18055e-02
I0212 18:01:14.763516 22542570456896 run_lib.py:133] step: 1033750, training_loss: 2.84993e-02
I0212 18:01:32.227411 22542570456896 run_lib.py:133] step: 1033800, training_loss: 3.46741e-02
I0212 18:01:32.382505 22542570456896 run_lib.py:146] step: 1033800, eval_loss: 3.01816e-02
I0212 18:01:50.039540 22542570456896 run_lib.py:133] step: 1033850, training_loss: 3.07641e-02
I0212 18:02:07.504811 22542570456896 run_lib.py:133] step: 1033900, training_loss: 2.62415e-02
I0212 18:02:07.663314 22542570456896 run_lib.py:146] step: 1033900, eval_loss: 2.66675e-02
I0212 18:02:25.258924 22542570456896 run_lib.py:133] step: 1033950, training_loss: 2.56730e-02
I0212 18:02:42.729200 22542570456896 run_lib.py:133] step: 1034000, training_loss: 3.50848e-02
I0212 18:02:42.911493 22542570456896 run_lib.py:146] step: 1034000, eval_loss: 3.11376e-02
I0212 18:03:00.418032 22542570456896 run_lib.py:133] step: 1034050, training_loss: 2.39949e-02
I0212 18:03:18.068885 22542570456896 run_lib.py:133] step: 1034100, training_loss: 2.45643e-02
I0212 18:03:18.225635 22542570456896 run_lib.py:146] step: 1034100, eval_loss: 2.86741e-02
I0212 18:03:35.746271 22542570456896 run_lib.py:133] step: 1034150, training_loss: 2.48915e-02
I0212 18:03:53.333141 22542570456896 run_lib.py:133] step: 1034200, training_loss: 2.61375e-02
I0212 18:03:53.489232 22542570456896 run_lib.py:146] step: 1034200, eval_loss: 2.90878e-02
I0212 18:04:10.951079 22542570456896 run_lib.py:133] step: 1034250, training_loss: 2.42309e-02
I0212 18:04:28.436974 22542570456896 run_lib.py:133] step: 1034300, training_loss: 3.46394e-02
I0212 18:04:28.592653 22542570456896 run_lib.py:146] step: 1034300, eval_loss: 2.99036e-02
I0212 18:04:46.305851 22542570456896 run_lib.py:133] step: 1034350, training_loss: 2.89650e-02
I0212 18:05:03.763959 22542570456896 run_lib.py:133] step: 1034400, training_loss: 2.86911e-02
I0212 18:05:03.923618 22542570456896 run_lib.py:146] step: 1034400, eval_loss: 3.02875e-02
I0212 18:05:21.341184 22542570456896 run_lib.py:133] step: 1034450, training_loss: 2.36268e-02
I0212 18:05:38.923377 22542570456896 run_lib.py:133] step: 1034500, training_loss: 2.41361e-02
I0212 18:05:39.080630 22542570456896 run_lib.py:146] step: 1034500, eval_loss: 3.55937e-02
I0212 18:05:56.572417 22542570456896 run_lib.py:133] step: 1034550, training_loss: 2.72318e-02
I0212 18:06:14.080630 22542570456896 run_lib.py:133] step: 1034600, training_loss: 2.45775e-02
I0212 18:06:14.241202 22542570456896 run_lib.py:146] step: 1034600, eval_loss: 2.88839e-02
I0212 18:06:31.833847 22542570456896 run_lib.py:133] step: 1034650, training_loss: 2.18653e-02
I0212 18:06:49.282118 22542570456896 run_lib.py:133] step: 1034700, training_loss: 2.60434e-02
I0212 18:06:49.438156 22542570456896 run_lib.py:146] step: 1034700, eval_loss: 2.80387e-02
I0212 18:07:06.902569 22542570456896 run_lib.py:133] step: 1034750, training_loss: 3.06231e-02
I0212 18:07:24.384835 22542570456896 run_lib.py:133] step: 1034800, training_loss: 2.77047e-02
I0212 18:07:24.543511 22542570456896 run_lib.py:146] step: 1034800, eval_loss: 3.24389e-02
I0212 18:07:42.172236 22542570456896 run_lib.py:133] step: 1034850, training_loss: 2.77127e-02
I0212 18:07:59.792116 22542570456896 run_lib.py:133] step: 1034900, training_loss: 2.35664e-02
I0212 18:07:59.954410 22542570456896 run_lib.py:146] step: 1034900, eval_loss: 3.87149e-02
I0212 18:08:17.428049 22542570456896 run_lib.py:133] step: 1034950, training_loss: 2.69137e-02
I0212 18:08:34.880954 22542570456896 run_lib.py:133] step: 1035000, training_loss: 2.30599e-02
I0212 18:08:35.038526 22542570456896 run_lib.py:146] step: 1035000, eval_loss: 3.08941e-02
I0212 18:08:52.633062 22542570456896 run_lib.py:133] step: 1035050, training_loss: 2.31776e-02
I0212 18:09:10.091609 22542570456896 run_lib.py:133] step: 1035100, training_loss: 2.79602e-02
I0212 18:09:10.250541 22542570456896 run_lib.py:146] step: 1035100, eval_loss: 2.37973e-02
I0212 18:09:27.926697 22542570456896 run_lib.py:133] step: 1035150, training_loss: 2.39446e-02
I0212 18:09:45.378454 22542570456896 run_lib.py:133] step: 1035200, training_loss: 2.44132e-02
I0212 18:09:45.531391 22542570456896 run_lib.py:146] step: 1035200, eval_loss: 2.44023e-02
I0212 18:10:03.215860 22542570456896 run_lib.py:133] step: 1035250, training_loss: 2.51859e-02
I0212 18:10:20.682643 22542570456896 run_lib.py:133] step: 1035300, training_loss: 2.84949e-02
I0212 18:10:20.841419 22542570456896 run_lib.py:146] step: 1035300, eval_loss: 2.90730e-02
I0212 18:10:38.460388 22542570456896 run_lib.py:133] step: 1035350, training_loss: 2.15670e-02
I0212 18:10:55.975738 22542570456896 run_lib.py:133] step: 1035400, training_loss: 2.70159e-02
I0212 18:10:56.139404 22542570456896 run_lib.py:146] step: 1035400, eval_loss: 2.15864e-02
I0212 18:11:13.627757 22542570456896 run_lib.py:133] step: 1035450, training_loss: 2.42357e-02
I0212 18:11:31.297025 22542570456896 run_lib.py:133] step: 1035500, training_loss: 2.97652e-02
I0212 18:11:31.452618 22542570456896 run_lib.py:146] step: 1035500, eval_loss: 2.96393e-02
I0212 18:11:48.915226 22542570456896 run_lib.py:133] step: 1035550, training_loss: 3.25457e-02
I0212 18:12:06.342972 22542570456896 run_lib.py:133] step: 1035600, training_loss: 2.82810e-02
I0212 18:12:06.499590 22542570456896 run_lib.py:146] step: 1035600, eval_loss: 2.44928e-02
I0212 18:12:24.114010 22542570456896 run_lib.py:133] step: 1035650, training_loss: 2.79524e-02
I0212 18:12:41.651359 22542570456896 run_lib.py:133] step: 1035700, training_loss: 2.49294e-02
I0212 18:12:41.807716 22542570456896 run_lib.py:146] step: 1035700, eval_loss: 3.39350e-02
I0212 18:12:59.476876 22542570456896 run_lib.py:133] step: 1035750, training_loss: 3.27476e-02
I0212 18:13:16.930186 22542570456896 run_lib.py:133] step: 1035800, training_loss: 3.30413e-02
I0212 18:13:17.088508 22542570456896 run_lib.py:146] step: 1035800, eval_loss: 3.00021e-02
I0212 18:13:34.540749 22542570456896 run_lib.py:133] step: 1035850, training_loss: 1.89616e-02
I0212 18:13:52.172379 22542570456896 run_lib.py:133] step: 1035900, training_loss: 2.47357e-02
I0212 18:13:52.336641 22542570456896 run_lib.py:146] step: 1035900, eval_loss: 2.47253e-02
I0212 18:14:09.844895 22542570456896 run_lib.py:133] step: 1035950, training_loss: 2.54722e-02
I0212 18:14:27.365616 22542570456896 run_lib.py:133] step: 1036000, training_loss: 2.55233e-02
I0212 18:14:27.527145 22542570456896 run_lib.py:146] step: 1036000, eval_loss: 2.72524e-02
I0212 18:14:44.969167 22542570456896 run_lib.py:133] step: 1036050, training_loss: 2.81954e-02
I0212 18:15:02.514848 22542570456896 run_lib.py:133] step: 1036100, training_loss: 2.84982e-02
I0212 18:15:02.672268 22542570456896 run_lib.py:146] step: 1036100, eval_loss: 3.34301e-02
I0212 18:15:20.028332 22542570456896 run_lib.py:133] step: 1036150, training_loss: 2.12209e-02
I0212 18:15:37.446039 22542570456896 run_lib.py:133] step: 1036200, training_loss: 2.75957e-02
I0212 18:15:37.597357 22542570456896 run_lib.py:146] step: 1036200, eval_loss: 2.21636e-02
I0212 18:15:54.981322 22542570456896 run_lib.py:133] step: 1036250, training_loss: 2.76183e-02
I0212 18:16:12.409081 22542570456896 run_lib.py:133] step: 1036300, training_loss: 2.49047e-02
I0212 18:16:12.569439 22542570456896 run_lib.py:146] step: 1036300, eval_loss: 3.46451e-02
I0212 18:16:30.113163 22542570456896 run_lib.py:133] step: 1036350, training_loss: 2.28272e-02
I0212 18:16:47.531063 22542570456896 run_lib.py:133] step: 1036400, training_loss: 2.92327e-02
I0212 18:16:47.686349 22542570456896 run_lib.py:146] step: 1036400, eval_loss: 2.86411e-02
I0212 18:17:05.121072 22542570456896 run_lib.py:133] step: 1036450, training_loss: 2.78325e-02
I0212 18:17:22.668138 22542570456896 run_lib.py:133] step: 1036500, training_loss: 2.48367e-02
I0212 18:17:22.823306 22542570456896 run_lib.py:146] step: 1036500, eval_loss: 2.56529e-02
I0212 18:17:40.530957 22542570456896 run_lib.py:133] step: 1036550, training_loss: 2.39923e-02
I0212 18:17:58.019830 22542570456896 run_lib.py:133] step: 1036600, training_loss: 1.99956e-02
I0212 18:17:58.175222 22542570456896 run_lib.py:146] step: 1036600, eval_loss: 2.98092e-02
I0212 18:18:15.794584 22542570456896 run_lib.py:133] step: 1036650, training_loss: 2.90819e-02
I0212 18:18:33.304787 22542570456896 run_lib.py:133] step: 1036700, training_loss: 2.75582e-02
I0212 18:18:33.462471 22542570456896 run_lib.py:146] step: 1036700, eval_loss: 2.83061e-02
I0212 18:18:51.078867 22542570456896 run_lib.py:133] step: 1036750, training_loss: 2.60237e-02
I0212 18:19:08.569148 22542570456896 run_lib.py:133] step: 1036800, training_loss: 2.79156e-02
I0212 18:19:08.746453 22542570456896 run_lib.py:146] step: 1036800, eval_loss: 2.59582e-02
I0212 18:19:26.227902 22542570456896 run_lib.py:133] step: 1036850, training_loss: 2.39175e-02
I0212 18:19:43.915890 22542570456896 run_lib.py:133] step: 1036900, training_loss: 2.35785e-02
I0212 18:19:44.076669 22542570456896 run_lib.py:146] step: 1036900, eval_loss: 2.55425e-02
I0212 18:20:01.561966 22542570456896 run_lib.py:133] step: 1036950, training_loss: 2.19081e-02
I0212 18:20:19.172634 22542570456896 run_lib.py:133] step: 1037000, training_loss: 2.75553e-02
I0212 18:20:19.330483 22542570456896 run_lib.py:146] step: 1037000, eval_loss: 3.18568e-02
I0212 18:20:36.803227 22542570456896 run_lib.py:133] step: 1037050, training_loss: 2.63846e-02
I0212 18:20:54.325794 22542570456896 run_lib.py:133] step: 1037100, training_loss: 2.47198e-02
I0212 18:20:54.487706 22542570456896 run_lib.py:146] step: 1037100, eval_loss: 3.55582e-02
I0212 18:21:12.196345 22542570456896 run_lib.py:133] step: 1037150, training_loss: 2.87419e-02
I0212 18:21:29.640574 22542570456896 run_lib.py:133] step: 1037200, training_loss: 2.38849e-02
I0212 18:21:29.802448 22542570456896 run_lib.py:146] step: 1037200, eval_loss: 3.84226e-02
I0212 18:21:47.255330 22542570456896 run_lib.py:133] step: 1037250, training_loss: 2.66133e-02
I0212 18:22:04.881795 22542570456896 run_lib.py:133] step: 1037300, training_loss: 2.75461e-02
I0212 18:22:05.041644 22542570456896 run_lib.py:146] step: 1037300, eval_loss: 2.85251e-02
I0212 18:22:22.509580 22542570456896 run_lib.py:133] step: 1037350, training_loss: 2.51447e-02
I0212 18:22:40.047475 22542570456896 run_lib.py:133] step: 1037400, training_loss: 2.32869e-02
I0212 18:22:40.413468 22542570456896 run_lib.py:146] step: 1037400, eval_loss: 2.93679e-02
I0212 18:22:57.888901 22542570456896 run_lib.py:133] step: 1037450, training_loss: 2.01072e-02
I0212 18:23:15.345430 22542570456896 run_lib.py:133] step: 1037500, training_loss: 2.47320e-02
I0212 18:23:15.506417 22542570456896 run_lib.py:146] step: 1037500, eval_loss: 2.51728e-02
I0212 18:23:32.964214 22542570456896 run_lib.py:133] step: 1037550, training_loss: 3.54429e-02
I0212 18:23:50.431183 22542570456896 run_lib.py:133] step: 1037600, training_loss: 2.32169e-02
I0212 18:23:50.587691 22542570456896 run_lib.py:146] step: 1037600, eval_loss: 3.25091e-02
I0212 18:24:08.224750 22542570456896 run_lib.py:133] step: 1037650, training_loss: 2.22986e-02
I0212 18:24:25.828403 22542570456896 run_lib.py:133] step: 1037700, training_loss: 2.61201e-02
I0212 18:24:25.989592 22542570456896 run_lib.py:146] step: 1037700, eval_loss: 2.76646e-02
I0212 18:24:43.465887 22542570456896 run_lib.py:133] step: 1037750, training_loss: 2.97114e-02
I0212 18:25:00.936081 22542570456896 run_lib.py:133] step: 1037800, training_loss: 2.57348e-02
I0212 18:25:01.104080 22542570456896 run_lib.py:146] step: 1037800, eval_loss: 3.65868e-02
I0212 18:25:18.725786 22542570456896 run_lib.py:133] step: 1037850, training_loss: 2.59575e-02
I0212 18:25:36.241578 22542570456896 run_lib.py:133] step: 1037900, training_loss: 3.23108e-02
I0212 18:25:36.407457 22542570456896 run_lib.py:146] step: 1037900, eval_loss: 3.40179e-02
I0212 18:25:53.930536 22542570456896 run_lib.py:133] step: 1037950, training_loss: 2.83371e-02
I0212 18:26:11.407445 22542570456896 run_lib.py:133] step: 1038000, training_loss: 3.06604e-02
I0212 18:26:11.563156 22542570456896 run_lib.py:146] step: 1038000, eval_loss: 2.66527e-02
I0212 18:26:29.253857 22542570456896 run_lib.py:133] step: 1038050, training_loss: 2.12951e-02
I0212 18:26:46.696235 22542570456896 run_lib.py:133] step: 1038100, training_loss: 2.88857e-02
I0212 18:26:46.858436 22542570456896 run_lib.py:146] step: 1038100, eval_loss: 2.69186e-02
I0212 18:27:04.444580 22542570456896 run_lib.py:133] step: 1038150, training_loss: 2.36425e-02
I0212 18:27:21.902579 22542570456896 run_lib.py:133] step: 1038200, training_loss: 2.80023e-02
I0212 18:27:22.079419 22542570456896 run_lib.py:146] step: 1038200, eval_loss: 2.86621e-02
I0212 18:27:39.803681 22542570456896 run_lib.py:133] step: 1038250, training_loss: 3.12159e-02
I0212 18:27:57.273628 22542570456896 run_lib.py:133] step: 1038300, training_loss: 3.19453e-02
I0212 18:27:57.431737 22542570456896 run_lib.py:146] step: 1038300, eval_loss: 2.79364e-02
I0212 18:28:14.900882 22542570456896 run_lib.py:133] step: 1038350, training_loss: 2.83038e-02
I0212 18:28:32.490917 22542570456896 run_lib.py:133] step: 1038400, training_loss: 3.13570e-02
I0212 18:28:32.649176 22542570456896 run_lib.py:146] step: 1038400, eval_loss: 3.10650e-02
I0212 18:28:50.119720 22542570456896 run_lib.py:133] step: 1038450, training_loss: 2.57846e-02
I0212 18:29:07.773855 22542570456896 run_lib.py:133] step: 1038500, training_loss: 2.70549e-02
I0212 18:29:07.931689 22542570456896 run_lib.py:146] step: 1038500, eval_loss: 3.80636e-02
I0212 18:29:25.432718 22542570456896 run_lib.py:133] step: 1038550, training_loss: 2.89364e-02
I0212 18:29:42.888002 22542570456896 run_lib.py:133] step: 1038600, training_loss: 2.36521e-02
I0212 18:29:43.044370 22542570456896 run_lib.py:146] step: 1038600, eval_loss: 3.34715e-02
I0212 18:30:00.765144 22542570456896 run_lib.py:133] step: 1038650, training_loss: 3.49381e-02
I0212 18:30:18.245676 22542570456896 run_lib.py:133] step: 1038700, training_loss: 2.21184e-02
I0212 18:30:18.414690 22542570456896 run_lib.py:146] step: 1038700, eval_loss: 2.69946e-02
I0212 18:30:35.848281 22542570456896 run_lib.py:133] step: 1038750, training_loss: 2.09631e-02
I0212 18:30:53.392411 22542570456896 run_lib.py:133] step: 1038800, training_loss: 3.07509e-02
I0212 18:30:53.552711 22542570456896 run_lib.py:146] step: 1038800, eval_loss: 3.00351e-02
I0212 18:31:11.244519 22542570456896 run_lib.py:133] step: 1038850, training_loss: 2.49925e-02
I0212 18:31:28.667677 22542570456896 run_lib.py:133] step: 1038900, training_loss: 2.50534e-02
I0212 18:31:28.825474 22542570456896 run_lib.py:146] step: 1038900, eval_loss: 3.22804e-02
I0212 18:31:46.364383 22542570456896 run_lib.py:133] step: 1038950, training_loss: 2.85965e-02
I0212 18:32:03.852746 22542570456896 run_lib.py:133] step: 1039000, training_loss: 2.17984e-02
I0212 18:32:04.006513 22542570456896 run_lib.py:146] step: 1039000, eval_loss: 2.86707e-02
I0212 18:32:21.462641 22542570456896 run_lib.py:133] step: 1039050, training_loss: 3.45312e-02
I0212 18:32:38.951026 22542570456896 run_lib.py:133] step: 1039100, training_loss: 3.12858e-02
I0212 18:32:39.121662 22542570456896 run_lib.py:146] step: 1039100, eval_loss: 3.37514e-02
I0212 18:32:56.798998 22542570456896 run_lib.py:133] step: 1039150, training_loss: 3.28402e-02
I0212 18:33:14.363661 22542570456896 run_lib.py:133] step: 1039200, training_loss: 3.08567e-02
I0212 18:33:14.524707 22542570456896 run_lib.py:146] step: 1039200, eval_loss: 3.18032e-02
I0212 18:33:31.980811 22542570456896 run_lib.py:133] step: 1039250, training_loss: 2.27553e-02
I0212 18:33:49.416897 22542570456896 run_lib.py:133] step: 1039300, training_loss: 2.63924e-02
I0212 18:33:49.577566 22542570456896 run_lib.py:146] step: 1039300, eval_loss: 2.75580e-02
I0212 18:34:07.220104 22542570456896 run_lib.py:133] step: 1039350, training_loss: 2.38696e-02
I0212 18:34:24.698671 22542570456896 run_lib.py:133] step: 1039400, training_loss: 2.88189e-02
I0212 18:34:24.855652 22542570456896 run_lib.py:146] step: 1039400, eval_loss: 2.59978e-02
I0212 18:34:42.556955 22542570456896 run_lib.py:133] step: 1039450, training_loss: 2.44402e-02
I0212 18:34:59.994824 22542570456896 run_lib.py:133] step: 1039500, training_loss: 2.67058e-02
I0212 18:35:00.147550 22542570456896 run_lib.py:146] step: 1039500, eval_loss: 2.78433e-02
I0212 18:35:17.757977 22542570456896 run_lib.py:133] step: 1039550, training_loss: 2.59538e-02
I0212 18:35:35.226506 22542570456896 run_lib.py:133] step: 1039600, training_loss: 3.63087e-02
I0212 18:35:35.402361 22542570456896 run_lib.py:146] step: 1039600, eval_loss: 3.09786e-02
I0212 18:35:53.153368 22542570456896 run_lib.py:133] step: 1039650, training_loss: 2.61398e-02
I0212 18:36:10.639455 22542570456896 run_lib.py:133] step: 1039700, training_loss: 2.74887e-02
I0212 18:36:10.797961 22542570456896 run_lib.py:146] step: 1039700, eval_loss: 2.62376e-02
I0212 18:36:28.262008 22542570456896 run_lib.py:133] step: 1039750, training_loss: 2.73397e-02
I0212 18:36:45.858638 22542570456896 run_lib.py:133] step: 1039800, training_loss: 3.36385e-02
I0212 18:36:46.016200 22542570456896 run_lib.py:146] step: 1039800, eval_loss: 3.01381e-02
I0212 18:37:03.483892 22542570456896 run_lib.py:133] step: 1039850, training_loss: 2.97342e-02
I0212 18:37:20.954235 22542570456896 run_lib.py:133] step: 1039900, training_loss: 2.24029e-02
I0212 18:37:21.110316 22542570456896 run_lib.py:146] step: 1039900, eval_loss: 3.28801e-02
I0212 18:37:38.816952 22542570456896 run_lib.py:133] step: 1039950, training_loss: 2.60904e-02
I0212 18:37:56.490969 22542570456896 run_lib.py:133] step: 1040000, training_loss: 2.05687e-02
I0212 18:37:57.212505 22542570456896 run_lib.py:146] step: 1040000, eval_loss: 3.68905e-02
I0212 18:38:17.291378 22542570456896 run_lib.py:133] step: 1040050, training_loss: 2.80033e-02
I0212 18:38:34.823902 22542570456896 run_lib.py:133] step: 1040100, training_loss: 2.57298e-02
I0212 18:38:34.979743 22542570456896 run_lib.py:146] step: 1040100, eval_loss: 3.65527e-02
I0212 18:38:52.410827 22542570456896 run_lib.py:133] step: 1040150, training_loss: 2.34725e-02
I0212 18:39:09.939069 22542570456896 run_lib.py:133] step: 1040200, training_loss: 2.54407e-02
I0212 18:39:10.115332 22542570456896 run_lib.py:146] step: 1040200, eval_loss: 2.83008e-02
I0212 18:39:27.773936 22542570456896 run_lib.py:133] step: 1040250, training_loss: 2.64803e-02
I0212 18:39:45.339515 22542570456896 run_lib.py:133] step: 1040300, training_loss: 2.52264e-02
I0212 18:39:45.497813 22542570456896 run_lib.py:146] step: 1040300, eval_loss: 3.02069e-02
I0212 18:40:02.957779 22542570456896 run_lib.py:133] step: 1040350, training_loss: 2.30890e-02
I0212 18:40:20.402594 22542570456896 run_lib.py:133] step: 1040400, training_loss: 2.18893e-02
I0212 18:40:20.559697 22542570456896 run_lib.py:146] step: 1040400, eval_loss: 2.50387e-02
I0212 18:40:38.171501 22542570456896 run_lib.py:133] step: 1040450, training_loss: 2.71571e-02
I0212 18:40:55.665827 22542570456896 run_lib.py:133] step: 1040500, training_loss: 2.18839e-02
I0212 18:40:55.820657 22542570456896 run_lib.py:146] step: 1040500, eval_loss: 3.63362e-02
I0212 18:41:13.521152 22542570456896 run_lib.py:133] step: 1040550, training_loss: 3.29371e-02
I0212 18:41:31.010820 22542570456896 run_lib.py:133] step: 1040600, training_loss: 3.39731e-02
I0212 18:41:31.167374 22542570456896 run_lib.py:146] step: 1040600, eval_loss: 2.84667e-02
I0212 18:41:48.750315 22542570456896 run_lib.py:133] step: 1040650, training_loss: 2.18525e-02
I0212 18:42:06.204051 22542570456896 run_lib.py:133] step: 1040700, training_loss: 2.08329e-02
I0212 18:42:06.362684 22542570456896 run_lib.py:146] step: 1040700, eval_loss: 3.28112e-02
I0212 18:42:23.833240 22542570456896 run_lib.py:133] step: 1040750, training_loss: 2.46533e-02
I0212 18:42:41.582771 22542570456896 run_lib.py:133] step: 1040800, training_loss: 2.36868e-02
I0212 18:42:41.748394 22542570456896 run_lib.py:146] step: 1040800, eval_loss: 3.01303e-02
I0212 18:42:59.229324 22542570456896 run_lib.py:133] step: 1040850, training_loss: 2.13190e-02
I0212 18:43:16.881519 22542570456896 run_lib.py:133] step: 1040900, training_loss: 3.33041e-02
I0212 18:43:17.035535 22542570456896 run_lib.py:146] step: 1040900, eval_loss: 3.39589e-02
I0212 18:43:34.511162 22542570456896 run_lib.py:133] step: 1040950, training_loss: 1.97474e-02
I0212 18:43:51.992537 22542570456896 run_lib.py:133] step: 1041000, training_loss: 2.57328e-02
I0212 18:43:52.146398 22542570456896 run_lib.py:146] step: 1041000, eval_loss: 2.80281e-02
I0212 18:44:09.788983 22542570456896 run_lib.py:133] step: 1041050, training_loss: 2.64251e-02
I0212 18:44:27.280317 22542570456896 run_lib.py:133] step: 1041100, training_loss: 2.28083e-02
I0212 18:44:27.445638 22542570456896 run_lib.py:146] step: 1041100, eval_loss: 3.35466e-02
I0212 18:44:44.903506 22542570456896 run_lib.py:133] step: 1041150, training_loss: 2.93615e-02
I0212 18:45:02.545147 22542570456896 run_lib.py:133] step: 1041200, training_loss: 2.90340e-02
I0212 18:45:02.701513 22542570456896 run_lib.py:146] step: 1041200, eval_loss: 3.09295e-02
I0212 18:45:20.113006 22542570456896 run_lib.py:133] step: 1041250, training_loss: 2.43284e-02
I0212 18:45:37.548703 22542570456896 run_lib.py:133] step: 1041300, training_loss: 2.76384e-02
I0212 18:45:37.712199 22542570456896 run_lib.py:146] step: 1041300, eval_loss: 2.91819e-02
I0212 18:45:55.179699 22542570456896 run_lib.py:133] step: 1041350, training_loss: 2.34784e-02
I0212 18:46:12.593843 22542570456896 run_lib.py:133] step: 1041400, training_loss: 2.38679e-02
I0212 18:46:12.745113 22542570456896 run_lib.py:146] step: 1041400, eval_loss: 2.98805e-02
I0212 18:46:30.128952 22542570456896 run_lib.py:133] step: 1041450, training_loss: 2.27723e-02
I0212 18:46:47.505747 22542570456896 run_lib.py:133] step: 1041500, training_loss: 2.65484e-02
I0212 18:46:47.660344 22542570456896 run_lib.py:146] step: 1041500, eval_loss: 2.76470e-02
I0212 18:47:05.163600 22542570456896 run_lib.py:133] step: 1041550, training_loss: 2.62223e-02
I0212 18:47:22.647076 22542570456896 run_lib.py:133] step: 1041600, training_loss: 2.61708e-02
I0212 18:47:22.822127 22542570456896 run_lib.py:146] step: 1041600, eval_loss: 2.43605e-02
I0212 18:47:40.311790 22542570456896 run_lib.py:133] step: 1041650, training_loss: 2.79098e-02
I0212 18:47:57.785250 22542570456896 run_lib.py:133] step: 1041700, training_loss: 3.50935e-02
I0212 18:47:57.942299 22542570456896 run_lib.py:146] step: 1041700, eval_loss: 3.04113e-02
I0212 18:48:15.606833 22542570456896 run_lib.py:133] step: 1041750, training_loss: 2.26177e-02
I0212 18:48:33.047078 22542570456896 run_lib.py:133] step: 1041800, training_loss: 2.85724e-02
I0212 18:48:33.204621 22542570456896 run_lib.py:146] step: 1041800, eval_loss: 3.23862e-02
I0212 18:48:50.847897 22542570456896 run_lib.py:133] step: 1041850, training_loss: 2.36802e-02
I0212 18:49:08.354828 22542570456896 run_lib.py:133] step: 1041900, training_loss: 2.50163e-02
I0212 18:49:08.517714 22542570456896 run_lib.py:146] step: 1041900, eval_loss: 2.95360e-02
I0212 18:49:26.238308 22542570456896 run_lib.py:133] step: 1041950, training_loss: 2.81026e-02
I0212 18:49:43.669073 22542570456896 run_lib.py:133] step: 1042000, training_loss: 2.85926e-02
I0212 18:49:43.826478 22542570456896 run_lib.py:146] step: 1042000, eval_loss: 3.66783e-02
I0212 18:50:01.463148 22542570456896 run_lib.py:133] step: 1042050, training_loss: 3.35722e-02
I0212 18:50:18.908173 22542570456896 run_lib.py:133] step: 1042100, training_loss: 2.45397e-02
I0212 18:50:19.069631 22542570456896 run_lib.py:146] step: 1042100, eval_loss: 2.90355e-02
I0212 18:50:36.616294 22542570456896 run_lib.py:133] step: 1042150, training_loss: 2.52066e-02
I0212 18:50:54.290098 22542570456896 run_lib.py:133] step: 1042200, training_loss: 2.57713e-02
I0212 18:50:54.447638 22542570456896 run_lib.py:146] step: 1042200, eval_loss: 2.61901e-02
I0212 18:51:11.907249 22542570456896 run_lib.py:133] step: 1042250, training_loss: 2.89918e-02
I0212 18:51:29.349590 22542570456896 run_lib.py:133] step: 1042300, training_loss: 2.72290e-02
I0212 18:51:29.507579 22542570456896 run_lib.py:146] step: 1042300, eval_loss: 2.99257e-02
I0212 18:51:47.160228 22542570456896 run_lib.py:133] step: 1042350, training_loss: 2.70863e-02
I0212 18:52:04.648553 22542570456896 run_lib.py:133] step: 1042400, training_loss: 2.39949e-02
I0212 18:52:04.807620 22542570456896 run_lib.py:146] step: 1042400, eval_loss: 3.36746e-02
I0212 18:52:22.470696 22542570456896 run_lib.py:133] step: 1042450, training_loss: 2.35840e-02
I0212 18:52:39.930013 22542570456896 run_lib.py:133] step: 1042500, training_loss: 3.31822e-02
I0212 18:52:40.087701 22542570456896 run_lib.py:146] step: 1042500, eval_loss: 3.09629e-02
I0212 18:52:57.537826 22542570456896 run_lib.py:133] step: 1042550, training_loss: 2.51548e-02
I0212 18:53:15.215455 22542570456896 run_lib.py:133] step: 1042600, training_loss: 2.56877e-02
I0212 18:53:15.378738 22542570456896 run_lib.py:146] step: 1042600, eval_loss: 2.68130e-02
I0212 18:53:32.840797 22542570456896 run_lib.py:133] step: 1042650, training_loss: 2.58108e-02
I0212 18:53:50.310782 22542570456896 run_lib.py:133] step: 1042700, training_loss: 3.38419e-02
I0212 18:53:50.467595 22542570456896 run_lib.py:146] step: 1042700, eval_loss: 2.78509e-02
I0212 18:54:07.964345 22542570456896 run_lib.py:133] step: 1042750, training_loss: 3.23688e-02
I0212 18:54:25.647411 22542570456896 run_lib.py:133] step: 1042800, training_loss: 2.74887e-02
I0212 18:54:25.803392 22542570456896 run_lib.py:146] step: 1042800, eval_loss: 2.62698e-02
I0212 18:54:43.306149 22542570456896 run_lib.py:133] step: 1042850, training_loss: 2.48669e-02
I0212 18:55:00.835000 22542570456896 run_lib.py:133] step: 1042900, training_loss: 2.72361e-02
I0212 18:55:00.986383 22542570456896 run_lib.py:146] step: 1042900, eval_loss: 3.16495e-02
I0212 18:55:18.424318 22542570456896 run_lib.py:133] step: 1042950, training_loss: 2.33154e-02
I0212 18:55:35.887079 22542570456896 run_lib.py:133] step: 1043000, training_loss: 2.67505e-02
I0212 18:55:36.063682 22542570456896 run_lib.py:146] step: 1043000, eval_loss: 2.71603e-02
I0212 18:55:53.755352 22542570456896 run_lib.py:133] step: 1043050, training_loss: 2.94966e-02
I0212 18:56:11.337169 22542570456896 run_lib.py:133] step: 1043100, training_loss: 3.04089e-02
I0212 18:56:11.494514 22542570456896 run_lib.py:146] step: 1043100, eval_loss: 2.85753e-02
I0212 18:56:28.975395 22542570456896 run_lib.py:133] step: 1043150, training_loss: 2.36230e-02
I0212 18:56:46.415450 22542570456896 run_lib.py:133] step: 1043200, training_loss: 2.61008e-02
I0212 18:56:46.581524 22542570456896 run_lib.py:146] step: 1043200, eval_loss: 2.80497e-02
I0212 18:57:04.224216 22542570456896 run_lib.py:133] step: 1043250, training_loss: 3.61987e-02
I0212 18:57:21.724573 22542570456896 run_lib.py:133] step: 1043300, training_loss: 2.64316e-02
I0212 18:57:21.887133 22542570456896 run_lib.py:146] step: 1043300, eval_loss: 2.94821e-02
I0212 18:57:39.564285 22542570456896 run_lib.py:133] step: 1043350, training_loss: 3.53541e-02
I0212 18:57:57.060409 22542570456896 run_lib.py:133] step: 1043400, training_loss: 2.59738e-02
I0212 18:57:57.216424 22542570456896 run_lib.py:146] step: 1043400, eval_loss: 3.04533e-02
I0212 18:58:14.874003 22542570456896 run_lib.py:133] step: 1043450, training_loss: 2.55823e-02
I0212 18:58:32.355756 22542570456896 run_lib.py:133] step: 1043500, training_loss: 3.30404e-02
I0212 18:58:32.521761 22542570456896 run_lib.py:146] step: 1043500, eval_loss: 2.38621e-02
I0212 18:58:50.012483 22542570456896 run_lib.py:133] step: 1043550, training_loss: 2.72256e-02
I0212 18:59:07.714188 22542570456896 run_lib.py:133] step: 1043600, training_loss: 3.05520e-02
I0212 18:59:07.881496 22542570456896 run_lib.py:146] step: 1043600, eval_loss: 2.63990e-02
I0212 18:59:25.377467 22542570456896 run_lib.py:133] step: 1043650, training_loss: 3.10580e-02
I0212 18:59:43.025515 22542570456896 run_lib.py:133] step: 1043700, training_loss: 2.94037e-02
I0212 18:59:43.183616 22542570456896 run_lib.py:146] step: 1043700, eval_loss: 3.56952e-02
I0212 19:00:00.656878 22542570456896 run_lib.py:133] step: 1043750, training_loss: 2.99360e-02
I0212 19:00:18.101945 22542570456896 run_lib.py:133] step: 1043800, training_loss: 2.59944e-02
I0212 19:00:18.257256 22542570456896 run_lib.py:146] step: 1043800, eval_loss: 3.12475e-02
I0212 19:00:36.003798 22542570456896 run_lib.py:133] step: 1043850, training_loss: 3.10759e-02
I0212 19:00:53.479810 22542570456896 run_lib.py:133] step: 1043900, training_loss: 2.49028e-02
I0212 19:00:53.639592 22542570456896 run_lib.py:146] step: 1043900, eval_loss: 2.63590e-02
I0212 19:01:11.137039 22542570456896 run_lib.py:133] step: 1043950, training_loss: 2.89562e-02
I0212 19:01:28.816005 22542570456896 run_lib.py:133] step: 1044000, training_loss: 2.82450e-02
I0212 19:01:28.984991 22542570456896 run_lib.py:146] step: 1044000, eval_loss: 3.24562e-02
I0212 19:01:46.465257 22542570456896 run_lib.py:133] step: 1044050, training_loss: 2.21836e-02
I0212 19:02:03.986199 22542570456896 run_lib.py:133] step: 1044100, training_loss: 3.15450e-02
I0212 19:02:04.299368 22542570456896 run_lib.py:146] step: 1044100, eval_loss: 2.57524e-02
I0212 19:02:21.790744 22542570456896 run_lib.py:133] step: 1044150, training_loss: 2.82087e-02
I0212 19:02:39.258208 22542570456896 run_lib.py:133] step: 1044200, training_loss: 2.23648e-02
I0212 19:02:39.415549 22542570456896 run_lib.py:146] step: 1044200, eval_loss: 2.97339e-02
I0212 19:02:56.906497 22542570456896 run_lib.py:133] step: 1044250, training_loss: 2.85957e-02
I0212 19:03:14.400279 22542570456896 run_lib.py:133] step: 1044300, training_loss: 2.97959e-02
I0212 19:03:14.563009 22542570456896 run_lib.py:146] step: 1044300, eval_loss: 3.16209e-02
I0212 19:03:32.213414 22542570456896 run_lib.py:133] step: 1044350, training_loss: 2.70189e-02
I0212 19:03:49.781849 22542570456896 run_lib.py:133] step: 1044400, training_loss: 2.95352e-02
I0212 19:03:49.955596 22542570456896 run_lib.py:146] step: 1044400, eval_loss: 2.60032e-02
I0212 19:04:07.501106 22542570456896 run_lib.py:133] step: 1044450, training_loss: 3.28497e-02
I0212 19:04:24.993428 22542570456896 run_lib.py:133] step: 1044500, training_loss: 2.71988e-02
I0212 19:04:25.154534 22542570456896 run_lib.py:146] step: 1044500, eval_loss: 2.53628e-02
I0212 19:04:42.809515 22542570456896 run_lib.py:133] step: 1044550, training_loss: 3.23446e-02
I0212 19:05:00.306284 22542570456896 run_lib.py:133] step: 1044600, training_loss: 2.45304e-02
I0212 19:05:00.461181 22542570456896 run_lib.py:146] step: 1044600, eval_loss: 3.31100e-02
I0212 19:05:17.927727 22542570456896 run_lib.py:133] step: 1044650, training_loss: 3.10423e-02
I0212 19:05:35.451726 22542570456896 run_lib.py:133] step: 1044700, training_loss: 1.97750e-02
I0212 19:05:35.608720 22542570456896 run_lib.py:146] step: 1044700, eval_loss: 3.00495e-02
I0212 19:05:53.298191 22542570456896 run_lib.py:133] step: 1044750, training_loss: 2.46872e-02
I0212 19:06:10.766324 22542570456896 run_lib.py:133] step: 1044800, training_loss: 2.85709e-02
I0212 19:06:10.920412 22542570456896 run_lib.py:146] step: 1044800, eval_loss: 3.44843e-02
I0212 19:06:28.532809 22542570456896 run_lib.py:133] step: 1044850, training_loss: 2.45307e-02
I0212 19:06:46.019865 22542570456896 run_lib.py:133] step: 1044900, training_loss: 2.82563e-02
I0212 19:06:46.178599 22542570456896 run_lib.py:146] step: 1044900, eval_loss: 3.50565e-02
I0212 19:07:03.773733 22542570456896 run_lib.py:133] step: 1044950, training_loss: 2.88586e-02
I0212 19:07:21.262588 22542570456896 run_lib.py:133] step: 1045000, training_loss: 2.35112e-02
I0212 19:07:21.435719 22542570456896 run_lib.py:146] step: 1045000, eval_loss: 2.99315e-02
I0212 19:07:38.937560 22542570456896 run_lib.py:133] step: 1045050, training_loss: 2.78422e-02
I0212 19:07:56.640736 22542570456896 run_lib.py:133] step: 1045100, training_loss: 2.17184e-02
I0212 19:07:56.798632 22542570456896 run_lib.py:146] step: 1045100, eval_loss: 3.39119e-02
I0212 19:08:14.311805 22542570456896 run_lib.py:133] step: 1045150, training_loss: 3.18768e-02
I0212 19:08:31.900122 22542570456896 run_lib.py:133] step: 1045200, training_loss: 2.78557e-02
I0212 19:08:32.055201 22542570456896 run_lib.py:146] step: 1045200, eval_loss: 2.88148e-02
I0212 19:08:49.515303 22542570456896 run_lib.py:133] step: 1045250, training_loss: 2.85665e-02
I0212 19:09:07.021173 22542570456896 run_lib.py:133] step: 1045300, training_loss: 3.07429e-02
I0212 19:09:07.184680 22542570456896 run_lib.py:146] step: 1045300, eval_loss: 3.80765e-02
I0212 19:09:24.861464 22542570456896 run_lib.py:133] step: 1045350, training_loss: 2.50843e-02
I0212 19:09:42.369747 22542570456896 run_lib.py:133] step: 1045400, training_loss: 2.70763e-02
I0212 19:09:42.526209 22542570456896 run_lib.py:146] step: 1045400, eval_loss: 3.02237e-02
I0212 19:09:59.980611 22542570456896 run_lib.py:133] step: 1045450, training_loss: 2.54582e-02
I0212 19:10:17.445325 22542570456896 run_lib.py:133] step: 1045500, training_loss: 2.11547e-02
I0212 19:10:17.602547 22542570456896 run_lib.py:146] step: 1045500, eval_loss: 2.66161e-02
I0212 19:10:35.210812 22542570456896 run_lib.py:133] step: 1045550, training_loss: 3.04235e-02
I0212 19:10:52.779120 22542570456896 run_lib.py:133] step: 1045600, training_loss: 2.51100e-02
I0212 19:10:52.941798 22542570456896 run_lib.py:146] step: 1045600, eval_loss: 2.64600e-02
I0212 19:11:10.554032 22542570456896 run_lib.py:133] step: 1045650, training_loss: 2.38138e-02
I0212 19:11:28.001135 22542570456896 run_lib.py:133] step: 1045700, training_loss: 2.68151e-02
I0212 19:11:28.155696 22542570456896 run_lib.py:146] step: 1045700, eval_loss: 2.69204e-02
I0212 19:11:45.608306 22542570456896 run_lib.py:133] step: 1045750, training_loss: 2.71438e-02
I0212 19:12:03.092493 22542570456896 run_lib.py:133] step: 1045800, training_loss: 2.16059e-02
I0212 19:12:03.259624 22542570456896 run_lib.py:146] step: 1045800, eval_loss: 3.11469e-02
I0212 19:12:20.968310 22542570456896 run_lib.py:133] step: 1045850, training_loss: 2.45411e-02
I0212 19:12:38.629306 22542570456896 run_lib.py:133] step: 1045900, training_loss: 2.37071e-02
I0212 19:12:38.788401 22542570456896 run_lib.py:146] step: 1045900, eval_loss: 3.14797e-02
I0212 19:12:56.235991 22542570456896 run_lib.py:133] step: 1045950, training_loss: 2.66079e-02
I0212 19:13:13.682833 22542570456896 run_lib.py:133] step: 1046000, training_loss: 2.84622e-02
I0212 19:13:13.848981 22542570456896 run_lib.py:146] step: 1046000, eval_loss: 3.48357e-02
I0212 19:13:31.493719 22542570456896 run_lib.py:133] step: 1046050, training_loss: 2.66226e-02
I0212 19:13:49.026468 22542570456896 run_lib.py:133] step: 1046100, training_loss: 2.35894e-02
I0212 19:13:49.187648 22542570456896 run_lib.py:146] step: 1046100, eval_loss: 3.19300e-02
I0212 19:14:06.880460 22542570456896 run_lib.py:133] step: 1046150, training_loss: 3.18864e-02
I0212 19:14:24.338974 22542570456896 run_lib.py:133] step: 1046200, training_loss: 2.45888e-02
I0212 19:14:24.493491 22542570456896 run_lib.py:146] step: 1046200, eval_loss: 3.07747e-02
I0212 19:14:42.170836 22542570456896 run_lib.py:133] step: 1046250, training_loss: 2.99763e-02
I0212 19:14:59.668987 22542570456896 run_lib.py:133] step: 1046300, training_loss: 2.54388e-02
I0212 19:14:59.833269 22542570456896 run_lib.py:146] step: 1046300, eval_loss: 2.65835e-02
I0212 19:15:17.428501 22542570456896 run_lib.py:133] step: 1046350, training_loss: 2.80903e-02
I0212 19:15:34.865910 22542570456896 run_lib.py:133] step: 1046400, training_loss: 2.08296e-02
I0212 19:15:35.043335 22542570456896 run_lib.py:146] step: 1046400, eval_loss: 2.83481e-02
I0212 19:15:52.496767 22542570456896 run_lib.py:133] step: 1046450, training_loss: 2.91684e-02
I0212 19:16:10.026861 22542570456896 run_lib.py:133] step: 1046500, training_loss: 3.04383e-02
I0212 19:16:10.186684 22542570456896 run_lib.py:146] step: 1046500, eval_loss: 3.43309e-02
I0212 19:16:27.593027 22542570456896 run_lib.py:133] step: 1046550, training_loss: 2.29378e-02
I0212 19:16:44.941834 22542570456896 run_lib.py:133] step: 1046600, training_loss: 2.42055e-02
I0212 19:16:45.096372 22542570456896 run_lib.py:146] step: 1046600, eval_loss: 3.37185e-02
I0212 19:17:02.630815 22542570456896 run_lib.py:133] step: 1046650, training_loss: 2.03244e-02
I0212 19:17:20.181833 22542570456896 run_lib.py:133] step: 1046700, training_loss: 2.41341e-02
I0212 19:17:20.336507 22542570456896 run_lib.py:146] step: 1046700, eval_loss: 3.26625e-02
I0212 19:17:37.739785 22542570456896 run_lib.py:133] step: 1046750, training_loss: 2.21116e-02
I0212 19:17:55.132488 22542570456896 run_lib.py:133] step: 1046800, training_loss: 2.29362e-02
I0212 19:17:55.288793 22542570456896 run_lib.py:146] step: 1046800, eval_loss: 3.26438e-02
I0212 19:18:12.753144 22542570456896 run_lib.py:133] step: 1046850, training_loss: 2.31634e-02
I0212 19:18:30.419470 22542570456896 run_lib.py:133] step: 1046900, training_loss: 2.90478e-02
I0212 19:18:30.574028 22542570456896 run_lib.py:146] step: 1046900, eval_loss: 2.54096e-02
I0212 19:18:48.044362 22542570456896 run_lib.py:133] step: 1046950, training_loss: 2.33762e-02
I0212 19:19:05.564398 22542570456896 run_lib.py:133] step: 1047000, training_loss: 2.97835e-02
I0212 19:19:05.723242 22542570456896 run_lib.py:146] step: 1047000, eval_loss: 2.83321e-02
I0212 19:19:23.216530 22542570456896 run_lib.py:133] step: 1047050, training_loss: 2.99300e-02
I0212 19:19:40.903435 22542570456896 run_lib.py:133] step: 1047100, training_loss: 1.83726e-02
I0212 19:19:41.058177 22542570456896 run_lib.py:146] step: 1047100, eval_loss: 2.54257e-02
I0212 19:19:58.507105 22542570456896 run_lib.py:133] step: 1047150, training_loss: 2.68074e-02
I0212 19:20:16.036655 22542570456896 run_lib.py:133] step: 1047200, training_loss: 2.43109e-02
I0212 19:20:16.195495 22542570456896 run_lib.py:146] step: 1047200, eval_loss: 3.26460e-02
I0212 19:20:33.682585 22542570456896 run_lib.py:133] step: 1047250, training_loss: 2.78129e-02
I0212 19:20:51.217286 22542570456896 run_lib.py:133] step: 1047300, training_loss: 3.11962e-02
I0212 19:20:51.383406 22542570456896 run_lib.py:146] step: 1047300, eval_loss: 2.85551e-02
I0212 19:21:09.076805 22542570456896 run_lib.py:133] step: 1047350, training_loss: 2.80658e-02
I0212 19:21:26.589667 22542570456896 run_lib.py:133] step: 1047400, training_loss: 2.67394e-02
I0212 19:21:26.745357 22542570456896 run_lib.py:146] step: 1047400, eval_loss: 2.88874e-02
I0212 19:21:44.232612 22542570456896 run_lib.py:133] step: 1047450, training_loss: 2.80731e-02
I0212 19:22:01.684128 22542570456896 run_lib.py:133] step: 1047500, training_loss: 3.22409e-02
I0212 19:22:01.837793 22542570456896 run_lib.py:146] step: 1047500, eval_loss: 2.94989e-02
I0212 19:22:19.436352 22542570456896 run_lib.py:133] step: 1047550, training_loss: 3.41530e-02
I0212 19:22:36.982129 22542570456896 run_lib.py:133] step: 1047600, training_loss: 2.27389e-02
I0212 19:22:37.137688 22542570456896 run_lib.py:146] step: 1047600, eval_loss: 2.88608e-02
I0212 19:22:54.848506 22542570456896 run_lib.py:133] step: 1047650, training_loss: 2.55764e-02
I0212 19:23:12.342935 22542570456896 run_lib.py:133] step: 1047700, training_loss: 2.67095e-02
I0212 19:23:12.500488 22542570456896 run_lib.py:146] step: 1047700, eval_loss: 3.27663e-02
I0212 19:23:30.086070 22542570456896 run_lib.py:133] step: 1047750, training_loss: 2.55308e-02
I0212 19:23:47.561868 22542570456896 run_lib.py:133] step: 1047800, training_loss: 2.70427e-02
I0212 19:23:47.729429 22542570456896 run_lib.py:146] step: 1047800, eval_loss: 2.39813e-02
I0212 19:24:05.248664 22542570456896 run_lib.py:133] step: 1047850, training_loss: 2.40147e-02
I0212 19:24:22.945672 22542570456896 run_lib.py:133] step: 1047900, training_loss: 3.10508e-02
I0212 19:24:23.102646 22542570456896 run_lib.py:146] step: 1047900, eval_loss: 2.42746e-02
I0212 19:24:40.583025 22542570456896 run_lib.py:133] step: 1047950, training_loss: 2.54962e-02
I0212 19:24:58.158522 22542570456896 run_lib.py:133] step: 1048000, training_loss: 3.50002e-02
I0212 19:24:58.317507 22542570456896 run_lib.py:146] step: 1048000, eval_loss: 2.52944e-02
I0212 19:25:15.807444 22542570456896 run_lib.py:133] step: 1048050, training_loss: 2.51198e-02
I0212 19:25:33.319311 22542570456896 run_lib.py:133] step: 1048100, training_loss: 3.48721e-02
I0212 19:25:33.484686 22542570456896 run_lib.py:146] step: 1048100, eval_loss: 3.36652e-02
I0212 19:25:51.228734 22542570456896 run_lib.py:133] step: 1048150, training_loss: 2.57004e-02
I0212 19:26:08.708866 22542570456896 run_lib.py:133] step: 1048200, training_loss: 2.30305e-02
I0212 19:26:08.871402 22542570456896 run_lib.py:146] step: 1048200, eval_loss: 3.18295e-02
I0212 19:26:26.295830 22542570456896 run_lib.py:133] step: 1048250, training_loss: 3.21724e-02
I0212 19:26:43.895252 22542570456896 run_lib.py:133] step: 1048300, training_loss: 2.65422e-02
I0212 19:26:44.054805 22542570456896 run_lib.py:146] step: 1048300, eval_loss: 2.98632e-02
I0212 19:27:01.512153 22542570456896 run_lib.py:133] step: 1048350, training_loss: 2.62254e-02
I0212 19:27:19.038786 22542570456896 run_lib.py:133] step: 1048400, training_loss: 3.26587e-02
I0212 19:27:19.197246 22542570456896 run_lib.py:146] step: 1048400, eval_loss: 2.36871e-02
I0212 19:27:36.747155 22542570456896 run_lib.py:133] step: 1048450, training_loss: 2.89171e-02
I0212 19:27:54.221767 22542570456896 run_lib.py:133] step: 1048500, training_loss: 2.40865e-02
I0212 19:27:54.376357 22542570456896 run_lib.py:146] step: 1048500, eval_loss: 2.31057e-02
I0212 19:28:11.857490 22542570456896 run_lib.py:133] step: 1048550, training_loss: 3.08367e-02
I0212 19:28:29.340090 22542570456896 run_lib.py:133] step: 1048600, training_loss: 2.48318e-02
I0212 19:28:29.493344 22542570456896 run_lib.py:146] step: 1048600, eval_loss: 3.95848e-02
I0212 19:28:47.102300 22542570456896 run_lib.py:133] step: 1048650, training_loss: 1.94965e-02
I0212 19:29:04.649327 22542570456896 run_lib.py:133] step: 1048700, training_loss: 3.02095e-02
I0212 19:29:04.820926 22542570456896 run_lib.py:146] step: 1048700, eval_loss: 2.43426e-02
I0212 19:29:22.328806 22542570456896 run_lib.py:133] step: 1048750, training_loss: 3.16484e-02
I0212 19:29:39.835177 22542570456896 run_lib.py:133] step: 1048800, training_loss: 2.56302e-02
I0212 19:29:39.991573 22542570456896 run_lib.py:146] step: 1048800, eval_loss: 2.46532e-02
I0212 19:29:57.617975 22542570456896 run_lib.py:133] step: 1048850, training_loss: 2.14747e-02
I0212 19:30:15.066509 22542570456896 run_lib.py:133] step: 1048900, training_loss: 3.03107e-02
I0212 19:30:15.224654 22542570456896 run_lib.py:146] step: 1048900, eval_loss: 2.76548e-02
I0212 19:30:32.839951 22542570456896 run_lib.py:133] step: 1048950, training_loss: 3.03225e-02
I0212 19:30:50.362811 22542570456896 run_lib.py:133] step: 1049000, training_loss: 2.41944e-02
I0212 19:30:50.516899 22542570456896 run_lib.py:146] step: 1049000, eval_loss: 3.04584e-02
I0212 19:31:08.224093 22542570456896 run_lib.py:133] step: 1049050, training_loss: 3.24031e-02
I0212 19:31:25.671321 22542570456896 run_lib.py:133] step: 1049100, training_loss: 3.02364e-02
I0212 19:31:25.827425 22542570456896 run_lib.py:146] step: 1049100, eval_loss: 3.23246e-02
I0212 19:31:43.450279 22542570456896 run_lib.py:133] step: 1049150, training_loss: 2.53452e-02
I0212 19:32:00.964956 22542570456896 run_lib.py:133] step: 1049200, training_loss: 2.69742e-02
I0212 19:32:01.123783 22542570456896 run_lib.py:146] step: 1049200, eval_loss: 2.20381e-02
I0212 19:32:18.644895 22542570456896 run_lib.py:133] step: 1049250, training_loss: 2.71833e-02
I0212 19:32:36.340883 22542570456896 run_lib.py:133] step: 1049300, training_loss: 2.64773e-02
I0212 19:32:36.498619 22542570456896 run_lib.py:146] step: 1049300, eval_loss: 3.24262e-02
I0212 19:32:53.977164 22542570456896 run_lib.py:133] step: 1049350, training_loss: 2.20495e-02
I0212 19:33:11.445779 22542570456896 run_lib.py:133] step: 1049400, training_loss: 3.01375e-02
I0212 19:33:11.601399 22542570456896 run_lib.py:146] step: 1049400, eval_loss: 3.41604e-02
I0212 19:33:29.251722 22542570456896 run_lib.py:133] step: 1049450, training_loss: 2.63894e-02
I0212 19:33:46.726521 22542570456896 run_lib.py:133] step: 1049500, training_loss: 3.12704e-02
I0212 19:33:46.880681 22542570456896 run_lib.py:146] step: 1049500, eval_loss: 2.80835e-02
I0212 19:34:04.541185 22542570456896 run_lib.py:133] step: 1049550, training_loss: 2.52140e-02
I0212 19:34:22.055056 22542570456896 run_lib.py:133] step: 1049600, training_loss: 3.07990e-02
I0212 19:34:22.213588 22542570456896 run_lib.py:146] step: 1049600, eval_loss: 3.51704e-02
I0212 19:34:39.649356 22542570456896 run_lib.py:133] step: 1049650, training_loss: 2.35632e-02
I0212 19:34:57.291677 22542570456896 run_lib.py:133] step: 1049700, training_loss: 2.91528e-02
I0212 19:34:57.453668 22542570456896 run_lib.py:146] step: 1049700, eval_loss: 2.52560e-02
I0212 19:35:14.912345 22542570456896 run_lib.py:133] step: 1049750, training_loss: 3.54364e-02
I0212 19:35:32.372416 22542570456896 run_lib.py:133] step: 1049800, training_loss: 2.85009e-02
I0212 19:35:32.538904 22542570456896 run_lib.py:146] step: 1049800, eval_loss: 2.77534e-02
I0212 19:35:50.045098 22542570456896 run_lib.py:133] step: 1049850, training_loss: 2.15907e-02
I0212 19:36:07.729196 22542570456896 run_lib.py:133] step: 1049900, training_loss: 2.67551e-02
I0212 19:36:07.891782 22542570456896 run_lib.py:146] step: 1049900, eval_loss: 2.30323e-02
I0212 19:36:25.378597 22542570456896 run_lib.py:133] step: 1049950, training_loss: 2.29646e-02
I0212 19:36:42.940795 22542570456896 run_lib.py:133] step: 1050000, training_loss: 2.66327e-02
I0212 19:36:43.651408 22542570456896 run_lib.py:146] step: 1050000, eval_loss: 2.71796e-02
I0212 19:37:03.742414 22542570456896 run_lib.py:133] step: 1050050, training_loss: 2.88013e-02
I0212 19:37:21.231245 22542570456896 run_lib.py:133] step: 1050100, training_loss: 2.65855e-02
I0212 19:37:21.388970 22542570456896 run_lib.py:146] step: 1050100, eval_loss: 2.54398e-02
I0212 19:37:39.104386 22542570456896 run_lib.py:133] step: 1050150, training_loss: 2.68046e-02
I0212 19:37:56.584015 22542570456896 run_lib.py:133] step: 1050200, training_loss: 2.86313e-02
I0212 19:37:56.745432 22542570456896 run_lib.py:146] step: 1050200, eval_loss: 2.21177e-02
I0212 19:38:14.253411 22542570456896 run_lib.py:133] step: 1050250, training_loss: 2.88162e-02
I0212 19:38:31.711175 22542570456896 run_lib.py:133] step: 1050300, training_loss: 3.19052e-02
I0212 19:38:31.868461 22542570456896 run_lib.py:146] step: 1050300, eval_loss: 2.92357e-02
I0212 19:38:49.350533 22542570456896 run_lib.py:133] step: 1050350, training_loss: 3.00395e-02
I0212 19:39:06.872295 22542570456896 run_lib.py:133] step: 1050400, training_loss: 2.46394e-02
I0212 19:39:07.034273 22542570456896 run_lib.py:146] step: 1050400, eval_loss: 2.77902e-02
I0212 19:39:24.744598 22542570456896 run_lib.py:133] step: 1050450, training_loss: 2.64579e-02
I0212 19:39:42.274174 22542570456896 run_lib.py:133] step: 1050500, training_loss: 2.65933e-02
I0212 19:39:42.425230 22542570456896 run_lib.py:146] step: 1050500, eval_loss: 2.90787e-02
I0212 19:39:59.913447 22542570456896 run_lib.py:133] step: 1050550, training_loss: 2.76385e-02
I0212 19:40:17.411908 22542570456896 run_lib.py:133] step: 1050600, training_loss: 2.58944e-02
I0212 19:40:17.569650 22542570456896 run_lib.py:146] step: 1050600, eval_loss: 2.89469e-02
I0212 19:40:35.236177 22542570456896 run_lib.py:133] step: 1050650, training_loss: 2.33724e-02
I0212 19:40:52.758341 22542570456896 run_lib.py:133] step: 1050700, training_loss: 2.81827e-02
I0212 19:40:52.919416 22542570456896 run_lib.py:146] step: 1050700, eval_loss: 3.06921e-02
I0212 19:41:10.609702 22542570456896 run_lib.py:133] step: 1050750, training_loss: 2.86290e-02
I0212 19:41:28.065397 22542570456896 run_lib.py:133] step: 1050800, training_loss: 2.63625e-02
I0212 19:41:28.224576 22542570456896 run_lib.py:146] step: 1050800, eval_loss: 2.70072e-02
I0212 19:41:45.851958 22542570456896 run_lib.py:133] step: 1050850, training_loss: 2.54235e-02
I0212 19:42:03.355260 22542570456896 run_lib.py:133] step: 1050900, training_loss: 2.94428e-02
I0212 19:42:03.515538 22542570456896 run_lib.py:146] step: 1050900, eval_loss: 3.26878e-02
I0212 19:42:21.046373 22542570456896 run_lib.py:133] step: 1050950, training_loss: 2.51353e-02
I0212 19:42:38.717353 22542570456896 run_lib.py:133] step: 1051000, training_loss: 3.03788e-02
I0212 19:42:38.869782 22542570456896 run_lib.py:146] step: 1051000, eval_loss: 3.23445e-02
I0212 19:42:56.365430 22542570456896 run_lib.py:133] step: 1051050, training_loss: 2.83689e-02
I0212 19:43:13.970733 22542570456896 run_lib.py:133] step: 1051100, training_loss: 2.80173e-02
I0212 19:43:14.127457 22542570456896 run_lib.py:146] step: 1051100, eval_loss: 3.13577e-02
I0212 19:43:31.606634 22542570456896 run_lib.py:133] step: 1051150, training_loss: 2.59578e-02
I0212 19:43:49.068245 22542570456896 run_lib.py:133] step: 1051200, training_loss: 3.00377e-02
I0212 19:43:49.254440 22542570456896 run_lib.py:146] step: 1051200, eval_loss: 3.48710e-02
I0212 19:44:06.970568 22542570456896 run_lib.py:133] step: 1051250, training_loss: 3.81488e-02
I0212 19:44:24.474752 22542570456896 run_lib.py:133] step: 1051300, training_loss: 2.28773e-02
I0212 19:44:24.631649 22542570456896 run_lib.py:146] step: 1051300, eval_loss: 2.64071e-02
I0212 19:44:42.094790 22542570456896 run_lib.py:133] step: 1051350, training_loss: 2.46027e-02
I0212 19:44:59.721307 22542570456896 run_lib.py:133] step: 1051400, training_loss: 3.48979e-02
I0212 19:44:59.876315 22542570456896 run_lib.py:146] step: 1051400, eval_loss: 2.49808e-02
I0212 19:45:17.344910 22542570456896 run_lib.py:133] step: 1051450, training_loss: 2.43137e-02
I0212 19:45:34.815714 22542570456896 run_lib.py:133] step: 1051500, training_loss: 3.04700e-02
I0212 19:45:35.130118 22542570456896 run_lib.py:146] step: 1051500, eval_loss: 3.28444e-02
I0212 19:45:52.680465 22542570456896 run_lib.py:133] step: 1051550, training_loss: 3.02360e-02
I0212 19:46:10.098102 22542570456896 run_lib.py:133] step: 1051600, training_loss: 2.77283e-02
I0212 19:46:10.255150 22542570456896 run_lib.py:146] step: 1051600, eval_loss: 2.54586e-02
I0212 19:46:27.551880 22542570456896 run_lib.py:133] step: 1051650, training_loss: 2.29486e-02
I0212 19:46:44.928552 22542570456896 run_lib.py:133] step: 1051700, training_loss: 3.17660e-02
I0212 19:46:45.084879 22542570456896 run_lib.py:146] step: 1051700, eval_loss: 2.97645e-02
I0212 19:47:02.655311 22542570456896 run_lib.py:133] step: 1051750, training_loss: 2.86695e-02
I0212 19:47:20.113510 22542570456896 run_lib.py:133] step: 1051800, training_loss: 2.42592e-02
I0212 19:47:20.268101 22542570456896 run_lib.py:146] step: 1051800, eval_loss: 2.25107e-02
I0212 19:47:37.689879 22542570456896 run_lib.py:133] step: 1051850, training_loss: 2.74591e-02
I0212 19:47:55.097708 22542570456896 run_lib.py:133] step: 1051900, training_loss: 2.44108e-02
I0212 19:47:55.251164 22542570456896 run_lib.py:146] step: 1051900, eval_loss: 3.30499e-02
I0212 19:48:12.856185 22542570456896 run_lib.py:133] step: 1051950, training_loss: 2.73807e-02
I0212 19:48:30.354522 22542570456896 run_lib.py:133] step: 1052000, training_loss: 2.57961e-02
I0212 19:48:30.507414 22542570456896 run_lib.py:146] step: 1052000, eval_loss: 2.57545e-02
I0212 19:48:48.019490 22542570456896 run_lib.py:133] step: 1052050, training_loss: 2.55497e-02
I0212 19:49:05.530753 22542570456896 run_lib.py:133] step: 1052100, training_loss: 3.21664e-02
I0212 19:49:05.703453 22542570456896 run_lib.py:146] step: 1052100, eval_loss: 2.76678e-02
I0212 19:49:23.420001 22542570456896 run_lib.py:133] step: 1052150, training_loss: 2.21635e-02
I0212 19:49:40.894548 22542570456896 run_lib.py:133] step: 1052200, training_loss: 2.64369e-02
I0212 19:49:41.059452 22542570456896 run_lib.py:146] step: 1052200, eval_loss: 2.78834e-02
I0212 19:49:58.704114 22542570456896 run_lib.py:133] step: 1052250, training_loss: 2.91833e-02
I0212 19:50:16.162891 22542570456896 run_lib.py:133] step: 1052300, training_loss: 3.02891e-02
I0212 19:50:16.320751 22542570456896 run_lib.py:146] step: 1052300, eval_loss: 3.05606e-02
I0212 19:50:33.952127 22542570456896 run_lib.py:133] step: 1052350, training_loss: 2.81162e-02
I0212 19:50:51.464081 22542570456896 run_lib.py:133] step: 1052400, training_loss: 2.38793e-02
I0212 19:50:51.620046 22542570456896 run_lib.py:146] step: 1052400, eval_loss: 2.03995e-02
I0212 19:51:09.127809 22542570456896 run_lib.py:133] step: 1052450, training_loss: 3.09046e-02
I0212 19:51:26.843049 22542570456896 run_lib.py:133] step: 1052500, training_loss: 2.29382e-02
I0212 19:51:27.006412 22542570456896 run_lib.py:146] step: 1052500, eval_loss: 2.67249e-02
I0212 19:51:44.440439 22542570456896 run_lib.py:133] step: 1052550, training_loss: 2.79060e-02
I0212 19:52:02.052144 22542570456896 run_lib.py:133] step: 1052600, training_loss: 2.39381e-02
I0212 19:52:02.231512 22542570456896 run_lib.py:146] step: 1052600, eval_loss: 2.82062e-02
I0212 19:52:19.747980 22542570456896 run_lib.py:133] step: 1052650, training_loss: 2.57585e-02
I0212 19:52:37.297630 22542570456896 run_lib.py:133] step: 1052700, training_loss: 2.74089e-02
I0212 19:52:37.456812 22542570456896 run_lib.py:146] step: 1052700, eval_loss: 2.88130e-02
I0212 19:52:55.144445 22542570456896 run_lib.py:133] step: 1052750, training_loss: 2.63549e-02
I0212 19:53:12.582605 22542570456896 run_lib.py:133] step: 1052800, training_loss: 2.05396e-02
I0212 19:53:12.738344 22542570456896 run_lib.py:146] step: 1052800, eval_loss: 2.51224e-02
I0212 19:53:30.209868 22542570456896 run_lib.py:133] step: 1052850, training_loss: 2.69926e-02
I0212 19:53:47.727987 22542570456896 run_lib.py:133] step: 1052900, training_loss: 3.20022e-02
I0212 19:53:47.882818 22542570456896 run_lib.py:146] step: 1052900, eval_loss: 2.86332e-02
I0212 19:54:05.567170 22542570456896 run_lib.py:133] step: 1052950, training_loss: 3.62241e-02
I0212 19:54:23.067792 22542570456896 run_lib.py:133] step: 1053000, training_loss: 2.47462e-02
I0212 19:54:23.224399 22542570456896 run_lib.py:146] step: 1053000, eval_loss: 2.89315e-02
I0212 19:54:40.748379 22542570456896 run_lib.py:133] step: 1053050, training_loss: 3.00896e-02
I0212 19:54:58.217243 22542570456896 run_lib.py:133] step: 1053100, training_loss: 2.31973e-02
I0212 19:54:58.383721 22542570456896 run_lib.py:146] step: 1053100, eval_loss: 3.34486e-02
I0212 19:55:15.894659 22542570456896 run_lib.py:133] step: 1053150, training_loss: 2.28587e-02
I0212 19:55:33.397787 22542570456896 run_lib.py:133] step: 1053200, training_loss: 2.62470e-02
I0212 19:55:33.562603 22542570456896 run_lib.py:146] step: 1053200, eval_loss: 2.26620e-02
I0212 19:55:51.228836 22542570456896 run_lib.py:133] step: 1053250, training_loss: 2.75887e-02
I0212 19:56:08.767650 22542570456896 run_lib.py:133] step: 1053300, training_loss: 2.55296e-02
I0212 19:56:08.923536 22542570456896 run_lib.py:146] step: 1053300, eval_loss: 3.56155e-02
I0212 19:56:26.362844 22542570456896 run_lib.py:133] step: 1053350, training_loss: 2.24156e-02
I0212 19:56:43.888152 22542570456896 run_lib.py:133] step: 1053400, training_loss: 2.84672e-02
I0212 19:56:44.046814 22542570456896 run_lib.py:146] step: 1053400, eval_loss: 2.65385e-02
I0212 19:57:01.763038 22542570456896 run_lib.py:133] step: 1053450, training_loss: 3.12881e-02
I0212 19:57:19.225544 22542570456896 run_lib.py:133] step: 1053500, training_loss: 2.06069e-02
I0212 19:57:19.386481 22542570456896 run_lib.py:146] step: 1053500, eval_loss: 2.66126e-02
I0212 19:57:37.011666 22542570456896 run_lib.py:133] step: 1053550, training_loss: 2.64530e-02
I0212 19:57:54.462399 22542570456896 run_lib.py:133] step: 1053600, training_loss: 2.09595e-02
I0212 19:57:54.620693 22542570456896 run_lib.py:146] step: 1053600, eval_loss: 2.72975e-02
I0212 19:58:12.235128 22542570456896 run_lib.py:133] step: 1053650, training_loss: 3.03632e-02
I0212 19:58:29.736066 22542570456896 run_lib.py:133] step: 1053700, training_loss: 2.91728e-02
I0212 19:58:29.894366 22542570456896 run_lib.py:146] step: 1053700, eval_loss: 2.74622e-02
I0212 19:58:47.595618 22542570456896 run_lib.py:133] step: 1053750, training_loss: 2.54612e-02
I0212 19:59:05.081763 22542570456896 run_lib.py:133] step: 1053800, training_loss: 2.96875e-02
I0212 19:59:05.237219 22542570456896 run_lib.py:146] step: 1053800, eval_loss: 2.90504e-02
I0212 19:59:22.697422 22542570456896 run_lib.py:133] step: 1053850, training_loss: 2.78143e-02
I0212 19:59:40.329430 22542570456896 run_lib.py:133] step: 1053900, training_loss: 2.31461e-02
I0212 19:59:40.489502 22542570456896 run_lib.py:146] step: 1053900, eval_loss: 3.35404e-02
I0212 19:59:57.967464 22542570456896 run_lib.py:133] step: 1053950, training_loss: 2.43255e-02
I0212 20:00:15.440843 22542570456896 run_lib.py:133] step: 1054000, training_loss: 2.40343e-02
I0212 20:00:15.602403 22542570456896 run_lib.py:146] step: 1054000, eval_loss: 2.95538e-02
I0212 20:00:33.270036 22542570456896 run_lib.py:133] step: 1054050, training_loss: 2.30652e-02
I0212 20:00:50.896997 22542570456896 run_lib.py:133] step: 1054100, training_loss: 2.85297e-02
I0212 20:00:51.053369 22542570456896 run_lib.py:146] step: 1054100, eval_loss: 2.49212e-02
I0212 20:01:08.538459 22542570456896 run_lib.py:133] step: 1054150, training_loss: 2.41740e-02
I0212 20:01:26.004652 22542570456896 run_lib.py:133] step: 1054200, training_loss: 2.46185e-02
I0212 20:01:26.173678 22542570456896 run_lib.py:146] step: 1054200, eval_loss: 3.33113e-02
I0212 20:01:43.666838 22542570456896 run_lib.py:133] step: 1054250, training_loss: 3.13251e-02
I0212 20:02:01.356937 22542570456896 run_lib.py:133] step: 1054300, training_loss: 2.66455e-02
I0212 20:02:01.512690 22542570456896 run_lib.py:146] step: 1054300, eval_loss: 2.28595e-02
I0212 20:02:18.998461 22542570456896 run_lib.py:133] step: 1054350, training_loss: 2.70535e-02
I0212 20:02:36.448892 22542570456896 run_lib.py:133] step: 1054400, training_loss: 3.12614e-02
I0212 20:02:36.606620 22542570456896 run_lib.py:146] step: 1054400, eval_loss: 2.89234e-02
I0212 20:02:54.061313 22542570456896 run_lib.py:133] step: 1054450, training_loss: 2.68940e-02
I0212 20:03:11.693741 22542570456896 run_lib.py:133] step: 1054500, training_loss: 2.79143e-02
I0212 20:03:11.867383 22542570456896 run_lib.py:146] step: 1054500, eval_loss: 2.78897e-02
I0212 20:03:29.377449 22542570456896 run_lib.py:133] step: 1054550, training_loss: 2.65926e-02
I0212 20:03:46.973934 22542570456896 run_lib.py:133] step: 1054600, training_loss: 2.54788e-02
I0212 20:03:47.131728 22542570456896 run_lib.py:146] step: 1054600, eval_loss: 3.45864e-02
I0212 20:04:04.628640 22542570456896 run_lib.py:133] step: 1054650, training_loss: 2.40770e-02
I0212 20:04:22.086515 22542570456896 run_lib.py:133] step: 1054700, training_loss: 2.28352e-02
I0212 20:04:22.250545 22542570456896 run_lib.py:146] step: 1054700, eval_loss: 2.55586e-02
I0212 20:04:39.886797 22542570456896 run_lib.py:133] step: 1054750, training_loss: 2.58892e-02
I0212 20:04:57.451747 22542570456896 run_lib.py:133] step: 1054800, training_loss: 3.46162e-02
I0212 20:04:57.606772 22542570456896 run_lib.py:146] step: 1054800, eval_loss: 3.65775e-02
I0212 20:05:15.216243 22542570456896 run_lib.py:133] step: 1054850, training_loss: 2.61008e-02
I0212 20:05:32.680877 22542570456896 run_lib.py:133] step: 1054900, training_loss: 3.11198e-02
I0212 20:05:32.837485 22542570456896 run_lib.py:146] step: 1054900, eval_loss: 2.69974e-02
I0212 20:05:50.488704 22542570456896 run_lib.py:133] step: 1054950, training_loss: 2.16498e-02
I0212 20:06:07.948017 22542570456896 run_lib.py:133] step: 1055000, training_loss: 2.48450e-02
I0212 20:06:08.110335 22542570456896 run_lib.py:146] step: 1055000, eval_loss: 2.88033e-02
I0212 20:06:25.767307 22542570456896 run_lib.py:133] step: 1055050, training_loss: 1.92066e-02
I0212 20:06:43.274394 22542570456896 run_lib.py:133] step: 1055100, training_loss: 2.44471e-02
I0212 20:06:43.440785 22542570456896 run_lib.py:146] step: 1055100, eval_loss: 2.76432e-02
I0212 20:07:01.122471 22542570456896 run_lib.py:133] step: 1055150, training_loss: 2.56993e-02
I0212 20:07:18.618282 22542570456896 run_lib.py:133] step: 1055200, training_loss: 2.00752e-02
I0212 20:07:18.772452 22542570456896 run_lib.py:146] step: 1055200, eval_loss: 2.67853e-02
I0212 20:07:36.260406 22542570456896 run_lib.py:133] step: 1055250, training_loss: 3.35083e-02
I0212 20:07:53.904340 22542570456896 run_lib.py:133] step: 1055300, training_loss: 3.42545e-02
I0212 20:07:54.056488 22542570456896 run_lib.py:146] step: 1055300, eval_loss: 2.60543e-02
I0212 20:08:11.510699 22542570456896 run_lib.py:133] step: 1055350, training_loss: 2.89540e-02
I0212 20:08:29.187603 22542570456896 run_lib.py:133] step: 1055400, training_loss: 2.33508e-02
I0212 20:08:29.364527 22542570456896 run_lib.py:146] step: 1055400, eval_loss: 2.20548e-02
I0212 20:08:46.886844 22542570456896 run_lib.py:133] step: 1055450, training_loss: 2.58429e-02
I0212 20:09:04.375124 22542570456896 run_lib.py:133] step: 1055500, training_loss: 2.61670e-02
I0212 20:09:04.532693 22542570456896 run_lib.py:146] step: 1055500, eval_loss: 2.77908e-02
I0212 20:09:22.196910 22542570456896 run_lib.py:133] step: 1055550, training_loss: 2.58887e-02
I0212 20:09:39.657531 22542570456896 run_lib.py:133] step: 1055600, training_loss: 2.92594e-02
I0212 20:09:39.818610 22542570456896 run_lib.py:146] step: 1055600, eval_loss: 2.72713e-02
I0212 20:09:57.301298 22542570456896 run_lib.py:133] step: 1055650, training_loss: 2.72395e-02
I0212 20:10:15.011410 22542570456896 run_lib.py:133] step: 1055700, training_loss: 2.41841e-02
I0212 20:10:15.168181 22542570456896 run_lib.py:146] step: 1055700, eval_loss: 2.86827e-02
I0212 20:10:32.659528 22542570456896 run_lib.py:133] step: 1055750, training_loss: 2.44605e-02
I0212 20:10:50.158674 22542570456896 run_lib.py:133] step: 1055800, training_loss: 2.55827e-02
I0212 20:10:50.313208 22542570456896 run_lib.py:146] step: 1055800, eval_loss: 3.33984e-02
I0212 20:11:07.841763 22542570456896 run_lib.py:133] step: 1055850, training_loss: 2.69108e-02
I0212 20:11:25.329991 22542570456896 run_lib.py:133] step: 1055900, training_loss: 2.73747e-02
I0212 20:11:25.505301 22542570456896 run_lib.py:146] step: 1055900, eval_loss: 2.77520e-02
I0212 20:11:43.014172 22542570456896 run_lib.py:133] step: 1055950, training_loss: 2.45555e-02
I0212 20:12:00.548607 22542570456896 run_lib.py:133] step: 1056000, training_loss: 2.68848e-02
I0212 20:12:00.713808 22542570456896 run_lib.py:146] step: 1056000, eval_loss: 3.35669e-02
I0212 20:12:18.397516 22542570456896 run_lib.py:133] step: 1056050, training_loss: 2.38989e-02
I0212 20:12:35.930591 22542570456896 run_lib.py:133] step: 1056100, training_loss: 2.61822e-02
I0212 20:12:36.087951 22542570456896 run_lib.py:146] step: 1056100, eval_loss: 2.34759e-02
I0212 20:12:53.535794 22542570456896 run_lib.py:133] step: 1056150, training_loss: 2.96031e-02
I0212 20:13:11.045552 22542570456896 run_lib.py:133] step: 1056200, training_loss: 3.15905e-02
I0212 20:13:11.207137 22542570456896 run_lib.py:146] step: 1056200, eval_loss: 3.48438e-02
I0212 20:13:28.899396 22542570456896 run_lib.py:133] step: 1056250, training_loss: 2.41403e-02
I0212 20:13:46.363970 22542570456896 run_lib.py:133] step: 1056300, training_loss: 2.98089e-02
I0212 20:13:46.521430 22542570456896 run_lib.py:146] step: 1056300, eval_loss: 2.75321e-02
I0212 20:14:04.110558 22542570456896 run_lib.py:133] step: 1056350, training_loss: 2.51272e-02
I0212 20:14:21.573366 22542570456896 run_lib.py:133] step: 1056400, training_loss: 2.71427e-02
I0212 20:14:21.740652 22542570456896 run_lib.py:146] step: 1056400, eval_loss: 3.41635e-02
I0212 20:14:39.393439 22542570456896 run_lib.py:133] step: 1056450, training_loss: 2.45406e-02
I0212 20:14:56.908443 22542570456896 run_lib.py:133] step: 1056500, training_loss: 2.22384e-02
I0212 20:14:57.076462 22542570456896 run_lib.py:146] step: 1056500, eval_loss: 2.79376e-02
I0212 20:15:14.760387 22542570456896 run_lib.py:133] step: 1056550, training_loss: 3.27871e-02
I0212 20:15:32.247206 22542570456896 run_lib.py:133] step: 1056600, training_loss: 3.11338e-02
I0212 20:15:32.403407 22542570456896 run_lib.py:146] step: 1056600, eval_loss: 3.17187e-02
I0212 20:15:49.857184 22542570456896 run_lib.py:133] step: 1056650, training_loss: 3.34022e-02
I0212 20:16:07.488698 22542570456896 run_lib.py:133] step: 1056700, training_loss: 2.28192e-02
I0212 20:16:07.643692 22542570456896 run_lib.py:146] step: 1056700, eval_loss: 2.65999e-02
I0212 20:16:25.156737 22542570456896 run_lib.py:133] step: 1056750, training_loss: 2.80327e-02
I0212 20:16:42.527619 22542570456896 run_lib.py:133] step: 1056800, training_loss: 3.33937e-02
I0212 20:16:42.683564 22542570456896 run_lib.py:146] step: 1056800, eval_loss: 1.94731e-02
I0212 20:17:00.247795 22542570456896 run_lib.py:133] step: 1056850, training_loss: 2.44909e-02
I0212 20:17:17.616015 22542570456896 run_lib.py:133] step: 1056900, training_loss: 2.90173e-02
I0212 20:17:17.773504 22542570456896 run_lib.py:146] step: 1056900, eval_loss: 3.32439e-02
I0212 20:17:35.292039 22542570456896 run_lib.py:133] step: 1056950, training_loss: 2.44353e-02
I0212 20:17:52.716446 22542570456896 run_lib.py:133] step: 1057000, training_loss: 2.77399e-02
I0212 20:17:52.877151 22542570456896 run_lib.py:146] step: 1057000, eval_loss: 3.24087e-02
I0212 20:18:10.223538 22542570456896 run_lib.py:133] step: 1057050, training_loss: 3.41836e-02
I0212 20:18:27.796016 22542570456896 run_lib.py:133] step: 1057100, training_loss: 2.95056e-02
I0212 20:18:27.954597 22542570456896 run_lib.py:146] step: 1057100, eval_loss: 2.41462e-02
I0212 20:18:45.368934 22542570456896 run_lib.py:133] step: 1057150, training_loss: 2.03749e-02
I0212 20:19:02.771113 22542570456896 run_lib.py:133] step: 1057200, training_loss: 1.85983e-02
I0212 20:19:02.933085 22542570456896 run_lib.py:146] step: 1057200, eval_loss: 3.18883e-02
I0212 20:19:20.397431 22542570456896 run_lib.py:133] step: 1057250, training_loss: 2.46593e-02
I0212 20:19:38.084669 22542570456896 run_lib.py:133] step: 1057300, training_loss: 2.44898e-02
I0212 20:19:38.250495 22542570456896 run_lib.py:146] step: 1057300, eval_loss: 2.35115e-02
I0212 20:19:55.776361 22542570456896 run_lib.py:133] step: 1057350, training_loss: 2.55531e-02
I0212 20:20:13.392024 22542570456896 run_lib.py:133] step: 1057400, training_loss: 2.72478e-02
I0212 20:20:13.548619 22542570456896 run_lib.py:146] step: 1057400, eval_loss: 3.09989e-02
I0212 20:20:30.997824 22542570456896 run_lib.py:133] step: 1057450, training_loss: 3.46031e-02
I0212 20:20:48.442374 22542570456896 run_lib.py:133] step: 1057500, training_loss: 2.80264e-02
I0212 20:20:48.599477 22542570456896 run_lib.py:146] step: 1057500, eval_loss: 2.40386e-02
I0212 20:21:06.232661 22542570456896 run_lib.py:133] step: 1057550, training_loss: 2.17940e-02
I0212 20:21:23.812369 22542570456896 run_lib.py:133] step: 1057600, training_loss: 1.83500e-02
I0212 20:21:23.967236 22542570456896 run_lib.py:146] step: 1057600, eval_loss: 2.11744e-02
I0212 20:21:41.487110 22542570456896 run_lib.py:133] step: 1057650, training_loss: 2.17915e-02
I0212 20:21:58.986376 22542570456896 run_lib.py:133] step: 1057700, training_loss: 2.32333e-02
I0212 20:21:59.140536 22542570456896 run_lib.py:146] step: 1057700, eval_loss: 2.85512e-02
I0212 20:22:16.785499 22542570456896 run_lib.py:133] step: 1057750, training_loss: 2.48206e-02
I0212 20:22:34.243155 22542570456896 run_lib.py:133] step: 1057800, training_loss: 2.48323e-02
I0212 20:22:34.402799 22542570456896 run_lib.py:146] step: 1057800, eval_loss: 2.72482e-02
I0212 20:22:52.019802 22542570456896 run_lib.py:133] step: 1057850, training_loss: 2.19517e-02
I0212 20:23:09.557866 22542570456896 run_lib.py:133] step: 1057900, training_loss: 3.01430e-02
I0212 20:23:09.719567 22542570456896 run_lib.py:146] step: 1057900, eval_loss: 2.86027e-02
I0212 20:23:27.398509 22542570456896 run_lib.py:133] step: 1057950, training_loss: 3.19957e-02
I0212 20:23:44.869419 22542570456896 run_lib.py:133] step: 1058000, training_loss: 2.94695e-02
I0212 20:23:45.026754 22542570456896 run_lib.py:146] step: 1058000, eval_loss: 3.67259e-02
I0212 20:24:02.506245 22542570456896 run_lib.py:133] step: 1058050, training_loss: 3.05443e-02
I0212 20:24:20.126568 22542570456896 run_lib.py:133] step: 1058100, training_loss: 2.98324e-02
I0212 20:24:20.283054 22542570456896 run_lib.py:146] step: 1058100, eval_loss: 2.61039e-02
I0212 20:24:37.822486 22542570456896 run_lib.py:133] step: 1058150, training_loss: 2.59494e-02
I0212 20:24:55.482887 22542570456896 run_lib.py:133] step: 1058200, training_loss: 3.33261e-02
I0212 20:24:55.640477 22542570456896 run_lib.py:146] step: 1058200, eval_loss: 3.01559e-02
I0212 20:25:13.092262 22542570456896 run_lib.py:133] step: 1058250, training_loss: 2.45775e-02
I0212 20:25:30.590559 22542570456896 run_lib.py:133] step: 1058300, training_loss: 2.65708e-02
I0212 20:25:30.752785 22542570456896 run_lib.py:146] step: 1058300, eval_loss: 2.86830e-02
I0212 20:25:48.343172 22542570456896 run_lib.py:133] step: 1058350, training_loss: 3.80156e-02
I0212 20:26:05.819095 22542570456896 run_lib.py:133] step: 1058400, training_loss: 2.98599e-02
I0212 20:26:05.999330 22542570456896 run_lib.py:146] step: 1058400, eval_loss: 3.59655e-02
I0212 20:26:23.464075 22542570456896 run_lib.py:133] step: 1058450, training_loss: 2.60432e-02
I0212 20:26:41.136498 22542570456896 run_lib.py:133] step: 1058500, training_loss: 2.70030e-02
I0212 20:26:41.298717 22542570456896 run_lib.py:146] step: 1058500, eval_loss: 2.84082e-02
I0212 20:26:58.796356 22542570456896 run_lib.py:133] step: 1058550, training_loss: 2.98856e-02
I0212 20:27:16.262775 22542570456896 run_lib.py:133] step: 1058600, training_loss: 2.40612e-02
I0212 20:27:16.579483 22542570456896 run_lib.py:146] step: 1058600, eval_loss: 2.82592e-02
I0212 20:27:34.030140 22542570456896 run_lib.py:133] step: 1058650, training_loss: 2.30788e-02
I0212 20:27:51.534989 22542570456896 run_lib.py:133] step: 1058700, training_loss: 2.80447e-02
I0212 20:27:51.706075 22542570456896 run_lib.py:146] step: 1058700, eval_loss: 2.81356e-02
I0212 20:28:09.218997 22542570456896 run_lib.py:133] step: 1058750, training_loss: 2.93741e-02
I0212 20:28:26.706489 22542570456896 run_lib.py:133] step: 1058800, training_loss: 2.36403e-02
I0212 20:28:26.873319 22542570456896 run_lib.py:146] step: 1058800, eval_loss: 2.27843e-02
I0212 20:28:44.503868 22542570456896 run_lib.py:133] step: 1058850, training_loss: 3.86305e-02
I0212 20:29:02.006877 22542570456896 run_lib.py:133] step: 1058900, training_loss: 2.40584e-02
I0212 20:29:02.175553 22542570456896 run_lib.py:146] step: 1058900, eval_loss: 3.15040e-02
I0212 20:29:19.696119 22542570456896 run_lib.py:133] step: 1058950, training_loss: 3.47908e-02
I0212 20:29:37.206142 22542570456896 run_lib.py:133] step: 1059000, training_loss: 2.58454e-02
I0212 20:29:37.362557 22542570456896 run_lib.py:146] step: 1059000, eval_loss: 3.65790e-02
I0212 20:29:55.021289 22542570456896 run_lib.py:133] step: 1059050, training_loss: 2.81679e-02
I0212 20:30:12.571129 22542570456896 run_lib.py:133] step: 1059100, training_loss: 2.59094e-02
I0212 20:30:12.726404 22542570456896 run_lib.py:146] step: 1059100, eval_loss: 3.03190e-02
I0212 20:30:30.209372 22542570456896 run_lib.py:133] step: 1059150, training_loss: 2.79773e-02
I0212 20:30:47.680409 22542570456896 run_lib.py:133] step: 1059200, training_loss: 2.45160e-02
I0212 20:30:47.864899 22542570456896 run_lib.py:146] step: 1059200, eval_loss: 2.96342e-02
I0212 20:31:05.553997 22542570456896 run_lib.py:133] step: 1059250, training_loss: 2.24272e-02
I0212 20:31:23.047299 22542570456896 run_lib.py:133] step: 1059300, training_loss: 3.27693e-02
I0212 20:31:23.204619 22542570456896 run_lib.py:146] step: 1059300, eval_loss: 2.80364e-02
I0212 20:31:40.824662 22542570456896 run_lib.py:133] step: 1059350, training_loss: 3.36503e-02
I0212 20:31:58.263540 22542570456896 run_lib.py:133] step: 1059400, training_loss: 2.80965e-02
I0212 20:31:58.421188 22542570456896 run_lib.py:146] step: 1059400, eval_loss: 2.29485e-02
I0212 20:32:16.005930 22542570456896 run_lib.py:133] step: 1059450, training_loss: 3.00937e-02
I0212 20:32:33.554973 22542570456896 run_lib.py:133] step: 1059500, training_loss: 1.82058e-02
I0212 20:32:33.710227 22542570456896 run_lib.py:146] step: 1059500, eval_loss: 2.76768e-02
I0212 20:32:51.233642 22542570456896 run_lib.py:133] step: 1059550, training_loss: 3.00748e-02
I0212 20:33:08.873573 22542570456896 run_lib.py:133] step: 1059600, training_loss: 2.59782e-02
I0212 20:33:09.030496 22542570456896 run_lib.py:146] step: 1059600, eval_loss: 2.72927e-02
I0212 20:33:26.477918 22542570456896 run_lib.py:133] step: 1059650, training_loss: 2.41579e-02
I0212 20:33:44.114174 22542570456896 run_lib.py:133] step: 1059700, training_loss: 2.03492e-02
I0212 20:33:44.284928 22542570456896 run_lib.py:146] step: 1059700, eval_loss: 2.64996e-02
I0212 20:34:01.844690 22542570456896 run_lib.py:133] step: 1059750, training_loss: 2.43857e-02
I0212 20:34:19.337905 22542570456896 run_lib.py:133] step: 1059800, training_loss: 2.95779e-02
I0212 20:34:19.493603 22542570456896 run_lib.py:146] step: 1059800, eval_loss: 3.06690e-02
I0212 20:34:37.198590 22542570456896 run_lib.py:133] step: 1059850, training_loss: 2.36843e-02
I0212 20:34:54.623793 22542570456896 run_lib.py:133] step: 1059900, training_loss: 3.19912e-02
I0212 20:34:54.780473 22542570456896 run_lib.py:146] step: 1059900, eval_loss: 2.72550e-02
I0212 20:35:12.262375 22542570456896 run_lib.py:133] step: 1059950, training_loss: 2.74704e-02
I0212 20:35:29.744433 22542570456896 run_lib.py:133] step: 1060000, training_loss: 2.41867e-02
I0212 20:35:30.476571 22542570456896 run_lib.py:146] step: 1060000, eval_loss: 3.00786e-02
I0212 20:35:50.826646 22542570456896 run_lib.py:133] step: 1060050, training_loss: 2.77400e-02
I0212 20:36:08.465116 22542570456896 run_lib.py:133] step: 1060100, training_loss: 3.03167e-02
I0212 20:36:08.621504 22542570456896 run_lib.py:146] step: 1060100, eval_loss: 3.07088e-02
I0212 20:36:26.074651 22542570456896 run_lib.py:133] step: 1060150, training_loss: 2.81938e-02
I0212 20:36:43.538488 22542570456896 run_lib.py:133] step: 1060200, training_loss: 2.55815e-02
I0212 20:36:43.696679 22542570456896 run_lib.py:146] step: 1060200, eval_loss: 2.11880e-02
I0212 20:37:01.328126 22542570456896 run_lib.py:133] step: 1060250, training_loss: 2.59440e-02
I0212 20:37:18.823567 22542570456896 run_lib.py:133] step: 1060300, training_loss: 2.70289e-02
I0212 20:37:18.987383 22542570456896 run_lib.py:146] step: 1060300, eval_loss: 2.57293e-02
I0212 20:37:36.489065 22542570456896 run_lib.py:133] step: 1060350, training_loss: 3.14001e-02
I0212 20:37:53.938833 22542570456896 run_lib.py:133] step: 1060400, training_loss: 2.15311e-02
I0212 20:37:54.096251 22542570456896 run_lib.py:146] step: 1060400, eval_loss: 3.16219e-02
I0212 20:38:11.742866 22542570456896 run_lib.py:133] step: 1060450, training_loss: 3.05395e-02
I0212 20:38:29.188357 22542570456896 run_lib.py:133] step: 1060500, training_loss: 2.86049e-02
I0212 20:38:29.350409 22542570456896 run_lib.py:146] step: 1060500, eval_loss: 3.40999e-02
I0212 20:38:46.923411 22542570456896 run_lib.py:133] step: 1060550, training_loss: 2.24335e-02
I0212 20:39:04.402725 22542570456896 run_lib.py:133] step: 1060600, training_loss: 2.34652e-02
I0212 20:39:04.559697 22542570456896 run_lib.py:146] step: 1060600, eval_loss: 3.05942e-02
I0212 20:39:22.063657 22542570456896 run_lib.py:133] step: 1060650, training_loss: 2.89887e-02
I0212 20:39:39.571353 22542570456896 run_lib.py:133] step: 1060700, training_loss: 2.33219e-02
I0212 20:39:39.732686 22542570456896 run_lib.py:146] step: 1060700, eval_loss: 2.90008e-02
I0212 20:39:57.369713 22542570456896 run_lib.py:133] step: 1060750, training_loss: 2.36812e-02
I0212 20:40:14.874189 22542570456896 run_lib.py:133] step: 1060800, training_loss: 3.14369e-02
I0212 20:40:15.039387 22542570456896 run_lib.py:146] step: 1060800, eval_loss: 2.37561e-02
I0212 20:40:32.537635 22542570456896 run_lib.py:133] step: 1060850, training_loss: 2.04886e-02
I0212 20:40:50.056705 22542570456896 run_lib.py:133] step: 1060900, training_loss: 2.74881e-02
I0212 20:40:50.212185 22542570456896 run_lib.py:146] step: 1060900, eval_loss: 3.13184e-02
I0212 20:41:07.872139 22542570456896 run_lib.py:133] step: 1060950, training_loss: 3.36062e-02
I0212 20:41:25.315707 22542570456896 run_lib.py:133] step: 1061000, training_loss: 2.32492e-02
I0212 20:41:25.468574 22542570456896 run_lib.py:146] step: 1061000, eval_loss: 2.68476e-02
I0212 20:41:43.062762 22542570456896 run_lib.py:133] step: 1061050, training_loss: 2.29138e-02
I0212 20:42:00.567101 22542570456896 run_lib.py:133] step: 1061100, training_loss: 2.13049e-02
I0212 20:42:00.733674 22542570456896 run_lib.py:146] step: 1061100, eval_loss: 3.07671e-02
I0212 20:42:18.462184 22542570456896 run_lib.py:133] step: 1061150, training_loss: 2.70026e-02
I0212 20:42:35.955936 22542570456896 run_lib.py:133] step: 1061200, training_loss: 2.40562e-02
I0212 20:42:36.116575 22542570456896 run_lib.py:146] step: 1061200, eval_loss: 2.95574e-02
I0212 20:42:53.737224 22542570456896 run_lib.py:133] step: 1061250, training_loss: 2.63309e-02
I0212 20:43:11.205321 22542570456896 run_lib.py:133] step: 1061300, training_loss: 3.18748e-02
I0212 20:43:11.362458 22542570456896 run_lib.py:146] step: 1061300, eval_loss: 2.85316e-02
I0212 20:43:28.841570 22542570456896 run_lib.py:133] step: 1061350, training_loss: 2.45906e-02
I0212 20:43:46.517509 22542570456896 run_lib.py:133] step: 1061400, training_loss: 2.49211e-02
I0212 20:43:46.675247 22542570456896 run_lib.py:146] step: 1061400, eval_loss: 3.13682e-02
I0212 20:44:04.171112 22542570456896 run_lib.py:133] step: 1061450, training_loss: 2.96294e-02
I0212 20:44:21.663742 22542570456896 run_lib.py:133] step: 1061500, training_loss: 2.83786e-02
I0212 20:44:21.817496 22542570456896 run_lib.py:146] step: 1061500, eval_loss: 2.45744e-02
I0212 20:44:39.485394 22542570456896 run_lib.py:133] step: 1061550, training_loss: 2.23138e-02
I0212 20:44:56.969269 22542570456896 run_lib.py:133] step: 1061600, training_loss: 2.69993e-02
I0212 20:44:57.135113 22542570456896 run_lib.py:146] step: 1061600, eval_loss: 3.28927e-02
I0212 20:45:14.804108 22542570456896 run_lib.py:133] step: 1061650, training_loss: 2.56846e-02
I0212 20:45:32.366972 22542570456896 run_lib.py:133] step: 1061700, training_loss: 3.21531e-02
I0212 20:45:32.528545 22542570456896 run_lib.py:146] step: 1061700, eval_loss: 3.15565e-02
I0212 20:45:49.976628 22542570456896 run_lib.py:133] step: 1061750, training_loss: 2.79200e-02
I0212 20:46:07.628680 22542570456896 run_lib.py:133] step: 1061800, training_loss: 2.07904e-02
I0212 20:46:07.791464 22542570456896 run_lib.py:146] step: 1061800, eval_loss: 2.38479e-02
I0212 20:46:25.258010 22542570456896 run_lib.py:133] step: 1061850, training_loss: 2.35470e-02
I0212 20:46:42.774427 22542570456896 run_lib.py:133] step: 1061900, training_loss: 2.56412e-02
I0212 20:46:42.932629 22542570456896 run_lib.py:146] step: 1061900, eval_loss: 2.77068e-02
I0212 20:47:00.421575 22542570456896 run_lib.py:133] step: 1061950, training_loss: 2.79977e-02
I0212 20:47:17.969443 22542570456896 run_lib.py:133] step: 1062000, training_loss: 3.36268e-02
I0212 20:47:18.118633 22542570456896 run_lib.py:146] step: 1062000, eval_loss: 2.65073e-02
I0212 20:47:35.446732 22542570456896 run_lib.py:133] step: 1062050, training_loss: 2.97010e-02
I0212 20:47:52.914298 22542570456896 run_lib.py:133] step: 1062100, training_loss: 2.11407e-02
I0212 20:47:53.070551 22542570456896 run_lib.py:146] step: 1062100, eval_loss: 3.00372e-02
I0212 20:48:10.389221 22542570456896 run_lib.py:133] step: 1062150, training_loss: 3.18791e-02
I0212 20:48:27.760545 22542570456896 run_lib.py:133] step: 1062200, training_loss: 2.30754e-02
I0212 20:48:27.922452 22542570456896 run_lib.py:146] step: 1062200, eval_loss: 2.48532e-02
I0212 20:48:45.470811 22542570456896 run_lib.py:133] step: 1062250, training_loss: 2.35269e-02
I0212 20:49:02.996048 22542570456896 run_lib.py:133] step: 1062300, training_loss: 2.34199e-02
I0212 20:49:03.150593 22542570456896 run_lib.py:146] step: 1062300, eval_loss: 2.78066e-02
I0212 20:49:20.513812 22542570456896 run_lib.py:133] step: 1062350, training_loss: 2.71696e-02
I0212 20:49:37.902752 22542570456896 run_lib.py:133] step: 1062400, training_loss: 2.35765e-02
I0212 20:49:38.058474 22542570456896 run_lib.py:146] step: 1062400, eval_loss: 3.16208e-02
I0212 20:49:55.687188 22542570456896 run_lib.py:133] step: 1062450, training_loss: 2.02979e-02
I0212 20:50:13.169409 22542570456896 run_lib.py:133] step: 1062500, training_loss: 2.62425e-02
I0212 20:50:13.326896 22542570456896 run_lib.py:146] step: 1062500, eval_loss: 2.51226e-02
I0212 20:50:31.050140 22542570456896 run_lib.py:133] step: 1062550, training_loss: 2.91147e-02
I0212 20:50:48.552431 22542570456896 run_lib.py:133] step: 1062600, training_loss: 2.53483e-02
I0212 20:50:48.713530 22542570456896 run_lib.py:146] step: 1062600, eval_loss: 2.72752e-02
I0212 20:51:06.379920 22542570456896 run_lib.py:133] step: 1062650, training_loss: 2.93915e-02
I0212 20:51:23.878566 22542570456896 run_lib.py:133] step: 1062700, training_loss: 2.32965e-02
I0212 20:51:24.034508 22542570456896 run_lib.py:146] step: 1062700, eval_loss: 3.16528e-02
I0212 20:51:41.523376 22542570456896 run_lib.py:133] step: 1062750, training_loss: 3.03615e-02
I0212 20:51:59.164607 22542570456896 run_lib.py:133] step: 1062800, training_loss: 3.06856e-02
I0212 20:51:59.323339 22542570456896 run_lib.py:146] step: 1062800, eval_loss: 3.41473e-02
I0212 20:52:16.904419 22542570456896 run_lib.py:133] step: 1062850, training_loss: 2.33086e-02
I0212 20:52:34.553590 22542570456896 run_lib.py:133] step: 1062900, training_loss: 2.19900e-02
I0212 20:52:34.706561 22542570456896 run_lib.py:146] step: 1062900, eval_loss: 3.49438e-02
I0212 20:52:52.143687 22542570456896 run_lib.py:133] step: 1062950, training_loss: 2.83404e-02
I0212 20:53:09.603818 22542570456896 run_lib.py:133] step: 1063000, training_loss: 3.53182e-02
I0212 20:53:09.761589 22542570456896 run_lib.py:146] step: 1063000, eval_loss: 3.05598e-02
I0212 20:53:27.418678 22542570456896 run_lib.py:133] step: 1063050, training_loss: 2.85095e-02
I0212 20:53:44.926451 22542570456896 run_lib.py:133] step: 1063100, training_loss: 2.69235e-02
I0212 20:53:45.087486 22542570456896 run_lib.py:146] step: 1063100, eval_loss: 3.00521e-02
I0212 20:54:02.556664 22542570456896 run_lib.py:133] step: 1063150, training_loss: 3.09071e-02
I0212 20:54:20.212158 22542570456896 run_lib.py:133] step: 1063200, training_loss: 2.33797e-02
I0212 20:54:20.369478 22542570456896 run_lib.py:146] step: 1063200, eval_loss: 2.71630e-02
I0212 20:54:37.867803 22542570456896 run_lib.py:133] step: 1063250, training_loss: 2.48923e-02
I0212 20:54:55.301200 22542570456896 run_lib.py:133] step: 1063300, training_loss: 3.84678e-02
I0212 20:54:55.608990 22542570456896 run_lib.py:146] step: 1063300, eval_loss: 3.39120e-02
I0212 20:55:13.064976 22542570456896 run_lib.py:133] step: 1063350, training_loss: 2.87402e-02
I0212 20:55:30.598455 22542570456896 run_lib.py:133] step: 1063400, training_loss: 2.04261e-02
I0212 20:55:30.751695 22542570456896 run_lib.py:146] step: 1063400, eval_loss: 2.72568e-02
I0212 20:55:48.279918 22542570456896 run_lib.py:133] step: 1063450, training_loss: 3.02392e-02
I0212 20:56:05.763317 22542570456896 run_lib.py:133] step: 1063500, training_loss: 2.96246e-02
I0212 20:56:05.920587 22542570456896 run_lib.py:146] step: 1063500, eval_loss: 2.59767e-02
I0212 20:56:23.565960 22542570456896 run_lib.py:133] step: 1063550, training_loss: 3.04272e-02
I0212 20:56:41.089758 22542570456896 run_lib.py:133] step: 1063600, training_loss: 3.05913e-02
I0212 20:56:41.254680 22542570456896 run_lib.py:146] step: 1063600, eval_loss: 2.68118e-02
I0212 20:56:58.757694 22542570456896 run_lib.py:133] step: 1063650, training_loss: 2.94079e-02
I0212 20:57:16.282177 22542570456896 run_lib.py:133] step: 1063700, training_loss: 2.50030e-02
I0212 20:57:16.448780 22542570456896 run_lib.py:146] step: 1063700, eval_loss: 2.88017e-02
I0212 20:57:34.116829 22542570456896 run_lib.py:133] step: 1063750, training_loss: 2.98594e-02
I0212 20:57:51.666406 22542570456896 run_lib.py:133] step: 1063800, training_loss: 2.41961e-02
I0212 20:57:51.822294 22542570456896 run_lib.py:146] step: 1063800, eval_loss: 3.38414e-02
I0212 20:58:09.305254 22542570456896 run_lib.py:133] step: 1063850, training_loss: 2.33581e-02
I0212 20:58:26.796316 22542570456896 run_lib.py:133] step: 1063900, training_loss: 2.90290e-02
I0212 20:58:26.959595 22542570456896 run_lib.py:146] step: 1063900, eval_loss: 3.33314e-02
I0212 20:58:44.629934 22542570456896 run_lib.py:133] step: 1063950, training_loss: 3.35202e-02
I0212 20:59:02.114745 22542570456896 run_lib.py:133] step: 1064000, training_loss: 2.78889e-02
I0212 20:59:02.274348 22542570456896 run_lib.py:146] step: 1064000, eval_loss: 3.06585e-02
I0212 20:59:19.922348 22542570456896 run_lib.py:133] step: 1064050, training_loss: 3.86083e-02
I0212 20:59:37.355391 22542570456896 run_lib.py:133] step: 1064100, training_loss: 2.39615e-02
I0212 20:59:37.515798 22542570456896 run_lib.py:146] step: 1064100, eval_loss: 3.20569e-02
I0212 20:59:55.117454 22542570456896 run_lib.py:133] step: 1064150, training_loss: 2.70212e-02
I0212 21:00:12.564995 22542570456896 run_lib.py:133] step: 1064200, training_loss: 3.29541e-02
I0212 21:00:12.734281 22542570456896 run_lib.py:146] step: 1064200, eval_loss: 2.86764e-02
I0212 21:00:30.248149 22542570456896 run_lib.py:133] step: 1064250, training_loss: 2.24958e-02
I0212 21:00:47.930234 22542570456896 run_lib.py:133] step: 1064300, training_loss: 3.33279e-02
I0212 21:00:48.092105 22542570456896 run_lib.py:146] step: 1064300, eval_loss: 2.83957e-02
I0212 21:01:05.588199 22542570456896 run_lib.py:133] step: 1064350, training_loss: 2.17492e-02
I0212 21:01:23.187705 22542570456896 run_lib.py:133] step: 1064400, training_loss: 3.04679e-02
I0212 21:01:23.350325 22542570456896 run_lib.py:146] step: 1064400, eval_loss: 2.56534e-02
I0212 21:01:40.791909 22542570456896 run_lib.py:133] step: 1064450, training_loss: 3.21544e-02
I0212 21:01:58.273334 22542570456896 run_lib.py:133] step: 1064500, training_loss: 2.85001e-02
I0212 21:01:58.451460 22542570456896 run_lib.py:146] step: 1064500, eval_loss: 1.98670e-02
I0212 21:02:16.162950 22542570456896 run_lib.py:133] step: 1064550, training_loss: 2.91857e-02
I0212 21:02:33.671167 22542570456896 run_lib.py:133] step: 1064600, training_loss: 2.63486e-02
I0212 21:02:33.827418 22542570456896 run_lib.py:146] step: 1064600, eval_loss: 2.39307e-02
I0212 21:02:51.297750 22542570456896 run_lib.py:133] step: 1064650, training_loss: 2.26510e-02
I0212 21:03:08.712014 22542570456896 run_lib.py:133] step: 1064700, training_loss: 3.06249e-02
I0212 21:03:08.869595 22542570456896 run_lib.py:146] step: 1064700, eval_loss: 2.92795e-02
I0212 21:03:26.542902 22542570456896 run_lib.py:133] step: 1064750, training_loss: 2.94042e-02
I0212 21:03:44.047466 22542570456896 run_lib.py:133] step: 1064800, training_loss: 2.98445e-02
I0212 21:03:44.203912 22542570456896 run_lib.py:146] step: 1064800, eval_loss: 3.04859e-02
I0212 21:04:01.816026 22542570456896 run_lib.py:133] step: 1064850, training_loss: 2.54170e-02
I0212 21:04:19.266905 22542570456896 run_lib.py:133] step: 1064900, training_loss: 3.20862e-02
I0212 21:04:19.433418 22542570456896 run_lib.py:146] step: 1064900, eval_loss: 2.49320e-02
I0212 21:04:36.867782 22542570456896 run_lib.py:133] step: 1064950, training_loss: 2.34106e-02
I0212 21:04:54.334014 22542570456896 run_lib.py:133] step: 1065000, training_loss: 3.29578e-02
I0212 21:04:54.512407 22542570456896 run_lib.py:146] step: 1065000, eval_loss: 3.37929e-02
I0212 21:05:12.162081 22542570456896 run_lib.py:133] step: 1065050, training_loss: 2.97422e-02
I0212 21:05:29.756574 22542570456896 run_lib.py:133] step: 1065100, training_loss: 2.26158e-02
I0212 21:05:29.915824 22542570456896 run_lib.py:146] step: 1065100, eval_loss: 2.67338e-02
I0212 21:05:47.386297 22542570456896 run_lib.py:133] step: 1065150, training_loss: 2.96889e-02
I0212 21:06:04.861299 22542570456896 run_lib.py:133] step: 1065200, training_loss: 2.29672e-02
I0212 21:06:05.019485 22542570456896 run_lib.py:146] step: 1065200, eval_loss: 3.19752e-02
I0212 21:06:22.657556 22542570456896 run_lib.py:133] step: 1065250, training_loss: 2.82138e-02
I0212 21:06:40.168990 22542570456896 run_lib.py:133] step: 1065300, training_loss: 3.80385e-02
I0212 21:06:40.324650 22542570456896 run_lib.py:146] step: 1065300, eval_loss: 3.33155e-02
I0212 21:06:58.010926 22542570456896 run_lib.py:133] step: 1065350, training_loss: 2.09785e-02
I0212 21:07:15.487379 22542570456896 run_lib.py:133] step: 1065400, training_loss: 2.16245e-02
I0212 21:07:15.652420 22542570456896 run_lib.py:146] step: 1065400, eval_loss: 2.85937e-02
I0212 21:07:33.274292 22542570456896 run_lib.py:133] step: 1065450, training_loss: 1.99244e-02
I0212 21:07:50.746469 22542570456896 run_lib.py:133] step: 1065500, training_loss: 2.44028e-02
I0212 21:07:50.911555 22542570456896 run_lib.py:146] step: 1065500, eval_loss: 3.31605e-02
I0212 21:08:08.585969 22542570456896 run_lib.py:133] step: 1065550, training_loss: 2.42327e-02
I0212 21:08:26.113132 22542570456896 run_lib.py:133] step: 1065600, training_loss: 2.55921e-02
I0212 21:08:26.278930 22542570456896 run_lib.py:146] step: 1065600, eval_loss: 2.77965e-02
I0212 21:08:43.714545 22542570456896 run_lib.py:133] step: 1065650, training_loss: 2.39319e-02
I0212 21:09:01.321644 22542570456896 run_lib.py:133] step: 1065700, training_loss: 3.07729e-02
I0212 21:09:01.478386 22542570456896 run_lib.py:146] step: 1065700, eval_loss: 2.86295e-02
I0212 21:09:18.930995 22542570456896 run_lib.py:133] step: 1065750, training_loss: 3.62720e-02
I0212 21:09:36.419392 22542570456896 run_lib.py:133] step: 1065800, training_loss: 2.67696e-02
I0212 21:09:36.574671 22542570456896 run_lib.py:146] step: 1065800, eval_loss: 2.59388e-02
I0212 21:09:54.273071 22542570456896 run_lib.py:133] step: 1065850, training_loss: 2.55526e-02
I0212 21:10:11.961987 22542570456896 run_lib.py:133] step: 1065900, training_loss: 3.05626e-02
I0212 21:10:12.120281 22542570456896 run_lib.py:146] step: 1065900, eval_loss: 3.17113e-02
I0212 21:10:29.583546 22542570456896 run_lib.py:133] step: 1065950, training_loss: 3.23068e-02
I0212 21:10:47.045025 22542570456896 run_lib.py:133] step: 1066000, training_loss: 2.74972e-02
I0212 21:10:47.203643 22542570456896 run_lib.py:146] step: 1066000, eval_loss: 3.18261e-02
I0212 21:11:04.677609 22542570456896 run_lib.py:133] step: 1066050, training_loss: 3.00422e-02
I0212 21:11:22.419822 22542570456896 run_lib.py:133] step: 1066100, training_loss: 2.78554e-02
I0212 21:11:22.580343 22542570456896 run_lib.py:146] step: 1066100, eval_loss: 2.71472e-02
I0212 21:11:40.042588 22542570456896 run_lib.py:133] step: 1066150, training_loss: 3.43375e-02
I0212 21:11:57.516475 22542570456896 run_lib.py:133] step: 1066200, training_loss: 2.80867e-02
I0212 21:11:57.667303 22542570456896 run_lib.py:146] step: 1066200, eval_loss: 3.65555e-02
I0212 21:12:15.132534 22542570456896 run_lib.py:133] step: 1066250, training_loss: 2.36954e-02
I0212 21:12:32.785313 22542570456896 run_lib.py:133] step: 1066300, training_loss: 2.98484e-02
I0212 21:12:32.940571 22542570456896 run_lib.py:146] step: 1066300, eval_loss: 3.13155e-02
I0212 21:12:50.405105 22542570456896 run_lib.py:133] step: 1066350, training_loss: 2.95419e-02
I0212 21:13:07.975697 22542570456896 run_lib.py:133] step: 1066400, training_loss: 3.13319e-02
I0212 21:13:08.141365 22542570456896 run_lib.py:146] step: 1066400, eval_loss: 2.96850e-02
I0212 21:13:25.600400 22542570456896 run_lib.py:133] step: 1066450, training_loss: 2.23149e-02
I0212 21:13:43.048043 22542570456896 run_lib.py:133] step: 1066500, training_loss: 2.48119e-02
I0212 21:13:43.204441 22542570456896 run_lib.py:146] step: 1066500, eval_loss: 2.85427e-02
I0212 21:14:00.845175 22542570456896 run_lib.py:133] step: 1066550, training_loss: 2.28549e-02
I0212 21:14:18.384888 22542570456896 run_lib.py:133] step: 1066600, training_loss: 2.70034e-02
I0212 21:14:18.548612 22542570456896 run_lib.py:146] step: 1066600, eval_loss: 3.07524e-02
I0212 21:14:36.013028 22542570456896 run_lib.py:133] step: 1066650, training_loss: 2.59320e-02
I0212 21:14:53.514901 22542570456896 run_lib.py:133] step: 1066700, training_loss: 3.01044e-02
I0212 21:14:53.669682 22542570456896 run_lib.py:146] step: 1066700, eval_loss: 3.41165e-02
I0212 21:15:11.372408 22542570456896 run_lib.py:133] step: 1066750, training_loss: 2.85263e-02
I0212 21:15:28.862111 22542570456896 run_lib.py:133] step: 1066800, training_loss: 2.61663e-02
I0212 21:15:29.020480 22542570456896 run_lib.py:146] step: 1066800, eval_loss: 2.86074e-02
I0212 21:15:46.601767 22542570456896 run_lib.py:133] step: 1066850, training_loss: 2.73931e-02
I0212 21:16:04.059728 22542570456896 run_lib.py:133] step: 1066900, training_loss: 2.57346e-02
I0212 21:16:04.219475 22542570456896 run_lib.py:146] step: 1066900, eval_loss: 2.48674e-02
I0212 21:16:21.871781 22542570456896 run_lib.py:133] step: 1066950, training_loss: 2.98388e-02
I0212 21:16:39.379398 22542570456896 run_lib.py:133] step: 1067000, training_loss: 3.15389e-02
I0212 21:16:39.545258 22542570456896 run_lib.py:146] step: 1067000, eval_loss: 2.29064e-02
I0212 21:16:57.037642 22542570456896 run_lib.py:133] step: 1067050, training_loss: 2.52879e-02
I0212 21:17:14.686157 22542570456896 run_lib.py:133] step: 1067100, training_loss: 2.83395e-02
I0212 21:17:14.843170 22542570456896 run_lib.py:146] step: 1067100, eval_loss: 2.89316e-02
I0212 21:17:32.315340 22542570456896 run_lib.py:133] step: 1067150, training_loss: 2.92545e-02
I0212 21:17:49.767047 22542570456896 run_lib.py:133] step: 1067200, training_loss: 3.29840e-02
I0212 21:17:49.919587 22542570456896 run_lib.py:146] step: 1067200, eval_loss: 2.83481e-02
I0212 21:18:07.285460 22542570456896 run_lib.py:133] step: 1067250, training_loss: 3.04582e-02
I0212 21:18:24.668052 22542570456896 run_lib.py:133] step: 1067300, training_loss: 2.29006e-02
I0212 21:18:24.828606 22542570456896 run_lib.py:146] step: 1067300, eval_loss: 2.43906e-02
I0212 21:18:42.411206 22542570456896 run_lib.py:133] step: 1067350, training_loss: 2.46995e-02
I0212 21:18:59.823017 22542570456896 run_lib.py:133] step: 1067400, training_loss: 2.15891e-02
I0212 21:18:59.980723 22542570456896 run_lib.py:146] step: 1067400, eval_loss: 2.35805e-02
I0212 21:19:17.372922 22542570456896 run_lib.py:133] step: 1067450, training_loss: 2.91554e-02
I0212 21:19:34.871479 22542570456896 run_lib.py:133] step: 1067500, training_loss: 2.87751e-02
I0212 21:19:35.034365 22542570456896 run_lib.py:146] step: 1067500, eval_loss: 2.54290e-02
I0212 21:19:52.480055 22542570456896 run_lib.py:133] step: 1067550, training_loss: 2.31474e-02
I0212 21:20:09.946252 22542570456896 run_lib.py:133] step: 1067600, training_loss: 2.19012e-02
I0212 21:20:10.103713 22542570456896 run_lib.py:146] step: 1067600, eval_loss: 3.31034e-02
I0212 21:20:27.730695 22542570456896 run_lib.py:133] step: 1067650, training_loss: 2.12286e-02
I0212 21:20:45.191746 22542570456896 run_lib.py:133] step: 1067700, training_loss: 2.64715e-02
I0212 21:20:45.345523 22542570456896 run_lib.py:146] step: 1067700, eval_loss: 2.62765e-02
I0212 21:21:02.810473 22542570456896 run_lib.py:133] step: 1067750, training_loss: 2.59105e-02
I0212 21:21:20.247748 22542570456896 run_lib.py:133] step: 1067800, training_loss: 2.85067e-02
I0212 21:21:20.410574 22542570456896 run_lib.py:146] step: 1067800, eval_loss: 2.63642e-02
I0212 21:21:38.031363 22542570456896 run_lib.py:133] step: 1067850, training_loss: 2.79770e-02
I0212 21:21:55.653826 22542570456896 run_lib.py:133] step: 1067900, training_loss: 2.36115e-02
I0212 21:21:55.815431 22542570456896 run_lib.py:146] step: 1067900, eval_loss: 2.90710e-02
I0212 21:22:13.292957 22542570456896 run_lib.py:133] step: 1067950, training_loss: 2.46180e-02
I0212 21:22:30.742839 22542570456896 run_lib.py:133] step: 1068000, training_loss: 2.92983e-02
I0212 21:22:30.908654 22542570456896 run_lib.py:146] step: 1068000, eval_loss: 3.17151e-02
I0212 21:22:48.523894 22542570456896 run_lib.py:133] step: 1068050, training_loss: 2.76558e-02
I0212 21:23:05.967969 22542570456896 run_lib.py:133] step: 1068100, training_loss: 2.63219e-02
I0212 21:23:06.129524 22542570456896 run_lib.py:146] step: 1068100, eval_loss: 2.55798e-02
I0212 21:23:23.783037 22542570456896 run_lib.py:133] step: 1068150, training_loss: 2.81029e-02
I0212 21:23:41.288318 22542570456896 run_lib.py:133] step: 1068200, training_loss: 2.99198e-02
I0212 21:23:41.455975 22542570456896 run_lib.py:146] step: 1068200, eval_loss: 2.83620e-02
I0212 21:23:59.131382 22542570456896 run_lib.py:133] step: 1068250, training_loss: 2.40043e-02
I0212 21:24:16.600082 22542570456896 run_lib.py:133] step: 1068300, training_loss: 2.50957e-02
I0212 21:24:16.760697 22542570456896 run_lib.py:146] step: 1068300, eval_loss: 2.83389e-02
I0212 21:24:34.349415 22542570456896 run_lib.py:133] step: 1068350, training_loss: 2.18406e-02
I0212 21:24:51.836187 22542570456896 run_lib.py:133] step: 1068400, training_loss: 2.79826e-02
I0212 21:24:52.005459 22542570456896 run_lib.py:146] step: 1068400, eval_loss: 3.24290e-02
I0212 21:25:09.527806 22542570456896 run_lib.py:133] step: 1068450, training_loss: 2.57965e-02
I0212 21:25:27.209082 22542570456896 run_lib.py:133] step: 1068500, training_loss: 2.32022e-02
I0212 21:25:27.367097 22542570456896 run_lib.py:146] step: 1068500, eval_loss: 2.61901e-02
I0212 21:25:44.856513 22542570456896 run_lib.py:133] step: 1068550, training_loss: 2.88564e-02
I0212 21:26:02.313210 22542570456896 run_lib.py:133] step: 1068600, training_loss: 3.16765e-02
I0212 21:26:02.465212 22542570456896 run_lib.py:146] step: 1068600, eval_loss: 2.87928e-02
I0212 21:26:20.076992 22542570456896 run_lib.py:133] step: 1068650, training_loss: 2.86217e-02
I0212 21:26:37.553138 22542570456896 run_lib.py:133] step: 1068700, training_loss: 2.54450e-02
I0212 21:26:37.722681 22542570456896 run_lib.py:146] step: 1068700, eval_loss: 2.95389e-02
I0212 21:26:55.366894 22542570456896 run_lib.py:133] step: 1068750, training_loss: 2.58535e-02
I0212 21:27:12.842420 22542570456896 run_lib.py:133] step: 1068800, training_loss: 2.59252e-02
I0212 21:27:13.002560 22542570456896 run_lib.py:146] step: 1068800, eval_loss: 2.56023e-02
I0212 21:27:30.443089 22542570456896 run_lib.py:133] step: 1068850, training_loss: 3.53420e-02
I0212 21:27:48.074698 22542570456896 run_lib.py:133] step: 1068900, training_loss: 2.65281e-02
I0212 21:27:48.228692 22542570456896 run_lib.py:146] step: 1068900, eval_loss: 2.90197e-02
I0212 21:28:05.725090 22542570456896 run_lib.py:133] step: 1068950, training_loss: 2.40054e-02
I0212 21:28:23.219813 22542570456896 run_lib.py:133] step: 1069000, training_loss: 2.79896e-02
I0212 21:28:23.377713 22542570456896 run_lib.py:146] step: 1069000, eval_loss: 3.14773e-02
I0212 21:28:40.884167 22542570456896 run_lib.py:133] step: 1069050, training_loss: 2.59727e-02
I0212 21:28:58.577513 22542570456896 run_lib.py:133] step: 1069100, training_loss: 2.63697e-02
I0212 21:28:58.727763 22542570456896 run_lib.py:146] step: 1069100, eval_loss: 2.80563e-02
I0212 21:29:16.200154 22542570456896 run_lib.py:133] step: 1069150, training_loss: 3.00442e-02
I0212 21:29:33.757655 22542570456896 run_lib.py:133] step: 1069200, training_loss: 2.81028e-02
I0212 21:29:33.913388 22542570456896 run_lib.py:146] step: 1069200, eval_loss: 3.13678e-02
I0212 21:29:51.353614 22542570456896 run_lib.py:133] step: 1069250, training_loss: 3.16565e-02
I0212 21:30:08.956411 22542570456896 run_lib.py:133] step: 1069300, training_loss: 2.00514e-02
I0212 21:30:09.132467 22542570456896 run_lib.py:146] step: 1069300, eval_loss: 3.29229e-02
I0212 21:30:26.784007 22542570456896 run_lib.py:133] step: 1069350, training_loss: 2.47227e-02
I0212 21:30:44.311005 22542570456896 run_lib.py:133] step: 1069400, training_loss: 2.70890e-02
I0212 21:30:44.468221 22542570456896 run_lib.py:146] step: 1069400, eval_loss: 2.10382e-02
I0212 21:31:01.941718 22542570456896 run_lib.py:133] step: 1069450, training_loss: 2.79034e-02
I0212 21:31:19.403057 22542570456896 run_lib.py:133] step: 1069500, training_loss: 3.26748e-02
I0212 21:31:19.559445 22542570456896 run_lib.py:146] step: 1069500, eval_loss: 3.34813e-02
I0212 21:31:37.164384 22542570456896 run_lib.py:133] step: 1069550, training_loss: 2.95305e-02
I0212 21:31:54.680566 22542570456896 run_lib.py:133] step: 1069600, training_loss: 2.48969e-02
I0212 21:31:54.836712 22542570456896 run_lib.py:146] step: 1069600, eval_loss: 2.29725e-02
I0212 21:32:12.545372 22542570456896 run_lib.py:133] step: 1069650, training_loss: 3.01349e-02
I0212 21:32:30.049554 22542570456896 run_lib.py:133] step: 1069700, training_loss: 2.57484e-02
I0212 21:32:30.212537 22542570456896 run_lib.py:146] step: 1069700, eval_loss: 3.40800e-02
I0212 21:32:47.812830 22542570456896 run_lib.py:133] step: 1069750, training_loss: 2.63540e-02
I0212 21:33:05.272264 22542570456896 run_lib.py:133] step: 1069800, training_loss: 2.77827e-02
I0212 21:33:05.442466 22542570456896 run_lib.py:146] step: 1069800, eval_loss: 2.67770e-02
I0212 21:33:22.961399 22542570456896 run_lib.py:133] step: 1069850, training_loss: 2.40448e-02
I0212 21:33:40.670797 22542570456896 run_lib.py:133] step: 1069900, training_loss: 3.37611e-02
I0212 21:33:40.828732 22542570456896 run_lib.py:146] step: 1069900, eval_loss: 2.78541e-02
I0212 21:33:58.305476 22542570456896 run_lib.py:133] step: 1069950, training_loss: 2.46151e-02
I0212 21:34:15.947927 22542570456896 run_lib.py:133] step: 1070000, training_loss: 3.04721e-02
I0212 21:34:16.696128 22542570456896 run_lib.py:146] step: 1070000, eval_loss: 2.69881e-02
I0212 21:34:36.921298 22542570456896 run_lib.py:133] step: 1070050, training_loss: 2.56109e-02
I0212 21:34:54.401224 22542570456896 run_lib.py:133] step: 1070100, training_loss: 2.45301e-02
I0212 21:34:54.557706 22542570456896 run_lib.py:146] step: 1070100, eval_loss: 2.75561e-02
I0212 21:35:12.047618 22542570456896 run_lib.py:133] step: 1070150, training_loss: 2.99791e-02
I0212 21:35:29.516471 22542570456896 run_lib.py:133] step: 1070200, training_loss: 2.12293e-02
I0212 21:35:29.675640 22542570456896 run_lib.py:146] step: 1070200, eval_loss: 2.85142e-02
I0212 21:35:47.288875 22542570456896 run_lib.py:133] step: 1070250, training_loss: 2.99684e-02
I0212 21:36:04.850195 22542570456896 run_lib.py:133] step: 1070300, training_loss: 2.37097e-02
I0212 21:36:05.015703 22542570456896 run_lib.py:146] step: 1070300, eval_loss: 3.28374e-02
I0212 21:36:22.479729 22542570456896 run_lib.py:133] step: 1070350, training_loss: 2.71651e-02
I0212 21:36:40.018507 22542570456896 run_lib.py:133] step: 1070400, training_loss: 2.87350e-02
I0212 21:36:40.176770 22542570456896 run_lib.py:146] step: 1070400, eval_loss: 2.60873e-02
I0212 21:36:57.834398 22542570456896 run_lib.py:133] step: 1070450, training_loss: 2.67689e-02
I0212 21:37:15.360387 22542570456896 run_lib.py:133] step: 1070500, training_loss: 2.36488e-02
I0212 21:37:15.518562 22542570456896 run_lib.py:146] step: 1070500, eval_loss: 2.67663e-02
I0212 21:37:33.121664 22542570456896 run_lib.py:133] step: 1070550, training_loss: 2.47774e-02
I0212 21:37:50.564172 22542570456896 run_lib.py:133] step: 1070600, training_loss: 2.78978e-02
I0212 21:37:50.717421 22542570456896 run_lib.py:146] step: 1070600, eval_loss: 3.08543e-02
I0212 21:38:08.316600 22542570456896 run_lib.py:133] step: 1070650, training_loss: 2.72632e-02
I0212 21:38:25.835751 22542570456896 run_lib.py:133] step: 1070700, training_loss: 2.46066e-02
I0212 21:38:26.005349 22542570456896 run_lib.py:146] step: 1070700, eval_loss: 2.58193e-02
I0212 21:38:43.665811 22542570456896 run_lib.py:133] step: 1070750, training_loss: 2.58568e-02
I0212 21:39:01.157039 22542570456896 run_lib.py:133] step: 1070800, training_loss: 2.82194e-02
I0212 21:39:01.318738 22542570456896 run_lib.py:146] step: 1070800, eval_loss: 2.98478e-02
I0212 21:39:18.790456 22542570456896 run_lib.py:133] step: 1070850, training_loss: 2.56668e-02
I0212 21:39:36.415554 22542570456896 run_lib.py:133] step: 1070900, training_loss: 2.54371e-02
I0212 21:39:36.582809 22542570456896 run_lib.py:146] step: 1070900, eval_loss: 2.65786e-02
I0212 21:39:54.077776 22542570456896 run_lib.py:133] step: 1070950, training_loss: 2.67422e-02
I0212 21:40:11.569336 22542570456896 run_lib.py:133] step: 1071000, training_loss: 2.32795e-02
I0212 21:40:11.727210 22542570456896 run_lib.py:146] step: 1071000, eval_loss: 4.07197e-02
I0212 21:40:29.427024 22542570456896 run_lib.py:133] step: 1071050, training_loss: 2.49339e-02
I0212 21:40:47.062303 22542570456896 run_lib.py:133] step: 1071100, training_loss: 3.27619e-02
I0212 21:40:47.214473 22542570456896 run_lib.py:146] step: 1071100, eval_loss: 3.37689e-02
I0212 21:41:04.692651 22542570456896 run_lib.py:133] step: 1071150, training_loss: 3.05245e-02
I0212 21:41:22.213285 22542570456896 run_lib.py:133] step: 1071200, training_loss: 2.58734e-02
I0212 21:41:22.392436 22542570456896 run_lib.py:146] step: 1071200, eval_loss: 2.98217e-02
I0212 21:41:39.899546 22542570456896 run_lib.py:133] step: 1071250, training_loss: 2.67542e-02
I0212 21:41:57.579752 22542570456896 run_lib.py:133] step: 1071300, training_loss: 2.43299e-02
I0212 21:41:57.737698 22542570456896 run_lib.py:146] step: 1071300, eval_loss: 3.64520e-02
I0212 21:42:15.250354 22542570456896 run_lib.py:133] step: 1071350, training_loss: 2.80001e-02
I0212 21:42:32.716235 22542570456896 run_lib.py:133] step: 1071400, training_loss: 2.46973e-02
I0212 21:42:32.873344 22542570456896 run_lib.py:146] step: 1071400, eval_loss: 3.22080e-02
I0212 21:42:50.362616 22542570456896 run_lib.py:133] step: 1071450, training_loss: 3.08521e-02
I0212 21:43:08.023077 22542570456896 run_lib.py:133] step: 1071500, training_loss: 2.72699e-02
I0212 21:43:08.178327 22542570456896 run_lib.py:146] step: 1071500, eval_loss: 3.59519e-02
I0212 21:43:25.666910 22542570456896 run_lib.py:133] step: 1071550, training_loss: 2.11474e-02
I0212 21:43:43.272516 22542570456896 run_lib.py:133] step: 1071600, training_loss: 2.92621e-02
I0212 21:43:43.429548 22542570456896 run_lib.py:146] step: 1071600, eval_loss: 2.51617e-02
I0212 21:44:00.901456 22542570456896 run_lib.py:133] step: 1071650, training_loss: 3.79900e-02
I0212 21:44:18.372056 22542570456896 run_lib.py:133] step: 1071700, training_loss: 2.32776e-02
I0212 21:44:18.531821 22542570456896 run_lib.py:146] step: 1071700, eval_loss: 2.83604e-02
I0212 21:44:36.169099 22542570456896 run_lib.py:133] step: 1071750, training_loss: 2.98406e-02
I0212 21:44:53.788222 22542570456896 run_lib.py:133] step: 1071800, training_loss: 2.71994e-02
I0212 21:44:53.948384 22542570456896 run_lib.py:146] step: 1071800, eval_loss: 2.82193e-02
I0212 21:45:11.451609 22542570456896 run_lib.py:133] step: 1071850, training_loss: 3.37178e-02
I0212 21:45:28.901459 22542570456896 run_lib.py:133] step: 1071900, training_loss: 2.78474e-02
I0212 21:45:29.061219 22542570456896 run_lib.py:146] step: 1071900, eval_loss: 2.66881e-02
I0212 21:45:46.697628 22542570456896 run_lib.py:133] step: 1071950, training_loss: 2.00777e-02
I0212 21:46:04.163894 22542570456896 run_lib.py:133] step: 1072000, training_loss: 2.78309e-02
I0212 21:46:04.318701 22542570456896 run_lib.py:146] step: 1072000, eval_loss: 2.85837e-02
I0212 21:46:22.019940 22542570456896 run_lib.py:133] step: 1072050, training_loss: 2.91742e-02
I0212 21:46:39.510369 22542570456896 run_lib.py:133] step: 1072100, training_loss: 2.88502e-02
I0212 21:46:39.668456 22542570456896 run_lib.py:146] step: 1072100, eval_loss: 3.48827e-02
I0212 21:46:57.299769 22542570456896 run_lib.py:133] step: 1072150, training_loss: 3.18895e-02
I0212 21:47:14.772221 22542570456896 run_lib.py:133] step: 1072200, training_loss: 3.05733e-02
I0212 21:47:14.937731 22542570456896 run_lib.py:146] step: 1072200, eval_loss: 2.97568e-02
I0212 21:47:32.422271 22542570456896 run_lib.py:133] step: 1072250, training_loss: 2.31961e-02
I0212 21:47:50.052688 22542570456896 run_lib.py:133] step: 1072300, training_loss: 2.27790e-02
I0212 21:47:50.225711 22542570456896 run_lib.py:146] step: 1072300, eval_loss: 2.62950e-02
I0212 21:48:07.722212 22542570456896 run_lib.py:133] step: 1072350, training_loss: 2.84493e-02
I0212 21:48:25.333191 22542570456896 run_lib.py:133] step: 1072400, training_loss: 3.08069e-02
I0212 21:48:25.488071 22542570456896 run_lib.py:146] step: 1072400, eval_loss: 2.71956e-02
I0212 21:48:42.911856 22542570456896 run_lib.py:133] step: 1072450, training_loss: 2.20932e-02
I0212 21:49:00.334167 22542570456896 run_lib.py:133] step: 1072500, training_loss: 3.28757e-02
I0212 21:49:00.485676 22542570456896 run_lib.py:146] step: 1072500, eval_loss: 2.55098e-02
I0212 21:49:17.988737 22542570456896 run_lib.py:133] step: 1072550, training_loss: 3.17666e-02
I0212 21:49:35.352878 22542570456896 run_lib.py:133] step: 1072600, training_loss: 2.96861e-02
I0212 21:49:35.519255 22542570456896 run_lib.py:146] step: 1072600, eval_loss: 2.49111e-02
I0212 21:49:52.970637 22542570456896 run_lib.py:133] step: 1072650, training_loss: 2.26962e-02
I0212 21:50:10.563655 22542570456896 run_lib.py:133] step: 1072700, training_loss: 3.08067e-02
I0212 21:50:10.721434 22542570456896 run_lib.py:146] step: 1072700, eval_loss: 3.23217e-02
I0212 21:50:28.130440 22542570456896 run_lib.py:133] step: 1072750, training_loss: 2.48428e-02
I0212 21:50:45.576832 22542570456896 run_lib.py:133] step: 1072800, training_loss: 2.03891e-02
I0212 21:50:45.733837 22542570456896 run_lib.py:146] step: 1072800, eval_loss: 3.70505e-02
I0212 21:51:03.292804 22542570456896 run_lib.py:133] step: 1072850, training_loss: 2.45169e-02
I0212 21:51:20.852985 22542570456896 run_lib.py:133] step: 1072900, training_loss: 3.17951e-02
I0212 21:51:21.009746 22542570456896 run_lib.py:146] step: 1072900, eval_loss: 2.66290e-02
I0212 21:51:38.523126 22542570456896 run_lib.py:133] step: 1072950, training_loss: 2.92639e-02
I0212 21:51:55.988248 22542570456896 run_lib.py:133] step: 1073000, training_loss: 2.97308e-02
I0212 21:51:56.142557 22542570456896 run_lib.py:146] step: 1073000, eval_loss: 3.61162e-02
I0212 21:52:13.784276 22542570456896 run_lib.py:133] step: 1073050, training_loss: 2.05655e-02
I0212 21:52:31.341977 22542570456896 run_lib.py:133] step: 1073100, training_loss: 2.86235e-02
I0212 21:52:31.501255 22542570456896 run_lib.py:146] step: 1073100, eval_loss: 3.26583e-02
I0212 21:52:48.947436 22542570456896 run_lib.py:133] step: 1073150, training_loss: 1.96976e-02
I0212 21:53:06.494945 22542570456896 run_lib.py:133] step: 1073200, training_loss: 3.01027e-02
I0212 21:53:06.663383 22542570456896 run_lib.py:146] step: 1073200, eval_loss: 2.61230e-02
I0212 21:53:24.353747 22542570456896 run_lib.py:133] step: 1073250, training_loss: 2.44423e-02
I0212 21:53:41.795197 22542570456896 run_lib.py:133] step: 1073300, training_loss: 2.68383e-02
I0212 21:53:41.950317 22542570456896 run_lib.py:146] step: 1073300, eval_loss: 2.36605e-02
I0212 21:53:59.566712 22542570456896 run_lib.py:133] step: 1073350, training_loss: 2.24013e-02
I0212 21:54:17.062082 22542570456896 run_lib.py:133] step: 1073400, training_loss: 3.33344e-02
I0212 21:54:17.215289 22542570456896 run_lib.py:146] step: 1073400, eval_loss: 3.10309e-02
I0212 21:54:34.885831 22542570456896 run_lib.py:133] step: 1073450, training_loss: 3.59054e-02
I0212 21:54:52.359234 22542570456896 run_lib.py:133] step: 1073500, training_loss: 2.54098e-02
I0212 21:54:52.518577 22542570456896 run_lib.py:146] step: 1073500, eval_loss: 2.42489e-02
I0212 21:55:10.219387 22542570456896 run_lib.py:133] step: 1073550, training_loss: 3.21301e-02
I0212 21:55:27.740887 22542570456896 run_lib.py:133] step: 1073600, training_loss: 2.79294e-02
I0212 21:55:27.900043 22542570456896 run_lib.py:146] step: 1073600, eval_loss: 3.37701e-02
I0212 21:55:45.325496 22542570456896 run_lib.py:133] step: 1073650, training_loss: 1.70167e-02
I0212 21:56:02.906045 22542570456896 run_lib.py:133] step: 1073700, training_loss: 2.79881e-02
I0212 21:56:03.065461 22542570456896 run_lib.py:146] step: 1073700, eval_loss: 3.70729e-02
I0212 21:56:20.555165 22542570456896 run_lib.py:133] step: 1073750, training_loss: 2.99179e-02
I0212 21:56:38.079546 22542570456896 run_lib.py:133] step: 1073800, training_loss: 2.95099e-02
I0212 21:56:38.237221 22542570456896 run_lib.py:146] step: 1073800, eval_loss: 2.90797e-02
I0212 21:56:55.902804 22542570456896 run_lib.py:133] step: 1073850, training_loss: 2.33926e-02
I0212 21:57:13.343193 22542570456896 run_lib.py:133] step: 1073900, training_loss: 2.48337e-02
I0212 21:57:13.501452 22542570456896 run_lib.py:146] step: 1073900, eval_loss: 2.73618e-02
I0212 21:57:31.098238 22542570456896 run_lib.py:133] step: 1073950, training_loss: 2.93180e-02
I0212 21:57:48.568737 22542570456896 run_lib.py:133] step: 1074000, training_loss: 2.71229e-02
I0212 21:57:48.725816 22542570456896 run_lib.py:146] step: 1074000, eval_loss: 3.28618e-02
I0212 21:58:06.239358 22542570456896 run_lib.py:133] step: 1074050, training_loss: 2.57292e-02
I0212 21:58:23.948412 22542570456896 run_lib.py:133] step: 1074100, training_loss: 3.32385e-02
I0212 21:58:24.109450 22542570456896 run_lib.py:146] step: 1074100, eval_loss: 3.34123e-02
I0212 21:58:41.608747 22542570456896 run_lib.py:133] step: 1074150, training_loss: 2.14204e-02
I0212 21:58:59.067734 22542570456896 run_lib.py:133] step: 1074200, training_loss: 2.67887e-02
I0212 21:58:59.229406 22542570456896 run_lib.py:146] step: 1074200, eval_loss: 3.45890e-02
I0212 21:59:16.719112 22542570456896 run_lib.py:133] step: 1074250, training_loss: 2.10423e-02
I0212 21:59:34.368511 22542570456896 run_lib.py:133] step: 1074300, training_loss: 2.63800e-02
I0212 21:59:34.526745 22542570456896 run_lib.py:146] step: 1074300, eval_loss: 3.40112e-02
I0212 21:59:52.079231 22542570456896 run_lib.py:133] step: 1074350, training_loss: 2.69126e-02
I0212 22:00:09.652130 22542570456896 run_lib.py:133] step: 1074400, training_loss: 2.74238e-02
I0212 22:00:09.805495 22542570456896 run_lib.py:146] step: 1074400, eval_loss: 2.61439e-02
I0212 22:00:27.260606 22542570456896 run_lib.py:133] step: 1074450, training_loss: 2.47460e-02
I0212 22:00:44.711647 22542570456896 run_lib.py:133] step: 1074500, training_loss: 2.38584e-02
I0212 22:00:44.870661 22542570456896 run_lib.py:146] step: 1074500, eval_loss: 3.67693e-02
I0212 22:01:02.458854 22542570456896 run_lib.py:133] step: 1074550, training_loss: 2.71376e-02
I0212 22:01:20.000370 22542570456896 run_lib.py:133] step: 1074600, training_loss: 3.00977e-02
I0212 22:01:20.173319 22542570456896 run_lib.py:146] step: 1074600, eval_loss: 2.13811e-02
I0212 22:01:37.686446 22542570456896 run_lib.py:133] step: 1074650, training_loss: 2.45204e-02
I0212 22:01:55.157974 22542570456896 run_lib.py:133] step: 1074700, training_loss: 3.11072e-02
I0212 22:01:55.316035 22542570456896 run_lib.py:146] step: 1074700, eval_loss: 2.70993e-02
I0212 22:02:13.007150 22542570456896 run_lib.py:133] step: 1074750, training_loss: 3.00096e-02
I0212 22:02:30.482225 22542570456896 run_lib.py:133] step: 1074800, training_loss: 2.98661e-02
I0212 22:02:30.637159 22542570456896 run_lib.py:146] step: 1074800, eval_loss: 2.33002e-02
I0212 22:02:48.260940 22542570456896 run_lib.py:133] step: 1074850, training_loss: 2.89835e-02
I0212 22:03:05.733493 22542570456896 run_lib.py:133] step: 1074900, training_loss: 2.78188e-02
I0212 22:03:05.891676 22542570456896 run_lib.py:146] step: 1074900, eval_loss: 2.90247e-02
I0212 22:03:23.594063 22542570456896 run_lib.py:133] step: 1074950, training_loss: 2.66918e-02
I0212 22:03:41.080579 22542570456896 run_lib.py:133] step: 1075000, training_loss: 2.68864e-02
I0212 22:03:41.240526 22542570456896 run_lib.py:146] step: 1075000, eval_loss: 3.21981e-02
I0212 22:03:58.719085 22542570456896 run_lib.py:133] step: 1075050, training_loss: 3.20072e-02
I0212 22:04:16.316680 22542570456896 run_lib.py:133] step: 1075100, training_loss: 2.55335e-02
I0212 22:04:16.473483 22542570456896 run_lib.py:146] step: 1075100, eval_loss: 2.79712e-02
I0212 22:04:33.988617 22542570456896 run_lib.py:133] step: 1075150, training_loss: 2.57718e-02
I0212 22:04:51.700786 22542570456896 run_lib.py:133] step: 1075200, training_loss: 2.46831e-02
I0212 22:04:51.858289 22542570456896 run_lib.py:146] step: 1075200, eval_loss: 2.57677e-02
I0212 22:05:09.357389 22542570456896 run_lib.py:133] step: 1075250, training_loss: 1.99855e-02
I0212 22:05:26.802017 22542570456896 run_lib.py:133] step: 1075300, training_loss: 2.72006e-02
I0212 22:05:26.963897 22542570456896 run_lib.py:146] step: 1075300, eval_loss: 2.70777e-02
I0212 22:05:44.632591 22542570456896 run_lib.py:133] step: 1075350, training_loss: 2.96781e-02
I0212 22:06:02.125149 22542570456896 run_lib.py:133] step: 1075400, training_loss: 2.67643e-02
I0212 22:06:02.293793 22542570456896 run_lib.py:146] step: 1075400, eval_loss: 2.51178e-02
I0212 22:06:19.802329 22542570456896 run_lib.py:133] step: 1075450, training_loss: 2.93458e-02
I0212 22:06:37.501110 22542570456896 run_lib.py:133] step: 1075500, training_loss: 2.47934e-02
I0212 22:06:37.659619 22542570456896 run_lib.py:146] step: 1075500, eval_loss: 2.38001e-02
I0212 22:06:55.128544 22542570456896 run_lib.py:133] step: 1075550, training_loss: 3.48054e-02
I0212 22:07:12.601224 22542570456896 run_lib.py:133] step: 1075600, training_loss: 2.55486e-02
I0212 22:07:12.919883 22542570456896 run_lib.py:146] step: 1075600, eval_loss: 2.73138e-02
I0212 22:07:30.373287 22542570456896 run_lib.py:133] step: 1075650, training_loss: 2.34914e-02
I0212 22:07:47.907172 22542570456896 run_lib.py:133] step: 1075700, training_loss: 2.99913e-02
I0212 22:07:48.065657 22542570456896 run_lib.py:146] step: 1075700, eval_loss: 2.67944e-02
I0212 22:08:05.561206 22542570456896 run_lib.py:133] step: 1075750, training_loss: 2.44244e-02
I0212 22:08:23.028640 22542570456896 run_lib.py:133] step: 1075800, training_loss: 2.37813e-02
I0212 22:08:23.182340 22542570456896 run_lib.py:146] step: 1075800, eval_loss: 2.67664e-02
I0212 22:08:40.844457 22542570456896 run_lib.py:133] step: 1075850, training_loss: 2.61924e-02
I0212 22:08:58.380738 22542570456896 run_lib.py:133] step: 1075900, training_loss: 3.14160e-02
I0212 22:08:58.537608 22542570456896 run_lib.py:146] step: 1075900, eval_loss: 2.92247e-02
I0212 22:09:16.001864 22542570456896 run_lib.py:133] step: 1075950, training_loss: 2.57768e-02
I0212 22:09:33.534931 22542570456896 run_lib.py:133] step: 1076000, training_loss: 2.60274e-02
I0212 22:09:33.698547 22542570456896 run_lib.py:146] step: 1076000, eval_loss: 2.14031e-02
I0212 22:09:51.357477 22542570456896 run_lib.py:133] step: 1076050, training_loss: 2.43193e-02
I0212 22:10:08.904672 22542570456896 run_lib.py:133] step: 1076100, training_loss: 2.83965e-02
I0212 22:10:09.057662 22542570456896 run_lib.py:146] step: 1076100, eval_loss: 2.94923e-02
I0212 22:10:26.544640 22542570456896 run_lib.py:133] step: 1076150, training_loss: 2.23991e-02
I0212 22:10:44.002935 22542570456896 run_lib.py:133] step: 1076200, training_loss: 2.49349e-02
I0212 22:10:44.160576 22542570456896 run_lib.py:146] step: 1076200, eval_loss: 2.95535e-02
I0212 22:11:01.790857 22542570456896 run_lib.py:133] step: 1076250, training_loss: 2.60989e-02
I0212 22:11:19.291900 22542570456896 run_lib.py:133] step: 1076300, training_loss: 2.97969e-02
I0212 22:11:19.447971 22542570456896 run_lib.py:146] step: 1076300, eval_loss: 3.21564e-02
I0212 22:11:37.164404 22542570456896 run_lib.py:133] step: 1076350, training_loss: 2.17667e-02
I0212 22:11:54.640045 22542570456896 run_lib.py:133] step: 1076400, training_loss: 3.29701e-02
I0212 22:11:54.799793 22542570456896 run_lib.py:146] step: 1076400, eval_loss: 2.53612e-02
I0212 22:12:12.403342 22542570456896 run_lib.py:133] step: 1076450, training_loss: 1.94704e-02
I0212 22:12:29.893759 22542570456896 run_lib.py:133] step: 1076500, training_loss: 2.22211e-02
I0212 22:12:30.066395 22542570456896 run_lib.py:146] step: 1076500, eval_loss: 2.78812e-02
I0212 22:12:47.613086 22542570456896 run_lib.py:133] step: 1076550, training_loss: 2.55120e-02
I0212 22:13:05.277853 22542570456896 run_lib.py:133] step: 1076600, training_loss: 2.75275e-02
I0212 22:13:05.434187 22542570456896 run_lib.py:146] step: 1076600, eval_loss: 2.89115e-02
I0212 22:13:22.919448 22542570456896 run_lib.py:133] step: 1076650, training_loss: 2.59297e-02
I0212 22:13:40.508177 22542570456896 run_lib.py:133] step: 1076700, training_loss: 3.06332e-02
I0212 22:13:40.663165 22542570456896 run_lib.py:146] step: 1076700, eval_loss: 3.23583e-02
I0212 22:13:58.125984 22542570456896 run_lib.py:133] step: 1076750, training_loss: 2.94678e-02
I0212 22:14:15.584660 22542570456896 run_lib.py:133] step: 1076800, training_loss: 2.35301e-02
I0212 22:14:15.741587 22542570456896 run_lib.py:146] step: 1076800, eval_loss: 2.58804e-02
I0212 22:14:33.469309 22542570456896 run_lib.py:133] step: 1076850, training_loss: 2.67563e-02
I0212 22:14:50.962266 22542570456896 run_lib.py:133] step: 1076900, training_loss: 2.91025e-02
I0212 22:14:51.122396 22542570456896 run_lib.py:146] step: 1076900, eval_loss: 3.03731e-02
I0212 22:15:08.556632 22542570456896 run_lib.py:133] step: 1076950, training_loss: 2.91078e-02
I0212 22:15:26.019412 22542570456896 run_lib.py:133] step: 1077000, training_loss: 2.69084e-02
I0212 22:15:26.176521 22542570456896 run_lib.py:146] step: 1077000, eval_loss: 3.05747e-02
I0212 22:15:43.799876 22542570456896 run_lib.py:133] step: 1077050, training_loss: 2.09723e-02
I0212 22:16:01.334363 22542570456896 run_lib.py:133] step: 1077100, training_loss: 2.21809e-02
I0212 22:16:01.497269 22542570456896 run_lib.py:146] step: 1077100, eval_loss: 3.12702e-02
I0212 22:16:19.060602 22542570456896 run_lib.py:133] step: 1077150, training_loss: 2.91901e-02
I0212 22:16:36.489232 22542570456896 run_lib.py:133] step: 1077200, training_loss: 3.42281e-02
I0212 22:16:36.641203 22542570456896 run_lib.py:146] step: 1077200, eval_loss: 3.31806e-02
I0212 22:16:54.075092 22542570456896 run_lib.py:133] step: 1077250, training_loss: 2.87710e-02
I0212 22:17:11.555397 22542570456896 run_lib.py:133] step: 1077300, training_loss: 3.06687e-02
I0212 22:17:11.711469 22542570456896 run_lib.py:146] step: 1077300, eval_loss: 3.14842e-02
I0212 22:17:29.360565 22542570456896 run_lib.py:133] step: 1077350, training_loss: 2.53756e-02
I0212 22:17:46.964470 22542570456896 run_lib.py:133] step: 1077400, training_loss: 3.77500e-02
I0212 22:17:47.128629 22542570456896 run_lib.py:146] step: 1077400, eval_loss: 3.61980e-02
I0212 22:18:04.623505 22542570456896 run_lib.py:133] step: 1077450, training_loss: 2.86009e-02
I0212 22:18:22.092384 22542570456896 run_lib.py:133] step: 1077500, training_loss: 2.44401e-02
I0212 22:18:22.257491 22542570456896 run_lib.py:146] step: 1077500, eval_loss: 2.32362e-02
I0212 22:18:39.828754 22542570456896 run_lib.py:133] step: 1077550, training_loss: 2.61096e-02
I0212 22:18:57.190743 22542570456896 run_lib.py:133] step: 1077600, training_loss: 2.48613e-02
I0212 22:18:57.353626 22542570456896 run_lib.py:146] step: 1077600, eval_loss: 2.72303e-02
I0212 22:19:14.930075 22542570456896 run_lib.py:133] step: 1077650, training_loss: 2.46808e-02
I0212 22:19:32.338016 22542570456896 run_lib.py:133] step: 1077700, training_loss: 2.30873e-02
I0212 22:19:32.490460 22542570456896 run_lib.py:146] step: 1077700, eval_loss: 2.46188e-02
I0212 22:19:50.051014 22542570456896 run_lib.py:133] step: 1077750, training_loss: 2.79748e-02
I0212 22:20:07.390141 22542570456896 run_lib.py:133] step: 1077800, training_loss: 2.65851e-02
I0212 22:20:07.556208 22542570456896 run_lib.py:146] step: 1077800, eval_loss: 2.98868e-02
I0212 22:20:25.051192 22542570456896 run_lib.py:133] step: 1077850, training_loss: 3.17506e-02
I0212 22:20:42.502947 22542570456896 run_lib.py:133] step: 1077900, training_loss: 2.40917e-02
I0212 22:20:42.679313 22542570456896 run_lib.py:146] step: 1077900, eval_loss: 2.89054e-02
I0212 22:21:00.074275 22542570456896 run_lib.py:133] step: 1077950, training_loss: 2.44866e-02
I0212 22:21:17.694072 22542570456896 run_lib.py:133] step: 1078000, training_loss: 2.98590e-02
I0212 22:21:17.851730 22542570456896 run_lib.py:146] step: 1078000, eval_loss: 3.06023e-02
I0212 22:21:35.346162 22542570456896 run_lib.py:133] step: 1078050, training_loss: 2.68800e-02
I0212 22:21:52.824795 22542570456896 run_lib.py:133] step: 1078100, training_loss: 3.22460e-02
I0212 22:21:52.983237 22542570456896 run_lib.py:146] step: 1078100, eval_loss: 3.27976e-02
I0212 22:22:10.616470 22542570456896 run_lib.py:133] step: 1078150, training_loss: 2.31038e-02
I0212 22:22:28.238615 22542570456896 run_lib.py:133] step: 1078200, training_loss: 2.42331e-02
I0212 22:22:28.394658 22542570456896 run_lib.py:146] step: 1078200, eval_loss: 3.00669e-02
I0212 22:22:45.929878 22542570456896 run_lib.py:133] step: 1078250, training_loss: 2.67954e-02
I0212 22:23:03.449018 22542570456896 run_lib.py:133] step: 1078300, training_loss: 3.02119e-02
I0212 22:23:03.614015 22542570456896 run_lib.py:146] step: 1078300, eval_loss: 2.62483e-02
I0212 22:23:21.043337 22542570456896 run_lib.py:133] step: 1078350, training_loss: 2.87619e-02
I0212 22:23:38.668643 22542570456896 run_lib.py:133] step: 1078400, training_loss: 3.00329e-02
I0212 22:23:38.826695 22542570456896 run_lib.py:146] step: 1078400, eval_loss: 2.53341e-02
I0212 22:23:56.321270 22542570456896 run_lib.py:133] step: 1078450, training_loss: 2.85591e-02
I0212 22:24:13.880789 22542570456896 run_lib.py:133] step: 1078500, training_loss: 2.46666e-02
I0212 22:24:14.040242 22542570456896 run_lib.py:146] step: 1078500, eval_loss: 2.62009e-02
I0212 22:24:31.491158 22542570456896 run_lib.py:133] step: 1078550, training_loss: 2.39426e-02
I0212 22:24:49.144389 22542570456896 run_lib.py:133] step: 1078600, training_loss: 2.60133e-02
I0212 22:24:49.298284 22542570456896 run_lib.py:146] step: 1078600, eval_loss: 3.06453e-02
I0212 22:25:06.769728 22542570456896 run_lib.py:133] step: 1078650, training_loss: 2.74126e-02
I0212 22:25:24.345815 22542570456896 run_lib.py:133] step: 1078700, training_loss: 2.69390e-02
I0212 22:25:24.501466 22542570456896 run_lib.py:146] step: 1078700, eval_loss: 2.91227e-02
I0212 22:25:41.987576 22542570456896 run_lib.py:133] step: 1078750, training_loss: 2.70744e-02
I0212 22:25:59.510957 22542570456896 run_lib.py:133] step: 1078800, training_loss: 2.43953e-02
I0212 22:25:59.672436 22542570456896 run_lib.py:146] step: 1078800, eval_loss: 2.81742e-02
I0212 22:26:17.320404 22542570456896 run_lib.py:133] step: 1078850, training_loss: 2.44483e-02
I0212 22:26:34.861999 22542570456896 run_lib.py:133] step: 1078900, training_loss: 2.75605e-02
I0212 22:26:35.019573 22542570456896 run_lib.py:146] step: 1078900, eval_loss: 3.03521e-02
I0212 22:26:52.519759 22542570456896 run_lib.py:133] step: 1078950, training_loss: 2.63400e-02
I0212 22:27:09.956185 22542570456896 run_lib.py:133] step: 1079000, training_loss: 2.22080e-02
I0212 22:27:10.123619 22542570456896 run_lib.py:146] step: 1079000, eval_loss: 2.22559e-02
I0212 22:27:27.829135 22542570456896 run_lib.py:133] step: 1079050, training_loss: 2.22302e-02
I0212 22:27:45.334706 22542570456896 run_lib.py:133] step: 1079100, training_loss: 2.67680e-02
I0212 22:27:45.490059 22542570456896 run_lib.py:146] step: 1079100, eval_loss: 3.36598e-02
I0212 22:28:03.161616 22542570456896 run_lib.py:133] step: 1079150, training_loss: 2.59599e-02
I0212 22:28:20.635584 22542570456896 run_lib.py:133] step: 1079200, training_loss: 2.93121e-02
I0212 22:28:20.791435 22542570456896 run_lib.py:146] step: 1079200, eval_loss: 3.01907e-02
I0212 22:28:38.386080 22542570456896 run_lib.py:133] step: 1079250, training_loss: 2.65873e-02
I0212 22:28:55.870658 22542570456896 run_lib.py:133] step: 1079300, training_loss: 2.87946e-02
I0212 22:28:56.042660 22542570456896 run_lib.py:146] step: 1079300, eval_loss: 2.91433e-02
I0212 22:29:13.589883 22542570456896 run_lib.py:133] step: 1079350, training_loss: 3.42001e-02
I0212 22:29:31.278776 22542570456896 run_lib.py:133] step: 1079400, training_loss: 3.11863e-02
I0212 22:29:31.435762 22542570456896 run_lib.py:146] step: 1079400, eval_loss: 2.60263e-02
I0212 22:29:48.920941 22542570456896 run_lib.py:133] step: 1079450, training_loss: 3.66219e-02
I0212 22:30:06.536793 22542570456896 run_lib.py:133] step: 1079500, training_loss: 3.09635e-02
I0212 22:30:06.694498 22542570456896 run_lib.py:146] step: 1079500, eval_loss: 3.09105e-02
I0212 22:30:24.135674 22542570456896 run_lib.py:133] step: 1079550, training_loss: 2.89079e-02
I0212 22:30:41.588031 22542570456896 run_lib.py:133] step: 1079600, training_loss: 2.28759e-02
I0212 22:30:41.744685 22542570456896 run_lib.py:146] step: 1079600, eval_loss: 2.73867e-02
I0212 22:30:59.494764 22542570456896 run_lib.py:133] step: 1079650, training_loss: 3.19912e-02
I0212 22:31:16.954053 22542570456896 run_lib.py:133] step: 1079700, training_loss: 2.86195e-02
I0212 22:31:17.113451 22542570456896 run_lib.py:146] step: 1079700, eval_loss: 3.57804e-02
I0212 22:31:34.551898 22542570456896 run_lib.py:133] step: 1079750, training_loss: 2.32298e-02
I0212 22:31:52.179398 22542570456896 run_lib.py:133] step: 1079800, training_loss: 3.23496e-02
I0212 22:31:52.340714 22542570456896 run_lib.py:146] step: 1079800, eval_loss: 2.96593e-02
I0212 22:32:09.834295 22542570456896 run_lib.py:133] step: 1079850, training_loss: 2.11909e-02
I0212 22:32:27.377191 22542570456896 run_lib.py:133] step: 1079900, training_loss: 3.27184e-02
I0212 22:32:27.536760 22542570456896 run_lib.py:146] step: 1079900, eval_loss: 3.43567e-02
I0212 22:32:45.138353 22542570456896 run_lib.py:133] step: 1079950, training_loss: 2.96010e-02
I0212 22:33:02.594749 22542570456896 run_lib.py:133] step: 1080000, training_loss: 1.78832e-02
I0212 22:33:03.350327 22542570456896 run_lib.py:146] step: 1080000, eval_loss: 2.74007e-02
I0212 22:33:23.467008 22542570456896 run_lib.py:133] step: 1080050, training_loss: 2.65508e-02
I0212 22:33:40.916082 22542570456896 run_lib.py:133] step: 1080100, training_loss: 2.68293e-02
I0212 22:33:41.069283 22542570456896 run_lib.py:146] step: 1080100, eval_loss: 2.73908e-02
I0212 22:33:58.725854 22542570456896 run_lib.py:133] step: 1080150, training_loss: 2.46716e-02
I0212 22:34:16.209321 22542570456896 run_lib.py:133] step: 1080200, training_loss: 3.03351e-02
I0212 22:34:16.379970 22542570456896 run_lib.py:146] step: 1080200, eval_loss: 2.98522e-02
I0212 22:34:33.995723 22542570456896 run_lib.py:133] step: 1080250, training_loss: 2.61078e-02
I0212 22:34:51.473410 22542570456896 run_lib.py:133] step: 1080300, training_loss: 2.40946e-02
I0212 22:34:51.634678 22542570456896 run_lib.py:146] step: 1080300, eval_loss: 3.30836e-02
I0212 22:35:09.102166 22542570456896 run_lib.py:133] step: 1080350, training_loss: 2.55339e-02
I0212 22:35:26.577849 22542570456896 run_lib.py:133] step: 1080400, training_loss: 2.03579e-02
I0212 22:35:26.748478 22542570456896 run_lib.py:146] step: 1080400, eval_loss: 3.49433e-02
I0212 22:35:44.417431 22542570456896 run_lib.py:133] step: 1080450, training_loss: 2.50769e-02
I0212 22:36:02.017988 22542570456896 run_lib.py:133] step: 1080500, training_loss: 2.33377e-02
I0212 22:36:02.175800 22542570456896 run_lib.py:146] step: 1080500, eval_loss: 3.09666e-02
I0212 22:36:19.653717 22542570456896 run_lib.py:133] step: 1080550, training_loss: 2.74764e-02
I0212 22:36:37.119018 22542570456896 run_lib.py:133] step: 1080600, training_loss: 3.53414e-02
I0212 22:36:37.271171 22542570456896 run_lib.py:146] step: 1080600, eval_loss: 3.48530e-02
I0212 22:36:54.910567 22542570456896 run_lib.py:133] step: 1080650, training_loss: 2.85056e-02
I0212 22:37:12.367886 22542570456896 run_lib.py:133] step: 1080700, training_loss: 3.11371e-02
I0212 22:37:12.536659 22542570456896 run_lib.py:146] step: 1080700, eval_loss: 2.74238e-02
I0212 22:37:30.217703 22542570456896 run_lib.py:133] step: 1080750, training_loss: 2.69490e-02
I0212 22:37:47.727694 22542570456896 run_lib.py:133] step: 1080800, training_loss: 3.53711e-02
I0212 22:37:47.887561 22542570456896 run_lib.py:146] step: 1080800, eval_loss: 3.08056e-02
I0212 22:38:05.550838 22542570456896 run_lib.py:133] step: 1080850, training_loss: 2.74760e-02
I0212 22:38:23.053411 22542570456896 run_lib.py:133] step: 1080900, training_loss: 2.56800e-02
I0212 22:38:23.216389 22542570456896 run_lib.py:146] step: 1080900, eval_loss: 3.10280e-02
I0212 22:38:40.873172 22542570456896 run_lib.py:133] step: 1080950, training_loss: 2.62056e-02
I0212 22:38:58.422666 22542570456896 run_lib.py:133] step: 1081000, training_loss: 2.33987e-02
I0212 22:38:58.588652 22542570456896 run_lib.py:146] step: 1081000, eval_loss: 2.36297e-02
I0212 22:39:16.114253 22542570456896 run_lib.py:133] step: 1081050, training_loss: 4.06621e-02
I0212 22:39:33.776244 22542570456896 run_lib.py:133] step: 1081100, training_loss: 3.03589e-02
I0212 22:39:33.928387 22542570456896 run_lib.py:146] step: 1081100, eval_loss: 2.53624e-02
I0212 22:39:51.367616 22542570456896 run_lib.py:133] step: 1081150, training_loss: 2.51057e-02
I0212 22:40:08.860290 22542570456896 run_lib.py:133] step: 1081200, training_loss: 2.77141e-02
I0212 22:40:09.021656 22542570456896 run_lib.py:146] step: 1081200, eval_loss: 3.06242e-02
I0212 22:40:26.682820 22542570456896 run_lib.py:133] step: 1081250, training_loss: 2.10846e-02
I0212 22:40:44.211492 22542570456896 run_lib.py:133] step: 1081300, training_loss: 2.27138e-02
I0212 22:40:44.371397 22542570456896 run_lib.py:146] step: 1081300, eval_loss: 2.97754e-02
I0212 22:41:02.034370 22542570456896 run_lib.py:133] step: 1081350, training_loss: 2.82005e-02
I0212 22:41:19.546680 22542570456896 run_lib.py:133] step: 1081400, training_loss: 2.27510e-02
I0212 22:41:19.704187 22542570456896 run_lib.py:146] step: 1081400, eval_loss: 3.42776e-02
I0212 22:41:37.189734 22542570456896 run_lib.py:133] step: 1081450, training_loss: 3.25804e-02
I0212 22:41:54.814781 22542570456896 run_lib.py:133] step: 1081500, training_loss: 2.68110e-02
I0212 22:41:54.971560 22542570456896 run_lib.py:146] step: 1081500, eval_loss: 3.05492e-02
I0212 22:42:12.518974 22542570456896 run_lib.py:133] step: 1081550, training_loss: 2.32600e-02
I0212 22:42:30.024207 22542570456896 run_lib.py:133] step: 1081600, training_loss: 2.77783e-02
I0212 22:42:30.175801 22542570456896 run_lib.py:146] step: 1081600, eval_loss: 3.27767e-02
I0212 22:42:47.633866 22542570456896 run_lib.py:133] step: 1081650, training_loss: 2.23402e-02
I0212 22:43:05.328490 22542570456896 run_lib.py:133] step: 1081700, training_loss: 3.32875e-02
I0212 22:43:05.493841 22542570456896 run_lib.py:146] step: 1081700, eval_loss: 2.91963e-02
I0212 22:43:22.979223 22542570456896 run_lib.py:133] step: 1081750, training_loss: 2.35700e-02
I0212 22:43:40.514542 22542570456896 run_lib.py:133] step: 1081800, training_loss: 2.43702e-02
I0212 22:43:40.691412 22542570456896 run_lib.py:146] step: 1081800, eval_loss: 3.38900e-02
I0212 22:43:58.216992 22542570456896 run_lib.py:133] step: 1081850, training_loss: 2.56795e-02
I0212 22:44:15.708117 22542570456896 run_lib.py:133] step: 1081900, training_loss: 2.14106e-02
I0212 22:44:15.870694 22542570456896 run_lib.py:146] step: 1081900, eval_loss: 3.32243e-02
I0212 22:44:33.540238 22542570456896 run_lib.py:133] step: 1081950, training_loss: 2.62169e-02
I0212 22:44:51.079560 22542570456896 run_lib.py:133] step: 1082000, training_loss: 2.50381e-02
I0212 22:44:51.233223 22542570456896 run_lib.py:146] step: 1082000, eval_loss: 2.49883e-02
I0212 22:45:08.676364 22542570456896 run_lib.py:133] step: 1082050, training_loss: 1.94666e-02
I0212 22:45:26.143428 22542570456896 run_lib.py:133] step: 1082100, training_loss: 3.15911e-02
I0212 22:45:26.304563 22542570456896 run_lib.py:146] step: 1082100, eval_loss: 3.17179e-02
I0212 22:45:44.015754 22542570456896 run_lib.py:133] step: 1082150, training_loss: 2.49000e-02
I0212 22:46:01.527317 22542570456896 run_lib.py:133] step: 1082200, training_loss: 3.34803e-02
I0212 22:46:01.696488 22542570456896 run_lib.py:146] step: 1082200, eval_loss: 2.76579e-02
I0212 22:46:19.350153 22542570456896 run_lib.py:133] step: 1082250, training_loss: 2.85373e-02
I0212 22:46:36.798748 22542570456896 run_lib.py:133] step: 1082300, training_loss: 2.60996e-02
I0212 22:46:36.956422 22542570456896 run_lib.py:146] step: 1082300, eval_loss: 3.15799e-02
I0212 22:46:54.594354 22542570456896 run_lib.py:133] step: 1082350, training_loss: 2.16524e-02
I0212 22:47:12.143843 22542570456896 run_lib.py:133] step: 1082400, training_loss: 2.56489e-02
I0212 22:47:12.301754 22542570456896 run_lib.py:146] step: 1082400, eval_loss: 3.08072e-02
I0212 22:47:29.814160 22542570456896 run_lib.py:133] step: 1082450, training_loss: 3.10847e-02
I0212 22:47:47.466001 22542570456896 run_lib.py:133] step: 1082500, training_loss: 2.45007e-02
I0212 22:47:47.618421 22542570456896 run_lib.py:146] step: 1082500, eval_loss: 2.76532e-02
I0212 22:48:05.092918 22542570456896 run_lib.py:133] step: 1082550, training_loss: 2.78212e-02
I0212 22:48:22.697699 22542570456896 run_lib.py:133] step: 1082600, training_loss: 2.85973e-02
I0212 22:48:22.854480 22542570456896 run_lib.py:146] step: 1082600, eval_loss: 3.12289e-02
I0212 22:48:40.319017 22542570456896 run_lib.py:133] step: 1082650, training_loss: 2.53455e-02
I0212 22:48:57.841173 22542570456896 run_lib.py:133] step: 1082700, training_loss: 2.78522e-02
I0212 22:48:58.002419 22542570456896 run_lib.py:146] step: 1082700, eval_loss: 2.71871e-02
I0212 22:49:15.602584 22542570456896 run_lib.py:133] step: 1082750, training_loss: 2.24852e-02
I0212 22:49:33.039097 22542570456896 run_lib.py:133] step: 1082800, training_loss: 2.66004e-02
I0212 22:49:33.194250 22542570456896 run_lib.py:146] step: 1082800, eval_loss: 3.13601e-02
I0212 22:49:50.567454 22542570456896 run_lib.py:133] step: 1082850, training_loss: 2.55133e-02
I0212 22:50:08.048771 22542570456896 run_lib.py:133] step: 1082900, training_loss: 2.70058e-02
I0212 22:50:08.209344 22542570456896 run_lib.py:146] step: 1082900, eval_loss: 3.20795e-02
I0212 22:50:25.616706 22542570456896 run_lib.py:133] step: 1082950, training_loss: 2.08023e-02
I0212 22:50:43.114330 22542570456896 run_lib.py:133] step: 1083000, training_loss: 2.62832e-02
I0212 22:50:43.459358 22542570456896 run_lib.py:146] step: 1083000, eval_loss: 3.68180e-02
I0212 22:51:00.837555 22542570456896 run_lib.py:133] step: 1083050, training_loss: 2.31963e-02
I0212 22:51:18.261206 22542570456896 run_lib.py:133] step: 1083100, training_loss: 2.66651e-02
I0212 22:51:18.416240 22542570456896 run_lib.py:146] step: 1083100, eval_loss: 2.53054e-02
I0212 22:51:35.785285 22542570456896 run_lib.py:133] step: 1083150, training_loss: 3.34430e-02
I0212 22:51:53.062588 22542570456896 run_lib.py:133] step: 1083200, training_loss: 2.60564e-02
I0212 22:51:53.230756 22542570456896 run_lib.py:146] step: 1083200, eval_loss: 2.93069e-02
I0212 22:52:10.639126 22542570456896 run_lib.py:133] step: 1083250, training_loss: 2.69233e-02
I0212 22:52:28.000407 22542570456896 run_lib.py:133] step: 1083300, training_loss: 2.53297e-02
I0212 22:52:28.154453 22542570456896 run_lib.py:146] step: 1083300, eval_loss: 2.71766e-02
I0212 22:52:45.403431 22542570456896 run_lib.py:133] step: 1083350, training_loss: 2.47211e-02
I0212 22:53:02.655039 22542570456896 run_lib.py:133] step: 1083400, training_loss: 3.28649e-02
I0212 22:53:02.811251 22542570456896 run_lib.py:146] step: 1083400, eval_loss: 3.27064e-02
I0212 22:53:20.185034 22542570456896 run_lib.py:133] step: 1083450, training_loss: 2.33239e-02
I0212 22:53:37.516189 22542570456896 run_lib.py:133] step: 1083500, training_loss: 2.49308e-02
I0212 22:53:37.664511 22542570456896 run_lib.py:146] step: 1083500, eval_loss: 3.17864e-02
I0212 22:53:54.979892 22542570456896 run_lib.py:133] step: 1083550, training_loss: 3.16803e-02
I0212 22:54:12.239428 22542570456896 run_lib.py:133] step: 1083600, training_loss: 3.08251e-02
I0212 22:54:12.396228 22542570456896 run_lib.py:146] step: 1083600, eval_loss: 3.18107e-02
I0212 22:54:29.813328 22542570456896 run_lib.py:133] step: 1083650, training_loss: 2.86411e-02
I0212 22:54:47.053142 22542570456896 run_lib.py:133] step: 1083700, training_loss: 3.10182e-02
I0212 22:54:47.207291 22542570456896 run_lib.py:146] step: 1083700, eval_loss: 3.17276e-02
I0212 22:55:04.609046 22542570456896 run_lib.py:133] step: 1083750, training_loss: 3.12386e-02
I0212 22:55:21.852972 22542570456896 run_lib.py:133] step: 1083800, training_loss: 2.50931e-02
I0212 22:55:22.020018 22542570456896 run_lib.py:146] step: 1083800, eval_loss: 3.63934e-02
I0212 22:55:39.452175 22542570456896 run_lib.py:133] step: 1083850, training_loss: 2.54860e-02
I0212 22:55:56.728776 22542570456896 run_lib.py:133] step: 1083900, training_loss: 2.81037e-02
I0212 22:55:56.879120 22542570456896 run_lib.py:146] step: 1083900, eval_loss: 3.24204e-02
I0212 22:56:14.142741 22542570456896 run_lib.py:133] step: 1083950, training_loss: 2.85515e-02
I0212 22:56:31.562330 22542570456896 run_lib.py:133] step: 1084000, training_loss: 2.91783e-02
I0212 22:56:31.717390 22542570456896 run_lib.py:146] step: 1084000, eval_loss: 2.82026e-02
I0212 22:56:48.920140 22542570456896 run_lib.py:133] step: 1084050, training_loss: 2.66803e-02
I0212 22:57:06.361473 22542570456896 run_lib.py:133] step: 1084100, training_loss: 3.55821e-02
I0212 22:57:06.536253 22542570456896 run_lib.py:146] step: 1084100, eval_loss: 3.09886e-02
I0212 22:57:23.857795 22542570456896 run_lib.py:133] step: 1084150, training_loss: 3.09602e-02
I0212 22:57:41.101154 22542570456896 run_lib.py:133] step: 1084200, training_loss: 2.76335e-02
I0212 22:57:41.255449 22542570456896 run_lib.py:146] step: 1084200, eval_loss: 3.18963e-02
I0212 22:57:58.645678 22542570456896 run_lib.py:133] step: 1084250, training_loss: 2.50490e-02
I0212 22:58:15.867447 22542570456896 run_lib.py:133] step: 1084300, training_loss: 2.47139e-02
I0212 22:58:16.021326 22542570456896 run_lib.py:146] step: 1084300, eval_loss: 2.60281e-02
I0212 22:58:33.261004 22542570456896 run_lib.py:133] step: 1084350, training_loss: 2.67616e-02
I0212 22:58:50.574644 22542570456896 run_lib.py:133] step: 1084400, training_loss: 2.22502e-02
I0212 22:58:50.726495 22542570456896 run_lib.py:146] step: 1084400, eval_loss: 3.20043e-02
I0212 22:59:08.203556 22542570456896 run_lib.py:133] step: 1084450, training_loss: 2.23757e-02
I0212 22:59:25.491724 22542570456896 run_lib.py:133] step: 1084500, training_loss: 3.03331e-02
I0212 22:59:25.646333 22542570456896 run_lib.py:146] step: 1084500, eval_loss: 3.39091e-02
I0212 22:59:42.921026 22542570456896 run_lib.py:133] step: 1084550, training_loss: 2.26811e-02
I0212 23:00:00.144014 22542570456896 run_lib.py:133] step: 1084600, training_loss: 2.15085e-02
I0212 23:00:00.314319 22542570456896 run_lib.py:146] step: 1084600, eval_loss: 2.76685e-02
I0212 23:00:17.642385 22542570456896 run_lib.py:133] step: 1084650, training_loss: 2.66564e-02
I0212 23:00:34.971115 22542570456896 run_lib.py:133] step: 1084700, training_loss: 2.77098e-02
I0212 23:00:35.125467 22542570456896 run_lib.py:146] step: 1084700, eval_loss: 3.01487e-02
I0212 23:00:52.547721 22542570456896 run_lib.py:133] step: 1084750, training_loss: 2.99993e-02
I0212 23:01:09.875457 22542570456896 run_lib.py:133] step: 1084800, training_loss: 2.74915e-02
I0212 23:01:10.031215 22542570456896 run_lib.py:146] step: 1084800, eval_loss: 2.35277e-02
I0212 23:01:27.272150 22542570456896 run_lib.py:133] step: 1084850, training_loss: 2.28787e-02
I0212 23:01:44.553762 22542570456896 run_lib.py:133] step: 1084900, training_loss: 2.22900e-02
I0212 23:01:44.706466 22542570456896 run_lib.py:146] step: 1084900, eval_loss: 2.87481e-02
I0212 23:02:02.177882 22542570456896 run_lib.py:133] step: 1084950, training_loss: 3.07331e-02
I0212 23:02:19.456743 22542570456896 run_lib.py:133] step: 1085000, training_loss: 2.57084e-02
I0212 23:02:19.610137 22542570456896 run_lib.py:146] step: 1085000, eval_loss: 3.56102e-02
I0212 23:02:37.030580 22542570456896 run_lib.py:133] step: 1085050, training_loss: 2.67999e-02
I0212 23:02:54.298402 22542570456896 run_lib.py:133] step: 1085100, training_loss: 3.15285e-02
I0212 23:02:54.454435 22542570456896 run_lib.py:146] step: 1085100, eval_loss: 3.06625e-02
I0212 23:03:11.843940 22542570456896 run_lib.py:133] step: 1085150, training_loss: 3.37908e-02
I0212 23:03:29.110394 22542570456896 run_lib.py:133] step: 1085200, training_loss: 2.39387e-02
I0212 23:03:29.265189 22542570456896 run_lib.py:146] step: 1085200, eval_loss: 2.92312e-02
I0212 23:03:46.724549 22542570456896 run_lib.py:133] step: 1085250, training_loss: 2.31517e-02
I0212 23:04:03.967872 22542570456896 run_lib.py:133] step: 1085300, training_loss: 2.57351e-02
I0212 23:04:04.118292 22542570456896 run_lib.py:146] step: 1085300, eval_loss: 2.80698e-02
I0212 23:04:21.364609 22542570456896 run_lib.py:133] step: 1085350, training_loss: 2.87231e-02
I0212 23:04:38.736337 22542570456896 run_lib.py:133] step: 1085400, training_loss: 2.60673e-02
I0212 23:04:38.886287 22542570456896 run_lib.py:146] step: 1085400, eval_loss: 2.55080e-02
I0212 23:04:56.132221 22542570456896 run_lib.py:133] step: 1085450, training_loss: 2.38890e-02
I0212 23:05:13.457264 22542570456896 run_lib.py:133] step: 1085500, training_loss: 2.18090e-02
I0212 23:05:13.630247 22542570456896 run_lib.py:146] step: 1085500, eval_loss: 3.27118e-02
I0212 23:05:31.094075 22542570456896 run_lib.py:133] step: 1085550, training_loss: 2.68247e-02
I0212 23:05:48.467133 22542570456896 run_lib.py:133] step: 1085600, training_loss: 1.85141e-02
I0212 23:05:48.624198 22542570456896 run_lib.py:146] step: 1085600, eval_loss: 3.70426e-02
I0212 23:06:05.897156 22542570456896 run_lib.py:133] step: 1085650, training_loss: 2.05712e-02
I0212 23:06:23.182486 22542570456896 run_lib.py:133] step: 1085700, training_loss: 2.59316e-02
I0212 23:06:23.348067 22542570456896 run_lib.py:146] step: 1085700, eval_loss: 2.70038e-02
I0212 23:06:40.671308 22542570456896 run_lib.py:133] step: 1085750, training_loss: 2.80329e-02
I0212 23:06:58.116644 22542570456896 run_lib.py:133] step: 1085800, training_loss: 3.04040e-02
I0212 23:06:58.275105 22542570456896 run_lib.py:146] step: 1085800, eval_loss: 3.42790e-02
I0212 23:07:15.542737 22542570456896 run_lib.py:133] step: 1085850, training_loss: 3.30634e-02
I0212 23:07:32.895283 22542570456896 run_lib.py:133] step: 1085900, training_loss: 2.58654e-02
I0212 23:07:33.051252 22542570456896 run_lib.py:146] step: 1085900, eval_loss: 2.99554e-02
I0212 23:07:50.321082 22542570456896 run_lib.py:133] step: 1085950, training_loss: 2.88395e-02
I0212 23:08:07.733215 22542570456896 run_lib.py:133] step: 1086000, training_loss: 3.24615e-02
I0212 23:08:07.889477 22542570456896 run_lib.py:146] step: 1086000, eval_loss: 2.47106e-02
I0212 23:08:25.170508 22542570456896 run_lib.py:133] step: 1086050, training_loss: 2.97493e-02
I0212 23:08:42.515558 22542570456896 run_lib.py:133] step: 1086100, training_loss: 2.73068e-02
I0212 23:08:42.673561 22542570456896 run_lib.py:146] step: 1086100, eval_loss: 2.60303e-02
I0212 23:08:59.915102 22542570456896 run_lib.py:133] step: 1086150, training_loss: 2.53679e-02
I0212 23:09:17.169696 22542570456896 run_lib.py:133] step: 1086200, training_loss: 2.57917e-02
I0212 23:09:17.323342 22542570456896 run_lib.py:146] step: 1086200, eval_loss: 3.00072e-02
I0212 23:09:34.734670 22542570456896 run_lib.py:133] step: 1086250, training_loss: 2.37163e-02
I0212 23:09:52.094726 22542570456896 run_lib.py:133] step: 1086300, training_loss: 2.94689e-02
I0212 23:09:52.254216 22542570456896 run_lib.py:146] step: 1086300, eval_loss: 3.02616e-02
I0212 23:10:09.589761 22542570456896 run_lib.py:133] step: 1086350, training_loss: 2.97286e-02
I0212 23:10:26.818254 22542570456896 run_lib.py:133] step: 1086400, training_loss: 2.41023e-02
I0212 23:10:26.972298 22542570456896 run_lib.py:146] step: 1086400, eval_loss: 2.60651e-02
I0212 23:10:44.389183 22542570456896 run_lib.py:133] step: 1086450, training_loss: 2.79995e-02
I0212 23:11:01.662281 22542570456896 run_lib.py:133] step: 1086500, training_loss: 2.89584e-02
I0212 23:11:01.819540 22542570456896 run_lib.py:146] step: 1086500, eval_loss: 2.98910e-02
I0212 23:11:19.238951 22542570456896 run_lib.py:133] step: 1086550, training_loss: 2.99481e-02
I0212 23:11:36.465060 22542570456896 run_lib.py:133] step: 1086600, training_loss: 2.47479e-02
I0212 23:11:36.633241 22542570456896 run_lib.py:146] step: 1086600, eval_loss: 2.66894e-02
I0212 23:11:54.091261 22542570456896 run_lib.py:133] step: 1086650, training_loss: 2.71505e-02
I0212 23:12:11.394939 22542570456896 run_lib.py:133] step: 1086700, training_loss: 3.60910e-02
I0212 23:12:11.548454 22542570456896 run_lib.py:146] step: 1086700, eval_loss: 2.54941e-02
I0212 23:12:28.842389 22542570456896 run_lib.py:133] step: 1086750, training_loss: 2.47288e-02
I0212 23:12:46.230111 22542570456896 run_lib.py:133] step: 1086800, training_loss: 3.04145e-02
I0212 23:12:46.380261 22542570456896 run_lib.py:146] step: 1086800, eval_loss: 3.04516e-02
I0212 23:13:03.608479 22542570456896 run_lib.py:133] step: 1086850, training_loss: 2.68241e-02
I0212 23:13:21.014962 22542570456896 run_lib.py:133] step: 1086900, training_loss: 2.85312e-02
I0212 23:13:21.187164 22542570456896 run_lib.py:146] step: 1086900, eval_loss: 3.07934e-02
I0212 23:13:38.487967 22542570456896 run_lib.py:133] step: 1086950, training_loss: 2.18830e-02
I0212 23:13:55.766537 22542570456896 run_lib.py:133] step: 1087000, training_loss: 2.12168e-02
I0212 23:13:55.922205 22542570456896 run_lib.py:146] step: 1087000, eval_loss: 3.05126e-02
I0212 23:14:13.348154 22542570456896 run_lib.py:133] step: 1087050, training_loss: 3.01585e-02
I0212 23:14:30.620419 22542570456896 run_lib.py:133] step: 1087100, training_loss: 2.60189e-02
I0212 23:14:30.774428 22542570456896 run_lib.py:146] step: 1087100, eval_loss: 2.77359e-02
I0212 23:14:48.027648 22542570456896 run_lib.py:133] step: 1087150, training_loss: 2.85746e-02
I0212 23:15:05.505714 22542570456896 run_lib.py:133] step: 1087200, training_loss: 2.82515e-02
I0212 23:15:05.659475 22542570456896 run_lib.py:146] step: 1087200, eval_loss: 3.98397e-02
I0212 23:15:22.985637 22542570456896 run_lib.py:133] step: 1087250, training_loss: 2.78555e-02
I0212 23:15:40.249758 22542570456896 run_lib.py:133] step: 1087300, training_loss: 2.08146e-02
I0212 23:15:40.402333 22542570456896 run_lib.py:146] step: 1087300, eval_loss: 3.61993e-02
I0212 23:15:57.716371 22542570456896 run_lib.py:133] step: 1087350, training_loss: 2.56138e-02
I0212 23:16:15.064022 22542570456896 run_lib.py:133] step: 1087400, training_loss: 2.31817e-02
I0212 23:16:15.221504 22542570456896 run_lib.py:146] step: 1087400, eval_loss: 2.67138e-02
I0212 23:16:32.558591 22542570456896 run_lib.py:133] step: 1087450, training_loss: 2.92912e-02
I0212 23:16:49.934148 22542570456896 run_lib.py:133] step: 1087500, training_loss: 2.41453e-02
I0212 23:16:50.089502 22542570456896 run_lib.py:146] step: 1087500, eval_loss: 2.77019e-02
I0212 23:17:07.526524 22542570456896 run_lib.py:133] step: 1087550, training_loss: 2.28113e-02
I0212 23:17:24.844419 22542570456896 run_lib.py:133] step: 1087600, training_loss: 2.36234e-02
I0212 23:17:24.999054 22542570456896 run_lib.py:146] step: 1087600, eval_loss: 3.28322e-02
I0212 23:17:42.286660 22542570456896 run_lib.py:133] step: 1087650, training_loss: 2.61362e-02
I0212 23:17:59.538374 22542570456896 run_lib.py:133] step: 1087700, training_loss: 2.58425e-02
I0212 23:17:59.688550 22542570456896 run_lib.py:146] step: 1087700, eval_loss: 2.56099e-02
I0212 23:18:17.131479 22542570456896 run_lib.py:133] step: 1087750, training_loss: 2.30507e-02
I0212 23:18:34.417967 22542570456896 run_lib.py:133] step: 1087800, training_loss: 2.00508e-02
I0212 23:18:34.574545 22542570456896 run_lib.py:146] step: 1087800, eval_loss: 2.94784e-02
I0212 23:18:52.047491 22542570456896 run_lib.py:133] step: 1087850, training_loss: 2.86475e-02
I0212 23:19:09.376167 22542570456896 run_lib.py:133] step: 1087900, training_loss: 2.78109e-02
I0212 23:19:09.533509 22542570456896 run_lib.py:146] step: 1087900, eval_loss: 2.59755e-02
I0212 23:19:26.984586 22542570456896 run_lib.py:133] step: 1087950, training_loss: 2.69992e-02
I0212 23:19:44.244425 22542570456896 run_lib.py:133] step: 1088000, training_loss: 3.12453e-02
I0212 23:19:44.409324 22542570456896 run_lib.py:146] step: 1088000, eval_loss: 2.68877e-02
I0212 23:20:01.909774 22542570456896 run_lib.py:133] step: 1088050, training_loss: 2.37405e-02
I0212 23:20:19.142169 22542570456896 run_lib.py:133] step: 1088100, training_loss: 2.55245e-02
I0212 23:20:19.295536 22542570456896 run_lib.py:146] step: 1088100, eval_loss: 3.21490e-02
I0212 23:20:36.579924 22542570456896 run_lib.py:133] step: 1088150, training_loss: 1.86518e-02
I0212 23:20:53.961479 22542570456896 run_lib.py:133] step: 1088200, training_loss: 2.51853e-02
I0212 23:20:54.117254 22542570456896 run_lib.py:146] step: 1088200, eval_loss: 3.39661e-02
I0212 23:21:11.359303 22542570456896 run_lib.py:133] step: 1088250, training_loss: 2.91049e-02
I0212 23:21:28.636965 22542570456896 run_lib.py:133] step: 1088300, training_loss: 2.61275e-02
I0212 23:21:28.811550 22542570456896 run_lib.py:146] step: 1088300, eval_loss: 2.87240e-02
I0212 23:21:46.247216 22542570456896 run_lib.py:133] step: 1088350, training_loss: 2.38282e-02
I0212 23:22:03.536750 22542570456896 run_lib.py:133] step: 1088400, training_loss: 2.60547e-02
I0212 23:22:03.692531 22542570456896 run_lib.py:146] step: 1088400, eval_loss: 2.64755e-02
I0212 23:22:21.045780 22542570456896 run_lib.py:133] step: 1088450, training_loss: 2.71868e-02
I0212 23:22:38.346267 22542570456896 run_lib.py:133] step: 1088500, training_loss: 3.01437e-02
I0212 23:22:38.500318 22542570456896 run_lib.py:146] step: 1088500, eval_loss: 3.06120e-02
I0212 23:22:55.830461 22542570456896 run_lib.py:133] step: 1088550, training_loss: 2.21249e-02
I0212 23:23:13.445260 22542570456896 run_lib.py:133] step: 1088600, training_loss: 2.57790e-02
I0212 23:23:13.603764 22542570456896 run_lib.py:146] step: 1088600, eval_loss: 2.78428e-02
I0212 23:23:31.099050 22542570456896 run_lib.py:133] step: 1088650, training_loss: 2.73202e-02
I0212 23:23:48.554062 22542570456896 run_lib.py:133] step: 1088700, training_loss: 2.89265e-02
I0212 23:23:48.707527 22542570456896 run_lib.py:146] step: 1088700, eval_loss: 2.52080e-02
I0212 23:24:06.164633 22542570456896 run_lib.py:133] step: 1088750, training_loss: 3.05411e-02
I0212 23:24:23.794137 22542570456896 run_lib.py:133] step: 1088800, training_loss: 2.74258e-02
I0212 23:24:23.970546 22542570456896 run_lib.py:146] step: 1088800, eval_loss: 2.98486e-02
I0212 23:24:41.479452 22542570456896 run_lib.py:133] step: 1088850, training_loss: 3.78978e-02
I0212 23:24:59.062482 22542570456896 run_lib.py:133] step: 1088900, training_loss: 2.61922e-02
I0212 23:24:59.220547 22542570456896 run_lib.py:146] step: 1088900, eval_loss: 3.12773e-02
I0212 23:25:16.506253 22542570456896 run_lib.py:133] step: 1088950, training_loss: 2.47943e-02
I0212 23:25:33.863618 22542570456896 run_lib.py:133] step: 1089000, training_loss: 2.41897e-02
I0212 23:25:34.031312 22542570456896 run_lib.py:146] step: 1089000, eval_loss: 3.32804e-02
I0212 23:25:51.705609 22542570456896 run_lib.py:133] step: 1089050, training_loss: 2.94025e-02
I0212 23:26:09.252288 22542570456896 run_lib.py:133] step: 1089100, training_loss: 2.75623e-02
I0212 23:26:09.406405 22542570456896 run_lib.py:146] step: 1089100, eval_loss: 3.06368e-02
I0212 23:26:26.962982 22542570456896 run_lib.py:133] step: 1089150, training_loss: 3.20473e-02
I0212 23:26:44.432785 22542570456896 run_lib.py:133] step: 1089200, training_loss: 2.69072e-02
I0212 23:26:44.588708 22542570456896 run_lib.py:146] step: 1089200, eval_loss: 2.72638e-02
I0212 23:27:02.289164 22542570456896 run_lib.py:133] step: 1089250, training_loss: 3.37694e-02
I0212 23:27:19.765779 22542570456896 run_lib.py:133] step: 1089300, training_loss: 2.57659e-02
I0212 23:27:19.926927 22542570456896 run_lib.py:146] step: 1089300, eval_loss: 3.20168e-02
I0212 23:27:37.564034 22542570456896 run_lib.py:133] step: 1089350, training_loss: 2.47765e-02
I0212 23:27:55.081899 22542570456896 run_lib.py:133] step: 1089400, training_loss: 2.25369e-02
I0212 23:27:55.239801 22542570456896 run_lib.py:146] step: 1089400, eval_loss: 3.00184e-02
I0212 23:28:12.934194 22542570456896 run_lib.py:133] step: 1089450, training_loss: 3.20793e-02
I0212 23:28:30.418312 22542570456896 run_lib.py:133] step: 1089500, training_loss: 2.40378e-02
I0212 23:28:30.579687 22542570456896 run_lib.py:146] step: 1089500, eval_loss: 2.49017e-02
I0212 23:28:48.036791 22542570456896 run_lib.py:133] step: 1089550, training_loss: 2.71147e-02
I0212 23:29:05.656762 22542570456896 run_lib.py:133] step: 1089600, training_loss: 3.24443e-02
I0212 23:29:05.809510 22542570456896 run_lib.py:146] step: 1089600, eval_loss: 2.80473e-02
I0212 23:29:23.309426 22542570456896 run_lib.py:133] step: 1089650, training_loss: 2.96669e-02
I0212 23:29:40.950580 22542570456896 run_lib.py:133] step: 1089700, training_loss: 2.51355e-02
I0212 23:29:41.108799 22542570456896 run_lib.py:146] step: 1089700, eval_loss: 3.21419e-02
I0212 23:29:58.640342 22542570456896 run_lib.py:133] step: 1089750, training_loss: 3.00430e-02
I0212 23:30:16.114707 22542570456896 run_lib.py:133] step: 1089800, training_loss: 2.61534e-02
I0212 23:30:16.279485 22542570456896 run_lib.py:146] step: 1089800, eval_loss: 3.02921e-02
I0212 23:30:33.887308 22542570456896 run_lib.py:133] step: 1089850, training_loss: 3.59605e-02
I0212 23:30:51.466149 22542570456896 run_lib.py:133] step: 1089900, training_loss: 2.05104e-02
I0212 23:30:51.624710 22542570456896 run_lib.py:146] step: 1089900, eval_loss: 2.04952e-02
I0212 23:31:09.115160 22542570456896 run_lib.py:133] step: 1089950, training_loss: 2.70289e-02
I0212 23:31:26.786089 22542570456896 run_lib.py:133] step: 1090000, training_loss: 2.63393e-02
I0212 23:31:27.549394 22542570456896 run_lib.py:146] step: 1090000, eval_loss: 2.82018e-02
I0212 23:31:47.651405 22542570456896 run_lib.py:133] step: 1090050, training_loss: 3.03807e-02
I0212 23:32:05.080574 22542570456896 run_lib.py:133] step: 1090100, training_loss: 3.18249e-02
I0212 23:32:05.235402 22542570456896 run_lib.py:146] step: 1090100, eval_loss: 2.97502e-02
I0212 23:32:22.820019 22542570456896 run_lib.py:133] step: 1090150, training_loss: 2.62582e-02
I0212 23:32:40.301270 22542570456896 run_lib.py:133] step: 1090200, training_loss: 3.03302e-02
I0212 23:32:40.456737 22542570456896 run_lib.py:146] step: 1090200, eval_loss: 3.61540e-02
I0212 23:32:57.961228 22542570456896 run_lib.py:133] step: 1090250, training_loss: 2.40005e-02
I0212 23:33:15.425053 22542570456896 run_lib.py:133] step: 1090300, training_loss: 3.25316e-02
I0212 23:33:15.586440 22542570456896 run_lib.py:146] step: 1090300, eval_loss: 3.73135e-02
I0212 23:33:33.205583 22542570456896 run_lib.py:133] step: 1090350, training_loss: 2.28095e-02
I0212 23:33:50.677028 22542570456896 run_lib.py:133] step: 1090400, training_loss: 2.81697e-02
I0212 23:33:50.839720 22542570456896 run_lib.py:146] step: 1090400, eval_loss: 3.13327e-02
I0212 23:34:08.365565 22542570456896 run_lib.py:133] step: 1090450, training_loss: 2.31800e-02
I0212 23:34:25.870079 22542570456896 run_lib.py:133] step: 1090500, training_loss: 2.81222e-02
I0212 23:34:26.026096 22542570456896 run_lib.py:146] step: 1090500, eval_loss: 3.29901e-02
I0212 23:34:43.509309 22542570456896 run_lib.py:133] step: 1090550, training_loss: 2.93348e-02
I0212 23:35:00.955693 22542570456896 run_lib.py:133] step: 1090600, training_loss: 2.14998e-02
I0212 23:35:01.111556 22542570456896 run_lib.py:146] step: 1090600, eval_loss: 3.43303e-02
I0212 23:35:18.736673 22542570456896 run_lib.py:133] step: 1090650, training_loss: 3.01402e-02
I0212 23:35:36.282286 22542570456896 run_lib.py:133] step: 1090700, training_loss: 2.69707e-02
I0212 23:35:36.436544 22542570456896 run_lib.py:146] step: 1090700, eval_loss: 2.74064e-02
I0212 23:35:53.860941 22542570456896 run_lib.py:133] step: 1090750, training_loss: 2.49222e-02
I0212 23:36:11.348264 22542570456896 run_lib.py:133] step: 1090800, training_loss: 2.81643e-02
I0212 23:36:11.528515 22542570456896 run_lib.py:146] step: 1090800, eval_loss: 3.21954e-02
I0212 23:36:29.202830 22542570456896 run_lib.py:133] step: 1090850, training_loss: 2.72771e-02
I0212 23:36:46.665823 22542570456896 run_lib.py:133] step: 1090900, training_loss: 2.46092e-02
I0212 23:36:46.823726 22542570456896 run_lib.py:146] step: 1090900, eval_loss: 3.70663e-02
I0212 23:37:04.415409 22542570456896 run_lib.py:133] step: 1090950, training_loss: 2.57658e-02
I0212 23:37:21.855043 22542570456896 run_lib.py:133] step: 1091000, training_loss: 2.77458e-02
I0212 23:37:22.012633 22542570456896 run_lib.py:146] step: 1091000, eval_loss: 3.49474e-02
I0212 23:37:39.622097 22542570456896 run_lib.py:133] step: 1091050, training_loss: 1.99399e-02
I0212 23:37:57.115206 22542570456896 run_lib.py:133] step: 1091100, training_loss: 2.11647e-02
I0212 23:37:57.271648 22542570456896 run_lib.py:146] step: 1091100, eval_loss: 2.40247e-02
I0212 23:38:14.952682 22542570456896 run_lib.py:133] step: 1091150, training_loss: 2.86231e-02
I0212 23:38:32.416020 22542570456896 run_lib.py:133] step: 1091200, training_loss: 2.33324e-02
I0212 23:38:32.572434 22542570456896 run_lib.py:146] step: 1091200, eval_loss: 3.05521e-02
I0212 23:38:50.004760 22542570456896 run_lib.py:133] step: 1091250, training_loss: 2.47505e-02
I0212 23:39:07.576324 22542570456896 run_lib.py:133] step: 1091300, training_loss: 3.03494e-02
I0212 23:39:07.752634 22542570456896 run_lib.py:146] step: 1091300, eval_loss: 2.54042e-02
I0212 23:39:25.224852 22542570456896 run_lib.py:133] step: 1091350, training_loss: 2.22222e-02
I0212 23:39:42.717896 22542570456896 run_lib.py:133] step: 1091400, training_loss: 2.99131e-02
I0212 23:39:42.876743 22542570456896 run_lib.py:146] step: 1091400, eval_loss: 2.92433e-02
I0212 23:40:00.490229 22542570456896 run_lib.py:133] step: 1091450, training_loss: 2.73262e-02
I0212 23:40:18.072529 22542570456896 run_lib.py:133] step: 1091500, training_loss: 2.72405e-02
I0212 23:40:18.238507 22542570456896 run_lib.py:146] step: 1091500, eval_loss: 2.27253e-02
I0212 23:40:35.690663 22542570456896 run_lib.py:133] step: 1091550, training_loss: 2.67942e-02
I0212 23:40:53.165621 22542570456896 run_lib.py:133] step: 1091600, training_loss: 2.91400e-02
I0212 23:40:53.319680 22542570456896 run_lib.py:146] step: 1091600, eval_loss: 2.61482e-02
I0212 23:41:10.811182 22542570456896 run_lib.py:133] step: 1091650, training_loss: 3.64610e-02
I0212 23:41:28.463249 22542570456896 run_lib.py:133] step: 1091700, training_loss: 2.62996e-02
I0212 23:41:28.620515 22542570456896 run_lib.py:146] step: 1091700, eval_loss: 2.66921e-02
I0212 23:41:46.073566 22542570456896 run_lib.py:133] step: 1091750, training_loss: 2.57582e-02
I0212 23:42:03.509018 22542570456896 run_lib.py:133] step: 1091800, training_loss: 2.48114e-02
I0212 23:42:03.665794 22542570456896 run_lib.py:146] step: 1091800, eval_loss: 2.43460e-02
I0212 23:42:21.117980 22542570456896 run_lib.py:133] step: 1091850, training_loss: 2.82869e-02
I0212 23:42:38.766190 22542570456896 run_lib.py:133] step: 1091900, training_loss: 3.27607e-02
I0212 23:42:38.924676 22542570456896 run_lib.py:146] step: 1091900, eval_loss: 2.84071e-02
I0212 23:42:56.408760 22542570456896 run_lib.py:133] step: 1091950, training_loss: 3.01612e-02
I0212 23:43:13.950890 22542570456896 run_lib.py:133] step: 1092000, training_loss: 2.03381e-02
I0212 23:43:14.113457 22542570456896 run_lib.py:146] step: 1092000, eval_loss: 3.10867e-02
I0212 23:43:31.554083 22542570456896 run_lib.py:133] step: 1092050, training_loss: 2.96350e-02
I0212 23:43:49.010688 22542570456896 run_lib.py:133] step: 1092100, training_loss: 3.10693e-02
I0212 23:43:49.163484 22542570456896 run_lib.py:146] step: 1092100, eval_loss: 2.80611e-02
I0212 23:44:06.759503 22542570456896 run_lib.py:133] step: 1092150, training_loss: 2.48441e-02
I0212 23:44:24.302610 22542570456896 run_lib.py:133] step: 1092200, training_loss: 2.47246e-02
I0212 23:44:24.480393 22542570456896 run_lib.py:146] step: 1092200, eval_loss: 3.04944e-02
I0212 23:44:41.949456 22542570456896 run_lib.py:133] step: 1092250, training_loss: 2.93973e-02
I0212 23:44:59.423421 22542570456896 run_lib.py:133] step: 1092300, training_loss: 2.72211e-02
I0212 23:44:59.579672 22542570456896 run_lib.py:146] step: 1092300, eval_loss: 3.05266e-02
I0212 23:45:17.226643 22542570456896 run_lib.py:133] step: 1092350, training_loss: 2.65361e-02
I0212 23:45:34.655331 22542570456896 run_lib.py:133] step: 1092400, training_loss: 3.09810e-02
I0212 23:45:34.811614 22542570456896 run_lib.py:146] step: 1092400, eval_loss: 2.72841e-02
I0212 23:45:52.423237 22542570456896 run_lib.py:133] step: 1092450, training_loss: 2.36636e-02
I0212 23:46:09.934710 22542570456896 run_lib.py:133] step: 1092500, training_loss: 3.29175e-02
I0212 23:46:10.089279 22542570456896 run_lib.py:146] step: 1092500, eval_loss: 3.02514e-02
I0212 23:46:27.743407 22542570456896 run_lib.py:133] step: 1092550, training_loss: 2.28191e-02
I0212 23:46:45.185337 22542570456896 run_lib.py:133] step: 1092600, training_loss: 2.77243e-02
I0212 23:46:45.340482 22542570456896 run_lib.py:146] step: 1092600, eval_loss: 2.53887e-02
I0212 23:47:02.756090 22542570456896 run_lib.py:133] step: 1092650, training_loss: 4.11576e-02
I0212 23:47:20.354430 22542570456896 run_lib.py:133] step: 1092700, training_loss: 2.29012e-02
I0212 23:47:20.532448 22542570456896 run_lib.py:146] step: 1092700, eval_loss: 2.95879e-02
I0212 23:47:38.080704 22542570456896 run_lib.py:133] step: 1092750, training_loss: 3.08009e-02
I0212 23:47:55.744560 22542570456896 run_lib.py:133] step: 1092800, training_loss: 2.55090e-02
I0212 23:47:55.899446 22542570456896 run_lib.py:146] step: 1092800, eval_loss: 2.59423e-02
I0212 23:48:13.348941 22542570456896 run_lib.py:133] step: 1092850, training_loss: 2.35210e-02
I0212 23:48:30.783036 22542570456896 run_lib.py:133] step: 1092900, training_loss: 2.29273e-02
I0212 23:48:30.940600 22542570456896 run_lib.py:146] step: 1092900, eval_loss: 2.58076e-02
I0212 23:48:48.573803 22542570456896 run_lib.py:133] step: 1092950, training_loss: 1.90472e-02
I0212 23:49:06.076372 22542570456896 run_lib.py:133] step: 1093000, training_loss: 2.37663e-02
I0212 23:49:06.230973 22542570456896 run_lib.py:146] step: 1093000, eval_loss: 3.04791e-02
I0212 23:49:23.711885 22542570456896 run_lib.py:133] step: 1093050, training_loss: 2.67710e-02
I0212 23:49:41.343142 22542570456896 run_lib.py:133] step: 1093100, training_loss: 2.89570e-02
I0212 23:49:41.499384 22542570456896 run_lib.py:146] step: 1093100, eval_loss: 2.94081e-02
I0212 23:49:58.927934 22542570456896 run_lib.py:133] step: 1093150, training_loss: 2.82818e-02
I0212 23:50:16.370694 22542570456896 run_lib.py:133] step: 1093200, training_loss: 2.95781e-02
I0212 23:50:16.528568 22542570456896 run_lib.py:146] step: 1093200, eval_loss: 3.02005e-02
I0212 23:50:34.080991 22542570456896 run_lib.py:133] step: 1093250, training_loss: 3.06839e-02
I0212 23:50:51.564192 22542570456896 run_lib.py:133] step: 1093300, training_loss: 2.82271e-02
I0212 23:50:51.721704 22542570456896 run_lib.py:146] step: 1093300, eval_loss: 2.77212e-02
I0212 23:51:09.212365 22542570456896 run_lib.py:133] step: 1093350, training_loss: 2.76473e-02
I0212 23:51:26.660561 22542570456896 run_lib.py:133] step: 1093400, training_loss: 2.62707e-02
I0212 23:51:26.820273 22542570456896 run_lib.py:146] step: 1093400, eval_loss: 2.16751e-02
I0212 23:51:44.471808 22542570456896 run_lib.py:133] step: 1093450, training_loss: 3.23927e-02
I0212 23:52:01.963848 22542570456896 run_lib.py:133] step: 1093500, training_loss: 2.50886e-02
I0212 23:52:02.116442 22542570456896 run_lib.py:146] step: 1093500, eval_loss: 2.28820e-02
I0212 23:52:19.572482 22542570456896 run_lib.py:133] step: 1093550, training_loss: 3.03699e-02
I0212 23:52:37.098511 22542570456896 run_lib.py:133] step: 1093600, training_loss: 2.74232e-02
I0212 23:52:37.267701 22542570456896 run_lib.py:146] step: 1093600, eval_loss: 3.23770e-02
I0212 23:52:54.961837 22542570456896 run_lib.py:133] step: 1093650, training_loss: 2.52987e-02
I0212 23:53:12.450031 22542570456896 run_lib.py:133] step: 1093700, training_loss: 3.01635e-02
I0212 23:53:12.614769 22542570456896 run_lib.py:146] step: 1093700, eval_loss: 3.06601e-02
I0212 23:53:30.243249 22542570456896 run_lib.py:133] step: 1093750, training_loss: 3.02620e-02
I0212 23:53:47.711587 22542570456896 run_lib.py:133] step: 1093800, training_loss: 3.00856e-02
I0212 23:53:47.879181 22542570456896 run_lib.py:146] step: 1093800, eval_loss: 2.83095e-02
I0212 23:54:05.511407 22542570456896 run_lib.py:133] step: 1093850, training_loss: 2.39512e-02
I0212 23:54:23.004582 22542570456896 run_lib.py:133] step: 1093900, training_loss: 2.80554e-02
I0212 23:54:23.162770 22542570456896 run_lib.py:146] step: 1093900, eval_loss: 3.17642e-02
I0212 23:54:40.857938 22542570456896 run_lib.py:133] step: 1093950, training_loss: 2.33765e-02
I0212 23:54:58.302838 22542570456896 run_lib.py:133] step: 1094000, training_loss: 2.59691e-02
I0212 23:54:58.455458 22542570456896 run_lib.py:146] step: 1094000, eval_loss: 2.52946e-02
I0212 23:55:15.890803 22542570456896 run_lib.py:133] step: 1094050, training_loss: 2.68991e-02
I0212 23:55:33.477184 22542570456896 run_lib.py:133] step: 1094100, training_loss: 2.47700e-02
I0212 23:55:33.659526 22542570456896 run_lib.py:146] step: 1094100, eval_loss: 3.16634e-02
I0212 23:55:51.140861 22542570456896 run_lib.py:133] step: 1094150, training_loss: 3.41297e-02
I0212 23:56:08.615903 22542570456896 run_lib.py:133] step: 1094200, training_loss: 2.87263e-02
I0212 23:56:08.773128 22542570456896 run_lib.py:146] step: 1094200, eval_loss: 2.43660e-02
I0212 23:56:26.418780 22542570456896 run_lib.py:133] step: 1094250, training_loss: 3.03752e-02
I0212 23:56:43.889784 22542570456896 run_lib.py:133] step: 1094300, training_loss: 2.38494e-02
I0212 23:56:44.047580 22542570456896 run_lib.py:146] step: 1094300, eval_loss: 2.78070e-02
I0212 23:57:01.632491 22542570456896 run_lib.py:133] step: 1094350, training_loss: 2.40860e-02
I0212 23:57:19.071277 22542570456896 run_lib.py:133] step: 1094400, training_loss: 2.35565e-02
I0212 23:57:19.225187 22542570456896 run_lib.py:146] step: 1094400, eval_loss: 3.44110e-02
I0212 23:57:36.745842 22542570456896 run_lib.py:133] step: 1094450, training_loss: 2.44371e-02
I0212 23:57:54.384490 22542570456896 run_lib.py:133] step: 1094500, training_loss: 2.67558e-02
I0212 23:57:54.540463 22542570456896 run_lib.py:146] step: 1094500, eval_loss: 2.37093e-02
I0212 23:58:11.973725 22542570456896 run_lib.py:133] step: 1094550, training_loss: 3.05040e-02
I0212 23:58:29.442326 22542570456896 run_lib.py:133] step: 1094600, training_loss: 2.51375e-02
I0212 23:58:29.603713 22542570456896 run_lib.py:146] step: 1094600, eval_loss: 3.15904e-02
I0212 23:58:47.089266 22542570456896 run_lib.py:133] step: 1094650, training_loss: 2.57969e-02
I0212 23:59:04.751131 22542570456896 run_lib.py:133] step: 1094700, training_loss: 2.22000e-02
I0212 23:59:04.923485 22542570456896 run_lib.py:146] step: 1094700, eval_loss: 2.95117e-02
I0212 23:59:22.367585 22542570456896 run_lib.py:133] step: 1094750, training_loss: 3.02838e-02
I0212 23:59:39.917834 22542570456896 run_lib.py:133] step: 1094800, training_loss: 2.51223e-02
I0212 23:59:40.075674 22542570456896 run_lib.py:146] step: 1094800, eval_loss: 2.93289e-02
I0212 23:59:57.523306 22542570456896 run_lib.py:133] step: 1094850, training_loss: 2.57594e-02
I0213 00:00:14.983309 22542570456896 run_lib.py:133] step: 1094900, training_loss: 3.28396e-02
I0213 00:00:15.134359 22542570456896 run_lib.py:146] step: 1094900, eval_loss: 2.57975e-02
I0213 00:00:32.720725 22542570456896 run_lib.py:133] step: 1094950, training_loss: 2.79930e-02
I0213 00:00:50.329552 22542570456896 run_lib.py:133] step: 1095000, training_loss: 2.84933e-02
I0213 00:00:50.498614 22542570456896 run_lib.py:146] step: 1095000, eval_loss: 3.14055e-02
I0213 00:01:08.002327 22542570456896 run_lib.py:133] step: 1095050, training_loss: 2.43045e-02
I0213 00:01:25.469906 22542570456896 run_lib.py:133] step: 1095100, training_loss: 3.18592e-02
I0213 00:01:25.627594 22542570456896 run_lib.py:146] step: 1095100, eval_loss: 3.52388e-02
I0213 00:01:43.256136 22542570456896 run_lib.py:133] step: 1095150, training_loss: 2.61701e-02
I0213 00:02:00.689680 22542570456896 run_lib.py:133] step: 1095200, training_loss: 3.27205e-02
I0213 00:02:00.852432 22542570456896 run_lib.py:146] step: 1095200, eval_loss: 3.09227e-02
I0213 00:02:18.426712 22542570456896 run_lib.py:133] step: 1095250, training_loss: 2.41630e-02
I0213 00:02:35.964262 22542570456896 run_lib.py:133] step: 1095300, training_loss: 2.92114e-02
I0213 00:02:36.121910 22542570456896 run_lib.py:146] step: 1095300, eval_loss: 3.21882e-02
I0213 00:02:53.792472 22542570456896 run_lib.py:133] step: 1095350, training_loss: 2.19184e-02
I0213 00:03:11.232007 22542570456896 run_lib.py:133] step: 1095400, training_loss: 2.46168e-02
I0213 00:03:11.386502 22542570456896 run_lib.py:146] step: 1095400, eval_loss: 3.37971e-02
I0213 00:03:28.834639 22542570456896 run_lib.py:133] step: 1095450, training_loss: 2.68538e-02
I0213 00:03:46.446531 22542570456896 run_lib.py:133] step: 1095500, training_loss: 2.32077e-02
I0213 00:03:46.615281 22542570456896 run_lib.py:146] step: 1095500, eval_loss: 3.09852e-02
I0213 00:04:04.114118 22542570456896 run_lib.py:133] step: 1095550, training_loss: 2.63062e-02
I0213 00:04:21.769837 22542570456896 run_lib.py:133] step: 1095600, training_loss: 3.00987e-02
I0213 00:04:21.928546 22542570456896 run_lib.py:146] step: 1095600, eval_loss: 3.25264e-02
I0213 00:04:39.389916 22542570456896 run_lib.py:133] step: 1095650, training_loss: 2.18865e-02
I0213 00:04:56.846678 22542570456896 run_lib.py:133] step: 1095700, training_loss: 2.87223e-02
I0213 00:04:57.004551 22542570456896 run_lib.py:146] step: 1095700, eval_loss: 2.94813e-02
I0213 00:05:14.619308 22542570456896 run_lib.py:133] step: 1095750, training_loss: 2.91104e-02
I0213 00:05:32.089677 22542570456896 run_lib.py:133] step: 1095800, training_loss: 2.56069e-02
I0213 00:05:32.246770 22542570456896 run_lib.py:146] step: 1095800, eval_loss: 2.63479e-02
I0213 00:05:49.773149 22542570456896 run_lib.py:133] step: 1095850, training_loss: 2.41413e-02
I0213 00:06:07.488508 22542570456896 run_lib.py:133] step: 1095900, training_loss: 2.17231e-02
I0213 00:06:07.641722 22542570456896 run_lib.py:146] step: 1095900, eval_loss: 3.74438e-02
I0213 00:06:25.079286 22542570456896 run_lib.py:133] step: 1095950, training_loss: 3.05730e-02
I0213 00:06:42.529344 22542570456896 run_lib.py:133] step: 1096000, training_loss: 2.56588e-02
I0213 00:06:42.845274 22542570456896 run_lib.py:146] step: 1096000, eval_loss: 3.14002e-02
I0213 00:07:00.296727 22542570456896 run_lib.py:133] step: 1096050, training_loss: 2.31798e-02
I0213 00:07:17.800725 22542570456896 run_lib.py:133] step: 1096100, training_loss: 2.80600e-02
I0213 00:07:17.959415 22542570456896 run_lib.py:146] step: 1096100, eval_loss: 2.49927e-02
I0213 00:07:35.415157 22542570456896 run_lib.py:133] step: 1096150, training_loss: 2.12821e-02
I0213 00:07:52.869642 22542570456896 run_lib.py:133] step: 1096200, training_loss: 2.19073e-02
I0213 00:07:53.027172 22542570456896 run_lib.py:146] step: 1096200, eval_loss: 2.91972e-02
I0213 00:08:10.677500 22542570456896 run_lib.py:133] step: 1096250, training_loss: 2.52132e-02
I0213 00:08:28.189415 22542570456896 run_lib.py:133] step: 1096300, training_loss: 3.27623e-02
I0213 00:08:28.343527 22542570456896 run_lib.py:146] step: 1096300, eval_loss: 2.86150e-02
I0213 00:08:45.778656 22542570456896 run_lib.py:133] step: 1096350, training_loss: 2.97522e-02
I0213 00:09:03.285540 22542570456896 run_lib.py:133] step: 1096400, training_loss: 2.64785e-02
I0213 00:09:03.450791 22542570456896 run_lib.py:146] step: 1096400, eval_loss: 2.49705e-02
I0213 00:09:21.132874 22542570456896 run_lib.py:133] step: 1096450, training_loss: 2.56582e-02
I0213 00:09:38.663709 22542570456896 run_lib.py:133] step: 1096500, training_loss: 2.73599e-02
I0213 00:09:38.821485 22542570456896 run_lib.py:146] step: 1096500, eval_loss: 2.78653e-02
I0213 00:09:56.163260 22542570456896 run_lib.py:133] step: 1096550, training_loss: 2.65346e-02
I0213 00:10:13.519511 22542570456896 run_lib.py:133] step: 1096600, training_loss: 2.33347e-02
I0213 00:10:13.675497 22542570456896 run_lib.py:146] step: 1096600, eval_loss: 2.97647e-02
I0213 00:10:31.276779 22542570456896 run_lib.py:133] step: 1096650, training_loss: 2.47311e-02
I0213 00:10:48.724994 22542570456896 run_lib.py:133] step: 1096700, training_loss: 2.22147e-02
I0213 00:10:48.881571 22542570456896 run_lib.py:146] step: 1096700, eval_loss: 2.93178e-02
I0213 00:11:06.469676 22542570456896 run_lib.py:133] step: 1096750, training_loss: 2.42344e-02
I0213 00:11:23.880905 22542570456896 run_lib.py:133] step: 1096800, training_loss: 2.51684e-02
I0213 00:11:24.037527 22542570456896 run_lib.py:146] step: 1096800, eval_loss: 3.14242e-02
I0213 00:11:41.551183 22542570456896 run_lib.py:133] step: 1096850, training_loss: 3.10002e-02
I0213 00:11:58.951900 22542570456896 run_lib.py:133] step: 1096900, training_loss: 3.11493e-02
I0213 00:11:59.115368 22542570456896 run_lib.py:146] step: 1096900, eval_loss: 3.11383e-02
I0213 00:12:16.558401 22542570456896 run_lib.py:133] step: 1096950, training_loss: 2.84591e-02
I0213 00:12:34.257581 22542570456896 run_lib.py:133] step: 1097000, training_loss: 2.39964e-02
I0213 00:12:34.417830 22542570456896 run_lib.py:146] step: 1097000, eval_loss: 3.01978e-02
I0213 00:12:51.916161 22542570456896 run_lib.py:133] step: 1097050, training_loss: 2.81390e-02
I0213 00:13:09.526388 22542570456896 run_lib.py:133] step: 1097100, training_loss: 3.06348e-02
I0213 00:13:09.682494 22542570456896 run_lib.py:146] step: 1097100, eval_loss: 3.17414e-02
I0213 00:13:27.157549 22542570456896 run_lib.py:133] step: 1097150, training_loss: 2.56181e-02
I0213 00:13:44.599037 22542570456896 run_lib.py:133] step: 1097200, training_loss: 2.37400e-02
I0213 00:13:44.758428 22542570456896 run_lib.py:146] step: 1097200, eval_loss: 3.24823e-02
I0213 00:14:02.471955 22542570456896 run_lib.py:133] step: 1097250, training_loss: 2.30400e-02
I0213 00:14:19.965875 22542570456896 run_lib.py:133] step: 1097300, training_loss: 2.90653e-02
I0213 00:14:20.127816 22542570456896 run_lib.py:146] step: 1097300, eval_loss: 3.53105e-02
I0213 00:14:37.680234 22542570456896 run_lib.py:133] step: 1097350, training_loss: 3.32625e-02
I0213 00:14:55.165040 22542570456896 run_lib.py:133] step: 1097400, training_loss: 3.00932e-02
I0213 00:14:55.326767 22542570456896 run_lib.py:146] step: 1097400, eval_loss: 2.94100e-02
I0213 00:15:12.920529 22542570456896 run_lib.py:133] step: 1097450, training_loss: 3.00543e-02
I0213 00:15:30.376149 22542570456896 run_lib.py:133] step: 1097500, training_loss: 2.79602e-02
I0213 00:15:30.557593 22542570456896 run_lib.py:146] step: 1097500, eval_loss: 3.35661e-02
I0213 00:15:48.171110 22542570456896 run_lib.py:133] step: 1097550, training_loss: 2.34577e-02
I0213 00:16:05.648793 22542570456896 run_lib.py:133] step: 1097600, training_loss: 2.82868e-02
I0213 00:16:05.804274 22542570456896 run_lib.py:146] step: 1097600, eval_loss: 3.04941e-02
I0213 00:16:23.309327 22542570456896 run_lib.py:133] step: 1097650, training_loss: 3.16511e-02
I0213 00:16:40.744752 22542570456896 run_lib.py:133] step: 1097700, training_loss: 2.90313e-02
I0213 00:16:40.900185 22542570456896 run_lib.py:146] step: 1097700, eval_loss: 2.22846e-02
I0213 00:16:58.552060 22542570456896 run_lib.py:133] step: 1097750, training_loss: 2.59618e-02
I0213 00:17:16.134642 22542570456896 run_lib.py:133] step: 1097800, training_loss: 2.43130e-02
I0213 00:17:16.291781 22542570456896 run_lib.py:146] step: 1097800, eval_loss: 3.05760e-02
I0213 00:17:33.816612 22542570456896 run_lib.py:133] step: 1097850, training_loss: 2.65972e-02
I0213 00:17:51.309223 22542570456896 run_lib.py:133] step: 1097900, training_loss: 3.04672e-02
I0213 00:17:51.468551 22542570456896 run_lib.py:146] step: 1097900, eval_loss: 2.78046e-02
I0213 00:18:09.097466 22542570456896 run_lib.py:133] step: 1097950, training_loss: 2.58983e-02
I0213 00:18:26.548915 22542570456896 run_lib.py:133] step: 1098000, training_loss: 2.82182e-02
I0213 00:18:26.704500 22542570456896 run_lib.py:146] step: 1098000, eval_loss: 2.83276e-02
I0213 00:18:44.371392 22542570456896 run_lib.py:133] step: 1098050, training_loss: 2.58587e-02
I0213 00:19:01.930047 22542570456896 run_lib.py:133] step: 1098100, training_loss: 2.98008e-02
I0213 00:19:02.086193 22542570456896 run_lib.py:146] step: 1098100, eval_loss: 3.36305e-02
I0213 00:19:19.724663 22542570456896 run_lib.py:133] step: 1098150, training_loss: 2.35652e-02
I0213 00:19:37.181901 22542570456896 run_lib.py:133] step: 1098200, training_loss: 2.26090e-02
I0213 00:19:37.335330 22542570456896 run_lib.py:146] step: 1098200, eval_loss: 2.90159e-02
I0213 00:19:54.912494 22542570456896 run_lib.py:133] step: 1098250, training_loss: 2.89291e-02
I0213 00:20:12.380563 22542570456896 run_lib.py:133] step: 1098300, training_loss: 3.28653e-02
I0213 00:20:12.544383 22542570456896 run_lib.py:146] step: 1098300, eval_loss: 2.71487e-02
I0213 00:20:29.959053 22542570456896 run_lib.py:133] step: 1098350, training_loss: 2.29951e-02
I0213 00:20:47.644279 22542570456896 run_lib.py:133] step: 1098400, training_loss: 3.29848e-02
I0213 00:20:47.818326 22542570456896 run_lib.py:146] step: 1098400, eval_loss: 3.03627e-02
I0213 00:21:05.294294 22542570456896 run_lib.py:133] step: 1098450, training_loss: 3.00548e-02
I0213 00:21:22.724249 22542570456896 run_lib.py:133] step: 1098500, training_loss: 2.41522e-02
I0213 00:21:22.881515 22542570456896 run_lib.py:146] step: 1098500, eval_loss: 2.57459e-02
I0213 00:21:40.523533 22542570456896 run_lib.py:133] step: 1098550, training_loss: 3.04086e-02
I0213 00:21:58.115687 22542570456896 run_lib.py:133] step: 1098600, training_loss: 2.92105e-02
I0213 00:21:58.280450 22542570456896 run_lib.py:146] step: 1098600, eval_loss: 3.22683e-02
I0213 00:22:15.745779 22542570456896 run_lib.py:133] step: 1098650, training_loss: 2.94020e-02
I0213 00:22:33.211727 22542570456896 run_lib.py:133] step: 1098700, training_loss: 2.37561e-02
I0213 00:22:33.363548 22542570456896 run_lib.py:146] step: 1098700, eval_loss: 2.79847e-02
I0213 00:22:50.830249 22542570456896 run_lib.py:133] step: 1098750, training_loss: 2.89182e-02
I0213 00:23:08.534469 22542570456896 run_lib.py:133] step: 1098800, training_loss: 2.48360e-02
I0213 00:23:08.692421 22542570456896 run_lib.py:146] step: 1098800, eval_loss: 2.96160e-02
I0213 00:23:26.143809 22542570456896 run_lib.py:133] step: 1098850, training_loss: 2.13607e-02
I0213 00:23:43.618574 22542570456896 run_lib.py:133] step: 1098900, training_loss: 2.73860e-02
I0213 00:23:43.797511 22542570456896 run_lib.py:146] step: 1098900, eval_loss: 2.52907e-02
I0213 00:24:01.288644 22542570456896 run_lib.py:133] step: 1098950, training_loss: 2.52297e-02
I0213 00:24:18.949954 22542570456896 run_lib.py:133] step: 1099000, training_loss: 3.05973e-02
I0213 00:24:19.108715 22542570456896 run_lib.py:146] step: 1099000, eval_loss: 2.83970e-02
I0213 00:24:36.549800 22542570456896 run_lib.py:133] step: 1099050, training_loss: 2.06520e-02
I0213 00:24:54.069215 22542570456896 run_lib.py:133] step: 1099100, training_loss: 3.32381e-02
I0213 00:24:54.228185 22542570456896 run_lib.py:146] step: 1099100, eval_loss: 2.88731e-02
I0213 00:25:11.701776 22542570456896 run_lib.py:133] step: 1099150, training_loss: 3.47605e-02
I0213 00:25:29.207282 22542570456896 run_lib.py:133] step: 1099200, training_loss: 3.19112e-02
I0213 00:25:29.360692 22542570456896 run_lib.py:146] step: 1099200, eval_loss: 2.65991e-02
I0213 00:25:46.997745 22542570456896 run_lib.py:133] step: 1099250, training_loss: 2.44726e-02
I0213 00:26:04.514988 22542570456896 run_lib.py:133] step: 1099300, training_loss: 2.30541e-02
I0213 00:26:04.673668 22542570456896 run_lib.py:146] step: 1099300, eval_loss: 3.54167e-02
I0213 00:26:22.102730 22542570456896 run_lib.py:133] step: 1099350, training_loss: 2.71435e-02
I0213 00:26:39.565082 22542570456896 run_lib.py:133] step: 1099400, training_loss: 2.06106e-02
I0213 00:26:39.735490 22542570456896 run_lib.py:146] step: 1099400, eval_loss: 2.80800e-02
I0213 00:26:57.359011 22542570456896 run_lib.py:133] step: 1099450, training_loss: 2.37038e-02
I0213 00:27:14.830525 22542570456896 run_lib.py:133] step: 1099500, training_loss: 3.09800e-02
I0213 00:27:14.986966 22542570456896 run_lib.py:146] step: 1099500, eval_loss: 2.76268e-02
I0213 00:27:32.643746 22542570456896 run_lib.py:133] step: 1099550, training_loss: 3.35499e-02
I0213 00:27:50.084370 22542570456896 run_lib.py:133] step: 1099600, training_loss: 2.45740e-02
I0213 00:27:50.240556 22542570456896 run_lib.py:146] step: 1099600, eval_loss: 3.11777e-02
I0213 00:28:07.851148 22542570456896 run_lib.py:133] step: 1099650, training_loss: 2.59883e-02
I0213 00:28:25.315732 22542570456896 run_lib.py:133] step: 1099700, training_loss: 2.78325e-02
I0213 00:28:25.472724 22542570456896 run_lib.py:146] step: 1099700, eval_loss: 2.40214e-02
I0213 00:28:42.971081 22542570456896 run_lib.py:133] step: 1099750, training_loss: 2.40393e-02
I0213 00:29:00.645184 22542570456896 run_lib.py:133] step: 1099800, training_loss: 2.67539e-02
I0213 00:29:00.807527 22542570456896 run_lib.py:146] step: 1099800, eval_loss: 3.16662e-02
I0213 00:29:18.248118 22542570456896 run_lib.py:133] step: 1099850, training_loss: 2.19752e-02
I0213 00:29:35.838699 22542570456896 run_lib.py:133] step: 1099900, training_loss: 3.15354e-02
I0213 00:29:35.995415 22542570456896 run_lib.py:146] step: 1099900, eval_loss: 3.01177e-02
I0213 00:29:53.463129 22542570456896 run_lib.py:133] step: 1099950, training_loss: 2.06431e-02
I0213 00:30:10.908412 22542570456896 run_lib.py:133] step: 1100000, training_loss: 2.14928e-02
I0213 00:30:11.647054 22542570456896 run_lib.py:146] step: 1100000, eval_loss: 2.62464e-02
I0213 00:30:31.812937 22542570456896 run_lib.py:133] step: 1100050, training_loss: 2.39632e-02
I0213 00:30:49.466547 22542570456896 run_lib.py:133] step: 1100100, training_loss: 2.72632e-02
I0213 00:30:49.624773 22542570456896 run_lib.py:146] step: 1100100, eval_loss: 2.92367e-02
I0213 00:31:07.114305 22542570456896 run_lib.py:133] step: 1100150, training_loss: 3.09799e-02
I0213 00:31:24.731367 22542570456896 run_lib.py:133] step: 1100200, training_loss: 2.86735e-02
I0213 00:31:24.884516 22542570456896 run_lib.py:146] step: 1100200, eval_loss: 3.02364e-02
I0213 00:31:42.304612 22542570456896 run_lib.py:133] step: 1100250, training_loss: 2.94938e-02
I0213 00:31:59.761605 22542570456896 run_lib.py:133] step: 1100300, training_loss: 2.53141e-02
I0213 00:31:59.934710 22542570456896 run_lib.py:146] step: 1100300, eval_loss: 3.02457e-02
I0213 00:32:17.617235 22542570456896 run_lib.py:133] step: 1100350, training_loss: 2.35670e-02
I0213 00:32:35.084422 22542570456896 run_lib.py:133] step: 1100400, training_loss: 2.96474e-02
I0213 00:32:35.244570 22542570456896 run_lib.py:146] step: 1100400, eval_loss: 2.20567e-02
I0213 00:32:52.869766 22542570456896 run_lib.py:133] step: 1100450, training_loss: 3.26120e-02
I0213 00:33:10.287970 22542570456896 run_lib.py:133] step: 1100500, training_loss: 2.02352e-02
I0213 00:33:10.445485 22542570456896 run_lib.py:146] step: 1100500, eval_loss: 3.00708e-02
I0213 00:33:27.913133 22542570456896 run_lib.py:133] step: 1100550, training_loss: 2.85576e-02
I0213 00:33:45.553130 22542570456896 run_lib.py:133] step: 1100600, training_loss: 2.90564e-02
I0213 00:33:45.709700 22542570456896 run_lib.py:146] step: 1100600, eval_loss: 2.87899e-02
I0213 00:34:03.192857 22542570456896 run_lib.py:133] step: 1100650, training_loss: 2.85186e-02
I0213 00:34:20.657113 22542570456896 run_lib.py:133] step: 1100700, training_loss: 3.46008e-02
I0213 00:34:20.810470 22542570456896 run_lib.py:146] step: 1100700, eval_loss: 2.03319e-02
I0213 00:34:38.256699 22542570456896 run_lib.py:133] step: 1100750, training_loss: 2.28218e-02
I0213 00:34:55.875290 22542570456896 run_lib.py:133] step: 1100800, training_loss: 2.82475e-02
I0213 00:34:56.035688 22542570456896 run_lib.py:146] step: 1100800, eval_loss: 3.25768e-02
I0213 00:35:13.448992 22542570456896 run_lib.py:133] step: 1100850, training_loss: 2.64038e-02
I0213 00:35:31.016235 22542570456896 run_lib.py:133] step: 1100900, training_loss: 2.23552e-02
I0213 00:35:31.182443 22542570456896 run_lib.py:146] step: 1100900, eval_loss: 3.50567e-02
I0213 00:35:48.662233 22542570456896 run_lib.py:133] step: 1100950, training_loss: 2.51529e-02
I0213 00:36:06.094792 22542570456896 run_lib.py:133] step: 1101000, training_loss: 3.36710e-02
I0213 00:36:06.253268 22542570456896 run_lib.py:146] step: 1101000, eval_loss: 2.78534e-02
I0213 00:36:23.902898 22542570456896 run_lib.py:133] step: 1101050, training_loss: 2.34648e-02
I0213 00:36:41.376780 22542570456896 run_lib.py:133] step: 1101100, training_loss: 2.48959e-02
I0213 00:36:41.531383 22542570456896 run_lib.py:146] step: 1101100, eval_loss: 3.43058e-02
I0213 00:36:58.969952 22542570456896 run_lib.py:133] step: 1101150, training_loss: 2.79181e-02
I0213 00:37:16.442557 22542570456896 run_lib.py:133] step: 1101200, training_loss: 3.09749e-02
I0213 00:37:16.608685 22542570456896 run_lib.py:146] step: 1101200, eval_loss: 2.61789e-02
I0213 00:37:34.291290 22542570456896 run_lib.py:133] step: 1101250, training_loss: 2.68241e-02
I0213 00:37:51.743186 22542570456896 run_lib.py:133] step: 1101300, training_loss: 3.48799e-02
I0213 00:37:51.899656 22542570456896 run_lib.py:146] step: 1101300, eval_loss: 3.93154e-02
I0213 00:38:09.504993 22542570456896 run_lib.py:133] step: 1101350, training_loss: 2.98921e-02
I0213 00:38:26.942023 22542570456896 run_lib.py:133] step: 1101400, training_loss: 2.18405e-02
I0213 00:38:27.099526 22542570456896 run_lib.py:146] step: 1101400, eval_loss: 2.75482e-02
I0213 00:38:44.690502 22542570456896 run_lib.py:133] step: 1101450, training_loss: 2.49135e-02
I0213 00:39:02.199521 22542570456896 run_lib.py:133] step: 1101500, training_loss: 2.50023e-02
I0213 00:39:02.358433 22542570456896 run_lib.py:146] step: 1101500, eval_loss: 2.36248e-02
I0213 00:39:19.871735 22542570456896 run_lib.py:133] step: 1101550, training_loss: 2.94000e-02
I0213 00:39:37.511043 22542570456896 run_lib.py:133] step: 1101600, training_loss: 2.28359e-02
I0213 00:39:37.664670 22542570456896 run_lib.py:146] step: 1101600, eval_loss: 3.66787e-02
I0213 00:39:55.158699 22542570456896 run_lib.py:133] step: 1101650, training_loss: 3.81199e-02
I0213 00:40:12.758705 22542570456896 run_lib.py:133] step: 1101700, training_loss: 2.56995e-02
I0213 00:40:12.916677 22542570456896 run_lib.py:146] step: 1101700, eval_loss: 2.66624e-02
I0213 00:40:30.414485 22542570456896 run_lib.py:133] step: 1101750, training_loss: 3.04426e-02
I0213 00:40:47.905978 22542570456896 run_lib.py:133] step: 1101800, training_loss: 2.82126e-02
I0213 00:40:48.065442 22542570456896 run_lib.py:146] step: 1101800, eval_loss: 2.62383e-02
I0213 00:41:05.722407 22542570456896 run_lib.py:133] step: 1101850, training_loss: 2.44628e-02
I0213 00:41:23.159669 22542570456896 run_lib.py:133] step: 1101900, training_loss: 2.74271e-02
I0213 00:41:23.316532 22542570456896 run_lib.py:146] step: 1101900, eval_loss: 3.04251e-02
I0213 00:41:40.808399 22542570456896 run_lib.py:133] step: 1101950, training_loss: 2.52884e-02
I0213 00:41:58.421411 22542570456896 run_lib.py:133] step: 1102000, training_loss: 2.57816e-02
I0213 00:41:58.579494 22542570456896 run_lib.py:146] step: 1102000, eval_loss: 2.96752e-02
I0213 00:42:16.069776 22542570456896 run_lib.py:133] step: 1102050, training_loss: 2.66673e-02
I0213 00:42:33.537492 22542570456896 run_lib.py:133] step: 1102100, training_loss: 2.75217e-02
I0213 00:42:33.692827 22542570456896 run_lib.py:146] step: 1102100, eval_loss: 2.52122e-02
I0213 00:42:51.317454 22542570456896 run_lib.py:133] step: 1102150, training_loss: 2.76448e-02
I0213 00:43:08.787585 22542570456896 run_lib.py:133] step: 1102200, training_loss: 2.90494e-02
I0213 00:43:08.941821 22542570456896 run_lib.py:146] step: 1102200, eval_loss: 3.08599e-02
I0213 00:43:26.362504 22542570456896 run_lib.py:133] step: 1102250, training_loss: 3.15721e-02
I0213 00:43:43.810209 22542570456896 run_lib.py:133] step: 1102300, training_loss: 3.06145e-02
I0213 00:43:43.988456 22542570456896 run_lib.py:146] step: 1102300, eval_loss: 3.82648e-02
I0213 00:44:01.683910 22542570456896 run_lib.py:133] step: 1102350, training_loss: 2.76702e-02
I0213 00:44:19.266821 22542570456896 run_lib.py:133] step: 1102400, training_loss: 2.31962e-02
I0213 00:44:19.423649 22542570456896 run_lib.py:146] step: 1102400, eval_loss: 3.07969e-02
I0213 00:44:36.908235 22542570456896 run_lib.py:133] step: 1102450, training_loss: 3.96213e-02
I0213 00:44:54.362253 22542570456896 run_lib.py:133] step: 1102500, training_loss: 2.20112e-02
I0213 00:44:54.515149 22542570456896 run_lib.py:146] step: 1102500, eval_loss: 2.58536e-02
I0213 00:45:12.091923 22542570456896 run_lib.py:133] step: 1102550, training_loss: 2.23425e-02
I0213 00:45:29.578048 22542570456896 run_lib.py:133] step: 1102600, training_loss: 2.22720e-02
I0213 00:45:29.733561 22542570456896 run_lib.py:146] step: 1102600, eval_loss: 3.00699e-02
I0213 00:45:47.435748 22542570456896 run_lib.py:133] step: 1102650, training_loss: 2.94308e-02
I0213 00:46:04.919414 22542570456896 run_lib.py:133] step: 1102700, training_loss: 3.54183e-02
I0213 00:46:05.084415 22542570456896 run_lib.py:146] step: 1102700, eval_loss: 3.21572e-02
I0213 00:46:22.690564 22542570456896 run_lib.py:133] step: 1102750, training_loss: 2.42542e-02
I0213 00:46:40.135860 22542570456896 run_lib.py:133] step: 1102800, training_loss: 3.16489e-02
I0213 00:46:40.291696 22542570456896 run_lib.py:146] step: 1102800, eval_loss: 2.50957e-02
I0213 00:46:57.915815 22542570456896 run_lib.py:133] step: 1102850, training_loss: 2.54201e-02
I0213 00:47:15.464656 22542570456896 run_lib.py:133] step: 1102900, training_loss: 2.83350e-02
I0213 00:47:15.630260 22542570456896 run_lib.py:146] step: 1102900, eval_loss: 3.11760e-02
I0213 00:47:33.114669 22542570456896 run_lib.py:133] step: 1102950, training_loss: 2.59568e-02
I0213 00:47:50.739653 22542570456896 run_lib.py:133] step: 1103000, training_loss: 2.25922e-02
I0213 00:47:50.895290 22542570456896 run_lib.py:146] step: 1103000, eval_loss: 2.50874e-02
I0213 00:48:08.335036 22542570456896 run_lib.py:133] step: 1103050, training_loss: 3.31119e-02
I0213 00:48:25.789024 22542570456896 run_lib.py:133] step: 1103100, training_loss: 2.84384e-02
I0213 00:48:25.954770 22542570456896 run_lib.py:146] step: 1103100, eval_loss: 3.31088e-02
I0213 00:48:43.625328 22542570456896 run_lib.py:133] step: 1103150, training_loss: 2.95942e-02
I0213 00:49:01.068781 22542570456896 run_lib.py:133] step: 1103200, training_loss: 2.40332e-02
I0213 00:49:01.227425 22542570456896 run_lib.py:146] step: 1103200, eval_loss: 2.63830e-02
I0213 00:49:18.857089 22542570456896 run_lib.py:133] step: 1103250, training_loss: 2.48903e-02
I0213 00:49:36.295972 22542570456896 run_lib.py:133] step: 1103300, training_loss: 2.90757e-02
I0213 00:49:36.451267 22542570456896 run_lib.py:146] step: 1103300, eval_loss: 3.15325e-02
I0213 00:49:53.930142 22542570456896 run_lib.py:133] step: 1103350, training_loss: 2.34612e-02
I0213 00:50:11.574867 22542570456896 run_lib.py:133] step: 1103400, training_loss: 2.92083e-02
I0213 00:50:11.733193 22542570456896 run_lib.py:146] step: 1103400, eval_loss: 3.21150e-02
I0213 00:50:29.215636 22542570456896 run_lib.py:133] step: 1103450, training_loss: 2.87533e-02
I0213 00:50:46.661580 22542570456896 run_lib.py:133] step: 1103500, training_loss: 2.78530e-02
I0213 00:50:46.823470 22542570456896 run_lib.py:146] step: 1103500, eval_loss: 2.89972e-02
I0213 00:51:04.262830 22542570456896 run_lib.py:133] step: 1103550, training_loss: 2.71941e-02
I0213 00:51:21.886477 22542570456896 run_lib.py:133] step: 1103600, training_loss: 2.73754e-02
I0213 00:51:22.042428 22542570456896 run_lib.py:146] step: 1103600, eval_loss: 3.47031e-02
I0213 00:51:39.474883 22542570456896 run_lib.py:133] step: 1103650, training_loss: 2.28089e-02
I0213 00:51:57.045241 22542570456896 run_lib.py:133] step: 1103700, training_loss: 2.78311e-02
I0213 00:51:57.209564 22542570456896 run_lib.py:146] step: 1103700, eval_loss: 2.95838e-02
I0213 00:52:14.680737 22542570456896 run_lib.py:133] step: 1103750, training_loss: 2.50570e-02
I0213 00:52:32.128634 22542570456896 run_lib.py:133] step: 1103800, training_loss: 2.20089e-02
I0213 00:52:32.292834 22542570456896 run_lib.py:146] step: 1103800, eval_loss: 3.28534e-02
I0213 00:52:49.946660 22542570456896 run_lib.py:133] step: 1103850, training_loss: 2.53353e-02
I0213 00:53:07.463842 22542570456896 run_lib.py:133] step: 1103900, training_loss: 2.43517e-02
I0213 00:53:07.622617 22542570456896 run_lib.py:146] step: 1103900, eval_loss: 3.25213e-02
I0213 00:53:25.058995 22542570456896 run_lib.py:133] step: 1103950, training_loss: 2.65029e-02
I0213 00:53:42.547012 22542570456896 run_lib.py:133] step: 1104000, training_loss: 2.40458e-02
I0213 00:53:42.703681 22542570456896 run_lib.py:146] step: 1104000, eval_loss: 2.74879e-02
I0213 00:54:00.391683 22542570456896 run_lib.py:133] step: 1104050, training_loss: 2.61480e-02
I0213 00:54:17.813382 22542570456896 run_lib.py:133] step: 1104100, training_loss: 2.90581e-02
I0213 00:54:17.969278 22542570456896 run_lib.py:146] step: 1104100, eval_loss: 2.58753e-02
I0213 00:54:35.465655 22542570456896 run_lib.py:133] step: 1104150, training_loss: 2.84409e-02
I0213 00:54:52.820969 22542570456896 run_lib.py:133] step: 1104200, training_loss: 3.13901e-02
I0213 00:54:52.983680 22542570456896 run_lib.py:146] step: 1104200, eval_loss: 2.81091e-02
I0213 00:55:10.559175 22542570456896 run_lib.py:133] step: 1104250, training_loss: 2.66592e-02
I0213 00:55:27.986897 22542570456896 run_lib.py:133] step: 1104300, training_loss: 3.36758e-02
I0213 00:55:28.142506 22542570456896 run_lib.py:146] step: 1104300, eval_loss: 3.00956e-02
I0213 00:55:45.506386 22542570456896 run_lib.py:133] step: 1104350, training_loss: 2.69985e-02
I0213 00:56:03.032962 22542570456896 run_lib.py:133] step: 1104400, training_loss: 3.47195e-02
I0213 00:56:03.187199 22542570456896 run_lib.py:146] step: 1104400, eval_loss: 2.90381e-02
I0213 00:56:20.579785 22542570456896 run_lib.py:133] step: 1104450, training_loss: 2.40117e-02
I0213 00:56:38.169056 22542570456896 run_lib.py:133] step: 1104500, training_loss: 2.40540e-02
I0213 00:56:38.322796 22542570456896 run_lib.py:146] step: 1104500, eval_loss: 3.78137e-02
I0213 00:56:55.815881 22542570456896 run_lib.py:133] step: 1104550, training_loss: 2.35456e-02
I0213 00:57:13.282476 22542570456896 run_lib.py:133] step: 1104600, training_loss: 2.66700e-02
I0213 00:57:13.443477 22542570456896 run_lib.py:146] step: 1104600, eval_loss: 2.35304e-02
I0213 00:57:31.100041 22542570456896 run_lib.py:133] step: 1104650, training_loss: 2.84947e-02
I0213 00:57:48.519254 22542570456896 run_lib.py:133] step: 1104700, training_loss: 3.28264e-02
I0213 00:57:48.674591 22542570456896 run_lib.py:146] step: 1104700, eval_loss: 3.36826e-02
I0213 00:58:06.137709 22542570456896 run_lib.py:133] step: 1104750, training_loss: 2.43394e-02
I0213 00:58:23.785240 22542570456896 run_lib.py:133] step: 1104800, training_loss: 2.48644e-02
I0213 00:58:23.942286 22542570456896 run_lib.py:146] step: 1104800, eval_loss: 2.51760e-02
I0213 00:58:41.451175 22542570456896 run_lib.py:133] step: 1104850, training_loss: 2.41201e-02
I0213 00:58:58.906092 22542570456896 run_lib.py:133] step: 1104900, training_loss: 3.09306e-02
I0213 00:58:59.256538 22542570456896 run_lib.py:146] step: 1104900, eval_loss: 2.20033e-02
I0213 00:59:16.678102 22542570456896 run_lib.py:133] step: 1104950, training_loss: 2.76369e-02
I0213 00:59:34.135890 22542570456896 run_lib.py:133] step: 1105000, training_loss: 2.04635e-02
I0213 00:59:34.298480 22542570456896 run_lib.py:146] step: 1105000, eval_loss: 3.07869e-02
I0213 00:59:51.741662 22542570456896 run_lib.py:133] step: 1105050, training_loss: 2.67330e-02
I0213 01:00:09.209991 22542570456896 run_lib.py:133] step: 1105100, training_loss: 2.46382e-02
I0213 01:00:09.403531 22542570456896 run_lib.py:146] step: 1105100, eval_loss: 3.02468e-02
I0213 01:00:27.078231 22542570456896 run_lib.py:133] step: 1105150, training_loss: 2.23968e-02
I0213 01:00:44.621695 22542570456896 run_lib.py:133] step: 1105200, training_loss: 2.21995e-02
I0213 01:00:44.781687 22542570456896 run_lib.py:146] step: 1105200, eval_loss: 2.16877e-02
I0213 01:01:02.241738 22542570456896 run_lib.py:133] step: 1105250, training_loss: 2.53130e-02
I0213 01:01:19.657789 22542570456896 run_lib.py:133] step: 1105300, training_loss: 2.73213e-02
I0213 01:01:19.814661 22542570456896 run_lib.py:146] step: 1105300, eval_loss: 2.55849e-02
I0213 01:01:37.423051 22542570456896 run_lib.py:133] step: 1105350, training_loss: 2.50209e-02
I0213 01:01:55.005243 22542570456896 run_lib.py:133] step: 1105400, training_loss: 3.19066e-02
I0213 01:01:55.159206 22542570456896 run_lib.py:146] step: 1105400, eval_loss: 3.14992e-02
I0213 01:02:12.718637 22542570456896 run_lib.py:133] step: 1105450, training_loss: 2.03758e-02
I0213 01:02:30.156773 22542570456896 run_lib.py:133] step: 1105500, training_loss: 2.40243e-02
I0213 01:02:30.314483 22542570456896 run_lib.py:146] step: 1105500, eval_loss: 2.29971e-02
I0213 01:02:47.953366 22542570456896 run_lib.py:133] step: 1105550, training_loss: 2.38064e-02
I0213 01:03:05.396463 22542570456896 run_lib.py:133] step: 1105600, training_loss: 3.17635e-02
I0213 01:03:05.561760 22542570456896 run_lib.py:146] step: 1105600, eval_loss: 3.13073e-02
I0213 01:03:23.183518 22542570456896 run_lib.py:133] step: 1105650, training_loss: 2.75475e-02
I0213 01:03:40.687514 22542570456896 run_lib.py:133] step: 1105700, training_loss: 2.59238e-02
I0213 01:03:40.847059 22542570456896 run_lib.py:146] step: 1105700, eval_loss: 3.22572e-02
I0213 01:03:58.469220 22542570456896 run_lib.py:133] step: 1105750, training_loss: 2.12403e-02
I0213 01:04:15.912670 22542570456896 run_lib.py:133] step: 1105800, training_loss: 2.97154e-02
I0213 01:04:16.069474 22542570456896 run_lib.py:146] step: 1105800, eval_loss: 2.93074e-02
I0213 01:04:33.521494 22542570456896 run_lib.py:133] step: 1105850, training_loss: 2.18005e-02
I0213 01:04:51.139737 22542570456896 run_lib.py:133] step: 1105900, training_loss: 3.15311e-02
I0213 01:04:51.294584 22542570456896 run_lib.py:146] step: 1105900, eval_loss: 2.47492e-02
I0213 01:05:08.784940 22542570456896 run_lib.py:133] step: 1105950, training_loss: 2.61858e-02
I0213 01:05:26.423102 22542570456896 run_lib.py:133] step: 1106000, training_loss: 2.45338e-02
I0213 01:05:26.581536 22542570456896 run_lib.py:146] step: 1106000, eval_loss: 3.13504e-02
I0213 01:05:44.014740 22542570456896 run_lib.py:133] step: 1106050, training_loss: 2.26537e-02
I0213 01:06:01.467873 22542570456896 run_lib.py:133] step: 1106100, training_loss: 2.64419e-02
I0213 01:06:01.623853 22542570456896 run_lib.py:146] step: 1106100, eval_loss: 2.24708e-02
I0213 01:06:19.235073 22542570456896 run_lib.py:133] step: 1106150, training_loss: 3.78178e-02
I0213 01:06:36.735395 22542570456896 run_lib.py:133] step: 1106200, training_loss: 3.12542e-02
I0213 01:06:36.893956 22542570456896 run_lib.py:146] step: 1106200, eval_loss: 2.47540e-02
I0213 01:06:54.373880 22542570456896 run_lib.py:133] step: 1106250, training_loss: 2.04517e-02
I0213 01:07:11.820886 22542570456896 run_lib.py:133] step: 1106300, training_loss: 2.21255e-02
I0213 01:07:11.978482 22542570456896 run_lib.py:146] step: 1106300, eval_loss: 3.38040e-02
I0213 01:07:29.651104 22542570456896 run_lib.py:133] step: 1106350, training_loss: 3.69799e-02
I0213 01:07:47.110523 22542570456896 run_lib.py:133] step: 1106400, training_loss: 2.92734e-02
I0213 01:07:47.263623 22542570456896 run_lib.py:146] step: 1106400, eval_loss: 2.83480e-02
I0213 01:08:04.796154 22542570456896 run_lib.py:133] step: 1106450, training_loss: 2.39637e-02
I0213 01:08:22.252214 22542570456896 run_lib.py:133] step: 1106500, training_loss: 3.37168e-02
I0213 01:08:22.436830 22542570456896 run_lib.py:146] step: 1106500, eval_loss: 3.21645e-02
I0213 01:08:39.929136 22542570456896 run_lib.py:133] step: 1106550, training_loss: 2.30925e-02
I0213 01:08:57.450683 22542570456896 run_lib.py:133] step: 1106600, training_loss: 3.18271e-02
I0213 01:08:57.607642 22542570456896 run_lib.py:146] step: 1106600, eval_loss: 2.69098e-02
I0213 01:09:15.252909 22542570456896 run_lib.py:133] step: 1106650, training_loss: 3.16613e-02
I0213 01:09:32.752892 22542570456896 run_lib.py:133] step: 1106700, training_loss: 3.39310e-02
I0213 01:09:32.908292 22542570456896 run_lib.py:146] step: 1106700, eval_loss: 3.47405e-02
I0213 01:09:50.368835 22542570456896 run_lib.py:133] step: 1106750, training_loss: 2.85535e-02
I0213 01:10:07.926433 22542570456896 run_lib.py:133] step: 1106800, training_loss: 2.17611e-02
I0213 01:10:08.089146 22542570456896 run_lib.py:146] step: 1106800, eval_loss: 2.68382e-02
I0213 01:10:25.794182 22542570456896 run_lib.py:133] step: 1106850, training_loss: 3.41924e-02
I0213 01:10:43.229294 22542570456896 run_lib.py:133] step: 1106900, training_loss: 2.90477e-02
I0213 01:10:43.385603 22542570456896 run_lib.py:146] step: 1106900, eval_loss: 2.88789e-02
I0213 01:11:00.986979 22542570456896 run_lib.py:133] step: 1106950, training_loss: 2.87466e-02
I0213 01:11:18.462308 22542570456896 run_lib.py:133] step: 1107000, training_loss: 2.72685e-02
I0213 01:11:18.622736 22542570456896 run_lib.py:146] step: 1107000, eval_loss: 2.89379e-02
I0213 01:11:36.262749 22542570456896 run_lib.py:133] step: 1107050, training_loss: 2.93869e-02
I0213 01:11:53.773190 22542570456896 run_lib.py:133] step: 1107100, training_loss: 2.89400e-02
I0213 01:11:53.931697 22542570456896 run_lib.py:146] step: 1107100, eval_loss: 2.70946e-02
I0213 01:12:11.579178 22542570456896 run_lib.py:133] step: 1107150, training_loss: 2.96051e-02
I0213 01:12:29.011618 22542570456896 run_lib.py:133] step: 1107200, training_loss: 2.72285e-02
I0213 01:12:29.168694 22542570456896 run_lib.py:146] step: 1107200, eval_loss: 3.29684e-02
I0213 01:12:46.613967 22542570456896 run_lib.py:133] step: 1107250, training_loss: 3.12594e-02
I0213 01:13:04.201879 22542570456896 run_lib.py:133] step: 1107300, training_loss: 2.89647e-02
I0213 01:13:04.354522 22542570456896 run_lib.py:146] step: 1107300, eval_loss: 2.42454e-02
I0213 01:13:21.801141 22542570456896 run_lib.py:133] step: 1107350, training_loss: 3.19046e-02
I0213 01:13:39.331795 22542570456896 run_lib.py:133] step: 1107400, training_loss: 3.03444e-02
I0213 01:13:39.510450 22542570456896 run_lib.py:146] step: 1107400, eval_loss: 2.69193e-02
I0213 01:13:57.199986 22542570456896 run_lib.py:133] step: 1107450, training_loss: 2.74275e-02
I0213 01:14:14.809696 22542570456896 run_lib.py:133] step: 1107500, training_loss: 2.50071e-02
I0213 01:14:14.968821 22542570456896 run_lib.py:146] step: 1107500, eval_loss: 3.14182e-02
I0213 01:14:32.415921 22542570456896 run_lib.py:133] step: 1107550, training_loss: 3.02147e-02
I0213 01:14:49.881204 22542570456896 run_lib.py:133] step: 1107600, training_loss: 2.54413e-02
I0213 01:14:50.049402 22542570456896 run_lib.py:146] step: 1107600, eval_loss: 2.53895e-02
I0213 01:15:07.526271 22542570456896 run_lib.py:133] step: 1107650, training_loss: 2.21688e-02
I0213 01:15:25.210485 22542570456896 run_lib.py:133] step: 1107700, training_loss: 2.25561e-02
I0213 01:15:25.367758 22542570456896 run_lib.py:146] step: 1107700, eval_loss: 2.71489e-02
I0213 01:15:42.856767 22542570456896 run_lib.py:133] step: 1107750, training_loss: 2.55031e-02
I0213 01:16:00.301642 22542570456896 run_lib.py:133] step: 1107800, training_loss: 3.38102e-02
I0213 01:16:00.462384 22542570456896 run_lib.py:146] step: 1107800, eval_loss: 2.48289e-02
I0213 01:16:17.903338 22542570456896 run_lib.py:133] step: 1107850, training_loss: 2.60396e-02
I0213 01:16:35.543060 22542570456896 run_lib.py:133] step: 1107900, training_loss: 2.23571e-02
I0213 01:16:35.715386 22542570456896 run_lib.py:146] step: 1107900, eval_loss: 2.32769e-02
I0213 01:16:53.197254 22542570456896 run_lib.py:133] step: 1107950, training_loss: 3.05779e-02
I0213 01:17:10.785064 22542570456896 run_lib.py:133] step: 1108000, training_loss: 2.21145e-02
I0213 01:17:10.941900 22542570456896 run_lib.py:146] step: 1108000, eval_loss: 2.57868e-02
I0213 01:17:28.464938 22542570456896 run_lib.py:133] step: 1108050, training_loss: 2.74738e-02
I0213 01:17:45.881387 22542570456896 run_lib.py:133] step: 1108100, training_loss: 2.21881e-02
I0213 01:17:46.042526 22542570456896 run_lib.py:146] step: 1108100, eval_loss: 2.47812e-02
I0213 01:18:03.659550 22542570456896 run_lib.py:133] step: 1108150, training_loss: 3.19671e-02
I0213 01:18:21.302297 22542570456896 run_lib.py:133] step: 1108200, training_loss: 2.41785e-02
I0213 01:18:21.468485 22542570456896 run_lib.py:146] step: 1108200, eval_loss: 3.01861e-02
I0213 01:18:38.931424 22542570456896 run_lib.py:133] step: 1108250, training_loss: 2.48722e-02
I0213 01:18:56.390885 22542570456896 run_lib.py:133] step: 1108300, training_loss: 2.32631e-02
I0213 01:18:56.544565 22542570456896 run_lib.py:146] step: 1108300, eval_loss: 2.45552e-02
I0213 01:19:14.113675 22542570456896 run_lib.py:133] step: 1108350, training_loss: 2.53738e-02
I0213 01:19:31.563242 22542570456896 run_lib.py:133] step: 1108400, training_loss: 2.64936e-02
I0213 01:19:31.746426 22542570456896 run_lib.py:146] step: 1108400, eval_loss: 2.93671e-02
I0213 01:19:49.407751 22542570456896 run_lib.py:133] step: 1108450, training_loss: 3.24164e-02
I0213 01:20:06.917203 22542570456896 run_lib.py:133] step: 1108500, training_loss: 2.74136e-02
I0213 01:20:07.073714 22542570456896 run_lib.py:146] step: 1108500, eval_loss: 3.17728e-02
I0213 01:20:24.707568 22542570456896 run_lib.py:133] step: 1108550, training_loss: 2.58337e-02
I0213 01:20:42.133701 22542570456896 run_lib.py:133] step: 1108600, training_loss: 2.45161e-02
I0213 01:20:42.290264 22542570456896 run_lib.py:146] step: 1108600, eval_loss: 3.43984e-02
I0213 01:20:59.743781 22542570456896 run_lib.py:133] step: 1108650, training_loss: 2.22566e-02
I0213 01:21:17.362900 22542570456896 run_lib.py:133] step: 1108700, training_loss: 2.85256e-02
I0213 01:21:17.518168 22542570456896 run_lib.py:146] step: 1108700, eval_loss: 3.56643e-02
I0213 01:21:35.044312 22542570456896 run_lib.py:133] step: 1108750, training_loss: 2.82726e-02
I0213 01:21:52.677452 22542570456896 run_lib.py:133] step: 1108800, training_loss: 2.42137e-02
I0213 01:21:52.833415 22542570456896 run_lib.py:146] step: 1108800, eval_loss: 2.76744e-02
I0213 01:22:10.248436 22542570456896 run_lib.py:133] step: 1108850, training_loss: 2.15233e-02
I0213 01:22:27.711151 22542570456896 run_lib.py:133] step: 1108900, training_loss: 2.95152e-02
I0213 01:22:27.873691 22542570456896 run_lib.py:146] step: 1108900, eval_loss: 3.07289e-02
I0213 01:22:45.506698 22542570456896 run_lib.py:133] step: 1108950, training_loss: 3.00327e-02
I0213 01:23:03.006781 22542570456896 run_lib.py:133] step: 1109000, training_loss: 2.37607e-02
I0213 01:23:03.167610 22542570456896 run_lib.py:146] step: 1109000, eval_loss: 2.96716e-02
I0213 01:23:20.594724 22542570456896 run_lib.py:133] step: 1109050, training_loss: 2.54176e-02
I0213 01:23:38.233669 22542570456896 run_lib.py:133] step: 1109100, training_loss: 2.89783e-02
I0213 01:23:38.392463 22542570456896 run_lib.py:146] step: 1109100, eval_loss: 2.37397e-02
I0213 01:23:55.874115 22542570456896 run_lib.py:133] step: 1109150, training_loss: 2.33481e-02
I0213 01:24:13.328327 22542570456896 run_lib.py:133] step: 1109200, training_loss: 2.93884e-02
I0213 01:24:13.482503 22542570456896 run_lib.py:146] step: 1109200, eval_loss: 3.19114e-02
I0213 01:24:31.013926 22542570456896 run_lib.py:133] step: 1109250, training_loss: 2.54720e-02
I0213 01:24:48.521823 22542570456896 run_lib.py:133] step: 1109300, training_loss: 3.21314e-02
I0213 01:24:48.694574 22542570456896 run_lib.py:146] step: 1109300, eval_loss: 2.64437e-02
I0213 01:25:06.189952 22542570456896 run_lib.py:133] step: 1109350, training_loss: 2.80119e-02
I0213 01:25:23.666001 22542570456896 run_lib.py:133] step: 1109400, training_loss: 4.17023e-02
I0213 01:25:23.829966 22542570456896 run_lib.py:146] step: 1109400, eval_loss: 3.36963e-02
I0213 01:25:41.434046 22542570456896 run_lib.py:133] step: 1109450, training_loss: 2.14799e-02
I0213 01:25:58.969479 22542570456896 run_lib.py:133] step: 1109500, training_loss: 2.67452e-02
I0213 01:25:59.127409 22542570456896 run_lib.py:146] step: 1109500, eval_loss: 2.94330e-02
I0213 01:26:16.604881 22542570456896 run_lib.py:133] step: 1109550, training_loss: 3.56292e-02
I0213 01:26:34.119813 22542570456896 run_lib.py:133] step: 1109600, training_loss: 2.53847e-02
I0213 01:26:34.276721 22542570456896 run_lib.py:146] step: 1109600, eval_loss: 2.72588e-02
I0213 01:26:51.947487 22542570456896 run_lib.py:133] step: 1109650, training_loss: 2.96742e-02
I0213 01:27:09.361747 22542570456896 run_lib.py:133] step: 1109700, training_loss: 2.38370e-02
I0213 01:27:09.515372 22542570456896 run_lib.py:146] step: 1109700, eval_loss: 2.66806e-02
I0213 01:27:27.129894 22542570456896 run_lib.py:133] step: 1109750, training_loss: 2.35441e-02
I0213 01:27:44.594665 22542570456896 run_lib.py:133] step: 1109800, training_loss: 2.73553e-02
I0213 01:27:44.770455 22542570456896 run_lib.py:146] step: 1109800, eval_loss: 2.53403e-02
I0213 01:28:02.491523 22542570456896 run_lib.py:133] step: 1109850, training_loss: 2.75078e-02
I0213 01:28:19.963706 22542570456896 run_lib.py:133] step: 1109900, training_loss: 2.59270e-02
I0213 01:28:20.124431 22542570456896 run_lib.py:146] step: 1109900, eval_loss: 2.72930e-02
I0213 01:28:37.765952 22542570456896 run_lib.py:133] step: 1109950, training_loss: 2.57572e-02
I0213 01:28:55.203514 22542570456896 run_lib.py:133] step: 1110000, training_loss: 2.94771e-02
I0213 01:28:55.937089 22542570456896 run_lib.py:146] step: 1110000, eval_loss: 2.46334e-02
I0213 01:29:16.036372 22542570456896 run_lib.py:133] step: 1110050, training_loss: 2.85886e-02
I0213 01:29:33.649784 22542570456896 run_lib.py:133] step: 1110100, training_loss: 3.03946e-02
I0213 01:29:33.817349 22542570456896 run_lib.py:146] step: 1110100, eval_loss: 2.55747e-02
I0213 01:29:51.305211 22542570456896 run_lib.py:133] step: 1110150, training_loss: 2.16343e-02
I0213 01:30:08.867872 22542570456896 run_lib.py:133] step: 1110200, training_loss: 2.55329e-02
I0213 01:30:09.020237 22542570456896 run_lib.py:146] step: 1110200, eval_loss: 2.87494e-02
I0213 01:30:26.464478 22542570456896 run_lib.py:133] step: 1110250, training_loss: 2.34170e-02
I0213 01:30:43.907582 22542570456896 run_lib.py:133] step: 1110300, training_loss: 3.01584e-02
I0213 01:30:44.063471 22542570456896 run_lib.py:146] step: 1110300, eval_loss: 3.20803e-02
I0213 01:31:01.680703 22542570456896 run_lib.py:133] step: 1110350, training_loss: 2.47902e-02
I0213 01:31:19.323333 22542570456896 run_lib.py:133] step: 1110400, training_loss: 2.26972e-02
I0213 01:31:19.490644 22542570456896 run_lib.py:146] step: 1110400, eval_loss: 2.82073e-02
I0213 01:31:36.953720 22542570456896 run_lib.py:133] step: 1110450, training_loss: 2.43752e-02
I0213 01:31:54.411871 22542570456896 run_lib.py:133] step: 1110500, training_loss: 2.41833e-02
I0213 01:31:54.577377 22542570456896 run_lib.py:146] step: 1110500, eval_loss: 3.08988e-02
I0213 01:32:12.189618 22542570456896 run_lib.py:133] step: 1110550, training_loss: 3.00164e-02
I0213 01:32:29.603564 22542570456896 run_lib.py:133] step: 1110600, training_loss: 3.51364e-02
I0213 01:32:29.759469 22542570456896 run_lib.py:146] step: 1110600, eval_loss: 3.07268e-02
I0213 01:32:47.365796 22542570456896 run_lib.py:133] step: 1110650, training_loss: 3.01203e-02
I0213 01:33:04.887413 22542570456896 run_lib.py:133] step: 1110700, training_loss: 2.43343e-02
I0213 01:33:05.050434 22542570456896 run_lib.py:146] step: 1110700, eval_loss: 3.27326e-02
I0213 01:33:22.693615 22542570456896 run_lib.py:133] step: 1110750, training_loss: 3.01210e-02
I0213 01:33:40.151453 22542570456896 run_lib.py:133] step: 1110800, training_loss: 2.56570e-02
I0213 01:33:40.308395 22542570456896 run_lib.py:146] step: 1110800, eval_loss: 3.07859e-02
I0213 01:33:57.715423 22542570456896 run_lib.py:133] step: 1110850, training_loss: 2.91593e-02
I0213 01:34:15.336063 22542570456896 run_lib.py:133] step: 1110900, training_loss: 3.03834e-02
I0213 01:34:15.511493 22542570456896 run_lib.py:146] step: 1110900, eval_loss: 2.57338e-02
I0213 01:34:33.017544 22542570456896 run_lib.py:133] step: 1110950, training_loss: 2.67768e-02
I0213 01:34:50.676993 22542570456896 run_lib.py:133] step: 1111000, training_loss: 3.04395e-02
I0213 01:34:50.833665 22542570456896 run_lib.py:146] step: 1111000, eval_loss: 3.22367e-02
I0213 01:35:08.305292 22542570456896 run_lib.py:133] step: 1111050, training_loss: 2.34017e-02
I0213 01:35:25.758118 22542570456896 run_lib.py:133] step: 1111100, training_loss: 2.00434e-02
I0213 01:35:25.920455 22542570456896 run_lib.py:146] step: 1111100, eval_loss: 2.91214e-02
I0213 01:35:43.585971 22542570456896 run_lib.py:133] step: 1111150, training_loss: 3.01336e-02
I0213 01:36:01.091326 22542570456896 run_lib.py:133] step: 1111200, training_loss: 2.29639e-02
I0213 01:36:01.246743 22542570456896 run_lib.py:146] step: 1111200, eval_loss: 2.92367e-02
I0213 01:36:18.724544 22542570456896 run_lib.py:133] step: 1111250, training_loss: 2.88361e-02
I0213 01:36:36.387533 22542570456896 run_lib.py:133] step: 1111300, training_loss: 2.89714e-02
I0213 01:36:36.550463 22542570456896 run_lib.py:146] step: 1111300, eval_loss: 3.05476e-02
I0213 01:36:54.005084 22542570456896 run_lib.py:133] step: 1111350, training_loss: 3.19500e-02
I0213 01:37:11.441201 22542570456896 run_lib.py:133] step: 1111400, training_loss: 2.64940e-02
I0213 01:37:11.598700 22542570456896 run_lib.py:146] step: 1111400, eval_loss: 2.70339e-02
I0213 01:37:29.113968 22542570456896 run_lib.py:133] step: 1111450, training_loss: 2.94891e-02
I0213 01:37:46.662932 22542570456896 run_lib.py:133] step: 1111500, training_loss: 2.45344e-02
I0213 01:37:46.821210 22542570456896 run_lib.py:146] step: 1111500, eval_loss: 2.72176e-02
I0213 01:38:04.279844 22542570456896 run_lib.py:133] step: 1111550, training_loss: 2.88936e-02
I0213 01:38:21.710966 22542570456896 run_lib.py:133] step: 1111600, training_loss: 3.46897e-02
I0213 01:38:21.867522 22542570456896 run_lib.py:146] step: 1111600, eval_loss: 2.59588e-02
I0213 01:38:39.513142 22542570456896 run_lib.py:133] step: 1111650, training_loss: 2.74226e-02
I0213 01:38:57.053718 22542570456896 run_lib.py:133] step: 1111700, training_loss: 2.60318e-02
I0213 01:38:57.210490 22542570456896 run_lib.py:146] step: 1111700, eval_loss: 2.77471e-02
I0213 01:39:14.628207 22542570456896 run_lib.py:133] step: 1111750, training_loss: 2.82169e-02
I0213 01:39:32.045696 22542570456896 run_lib.py:133] step: 1111800, training_loss: 2.13418e-02
I0213 01:39:32.211265 22542570456896 run_lib.py:146] step: 1111800, eval_loss: 2.73745e-02
I0213 01:39:49.761090 22542570456896 run_lib.py:133] step: 1111850, training_loss: 2.82634e-02
I0213 01:40:07.136948 22542570456896 run_lib.py:133] step: 1111900, training_loss: 2.46504e-02
I0213 01:40:07.292424 22542570456896 run_lib.py:146] step: 1111900, eval_loss: 3.12823e-02
I0213 01:40:24.827926 22542570456896 run_lib.py:133] step: 1111950, training_loss: 3.11940e-02
I0213 01:40:42.239382 22542570456896 run_lib.py:133] step: 1112000, training_loss: 2.76149e-02
I0213 01:40:42.407176 22542570456896 run_lib.py:146] step: 1112000, eval_loss: 2.26769e-02
I0213 01:40:59.952236 22542570456896 run_lib.py:133] step: 1112050, training_loss: 3.25140e-02
I0213 01:41:17.376534 22542570456896 run_lib.py:133] step: 1112100, training_loss: 2.41947e-02
I0213 01:41:17.528719 22542570456896 run_lib.py:146] step: 1112100, eval_loss: 3.31863e-02
I0213 01:41:35.132037 22542570456896 run_lib.py:133] step: 1112150, training_loss: 3.81322e-02
I0213 01:41:52.602887 22542570456896 run_lib.py:133] step: 1112200, training_loss: 2.98890e-02
I0213 01:41:52.759508 22542570456896 run_lib.py:146] step: 1112200, eval_loss: 2.69155e-02
I0213 01:42:10.214514 22542570456896 run_lib.py:133] step: 1112250, training_loss: 2.30398e-02
I0213 01:42:27.841504 22542570456896 run_lib.py:133] step: 1112300, training_loss: 2.53019e-02
I0213 01:42:28.018370 22542570456896 run_lib.py:146] step: 1112300, eval_loss: 3.29812e-02
I0213 01:42:45.523481 22542570456896 run_lib.py:133] step: 1112350, training_loss: 2.52238e-02
I0213 01:43:03.006995 22542570456896 run_lib.py:133] step: 1112400, training_loss: 2.71827e-02
I0213 01:43:03.164675 22542570456896 run_lib.py:146] step: 1112400, eval_loss: 2.32350e-02
I0213 01:43:20.835784 22542570456896 run_lib.py:133] step: 1112450, training_loss: 2.77024e-02
I0213 01:43:38.303400 22542570456896 run_lib.py:133] step: 1112500, training_loss: 2.90711e-02
I0213 01:43:38.463502 22542570456896 run_lib.py:146] step: 1112500, eval_loss: 2.82853e-02
I0213 01:43:56.063887 22542570456896 run_lib.py:133] step: 1112550, training_loss: 2.39772e-02
I0213 01:44:13.541771 22542570456896 run_lib.py:133] step: 1112600, training_loss: 2.53467e-02
I0213 01:44:13.696413 22542570456896 run_lib.py:146] step: 1112600, eval_loss: 2.65616e-02
I0213 01:44:31.193442 22542570456896 run_lib.py:133] step: 1112650, training_loss: 3.34271e-02
I0213 01:44:48.840004 22542570456896 run_lib.py:133] step: 1112700, training_loss: 2.06360e-02
I0213 01:44:48.997529 22542570456896 run_lib.py:146] step: 1112700, eval_loss: 3.01326e-02
I0213 01:45:06.431281 22542570456896 run_lib.py:133] step: 1112750, training_loss: 2.37381e-02
I0213 01:45:23.871829 22542570456896 run_lib.py:133] step: 1112800, training_loss: 2.54976e-02
I0213 01:45:24.032775 22542570456896 run_lib.py:146] step: 1112800, eval_loss: 2.99592e-02
I0213 01:45:41.506704 22542570456896 run_lib.py:133] step: 1112850, training_loss: 3.23491e-02
I0213 01:45:59.171565 22542570456896 run_lib.py:133] step: 1112900, training_loss: 2.69453e-02
I0213 01:45:59.332371 22542570456896 run_lib.py:146] step: 1112900, eval_loss: 2.53944e-02
I0213 01:46:16.792979 22542570456896 run_lib.py:133] step: 1112950, training_loss: 2.57653e-02
I0213 01:46:34.341882 22542570456896 run_lib.py:133] step: 1113000, training_loss: 2.65768e-02
I0213 01:46:34.497520 22542570456896 run_lib.py:146] step: 1113000, eval_loss: 3.21752e-02
I0213 01:46:51.982304 22542570456896 run_lib.py:133] step: 1113050, training_loss: 2.52981e-02
I0213 01:47:09.448700 22542570456896 run_lib.py:133] step: 1113100, training_loss: 2.68657e-02
I0213 01:47:09.603019 22542570456896 run_lib.py:146] step: 1113100, eval_loss: 2.55984e-02
I0213 01:47:27.232294 22542570456896 run_lib.py:133] step: 1113150, training_loss: 2.51413e-02
I0213 01:47:44.787269 22542570456896 run_lib.py:133] step: 1113200, training_loss: 3.06524e-02
I0213 01:47:44.957455 22542570456896 run_lib.py:146] step: 1113200, eval_loss: 2.83520e-02
I0213 01:48:02.430669 22542570456896 run_lib.py:133] step: 1113250, training_loss: 2.48350e-02
I0213 01:48:19.877932 22542570456896 run_lib.py:133] step: 1113300, training_loss: 2.69746e-02
I0213 01:48:20.037822 22542570456896 run_lib.py:146] step: 1113300, eval_loss: 2.64397e-02
I0213 01:48:37.675516 22542570456896 run_lib.py:133] step: 1113350, training_loss: 2.97226e-02
I0213 01:48:55.114823 22542570456896 run_lib.py:133] step: 1113400, training_loss: 2.79074e-02
I0213 01:48:55.283278 22542570456896 run_lib.py:146] step: 1113400, eval_loss: 3.40392e-02
I0213 01:49:12.998358 22542570456896 run_lib.py:133] step: 1113450, training_loss: 3.13035e-02
I0213 01:49:30.475392 22542570456896 run_lib.py:133] step: 1113500, training_loss: 2.32995e-02
I0213 01:49:30.630237 22542570456896 run_lib.py:146] step: 1113500, eval_loss: 3.42508e-02
I0213 01:49:48.313212 22542570456896 run_lib.py:133] step: 1113550, training_loss: 2.78931e-02
I0213 01:50:05.794371 22542570456896 run_lib.py:133] step: 1113600, training_loss: 2.06197e-02
I0213 01:50:05.954417 22542570456896 run_lib.py:146] step: 1113600, eval_loss: 2.36866e-02
I0213 01:50:23.420269 22542570456896 run_lib.py:133] step: 1113650, training_loss: 2.57240e-02
I0213 01:50:41.028295 22542570456896 run_lib.py:133] step: 1113700, training_loss: 3.07773e-02
I0213 01:50:41.209470 22542570456896 run_lib.py:146] step: 1113700, eval_loss: 3.07733e-02
I0213 01:50:58.713425 22542570456896 run_lib.py:133] step: 1113750, training_loss: 2.44298e-02
I0213 01:51:16.383972 22542570456896 run_lib.py:133] step: 1113800, training_loss: 2.26137e-02
I0213 01:51:16.541661 22542570456896 run_lib.py:146] step: 1113800, eval_loss: 2.93394e-02
I0213 01:51:34.027978 22542570456896 run_lib.py:133] step: 1113850, training_loss: 3.03208e-02
I0213 01:51:51.452151 22542570456896 run_lib.py:133] step: 1113900, training_loss: 2.45495e-02
I0213 01:51:51.605870 22542570456896 run_lib.py:146] step: 1113900, eval_loss: 3.33662e-02
I0213 01:52:09.262806 22542570456896 run_lib.py:133] step: 1113950, training_loss: 2.46511e-02
I0213 01:52:26.768523 22542570456896 run_lib.py:133] step: 1114000, training_loss: 2.47272e-02
I0213 01:52:26.923145 22542570456896 run_lib.py:146] step: 1114000, eval_loss: 3.31110e-02
I0213 01:52:44.365220 22542570456896 run_lib.py:133] step: 1114050, training_loss: 2.50503e-02
I0213 01:53:01.800050 22542570456896 run_lib.py:133] step: 1114100, training_loss: 2.99804e-02
I0213 01:53:01.954322 22542570456896 run_lib.py:146] step: 1114100, eval_loss: 2.55872e-02
I0213 01:53:19.215641 22542570456896 run_lib.py:133] step: 1114150, training_loss: 2.74766e-02
I0213 01:53:36.457399 22542570456896 run_lib.py:133] step: 1114200, training_loss: 2.59428e-02
I0213 01:53:36.750514 22542570456896 run_lib.py:146] step: 1114200, eval_loss: 3.02765e-02
I0213 01:53:54.022477 22542570456896 run_lib.py:133] step: 1114250, training_loss: 2.00061e-02
I0213 01:54:11.315759 22542570456896 run_lib.py:133] step: 1114300, training_loss: 2.75268e-02
I0213 01:54:11.470535 22542570456896 run_lib.py:146] step: 1114300, eval_loss: 2.53228e-02
I0213 01:54:28.703962 22542570456896 run_lib.py:133] step: 1114350, training_loss: 2.57017e-02
I0213 01:54:45.921674 22542570456896 run_lib.py:133] step: 1114400, training_loss: 2.56904e-02
I0213 01:54:46.075276 22542570456896 run_lib.py:146] step: 1114400, eval_loss: 2.29030e-02
I0213 01:55:03.499629 22542570456896 run_lib.py:133] step: 1114450, training_loss: 2.64976e-02
I0213 01:55:20.844013 22542570456896 run_lib.py:133] step: 1114500, training_loss: 2.42847e-02
I0213 01:55:20.994123 22542570456896 run_lib.py:146] step: 1114500, eval_loss: 3.07885e-02
I0213 01:55:38.293164 22542570456896 run_lib.py:133] step: 1114550, training_loss: 3.86101e-02
I0213 01:55:55.594783 22542570456896 run_lib.py:133] step: 1114600, training_loss: 2.32047e-02
I0213 01:55:55.761545 22542570456896 run_lib.py:146] step: 1114600, eval_loss: 2.64210e-02
I0213 01:56:13.259930 22542570456896 run_lib.py:133] step: 1114650, training_loss: 2.67864e-02
I0213 01:56:30.628319 22542570456896 run_lib.py:133] step: 1114700, training_loss: 2.87757e-02
I0213 01:56:30.783496 22542570456896 run_lib.py:146] step: 1114700, eval_loss: 2.02188e-02
I0213 01:56:48.024326 22542570456896 run_lib.py:133] step: 1114750, training_loss: 2.81838e-02
I0213 01:57:05.260338 22542570456896 run_lib.py:133] step: 1114800, training_loss: 2.35290e-02
I0213 01:57:05.414268 22542570456896 run_lib.py:146] step: 1114800, eval_loss: 2.80453e-02
I0213 01:57:22.808909 22542570456896 run_lib.py:133] step: 1114850, training_loss: 3.51920e-02
I0213 01:57:40.122528 22542570456896 run_lib.py:133] step: 1114900, training_loss: 2.83218e-02
I0213 01:57:40.276613 22542570456896 run_lib.py:146] step: 1114900, eval_loss: 3.16249e-02
I0213 01:57:57.744402 22542570456896 run_lib.py:133] step: 1114950, training_loss: 3.29536e-02
I0213 01:58:15.007668 22542570456896 run_lib.py:133] step: 1115000, training_loss: 2.66470e-02
I0213 01:58:15.158332 22542570456896 run_lib.py:146] step: 1115000, eval_loss: 2.95840e-02
I0213 01:58:32.511467 22542570456896 run_lib.py:133] step: 1115050, training_loss: 2.28446e-02
I0213 01:58:49.768755 22542570456896 run_lib.py:133] step: 1115100, training_loss: 2.46243e-02
I0213 01:58:49.932648 22542570456896 run_lib.py:146] step: 1115100, eval_loss: 2.41987e-02
I0213 01:59:07.190732 22542570456896 run_lib.py:133] step: 1115150, training_loss: 2.46537e-02
I0213 01:59:24.654546 22542570456896 run_lib.py:133] step: 1115200, training_loss: 2.13503e-02
I0213 01:59:24.808223 22542570456896 run_lib.py:146] step: 1115200, eval_loss: 2.23470e-02
I0213 01:59:42.055438 22542570456896 run_lib.py:133] step: 1115250, training_loss: 2.79186e-02
I0213 01:59:59.413708 22542570456896 run_lib.py:133] step: 1115300, training_loss: 2.88818e-02
I0213 01:59:59.567017 22542570456896 run_lib.py:146] step: 1115300, eval_loss: 2.28693e-02
I0213 02:00:16.826515 22542570456896 run_lib.py:133] step: 1115350, training_loss: 2.84412e-02
I0213 02:00:34.107065 22542570456896 run_lib.py:133] step: 1115400, training_loss: 2.35305e-02
I0213 02:00:34.258878 22542570456896 run_lib.py:146] step: 1115400, eval_loss: 3.09445e-02
I0213 02:00:51.794477 22542570456896 run_lib.py:133] step: 1115450, training_loss: 2.48110e-02
I0213 02:01:09.069792 22542570456896 run_lib.py:133] step: 1115500, training_loss: 3.25817e-02
I0213 02:01:09.222362 22542570456896 run_lib.py:146] step: 1115500, eval_loss: 3.23209e-02
I0213 02:01:26.462562 22542570456896 run_lib.py:133] step: 1115550, training_loss: 3.32647e-02
I0213 02:01:43.749595 22542570456896 run_lib.py:133] step: 1115600, training_loss: 3.14902e-02
I0213 02:01:43.904972 22542570456896 run_lib.py:146] step: 1115600, eval_loss: 2.68292e-02
I0213 02:02:01.285450 22542570456896 run_lib.py:133] step: 1115650, training_loss: 2.44069e-02
I0213 02:02:18.577862 22542570456896 run_lib.py:133] step: 1115700, training_loss: 3.63063e-02
I0213 02:02:18.733504 22542570456896 run_lib.py:146] step: 1115700, eval_loss: 2.81419e-02
I0213 02:02:36.096439 22542570456896 run_lib.py:133] step: 1115750, training_loss: 2.88503e-02
I0213 02:02:53.335868 22542570456896 run_lib.py:133] step: 1115800, training_loss: 3.44782e-02
I0213 02:02:53.489445 22542570456896 run_lib.py:146] step: 1115800, eval_loss: 2.96658e-02
I0213 02:03:10.730475 22542570456896 run_lib.py:133] step: 1115850, training_loss: 1.90835e-02
I0213 02:03:27.956222 22542570456896 run_lib.py:133] step: 1115900, training_loss: 2.82679e-02
I0213 02:03:28.106285 22542570456896 run_lib.py:146] step: 1115900, eval_loss: 2.67547e-02
I0213 02:03:45.499332 22542570456896 run_lib.py:133] step: 1115950, training_loss: 3.00152e-02
I0213 02:04:02.850010 22542570456896 run_lib.py:133] step: 1116000, training_loss: 2.59683e-02
I0213 02:04:03.017539 22542570456896 run_lib.py:146] step: 1116000, eval_loss: 2.80961e-02
I0213 02:04:20.260540 22542570456896 run_lib.py:133] step: 1116050, training_loss: 3.21419e-02
I0213 02:04:37.529319 22542570456896 run_lib.py:133] step: 1116100, training_loss: 2.18075e-02
I0213 02:04:37.686335 22542570456896 run_lib.py:146] step: 1116100, eval_loss: 3.51840e-02
I0213 02:04:55.117363 22542570456896 run_lib.py:133] step: 1116150, training_loss: 2.57146e-02
I0213 02:05:12.352601 22542570456896 run_lib.py:133] step: 1116200, training_loss: 2.62634e-02
I0213 02:05:12.511313 22542570456896 run_lib.py:146] step: 1116200, eval_loss: 2.57591e-02
I0213 02:05:29.890693 22542570456896 run_lib.py:133] step: 1116250, training_loss: 3.21433e-02
I0213 02:05:47.235600 22542570456896 run_lib.py:133] step: 1116300, training_loss: 3.06699e-02
I0213 02:05:47.393530 22542570456896 run_lib.py:146] step: 1116300, eval_loss: 2.56761e-02
I0213 02:06:04.835874 22542570456896 run_lib.py:133] step: 1116350, training_loss: 2.80045e-02
I0213 02:06:22.075880 22542570456896 run_lib.py:133] step: 1116400, training_loss: 2.49341e-02
I0213 02:06:22.226295 22542570456896 run_lib.py:146] step: 1116400, eval_loss: 2.96900e-02
I0213 02:06:39.630765 22542570456896 run_lib.py:133] step: 1116450, training_loss: 2.72120e-02
I0213 02:06:56.954478 22542570456896 run_lib.py:133] step: 1116500, training_loss: 2.53948e-02
I0213 02:06:57.115211 22542570456896 run_lib.py:146] step: 1116500, eval_loss: 3.37642e-02
I0213 02:07:14.382125 22542570456896 run_lib.py:133] step: 1116550, training_loss: 2.83570e-02
I0213 02:07:31.830505 22542570456896 run_lib.py:133] step: 1116600, training_loss: 2.76803e-02
I0213 02:07:31.986206 22542570456896 run_lib.py:146] step: 1116600, eval_loss: 2.85352e-02
I0213 02:07:49.238309 22542570456896 run_lib.py:133] step: 1116650, training_loss: 2.25881e-02
I0213 02:08:06.479045 22542570456896 run_lib.py:133] step: 1116700, training_loss: 3.01173e-02
I0213 02:08:06.636208 22542570456896 run_lib.py:146] step: 1116700, eval_loss: 2.62390e-02
I0213 02:08:24.053571 22542570456896 run_lib.py:133] step: 1116750, training_loss: 2.38589e-02
I0213 02:08:41.407384 22542570456896 run_lib.py:133] step: 1116800, training_loss: 3.11973e-02
I0213 02:08:41.563828 22542570456896 run_lib.py:146] step: 1116800, eval_loss: 3.17864e-02
I0213 02:08:58.818053 22542570456896 run_lib.py:133] step: 1116850, training_loss: 2.52987e-02
I0213 02:09:16.119681 22542570456896 run_lib.py:133] step: 1116900, training_loss: 2.68594e-02
I0213 02:09:16.280482 22542570456896 run_lib.py:146] step: 1116900, eval_loss: 3.12947e-02
I0213 02:09:33.586775 22542570456896 run_lib.py:133] step: 1116950, training_loss: 2.47978e-02
I0213 02:09:51.042619 22542570456896 run_lib.py:133] step: 1117000, training_loss: 2.99437e-02
I0213 02:09:51.198026 22542570456896 run_lib.py:146] step: 1117000, eval_loss: 2.77941e-02
I0213 02:10:08.424954 22542570456896 run_lib.py:133] step: 1117050, training_loss: 3.21423e-02
I0213 02:10:25.687378 22542570456896 run_lib.py:133] step: 1117100, training_loss: 2.59506e-02
I0213 02:10:25.842413 22542570456896 run_lib.py:146] step: 1117100, eval_loss: 3.34886e-02
I0213 02:10:43.208270 22542570456896 run_lib.py:133] step: 1117150, training_loss: 2.51944e-02
I0213 02:11:00.641752 22542570456896 run_lib.py:133] step: 1117200, training_loss: 2.53888e-02
I0213 02:11:00.795543 22542570456896 run_lib.py:146] step: 1117200, eval_loss: 3.40572e-02
I0213 02:11:18.066546 22542570456896 run_lib.py:133] step: 1117250, training_loss: 2.77494e-02
I0213 02:11:35.376244 22542570456896 run_lib.py:133] step: 1117300, training_loss: 2.65630e-02
I0213 02:11:35.527054 22542570456896 run_lib.py:146] step: 1117300, eval_loss: 2.97224e-02
I0213 02:11:52.778947 22542570456896 run_lib.py:133] step: 1117350, training_loss: 2.61039e-02
I0213 02:12:10.100866 22542570456896 run_lib.py:133] step: 1117400, training_loss: 2.53775e-02
I0213 02:12:10.260535 22542570456896 run_lib.py:146] step: 1117400, eval_loss: 2.51840e-02
I0213 02:12:27.700682 22542570456896 run_lib.py:133] step: 1117450, training_loss: 2.63574e-02
I0213 02:12:45.019870 22542570456896 run_lib.py:133] step: 1117500, training_loss: 3.10785e-02
I0213 02:12:45.181507 22542570456896 run_lib.py:146] step: 1117500, eval_loss: 2.62968e-02
I0213 02:13:02.444688 22542570456896 run_lib.py:133] step: 1117550, training_loss: 2.73475e-02
I0213 02:13:19.680312 22542570456896 run_lib.py:133] step: 1117600, training_loss: 2.12801e-02
I0213 02:13:19.836321 22542570456896 run_lib.py:146] step: 1117600, eval_loss: 2.74483e-02
I0213 02:13:37.207264 22542570456896 run_lib.py:133] step: 1117650, training_loss: 2.87700e-02
I0213 02:13:54.515551 22542570456896 run_lib.py:133] step: 1117700, training_loss: 2.69363e-02
I0213 02:13:54.670065 22542570456896 run_lib.py:146] step: 1117700, eval_loss: 2.98271e-02
I0213 02:14:12.152278 22542570456896 run_lib.py:133] step: 1117750, training_loss: 2.63476e-02
I0213 02:14:29.356822 22542570456896 run_lib.py:133] step: 1117800, training_loss: 2.84756e-02
I0213 02:14:29.503443 22542570456896 run_lib.py:146] step: 1117800, eval_loss: 2.87170e-02
I0213 02:14:46.871752 22542570456896 run_lib.py:133] step: 1117850, training_loss: 2.93061e-02
I0213 02:15:04.091929 22542570456896 run_lib.py:133] step: 1117900, training_loss: 2.51537e-02
I0213 02:15:04.245458 22542570456896 run_lib.py:146] step: 1117900, eval_loss: 2.73390e-02
I0213 02:15:21.548139 22542570456896 run_lib.py:133] step: 1117950, training_loss: 2.82208e-02
I0213 02:15:38.988635 22542570456896 run_lib.py:133] step: 1118000, training_loss: 2.61504e-02
I0213 02:15:39.144357 22542570456896 run_lib.py:146] step: 1118000, eval_loss: 2.42856e-02
I0213 02:15:56.388322 22542570456896 run_lib.py:133] step: 1118050, training_loss: 2.30905e-02
I0213 02:16:13.794757 22542570456896 run_lib.py:133] step: 1118100, training_loss: 2.43767e-02
I0213 02:16:13.954315 22542570456896 run_lib.py:146] step: 1118100, eval_loss: 2.20800e-02
I0213 02:16:31.229027 22542570456896 run_lib.py:133] step: 1118150, training_loss: 2.59721e-02
I0213 02:16:48.457296 22542570456896 run_lib.py:133] step: 1118200, training_loss: 3.15715e-02
I0213 02:16:48.610185 22542570456896 run_lib.py:146] step: 1118200, eval_loss: 2.70944e-02
I0213 02:17:06.006238 22542570456896 run_lib.py:133] step: 1118250, training_loss: 2.84132e-02
I0213 02:17:23.260409 22542570456896 run_lib.py:133] step: 1118300, training_loss: 2.36417e-02
I0213 02:17:23.413480 22542570456896 run_lib.py:146] step: 1118300, eval_loss: 3.42844e-02
I0213 02:17:40.697591 22542570456896 run_lib.py:133] step: 1118350, training_loss: 3.12474e-02
I0213 02:17:58.130579 22542570456896 run_lib.py:133] step: 1118400, training_loss: 2.94214e-02
I0213 02:17:58.284262 22542570456896 run_lib.py:146] step: 1118400, eval_loss: 2.70037e-02
I0213 02:18:15.535851 22542570456896 run_lib.py:133] step: 1118450, training_loss: 2.77458e-02
I0213 02:18:32.780058 22542570456896 run_lib.py:133] step: 1118500, training_loss: 2.66118e-02
I0213 02:18:32.956284 22542570456896 run_lib.py:146] step: 1118500, eval_loss: 2.97677e-02
I0213 02:18:50.332526 22542570456896 run_lib.py:133] step: 1118550, training_loss: 2.27739e-02
I0213 02:19:07.618730 22542570456896 run_lib.py:133] step: 1118600, training_loss: 2.73836e-02
I0213 02:19:07.770073 22542570456896 run_lib.py:146] step: 1118600, eval_loss: 3.12526e-02
I0213 02:19:25.038544 22542570456896 run_lib.py:133] step: 1118650, training_loss: 2.55111e-02
I0213 02:19:42.271383 22542570456896 run_lib.py:133] step: 1118700, training_loss: 2.19700e-02
I0213 02:19:42.425235 22542570456896 run_lib.py:146] step: 1118700, eval_loss: 3.07470e-02
I0213 02:19:59.886878 22542570456896 run_lib.py:133] step: 1118750, training_loss: 3.05077e-02
I0213 02:20:17.211551 22542570456896 run_lib.py:133] step: 1118800, training_loss: 2.10408e-02
I0213 02:20:17.364452 22542570456896 run_lib.py:146] step: 1118800, eval_loss: 2.70542e-02
I0213 02:20:34.650084 22542570456896 run_lib.py:133] step: 1118850, training_loss: 2.46752e-02
I0213 02:20:51.955116 22542570456896 run_lib.py:133] step: 1118900, training_loss: 1.97587e-02
I0213 02:20:52.111265 22542570456896 run_lib.py:146] step: 1118900, eval_loss: 3.29886e-02
I0213 02:21:09.546440 22542570456896 run_lib.py:133] step: 1118950, training_loss: 2.53648e-02
I0213 02:21:26.767099 22542570456896 run_lib.py:133] step: 1119000, training_loss: 2.06689e-02
I0213 02:21:26.920314 22542570456896 run_lib.py:146] step: 1119000, eval_loss: 3.12412e-02
I0213 02:21:44.326902 22542570456896 run_lib.py:133] step: 1119050, training_loss: 3.63193e-02
I0213 02:22:01.590997 22542570456896 run_lib.py:133] step: 1119100, training_loss: 2.19071e-02
I0213 02:22:01.751330 22542570456896 run_lib.py:146] step: 1119100, eval_loss: 2.92697e-02
I0213 02:22:19.189450 22542570456896 run_lib.py:133] step: 1119150, training_loss: 3.54260e-02
I0213 02:22:36.458342 22542570456896 run_lib.py:133] step: 1119200, training_loss: 2.48532e-02
I0213 02:22:36.608968 22542570456896 run_lib.py:146] step: 1119200, eval_loss: 3.54825e-02
I0213 02:22:54.018107 22542570456896 run_lib.py:133] step: 1119250, training_loss: 2.70313e-02
I0213 02:23:11.281078 22542570456896 run_lib.py:133] step: 1119300, training_loss: 2.64330e-02
I0213 02:23:11.433323 22542570456896 run_lib.py:146] step: 1119300, eval_loss: 3.00369e-02
I0213 02:23:28.645769 22542570456896 run_lib.py:133] step: 1119350, training_loss: 2.87995e-02
I0213 02:23:46.100214 22542570456896 run_lib.py:133] step: 1119400, training_loss: 3.12800e-02
I0213 02:23:46.275340 22542570456896 run_lib.py:146] step: 1119400, eval_loss: 3.89387e-02
I0213 02:24:03.555870 22542570456896 run_lib.py:133] step: 1119450, training_loss: 2.74493e-02
I0213 02:24:20.828790 22542570456896 run_lib.py:133] step: 1119500, training_loss: 2.62476e-02
I0213 02:24:20.983585 22542570456896 run_lib.py:146] step: 1119500, eval_loss: 3.28454e-02
I0213 02:24:38.460335 22542570456896 run_lib.py:133] step: 1119550, training_loss: 2.55727e-02
I0213 02:24:55.667004 22542570456896 run_lib.py:133] step: 1119600, training_loss: 2.74937e-02
I0213 02:24:55.820419 22542570456896 run_lib.py:146] step: 1119600, eval_loss: 2.44157e-02
I0213 02:25:13.217728 22542570456896 run_lib.py:133] step: 1119650, training_loss: 3.41760e-02
I0213 02:25:30.513125 22542570456896 run_lib.py:133] step: 1119700, training_loss: 2.90286e-02
I0213 02:25:30.665616 22542570456896 run_lib.py:146] step: 1119700, eval_loss: 3.08419e-02
I0213 02:25:47.978598 22542570456896 run_lib.py:133] step: 1119750, training_loss: 2.39598e-02
I0213 02:26:05.436139 22542570456896 run_lib.py:133] step: 1119800, training_loss: 2.45909e-02
I0213 02:26:05.590718 22542570456896 run_lib.py:146] step: 1119800, eval_loss: 2.53995e-02
I0213 02:26:22.827455 22542570456896 run_lib.py:133] step: 1119850, training_loss: 2.28915e-02
I0213 02:26:40.099413 22542570456896 run_lib.py:133] step: 1119900, training_loss: 2.71954e-02
I0213 02:26:40.260351 22542570456896 run_lib.py:146] step: 1119900, eval_loss: 2.25922e-02
I0213 02:26:57.578358 22542570456896 run_lib.py:133] step: 1119950, training_loss: 2.94915e-02
I0213 02:27:15.084096 22542570456896 run_lib.py:133] step: 1120000, training_loss: 2.52611e-02
I0213 02:27:15.757436 22542570456896 run_lib.py:146] step: 1120000, eval_loss: 3.52015e-02
I0213 02:27:35.578801 22542570456896 run_lib.py:133] step: 1120050, training_loss: 2.49279e-02
I0213 02:27:52.976025 22542570456896 run_lib.py:133] step: 1120100, training_loss: 2.17922e-02
I0213 02:27:53.130310 22542570456896 run_lib.py:146] step: 1120100, eval_loss: 2.78235e-02
I0213 02:28:10.373468 22542570456896 run_lib.py:133] step: 1120150, training_loss: 2.24197e-02
I0213 02:28:27.635460 22542570456896 run_lib.py:133] step: 1120200, training_loss: 2.96832e-02
I0213 02:28:27.785246 22542570456896 run_lib.py:146] step: 1120200, eval_loss: 2.84333e-02
I0213 02:28:45.100693 22542570456896 run_lib.py:133] step: 1120250, training_loss: 2.43485e-02
I0213 02:29:02.580262 22542570456896 run_lib.py:133] step: 1120300, training_loss: 2.58094e-02
I0213 02:29:02.731243 22542570456896 run_lib.py:146] step: 1120300, eval_loss: 2.69418e-02
I0213 02:29:20.023975 22542570456896 run_lib.py:133] step: 1120350, training_loss: 2.11208e-02
I0213 02:29:37.328825 22542570456896 run_lib.py:133] step: 1120400, training_loss: 2.91105e-02
I0213 02:29:37.484644 22542570456896 run_lib.py:146] step: 1120400, eval_loss: 3.17321e-02
I0213 02:29:54.742944 22542570456896 run_lib.py:133] step: 1120450, training_loss: 2.82141e-02
I0213 02:30:12.084170 22542570456896 run_lib.py:133] step: 1120500, training_loss: 2.36799e-02
I0213 02:30:12.238412 22542570456896 run_lib.py:146] step: 1120500, eval_loss: 2.41632e-02
I0213 02:30:29.652267 22542570456896 run_lib.py:133] step: 1120550, training_loss: 2.72895e-02
I0213 02:30:46.975441 22542570456896 run_lib.py:133] step: 1120600, training_loss: 2.82223e-02
I0213 02:30:47.129045 22542570456896 run_lib.py:146] step: 1120600, eval_loss: 2.86708e-02
I0213 02:31:04.380900 22542570456896 run_lib.py:133] step: 1120650, training_loss: 2.56647e-02
I0213 02:31:21.620375 22542570456896 run_lib.py:133] step: 1120700, training_loss: 2.66801e-02
I0213 02:31:21.769490 22542570456896 run_lib.py:146] step: 1120700, eval_loss: 3.16230e-02
I0213 02:31:39.155057 22542570456896 run_lib.py:133] step: 1120750, training_loss: 2.44591e-02
I0213 02:31:56.416381 22542570456896 run_lib.py:133] step: 1120800, training_loss: 2.83233e-02
I0213 02:31:56.578398 22542570456896 run_lib.py:146] step: 1120800, eval_loss: 2.67255e-02
I0213 02:32:14.003341 22542570456896 run_lib.py:133] step: 1120850, training_loss: 2.59062e-02
I0213 02:32:31.330596 22542570456896 run_lib.py:133] step: 1120900, training_loss: 2.74377e-02
I0213 02:32:31.487496 22542570456896 run_lib.py:146] step: 1120900, eval_loss: 3.18524e-02
I0213 02:32:48.848237 22542570456896 run_lib.py:133] step: 1120950, training_loss: 2.64514e-02
I0213 02:33:06.071581 22542570456896 run_lib.py:133] step: 1121000, training_loss: 2.55142e-02
I0213 02:33:06.240366 22542570456896 run_lib.py:146] step: 1121000, eval_loss: 4.20924e-02
I0213 02:33:23.536653 22542570456896 run_lib.py:133] step: 1121050, training_loss: 3.05697e-02
I0213 02:33:40.991288 22542570456896 run_lib.py:133] step: 1121100, training_loss: 2.85182e-02
I0213 02:33:41.145007 22542570456896 run_lib.py:146] step: 1121100, eval_loss: 2.65969e-02
I0213 02:33:58.387467 22542570456896 run_lib.py:133] step: 1121150, training_loss: 2.79044e-02
I0213 02:34:15.729516 22542570456896 run_lib.py:133] step: 1121200, training_loss: 2.85362e-02
I0213 02:34:15.878249 22542570456896 run_lib.py:146] step: 1121200, eval_loss: 2.47504e-02
I0213 02:34:33.126854 22542570456896 run_lib.py:133] step: 1121250, training_loss: 2.76738e-02
I0213 02:34:50.424306 22542570456896 run_lib.py:133] step: 1121300, training_loss: 3.04910e-02
I0213 02:34:50.591542 22542570456896 run_lib.py:146] step: 1121300, eval_loss: 2.63334e-02
I0213 02:35:08.067057 22542570456896 run_lib.py:133] step: 1121350, training_loss: 2.76060e-02
I0213 02:35:25.372927 22542570456896 run_lib.py:133] step: 1121400, training_loss: 2.59066e-02
I0213 02:35:25.529519 22542570456896 run_lib.py:146] step: 1121400, eval_loss: 2.53319e-02
I0213 02:35:42.781831 22542570456896 run_lib.py:133] step: 1121450, training_loss: 3.19773e-02
I0213 02:36:00.156258 22542570456896 run_lib.py:133] step: 1121500, training_loss: 3.78706e-02
I0213 02:36:00.309178 22542570456896 run_lib.py:146] step: 1121500, eval_loss: 2.74857e-02
I0213 02:36:17.569156 22542570456896 run_lib.py:133] step: 1121550, training_loss: 2.26709e-02
I0213 02:36:34.859224 22542570456896 run_lib.py:133] step: 1121600, training_loss: 2.29988e-02
I0213 02:36:35.171704 22542570456896 run_lib.py:146] step: 1121600, eval_loss: 3.04028e-02
I0213 02:36:52.474198 22542570456896 run_lib.py:133] step: 1121650, training_loss: 2.69590e-02
I0213 02:37:09.698114 22542570456896 run_lib.py:133] step: 1121700, training_loss: 2.34846e-02
I0213 02:37:09.849342 22542570456896 run_lib.py:146] step: 1121700, eval_loss: 2.56871e-02
I0213 02:37:27.096044 22542570456896 run_lib.py:133] step: 1121750, training_loss: 3.27494e-02
I0213 02:37:44.354275 22542570456896 run_lib.py:133] step: 1121800, training_loss: 2.59198e-02
I0213 02:37:44.522284 22542570456896 run_lib.py:146] step: 1121800, eval_loss: 2.72483e-02
I0213 02:38:01.959484 22542570456896 run_lib.py:133] step: 1121850, training_loss: 2.28183e-02
I0213 02:38:19.342531 22542570456896 run_lib.py:133] step: 1121900, training_loss: 3.10736e-02
I0213 02:38:19.498251 22542570456896 run_lib.py:146] step: 1121900, eval_loss: 2.90724e-02
I0213 02:38:36.757405 22542570456896 run_lib.py:133] step: 1121950, training_loss: 2.89417e-02
I0213 02:38:54.018916 22542570456896 run_lib.py:133] step: 1122000, training_loss: 2.83363e-02
I0213 02:38:54.173104 22542570456896 run_lib.py:146] step: 1122000, eval_loss: 2.46366e-02
I0213 02:39:11.574340 22542570456896 run_lib.py:133] step: 1122050, training_loss: 2.93225e-02
I0213 02:39:28.843369 22542570456896 run_lib.py:133] step: 1122100, training_loss: 2.02193e-02
I0213 02:39:28.996254 22542570456896 run_lib.py:146] step: 1122100, eval_loss: 3.79863e-02
I0213 02:39:46.266493 22542570456896 run_lib.py:133] step: 1122150, training_loss: 3.09310e-02
I0213 02:40:03.558549 22542570456896 run_lib.py:133] step: 1122200, training_loss: 1.97208e-02
I0213 02:40:03.716490 22542570456896 run_lib.py:146] step: 1122200, eval_loss: 3.12920e-02
I0213 02:40:21.195244 22542570456896 run_lib.py:133] step: 1122250, training_loss: 2.91240e-02
I0213 02:40:38.465686 22542570456896 run_lib.py:133] step: 1122300, training_loss: 3.34154e-02
I0213 02:40:38.622427 22542570456896 run_lib.py:146] step: 1122300, eval_loss: 2.31674e-02
I0213 02:40:56.015043 22542570456896 run_lib.py:133] step: 1122350, training_loss: 2.68083e-02
I0213 02:41:13.262149 22542570456896 run_lib.py:133] step: 1122400, training_loss: 2.88412e-02
I0213 02:41:13.417366 22542570456896 run_lib.py:146] step: 1122400, eval_loss: 2.81497e-02
I0213 02:41:30.835451 22542570456896 run_lib.py:133] step: 1122450, training_loss: 2.83531e-02
I0213 02:41:48.133985 22542570456896 run_lib.py:133] step: 1122500, training_loss: 2.25291e-02
I0213 02:41:48.288016 22542570456896 run_lib.py:146] step: 1122500, eval_loss: 2.61560e-02
I0213 02:42:05.600258 22542570456896 run_lib.py:133] step: 1122550, training_loss: 2.98846e-02
I0213 02:42:23.053654 22542570456896 run_lib.py:133] step: 1122600, training_loss: 3.47680e-02
I0213 02:42:23.210342 22542570456896 run_lib.py:146] step: 1122600, eval_loss: 3.16055e-02
I0213 02:42:40.444233 22542570456896 run_lib.py:133] step: 1122650, training_loss: 3.13020e-02
I0213 02:42:57.862174 22542570456896 run_lib.py:133] step: 1122700, training_loss: 2.56669e-02
I0213 02:42:58.024564 22542570456896 run_lib.py:146] step: 1122700, eval_loss: 3.64177e-02
I0213 02:43:15.322821 22542570456896 run_lib.py:133] step: 1122750, training_loss: 2.51670e-02
I0213 02:43:32.598247 22542570456896 run_lib.py:133] step: 1122800, training_loss: 2.57132e-02
I0213 02:43:32.755318 22542570456896 run_lib.py:146] step: 1122800, eval_loss: 3.18864e-02
I0213 02:43:50.155520 22542570456896 run_lib.py:133] step: 1122850, training_loss: 2.53096e-02
I0213 02:44:07.393324 22542570456896 run_lib.py:133] step: 1122900, training_loss: 3.12191e-02
I0213 02:44:07.547264 22542570456896 run_lib.py:146] step: 1122900, eval_loss: 2.76587e-02
I0213 02:44:24.787497 22542570456896 run_lib.py:133] step: 1122950, training_loss: 3.00154e-02
I0213 02:44:42.020595 22542570456896 run_lib.py:133] step: 1123000, training_loss: 3.59166e-02
I0213 02:44:42.176492 22542570456896 run_lib.py:146] step: 1123000, eval_loss: 3.11746e-02
I0213 02:44:59.632076 22542570456896 run_lib.py:133] step: 1123050, training_loss: 2.17691e-02
I0213 02:45:16.873603 22542570456896 run_lib.py:133] step: 1123100, training_loss: 2.30073e-02
I0213 02:45:17.022230 22542570456896 run_lib.py:146] step: 1123100, eval_loss: 3.39945e-02
I0213 02:45:34.370340 22542570456896 run_lib.py:133] step: 1123150, training_loss: 2.48932e-02
I0213 02:45:51.624421 22542570456896 run_lib.py:133] step: 1123200, training_loss: 3.00118e-02
I0213 02:45:51.778298 22542570456896 run_lib.py:146] step: 1123200, eval_loss: 3.50613e-02
I0213 02:46:09.003216 22542570456896 run_lib.py:133] step: 1123250, training_loss: 2.78585e-02
I0213 02:46:26.303161 22542570456896 run_lib.py:133] step: 1123300, training_loss: 2.54799e-02
I0213 02:46:26.470446 22542570456896 run_lib.py:146] step: 1123300, eval_loss: 2.94918e-02
I0213 02:46:43.909515 22542570456896 run_lib.py:133] step: 1123350, training_loss: 3.03675e-02
I0213 02:47:01.237354 22542570456896 run_lib.py:133] step: 1123400, training_loss: 3.14266e-02
I0213 02:47:01.393425 22542570456896 run_lib.py:146] step: 1123400, eval_loss: 2.89719e-02
I0213 02:47:18.669105 22542570456896 run_lib.py:133] step: 1123450, training_loss: 3.27571e-02
I0213 02:47:35.909442 22542570456896 run_lib.py:133] step: 1123500, training_loss: 2.62443e-02
I0213 02:47:36.063241 22542570456896 run_lib.py:146] step: 1123500, eval_loss: 2.91455e-02
I0213 02:47:53.405148 22542570456896 run_lib.py:133] step: 1123550, training_loss: 2.42016e-02
I0213 02:48:10.728463 22542570456896 run_lib.py:133] step: 1123600, training_loss: 2.93531e-02
I0213 02:48:10.886506 22542570456896 run_lib.py:146] step: 1123600, eval_loss: 3.47936e-02
I0213 02:48:28.302440 22542570456896 run_lib.py:133] step: 1123650, training_loss: 2.52036e-02
I0213 02:48:45.568657 22542570456896 run_lib.py:133] step: 1123700, training_loss: 2.79720e-02
I0213 02:48:45.728482 22542570456896 run_lib.py:146] step: 1123700, eval_loss: 3.10679e-02
I0213 02:49:03.129252 22542570456896 run_lib.py:133] step: 1123750, training_loss: 3.06328e-02
I0213 02:49:20.373196 22542570456896 run_lib.py:133] step: 1123800, training_loss: 2.82636e-02
I0213 02:49:20.527579 22542570456896 run_lib.py:146] step: 1123800, eval_loss: 3.39865e-02
I0213 02:49:37.923211 22542570456896 run_lib.py:133] step: 1123850, training_loss: 2.27417e-02
I0213 02:49:55.255387 22542570456896 run_lib.py:133] step: 1123900, training_loss: 2.45184e-02
I0213 02:49:55.415797 22542570456896 run_lib.py:146] step: 1123900, eval_loss: 2.50523e-02
I0213 02:50:12.730615 22542570456896 run_lib.py:133] step: 1123950, training_loss: 2.61863e-02
I0213 02:50:30.189846 22542570456896 run_lib.py:133] step: 1124000, training_loss: 2.65616e-02
I0213 02:50:30.341041 22542570456896 run_lib.py:146] step: 1124000, eval_loss: 2.79312e-02
I0213 02:50:47.563036 22542570456896 run_lib.py:133] step: 1124050, training_loss: 2.28539e-02
I0213 02:51:04.832361 22542570456896 run_lib.py:133] step: 1124100, training_loss: 3.11082e-02
I0213 02:51:04.984246 22542570456896 run_lib.py:146] step: 1124100, eval_loss: 2.97780e-02
I0213 02:51:22.407895 22542570456896 run_lib.py:133] step: 1124150, training_loss: 2.53204e-02
I0213 02:51:39.888804 22542570456896 run_lib.py:133] step: 1124200, training_loss: 2.93910e-02
I0213 02:51:40.045164 22542570456896 run_lib.py:146] step: 1124200, eval_loss: 3.02399e-02
I0213 02:51:57.306478 22542570456896 run_lib.py:133] step: 1124250, training_loss: 2.84728e-02
I0213 02:52:14.595148 22542570456896 run_lib.py:133] step: 1124300, training_loss: 2.72159e-02
I0213 02:52:14.752508 22542570456896 run_lib.py:146] step: 1124300, eval_loss: 3.64373e-02
I0213 02:52:32.031883 22542570456896 run_lib.py:133] step: 1124350, training_loss: 2.80870e-02
I0213 02:52:49.446161 22542570456896 run_lib.py:133] step: 1124400, training_loss: 2.39240e-02
I0213 02:52:49.596678 22542570456896 run_lib.py:146] step: 1124400, eval_loss: 3.11739e-02
I0213 02:53:06.817991 22542570456896 run_lib.py:133] step: 1124450, training_loss: 2.73298e-02
I0213 02:53:24.118364 22542570456896 run_lib.py:133] step: 1124500, training_loss: 2.34360e-02
I0213 02:53:24.269510 22542570456896 run_lib.py:146] step: 1124500, eval_loss: 2.70372e-02
I0213 02:53:41.587412 22542570456896 run_lib.py:133] step: 1124550, training_loss: 2.33804e-02
I0213 02:53:59.046509 22542570456896 run_lib.py:133] step: 1124600, training_loss: 3.16137e-02
I0213 02:53:59.199235 22542570456896 run_lib.py:146] step: 1124600, eval_loss: 2.70529e-02
I0213 02:54:16.469775 22542570456896 run_lib.py:133] step: 1124650, training_loss: 3.24083e-02
I0213 02:54:33.796442 22542570456896 run_lib.py:133] step: 1124700, training_loss: 2.66867e-02
I0213 02:54:33.955280 22542570456896 run_lib.py:146] step: 1124700, eval_loss: 3.71989e-02
I0213 02:54:51.269805 22542570456896 run_lib.py:133] step: 1124750, training_loss: 2.65569e-02
I0213 02:55:08.623981 22542570456896 run_lib.py:133] step: 1124800, training_loss: 2.67635e-02
I0213 02:55:08.778541 22542570456896 run_lib.py:146] step: 1124800, eval_loss: 3.01971e-02
I0213 02:55:26.197962 22542570456896 run_lib.py:133] step: 1124850, training_loss: 2.90517e-02
I0213 02:55:43.475670 22542570456896 run_lib.py:133] step: 1124900, training_loss: 2.46607e-02
I0213 02:55:43.628254 22542570456896 run_lib.py:146] step: 1124900, eval_loss: 3.74048e-02
I0213 02:56:00.885857 22542570456896 run_lib.py:133] step: 1124950, training_loss: 3.36817e-02
I0213 02:56:18.206239 22542570456896 run_lib.py:133] step: 1125000, training_loss: 3.02281e-02
I0213 02:56:18.358499 22542570456896 run_lib.py:146] step: 1125000, eval_loss: 2.65605e-02
I0213 02:56:35.842683 22542570456896 run_lib.py:133] step: 1125050, training_loss: 2.50183e-02
I0213 02:56:53.089956 22542570456896 run_lib.py:133] step: 1125100, training_loss: 3.61516e-02
I0213 02:56:53.243170 22542570456896 run_lib.py:146] step: 1125100, eval_loss: 3.58867e-02
I0213 02:57:10.683169 22542570456896 run_lib.py:133] step: 1125150, training_loss: 2.98550e-02
I0213 02:57:27.932272 22542570456896 run_lib.py:133] step: 1125200, training_loss: 2.78354e-02
I0213 02:57:28.087754 22542570456896 run_lib.py:146] step: 1125200, eval_loss: 2.96868e-02
I0213 02:57:45.472845 22542570456896 run_lib.py:133] step: 1125250, training_loss: 2.06536e-02
I0213 02:58:02.705669 22542570456896 run_lib.py:133] step: 1125300, training_loss: 2.65001e-02
I0213 02:58:02.870275 22542570456896 run_lib.py:146] step: 1125300, eval_loss: 2.62510e-02
I0213 02:58:20.184899 22542570456896 run_lib.py:133] step: 1125350, training_loss: 2.50193e-02
I0213 02:58:37.625676 22542570456896 run_lib.py:133] step: 1125400, training_loss: 2.50185e-02
I0213 02:58:37.778530 22542570456896 run_lib.py:146] step: 1125400, eval_loss: 3.13177e-02
I0213 02:58:55.027943 22542570456896 run_lib.py:133] step: 1125450, training_loss: 2.58822e-02
I0213 02:59:12.426029 22542570456896 run_lib.py:133] step: 1125500, training_loss: 2.73592e-02
I0213 02:59:12.576309 22542570456896 run_lib.py:146] step: 1125500, eval_loss: 2.92749e-02
I0213 02:59:29.789835 22542570456896 run_lib.py:133] step: 1125550, training_loss: 2.99699e-02
I0213 02:59:47.017959 22542570456896 run_lib.py:133] step: 1125600, training_loss: 2.41847e-02
I0213 02:59:47.189300 22542570456896 run_lib.py:146] step: 1125600, eval_loss: 2.41108e-02
I0213 03:00:04.624274 22542570456896 run_lib.py:133] step: 1125650, training_loss: 2.04851e-02
I0213 03:00:21.911246 22542570456896 run_lib.py:133] step: 1125700, training_loss: 2.79987e-02
I0213 03:00:22.067354 22542570456896 run_lib.py:146] step: 1125700, eval_loss: 3.11406e-02
I0213 03:00:39.341457 22542570456896 run_lib.py:133] step: 1125750, training_loss: 3.40546e-02
I0213 03:00:56.755905 22542570456896 run_lib.py:133] step: 1125800, training_loss: 2.58972e-02
I0213 03:00:56.912014 22542570456896 run_lib.py:146] step: 1125800, eval_loss: 3.26338e-02
I0213 03:01:14.166084 22542570456896 run_lib.py:133] step: 1125850, training_loss: 3.19161e-02
I0213 03:01:31.464997 22542570456896 run_lib.py:133] step: 1125900, training_loss: 2.67224e-02
I0213 03:01:31.618938 22542570456896 run_lib.py:146] step: 1125900, eval_loss: 3.53600e-02
I0213 03:01:49.011840 22542570456896 run_lib.py:133] step: 1125950, training_loss: 2.63408e-02
I0213 03:02:06.295674 22542570456896 run_lib.py:133] step: 1126000, training_loss: 2.34606e-02
I0213 03:02:06.444329 22542570456896 run_lib.py:146] step: 1126000, eval_loss: 2.27554e-02
I0213 03:02:23.668713 22542570456896 run_lib.py:133] step: 1126050, training_loss: 2.73968e-02
I0213 03:02:40.924816 22542570456896 run_lib.py:133] step: 1126100, training_loss: 2.82136e-02
I0213 03:02:41.081449 22542570456896 run_lib.py:146] step: 1126100, eval_loss: 2.58823e-02
I0213 03:02:58.541276 22542570456896 run_lib.py:133] step: 1126150, training_loss: 2.34481e-02
I0213 03:03:15.908322 22542570456896 run_lib.py:133] step: 1126200, training_loss: 3.38141e-02
I0213 03:03:16.064507 22542570456896 run_lib.py:146] step: 1126200, eval_loss: 3.01133e-02
I0213 03:03:33.333160 22542570456896 run_lib.py:133] step: 1126250, training_loss: 3.22337e-02
I0213 03:03:50.585986 22542570456896 run_lib.py:133] step: 1126300, training_loss: 2.59830e-02
I0213 03:03:50.739488 22542570456896 run_lib.py:146] step: 1126300, eval_loss: 3.15440e-02
I0213 03:04:08.213196 22542570456896 run_lib.py:133] step: 1126350, training_loss: 2.19269e-02
I0213 03:04:25.457494 22542570456896 run_lib.py:133] step: 1126400, training_loss: 2.82561e-02
I0213 03:04:25.613339 22542570456896 run_lib.py:146] step: 1126400, eval_loss: 3.03724e-02
I0213 03:04:43.009871 22542570456896 run_lib.py:133] step: 1126450, training_loss: 3.02833e-02
I0213 03:05:00.339444 22542570456896 run_lib.py:133] step: 1126500, training_loss: 2.40411e-02
I0213 03:05:00.503356 22542570456896 run_lib.py:146] step: 1126500, eval_loss: 2.43331e-02
I0213 03:05:17.953683 22542570456896 run_lib.py:133] step: 1126550, training_loss: 2.77190e-02
I0213 03:05:35.208000 22542570456896 run_lib.py:133] step: 1126600, training_loss: 3.48256e-02
I0213 03:05:35.365470 22542570456896 run_lib.py:146] step: 1126600, eval_loss: 2.76090e-02
I0213 03:05:52.720043 22542570456896 run_lib.py:133] step: 1126650, training_loss: 2.63985e-02
I0213 03:06:09.934891 22542570456896 run_lib.py:133] step: 1126700, training_loss: 2.49383e-02
I0213 03:06:10.104285 22542570456896 run_lib.py:146] step: 1126700, eval_loss: 2.82401e-02
I0213 03:06:27.408568 22542570456896 run_lib.py:133] step: 1126750, training_loss: 2.95500e-02
I0213 03:06:44.844010 22542570456896 run_lib.py:133] step: 1126800, training_loss: 2.19250e-02
I0213 03:06:44.998463 22542570456896 run_lib.py:146] step: 1126800, eval_loss: 2.89661e-02
I0213 03:07:02.266471 22542570456896 run_lib.py:133] step: 1126850, training_loss: 3.15503e-02
I0213 03:07:19.548297 22542570456896 run_lib.py:133] step: 1126900, training_loss: 2.35176e-02
I0213 03:07:19.698255 22542570456896 run_lib.py:146] step: 1126900, eval_loss: 3.03474e-02
I0213 03:07:37.113131 22542570456896 run_lib.py:133] step: 1126950, training_loss: 2.63066e-02
I0213 03:07:54.364984 22542570456896 run_lib.py:133] step: 1127000, training_loss: 2.95384e-02
I0213 03:07:54.523500 22542570456896 run_lib.py:146] step: 1127000, eval_loss: 2.58353e-02
I0213 03:08:11.941492 22542570456896 run_lib.py:133] step: 1127050, training_loss: 2.55527e-02
I0213 03:08:29.250347 22542570456896 run_lib.py:133] step: 1127100, training_loss: 2.91055e-02
I0213 03:08:29.413356 22542570456896 run_lib.py:146] step: 1127100, eval_loss: 3.39421e-02
I0213 03:08:46.674241 22542570456896 run_lib.py:133] step: 1127150, training_loss: 2.79321e-02
I0213 03:09:04.075402 22542570456896 run_lib.py:133] step: 1127200, training_loss: 3.27194e-02
I0213 03:09:04.230308 22542570456896 run_lib.py:146] step: 1127200, eval_loss: 2.69688e-02
I0213 03:09:21.513305 22542570456896 run_lib.py:133] step: 1127250, training_loss: 2.87468e-02
I0213 03:09:38.799728 22542570456896 run_lib.py:133] step: 1127300, training_loss: 3.09661e-02
I0213 03:09:38.954139 22542570456896 run_lib.py:146] step: 1127300, eval_loss: 3.15177e-02
I0213 03:09:56.299877 22542570456896 run_lib.py:133] step: 1127350, training_loss: 2.52647e-02
I0213 03:10:13.770923 22542570456896 run_lib.py:133] step: 1127400, training_loss: 2.30974e-02
I0213 03:10:13.920295 22542570456896 run_lib.py:146] step: 1127400, eval_loss: 3.04703e-02
I0213 03:10:31.155647 22542570456896 run_lib.py:133] step: 1127450, training_loss: 2.33430e-02
I0213 03:10:48.516795 22542570456896 run_lib.py:133] step: 1127500, training_loss: 3.28567e-02
I0213 03:10:48.681427 22542570456896 run_lib.py:146] step: 1127500, eval_loss: 2.83221e-02
I0213 03:11:05.928982 22542570456896 run_lib.py:133] step: 1127550, training_loss: 2.40020e-02
I0213 03:11:23.191641 22542570456896 run_lib.py:133] step: 1127600, training_loss: 2.91290e-02
I0213 03:11:23.358252 22542570456896 run_lib.py:146] step: 1127600, eval_loss: 3.22113e-02
I0213 03:11:40.777683 22542570456896 run_lib.py:133] step: 1127650, training_loss: 3.45684e-02
I0213 03:11:58.197581 22542570456896 run_lib.py:133] step: 1127700, training_loss: 3.12287e-02
I0213 03:11:58.351063 22542570456896 run_lib.py:146] step: 1127700, eval_loss: 3.72672e-02
I0213 03:12:15.621819 22542570456896 run_lib.py:133] step: 1127750, training_loss: 2.79002e-02
I0213 03:12:32.864668 22542570456896 run_lib.py:133] step: 1127800, training_loss: 2.38612e-02
I0213 03:12:33.014994 22542570456896 run_lib.py:146] step: 1127800, eval_loss: 3.05150e-02
I0213 03:12:50.377234 22542570456896 run_lib.py:133] step: 1127850, training_loss: 3.25699e-02
I0213 03:13:07.687763 22542570456896 run_lib.py:133] step: 1127900, training_loss: 2.58013e-02
I0213 03:13:07.845537 22542570456896 run_lib.py:146] step: 1127900, eval_loss: 2.65407e-02
I0213 03:13:25.305438 22542570456896 run_lib.py:133] step: 1127950, training_loss: 2.63808e-02
I0213 03:13:42.602477 22542570456896 run_lib.py:133] step: 1128000, training_loss: 2.31777e-02
I0213 03:13:42.759271 22542570456896 run_lib.py:146] step: 1128000, eval_loss: 3.91847e-02
I0213 03:14:00.195012 22542570456896 run_lib.py:133] step: 1128050, training_loss: 2.48933e-02
I0213 03:14:17.462541 22542570456896 run_lib.py:133] step: 1128100, training_loss: 2.78748e-02
I0213 03:14:17.616246 22542570456896 run_lib.py:146] step: 1128100, eval_loss: 2.59371e-02
I0213 03:14:34.898521 22542570456896 run_lib.py:133] step: 1128150, training_loss: 2.13292e-02
I0213 03:14:52.337494 22542570456896 run_lib.py:133] step: 1128200, training_loss: 2.83832e-02
I0213 03:14:52.492257 22542570456896 run_lib.py:146] step: 1128200, eval_loss: 3.25731e-02
I0213 03:15:09.807849 22542570456896 run_lib.py:133] step: 1128250, training_loss: 2.55610e-02
I0213 03:15:27.281878 22542570456896 run_lib.py:133] step: 1128300, training_loss: 3.31940e-02
I0213 03:15:27.430597 22542570456896 run_lib.py:146] step: 1128300, eval_loss: 2.58548e-02
I0213 03:15:44.718466 22542570456896 run_lib.py:133] step: 1128350, training_loss: 2.71843e-02
I0213 03:16:01.979614 22542570456896 run_lib.py:133] step: 1128400, training_loss: 3.27188e-02
I0213 03:16:02.133365 22542570456896 run_lib.py:146] step: 1128400, eval_loss: 2.74883e-02
I0213 03:16:19.508273 22542570456896 run_lib.py:133] step: 1128450, training_loss: 2.40001e-02
I0213 03:16:36.790107 22542570456896 run_lib.py:133] step: 1128500, training_loss: 2.63508e-02
I0213 03:16:36.964367 22542570456896 run_lib.py:146] step: 1128500, eval_loss: 2.83361e-02
I0213 03:16:54.286344 22542570456896 run_lib.py:133] step: 1128550, training_loss: 2.76321e-02
I0213 03:17:11.755474 22542570456896 run_lib.py:133] step: 1128600, training_loss: 2.68674e-02
I0213 03:17:11.913525 22542570456896 run_lib.py:146] step: 1128600, eval_loss: 3.05996e-02
I0213 03:17:29.218465 22542570456896 run_lib.py:133] step: 1128650, training_loss: 3.06409e-02
I0213 03:17:46.486474 22542570456896 run_lib.py:133] step: 1128700, training_loss: 3.22615e-02
I0213 03:17:46.775278 22542570456896 run_lib.py:146] step: 1128700, eval_loss: 3.24065e-02
I0213 03:18:04.021968 22542570456896 run_lib.py:133] step: 1128750, training_loss: 2.71199e-02
I0213 03:18:21.346704 22542570456896 run_lib.py:133] step: 1128800, training_loss: 2.43502e-02
I0213 03:18:21.499562 22542570456896 run_lib.py:146] step: 1128800, eval_loss: 4.24675e-02
I0213 03:18:38.798358 22542570456896 run_lib.py:133] step: 1128850, training_loss: 3.43943e-02
I0213 03:18:56.066498 22542570456896 run_lib.py:133] step: 1128900, training_loss: 2.68181e-02
I0213 03:18:56.223243 22542570456896 run_lib.py:146] step: 1128900, eval_loss: 3.66855e-02
I0213 03:19:13.622542 22542570456896 run_lib.py:133] step: 1128950, training_loss: 2.73639e-02
I0213 03:19:30.947636 22542570456896 run_lib.py:133] step: 1129000, training_loss: 3.07001e-02
I0213 03:19:31.105497 22542570456896 run_lib.py:146] step: 1129000, eval_loss: 3.35549e-02
I0213 03:19:48.370649 22542570456896 run_lib.py:133] step: 1129050, training_loss: 2.23452e-02
I0213 03:20:05.697640 22542570456896 run_lib.py:133] step: 1129100, training_loss: 2.36799e-02
I0213 03:20:05.851520 22542570456896 run_lib.py:146] step: 1129100, eval_loss: 2.71388e-02
I0213 03:20:23.269939 22542570456896 run_lib.py:133] step: 1129150, training_loss: 1.95470e-02
I0213 03:20:40.575113 22542570456896 run_lib.py:133] step: 1129200, training_loss: 2.15877e-02
I0213 03:20:40.728268 22542570456896 run_lib.py:146] step: 1129200, eval_loss: 2.90016e-02
I0213 03:20:57.999743 22542570456896 run_lib.py:133] step: 1129250, training_loss: 2.92342e-02
I0213 03:21:15.255541 22542570456896 run_lib.py:133] step: 1129300, training_loss: 2.24170e-02
I0213 03:21:15.406198 22542570456896 run_lib.py:146] step: 1129300, eval_loss: 2.88872e-02
I0213 03:21:32.831979 22542570456896 run_lib.py:133] step: 1129350, training_loss: 2.81274e-02
I0213 03:21:50.127821 22542570456896 run_lib.py:133] step: 1129400, training_loss: 2.81327e-02
I0213 03:21:50.284203 22542570456896 run_lib.py:146] step: 1129400, eval_loss: 2.76141e-02
I0213 03:22:07.716731 22542570456896 run_lib.py:133] step: 1129450, training_loss: 2.14782e-02
I0213 03:22:24.965539 22542570456896 run_lib.py:133] step: 1129500, training_loss: 3.16316e-02
I0213 03:22:25.123514 22542570456896 run_lib.py:146] step: 1129500, eval_loss: 2.77187e-02
I0213 03:22:42.499572 22542570456896 run_lib.py:133] step: 1129550, training_loss: 2.83780e-02
I0213 03:22:59.746816 22542570456896 run_lib.py:133] step: 1129600, training_loss: 2.85465e-02
I0213 03:22:59.900394 22542570456896 run_lib.py:146] step: 1129600, eval_loss: 2.45628e-02
I0213 03:23:17.200513 22542570456896 run_lib.py:133] step: 1129650, training_loss: 2.98977e-02
I0213 03:23:34.654905 22542570456896 run_lib.py:133] step: 1129700, training_loss: 3.43906e-02
I0213 03:23:34.812051 22542570456896 run_lib.py:146] step: 1129700, eval_loss: 2.56312e-02
I0213 03:23:52.081362 22542570456896 run_lib.py:133] step: 1129750, training_loss: 3.09374e-02
I0213 03:24:09.499594 22542570456896 run_lib.py:133] step: 1129800, training_loss: 3.08830e-02
I0213 03:24:09.651556 22542570456896 run_lib.py:146] step: 1129800, eval_loss: 2.92505e-02
I0213 03:24:26.934414 22542570456896 run_lib.py:133] step: 1129850, training_loss: 2.72100e-02
I0213 03:24:44.179519 22542570456896 run_lib.py:133] step: 1129900, training_loss: 3.04643e-02
I0213 03:24:44.354287 22542570456896 run_lib.py:146] step: 1129900, eval_loss: 3.09474e-02
I0213 03:25:01.809371 22542570456896 run_lib.py:133] step: 1129950, training_loss: 2.90314e-02
I0213 03:25:19.061451 22542570456896 run_lib.py:133] step: 1130000, training_loss: 2.74217e-02
I0213 03:25:19.737456 22542570456896 run_lib.py:146] step: 1130000, eval_loss: 2.49631e-02
I0213 03:25:39.727952 22542570456896 run_lib.py:133] step: 1130050, training_loss: 2.30303e-02
I0213 03:25:57.040889 22542570456896 run_lib.py:133] step: 1130100, training_loss: 2.29753e-02
I0213 03:25:57.194266 22542570456896 run_lib.py:146] step: 1130100, eval_loss: 2.65096e-02
I0213 03:26:14.486617 22542570456896 run_lib.py:133] step: 1130150, training_loss: 3.04296e-02
I0213 03:26:31.786070 22542570456896 run_lib.py:133] step: 1130200, training_loss: 3.21569e-02
I0213 03:26:31.939492 22542570456896 run_lib.py:146] step: 1130200, eval_loss: 2.66935e-02
I0213 03:26:49.426217 22542570456896 run_lib.py:133] step: 1130250, training_loss: 3.03404e-02
I0213 03:27:06.728742 22542570456896 run_lib.py:133] step: 1130300, training_loss: 2.38675e-02
I0213 03:27:06.875206 22542570456896 run_lib.py:146] step: 1130300, eval_loss: 2.72545e-02
I0213 03:27:24.119567 22542570456896 run_lib.py:133] step: 1130350, training_loss: 2.13738e-02
I0213 03:27:41.352707 22542570456896 run_lib.py:133] step: 1130400, training_loss: 2.06097e-02
I0213 03:27:41.506320 22542570456896 run_lib.py:146] step: 1130400, eval_loss: 3.12122e-02
I0213 03:27:58.891311 22542570456896 run_lib.py:133] step: 1130450, training_loss: 3.15656e-02
I0213 03:28:16.166631 22542570456896 run_lib.py:133] step: 1130500, training_loss: 2.61482e-02
I0213 03:28:16.341279 22542570456896 run_lib.py:146] step: 1130500, eval_loss: 2.85835e-02
I0213 03:28:33.809885 22542570456896 run_lib.py:133] step: 1130550, training_loss: 3.10035e-02
I0213 03:28:51.069218 22542570456896 run_lib.py:133] step: 1130600, training_loss: 2.31994e-02
I0213 03:28:51.223025 22542570456896 run_lib.py:146] step: 1130600, eval_loss: 2.63496e-02
I0213 03:29:08.614663 22542570456896 run_lib.py:133] step: 1130650, training_loss: 2.61306e-02
I0213 03:29:25.857863 22542570456896 run_lib.py:133] step: 1130700, training_loss: 2.57632e-02
I0213 03:29:26.018945 22542570456896 run_lib.py:146] step: 1130700, eval_loss: 3.02240e-02
I0213 03:29:43.272176 22542570456896 run_lib.py:133] step: 1130750, training_loss: 2.84232e-02
I0213 03:30:00.721751 22542570456896 run_lib.py:133] step: 1130800, training_loss: 2.77010e-02
I0213 03:30:00.875503 22542570456896 run_lib.py:146] step: 1130800, eval_loss: 3.27440e-02
I0213 03:30:18.198222 22542570456896 run_lib.py:133] step: 1130850, training_loss: 2.54401e-02
I0213 03:30:35.650495 22542570456896 run_lib.py:133] step: 1130900, training_loss: 2.02370e-02
I0213 03:30:35.807515 22542570456896 run_lib.py:146] step: 1130900, eval_loss: 2.66797e-02
I0213 03:30:53.085467 22542570456896 run_lib.py:133] step: 1130950, training_loss: 1.77262e-02
I0213 03:31:10.330178 22542570456896 run_lib.py:133] step: 1131000, training_loss: 2.43972e-02
I0213 03:31:10.497283 22542570456896 run_lib.py:146] step: 1131000, eval_loss: 3.11146e-02
I0213 03:31:28.008548 22542570456896 run_lib.py:133] step: 1131050, training_loss: 2.76671e-02
I0213 03:31:45.267344 22542570456896 run_lib.py:133] step: 1131100, training_loss: 2.65861e-02
I0213 03:31:45.422453 22542570456896 run_lib.py:146] step: 1131100, eval_loss: 2.98862e-02
I0213 03:32:02.706984 22542570456896 run_lib.py:133] step: 1131150, training_loss: 2.42443e-02
I0213 03:32:19.961894 22542570456896 run_lib.py:133] step: 1131200, training_loss: 2.22058e-02
I0213 03:32:20.112982 22542570456896 run_lib.py:146] step: 1131200, eval_loss: 2.94020e-02
I0213 03:32:37.545798 22542570456896 run_lib.py:133] step: 1131250, training_loss: 3.04025e-02
I0213 03:32:54.809026 22542570456896 run_lib.py:133] step: 1131300, training_loss: 2.83604e-02
I0213 03:32:54.965521 22542570456896 run_lib.py:146] step: 1131300, eval_loss: 2.25044e-02
I0213 03:33:12.333528 22542570456896 run_lib.py:133] step: 1131350, training_loss: 2.43305e-02
I0213 03:33:29.652500 22542570456896 run_lib.py:133] step: 1131400, training_loss: 3.01028e-02
I0213 03:33:29.816915 22542570456896 run_lib.py:146] step: 1131400, eval_loss: 2.66913e-02
I0213 03:33:47.089069 22542570456896 run_lib.py:133] step: 1131450, training_loss: 2.61037e-02
I0213 03:34:04.346556 22542570456896 run_lib.py:133] step: 1131500, training_loss: 2.57124e-02
I0213 03:34:04.507601 22542570456896 run_lib.py:146] step: 1131500, eval_loss: 3.06515e-02
I0213 03:34:21.948747 22542570456896 run_lib.py:133] step: 1131550, training_loss: 2.56877e-02
I0213 03:34:39.290504 22542570456896 run_lib.py:133] step: 1131600, training_loss: 2.90393e-02
I0213 03:34:39.447625 22542570456896 run_lib.py:146] step: 1131600, eval_loss: 2.60226e-02
I0213 03:34:56.753910 22542570456896 run_lib.py:133] step: 1131650, training_loss: 2.46707e-02
I0213 03:35:14.028801 22542570456896 run_lib.py:133] step: 1131700, training_loss: 2.33747e-02
I0213 03:35:14.175606 22542570456896 run_lib.py:146] step: 1131700, eval_loss: 3.21321e-02
I0213 03:35:31.591025 22542570456896 run_lib.py:133] step: 1131750, training_loss: 2.69497e-02
I0213 03:35:48.857128 22542570456896 run_lib.py:133] step: 1131800, training_loss: 2.74096e-02
I0213 03:35:49.011355 22542570456896 run_lib.py:146] step: 1131800, eval_loss: 2.89452e-02
I0213 03:36:06.418354 22542570456896 run_lib.py:133] step: 1131850, training_loss: 3.17609e-02
I0213 03:36:23.650346 22542570456896 run_lib.py:133] step: 1131900, training_loss: 3.43792e-02
I0213 03:36:23.820319 22542570456896 run_lib.py:146] step: 1131900, eval_loss: 2.54106e-02
I0213 03:36:41.269593 22542570456896 run_lib.py:133] step: 1131950, training_loss: 3.20112e-02
I0213 03:36:58.620491 22542570456896 run_lib.py:133] step: 1132000, training_loss: 3.23381e-02
I0213 03:36:58.774477 22542570456896 run_lib.py:146] step: 1132000, eval_loss: 2.80517e-02
I0213 03:37:16.204351 22542570456896 run_lib.py:133] step: 1132050, training_loss: 1.98138e-02
I0213 03:37:33.444980 22542570456896 run_lib.py:133] step: 1132100, training_loss: 3.07249e-02
I0213 03:37:33.599237 22542570456896 run_lib.py:146] step: 1132100, eval_loss: 2.60857e-02
I0213 03:37:50.843845 22542570456896 run_lib.py:133] step: 1132150, training_loss: 2.61977e-02
I0213 03:38:08.277514 22542570456896 run_lib.py:133] step: 1132200, training_loss: 2.40333e-02
I0213 03:38:08.428492 22542570456896 run_lib.py:146] step: 1132200, eval_loss: 3.29400e-02
I0213 03:38:25.715487 22542570456896 run_lib.py:133] step: 1132250, training_loss: 3.21073e-02
I0213 03:38:42.959644 22542570456896 run_lib.py:133] step: 1132300, training_loss: 2.46497e-02
I0213 03:38:43.116067 22542570456896 run_lib.py:146] step: 1132300, eval_loss: 3.20571e-02
I0213 03:39:00.526472 22542570456896 run_lib.py:133] step: 1132350, training_loss: 2.63087e-02
I0213 03:39:17.887917 22542570456896 run_lib.py:133] step: 1132400, training_loss: 2.76856e-02
I0213 03:39:18.043449 22542570456896 run_lib.py:146] step: 1132400, eval_loss: 2.85073e-02
I0213 03:39:35.308932 22542570456896 run_lib.py:133] step: 1132450, training_loss: 2.84306e-02
I0213 03:39:52.609382 22542570456896 run_lib.py:133] step: 1132500, training_loss: 2.67960e-02
I0213 03:39:52.766655 22542570456896 run_lib.py:146] step: 1132500, eval_loss: 3.09482e-02
I0213 03:40:10.013024 22542570456896 run_lib.py:133] step: 1132550, training_loss: 3.12032e-02
I0213 03:40:27.444694 22542570456896 run_lib.py:133] step: 1132600, training_loss: 2.53374e-02
I0213 03:40:27.602442 22542570456896 run_lib.py:146] step: 1132600, eval_loss: 3.19762e-02
I0213 03:40:44.869867 22542570456896 run_lib.py:133] step: 1132650, training_loss: 1.95252e-02
I0213 03:41:02.112041 22542570456896 run_lib.py:133] step: 1132700, training_loss: 2.46700e-02
I0213 03:41:02.261263 22542570456896 run_lib.py:146] step: 1132700, eval_loss: 2.82645e-02
I0213 03:41:19.556243 22542570456896 run_lib.py:133] step: 1132750, training_loss: 2.93998e-02
I0213 03:41:37.012147 22542570456896 run_lib.py:133] step: 1132800, training_loss: 3.15048e-02
I0213 03:41:37.169288 22542570456896 run_lib.py:146] step: 1132800, eval_loss: 3.00938e-02
I0213 03:41:54.418359 22542570456896 run_lib.py:133] step: 1132850, training_loss: 2.59177e-02
I0213 03:42:11.717656 22542570456896 run_lib.py:133] step: 1132900, training_loss: 2.73126e-02
I0213 03:42:11.871271 22542570456896 run_lib.py:146] step: 1132900, eval_loss: 2.97664e-02
I0213 03:42:29.122545 22542570456896 run_lib.py:133] step: 1132950, training_loss: 2.37084e-02
I0213 03:42:46.384258 22542570456896 run_lib.py:133] step: 1133000, training_loss: 2.76945e-02
I0213 03:42:46.543470 22542570456896 run_lib.py:146] step: 1133000, eval_loss: 2.62527e-02
I0213 03:43:03.985443 22542570456896 run_lib.py:133] step: 1133050, training_loss: 2.61649e-02
I0213 03:43:21.422132 22542570456896 run_lib.py:133] step: 1133100, training_loss: 2.48689e-02
I0213 03:43:21.576878 22542570456896 run_lib.py:146] step: 1133100, eval_loss: 2.45342e-02
I0213 03:43:38.868538 22542570456896 run_lib.py:133] step: 1133150, training_loss: 2.78767e-02
I0213 03:43:56.136210 22542570456896 run_lib.py:133] step: 1133200, training_loss: 2.03214e-02
I0213 03:43:56.288928 22542570456896 run_lib.py:146] step: 1133200, eval_loss: 2.47832e-02
I0213 03:44:13.635781 22542570456896 run_lib.py:133] step: 1133250, training_loss: 2.52947e-02
I0213 03:44:30.863980 22542570456896 run_lib.py:133] step: 1133300, training_loss: 3.22051e-02
I0213 03:44:31.034298 22542570456896 run_lib.py:146] step: 1133300, eval_loss: 3.33324e-02
I0213 03:44:48.504924 22542570456896 run_lib.py:133] step: 1133350, training_loss: 2.93876e-02
I0213 03:45:05.767652 22542570456896 run_lib.py:133] step: 1133400, training_loss: 2.23632e-02
I0213 03:45:05.922394 22542570456896 run_lib.py:146] step: 1133400, eval_loss: 2.42974e-02
I0213 03:45:23.354915 22542570456896 run_lib.py:133] step: 1133450, training_loss: 2.48792e-02
I0213 03:45:40.613828 22542570456896 run_lib.py:133] step: 1133500, training_loss: 2.48673e-02
I0213 03:45:40.771260 22542570456896 run_lib.py:146] step: 1133500, eval_loss: 3.35068e-02
I0213 03:45:58.041506 22542570456896 run_lib.py:133] step: 1133550, training_loss: 1.76439e-02
I0213 03:46:15.434390 22542570456896 run_lib.py:133] step: 1133600, training_loss: 2.58491e-02
I0213 03:46:15.586551 22542570456896 run_lib.py:146] step: 1133600, eval_loss: 3.45856e-02
I0213 03:46:32.924284 22542570456896 run_lib.py:133] step: 1133650, training_loss: 3.14232e-02
I0213 03:46:50.342362 22542570456896 run_lib.py:133] step: 1133700, training_loss: 2.39619e-02
I0213 03:46:50.503850 22542570456896 run_lib.py:146] step: 1133700, eval_loss: 3.04001e-02
I0213 03:47:07.730448 22542570456896 run_lib.py:133] step: 1133750, training_loss: 2.39476e-02
I0213 03:47:24.964436 22542570456896 run_lib.py:133] step: 1133800, training_loss: 2.65694e-02
I0213 03:47:25.122482 22542570456896 run_lib.py:146] step: 1133800, eval_loss: 3.70946e-02
I0213 03:47:42.513014 22542570456896 run_lib.py:133] step: 1133850, training_loss: 2.44221e-02
I0213 03:47:59.772592 22542570456896 run_lib.py:133] step: 1133900, training_loss: 2.86653e-02
I0213 03:47:59.941624 22542570456896 run_lib.py:146] step: 1133900, eval_loss: 3.23312e-02
I0213 03:48:17.243361 22542570456896 run_lib.py:133] step: 1133950, training_loss: 2.38483e-02
I0213 03:48:34.670393 22542570456896 run_lib.py:133] step: 1134000, training_loss: 2.75860e-02
I0213 03:48:34.824011 22542570456896 run_lib.py:146] step: 1134000, eval_loss: 2.84270e-02
I0213 03:48:52.106799 22542570456896 run_lib.py:133] step: 1134050, training_loss: 3.20661e-02
I0213 03:49:09.347853 22542570456896 run_lib.py:133] step: 1134100, training_loss: 2.48666e-02
I0213 03:49:09.497215 22542570456896 run_lib.py:146] step: 1134100, eval_loss: 3.03459e-02
I0213 03:49:26.825359 22542570456896 run_lib.py:133] step: 1134150, training_loss: 3.04450e-02
I0213 03:49:44.077902 22542570456896 run_lib.py:133] step: 1134200, training_loss: 2.25722e-02
I0213 03:49:44.247157 22542570456896 run_lib.py:146] step: 1134200, eval_loss: 2.78828e-02
I0213 03:50:01.547740 22542570456896 run_lib.py:133] step: 1134250, training_loss: 2.67396e-02
I0213 03:50:18.812290 22542570456896 run_lib.py:133] step: 1134300, training_loss: 2.66939e-02
I0213 03:50:18.969035 22542570456896 run_lib.py:146] step: 1134300, eval_loss: 2.79682e-02
I0213 03:50:36.386279 22542570456896 run_lib.py:133] step: 1134350, training_loss: 2.94325e-02
I0213 03:50:53.684728 22542570456896 run_lib.py:133] step: 1134400, training_loss: 2.79056e-02
I0213 03:50:53.838095 22542570456896 run_lib.py:146] step: 1134400, eval_loss: 3.48523e-02
I0213 03:51:11.081978 22542570456896 run_lib.py:133] step: 1134450, training_loss: 2.17337e-02
I0213 03:51:28.358340 22542570456896 run_lib.py:133] step: 1134500, training_loss: 3.27555e-02
I0213 03:51:28.511493 22542570456896 run_lib.py:146] step: 1134500, eval_loss: 2.54664e-02
I0213 03:51:45.998829 22542570456896 run_lib.py:133] step: 1134550, training_loss: 2.51198e-02
I0213 03:52:03.241180 22542570456896 run_lib.py:133] step: 1134600, training_loss: 2.91835e-02
I0213 03:52:03.391346 22542570456896 run_lib.py:146] step: 1134600, eval_loss: 3.31495e-02
I0213 03:52:20.788009 22542570456896 run_lib.py:133] step: 1134650, training_loss: 2.11148e-02
I0213 03:52:37.994399 22542570456896 run_lib.py:133] step: 1134700, training_loss: 2.34893e-02
I0213 03:52:38.147510 22542570456896 run_lib.py:146] step: 1134700, eval_loss: 3.02848e-02
I0213 03:52:55.531312 22542570456896 run_lib.py:133] step: 1134750, training_loss: 2.76141e-02
I0213 03:53:12.849022 22542570456896 run_lib.py:133] step: 1134800, training_loss: 2.84247e-02
I0213 03:53:13.003440 22542570456896 run_lib.py:146] step: 1134800, eval_loss: 2.86914e-02
I0213 03:53:30.406733 22542570456896 run_lib.py:133] step: 1134850, training_loss: 3.15785e-02
I0213 03:53:47.642569 22542570456896 run_lib.py:133] step: 1134900, training_loss: 2.36229e-02
I0213 03:53:47.796027 22542570456896 run_lib.py:146] step: 1134900, eval_loss: 3.03677e-02
I0213 03:54:05.100013 22542570456896 run_lib.py:133] step: 1134950, training_loss: 2.03441e-02
I0213 03:54:22.456326 22542570456896 run_lib.py:133] step: 1135000, training_loss: 1.99000e-02
I0213 03:54:22.613985 22542570456896 run_lib.py:146] step: 1135000, eval_loss: 3.54390e-02
I0213 03:54:39.861088 22542570456896 run_lib.py:133] step: 1135050, training_loss: 2.83481e-02
I0213 03:54:57.172610 22542570456896 run_lib.py:133] step: 1135100, training_loss: 2.64317e-02
I0213 03:54:57.334467 22542570456896 run_lib.py:146] step: 1135100, eval_loss: 2.42687e-02
I0213 03:55:14.821893 22542570456896 run_lib.py:133] step: 1135150, training_loss: 3.07928e-02
I0213 03:55:32.056427 22542570456896 run_lib.py:133] step: 1135200, training_loss: 3.14706e-02
I0213 03:55:32.212531 22542570456896 run_lib.py:146] step: 1135200, eval_loss: 3.21176e-02
I0213 03:55:49.584183 22542570456896 run_lib.py:133] step: 1135250, training_loss: 2.68691e-02
I0213 03:56:06.802668 22542570456896 run_lib.py:133] step: 1135300, training_loss: 2.82089e-02
I0213 03:56:06.956256 22542570456896 run_lib.py:146] step: 1135300, eval_loss: 3.21071e-02
I0213 03:56:24.216302 22542570456896 run_lib.py:133] step: 1135350, training_loss: 2.01875e-02
I0213 03:56:41.689610 22542570456896 run_lib.py:133] step: 1135400, training_loss: 2.09714e-02
I0213 03:56:41.844398 22542570456896 run_lib.py:146] step: 1135400, eval_loss: 2.68397e-02
I0213 03:56:59.118002 22542570456896 run_lib.py:133] step: 1135450, training_loss: 2.64646e-02
I0213 03:57:16.355701 22542570456896 run_lib.py:133] step: 1135500, training_loss: 2.75891e-02
I0213 03:57:16.502583 22542570456896 run_lib.py:146] step: 1135500, eval_loss: 3.10327e-02
I0213 03:57:33.738343 22542570456896 run_lib.py:133] step: 1135550, training_loss: 2.40031e-02
I0213 03:57:51.086607 22542570456896 run_lib.py:133] step: 1135600, training_loss: 2.83878e-02
I0213 03:57:51.246544 22542570456896 run_lib.py:146] step: 1135600, eval_loss: 3.10553e-02
I0213 03:58:08.497263 22542570456896 run_lib.py:133] step: 1135650, training_loss: 2.24962e-02
I0213 03:58:25.907920 22542570456896 run_lib.py:133] step: 1135700, training_loss: 3.01548e-02
I0213 03:58:26.063947 22542570456896 run_lib.py:146] step: 1135700, eval_loss: 2.46832e-02
I0213 03:58:43.334255 22542570456896 run_lib.py:133] step: 1135750, training_loss: 2.90753e-02
I0213 03:59:00.570144 22542570456896 run_lib.py:133] step: 1135800, training_loss: 2.84368e-02
I0213 03:59:00.724308 22542570456896 run_lib.py:146] step: 1135800, eval_loss: 2.90908e-02
I0213 03:59:18.119271 22542570456896 run_lib.py:133] step: 1135850, training_loss: 2.70936e-02
I0213 03:59:35.408957 22542570456896 run_lib.py:133] step: 1135900, training_loss: 3.60226e-02
I0213 03:59:35.566472 22542570456896 run_lib.py:146] step: 1135900, eval_loss: 2.65181e-02
I0213 03:59:52.848189 22542570456896 run_lib.py:133] step: 1135950, training_loss: 2.64841e-02
I0213 04:00:10.103291 22542570456896 run_lib.py:133] step: 1136000, training_loss: 2.90070e-02
I0213 04:00:10.253433 22542570456896 run_lib.py:146] step: 1136000, eval_loss: 3.17811e-02
I0213 04:00:27.677143 22542570456896 run_lib.py:133] step: 1136050, training_loss: 2.84774e-02
I0213 04:00:44.980237 22542570456896 run_lib.py:133] step: 1136100, training_loss: 2.67492e-02
I0213 04:00:45.138464 22542570456896 run_lib.py:146] step: 1136100, eval_loss: 3.24688e-02
I0213 04:01:02.498638 22542570456896 run_lib.py:133] step: 1136150, training_loss: 2.49031e-02
I0213 04:01:19.789545 22542570456896 run_lib.py:133] step: 1136200, training_loss: 3.16437e-02
I0213 04:01:19.964319 22542570456896 run_lib.py:146] step: 1136200, eval_loss: 3.47470e-02
I0213 04:01:37.448640 22542570456896 run_lib.py:133] step: 1136250, training_loss: 2.66284e-02
I0213 04:01:54.735510 22542570456896 run_lib.py:133] step: 1136300, training_loss: 2.97279e-02
I0213 04:01:54.889545 22542570456896 run_lib.py:146] step: 1136300, eval_loss: 2.62842e-02
I0213 04:02:12.143161 22542570456896 run_lib.py:133] step: 1136350, training_loss: 1.79646e-02
I0213 04:02:29.516208 22542570456896 run_lib.py:133] step: 1136400, training_loss: 3.01446e-02
I0213 04:02:29.669013 22542570456896 run_lib.py:146] step: 1136400, eval_loss: 3.22318e-02
I0213 04:02:46.922332 22542570456896 run_lib.py:133] step: 1136450, training_loss: 2.85334e-02
I0213 04:03:04.316858 22542570456896 run_lib.py:133] step: 1136500, training_loss: 2.89151e-02
I0213 04:03:04.473436 22542570456896 run_lib.py:146] step: 1136500, eval_loss: 2.43717e-02
I0213 04:03:21.759981 22542570456896 run_lib.py:133] step: 1136550, training_loss: 2.20754e-02
I0213 04:03:39.011073 22542570456896 run_lib.py:133] step: 1136600, training_loss: 2.50417e-02
I0213 04:03:39.166414 22542570456896 run_lib.py:146] step: 1136600, eval_loss: 2.39057e-02
I0213 04:03:56.593242 22542570456896 run_lib.py:133] step: 1136650, training_loss: 2.50820e-02
I0213 04:04:13.810270 22542570456896 run_lib.py:133] step: 1136700, training_loss: 3.24267e-02
I0213 04:04:13.963904 22542570456896 run_lib.py:146] step: 1136700, eval_loss: 2.48764e-02
I0213 04:04:31.238501 22542570456896 run_lib.py:133] step: 1136750, training_loss: 2.87977e-02
I0213 04:04:48.701362 22542570456896 run_lib.py:133] step: 1136800, training_loss: 2.30498e-02
I0213 04:04:48.856029 22542570456896 run_lib.py:146] step: 1136800, eval_loss: 3.33587e-02
I0213 04:05:06.133284 22542570456896 run_lib.py:133] step: 1136850, training_loss: 2.58875e-02
I0213 04:05:23.399092 22542570456896 run_lib.py:133] step: 1136900, training_loss: 2.35645e-02
I0213 04:05:23.724339 22542570456896 run_lib.py:146] step: 1136900, eval_loss: 2.72278e-02
I0213 04:05:40.996725 22542570456896 run_lib.py:133] step: 1136950, training_loss: 2.11307e-02
I0213 04:05:58.262163 22542570456896 run_lib.py:133] step: 1137000, training_loss: 3.57296e-02
I0213 04:05:58.418420 22542570456896 run_lib.py:146] step: 1137000, eval_loss: 2.85511e-02
I0213 04:06:15.684513 22542570456896 run_lib.py:133] step: 1137050, training_loss: 2.77862e-02
I0213 04:06:33.000033 22542570456896 run_lib.py:133] step: 1137100, training_loss: 2.93541e-02
I0213 04:06:33.157256 22542570456896 run_lib.py:146] step: 1137100, eval_loss: 2.67948e-02
I0213 04:06:50.587537 22542570456896 run_lib.py:133] step: 1137150, training_loss: 2.37047e-02
I0213 04:07:07.890359 22542570456896 run_lib.py:133] step: 1137200, training_loss: 2.69828e-02
I0213 04:07:08.045261 22542570456896 run_lib.py:146] step: 1137200, eval_loss: 3.03059e-02
I0213 04:07:25.305687 22542570456896 run_lib.py:133] step: 1137250, training_loss: 2.47794e-02
I0213 04:07:42.597254 22542570456896 run_lib.py:133] step: 1137300, training_loss: 3.11274e-02
I0213 04:07:42.755481 22542570456896 run_lib.py:146] step: 1137300, eval_loss: 2.73775e-02
I0213 04:08:00.230113 22542570456896 run_lib.py:133] step: 1137350, training_loss: 2.76206e-02
I0213 04:08:17.583133 22542570456896 run_lib.py:133] step: 1137400, training_loss: 2.02990e-02
I0213 04:08:17.733265 22542570456896 run_lib.py:146] step: 1137400, eval_loss: 2.92969e-02
I0213 04:08:34.992445 22542570456896 run_lib.py:133] step: 1137450, training_loss: 2.66962e-02
I0213 04:08:52.250245 22542570456896 run_lib.py:133] step: 1137500, training_loss: 2.81801e-02
I0213 04:08:52.407263 22542570456896 run_lib.py:146] step: 1137500, eval_loss: 2.76632e-02
I0213 04:09:09.777237 22542570456896 run_lib.py:133] step: 1137550, training_loss: 3.52369e-02
I0213 04:09:27.058730 22542570456896 run_lib.py:133] step: 1137600, training_loss: 2.82645e-02
I0213 04:09:27.232275 22542570456896 run_lib.py:146] step: 1137600, eval_loss: 2.90846e-02
I0213 04:09:44.744680 22542570456896 run_lib.py:133] step: 1137650, training_loss: 3.01999e-02
I0213 04:10:01.993409 22542570456896 run_lib.py:133] step: 1137700, training_loss: 2.47282e-02
I0213 04:10:02.146914 22542570456896 run_lib.py:146] step: 1137700, eval_loss: 3.31290e-02
I0213 04:10:19.501331 22542570456896 run_lib.py:133] step: 1137750, training_loss: 2.17957e-02
I0213 04:10:36.757138 22542570456896 run_lib.py:133] step: 1137800, training_loss: 2.22803e-02
I0213 04:10:36.911220 22542570456896 run_lib.py:146] step: 1137800, eval_loss: 2.79504e-02
I0213 04:10:54.238109 22542570456896 run_lib.py:133] step: 1137850, training_loss: 3.02275e-02
I0213 04:11:11.693182 22542570456896 run_lib.py:133] step: 1137900, training_loss: 2.72979e-02
I0213 04:11:11.850503 22542570456896 run_lib.py:146] step: 1137900, eval_loss: 2.22479e-02
I0213 04:11:29.134094 22542570456896 run_lib.py:133] step: 1137950, training_loss: 2.43291e-02
I0213 04:11:46.579347 22542570456896 run_lib.py:133] step: 1138000, training_loss: 3.07470e-02
I0213 04:11:46.735351 22542570456896 run_lib.py:146] step: 1138000, eval_loss: 3.23036e-02
I0213 04:12:03.978267 22542570456896 run_lib.py:133] step: 1138050, training_loss: 2.64217e-02
I0213 04:12:21.202800 22542570456896 run_lib.py:133] step: 1138100, training_loss: 2.66890e-02
I0213 04:12:21.362233 22542570456896 run_lib.py:146] step: 1138100, eval_loss: 2.91642e-02
I0213 04:12:38.765470 22542570456896 run_lib.py:133] step: 1138150, training_loss: 2.47197e-02
I0213 04:12:56.053375 22542570456896 run_lib.py:133] step: 1138200, training_loss: 2.69479e-02
I0213 04:12:56.203078 22542570456896 run_lib.py:146] step: 1138200, eval_loss: 2.91031e-02
I0213 04:13:13.500359 22542570456896 run_lib.py:133] step: 1138250, training_loss: 2.93449e-02
I0213 04:13:30.746253 22542570456896 run_lib.py:133] step: 1138300, training_loss: 3.24340e-02
I0213 04:13:30.897969 22542570456896 run_lib.py:146] step: 1138300, eval_loss: 2.97320e-02
I0213 04:13:48.328431 22542570456896 run_lib.py:133] step: 1138350, training_loss: 2.93509e-02
I0213 04:14:05.622701 22542570456896 run_lib.py:133] step: 1138400, training_loss: 2.89031e-02
I0213 04:14:05.775360 22542570456896 run_lib.py:146] step: 1138400, eval_loss: 4.01057e-02
I0213 04:14:23.155691 22542570456896 run_lib.py:133] step: 1138450, training_loss: 2.11105e-02
I0213 04:14:40.411244 22542570456896 run_lib.py:133] step: 1138500, training_loss: 2.73927e-02
I0213 04:14:40.568228 22542570456896 run_lib.py:146] step: 1138500, eval_loss: 2.76628e-02
I0213 04:14:57.811500 22542570456896 run_lib.py:133] step: 1138550, training_loss: 2.78551e-02
I0213 04:15:15.025210 22542570456896 run_lib.py:133] step: 1138600, training_loss: 2.53641e-02
I0213 04:15:15.179330 22542570456896 run_lib.py:146] step: 1138600, eval_loss: 2.53923e-02
I0213 04:15:32.602172 22542570456896 run_lib.py:133] step: 1138650, training_loss: 2.98870e-02
I0213 04:15:49.938812 22542570456896 run_lib.py:133] step: 1138700, training_loss: 2.28602e-02
I0213 04:15:50.094165 22542570456896 run_lib.py:146] step: 1138700, eval_loss: 3.01825e-02
I0213 04:16:07.345466 22542570456896 run_lib.py:133] step: 1138750, training_loss: 2.69309e-02
I0213 04:16:24.586281 22542570456896 run_lib.py:133] step: 1138800, training_loss: 2.67836e-02
I0213 04:16:24.739371 22542570456896 run_lib.py:146] step: 1138800, eval_loss: 2.46889e-02
I0213 04:16:42.155376 22542570456896 run_lib.py:133] step: 1138850, training_loss: 2.04020e-02
I0213 04:16:59.393529 22542570456896 run_lib.py:133] step: 1138900, training_loss: 3.07620e-02
I0213 04:16:59.546263 22542570456896 run_lib.py:146] step: 1138900, eval_loss: 2.72658e-02
I0213 04:17:16.925262 22542570456896 run_lib.py:133] step: 1138950, training_loss: 2.43439e-02
I0213 04:17:34.179061 22542570456896 run_lib.py:133] step: 1139000, training_loss: 2.37565e-02
I0213 04:17:34.350296 22542570456896 run_lib.py:146] step: 1139000, eval_loss: 2.68617e-02
I0213 04:17:51.834146 22542570456896 run_lib.py:133] step: 1139050, training_loss: 2.22001e-02
I0213 04:18:09.047863 22542570456896 run_lib.py:133] step: 1139100, training_loss: 3.32506e-02
I0213 04:18:09.202449 22542570456896 run_lib.py:146] step: 1139100, eval_loss: 3.35926e-02
I0213 04:18:26.561223 22542570456896 run_lib.py:133] step: 1139150, training_loss: 2.87882e-02
I0213 04:18:43.792600 22542570456896 run_lib.py:133] step: 1139200, training_loss: 2.89232e-02
I0213 04:18:43.953464 22542570456896 run_lib.py:146] step: 1139200, eval_loss: 2.65989e-02
I0213 04:19:01.204060 22542570456896 run_lib.py:133] step: 1139250, training_loss: 3.09368e-02
I0213 04:19:18.629303 22542570456896 run_lib.py:133] step: 1139300, training_loss: 3.41168e-02
I0213 04:19:18.782516 22542570456896 run_lib.py:146] step: 1139300, eval_loss: 3.13960e-02
I0213 04:19:36.029615 22542570456896 run_lib.py:133] step: 1139350, training_loss: 2.27879e-02
I0213 04:19:53.280274 22542570456896 run_lib.py:133] step: 1139400, training_loss: 1.91580e-02
I0213 04:19:53.434341 22542570456896 run_lib.py:146] step: 1139400, eval_loss: 2.76835e-02
I0213 04:20:10.846379 22542570456896 run_lib.py:133] step: 1139450, training_loss: 3.15511e-02
I0213 04:20:28.209343 22542570456896 run_lib.py:133] step: 1139500, training_loss: 2.51893e-02
I0213 04:20:28.382360 22542570456896 run_lib.py:146] step: 1139500, eval_loss: 3.25413e-02
I0213 04:20:45.666401 22542570456896 run_lib.py:133] step: 1139550, training_loss: 2.29221e-02
I0213 04:21:02.916676 22542570456896 run_lib.py:133] step: 1139600, training_loss: 3.39890e-02
I0213 04:21:03.071591 22542570456896 run_lib.py:146] step: 1139600, eval_loss: 2.97042e-02
I0213 04:21:20.349347 22542570456896 run_lib.py:133] step: 1139650, training_loss: 2.45317e-02
I0213 04:21:37.748707 22542570456896 run_lib.py:133] step: 1139700, training_loss: 2.50821e-02
I0213 04:21:37.899168 22542570456896 run_lib.py:146] step: 1139700, eval_loss: 3.30816e-02
I0213 04:21:55.118143 22542570456896 run_lib.py:133] step: 1139750, training_loss: 2.86187e-02
I0213 04:22:12.420530 22542570456896 run_lib.py:133] step: 1139800, training_loss: 2.76217e-02
I0213 04:22:12.573554 22542570456896 run_lib.py:146] step: 1139800, eval_loss: 2.58176e-02
I0213 04:22:29.850512 22542570456896 run_lib.py:133] step: 1139850, training_loss: 2.21036e-02
I0213 04:22:47.284170 22542570456896 run_lib.py:133] step: 1139900, training_loss: 3.09654e-02
I0213 04:22:47.441243 22542570456896 run_lib.py:146] step: 1139900, eval_loss: 3.20464e-02
I0213 04:23:04.656918 22542570456896 run_lib.py:133] step: 1139950, training_loss: 2.19545e-02
I0213 04:23:21.949658 22542570456896 run_lib.py:133] step: 1140000, training_loss: 2.62593e-02
I0213 04:23:22.630334 22542570456896 run_lib.py:146] step: 1140000, eval_loss: 2.38135e-02
I0213 04:23:42.477969 22542570456896 run_lib.py:133] step: 1140050, training_loss: 2.21249e-02
I0213 04:23:59.823619 22542570456896 run_lib.py:133] step: 1140100, training_loss: 2.59913e-02
I0213 04:23:59.978427 22542570456896 run_lib.py:146] step: 1140100, eval_loss: 3.53341e-02
I0213 04:24:17.232475 22542570456896 run_lib.py:133] step: 1140150, training_loss: 2.47002e-02
I0213 04:24:34.641764 22542570456896 run_lib.py:133] step: 1140200, training_loss: 2.84902e-02
I0213 04:24:34.795473 22542570456896 run_lib.py:146] step: 1140200, eval_loss: 3.10197e-02
I0213 04:24:52.002480 22542570456896 run_lib.py:133] step: 1140250, training_loss: 2.70303e-02
I0213 04:25:09.295040 22542570456896 run_lib.py:133] step: 1140300, training_loss: 3.73621e-02
I0213 04:25:09.444241 22542570456896 run_lib.py:146] step: 1140300, eval_loss: 2.45306e-02
I0213 04:25:26.673885 22542570456896 run_lib.py:133] step: 1140350, training_loss: 2.38961e-02
I0213 04:25:43.977989 22542570456896 run_lib.py:133] step: 1140400, training_loss: 2.78676e-02
I0213 04:25:44.145450 22542570456896 run_lib.py:146] step: 1140400, eval_loss: 2.82073e-02
I0213 04:26:01.569855 22542570456896 run_lib.py:133] step: 1140450, training_loss: 2.21268e-02
I0213 04:26:18.896352 22542570456896 run_lib.py:133] step: 1140500, training_loss: 3.30902e-02
I0213 04:26:19.052581 22542570456896 run_lib.py:146] step: 1140500, eval_loss: 2.54579e-02
I0213 04:26:36.292432 22542570456896 run_lib.py:133] step: 1140550, training_loss: 3.02207e-02
I0213 04:26:53.545184 22542570456896 run_lib.py:133] step: 1140600, training_loss: 2.32535e-02
I0213 04:26:53.698341 22542570456896 run_lib.py:146] step: 1140600, eval_loss: 2.46375e-02
I0213 04:27:11.068414 22542570456896 run_lib.py:133] step: 1140650, training_loss: 2.94575e-02
I0213 04:27:28.340655 22542570456896 run_lib.py:133] step: 1140700, training_loss: 3.15629e-02
I0213 04:27:28.495423 22542570456896 run_lib.py:146] step: 1140700, eval_loss: 2.60615e-02
I0213 04:27:45.959869 22542570456896 run_lib.py:133] step: 1140750, training_loss: 3.28855e-02
I0213 04:28:03.235029 22542570456896 run_lib.py:133] step: 1140800, training_loss: 2.99343e-02
I0213 04:28:03.385262 22542570456896 run_lib.py:146] step: 1140800, eval_loss: 2.64053e-02
I0213 04:28:20.786567 22542570456896 run_lib.py:133] step: 1140850, training_loss: 3.87696e-02
I0213 04:28:38.066329 22542570456896 run_lib.py:133] step: 1140900, training_loss: 2.91218e-02
I0213 04:28:38.220432 22542570456896 run_lib.py:146] step: 1140900, eval_loss: 3.66454e-02
I0213 04:28:55.439427 22542570456896 run_lib.py:133] step: 1140950, training_loss: 1.94748e-02
I0213 04:29:12.941221 22542570456896 run_lib.py:133] step: 1141000, training_loss: 2.78705e-02
I0213 04:29:13.098476 22542570456896 run_lib.py:146] step: 1141000, eval_loss: 2.79752e-02
I0213 04:29:30.338183 22542570456896 run_lib.py:133] step: 1141050, training_loss: 2.01514e-02
I0213 04:29:47.721083 22542570456896 run_lib.py:133] step: 1141100, training_loss: 2.64399e-02
I0213 04:29:47.874206 22542570456896 run_lib.py:146] step: 1141100, eval_loss: 2.34958e-02
I0213 04:30:05.100450 22542570456896 run_lib.py:133] step: 1141150, training_loss: 2.23009e-02
I0213 04:30:22.378255 22542570456896 run_lib.py:133] step: 1141200, training_loss: 2.48981e-02
I0213 04:30:22.535266 22542570456896 run_lib.py:146] step: 1141200, eval_loss: 2.76045e-02
I0213 04:30:39.946790 22542570456896 run_lib.py:133] step: 1141250, training_loss: 3.15737e-02
I0213 04:30:57.309440 22542570456896 run_lib.py:133] step: 1141300, training_loss: 2.44987e-02
I0213 04:30:57.462634 22542570456896 run_lib.py:146] step: 1141300, eval_loss: 2.63830e-02
I0213 04:31:14.745666 22542570456896 run_lib.py:133] step: 1141350, training_loss: 3.05406e-02
I0213 04:31:32.191152 22542570456896 run_lib.py:133] step: 1141400, training_loss: 2.47039e-02
I0213 04:31:32.353538 22542570456896 run_lib.py:146] step: 1141400, eval_loss: 2.74592e-02
I0213 04:31:49.640354 22542570456896 run_lib.py:133] step: 1141450, training_loss: 2.92088e-02
I0213 04:32:06.881308 22542570456896 run_lib.py:133] step: 1141500, training_loss: 2.75802e-02
I0213 04:32:07.038454 22542570456896 run_lib.py:146] step: 1141500, eval_loss: 3.37059e-02
I0213 04:32:24.349745 22542570456896 run_lib.py:133] step: 1141550, training_loss: 3.18449e-02
I0213 04:32:41.667505 22542570456896 run_lib.py:133] step: 1141600, training_loss: 3.29212e-02
I0213 04:32:41.820605 22542570456896 run_lib.py:146] step: 1141600, eval_loss: 3.08492e-02
I0213 04:32:59.062936 22542570456896 run_lib.py:133] step: 1141650, training_loss: 3.01578e-02
I0213 04:33:16.309115 22542570456896 run_lib.py:133] step: 1141700, training_loss: 2.99967e-02
I0213 04:33:16.460361 22542570456896 run_lib.py:146] step: 1141700, eval_loss: 2.96683e-02
I0213 04:33:33.870957 22542570456896 run_lib.py:133] step: 1141750, training_loss: 2.80975e-02
I0213 04:33:51.184095 22542570456896 run_lib.py:133] step: 1141800, training_loss: 2.62605e-02
I0213 04:33:51.341409 22542570456896 run_lib.py:146] step: 1141800, eval_loss: 4.15043e-02
I0213 04:34:08.657961 22542570456896 run_lib.py:133] step: 1141850, training_loss: 2.94508e-02
I0213 04:34:25.915894 22542570456896 run_lib.py:133] step: 1141900, training_loss: 2.57423e-02
I0213 04:34:26.072269 22542570456896 run_lib.py:146] step: 1141900, eval_loss: 2.71653e-02
I0213 04:34:43.510478 22542570456896 run_lib.py:133] step: 1141950, training_loss: 3.08204e-02
I0213 04:35:00.782921 22542570456896 run_lib.py:133] step: 1142000, training_loss: 2.55244e-02
I0213 04:35:00.937231 22542570456896 run_lib.py:146] step: 1142000, eval_loss: 2.53937e-02
I0213 04:35:18.363604 22542570456896 run_lib.py:133] step: 1142050, training_loss: 2.45479e-02
I0213 04:35:35.664182 22542570456896 run_lib.py:133] step: 1142100, training_loss: 3.16431e-02
I0213 04:35:35.819022 22542570456896 run_lib.py:146] step: 1142100, eval_loss: 3.14013e-02
I0213 04:35:53.278430 22542570456896 run_lib.py:133] step: 1142150, training_loss: 3.26997e-02
I0213 04:36:10.518562 22542570456896 run_lib.py:133] step: 1142200, training_loss: 2.05659e-02
I0213 04:36:10.673869 22542570456896 run_lib.py:146] step: 1142200, eval_loss: 4.04686e-02
I0213 04:36:28.021297 22542570456896 run_lib.py:133] step: 1142250, training_loss: 3.10632e-02
I0213 04:36:45.245065 22542570456896 run_lib.py:133] step: 1142300, training_loss: 2.42331e-02
I0213 04:36:45.398297 22542570456896 run_lib.py:146] step: 1142300, eval_loss: 2.80170e-02
I0213 04:37:02.649483 22542570456896 run_lib.py:133] step: 1142350, training_loss: 2.90249e-02
I0213 04:37:20.052930 22542570456896 run_lib.py:133] step: 1142400, training_loss: 3.52221e-02
I0213 04:37:20.225270 22542570456896 run_lib.py:146] step: 1142400, eval_loss: 2.76099e-02
I0213 04:37:37.486805 22542570456896 run_lib.py:133] step: 1142450, training_loss: 2.18758e-02
I0213 04:37:54.766935 22542570456896 run_lib.py:133] step: 1142500, training_loss: 3.06186e-02
I0213 04:37:54.921550 22542570456896 run_lib.py:146] step: 1142500, eval_loss: 3.22435e-02
I0213 04:38:12.399398 22542570456896 run_lib.py:133] step: 1142550, training_loss: 2.62126e-02
I0213 04:38:29.646962 22542570456896 run_lib.py:133] step: 1142600, training_loss: 2.30728e-02
I0213 04:38:29.800235 22542570456896 run_lib.py:146] step: 1142600, eval_loss: 3.16133e-02
I0213 04:38:47.156046 22542570456896 run_lib.py:133] step: 1142650, training_loss: 2.99927e-02
I0213 04:39:04.421043 22542570456896 run_lib.py:133] step: 1142700, training_loss: 3.03705e-02
I0213 04:39:04.572422 22542570456896 run_lib.py:146] step: 1142700, eval_loss: 3.05303e-02
I0213 04:39:21.884606 22542570456896 run_lib.py:133] step: 1142750, training_loss: 2.09223e-02
I0213 04:39:39.342073 22542570456896 run_lib.py:133] step: 1142800, training_loss: 2.09296e-02
I0213 04:39:39.496218 22542570456896 run_lib.py:146] step: 1142800, eval_loss: 3.06340e-02
I0213 04:39:56.696683 22542570456896 run_lib.py:133] step: 1142850, training_loss: 2.01815e-02
I0213 04:40:13.916093 22542570456896 run_lib.py:133] step: 1142900, training_loss: 3.35262e-02
I0213 04:40:14.077293 22542570456896 run_lib.py:146] step: 1142900, eval_loss: 3.11357e-02
I0213 04:40:31.373059 22542570456896 run_lib.py:133] step: 1142950, training_loss: 2.90094e-02
I0213 04:40:48.833532 22542570456896 run_lib.py:133] step: 1143000, training_loss: 2.44729e-02
I0213 04:40:48.987015 22542570456896 run_lib.py:146] step: 1143000, eval_loss: 2.73607e-02
I0213 04:41:06.276778 22542570456896 run_lib.py:133] step: 1143050, training_loss: 2.62914e-02
I0213 04:41:23.579770 22542570456896 run_lib.py:133] step: 1143100, training_loss: 2.47038e-02
I0213 04:41:23.733014 22542570456896 run_lib.py:146] step: 1143100, eval_loss: 3.50052e-02
I0213 04:41:40.996955 22542570456896 run_lib.py:133] step: 1143150, training_loss: 2.39618e-02
I0213 04:41:58.295063 22542570456896 run_lib.py:133] step: 1143200, training_loss: 2.45533e-02
I0213 04:41:58.448423 22542570456896 run_lib.py:146] step: 1143200, eval_loss: 3.34238e-02
I0213 04:42:15.912524 22542570456896 run_lib.py:133] step: 1143250, training_loss: 1.92487e-02
I0213 04:42:33.256089 22542570456896 run_lib.py:133] step: 1143300, training_loss: 2.63702e-02
I0213 04:42:33.412237 22542570456896 run_lib.py:146] step: 1143300, eval_loss: 2.60832e-02
I0213 04:42:50.676168 22542570456896 run_lib.py:133] step: 1143350, training_loss: 2.54109e-02
I0213 04:43:07.930034 22542570456896 run_lib.py:133] step: 1143400, training_loss: 3.24649e-02
I0213 04:43:08.084304 22542570456896 run_lib.py:146] step: 1143400, eval_loss: 2.36548e-02
I0213 04:43:25.456525 22542570456896 run_lib.py:133] step: 1143450, training_loss: 2.44981e-02
I0213 04:43:42.792315 22542570456896 run_lib.py:133] step: 1143500, training_loss: 2.70485e-02
I0213 04:43:42.954575 22542570456896 run_lib.py:146] step: 1143500, eval_loss: 2.75170e-02
I0213 04:44:00.427246 22542570456896 run_lib.py:133] step: 1143550, training_loss: 2.65589e-02
I0213 04:44:17.645301 22542570456896 run_lib.py:133] step: 1143600, training_loss: 3.06153e-02
I0213 04:44:17.795022 22542570456896 run_lib.py:146] step: 1143600, eval_loss: 3.06596e-02
I0213 04:44:35.208287 22542570456896 run_lib.py:133] step: 1143650, training_loss: 2.66275e-02
I0213 04:44:52.430605 22542570456896 run_lib.py:133] step: 1143700, training_loss: 2.48664e-02
I0213 04:44:52.582207 22542570456896 run_lib.py:146] step: 1143700, eval_loss: 3.41330e-02
I0213 04:45:09.850488 22542570456896 run_lib.py:133] step: 1143750, training_loss: 2.51901e-02
I0213 04:45:27.298642 22542570456896 run_lib.py:133] step: 1143800, training_loss: 2.71185e-02
I0213 04:45:27.469335 22542570456896 run_lib.py:146] step: 1143800, eval_loss: 3.05356e-02
I0213 04:45:44.776087 22542570456896 run_lib.py:133] step: 1143850, training_loss: 2.72870e-02
I0213 04:46:02.211253 22542570456896 run_lib.py:133] step: 1143900, training_loss: 2.84192e-02
I0213 04:46:02.365226 22542570456896 run_lib.py:146] step: 1143900, eval_loss: 3.13707e-02
I0213 04:46:19.621421 22542570456896 run_lib.py:133] step: 1143950, training_loss: 2.33325e-02
I0213 04:46:36.860211 22542570456896 run_lib.py:133] step: 1144000, training_loss: 2.26719e-02
I0213 04:46:37.014419 22542570456896 run_lib.py:146] step: 1144000, eval_loss: 2.94041e-02
I0213 04:46:54.383632 22542570456896 run_lib.py:133] step: 1144050, training_loss: 2.71564e-02
I0213 04:47:11.740863 22542570456896 run_lib.py:133] step: 1144100, training_loss: 2.50392e-02
I0213 04:47:11.892509 22542570456896 run_lib.py:146] step: 1144100, eval_loss: 2.52934e-02
I0213 04:47:29.125700 22542570456896 run_lib.py:133] step: 1144150, training_loss: 3.35742e-02
I0213 04:47:46.530532 22542570456896 run_lib.py:133] step: 1144200, training_loss: 2.64410e-02
I0213 04:47:46.687272 22542570456896 run_lib.py:146] step: 1144200, eval_loss: 3.18334e-02
I0213 04:48:03.915284 22542570456896 run_lib.py:133] step: 1144250, training_loss: 2.97122e-02
I0213 04:48:21.223155 22542570456896 run_lib.py:133] step: 1144300, training_loss: 2.74707e-02
I0213 04:48:21.515300 22542570456896 run_lib.py:146] step: 1144300, eval_loss: 2.96855e-02
I0213 04:48:38.790090 22542570456896 run_lib.py:133] step: 1144350, training_loss: 2.10657e-02
I0213 04:48:56.075036 22542570456896 run_lib.py:133] step: 1144400, training_loss: 3.18032e-02
I0213 04:48:56.229488 22542570456896 run_lib.py:146] step: 1144400, eval_loss: 2.60855e-02
I0213 04:49:13.511233 22542570456896 run_lib.py:133] step: 1144450, training_loss: 2.76382e-02
I0213 04:49:30.767077 22542570456896 run_lib.py:133] step: 1144500, training_loss: 2.57569e-02
I0213 04:49:30.920199 22542570456896 run_lib.py:146] step: 1144500, eval_loss: 2.63906e-02
I0213 04:49:48.335598 22542570456896 run_lib.py:133] step: 1144550, training_loss: 2.83027e-02
I0213 04:50:05.615403 22542570456896 run_lib.py:133] step: 1144600, training_loss: 2.79026e-02
I0213 04:50:05.772570 22542570456896 run_lib.py:146] step: 1144600, eval_loss: 3.12656e-02
I0213 04:50:23.029567 22542570456896 run_lib.py:133] step: 1144650, training_loss: 2.33303e-02
I0213 04:50:40.285509 22542570456896 run_lib.py:133] step: 1144700, training_loss: 2.99614e-02
I0213 04:50:40.439026 22542570456896 run_lib.py:146] step: 1144700, eval_loss: 3.46483e-02
I0213 04:50:57.857710 22542570456896 run_lib.py:133] step: 1144750, training_loss: 2.51111e-02
I0213 04:51:15.155155 22542570456896 run_lib.py:133] step: 1144800, training_loss: 2.88596e-02
I0213 04:51:15.313480 22542570456896 run_lib.py:146] step: 1144800, eval_loss: 2.89504e-02
I0213 04:51:32.526204 22542570456896 run_lib.py:133] step: 1144850, training_loss: 3.27371e-02
I0213 04:51:49.789934 22542570456896 run_lib.py:133] step: 1144900, training_loss: 2.30002e-02
I0213 04:51:49.955290 22542570456896 run_lib.py:146] step: 1144900, eval_loss: 3.21316e-02
I0213 04:52:07.345589 22542570456896 run_lib.py:133] step: 1144950, training_loss: 3.04365e-02
I0213 04:52:24.628098 22542570456896 run_lib.py:133] step: 1145000, training_loss: 2.35522e-02
I0213 04:52:24.780025 22542570456896 run_lib.py:146] step: 1145000, eval_loss: 2.81952e-02
I0213 04:52:42.215772 22542570456896 run_lib.py:133] step: 1145050, training_loss: 2.32686e-02
I0213 04:52:59.487991 22542570456896 run_lib.py:133] step: 1145100, training_loss: 3.20369e-02
I0213 04:52:59.639269 22542570456896 run_lib.py:146] step: 1145100, eval_loss: 2.95551e-02
I0213 04:53:16.988473 22542570456896 run_lib.py:133] step: 1145150, training_loss: 1.99351e-02
I0213 04:53:34.225933 22542570456896 run_lib.py:133] step: 1145200, training_loss: 2.56363e-02
I0213 04:53:34.394259 22542570456896 run_lib.py:146] step: 1145200, eval_loss: 2.53903e-02
I0213 04:53:51.684554 22542570456896 run_lib.py:133] step: 1145250, training_loss: 1.93847e-02
I0213 04:54:09.155234 22542570456896 run_lib.py:133] step: 1145300, training_loss: 2.90063e-02
I0213 04:54:09.311518 22542570456896 run_lib.py:146] step: 1145300, eval_loss: 3.39255e-02
I0213 04:54:26.531142 22542570456896 run_lib.py:133] step: 1145350, training_loss: 3.38927e-02
I0213 04:54:43.889694 22542570456896 run_lib.py:133] step: 1145400, training_loss: 2.93562e-02
I0213 04:54:44.044061 22542570456896 run_lib.py:146] step: 1145400, eval_loss: 3.28643e-02
I0213 04:55:01.290347 22542570456896 run_lib.py:133] step: 1145450, training_loss: 2.92729e-02
I0213 04:55:18.627495 22542570456896 run_lib.py:133] step: 1145500, training_loss: 2.17809e-02
I0213 04:55:18.779899 22542570456896 run_lib.py:146] step: 1145500, eval_loss: 2.90696e-02
I0213 04:55:36.262011 22542570456896 run_lib.py:133] step: 1145550, training_loss: 2.99982e-02
I0213 04:55:53.516332 22542570456896 run_lib.py:133] step: 1145600, training_loss: 2.61492e-02
I0213 04:55:53.670292 22542570456896 run_lib.py:146] step: 1145600, eval_loss: 2.58707e-02
I0213 04:56:10.909404 22542570456896 run_lib.py:133] step: 1145650, training_loss: 2.72642e-02
I0213 04:56:28.166384 22542570456896 run_lib.py:133] step: 1145700, training_loss: 2.78687e-02
I0213 04:56:28.324474 22542570456896 run_lib.py:146] step: 1145700, eval_loss: 3.30718e-02
I0213 04:56:45.721825 22542570456896 run_lib.py:133] step: 1145750, training_loss: 3.00549e-02
I0213 04:57:03.011282 22542570456896 run_lib.py:133] step: 1145800, training_loss: 2.84078e-02
I0213 04:57:03.170589 22542570456896 run_lib.py:146] step: 1145800, eval_loss: 2.46555e-02
I0213 04:57:20.501935 22542570456896 run_lib.py:133] step: 1145850, training_loss: 2.39699e-02
I0213 04:57:37.739003 22542570456896 run_lib.py:133] step: 1145900, training_loss: 1.87716e-02
I0213 04:57:37.892242 22542570456896 run_lib.py:146] step: 1145900, eval_loss: 2.44715e-02
I0213 04:57:55.131179 22542570456896 run_lib.py:133] step: 1145950, training_loss: 2.12596e-02
I0213 04:58:12.398895 22542570456896 run_lib.py:133] step: 1146000, training_loss: 3.26129e-02
I0213 04:58:12.550591 22542570456896 run_lib.py:146] step: 1146000, eval_loss: 3.35280e-02
I0213 04:58:29.946676 22542570456896 run_lib.py:133] step: 1146050, training_loss: 2.81794e-02
I0213 04:58:47.364557 22542570456896 run_lib.py:133] step: 1146100, training_loss: 2.22518e-02
I0213 04:58:47.518199 22542570456896 run_lib.py:146] step: 1146100, eval_loss: 3.02418e-02
I0213 04:59:04.788464 22542570456896 run_lib.py:133] step: 1146150, training_loss: 3.12363e-02
I0213 04:59:22.037416 22542570456896 run_lib.py:133] step: 1146200, training_loss: 2.47789e-02
I0213 04:59:22.192581 22542570456896 run_lib.py:146] step: 1146200, eval_loss: 3.33790e-02
I0213 04:59:39.596426 22542570456896 run_lib.py:133] step: 1146250, training_loss: 2.87040e-02
I0213 04:59:56.906385 22542570456896 run_lib.py:133] step: 1146300, training_loss: 2.53660e-02
I0213 04:59:57.067816 22542570456896 run_lib.py:146] step: 1146300, eval_loss: 2.10209e-02
I0213 05:00:14.462428 22542570456896 run_lib.py:133] step: 1146350, training_loss: 2.48300e-02
I0213 05:00:31.780853 22542570456896 run_lib.py:133] step: 1146400, training_loss: 2.61578e-02
I0213 05:00:31.934736 22542570456896 run_lib.py:146] step: 1146400, eval_loss: 3.17869e-02
I0213 05:00:49.376571 22542570456896 run_lib.py:133] step: 1146450, training_loss: 2.51000e-02
I0213 05:01:06.611122 22542570456896 run_lib.py:133] step: 1146500, training_loss: 2.35844e-02
I0213 05:01:06.760373 22542570456896 run_lib.py:146] step: 1146500, eval_loss: 2.24657e-02
I0213 05:01:24.167385 22542570456896 run_lib.py:133] step: 1146550, training_loss: 2.63374e-02
I0213 05:01:41.384800 22542570456896 run_lib.py:133] step: 1146600, training_loss: 3.18630e-02
I0213 05:01:41.553240 22542570456896 run_lib.py:146] step: 1146600, eval_loss: 2.75840e-02
I0213 05:01:58.921031 22542570456896 run_lib.py:133] step: 1146650, training_loss: 2.38278e-02
I0213 05:02:16.352056 22542570456896 run_lib.py:133] step: 1146700, training_loss: 2.74669e-02
I0213 05:02:16.511299 22542570456896 run_lib.py:146] step: 1146700, eval_loss: 2.89562e-02
I0213 05:02:33.732383 22542570456896 run_lib.py:133] step: 1146750, training_loss: 2.67470e-02
I0213 05:02:50.968255 22542570456896 run_lib.py:133] step: 1146800, training_loss: 2.71574e-02
I0213 05:02:51.123111 22542570456896 run_lib.py:146] step: 1146800, eval_loss: 2.93776e-02
I0213 05:03:08.533221 22542570456896 run_lib.py:133] step: 1146850, training_loss: 3.70042e-02
I0213 05:03:25.939931 22542570456896 run_lib.py:133] step: 1146900, training_loss: 2.69948e-02
I0213 05:03:26.093172 22542570456896 run_lib.py:146] step: 1146900, eval_loss: 2.94374e-02
I0213 05:03:43.440801 22542570456896 run_lib.py:133] step: 1146950, training_loss: 1.90150e-02
I0213 05:04:00.707641 22542570456896 run_lib.py:133] step: 1147000, training_loss: 2.74137e-02
I0213 05:04:00.863477 22542570456896 run_lib.py:146] step: 1147000, eval_loss: 3.45704e-02
I0213 05:04:18.123851 22542570456896 run_lib.py:133] step: 1147050, training_loss: 3.24814e-02
I0213 05:04:35.582577 22542570456896 run_lib.py:133] step: 1147100, training_loss: 2.74019e-02
I0213 05:04:35.740477 22542570456896 run_lib.py:146] step: 1147100, eval_loss: 2.78051e-02
I0213 05:04:52.952435 22542570456896 run_lib.py:133] step: 1147150, training_loss: 2.56695e-02
I0213 05:05:10.255272 22542570456896 run_lib.py:133] step: 1147200, training_loss: 2.54356e-02
I0213 05:05:10.409470 22542570456896 run_lib.py:146] step: 1147200, eval_loss: 2.75312e-02
I0213 05:05:27.718698 22542570456896 run_lib.py:133] step: 1147250, training_loss: 3.37456e-02
I0213 05:05:45.118831 22542570456896 run_lib.py:133] step: 1147300, training_loss: 2.55084e-02
I0213 05:05:45.273041 22542570456896 run_lib.py:146] step: 1147300, eval_loss: 3.10647e-02
I0213 05:06:02.505610 22542570456896 run_lib.py:133] step: 1147350, training_loss: 2.71948e-02
I0213 05:06:19.800501 22542570456896 run_lib.py:133] step: 1147400, training_loss: 2.53677e-02
I0213 05:06:19.953974 22542570456896 run_lib.py:146] step: 1147400, eval_loss: 3.05354e-02
I0213 05:06:37.193065 22542570456896 run_lib.py:133] step: 1147450, training_loss: 2.44207e-02
I0213 05:06:54.461051 22542570456896 run_lib.py:133] step: 1147500, training_loss: 2.55387e-02
I0213 05:06:54.633513 22542570456896 run_lib.py:146] step: 1147500, eval_loss: 2.86910e-02
I0213 05:07:12.066988 22542570456896 run_lib.py:133] step: 1147550, training_loss: 2.01300e-02
I0213 05:07:29.404447 22542570456896 run_lib.py:133] step: 1147600, training_loss: 2.61729e-02
I0213 05:07:29.566217 22542570456896 run_lib.py:146] step: 1147600, eval_loss: 3.59298e-02
I0213 05:07:46.797366 22542570456896 run_lib.py:133] step: 1147650, training_loss: 2.50344e-02
I0213 05:08:04.034386 22542570456896 run_lib.py:133] step: 1147700, training_loss: 3.13587e-02
I0213 05:08:04.191240 22542570456896 run_lib.py:146] step: 1147700, eval_loss: 2.97155e-02
I0213 05:08:21.613769 22542570456896 run_lib.py:133] step: 1147750, training_loss: 2.80525e-02
I0213 05:08:38.943247 22542570456896 run_lib.py:133] step: 1147800, training_loss: 1.96600e-02
I0213 05:08:39.098031 22542570456896 run_lib.py:146] step: 1147800, eval_loss: 2.83788e-02
I0213 05:08:56.595551 22542570456896 run_lib.py:133] step: 1147850, training_loss: 3.39878e-02
I0213 05:09:13.846370 22542570456896 run_lib.py:133] step: 1147900, training_loss: 3.69944e-02
I0213 05:09:13.997254 22542570456896 run_lib.py:146] step: 1147900, eval_loss: 2.91059e-02
I0213 05:09:31.389094 22542570456896 run_lib.py:133] step: 1147950, training_loss: 2.52925e-02
I0213 05:09:48.614523 22542570456896 run_lib.py:133] step: 1148000, training_loss: 2.18007e-02
I0213 05:09:48.768283 22542570456896 run_lib.py:146] step: 1148000, eval_loss: 2.55567e-02
I0213 05:10:06.092402 22542570456896 run_lib.py:133] step: 1148050, training_loss: 2.40042e-02
I0213 05:10:23.543642 22542570456896 run_lib.py:133] step: 1148100, training_loss: 1.99413e-02
I0213 05:10:23.703320 22542570456896 run_lib.py:146] step: 1148100, eval_loss: 2.94527e-02
I0213 05:10:40.968425 22542570456896 run_lib.py:133] step: 1148150, training_loss: 2.40247e-02
I0213 05:10:58.401298 22542570456896 run_lib.py:133] step: 1148200, training_loss: 2.98672e-02
I0213 05:10:58.559317 22542570456896 run_lib.py:146] step: 1148200, eval_loss: 2.16472e-02
I0213 05:11:15.797458 22542570456896 run_lib.py:133] step: 1148250, training_loss: 2.28996e-02
I0213 05:11:33.028603 22542570456896 run_lib.py:133] step: 1148300, training_loss: 2.71325e-02
I0213 05:11:33.183305 22542570456896 run_lib.py:146] step: 1148300, eval_loss: 2.87171e-02
I0213 05:11:50.641333 22542570456896 run_lib.py:133] step: 1148350, training_loss: 2.95349e-02
I0213 05:12:07.955658 22542570456896 run_lib.py:133] step: 1148400, training_loss: 1.90264e-02
I0213 05:12:08.106466 22542570456896 run_lib.py:146] step: 1148400, eval_loss: 3.46884e-02
I0213 05:12:25.369043 22542570456896 run_lib.py:133] step: 1148450, training_loss: 3.24045e-02
I0213 05:12:42.790039 22542570456896 run_lib.py:133] step: 1148500, training_loss: 2.83919e-02
I0213 05:12:42.953889 22542570456896 run_lib.py:146] step: 1148500, eval_loss: 3.31690e-02
I0213 05:13:00.243554 22542570456896 run_lib.py:133] step: 1148550, training_loss: 2.42753e-02
I0213 05:13:17.529246 22542570456896 run_lib.py:133] step: 1148600, training_loss: 2.62070e-02
I0213 05:13:17.688545 22542570456896 run_lib.py:146] step: 1148600, eval_loss: 3.12272e-02
I0213 05:13:35.022019 22542570456896 run_lib.py:133] step: 1148650, training_loss: 2.64607e-02
I0213 05:13:52.341422 22542570456896 run_lib.py:133] step: 1148700, training_loss: 2.01777e-02
I0213 05:13:52.495818 22542570456896 run_lib.py:146] step: 1148700, eval_loss: 3.48741e-02
I0213 05:14:09.754385 22542570456896 run_lib.py:133] step: 1148750, training_loss: 2.79020e-02
I0213 05:14:27.011089 22542570456896 run_lib.py:133] step: 1148800, training_loss: 3.26755e-02
I0213 05:14:27.164288 22542570456896 run_lib.py:146] step: 1148800, eval_loss: 3.27359e-02
I0213 05:14:44.567983 22542570456896 run_lib.py:133] step: 1148850, training_loss: 2.73796e-02
I0213 05:15:01.923764 22542570456896 run_lib.py:133] step: 1148900, training_loss: 2.68285e-02
I0213 05:15:02.075474 22542570456896 run_lib.py:146] step: 1148900, eval_loss: 3.09943e-02
I0213 05:15:19.404675 22542570456896 run_lib.py:133] step: 1148950, training_loss: 3.02582e-02
I0213 05:15:36.692464 22542570456896 run_lib.py:133] step: 1149000, training_loss: 3.06584e-02
I0213 05:15:36.849241 22542570456896 run_lib.py:146] step: 1149000, eval_loss: 2.45796e-02
I0213 05:15:54.283295 22542570456896 run_lib.py:133] step: 1149050, training_loss: 2.58838e-02
I0213 05:16:11.533561 22542570456896 run_lib.py:133] step: 1149100, training_loss: 2.84939e-02
I0213 05:16:11.687293 22542570456896 run_lib.py:146] step: 1149100, eval_loss: 3.68005e-02
I0213 05:16:29.123224 22542570456896 run_lib.py:133] step: 1149150, training_loss: 1.89716e-02
I0213 05:16:46.466438 22542570456896 run_lib.py:133] step: 1149200, training_loss: 2.78892e-02
I0213 05:16:46.624070 22542570456896 run_lib.py:146] step: 1149200, eval_loss: 2.96264e-02
I0213 05:17:04.066068 22542570456896 run_lib.py:133] step: 1149250, training_loss: 2.46710e-02
I0213 05:17:21.308867 22542570456896 run_lib.py:133] step: 1149300, training_loss: 2.77805e-02
I0213 05:17:21.459257 22542570456896 run_lib.py:146] step: 1149300, eval_loss: 3.16309e-02
I0213 05:17:38.858324 22542570456896 run_lib.py:133] step: 1149350, training_loss: 3.42759e-02
I0213 05:17:56.150754 22542570456896 run_lib.py:133] step: 1149400, training_loss: 2.57265e-02
I0213 05:17:56.311830 22542570456896 run_lib.py:146] step: 1149400, eval_loss: 2.90620e-02
I0213 05:18:13.625937 22542570456896 run_lib.py:133] step: 1149450, training_loss: 2.59941e-02
I0213 05:18:31.051448 22542570456896 run_lib.py:133] step: 1149500, training_loss: 2.47297e-02
I0213 05:18:31.211401 22542570456896 run_lib.py:146] step: 1149500, eval_loss: 3.43513e-02
I0213 05:18:48.470200 22542570456896 run_lib.py:133] step: 1149550, training_loss: 3.35288e-02
I0213 05:19:05.745432 22542570456896 run_lib.py:133] step: 1149600, training_loss: 2.52039e-02
I0213 05:19:05.899419 22542570456896 run_lib.py:146] step: 1149600, eval_loss: 3.48972e-02
I0213 05:19:23.369153 22542570456896 run_lib.py:133] step: 1149650, training_loss: 3.11739e-02
I0213 05:19:40.598315 22542570456896 run_lib.py:133] step: 1149700, training_loss: 2.79502e-02
I0213 05:19:40.749334 22542570456896 run_lib.py:146] step: 1149700, eval_loss: 3.15777e-02
I0213 05:19:58.141787 22542570456896 run_lib.py:133] step: 1149750, training_loss: 2.42288e-02
I0213 05:20:15.451104 22542570456896 run_lib.py:133] step: 1149800, training_loss: 2.68404e-02
I0213 05:20:15.601533 22542570456896 run_lib.py:146] step: 1149800, eval_loss: 2.94022e-02
I0213 05:20:32.879667 22542570456896 run_lib.py:133] step: 1149850, training_loss: 3.29893e-02
I0213 05:20:50.311391 22542570456896 run_lib.py:133] step: 1149900, training_loss: 2.84006e-02
I0213 05:20:50.465321 22542570456896 run_lib.py:146] step: 1149900, eval_loss: 2.84918e-02
I0213 05:21:07.682641 22542570456896 run_lib.py:133] step: 1149950, training_loss: 3.16812e-02
I0213 05:21:24.955161 22542570456896 run_lib.py:133] step: 1150000, training_loss: 2.71921e-02
I0213 05:21:25.636389 22542570456896 run_lib.py:146] step: 1150000, eval_loss: 2.40244e-02
I0213 05:21:45.506308 22542570456896 run_lib.py:133] step: 1150050, training_loss: 2.37444e-02
I0213 05:22:02.822700 22542570456896 run_lib.py:133] step: 1150100, training_loss: 2.39732e-02
I0213 05:22:02.979184 22542570456896 run_lib.py:146] step: 1150100, eval_loss: 2.96344e-02
I0213 05:22:20.366577 22542570456896 run_lib.py:133] step: 1150150, training_loss: 2.27109e-02
I0213 05:22:37.632857 22542570456896 run_lib.py:133] step: 1150200, training_loss: 3.78865e-02
I0213 05:22:37.786085 22542570456896 run_lib.py:146] step: 1150200, eval_loss: 2.65204e-02
I0213 05:22:55.085320 22542570456896 run_lib.py:133] step: 1150250, training_loss: 2.95793e-02
I0213 05:23:12.370898 22542570456896 run_lib.py:133] step: 1150300, training_loss: 2.88891e-02
I0213 05:23:12.523178 22542570456896 run_lib.py:146] step: 1150300, eval_loss: 2.88491e-02
I0213 05:23:29.894490 22542570456896 run_lib.py:133] step: 1150350, training_loss: 2.89983e-02
I0213 05:23:47.111487 22542570456896 run_lib.py:133] step: 1150400, training_loss: 2.28369e-02
I0213 05:23:47.265275 22542570456896 run_lib.py:146] step: 1150400, eval_loss: 2.86816e-02
I0213 05:24:04.684867 22542570456896 run_lib.py:133] step: 1150450, training_loss: 3.19881e-02
I0213 05:24:22.005114 22542570456896 run_lib.py:133] step: 1150500, training_loss: 2.44099e-02
I0213 05:24:22.161457 22542570456896 run_lib.py:146] step: 1150500, eval_loss: 3.00593e-02
I0213 05:24:39.427915 22542570456896 run_lib.py:133] step: 1150550, training_loss: 2.77188e-02
I0213 05:24:56.704377 22542570456896 run_lib.py:133] step: 1150600, training_loss: 3.01184e-02
I0213 05:24:56.858609 22542570456896 run_lib.py:146] step: 1150600, eval_loss: 3.13139e-02
I0213 05:25:14.273071 22542570456896 run_lib.py:133] step: 1150650, training_loss: 3.02198e-02
I0213 05:25:31.501786 22542570456896 run_lib.py:133] step: 1150700, training_loss: 3.15661e-02
I0213 05:25:31.652571 22542570456896 run_lib.py:146] step: 1150700, eval_loss: 2.81233e-02
I0213 05:25:49.067161 22542570456896 run_lib.py:133] step: 1150750, training_loss: 2.68663e-02
I0213 05:26:06.293459 22542570456896 run_lib.py:133] step: 1150800, training_loss: 3.27416e-02
I0213 05:26:06.441983 22542570456896 run_lib.py:146] step: 1150800, eval_loss: 3.05214e-02
I0213 05:26:23.814010 22542570456896 run_lib.py:133] step: 1150850, training_loss: 2.85021e-02
I0213 05:26:41.095731 22542570456896 run_lib.py:133] step: 1150900, training_loss: 2.82756e-02
I0213 05:26:41.262871 22542570456896 run_lib.py:146] step: 1150900, eval_loss: 2.90427e-02
I0213 05:26:58.738402 22542570456896 run_lib.py:133] step: 1150950, training_loss: 2.80030e-02
I0213 05:27:15.984024 22542570456896 run_lib.py:133] step: 1151000, training_loss: 2.71519e-02
I0213 05:27:16.140519 22542570456896 run_lib.py:146] step: 1151000, eval_loss: 2.83046e-02
I0213 05:27:33.389228 22542570456896 run_lib.py:133] step: 1151050, training_loss: 2.57197e-02
I0213 05:27:50.768042 22542570456896 run_lib.py:133] step: 1151100, training_loss: 2.78060e-02
I0213 05:27:50.921331 22542570456896 run_lib.py:146] step: 1151100, eval_loss: 2.82456e-02
I0213 05:28:08.174423 22542570456896 run_lib.py:133] step: 1151150, training_loss: 2.55382e-02
I0213 05:28:25.455607 22542570456896 run_lib.py:133] step: 1151200, training_loss: 3.62853e-02
I0213 05:28:25.608925 22542570456896 run_lib.py:146] step: 1151200, eval_loss: 3.25084e-02
I0213 05:28:43.080314 22542570456896 run_lib.py:133] step: 1151250, training_loss: 2.79702e-02
I0213 05:29:00.480416 22542570456896 run_lib.py:133] step: 1151300, training_loss: 2.01123e-02
I0213 05:29:00.633335 22542570456896 run_lib.py:146] step: 1151300, eval_loss: 3.33274e-02
I0213 05:29:17.933763 22542570456896 run_lib.py:133] step: 1151350, training_loss: 2.35904e-02
I0213 05:29:35.187630 22542570456896 run_lib.py:133] step: 1151400, training_loss: 2.90812e-02
I0213 05:29:35.347524 22542570456896 run_lib.py:146] step: 1151400, eval_loss: 3.39766e-02
I0213 05:29:52.613830 22542570456896 run_lib.py:133] step: 1151450, training_loss: 3.01127e-02
I0213 05:30:10.112925 22542570456896 run_lib.py:133] step: 1151500, training_loss: 3.40162e-02
I0213 05:30:10.265431 22542570456896 run_lib.py:146] step: 1151500, eval_loss: 2.72507e-02
I0213 05:30:27.530305 22542570456896 run_lib.py:133] step: 1151550, training_loss: 2.29727e-02
I0213 05:30:44.788494 22542570456896 run_lib.py:133] step: 1151600, training_loss: 2.83667e-02
I0213 05:30:44.941570 22542570456896 run_lib.py:146] step: 1151600, eval_loss: 3.09713e-02
I0213 05:31:02.191159 22542570456896 run_lib.py:133] step: 1151650, training_loss: 2.42136e-02
I0213 05:31:19.601464 22542570456896 run_lib.py:133] step: 1151700, training_loss: 2.86890e-02
I0213 05:31:19.753923 22542570456896 run_lib.py:146] step: 1151700, eval_loss: 2.28733e-02
I0213 05:31:37.068417 22542570456896 run_lib.py:133] step: 1151750, training_loss: 2.97371e-02
I0213 05:31:54.435949 22542570456896 run_lib.py:133] step: 1151800, training_loss: 2.29684e-02
I0213 05:31:54.586222 22542570456896 run_lib.py:146] step: 1151800, eval_loss: 3.06432e-02
I0213 05:32:11.814552 22542570456896 run_lib.py:133] step: 1151850, training_loss: 3.47049e-02
I0213 05:32:29.070676 22542570456896 run_lib.py:133] step: 1151900, training_loss: 2.64961e-02
I0213 05:32:29.227651 22542570456896 run_lib.py:146] step: 1151900, eval_loss: 2.90151e-02
I0213 05:32:46.625838 22542570456896 run_lib.py:133] step: 1151950, training_loss: 2.65162e-02
I0213 05:33:04.023610 22542570456896 run_lib.py:133] step: 1152000, training_loss: 2.51703e-02
I0213 05:33:04.185314 22542570456896 run_lib.py:146] step: 1152000, eval_loss: 2.87798e-02
I0213 05:33:21.465341 22542570456896 run_lib.py:133] step: 1152050, training_loss: 2.96577e-02
I0213 05:33:38.722936 22542570456896 run_lib.py:133] step: 1152100, training_loss: 2.56105e-02
I0213 05:33:38.876095 22542570456896 run_lib.py:146] step: 1152100, eval_loss: 3.20061e-02
I0213 05:33:56.313549 22542570456896 run_lib.py:133] step: 1152150, training_loss: 2.67762e-02
I0213 05:34:13.546475 22542570456896 run_lib.py:133] step: 1152200, training_loss: 2.80564e-02
I0213 05:34:13.694414 22542570456896 run_lib.py:146] step: 1152200, eval_loss: 3.36111e-02
I0213 05:34:31.071313 22542570456896 run_lib.py:133] step: 1152250, training_loss: 2.84813e-02
I0213 05:34:48.385011 22542570456896 run_lib.py:133] step: 1152300, training_loss: 3.17596e-02
I0213 05:34:48.539476 22542570456896 run_lib.py:146] step: 1152300, eval_loss: 2.98910e-02
I0213 05:35:06.015869 22542570456896 run_lib.py:133] step: 1152350, training_loss: 2.84249e-02
I0213 05:35:23.301838 22542570456896 run_lib.py:133] step: 1152400, training_loss: 2.62242e-02
I0213 05:35:23.457483 22542570456896 run_lib.py:146] step: 1152400, eval_loss: 4.44413e-02
I0213 05:35:40.701732 22542570456896 run_lib.py:133] step: 1152450, training_loss: 3.51437e-02
I0213 05:35:58.093768 22542570456896 run_lib.py:133] step: 1152500, training_loss: 2.13121e-02
I0213 05:35:58.248231 22542570456896 run_lib.py:146] step: 1152500, eval_loss: 3.19787e-02
I0213 05:36:15.537653 22542570456896 run_lib.py:133] step: 1152550, training_loss: 2.71368e-02
I0213 05:36:32.999763 22542570456896 run_lib.py:133] step: 1152600, training_loss: 3.34039e-02
I0213 05:36:33.154856 22542570456896 run_lib.py:146] step: 1152600, eval_loss: 2.93821e-02
I0213 05:36:50.401001 22542570456896 run_lib.py:133] step: 1152650, training_loss: 2.48373e-02
I0213 05:37:07.653596 22542570456896 run_lib.py:133] step: 1152700, training_loss: 2.93510e-02
I0213 05:37:07.811871 22542570456896 run_lib.py:146] step: 1152700, eval_loss: 3.28962e-02
I0213 05:37:25.246204 22542570456896 run_lib.py:133] step: 1152750, training_loss: 1.91477e-02
I0213 05:37:42.548667 22542570456896 run_lib.py:133] step: 1152800, training_loss: 3.56100e-02
I0213 05:37:42.706272 22542570456896 run_lib.py:146] step: 1152800, eval_loss: 2.49125e-02
I0213 05:37:59.987248 22542570456896 run_lib.py:133] step: 1152850, training_loss: 2.93148e-02
I0213 05:38:17.499403 22542570456896 run_lib.py:133] step: 1152900, training_loss: 3.29438e-02
I0213 05:38:17.655172 22542570456896 run_lib.py:146] step: 1152900, eval_loss: 2.89617e-02
I0213 05:38:34.933293 22542570456896 run_lib.py:133] step: 1152950, training_loss: 2.88853e-02
I0213 05:38:52.140822 22542570456896 run_lib.py:133] step: 1153000, training_loss: 2.05668e-02
I0213 05:38:52.295256 22542570456896 run_lib.py:146] step: 1153000, eval_loss: 2.90059e-02
I0213 05:39:09.580709 22542570456896 run_lib.py:133] step: 1153050, training_loss: 2.79034e-02
I0213 05:39:26.809677 22542570456896 run_lib.py:133] step: 1153100, training_loss: 2.61560e-02
I0213 05:39:26.968186 22542570456896 run_lib.py:146] step: 1153100, eval_loss: 2.93521e-02
I0213 05:39:44.231349 22542570456896 run_lib.py:133] step: 1153150, training_loss: 2.74965e-02
I0213 05:40:01.481293 22542570456896 run_lib.py:133] step: 1153200, training_loss: 2.40225e-02
I0213 05:40:01.632455 22542570456896 run_lib.py:146] step: 1153200, eval_loss: 2.29509e-02
I0213 05:40:19.091813 22542570456896 run_lib.py:133] step: 1153250, training_loss: 3.09298e-02
I0213 05:40:36.434171 22542570456896 run_lib.py:133] step: 1153300, training_loss: 2.79331e-02
I0213 05:40:36.588267 22542570456896 run_lib.py:146] step: 1153300, eval_loss: 2.94324e-02
I0213 05:40:53.859351 22542570456896 run_lib.py:133] step: 1153350, training_loss: 2.98968e-02
I0213 05:41:11.127396 22542570456896 run_lib.py:133] step: 1153400, training_loss: 2.93012e-02
I0213 05:41:11.302300 22542570456896 run_lib.py:146] step: 1153400, eval_loss: 3.26493e-02
I0213 05:41:28.742587 22542570456896 run_lib.py:133] step: 1153450, training_loss: 2.99481e-02
I0213 05:41:46.003083 22542570456896 run_lib.py:133] step: 1153500, training_loss: 2.52783e-02
I0213 05:41:46.160487 22542570456896 run_lib.py:146] step: 1153500, eval_loss: 2.86469e-02
I0213 05:42:03.581315 22542570456896 run_lib.py:133] step: 1153550, training_loss: 2.69650e-02
I0213 05:42:20.819229 22542570456896 run_lib.py:133] step: 1153600, training_loss: 2.04782e-02
I0213 05:42:20.971216 22542570456896 run_lib.py:146] step: 1153600, eval_loss: 3.55558e-02
I0213 05:42:38.324784 22542570456896 run_lib.py:133] step: 1153650, training_loss: 2.53065e-02
I0213 05:42:55.632736 22542570456896 run_lib.py:133] step: 1153700, training_loss: 2.26375e-02
I0213 05:42:55.786571 22542570456896 run_lib.py:146] step: 1153700, eval_loss: 3.37430e-02
I0213 05:43:13.227631 22542570456896 run_lib.py:133] step: 1153750, training_loss: 2.43171e-02
I0213 05:43:30.490529 22542570456896 run_lib.py:133] step: 1153800, training_loss: 2.97428e-02
I0213 05:43:30.648452 22542570456896 run_lib.py:146] step: 1153800, eval_loss: 2.56544e-02
I0213 05:43:47.901914 22542570456896 run_lib.py:133] step: 1153850, training_loss: 2.87058e-02
I0213 05:44:05.279463 22542570456896 run_lib.py:133] step: 1153900, training_loss: 2.68276e-02
I0213 05:44:05.439465 22542570456896 run_lib.py:146] step: 1153900, eval_loss: 3.66575e-02
I0213 05:44:22.726562 22542570456896 run_lib.py:133] step: 1153950, training_loss: 2.63367e-02
I0213 05:44:39.999003 22542570456896 run_lib.py:133] step: 1154000, training_loss: 2.57539e-02
I0213 05:44:40.153633 22542570456896 run_lib.py:146] step: 1154000, eval_loss: 4.19480e-02
I0213 05:44:57.595297 22542570456896 run_lib.py:133] step: 1154050, training_loss: 2.95409e-02
I0213 05:45:14.847402 22542570456896 run_lib.py:133] step: 1154100, training_loss: 2.85712e-02
I0213 05:45:14.998061 22542570456896 run_lib.py:146] step: 1154100, eval_loss: 3.61025e-02
I0213 05:45:32.353377 22542570456896 run_lib.py:133] step: 1154150, training_loss: 2.30040e-02
I0213 05:45:49.614272 22542570456896 run_lib.py:133] step: 1154200, training_loss: 2.80304e-02
I0213 05:45:49.777497 22542570456896 run_lib.py:146] step: 1154200, eval_loss: 3.05294e-02
I0213 05:46:07.100290 22542570456896 run_lib.py:133] step: 1154250, training_loss: 2.98553e-02
I0213 05:46:24.550444 22542570456896 run_lib.py:133] step: 1154300, training_loss: 1.95894e-02
I0213 05:46:24.706287 22542570456896 run_lib.py:146] step: 1154300, eval_loss: 2.47820e-02
I0213 05:46:41.991302 22542570456896 run_lib.py:133] step: 1154350, training_loss: 2.44870e-02
I0213 05:46:59.216584 22542570456896 run_lib.py:133] step: 1154400, training_loss: 3.05028e-02
I0213 05:46:59.370334 22542570456896 run_lib.py:146] step: 1154400, eval_loss: 2.33144e-02
I0213 05:47:16.621640 22542570456896 run_lib.py:133] step: 1154450, training_loss: 2.62430e-02
I0213 05:47:34.039263 22542570456896 run_lib.py:133] step: 1154500, training_loss: 3.18247e-02
I0213 05:47:34.195373 22542570456896 run_lib.py:146] step: 1154500, eval_loss: 3.68345e-02
I0213 05:47:51.461857 22542570456896 run_lib.py:133] step: 1154550, training_loss: 3.43770e-02
I0213 05:48:08.831139 22542570456896 run_lib.py:133] step: 1154600, training_loss: 3.08012e-02
I0213 05:48:08.981040 22542570456896 run_lib.py:146] step: 1154600, eval_loss: 3.75535e-02
I0213 05:48:26.278307 22542570456896 run_lib.py:133] step: 1154650, training_loss: 3.09815e-02
I0213 05:48:43.555836 22542570456896 run_lib.py:133] step: 1154700, training_loss: 2.69270e-02
I0213 05:48:43.709347 22542570456896 run_lib.py:146] step: 1154700, eval_loss: 2.56719e-02
I0213 05:49:01.119862 22542570456896 run_lib.py:133] step: 1154750, training_loss: 2.59375e-02
I0213 05:49:18.473297 22542570456896 run_lib.py:133] step: 1154800, training_loss: 2.83335e-02
I0213 05:49:18.654255 22542570456896 run_lib.py:146] step: 1154800, eval_loss: 3.25556e-02
I0213 05:49:35.986489 22542570456896 run_lib.py:133] step: 1154850, training_loss: 2.43977e-02
I0213 05:49:53.268350 22542570456896 run_lib.py:133] step: 1154900, training_loss: 2.68433e-02
I0213 05:49:53.423501 22542570456896 run_lib.py:146] step: 1154900, eval_loss: 3.23018e-02
I0213 05:50:10.864439 22542570456896 run_lib.py:133] step: 1154950, training_loss: 3.43769e-02
I0213 05:50:28.125897 22542570456896 run_lib.py:133] step: 1155000, training_loss: 2.84502e-02
I0213 05:50:28.279335 22542570456896 run_lib.py:146] step: 1155000, eval_loss: 2.71400e-02
I0213 05:50:45.705273 22542570456896 run_lib.py:133] step: 1155050, training_loss: 2.97629e-02
I0213 05:51:03.021379 22542570456896 run_lib.py:133] step: 1155100, training_loss: 2.16578e-02
I0213 05:51:03.181542 22542570456896 run_lib.py:146] step: 1155100, eval_loss: 3.45614e-02
I0213 05:51:20.636640 22542570456896 run_lib.py:133] step: 1155150, training_loss: 2.78985e-02
I0213 05:51:37.915154 22542570456896 run_lib.py:133] step: 1155200, training_loss: 3.15708e-02
I0213 05:51:38.068283 22542570456896 run_lib.py:146] step: 1155200, eval_loss: 2.08177e-02
I0213 05:51:55.319302 22542570456896 run_lib.py:133] step: 1155250, training_loss: 2.64568e-02
I0213 05:52:12.722164 22542570456896 run_lib.py:133] step: 1155300, training_loss: 3.27393e-02
I0213 05:52:12.889337 22542570456896 run_lib.py:146] step: 1155300, eval_loss: 2.55229e-02
I0213 05:52:30.211618 22542570456896 run_lib.py:133] step: 1155350, training_loss: 2.40167e-02
I0213 05:52:47.675613 22542570456896 run_lib.py:133] step: 1155400, training_loss: 2.40377e-02
I0213 05:52:47.829982 22542570456896 run_lib.py:146] step: 1155400, eval_loss: 3.12059e-02
I0213 05:53:05.128560 22542570456896 run_lib.py:133] step: 1155450, training_loss: 3.27875e-02
I0213 05:53:22.370570 22542570456896 run_lib.py:133] step: 1155500, training_loss: 2.13942e-02
I0213 05:53:22.526303 22542570456896 run_lib.py:146] step: 1155500, eval_loss: 2.82044e-02
I0213 05:53:39.923087 22542570456896 run_lib.py:133] step: 1155550, training_loss: 2.69052e-02
I0213 05:53:57.186581 22542570456896 run_lib.py:133] step: 1155600, training_loss: 3.01669e-02
I0213 05:53:57.341330 22542570456896 run_lib.py:146] step: 1155600, eval_loss: 3.62955e-02
I0213 05:54:14.670477 22542570456896 run_lib.py:133] step: 1155650, training_loss: 2.54217e-02
I0213 05:54:32.112898 22542570456896 run_lib.py:133] step: 1155700, training_loss: 3.31299e-02
I0213 05:54:32.269350 22542570456896 run_lib.py:146] step: 1155700, eval_loss: 2.93570e-02
I0213 05:54:49.500301 22542570456896 run_lib.py:133] step: 1155750, training_loss: 2.86255e-02
I0213 05:55:06.725554 22542570456896 run_lib.py:133] step: 1155800, training_loss: 2.88759e-02
I0213 05:55:07.023302 22542570456896 run_lib.py:146] step: 1155800, eval_loss: 2.89200e-02
I0213 05:55:24.258448 22542570456896 run_lib.py:133] step: 1155850, training_loss: 2.46460e-02
I0213 05:55:41.533524 22542570456896 run_lib.py:133] step: 1155900, training_loss: 2.75017e-02
I0213 05:55:41.691592 22542570456896 run_lib.py:146] step: 1155900, eval_loss: 3.38148e-02
I0213 05:55:58.965557 22542570456896 run_lib.py:133] step: 1155950, training_loss: 2.75083e-02
I0213 05:56:16.224381 22542570456896 run_lib.py:133] step: 1156000, training_loss: 3.01060e-02
I0213 05:56:16.373108 22542570456896 run_lib.py:146] step: 1156000, eval_loss: 3.00467e-02
I0213 05:56:33.772035 22542570456896 run_lib.py:133] step: 1156050, training_loss: 2.82090e-02
I0213 05:56:51.099269 22542570456896 run_lib.py:133] step: 1156100, training_loss: 2.77814e-02
I0213 05:56:51.250047 22542570456896 run_lib.py:146] step: 1156100, eval_loss: 2.54587e-02
I0213 05:57:08.475748 22542570456896 run_lib.py:133] step: 1156150, training_loss: 2.32634e-02
I0213 05:57:25.751616 22542570456896 run_lib.py:133] step: 1156200, training_loss: 2.98855e-02
I0213 05:57:25.913313 22542570456896 run_lib.py:146] step: 1156200, eval_loss: 2.18422e-02
I0213 05:57:43.358311 22542570456896 run_lib.py:133] step: 1156250, training_loss: 2.98062e-02
I0213 05:58:00.662922 22542570456896 run_lib.py:133] step: 1156300, training_loss: 2.40348e-02
I0213 05:58:00.819176 22542570456896 run_lib.py:146] step: 1156300, eval_loss: 2.56045e-02
I0213 05:58:18.058904 22542570456896 run_lib.py:133] step: 1156350, training_loss: 3.59732e-02
I0213 05:58:35.277265 22542570456896 run_lib.py:133] step: 1156400, training_loss: 2.74053e-02
I0213 05:58:35.433487 22542570456896 run_lib.py:146] step: 1156400, eval_loss: 2.38868e-02
I0213 05:58:52.858492 22542570456896 run_lib.py:133] step: 1156450, training_loss: 2.87328e-02
I0213 05:59:10.123184 22542570456896 run_lib.py:133] step: 1156500, training_loss: 3.03616e-02
I0213 05:59:10.282323 22542570456896 run_lib.py:146] step: 1156500, eval_loss: 2.69915e-02
I0213 05:59:27.749448 22542570456896 run_lib.py:133] step: 1156550, training_loss: 2.92854e-02
I0213 05:59:45.047470 22542570456896 run_lib.py:133] step: 1156600, training_loss: 2.63326e-02
I0213 05:59:45.201158 22542570456896 run_lib.py:146] step: 1156600, eval_loss: 2.65442e-02
I0213 06:00:02.566019 22542570456896 run_lib.py:133] step: 1156650, training_loss: 2.81745e-02
I0213 06:00:19.867306 22542570456896 run_lib.py:133] step: 1156700, training_loss: 2.94068e-02
I0213 06:00:20.024315 22542570456896 run_lib.py:146] step: 1156700, eval_loss: 2.06658e-02
I0213 06:00:37.309353 22542570456896 run_lib.py:133] step: 1156750, training_loss: 2.87374e-02
I0213 06:00:54.830276 22542570456896 run_lib.py:133] step: 1156800, training_loss: 2.12651e-02
I0213 06:00:54.984535 22542570456896 run_lib.py:146] step: 1156800, eval_loss: 3.06901e-02
I0213 06:01:12.265668 22542570456896 run_lib.py:133] step: 1156850, training_loss: 2.44048e-02
I0213 06:01:29.657282 22542570456896 run_lib.py:133] step: 1156900, training_loss: 3.52455e-02
I0213 06:01:29.810326 22542570456896 run_lib.py:146] step: 1156900, eval_loss: 3.52749e-02
I0213 06:01:47.075355 22542570456896 run_lib.py:133] step: 1156950, training_loss: 2.52126e-02
I0213 06:02:04.360219 22542570456896 run_lib.py:133] step: 1157000, training_loss: 2.46741e-02
I0213 06:02:04.511459 22542570456896 run_lib.py:146] step: 1157000, eval_loss: 2.64193e-02
I0213 06:02:21.997292 22542570456896 run_lib.py:133] step: 1157050, training_loss: 2.12395e-02
I0213 06:02:39.277744 22542570456896 run_lib.py:133] step: 1157100, training_loss: 1.99871e-02
I0213 06:02:39.432020 22542570456896 run_lib.py:146] step: 1157100, eval_loss: 2.56701e-02
I0213 06:02:56.656493 22542570456896 run_lib.py:133] step: 1157150, training_loss: 3.33939e-02
I0213 06:03:13.922975 22542570456896 run_lib.py:133] step: 1157200, training_loss: 1.97802e-02
I0213 06:03:14.079772 22542570456896 run_lib.py:146] step: 1157200, eval_loss: 2.84550e-02
I0213 06:03:31.487336 22542570456896 run_lib.py:133] step: 1157250, training_loss: 2.67856e-02
I0213 06:03:48.743954 22542570456896 run_lib.py:133] step: 1157300, training_loss: 2.32215e-02
I0213 06:03:48.905323 22542570456896 run_lib.py:146] step: 1157300, eval_loss: 3.02696e-02
I0213 06:04:06.255694 22542570456896 run_lib.py:133] step: 1157350, training_loss: 3.12903e-02
I0213 06:04:23.620169 22542570456896 run_lib.py:133] step: 1157400, training_loss: 3.08847e-02
I0213 06:04:23.773495 22542570456896 run_lib.py:146] step: 1157400, eval_loss: 2.93927e-02
I0213 06:04:41.049989 22542570456896 run_lib.py:133] step: 1157450, training_loss: 2.12065e-02
I0213 06:04:58.321854 22542570456896 run_lib.py:133] step: 1157500, training_loss: 2.51201e-02
I0213 06:04:58.472233 22542570456896 run_lib.py:146] step: 1157500, eval_loss: 3.10614e-02
I0213 06:05:15.885989 22542570456896 run_lib.py:133] step: 1157550, training_loss: 3.47309e-02
I0213 06:05:33.202200 22542570456896 run_lib.py:133] step: 1157600, training_loss: 2.42584e-02
I0213 06:05:33.379402 22542570456896 run_lib.py:146] step: 1157600, eval_loss: 2.89962e-02
I0213 06:05:50.653850 22542570456896 run_lib.py:133] step: 1157650, training_loss: 3.34999e-02
I0213 06:06:07.919812 22542570456896 run_lib.py:133] step: 1157700, training_loss: 2.38856e-02
I0213 06:06:08.077595 22542570456896 run_lib.py:146] step: 1157700, eval_loss: 3.48761e-02
I0213 06:06:25.501274 22542570456896 run_lib.py:133] step: 1157750, training_loss: 2.34077e-02
I0213 06:06:42.730605 22542570456896 run_lib.py:133] step: 1157800, training_loss: 2.79406e-02
I0213 06:06:42.889013 22542570456896 run_lib.py:146] step: 1157800, eval_loss: 2.74973e-02
I0213 06:07:00.264449 22542570456896 run_lib.py:133] step: 1157850, training_loss: 2.60163e-02
I0213 06:07:17.538079 22542570456896 run_lib.py:133] step: 1157900, training_loss: 3.79646e-02
I0213 06:07:17.690172 22542570456896 run_lib.py:146] step: 1157900, eval_loss: 2.61184e-02
I0213 06:07:35.158010 22542570456896 run_lib.py:133] step: 1157950, training_loss: 3.08157e-02
I0213 06:07:52.438251 22542570456896 run_lib.py:133] step: 1158000, training_loss: 2.14810e-02
I0213 06:07:52.594209 22542570456896 run_lib.py:146] step: 1158000, eval_loss: 3.69842e-02
I0213 06:08:09.942567 22542570456896 run_lib.py:133] step: 1158050, training_loss: 2.65915e-02
I0213 06:08:27.203683 22542570456896 run_lib.py:133] step: 1158100, training_loss: 2.58947e-02
I0213 06:08:27.360504 22542570456896 run_lib.py:146] step: 1158100, eval_loss: 3.48070e-02
I0213 06:08:44.646650 22542570456896 run_lib.py:133] step: 1158150, training_loss: 2.60220e-02
I0213 06:09:02.081978 22542570456896 run_lib.py:133] step: 1158200, training_loss: 2.67741e-02
I0213 06:09:02.236441 22542570456896 run_lib.py:146] step: 1158200, eval_loss: 3.26444e-02
I0213 06:09:19.456102 22542570456896 run_lib.py:133] step: 1158250, training_loss: 2.79714e-02
I0213 06:09:36.691565 22542570456896 run_lib.py:133] step: 1158300, training_loss: 3.14754e-02
I0213 06:09:36.845230 22542570456896 run_lib.py:146] step: 1158300, eval_loss: 2.89456e-02
I0213 06:09:54.272734 22542570456896 run_lib.py:133] step: 1158350, training_loss: 2.06418e-02
I0213 06:10:11.674125 22542570456896 run_lib.py:133] step: 1158400, training_loss: 3.16640e-02
I0213 06:10:11.820318 22542570456896 run_lib.py:146] step: 1158400, eval_loss: 2.94540e-02
I0213 06:10:29.065316 22542570456896 run_lib.py:133] step: 1158450, training_loss: 2.52448e-02
I0213 06:10:46.348822 22542570456896 run_lib.py:133] step: 1158500, training_loss: 2.63306e-02
I0213 06:10:46.516427 22542570456896 run_lib.py:146] step: 1158500, eval_loss: 2.83460e-02
I0213 06:11:03.814805 22542570456896 run_lib.py:133] step: 1158550, training_loss: 2.35471e-02
I0213 06:11:21.268767 22542570456896 run_lib.py:133] step: 1158600, training_loss: 3.30473e-02
I0213 06:11:21.424347 22542570456896 run_lib.py:146] step: 1158600, eval_loss: 3.34840e-02
I0213 06:11:38.673666 22542570456896 run_lib.py:133] step: 1158650, training_loss: 2.77923e-02
I0213 06:11:55.916315 22542570456896 run_lib.py:133] step: 1158700, training_loss: 3.05189e-02
I0213 06:11:56.070180 22542570456896 run_lib.py:146] step: 1158700, eval_loss: 3.53573e-02
I0213 06:12:13.340237 22542570456896 run_lib.py:133] step: 1158750, training_loss: 1.82187e-02
I0213 06:12:30.763177 22542570456896 run_lib.py:133] step: 1158800, training_loss: 2.58326e-02
I0213 06:12:30.917598 22542570456896 run_lib.py:146] step: 1158800, eval_loss: 3.06670e-02
I0213 06:12:48.249069 22542570456896 run_lib.py:133] step: 1158850, training_loss: 2.75516e-02
I0213 06:13:05.603752 22542570456896 run_lib.py:133] step: 1158900, training_loss: 2.77387e-02
I0213 06:13:05.753187 22542570456896 run_lib.py:146] step: 1158900, eval_loss: 3.14126e-02
I0213 06:13:23.007872 22542570456896 run_lib.py:133] step: 1158950, training_loss: 2.23273e-02
I0213 06:13:40.281903 22542570456896 run_lib.py:133] step: 1159000, training_loss: 2.55935e-02
I0213 06:13:40.438491 22542570456896 run_lib.py:146] step: 1159000, eval_loss: 3.32134e-02
I0213 06:13:57.780477 22542570456896 run_lib.py:133] step: 1159050, training_loss: 2.96999e-02
I0213 06:14:15.139059 22542570456896 run_lib.py:133] step: 1159100, training_loss: 2.92426e-02
I0213 06:14:15.319473 22542570456896 run_lib.py:146] step: 1159100, eval_loss: 3.39436e-02
I0213 06:14:32.620119 22542570456896 run_lib.py:133] step: 1159150, training_loss: 2.81069e-02
I0213 06:14:49.861845 22542570456896 run_lib.py:133] step: 1159200, training_loss: 2.34299e-02
I0213 06:14:50.016216 22542570456896 run_lib.py:146] step: 1159200, eval_loss: 2.91261e-02
I0213 06:15:07.445271 22542570456896 run_lib.py:133] step: 1159250, training_loss: 3.18219e-02
I0213 06:15:24.678723 22542570456896 run_lib.py:133] step: 1159300, training_loss: 3.52368e-02
I0213 06:15:24.831260 22542570456896 run_lib.py:146] step: 1159300, eval_loss: 2.39689e-02
I0213 06:15:42.222461 22542570456896 run_lib.py:133] step: 1159350, training_loss: 2.62686e-02
I0213 06:15:59.554720 22542570456896 run_lib.py:133] step: 1159400, training_loss: 3.39866e-02
I0213 06:15:59.707448 22542570456896 run_lib.py:146] step: 1159400, eval_loss: 2.49195e-02
I0213 06:16:17.179634 22542570456896 run_lib.py:133] step: 1159450, training_loss: 2.60694e-02
I0213 06:16:34.473192 22542570456896 run_lib.py:133] step: 1159500, training_loss: 2.79436e-02
I0213 06:16:34.629515 22542570456896 run_lib.py:146] step: 1159500, eval_loss: 3.41196e-02
I0213 06:16:51.903278 22542570456896 run_lib.py:133] step: 1159550, training_loss: 2.32591e-02
I0213 06:17:09.277010 22542570456896 run_lib.py:133] step: 1159600, training_loss: 3.10946e-02
I0213 06:17:09.447080 22542570456896 run_lib.py:146] step: 1159600, eval_loss: 3.01524e-02
I0213 06:17:26.767184 22542570456896 run_lib.py:133] step: 1159650, training_loss: 2.63384e-02
I0213 06:17:44.246314 22542570456896 run_lib.py:133] step: 1159700, training_loss: 2.78798e-02
I0213 06:17:44.400053 22542570456896 run_lib.py:146] step: 1159700, eval_loss: 3.30018e-02
I0213 06:18:01.659774 22542570456896 run_lib.py:133] step: 1159750, training_loss: 3.36950e-02
I0213 06:18:18.953552 22542570456896 run_lib.py:133] step: 1159800, training_loss: 2.40123e-02
I0213 06:18:19.107050 22542570456896 run_lib.py:146] step: 1159800, eval_loss: 2.09428e-02
I0213 06:18:36.523277 22542570456896 run_lib.py:133] step: 1159850, training_loss: 2.72116e-02
I0213 06:18:53.849188 22542570456896 run_lib.py:133] step: 1159900, training_loss: 3.53426e-02
I0213 06:18:54.015519 22542570456896 run_lib.py:146] step: 1159900, eval_loss: 3.42630e-02
I0213 06:19:11.342496 22542570456896 run_lib.py:133] step: 1159950, training_loss: 2.45140e-02
I0213 06:19:28.772523 22542570456896 run_lib.py:133] step: 1160000, training_loss: 2.72654e-02
I0213 06:19:29.464249 22542570456896 run_lib.py:146] step: 1160000, eval_loss: 3.41013e-02
I0213 06:19:49.294052 22542570456896 run_lib.py:133] step: 1160050, training_loss: 2.57041e-02
I0213 06:20:06.544957 22542570456896 run_lib.py:133] step: 1160100, training_loss: 2.04216e-02
I0213 06:20:06.700466 22542570456896 run_lib.py:146] step: 1160100, eval_loss: 2.29390e-02
I0213 06:20:23.970501 22542570456896 run_lib.py:133] step: 1160150, training_loss: 1.97962e-02
I0213 06:20:41.483729 22542570456896 run_lib.py:133] step: 1160200, training_loss: 2.61086e-02
I0213 06:20:41.636448 22542570456896 run_lib.py:146] step: 1160200, eval_loss: 2.14243e-02
I0213 06:20:58.948598 22542570456896 run_lib.py:133] step: 1160250, training_loss: 2.52871e-02
I0213 06:21:16.198272 22542570456896 run_lib.py:133] step: 1160300, training_loss: 2.27321e-02
I0213 06:21:16.355247 22542570456896 run_lib.py:146] step: 1160300, eval_loss: 3.05776e-02
I0213 06:21:33.784911 22542570456896 run_lib.py:133] step: 1160350, training_loss: 2.75372e-02
I0213 06:21:51.028128 22542570456896 run_lib.py:133] step: 1160400, training_loss: 2.30546e-02
I0213 06:21:51.177186 22542570456896 run_lib.py:146] step: 1160400, eval_loss: 2.60908e-02
I0213 06:22:08.476424 22542570456896 run_lib.py:133] step: 1160450, training_loss: 2.48094e-02
I0213 06:22:25.752282 22542570456896 run_lib.py:133] step: 1160500, training_loss: 3.29786e-02
I0213 06:22:25.921218 22542570456896 run_lib.py:146] step: 1160500, eval_loss: 3.15087e-02
I0213 06:22:43.208666 22542570456896 run_lib.py:133] step: 1160550, training_loss: 2.77736e-02
I0213 06:23:00.444736 22542570456896 run_lib.py:133] step: 1160600, training_loss: 2.77595e-02
I0213 06:23:00.598499 22542570456896 run_lib.py:146] step: 1160600, eval_loss: 2.19719e-02
I0213 06:23:18.000960 22542570456896 run_lib.py:133] step: 1160650, training_loss: 2.79027e-02
I0213 06:23:35.299378 22542570456896 run_lib.py:133] step: 1160700, training_loss: 2.37016e-02
I0213 06:23:35.452282 22542570456896 run_lib.py:146] step: 1160700, eval_loss: 2.29780e-02
I0213 06:23:52.679747 22542570456896 run_lib.py:133] step: 1160750, training_loss: 3.03017e-02
I0213 06:24:09.998968 22542570456896 run_lib.py:133] step: 1160800, training_loss: 3.11500e-02
I0213 06:24:10.152482 22542570456896 run_lib.py:146] step: 1160800, eval_loss: 3.03421e-02
I0213 06:24:27.583686 22542570456896 run_lib.py:133] step: 1160850, training_loss: 2.08215e-02
I0213 06:24:44.861858 22542570456896 run_lib.py:133] step: 1160900, training_loss: 2.38261e-02
I0213 06:24:45.018221 22542570456896 run_lib.py:146] step: 1160900, eval_loss: 2.50330e-02
I0213 06:25:02.386702 22542570456896 run_lib.py:133] step: 1160950, training_loss: 2.49132e-02
I0213 06:25:19.651926 22542570456896 run_lib.py:133] step: 1161000, training_loss: 3.03885e-02
I0213 06:25:19.813313 22542570456896 run_lib.py:146] step: 1161000, eval_loss: 3.28740e-02
I0213 06:25:37.192930 22542570456896 run_lib.py:133] step: 1161050, training_loss: 3.12947e-02
I0213 06:25:54.519836 22542570456896 run_lib.py:133] step: 1161100, training_loss: 2.72851e-02
I0213 06:25:54.674482 22542570456896 run_lib.py:146] step: 1161100, eval_loss: 2.99972e-02
I0213 06:26:12.090505 22542570456896 run_lib.py:133] step: 1161150, training_loss: 2.53279e-02
I0213 06:26:29.333054 22542570456896 run_lib.py:133] step: 1161200, training_loss: 2.44822e-02
I0213 06:26:29.487084 22542570456896 run_lib.py:146] step: 1161200, eval_loss: 2.88756e-02
I0213 06:26:46.771522 22542570456896 run_lib.py:133] step: 1161250, training_loss: 2.83550e-02
I0213 06:27:04.155730 22542570456896 run_lib.py:133] step: 1161300, training_loss: 2.71898e-02
I0213 06:27:04.311051 22542570456896 run_lib.py:146] step: 1161300, eval_loss: 2.99525e-02
I0213 06:27:21.580635 22542570456896 run_lib.py:133] step: 1161350, training_loss: 2.01338e-02
I0213 06:27:38.846929 22542570456896 run_lib.py:133] step: 1161400, training_loss: 2.64515e-02
I0213 06:27:39.004273 22542570456896 run_lib.py:146] step: 1161400, eval_loss: 2.75099e-02
I0213 06:27:56.436473 22542570456896 run_lib.py:133] step: 1161450, training_loss: 2.27712e-02
I0213 06:28:13.746457 22542570456896 run_lib.py:133] step: 1161500, training_loss: 2.99682e-02
I0213 06:28:13.899389 22542570456896 run_lib.py:146] step: 1161500, eval_loss: 2.99729e-02
I0213 06:28:31.257439 22542570456896 run_lib.py:133] step: 1161550, training_loss: 2.90781e-02
I0213 06:28:48.520899 22542570456896 run_lib.py:133] step: 1161600, training_loss: 3.25315e-02
I0213 06:28:48.684518 22542570456896 run_lib.py:146] step: 1161600, eval_loss: 3.11752e-02
I0213 06:29:05.956744 22542570456896 run_lib.py:133] step: 1161650, training_loss: 2.60813e-02
I0213 06:29:23.442460 22542570456896 run_lib.py:133] step: 1161700, training_loss: 2.63492e-02
I0213 06:29:23.599445 22542570456896 run_lib.py:146] step: 1161700, eval_loss: 3.23293e-02
I0213 06:29:40.851721 22542570456896 run_lib.py:133] step: 1161750, training_loss: 2.29497e-02
I0213 06:29:58.098375 22542570456896 run_lib.py:133] step: 1161800, training_loss: 2.70466e-02
I0213 06:29:58.255963 22542570456896 run_lib.py:146] step: 1161800, eval_loss: 2.00744e-02
I0213 06:30:15.536357 22542570456896 run_lib.py:133] step: 1161850, training_loss: 2.47550e-02
I0213 06:30:33.040037 22542570456896 run_lib.py:133] step: 1161900, training_loss: 2.56123e-02
I0213 06:30:33.195638 22542570456896 run_lib.py:146] step: 1161900, eval_loss: 2.98147e-02
I0213 06:30:50.482906 22542570456896 run_lib.py:133] step: 1161950, training_loss: 2.96776e-02
I0213 06:31:07.797631 22542570456896 run_lib.py:133] step: 1162000, training_loss: 2.22330e-02
I0213 06:31:07.955563 22542570456896 run_lib.py:146] step: 1162000, eval_loss: 3.08103e-02
I0213 06:31:25.188395 22542570456896 run_lib.py:133] step: 1162050, training_loss: 2.45819e-02
I0213 06:31:42.444283 22542570456896 run_lib.py:133] step: 1162100, training_loss: 2.47715e-02
I0213 06:31:42.597324 22542570456896 run_lib.py:146] step: 1162100, eval_loss: 3.32462e-02
I0213 06:32:00.000246 22542570456896 run_lib.py:133] step: 1162150, training_loss: 2.39916e-02
I0213 06:32:17.418442 22542570456896 run_lib.py:133] step: 1162200, training_loss: 2.71816e-02
I0213 06:32:17.571513 22542570456896 run_lib.py:146] step: 1162200, eval_loss: 3.21556e-02
I0213 06:32:34.844475 22542570456896 run_lib.py:133] step: 1162250, training_loss: 3.24810e-02
I0213 06:32:52.108334 22542570456896 run_lib.py:133] step: 1162300, training_loss: 2.29896e-02
I0213 06:32:52.259334 22542570456896 run_lib.py:146] step: 1162300, eval_loss: 2.88000e-02
I0213 06:33:09.658616 22542570456896 run_lib.py:133] step: 1162350, training_loss: 3.23054e-02
I0213 06:33:26.897276 22542570456896 run_lib.py:133] step: 1162400, training_loss: 2.81267e-02
I0213 06:33:27.064224 22542570456896 run_lib.py:146] step: 1162400, eval_loss: 2.48696e-02
I0213 06:33:44.475701 22542570456896 run_lib.py:133] step: 1162450, training_loss: 2.93353e-02
I0213 06:34:01.751370 22542570456896 run_lib.py:133] step: 1162500, training_loss: 3.36090e-02
I0213 06:34:01.911346 22542570456896 run_lib.py:146] step: 1162500, eval_loss: 3.47502e-02
I0213 06:34:19.309029 22542570456896 run_lib.py:133] step: 1162550, training_loss: 2.05477e-02
I0213 06:34:36.564121 22542570456896 run_lib.py:133] step: 1162600, training_loss: 2.75538e-02
I0213 06:34:36.718096 22542570456896 run_lib.py:146] step: 1162600, eval_loss: 2.20203e-02
I0213 06:34:53.974807 22542570456896 run_lib.py:133] step: 1162650, training_loss: 2.15256e-02
I0213 06:35:11.406203 22542570456896 run_lib.py:133] step: 1162700, training_loss: 3.52481e-02
I0213 06:35:11.558074 22542570456896 run_lib.py:146] step: 1162700, eval_loss: 2.95672e-02
I0213 06:35:28.862367 22542570456896 run_lib.py:133] step: 1162750, training_loss: 3.04350e-02
I0213 06:35:46.270690 22542570456896 run_lib.py:133] step: 1162800, training_loss: 2.12503e-02
I0213 06:35:46.425319 22542570456896 run_lib.py:146] step: 1162800, eval_loss: 3.25398e-02
I0213 06:36:03.686941 22542570456896 run_lib.py:133] step: 1162850, training_loss: 2.79071e-02
I0213 06:36:20.945947 22542570456896 run_lib.py:133] step: 1162900, training_loss: 3.02492e-02
I0213 06:36:21.102494 22542570456896 run_lib.py:146] step: 1162900, eval_loss: 3.49594e-02
I0213 06:36:38.515884 22542570456896 run_lib.py:133] step: 1162950, training_loss: 2.39450e-02
I0213 06:36:55.813862 22542570456896 run_lib.py:133] step: 1163000, training_loss: 1.90653e-02
I0213 06:36:55.981269 22542570456896 run_lib.py:146] step: 1163000, eval_loss: 2.61423e-02
I0213 06:37:13.301325 22542570456896 run_lib.py:133] step: 1163050, training_loss: 2.35488e-02
I0213 06:37:30.722388 22542570456896 run_lib.py:133] step: 1163100, training_loss: 3.15579e-02
I0213 06:37:30.879548 22542570456896 run_lib.py:146] step: 1163100, eval_loss: 3.70103e-02
I0213 06:37:48.134272 22542570456896 run_lib.py:133] step: 1163150, training_loss: 2.68973e-02
I0213 06:38:05.368107 22542570456896 run_lib.py:133] step: 1163200, training_loss: 2.63198e-02
I0213 06:38:05.653410 22542570456896 run_lib.py:146] step: 1163200, eval_loss: 3.47323e-02
I0213 06:38:22.953608 22542570456896 run_lib.py:133] step: 1163250, training_loss: 2.60103e-02
I0213 06:38:40.217856 22542570456896 run_lib.py:133] step: 1163300, training_loss: 2.40946e-02
I0213 06:38:40.382517 22542570456896 run_lib.py:146] step: 1163300, eval_loss: 2.81327e-02
I0213 06:38:57.681498 22542570456896 run_lib.py:133] step: 1163350, training_loss: 2.62684e-02
I0213 06:39:14.991109 22542570456896 run_lib.py:133] step: 1163400, training_loss: 3.12469e-02
I0213 06:39:15.154320 22542570456896 run_lib.py:146] step: 1163400, eval_loss: 3.33851e-02
I0213 06:39:32.597456 22542570456896 run_lib.py:133] step: 1163450, training_loss: 2.16569e-02
I0213 06:39:49.920652 22542570456896 run_lib.py:133] step: 1163500, training_loss: 2.58746e-02
I0213 06:39:50.074248 22542570456896 run_lib.py:146] step: 1163500, eval_loss: 2.59338e-02
I0213 06:40:07.383435 22542570456896 run_lib.py:133] step: 1163550, training_loss: 2.82855e-02
I0213 06:40:24.670900 22542570456896 run_lib.py:133] step: 1163600, training_loss: 2.55150e-02
I0213 06:40:24.825506 22542570456896 run_lib.py:146] step: 1163600, eval_loss: 3.74114e-02
I0213 06:40:42.293147 22542570456896 run_lib.py:133] step: 1163650, training_loss: 2.51403e-02
I0213 06:40:59.621222 22542570456896 run_lib.py:133] step: 1163700, training_loss: 2.72366e-02
I0213 06:40:59.774269 22542570456896 run_lib.py:146] step: 1163700, eval_loss: 2.93088e-02
I0213 06:41:17.026781 22542570456896 run_lib.py:133] step: 1163750, training_loss: 2.60757e-02
I0213 06:41:34.311195 22542570456896 run_lib.py:133] step: 1163800, training_loss: 2.94811e-02
I0213 06:41:34.466804 22542570456896 run_lib.py:146] step: 1163800, eval_loss: 3.00407e-02
I0213 06:41:51.848493 22542570456896 run_lib.py:133] step: 1163850, training_loss: 2.68188e-02
I0213 06:42:09.156215 22542570456896 run_lib.py:133] step: 1163900, training_loss: 3.46543e-02
I0213 06:42:09.321818 22542570456896 run_lib.py:146] step: 1163900, eval_loss: 2.69357e-02
I0213 06:42:26.788761 22542570456896 run_lib.py:133] step: 1163950, training_loss: 3.33476e-02
I0213 06:42:44.046014 22542570456896 run_lib.py:133] step: 1164000, training_loss: 1.81212e-02
I0213 06:42:44.199540 22542570456896 run_lib.py:146] step: 1164000, eval_loss: 2.87833e-02
I0213 06:43:01.604969 22542570456896 run_lib.py:133] step: 1164050, training_loss: 2.98282e-02
I0213 06:43:18.816759 22542570456896 run_lib.py:133] step: 1164100, training_loss: 3.41675e-02
I0213 06:43:18.968972 22542570456896 run_lib.py:146] step: 1164100, eval_loss: 2.58319e-02
I0213 06:43:36.199497 22542570456896 run_lib.py:133] step: 1164150, training_loss: 2.40945e-02
I0213 06:43:53.676783 22542570456896 run_lib.py:133] step: 1164200, training_loss: 2.23210e-02
I0213 06:43:53.831584 22542570456896 run_lib.py:146] step: 1164200, eval_loss: 2.81930e-02
I0213 06:44:11.197692 22542570456896 run_lib.py:133] step: 1164250, training_loss: 2.93520e-02
I0213 06:44:28.607728 22542570456896 run_lib.py:133] step: 1164300, training_loss: 2.37622e-02
I0213 06:44:28.765695 22542570456896 run_lib.py:146] step: 1164300, eval_loss: 3.41766e-02
I0213 06:44:46.034102 22542570456896 run_lib.py:133] step: 1164350, training_loss: 2.69620e-02
I0213 06:45:03.259972 22542570456896 run_lib.py:133] step: 1164400, training_loss: 2.45888e-02
I0213 06:45:03.424681 22542570456896 run_lib.py:146] step: 1164400, eval_loss: 3.17334e-02
I0213 06:45:20.869559 22542570456896 run_lib.py:133] step: 1164450, training_loss: 3.16797e-02
I0213 06:45:38.156182 22542570456896 run_lib.py:133] step: 1164500, training_loss: 2.58694e-02
I0213 06:45:38.310116 22542570456896 run_lib.py:146] step: 1164500, eval_loss: 2.51113e-02
I0213 06:45:55.562392 22542570456896 run_lib.py:133] step: 1164550, training_loss: 2.91358e-02
I0213 06:46:12.820476 22542570456896 run_lib.py:133] step: 1164600, training_loss: 2.73338e-02
I0213 06:46:12.971117 22542570456896 run_lib.py:146] step: 1164600, eval_loss: 2.77082e-02
I0213 06:46:30.415449 22542570456896 run_lib.py:133] step: 1164650, training_loss: 3.14369e-02
I0213 06:46:47.668764 22542570456896 run_lib.py:133] step: 1164700, training_loss: 3.16960e-02
I0213 06:46:47.825277 22542570456896 run_lib.py:146] step: 1164700, eval_loss: 3.33786e-02
I0213 06:47:05.186493 22542570456896 run_lib.py:133] step: 1164750, training_loss: 2.36333e-02
I0213 06:47:22.486316 22542570456896 run_lib.py:133] step: 1164800, training_loss: 2.92691e-02
I0213 06:47:22.650870 22542570456896 run_lib.py:146] step: 1164800, eval_loss: 2.66606e-02
I0213 06:47:39.906248 22542570456896 run_lib.py:133] step: 1164850, training_loss: 2.37286e-02
I0213 06:47:57.165853 22542570456896 run_lib.py:133] step: 1164900, training_loss: 2.05295e-02
I0213 06:47:57.319246 22542570456896 run_lib.py:146] step: 1164900, eval_loss: 2.90026e-02
I0213 06:48:14.728326 22542570456896 run_lib.py:133] step: 1164950, training_loss: 2.50818e-02
I0213 06:48:32.038952 22542570456896 run_lib.py:133] step: 1165000, training_loss: 2.64442e-02
I0213 06:48:32.203389 22542570456896 run_lib.py:146] step: 1165000, eval_loss: 3.02819e-02
I0213 06:48:49.477455 22542570456896 run_lib.py:133] step: 1165050, training_loss: 2.49988e-02
I0213 06:49:06.751464 22542570456896 run_lib.py:133] step: 1165100, training_loss: 2.59260e-02
I0213 06:49:06.899438 22542570456896 run_lib.py:146] step: 1165100, eval_loss: 2.91097e-02
I0213 06:49:24.339993 22542570456896 run_lib.py:133] step: 1165150, training_loss: 2.98778e-02
I0213 06:49:41.575734 22542570456896 run_lib.py:133] step: 1165200, training_loss: 2.22054e-02
I0213 06:49:41.731229 22542570456896 run_lib.py:146] step: 1165200, eval_loss: 3.07665e-02
I0213 06:49:59.096111 22542570456896 run_lib.py:133] step: 1165250, training_loss: 2.50385e-02
I0213 06:50:16.318778 22542570456896 run_lib.py:133] step: 1165300, training_loss: 2.68883e-02
I0213 06:50:16.494302 22542570456896 run_lib.py:146] step: 1165300, eval_loss: 2.75783e-02
I0213 06:50:33.904273 22542570456896 run_lib.py:133] step: 1165350, training_loss: 3.18073e-02
I0213 06:50:51.200951 22542570456896 run_lib.py:133] step: 1165400, training_loss: 3.00417e-02
I0213 06:50:51.355458 22542570456896 run_lib.py:146] step: 1165400, eval_loss: 2.81110e-02
I0213 06:51:08.798128 22542570456896 run_lib.py:133] step: 1165450, training_loss: 2.34577e-02
I0213 06:51:26.018999 22542570456896 run_lib.py:133] step: 1165500, training_loss: 3.23364e-02
I0213 06:51:26.173261 22542570456896 run_lib.py:146] step: 1165500, eval_loss: 3.01161e-02
I0213 06:51:43.428662 22542570456896 run_lib.py:133] step: 1165550, training_loss: 2.67789e-02
I0213 06:52:00.848345 22542570456896 run_lib.py:133] step: 1165600, training_loss: 2.64276e-02
I0213 06:52:01.000486 22542570456896 run_lib.py:146] step: 1165600, eval_loss: 2.60517e-02
I0213 06:52:18.275662 22542570456896 run_lib.py:133] step: 1165650, training_loss: 2.22085e-02
I0213 06:52:35.564380 22542570456896 run_lib.py:133] step: 1165700, training_loss: 2.75915e-02
I0213 06:52:35.718245 22542570456896 run_lib.py:146] step: 1165700, eval_loss: 3.17424e-02
I0213 06:52:53.142345 22542570456896 run_lib.py:133] step: 1165750, training_loss: 2.52278e-02
I0213 06:53:10.534706 22542570456896 run_lib.py:133] step: 1165800, training_loss: 2.62066e-02
I0213 06:53:10.691468 22542570456896 run_lib.py:146] step: 1165800, eval_loss: 3.17401e-02
I0213 06:53:27.967411 22542570456896 run_lib.py:133] step: 1165850, training_loss: 2.75152e-02
I0213 06:53:45.278689 22542570456896 run_lib.py:133] step: 1165900, training_loss: 3.00381e-02
I0213 06:53:45.433521 22542570456896 run_lib.py:146] step: 1165900, eval_loss: 2.81523e-02
I0213 06:54:02.660141 22542570456896 run_lib.py:133] step: 1165950, training_loss: 2.66009e-02
I0213 06:54:20.099463 22542570456896 run_lib.py:133] step: 1166000, training_loss: 2.57652e-02
I0213 06:54:20.252250 22542570456896 run_lib.py:146] step: 1166000, eval_loss: 3.23077e-02
I0213 06:54:37.510796 22542570456896 run_lib.py:133] step: 1166050, training_loss: 3.51512e-02
I0213 06:54:54.749202 22542570456896 run_lib.py:133] step: 1166100, training_loss: 2.58589e-02
I0213 06:54:54.899024 22542570456896 run_lib.py:146] step: 1166100, eval_loss: 2.45420e-02
I0213 06:55:12.189947 22542570456896 run_lib.py:133] step: 1166150, training_loss: 2.80284e-02
I0213 06:55:29.620902 22542570456896 run_lib.py:133] step: 1166200, training_loss: 2.77800e-02
I0213 06:55:29.776839 22542570456896 run_lib.py:146] step: 1166200, eval_loss: 3.05652e-02
I0213 06:55:46.993418 22542570456896 run_lib.py:133] step: 1166250, training_loss: 2.80837e-02
I0213 06:56:04.309829 22542570456896 run_lib.py:133] step: 1166300, training_loss: 2.56803e-02
I0213 06:56:04.465538 22542570456896 run_lib.py:146] step: 1166300, eval_loss: 3.00892e-02
I0213 06:56:21.683504 22542570456896 run_lib.py:133] step: 1166350, training_loss: 2.48676e-02
I0213 06:56:38.940179 22542570456896 run_lib.py:133] step: 1166400, training_loss: 2.55039e-02
I0213 06:56:39.104479 22542570456896 run_lib.py:146] step: 1166400, eval_loss: 2.86800e-02
I0213 06:56:56.522411 22542570456896 run_lib.py:133] step: 1166450, training_loss: 2.44261e-02
I0213 06:57:13.903241 22542570456896 run_lib.py:133] step: 1166500, training_loss: 3.70531e-02
I0213 06:57:14.051023 22542570456896 run_lib.py:146] step: 1166500, eval_loss: 2.67583e-02
I0213 06:57:31.314104 22542570456896 run_lib.py:133] step: 1166550, training_loss: 2.54992e-02
I0213 06:57:48.571338 22542570456896 run_lib.py:133] step: 1166600, training_loss: 3.00221e-02
I0213 06:57:48.723222 22542570456896 run_lib.py:146] step: 1166600, eval_loss: 3.15270e-02
I0213 06:58:06.097263 22542570456896 run_lib.py:133] step: 1166650, training_loss: 2.48307e-02
I0213 06:58:23.375543 22542570456896 run_lib.py:133] step: 1166700, training_loss: 2.79915e-02
I0213 06:58:23.548210 22542570456896 run_lib.py:146] step: 1166700, eval_loss: 2.61118e-02
I0213 06:58:40.994060 22542570456896 run_lib.py:133] step: 1166750, training_loss: 2.31759e-02
I0213 06:58:58.297287 22542570456896 run_lib.py:133] step: 1166800, training_loss: 2.25696e-02
I0213 06:58:58.454479 22542570456896 run_lib.py:146] step: 1166800, eval_loss: 3.23543e-02
I0213 06:59:15.837324 22542570456896 run_lib.py:133] step: 1166850, training_loss: 2.96973e-02
I0213 06:59:33.074408 22542570456896 run_lib.py:133] step: 1166900, training_loss: 2.89188e-02
I0213 06:59:33.230555 22542570456896 run_lib.py:146] step: 1166900, eval_loss: 2.94685e-02
I0213 06:59:50.531248 22542570456896 run_lib.py:133] step: 1166950, training_loss: 3.50460e-02
I0213 07:00:07.987868 22542570456896 run_lib.py:133] step: 1167000, training_loss: 2.45153e-02
I0213 07:00:08.139090 22542570456896 run_lib.py:146] step: 1167000, eval_loss: 2.26921e-02
I0213 07:00:25.390065 22542570456896 run_lib.py:133] step: 1167050, training_loss: 2.32751e-02
I0213 07:00:42.822790 22542570456896 run_lib.py:133] step: 1167100, training_loss: 3.35479e-02
I0213 07:00:42.976237 22542570456896 run_lib.py:146] step: 1167100, eval_loss: 3.07457e-02
I0213 07:01:00.240474 22542570456896 run_lib.py:133] step: 1167150, training_loss: 2.42878e-02
I0213 07:01:17.513119 22542570456896 run_lib.py:133] step: 1167200, training_loss: 2.64263e-02
I0213 07:01:17.670297 22542570456896 run_lib.py:146] step: 1167200, eval_loss: 2.85784e-02
I0213 07:01:35.100607 22542570456896 run_lib.py:133] step: 1167250, training_loss: 2.56888e-02
I0213 07:01:52.411518 22542570456896 run_lib.py:133] step: 1167300, training_loss: 2.53279e-02
I0213 07:01:52.566525 22542570456896 run_lib.py:146] step: 1167300, eval_loss: 3.11857e-02
I0213 07:02:09.851253 22542570456896 run_lib.py:133] step: 1167350, training_loss: 2.88907e-02
I0213 07:02:27.284368 22542570456896 run_lib.py:133] step: 1167400, training_loss: 3.03560e-02
I0213 07:02:27.438230 22542570456896 run_lib.py:146] step: 1167400, eval_loss: 2.30093e-02
I0213 07:02:44.708148 22542570456896 run_lib.py:133] step: 1167450, training_loss: 3.00451e-02
I0213 07:03:01.973667 22542570456896 run_lib.py:133] step: 1167500, training_loss: 2.59901e-02
I0213 07:03:02.123437 22542570456896 run_lib.py:146] step: 1167500, eval_loss: 2.61141e-02
I0213 07:03:19.519349 22542570456896 run_lib.py:133] step: 1167550, training_loss: 3.16225e-02
I0213 07:03:36.788761 22542570456896 run_lib.py:133] step: 1167600, training_loss: 2.50414e-02
I0213 07:03:36.954270 22542570456896 run_lib.py:146] step: 1167600, eval_loss: 3.24739e-02
I0213 07:03:54.198921 22542570456896 run_lib.py:133] step: 1167650, training_loss: 3.09615e-02
I0213 07:04:11.440932 22542570456896 run_lib.py:133] step: 1167700, training_loss: 2.23509e-02
I0213 07:04:11.597532 22542570456896 run_lib.py:146] step: 1167700, eval_loss: 2.99109e-02
I0213 07:04:29.040073 22542570456896 run_lib.py:133] step: 1167750, training_loss: 2.95308e-02
I0213 07:04:46.303511 22542570456896 run_lib.py:133] step: 1167800, training_loss: 3.40952e-02
I0213 07:04:46.462018 22542570456896 run_lib.py:146] step: 1167800, eval_loss: 3.84486e-02
I0213 07:05:03.740781 22542570456896 run_lib.py:133] step: 1167850, training_loss: 2.96530e-02
I0213 07:05:21.022587 22542570456896 run_lib.py:133] step: 1167900, training_loss: 2.21727e-02
I0213 07:05:21.180542 22542570456896 run_lib.py:146] step: 1167900, eval_loss: 3.16936e-02
I0213 07:05:38.614167 22542570456896 run_lib.py:133] step: 1167950, training_loss: 2.55064e-02
I0213 07:05:55.843328 22542570456896 run_lib.py:133] step: 1168000, training_loss: 3.21643e-02
I0213 07:05:55.994270 22542570456896 run_lib.py:146] step: 1168000, eval_loss: 3.00811e-02
I0213 07:06:13.340732 22542570456896 run_lib.py:133] step: 1168050, training_loss: 2.65375e-02
I0213 07:06:30.592257 22542570456896 run_lib.py:133] step: 1168100, training_loss: 2.23169e-02
I0213 07:06:30.768314 22542570456896 run_lib.py:146] step: 1168100, eval_loss: 3.16131e-02
I0213 07:06:48.247483 22542570456896 run_lib.py:133] step: 1168150, training_loss: 3.18561e-02
I0213 07:07:05.511680 22542570456896 run_lib.py:133] step: 1168200, training_loss: 1.87630e-02
I0213 07:07:05.665486 22542570456896 run_lib.py:146] step: 1168200, eval_loss: 3.18691e-02
I0213 07:07:23.062883 22542570456896 run_lib.py:133] step: 1168250, training_loss: 2.72543e-02
I0213 07:07:40.272986 22542570456896 run_lib.py:133] step: 1168300, training_loss: 2.71370e-02
I0213 07:07:40.430329 22542570456896 run_lib.py:146] step: 1168300, eval_loss: 2.86513e-02
I0213 07:07:57.696464 22542570456896 run_lib.py:133] step: 1168350, training_loss: 2.59864e-02
I0213 07:08:15.094884 22542570456896 run_lib.py:133] step: 1168400, training_loss: 2.31525e-02
I0213 07:08:15.247134 22542570456896 run_lib.py:146] step: 1168400, eval_loss: 2.81621e-02
I0213 07:08:32.522788 22542570456896 run_lib.py:133] step: 1168450, training_loss: 2.50626e-02
I0213 07:08:49.794898 22542570456896 run_lib.py:133] step: 1168500, training_loss: 2.42674e-02
I0213 07:08:49.954288 22542570456896 run_lib.py:146] step: 1168500, eval_loss: 2.53514e-02
I0213 07:09:07.364007 22542570456896 run_lib.py:133] step: 1168550, training_loss: 3.68229e-02
I0213 07:09:24.623708 22542570456896 run_lib.py:133] step: 1168600, training_loss: 2.33633e-02
I0213 07:09:24.788216 22542570456896 run_lib.py:146] step: 1168600, eval_loss: 2.97702e-02
I0213 07:09:42.208144 22542570456896 run_lib.py:133] step: 1168650, training_loss: 2.72479e-02
I0213 07:09:59.487828 22542570456896 run_lib.py:133] step: 1168700, training_loss: 2.18502e-02
I0213 07:09:59.640470 22542570456896 run_lib.py:146] step: 1168700, eval_loss: 2.80669e-02
I0213 07:10:16.883966 22542570456896 run_lib.py:133] step: 1168750, training_loss: 2.73492e-02
I0213 07:10:34.302655 22542570456896 run_lib.py:133] step: 1168800, training_loss: 2.50808e-02
I0213 07:10:34.457533 22542570456896 run_lib.py:146] step: 1168800, eval_loss: 3.55804e-02
I0213 07:10:51.705492 22542570456896 run_lib.py:133] step: 1168850, training_loss: 2.32189e-02
I0213 07:11:08.957380 22542570456896 run_lib.py:133] step: 1168900, training_loss: 3.11034e-02
I0213 07:11:09.114861 22542570456896 run_lib.py:146] step: 1168900, eval_loss: 2.70792e-02
I0213 07:11:26.425122 22542570456896 run_lib.py:133] step: 1168950, training_loss: 2.47538e-02
I0213 07:11:43.838928 22542570456896 run_lib.py:133] step: 1169000, training_loss: 2.51241e-02
I0213 07:11:43.993427 22542570456896 run_lib.py:146] step: 1169000, eval_loss: 3.15818e-02
I0213 07:12:01.208052 22542570456896 run_lib.py:133] step: 1169050, training_loss: 2.76013e-02
I0213 07:12:18.523652 22542570456896 run_lib.py:133] step: 1169100, training_loss: 2.47798e-02
I0213 07:12:18.681538 22542570456896 run_lib.py:146] step: 1169100, eval_loss: 2.76678e-02
I0213 07:12:35.882930 22542570456896 run_lib.py:133] step: 1169150, training_loss: 2.14087e-02
I0213 07:12:53.127530 22542570456896 run_lib.py:133] step: 1169200, training_loss: 2.37144e-02
I0213 07:12:53.300523 22542570456896 run_lib.py:146] step: 1169200, eval_loss: 3.12371e-02
I0213 07:13:10.729352 22542570456896 run_lib.py:133] step: 1169250, training_loss: 2.93843e-02
I0213 07:13:28.113776 22542570456896 run_lib.py:133] step: 1169300, training_loss: 2.91865e-02
I0213 07:13:28.267501 22542570456896 run_lib.py:146] step: 1169300, eval_loss: 2.90853e-02
I0213 07:13:45.512416 22542570456896 run_lib.py:133] step: 1169350, training_loss: 3.32629e-02
I0213 07:14:02.739687 22542570456896 run_lib.py:133] step: 1169400, training_loss: 2.49890e-02
I0213 07:14:02.889276 22542570456896 run_lib.py:146] step: 1169400, eval_loss: 3.04208e-02
I0213 07:14:20.320111 22542570456896 run_lib.py:133] step: 1169450, training_loss: 3.05391e-02
I0213 07:14:37.623967 22542570456896 run_lib.py:133] step: 1169500, training_loss: 3.03094e-02
I0213 07:14:37.792009 22542570456896 run_lib.py:146] step: 1169500, eval_loss: 3.13474e-02
I0213 07:14:55.231564 22542570456896 run_lib.py:133] step: 1169550, training_loss: 3.35173e-02
I0213 07:15:12.500430 22542570456896 run_lib.py:133] step: 1169600, training_loss: 2.79947e-02
I0213 07:15:12.657332 22542570456896 run_lib.py:146] step: 1169600, eval_loss: 3.01995e-02
I0213 07:15:30.067329 22542570456896 run_lib.py:133] step: 1169650, training_loss: 3.21037e-02
I0213 07:15:47.304799 22542570456896 run_lib.py:133] step: 1169700, training_loss: 2.93427e-02
I0213 07:15:47.458347 22542570456896 run_lib.py:146] step: 1169700, eval_loss: 2.67237e-02
I0213 07:16:04.698955 22542570456896 run_lib.py:133] step: 1169750, training_loss: 2.87980e-02
I0213 07:16:22.113093 22542570456896 run_lib.py:133] step: 1169800, training_loss: 2.65105e-02
I0213 07:16:22.264591 22542570456896 run_lib.py:146] step: 1169800, eval_loss: 2.52365e-02
I0213 07:16:39.578561 22542570456896 run_lib.py:133] step: 1169850, training_loss: 2.64331e-02
I0213 07:16:56.988929 22542570456896 run_lib.py:133] step: 1169900, training_loss: 3.49141e-02
I0213 07:16:57.139258 22542570456896 run_lib.py:146] step: 1169900, eval_loss: 2.95656e-02
I0213 07:17:14.382053 22542570456896 run_lib.py:133] step: 1169950, training_loss: 3.18054e-02
I0213 07:17:31.622421 22542570456896 run_lib.py:133] step: 1170000, training_loss: 2.74798e-02
I0213 07:17:32.314748 22542570456896 run_lib.py:146] step: 1170000, eval_loss: 3.04139e-02
I0213 07:17:52.252590 22542570456896 run_lib.py:133] step: 1170050, training_loss: 2.73947e-02
I0213 07:18:09.565078 22542570456896 run_lib.py:133] step: 1170100, training_loss: 2.14784e-02
I0213 07:18:09.736312 22542570456896 run_lib.py:146] step: 1170100, eval_loss: 3.16291e-02
I0213 07:18:27.160519 22542570456896 run_lib.py:133] step: 1170150, training_loss: 2.99014e-02
I0213 07:18:44.419224 22542570456896 run_lib.py:133] step: 1170200, training_loss: 2.76567e-02
I0213 07:18:44.572227 22542570456896 run_lib.py:146] step: 1170200, eval_loss: 3.30531e-02
I0213 07:19:01.800907 22542570456896 run_lib.py:133] step: 1170250, training_loss: 2.44899e-02
I0213 07:19:19.174537 22542570456896 run_lib.py:133] step: 1170300, training_loss: 2.26628e-02
I0213 07:19:19.331228 22542570456896 run_lib.py:146] step: 1170300, eval_loss: 2.37315e-02
I0213 07:19:36.585113 22542570456896 run_lib.py:133] step: 1170350, training_loss: 3.11835e-02
I0213 07:19:54.050085 22542570456896 run_lib.py:133] step: 1170400, training_loss: 2.47820e-02
I0213 07:19:54.201530 22542570456896 run_lib.py:146] step: 1170400, eval_loss: 2.50570e-02
I0213 07:20:11.466181 22542570456896 run_lib.py:133] step: 1170450, training_loss: 2.71426e-02
I0213 07:20:28.725015 22542570456896 run_lib.py:133] step: 1170500, training_loss: 2.62463e-02
I0213 07:20:28.878145 22542570456896 run_lib.py:146] step: 1170500, eval_loss: 2.99438e-02
I0213 07:20:46.112589 22542570456896 run_lib.py:133] step: 1170550, training_loss: 2.81686e-02
I0213 07:21:03.497029 22542570456896 run_lib.py:133] step: 1170600, training_loss: 2.56433e-02
I0213 07:21:03.666332 22542570456896 run_lib.py:146] step: 1170600, eval_loss: 2.78586e-02
I0213 07:21:20.936663 22542570456896 run_lib.py:133] step: 1170650, training_loss: 2.84652e-02
I0213 07:21:38.218501 22542570456896 run_lib.py:133] step: 1170700, training_loss: 2.75773e-02
I0213 07:21:38.372433 22542570456896 run_lib.py:146] step: 1170700, eval_loss: 2.43008e-02
I0213 07:21:55.807103 22542570456896 run_lib.py:133] step: 1170750, training_loss: 2.23971e-02
I0213 07:22:13.063685 22542570456896 run_lib.py:133] step: 1170800, training_loss: 2.83042e-02
I0213 07:22:13.217177 22542570456896 run_lib.py:146] step: 1170800, eval_loss: 2.49879e-02
I0213 07:22:30.485069 22542570456896 run_lib.py:133] step: 1170850, training_loss: 2.13108e-02
I0213 07:22:47.757318 22542570456896 run_lib.py:133] step: 1170900, training_loss: 2.43457e-02
I0213 07:22:47.911506 22542570456896 run_lib.py:146] step: 1170900, eval_loss: 2.93854e-02
I0213 07:23:05.237632 22542570456896 run_lib.py:133] step: 1170950, training_loss: 2.38746e-02
I0213 07:23:22.504442 22542570456896 run_lib.py:133] step: 1171000, training_loss: 2.57380e-02
I0213 07:23:22.659264 22542570456896 run_lib.py:146] step: 1171000, eval_loss: 2.56648e-02
I0213 07:23:40.085351 22542570456896 run_lib.py:133] step: 1171050, training_loss: 2.59768e-02
I0213 07:23:57.381941 22542570456896 run_lib.py:133] step: 1171100, training_loss: 2.18557e-02
I0213 07:23:57.545881 22542570456896 run_lib.py:146] step: 1171100, eval_loss: 3.43836e-02
I0213 07:24:14.830446 22542570456896 run_lib.py:133] step: 1171150, training_loss: 2.88499e-02
I0213 07:24:32.072870 22542570456896 run_lib.py:133] step: 1171200, training_loss: 2.61847e-02
I0213 07:24:32.237991 22542570456896 run_lib.py:146] step: 1171200, eval_loss: 3.32140e-02
I0213 07:24:49.677833 22542570456896 run_lib.py:133] step: 1171250, training_loss: 3.10914e-02
I0213 07:25:06.916428 22542570456896 run_lib.py:133] step: 1171300, training_loss: 2.33999e-02
I0213 07:25:07.068010 22542570456896 run_lib.py:146] step: 1171300, eval_loss: 2.86780e-02
I0213 07:25:24.520325 22542570456896 run_lib.py:133] step: 1171350, training_loss: 2.81636e-02
I0213 07:25:41.749400 22542570456896 run_lib.py:133] step: 1171400, training_loss: 2.40333e-02
I0213 07:25:41.899215 22542570456896 run_lib.py:146] step: 1171400, eval_loss: 3.95403e-02
I0213 07:25:59.273789 22542570456896 run_lib.py:133] step: 1171450, training_loss: 1.80243e-02
I0213 07:26:16.509527 22542570456896 run_lib.py:133] step: 1171500, training_loss: 2.48505e-02
I0213 07:26:16.686243 22542570456896 run_lib.py:146] step: 1171500, eval_loss: 2.61685e-02
I0213 07:26:34.184373 22542570456896 run_lib.py:133] step: 1171550, training_loss: 2.89497e-02
I0213 07:26:51.458755 22542570456896 run_lib.py:133] step: 1171600, training_loss: 2.58884e-02
I0213 07:26:51.609652 22542570456896 run_lib.py:146] step: 1171600, eval_loss: 3.35264e-02
I0213 07:27:08.862357 22542570456896 run_lib.py:133] step: 1171650, training_loss: 2.22684e-02
I0213 07:27:26.202018 22542570456896 run_lib.py:133] step: 1171700, training_loss: 2.77752e-02
I0213 07:27:26.355448 22542570456896 run_lib.py:146] step: 1171700, eval_loss: 3.08970e-02
I0213 07:27:43.607086 22542570456896 run_lib.py:133] step: 1171750, training_loss: 2.93102e-02
I0213 07:28:00.895815 22542570456896 run_lib.py:133] step: 1171800, training_loss: 2.69395e-02
I0213 07:28:01.047131 22542570456896 run_lib.py:146] step: 1171800, eval_loss: 3.44940e-02
I0213 07:28:18.513524 22542570456896 run_lib.py:133] step: 1171850, training_loss: 2.02052e-02
I0213 07:28:35.739941 22542570456896 run_lib.py:133] step: 1171900, training_loss: 2.49790e-02
I0213 07:28:35.896318 22542570456896 run_lib.py:146] step: 1171900, eval_loss: 2.56975e-02
I0213 07:28:53.259937 22542570456896 run_lib.py:133] step: 1171950, training_loss: 2.06977e-02
I0213 07:29:10.509522 22542570456896 run_lib.py:133] step: 1172000, training_loss: 2.67484e-02
I0213 07:29:10.666525 22542570456896 run_lib.py:146] step: 1172000, eval_loss: 2.63628e-02
I0213 07:29:27.948442 22542570456896 run_lib.py:133] step: 1172050, training_loss: 3.00330e-02
I0213 07:29:45.371322 22542570456896 run_lib.py:133] step: 1172100, training_loss: 3.09505e-02
I0213 07:29:45.525565 22542570456896 run_lib.py:146] step: 1172100, eval_loss: 2.60281e-02
I0213 07:30:02.738635 22542570456896 run_lib.py:133] step: 1172150, training_loss: 2.62176e-02
I0213 07:30:19.985502 22542570456896 run_lib.py:133] step: 1172200, training_loss: 3.09366e-02
I0213 07:30:20.139256 22542570456896 run_lib.py:146] step: 1172200, eval_loss: 2.23947e-02
I0213 07:30:37.414338 22542570456896 run_lib.py:133] step: 1172250, training_loss: 2.35324e-02
I0213 07:30:54.848843 22542570456896 run_lib.py:133] step: 1172300, training_loss: 3.48780e-02
I0213 07:30:55.005545 22542570456896 run_lib.py:146] step: 1172300, eval_loss: 3.30503e-02
I0213 07:31:12.266464 22542570456896 run_lib.py:133] step: 1172350, training_loss: 2.87128e-02
I0213 07:31:29.628929 22542570456896 run_lib.py:133] step: 1172400, training_loss: 2.68086e-02
I0213 07:31:29.796480 22542570456896 run_lib.py:146] step: 1172400, eval_loss: 4.07283e-02
I0213 07:31:47.082361 22542570456896 run_lib.py:133] step: 1172450, training_loss: 3.09651e-02
I0213 07:32:04.336309 22542570456896 run_lib.py:133] step: 1172500, training_loss: 2.47949e-02
I0213 07:32:04.493488 22542570456896 run_lib.py:146] step: 1172500, eval_loss: 2.63410e-02
I0213 07:32:21.920274 22542570456896 run_lib.py:133] step: 1172550, training_loss: 2.26944e-02
I0213 07:32:39.225142 22542570456896 run_lib.py:133] step: 1172600, training_loss: 2.11427e-02
I0213 07:32:39.378342 22542570456896 run_lib.py:146] step: 1172600, eval_loss: 3.09273e-02
I0213 07:32:56.649698 22542570456896 run_lib.py:133] step: 1172650, training_loss: 2.66787e-02
I0213 07:33:13.945552 22542570456896 run_lib.py:133] step: 1172700, training_loss: 3.23328e-02
I0213 07:33:14.099548 22542570456896 run_lib.py:146] step: 1172700, eval_loss: 2.99983e-02
I0213 07:33:31.535413 22542570456896 run_lib.py:133] step: 1172750, training_loss: 2.51724e-02
I0213 07:33:48.794761 22542570456896 run_lib.py:133] step: 1172800, training_loss: 2.09337e-02
I0213 07:33:48.941623 22542570456896 run_lib.py:146] step: 1172800, eval_loss: 3.39898e-02
I0213 07:34:06.313397 22542570456896 run_lib.py:133] step: 1172850, training_loss: 2.48702e-02
I0213 07:34:23.549910 22542570456896 run_lib.py:133] step: 1172900, training_loss: 3.15016e-02
I0213 07:34:23.718275 22542570456896 run_lib.py:146] step: 1172900, eval_loss: 3.14588e-02
I0213 07:34:41.099898 22542570456896 run_lib.py:133] step: 1172950, training_loss: 2.43730e-02
I0213 07:34:58.410304 22542570456896 run_lib.py:133] step: 1173000, training_loss: 3.38240e-02
I0213 07:34:58.564466 22542570456896 run_lib.py:146] step: 1173000, eval_loss: 3.40118e-02
I0213 07:35:15.810033 22542570456896 run_lib.py:133] step: 1173050, training_loss: 2.85408e-02
I0213 07:35:33.217550 22542570456896 run_lib.py:133] step: 1173100, training_loss: 2.50000e-02
I0213 07:35:33.370044 22542570456896 run_lib.py:146] step: 1173100, eval_loss: 3.05879e-02
I0213 07:35:50.651810 22542570456896 run_lib.py:133] step: 1173150, training_loss: 2.94350e-02
I0213 07:36:08.041930 22542570456896 run_lib.py:133] step: 1173200, training_loss: 2.07503e-02
I0213 07:36:08.194557 22542570456896 run_lib.py:146] step: 1173200, eval_loss: 2.07041e-02
I0213 07:36:25.500839 22542570456896 run_lib.py:133] step: 1173250, training_loss: 2.46570e-02
I0213 07:36:42.726718 22542570456896 run_lib.py:133] step: 1173300, training_loss: 3.07740e-02
I0213 07:36:42.882193 22542570456896 run_lib.py:146] step: 1173300, eval_loss: 3.61634e-02
I0213 07:37:00.280734 22542570456896 run_lib.py:133] step: 1173350, training_loss: 2.36709e-02
I0213 07:37:17.553537 22542570456896 run_lib.py:133] step: 1173400, training_loss: 3.44143e-02
I0213 07:37:17.710474 22542570456896 run_lib.py:146] step: 1173400, eval_loss: 2.79031e-02
I0213 07:37:34.938937 22542570456896 run_lib.py:133] step: 1173450, training_loss: 2.77790e-02
I0213 07:37:52.320462 22542570456896 run_lib.py:133] step: 1173500, training_loss: 2.61637e-02
I0213 07:37:52.482307 22542570456896 run_lib.py:146] step: 1173500, eval_loss: 2.88714e-02
I0213 07:38:09.788588 22542570456896 run_lib.py:133] step: 1173550, training_loss: 3.23259e-02
I0213 07:38:27.078474 22542570456896 run_lib.py:133] step: 1173600, training_loss: 2.32990e-02
I0213 07:38:27.406953 22542570456896 run_lib.py:146] step: 1173600, eval_loss: 2.65071e-02
I0213 07:38:44.660505 22542570456896 run_lib.py:133] step: 1173650, training_loss: 2.53731e-02
I0213 07:39:01.882792 22542570456896 run_lib.py:133] step: 1173700, training_loss: 2.66033e-02
I0213 07:39:02.033215 22542570456896 run_lib.py:146] step: 1173700, eval_loss: 3.64950e-02
I0213 07:39:19.267258 22542570456896 run_lib.py:133] step: 1173750, training_loss: 2.09664e-02
I0213 07:39:36.544736 22542570456896 run_lib.py:133] step: 1173800, training_loss: 2.02794e-02
I0213 07:39:36.710526 22542570456896 run_lib.py:146] step: 1173800, eval_loss: 3.00051e-02
I0213 07:39:54.157183 22542570456896 run_lib.py:133] step: 1173850, training_loss: 2.57865e-02
I0213 07:40:11.531985 22542570456896 run_lib.py:133] step: 1173900, training_loss: 2.93267e-02
I0213 07:40:11.690256 22542570456896 run_lib.py:146] step: 1173900, eval_loss: 2.65894e-02
I0213 07:40:28.938876 22542570456896 run_lib.py:133] step: 1173950, training_loss: 3.09394e-02
I0213 07:40:46.236229 22542570456896 run_lib.py:133] step: 1174000, training_loss: 2.50401e-02
I0213 07:40:46.390271 22542570456896 run_lib.py:146] step: 1174000, eval_loss: 2.39307e-02
I0213 07:41:03.770004 22542570456896 run_lib.py:133] step: 1174050, training_loss: 2.69785e-02
I0213 07:41:21.131447 22542570456896 run_lib.py:133] step: 1174100, training_loss: 2.73153e-02
I0213 07:41:21.285499 22542570456896 run_lib.py:146] step: 1174100, eval_loss: 3.41322e-02
I0213 07:41:38.566386 22542570456896 run_lib.py:133] step: 1174150, training_loss: 2.61642e-02
I0213 07:41:55.838127 22542570456896 run_lib.py:133] step: 1174200, training_loss: 2.84640e-02
I0213 07:41:55.991228 22542570456896 run_lib.py:146] step: 1174200, eval_loss: 3.29233e-02
I0213 07:42:13.353290 22542570456896 run_lib.py:133] step: 1174250, training_loss: 2.32927e-02
I0213 07:42:30.576762 22542570456896 run_lib.py:133] step: 1174300, training_loss: 1.76135e-02
I0213 07:42:30.734427 22542570456896 run_lib.py:146] step: 1174300, eval_loss: 3.12875e-02
I0213 07:42:48.156069 22542570456896 run_lib.py:133] step: 1174350, training_loss: 3.06193e-02
I0213 07:43:05.500682 22542570456896 run_lib.py:133] step: 1174400, training_loss: 2.56204e-02
I0213 07:43:05.656263 22542570456896 run_lib.py:146] step: 1174400, eval_loss: 3.39870e-02
I0213 07:43:23.084001 22542570456896 run_lib.py:133] step: 1174450, training_loss: 2.70560e-02
I0213 07:43:40.303350 22542570456896 run_lib.py:133] step: 1174500, training_loss: 2.41682e-02
I0213 07:43:40.459373 22542570456896 run_lib.py:146] step: 1174500, eval_loss: 2.32698e-02
I0213 07:43:57.723767 22542570456896 run_lib.py:133] step: 1174550, training_loss: 3.17206e-02
I0213 07:44:15.113331 22542570456896 run_lib.py:133] step: 1174600, training_loss: 2.41850e-02
I0213 07:44:15.270253 22542570456896 run_lib.py:146] step: 1174600, eval_loss: 2.78546e-02
I0213 07:44:32.581279 22542570456896 run_lib.py:133] step: 1174650, training_loss: 3.53371e-02
I0213 07:44:50.062355 22542570456896 run_lib.py:133] step: 1174700, training_loss: 2.29200e-02
I0213 07:44:50.216458 22542570456896 run_lib.py:146] step: 1174700, eval_loss: 2.48169e-02
I0213 07:45:07.462750 22542570456896 run_lib.py:133] step: 1174750, training_loss: 2.95491e-02
I0213 07:45:24.785627 22542570456896 run_lib.py:133] step: 1174800, training_loss: 2.95724e-02
I0213 07:45:24.941729 22542570456896 run_lib.py:146] step: 1174800, eval_loss: 3.22018e-02
I0213 07:45:42.283461 22542570456896 run_lib.py:133] step: 1174850, training_loss: 2.70444e-02
I0213 07:45:59.549702 22542570456896 run_lib.py:133] step: 1174900, training_loss: 2.82513e-02
I0213 07:45:59.709209 22542570456896 run_lib.py:146] step: 1174900, eval_loss: 2.59956e-02
I0213 07:46:16.956637 22542570456896 run_lib.py:133] step: 1174950, training_loss: 2.48732e-02
I0213 07:46:34.279275 22542570456896 run_lib.py:133] step: 1175000, training_loss: 2.22519e-02
I0213 07:46:34.433031 22542570456896 run_lib.py:146] step: 1175000, eval_loss: 2.87067e-02
I0213 07:46:51.900058 22542570456896 run_lib.py:133] step: 1175050, training_loss: 2.10498e-02
I0213 07:47:09.205511 22542570456896 run_lib.py:133] step: 1175100, training_loss: 2.85446e-02
I0213 07:47:09.357016 22542570456896 run_lib.py:146] step: 1175100, eval_loss: 3.74080e-02
I0213 07:47:26.661017 22542570456896 run_lib.py:133] step: 1175150, training_loss: 2.91583e-02
I0213 07:47:43.954422 22542570456896 run_lib.py:133] step: 1175200, training_loss: 2.51745e-02
I0213 07:47:44.106472 22542570456896 run_lib.py:146] step: 1175200, eval_loss: 2.87520e-02
I0213 07:48:01.426197 22542570456896 run_lib.py:133] step: 1175250, training_loss: 2.95282e-02
I0213 07:48:18.694115 22542570456896 run_lib.py:133] step: 1175300, training_loss: 2.62409e-02
I0213 07:48:18.850384 22542570456896 run_lib.py:146] step: 1175300, eval_loss: 2.81949e-02
I0213 07:48:36.253324 22542570456896 run_lib.py:133] step: 1175350, training_loss: 2.98679e-02
I0213 07:48:53.568274 22542570456896 run_lib.py:133] step: 1175400, training_loss: 1.87499e-02
I0213 07:48:53.725227 22542570456896 run_lib.py:146] step: 1175400, eval_loss: 2.35389e-02
I0213 07:49:10.961261 22542570456896 run_lib.py:133] step: 1175450, training_loss: 3.08788e-02
I0213 07:49:28.219372 22542570456896 run_lib.py:133] step: 1175500, training_loss: 2.72379e-02
I0213 07:49:28.374287 22542570456896 run_lib.py:146] step: 1175500, eval_loss: 2.57865e-02
I0213 07:49:45.852059 22542570456896 run_lib.py:133] step: 1175550, training_loss: 2.44989e-02
I0213 07:50:03.112634 22542570456896 run_lib.py:133] step: 1175600, training_loss: 2.79164e-02
I0213 07:50:03.262423 22542570456896 run_lib.py:146] step: 1175600, eval_loss: 3.09144e-02
I0213 07:50:20.633938 22542570456896 run_lib.py:133] step: 1175650, training_loss: 2.83469e-02
I0213 07:50:37.875283 22542570456896 run_lib.py:133] step: 1175700, training_loss: 2.67592e-02
I0213 07:50:38.028336 22542570456896 run_lib.py:146] step: 1175700, eval_loss: 3.14909e-02
I0213 07:50:55.386350 22542570456896 run_lib.py:133] step: 1175750, training_loss: 2.72960e-02
I0213 07:51:12.640921 22542570456896 run_lib.py:133] step: 1175800, training_loss: 3.02032e-02
I0213 07:51:12.816273 22542570456896 run_lib.py:146] step: 1175800, eval_loss: 3.52919e-02
I0213 07:51:30.310207 22542570456896 run_lib.py:133] step: 1175850, training_loss: 2.83515e-02
I0213 07:51:47.594365 22542570456896 run_lib.py:133] step: 1175900, training_loss: 2.83218e-02
I0213 07:51:47.748488 22542570456896 run_lib.py:146] step: 1175900, eval_loss: 2.56945e-02
I0213 07:52:04.994509 22542570456896 run_lib.py:133] step: 1175950, training_loss: 2.58215e-02
I0213 07:52:22.319365 22542570456896 run_lib.py:133] step: 1176000, training_loss: 2.81442e-02
I0213 07:52:22.480719 22542570456896 run_lib.py:146] step: 1176000, eval_loss: 2.51409e-02
I0213 07:52:39.728819 22542570456896 run_lib.py:133] step: 1176050, training_loss: 3.58513e-02
I0213 07:52:57.035696 22542570456896 run_lib.py:133] step: 1176100, training_loss: 2.44340e-02
I0213 07:52:57.188493 22542570456896 run_lib.py:146] step: 1176100, eval_loss: 3.04061e-02
I0213 07:53:14.681711 22542570456896 run_lib.py:133] step: 1176150, training_loss: 2.68497e-02
I0213 07:53:32.042272 22542570456896 run_lib.py:133] step: 1176200, training_loss: 2.71060e-02
I0213 07:53:32.194901 22542570456896 run_lib.py:146] step: 1176200, eval_loss: 3.05591e-02
I0213 07:53:49.432378 22542570456896 run_lib.py:133] step: 1176250, training_loss: 2.19976e-02
I0213 07:54:06.662264 22542570456896 run_lib.py:133] step: 1176300, training_loss: 2.38161e-02
I0213 07:54:06.819447 22542570456896 run_lib.py:146] step: 1176300, eval_loss: 3.08652e-02
I0213 07:54:24.156354 22542570456896 run_lib.py:133] step: 1176350, training_loss: 2.62117e-02
I0213 07:54:41.578211 22542570456896 run_lib.py:133] step: 1176400, training_loss: 2.74792e-02
I0213 07:54:41.732460 22542570456896 run_lib.py:146] step: 1176400, eval_loss: 3.08991e-02
I0213 07:54:58.957344 22542570456896 run_lib.py:133] step: 1176450, training_loss: 2.71514e-02
I0213 07:55:16.213274 22542570456896 run_lib.py:133] step: 1176500, training_loss: 2.90435e-02
I0213 07:55:16.366375 22542570456896 run_lib.py:146] step: 1176500, eval_loss: 2.68625e-02
I0213 07:55:33.619396 22542570456896 run_lib.py:133] step: 1176550, training_loss: 2.22167e-02
I0213 07:55:51.083174 22542570456896 run_lib.py:133] step: 1176600, training_loss: 2.21345e-02
I0213 07:55:51.241865 22542570456896 run_lib.py:146] step: 1176600, eval_loss: 2.93670e-02
I0213 07:56:08.572316 22542570456896 run_lib.py:133] step: 1176650, training_loss: 2.75366e-02
I0213 07:56:25.893374 22542570456896 run_lib.py:133] step: 1176700, training_loss: 3.70809e-02
I0213 07:56:26.050280 22542570456896 run_lib.py:146] step: 1176700, eval_loss: 2.48114e-02
I0213 07:56:43.327474 22542570456896 run_lib.py:133] step: 1176750, training_loss: 2.29361e-02
I0213 07:57:00.562580 22542570456896 run_lib.py:133] step: 1176800, training_loss: 2.14240e-02
I0213 07:57:00.720552 22542570456896 run_lib.py:146] step: 1176800, eval_loss: 3.01911e-02
I0213 07:57:18.155803 22542570456896 run_lib.py:133] step: 1176850, training_loss: 2.39618e-02
I0213 07:57:35.459492 22542570456896 run_lib.py:133] step: 1176900, training_loss: 2.67258e-02
I0213 07:57:35.627141 22542570456896 run_lib.py:146] step: 1176900, eval_loss: 2.14937e-02
I0213 07:57:52.927616 22542570456896 run_lib.py:133] step: 1176950, training_loss: 2.56695e-02
I0213 07:58:10.213181 22542570456896 run_lib.py:133] step: 1177000, training_loss: 2.98490e-02
I0213 07:58:10.370046 22542570456896 run_lib.py:146] step: 1177000, eval_loss: 2.49371e-02
I0213 07:58:27.822205 22542570456896 run_lib.py:133] step: 1177050, training_loss: 2.61003e-02
I0213 07:58:45.067059 22542570456896 run_lib.py:133] step: 1177100, training_loss: 2.88158e-02
I0213 07:58:45.225863 22542570456896 run_lib.py:146] step: 1177100, eval_loss: 3.03025e-02
I0213 07:59:02.626975 22542570456896 run_lib.py:133] step: 1177150, training_loss: 2.90000e-02
I0213 07:59:19.869471 22542570456896 run_lib.py:133] step: 1177200, training_loss: 2.30605e-02
I0213 07:59:20.044297 22542570456896 run_lib.py:146] step: 1177200, eval_loss: 3.08758e-02
I0213 07:59:37.530958 22542570456896 run_lib.py:133] step: 1177250, training_loss: 2.75137e-02
I0213 07:59:54.808587 22542570456896 run_lib.py:133] step: 1177300, training_loss: 2.63519e-02
I0213 07:59:54.965474 22542570456896 run_lib.py:146] step: 1177300, eval_loss: 3.50216e-02
I0213 08:00:12.206176 22542570456896 run_lib.py:133] step: 1177350, training_loss: 2.94524e-02
I0213 08:00:29.557882 22542570456896 run_lib.py:133] step: 1177400, training_loss: 2.90726e-02
I0213 08:00:29.712440 22542570456896 run_lib.py:146] step: 1177400, eval_loss: 3.04764e-02
I0213 08:00:46.968035 22542570456896 run_lib.py:133] step: 1177450, training_loss: 1.97485e-02
I0213 08:01:04.428913 22542570456896 run_lib.py:133] step: 1177500, training_loss: 3.19741e-02
I0213 08:01:04.586494 22542570456896 run_lib.py:146] step: 1177500, eval_loss: 2.90487e-02
I0213 08:01:21.857528 22542570456896 run_lib.py:133] step: 1177550, training_loss: 2.50465e-02
I0213 08:01:39.155704 22542570456896 run_lib.py:133] step: 1177600, training_loss: 2.48178e-02
I0213 08:01:39.313337 22542570456896 run_lib.py:146] step: 1177600, eval_loss: 2.54691e-02
I0213 08:01:56.700095 22542570456896 run_lib.py:133] step: 1177650, training_loss: 3.03084e-02
I0213 08:02:13.963145 22542570456896 run_lib.py:133] step: 1177700, training_loss: 1.97898e-02
I0213 08:02:14.120349 22542570456896 run_lib.py:146] step: 1177700, eval_loss: 3.57742e-02
I0213 08:02:31.372141 22542570456896 run_lib.py:133] step: 1177750, training_loss: 2.88675e-02
I0213 08:02:48.816394 22542570456896 run_lib.py:133] step: 1177800, training_loss: 2.74839e-02
I0213 08:02:48.976425 22542570456896 run_lib.py:146] step: 1177800, eval_loss: 3.79362e-02
I0213 08:03:06.257704 22542570456896 run_lib.py:133] step: 1177850, training_loss: 2.88524e-02
I0213 08:03:23.515249 22542570456896 run_lib.py:133] step: 1177900, training_loss: 3.30055e-02
I0213 08:03:23.676611 22542570456896 run_lib.py:146] step: 1177900, eval_loss: 2.83369e-02
I0213 08:03:41.016373 22542570456896 run_lib.py:133] step: 1177950, training_loss: 2.47685e-02
I0213 08:03:58.270326 22542570456896 run_lib.py:133] step: 1178000, training_loss: 3.57488e-02
I0213 08:03:58.420394 22542570456896 run_lib.py:146] step: 1178000, eval_loss: 2.98424e-02
I0213 08:04:15.666496 22542570456896 run_lib.py:133] step: 1178050, training_loss: 2.44670e-02
I0213 08:04:32.984495 22542570456896 run_lib.py:133] step: 1178100, training_loss: 1.97078e-02
I0213 08:04:33.153464 22542570456896 run_lib.py:146] step: 1178100, eval_loss: 2.70501e-02
I0213 08:04:50.612162 22542570456896 run_lib.py:133] step: 1178150, training_loss: 2.23405e-02
I0213 08:05:07.939705 22542570456896 run_lib.py:133] step: 1178200, training_loss: 2.43998e-02
I0213 08:05:08.095491 22542570456896 run_lib.py:146] step: 1178200, eval_loss: 3.35926e-02
I0213 08:05:25.318291 22542570456896 run_lib.py:133] step: 1178250, training_loss: 2.48522e-02
I0213 08:05:42.571178 22542570456896 run_lib.py:133] step: 1178300, training_loss: 2.86926e-02
I0213 08:05:42.724316 22542570456896 run_lib.py:146] step: 1178300, eval_loss: 2.48744e-02
I0213 08:06:00.112294 22542570456896 run_lib.py:133] step: 1178350, training_loss: 3.37117e-02
I0213 08:06:17.427666 22542570456896 run_lib.py:133] step: 1178400, training_loss: 2.57112e-02
I0213 08:06:17.582062 22542570456896 run_lib.py:146] step: 1178400, eval_loss: 3.37520e-02
I0213 08:06:34.996430 22542570456896 run_lib.py:133] step: 1178450, training_loss: 2.15107e-02
I0213 08:06:52.236010 22542570456896 run_lib.py:133] step: 1178500, training_loss: 3.30996e-02
I0213 08:06:52.386310 22542570456896 run_lib.py:146] step: 1178500, eval_loss: 2.58413e-02
I0213 08:07:09.748749 22542570456896 run_lib.py:133] step: 1178550, training_loss: 2.70474e-02
I0213 08:07:26.982089 22542570456896 run_lib.py:133] step: 1178600, training_loss: 3.07878e-02
I0213 08:07:27.150218 22542570456896 run_lib.py:146] step: 1178600, eval_loss: 2.73202e-02
I0213 08:07:44.586081 22542570456896 run_lib.py:133] step: 1178650, training_loss: 2.67006e-02
I0213 08:08:01.879204 22542570456896 run_lib.py:133] step: 1178700, training_loss: 2.32236e-02
I0213 08:08:02.032203 22542570456896 run_lib.py:146] step: 1178700, eval_loss: 2.32292e-02
I0213 08:08:19.261564 22542570456896 run_lib.py:133] step: 1178750, training_loss: 2.84895e-02
I0213 08:08:36.656820 22542570456896 run_lib.py:133] step: 1178800, training_loss: 3.00400e-02
I0213 08:08:36.811498 22542570456896 run_lib.py:146] step: 1178800, eval_loss: 2.65959e-02
I0213 08:08:54.059590 22542570456896 run_lib.py:133] step: 1178850, training_loss: 2.98747e-02
I0213 08:09:11.384596 22542570456896 run_lib.py:133] step: 1178900, training_loss: 2.54701e-02
I0213 08:09:11.533411 22542570456896 run_lib.py:146] step: 1178900, eval_loss: 2.96739e-02
I0213 08:09:28.988680 22542570456896 run_lib.py:133] step: 1178950, training_loss: 3.11225e-02
I0213 08:09:46.234602 22542570456896 run_lib.py:133] step: 1179000, training_loss: 3.62579e-02
I0213 08:09:46.390276 22542570456896 run_lib.py:146] step: 1179000, eval_loss: 2.36660e-02
I0213 08:10:03.803203 22542570456896 run_lib.py:133] step: 1179050, training_loss: 2.64721e-02
I0213 08:10:21.081920 22542570456896 run_lib.py:133] step: 1179100, training_loss: 2.48739e-02
I0213 08:10:21.239507 22542570456896 run_lib.py:146] step: 1179100, eval_loss: 2.77990e-02
I0213 08:10:38.510469 22542570456896 run_lib.py:133] step: 1179150, training_loss: 3.06597e-02
I0213 08:10:55.964457 22542570456896 run_lib.py:133] step: 1179200, training_loss: 2.21922e-02
I0213 08:10:56.119086 22542570456896 run_lib.py:146] step: 1179200, eval_loss: 2.42488e-02
I0213 08:11:13.357820 22542570456896 run_lib.py:133] step: 1179250, training_loss: 3.08312e-02
I0213 08:11:30.563407 22542570456896 run_lib.py:133] step: 1179300, training_loss: 2.57649e-02
I0213 08:11:30.721454 22542570456896 run_lib.py:146] step: 1179300, eval_loss: 2.82408e-02
I0213 08:11:47.990390 22542570456896 run_lib.py:133] step: 1179350, training_loss: 2.85555e-02
I0213 08:12:05.416026 22542570456896 run_lib.py:133] step: 1179400, training_loss: 2.80510e-02
I0213 08:12:05.565012 22542570456896 run_lib.py:146] step: 1179400, eval_loss: 2.91191e-02
I0213 08:12:22.797793 22542570456896 run_lib.py:133] step: 1179450, training_loss: 2.51239e-02
I0213 08:12:40.112261 22542570456896 run_lib.py:133] step: 1179500, training_loss: 2.36504e-02
I0213 08:12:40.280470 22542570456896 run_lib.py:146] step: 1179500, eval_loss: 3.18221e-02
I0213 08:12:57.569649 22542570456896 run_lib.py:133] step: 1179550, training_loss: 2.92616e-02
I0213 08:13:14.843048 22542570456896 run_lib.py:133] step: 1179600, training_loss: 2.84784e-02
I0213 08:13:14.998351 22542570456896 run_lib.py:146] step: 1179600, eval_loss: 2.85218e-02
I0213 08:13:32.400512 22542570456896 run_lib.py:133] step: 1179650, training_loss: 3.07547e-02
I0213 08:13:49.710113 22542570456896 run_lib.py:133] step: 1179700, training_loss: 2.75145e-02
I0213 08:13:49.864304 22542570456896 run_lib.py:146] step: 1179700, eval_loss: 2.50281e-02
I0213 08:14:07.111953 22542570456896 run_lib.py:133] step: 1179750, training_loss: 2.71532e-02
I0213 08:14:24.430609 22542570456896 run_lib.py:133] step: 1179800, training_loss: 2.25412e-02
I0213 08:14:24.588547 22542570456896 run_lib.py:146] step: 1179800, eval_loss: 2.91655e-02
I0213 08:14:42.034975 22542570456896 run_lib.py:133] step: 1179850, training_loss: 3.68328e-02
I0213 08:14:59.280838 22542570456896 run_lib.py:133] step: 1179900, training_loss: 2.62138e-02
I0213 08:14:59.431373 22542570456896 run_lib.py:146] step: 1179900, eval_loss: 2.68493e-02
I0213 08:15:16.807495 22542570456896 run_lib.py:133] step: 1179950, training_loss: 2.56747e-02
I0213 08:15:34.060665 22542570456896 run_lib.py:133] step: 1180000, training_loss: 2.71579e-02
I0213 08:15:34.739177 22542570456896 run_lib.py:146] step: 1180000, eval_loss: 3.13708e-02
I0213 08:15:54.742522 22542570456896 run_lib.py:133] step: 1180050, training_loss: 3.00658e-02
I0213 08:16:12.048966 22542570456896 run_lib.py:133] step: 1180100, training_loss: 2.81947e-02
I0213 08:16:12.220319 22542570456896 run_lib.py:146] step: 1180100, eval_loss: 1.89098e-02
I0213 08:16:29.595128 22542570456896 run_lib.py:133] step: 1180150, training_loss: 2.70203e-02
I0213 08:16:46.879906 22542570456896 run_lib.py:133] step: 1180200, training_loss: 3.02949e-02
I0213 08:16:47.034538 22542570456896 run_lib.py:146] step: 1180200, eval_loss: 2.34519e-02
I0213 08:17:04.297454 22542570456896 run_lib.py:133] step: 1180250, training_loss: 2.25015e-02
I0213 08:17:21.543069 22542570456896 run_lib.py:133] step: 1180300, training_loss: 2.38843e-02
I0213 08:17:21.697292 22542570456896 run_lib.py:146] step: 1180300, eval_loss: 3.12175e-02
I0213 08:17:39.082954 22542570456896 run_lib.py:133] step: 1180350, training_loss: 2.29671e-02
I0213 08:17:56.471794 22542570456896 run_lib.py:133] step: 1180400, training_loss: 2.07570e-02
I0213 08:17:56.630053 22542570456896 run_lib.py:146] step: 1180400, eval_loss: 3.17564e-02
I0213 08:18:13.918737 22542570456896 run_lib.py:133] step: 1180450, training_loss: 3.01950e-02
I0213 08:18:31.178288 22542570456896 run_lib.py:133] step: 1180500, training_loss: 2.64217e-02
I0213 08:18:31.335277 22542570456896 run_lib.py:146] step: 1180500, eval_loss: 3.40716e-02
I0213 08:18:48.676511 22542570456896 run_lib.py:133] step: 1180550, training_loss: 2.58690e-02
I0213 08:19:05.918427 22542570456896 run_lib.py:133] step: 1180600, training_loss: 2.89068e-02
I0213 08:19:06.091181 22542570456896 run_lib.py:146] step: 1180600, eval_loss: 3.08922e-02
I0213 08:19:23.577132 22542570456896 run_lib.py:133] step: 1180650, training_loss: 2.84069e-02
I0213 08:19:40.817894 22542570456896 run_lib.py:133] step: 1180700, training_loss: 2.71109e-02
I0213 08:19:40.971503 22542570456896 run_lib.py:146] step: 1180700, eval_loss: 2.93308e-02
I0213 08:19:58.394811 22542570456896 run_lib.py:133] step: 1180750, training_loss: 3.11970e-02
I0213 08:20:15.691675 22542570456896 run_lib.py:133] step: 1180800, training_loss: 3.10050e-02
I0213 08:20:15.845434 22542570456896 run_lib.py:146] step: 1180800, eval_loss: 2.89693e-02
I0213 08:20:33.143429 22542570456896 run_lib.py:133] step: 1180850, training_loss: 1.98082e-02
I0213 08:20:50.514603 22542570456896 run_lib.py:133] step: 1180900, training_loss: 2.85765e-02
I0213 08:20:50.666679 22542570456896 run_lib.py:146] step: 1180900, eval_loss: 2.99024e-02
I0213 08:21:07.998239 22542570456896 run_lib.py:133] step: 1180950, training_loss: 2.83646e-02
I0213 08:21:25.401732 22542570456896 run_lib.py:133] step: 1181000, training_loss: 2.37332e-02
I0213 08:21:25.555365 22542570456896 run_lib.py:146] step: 1181000, eval_loss: 2.96633e-02
I0213 08:21:42.810087 22542570456896 run_lib.py:133] step: 1181050, training_loss: 2.01817e-02
I0213 08:22:00.052535 22542570456896 run_lib.py:133] step: 1181100, training_loss: 3.01451e-02
I0213 08:22:00.208437 22542570456896 run_lib.py:146] step: 1181100, eval_loss: 3.52334e-02
I0213 08:22:17.605119 22542570456896 run_lib.py:133] step: 1181150, training_loss: 2.20516e-02
I0213 08:22:34.846283 22542570456896 run_lib.py:133] step: 1181200, training_loss: 2.78753e-02
I0213 08:22:35.014298 22542570456896 run_lib.py:146] step: 1181200, eval_loss: 3.53658e-02
I0213 08:22:52.331994 22542570456896 run_lib.py:133] step: 1181250, training_loss: 2.81140e-02
I0213 08:23:09.794775 22542570456896 run_lib.py:133] step: 1181300, training_loss: 2.91018e-02
I0213 08:23:09.954451 22542570456896 run_lib.py:146] step: 1181300, eval_loss: 3.24278e-02
I0213 08:23:27.274487 22542570456896 run_lib.py:133] step: 1181350, training_loss: 3.15870e-02
I0213 08:23:44.512455 22542570456896 run_lib.py:133] step: 1181400, training_loss: 2.59749e-02
I0213 08:23:44.801254 22542570456896 run_lib.py:146] step: 1181400, eval_loss: 3.14235e-02
I0213 08:24:02.050357 22542570456896 run_lib.py:133] step: 1181450, training_loss: 2.55623e-02
I0213 08:24:19.314743 22542570456896 run_lib.py:133] step: 1181500, training_loss: 3.01794e-02
I0213 08:24:19.482022 22542570456896 run_lib.py:146] step: 1181500, eval_loss: 2.87898e-02
I0213 08:24:36.769230 22542570456896 run_lib.py:133] step: 1181550, training_loss: 2.79639e-02
I0213 08:24:54.071223 22542570456896 run_lib.py:133] step: 1181600, training_loss: 2.99205e-02
I0213 08:24:54.227507 22542570456896 run_lib.py:146] step: 1181600, eval_loss: 2.73721e-02
I0213 08:25:11.625896 22542570456896 run_lib.py:133] step: 1181650, training_loss: 2.53451e-02
I0213 08:25:28.899455 22542570456896 run_lib.py:133] step: 1181700, training_loss: 2.78788e-02
I0213 08:25:29.052262 22542570456896 run_lib.py:146] step: 1181700, eval_loss: 3.60640e-02
I0213 08:25:46.281076 22542570456896 run_lib.py:133] step: 1181750, training_loss: 2.92936e-02
I0213 08:26:03.593304 22542570456896 run_lib.py:133] step: 1181800, training_loss: 2.70660e-02
I0213 08:26:03.746466 22542570456896 run_lib.py:146] step: 1181800, eval_loss: 2.79556e-02
I0213 08:26:21.152612 22542570456896 run_lib.py:133] step: 1181850, training_loss: 2.78111e-02
I0213 08:26:38.444461 22542570456896 run_lib.py:133] step: 1181900, training_loss: 2.30513e-02
I0213 08:26:38.596246 22542570456896 run_lib.py:146] step: 1181900, eval_loss: 2.74263e-02
I0213 08:26:55.870584 22542570456896 run_lib.py:133] step: 1181950, training_loss: 3.44224e-02
I0213 08:27:13.122823 22542570456896 run_lib.py:133] step: 1182000, training_loss: 2.49887e-02
I0213 08:27:13.280485 22542570456896 run_lib.py:146] step: 1182000, eval_loss: 2.71599e-02
I0213 08:27:30.687529 22542570456896 run_lib.py:133] step: 1182050, training_loss: 2.87404e-02
I0213 08:27:48.008336 22542570456896 run_lib.py:133] step: 1182100, training_loss: 2.16429e-02
I0213 08:27:48.162542 22542570456896 run_lib.py:146] step: 1182100, eval_loss: 3.28395e-02
I0213 08:28:05.556390 22542570456896 run_lib.py:133] step: 1182150, training_loss: 2.48303e-02
I0213 08:28:22.804855 22542570456896 run_lib.py:133] step: 1182200, training_loss: 3.15726e-02
I0213 08:28:22.959141 22542570456896 run_lib.py:146] step: 1182200, eval_loss: 2.99827e-02
I0213 08:28:40.326682 22542570456896 run_lib.py:133] step: 1182250, training_loss: 2.70056e-02
I0213 08:28:57.539965 22542570456896 run_lib.py:133] step: 1182300, training_loss: 3.33578e-02
I0213 08:28:57.687402 22542570456896 run_lib.py:146] step: 1182300, eval_loss: 2.84976e-02
I0213 08:29:14.934073 22542570456896 run_lib.py:133] step: 1182350, training_loss: 2.25025e-02
I0213 08:29:32.427699 22542570456896 run_lib.py:133] step: 1182400, training_loss: 2.83920e-02
I0213 08:29:32.596482 22542570456896 run_lib.py:146] step: 1182400, eval_loss: 2.93020e-02
I0213 08:29:49.872373 22542570456896 run_lib.py:133] step: 1182450, training_loss: 2.22392e-02
I0213 08:30:07.287905 22542570456896 run_lib.py:133] step: 1182500, training_loss: 3.08107e-02
I0213 08:30:07.443506 22542570456896 run_lib.py:146] step: 1182500, eval_loss: 2.74501e-02
I0213 08:30:24.738257 22542570456896 run_lib.py:133] step: 1182550, training_loss: 2.25160e-02
I0213 08:30:42.008316 22542570456896 run_lib.py:133] step: 1182600, training_loss: 2.36746e-02
I0213 08:30:42.176323 22542570456896 run_lib.py:146] step: 1182600, eval_loss: 2.74022e-02
I0213 08:30:59.638489 22542570456896 run_lib.py:133] step: 1182650, training_loss: 2.44424e-02
I0213 08:31:16.934426 22542570456896 run_lib.py:133] step: 1182700, training_loss: 2.51278e-02
I0213 08:31:17.092980 22542570456896 run_lib.py:146] step: 1182700, eval_loss: 2.27078e-02
I0213 08:31:34.371253 22542570456896 run_lib.py:133] step: 1182750, training_loss: 3.26745e-02
I0213 08:31:51.600140 22542570456896 run_lib.py:133] step: 1182800, training_loss: 2.63313e-02
I0213 08:31:51.750244 22542570456896 run_lib.py:146] step: 1182800, eval_loss: 3.25652e-02
I0213 08:32:09.202424 22542570456896 run_lib.py:133] step: 1182850, training_loss: 2.85076e-02
I0213 08:32:26.463987 22542570456896 run_lib.py:133] step: 1182900, training_loss: 2.99611e-02
I0213 08:32:26.632450 22542570456896 run_lib.py:146] step: 1182900, eval_loss: 1.87734e-02
I0213 08:32:43.993149 22542570456896 run_lib.py:133] step: 1182950, training_loss: 2.51425e-02
I0213 08:33:01.294494 22542570456896 run_lib.py:133] step: 1183000, training_loss: 2.90175e-02
I0213 08:33:01.451248 22542570456896 run_lib.py:146] step: 1183000, eval_loss: 3.03481e-02
I0213 08:33:18.717154 22542570456896 run_lib.py:133] step: 1183050, training_loss: 2.53955e-02
I0213 08:33:35.963237 22542570456896 run_lib.py:133] step: 1183100, training_loss: 2.44837e-02
I0213 08:33:36.117351 22542570456896 run_lib.py:146] step: 1183100, eval_loss: 2.51757e-02
I0213 08:33:53.562116 22542570456896 run_lib.py:133] step: 1183150, training_loss: 2.35432e-02
I0213 08:34:10.954838 22542570456896 run_lib.py:133] step: 1183200, training_loss: 2.77154e-02
I0213 08:34:11.120494 22542570456896 run_lib.py:146] step: 1183200, eval_loss: 2.97537e-02
I0213 08:34:28.443506 22542570456896 run_lib.py:133] step: 1183250, training_loss: 2.42057e-02
I0213 08:34:45.700445 22542570456896 run_lib.py:133] step: 1183300, training_loss: 3.02236e-02
I0213 08:34:45.857793 22542570456896 run_lib.py:146] step: 1183300, eval_loss: 3.30549e-02
I0213 08:35:03.240097 22542570456896 run_lib.py:133] step: 1183350, training_loss: 2.23441e-02
I0213 08:35:20.516338 22542570456896 run_lib.py:133] step: 1183400, training_loss: 2.97142e-02
I0213 08:35:20.670471 22542570456896 run_lib.py:146] step: 1183400, eval_loss: 2.71887e-02
I0213 08:35:38.037868 22542570456896 run_lib.py:133] step: 1183450, training_loss: 2.64751e-02
I0213 08:35:55.318972 22542570456896 run_lib.py:133] step: 1183500, training_loss: 3.47580e-02
I0213 08:35:55.476351 22542570456896 run_lib.py:146] step: 1183500, eval_loss: 2.91067e-02
I0213 08:36:12.897194 22542570456896 run_lib.py:133] step: 1183550, training_loss: 3.13735e-02
I0213 08:36:30.195737 22542570456896 run_lib.py:133] step: 1183600, training_loss: 2.91931e-02
I0213 08:36:30.349015 22542570456896 run_lib.py:146] step: 1183600, eval_loss: 2.98701e-02
I0213 08:36:47.742698 22542570456896 run_lib.py:133] step: 1183650, training_loss: 3.11404e-02
I0213 08:37:04.981374 22542570456896 run_lib.py:133] step: 1183700, training_loss: 2.58362e-02
I0213 08:37:05.133279 22542570456896 run_lib.py:146] step: 1183700, eval_loss: 3.80256e-02
I0213 08:37:22.409980 22542570456896 run_lib.py:133] step: 1183750, training_loss: 2.50449e-02
I0213 08:37:39.827913 22542570456896 run_lib.py:133] step: 1183800, training_loss: 2.97098e-02
I0213 08:37:39.984536 22542570456896 run_lib.py:146] step: 1183800, eval_loss: 2.56182e-02
I0213 08:37:57.277775 22542570456896 run_lib.py:133] step: 1183850, training_loss: 2.53576e-02
I0213 08:38:14.558681 22542570456896 run_lib.py:133] step: 1183900, training_loss: 1.94936e-02
I0213 08:38:14.715541 22542570456896 run_lib.py:146] step: 1183900, eval_loss: 2.69290e-02
I0213 08:38:32.096019 22542570456896 run_lib.py:133] step: 1183950, training_loss: 2.69777e-02
I0213 08:38:49.467092 22542570456896 run_lib.py:133] step: 1184000, training_loss: 2.75840e-02
I0213 08:38:49.620216 22542570456896 run_lib.py:146] step: 1184000, eval_loss: 3.44708e-02
I0213 08:39:06.880470 22542570456896 run_lib.py:133] step: 1184050, training_loss: 2.50527e-02
I0213 08:39:24.194576 22542570456896 run_lib.py:133] step: 1184100, training_loss: 3.44660e-02
I0213 08:39:24.349056 22542570456896 run_lib.py:146] step: 1184100, eval_loss: 2.62655e-02
I0213 08:39:41.640508 22542570456896 run_lib.py:133] step: 1184150, training_loss: 2.95080e-02
I0213 08:39:59.072221 22542570456896 run_lib.py:133] step: 1184200, training_loss: 3.02755e-02
I0213 08:39:59.222035 22542570456896 run_lib.py:146] step: 1184200, eval_loss: 2.72539e-02
I0213 08:40:16.466074 22542570456896 run_lib.py:133] step: 1184250, training_loss: 2.30920e-02
I0213 08:40:33.670910 22542570456896 run_lib.py:133] step: 1184300, training_loss: 3.01105e-02
I0213 08:40:33.822273 22542570456896 run_lib.py:146] step: 1184300, eval_loss: 2.87107e-02
I0213 08:40:51.115981 22542570456896 run_lib.py:133] step: 1184350, training_loss: 2.32748e-02
I0213 08:41:08.576936 22542570456896 run_lib.py:133] step: 1184400, training_loss: 2.33653e-02
I0213 08:41:08.733212 22542570456896 run_lib.py:146] step: 1184400, eval_loss: 3.02999e-02
I0213 08:41:26.003173 22542570456896 run_lib.py:133] step: 1184450, training_loss: 2.39048e-02
I0213 08:41:43.325026 22542570456896 run_lib.py:133] step: 1184500, training_loss: 2.68148e-02
I0213 08:41:43.479297 22542570456896 run_lib.py:146] step: 1184500, eval_loss: 3.61380e-02
I0213 08:42:00.707052 22542570456896 run_lib.py:133] step: 1184550, training_loss: 2.70164e-02
I0213 08:42:17.912500 22542570456896 run_lib.py:133] step: 1184600, training_loss: 3.11927e-02
I0213 08:42:18.072013 22542570456896 run_lib.py:146] step: 1184600, eval_loss: 3.42101e-02
I0213 08:42:35.457133 22542570456896 run_lib.py:133] step: 1184650, training_loss: 3.14568e-02
I0213 08:42:52.891868 22542570456896 run_lib.py:133] step: 1184700, training_loss: 2.93479e-02
I0213 08:42:53.040756 22542570456896 run_lib.py:146] step: 1184700, eval_loss: 2.52199e-02
I0213 08:43:10.320965 22542570456896 run_lib.py:133] step: 1184750, training_loss: 2.49471e-02
I0213 08:43:27.577649 22542570456896 run_lib.py:133] step: 1184800, training_loss: 2.46037e-02
I0213 08:43:27.731247 22542570456896 run_lib.py:146] step: 1184800, eval_loss: 3.23852e-02
I0213 08:43:45.065646 22542570456896 run_lib.py:133] step: 1184850, training_loss: 2.23124e-02
I0213 08:44:02.311973 22542570456896 run_lib.py:133] step: 1184900, training_loss: 2.88488e-02
I0213 08:44:02.485253 22542570456896 run_lib.py:146] step: 1184900, eval_loss: 2.80217e-02
I0213 08:44:19.897163 22542570456896 run_lib.py:133] step: 1184950, training_loss: 2.70893e-02
I0213 08:44:37.142801 22542570456896 run_lib.py:133] step: 1185000, training_loss: 2.91479e-02
I0213 08:44:37.296477 22542570456896 run_lib.py:146] step: 1185000, eval_loss: 2.73649e-02
I0213 08:44:54.738884 22542570456896 run_lib.py:133] step: 1185050, training_loss: 2.24325e-02
I0213 08:45:11.966419 22542570456896 run_lib.py:133] step: 1185100, training_loss: 3.41250e-02
I0213 08:45:12.119214 22542570456896 run_lib.py:146] step: 1185100, eval_loss: 3.92099e-02
I0213 08:45:29.345394 22542570456896 run_lib.py:133] step: 1185150, training_loss: 2.93331e-02
I0213 08:45:46.763612 22542570456896 run_lib.py:133] step: 1185200, training_loss: 2.15820e-02
I0213 08:45:46.920457 22542570456896 run_lib.py:146] step: 1185200, eval_loss: 3.56304e-02
I0213 08:46:04.226831 22542570456896 run_lib.py:133] step: 1185250, training_loss: 3.07480e-02
I0213 08:46:21.641929 22542570456896 run_lib.py:133] step: 1185300, training_loss: 2.95697e-02
I0213 08:46:21.797487 22542570456896 run_lib.py:146] step: 1185300, eval_loss: 3.04005e-02
I0213 08:46:39.028129 22542570456896 run_lib.py:133] step: 1185350, training_loss: 2.53404e-02
I0213 08:46:56.276835 22542570456896 run_lib.py:133] step: 1185400, training_loss: 2.05913e-02
I0213 08:46:56.431553 22542570456896 run_lib.py:146] step: 1185400, eval_loss: 2.83954e-02
I0213 08:47:13.857172 22542570456896 run_lib.py:133] step: 1185450, training_loss: 3.59127e-02
I0213 08:47:31.186911 22542570456896 run_lib.py:133] step: 1185500, training_loss: 2.62863e-02
I0213 08:47:31.341728 22542570456896 run_lib.py:146] step: 1185500, eval_loss: 2.65155e-02
I0213 08:47:48.622309 22542570456896 run_lib.py:133] step: 1185550, training_loss: 2.98786e-02
I0213 08:48:06.032404 22542570456896 run_lib.py:133] step: 1185600, training_loss: 2.98918e-02
I0213 08:48:06.185270 22542570456896 run_lib.py:146] step: 1185600, eval_loss: 3.13855e-02
I0213 08:48:23.457331 22542570456896 run_lib.py:133] step: 1185650, training_loss: 2.47393e-02
I0213 08:48:40.720310 22542570456896 run_lib.py:133] step: 1185700, training_loss: 3.41304e-02
I0213 08:48:40.871219 22542570456896 run_lib.py:146] step: 1185700, eval_loss: 2.29272e-02
I0213 08:48:58.224309 22542570456896 run_lib.py:133] step: 1185750, training_loss: 1.99674e-02
I0213 08:49:15.524078 22542570456896 run_lib.py:133] step: 1185800, training_loss: 2.42512e-02
I0213 08:49:15.688243 22542570456896 run_lib.py:146] step: 1185800, eval_loss: 2.93477e-02
I0213 08:49:32.937794 22542570456896 run_lib.py:133] step: 1185850, training_loss: 2.69371e-02
I0213 08:49:50.209521 22542570456896 run_lib.py:133] step: 1185900, training_loss: 3.62525e-02
I0213 08:49:50.363328 22542570456896 run_lib.py:146] step: 1185900, eval_loss: 3.59173e-02
I0213 08:50:07.808979 22542570456896 run_lib.py:133] step: 1185950, training_loss: 2.35384e-02
I0213 08:50:25.098754 22542570456896 run_lib.py:133] step: 1186000, training_loss: 2.71470e-02
I0213 08:50:25.270022 22542570456896 run_lib.py:146] step: 1186000, eval_loss: 3.21589e-02
I0213 08:50:42.522504 22542570456896 run_lib.py:133] step: 1186050, training_loss: 2.09836e-02
I0213 08:50:59.781907 22542570456896 run_lib.py:133] step: 1186100, training_loss: 2.69320e-02
I0213 08:50:59.931052 22542570456896 run_lib.py:146] step: 1186100, eval_loss: 3.25669e-02
I0213 08:51:17.355285 22542570456896 run_lib.py:133] step: 1186150, training_loss: 2.26544e-02
I0213 08:51:34.597682 22542570456896 run_lib.py:133] step: 1186200, training_loss: 3.30280e-02
I0213 08:51:34.750252 22542570456896 run_lib.py:146] step: 1186200, eval_loss: 2.23031e-02
I0213 08:51:52.139474 22542570456896 run_lib.py:133] step: 1186250, training_loss: 2.81050e-02
I0213 08:52:09.375196 22542570456896 run_lib.py:133] step: 1186300, training_loss: 2.81570e-02
I0213 08:52:09.544253 22542570456896 run_lib.py:146] step: 1186300, eval_loss: 3.38071e-02
I0213 08:52:26.966401 22542570456896 run_lib.py:133] step: 1186350, training_loss: 2.25671e-02
I0213 08:52:44.232372 22542570456896 run_lib.py:133] step: 1186400, training_loss: 2.79647e-02
I0213 08:52:44.388380 22542570456896 run_lib.py:146] step: 1186400, eval_loss: 2.17936e-02
I0213 08:53:01.785339 22542570456896 run_lib.py:133] step: 1186450, training_loss: 2.85877e-02
I0213 08:53:19.009029 22542570456896 run_lib.py:133] step: 1186500, training_loss: 2.91899e-02
I0213 08:53:19.165333 22542570456896 run_lib.py:146] step: 1186500, eval_loss: 2.42722e-02
I0213 08:53:36.374460 22542570456896 run_lib.py:133] step: 1186550, training_loss: 2.94760e-02
I0213 08:53:53.752374 22542570456896 run_lib.py:133] step: 1186600, training_loss: 1.86209e-02
I0213 08:53:53.911493 22542570456896 run_lib.py:146] step: 1186600, eval_loss: 3.44060e-02
I0213 08:54:11.195557 22542570456896 run_lib.py:133] step: 1186650, training_loss: 2.79274e-02
I0213 08:54:28.466242 22542570456896 run_lib.py:133] step: 1186700, training_loss: 2.46576e-02
I0213 08:54:28.620243 22542570456896 run_lib.py:146] step: 1186700, eval_loss: 3.21621e-02
I0213 08:54:46.044311 22542570456896 run_lib.py:133] step: 1186750, training_loss: 2.11778e-02
I0213 08:55:03.280577 22542570456896 run_lib.py:133] step: 1186800, training_loss: 2.93224e-02
I0213 08:55:03.436439 22542570456896 run_lib.py:146] step: 1186800, eval_loss: 2.86032e-02
I0213 08:55:20.806216 22542570456896 run_lib.py:133] step: 1186850, training_loss: 2.52121e-02
I0213 08:55:38.068715 22542570456896 run_lib.py:133] step: 1186900, training_loss: 2.42653e-02
I0213 08:55:38.231022 22542570456896 run_lib.py:146] step: 1186900, eval_loss: 3.24256e-02
I0213 08:55:55.507076 22542570456896 run_lib.py:133] step: 1186950, training_loss: 3.52634e-02
I0213 08:56:12.927289 22542570456896 run_lib.py:133] step: 1187000, training_loss: 2.81937e-02
I0213 08:56:13.080231 22542570456896 run_lib.py:146] step: 1187000, eval_loss: 3.16922e-02
I0213 08:56:30.336440 22542570456896 run_lib.py:133] step: 1187050, training_loss: 3.35459e-02
I0213 08:56:47.599298 22542570456896 run_lib.py:133] step: 1187100, training_loss: 2.59786e-02
I0213 08:56:47.744670 22542570456896 run_lib.py:146] step: 1187100, eval_loss: 3.29537e-02
I0213 08:57:04.962887 22542570456896 run_lib.py:133] step: 1187150, training_loss: 2.24909e-02
I0213 08:57:22.366162 22542570456896 run_lib.py:133] step: 1187200, training_loss: 2.80268e-02
I0213 08:57:22.525197 22542570456896 run_lib.py:146] step: 1187200, eval_loss: 3.40802e-02
I0213 08:57:39.819642 22542570456896 run_lib.py:133] step: 1187250, training_loss: 2.75143e-02
I0213 08:57:57.180298 22542570456896 run_lib.py:133] step: 1187300, training_loss: 3.17637e-02
I0213 08:57:57.335271 22542570456896 run_lib.py:146] step: 1187300, eval_loss: 3.28699e-02
I0213 08:58:14.568472 22542570456896 run_lib.py:133] step: 1187350, training_loss: 2.74063e-02
I0213 08:58:31.762304 22542570456896 run_lib.py:133] step: 1187400, training_loss: 2.32827e-02
I0213 08:58:31.916051 22542570456896 run_lib.py:146] step: 1187400, eval_loss: 3.10984e-02
I0213 08:58:49.285885 22542570456896 run_lib.py:133] step: 1187450, training_loss: 2.67950e-02
I0213 08:59:06.667381 22542570456896 run_lib.py:133] step: 1187500, training_loss: 3.12832e-02
I0213 08:59:06.822108 22542570456896 run_lib.py:146] step: 1187500, eval_loss: 2.99110e-02
I0213 08:59:24.124606 22542570456896 run_lib.py:133] step: 1187550, training_loss: 3.12426e-02
I0213 08:59:41.355086 22542570456896 run_lib.py:133] step: 1187600, training_loss: 2.87048e-02
I0213 08:59:41.507245 22542570456896 run_lib.py:146] step: 1187600, eval_loss: 3.20134e-02
I0213 08:59:58.916211 22542570456896 run_lib.py:133] step: 1187650, training_loss: 3.41380e-02
I0213 09:00:16.191120 22542570456896 run_lib.py:133] step: 1187700, training_loss: 2.63058e-02
I0213 09:00:16.347070 22542570456896 run_lib.py:146] step: 1187700, eval_loss: 2.82855e-02
I0213 09:00:33.723258 22542570456896 run_lib.py:133] step: 1187750, training_loss: 2.90390e-02
I0213 09:00:51.021794 22542570456896 run_lib.py:133] step: 1187800, training_loss: 2.93982e-02
I0213 09:00:51.176477 22542570456896 run_lib.py:146] step: 1187800, eval_loss: 2.79315e-02
I0213 09:01:08.609735 22542570456896 run_lib.py:133] step: 1187850, training_loss: 2.20931e-02
I0213 09:01:25.856492 22542570456896 run_lib.py:133] step: 1187900, training_loss: 2.72871e-02
I0213 09:01:26.010246 22542570456896 run_lib.py:146] step: 1187900, eval_loss: 2.41340e-02
I0213 09:01:43.235822 22542570456896 run_lib.py:133] step: 1187950, training_loss: 2.78433e-02
I0213 09:02:00.600575 22542570456896 run_lib.py:133] step: 1188000, training_loss: 2.50230e-02
I0213 09:02:00.751625 22542570456896 run_lib.py:146] step: 1188000, eval_loss: 2.75502e-02
I0213 09:02:18.057950 22542570456896 run_lib.py:133] step: 1188050, training_loss: 2.60458e-02
I0213 09:02:35.491714 22542570456896 run_lib.py:133] step: 1188100, training_loss: 2.50308e-02
I0213 09:02:35.646465 22542570456896 run_lib.py:146] step: 1188100, eval_loss: 2.20094e-02
I0213 09:02:52.940713 22542570456896 run_lib.py:133] step: 1188150, training_loss: 2.48145e-02
I0213 09:03:10.190850 22542570456896 run_lib.py:133] step: 1188200, training_loss: 2.39866e-02
I0213 09:03:10.348553 22542570456896 run_lib.py:146] step: 1188200, eval_loss: 2.81181e-02
I0213 09:03:27.690929 22542570456896 run_lib.py:133] step: 1188250, training_loss: 3.48571e-02
I0213 09:03:44.913074 22542570456896 run_lib.py:133] step: 1188300, training_loss: 2.78451e-02
I0213 09:03:45.085249 22542570456896 run_lib.py:146] step: 1188300, eval_loss: 3.18535e-02
I0213 09:04:02.361278 22542570456896 run_lib.py:133] step: 1188350, training_loss: 3.01230e-02
I0213 09:04:19.829985 22542570456896 run_lib.py:133] step: 1188400, training_loss: 3.19001e-02
I0213 09:04:19.987605 22542570456896 run_lib.py:146] step: 1188400, eval_loss: 2.43836e-02
I0213 09:04:37.295069 22542570456896 run_lib.py:133] step: 1188450, training_loss: 2.85881e-02
I0213 09:04:54.538125 22542570456896 run_lib.py:133] step: 1188500, training_loss: 2.78902e-02
I0213 09:04:54.823049 22542570456896 run_lib.py:146] step: 1188500, eval_loss: 2.62304e-02
I0213 09:05:12.041395 22542570456896 run_lib.py:133] step: 1188550, training_loss: 2.22621e-02
I0213 09:05:29.300478 22542570456896 run_lib.py:133] step: 1188600, training_loss: 2.51877e-02
I0213 09:05:29.467524 22542570456896 run_lib.py:146] step: 1188600, eval_loss: 2.92826e-02
I0213 09:05:46.821630 22542570456896 run_lib.py:133] step: 1188650, training_loss: 2.36787e-02
I0213 09:06:04.079167 22542570456896 run_lib.py:133] step: 1188700, training_loss: 2.86898e-02
I0213 09:06:04.235265 22542570456896 run_lib.py:146] step: 1188700, eval_loss: 3.09520e-02
I0213 09:06:21.629373 22542570456896 run_lib.py:133] step: 1188750, training_loss: 2.80220e-02
I0213 09:06:38.900528 22542570456896 run_lib.py:133] step: 1188800, training_loss: 2.79678e-02
I0213 09:06:39.054406 22542570456896 run_lib.py:146] step: 1188800, eval_loss: 2.39005e-02
I0213 09:06:56.361886 22542570456896 run_lib.py:133] step: 1188850, training_loss: 2.95417e-02
I0213 09:07:13.642159 22542570456896 run_lib.py:133] step: 1188900, training_loss: 2.95373e-02
I0213 09:07:13.796413 22542570456896 run_lib.py:146] step: 1188900, eval_loss: 2.34725e-02
I0213 09:07:31.271040 22542570456896 run_lib.py:133] step: 1188950, training_loss: 2.16212e-02
I0213 09:07:48.541102 22542570456896 run_lib.py:133] step: 1189000, training_loss: 2.09601e-02
I0213 09:07:48.700018 22542570456896 run_lib.py:146] step: 1189000, eval_loss: 3.06942e-02
I0213 09:08:05.967536 22542570456896 run_lib.py:133] step: 1189050, training_loss: 3.02265e-02
I0213 09:08:23.188589 22542570456896 run_lib.py:133] step: 1189100, training_loss: 2.54615e-02
I0213 09:08:23.346611 22542570456896 run_lib.py:146] step: 1189100, eval_loss: 2.34891e-02
I0213 09:08:40.673353 22542570456896 run_lib.py:133] step: 1189150, training_loss: 2.84252e-02
I0213 09:08:57.908863 22542570456896 run_lib.py:133] step: 1189200, training_loss: 2.77037e-02
I0213 09:08:58.075386 22542570456896 run_lib.py:146] step: 1189200, eval_loss: 3.45843e-02
I0213 09:09:15.527241 22542570456896 run_lib.py:133] step: 1189250, training_loss: 2.69300e-02
I0213 09:09:32.783555 22542570456896 run_lib.py:133] step: 1189300, training_loss: 2.28387e-02
I0213 09:09:32.937011 22542570456896 run_lib.py:146] step: 1189300, eval_loss: 2.85940e-02
I0213 09:09:50.348478 22542570456896 run_lib.py:133] step: 1189350, training_loss: 3.33306e-02
I0213 09:10:07.613773 22542570456896 run_lib.py:133] step: 1189400, training_loss: 2.35408e-02
I0213 09:10:07.763957 22542570456896 run_lib.py:146] step: 1189400, eval_loss: 2.78982e-02
I0213 09:10:25.026731 22542570456896 run_lib.py:133] step: 1189450, training_loss: 2.38921e-02
I0213 09:10:42.446898 22542570456896 run_lib.py:133] step: 1189500, training_loss: 2.11470e-02
I0213 09:10:42.602025 22542570456896 run_lib.py:146] step: 1189500, eval_loss: 3.07771e-02
I0213 09:10:59.890736 22542570456896 run_lib.py:133] step: 1189550, training_loss: 2.75386e-02
I0213 09:11:17.337377 22542570456896 run_lib.py:133] step: 1189600, training_loss: 2.98453e-02
I0213 09:11:17.495483 22542570456896 run_lib.py:146] step: 1189600, eval_loss: 2.09440e-02
I0213 09:11:34.741461 22542570456896 run_lib.py:133] step: 1189650, training_loss: 3.20550e-02
I0213 09:11:51.991014 22542570456896 run_lib.py:133] step: 1189700, training_loss: 2.93302e-02
I0213 09:11:52.145316 22542570456896 run_lib.py:146] step: 1189700, eval_loss: 2.60200e-02
I0213 09:12:09.544426 22542570456896 run_lib.py:133] step: 1189750, training_loss: 2.09440e-02
I0213 09:12:26.852150 22542570456896 run_lib.py:133] step: 1189800, training_loss: 2.94723e-02
I0213 09:12:27.008027 22542570456896 run_lib.py:146] step: 1189800, eval_loss: 2.72828e-02
I0213 09:12:44.336332 22542570456896 run_lib.py:133] step: 1189850, training_loss: 2.81722e-02
I0213 09:13:01.602413 22542570456896 run_lib.py:133] step: 1189900, training_loss: 2.43456e-02
I0213 09:13:01.754229 22542570456896 run_lib.py:146] step: 1189900, eval_loss: 3.26342e-02
I0213 09:13:19.231022 22542570456896 run_lib.py:133] step: 1189950, training_loss: 3.37304e-02
I0213 09:13:36.522525 22542570456896 run_lib.py:133] step: 1190000, training_loss: 3.12889e-02
I0213 09:13:37.207323 22542570456896 run_lib.py:146] step: 1190000, eval_loss: 3.49873e-02
I0213 09:13:57.243137 22542570456896 run_lib.py:133] step: 1190050, training_loss: 2.79070e-02
I0213 09:14:14.510287 22542570456896 run_lib.py:133] step: 1190100, training_loss: 2.73742e-02
I0213 09:14:14.669257 22542570456896 run_lib.py:146] step: 1190100, eval_loss: 2.75914e-02
I0213 09:14:32.047858 22542570456896 run_lib.py:133] step: 1190150, training_loss: 2.69729e-02
I0213 09:14:49.295736 22542570456896 run_lib.py:133] step: 1190200, training_loss: 3.03277e-02
I0213 09:14:49.452359 22542570456896 run_lib.py:146] step: 1190200, eval_loss: 2.43089e-02
I0213 09:15:06.682503 22542570456896 run_lib.py:133] step: 1190250, training_loss: 3.01559e-02
I0213 09:15:24.046944 22542570456896 run_lib.py:133] step: 1190300, training_loss: 2.15702e-02
I0213 09:15:24.216294 22542570456896 run_lib.py:146] step: 1190300, eval_loss: 2.98892e-02
I0213 09:15:41.546916 22542570456896 run_lib.py:133] step: 1190350, training_loss: 2.57580e-02
I0213 09:15:58.810277 22542570456896 run_lib.py:133] step: 1190400, training_loss: 2.98187e-02
I0213 09:15:58.968997 22542570456896 run_lib.py:146] step: 1190400, eval_loss: 2.65466e-02
I0213 09:16:16.235106 22542570456896 run_lib.py:133] step: 1190450, training_loss: 2.84812e-02
I0213 09:16:33.636382 22542570456896 run_lib.py:133] step: 1190500, training_loss: 2.39966e-02
I0213 09:16:33.794293 22542570456896 run_lib.py:146] step: 1190500, eval_loss: 3.21307e-02
I0213 09:16:51.018068 22542570456896 run_lib.py:133] step: 1190550, training_loss: 2.35289e-02
I0213 09:17:08.324087 22542570456896 run_lib.py:133] step: 1190600, training_loss: 3.51304e-02
I0213 09:17:08.504604 22542570456896 run_lib.py:146] step: 1190600, eval_loss: 3.25964e-02
I0213 09:17:25.817119 22542570456896 run_lib.py:133] step: 1190650, training_loss: 2.34818e-02
I0213 09:17:43.100375 22542570456896 run_lib.py:133] step: 1190700, training_loss: 2.74066e-02
I0213 09:17:43.254262 22542570456896 run_lib.py:146] step: 1190700, eval_loss: 2.42592e-02
I0213 09:18:00.682307 22542570456896 run_lib.py:133] step: 1190750, training_loss: 2.80611e-02
I0213 09:18:17.977524 22542570456896 run_lib.py:133] step: 1190800, training_loss: 2.53443e-02
I0213 09:18:18.132468 22542570456896 run_lib.py:146] step: 1190800, eval_loss: 3.22935e-02
I0213 09:18:35.394414 22542570456896 run_lib.py:133] step: 1190850, training_loss: 2.73239e-02
I0213 09:18:52.702159 22542570456896 run_lib.py:133] step: 1190900, training_loss: 3.47765e-02
I0213 09:18:52.857923 22542570456896 run_lib.py:146] step: 1190900, eval_loss: 3.77948e-02
I0213 09:19:10.325789 22542570456896 run_lib.py:133] step: 1190950, training_loss: 2.87086e-02
I0213 09:19:27.581315 22542570456896 run_lib.py:133] step: 1191000, training_loss: 1.94400e-02
I0213 09:19:27.733260 22542570456896 run_lib.py:146] step: 1191000, eval_loss: 3.25577e-02
I0213 09:19:45.110759 22542570456896 run_lib.py:133] step: 1191050, training_loss: 2.68785e-02
I0213 09:20:02.361896 22542570456896 run_lib.py:133] step: 1191100, training_loss: 3.26560e-02
I0213 09:20:02.520539 22542570456896 run_lib.py:146] step: 1191100, eval_loss: 3.20594e-02
I0213 09:20:19.934040 22542570456896 run_lib.py:133] step: 1191150, training_loss: 2.39062e-02
I0213 09:20:37.249495 22542570456896 run_lib.py:133] step: 1191200, training_loss: 2.42732e-02
I0213 09:20:37.404390 22542570456896 run_lib.py:146] step: 1191200, eval_loss: 2.90947e-02
I0213 09:20:54.612809 22542570456896 run_lib.py:133] step: 1191250, training_loss: 2.75152e-02
I0213 09:21:12.006266 22542570456896 run_lib.py:133] step: 1191300, training_loss: 3.21217e-02
I0213 09:21:12.165376 22542570456896 run_lib.py:146] step: 1191300, eval_loss: 3.18241e-02
I0213 09:21:29.410714 22542570456896 run_lib.py:133] step: 1191350, training_loss: 3.33690e-02
I0213 09:21:46.825644 22542570456896 run_lib.py:133] step: 1191400, training_loss: 2.71187e-02
I0213 09:21:46.978000 22542570456896 run_lib.py:146] step: 1191400, eval_loss: 3.25737e-02
I0213 09:22:04.231310 22542570456896 run_lib.py:133] step: 1191450, training_loss: 2.66336e-02
I0213 09:22:21.495236 22542570456896 run_lib.py:133] step: 1191500, training_loss: 3.20262e-02
I0213 09:22:21.662379 22542570456896 run_lib.py:146] step: 1191500, eval_loss: 2.33086e-02
I0213 09:22:39.140536 22542570456896 run_lib.py:133] step: 1191550, training_loss: 3.10898e-02
I0213 09:22:56.457781 22542570456896 run_lib.py:133] step: 1191600, training_loss: 2.66581e-02
I0213 09:22:56.614548 22542570456896 run_lib.py:146] step: 1191600, eval_loss: 2.91268e-02
I0213 09:23:13.848473 22542570456896 run_lib.py:133] step: 1191650, training_loss: 2.37451e-02
I0213 09:23:31.110632 22542570456896 run_lib.py:133] step: 1191700, training_loss: 2.74238e-02
I0213 09:23:31.268229 22542570456896 run_lib.py:146] step: 1191700, eval_loss: 3.07923e-02
I0213 09:23:48.698464 22542570456896 run_lib.py:133] step: 1191750, training_loss: 3.36111e-02
I0213 09:24:06.005745 22542570456896 run_lib.py:133] step: 1191800, training_loss: 2.09227e-02
I0213 09:24:06.160475 22542570456896 run_lib.py:146] step: 1191800, eval_loss: 3.17477e-02
I0213 09:24:23.533678 22542570456896 run_lib.py:133] step: 1191850, training_loss: 2.42807e-02
I0213 09:24:40.761544 22542570456896 run_lib.py:133] step: 1191900, training_loss: 2.35049e-02
I0213 09:24:40.912235 22542570456896 run_lib.py:146] step: 1191900, eval_loss: 3.45985e-02
I0213 09:24:58.166030 22542570456896 run_lib.py:133] step: 1191950, training_loss: 2.56441e-02
I0213 09:25:15.375251 22542570456896 run_lib.py:133] step: 1192000, training_loss: 2.31325e-02
I0213 09:25:15.535495 22542570456896 run_lib.py:146] step: 1192000, eval_loss: 2.53760e-02
I0213 09:25:32.949565 22542570456896 run_lib.py:133] step: 1192050, training_loss: 2.35301e-02
I0213 09:25:50.313465 22542570456896 run_lib.py:133] step: 1192100, training_loss: 2.51551e-02
I0213 09:25:50.469316 22542570456896 run_lib.py:146] step: 1192100, eval_loss: 3.18882e-02
I0213 09:26:07.735251 22542570456896 run_lib.py:133] step: 1192150, training_loss: 2.67365e-02
I0213 09:26:24.992820 22542570456896 run_lib.py:133] step: 1192200, training_loss: 2.43960e-02
I0213 09:26:25.146017 22542570456896 run_lib.py:146] step: 1192200, eval_loss: 3.31068e-02
I0213 09:26:42.499373 22542570456896 run_lib.py:133] step: 1192250, training_loss: 2.92018e-02
I0213 09:26:59.724000 22542570456896 run_lib.py:133] step: 1192300, training_loss: 2.60347e-02
I0213 09:26:59.876793 22542570456896 run_lib.py:146] step: 1192300, eval_loss: 3.10386e-02
I0213 09:27:17.300775 22542570456896 run_lib.py:133] step: 1192350, training_loss: 2.90763e-02
I0213 09:27:34.536612 22542570456896 run_lib.py:133] step: 1192400, training_loss: 3.03371e-02
I0213 09:27:34.688508 22542570456896 run_lib.py:146] step: 1192400, eval_loss: 3.30252e-02
I0213 09:27:52.142607 22542570456896 run_lib.py:133] step: 1192450, training_loss: 2.23572e-02
I0213 09:28:09.426218 22542570456896 run_lib.py:133] step: 1192500, training_loss: 2.15413e-02
I0213 09:28:09.583369 22542570456896 run_lib.py:146] step: 1192500, eval_loss: 2.82895e-02
I0213 09:28:26.981999 22542570456896 run_lib.py:133] step: 1192550, training_loss: 2.59824e-02
I0213 09:28:44.265958 22542570456896 run_lib.py:133] step: 1192600, training_loss: 1.98125e-02
I0213 09:28:44.432913 22542570456896 run_lib.py:146] step: 1192600, eval_loss: 3.62547e-02
I0213 09:29:01.728499 22542570456896 run_lib.py:133] step: 1192650, training_loss: 2.62910e-02
I0213 09:29:19.172929 22542570456896 run_lib.py:133] step: 1192700, training_loss: 2.70621e-02
I0213 09:29:19.335858 22542570456896 run_lib.py:146] step: 1192700, eval_loss: 2.77277e-02
I0213 09:29:36.633491 22542570456896 run_lib.py:133] step: 1192750, training_loss: 2.13582e-02
I0213 09:29:53.863574 22542570456896 run_lib.py:133] step: 1192800, training_loss: 2.31222e-02
I0213 09:29:54.012372 22542570456896 run_lib.py:146] step: 1192800, eval_loss: 2.87217e-02
I0213 09:30:11.402473 22542570456896 run_lib.py:133] step: 1192850, training_loss: 2.32088e-02
I0213 09:30:28.820892 22542570456896 run_lib.py:133] step: 1192900, training_loss: 3.05008e-02
I0213 09:30:28.972325 22542570456896 run_lib.py:146] step: 1192900, eval_loss: 3.04350e-02
I0213 09:30:46.295900 22542570456896 run_lib.py:133] step: 1192950, training_loss: 2.05533e-02
I0213 09:31:03.578118 22542570456896 run_lib.py:133] step: 1193000, training_loss: 2.45144e-02
I0213 09:31:03.735206 22542570456896 run_lib.py:146] step: 1193000, eval_loss: 2.67241e-02
I0213 09:31:20.984633 22542570456896 run_lib.py:133] step: 1193050, training_loss: 2.35423e-02
I0213 09:31:38.404481 22542570456896 run_lib.py:133] step: 1193100, training_loss: 3.09102e-02
I0213 09:31:38.558265 22542570456896 run_lib.py:146] step: 1193100, eval_loss: 3.09653e-02
I0213 09:31:55.801186 22542570456896 run_lib.py:133] step: 1193150, training_loss: 2.97693e-02
I0213 09:32:13.028368 22542570456896 run_lib.py:133] step: 1193200, training_loss: 2.99151e-02
I0213 09:32:13.187983 22542570456896 run_lib.py:146] step: 1193200, eval_loss: 3.14340e-02
I0213 09:32:30.457675 22542570456896 run_lib.py:133] step: 1193250, training_loss: 2.12725e-02
I0213 09:32:47.903091 22542570456896 run_lib.py:133] step: 1193300, training_loss: 2.15568e-02
I0213 09:32:48.054625 22542570456896 run_lib.py:146] step: 1193300, eval_loss: 3.15630e-02
I0213 09:33:05.342063 22542570456896 run_lib.py:133] step: 1193350, training_loss: 3.63788e-02
I0213 09:33:22.641376 22542570456896 run_lib.py:133] step: 1193400, training_loss: 2.64196e-02
I0213 09:33:22.795297 22542570456896 run_lib.py:146] step: 1193400, eval_loss: 2.92484e-02
I0213 09:33:40.043600 22542570456896 run_lib.py:133] step: 1193450, training_loss: 2.87305e-02
I0213 09:33:57.256399 22542570456896 run_lib.py:133] step: 1193500, training_loss: 2.26797e-02
I0213 09:33:57.427297 22542570456896 run_lib.py:146] step: 1193500, eval_loss: 2.73934e-02
I0213 09:34:14.855765 22542570456896 run_lib.py:133] step: 1193550, training_loss: 3.25801e-02
I0213 09:34:32.178536 22542570456896 run_lib.py:133] step: 1193600, training_loss: 2.59260e-02
I0213 09:34:32.329436 22542570456896 run_lib.py:146] step: 1193600, eval_loss: 3.02541e-02
I0213 09:34:49.564912 22542570456896 run_lib.py:133] step: 1193650, training_loss: 2.59370e-02
I0213 09:35:06.802681 22542570456896 run_lib.py:133] step: 1193700, training_loss: 3.43706e-02
I0213 09:35:06.960226 22542570456896 run_lib.py:146] step: 1193700, eval_loss: 3.37914e-02
I0213 09:35:24.373640 22542570456896 run_lib.py:133] step: 1193750, training_loss: 2.61302e-02
I0213 09:35:41.636727 22542570456896 run_lib.py:133] step: 1193800, training_loss: 3.04129e-02
I0213 09:35:41.794559 22542570456896 run_lib.py:146] step: 1193800, eval_loss: 3.62982e-02
I0213 09:35:59.281662 22542570456896 run_lib.py:133] step: 1193850, training_loss: 2.19526e-02
I0213 09:36:16.537569 22542570456896 run_lib.py:133] step: 1193900, training_loss: 2.34635e-02
I0213 09:36:16.694058 22542570456896 run_lib.py:146] step: 1193900, eval_loss: 3.07541e-02
I0213 09:36:34.123510 22542570456896 run_lib.py:133] step: 1193950, training_loss: 3.46061e-02
I0213 09:36:51.356738 22542570456896 run_lib.py:133] step: 1194000, training_loss: 2.37704e-02
I0213 09:36:51.512525 22542570456896 run_lib.py:146] step: 1194000, eval_loss: 2.84999e-02
I0213 09:37:08.768594 22542570456896 run_lib.py:133] step: 1194050, training_loss: 2.54666e-02
I0213 09:37:26.188211 22542570456896 run_lib.py:133] step: 1194100, training_loss: 3.11917e-02
I0213 09:37:26.347332 22542570456896 run_lib.py:146] step: 1194100, eval_loss: 3.07592e-02
I0213 09:37:43.623633 22542570456896 run_lib.py:133] step: 1194150, training_loss: 2.75910e-02
I0213 09:38:01.051599 22542570456896 run_lib.py:133] step: 1194200, training_loss: 2.04892e-02
I0213 09:38:01.204458 22542570456896 run_lib.py:146] step: 1194200, eval_loss: 3.51792e-02
I0213 09:38:18.486439 22542570456896 run_lib.py:133] step: 1194250, training_loss: 2.44920e-02
I0213 09:38:35.779816 22542570456896 run_lib.py:133] step: 1194300, training_loss: 2.44822e-02
I0213 09:38:35.930248 22542570456896 run_lib.py:146] step: 1194300, eval_loss: 2.46515e-02
I0213 09:38:53.329860 22542570456896 run_lib.py:133] step: 1194350, training_loss: 3.53229e-02
I0213 09:39:10.599133 22542570456896 run_lib.py:133] step: 1194400, training_loss: 2.24839e-02
I0213 09:39:10.772289 22542570456896 run_lib.py:146] step: 1194400, eval_loss: 3.03209e-02
I0213 09:39:28.055612 22542570456896 run_lib.py:133] step: 1194450, training_loss: 2.52713e-02
I0213 09:39:45.500608 22542570456896 run_lib.py:133] step: 1194500, training_loss: 2.58036e-02
I0213 09:39:45.654482 22542570456896 run_lib.py:146] step: 1194500, eval_loss: 3.17095e-02
I0213 09:40:02.925102 22542570456896 run_lib.py:133] step: 1194550, training_loss: 2.25805e-02
I0213 09:40:20.189535 22542570456896 run_lib.py:133] step: 1194600, training_loss: 2.93841e-02
I0213 09:40:20.342961 22542570456896 run_lib.py:146] step: 1194600, eval_loss: 2.82964e-02
I0213 09:40:37.638921 22542570456896 run_lib.py:133] step: 1194650, training_loss: 2.33238e-02
I0213 09:40:54.917334 22542570456896 run_lib.py:133] step: 1194700, training_loss: 2.45305e-02
I0213 09:40:55.068087 22542570456896 run_lib.py:146] step: 1194700, eval_loss: 3.29402e-02
I0213 09:41:12.363351 22542570456896 run_lib.py:133] step: 1194750, training_loss: 2.60137e-02
I0213 09:41:29.598368 22542570456896 run_lib.py:133] step: 1194800, training_loss: 2.50289e-02
I0213 09:41:29.754284 22542570456896 run_lib.py:146] step: 1194800, eval_loss: 3.23061e-02
I0213 09:41:47.158387 22542570456896 run_lib.py:133] step: 1194850, training_loss: 2.38183e-02
I0213 09:42:04.482929 22542570456896 run_lib.py:133] step: 1194900, training_loss: 2.72407e-02
I0213 09:42:04.637495 22542570456896 run_lib.py:146] step: 1194900, eval_loss: 3.48798e-02
I0213 09:42:21.910089 22542570456896 run_lib.py:133] step: 1194950, training_loss: 3.01394e-02
I0213 09:42:39.197888 22542570456896 run_lib.py:133] step: 1195000, training_loss: 3.32141e-02
I0213 09:42:39.353766 22542570456896 run_lib.py:146] step: 1195000, eval_loss: 3.21234e-02
I0213 09:42:56.788272 22542570456896 run_lib.py:133] step: 1195050, training_loss: 3.01142e-02
I0213 09:43:14.051129 22542570456896 run_lib.py:133] step: 1195100, training_loss: 2.68460e-02
I0213 09:43:14.212126 22542570456896 run_lib.py:146] step: 1195100, eval_loss: 2.79555e-02
I0213 09:43:31.612514 22542570456896 run_lib.py:133] step: 1195150, training_loss: 2.62138e-02
I0213 09:43:48.869472 22542570456896 run_lib.py:133] step: 1195200, training_loss: 3.82760e-02
I0213 09:43:49.018364 22542570456896 run_lib.py:146] step: 1195200, eval_loss: 2.77022e-02
I0213 09:44:06.405570 22542570456896 run_lib.py:133] step: 1195250, training_loss: 2.61581e-02
I0213 09:44:23.688241 22542570456896 run_lib.py:133] step: 1195300, training_loss: 2.42516e-02
I0213 09:44:23.859290 22542570456896 run_lib.py:146] step: 1195300, eval_loss: 3.04026e-02
I0213 09:44:41.330076 22542570456896 run_lib.py:133] step: 1195350, training_loss: 3.35850e-02
I0213 09:44:58.585224 22542570456896 run_lib.py:133] step: 1195400, training_loss: 2.95514e-02
I0213 09:44:58.749276 22542570456896 run_lib.py:146] step: 1195400, eval_loss: 3.11039e-02
I0213 09:45:15.982092 22542570456896 run_lib.py:133] step: 1195450, training_loss: 2.65151e-02
I0213 09:45:33.367826 22542570456896 run_lib.py:133] step: 1195500, training_loss: 3.13589e-02
I0213 09:45:33.521220 22542570456896 run_lib.py:146] step: 1195500, eval_loss: 2.50831e-02
I0213 09:45:50.801284 22542570456896 run_lib.py:133] step: 1195550, training_loss: 2.59523e-02
I0213 09:46:08.112770 22542570456896 run_lib.py:133] step: 1195600, training_loss: 2.85500e-02
I0213 09:46:08.263520 22542570456896 run_lib.py:146] step: 1195600, eval_loss: 3.08515e-02
I0213 09:46:25.696287 22542570456896 run_lib.py:133] step: 1195650, training_loss: 2.33900e-02
I0213 09:46:42.938365 22542570456896 run_lib.py:133] step: 1195700, training_loss: 2.77321e-02
I0213 09:46:43.088345 22542570456896 run_lib.py:146] step: 1195700, eval_loss: 3.10725e-02
I0213 09:47:00.478070 22542570456896 run_lib.py:133] step: 1195750, training_loss: 2.52544e-02
I0213 09:47:17.725775 22542570456896 run_lib.py:133] step: 1195800, training_loss: 2.35313e-02
I0213 09:47:17.880290 22542570456896 run_lib.py:146] step: 1195800, eval_loss: 2.58292e-02
I0213 09:47:35.112136 22542570456896 run_lib.py:133] step: 1195850, training_loss: 2.57379e-02
I0213 09:47:52.534484 22542570456896 run_lib.py:133] step: 1195900, training_loss: 2.65886e-02
I0213 09:47:52.692232 22542570456896 run_lib.py:146] step: 1195900, eval_loss: 3.16177e-02
I0213 09:48:09.919144 22542570456896 run_lib.py:133] step: 1195950, training_loss: 2.19272e-02
I0213 09:48:27.155970 22542570456896 run_lib.py:133] step: 1196000, training_loss: 3.19822e-02
I0213 09:48:27.310231 22542570456896 run_lib.py:146] step: 1196000, eval_loss: 3.26821e-02
I0213 09:48:44.579005 22542570456896 run_lib.py:133] step: 1196050, training_loss: 2.12663e-02
I0213 09:49:01.969180 22542570456896 run_lib.py:133] step: 1196100, training_loss: 3.38392e-02
I0213 09:49:02.121241 22542570456896 run_lib.py:146] step: 1196100, eval_loss: 3.34660e-02
I0213 09:49:19.335253 22542570456896 run_lib.py:133] step: 1196150, training_loss: 2.31793e-02
I0213 09:49:36.710416 22542570456896 run_lib.py:133] step: 1196200, training_loss: 2.49481e-02
I0213 09:49:36.867534 22542570456896 run_lib.py:146] step: 1196200, eval_loss: 3.49744e-02
I0213 09:49:54.156871 22542570456896 run_lib.py:133] step: 1196250, training_loss: 2.23154e-02
I0213 09:50:11.427489 22542570456896 run_lib.py:133] step: 1196300, training_loss: 3.04244e-02
I0213 09:50:11.585476 22542570456896 run_lib.py:146] step: 1196300, eval_loss: 2.78996e-02
I0213 09:50:28.973990 22542570456896 run_lib.py:133] step: 1196350, training_loss: 2.65404e-02
I0213 09:50:46.309670 22542570456896 run_lib.py:133] step: 1196400, training_loss: 2.30726e-02
I0213 09:50:46.467303 22542570456896 run_lib.py:146] step: 1196400, eval_loss: 3.60648e-02
I0213 09:51:03.766709 22542570456896 run_lib.py:133] step: 1196450, training_loss: 2.71135e-02
I0213 09:51:21.080020 22542570456896 run_lib.py:133] step: 1196500, training_loss: 2.76444e-02
I0213 09:51:21.234017 22542570456896 run_lib.py:146] step: 1196500, eval_loss: 3.07964e-02
I0213 09:51:38.643495 22542570456896 run_lib.py:133] step: 1196550, training_loss: 2.43478e-02
I0213 09:51:55.839578 22542570456896 run_lib.py:133] step: 1196600, training_loss: 2.96103e-02
I0213 09:51:55.987000 22542570456896 run_lib.py:146] step: 1196600, eval_loss: 2.84706e-02
I0213 09:52:13.364123 22542570456896 run_lib.py:133] step: 1196650, training_loss: 3.08018e-02
I0213 09:52:30.639636 22542570456896 run_lib.py:133] step: 1196700, training_loss: 3.53369e-02
I0213 09:52:30.805158 22542570456896 run_lib.py:146] step: 1196700, eval_loss: 2.34033e-02
I0213 09:52:48.275236 22542570456896 run_lib.py:133] step: 1196750, training_loss: 2.31605e-02
I0213 09:53:05.564987 22542570456896 run_lib.py:133] step: 1196800, training_loss: 2.13269e-02
I0213 09:53:05.721314 22542570456896 run_lib.py:146] step: 1196800, eval_loss: 2.91301e-02
I0213 09:53:22.980464 22542570456896 run_lib.py:133] step: 1196850, training_loss: 2.36153e-02
I0213 09:53:40.382202 22542570456896 run_lib.py:133] step: 1196900, training_loss: 2.54308e-02
I0213 09:53:40.538385 22542570456896 run_lib.py:146] step: 1196900, eval_loss: 2.86464e-02
I0213 09:53:57.831528 22542570456896 run_lib.py:133] step: 1196950, training_loss: 2.34906e-02
I0213 09:54:15.211161 22542570456896 run_lib.py:133] step: 1197000, training_loss: 2.45393e-02
I0213 09:54:15.365565 22542570456896 run_lib.py:146] step: 1197000, eval_loss: 3.37361e-02
I0213 09:54:32.688203 22542570456896 run_lib.py:133] step: 1197050, training_loss: 3.27532e-02
I0213 09:54:49.905223 22542570456896 run_lib.py:133] step: 1197100, training_loss: 2.24747e-02
I0213 09:54:50.054198 22542570456896 run_lib.py:146] step: 1197100, eval_loss: 2.62689e-02
I0213 09:55:07.460253 22542570456896 run_lib.py:133] step: 1197150, training_loss: 2.61535e-02
I0213 09:55:24.725608 22542570456896 run_lib.py:133] step: 1197200, training_loss: 2.44363e-02
I0213 09:55:24.879211 22542570456896 run_lib.py:146] step: 1197200, eval_loss: 2.72267e-02
I0213 09:55:42.100454 22542570456896 run_lib.py:133] step: 1197250, training_loss: 2.52407e-02
I0213 09:55:59.487620 22542570456896 run_lib.py:133] step: 1197300, training_loss: 2.12557e-02
I0213 09:55:59.662241 22542570456896 run_lib.py:146] step: 1197300, eval_loss: 3.00789e-02
I0213 09:56:16.969975 22542570456896 run_lib.py:133] step: 1197350, training_loss: 2.54484e-02
I0213 09:56:34.248661 22542570456896 run_lib.py:133] step: 1197400, training_loss: 2.96632e-02
I0213 09:56:34.578493 22542570456896 run_lib.py:146] step: 1197400, eval_loss: 3.11331e-02
I0213 09:56:51.859685 22542570456896 run_lib.py:133] step: 1197450, training_loss: 3.02468e-02
I0213 09:57:09.080465 22542570456896 run_lib.py:133] step: 1197500, training_loss: 3.42121e-02
I0213 09:57:09.233320 22542570456896 run_lib.py:146] step: 1197500, eval_loss: 2.98642e-02
I0213 09:57:26.484788 22542570456896 run_lib.py:133] step: 1197550, training_loss: 2.77020e-02
I0213 09:57:43.778684 22542570456896 run_lib.py:133] step: 1197600, training_loss: 2.47743e-02
I0213 09:57:43.932392 22542570456896 run_lib.py:146] step: 1197600, eval_loss: 2.85474e-02
I0213 09:58:01.353724 22542570456896 run_lib.py:133] step: 1197650, training_loss: 2.25626e-02
I0213 09:58:18.712757 22542570456896 run_lib.py:133] step: 1197700, training_loss: 2.86860e-02
I0213 09:58:18.868592 22542570456896 run_lib.py:146] step: 1197700, eval_loss: 3.80899e-02
I0213 09:58:36.096257 22542570456896 run_lib.py:133] step: 1197750, training_loss: 2.57254e-02
I0213 09:58:53.328809 22542570456896 run_lib.py:133] step: 1197800, training_loss: 2.67154e-02
I0213 09:58:53.482498 22542570456896 run_lib.py:146] step: 1197800, eval_loss: 3.15084e-02
I0213 09:59:10.887183 22542570456896 run_lib.py:133] step: 1197850, training_loss: 2.67987e-02
I0213 09:59:28.273616 22542570456896 run_lib.py:133] step: 1197900, training_loss: 2.57770e-02
I0213 09:59:28.428893 22542570456896 run_lib.py:146] step: 1197900, eval_loss: 3.17197e-02
I0213 09:59:45.715827 22542570456896 run_lib.py:133] step: 1197950, training_loss: 2.57738e-02
I0213 10:00:02.970288 22542570456896 run_lib.py:133] step: 1198000, training_loss: 2.75035e-02
I0213 10:00:03.121236 22542570456896 run_lib.py:146] step: 1198000, eval_loss: 3.13087e-02
I0213 10:00:20.529638 22542570456896 run_lib.py:133] step: 1198050, training_loss: 2.56810e-02
I0213 10:00:37.784426 22542570456896 run_lib.py:133] step: 1198100, training_loss: 2.35741e-02
I0213 10:00:37.936482 22542570456896 run_lib.py:146] step: 1198100, eval_loss: 2.97680e-02
I0213 10:00:55.368833 22542570456896 run_lib.py:133] step: 1198150, training_loss: 2.50166e-02
I0213 10:01:12.687457 22542570456896 run_lib.py:133] step: 1198200, training_loss: 2.50910e-02
I0213 10:01:12.844233 22542570456896 run_lib.py:146] step: 1198200, eval_loss: 2.91218e-02
I0213 10:01:30.235898 22542570456896 run_lib.py:133] step: 1198250, training_loss: 3.07170e-02
I0213 10:01:47.457364 22542570456896 run_lib.py:133] step: 1198300, training_loss: 3.08221e-02
I0213 10:01:47.614202 22542570456896 run_lib.py:146] step: 1198300, eval_loss: 3.45060e-02
I0213 10:02:04.852720 22542570456896 run_lib.py:133] step: 1198350, training_loss: 3.22463e-02
I0213 10:02:22.256058 22542570456896 run_lib.py:133] step: 1198400, training_loss: 2.97246e-02
I0213 10:02:22.424001 22542570456896 run_lib.py:146] step: 1198400, eval_loss: 3.08002e-02
I0213 10:02:39.697297 22542570456896 run_lib.py:133] step: 1198450, training_loss: 2.86284e-02
I0213 10:02:57.123005 22542570456896 run_lib.py:133] step: 1198500, training_loss: 3.16202e-02
I0213 10:02:57.272562 22542570456896 run_lib.py:146] step: 1198500, eval_loss: 3.22540e-02
I0213 10:03:14.525573 22542570456896 run_lib.py:133] step: 1198550, training_loss: 2.60510e-02
I0213 10:03:31.788897 22542570456896 run_lib.py:133] step: 1198600, training_loss: 2.69292e-02
I0213 10:03:31.941488 22542570456896 run_lib.py:146] step: 1198600, eval_loss: 2.74463e-02
I0213 10:03:49.303867 22542570456896 run_lib.py:133] step: 1198650, training_loss: 2.19756e-02
I0213 10:04:06.532077 22542570456896 run_lib.py:133] step: 1198700, training_loss: 3.92038e-02
I0213 10:04:06.699339 22542570456896 run_lib.py:146] step: 1198700, eval_loss: 3.16446e-02
I0213 10:04:23.992132 22542570456896 run_lib.py:133] step: 1198750, training_loss: 2.39020e-02
I0213 10:04:41.281481 22542570456896 run_lib.py:133] step: 1198800, training_loss: 2.94670e-02
I0213 10:04:41.439495 22542570456896 run_lib.py:146] step: 1198800, eval_loss: 2.63650e-02
I0213 10:04:58.843871 22542570456896 run_lib.py:133] step: 1198850, training_loss: 1.95797e-02
I0213 10:05:16.088199 22542570456896 run_lib.py:133] step: 1198900, training_loss: 2.41074e-02
I0213 10:05:16.244229 22542570456896 run_lib.py:146] step: 1198900, eval_loss: 3.03697e-02
I0213 10:05:33.558801 22542570456896 run_lib.py:133] step: 1198950, training_loss: 2.60571e-02
I0213 10:05:50.848911 22542570456896 run_lib.py:133] step: 1199000, training_loss: 2.41943e-02
I0213 10:05:51.003481 22542570456896 run_lib.py:146] step: 1199000, eval_loss: 3.49337e-02
I0213 10:06:08.349851 22542570456896 run_lib.py:133] step: 1199050, training_loss: 2.68093e-02
I0213 10:06:25.586219 22542570456896 run_lib.py:133] step: 1199100, training_loss: 2.67453e-02
I0213 10:06:25.740237 22542570456896 run_lib.py:146] step: 1199100, eval_loss: 3.27386e-02
I0213 10:06:43.163209 22542570456896 run_lib.py:133] step: 1199150, training_loss: 2.62789e-02
I0213 10:07:00.456180 22542570456896 run_lib.py:133] step: 1199200, training_loss: 2.50631e-02
I0213 10:07:00.612496 22542570456896 run_lib.py:146] step: 1199200, eval_loss: 2.85082e-02
I0213 10:07:17.917191 22542570456896 run_lib.py:133] step: 1199250, training_loss: 2.34656e-02
I0213 10:07:35.239449 22542570456896 run_lib.py:133] step: 1199300, training_loss: 2.91181e-02
I0213 10:07:35.394511 22542570456896 run_lib.py:146] step: 1199300, eval_loss: 3.56693e-02
I0213 10:07:52.822259 22542570456896 run_lib.py:133] step: 1199350, training_loss: 3.24820e-02
I0213 10:08:10.086723 22542570456896 run_lib.py:133] step: 1199400, training_loss: 2.58879e-02
I0213 10:08:10.239031 22542570456896 run_lib.py:146] step: 1199400, eval_loss: 3.11307e-02
I0213 10:08:27.643536 22542570456896 run_lib.py:133] step: 1199450, training_loss: 3.00452e-02
I0213 10:08:44.862524 22542570456896 run_lib.py:133] step: 1199500, training_loss: 2.05334e-02
I0213 10:08:45.015326 22542570456896 run_lib.py:146] step: 1199500, eval_loss: 3.13174e-02
I0213 10:09:02.417866 22542570456896 run_lib.py:133] step: 1199550, training_loss: 2.35060e-02
I0213 10:09:19.762048 22542570456896 run_lib.py:133] step: 1199600, training_loss: 2.42201e-02
I0213 10:09:19.925304 22542570456896 run_lib.py:146] step: 1199600, eval_loss: 3.33319e-02
I0213 10:09:37.351582 22542570456896 run_lib.py:133] step: 1199650, training_loss: 2.72702e-02
I0213 10:09:54.638949 22542570456896 run_lib.py:133] step: 1199700, training_loss: 2.29536e-02
I0213 10:09:54.796531 22542570456896 run_lib.py:146] step: 1199700, eval_loss: 3.67346e-02
I0213 10:10:12.066604 22542570456896 run_lib.py:133] step: 1199750, training_loss: 2.25595e-02
I0213 10:10:29.469723 22542570456896 run_lib.py:133] step: 1199800, training_loss: 3.15253e-02
I0213 10:10:29.623078 22542570456896 run_lib.py:146] step: 1199800, eval_loss: 3.09886e-02
I0213 10:10:46.888225 22542570456896 run_lib.py:133] step: 1199850, training_loss: 2.73307e-02
I0213 10:11:04.192669 22542570456896 run_lib.py:133] step: 1199900, training_loss: 2.31327e-02
I0213 10:11:04.344000 22542570456896 run_lib.py:146] step: 1199900, eval_loss: 3.25050e-02
I0213 10:11:21.832808 22542570456896 run_lib.py:133] step: 1199950, training_loss: 3.20747e-02
I0213 10:11:39.267098 22542570456896 run_lib.py:133] step: 1200000, training_loss: 2.50187e-02
I0213 10:11:39.943694 22542570456896 run_lib.py:146] step: 1200000, eval_loss: 3.21563e-02
I0213 10:11:59.774505 22542570456896 run_lib.py:133] step: 1200050, training_loss: 2.63430e-02
I0213 10:12:17.052525 22542570456896 run_lib.py:133] step: 1200100, training_loss: 2.72139e-02
I0213 10:12:17.226455 22542570456896 run_lib.py:146] step: 1200100, eval_loss: 2.78709e-02
I0213 10:12:34.565869 22542570456896 run_lib.py:133] step: 1200150, training_loss: 2.72425e-02
I0213 10:12:51.821396 22542570456896 run_lib.py:133] step: 1200200, training_loss: 2.97375e-02
I0213 10:12:51.977312 22542570456896 run_lib.py:146] step: 1200200, eval_loss: 3.00049e-02
I0213 10:13:09.385983 22542570456896 run_lib.py:133] step: 1200250, training_loss: 2.89922e-02
I0213 10:13:26.687272 22542570456896 run_lib.py:133] step: 1200300, training_loss: 2.31150e-02
I0213 10:13:26.841211 22542570456896 run_lib.py:146] step: 1200300, eval_loss: 2.52710e-02
I0213 10:13:44.076238 22542570456896 run_lib.py:133] step: 1200350, training_loss: 2.85328e-02
I0213 10:14:01.359530 22542570456896 run_lib.py:133] step: 1200400, training_loss: 3.01801e-02
I0213 10:14:01.509933 22542570456896 run_lib.py:146] step: 1200400, eval_loss: 3.21252e-02
I0213 10:14:18.961543 22542570456896 run_lib.py:133] step: 1200450, training_loss: 2.34246e-02
I0213 10:14:36.176390 22542570456896 run_lib.py:133] step: 1200500, training_loss: 2.66071e-02
I0213 10:14:36.333885 22542570456896 run_lib.py:146] step: 1200500, eval_loss: 2.45087e-02
I0213 10:14:53.716938 22542570456896 run_lib.py:133] step: 1200550, training_loss: 3.25200e-02
I0213 10:15:11.014635 22542570456896 run_lib.py:133] step: 1200600, training_loss: 2.27681e-02
I0213 10:15:11.168298 22542570456896 run_lib.py:146] step: 1200600, eval_loss: 2.96692e-02
I0213 10:15:28.513169 22542570456896 run_lib.py:133] step: 1200650, training_loss: 3.06465e-02
I0213 10:15:45.806143 22542570456896 run_lib.py:133] step: 1200700, training_loss: 2.41103e-02
I0213 10:15:45.981281 22542570456896 run_lib.py:146] step: 1200700, eval_loss: 2.80186e-02
I0213 10:16:03.289619 22542570456896 run_lib.py:133] step: 1200750, training_loss: 2.62222e-02
I0213 10:16:20.723848 22542570456896 run_lib.py:133] step: 1200800, training_loss: 2.62677e-02
I0213 10:16:20.881533 22542570456896 run_lib.py:146] step: 1200800, eval_loss: 3.42838e-02
I0213 10:16:38.110062 22542570456896 run_lib.py:133] step: 1200850, training_loss: 2.68882e-02
I0213 10:16:55.455051 22542570456896 run_lib.py:133] step: 1200900, training_loss: 3.11552e-02
I0213 10:16:55.606950 22542570456896 run_lib.py:146] step: 1200900, eval_loss: 3.49239e-02
I0213 10:17:12.863500 22542570456896 run_lib.py:133] step: 1200950, training_loss: 2.78989e-02
I0213 10:17:30.171114 22542570456896 run_lib.py:133] step: 1201000, training_loss: 2.67874e-02
I0213 10:17:30.323544 22542570456896 run_lib.py:146] step: 1201000, eval_loss: 2.93482e-02
I0213 10:17:47.804648 22542570456896 run_lib.py:133] step: 1201050, training_loss: 3.76595e-02
I0213 10:18:05.076746 22542570456896 run_lib.py:133] step: 1201100, training_loss: 2.64476e-02
I0213 10:18:05.237668 22542570456896 run_lib.py:146] step: 1201100, eval_loss: 2.84895e-02
I0213 10:18:22.485439 22542570456896 run_lib.py:133] step: 1201150, training_loss: 2.46663e-02
I0213 10:18:39.907517 22542570456896 run_lib.py:133] step: 1201200, training_loss: 2.74594e-02
I0213 10:18:40.061494 22542570456896 run_lib.py:146] step: 1201200, eval_loss: 3.25402e-02
I0213 10:18:57.300956 22542570456896 run_lib.py:133] step: 1201250, training_loss: 2.95098e-02
I0213 10:19:14.612920 22542570456896 run_lib.py:133] step: 1201300, training_loss: 2.55836e-02
I0213 10:19:14.772993 22542570456896 run_lib.py:146] step: 1201300, eval_loss: 2.56465e-02
I0213 10:19:32.203420 22542570456896 run_lib.py:133] step: 1201350, training_loss: 2.86725e-02
I0213 10:19:49.459966 22542570456896 run_lib.py:133] step: 1201400, training_loss: 2.54536e-02
I0213 10:19:49.611066 22542570456896 run_lib.py:146] step: 1201400, eval_loss: 3.41393e-02
I0213 10:20:06.862647 22542570456896 run_lib.py:133] step: 1201450, training_loss: 3.13854e-02
I0213 10:20:24.142442 22542570456896 run_lib.py:133] step: 1201500, training_loss: 2.26227e-02
I0213 10:20:24.301270 22542570456896 run_lib.py:146] step: 1201500, eval_loss: 2.40055e-02
I0213 10:20:41.695488 22542570456896 run_lib.py:133] step: 1201550, training_loss: 2.90734e-02
I0213 10:20:59.087451 22542570456896 run_lib.py:133] step: 1201600, training_loss: 2.48051e-02
I0213 10:20:59.260301 22542570456896 run_lib.py:146] step: 1201600, eval_loss: 2.70191e-02
I0213 10:21:16.542596 22542570456896 run_lib.py:133] step: 1201650, training_loss: 3.14056e-02
I0213 10:21:33.854512 22542570456896 run_lib.py:133] step: 1201700, training_loss: 3.47439e-02
I0213 10:21:34.008308 22542570456896 run_lib.py:146] step: 1201700, eval_loss: 3.91309e-02
I0213 10:21:51.430334 22542570456896 run_lib.py:133] step: 1201750, training_loss: 3.27495e-02
I0213 10:22:08.680006 22542570456896 run_lib.py:133] step: 1201800, training_loss: 2.67095e-02
I0213 10:22:08.849373 22542570456896 run_lib.py:146] step: 1201800, eval_loss: 2.97646e-02
I0213 10:22:26.294723 22542570456896 run_lib.py:133] step: 1201850, training_loss: 2.61020e-02
I0213 10:22:43.594882 22542570456896 run_lib.py:133] step: 1201900, training_loss: 2.35377e-02
I0213 10:22:43.749540 22542570456896 run_lib.py:146] step: 1201900, eval_loss: 3.31588e-02
I0213 10:23:01.225754 22542570456896 run_lib.py:133] step: 1201950, training_loss: 1.94238e-02
I0213 10:23:18.505162 22542570456896 run_lib.py:133] step: 1202000, training_loss: 2.82920e-02
I0213 10:23:18.663288 22542570456896 run_lib.py:146] step: 1202000, eval_loss: 3.31779e-02
I0213 10:23:36.025235 22542570456896 run_lib.py:133] step: 1202050, training_loss: 2.90960e-02
I0213 10:23:53.370941 22542570456896 run_lib.py:133] step: 1202100, training_loss: 3.30943e-02
I0213 10:23:53.545238 22542570456896 run_lib.py:146] step: 1202100, eval_loss: 2.79385e-02
I0213 10:24:10.868716 22542570456896 run_lib.py:133] step: 1202150, training_loss: 2.63627e-02
I0213 10:24:28.306256 22542570456896 run_lib.py:133] step: 1202200, training_loss: 1.71149e-02
I0213 10:24:28.467802 22542570456896 run_lib.py:146] step: 1202200, eval_loss: 3.22760e-02
I0213 10:24:45.743344 22542570456896 run_lib.py:133] step: 1202250, training_loss: 2.59552e-02
I0213 10:25:03.000425 22542570456896 run_lib.py:133] step: 1202300, training_loss: 3.24578e-02
I0213 10:25:03.155262 22542570456896 run_lib.py:146] step: 1202300, eval_loss: 3.33755e-02
I0213 10:25:20.539868 22542570456896 run_lib.py:133] step: 1202350, training_loss: 2.70147e-02
I0213 10:25:37.818528 22542570456896 run_lib.py:133] step: 1202400, training_loss: 2.52779e-02
I0213 10:25:37.975475 22542570456896 run_lib.py:146] step: 1202400, eval_loss: 2.79513e-02
I0213 10:25:55.414523 22542570456896 run_lib.py:133] step: 1202450, training_loss: 2.55992e-02
I0213 10:26:12.693361 22542570456896 run_lib.py:133] step: 1202500, training_loss: 2.09224e-02
I0213 10:26:12.844386 22542570456896 run_lib.py:146] step: 1202500, eval_loss: 2.89246e-02
I0213 10:26:30.100318 22542570456896 run_lib.py:133] step: 1202550, training_loss: 2.71631e-02
I0213 10:26:47.556455 22542570456896 run_lib.py:133] step: 1202600, training_loss: 2.72825e-02
I0213 10:26:47.713447 22542570456896 run_lib.py:146] step: 1202600, eval_loss: 2.95013e-02
I0213 10:27:04.979341 22542570456896 run_lib.py:133] step: 1202650, training_loss: 2.38873e-02
I0213 10:27:22.328798 22542570456896 run_lib.py:133] step: 1202700, training_loss: 2.57001e-02
I0213 10:27:22.486487 22542570456896 run_lib.py:146] step: 1202700, eval_loss: 2.48982e-02
I0213 10:27:39.736001 22542570456896 run_lib.py:133] step: 1202750, training_loss: 2.47273e-02
I0213 10:27:57.155012 22542570456896 run_lib.py:133] step: 1202800, training_loss: 2.79316e-02
I0213 10:27:57.310208 22542570456896 run_lib.py:146] step: 1202800, eval_loss: 3.28023e-02
I0213 10:28:14.570667 22542570456896 run_lib.py:133] step: 1202850, training_loss: 2.92467e-02
I0213 10:28:31.897174 22542570456896 run_lib.py:133] step: 1202900, training_loss: 3.32423e-02
I0213 10:28:32.051557 22542570456896 run_lib.py:146] step: 1202900, eval_loss: 2.83410e-02
I0213 10:28:49.369679 22542570456896 run_lib.py:133] step: 1202950, training_loss: 2.54344e-02
I0213 10:29:06.628865 22542570456896 run_lib.py:133] step: 1203000, training_loss: 3.93985e-02
I0213 10:29:06.784346 22542570456896 run_lib.py:146] step: 1203000, eval_loss: 3.16716e-02
I0213 10:29:24.176519 22542570456896 run_lib.py:133] step: 1203050, training_loss: 3.21844e-02
I0213 10:29:41.471525 22542570456896 run_lib.py:133] step: 1203100, training_loss: 2.68927e-02
I0213 10:29:41.625855 22542570456896 run_lib.py:146] step: 1203100, eval_loss: 3.90620e-02
I0213 10:29:58.883491 22542570456896 run_lib.py:133] step: 1203150, training_loss: 2.99555e-02
I0213 10:30:16.138101 22542570456896 run_lib.py:133] step: 1203200, training_loss: 2.45469e-02
I0213 10:30:16.294517 22542570456896 run_lib.py:146] step: 1203200, eval_loss: 3.37053e-02
I0213 10:30:33.759096 22542570456896 run_lib.py:133] step: 1203250, training_loss: 2.72788e-02
I0213 10:30:51.066277 22542570456896 run_lib.py:133] step: 1203300, training_loss: 2.41579e-02
I0213 10:30:51.216987 22542570456896 run_lib.py:146] step: 1203300, eval_loss: 2.88671e-02
I0213 10:31:08.638446 22542570456896 run_lib.py:133] step: 1203350, training_loss: 2.61210e-02
I0213 10:31:25.887697 22542570456896 run_lib.py:133] step: 1203400, training_loss: 2.32542e-02
I0213 10:31:26.047318 22542570456896 run_lib.py:146] step: 1203400, eval_loss: 2.72138e-02
I0213 10:31:43.478073 22542570456896 run_lib.py:133] step: 1203450, training_loss: 2.46798e-02
I0213 10:32:00.761298 22542570456896 run_lib.py:133] step: 1203500, training_loss: 2.76198e-02
I0213 10:32:00.920238 22542570456896 run_lib.py:146] step: 1203500, eval_loss: 2.16803e-02
I0213 10:32:18.156087 22542570456896 run_lib.py:133] step: 1203550, training_loss: 2.09344e-02
I0213 10:32:35.574188 22542570456896 run_lib.py:133] step: 1203600, training_loss: 2.52209e-02
I0213 10:32:35.734431 22542570456896 run_lib.py:146] step: 1203600, eval_loss: 2.82879e-02
I0213 10:32:53.033428 22542570456896 run_lib.py:133] step: 1203650, training_loss: 1.64954e-02
I0213 10:33:10.409062 22542570456896 run_lib.py:133] step: 1203700, training_loss: 2.67232e-02
I0213 10:33:10.566462 22542570456896 run_lib.py:146] step: 1203700, eval_loss: 2.91231e-02
I0213 10:33:27.817916 22542570456896 run_lib.py:133] step: 1203750, training_loss: 2.09662e-02
I0213 10:33:45.117036 22542570456896 run_lib.py:133] step: 1203800, training_loss: 2.07939e-02
I0213 10:33:45.267990 22542570456896 run_lib.py:146] step: 1203800, eval_loss: 2.99265e-02
I0213 10:34:02.753272 22542570456896 run_lib.py:133] step: 1203850, training_loss: 2.90856e-02
I0213 10:34:20.042110 22542570456896 run_lib.py:133] step: 1203900, training_loss: 2.37346e-02
I0213 10:34:20.199235 22542570456896 run_lib.py:146] step: 1203900, eval_loss: 2.63449e-02
I0213 10:34:37.467151 22542570456896 run_lib.py:133] step: 1203950, training_loss: 2.35902e-02
I0213 10:34:54.844607 22542570456896 run_lib.py:133] step: 1204000, training_loss: 1.95395e-02
I0213 10:34:55.006192 22542570456896 run_lib.py:146] step: 1204000, eval_loss: 3.71461e-02
I0213 10:35:12.285461 22542570456896 run_lib.py:133] step: 1204050, training_loss: 2.19807e-02
I0213 10:35:29.581801 22542570456896 run_lib.py:133] step: 1204100, training_loss: 2.55289e-02
I0213 10:35:29.915785 22542570456896 run_lib.py:146] step: 1204100, eval_loss: 3.69502e-02
I0213 10:35:47.131154 22542570456896 run_lib.py:133] step: 1204150, training_loss: 1.88478e-02
I0213 10:36:04.365217 22542570456896 run_lib.py:133] step: 1204200, training_loss: 3.12489e-02
I0213 10:36:04.518255 22542570456896 run_lib.py:146] step: 1204200, eval_loss: 3.21938e-02
I0213 10:36:21.747311 22542570456896 run_lib.py:133] step: 1204250, training_loss: 3.24866e-02
I0213 10:36:39.033072 22542570456896 run_lib.py:133] step: 1204300, training_loss: 2.36367e-02
I0213 10:36:39.185415 22542570456896 run_lib.py:146] step: 1204300, eval_loss: 3.30219e-02
I0213 10:36:56.663159 22542570456896 run_lib.py:133] step: 1204350, training_loss: 2.64798e-02
I0213 10:37:14.023415 22542570456896 run_lib.py:133] step: 1204400, training_loss: 3.11012e-02
I0213 10:37:14.181318 22542570456896 run_lib.py:146] step: 1204400, eval_loss: 2.23390e-02
I0213 10:37:31.445791 22542570456896 run_lib.py:133] step: 1204450, training_loss: 2.33035e-02
I0213 10:37:48.686948 22542570456896 run_lib.py:133] step: 1204500, training_loss: 3.03917e-02
I0213 10:37:48.844566 22542570456896 run_lib.py:146] step: 1204500, eval_loss: 3.00037e-02
I0213 10:38:06.217921 22542570456896 run_lib.py:133] step: 1204550, training_loss: 2.81450e-02
I0213 10:38:23.510851 22542570456896 run_lib.py:133] step: 1204600, training_loss: 2.08048e-02
I0213 10:38:23.668001 22542570456896 run_lib.py:146] step: 1204600, eval_loss: 3.12808e-02
I0213 10:38:40.978751 22542570456896 run_lib.py:133] step: 1204650, training_loss: 2.58143e-02
I0213 10:38:58.265938 22542570456896 run_lib.py:133] step: 1204700, training_loss: 2.60876e-02
I0213 10:38:58.418049 22542570456896 run_lib.py:146] step: 1204700, eval_loss: 2.58881e-02
I0213 10:39:15.846455 22542570456896 run_lib.py:133] step: 1204750, training_loss: 3.21238e-02
I0213 10:39:33.084023 22542570456896 run_lib.py:133] step: 1204800, training_loss: 2.52880e-02
I0213 10:39:33.239254 22542570456896 run_lib.py:146] step: 1204800, eval_loss: 2.68151e-02
I0213 10:39:50.608875 22542570456896 run_lib.py:133] step: 1204850, training_loss: 2.42832e-02
I0213 10:40:07.925295 22542570456896 run_lib.py:133] step: 1204900, training_loss: 2.03427e-02
I0213 10:40:08.097369 22542570456896 run_lib.py:146] step: 1204900, eval_loss: 2.94020e-02
I0213 10:40:25.570314 22542570456896 run_lib.py:133] step: 1204950, training_loss: 2.35925e-02
I0213 10:40:42.827214 22542570456896 run_lib.py:133] step: 1205000, training_loss: 3.07052e-02
I0213 10:40:42.980401 22542570456896 run_lib.py:146] step: 1205000, eval_loss: 3.18006e-02
I0213 10:41:00.287429 22542570456896 run_lib.py:133] step: 1205050, training_loss: 2.90341e-02
I0213 10:41:17.651440 22542570456896 run_lib.py:133] step: 1205100, training_loss: 3.08005e-02
I0213 10:41:17.806291 22542570456896 run_lib.py:146] step: 1205100, eval_loss: 3.53579e-02
I0213 10:41:35.078963 22542570456896 run_lib.py:133] step: 1205150, training_loss: 3.41768e-02
I0213 10:41:52.515642 22542570456896 run_lib.py:133] step: 1205200, training_loss: 2.69822e-02
I0213 10:41:52.666064 22542570456896 run_lib.py:146] step: 1205200, eval_loss: 2.50326e-02
I0213 10:42:10.017490 22542570456896 run_lib.py:133] step: 1205250, training_loss: 3.04462e-02
I0213 10:42:27.253739 22542570456896 run_lib.py:133] step: 1205300, training_loss: 2.57621e-02
I0213 10:42:27.414551 22542570456896 run_lib.py:146] step: 1205300, eval_loss: 3.09125e-02
I0213 10:42:44.833264 22542570456896 run_lib.py:133] step: 1205350, training_loss: 2.20454e-02
I0213 10:43:02.100267 22542570456896 run_lib.py:133] step: 1205400, training_loss: 2.63387e-02
I0213 10:43:02.257500 22542570456896 run_lib.py:146] step: 1205400, eval_loss: 3.07288e-02
I0213 10:43:19.531439 22542570456896 run_lib.py:133] step: 1205450, training_loss: 2.10729e-02
I0213 10:43:36.823523 22542570456896 run_lib.py:133] step: 1205500, training_loss: 3.03436e-02
I0213 10:43:36.985458 22542570456896 run_lib.py:146] step: 1205500, eval_loss: 3.33521e-02
I0213 10:43:54.417360 22542570456896 run_lib.py:133] step: 1205550, training_loss: 3.32965e-02
I0213 10:44:11.666437 22542570456896 run_lib.py:133] step: 1205600, training_loss: 2.71779e-02
I0213 10:44:11.820421 22542570456896 run_lib.py:146] step: 1205600, eval_loss: 3.48173e-02
I0213 10:44:29.157002 22542570456896 run_lib.py:133] step: 1205650, training_loss: 2.72753e-02
I0213 10:44:46.422348 22542570456896 run_lib.py:133] step: 1205700, training_loss: 2.72075e-02
I0213 10:44:46.578346 22542570456896 run_lib.py:146] step: 1205700, eval_loss: 2.83271e-02
I0213 10:45:03.856363 22542570456896 run_lib.py:133] step: 1205750, training_loss: 2.97389e-02
I0213 10:45:21.198586 22542570456896 run_lib.py:133] step: 1205800, training_loss: 3.09552e-02
I0213 10:45:21.366488 22542570456896 run_lib.py:146] step: 1205800, eval_loss: 2.99227e-02
I0213 10:45:38.828560 22542570456896 run_lib.py:133] step: 1205850, training_loss: 2.49303e-02
I0213 10:45:56.160000 22542570456896 run_lib.py:133] step: 1205900, training_loss: 2.31044e-02
I0213 10:45:56.315767 22542570456896 run_lib.py:146] step: 1205900, eval_loss: 2.92211e-02
I0213 10:46:13.571821 22542570456896 run_lib.py:133] step: 1205950, training_loss: 2.60511e-02
I0213 10:46:30.816325 22542570456896 run_lib.py:133] step: 1206000, training_loss: 2.40109e-02
I0213 10:46:30.982589 22542570456896 run_lib.py:146] step: 1206000, eval_loss: 2.91706e-02
I0213 10:46:48.417989 22542570456896 run_lib.py:133] step: 1206050, training_loss: 2.86821e-02
I0213 10:47:05.709318 22542570456896 run_lib.py:133] step: 1206100, training_loss: 2.28414e-02
I0213 10:47:05.870521 22542570456896 run_lib.py:146] step: 1206100, eval_loss: 2.73408e-02
I0213 10:47:23.316690 22542570456896 run_lib.py:133] step: 1206150, training_loss: 2.23910e-02
I0213 10:47:40.567211 22542570456896 run_lib.py:133] step: 1206200, training_loss: 2.62970e-02
I0213 10:47:40.716172 22542570456896 run_lib.py:146] step: 1206200, eval_loss: 3.25414e-02
I0213 10:47:58.080282 22542570456896 run_lib.py:133] step: 1206250, training_loss: 2.45383e-02
I0213 10:48:15.316531 22542570456896 run_lib.py:133] step: 1206300, training_loss: 2.81519e-02
I0213 10:48:15.482145 22542570456896 run_lib.py:146] step: 1206300, eval_loss: 3.00104e-02
I0213 10:48:33.009863 22542570456896 run_lib.py:133] step: 1206350, training_loss: 2.94558e-02
I0213 10:48:50.342069 22542570456896 run_lib.py:133] step: 1206400, training_loss: 2.90966e-02
I0213 10:48:50.499234 22542570456896 run_lib.py:146] step: 1206400, eval_loss: 2.69293e-02
I0213 10:49:07.739271 22542570456896 run_lib.py:133] step: 1206450, training_loss: 2.42213e-02
I0213 10:49:25.143404 22542570456896 run_lib.py:133] step: 1206500, training_loss: 2.20252e-02
I0213 10:49:25.296329 22542570456896 run_lib.py:146] step: 1206500, eval_loss: 2.99343e-02
I0213 10:49:42.547656 22542570456896 run_lib.py:133] step: 1206550, training_loss: 3.06868e-02
I0213 10:49:59.847542 22542570456896 run_lib.py:133] step: 1206600, training_loss: 2.64850e-02
I0213 10:50:00.000461 22542570456896 run_lib.py:146] step: 1206600, eval_loss: 2.94922e-02
I0213 10:50:17.434378 22542570456896 run_lib.py:133] step: 1206650, training_loss: 2.76972e-02
I0213 10:50:34.833023 22542570456896 run_lib.py:133] step: 1206700, training_loss: 2.65675e-02
I0213 10:50:34.987338 22542570456896 run_lib.py:146] step: 1206700, eval_loss: 3.62770e-02
I0213 10:50:52.225441 22542570456896 run_lib.py:133] step: 1206750, training_loss: 2.66760e-02
I0213 10:51:09.481728 22542570456896 run_lib.py:133] step: 1206800, training_loss: 2.26551e-02
I0213 10:51:09.638529 22542570456896 run_lib.py:146] step: 1206800, eval_loss: 2.48418e-02
I0213 10:51:26.916695 22542570456896 run_lib.py:133] step: 1206850, training_loss: 3.31891e-02
I0213 10:51:44.384384 22542570456896 run_lib.py:133] step: 1206900, training_loss: 2.86036e-02
I0213 10:51:44.539573 22542570456896 run_lib.py:146] step: 1206900, eval_loss: 2.63825e-02
I0213 10:52:01.801655 22542570456896 run_lib.py:133] step: 1206950, training_loss: 2.57409e-02
I0213 10:52:19.030058 22542570456896 run_lib.py:133] step: 1207000, training_loss: 3.14044e-02
I0213 10:52:19.184058 22542570456896 run_lib.py:146] step: 1207000, eval_loss: 3.24813e-02
I0213 10:52:36.405810 22542570456896 run_lib.py:133] step: 1207050, training_loss: 2.51260e-02
I0213 10:52:53.807103 22542570456896 run_lib.py:133] step: 1207100, training_loss: 2.67037e-02
I0213 10:52:53.956974 22542570456896 run_lib.py:146] step: 1207100, eval_loss: 3.41293e-02
I0213 10:53:11.220496 22542570456896 run_lib.py:133] step: 1207150, training_loss: 2.44049e-02
I0213 10:53:28.624312 22542570456896 run_lib.py:133] step: 1207200, training_loss: 2.26512e-02
I0213 10:53:28.788477 22542570456896 run_lib.py:146] step: 1207200, eval_loss: 2.75203e-02
I0213 10:53:46.051398 22542570456896 run_lib.py:133] step: 1207250, training_loss: 2.10499e-02
I0213 10:54:03.310751 22542570456896 run_lib.py:133] step: 1207300, training_loss: 2.44789e-02
I0213 10:54:03.467298 22542570456896 run_lib.py:146] step: 1207300, eval_loss: 2.85897e-02
I0213 10:54:20.903472 22542570456896 run_lib.py:133] step: 1207350, training_loss: 2.60868e-02
I0213 10:54:38.176212 22542570456896 run_lib.py:133] step: 1207400, training_loss: 2.77000e-02
I0213 10:54:38.338536 22542570456896 run_lib.py:146] step: 1207400, eval_loss: 2.11983e-02
I0213 10:54:55.610556 22542570456896 run_lib.py:133] step: 1207450, training_loss: 2.76625e-02
I0213 10:55:12.940101 22542570456896 run_lib.py:133] step: 1207500, training_loss: 2.30504e-02
I0213 10:55:13.094528 22542570456896 run_lib.py:146] step: 1207500, eval_loss: 2.84592e-02
I0213 10:55:30.538506 22542570456896 run_lib.py:133] step: 1207550, training_loss: 2.00545e-02
I0213 10:55:47.821450 22542570456896 run_lib.py:133] step: 1207600, training_loss: 2.19177e-02
I0213 10:55:47.971231 22542570456896 run_lib.py:146] step: 1207600, eval_loss: 2.99264e-02
I0213 10:56:05.383422 22542570456896 run_lib.py:133] step: 1207650, training_loss: 3.52302e-02
I0213 10:56:22.623505 22542570456896 run_lib.py:133] step: 1207700, training_loss: 2.13331e-02
I0213 10:56:22.780549 22542570456896 run_lib.py:146] step: 1207700, eval_loss: 3.16296e-02
I0213 10:56:40.194264 22542570456896 run_lib.py:133] step: 1207750, training_loss: 2.88299e-02
I0213 10:56:57.500464 22542570456896 run_lib.py:133] step: 1207800, training_loss: 2.14879e-02
I0213 10:56:57.657248 22542570456896 run_lib.py:146] step: 1207800, eval_loss: 2.46296e-02
I0213 10:57:14.897882 22542570456896 run_lib.py:133] step: 1207850, training_loss: 2.34639e-02
I0213 10:57:32.307221 22542570456896 run_lib.py:133] step: 1207900, training_loss: 3.27394e-02
I0213 10:57:32.460351 22542570456896 run_lib.py:146] step: 1207900, eval_loss: 3.56732e-02
I0213 10:57:49.698485 22542570456896 run_lib.py:133] step: 1207950, training_loss: 2.87324e-02
I0213 10:58:07.112485 22542570456896 run_lib.py:133] step: 1208000, training_loss: 2.72722e-02
I0213 10:58:07.272293 22542570456896 run_lib.py:146] step: 1208000, eval_loss: 3.19879e-02
I0213 10:58:24.519947 22542570456896 run_lib.py:133] step: 1208050, training_loss: 2.46415e-02
I0213 10:58:41.812240 22542570456896 run_lib.py:133] step: 1208100, training_loss: 2.16154e-02
I0213 10:58:41.966500 22542570456896 run_lib.py:146] step: 1208100, eval_loss: 3.12607e-02
I0213 10:58:59.437724 22542570456896 run_lib.py:133] step: 1208150, training_loss: 2.93486e-02
I0213 10:59:16.700644 22542570456896 run_lib.py:133] step: 1208200, training_loss: 2.87616e-02
I0213 10:59:16.857458 22542570456896 run_lib.py:146] step: 1208200, eval_loss: 2.89266e-02
I0213 10:59:34.100413 22542570456896 run_lib.py:133] step: 1208250, training_loss: 2.28970e-02
I0213 10:59:51.506505 22542570456896 run_lib.py:133] step: 1208300, training_loss: 2.36981e-02
I0213 10:59:51.666236 22542570456896 run_lib.py:146] step: 1208300, eval_loss: 3.58037e-02
I0213 11:00:08.956734 22542570456896 run_lib.py:133] step: 1208350, training_loss: 2.02610e-02
I0213 11:00:26.248782 22542570456896 run_lib.py:133] step: 1208400, training_loss: 2.46936e-02
I0213 11:00:26.403072 22542570456896 run_lib.py:146] step: 1208400, eval_loss: 2.69543e-02
I0213 11:00:43.772285 22542570456896 run_lib.py:133] step: 1208450, training_loss: 2.81168e-02
I0213 11:01:01.031038 22542570456896 run_lib.py:133] step: 1208500, training_loss: 2.60993e-02
I0213 11:01:01.185961 22542570456896 run_lib.py:146] step: 1208500, eval_loss: 2.96522e-02
I0213 11:01:18.444253 22542570456896 run_lib.py:133] step: 1208550, training_loss: 2.35566e-02
I0213 11:01:35.730659 22542570456896 run_lib.py:133] step: 1208600, training_loss: 2.50076e-02
I0213 11:01:35.891547 22542570456896 run_lib.py:146] step: 1208600, eval_loss: 2.98863e-02
I0213 11:01:53.396872 22542570456896 run_lib.py:133] step: 1208650, training_loss: 2.95464e-02
I0213 11:02:10.778452 22542570456896 run_lib.py:133] step: 1208700, training_loss: 2.44640e-02
I0213 11:02:10.937286 22542570456896 run_lib.py:146] step: 1208700, eval_loss: 2.48055e-02
I0213 11:02:28.188182 22542570456896 run_lib.py:133] step: 1208750, training_loss: 2.73169e-02
I0213 11:02:45.437069 22542570456896 run_lib.py:133] step: 1208800, training_loss: 1.98966e-02
I0213 11:02:45.590234 22542570456896 run_lib.py:146] step: 1208800, eval_loss: 2.80318e-02
I0213 11:03:02.985083 22542570456896 run_lib.py:133] step: 1208850, training_loss: 2.60354e-02
I0213 11:03:20.241719 22542570456896 run_lib.py:133] step: 1208900, training_loss: 2.44834e-02
I0213 11:03:20.396078 22542570456896 run_lib.py:146] step: 1208900, eval_loss: 3.28850e-02
I0213 11:03:37.843646 22542570456896 run_lib.py:133] step: 1208950, training_loss: 3.71751e-02
I0213 11:03:55.074137 22542570456896 run_lib.py:133] step: 1209000, training_loss: 3.04559e-02
I0213 11:03:55.231628 22542570456896 run_lib.py:146] step: 1209000, eval_loss: 2.75687e-02
I0213 11:04:12.632617 22542570456896 run_lib.py:133] step: 1209050, training_loss: 2.78148e-02
I0213 11:04:29.893495 22542570456896 run_lib.py:133] step: 1209100, training_loss: 2.06211e-02
I0213 11:04:30.046264 22542570456896 run_lib.py:146] step: 1209100, eval_loss: 3.04669e-02
I0213 11:04:47.439581 22542570456896 run_lib.py:133] step: 1209150, training_loss: 3.11321e-02
I0213 11:05:04.693031 22542570456896 run_lib.py:133] step: 1209200, training_loss: 3.76391e-02
I0213 11:05:04.864226 22542570456896 run_lib.py:146] step: 1209200, eval_loss: 3.11925e-02
I0213 11:05:22.165868 22542570456896 run_lib.py:133] step: 1209250, training_loss: 2.76960e-02
I0213 11:05:39.603194 22542570456896 run_lib.py:133] step: 1209300, training_loss: 3.27323e-02
I0213 11:05:39.757455 22542570456896 run_lib.py:146] step: 1209300, eval_loss: 3.21430e-02
I0213 11:05:57.013180 22542570456896 run_lib.py:133] step: 1209350, training_loss: 2.91859e-02
I0213 11:06:14.270431 22542570456896 run_lib.py:133] step: 1209400, training_loss: 2.83878e-02
I0213 11:06:14.424354 22542570456896 run_lib.py:146] step: 1209400, eval_loss: 2.58389e-02
I0213 11:06:31.850453 22542570456896 run_lib.py:133] step: 1209450, training_loss: 2.51042e-02
I0213 11:06:49.130407 22542570456896 run_lib.py:133] step: 1209500, training_loss: 2.91058e-02
I0213 11:06:49.282531 22542570456896 run_lib.py:146] step: 1209500, eval_loss: 3.63512e-02
I0213 11:07:06.762466 22542570456896 run_lib.py:133] step: 1209550, training_loss: 2.49408e-02
I0213 11:07:24.044597 22542570456896 run_lib.py:133] step: 1209600, training_loss: 2.69526e-02
I0213 11:07:24.198303 22542570456896 run_lib.py:146] step: 1209600, eval_loss: 3.69317e-02
I0213 11:07:41.433493 22542570456896 run_lib.py:133] step: 1209650, training_loss: 3.11282e-02
I0213 11:07:58.873966 22542570456896 run_lib.py:133] step: 1209700, training_loss: 2.61707e-02
I0213 11:07:59.029448 22542570456896 run_lib.py:146] step: 1209700, eval_loss: 2.29496e-02
I0213 11:08:16.308979 22542570456896 run_lib.py:133] step: 1209750, training_loss: 2.27537e-02
I0213 11:08:33.614595 22542570456896 run_lib.py:133] step: 1209800, training_loss: 2.35816e-02
I0213 11:08:33.769494 22542570456896 run_lib.py:146] step: 1209800, eval_loss: 3.22173e-02
I0213 11:08:51.057481 22542570456896 run_lib.py:133] step: 1209850, training_loss: 2.30846e-02
I0213 11:09:08.436961 22542570456896 run_lib.py:133] step: 1209900, training_loss: 2.46900e-02
I0213 11:09:08.597877 22542570456896 run_lib.py:146] step: 1209900, eval_loss: 3.33220e-02
I0213 11:09:25.861716 22542570456896 run_lib.py:133] step: 1209950, training_loss: 3.22183e-02
I0213 11:09:43.169517 22542570456896 run_lib.py:133] step: 1210000, training_loss: 2.75858e-02
I0213 11:09:43.851225 22542570456896 run_lib.py:146] step: 1210000, eval_loss: 2.96019e-02
I0213 11:10:03.693470 22542570456896 run_lib.py:133] step: 1210050, training_loss: 2.56144e-02
I0213 11:10:21.058657 22542570456896 run_lib.py:133] step: 1210100, training_loss: 2.86878e-02
I0213 11:10:21.213472 22542570456896 run_lib.py:146] step: 1210100, eval_loss: 2.51848e-02
I0213 11:10:38.680877 22542570456896 run_lib.py:133] step: 1210150, training_loss: 3.01971e-02
I0213 11:10:55.949509 22542570456896 run_lib.py:133] step: 1210200, training_loss: 2.17660e-02
I0213 11:10:56.104091 22542570456896 run_lib.py:146] step: 1210200, eval_loss: 3.07245e-02
I0213 11:11:13.384133 22542570456896 run_lib.py:133] step: 1210250, training_loss: 3.22944e-02
I0213 11:11:30.598819 22542570456896 run_lib.py:133] step: 1210300, training_loss: 2.30941e-02
I0213 11:11:30.758224 22542570456896 run_lib.py:146] step: 1210300, eval_loss: 3.18812e-02
I0213 11:11:48.054694 22542570456896 run_lib.py:133] step: 1210350, training_loss: 3.14976e-02
I0213 11:12:05.392303 22542570456896 run_lib.py:133] step: 1210400, training_loss: 2.65378e-02
I0213 11:12:05.547055 22542570456896 run_lib.py:146] step: 1210400, eval_loss: 2.50908e-02
I0213 11:12:22.981319 22542570456896 run_lib.py:133] step: 1210450, training_loss: 2.59024e-02
I0213 11:12:40.296968 22542570456896 run_lib.py:133] step: 1210500, training_loss: 2.78331e-02
I0213 11:12:40.447267 22542570456896 run_lib.py:146] step: 1210500, eval_loss: 2.46909e-02
I0213 11:12:57.720619 22542570456896 run_lib.py:133] step: 1210550, training_loss: 2.96216e-02
I0213 11:13:14.963793 22542570456896 run_lib.py:133] step: 1210600, training_loss: 2.77064e-02
I0213 11:13:15.133478 22542570456896 run_lib.py:146] step: 1210600, eval_loss: 2.46349e-02
I0213 11:13:32.574361 22542570456896 run_lib.py:133] step: 1210650, training_loss: 2.41421e-02
I0213 11:13:49.872440 22542570456896 run_lib.py:133] step: 1210700, training_loss: 3.27333e-02
I0213 11:13:50.026202 22542570456896 run_lib.py:146] step: 1210700, eval_loss: 2.36179e-02
I0213 11:14:07.414240 22542570456896 run_lib.py:133] step: 1210750, training_loss: 3.36553e-02
I0213 11:14:24.635015 22542570456896 run_lib.py:133] step: 1210800, training_loss: 2.27069e-02
I0213 11:14:24.788205 22542570456896 run_lib.py:146] step: 1210800, eval_loss: 2.37576e-02
I0213 11:14:42.155717 22542570456896 run_lib.py:133] step: 1210850, training_loss: 2.20709e-02
I0213 11:14:59.445527 22542570456896 run_lib.py:133] step: 1210900, training_loss: 2.41959e-02
I0213 11:14:59.604347 22542570456896 run_lib.py:146] step: 1210900, eval_loss: 3.93356e-02
I0213 11:15:16.914421 22542570456896 run_lib.py:133] step: 1210950, training_loss: 2.34631e-02
I0213 11:15:34.362104 22542570456896 run_lib.py:133] step: 1211000, training_loss: 2.38062e-02
I0213 11:15:34.512277 22542570456896 run_lib.py:146] step: 1211000, eval_loss: 2.87790e-02
I0213 11:15:51.760548 22542570456896 run_lib.py:133] step: 1211050, training_loss: 2.90357e-02
I0213 11:16:09.150829 22542570456896 run_lib.py:133] step: 1211100, training_loss: 2.47990e-02
I0213 11:16:09.304310 22542570456896 run_lib.py:146] step: 1211100, eval_loss: 3.00121e-02
I0213 11:16:26.541082 22542570456896 run_lib.py:133] step: 1211150, training_loss: 2.67498e-02
I0213 11:16:43.851974 22542570456896 run_lib.py:133] step: 1211200, training_loss: 2.20913e-02
I0213 11:16:44.014320 22542570456896 run_lib.py:146] step: 1211200, eval_loss: 2.99427e-02
I0213 11:17:01.467016 22542570456896 run_lib.py:133] step: 1211250, training_loss: 2.90290e-02
I0213 11:17:18.781533 22542570456896 run_lib.py:133] step: 1211300, training_loss: 2.74370e-02
I0213 11:17:18.935534 22542570456896 run_lib.py:146] step: 1211300, eval_loss: 2.16314e-02
I0213 11:17:36.155840 22542570456896 run_lib.py:133] step: 1211350, training_loss: 3.23450e-02
I0213 11:17:53.515434 22542570456896 run_lib.py:133] step: 1211400, training_loss: 2.21828e-02
I0213 11:17:53.669285 22542570456896 run_lib.py:146] step: 1211400, eval_loss: 3.00280e-02
I0213 11:18:10.906837 22542570456896 run_lib.py:133] step: 1211450, training_loss: 2.33108e-02
I0213 11:18:28.189458 22542570456896 run_lib.py:133] step: 1211500, training_loss: 2.31451e-02
I0213 11:18:28.517488 22542570456896 run_lib.py:146] step: 1211500, eval_loss: 2.88905e-02
I0213 11:18:45.807817 22542570456896 run_lib.py:133] step: 1211550, training_loss: 2.30779e-02
I0213 11:19:03.074768 22542570456896 run_lib.py:133] step: 1211600, training_loss: 3.13288e-02
I0213 11:19:03.230499 22542570456896 run_lib.py:146] step: 1211600, eval_loss: 2.85016e-02
I0213 11:19:20.510144 22542570456896 run_lib.py:133] step: 1211650, training_loss: 3.00221e-02
I0213 11:19:37.774955 22542570456896 run_lib.py:133] step: 1211700, training_loss: 2.25382e-02
I0213 11:19:37.935312 22542570456896 run_lib.py:146] step: 1211700, eval_loss: 2.74248e-02
I0213 11:19:55.317676 22542570456896 run_lib.py:133] step: 1211750, training_loss: 2.83951e-02
I0213 11:20:12.694331 22542570456896 run_lib.py:133] step: 1211800, training_loss: 2.63438e-02
I0213 11:20:12.856238 22542570456896 run_lib.py:146] step: 1211800, eval_loss: 2.82495e-02
I0213 11:20:30.126726 22542570456896 run_lib.py:133] step: 1211850, training_loss: 2.66929e-02
I0213 11:20:47.394902 22542570456896 run_lib.py:133] step: 1211900, training_loss: 2.86857e-02
I0213 11:20:47.542789 22542570456896 run_lib.py:146] step: 1211900, eval_loss: 4.17153e-02
I0213 11:21:04.912338 22542570456896 run_lib.py:133] step: 1211950, training_loss: 2.43906e-02
I0213 11:21:22.217387 22542570456896 run_lib.py:133] step: 1212000, training_loss: 2.61934e-02
I0213 11:21:22.370438 22542570456896 run_lib.py:146] step: 1212000, eval_loss: 2.61780e-02
I0213 11:21:39.671591 22542570456896 run_lib.py:133] step: 1212050, training_loss: 2.67456e-02
I0213 11:21:56.956201 22542570456896 run_lib.py:133] step: 1212100, training_loss: 2.88734e-02
I0213 11:21:57.113259 22542570456896 run_lib.py:146] step: 1212100, eval_loss: 3.65343e-02
I0213 11:22:14.531864 22542570456896 run_lib.py:133] step: 1212150, training_loss: 2.51556e-02
I0213 11:22:31.744633 22542570456896 run_lib.py:133] step: 1212200, training_loss: 2.22880e-02
I0213 11:22:31.897212 22542570456896 run_lib.py:146] step: 1212200, eval_loss: 3.36516e-02
I0213 11:22:49.279273 22542570456896 run_lib.py:133] step: 1212250, training_loss: 2.37418e-02
I0213 11:23:06.563339 22542570456896 run_lib.py:133] step: 1212300, training_loss: 2.55270e-02
I0213 11:23:06.719295 22542570456896 run_lib.py:146] step: 1212300, eval_loss: 2.55277e-02
I0213 11:23:24.172406 22542570456896 run_lib.py:133] step: 1212350, training_loss: 2.82609e-02
I0213 11:23:41.423693 22542570456896 run_lib.py:133] step: 1212400, training_loss: 2.69927e-02
I0213 11:23:41.573075 22542570456896 run_lib.py:146] step: 1212400, eval_loss: 2.69167e-02
I0213 11:23:58.839571 22542570456896 run_lib.py:133] step: 1212450, training_loss: 2.72294e-02
I0213 11:24:16.262697 22542570456896 run_lib.py:133] step: 1212500, training_loss: 3.16948e-02
I0213 11:24:16.416294 22542570456896 run_lib.py:146] step: 1212500, eval_loss: 2.06656e-02
I0213 11:24:33.658075 22542570456896 run_lib.py:133] step: 1212550, training_loss: 2.70703e-02
I0213 11:24:51.084700 22542570456896 run_lib.py:133] step: 1212600, training_loss: 3.51600e-02
I0213 11:24:51.254269 22542570456896 run_lib.py:146] step: 1212600, eval_loss: 2.80101e-02
I0213 11:25:08.508131 22542570456896 run_lib.py:133] step: 1212650, training_loss: 2.91872e-02
I0213 11:25:25.797272 22542570456896 run_lib.py:133] step: 1212700, training_loss: 2.61064e-02
I0213 11:25:25.955480 22542570456896 run_lib.py:146] step: 1212700, eval_loss: 2.33056e-02
I0213 11:25:43.373272 22542570456896 run_lib.py:133] step: 1212750, training_loss: 2.50159e-02
I0213 11:26:00.602146 22542570456896 run_lib.py:133] step: 1212800, training_loss: 2.52810e-02
I0213 11:26:00.755266 22542570456896 run_lib.py:146] step: 1212800, eval_loss: 2.44525e-02
I0213 11:26:18.050902 22542570456896 run_lib.py:133] step: 1212850, training_loss: 2.28039e-02
I0213 11:26:35.340316 22542570456896 run_lib.py:133] step: 1212900, training_loss: 2.08465e-02
I0213 11:26:35.489804 22542570456896 run_lib.py:146] step: 1212900, eval_loss: 2.59370e-02
I0213 11:26:52.904940 22542570456896 run_lib.py:133] step: 1212950, training_loss: 2.39035e-02
I0213 11:27:10.163339 22542570456896 run_lib.py:133] step: 1213000, training_loss: 2.21699e-02
I0213 11:27:10.315157 22542570456896 run_lib.py:146] step: 1213000, eval_loss: 3.71535e-02
I0213 11:27:27.614139 22542570456896 run_lib.py:133] step: 1213050, training_loss: 2.85185e-02
I0213 11:27:44.837420 22542570456896 run_lib.py:133] step: 1213100, training_loss: 1.90867e-02
I0213 11:27:45.016569 22542570456896 run_lib.py:146] step: 1213100, eval_loss: 3.35801e-02
I0213 11:28:02.342077 22542570456896 run_lib.py:133] step: 1213150, training_loss: 1.96971e-02
I0213 11:28:19.624476 22542570456896 run_lib.py:133] step: 1213200, training_loss: 3.09294e-02
I0213 11:28:19.778478 22542570456896 run_lib.py:146] step: 1213200, eval_loss: 3.27436e-02
I0213 11:28:37.238525 22542570456896 run_lib.py:133] step: 1213250, training_loss: 2.74532e-02
I0213 11:28:54.557117 22542570456896 run_lib.py:133] step: 1213300, training_loss: 2.58785e-02
I0213 11:28:54.710300 22542570456896 run_lib.py:146] step: 1213300, eval_loss: 2.57827e-02
I0213 11:29:11.963260 22542570456896 run_lib.py:133] step: 1213350, training_loss: 2.27363e-02
I0213 11:29:29.269948 22542570456896 run_lib.py:133] step: 1213400, training_loss: 1.98304e-02
I0213 11:29:29.421485 22542570456896 run_lib.py:146] step: 1213400, eval_loss: 3.06025e-02
I0213 11:29:46.945930 22542570456896 run_lib.py:133] step: 1213450, training_loss: 2.56139e-02
I0213 11:30:04.196433 22542570456896 run_lib.py:133] step: 1213500, training_loss: 2.31710e-02
I0213 11:30:04.352289 22542570456896 run_lib.py:146] step: 1213500, eval_loss: 3.87688e-02
I0213 11:30:21.755213 22542570456896 run_lib.py:133] step: 1213550, training_loss: 2.79463e-02
I0213 11:30:38.985631 22542570456896 run_lib.py:133] step: 1213600, training_loss: 2.63324e-02
I0213 11:30:39.138701 22542570456896 run_lib.py:146] step: 1213600, eval_loss: 3.25061e-02
I0213 11:30:56.539517 22542570456896 run_lib.py:133] step: 1213650, training_loss: 3.00326e-02
I0213 11:31:13.808609 22542570456896 run_lib.py:133] step: 1213700, training_loss: 2.58663e-02
I0213 11:31:13.968035 22542570456896 run_lib.py:146] step: 1213700, eval_loss: 3.28118e-02
I0213 11:31:31.449262 22542570456896 run_lib.py:133] step: 1213750, training_loss: 2.91373e-02
I0213 11:31:48.704339 22542570456896 run_lib.py:133] step: 1213800, training_loss: 3.07857e-02
I0213 11:31:48.857011 22542570456896 run_lib.py:146] step: 1213800, eval_loss: 2.75459e-02
I0213 11:32:06.172481 22542570456896 run_lib.py:133] step: 1213850, training_loss: 2.42846e-02
I0213 11:32:23.547240 22542570456896 run_lib.py:133] step: 1213900, training_loss: 2.99495e-02
I0213 11:32:23.698247 22542570456896 run_lib.py:146] step: 1213900, eval_loss: 2.81097e-02
I0213 11:32:40.936515 22542570456896 run_lib.py:133] step: 1213950, training_loss: 3.20084e-02
I0213 11:32:58.169918 22542570456896 run_lib.py:133] step: 1214000, training_loss: 2.01072e-02
I0213 11:32:58.348281 22542570456896 run_lib.py:146] step: 1214000, eval_loss: 3.43993e-02
I0213 11:33:15.855406 22542570456896 run_lib.py:133] step: 1214050, training_loss: 2.92296e-02
I0213 11:33:33.263488 22542570456896 run_lib.py:133] step: 1214100, training_loss: 2.60974e-02
I0213 11:33:33.417376 22542570456896 run_lib.py:146] step: 1214100, eval_loss: 3.02033e-02
I0213 11:33:50.660135 22542570456896 run_lib.py:133] step: 1214150, training_loss: 2.33242e-02
I0213 11:34:07.905426 22542570456896 run_lib.py:133] step: 1214200, training_loss: 2.37628e-02
I0213 11:34:08.059375 22542570456896 run_lib.py:146] step: 1214200, eval_loss: 2.54278e-02
I0213 11:34:25.296386 22542570456896 run_lib.py:133] step: 1214250, training_loss: 2.15758e-02
I0213 11:34:42.724150 22542570456896 run_lib.py:133] step: 1214300, training_loss: 2.94361e-02
I0213 11:34:42.876515 22542570456896 run_lib.py:146] step: 1214300, eval_loss: 3.57138e-02
I0213 11:35:00.142909 22542570456896 run_lib.py:133] step: 1214350, training_loss: 2.05388e-02
I0213 11:35:17.407728 22542570456896 run_lib.py:133] step: 1214400, training_loss: 3.50130e-02
I0213 11:35:17.561322 22542570456896 run_lib.py:146] step: 1214400, eval_loss: 3.57191e-02
I0213 11:35:34.810555 22542570456896 run_lib.py:133] step: 1214450, training_loss: 2.55295e-02
I0213 11:35:52.239357 22542570456896 run_lib.py:133] step: 1214500, training_loss: 2.49059e-02
I0213 11:35:52.409259 22542570456896 run_lib.py:146] step: 1214500, eval_loss: 2.58420e-02
I0213 11:36:09.710612 22542570456896 run_lib.py:133] step: 1214550, training_loss: 2.78783e-02
I0213 11:36:27.091260 22542570456896 run_lib.py:133] step: 1214600, training_loss: 2.53603e-02
I0213 11:36:27.251442 22542570456896 run_lib.py:146] step: 1214600, eval_loss: 2.91809e-02
I0213 11:36:44.501200 22542570456896 run_lib.py:133] step: 1214650, training_loss: 3.19227e-02
I0213 11:37:01.751036 22542570456896 run_lib.py:133] step: 1214700, training_loss: 2.44078e-02
I0213 11:37:01.911220 22542570456896 run_lib.py:146] step: 1214700, eval_loss: 3.36452e-02
I0213 11:37:19.346856 22542570456896 run_lib.py:133] step: 1214750, training_loss: 2.01428e-02
I0213 11:37:36.636871 22542570456896 run_lib.py:133] step: 1214800, training_loss: 2.96747e-02
I0213 11:37:36.790503 22542570456896 run_lib.py:146] step: 1214800, eval_loss: 2.68923e-02
I0213 11:37:54.072701 22542570456896 run_lib.py:133] step: 1214850, training_loss: 3.16680e-02
I0213 11:38:11.325868 22542570456896 run_lib.py:133] step: 1214900, training_loss: 2.94712e-02
I0213 11:38:11.480405 22542570456896 run_lib.py:146] step: 1214900, eval_loss: 2.56125e-02
I0213 11:38:28.906914 22542570456896 run_lib.py:133] step: 1214950, training_loss: 2.72330e-02
I0213 11:38:46.154765 22542570456896 run_lib.py:133] step: 1215000, training_loss: 2.86820e-02
I0213 11:38:46.311435 22542570456896 run_lib.py:146] step: 1215000, eval_loss: 2.86633e-02
I0213 11:39:03.688251 22542570456896 run_lib.py:133] step: 1215050, training_loss: 2.61135e-02
I0213 11:39:20.942423 22542570456896 run_lib.py:133] step: 1215100, training_loss: 3.32135e-02
I0213 11:39:21.099215 22542570456896 run_lib.py:146] step: 1215100, eval_loss: 2.66381e-02
I0213 11:39:38.459890 22542570456896 run_lib.py:133] step: 1215150, training_loss: 3.49145e-02
I0213 11:39:55.768840 22542570456896 run_lib.py:133] step: 1215200, training_loss: 2.64744e-02
I0213 11:39:55.922114 22542570456896 run_lib.py:146] step: 1215200, eval_loss: 2.51784e-02
I0213 11:40:13.156577 22542570456896 run_lib.py:133] step: 1215250, training_loss: 2.81806e-02
I0213 11:40:30.566059 22542570456896 run_lib.py:133] step: 1215300, training_loss: 1.98227e-02
I0213 11:40:30.715267 22542570456896 run_lib.py:146] step: 1215300, eval_loss: 2.93744e-02
I0213 11:40:47.964771 22542570456896 run_lib.py:133] step: 1215350, training_loss: 3.03687e-02
I0213 11:41:05.333045 22542570456896 run_lib.py:133] step: 1215400, training_loss: 3.24685e-02
I0213 11:41:05.502279 22542570456896 run_lib.py:146] step: 1215400, eval_loss: 2.27868e-02
I0213 11:41:22.840962 22542570456896 run_lib.py:133] step: 1215450, training_loss: 2.53825e-02
I0213 11:41:40.118079 22542570456896 run_lib.py:133] step: 1215500, training_loss: 2.21448e-02
I0213 11:41:40.271294 22542570456896 run_lib.py:146] step: 1215500, eval_loss: 2.81561e-02
I0213 11:41:57.670268 22542570456896 run_lib.py:133] step: 1215550, training_loss: 2.99268e-02
I0213 11:42:14.919905 22542570456896 run_lib.py:133] step: 1215600, training_loss: 2.73002e-02
I0213 11:42:15.074432 22542570456896 run_lib.py:146] step: 1215600, eval_loss: 2.69383e-02
I0213 11:42:32.342408 22542570456896 run_lib.py:133] step: 1215650, training_loss: 2.69940e-02
I0213 11:42:49.761371 22542570456896 run_lib.py:133] step: 1215700, training_loss: 2.32673e-02
I0213 11:42:49.914103 22542570456896 run_lib.py:146] step: 1215700, eval_loss: 3.57222e-02
I0213 11:43:07.225518 22542570456896 run_lib.py:133] step: 1215750, training_loss: 2.18697e-02
I0213 11:43:24.503781 22542570456896 run_lib.py:133] step: 1215800, training_loss: 2.71517e-02
I0213 11:43:24.655509 22542570456896 run_lib.py:146] step: 1215800, eval_loss: 2.50432e-02
I0213 11:43:41.972879 22542570456896 run_lib.py:133] step: 1215850, training_loss: 2.49556e-02
I0213 11:43:59.218403 22542570456896 run_lib.py:133] step: 1215900, training_loss: 2.48038e-02
I0213 11:43:59.375587 22542570456896 run_lib.py:146] step: 1215900, eval_loss: 3.05438e-02
I0213 11:44:16.613146 22542570456896 run_lib.py:133] step: 1215950, training_loss: 3.31889e-02
I0213 11:44:33.960663 22542570456896 run_lib.py:133] step: 1216000, training_loss: 2.38625e-02
I0213 11:44:34.122583 22542570456896 run_lib.py:146] step: 1216000, eval_loss: 3.06438e-02
I0213 11:44:51.499808 22542570456896 run_lib.py:133] step: 1216050, training_loss: 2.81106e-02
I0213 11:45:08.809629 22542570456896 run_lib.py:133] step: 1216100, training_loss: 2.69588e-02
I0213 11:45:08.963452 22542570456896 run_lib.py:146] step: 1216100, eval_loss: 2.78835e-02
I0213 11:45:26.216518 22542570456896 run_lib.py:133] step: 1216150, training_loss: 2.32055e-02
I0213 11:45:43.475418 22542570456896 run_lib.py:133] step: 1216200, training_loss: 2.96875e-02
I0213 11:45:43.631083 22542570456896 run_lib.py:146] step: 1216200, eval_loss: 2.50955e-02
I0213 11:46:01.053117 22542570456896 run_lib.py:133] step: 1216250, training_loss: 3.12579e-02
I0213 11:46:18.324366 22542570456896 run_lib.py:133] step: 1216300, training_loss: 3.16077e-02
I0213 11:46:18.492391 22542570456896 run_lib.py:146] step: 1216300, eval_loss: 3.49717e-02
I0213 11:46:35.903718 22542570456896 run_lib.py:133] step: 1216350, training_loss: 1.98177e-02
I0213 11:46:53.161226 22542570456896 run_lib.py:133] step: 1216400, training_loss: 2.44983e-02
I0213 11:46:53.319264 22542570456896 run_lib.py:146] step: 1216400, eval_loss: 2.99803e-02
I0213 11:47:10.707342 22542570456896 run_lib.py:133] step: 1216450, training_loss: 2.94554e-02
I0213 11:47:27.906394 22542570456896 run_lib.py:133] step: 1216500, training_loss: 2.29544e-02
I0213 11:47:28.060267 22542570456896 run_lib.py:146] step: 1216500, eval_loss: 3.04674e-02
I0213 11:47:45.463441 22542570456896 run_lib.py:133] step: 1216550, training_loss: 2.78885e-02
I0213 11:48:02.779405 22542570456896 run_lib.py:133] step: 1216600, training_loss: 2.15006e-02
I0213 11:48:02.933460 22542570456896 run_lib.py:146] step: 1216600, eval_loss: 3.47979e-02
I0213 11:48:20.201694 22542570456896 run_lib.py:133] step: 1216650, training_loss: 3.27706e-02
I0213 11:48:37.632789 22542570456896 run_lib.py:133] step: 1216700, training_loss: 2.80478e-02
I0213 11:48:37.779580 22542570456896 run_lib.py:146] step: 1216700, eval_loss: 2.94776e-02
I0213 11:48:55.035086 22542570456896 run_lib.py:133] step: 1216750, training_loss: 3.04251e-02
I0213 11:49:12.269222 22542570456896 run_lib.py:133] step: 1216800, training_loss: 2.51365e-02
I0213 11:49:12.423265 22542570456896 run_lib.py:146] step: 1216800, eval_loss: 3.04045e-02
I0213 11:49:29.775629 22542570456896 run_lib.py:133] step: 1216850, training_loss: 2.68602e-02
I0213 11:49:47.061050 22542570456896 run_lib.py:133] step: 1216900, training_loss: 2.69031e-02
I0213 11:49:47.221204 22542570456896 run_lib.py:146] step: 1216900, eval_loss: 2.54708e-02
I0213 11:50:04.627150 22542570456896 run_lib.py:133] step: 1216950, training_loss: 2.93713e-02
I0213 11:50:21.856987 22542570456896 run_lib.py:133] step: 1217000, training_loss: 3.04694e-02
I0213 11:50:22.010055 22542570456896 run_lib.py:146] step: 1217000, eval_loss: 2.49777e-02
I0213 11:50:39.288413 22542570456896 run_lib.py:133] step: 1217050, training_loss: 3.20522e-02
I0213 11:50:56.668003 22542570456896 run_lib.py:133] step: 1217100, training_loss: 1.95359e-02
I0213 11:50:56.824949 22542570456896 run_lib.py:146] step: 1217100, eval_loss: 2.63999e-02
I0213 11:51:14.064048 22542570456896 run_lib.py:133] step: 1217150, training_loss: 2.12530e-02
I0213 11:51:31.352336 22542570456896 run_lib.py:133] step: 1217200, training_loss: 2.25866e-02
I0213 11:51:31.505507 22542570456896 run_lib.py:146] step: 1217200, eval_loss: 3.01863e-02
I0213 11:51:48.776597 22542570456896 run_lib.py:133] step: 1217250, training_loss: 2.35017e-02
I0213 11:52:06.162012 22542570456896 run_lib.py:133] step: 1217300, training_loss: 2.89029e-02
I0213 11:52:06.325252 22542570456896 run_lib.py:146] step: 1217300, eval_loss: 3.85087e-02
I0213 11:52:23.575164 22542570456896 run_lib.py:133] step: 1217350, training_loss: 2.43026e-02
I0213 11:52:40.872774 22542570456896 run_lib.py:133] step: 1217400, training_loss: 2.63215e-02
I0213 11:52:41.028226 22542570456896 run_lib.py:146] step: 1217400, eval_loss: 2.82074e-02
I0213 11:52:58.277342 22542570456896 run_lib.py:133] step: 1217450, training_loss: 2.95696e-02
I0213 11:53:15.623944 22542570456896 run_lib.py:133] step: 1217500, training_loss: 2.56943e-02
I0213 11:53:15.779639 22542570456896 run_lib.py:146] step: 1217500, eval_loss: 3.56197e-02
I0213 11:53:33.252922 22542570456896 run_lib.py:133] step: 1217550, training_loss: 2.70121e-02
I0213 11:53:50.532834 22542570456896 run_lib.py:133] step: 1217600, training_loss: 2.39628e-02
I0213 11:53:50.683973 22542570456896 run_lib.py:146] step: 1217600, eval_loss: 2.72992e-02
I0213 11:54:07.914544 22542570456896 run_lib.py:133] step: 1217650, training_loss: 2.78700e-02
I0213 11:54:25.165541 22542570456896 run_lib.py:133] step: 1217700, training_loss: 2.61931e-02
I0213 11:54:25.321249 22542570456896 run_lib.py:146] step: 1217700, eval_loss: 2.51561e-02
I0213 11:54:42.726015 22542570456896 run_lib.py:133] step: 1217750, training_loss: 3.37320e-02
I0213 11:55:00.047793 22542570456896 run_lib.py:133] step: 1217800, training_loss: 2.34638e-02
I0213 11:55:00.213311 22542570456896 run_lib.py:146] step: 1217800, eval_loss: 3.91927e-02
I0213 11:55:17.639742 22542570456896 run_lib.py:133] step: 1217850, training_loss: 2.46291e-02
I0213 11:55:34.894178 22542570456896 run_lib.py:133] step: 1217900, training_loss: 2.80634e-02
I0213 11:55:35.049326 22542570456896 run_lib.py:146] step: 1217900, eval_loss: 2.85474e-02
I0213 11:55:52.469459 22542570456896 run_lib.py:133] step: 1217950, training_loss: 3.09678e-02
I0213 11:56:09.692679 22542570456896 run_lib.py:133] step: 1218000, training_loss: 2.25951e-02
I0213 11:56:09.849391 22542570456896 run_lib.py:146] step: 1218000, eval_loss: 2.98982e-02
I0213 11:56:27.067103 22542570456896 run_lib.py:133] step: 1218050, training_loss: 2.27345e-02
I0213 11:56:44.475281 22542570456896 run_lib.py:133] step: 1218100, training_loss: 2.81398e-02
I0213 11:56:44.628535 22542570456896 run_lib.py:146] step: 1218100, eval_loss: 3.11029e-02
I0213 11:57:01.954223 22542570456896 run_lib.py:133] step: 1218150, training_loss: 3.19625e-02
I0213 11:57:19.367750 22542570456896 run_lib.py:133] step: 1218200, training_loss: 2.54116e-02
I0213 11:57:19.522243 22542570456896 run_lib.py:146] step: 1218200, eval_loss: 2.87701e-02
I0213 11:57:36.731305 22542570456896 run_lib.py:133] step: 1218250, training_loss: 2.34477e-02
I0213 11:57:53.993189 22542570456896 run_lib.py:133] step: 1218300, training_loss: 3.01430e-02
I0213 11:57:54.157895 22542570456896 run_lib.py:146] step: 1218300, eval_loss: 3.24634e-02
I0213 11:58:11.578778 22542570456896 run_lib.py:133] step: 1218350, training_loss: 2.82360e-02
I0213 11:58:28.888928 22542570456896 run_lib.py:133] step: 1218400, training_loss: 2.36891e-02
I0213 11:58:29.047403 22542570456896 run_lib.py:146] step: 1218400, eval_loss: 2.98522e-02
I0213 11:58:46.278641 22542570456896 run_lib.py:133] step: 1218450, training_loss: 2.62395e-02
I0213 11:59:03.668954 22542570456896 run_lib.py:133] step: 1218500, training_loss: 3.47932e-02
I0213 11:59:03.830298 22542570456896 run_lib.py:146] step: 1218500, eval_loss: 2.99049e-02
I0213 11:59:21.074729 22542570456896 run_lib.py:133] step: 1218550, training_loss: 2.02130e-02
I0213 11:59:38.333157 22542570456896 run_lib.py:133] step: 1218600, training_loss: 2.46043e-02
I0213 11:59:38.619334 22542570456896 run_lib.py:146] step: 1218600, eval_loss: 3.03855e-02
I0213 11:59:55.852391 22542570456896 run_lib.py:133] step: 1218650, training_loss: 2.64709e-02
I0213 12:00:13.142742 22542570456896 run_lib.py:133] step: 1218700, training_loss: 2.62274e-02
I0213 12:00:13.318332 22542570456896 run_lib.py:146] step: 1218700, eval_loss: 3.58499e-02
I0213 12:00:30.602911 22542570456896 run_lib.py:133] step: 1218750, training_loss: 2.30736e-02
I0213 12:00:47.866097 22542570456896 run_lib.py:133] step: 1218800, training_loss: 2.56659e-02
I0213 12:00:48.023469 22542570456896 run_lib.py:146] step: 1218800, eval_loss: 3.25067e-02
I0213 12:01:05.436686 22542570456896 run_lib.py:133] step: 1218850, training_loss: 2.83241e-02
I0213 12:01:22.712891 22542570456896 run_lib.py:133] step: 1218900, training_loss: 3.04108e-02
I0213 12:01:22.874347 22542570456896 run_lib.py:146] step: 1218900, eval_loss: 2.87694e-02
I0213 12:01:40.154769 22542570456896 run_lib.py:133] step: 1218950, training_loss: 2.80040e-02
I0213 12:01:57.466820 22542570456896 run_lib.py:133] step: 1219000, training_loss: 2.74242e-02
I0213 12:01:57.620547 22542570456896 run_lib.py:146] step: 1219000, eval_loss: 3.57738e-02
I0213 12:02:15.080777 22542570456896 run_lib.py:133] step: 1219050, training_loss: 2.50889e-02
I0213 12:02:32.354403 22542570456896 run_lib.py:133] step: 1219100, training_loss: 2.48230e-02
I0213 12:02:32.505045 22542570456896 run_lib.py:146] step: 1219100, eval_loss: 2.76565e-02
I0213 12:02:49.757459 22542570456896 run_lib.py:133] step: 1219150, training_loss: 2.80077e-02
I0213 12:03:06.968337 22542570456896 run_lib.py:133] step: 1219200, training_loss: 3.04895e-02
I0213 12:03:07.146201 22542570456896 run_lib.py:146] step: 1219200, eval_loss: 2.47760e-02
I0213 12:03:24.599135 22542570456896 run_lib.py:133] step: 1219250, training_loss: 2.66105e-02
I0213 12:03:41.881667 22542570456896 run_lib.py:133] step: 1219300, training_loss: 2.96730e-02
I0213 12:03:42.037462 22542570456896 run_lib.py:146] step: 1219300, eval_loss: 2.91206e-02
I0213 12:03:59.476209 22542570456896 run_lib.py:133] step: 1219350, training_loss: 2.71167e-02
I0213 12:04:16.740179 22542570456896 run_lib.py:133] step: 1219400, training_loss: 3.40418e-02
I0213 12:04:16.894004 22542570456896 run_lib.py:146] step: 1219400, eval_loss: 2.93546e-02
I0213 12:04:34.273087 22542570456896 run_lib.py:133] step: 1219450, training_loss: 2.55671e-02
I0213 12:04:51.564358 22542570456896 run_lib.py:133] step: 1219500, training_loss: 2.74990e-02
I0213 12:04:51.716050 22542570456896 run_lib.py:146] step: 1219500, eval_loss: 2.65271e-02
I0213 12:05:09.015073 22542570456896 run_lib.py:133] step: 1219550, training_loss: 2.93416e-02
I0213 12:05:26.440416 22542570456896 run_lib.py:133] step: 1219600, training_loss: 2.17570e-02
I0213 12:05:26.593261 22542570456896 run_lib.py:146] step: 1219600, eval_loss: 3.92058e-02
I0213 12:05:43.863866 22542570456896 run_lib.py:133] step: 1219650, training_loss: 2.34566e-02
I0213 12:06:01.251338 22542570456896 run_lib.py:133] step: 1219700, training_loss: 3.16464e-02
I0213 12:06:01.409424 22542570456896 run_lib.py:146] step: 1219700, eval_loss: 2.72680e-02
I0213 12:06:18.680449 22542570456896 run_lib.py:133] step: 1219750, training_loss: 3.29021e-02
I0213 12:06:35.978657 22542570456896 run_lib.py:133] step: 1219800, training_loss: 2.71169e-02
I0213 12:06:36.133471 22542570456896 run_lib.py:146] step: 1219800, eval_loss: 3.06648e-02
I0213 12:06:53.556499 22542570456896 run_lib.py:133] step: 1219850, training_loss: 2.65152e-02
I0213 12:07:10.818267 22542570456896 run_lib.py:133] step: 1219900, training_loss: 2.86651e-02
I0213 12:07:10.972191 22542570456896 run_lib.py:146] step: 1219900, eval_loss: 2.92613e-02
I0213 12:07:28.202851 22542570456896 run_lib.py:133] step: 1219950, training_loss: 2.28958e-02
I0213 12:07:45.425523 22542570456896 run_lib.py:133] step: 1220000, training_loss: 2.80725e-02
I0213 12:07:46.221335 22542570456896 run_lib.py:146] step: 1220000, eval_loss: 2.81386e-02
I0213 12:08:06.335081 22542570456896 run_lib.py:133] step: 1220050, training_loss: 2.83273e-02
I0213 12:08:23.807563 22542570456896 run_lib.py:133] step: 1220100, training_loss: 2.92119e-02
I0213 12:08:23.959430 22542570456896 run_lib.py:146] step: 1220100, eval_loss: 2.95670e-02
I0213 12:08:41.181647 22542570456896 run_lib.py:133] step: 1220150, training_loss: 3.03648e-02
I0213 12:08:58.445354 22542570456896 run_lib.py:133] step: 1220200, training_loss: 2.08297e-02
I0213 12:08:58.607869 22542570456896 run_lib.py:146] step: 1220200, eval_loss: 2.69109e-02
I0213 12:09:15.966720 22542570456896 run_lib.py:133] step: 1220250, training_loss: 4.28647e-02
I0213 12:09:33.299114 22542570456896 run_lib.py:133] step: 1220300, training_loss: 3.29827e-02
I0213 12:09:33.471266 22542570456896 run_lib.py:146] step: 1220300, eval_loss: 3.22110e-02
I0213 12:09:50.729658 22542570456896 run_lib.py:133] step: 1220350, training_loss: 2.74097e-02
I0213 12:10:07.962759 22542570456896 run_lib.py:133] step: 1220400, training_loss: 2.13917e-02
I0213 12:10:08.119027 22542570456896 run_lib.py:146] step: 1220400, eval_loss: 2.06630e-02
I0213 12:10:25.559352 22542570456896 run_lib.py:133] step: 1220450, training_loss: 3.44820e-02
I0213 12:10:42.802278 22542570456896 run_lib.py:133] step: 1220500, training_loss: 2.58940e-02
I0213 12:10:42.955987 22542570456896 run_lib.py:146] step: 1220500, eval_loss: 3.18515e-02
I0213 12:11:00.259366 22542570456896 run_lib.py:133] step: 1220550, training_loss: 3.28336e-02
I0213 12:11:17.546104 22542570456896 run_lib.py:133] step: 1220600, training_loss: 2.63486e-02
I0213 12:11:17.700444 22542570456896 run_lib.py:146] step: 1220600, eval_loss: 3.27923e-02
I0213 12:11:34.968198 22542570456896 run_lib.py:133] step: 1220650, training_loss: 2.51607e-02
I0213 12:11:52.259328 22542570456896 run_lib.py:133] step: 1220700, training_loss: 2.30470e-02
I0213 12:11:52.415218 22542570456896 run_lib.py:146] step: 1220700, eval_loss: 3.21822e-02
I0213 12:12:09.829668 22542570456896 run_lib.py:133] step: 1220750, training_loss: 2.49407e-02
I0213 12:12:27.115003 22542570456896 run_lib.py:133] step: 1220800, training_loss: 2.91243e-02
I0213 12:12:27.275204 22542570456896 run_lib.py:146] step: 1220800, eval_loss: 2.83831e-02
I0213 12:12:44.579481 22542570456896 run_lib.py:133] step: 1220850, training_loss: 2.61005e-02
I0213 12:13:01.887181 22542570456896 run_lib.py:133] step: 1220900, training_loss: 2.59036e-02
I0213 12:13:02.042042 22542570456896 run_lib.py:146] step: 1220900, eval_loss: 3.18373e-02
I0213 12:13:19.499238 22542570456896 run_lib.py:133] step: 1220950, training_loss: 3.20146e-02
I0213 12:13:36.737989 22542570456896 run_lib.py:133] step: 1221000, training_loss: 2.38025e-02
I0213 12:13:36.889058 22542570456896 run_lib.py:146] step: 1221000, eval_loss: 2.88624e-02
I0213 12:13:54.319336 22542570456896 run_lib.py:133] step: 1221050, training_loss: 3.30795e-02
I0213 12:14:11.592135 22542570456896 run_lib.py:133] step: 1221100, training_loss: 2.52263e-02
I0213 12:14:11.748450 22542570456896 run_lib.py:146] step: 1221100, eval_loss: 3.11745e-02
I0213 12:14:29.155951 22542570456896 run_lib.py:133] step: 1221150, training_loss: 2.71988e-02
I0213 12:14:46.477596 22542570456896 run_lib.py:133] step: 1221200, training_loss: 2.52070e-02
I0213 12:14:46.634264 22542570456896 run_lib.py:146] step: 1221200, eval_loss: 3.04388e-02
I0213 12:15:04.022393 22542570456896 run_lib.py:133] step: 1221250, training_loss: 3.03816e-02
I0213 12:15:21.233547 22542570456896 run_lib.py:133] step: 1221300, training_loss: 2.91335e-02
I0213 12:15:21.391246 22542570456896 run_lib.py:146] step: 1221300, eval_loss: 3.17535e-02
I0213 12:15:38.657451 22542570456896 run_lib.py:133] step: 1221350, training_loss: 2.14106e-02
I0213 12:15:56.062526 22542570456896 run_lib.py:133] step: 1221400, training_loss: 2.22060e-02
I0213 12:15:56.230287 22542570456896 run_lib.py:146] step: 1221400, eval_loss: 3.00192e-02
I0213 12:16:13.551714 22542570456896 run_lib.py:133] step: 1221450, training_loss: 3.04258e-02
I0213 12:16:30.817771 22542570456896 run_lib.py:133] step: 1221500, training_loss: 3.43309e-02
I0213 12:16:30.965859 22542570456896 run_lib.py:146] step: 1221500, eval_loss: 2.03559e-02
I0213 12:16:48.381189 22542570456896 run_lib.py:133] step: 1221550, training_loss: 2.80407e-02
I0213 12:17:05.641543 22542570456896 run_lib.py:133] step: 1221600, training_loss: 2.72666e-02
I0213 12:17:05.795249 22542570456896 run_lib.py:146] step: 1221600, eval_loss: 2.91491e-02
I0213 12:17:23.163176 22542570456896 run_lib.py:133] step: 1221650, training_loss: 2.53312e-02
I0213 12:17:40.392338 22542570456896 run_lib.py:133] step: 1221700, training_loss: 2.70402e-02
I0213 12:17:40.565322 22542570456896 run_lib.py:146] step: 1221700, eval_loss: 3.16914e-02
I0213 12:17:57.881675 22542570456896 run_lib.py:133] step: 1221750, training_loss: 3.39566e-02
I0213 12:18:15.328341 22542570456896 run_lib.py:133] step: 1221800, training_loss: 2.40519e-02
I0213 12:18:15.482440 22542570456896 run_lib.py:146] step: 1221800, eval_loss: 3.65221e-02
I0213 12:18:32.768777 22542570456896 run_lib.py:133] step: 1221850, training_loss: 2.15419e-02
I0213 12:18:49.997471 22542570456896 run_lib.py:133] step: 1221900, training_loss: 2.91364e-02
I0213 12:18:50.147214 22542570456896 run_lib.py:146] step: 1221900, eval_loss: 3.25201e-02
I0213 12:19:07.392290 22542570456896 run_lib.py:133] step: 1221950, training_loss: 2.32858e-02
I0213 12:19:24.780691 22542570456896 run_lib.py:133] step: 1222000, training_loss: 2.67720e-02
I0213 12:19:24.941334 22542570456896 run_lib.py:146] step: 1222000, eval_loss: 3.52131e-02
I0213 12:19:42.268951 22542570456896 run_lib.py:133] step: 1222050, training_loss: 3.20124e-02
I0213 12:19:59.612071 22542570456896 run_lib.py:133] step: 1222100, training_loss: 3.15976e-02
I0213 12:19:59.768311 22542570456896 run_lib.py:146] step: 1222100, eval_loss: 3.23009e-02
I0213 12:20:17.022575 22542570456896 run_lib.py:133] step: 1222150, training_loss: 2.63681e-02
I0213 12:20:34.256818 22542570456896 run_lib.py:133] step: 1222200, training_loss: 3.45714e-02
I0213 12:20:34.411463 22542570456896 run_lib.py:146] step: 1222200, eval_loss: 3.16992e-02
I0213 12:20:51.810107 22542570456896 run_lib.py:133] step: 1222250, training_loss: 2.45661e-02
I0213 12:21:09.131170 22542570456896 run_lib.py:133] step: 1222300, training_loss: 2.43655e-02
I0213 12:21:09.292350 22542570456896 run_lib.py:146] step: 1222300, eval_loss: 2.63430e-02
I0213 12:21:26.577321 22542570456896 run_lib.py:133] step: 1222350, training_loss: 3.05271e-02
I0213 12:21:43.848851 22542570456896 run_lib.py:133] step: 1222400, training_loss: 2.91166e-02
I0213 12:21:44.002324 22542570456896 run_lib.py:146] step: 1222400, eval_loss: 3.58058e-02
I0213 12:22:01.455633 22542570456896 run_lib.py:133] step: 1222450, training_loss: 2.65591e-02
I0213 12:22:18.715512 22542570456896 run_lib.py:133] step: 1222500, training_loss: 2.48116e-02
I0213 12:22:18.874467 22542570456896 run_lib.py:146] step: 1222500, eval_loss: 3.17809e-02
I0213 12:22:36.217166 22542570456896 run_lib.py:133] step: 1222550, training_loss: 1.75305e-02
I0213 12:22:53.488120 22542570456896 run_lib.py:133] step: 1222600, training_loss: 2.70226e-02
I0213 12:22:53.662329 22542570456896 run_lib.py:146] step: 1222600, eval_loss: 3.30987e-02
I0213 12:23:11.130257 22542570456896 run_lib.py:133] step: 1222650, training_loss: 2.79225e-02
I0213 12:23:28.379098 22542570456896 run_lib.py:133] step: 1222700, training_loss: 2.29616e-02
I0213 12:23:28.533477 22542570456896 run_lib.py:146] step: 1222700, eval_loss: 2.57470e-02
I0213 12:23:45.766509 22542570456896 run_lib.py:133] step: 1222750, training_loss: 2.67155e-02
I0213 12:24:03.164100 22542570456896 run_lib.py:133] step: 1222800, training_loss: 2.63713e-02
I0213 12:24:03.316096 22542570456896 run_lib.py:146] step: 1222800, eval_loss: 3.10244e-02
I0213 12:24:20.567508 22542570456896 run_lib.py:133] step: 1222850, training_loss: 2.56650e-02
I0213 12:24:37.988866 22542570456896 run_lib.py:133] step: 1222900, training_loss: 2.40077e-02
I0213 12:24:38.141503 22542570456896 run_lib.py:146] step: 1222900, eval_loss: 2.81246e-02
I0213 12:24:55.443547 22542570456896 run_lib.py:133] step: 1222950, training_loss: 2.99071e-02
I0213 12:25:12.688768 22542570456896 run_lib.py:133] step: 1223000, training_loss: 4.07482e-02
I0213 12:25:12.844369 22542570456896 run_lib.py:146] step: 1223000, eval_loss: 3.03630e-02
I0213 12:25:30.282685 22542570456896 run_lib.py:133] step: 1223050, training_loss: 2.30577e-02
I0213 12:25:47.537997 22542570456896 run_lib.py:133] step: 1223100, training_loss: 2.94963e-02
I0213 12:25:47.695454 22542570456896 run_lib.py:146] step: 1223100, eval_loss: 3.25252e-02
I0213 12:26:04.968582 22542570456896 run_lib.py:133] step: 1223150, training_loss: 2.87927e-02
I0213 12:26:22.432331 22542570456896 run_lib.py:133] step: 1223200, training_loss: 2.58574e-02
I0213 12:26:22.596202 22542570456896 run_lib.py:146] step: 1223200, eval_loss: 2.88746e-02
I0213 12:26:39.844224 22542570456896 run_lib.py:133] step: 1223250, training_loss: 3.19773e-02
I0213 12:26:57.088474 22542570456896 run_lib.py:133] step: 1223300, training_loss: 2.62223e-02
I0213 12:26:57.416334 22542570456896 run_lib.py:146] step: 1223300, eval_loss: 3.24020e-02
I0213 12:27:14.641526 22542570456896 run_lib.py:133] step: 1223350, training_loss: 2.49813e-02
I0213 12:27:31.887323 22542570456896 run_lib.py:133] step: 1223400, training_loss: 2.54042e-02
I0213 12:27:32.043257 22542570456896 run_lib.py:146] step: 1223400, eval_loss: 3.34528e-02
I0213 12:27:49.329305 22542570456896 run_lib.py:133] step: 1223450, training_loss: 2.24216e-02
I0213 12:28:06.632051 22542570456896 run_lib.py:133] step: 1223500, training_loss: 2.41909e-02
I0213 12:28:06.791459 22542570456896 run_lib.py:146] step: 1223500, eval_loss: 2.51646e-02
I0213 12:28:24.242887 22542570456896 run_lib.py:133] step: 1223550, training_loss: 2.29362e-02
I0213 12:28:41.583532 22542570456896 run_lib.py:133] step: 1223600, training_loss: 2.34823e-02
I0213 12:28:41.740483 22542570456896 run_lib.py:146] step: 1223600, eval_loss: 3.00704e-02
I0213 12:28:58.966339 22542570456896 run_lib.py:133] step: 1223650, training_loss: 2.68025e-02
I0213 12:29:16.230348 22542570456896 run_lib.py:133] step: 1223700, training_loss: 2.90813e-02
I0213 12:29:16.396401 22542570456896 run_lib.py:146] step: 1223700, eval_loss: 2.70836e-02
I0213 12:29:33.811915 22542570456896 run_lib.py:133] step: 1223750, training_loss: 2.51798e-02
I0213 12:29:51.194400 22542570456896 run_lib.py:133] step: 1223800, training_loss: 1.86297e-02
I0213 12:29:51.347971 22542570456896 run_lib.py:146] step: 1223800, eval_loss: 2.74657e-02
I0213 12:30:08.592369 22542570456896 run_lib.py:133] step: 1223850, training_loss: 2.56837e-02
I0213 12:30:25.846865 22542570456896 run_lib.py:133] step: 1223900, training_loss: 3.23736e-02
I0213 12:30:25.996134 22542570456896 run_lib.py:146] step: 1223900, eval_loss: 2.54518e-02
I0213 12:30:43.427587 22542570456896 run_lib.py:133] step: 1223950, training_loss: 2.73470e-02
I0213 12:31:00.679565 22542570456896 run_lib.py:133] step: 1224000, training_loss: 3.06327e-02
I0213 12:31:00.858224 22542570456896 run_lib.py:146] step: 1224000, eval_loss: 3.18233e-02
I0213 12:31:18.308824 22542570456896 run_lib.py:133] step: 1224050, training_loss: 2.79683e-02
I0213 12:31:35.571767 22542570456896 run_lib.py:133] step: 1224100, training_loss: 3.52048e-02
I0213 12:31:35.728429 22542570456896 run_lib.py:146] step: 1224100, eval_loss: 3.07666e-02
I0213 12:31:53.115543 22542570456896 run_lib.py:133] step: 1224150, training_loss: 2.05817e-02
I0213 12:32:10.364031 22542570456896 run_lib.py:133] step: 1224200, training_loss: 3.06213e-02
I0213 12:32:10.517102 22542570456896 run_lib.py:146] step: 1224200, eval_loss: 2.66994e-02
I0213 12:32:27.777472 22542570456896 run_lib.py:133] step: 1224250, training_loss: 2.28585e-02
I0213 12:32:45.129415 22542570456896 run_lib.py:133] step: 1224300, training_loss: 2.40324e-02
I0213 12:32:45.280012 22542570456896 run_lib.py:146] step: 1224300, eval_loss: 2.58819e-02
I0213 12:33:02.583983 22542570456896 run_lib.py:133] step: 1224350, training_loss: 2.25938e-02
I0213 12:33:20.044860 22542570456896 run_lib.py:133] step: 1224400, training_loss: 2.53149e-02
I0213 12:33:20.197501 22542570456896 run_lib.py:146] step: 1224400, eval_loss: 3.36119e-02
I0213 12:33:37.473137 22542570456896 run_lib.py:133] step: 1224450, training_loss: 2.96235e-02
I0213 12:33:54.770469 22542570456896 run_lib.py:133] step: 1224500, training_loss: 3.06356e-02
I0213 12:33:54.932414 22542570456896 run_lib.py:146] step: 1224500, eval_loss: 2.85424e-02
I0213 12:34:12.289078 22542570456896 run_lib.py:133] step: 1224550, training_loss: 2.89424e-02
I0213 12:34:29.548643 22542570456896 run_lib.py:133] step: 1224600, training_loss: 2.75269e-02
I0213 12:34:29.716224 22542570456896 run_lib.py:146] step: 1224600, eval_loss: 3.34415e-02
I0213 12:34:47.021729 22542570456896 run_lib.py:133] step: 1224650, training_loss: 2.95402e-02
I0213 12:35:04.268505 22542570456896 run_lib.py:133] step: 1224700, training_loss: 3.26202e-02
I0213 12:35:04.427643 22542570456896 run_lib.py:146] step: 1224700, eval_loss: 3.22123e-02
I0213 12:35:21.851722 22542570456896 run_lib.py:133] step: 1224750, training_loss: 2.75702e-02
I0213 12:35:39.112933 22542570456896 run_lib.py:133] step: 1224800, training_loss: 3.08349e-02
I0213 12:35:39.262300 22542570456896 run_lib.py:146] step: 1224800, eval_loss: 3.08124e-02
I0213 12:35:56.563363 22542570456896 run_lib.py:133] step: 1224850, training_loss: 2.57704e-02
I0213 12:36:13.861002 22542570456896 run_lib.py:133] step: 1224900, training_loss: 2.80265e-02
I0213 12:36:14.028452 22542570456896 run_lib.py:146] step: 1224900, eval_loss: 2.19327e-02
I0213 12:36:31.309179 22542570456896 run_lib.py:133] step: 1224950, training_loss: 2.18684e-02
I0213 12:36:48.591698 22542570456896 run_lib.py:133] step: 1225000, training_loss: 2.42600e-02
I0213 12:36:48.748446 22542570456896 run_lib.py:146] step: 1225000, eval_loss: 3.00040e-02
I0213 12:37:06.142701 22542570456896 run_lib.py:133] step: 1225050, training_loss: 3.05061e-02
I0213 12:37:23.408830 22542570456896 run_lib.py:133] step: 1225100, training_loss: 2.81420e-02
I0213 12:37:23.562244 22542570456896 run_lib.py:146] step: 1225100, eval_loss: 2.97321e-02
I0213 12:37:40.839569 22542570456896 run_lib.py:133] step: 1225150, training_loss: 3.18398e-02
I0213 12:37:58.199248 22542570456896 run_lib.py:133] step: 1225200, training_loss: 2.05378e-02
I0213 12:37:58.353446 22542570456896 run_lib.py:146] step: 1225200, eval_loss: 2.49424e-02
I0213 12:38:15.792877 22542570456896 run_lib.py:133] step: 1225250, training_loss: 2.40273e-02
I0213 12:38:33.006456 22542570456896 run_lib.py:133] step: 1225300, training_loss: 2.89244e-02
I0213 12:38:33.157324 22542570456896 run_lib.py:146] step: 1225300, eval_loss: 2.88811e-02
I0213 12:38:50.563077 22542570456896 run_lib.py:133] step: 1225350, training_loss: 2.56509e-02
I0213 12:39:07.847692 22542570456896 run_lib.py:133] step: 1225400, training_loss: 2.59880e-02
I0213 12:39:07.998656 22542570456896 run_lib.py:146] step: 1225400, eval_loss: 3.92643e-02
I0213 12:39:25.416389 22542570456896 run_lib.py:133] step: 1225450, training_loss: 2.60236e-02
I0213 12:39:42.689208 22542570456896 run_lib.py:133] step: 1225500, training_loss: 2.19469e-02
I0213 12:39:42.850223 22542570456896 run_lib.py:146] step: 1225500, eval_loss: 2.93068e-02
I0213 12:40:00.303282 22542570456896 run_lib.py:133] step: 1225550, training_loss: 2.47618e-02
I0213 12:40:17.545176 22542570456896 run_lib.py:133] step: 1225600, training_loss: 2.83401e-02
I0213 12:40:17.696350 22542570456896 run_lib.py:146] step: 1225600, eval_loss: 3.02130e-02
I0213 12:40:34.950181 22542570456896 run_lib.py:133] step: 1225650, training_loss: 3.39744e-02
I0213 12:40:52.350964 22542570456896 run_lib.py:133] step: 1225700, training_loss: 3.09067e-02
I0213 12:40:52.503180 22542570456896 run_lib.py:146] step: 1225700, eval_loss: 2.94156e-02
I0213 12:41:09.812473 22542570456896 run_lib.py:133] step: 1225750, training_loss: 2.62603e-02
I0213 12:41:27.089279 22542570456896 run_lib.py:133] step: 1225800, training_loss: 2.99402e-02
I0213 12:41:27.246440 22542570456896 run_lib.py:146] step: 1225800, eval_loss: 2.94986e-02
I0213 12:41:44.672507 22542570456896 run_lib.py:133] step: 1225850, training_loss: 3.10402e-02
I0213 12:42:02.057235 22542570456896 run_lib.py:133] step: 1225900, training_loss: 2.96044e-02
I0213 12:42:02.215737 22542570456896 run_lib.py:146] step: 1225900, eval_loss: 2.55919e-02
I0213 12:42:19.428004 22542570456896 run_lib.py:133] step: 1225950, training_loss: 2.26581e-02
I0213 12:42:36.643276 22542570456896 run_lib.py:133] step: 1226000, training_loss: 2.55290e-02
I0213 12:42:36.809193 22542570456896 run_lib.py:146] step: 1226000, eval_loss: 3.85232e-02
I0213 12:42:54.163028 22542570456896 run_lib.py:133] step: 1226050, training_loss: 2.77016e-02
I0213 12:43:11.584922 22542570456896 run_lib.py:133] step: 1226100, training_loss: 3.30793e-02
I0213 12:43:11.738032 22542570456896 run_lib.py:146] step: 1226100, eval_loss: 2.71461e-02
I0213 12:43:29.041242 22542570456896 run_lib.py:133] step: 1226150, training_loss: 2.57486e-02
I0213 12:43:46.288700 22542570456896 run_lib.py:133] step: 1226200, training_loss: 3.02489e-02
I0213 12:43:46.442037 22542570456896 run_lib.py:146] step: 1226200, eval_loss: 2.63286e-02
I0213 12:44:03.666336 22542570456896 run_lib.py:133] step: 1226250, training_loss: 2.27604e-02
I0213 12:44:21.096198 22542570456896 run_lib.py:133] step: 1226300, training_loss: 2.62531e-02
I0213 12:44:21.252474 22542570456896 run_lib.py:146] step: 1226300, eval_loss: 2.68425e-02
I0213 12:44:38.639038 22542570456896 run_lib.py:133] step: 1226350, training_loss: 2.30882e-02
I0213 12:44:55.956662 22542570456896 run_lib.py:133] step: 1226400, training_loss: 2.54883e-02
I0213 12:44:56.112249 22542570456896 run_lib.py:146] step: 1226400, eval_loss: 2.68873e-02
I0213 12:45:13.352914 22542570456896 run_lib.py:133] step: 1226450, training_loss: 3.07054e-02
I0213 12:45:30.541646 22542570456896 run_lib.py:133] step: 1226500, training_loss: 2.88699e-02
I0213 12:45:30.695250 22542570456896 run_lib.py:146] step: 1226500, eval_loss: 3.03532e-02
I0213 12:45:48.091303 22542570456896 run_lib.py:133] step: 1226550, training_loss: 2.68492e-02
I0213 12:46:05.479149 22542570456896 run_lib.py:133] step: 1226600, training_loss: 2.69103e-02
I0213 12:46:05.634757 22542570456896 run_lib.py:146] step: 1226600, eval_loss: 2.30499e-02
I0213 12:46:22.914203 22542570456896 run_lib.py:133] step: 1226650, training_loss: 2.12196e-02
I0213 12:46:40.208253 22542570456896 run_lib.py:133] step: 1226700, training_loss: 3.29642e-02
I0213 12:46:40.358279 22542570456896 run_lib.py:146] step: 1226700, eval_loss: 3.02209e-02
I0213 12:46:57.867366 22542570456896 run_lib.py:133] step: 1226750, training_loss: 2.90551e-02
I0213 12:47:15.269426 22542570456896 run_lib.py:133] step: 1226800, training_loss: 2.52922e-02
I0213 12:47:15.425492 22542570456896 run_lib.py:146] step: 1226800, eval_loss: 3.26816e-02
I0213 12:47:33.093610 22542570456896 run_lib.py:133] step: 1226850, training_loss: 2.52956e-02
I0213 12:47:50.659292 22542570456896 run_lib.py:133] step: 1226900, training_loss: 2.48295e-02
I0213 12:47:50.827462 22542570456896 run_lib.py:146] step: 1226900, eval_loss: 3.31829e-02
I0213 12:48:08.522362 22542570456896 run_lib.py:133] step: 1226950, training_loss: 2.71057e-02
I0213 12:48:25.982613 22542570456896 run_lib.py:133] step: 1227000, training_loss: 2.42666e-02
I0213 12:48:26.140426 22542570456896 run_lib.py:146] step: 1227000, eval_loss: 2.55709e-02
I0213 12:48:43.617074 22542570456896 run_lib.py:133] step: 1227050, training_loss: 3.00189e-02
I0213 12:49:01.178562 22542570456896 run_lib.py:133] step: 1227100, training_loss: 2.64365e-02
I0213 12:49:01.337183 22542570456896 run_lib.py:146] step: 1227100, eval_loss: 2.77615e-02
I0213 12:49:18.889386 22542570456896 run_lib.py:133] step: 1227150, training_loss: 3.10763e-02
I0213 12:49:36.397061 22542570456896 run_lib.py:133] step: 1227200, training_loss: 2.32097e-02
I0213 12:49:36.547342 22542570456896 run_lib.py:146] step: 1227200, eval_loss: 2.46939e-02
I0213 12:49:53.784779 22542570456896 run_lib.py:133] step: 1227250, training_loss: 2.41860e-02
I0213 12:50:11.157449 22542570456896 run_lib.py:133] step: 1227300, training_loss: 2.83172e-02
I0213 12:50:11.315797 22542570456896 run_lib.py:146] step: 1227300, eval_loss: 2.71301e-02
I0213 12:50:28.961897 22542570456896 run_lib.py:133] step: 1227350, training_loss: 2.74870e-02
I0213 12:50:46.470514 22542570456896 run_lib.py:133] step: 1227400, training_loss: 2.41216e-02
I0213 12:50:46.654535 22542570456896 run_lib.py:146] step: 1227400, eval_loss: 2.90290e-02
I0213 12:51:04.217607 22542570456896 run_lib.py:133] step: 1227450, training_loss: 2.57524e-02
I0213 12:51:21.899986 22542570456896 run_lib.py:133] step: 1227500, training_loss: 2.95353e-02
I0213 12:51:22.065454 22542570456896 run_lib.py:146] step: 1227500, eval_loss: 2.97938e-02
I0213 12:51:39.566235 22542570456896 run_lib.py:133] step: 1227550, training_loss: 3.02241e-02
I0213 12:51:57.033648 22542570456896 run_lib.py:133] step: 1227600, training_loss: 2.28092e-02
I0213 12:51:57.192522 22542570456896 run_lib.py:146] step: 1227600, eval_loss: 2.97790e-02
I0213 12:52:14.764112 22542570456896 run_lib.py:133] step: 1227650, training_loss: 2.65552e-02
I0213 12:52:32.305613 22542570456896 run_lib.py:133] step: 1227700, training_loss: 2.93243e-02
I0213 12:52:32.472697 22542570456896 run_lib.py:146] step: 1227700, eval_loss: 2.80844e-02
I0213 12:52:49.972030 22542570456896 run_lib.py:133] step: 1227750, training_loss: 2.97446e-02
I0213 12:53:07.470224 22542570456896 run_lib.py:133] step: 1227800, training_loss: 2.33470e-02
I0213 12:53:07.629557 22542570456896 run_lib.py:146] step: 1227800, eval_loss: 2.75806e-02
I0213 12:53:25.219384 22542570456896 run_lib.py:133] step: 1227850, training_loss: 2.08849e-02
I0213 12:53:42.775178 22542570456896 run_lib.py:133] step: 1227900, training_loss: 2.55711e-02
I0213 12:53:42.941912 22542570456896 run_lib.py:146] step: 1227900, eval_loss: 2.50387e-02
I0213 12:54:00.464463 22542570456896 run_lib.py:133] step: 1227950, training_loss: 3.86811e-02
I0213 12:54:17.959257 22542570456896 run_lib.py:133] step: 1228000, training_loss: 2.45891e-02
I0213 12:54:18.115712 22542570456896 run_lib.py:146] step: 1228000, eval_loss: 2.61078e-02
I0213 12:54:35.778923 22542570456896 run_lib.py:133] step: 1228050, training_loss: 2.73037e-02
I0213 12:54:53.243012 22542570456896 run_lib.py:133] step: 1228100, training_loss: 2.78738e-02
I0213 12:54:53.401458 22542570456896 run_lib.py:146] step: 1228100, eval_loss: 2.47167e-02
I0213 12:55:11.023831 22542570456896 run_lib.py:133] step: 1228150, training_loss: 2.78107e-02
I0213 12:55:28.551542 22542570456896 run_lib.py:133] step: 1228200, training_loss: 2.84517e-02
I0213 12:55:28.720597 22542570456896 run_lib.py:146] step: 1228200, eval_loss: 3.16786e-02
I0213 12:55:46.451040 22542570456896 run_lib.py:133] step: 1228250, training_loss: 2.97573e-02
I0213 12:56:03.930545 22542570456896 run_lib.py:133] step: 1228300, training_loss: 2.15416e-02
I0213 12:56:04.090860 22542570456896 run_lib.py:146] step: 1228300, eval_loss: 2.72670e-02
I0213 12:56:21.702826 22542570456896 run_lib.py:133] step: 1228350, training_loss: 2.90582e-02
I0213 12:56:39.160232 22542570456896 run_lib.py:133] step: 1228400, training_loss: 2.24829e-02
I0213 12:56:39.317533 22542570456896 run_lib.py:146] step: 1228400, eval_loss: 2.95589e-02
I0213 12:56:56.791948 22542570456896 run_lib.py:133] step: 1228450, training_loss: 3.16403e-02
I0213 12:57:14.505664 22542570456896 run_lib.py:133] step: 1228500, training_loss: 2.49329e-02
I0213 12:57:14.664846 22542570456896 run_lib.py:146] step: 1228500, eval_loss: 2.85587e-02
I0213 12:57:32.162875 22542570456896 run_lib.py:133] step: 1228550, training_loss: 3.09903e-02
I0213 12:57:49.602827 22542570456896 run_lib.py:133] step: 1228600, training_loss: 3.17162e-02
I0213 12:57:49.755245 22542570456896 run_lib.py:146] step: 1228600, eval_loss: 2.91666e-02
I0213 12:58:07.412509 22542570456896 run_lib.py:133] step: 1228650, training_loss: 2.86723e-02
I0213 12:58:24.911401 22542570456896 run_lib.py:133] step: 1228700, training_loss: 3.41620e-02
I0213 12:58:25.083708 22542570456896 run_lib.py:146] step: 1228700, eval_loss: 2.82955e-02
I0213 12:58:42.777702 22542570456896 run_lib.py:133] step: 1228750, training_loss: 2.77257e-02
I0213 12:59:00.285819 22542570456896 run_lib.py:133] step: 1228800, training_loss: 3.03188e-02
I0213 12:59:00.447571 22542570456896 run_lib.py:146] step: 1228800, eval_loss: 3.33041e-02
I0213 12:59:17.907280 22542570456896 run_lib.py:133] step: 1228850, training_loss: 2.22181e-02
I0213 12:59:35.576471 22542570456896 run_lib.py:133] step: 1228900, training_loss: 2.67320e-02
I0213 12:59:35.732332 22542570456896 run_lib.py:146] step: 1228900, eval_loss: 3.33234e-02
I0213 12:59:53.220114 22542570456896 run_lib.py:133] step: 1228950, training_loss: 2.60127e-02
I0213 13:00:10.719920 22542570456896 run_lib.py:133] step: 1229000, training_loss: 2.33800e-02
I0213 13:00:10.883475 22542570456896 run_lib.py:146] step: 1229000, eval_loss: 3.58135e-02
I0213 13:00:28.389749 22542570456896 run_lib.py:133] step: 1229050, training_loss: 2.63038e-02
I0213 13:00:46.086908 22542570456896 run_lib.py:133] step: 1229100, training_loss: 2.88863e-02
I0213 13:00:46.239494 22542570456896 run_lib.py:146] step: 1229100, eval_loss: 2.80204e-02
I0213 13:01:03.724799 22542570456896 run_lib.py:133] step: 1229150, training_loss: 2.83081e-02
I0213 13:01:21.258363 22542570456896 run_lib.py:133] step: 1229200, training_loss: 2.42785e-02
I0213 13:01:21.423521 22542570456896 run_lib.py:146] step: 1229200, eval_loss: 3.44631e-02
I0213 13:01:38.866666 22542570456896 run_lib.py:133] step: 1229250, training_loss: 2.71130e-02
I0213 13:01:56.368606 22542570456896 run_lib.py:133] step: 1229300, training_loss: 2.59362e-02
I0213 13:01:56.546478 22542570456896 run_lib.py:146] step: 1229300, eval_loss: 2.85597e-02
I0213 13:02:14.229302 22542570456896 run_lib.py:133] step: 1229350, training_loss: 2.41210e-02
I0213 13:02:31.783285 22542570456896 run_lib.py:133] step: 1229400, training_loss: 2.42161e-02
I0213 13:02:31.940186 22542570456896 run_lib.py:146] step: 1229400, eval_loss: 3.25229e-02
I0213 13:02:49.426814 22542570456896 run_lib.py:133] step: 1229450, training_loss: 2.68461e-02
I0213 13:03:06.859224 22542570456896 run_lib.py:133] step: 1229500, training_loss: 2.79159e-02
I0213 13:03:07.013466 22542570456896 run_lib.py:146] step: 1229500, eval_loss: 3.27279e-02
I0213 13:03:24.635926 22542570456896 run_lib.py:133] step: 1229550, training_loss: 2.52350e-02
I0213 13:03:42.125079 22542570456896 run_lib.py:133] step: 1229600, training_loss: 2.94911e-02
I0213 13:03:42.281776 22542570456896 run_lib.py:146] step: 1229600, eval_loss: 2.41017e-02
I0213 13:03:59.999785 22542570456896 run_lib.py:133] step: 1229650, training_loss: 2.74319e-02
I0213 13:04:17.470725 22542570456896 run_lib.py:133] step: 1229700, training_loss: 3.26184e-02
I0213 13:04:17.629397 22542570456896 run_lib.py:146] step: 1229700, eval_loss: 2.77919e-02
I0213 13:04:35.227166 22542570456896 run_lib.py:133] step: 1229750, training_loss: 2.51831e-02
I0213 13:04:52.669721 22542570456896 run_lib.py:133] step: 1229800, training_loss: 2.44639e-02
I0213 13:04:52.827424 22542570456896 run_lib.py:146] step: 1229800, eval_loss: 2.28545e-02
I0213 13:05:10.338501 22542570456896 run_lib.py:133] step: 1229850, training_loss: 2.57183e-02
I0213 13:05:28.070938 22542570456896 run_lib.py:133] step: 1229900, training_loss: 2.37791e-02
I0213 13:05:28.229698 22542570456896 run_lib.py:146] step: 1229900, eval_loss: 2.81447e-02
I0213 13:05:45.725600 22542570456896 run_lib.py:133] step: 1229950, training_loss: 2.22578e-02
I0213 13:06:03.362911 22542570456896 run_lib.py:133] step: 1230000, training_loss: 2.75024e-02
I0213 13:06:04.106073 22542570456896 run_lib.py:146] step: 1230000, eval_loss: 3.13315e-02
I0213 13:06:24.314037 22542570456896 run_lib.py:133] step: 1230050, training_loss: 2.12792e-02
I0213 13:06:41.768391 22542570456896 run_lib.py:133] step: 1230100, training_loss: 2.56557e-02
I0213 13:06:41.927589 22542570456896 run_lib.py:146] step: 1230100, eval_loss: 2.79650e-02
I0213 13:06:59.425982 22542570456896 run_lib.py:133] step: 1230150, training_loss: 2.27622e-02
I0213 13:07:16.913779 22542570456896 run_lib.py:133] step: 1230200, training_loss: 3.23895e-02
I0213 13:07:17.072666 22542570456896 run_lib.py:146] step: 1230200, eval_loss: 2.78189e-02
I0213 13:07:34.746388 22542570456896 run_lib.py:133] step: 1230250, training_loss: 3.27052e-02
I0213 13:07:52.327123 22542570456896 run_lib.py:133] step: 1230300, training_loss: 2.77118e-02
I0213 13:07:52.486731 22542570456896 run_lib.py:146] step: 1230300, eval_loss: 2.62453e-02
I0213 13:08:09.939352 22542570456896 run_lib.py:133] step: 1230350, training_loss: 2.21580e-02
I0213 13:08:27.387248 22542570456896 run_lib.py:133] step: 1230400, training_loss: 2.26633e-02
I0213 13:08:27.557493 22542570456896 run_lib.py:146] step: 1230400, eval_loss: 2.56645e-02
I0213 13:08:45.170899 22542570456896 run_lib.py:133] step: 1230450, training_loss: 2.41058e-02
I0213 13:09:02.659400 22542570456896 run_lib.py:133] step: 1230500, training_loss: 3.44472e-02
I0213 13:09:02.816689 22542570456896 run_lib.py:146] step: 1230500, eval_loss: 3.10949e-02
I0213 13:09:20.538500 22542570456896 run_lib.py:133] step: 1230550, training_loss: 3.23755e-02
I0213 13:09:38.023124 22542570456896 run_lib.py:133] step: 1230600, training_loss: 2.44863e-02
I0213 13:09:38.176545 22542570456896 run_lib.py:146] step: 1230600, eval_loss: 3.22249e-02
I0213 13:09:55.816003 22542570456896 run_lib.py:133] step: 1230650, training_loss: 2.72317e-02
I0213 13:10:13.298025 22542570456896 run_lib.py:133] step: 1230700, training_loss: 2.49733e-02
I0213 13:10:13.468258 22542570456896 run_lib.py:146] step: 1230700, eval_loss: 2.86290e-02
I0213 13:10:31.176560 22542570456896 run_lib.py:133] step: 1230750, training_loss: 2.96968e-02
I0213 13:10:48.652382 22542570456896 run_lib.py:133] step: 1230800, training_loss: 2.56263e-02
I0213 13:10:48.812728 22542570456896 run_lib.py:146] step: 1230800, eval_loss: 2.69755e-02
I0213 13:11:06.267036 22542570456896 run_lib.py:133] step: 1230850, training_loss: 3.02107e-02
I0213 13:11:23.878081 22542570456896 run_lib.py:133] step: 1230900, training_loss: 2.75963e-02
I0213 13:11:24.034503 22542570456896 run_lib.py:146] step: 1230900, eval_loss: 3.31446e-02
I0213 13:11:41.484660 22542570456896 run_lib.py:133] step: 1230950, training_loss: 2.61979e-02
I0213 13:11:58.949721 22542570456896 run_lib.py:133] step: 1231000, training_loss: 2.90555e-02
I0213 13:11:59.104688 22542570456896 run_lib.py:146] step: 1231000, eval_loss: 2.64771e-02
I0213 13:12:16.831539 22542570456896 run_lib.py:133] step: 1231050, training_loss: 2.67004e-02
I0213 13:12:34.456042 22542570456896 run_lib.py:133] step: 1231100, training_loss: 2.27960e-02
I0213 13:12:34.608377 22542570456896 run_lib.py:146] step: 1231100, eval_loss: 2.54946e-02
I0213 13:12:52.059517 22542570456896 run_lib.py:133] step: 1231150, training_loss: 2.34747e-02
I0213 13:13:09.517592 22542570456896 run_lib.py:133] step: 1231200, training_loss: 2.79206e-02
I0213 13:13:09.677740 22542570456896 run_lib.py:146] step: 1231200, eval_loss: 2.69204e-02
I0213 13:13:27.176385 22542570456896 run_lib.py:133] step: 1231250, training_loss: 3.23114e-02
I0213 13:13:44.869014 22542570456896 run_lib.py:133] step: 1231300, training_loss: 3.15243e-02
I0213 13:13:45.031677 22542570456896 run_lib.py:146] step: 1231300, eval_loss: 2.98634e-02
I0213 13:14:02.515877 22542570456896 run_lib.py:133] step: 1231350, training_loss: 2.70506e-02
I0213 13:14:19.960547 22542570456896 run_lib.py:133] step: 1231400, training_loss: 3.08787e-02
I0213 13:14:20.118448 22542570456896 run_lib.py:146] step: 1231400, eval_loss: 2.76566e-02
I0213 13:14:37.585138 22542570456896 run_lib.py:133] step: 1231450, training_loss: 2.46749e-02
I0213 13:14:55.246558 22542570456896 run_lib.py:133] step: 1231500, training_loss: 2.36443e-02
I0213 13:14:55.399253 22542570456896 run_lib.py:146] step: 1231500, eval_loss: 3.11979e-02
I0213 13:15:12.867666 22542570456896 run_lib.py:133] step: 1231550, training_loss: 2.99757e-02
I0213 13:15:30.468353 22542570456896 run_lib.py:133] step: 1231600, training_loss: 2.42224e-02
I0213 13:15:30.634558 22542570456896 run_lib.py:146] step: 1231600, eval_loss: 2.08640e-02
I0213 13:15:48.122109 22542570456896 run_lib.py:133] step: 1231650, training_loss: 2.39113e-02
I0213 13:16:05.610682 22542570456896 run_lib.py:133] step: 1231700, training_loss: 2.02769e-02
I0213 13:16:05.771703 22542570456896 run_lib.py:146] step: 1231700, eval_loss: 2.80870e-02
I0213 13:16:23.426298 22542570456896 run_lib.py:133] step: 1231750, training_loss: 3.29541e-02
I0213 13:16:40.953316 22542570456896 run_lib.py:133] step: 1231800, training_loss: 2.70145e-02
I0213 13:16:41.109434 22542570456896 run_lib.py:146] step: 1231800, eval_loss: 3.43891e-02
I0213 13:16:58.598433 22542570456896 run_lib.py:133] step: 1231850, training_loss: 2.49943e-02
I0213 13:17:16.114640 22542570456896 run_lib.py:133] step: 1231900, training_loss: 2.20492e-02
I0213 13:17:16.273761 22542570456896 run_lib.py:146] step: 1231900, eval_loss: 2.65307e-02
I0213 13:17:33.965044 22542570456896 run_lib.py:133] step: 1231950, training_loss: 3.41921e-02
I0213 13:17:51.449389 22542570456896 run_lib.py:133] step: 1232000, training_loss: 2.58396e-02
I0213 13:17:51.608560 22542570456896 run_lib.py:146] step: 1232000, eval_loss: 2.15161e-02
I0213 13:18:09.216071 22542570456896 run_lib.py:133] step: 1232050, training_loss: 2.72609e-02
I0213 13:18:26.718126 22542570456896 run_lib.py:133] step: 1232100, training_loss: 2.66927e-02
I0213 13:18:26.891603 22542570456896 run_lib.py:146] step: 1232100, eval_loss: 3.37217e-02
I0213 13:18:44.585146 22542570456896 run_lib.py:133] step: 1232150, training_loss: 2.39340e-02
I0213 13:19:02.115363 22542570456896 run_lib.py:133] step: 1232200, training_loss: 2.12291e-02
I0213 13:19:02.277658 22542570456896 run_lib.py:146] step: 1232200, eval_loss: 2.43587e-02
I0213 13:19:19.741142 22542570456896 run_lib.py:133] step: 1232250, training_loss: 2.87639e-02
I0213 13:19:37.362563 22542570456896 run_lib.py:133] step: 1232300, training_loss: 3.50738e-02
I0213 13:19:37.519493 22542570456896 run_lib.py:146] step: 1232300, eval_loss: 2.68630e-02
I0213 13:19:54.981258 22542570456896 run_lib.py:133] step: 1232350, training_loss: 2.84257e-02
I0213 13:20:12.673583 22542570456896 run_lib.py:133] step: 1232400, training_loss: 2.49270e-02
I0213 13:20:12.835280 22542570456896 run_lib.py:146] step: 1232400, eval_loss: 3.22767e-02
I0213 13:20:30.325203 22542570456896 run_lib.py:133] step: 1232450, training_loss: 3.07218e-02
I0213 13:20:47.772696 22542570456896 run_lib.py:133] step: 1232500, training_loss: 2.86864e-02
I0213 13:20:47.926545 22542570456896 run_lib.py:146] step: 1232500, eval_loss: 2.00508e-02
I0213 13:21:05.614568 22542570456896 run_lib.py:133] step: 1232550, training_loss: 2.11730e-02
I0213 13:21:23.122990 22542570456896 run_lib.py:133] step: 1232600, training_loss: 2.84120e-02
I0213 13:21:23.280444 22542570456896 run_lib.py:146] step: 1232600, eval_loss: 2.96327e-02
I0213 13:21:40.739148 22542570456896 run_lib.py:133] step: 1232650, training_loss: 2.75641e-02
I0213 13:21:58.393640 22542570456896 run_lib.py:133] step: 1232700, training_loss: 2.72414e-02
I0213 13:21:58.571548 22542570456896 run_lib.py:146] step: 1232700, eval_loss: 3.31047e-02
I0213 13:22:16.093966 22542570456896 run_lib.py:133] step: 1232750, training_loss: 2.43206e-02
I0213 13:22:33.589638 22542570456896 run_lib.py:133] step: 1232800, training_loss: 2.40134e-02
I0213 13:22:33.754187 22542570456896 run_lib.py:146] step: 1232800, eval_loss: 3.01605e-02
I0213 13:22:51.372976 22542570456896 run_lib.py:133] step: 1232850, training_loss: 2.65863e-02
I0213 13:23:08.828067 22542570456896 run_lib.py:133] step: 1232900, training_loss: 2.81450e-02
I0213 13:23:08.984509 22542570456896 run_lib.py:146] step: 1232900, eval_loss: 2.05870e-02
I0213 13:23:26.481103 22542570456896 run_lib.py:133] step: 1232950, training_loss: 2.37676e-02
I0213 13:23:43.959696 22542570456896 run_lib.py:133] step: 1233000, training_loss: 2.90929e-02
I0213 13:23:44.115545 22542570456896 run_lib.py:146] step: 1233000, eval_loss: 3.05124e-02
I0213 13:24:01.865143 22542570456896 run_lib.py:133] step: 1233050, training_loss: 2.33947e-02
I0213 13:24:19.475328 22542570456896 run_lib.py:133] step: 1233100, training_loss: 2.53478e-02
I0213 13:24:19.634449 22542570456896 run_lib.py:146] step: 1233100, eval_loss: 3.22158e-02
I0213 13:24:37.093891 22542570456896 run_lib.py:133] step: 1233150, training_loss: 2.73981e-02
I0213 13:24:54.556911 22542570456896 run_lib.py:133] step: 1233200, training_loss: 2.73704e-02
I0213 13:24:54.715443 22542570456896 run_lib.py:146] step: 1233200, eval_loss: 2.76568e-02
I0213 13:25:12.373766 22542570456896 run_lib.py:133] step: 1233250, training_loss: 2.84711e-02
I0213 13:25:29.900082 22542570456896 run_lib.py:133] step: 1233300, training_loss: 2.60457e-02
I0213 13:25:30.053690 22542570456896 run_lib.py:146] step: 1233300, eval_loss: 3.13406e-02
I0213 13:25:47.645555 22542570456896 run_lib.py:133] step: 1233350, training_loss: 2.22149e-02
I0213 13:26:05.030560 22542570456896 run_lib.py:133] step: 1233400, training_loss: 3.32376e-02
I0213 13:26:05.183445 22542570456896 run_lib.py:146] step: 1233400, eval_loss: 2.55105e-02
I0213 13:26:22.695922 22542570456896 run_lib.py:133] step: 1233450, training_loss: 2.87460e-02
I0213 13:26:40.037613 22542570456896 run_lib.py:133] step: 1233500, training_loss: 2.69703e-02
I0213 13:26:40.200310 22542570456896 run_lib.py:146] step: 1233500, eval_loss: 2.96270e-02
I0213 13:26:57.695203 22542570456896 run_lib.py:133] step: 1233550, training_loss: 2.63534e-02
I0213 13:27:15.172407 22542570456896 run_lib.py:133] step: 1233600, training_loss: 3.09610e-02
I0213 13:27:15.343370 22542570456896 run_lib.py:146] step: 1233600, eval_loss: 3.14363e-02
I0213 13:27:32.752028 22542570456896 run_lib.py:133] step: 1233650, training_loss: 2.07206e-02
I0213 13:27:50.302252 22542570456896 run_lib.py:133] step: 1233700, training_loss: 2.26268e-02
I0213 13:27:50.457582 22542570456896 run_lib.py:146] step: 1233700, eval_loss: 2.74098e-02
I0213 13:28:07.864416 22542570456896 run_lib.py:133] step: 1233750, training_loss: 2.80099e-02
I0213 13:28:25.316575 22542570456896 run_lib.py:133] step: 1233800, training_loss: 2.75383e-02
I0213 13:28:25.476510 22542570456896 run_lib.py:146] step: 1233800, eval_loss: 2.37536e-02
I0213 13:28:43.123210 22542570456896 run_lib.py:133] step: 1233850, training_loss: 2.89041e-02
I0213 13:29:00.646193 22542570456896 run_lib.py:133] step: 1233900, training_loss: 2.99756e-02
I0213 13:29:00.802658 22542570456896 run_lib.py:146] step: 1233900, eval_loss: 3.16217e-02
I0213 13:29:18.523253 22542570456896 run_lib.py:133] step: 1233950, training_loss: 2.41373e-02
I0213 13:29:36.000678 22542570456896 run_lib.py:133] step: 1234000, training_loss: 2.45468e-02
I0213 13:29:36.162414 22542570456896 run_lib.py:146] step: 1234000, eval_loss: 3.60241e-02
I0213 13:29:53.652038 22542570456896 run_lib.py:133] step: 1234050, training_loss: 2.62297e-02
I0213 13:30:11.254909 22542570456896 run_lib.py:133] step: 1234100, training_loss: 2.82792e-02
I0213 13:30:11.420455 22542570456896 run_lib.py:146] step: 1234100, eval_loss: 3.28058e-02
I0213 13:30:28.958720 22542570456896 run_lib.py:133] step: 1234150, training_loss: 2.58978e-02
I0213 13:30:46.465988 22542570456896 run_lib.py:133] step: 1234200, training_loss: 2.57346e-02
I0213 13:30:46.622726 22542570456896 run_lib.py:146] step: 1234200, eval_loss: 2.80431e-02
I0213 13:31:04.101925 22542570456896 run_lib.py:133] step: 1234250, training_loss: 2.20999e-02
I0213 13:31:21.757824 22542570456896 run_lib.py:133] step: 1234300, training_loss: 2.52912e-02
I0213 13:31:21.914527 22542570456896 run_lib.py:146] step: 1234300, eval_loss: 2.43135e-02
I0213 13:31:39.427230 22542570456896 run_lib.py:133] step: 1234350, training_loss: 1.97578e-02
I0213 13:31:56.973415 22542570456896 run_lib.py:133] step: 1234400, training_loss: 2.77162e-02
I0213 13:31:57.128794 22542570456896 run_lib.py:146] step: 1234400, eval_loss: 2.98907e-02
I0213 13:32:14.656972 22542570456896 run_lib.py:133] step: 1234450, training_loss: 3.20625e-02
I0213 13:32:32.119328 22542570456896 run_lib.py:133] step: 1234500, training_loss: 3.11639e-02
I0213 13:32:32.277493 22542570456896 run_lib.py:146] step: 1234500, eval_loss: 2.43410e-02
I0213 13:32:49.957295 22542570456896 run_lib.py:133] step: 1234550, training_loss: 2.37375e-02
I0213 13:33:07.506530 22542570456896 run_lib.py:133] step: 1234600, training_loss: 2.18339e-02
I0213 13:33:07.664895 22542570456896 run_lib.py:146] step: 1234600, eval_loss: 3.41497e-02
I0213 13:33:25.163360 22542570456896 run_lib.py:133] step: 1234650, training_loss: 2.74780e-02
I0213 13:33:42.623442 22542570456896 run_lib.py:133] step: 1234700, training_loss: 2.72433e-02
I0213 13:33:42.783621 22542570456896 run_lib.py:146] step: 1234700, eval_loss: 2.87124e-02
I0213 13:34:00.420181 22542570456896 run_lib.py:133] step: 1234750, training_loss: 2.63772e-02
I0213 13:34:17.929560 22542570456896 run_lib.py:133] step: 1234800, training_loss: 3.12641e-02
I0213 13:34:18.086854 22542570456896 run_lib.py:146] step: 1234800, eval_loss: 2.65667e-02
I0213 13:34:35.768761 22542570456896 run_lib.py:133] step: 1234850, training_loss: 3.11069e-02
I0213 13:34:53.248183 22542570456896 run_lib.py:133] step: 1234900, training_loss: 2.78266e-02
I0213 13:34:53.401515 22542570456896 run_lib.py:146] step: 1234900, eval_loss: 2.63912e-02
I0213 13:35:11.031925 22542570456896 run_lib.py:133] step: 1234950, training_loss: 3.01675e-02
I0213 13:35:28.520441 22542570456896 run_lib.py:133] step: 1235000, training_loss: 2.61799e-02
I0213 13:35:28.685523 22542570456896 run_lib.py:146] step: 1235000, eval_loss: 2.42094e-02
I0213 13:35:46.232179 22542570456896 run_lib.py:133] step: 1235050, training_loss: 2.54142e-02
I0213 13:36:03.921918 22542570456896 run_lib.py:133] step: 1235100, training_loss: 2.39783e-02
I0213 13:36:04.076782 22542570456896 run_lib.py:146] step: 1235100, eval_loss: 2.90342e-02
I0213 13:36:21.562971 22542570456896 run_lib.py:133] step: 1235150, training_loss: 3.01588e-02
I0213 13:36:39.166798 22542570456896 run_lib.py:133] step: 1235200, training_loss: 2.38092e-02
I0213 13:36:39.323217 22542570456896 run_lib.py:146] step: 1235200, eval_loss: 3.39339e-02
I0213 13:36:56.808975 22542570456896 run_lib.py:133] step: 1235250, training_loss: 2.22151e-02
I0213 13:37:14.331613 22542570456896 run_lib.py:133] step: 1235300, training_loss: 2.30098e-02
I0213 13:37:14.495604 22542570456896 run_lib.py:146] step: 1235300, eval_loss: 2.78108e-02
I0213 13:37:32.218413 22542570456896 run_lib.py:133] step: 1235350, training_loss: 2.74676e-02
I0213 13:37:49.674233 22542570456896 run_lib.py:133] step: 1235400, training_loss: 2.52191e-02
I0213 13:37:49.831497 22542570456896 run_lib.py:146] step: 1235400, eval_loss: 3.48433e-02
I0213 13:38:07.311113 22542570456896 run_lib.py:133] step: 1235450, training_loss: 2.90589e-02
I0213 13:38:24.951187 22542570456896 run_lib.py:133] step: 1235500, training_loss: 3.26040e-02
I0213 13:38:25.118660 22542570456896 run_lib.py:146] step: 1235500, eval_loss: 3.22002e-02
I0213 13:38:42.599270 22542570456896 run_lib.py:133] step: 1235550, training_loss: 2.86646e-02
I0213 13:39:00.049596 22542570456896 run_lib.py:133] step: 1235600, training_loss: 2.95927e-02
I0213 13:39:00.383500 22542570456896 run_lib.py:146] step: 1235600, eval_loss: 2.42859e-02
I0213 13:39:17.904396 22542570456896 run_lib.py:133] step: 1235650, training_loss: 2.05164e-02
I0213 13:39:35.411311 22542570456896 run_lib.py:133] step: 1235700, training_loss: 2.05251e-02
I0213 13:39:35.573829 22542570456896 run_lib.py:146] step: 1235700, eval_loss: 3.07037e-02
I0213 13:39:53.057532 22542570456896 run_lib.py:133] step: 1235750, training_loss: 2.56763e-02
I0213 13:40:10.489578 22542570456896 run_lib.py:133] step: 1235800, training_loss: 2.97849e-02
I0213 13:40:10.642383 22542570456896 run_lib.py:146] step: 1235800, eval_loss: 2.70581e-02
I0213 13:40:28.306848 22542570456896 run_lib.py:133] step: 1235850, training_loss: 2.50174e-02
I0213 13:40:45.910927 22542570456896 run_lib.py:133] step: 1235900, training_loss: 1.95893e-02
I0213 13:40:46.082708 22542570456896 run_lib.py:146] step: 1235900, eval_loss: 3.12092e-02
I0213 13:41:03.572402 22542570456896 run_lib.py:133] step: 1235950, training_loss: 2.45035e-02
I0213 13:41:21.058903 22542570456896 run_lib.py:133] step: 1236000, training_loss: 2.84613e-02
I0213 13:41:21.222436 22542570456896 run_lib.py:146] step: 1236000, eval_loss: 2.92988e-02
I0213 13:41:38.896319 22542570456896 run_lib.py:133] step: 1236050, training_loss: 2.41256e-02
I0213 13:41:56.442194 22542570456896 run_lib.py:133] step: 1236100, training_loss: 2.39920e-02
I0213 13:41:56.599460 22542570456896 run_lib.py:146] step: 1236100, eval_loss: 2.55544e-02
I0213 13:42:14.062350 22542570456896 run_lib.py:133] step: 1236150, training_loss: 3.14597e-02
I0213 13:42:31.572487 22542570456896 run_lib.py:133] step: 1236200, training_loss: 2.71485e-02
I0213 13:42:31.731775 22542570456896 run_lib.py:146] step: 1236200, eval_loss: 3.30819e-02
I0213 13:42:49.395677 22542570456896 run_lib.py:133] step: 1236250, training_loss: 2.53667e-02
I0213 13:43:06.877537 22542570456896 run_lib.py:133] step: 1236300, training_loss: 2.79691e-02
I0213 13:43:07.030397 22542570456896 run_lib.py:146] step: 1236300, eval_loss: 2.71454e-02
I0213 13:43:24.632229 22542570456896 run_lib.py:133] step: 1236350, training_loss: 3.13364e-02
I0213 13:43:42.091679 22542570456896 run_lib.py:133] step: 1236400, training_loss: 3.11572e-02
I0213 13:43:42.252657 22542570456896 run_lib.py:146] step: 1236400, eval_loss: 2.53714e-02
I0213 13:43:59.846741 22542570456896 run_lib.py:133] step: 1236450, training_loss: 2.80703e-02
I0213 13:44:17.405965 22542570456896 run_lib.py:133] step: 1236500, training_loss: 2.83270e-02
I0213 13:44:17.568512 22542570456896 run_lib.py:146] step: 1236500, eval_loss: 2.87310e-02
I0213 13:44:35.022764 22542570456896 run_lib.py:133] step: 1236550, training_loss: 1.99725e-02
I0213 13:44:52.684403 22542570456896 run_lib.py:133] step: 1236600, training_loss: 2.05543e-02
I0213 13:44:52.841215 22542570456896 run_lib.py:146] step: 1236600, eval_loss: 3.53884e-02
I0213 13:45:10.311986 22542570456896 run_lib.py:133] step: 1236650, training_loss: 1.83660e-02
I0213 13:45:27.944359 22542570456896 run_lib.py:133] step: 1236700, training_loss: 2.79501e-02
I0213 13:45:28.098901 22542570456896 run_lib.py:146] step: 1236700, eval_loss: 3.16782e-02
I0213 13:45:45.536158 22542570456896 run_lib.py:133] step: 1236750, training_loss: 2.83136e-02
I0213 13:46:03.040162 22542570456896 run_lib.py:133] step: 1236800, training_loss: 2.33786e-02
I0213 13:46:03.208978 22542570456896 run_lib.py:146] step: 1236800, eval_loss: 2.76209e-02
I0213 13:46:20.909224 22542570456896 run_lib.py:133] step: 1236850, training_loss: 2.57970e-02
I0213 13:46:38.433661 22542570456896 run_lib.py:133] step: 1236900, training_loss: 2.75694e-02
I0213 13:46:38.596697 22542570456896 run_lib.py:146] step: 1236900, eval_loss: 2.87197e-02
I0213 13:46:56.041009 22542570456896 run_lib.py:133] step: 1236950, training_loss: 2.70591e-02
I0213 13:47:13.507650 22542570456896 run_lib.py:133] step: 1237000, training_loss: 2.75331e-02
I0213 13:47:13.670521 22542570456896 run_lib.py:146] step: 1237000, eval_loss: 2.84595e-02
I0213 13:47:31.325049 22542570456896 run_lib.py:133] step: 1237050, training_loss: 3.69854e-02
I0213 13:47:48.844227 22542570456896 run_lib.py:133] step: 1237100, training_loss: 3.28883e-02
I0213 13:47:49.002882 22542570456896 run_lib.py:146] step: 1237100, eval_loss: 2.72797e-02
I0213 13:48:06.589753 22542570456896 run_lib.py:133] step: 1237150, training_loss: 3.18485e-02
I0213 13:48:24.036262 22542570456896 run_lib.py:133] step: 1237200, training_loss: 2.90243e-02
I0213 13:48:24.189277 22542570456896 run_lib.py:146] step: 1237200, eval_loss: 2.80971e-02
I0213 13:48:41.663945 22542570456896 run_lib.py:133] step: 1237250, training_loss: 3.08145e-02
I0213 13:48:59.169951 22542570456896 run_lib.py:133] step: 1237300, training_loss: 3.18273e-02
I0213 13:48:59.337633 22542570456896 run_lib.py:146] step: 1237300, eval_loss: 2.18384e-02
I0213 13:49:17.016446 22542570456896 run_lib.py:133] step: 1237350, training_loss: 3.08058e-02
I0213 13:49:34.624720 22542570456896 run_lib.py:133] step: 1237400, training_loss: 2.62467e-02
I0213 13:49:34.781578 22542570456896 run_lib.py:146] step: 1237400, eval_loss: 2.76948e-02
I0213 13:49:52.255115 22542570456896 run_lib.py:133] step: 1237450, training_loss: 2.50784e-02
I0213 13:50:09.728753 22542570456896 run_lib.py:133] step: 1237500, training_loss: 3.01376e-02
I0213 13:50:09.886407 22542570456896 run_lib.py:146] step: 1237500, eval_loss: 3.34348e-02
I0213 13:50:27.505864 22542570456896 run_lib.py:133] step: 1237550, training_loss: 2.34164e-02
I0213 13:50:45.059542 22542570456896 run_lib.py:133] step: 1237600, training_loss: 2.82960e-02
I0213 13:50:45.222680 22542570456896 run_lib.py:146] step: 1237600, eval_loss: 3.32510e-02
I0213 13:51:02.914973 22542570456896 run_lib.py:133] step: 1237650, training_loss: 2.86689e-02
I0213 13:51:20.390397 22542570456896 run_lib.py:133] step: 1237700, training_loss: 2.83018e-02
I0213 13:51:20.544480 22542570456896 run_lib.py:146] step: 1237700, eval_loss: 3.12064e-02
I0213 13:51:38.157214 22542570456896 run_lib.py:133] step: 1237750, training_loss: 2.62711e-02
I0213 13:51:55.647368 22542570456896 run_lib.py:133] step: 1237800, training_loss: 3.04833e-02
I0213 13:51:55.806705 22542570456896 run_lib.py:146] step: 1237800, eval_loss: 3.12670e-02
I0213 13:52:13.528973 22542570456896 run_lib.py:133] step: 1237850, training_loss: 2.53860e-02
I0213 13:52:31.044277 22542570456896 run_lib.py:133] step: 1237900, training_loss: 2.65454e-02
I0213 13:52:31.208449 22542570456896 run_lib.py:146] step: 1237900, eval_loss: 2.37649e-02
I0213 13:52:48.652359 22542570456896 run_lib.py:133] step: 1237950, training_loss: 2.82202e-02
I0213 13:53:06.323034 22542570456896 run_lib.py:133] step: 1238000, training_loss: 3.42390e-02
I0213 13:53:06.480456 22542570456896 run_lib.py:146] step: 1238000, eval_loss: 3.26845e-02
I0213 13:53:23.970648 22542570456896 run_lib.py:133] step: 1238050, training_loss: 2.19655e-02
I0213 13:53:41.444114 22542570456896 run_lib.py:133] step: 1238100, training_loss: 2.94546e-02
I0213 13:53:41.610417 22542570456896 run_lib.py:146] step: 1238100, eval_loss: 2.27174e-02
I0213 13:53:59.309761 22542570456896 run_lib.py:133] step: 1238150, training_loss: 3.11687e-02
I0213 13:54:16.996871 22542570456896 run_lib.py:133] step: 1238200, training_loss: 3.52070e-02
I0213 13:54:17.156436 22542570456896 run_lib.py:146] step: 1238200, eval_loss: 3.30246e-02
I0213 13:54:34.623498 22542570456896 run_lib.py:133] step: 1238250, training_loss: 2.52777e-02
I0213 13:54:52.087658 22542570456896 run_lib.py:133] step: 1238300, training_loss: 2.37102e-02
I0213 13:54:52.248813 22542570456896 run_lib.py:146] step: 1238300, eval_loss: 2.92943e-02
I0213 13:55:09.713153 22542570456896 run_lib.py:133] step: 1238350, training_loss: 2.79947e-02
I0213 13:55:27.365671 22542570456896 run_lib.py:133] step: 1238400, training_loss: 2.49557e-02
I0213 13:55:27.532361 22542570456896 run_lib.py:146] step: 1238400, eval_loss: 3.66076e-02
I0213 13:55:45.074182 22542570456896 run_lib.py:133] step: 1238450, training_loss: 2.78909e-02
I0213 13:56:02.563603 22542570456896 run_lib.py:133] step: 1238500, training_loss: 2.42577e-02
I0213 13:56:02.721267 22542570456896 run_lib.py:146] step: 1238500, eval_loss: 2.77546e-02
I0213 13:56:20.224516 22542570456896 run_lib.py:133] step: 1238550, training_loss: 2.51277e-02
I0213 13:56:37.901889 22542570456896 run_lib.py:133] step: 1238600, training_loss: 3.13324e-02
I0213 13:56:38.057589 22542570456896 run_lib.py:146] step: 1238600, eval_loss: 2.80110e-02
I0213 13:56:55.567254 22542570456896 run_lib.py:133] step: 1238650, training_loss: 2.64299e-02
I0213 13:57:13.174862 22542570456896 run_lib.py:133] step: 1238700, training_loss: 2.61737e-02
I0213 13:57:13.333662 22542570456896 run_lib.py:146] step: 1238700, eval_loss: 3.07369e-02
I0213 13:57:30.814893 22542570456896 run_lib.py:133] step: 1238750, training_loss: 2.82543e-02
I0213 13:57:48.323962 22542570456896 run_lib.py:133] step: 1238800, training_loss: 2.79773e-02
I0213 13:57:48.492435 22542570456896 run_lib.py:146] step: 1238800, eval_loss: 3.59456e-02
I0213 13:58:06.168905 22542570456896 run_lib.py:133] step: 1238850, training_loss: 3.05071e-02
I0213 13:58:23.713344 22542570456896 run_lib.py:133] step: 1238900, training_loss: 2.78157e-02
I0213 13:58:23.869545 22542570456896 run_lib.py:146] step: 1238900, eval_loss: 3.49576e-02
I0213 13:58:41.365445 22542570456896 run_lib.py:133] step: 1238950, training_loss: 2.47252e-02
I0213 13:58:58.885199 22542570456896 run_lib.py:133] step: 1239000, training_loss: 3.38802e-02
I0213 13:58:59.043057 22542570456896 run_lib.py:146] step: 1239000, eval_loss: 2.89593e-02
I0213 13:59:16.735142 22542570456896 run_lib.py:133] step: 1239050, training_loss: 2.74260e-02
I0213 13:59:34.169345 22542570456896 run_lib.py:133] step: 1239100, training_loss: 2.23747e-02
I0213 13:59:34.322477 22542570456896 run_lib.py:146] step: 1239100, eval_loss: 2.94437e-02
I0213 13:59:51.931274 22542570456896 run_lib.py:133] step: 1239150, training_loss: 3.43867e-02
I0213 14:00:09.431920 22542570456896 run_lib.py:133] step: 1239200, training_loss: 2.23601e-02
I0213 14:00:09.602738 22542570456896 run_lib.py:146] step: 1239200, eval_loss: 2.75461e-02
I0213 14:00:27.340849 22542570456896 run_lib.py:133] step: 1239250, training_loss: 3.07771e-02
I0213 14:00:44.852503 22542570456896 run_lib.py:133] step: 1239300, training_loss: 2.98403e-02
I0213 14:00:45.014455 22542570456896 run_lib.py:146] step: 1239300, eval_loss: 2.32176e-02
I0213 14:01:02.488046 22542570456896 run_lib.py:133] step: 1239350, training_loss: 2.88049e-02
I0213 14:01:20.091522 22542570456896 run_lib.py:133] step: 1239400, training_loss: 2.31499e-02
I0213 14:01:20.253421 22542570456896 run_lib.py:146] step: 1239400, eval_loss: 3.40869e-02
I0213 14:01:37.713262 22542570456896 run_lib.py:133] step: 1239450, training_loss: 2.16236e-02
I0213 14:01:55.257827 22542570456896 run_lib.py:133] step: 1239500, training_loss: 2.38906e-02
I0213 14:01:55.412490 22542570456896 run_lib.py:146] step: 1239500, eval_loss: 2.44569e-02
I0213 14:02:12.832454 22542570456896 run_lib.py:133] step: 1239550, training_loss: 3.50857e-02
I0213 14:02:30.234344 22542570456896 run_lib.py:133] step: 1239600, training_loss: 3.22518e-02
I0213 14:02:30.386638 22542570456896 run_lib.py:146] step: 1239600, eval_loss: 2.52381e-02
I0213 14:02:47.966190 22542570456896 run_lib.py:133] step: 1239650, training_loss: 2.62844e-02
I0213 14:03:05.358603 22542570456896 run_lib.py:133] step: 1239700, training_loss: 2.54299e-02
I0213 14:03:05.514172 22542570456896 run_lib.py:146] step: 1239700, eval_loss: 3.54591e-02
I0213 14:03:22.899312 22542570456896 run_lib.py:133] step: 1239750, training_loss: 3.16805e-02
I0213 14:03:40.488737 22542570456896 run_lib.py:133] step: 1239800, training_loss: 2.80615e-02
I0213 14:03:40.646232 22542570456896 run_lib.py:146] step: 1239800, eval_loss: 3.22241e-02
I0213 14:03:58.062062 22542570456896 run_lib.py:133] step: 1239850, training_loss: 2.78097e-02
I0213 14:04:15.506542 22542570456896 run_lib.py:133] step: 1239900, training_loss: 3.01043e-02
I0213 14:04:15.663405 22542570456896 run_lib.py:146] step: 1239900, eval_loss: 3.26755e-02
I0213 14:04:33.212250 22542570456896 run_lib.py:133] step: 1239950, training_loss: 2.49486e-02
I0213 14:04:50.670966 22542570456896 run_lib.py:133] step: 1240000, training_loss: 2.78644e-02
I0213 14:04:51.517317 22542570456896 run_lib.py:146] step: 1240000, eval_loss: 3.16680e-02
I0213 14:05:12.049671 22542570456896 run_lib.py:133] step: 1240050, training_loss: 2.54744e-02
I0213 14:05:29.570373 22542570456896 run_lib.py:133] step: 1240100, training_loss: 2.65614e-02
I0213 14:05:29.731453 22542570456896 run_lib.py:146] step: 1240100, eval_loss: 2.34794e-02
I0213 14:05:47.449839 22542570456896 run_lib.py:133] step: 1240150, training_loss: 2.65083e-02
I0213 14:06:04.922234 22542570456896 run_lib.py:133] step: 1240200, training_loss: 3.15859e-02
I0213 14:06:05.076443 22542570456896 run_lib.py:146] step: 1240200, eval_loss: 3.02972e-02
I0213 14:06:22.619370 22542570456896 run_lib.py:133] step: 1240250, training_loss: 2.43437e-02
I0213 14:06:40.112829 22542570456896 run_lib.py:133] step: 1240300, training_loss: 1.95447e-02
I0213 14:06:40.277706 22542570456896 run_lib.py:146] step: 1240300, eval_loss: 2.97153e-02
I0213 14:06:57.816616 22542570456896 run_lib.py:133] step: 1240350, training_loss: 3.14735e-02
I0213 14:07:15.347240 22542570456896 run_lib.py:133] step: 1240400, training_loss: 3.20659e-02
I0213 14:07:15.513453 22542570456896 run_lib.py:146] step: 1240400, eval_loss: 2.83609e-02
I0213 14:07:33.169795 22542570456896 run_lib.py:133] step: 1240450, training_loss: 2.57368e-02
I0213 14:07:50.759685 22542570456896 run_lib.py:133] step: 1240500, training_loss: 2.14457e-02
I0213 14:07:50.921560 22542570456896 run_lib.py:146] step: 1240500, eval_loss: 2.08231e-02
I0213 14:08:08.393555 22542570456896 run_lib.py:133] step: 1240550, training_loss: 2.92891e-02
I0213 14:08:25.928169 22542570456896 run_lib.py:133] step: 1240600, training_loss: 1.80392e-02
I0213 14:08:26.085292 22542570456896 run_lib.py:146] step: 1240600, eval_loss: 2.92061e-02
I0213 14:08:43.776077 22542570456896 run_lib.py:133] step: 1240650, training_loss: 2.35354e-02
I0213 14:09:01.240198 22542570456896 run_lib.py:133] step: 1240700, training_loss: 2.60965e-02
I0213 14:09:01.397389 22542570456896 run_lib.py:146] step: 1240700, eval_loss: 2.95833e-02
I0213 14:09:18.997364 22542570456896 run_lib.py:133] step: 1240750, training_loss: 3.38301e-02
I0213 14:09:36.473007 22542570456896 run_lib.py:133] step: 1240800, training_loss: 2.35422e-02
I0213 14:09:36.633593 22542570456896 run_lib.py:146] step: 1240800, eval_loss: 3.07408e-02
I0213 14:09:54.291260 22542570456896 run_lib.py:133] step: 1240850, training_loss: 2.70621e-02
I0213 14:10:11.828275 22542570456896 run_lib.py:133] step: 1240900, training_loss: 2.25163e-02
I0213 14:10:11.982652 22542570456896 run_lib.py:146] step: 1240900, eval_loss: 2.87724e-02
I0213 14:10:29.637708 22542570456896 run_lib.py:133] step: 1240950, training_loss: 2.21353e-02
I0213 14:10:47.131150 22542570456896 run_lib.py:133] step: 1241000, training_loss: 3.10079e-02
I0213 14:10:47.292475 22542570456896 run_lib.py:146] step: 1241000, eval_loss: 2.99321e-02
I0213 14:11:04.774846 22542570456896 run_lib.py:133] step: 1241050, training_loss: 3.47141e-02
I0213 14:11:22.401588 22542570456896 run_lib.py:133] step: 1241100, training_loss: 3.60398e-02
I0213 14:11:22.554417 22542570456896 run_lib.py:146] step: 1241100, eval_loss: 2.71986e-02
I0213 14:11:40.035983 22542570456896 run_lib.py:133] step: 1241150, training_loss: 3.44251e-02
I0213 14:11:57.564223 22542570456896 run_lib.py:133] step: 1241200, training_loss: 2.53852e-02
I0213 14:11:57.726627 22542570456896 run_lib.py:146] step: 1241200, eval_loss: 2.75651e-02
I0213 14:12:15.392857 22542570456896 run_lib.py:133] step: 1241250, training_loss: 2.57333e-02
I0213 14:12:32.876630 22542570456896 run_lib.py:133] step: 1241300, training_loss: 2.81795e-02
I0213 14:12:33.036607 22542570456896 run_lib.py:146] step: 1241300, eval_loss: 2.95686e-02
I0213 14:12:50.644016 22542570456896 run_lib.py:133] step: 1241350, training_loss: 2.00543e-02
I0213 14:13:08.094801 22542570456896 run_lib.py:133] step: 1241400, training_loss: 2.69175e-02
I0213 14:13:08.255224 22542570456896 run_lib.py:146] step: 1241400, eval_loss: 2.60059e-02
I0213 14:13:25.756731 22542570456896 run_lib.py:133] step: 1241450, training_loss: 2.58503e-02
I0213 14:13:43.448608 22542570456896 run_lib.py:133] step: 1241500, training_loss: 2.85863e-02
I0213 14:13:43.604863 22542570456896 run_lib.py:146] step: 1241500, eval_loss: 2.61130e-02
I0213 14:14:01.114022 22542570456896 run_lib.py:133] step: 1241550, training_loss: 2.58821e-02
I0213 14:14:18.612687 22542570456896 run_lib.py:133] step: 1241600, training_loss: 2.34559e-02
I0213 14:14:18.767523 22542570456896 run_lib.py:146] step: 1241600, eval_loss: 2.61684e-02
I0213 14:14:36.233900 22542570456896 run_lib.py:133] step: 1241650, training_loss: 2.21821e-02
I0213 14:14:53.874263 22542570456896 run_lib.py:133] step: 1241700, training_loss: 2.62076e-02
I0213 14:14:54.053654 22542570456896 run_lib.py:146] step: 1241700, eval_loss: 2.43827e-02
I0213 14:15:11.548397 22542570456896 run_lib.py:133] step: 1241750, training_loss: 2.91665e-02
I0213 14:15:29.139188 22542570456896 run_lib.py:133] step: 1241800, training_loss: 2.44674e-02
I0213 14:15:29.300755 22542570456896 run_lib.py:146] step: 1241800, eval_loss: 3.36240e-02
I0213 14:15:46.793327 22542570456896 run_lib.py:133] step: 1241850, training_loss: 2.43438e-02
I0213 14:16:04.230294 22542570456896 run_lib.py:133] step: 1241900, training_loss: 2.96052e-02
I0213 14:16:04.387469 22542570456896 run_lib.py:146] step: 1241900, eval_loss: 2.72868e-02
I0213 14:16:21.994819 22542570456896 run_lib.py:133] step: 1241950, training_loss: 2.27869e-02
I0213 14:16:39.583638 22542570456896 run_lib.py:133] step: 1242000, training_loss: 2.82529e-02
I0213 14:16:39.739265 22542570456896 run_lib.py:146] step: 1242000, eval_loss: 2.80565e-02
I0213 14:16:57.225650 22542570456896 run_lib.py:133] step: 1242050, training_loss: 2.07938e-02
I0213 14:17:14.711804 22542570456896 run_lib.py:133] step: 1242100, training_loss: 2.63398e-02
I0213 14:17:14.869573 22542570456896 run_lib.py:146] step: 1242100, eval_loss: 2.85122e-02
I0213 14:17:32.523194 22542570456896 run_lib.py:133] step: 1242150, training_loss: 3.30705e-02
I0213 14:17:50.007290 22542570456896 run_lib.py:133] step: 1242200, training_loss: 2.17563e-02
I0213 14:17:50.167644 22542570456896 run_lib.py:146] step: 1242200, eval_loss: 3.12999e-02
I0213 14:18:07.792439 22542570456896 run_lib.py:133] step: 1242250, training_loss: 3.48543e-02
I0213 14:18:25.300988 22542570456896 run_lib.py:133] step: 1242300, training_loss: 2.58313e-02
I0213 14:18:25.460838 22542570456896 run_lib.py:146] step: 1242300, eval_loss: 3.48474e-02
I0213 14:18:43.132881 22542570456896 run_lib.py:133] step: 1242350, training_loss: 3.07433e-02
I0213 14:19:00.582910 22542570456896 run_lib.py:133] step: 1242400, training_loss: 2.44978e-02
I0213 14:19:00.739643 22542570456896 run_lib.py:146] step: 1242400, eval_loss: 2.86504e-02
I0213 14:19:18.214792 22542570456896 run_lib.py:133] step: 1242450, training_loss: 2.55287e-02
I0213 14:19:35.861828 22542570456896 run_lib.py:133] step: 1242500, training_loss: 2.54021e-02
I0213 14:19:36.017003 22542570456896 run_lib.py:146] step: 1242500, eval_loss: 2.65895e-02
I0213 14:19:53.570670 22542570456896 run_lib.py:133] step: 1242550, training_loss: 3.39682e-02
I0213 14:20:11.231639 22542570456896 run_lib.py:133] step: 1242600, training_loss: 2.28161e-02
I0213 14:20:11.390615 22542570456896 run_lib.py:146] step: 1242600, eval_loss: 3.06248e-02
I0213 14:20:28.861262 22542570456896 run_lib.py:133] step: 1242650, training_loss: 2.38901e-02
I0213 14:20:46.356675 22542570456896 run_lib.py:133] step: 1242700, training_loss: 2.29825e-02
I0213 14:20:46.525429 22542570456896 run_lib.py:146] step: 1242700, eval_loss: 2.60446e-02
I0213 14:21:04.159073 22542570456896 run_lib.py:133] step: 1242750, training_loss: 3.00341e-02
I0213 14:21:21.668751 22542570456896 run_lib.py:133] step: 1242800, training_loss: 2.15160e-02
I0213 14:21:21.826431 22542570456896 run_lib.py:146] step: 1242800, eval_loss: 4.49834e-02
I0213 14:21:39.309249 22542570456896 run_lib.py:133] step: 1242850, training_loss: 3.10056e-02
I0213 14:21:56.954822 22542570456896 run_lib.py:133] step: 1242900, training_loss: 2.45138e-02
I0213 14:21:57.114463 22542570456896 run_lib.py:146] step: 1242900, eval_loss: 3.33847e-02
I0213 14:22:14.606548 22542570456896 run_lib.py:133] step: 1242950, training_loss: 2.80224e-02
I0213 14:22:32.097224 22542570456896 run_lib.py:133] step: 1243000, training_loss: 2.32071e-02
I0213 14:22:32.404411 22542570456896 run_lib.py:146] step: 1243000, eval_loss: 2.68712e-02
I0213 14:22:49.844129 22542570456896 run_lib.py:133] step: 1243050, training_loss: 2.71094e-02
I0213 14:23:07.337409 22542570456896 run_lib.py:133] step: 1243100, training_loss: 2.98382e-02
I0213 14:23:07.508286 22542570456896 run_lib.py:146] step: 1243100, eval_loss: 2.49621e-02
I0213 14:23:25.028971 22542570456896 run_lib.py:133] step: 1243150, training_loss: 2.66280e-02
I0213 14:23:42.528029 22542570456896 run_lib.py:133] step: 1243200, training_loss: 2.22641e-02
I0213 14:23:42.688820 22542570456896 run_lib.py:146] step: 1243200, eval_loss: 2.92780e-02
I0213 14:24:00.349112 22542570456896 run_lib.py:133] step: 1243250, training_loss: 2.51414e-02
I0213 14:24:17.875711 22542570456896 run_lib.py:133] step: 1243300, training_loss: 2.24459e-02
I0213 14:24:18.033185 22542570456896 run_lib.py:146] step: 1243300, eval_loss: 3.19969e-02
I0213 14:24:35.506067 22542570456896 run_lib.py:133] step: 1243350, training_loss: 2.40795e-02
I0213 14:24:53.067394 22542570456896 run_lib.py:133] step: 1243400, training_loss: 2.83434e-02
I0213 14:24:53.229590 22542570456896 run_lib.py:146] step: 1243400, eval_loss: 2.60408e-02
I0213 14:25:10.908908 22542570456896 run_lib.py:133] step: 1243450, training_loss: 3.08360e-02
I0213 14:25:28.430907 22542570456896 run_lib.py:133] step: 1243500, training_loss: 2.90927e-02
I0213 14:25:28.583726 22542570456896 run_lib.py:146] step: 1243500, eval_loss: 2.37454e-02
I0213 14:25:46.021635 22542570456896 run_lib.py:133] step: 1243550, training_loss: 3.44114e-02
I0213 14:26:03.477266 22542570456896 run_lib.py:133] step: 1243600, training_loss: 2.84956e-02
I0213 14:26:03.653453 22542570456896 run_lib.py:146] step: 1243600, eval_loss: 2.32811e-02
I0213 14:26:21.365265 22542570456896 run_lib.py:133] step: 1243650, training_loss: 3.53344e-02
I0213 14:26:38.856765 22542570456896 run_lib.py:133] step: 1243700, training_loss: 3.51065e-02
I0213 14:26:39.015778 22542570456896 run_lib.py:146] step: 1243700, eval_loss: 2.69685e-02
I0213 14:26:56.698488 22542570456896 run_lib.py:133] step: 1243750, training_loss: 2.82172e-02
I0213 14:27:14.156387 22542570456896 run_lib.py:133] step: 1243800, training_loss: 2.90523e-02
I0213 14:27:14.312280 22542570456896 run_lib.py:146] step: 1243800, eval_loss: 2.92377e-02
I0213 14:27:31.899932 22542570456896 run_lib.py:133] step: 1243850, training_loss: 2.04701e-02
I0213 14:27:49.414603 22542570456896 run_lib.py:133] step: 1243900, training_loss: 2.76635e-02
I0213 14:27:49.577281 22542570456896 run_lib.py:146] step: 1243900, eval_loss: 2.75530e-02
I0213 14:28:07.123891 22542570456896 run_lib.py:133] step: 1243950, training_loss: 3.21196e-02
I0213 14:28:24.777517 22542570456896 run_lib.py:133] step: 1244000, training_loss: 2.82620e-02
I0213 14:28:24.941484 22542570456896 run_lib.py:146] step: 1244000, eval_loss: 3.53914e-02
I0213 14:28:42.387783 22542570456896 run_lib.py:133] step: 1244050, training_loss: 3.20415e-02
I0213 14:29:00.021311 22542570456896 run_lib.py:133] step: 1244100, training_loss: 3.17907e-02
I0213 14:29:00.185674 22542570456896 run_lib.py:146] step: 1244100, eval_loss: 2.54297e-02
I0213 14:29:17.664159 22542570456896 run_lib.py:133] step: 1244150, training_loss: 2.39446e-02
I0213 14:29:35.215629 22542570456896 run_lib.py:133] step: 1244200, training_loss: 3.21032e-02
I0213 14:29:35.373706 22542570456896 run_lib.py:146] step: 1244200, eval_loss: 3.12624e-02
I0213 14:29:53.029408 22542570456896 run_lib.py:133] step: 1244250, training_loss: 2.44008e-02
I0213 14:30:10.478056 22542570456896 run_lib.py:133] step: 1244300, training_loss: 2.18994e-02
I0213 14:30:10.634395 22542570456896 run_lib.py:146] step: 1244300, eval_loss: 2.68447e-02
I0213 14:30:28.115950 22542570456896 run_lib.py:133] step: 1244350, training_loss: 2.66061e-02
I0213 14:30:45.596891 22542570456896 run_lib.py:133] step: 1244400, training_loss: 2.19524e-02
I0213 14:30:45.752834 22542570456896 run_lib.py:146] step: 1244400, eval_loss: 2.82269e-02
I0213 14:31:03.402283 22542570456896 run_lib.py:133] step: 1244450, training_loss: 2.19836e-02
I0213 14:31:20.904542 22542570456896 run_lib.py:133] step: 1244500, training_loss: 2.38216e-02
I0213 14:31:21.063485 22542570456896 run_lib.py:146] step: 1244500, eval_loss: 2.97148e-02
I0213 14:31:38.628413 22542570456896 run_lib.py:133] step: 1244550, training_loss: 2.70132e-02
I0213 14:31:56.096051 22542570456896 run_lib.py:133] step: 1244600, training_loss: 2.33565e-02
I0213 14:31:56.257722 22542570456896 run_lib.py:146] step: 1244600, eval_loss: 3.74841e-02
I0213 14:32:13.732239 22542570456896 run_lib.py:133] step: 1244650, training_loss: 3.13597e-02
I0213 14:32:31.188502 22542570456896 run_lib.py:133] step: 1244700, training_loss: 2.86432e-02
I0213 14:32:31.360391 22542570456896 run_lib.py:146] step: 1244700, eval_loss: 3.18107e-02
I0213 14:32:49.035542 22542570456896 run_lib.py:133] step: 1244750, training_loss: 2.72255e-02
I0213 14:33:06.620141 22542570456896 run_lib.py:133] step: 1244800, training_loss: 2.29962e-02
I0213 14:33:06.777162 22542570456896 run_lib.py:146] step: 1244800, eval_loss: 3.00787e-02
I0213 14:33:24.258985 22542570456896 run_lib.py:133] step: 1244850, training_loss: 2.74631e-02
I0213 14:33:41.720746 22542570456896 run_lib.py:133] step: 1244900, training_loss: 2.33688e-02
I0213 14:33:41.874423 22542570456896 run_lib.py:146] step: 1244900, eval_loss: 2.68888e-02
I0213 14:33:59.482451 22542570456896 run_lib.py:133] step: 1244950, training_loss: 3.25307e-02
I0213 14:34:16.943192 22542570456896 run_lib.py:133] step: 1245000, training_loss: 2.39992e-02
I0213 14:34:17.115453 22542570456896 run_lib.py:146] step: 1245000, eval_loss: 3.24400e-02
I0213 14:34:34.791590 22542570456896 run_lib.py:133] step: 1245050, training_loss: 2.48561e-02
I0213 14:34:52.290907 22542570456896 run_lib.py:133] step: 1245100, training_loss: 2.94317e-02
I0213 14:34:52.451720 22542570456896 run_lib.py:146] step: 1245100, eval_loss: 2.33210e-02
I0213 14:35:10.093173 22542570456896 run_lib.py:133] step: 1245150, training_loss: 2.28404e-02
I0213 14:35:27.551108 22542570456896 run_lib.py:133] step: 1245200, training_loss: 2.95232e-02
I0213 14:35:27.709290 22542570456896 run_lib.py:146] step: 1245200, eval_loss: 2.98854e-02
I0213 14:35:45.323042 22542570456896 run_lib.py:133] step: 1245250, training_loss: 2.67302e-02
I0213 14:36:02.861314 22542570456896 run_lib.py:133] step: 1245300, training_loss: 2.85390e-02
I0213 14:36:03.017218 22542570456896 run_lib.py:146] step: 1245300, eval_loss: 3.04666e-02
I0213 14:36:20.545662 22542570456896 run_lib.py:133] step: 1245350, training_loss: 2.66367e-02
I0213 14:36:38.234173 22542570456896 run_lib.py:133] step: 1245400, training_loss: 3.19203e-02
I0213 14:36:38.388456 22542570456896 run_lib.py:146] step: 1245400, eval_loss: 2.53391e-02
I0213 14:36:55.840294 22542570456896 run_lib.py:133] step: 1245450, training_loss: 2.84557e-02
I0213 14:37:13.294952 22542570456896 run_lib.py:133] step: 1245500, training_loss: 3.20054e-02
I0213 14:37:13.451464 22542570456896 run_lib.py:146] step: 1245500, eval_loss: 2.81794e-02
I0213 14:37:30.931657 22542570456896 run_lib.py:133] step: 1245550, training_loss: 2.00767e-02
I0213 14:37:48.448045 22542570456896 run_lib.py:133] step: 1245600, training_loss: 2.54628e-02
I0213 14:37:48.607550 22542570456896 run_lib.py:146] step: 1245600, eval_loss: 2.88521e-02
I0213 14:38:05.893369 22542570456896 run_lib.py:133] step: 1245650, training_loss: 2.39605e-02
I0213 14:38:23.205147 22542570456896 run_lib.py:133] step: 1245700, training_loss: 2.76080e-02
I0213 14:38:23.362464 22542570456896 run_lib.py:146] step: 1245700, eval_loss: 2.75819e-02
I0213 14:38:40.664396 22542570456896 run_lib.py:133] step: 1245750, training_loss: 2.80107e-02
I0213 14:38:58.099863 22542570456896 run_lib.py:133] step: 1245800, training_loss: 2.45952e-02
I0213 14:38:58.249000 22542570456896 run_lib.py:146] step: 1245800, eval_loss: 2.61805e-02
I0213 14:39:15.567759 22542570456896 run_lib.py:133] step: 1245850, training_loss: 2.96288e-02
I0213 14:39:32.911473 22542570456896 run_lib.py:133] step: 1245900, training_loss: 3.32809e-02
I0213 14:39:33.077327 22542570456896 run_lib.py:146] step: 1245900, eval_loss: 2.79290e-02
I0213 14:39:50.464111 22542570456896 run_lib.py:133] step: 1245950, training_loss: 2.57265e-02
I0213 14:40:08.170122 22542570456896 run_lib.py:133] step: 1246000, training_loss: 2.71976e-02
I0213 14:40:08.329684 22542570456896 run_lib.py:146] step: 1246000, eval_loss: 2.72967e-02
I0213 14:40:25.788977 22542570456896 run_lib.py:133] step: 1246050, training_loss: 2.83042e-02
I0213 14:40:43.336343 22542570456896 run_lib.py:133] step: 1246100, training_loss: 2.28889e-02
I0213 14:40:43.493602 22542570456896 run_lib.py:146] step: 1246100, eval_loss: 3.19793e-02
I0213 14:41:00.953558 22542570456896 run_lib.py:133] step: 1246150, training_loss: 2.77861e-02
I0213 14:41:18.494056 22542570456896 run_lib.py:133] step: 1246200, training_loss: 1.75458e-02
I0213 14:41:18.653064 22542570456896 run_lib.py:146] step: 1246200, eval_loss: 3.29084e-02
I0213 14:41:36.353552 22542570456896 run_lib.py:133] step: 1246250, training_loss: 2.85362e-02
I0213 14:41:53.863199 22542570456896 run_lib.py:133] step: 1246300, training_loss: 1.97174e-02
I0213 14:41:54.016442 22542570456896 run_lib.py:146] step: 1246300, eval_loss: 3.01182e-02
I0213 14:42:11.475231 22542570456896 run_lib.py:133] step: 1246350, training_loss: 2.96734e-02
I0213 14:42:28.961250 22542570456896 run_lib.py:133] step: 1246400, training_loss: 3.27298e-02
I0213 14:42:29.134759 22542570456896 run_lib.py:146] step: 1246400, eval_loss: 3.01923e-02
I0213 14:42:46.869223 22542570456896 run_lib.py:133] step: 1246450, training_loss: 2.57639e-02
I0213 14:43:04.370440 22542570456896 run_lib.py:133] step: 1246500, training_loss: 2.27937e-02
I0213 14:43:04.531517 22542570456896 run_lib.py:146] step: 1246500, eval_loss: 2.70535e-02
I0213 14:43:22.131668 22542570456896 run_lib.py:133] step: 1246550, training_loss: 2.51059e-02
I0213 14:43:39.657304 22542570456896 run_lib.py:133] step: 1246600, training_loss: 2.60770e-02
I0213 14:43:39.820421 22542570456896 run_lib.py:146] step: 1246600, eval_loss: 2.86837e-02
I0213 14:43:57.419857 22542570456896 run_lib.py:133] step: 1246650, training_loss: 3.07580e-02
I0213 14:44:14.932898 22542570456896 run_lib.py:133] step: 1246700, training_loss: 3.15432e-02
I0213 14:44:15.096796 22542570456896 run_lib.py:146] step: 1246700, eval_loss: 2.31381e-02
I0213 14:44:32.640033 22542570456896 run_lib.py:133] step: 1246750, training_loss: 3.07231e-02
I0213 14:44:50.298165 22542570456896 run_lib.py:133] step: 1246800, training_loss: 2.53354e-02
I0213 14:44:50.459344 22542570456896 run_lib.py:146] step: 1246800, eval_loss: 3.05142e-02
I0213 14:45:07.961398 22542570456896 run_lib.py:133] step: 1246850, training_loss: 3.31031e-02
I0213 14:45:25.579525 22542570456896 run_lib.py:133] step: 1246900, training_loss: 2.90208e-02
I0213 14:45:25.738626 22542570456896 run_lib.py:146] step: 1246900, eval_loss: 2.71744e-02
I0213 14:45:43.158102 22542570456896 run_lib.py:133] step: 1246950, training_loss: 3.26910e-02
I0213 14:46:00.667600 22542570456896 run_lib.py:133] step: 1247000, training_loss: 2.85420e-02
I0213 14:46:00.825566 22542570456896 run_lib.py:146] step: 1247000, eval_loss: 3.11171e-02
I0213 14:46:18.522253 22542570456896 run_lib.py:133] step: 1247050, training_loss: 3.60476e-02
I0213 14:46:35.990440 22542570456896 run_lib.py:133] step: 1247100, training_loss: 2.96242e-02
I0213 14:46:36.145906 22542570456896 run_lib.py:146] step: 1247100, eval_loss: 2.56798e-02
I0213 14:46:53.603435 22542570456896 run_lib.py:133] step: 1247150, training_loss: 3.15750e-02
I0213 14:47:11.201095 22542570456896 run_lib.py:133] step: 1247200, training_loss: 2.82013e-02
I0213 14:47:11.365419 22542570456896 run_lib.py:146] step: 1247200, eval_loss: 3.35658e-02
I0213 14:47:28.815693 22542570456896 run_lib.py:133] step: 1247250, training_loss: 3.44027e-02
I0213 14:47:46.288442 22542570456896 run_lib.py:133] step: 1247300, training_loss: 2.48505e-02
I0213 14:47:46.445780 22542570456896 run_lib.py:146] step: 1247300, eval_loss: 3.06025e-02
I0213 14:48:04.036760 22542570456896 run_lib.py:133] step: 1247350, training_loss: 3.10862e-02
I0213 14:48:21.534802 22542570456896 run_lib.py:133] step: 1247400, training_loss: 2.99872e-02
I0213 14:48:21.695483 22542570456896 run_lib.py:146] step: 1247400, eval_loss: 3.09249e-02
I0213 14:48:39.144840 22542570456896 run_lib.py:133] step: 1247450, training_loss: 2.57695e-02
I0213 14:48:56.608462 22542570456896 run_lib.py:133] step: 1247500, training_loss: 2.30959e-02
I0213 14:48:56.773442 22542570456896 run_lib.py:146] step: 1247500, eval_loss: 3.46767e-02
I0213 14:49:14.388947 22542570456896 run_lib.py:133] step: 1247550, training_loss: 2.18226e-02
I0213 14:49:32.025909 22542570456896 run_lib.py:133] step: 1247600, training_loss: 2.35586e-02
I0213 14:49:32.187281 22542570456896 run_lib.py:146] step: 1247600, eval_loss: 3.30207e-02
I0213 14:49:49.646161 22542570456896 run_lib.py:133] step: 1247650, training_loss: 2.25652e-02
I0213 14:50:07.092816 22542570456896 run_lib.py:133] step: 1247700, training_loss: 2.00432e-02
I0213 14:50:07.246437 22542570456896 run_lib.py:146] step: 1247700, eval_loss: 3.15685e-02
I0213 14:50:24.871441 22542570456896 run_lib.py:133] step: 1247750, training_loss: 3.29070e-02
I0213 14:50:42.362459 22542570456896 run_lib.py:133] step: 1247800, training_loss: 2.95179e-02
I0213 14:50:42.522675 22542570456896 run_lib.py:146] step: 1247800, eval_loss: 2.83404e-02
I0213 14:51:00.188411 22542570456896 run_lib.py:133] step: 1247850, training_loss: 2.88759e-02
I0213 14:51:17.701206 22542570456896 run_lib.py:133] step: 1247900, training_loss: 2.83214e-02
I0213 14:51:17.862534 22542570456896 run_lib.py:146] step: 1247900, eval_loss: 2.31587e-02
I0213 14:51:35.504948 22542570456896 run_lib.py:133] step: 1247950, training_loss: 2.99387e-02
I0213 14:51:52.973536 22542570456896 run_lib.py:133] step: 1248000, training_loss: 2.95522e-02
I0213 14:51:53.130349 22542570456896 run_lib.py:146] step: 1248000, eval_loss: 2.95778e-02
I0213 14:52:10.765637 22542570456896 run_lib.py:133] step: 1248050, training_loss: 2.59296e-02
I0213 14:52:28.237757 22542570456896 run_lib.py:133] step: 1248100, training_loss: 2.16807e-02
I0213 14:52:28.390340 22542570456896 run_lib.py:146] step: 1248100, eval_loss: 2.34265e-02
I0213 14:52:45.872853 22542570456896 run_lib.py:133] step: 1248150, training_loss: 3.09342e-02
I0213 14:53:03.610306 22542570456896 run_lib.py:133] step: 1248200, training_loss: 2.74688e-02
I0213 14:53:03.765756 22542570456896 run_lib.py:146] step: 1248200, eval_loss: 2.89417e-02
I0213 14:53:21.211869 22542570456896 run_lib.py:133] step: 1248250, training_loss: 3.58769e-02
I0213 14:53:38.704727 22542570456896 run_lib.py:133] step: 1248300, training_loss: 3.43071e-02
I0213 14:53:38.863457 22542570456896 run_lib.py:146] step: 1248300, eval_loss: 2.35866e-02
I0213 14:53:56.479037 22542570456896 run_lib.py:133] step: 1248350, training_loss: 3.29043e-02
I0213 14:54:14.033960 22542570456896 run_lib.py:133] step: 1248400, training_loss: 3.04863e-02
I0213 14:54:14.213662 22542570456896 run_lib.py:146] step: 1248400, eval_loss: 3.62082e-02
I0213 14:54:31.889852 22542570456896 run_lib.py:133] step: 1248450, training_loss: 2.55616e-02
I0213 14:54:49.363987 22542570456896 run_lib.py:133] step: 1248500, training_loss: 2.96379e-02
I0213 14:54:49.521667 22542570456896 run_lib.py:146] step: 1248500, eval_loss: 2.69825e-02
I0213 14:55:06.985189 22542570456896 run_lib.py:133] step: 1248550, training_loss: 2.69176e-02
I0213 14:55:24.600781 22542570456896 run_lib.py:133] step: 1248600, training_loss: 2.74020e-02
I0213 14:55:24.758399 22542570456896 run_lib.py:146] step: 1248600, eval_loss: 3.30217e-02
I0213 14:55:42.244846 22542570456896 run_lib.py:133] step: 1248650, training_loss: 3.25208e-02
I0213 14:55:59.739000 22542570456896 run_lib.py:133] step: 1248700, training_loss: 2.62228e-02
I0213 14:55:59.894619 22542570456896 run_lib.py:146] step: 1248700, eval_loss: 3.18044e-02
I0213 14:56:17.385448 22542570456896 run_lib.py:133] step: 1248750, training_loss: 3.47790e-02
I0213 14:56:35.085517 22542570456896 run_lib.py:133] step: 1248800, training_loss: 2.80815e-02
I0213 14:56:35.247750 22542570456896 run_lib.py:146] step: 1248800, eval_loss: 2.77835e-02
I0213 14:56:52.672642 22542570456896 run_lib.py:133] step: 1248850, training_loss: 2.75950e-02
I0213 14:57:10.190104 22542570456896 run_lib.py:133] step: 1248900, training_loss: 2.85454e-02
I0213 14:57:10.366430 22542570456896 run_lib.py:146] step: 1248900, eval_loss: 2.90993e-02
I0213 14:57:27.868044 22542570456896 run_lib.py:133] step: 1248950, training_loss: 3.02226e-02
I0213 14:57:45.352073 22542570456896 run_lib.py:133] step: 1249000, training_loss: 2.72952e-02
I0213 14:57:45.509168 22542570456896 run_lib.py:146] step: 1249000, eval_loss: 2.59744e-02
I0213 14:58:03.170598 22542570456896 run_lib.py:133] step: 1249050, training_loss: 2.80184e-02
I0213 14:58:20.693060 22542570456896 run_lib.py:133] step: 1249100, training_loss: 2.71464e-02
I0213 14:58:20.844085 22542570456896 run_lib.py:146] step: 1249100, eval_loss: 3.28648e-02
I0213 14:58:38.313807 22542570456896 run_lib.py:133] step: 1249150, training_loss: 2.62058e-02
I0213 14:58:55.827148 22542570456896 run_lib.py:133] step: 1249200, training_loss: 2.49263e-02
I0213 14:58:55.984696 22542570456896 run_lib.py:146] step: 1249200, eval_loss: 3.07209e-02
I0213 14:59:13.647275 22542570456896 run_lib.py:133] step: 1249250, training_loss: 2.57151e-02
I0213 14:59:31.095039 22542570456896 run_lib.py:133] step: 1249300, training_loss: 2.77093e-02
I0213 14:59:31.253616 22542570456896 run_lib.py:146] step: 1249300, eval_loss: 3.25940e-02
I0213 14:59:48.829030 22542570456896 run_lib.py:133] step: 1249350, training_loss: 3.25728e-02
I0213 15:00:06.293475 22542570456896 run_lib.py:133] step: 1249400, training_loss: 2.40853e-02
I0213 15:00:06.451885 22542570456896 run_lib.py:146] step: 1249400, eval_loss: 2.87142e-02
I0213 15:00:24.073343 22542570456896 run_lib.py:133] step: 1249450, training_loss: 2.75851e-02
I0213 15:00:41.542131 22542570456896 run_lib.py:133] step: 1249500, training_loss: 3.00930e-02
I0213 15:00:41.697764 22542570456896 run_lib.py:146] step: 1249500, eval_loss: 2.66127e-02
I0213 15:00:59.143069 22542570456896 run_lib.py:133] step: 1249550, training_loss: 2.78764e-02
I0213 15:01:16.779948 22542570456896 run_lib.py:133] step: 1249600, training_loss: 2.65043e-02
I0213 15:01:16.932559 22542570456896 run_lib.py:146] step: 1249600, eval_loss: 3.19144e-02
I0213 15:01:34.404516 22542570456896 run_lib.py:133] step: 1249650, training_loss: 2.88441e-02
I0213 15:01:52.003767 22542570456896 run_lib.py:133] step: 1249700, training_loss: 1.88333e-02
I0213 15:01:52.173937 22542570456896 run_lib.py:146] step: 1249700, eval_loss: 3.04791e-02
I0213 15:02:09.658526 22542570456896 run_lib.py:133] step: 1249750, training_loss: 2.87404e-02
I0213 15:02:27.185586 22542570456896 run_lib.py:133] step: 1249800, training_loss: 2.82807e-02
I0213 15:02:27.344342 22542570456896 run_lib.py:146] step: 1249800, eval_loss: 3.55200e-02
I0213 15:02:44.867323 22542570456896 run_lib.py:133] step: 1249850, training_loss: 2.85144e-02
I0213 15:03:02.278299 22542570456896 run_lib.py:133] step: 1249900, training_loss: 2.96682e-02
I0213 15:03:02.443381 22542570456896 run_lib.py:146] step: 1249900, eval_loss: 2.72859e-02
I0213 15:03:19.853071 22542570456896 run_lib.py:133] step: 1249950, training_loss: 2.43226e-02
I0213 15:03:37.349783 22542570456896 run_lib.py:133] step: 1250000, training_loss: 2.45296e-02
I0213 15:03:38.066994 22542570456896 run_lib.py:146] step: 1250000, eval_loss: 2.84218e-02
I0213 15:03:58.101351 22542570456896 run_lib.py:133] step: 1250050, training_loss: 2.41029e-02
I0213 15:04:15.536970 22542570456896 run_lib.py:133] step: 1250100, training_loss: 3.26370e-02
I0213 15:04:15.698306 22542570456896 run_lib.py:146] step: 1250100, eval_loss: 2.72993e-02
I0213 15:04:33.334430 22542570456896 run_lib.py:133] step: 1250150, training_loss: 2.54850e-02
I0213 15:04:50.717952 22542570456896 run_lib.py:133] step: 1250200, training_loss: 3.08053e-02
I0213 15:04:50.869300 22542570456896 run_lib.py:146] step: 1250200, eval_loss: 2.64672e-02
I0213 15:05:08.268699 22542570456896 run_lib.py:133] step: 1250250, training_loss: 1.90864e-02
I0213 15:05:25.759544 22542570456896 run_lib.py:133] step: 1250300, training_loss: 3.00600e-02
I0213 15:05:25.941343 22542570456896 run_lib.py:146] step: 1250300, eval_loss: 3.05536e-02
I0213 15:05:43.608192 22542570456896 run_lib.py:133] step: 1250350, training_loss: 2.53527e-02
I0213 15:06:01.041844 22542570456896 run_lib.py:133] step: 1250400, training_loss: 2.50232e-02
I0213 15:06:01.198640 22542570456896 run_lib.py:146] step: 1250400, eval_loss: 2.97862e-02
I0213 15:06:18.716639 22542570456896 run_lib.py:133] step: 1250450, training_loss: 2.81590e-02
I0213 15:06:36.097384 22542570456896 run_lib.py:133] step: 1250500, training_loss: 2.87078e-02
I0213 15:06:36.252290 22542570456896 run_lib.py:146] step: 1250500, eval_loss: 3.25192e-02
I0213 15:06:53.733802 22542570456896 run_lib.py:133] step: 1250550, training_loss: 2.35486e-02
slurmstepd: error: *** JOB 47658247 ON gl1511 CANCELLED AT 2023-02-13T15:07:05 ***
