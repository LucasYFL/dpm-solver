[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
2023-05-18 01:57:21.773276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-18 01:57:27.327208: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-18 01:57:42.299106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 01:57:42.300255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 01:57:42.300274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
I0518 01:58:25.551187 23046703068992 main_interval.py:85] (0.442, 0.6308)
I0518 01:59:12.847747 23046703068992 sampling.py:98] dpm_solver
I0518 01:59:12.848187 23046703068992 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
I0518 01:59:16.156919 23046703068992 main_interval.py:152] begin checkpoint: 5
I0518 01:59:16.157190 23046703068992 main_interval.py:156] 0 is converged model
I0518 01:59:16.157249 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 02:00:25.858772 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_5.pth
I0518 02:01:41.124704 23046703068992 main_interval.py:156] 2 is converged model
I0518 02:01:41.163787 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 02:02:52.499926 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 02:02:52.509997 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 0
[2023-05-18 02:02:53,273] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:02:53,938] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-18 02:02:54,213] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-18 02:02:54,215] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:02:54,215] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:02:54,347] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:03:00,345] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-05-18 02:03:00,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-18 02:03:00,610] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:00,935] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-18 02:03:00,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-18 02:03:00,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-18 02:03:47,593] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:53,742] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:53,742] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:53,747] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:53,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-05-18 02:03:54,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-18 02:03:54,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-18 02:03:54,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-18 02:03:54,659] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:54,779] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:03:54,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:03:54,782] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:54,782] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:54,782] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:03:54,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-05-18 02:03:54,881] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-18 02:03:54,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:54,887] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:54,925] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:54,925] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:54,926] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:54,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-18 02:03:55,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-18 02:03:55,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-18 02:03:55,276] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-18 02:03:55,286] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:55,292] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:55,329] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:55,330] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:55,330] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:55,372] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-18 02:03:55,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-18 02:03:55,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-18 02:03:55,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-18 02:03:55,655] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:55,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:55,698] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:55,698] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:55,699] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:55,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-18 02:03:55,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-18 02:03:55,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-18 02:03:56,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-18 02:03:56,025] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:56,031] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:56,068] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:56,068] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:56,069] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:56,110] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-18 02:03:56,174] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-18 02:03:56,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-18 02:03:56,390] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-18 02:03:56,402] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:56,409] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:56,448] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:56,448] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:56,449] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:56,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-18 02:03:56,564] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-18 02:03:56,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-18 02:03:56,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-18 02:03:56,800] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:56,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:56,846] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:56,846] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:56,847] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:56,891] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-18 02:03:56,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-18 02:03:57,059] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-18 02:03:57,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-18 02:03:57,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:57,197] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:57,236] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:57,236] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:57,237] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:57,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-18 02:03:57,346] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-18 02:03:57,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-18 02:03:57,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-18 02:03:57,572] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:57,578] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:57,643] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:57,643] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:57,644] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:57,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-05-18 02:03:57,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-05-18 02:03:57,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-18 02:03:58,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-18 02:03:58,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:58,379] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:03:58,382] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:03:58,384] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:58,384] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:58,385] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:03:58,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-18 02:03:58,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-18 02:03:58,425] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:58,431] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:58,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:58,475] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:58,476] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:58,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-18 02:03:59,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-18 02:03:59,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-18 02:03:59,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-18 02:03:59,291] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:59,316] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:03:59,317] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:03:59,319] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:59,319] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:59,319] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:03:59,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-18 02:03:59,347] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-18 02:03:59,347] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:03:59,351] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:03:59,485] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:03:59,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:03:59,486] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:03:59,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-05-18 02:03:59,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-05-18 02:03:59,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-05-18 02:04:00,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-18 02:04:00,111] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:00,167] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:04:00,168] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:04:00,169] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:00,169] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:00,170] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:00,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-18 02:04:00,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-18 02:04:00,188] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:00,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:00,231] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:00,231] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:00,232] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:00,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-18 02:04:00,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-18 02:04:00,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-18 02:04:00,588] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-18 02:04:00,590] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:00,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:00,717] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:00,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:00,718] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:00,761] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-18 02:04:00,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-18 02:04:01,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-18 02:04:01,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-18 02:04:01,194] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:01,202] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:01,242] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:01,242] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:01,243] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:01,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-18 02:04:01,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-18 02:04:01,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-18 02:04:01,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-18 02:04:01,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:01,566] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:01,675] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:01,675] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:01,676] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:01,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-18 02:04:01,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-18 02:04:01,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-18 02:04:02,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-18 02:04:02,145] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:02,151] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:02,190] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:02,190] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:02,191] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:02,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-18 02:04:02,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-18 02:04:02,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-18 02:04:02,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-18 02:04:02,501] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:02,506] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:02,620] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:02,620] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:02,621] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:02,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-18 02:04:02,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-18 02:04:02,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-18 02:04:03,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-18 02:04:03,089] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:03,096] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:03,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:03,138] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:03,138] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:03,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-18 02:04:03,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-18 02:04:03,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-18 02:04:03,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-18 02:04:03,447] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:03,451] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:03,560] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:03,560] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:03,560] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:03,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-18 02:04:03,656] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-18 02:04:03,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-18 02:04:04,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-18 02:04:04,031] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:04,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:04,079] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:04,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:04,080] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:04,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-18 02:04:04,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-18 02:04:04,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-18 02:04:04,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-18 02:04:04,388] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:04,393] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:04,500] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:04,500] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:04,501] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:04,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-18 02:04:04,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-18 02:04:04,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-18 02:04:04,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-18 02:04:04,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:04,979] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:05,018] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:05,019] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:05,019] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:05,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-18 02:04:05,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-18 02:04:05,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-18 02:04:05,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-18 02:04:05,340] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:05,346] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:05,459] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:05,459] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:05,460] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:05,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-18 02:04:05,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-18 02:04:05,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-18 02:04:05,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-18 02:04:05,931] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:05,938] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:05,978] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:05,978] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:05,979] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:06,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-18 02:04:06,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-18 02:04:06,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-18 02:04:06,287] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-18 02:04:06,289] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:06,294] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:06,402] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:06,402] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:06,403] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:06,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-18 02:04:06,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-18 02:04:06,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-18 02:04:06,836] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-18 02:04:06,866] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:06,874] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:06,928] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:06,928] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:06,929] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:07,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-18 02:04:07,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-18 02:04:07,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-18 02:04:07,436] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-18 02:04:07,440] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:07,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:04:07,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:04:07,485] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:07,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:07,485] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:07,494] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
[2023-05-18 02:04:07,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-18 02:04:07,514] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:07,519] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:07,560] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:07,560] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:07,561] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:07,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-18 02:04:07,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-18 02:04:07,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-18 02:04:07,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-18 02:04:07,918] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:07,928] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:07,966] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:07,967] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:07,967] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:08,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-18 02:04:08,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-18 02:04:08,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-18 02:04:08,606] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-18 02:04:08,608] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:08,614] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:08,652] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:08,652] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:08,653] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:08,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-18 02:04:08,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-18 02:04:08,946] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-18 02:04:08,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-18 02:04:08,966] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:08,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:09,009] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:09,009] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:09,010] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:09,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-18 02:04:09,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-18 02:04:09,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-18 02:04:09,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-18 02:04:09,315] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:09,320] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:09,359] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:09,359] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:09,359] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:09,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-18 02:04:09,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-18 02:04:09,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-18 02:04:09,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-18 02:04:09,672] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:09,677] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:09,715] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:09,715] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:09,716] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:09,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-18 02:04:09,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-18 02:04:09,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-18 02:04:10,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-18 02:04:10,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:10,023] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:10,061] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:10,062] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:10,062] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:10,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-18 02:04:10,325] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-18 02:04:10,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-18 02:04:10,372] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-18 02:04:10,374] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:10,380] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:10,419] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:10,419] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:10,420] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:10,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-18 02:04:10,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-18 02:04:10,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-18 02:04:10,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-18 02:04:10,722] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:10,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:10,779] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:10,779] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:10,780] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:10,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-18 02:04:11,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-18 02:04:11,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-18 02:04:11,284] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-18 02:04:11,287] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:11,330] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:04:11,331] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:04:11,332] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:11,332] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:11,333] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:11,341] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-18 02:04:11,362] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-18 02:04:11,363] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:11,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:11,405] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:11,406] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:11,406] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:11,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-18 02:04:11,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-18 02:04:11,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-18 02:04:11,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-18 02:04:11,773] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:11,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:11,821] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:11,822] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:11,822] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:11,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-18 02:04:12,075] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-18 02:04:12,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-18 02:04:12,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-18 02:04:12,125] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:12,130] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:12,169] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:12,169] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:12,170] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:12,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-18 02:04:12,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-18 02:04:12,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-18 02:04:12,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-18 02:04:12,485] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:12,491] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:12,530] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:12,530] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:12,530] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:12,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-18 02:04:12,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-18 02:04:12,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-18 02:04:12,834] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-18 02:04:12,837] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:12,842] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:12,882] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:12,882] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:12,883] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:13,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-18 02:04:13,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-18 02:04:13,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-18 02:04:13,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-18 02:04:13,195] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:13,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:13,238] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:13,239] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:13,239] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:13,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-18 02:04:13,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-18 02:04:13,532] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-18 02:04:13,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-18 02:04:13,552] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:13,559] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:13,599] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:13,599] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:13,742] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:13,861] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-18 02:04:13,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-18 02:04:14,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-18 02:04:14,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-18 02:04:14,046] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:14,052] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:14,089] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:14,090] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:14,090] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:14,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-18 02:04:14,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-18 02:04:14,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-18 02:04:14,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-18 02:04:14,403] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:14,409] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:14,450] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:14,450] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:14,451] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:14,574] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-18 02:04:14,710] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-18 02:04:14,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-18 02:04:14,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-18 02:04:14,760] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:14,765] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:14,876] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:14,876] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:14,877] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:14,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-18 02:04:14,988] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-18 02:04:15,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
[2023-05-18 02:04:15,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-18 02:04:15,492] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:15,518] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:04:15,519] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:04:15,520] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:15,521] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:15,521] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:15,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-18 02:04:15,540] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-18 02:04:15,541] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:15,545] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:15,584] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:15,584] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:15,585] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:15,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-18 02:04:15,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-18 02:04:15,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-18 02:04:15,906] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-18 02:04:15,909] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:15,915] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:15,958] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:15,958] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:15,959] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:16,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-18 02:04:16,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-18 02:04:16,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-18 02:04:16,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-18 02:04:16,356] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:16,373] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:16,415] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:16,415] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:16,416] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:16,534] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-18 02:04:16,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-18 02:04:16,721] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-18 02:04:16,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-18 02:04:16,746] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:16,752] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:16,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:16,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:16,799] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:16,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-18 02:04:17,058] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-18 02:04:17,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-18 02:04:17,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-18 02:04:17,123] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:17,128] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:17,170] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:17,170] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:17,171] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:17,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-18 02:04:17,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-18 02:04:17,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-18 02:04:17,872] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-18 02:04:17,875] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:17,881] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:17,924] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:17,924] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:17,925] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:18,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-18 02:04:18,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-18 02:04:18,235] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-18 02:04:18,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-18 02:04:18,261] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:18,267] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:18,308] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:18,308] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:18,309] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:18,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-18 02:04:18,569] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-18 02:04:18,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-18 02:04:18,633] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-18 02:04:18,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:18,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:18,686] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:18,686] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:18,687] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:18,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-18 02:04:18,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-18 02:04:18,991] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-18 02:04:19,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-18 02:04:19,017] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:19,022] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:19,064] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:19,065] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:19,065] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:19,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-18 02:04:19,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-18 02:04:19,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-18 02:04:19,396] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-18 02:04:19,399] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:19,405] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:19,447] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:19,447] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:19,448] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:19,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-18 02:04:19,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-18 02:04:19,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-18 02:04:19,775] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-18 02:04:19,779] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:19,785] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:19,839] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:19,839] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:19,840] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:19,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-18 02:04:20,207] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-18 02:04:20,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-18 02:04:20,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-18 02:04:20,274] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:20,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:20,323] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:20,323] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:20,324] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:20,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-18 02:04:20,631] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-18 02:04:20,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-18 02:04:20,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-18 02:04:20,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:20,722] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:20,764] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:20,765] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:20,766] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:20,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-18 02:04:21,030] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-18 02:04:21,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-18 02:04:21,096] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-18 02:04:21,098] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:21,104] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:21,146] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:21,146] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:21,147] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:21,268] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-18 02:04:21,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-18 02:04:21,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-18 02:04:21,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-18 02:04:21,481] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:21,487] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:21,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:21,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:21,530] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:21,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-18 02:04:21,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-18 02:04:21,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-18 02:04:21,854] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-18 02:04:21,857] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:21,863] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:21,904] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:21,905] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:21,905] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:22,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-18 02:04:22,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-18 02:04:22,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-18 02:04:22,241] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-18 02:04:22,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:22,250] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:22,291] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:22,291] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:22,292] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:22,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-18 02:04:22,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-18 02:04:22,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-18 02:04:22,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-18 02:04:22,616] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:22,622] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:22,664] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:22,665] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:22,665] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:22,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-18 02:04:22,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-18 02:04:22,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-18 02:04:23,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-18 02:04:23,005] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:23,010] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:23,051] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:23,052] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:23,052] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:23,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-18 02:04:23,315] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-18 02:04:23,358] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-18 02:04:23,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-18 02:04:23,384] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:23,391] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:23,437] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:23,437] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:23,437] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:23,560] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-18 02:04:23,705] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-18 02:04:23,744] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-18 02:04:23,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-18 02:04:23,768] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:23,774] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:23,826] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:23,827] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:23,827] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:23,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-18 02:04:24,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-18 02:04:24,236] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-18 02:04:24,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-18 02:04:24,267] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:24,279] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:24,321] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:24,321] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:24,322] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:24,439] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-18 02:04:24,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-18 02:04:24,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-18 02:04:24,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-18 02:04:24,691] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:24,709] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:24,753] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:24,753] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:24,753] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:24,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-18 02:04:25,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-18 02:04:25,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-18 02:04:25,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-18 02:04:25,111] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:25,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:25,158] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:25,158] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:25,159] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:25,276] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-18 02:04:25,421] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-18 02:04:25,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-18 02:04:25,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-18 02:04:25,490] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:25,496] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:25,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:25,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:25,544] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:25,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-18 02:04:25,810] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-18 02:04:25,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-18 02:04:25,872] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-18 02:04:25,874] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:25,880] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:25,921] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:25,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:25,922] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:26,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-18 02:04:26,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-18 02:04:26,230] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-18 02:04:26,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-18 02:04:26,255] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:26,261] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:26,303] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:26,303] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:26,304] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:26,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-18 02:04:26,569] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-18 02:04:26,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-18 02:04:26,633] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-18 02:04:26,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:26,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:26,683] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:26,683] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:26,684] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:26,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-18 02:04:27,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-18 02:04:27,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-18 02:04:27,388] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-18 02:04:27,391] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:27,395] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 23041298606592)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-18 02:04:27,395] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-18 02:04:27,447] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:27,563] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:27,563] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:27,564] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:27,606] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-18 02:04:27,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-18 02:04:27,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-18 02:04:28,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-18 02:04:28,045] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:28,051] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:04:28,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:04:28,056] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:28,057] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:28,057] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:28,070] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-18 02:04:28,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-18 02:04:28,132] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:28,749] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:04:28,753] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:04:28,754] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:28,754] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:28,754] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:28,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-18 02:04:28,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-18 02:04:28,802] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:28,818] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:04:28,822] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:04:28,823] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:28,823] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:28,824] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:29,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
[2023-05-18 02:04:29,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-18 02:04:29,172] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:29,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:04:29,185] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:04:29,186] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:29,186] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:29,186] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:29,197] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-18 02:04:29,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-18 02:04:29,226] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:29,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:04:29,247] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:04:29,248] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:29,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:29,249] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:29,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-18 02:04:29,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-18 02:04:29,289] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:29,332] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:04:29,337] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:04:29,338] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:29,338] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:29,339] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:04:29,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-18 02:04:29,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-18 02:04:29,383] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:37,673] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:37,786] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:37,786] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:37,787] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:37,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-18 02:04:37,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-18 02:04:38,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-18 02:04:38,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-18 02:04:38,279] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:38,286] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:38,413] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:38,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:38,413] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:38,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-18 02:04:38,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-18 02:04:38,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-18 02:04:38,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-18 02:04:38,888] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:38,894] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:39,000] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:39,000] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:39,001] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:39,043] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-18 02:04:39,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-18 02:04:39,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-18 02:04:39,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-18 02:04:39,473] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:39,479] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:39,591] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:39,592] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:39,592] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:39,635] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-18 02:04:39,684] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-18 02:04:39,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-18 02:04:40,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-18 02:04:40,063] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:40,069] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:40,185] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:40,185] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:40,186] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:40,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-18 02:04:40,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-18 02:04:40,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-18 02:04:40,626] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-18 02:04:40,657] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:40,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:40,775] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:40,776] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:40,776] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:40,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-18 02:04:40,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-18 02:04:41,097] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-18 02:04:41,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-18 02:04:41,245] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:41,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:41,366] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:41,367] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:41,367] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:41,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-18 02:04:41,461] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-18 02:04:41,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-18 02:04:41,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-18 02:04:41,836] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:41,842] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:41,957] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:41,957] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:41,957] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:42,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-18 02:04:42,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-18 02:04:42,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-18 02:04:42,398] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-18 02:04:42,429] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:42,445] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:42,553] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:42,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:42,554] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:42,596] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-18 02:04:42,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-18 02:04:42,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-18 02:04:43,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-18 02:04:43,049] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:43,073] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:43,181] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:43,181] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:43,181] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:43,225] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-18 02:04:43,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-18 02:04:43,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-18 02:04:43,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-18 02:04:43,654] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:46,076] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:46,192] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:46,192] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:46,193] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:46,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 182
[2023-05-18 02:04:46,297] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 182
[2023-05-18 02:04:46,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 183
[2023-05-18 02:04:46,641] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 183
[2023-05-18 02:04:46,672] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:46,678] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:46,790] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:46,790] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:46,790] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:46,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 184
[2023-05-18 02:04:46,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 184
[2023-05-18 02:04:47,118] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 185
[2023-05-18 02:04:47,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 185
[2023-05-18 02:04:47,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:47,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:47,377] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:47,377] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:47,377] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:47,421] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 186
[2023-05-18 02:04:47,471] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 186
[2023-05-18 02:04:47,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 187
[2023-05-18 02:04:47,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 187
[2023-05-18 02:04:47,851] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:47,857] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:47,964] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:47,964] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:47,964] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:48,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 188
[2023-05-18 02:04:48,055] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 188
[2023-05-18 02:04:48,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 189
[2023-05-18 02:04:48,405] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 189
[2023-05-18 02:04:48,436] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:48,442] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:48,548] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:48,548] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:48,549] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:48,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 190
[2023-05-18 02:04:48,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 190
[2023-05-18 02:04:48,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 191
[2023-05-18 02:04:48,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 191
[2023-05-18 02:04:49,021] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:49,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:49,135] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:49,135] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:49,135] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:49,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 192
[2023-05-18 02:04:49,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 192
[2023-05-18 02:04:49,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 193
[2023-05-18 02:04:49,572] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 193
[2023-05-18 02:04:49,603] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:49,610] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:49,722] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:49,722] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:49,723] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:49,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 194
[2023-05-18 02:04:49,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 194
[2023-05-18 02:04:50,039] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 195
[2023-05-18 02:04:50,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 195
[2023-05-18 02:04:50,185] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:50,191] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:50,310] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:50,310] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:50,310] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:50,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 196
[2023-05-18 02:04:50,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 196
[2023-05-18 02:04:50,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 197
[2023-05-18 02:04:50,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 197
[2023-05-18 02:04:50,778] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:50,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:50,910] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:50,910] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:50,910] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:51,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 198
[2023-05-18 02:04:51,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 198
[2023-05-18 02:04:51,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 199
[2023-05-18 02:04:51,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 199
[2023-05-18 02:04:51,825] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:04:51,849] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:04:51,955] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:04:51,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:04:51,956] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:04:51,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 200
[2023-05-18 02:04:52,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 200
[2023-05-18 02:04:52,273] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 201
[2023-05-18 02:04:52,392] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 201
[2023-05-18 02:04:52,423] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0518 02:05:13.187098 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 1
I0518 02:05:49.208286 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 2
I0518 02:06:25.378696 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 3
I0518 02:07:01.580166 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 4
I0518 02:07:37.796412 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 5
I0518 02:08:14.025870 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 6
I0518 02:08:50.450241 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 7
I0518 02:09:26.681742 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 8
I0518 02:10:02.922161 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 9
I0518 02:10:39.164169 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 10
I0518 02:11:15.447226 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 11
I0518 02:11:51.683292 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 12
I0518 02:12:27.926901 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 13
I0518 02:13:04.155505 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 14
I0518 02:13:40.542441 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 15
I0518 02:14:16.784002 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 16
I0518 02:14:53.007857 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 17
I0518 02:15:29.230475 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 18
I0518 02:16:05.458309 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 19
I0518 02:16:41.737365 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 20
I0518 02:17:17.972279 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 21
I0518 02:17:54.200982 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 22
I0518 02:18:30.445473 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 23
I0518 02:19:06.835093 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 24
I0518 02:19:43.074240 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 25
I0518 02:20:19.301515 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 26
I0518 02:20:55.579657 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 27
I0518 02:21:31.819169 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 28
I0518 02:22:08.045595 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 29
I0518 02:22:44.279776 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 30
I0518 02:23:20.516064 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 31
I0518 02:23:56.790114 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 32
I0518 02:24:33.027190 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 33
I0518 02:25:09.266983 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 34
I0518 02:25:45.493710 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 35
I0518 02:26:21.759784 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 36
I0518 02:26:57.996521 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 37
I0518 02:27:34.239412 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 38
I0518 02:28:10.490319 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 39
I0518 02:28:46.792514 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 40
I0518 02:29:23.123558 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 41
I0518 02:29:59.364211 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 42
I0518 02:30:35.587594 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 43
I0518 02:31:11.883820 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 44
I0518 02:31:48.148958 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 45
I0518 02:32:24.400058 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 46
I0518 02:33:00.637957 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 47
I0518 02:33:36.910700 23046703068992 main_interval.py:215] sampling -- ckpt: 5, round: 48
I0518 02:34:13.137517 23046703068992 main_interval.py:156] 0 is converged model
I0518 02:34:13.137706 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 02:38:03.199733 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth
W0518 02:38:03.226210 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth. Returned the same state as input
I0518 02:38:03.236811 23046703068992 main_interval.py:156] 2 is converged model
I0518 02:38:03.236921 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 02:40:31.842224 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 02:40:31.958743 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 0
I0518 02:41:08.361792 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 1
I0518 02:41:44.394529 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 2
I0518 02:42:20.591228 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 3
I0518 02:42:56.838885 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 4
I0518 02:43:33.059198 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 5
I0518 02:44:09.332332 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 6
I0518 02:44:45.558129 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 7
I0518 02:45:21.786839 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 8
I0518 02:45:58.019606 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 9
I0518 02:46:34.248808 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 10
I0518 02:47:10.499080 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 11
I0518 02:47:46.763685 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 12
I0518 02:48:23.004083 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 13
I0518 02:48:59.333747 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 14
I0518 02:49:35.577369 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 15
I0518 02:50:11.822103 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 16
I0518 02:50:48.054232 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 17
I0518 02:51:24.285651 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 18
I0518 02:52:00.522378 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 19
I0518 02:52:36.760566 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 20
I0518 02:53:13.054305 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 21
I0518 02:53:49.297373 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 22
I0518 02:54:25.541866 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 23
I0518 02:55:01.782248 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 24
I0518 02:55:38.023903 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 25
I0518 02:56:14.258939 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 26
I0518 02:56:50.556909 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 27
I0518 02:57:26.800376 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 28
I0518 02:58:03.034882 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 29
I0518 02:58:39.429760 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 30
I0518 02:59:15.712004 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 31
I0518 02:59:51.954595 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 32
I0518 03:00:28.188704 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 33
I0518 03:01:04.419920 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 34
I0518 03:01:40.663288 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 35
I0518 03:02:16.907515 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 36
I0518 03:02:53.192419 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 37
I0518 03:03:29.435350 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 38
I0518 03:04:05.708365 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 39
I0518 03:04:41.942770 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 40
I0518 03:05:18.226116 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 41
I0518 03:05:54.474698 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 42
I0518 03:06:30.720284 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 43
I0518 03:07:06.967127 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 44
I0518 03:07:43.207481 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 45
I0518 03:08:19.442863 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 46
I0518 03:08:55.845625 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 47
I0518 03:09:32.091742 23046703068992 main_interval.py:215] sampling -- ckpt: 10, round: 48
I0518 03:10:08.339348 23046703068992 main_interval.py:156] 0 is converged model
I0518 03:10:08.339639 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:12:49.259613 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth
W0518 03:12:49.350866 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth. Returned the same state as input
I0518 03:12:49.361857 23046703068992 main_interval.py:156] 2 is converged model
I0518 03:12:49.361965 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:16:01.105909 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 03:16:01.567599 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 0
I0518 03:16:37.751700 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 1
I0518 03:17:13.798484 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 2
I0518 03:17:49.990903 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 3
I0518 03:18:26.233436 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 4
I0518 03:19:02.481595 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 5
I0518 03:19:38.767778 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 6
I0518 03:20:15.007405 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 7
I0518 03:20:51.257896 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 8
I0518 03:21:27.493134 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 9
I0518 03:22:03.743786 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 10
I0518 03:22:39.979243 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 11
I0518 03:23:16.283195 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 12
I0518 03:23:52.531820 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 13
I0518 03:24:28.782422 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 14
I0518 03:25:05.000988 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 15
I0518 03:25:41.223858 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 16
I0518 03:26:17.474475 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 17
I0518 03:26:53.725391 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 18
I0518 03:27:30.009804 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 19
I0518 03:28:06.261143 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 20
I0518 03:28:42.508878 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 21
I0518 03:29:18.759188 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 22
I0518 03:29:55.008633 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 23
I0518 03:30:31.257575 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 24
I0518 03:31:07.487055 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 25
I0518 03:31:43.720082 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 26
I0518 03:32:20.713773 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 27
I0518 03:32:56.953801 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 28
I0518 03:33:33.200820 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 29
I0518 03:34:09.711908 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 30
I0518 03:34:45.961081 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 31
I0518 03:35:22.231641 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 32
I0518 03:35:58.481199 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 33
I0518 03:36:34.713609 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 34
I0518 03:37:10.965416 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 35
I0518 03:37:47.210075 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 36
I0518 03:38:23.445659 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 37
I0518 03:38:59.953014 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 38
I0518 03:39:36.200734 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 39
I0518 03:40:12.467191 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 40
I0518 03:40:48.712853 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 41
I0518 03:41:24.959557 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 42
I0518 03:42:01.232918 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 43
I0518 03:42:37.478829 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 44
I0518 03:43:13.727418 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 45
I0518 03:43:49.975983 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 46
I0518 03:44:26.212252 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 47
I0518 03:45:02.449268 23046703068992 main_interval.py:215] sampling -- ckpt: 15, round: 48
I0518 03:45:38.699370 23046703068992 main_interval.py:156] 0 is converged model
I0518 03:45:38.699646 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:50:07.056303 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth
W0518 03:50:07.091175 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth. Returned the same state as input
I0518 03:50:07.100788 23046703068992 main_interval.py:156] 2 is converged model
I0518 03:50:07.100931 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:54:29.106848 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 03:54:29.112571 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 0
I0518 03:55:05.668707 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 1
I0518 03:55:41.713211 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 2
I0518 03:56:17.893951 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 3
I0518 03:56:54.118474 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 4
I0518 03:57:30.359560 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 5
I0518 03:58:06.605250 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 6
I0518 03:58:42.909564 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 7
I0518 03:59:19.154861 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 8
I0518 03:59:55.402223 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 9
I0518 04:00:31.646766 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 10
I0518 04:01:07.891045 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 11
I0518 04:01:44.138341 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 12
I0518 04:02:20.374778 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 13
I0518 04:02:56.607537 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 14
I0518 04:03:32.854198 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 15
I0518 04:04:09.243061 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 16
I0518 04:04:45.491561 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 17
I0518 04:05:21.773629 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 18
I0518 04:05:58.014780 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 19
I0518 04:06:34.296100 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 20
I0518 04:07:10.583762 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 21
I0518 04:07:46.868781 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 22
I0518 04:08:23.111269 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 23
I0518 04:08:59.572301 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 24
I0518 04:09:35.815124 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 25
I0518 04:10:12.062138 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 26
I0518 04:10:48.326396 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 27
I0518 04:11:24.564327 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 28
I0518 04:12:00.849895 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 29
I0518 04:12:37.088702 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 30
I0518 04:13:13.316713 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 31
I0518 04:13:49.553129 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 32
I0518 04:14:25.789465 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 33
I0518 04:15:02.026700 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 34
I0518 04:15:38.276469 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 35
I0518 04:16:14.562079 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 36
I0518 04:16:50.813997 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 37
I0518 04:17:27.065562 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 38
I0518 04:18:03.305707 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 39
I0518 04:18:39.549775 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 40
I0518 04:19:15.828725 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 41
I0518 04:19:52.088572 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 42
I0518 04:20:28.338471 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 43
I0518 04:21:04.579960 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 44
I0518 04:21:40.828295 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 45
I0518 04:22:17.077847 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 46
I0518 04:22:53.366829 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 47
I0518 04:23:29.616935 23046703068992 main_interval.py:215] sampling -- ckpt: 20, round: 48
I0518 04:24:05.916915 23046703068992 main_interval.py:156] 0 is converged model
I0518 04:24:05.917081 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:25:01.365100 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth
W0518 04:25:01.406161 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth. Returned the same state as input
I0518 04:25:01.416080 23046703068992 main_interval.py:156] 2 is converged model
I0518 04:25:01.416226 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:25:57.807408 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 04:25:57.821201 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 0
I0518 04:26:34.066886 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 1
I0518 04:27:10.190077 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 2
I0518 04:27:46.401228 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 3
I0518 04:28:22.644268 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 4
I0518 04:28:58.889973 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 5
I0518 04:29:35.140847 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 6
I0518 04:30:11.414451 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 7
I0518 04:30:47.662074 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 8
I0518 04:31:23.908977 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 9
I0518 04:32:00.194080 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 10
I0518 04:32:36.430862 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 11
I0518 04:33:12.659380 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 12
I0518 04:33:48.904838 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 13
I0518 04:34:25.147884 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 14
I0518 04:35:01.394627 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 15
I0518 04:35:37.639396 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 16
I0518 04:36:13.883674 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 17
I0518 04:36:50.129954 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 18
I0518 04:37:26.400313 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 19
I0518 04:38:02.670111 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 20
I0518 04:38:38.916665 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 21
I0518 04:39:15.164354 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 22
I0518 04:39:51.447321 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 23
I0518 04:40:27.693883 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 24
I0518 04:41:03.947906 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 25
I0518 04:41:40.189154 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 26
I0518 04:42:16.425775 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 27
I0518 04:42:52.721963 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 28
I0518 04:43:28.968639 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 29
I0518 04:44:05.257968 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 30
I0518 04:44:41.496438 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 31
I0518 04:45:17.731670 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 32
I0518 04:45:53.982423 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 33
I0518 04:46:30.232981 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 34
I0518 04:47:06.470555 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 35
I0518 04:47:42.753299 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 36
I0518 04:48:19.005662 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 37
I0518 04:48:55.261945 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 38
I0518 04:49:31.507648 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 39
I0518 04:50:07.756594 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 40
I0518 04:50:44.017916 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 41
I0518 04:51:20.253955 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 42
I0518 04:51:56.500126 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 43
I0518 04:52:32.750450 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 44
I0518 04:53:09.000937 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 45
I0518 04:53:45.238306 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 46
I0518 04:54:21.485870 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 47
I0518 04:54:57.951521 23046703068992 main_interval.py:215] sampling -- ckpt: 25, round: 48
I0518 04:55:34.198406 23046703068992 main_interval.py:156] 0 is converged model
I0518 04:55:34.198695 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:55:56.012642 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth
W0518 04:55:56.013296 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth. Returned the same state as input
I0518 04:55:56.023204 23046703068992 main_interval.py:156] 2 is converged model
I0518 04:55:56.023311 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:56:17.928941 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 04:56:17.929524 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 0
I0518 04:56:54.295438 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 1
I0518 04:57:30.498373 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 2
I0518 04:58:06.769215 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 3
I0518 04:58:43.001807 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 4
I0518 04:59:19.249974 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 5
I0518 04:59:55.486272 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 6
I0518 05:00:31.717396 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 7
I0518 05:01:07.963922 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 8
I0518 05:01:44.211728 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 9
I0518 05:02:20.496537 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 10
I0518 05:02:56.728986 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 11
I0518 05:03:32.967096 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 12
I0518 05:04:09.227033 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 13
I0518 05:04:45.473881 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 14
I0518 05:05:21.755975 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 15
I0518 05:05:58.003433 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 16
I0518 05:06:34.235209 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 17
I0518 05:07:10.513310 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 18
I0518 05:07:46.760312 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 19
I0518 05:08:23.012076 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 20
I0518 05:08:59.261591 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 21
I0518 05:09:35.498038 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 22
I0518 05:10:11.731821 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 23
I0518 05:10:47.979932 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 24
I0518 05:11:24.227267 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 25
I0518 05:12:00.503535 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 26
I0518 05:12:36.748068 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 27
I0518 05:13:12.989238 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 28
I0518 05:13:49.234549 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 29
I0518 05:14:25.483014 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 30
I0518 05:15:01.720885 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 31
I0518 05:15:37.961602 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 32
I0518 05:16:14.209378 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 33
I0518 05:16:50.452828 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 34
I0518 05:17:26.737668 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 35
I0518 05:18:02.986272 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 36
I0518 05:18:39.236394 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 37
I0518 05:19:15.734799 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 38
I0518 05:19:51.986283 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 39
I0518 05:20:28.238557 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 40
I0518 05:21:04.473687 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 41
I0518 05:21:40.720642 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 42
I0518 05:22:16.970491 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 43
I0518 05:22:53.244121 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 44
I0518 05:23:29.477347 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 45
I0518 05:24:05.844322 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 46
I0518 05:24:42.094299 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 47
I0518 05:25:18.344183 23046703068992 main_interval.py:215] sampling -- ckpt: 30, round: 48
I0518 05:25:54.577292 23046703068992 main_interval.py:156] 0 is converged model
I0518 05:25:54.577573 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:26:33.638948 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth
W0518 05:26:33.671152 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth. Returned the same state as input
I0518 05:26:33.680832 23046703068992 main_interval.py:156] 2 is converged model
I0518 05:26:33.680929 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:27:08.241519 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 05:27:08.256747 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 0
I0518 05:27:44.534778 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 1
I0518 05:28:20.686595 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 2
I0518 05:28:57.097259 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 3
I0518 05:29:33.333790 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 4
I0518 05:30:09.579910 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 5
I0518 05:30:45.860321 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 6
I0518 05:31:22.091261 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 7
I0518 05:31:58.321535 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 8
I0518 05:32:34.563711 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 9
I0518 05:33:10.809796 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 10
I0518 05:33:47.086224 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 11
I0518 05:34:23.333046 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 12
I0518 05:34:59.563920 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 13
I0518 05:35:35.816750 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 14
I0518 05:36:12.051098 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 15
I0518 05:36:48.284404 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 16
I0518 05:37:24.522289 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 17
I0518 05:38:00.807600 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 18
I0518 05:38:37.053677 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 19
I0518 05:39:13.441967 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 20
I0518 05:39:49.652404 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 21
I0518 05:40:25.868028 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 22
I0518 05:41:02.145720 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 23
I0518 05:41:38.376453 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 24
I0518 05:42:14.621320 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 25
I0518 05:42:50.873772 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 26
I0518 05:43:27.118634 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 27
I0518 05:44:03.398196 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 28
I0518 05:44:39.626982 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 29
I0518 05:45:15.873083 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 30
I0518 05:45:52.152529 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 31
I0518 05:46:28.396037 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 32
I0518 05:47:04.624195 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 33
I0518 05:47:40.858780 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 34
I0518 05:48:17.102398 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 35
I0518 05:48:53.349476 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 36
I0518 05:49:29.594693 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 37
I0518 05:50:05.840195 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 38
I0518 05:50:42.120699 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 39
I0518 05:51:18.404645 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 40
I0518 05:51:54.648256 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 41
I0518 05:52:30.892713 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 42
I0518 05:53:07.138064 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 43
I0518 05:53:43.385665 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 44
I0518 05:54:19.633034 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 45
I0518 05:54:55.921883 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 46
I0518 05:55:32.168290 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 47
I0518 05:56:08.415955 23046703068992 main_interval.py:215] sampling -- ckpt: 35, round: 48
I0518 05:56:44.694401 23046703068992 main_interval.py:156] 0 is converged model
I0518 05:56:44.694691 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:57:04.031291 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth
W0518 05:57:04.031966 23046703068992 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth. Returned the same state as input
I0518 05:57:04.042357 23046703068992 main_interval.py:156] 2 is converged model
I0518 05:57:04.042468 23046703068992 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:57:24.493942 23046703068992 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 05:57:24.494493 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 0
I0518 05:58:00.875610 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 1
I0518 05:58:37.077877 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 2
I0518 05:59:13.424024 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 3
I0518 05:59:49.671396 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 4
I0518 06:00:25.918778 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 5
I0518 06:01:02.151736 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 6
I0518 06:01:38.385649 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 7
I0518 06:02:14.672570 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 8
I0518 06:02:50.921791 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 9
I0518 06:03:27.167645 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 10
I0518 06:04:03.458616 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 11
I0518 06:04:39.710777 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 12
I0518 06:05:15.960243 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 13
I0518 06:05:52.208811 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 14
I0518 06:06:28.443966 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 15
I0518 06:07:04.683437 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 16
I0518 06:07:40.968752 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 17
I0518 06:08:17.220822 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 18
I0518 06:08:53.472265 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 19
I0518 06:09:29.710416 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 20
I0518 06:10:05.963044 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 21
I0518 06:10:42.199330 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 22
I0518 06:11:18.448517 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 23
I0518 06:11:54.699150 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 24
I0518 06:12:30.948530 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 25
I0518 06:13:07.195991 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 26
I0518 06:13:43.446474 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 27
I0518 06:14:19.698261 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 28
I0518 06:14:55.954492 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 29
I0518 06:15:32.228774 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 30
I0518 06:16:08.477244 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 31
I0518 06:16:44.727173 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 32
I0518 06:17:20.994392 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 33
I0518 06:17:57.240019 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 34
I0518 06:18:33.481812 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 35
I0518 06:19:09.847558 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 36
I0518 06:19:46.125012 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 37
I0518 06:20:22.354380 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 38
I0518 06:20:58.599843 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 39
I0518 06:21:34.881373 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 40
I0518 06:22:11.125835 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 41
I0518 06:22:47.370296 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 42
I0518 06:23:23.607284 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 43
I0518 06:23:59.949705 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 44
I0518 06:24:36.212801 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 45
I0518 06:25:12.482889 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 46
I0518 06:25:48.725190 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 47
I0518 06:26:25.012778 23046703068992 main_interval.py:215] sampling -- ckpt: 40, round: 48
2023-05-18 06:27:20.862085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-18 06:27:20.975103: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-18 06:27:22.976499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 06:27:22.976611: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 06:27:22.976624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/absl/flags/_validators.py:254: UserWarning: Flag --eval_folder has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
I0518 06:27:33.247053 22612968224576 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
2023-05-18 06:27:35.892595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43102 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:21:00.0, compute capability: 8.6
I0518 06:27:38.140489 22612968224576 evaluation_fromsample.py:48] begin checkpoint: 5
I0518 06:27:38.140754 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:27:38.141516 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 0
I0518 06:27:39.687758 22612968224576 xla_bridge.py:440] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 06:27:39.687952 22612968224576 xla_bridge.py:440] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 06:27:39.786582 22612968224576 xla_bridge.py:440] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0518 06:27:39.786781 22612968224576 xla_bridge.py:440] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0518 06:27:39.786853 22612968224576 xla_bridge.py:448] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0518 06:27:40.328456 22612968224576 deprecation.py:350] From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
2023-05-18 06:27:46.758643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
2023-05-18 06:27:48.942758: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2023-05-18 06:27:55.738185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.
  structure[0], [func(*x) for x in entries],
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:627: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS
I0518 06:27:56.411218 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 1
I0518 06:27:57.899698 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 10
I0518 06:27:59.427513 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 11
I0518 06:28:00.921284 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 12
I0518 06:28:02.445752 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 13
I0518 06:28:03.944005 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 14
I0518 06:28:05.461165 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 15
I0518 06:28:07.041450 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 16
I0518 06:28:08.559627 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 17
I0518 06:28:10.082731 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 18
I0518 06:28:11.584862 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 19
I0518 06:28:13.137684 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 2
I0518 06:28:14.775344 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 20
I0518 06:28:16.275902 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 21
I0518 06:28:17.796721 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 22
I0518 06:28:19.401943 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 23
I0518 06:28:20.899240 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 24
I0518 06:28:22.428896 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 25
I0518 06:28:23.924910 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 26
I0518 06:28:25.480958 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 27
I0518 06:28:27.002169 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 28
I0518 06:28:28.508947 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 29
I0518 06:28:30.059833 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 3
I0518 06:28:31.572694 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 30
I0518 06:28:33.060053 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 31
I0518 06:28:34.563278 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 32
I0518 06:28:36.117953 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 33
I0518 06:28:37.642995 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 34
I0518 06:28:39.149735 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 35
I0518 06:28:40.657698 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 36
I0518 06:28:42.161540 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 37
I0518 06:28:43.652200 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 38
I0518 06:28:45.232943 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 39
I0518 06:28:46.761891 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 4
I0518 06:28:48.315799 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 40
I0518 06:28:49.840960 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 41
I0518 06:28:51.381358 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 42
I0518 06:28:52.908139 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 43
I0518 06:28:54.475577 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 44
I0518 06:28:56.019885 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 45
I0518 06:28:57.671950 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 46
I0518 06:28:59.260035 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 47
I0518 06:29:00.747669 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 48
I0518 06:29:02.242021 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 5
I0518 06:29:03.792639 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 6
I0518 06:29:05.290054 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 7
I0518 06:29:06.779436 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 8
I0518 06:29:08.273847 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 9
I0518 06:29:36.306373 22612968224576 evaluation_fromsample.py:105] ckpt-5 --- FID: 2.813026e+00
I0518 06:29:36.307498 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:29:36.308059 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 0
I0518 06:29:37.894409 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 1
I0518 06:29:39.398923 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 10
I0518 06:29:40.874925 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 11
I0518 06:29:42.585500 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 12
I0518 06:29:44.085302 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 13
I0518 06:29:45.682391 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 14
I0518 06:29:47.274378 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 15
I0518 06:29:48.798212 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 16
I0518 06:29:50.282182 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 17
I0518 06:29:51.766158 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 18
I0518 06:29:53.292423 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 19
I0518 06:29:54.939666 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 2
I0518 06:29:56.434352 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 20
I0518 06:29:57.936896 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 21
I0518 06:29:59.502618 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 22
I0518 06:30:00.984523 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 23
I0518 06:30:02.552978 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 24
I0518 06:30:04.040748 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 25
I0518 06:30:05.525908 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 26
I0518 06:30:07.017260 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 27
I0518 06:30:08.499947 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 28
I0518 06:30:09.989280 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 29
I0518 06:30:11.480773 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 3
I0518 06:30:13.122024 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 30
I0518 06:30:14.752772 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 31
I0518 06:30:16.289438 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 32
I0518 06:30:17.786119 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 33
I0518 06:30:19.275349 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 34
I0518 06:30:20.765979 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 35
I0518 06:30:22.296887 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 36
I0518 06:30:23.898946 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 37
I0518 06:30:25.458660 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 38
I0518 06:30:26.938117 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 39
I0518 06:30:28.443972 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 4
I0518 06:30:29.975130 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 40
I0518 06:30:31.481562 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 41
I0518 06:30:33.007368 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 42
I0518 06:30:34.498315 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 43
I0518 06:30:36.120452 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 44
I0518 06:30:37.656726 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 45
I0518 06:30:39.264733 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 46
I0518 06:30:40.825917 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 47
I0518 06:30:42.324474 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 48
I0518 06:30:43.841568 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 5
I0518 06:30:45.342219 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 6
I0518 06:30:46.930893 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 7
I0518 06:30:48.444999 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 8
I0518 06:30:49.944728 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 9
I0518 06:31:04.236526 22612968224576 evaluation_fromsample.py:105] ckpt-10 --- FID: 2.795527e+00
I0518 06:31:04.237556 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:31:04.238097 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 0
I0518 06:31:05.760243 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 1
I0518 06:31:07.244395 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 10
I0518 06:31:08.727676 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 11
I0518 06:31:10.226201 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 12
I0518 06:31:11.734551 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 13
I0518 06:31:13.225454 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 14
I0518 06:31:14.924890 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 15
I0518 06:31:16.421343 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 16
I0518 06:31:17.915900 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 17
I0518 06:31:19.422902 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 18
I0518 06:31:20.981471 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 19
I0518 06:31:22.484514 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 2
I0518 06:31:24.022272 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 20
I0518 06:31:25.531757 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 21
I0518 06:31:27.023633 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 22
I0518 06:31:28.614764 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 23
I0518 06:31:30.164719 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 24
I0518 06:31:31.751285 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 25
I0518 06:31:33.253963 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 26
I0518 06:31:34.899569 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 27
I0518 06:31:36.381300 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 28
I0518 06:31:38.142485 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 29
I0518 06:31:39.668659 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 3
I0518 06:31:41.277842 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 30
I0518 06:31:42.850325 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 31
I0518 06:31:44.356999 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 32
I0518 06:31:45.985144 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 33
I0518 06:31:47.467581 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 34
I0518 06:31:48.961729 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 35
I0518 06:31:50.461730 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 36
I0518 06:31:51.982461 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 37
I0518 06:31:53.499429 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 38
I0518 06:31:54.998104 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 39
I0518 06:31:56.497613 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 4
I0518 06:31:57.988336 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 40
I0518 06:31:59.715075 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 41
I0518 06:32:01.213284 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 42
I0518 06:32:02.850513 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 43
I0518 06:32:04.349334 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 44
I0518 06:32:05.940649 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 45
I0518 06:32:07.447581 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 46
I0518 06:32:08.985550 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 47
I0518 06:32:10.599686 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 48
I0518 06:32:12.480705 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 5
I0518 06:32:14.204484 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 6
I0518 06:32:15.915664 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 7
I0518 06:32:17.790547 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 8
I0518 06:32:19.442203 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 9
I0518 06:32:33.527671 22612968224576 evaluation_fromsample.py:105] ckpt-15 --- FID: 2.784485e+00
I0518 06:32:33.530110 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:32:33.531318 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 0
I0518 06:32:35.464428 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 1
I0518 06:32:36.981468 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 10
I0518 06:32:38.472334 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 11
I0518 06:32:40.300597 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 12
I0518 06:32:41.943109 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 13
I0518 06:32:43.884319 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 14
I0518 06:32:45.352556 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 15
I0518 06:32:46.873225 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 16
I0518 06:32:48.383422 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 17
I0518 06:32:50.123861 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 18
I0518 06:32:51.709237 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 19
I0518 06:32:53.231969 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 2
I0518 06:32:54.775730 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 20
I0518 06:32:56.354622 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 21
I0518 06:32:57.872919 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 22
I0518 06:32:59.359779 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 23
I0518 06:33:01.059364 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 24
I0518 06:33:02.561133 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 25
I0518 06:33:04.067486 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 26
I0518 06:33:05.535810 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 27
I0518 06:33:07.059205 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 28
I0518 06:33:08.660292 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 29
I0518 06:33:10.194956 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 3
I0518 06:33:12.234680 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 30
I0518 06:33:13.848003 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 31
I0518 06:33:16.051265 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 32
I0518 06:33:17.521086 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 33
I0518 06:33:18.968629 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 34
I0518 06:33:20.490744 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 35
I0518 06:33:21.974840 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 36
I0518 06:33:23.710111 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 37
I0518 06:33:25.320533 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 38
I0518 06:33:26.838710 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 39
I0518 06:33:28.384577 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 4
I0518 06:33:29.976826 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 40
I0518 06:33:31.459375 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 41
I0518 06:33:33.226897 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 42
I0518 06:33:34.924324 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 43
I0518 06:33:36.422978 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 44
I0518 06:33:37.950073 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 45
I0518 06:33:39.447083 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 46
I0518 06:33:40.914265 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 47
I0518 06:33:42.402321 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 48
I0518 06:33:43.931465 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 5
I0518 06:33:45.506730 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 6
I0518 06:33:46.995310 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 7
I0518 06:33:48.620419 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 8
I0518 06:33:50.151849 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 9
I0518 06:34:03.485233 22612968224576 evaluation_fromsample.py:105] ckpt-20 --- FID: 2.739126e+00
I0518 06:34:03.486514 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:34:03.487218 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 0
I0518 06:34:05.055217 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 1
I0518 06:34:06.537491 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 10
I0518 06:34:08.013535 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 11
I0518 06:34:09.567331 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 12
I0518 06:34:11.068527 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 13
I0518 06:34:12.543101 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 14
I0518 06:34:14.035110 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 15
I0518 06:34:15.519650 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 16
I0518 06:34:17.006366 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 17
I0518 06:34:18.481629 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 18
I0518 06:34:19.967657 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 19
I0518 06:34:21.424876 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 2
I0518 06:34:23.068659 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 20
I0518 06:34:24.651412 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 21
I0518 06:34:26.196145 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 22
I0518 06:34:27.715712 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 23
I0518 06:34:29.177881 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 24
I0518 06:34:30.939450 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 25
I0518 06:34:32.433711 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 26
I0518 06:34:33.972022 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 27
I0518 06:34:35.525185 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 28
I0518 06:34:37.009993 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 29
I0518 06:34:38.488732 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 3
I0518 06:34:40.024717 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 30
I0518 06:34:41.504086 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 31
I0518 06:34:42.964179 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 32
I0518 06:34:44.447618 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 33
I0518 06:34:45.904243 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 34
I0518 06:34:47.471354 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 35
I0518 06:34:48.938123 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 36
I0518 06:34:50.475967 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 37
I0518 06:34:52.004786 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 38
I0518 06:34:53.487695 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 39
I0518 06:34:55.065267 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 4
I0518 06:34:56.564213 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 40
I0518 06:34:58.103375 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 41
I0518 06:34:59.583292 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 42
I0518 06:35:01.083173 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 43
I0518 06:35:02.584281 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 44
I0518 06:35:04.154422 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 45
I0518 06:35:05.692178 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 46
I0518 06:35:07.182498 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 47
I0518 06:35:08.802121 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 48
I0518 06:35:10.368437 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 5
I0518 06:35:11.973719 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 6
I0518 06:35:13.677071 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 7
I0518 06:35:15.185669 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 8
I0518 06:35:16.733729 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 9
I0518 06:35:29.857427 22612968224576 evaluation_fromsample.py:105] ckpt-25 --- FID: 2.794457e+00
I0518 06:35:29.858910 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:35:29.859673 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 0
I0518 06:35:31.382459 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 1
I0518 06:35:32.997652 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 10
I0518 06:35:34.489848 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 11
I0518 06:35:35.972659 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 12
I0518 06:35:37.442802 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 13
I0518 06:35:38.953283 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 14
I0518 06:35:40.417841 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 15
I0518 06:35:42.075190 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 16
I0518 06:35:43.534653 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 17
I0518 06:35:45.356725 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 18
I0518 06:35:46.853427 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 19
I0518 06:35:48.461389 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 2
I0518 06:35:50.135744 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 20
I0518 06:35:51.624631 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 21
I0518 06:35:53.102257 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 22
I0518 06:35:54.690279 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 23
I0518 06:35:56.201550 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 24
I0518 06:35:57.799264 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 25
I0518 06:35:59.303394 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 26
I0518 06:36:00.801565 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 27
I0518 06:36:02.514585 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 28
I0518 06:36:04.167731 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 29
I0518 06:36:05.735902 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 3
I0518 06:36:07.411340 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 30
I0518 06:36:08.915712 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 31
I0518 06:36:10.554650 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 32
I0518 06:36:12.060142 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 33
I0518 06:36:13.586139 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 34
I0518 06:36:15.163447 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 35
I0518 06:36:16.684324 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 36
I0518 06:36:18.257558 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 37
I0518 06:36:19.869778 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 38
I0518 06:36:21.347847 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 39
I0518 06:36:22.912144 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 4
I0518 06:36:24.389633 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 40
I0518 06:36:25.957177 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 41
I0518 06:36:27.784658 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 42
I0518 06:36:29.350795 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 43
I0518 06:36:30.901135 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 44
I0518 06:36:32.377428 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 45
I0518 06:36:33.945653 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 46
I0518 06:36:35.417818 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 47
I0518 06:36:37.043649 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 48
I0518 06:36:38.549959 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 5
I0518 06:36:40.029942 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 6
I0518 06:36:41.503402 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 7
I0518 06:36:42.972989 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 8
I0518 06:36:44.509827 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 9
I0518 06:36:57.172814 22612968224576 evaluation_fromsample.py:105] ckpt-30 --- FID: 2.745001e+00
I0518 06:36:57.174216 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:36:57.174930 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 0
I0518 06:36:58.759240 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 1
I0518 06:37:00.239269 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 10
I0518 06:37:01.706553 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 11
I0518 06:37:03.229456 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 12
I0518 06:37:04.705171 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 13
I0518 06:37:06.190129 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 14
I0518 06:37:07.680552 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 15
I0518 06:37:09.484687 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 16
I0518 06:37:10.983212 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 17
I0518 06:37:12.727715 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 18
I0518 06:37:14.265267 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 19
I0518 06:37:15.775928 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 2
I0518 06:37:17.318401 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 20
I0518 06:37:18.828621 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 21
I0518 06:37:20.304883 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 22
I0518 06:37:21.883289 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 23
I0518 06:37:23.436530 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 24
I0518 06:37:24.917932 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 25
I0518 06:37:26.384674 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 26
I0518 06:37:27.888490 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 27
I0518 06:37:29.387653 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 28
I0518 06:37:30.944809 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 29
I0518 06:37:32.506176 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 3
I0518 06:37:33.996051 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 30
I0518 06:37:35.584955 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 31
I0518 06:37:37.080588 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 32
I0518 06:37:38.592166 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 33
I0518 06:37:40.102885 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 34
I0518 06:37:41.618694 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 35
I0518 06:37:43.091182 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 36
I0518 06:37:44.582708 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 37
I0518 06:37:46.133399 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 38
I0518 06:37:47.619422 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 39
I0518 06:37:49.294930 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 4
I0518 06:37:50.814668 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 40
I0518 06:37:52.340304 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 41
I0518 06:37:53.820612 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 42
I0518 06:37:55.297447 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 43
I0518 06:37:56.772925 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 44
I0518 06:37:58.344533 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 45
I0518 06:37:59.852487 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 46
I0518 06:38:01.350979 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 47
I0518 06:38:02.838614 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 48
I0518 06:38:04.335590 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 5
I0518 06:38:05.819729 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 6
I0518 06:38:07.315642 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 7
I0518 06:38:08.808726 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 8
I0518 06:38:10.261069 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 9
I0518 06:38:23.101194 22612968224576 evaluation_fromsample.py:105] ckpt-35 --- FID: 2.800883e+00
I0518 06:38:23.102481 22612968224576 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval1_control
I0518 06:38:23.103160 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 0
I0518 06:38:24.736941 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 1
I0518 06:38:26.211676 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 10
I0518 06:38:27.699455 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 11
I0518 06:38:29.268903 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 12
I0518 06:38:30.822215 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 13
I0518 06:38:32.345148 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 14
I0518 06:38:33.849152 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 15
I0518 06:38:35.363892 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 16
I0518 06:38:36.854845 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 17
I0518 06:38:38.351496 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 18
I0518 06:38:39.867339 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 19
I0518 06:38:41.485457 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 2
I0518 06:38:43.000710 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 20
I0518 06:38:44.502655 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 21
I0518 06:38:45.994853 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 22
I0518 06:38:47.520532 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 23
I0518 06:38:49.367537 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 24
I0518 06:38:50.831178 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 25
I0518 06:38:52.336883 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 26
I0518 06:38:53.859728 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 27
I0518 06:38:55.388037 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 28
I0518 06:38:56.882304 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 29
I0518 06:38:58.355702 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 3
I0518 06:38:59.907766 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 30
I0518 06:39:01.470067 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 31
I0518 06:39:02.967696 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 32
I0518 06:39:04.451627 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 33
I0518 06:39:06.006159 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 34
I0518 06:39:07.496987 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 35
I0518 06:39:09.104419 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 36
I0518 06:39:10.612750 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 37
I0518 06:39:12.126768 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 38
I0518 06:39:13.654139 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 39
I0518 06:39:15.183211 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 4
I0518 06:39:16.728315 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 40
I0518 06:39:18.225030 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 41
I0518 06:39:19.716105 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 42
I0518 06:39:21.187231 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 43
I0518 06:39:22.704653 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 44
I0518 06:39:24.269330 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 45
I0518 06:39:25.812801 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 46
I0518 06:39:27.324184 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 47
I0518 06:39:28.803811 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 48
I0518 06:39:30.300040 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 5
I0518 06:39:31.767534 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 6
I0518 06:39:33.268612 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 7
I0518 06:39:34.731688 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 8
I0518 06:39:36.323964 22612968224576 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 9
I0518 06:39:52.184046 22612968224576 evaluation_fromsample.py:105] ckpt-40 --- FID: 2.782050e+00
