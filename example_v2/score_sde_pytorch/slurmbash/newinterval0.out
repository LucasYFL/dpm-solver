4
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
2023-05-13 19:32:10.278281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-13 19:32:10.278287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-13 19:32:11.892196: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-13 19:32:11.892195: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-13 19:32:22.976810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-13 19:32:22.976811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-13 19:32:22.977434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-13 19:32:22.977440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-13 19:32:22.977452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-13 19:32:22.977462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
10

22

[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
64
64
I0513 19:32:50.101187 22392998065984 main.py:64] Conditional: True
W0513 19:33:06.082574 23355123337024 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/dpm_deep_I0/checkpoints-meta/checkpoint.pth. Returned the same state as input
W0513 19:33:06.087413 22392998065984 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/dpm_deep_I0/checkpoints-meta/checkpoint.pth. Returned the same state as input
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:33:36.060807 23355123337024 losses.py:105] Sde loss
I0513 19:33:36.060840 22392998065984 losses.py:105] Sde loss
I0513 19:33:36.061245 23355123337024 losses.py:108] Fewer: 4
I0513 19:33:36.061324 23355123337024 losses.py:127] (0.0, 0.442]
I0513 19:33:36.061336 22392998065984 losses.py:108] Fewer: 4
I0513 19:33:36.061385 23355123337024 losses.py:105] Sde loss
I0513 19:33:36.061416 22392998065984 losses.py:127] (0.0, 0.442]
I0513 19:33:36.061425 23355123337024 losses.py:108] Fewer: 4
I0513 19:33:36.061459 23355123337024 losses.py:127] (0.0, 0.442]
I0513 19:33:36.061497 22392998065984 losses.py:105] Sde loss
I0513 19:33:36.061500 23355123337024 run_lib.py:130] Starting training loop at step 0.
I0513 19:33:36.061552 22392998065984 losses.py:108] Fewer: 4
I0513 19:33:36.061602 22392998065984 losses.py:127] (0.0, 0.442]
I0513 19:33:36.061775 22392998065984 run_lib.py:130] Starting training loop at step 0.
[2023-05-13 19:33:36,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:33:36,366] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:33:36,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 19:33:36,611] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 19:33:36,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 19:33:36,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 19:33:36,627] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:33:36,627] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:33:36,627] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:33:36,627] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:33:36,760] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:33:36,760] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:33:39,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-05-13 19:33:39,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libcuda.solibc.so  whenwhen  searchingsearching  forfor  --lcudalc

/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:33:42,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-13 19:33:42,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-13 19:33:42,922] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:33:42,922] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:33:44,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-13 19:33:44,372] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-13 19:33:44,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-13 19:33:44,383] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-13 19:33:44,385] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-13 19:33:44,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-13 19:34:11,328] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:11,329] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:11,372] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:11,372] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:11,373] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:11,373] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:11,374] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:11,375] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:12,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-05-13 19:34:12,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:14,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
[2023-05-13 19:34:14,234] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-13 19:34:14,752] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-13 19:34:14,788] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-13 19:34:14,960] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-13 19:34:14,997] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:15,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-13 19:34:15,926] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:15,992] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:15,994] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:15,995] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:15,995] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:15,995] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:16,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-05-13 19:34:16,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-13 19:34:16,241] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:16,265] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:16,267] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:16,268] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:16,268] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:16,268] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:16,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:16,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-13 19:34:16,663] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:16,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:16,711] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:16,711] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:16,712] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:16,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-13 19:34:16,937] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-13 19:34:16,992] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-13 19:34:16,992] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:16,999] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:17,040] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:17,041] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:17,041] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:17,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-13 19:34:17,211] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-13 19:34:17,238] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:17,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-13 19:34:17,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-13 19:34:17,379] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:17,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:17,427] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:17,427] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:17,428] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:17,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-13 19:34:17,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-13 19:34:17,571] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:17,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-13 19:34:17,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-13 19:34:17,714] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:17,723] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:17,764] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:17,764] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:17,764] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:17,904] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-13 19:34:17,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-13 19:34:17,947] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:17,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-13 19:34:18,070] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-13 19:34:18,083] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:18,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:18,131] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:18,131] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:18,132] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:18,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-13 19:34:18,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-13 19:34:18,286] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:18,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-13 19:34:18,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-13 19:34:18,423] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:18,431] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:18,472] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:18,472] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:18,472] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:18,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-13 19:34:18,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-13 19:34:18,648] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:18,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-13 19:34:18,775] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-13 19:34:18,788] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:18,795] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:18,836] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:18,836] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:18,836] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:18,959] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-13 19:34:18,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-13 19:34:18,986] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:19,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-13 19:34:19,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-13 19:34:19,125] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:19,132] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:19,173] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:19,173] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:19,173] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:19,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-13 19:34:19,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-13 19:34:19,354] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:19,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-13 19:34:19,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-13 19:34:19,492] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:19,500] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:19,542] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:19,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:19,543] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:19,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-13 19:34:19,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-13 19:34:19,693] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:19,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-13 19:34:19,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-13 19:34:19,829] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:19,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:19,879] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:19,879] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:19,879] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:20,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-13 19:34:20,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-13 19:34:20,061] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:20,094] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-13 19:34:20,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-13 19:34:20,206] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:20,214] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:20,256] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:20,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:20,256] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:20,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-13 19:34:20,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-13 19:34:20,394] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:20,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-13 19:34:20,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-13 19:34:20,531] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:20,539] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:20,579] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:20,580] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:20,580] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:20,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-13 19:34:20,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-13 19:34:20,776] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:20,797] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-13 19:34:20,900] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-13 19:34:20,913] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:20,921] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:20,962] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:20,962] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:20,963] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:21,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-13 19:34:21,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-13 19:34:21,106] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:21,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-13 19:34:21,231] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-13 19:34:21,244] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:21,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:21,294] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:21,294] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:21,295] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:21,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-13 19:34:21,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-13 19:34:21,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-13 19:34:21,735] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:21,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-13 19:34:21,875] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:21,884] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:21,954] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:21,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:21,955] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:22,097] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-13 19:34:22,124] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:22,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-05-13 19:34:22,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-13 19:34:22,262] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:22,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:22,327] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:22,328] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:22,328] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:22,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:22,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:23,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-13 19:34:23,254] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:23,388] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:23,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-13 19:34:23,722] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:24,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-13 19:34:24,154] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:24,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:24,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:24,389] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:24,389] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:24,389] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:24,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-13 19:34:24,590] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-13 19:34:24,605] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:24,626] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:24,628] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:24,629] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:24,629] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:24,629] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:24,645] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-13 19:34:24,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-13 19:34:24,744] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:24,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:24,794] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:24,794] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:24,794] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:25,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-13 19:34:25,048] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:25,055] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:25,100] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:25,100] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:25,101] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:25,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-13 19:34:25,221] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:25,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-13 19:34:25,534] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:26,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-13 19:34:26,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-13 19:34:26,520] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-13 19:34:26,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-13 19:34:26,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:26,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-13 19:34:26,606] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:26,607] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:26,608] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:26,608] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:26,608] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:26,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-13 19:34:26,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-13 19:34:26,962] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:26,967] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:27,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-13 19:34:27,046] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:27,069] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:27,071] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:27,072] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:27,072] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:27,072] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:27,082] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:27,082] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:27,082] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:27,088] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-13 19:34:27,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:27,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-13 19:34:27,506] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:27,512] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:27,631] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:27,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:27,632] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:27,756] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-05-13 19:34:27,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:28,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-05-13 19:34:28,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:28,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible/ usr//usrbin//libld/:libcuda.so  skippingwhen  incompatiblesearching  /forusr /-liblcuda/
libcuda.so/ usrwhen/ binsearching/ ldfor:  -skippinglcuda 
incompatible/ usr//usrbin//libld/:libc.so  skippingwhen  incompatiblesearching  /forusr /-liblc/
libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libcuda.solibcuda.so  whenwhen  searchingsearching  forfor  --lcudalcuda

//usrusr//binbin//ldld::  skippingskipping  incompatibleincompatible  //usrusr//liblib//libc.solibc.so  whenwhen  searchingsearching  forfor  --lclc

[2023-05-13 19:34:32,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-13 19:34:32,105] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:32,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-13 19:34:32,651] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:34,868] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:34,870] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:34,871] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:34,871] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:34,871] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:34,889] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-13 19:34:34,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-13 19:34:34,900] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:34,905] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:34,946] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:34,946] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:34,947] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:35,281] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:35,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:35,286] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:35,286] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:35,287] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:35,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-13 19:34:35,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-13 19:34:35,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-13 19:34:35,329] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:35,335] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:35,365] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:35,378] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:35,379] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:35,379] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:35,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-13 19:34:35,817] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:35,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-13 19:34:35,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-13 19:34:36,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-13 19:34:36,319] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:36,326] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:36,396] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-13 19:34:36,434] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:36,434] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:36,435] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:36,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-13 19:34:36,555] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-13 19:34:36,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-13 19:34:36,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-13 19:34:36,801] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:36,811] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:36,922] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:36,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:36,923] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:37,044] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-13 19:34:37,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-13 19:34:37,097] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-13 19:34:37,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-13 19:34:37,253] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:37,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:37,300] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:37,300] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:37,301] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:37,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-13 19:34:37,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-13 19:34:37,753] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:37,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:37,803] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:37,803] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:37,804] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:37,930] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-13 19:34:37,969] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:38,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-13 19:34:38,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-13 19:34:38,170] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-13 19:34:38,172] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:38,177] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:38,282] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:38,282] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:38,283] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:38,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-13 19:34:38,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-13 19:34:38,547] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-13 19:34:38,586] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:38,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-13 19:34:38,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-13 19:34:38,793] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-13 19:34:38,795] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:38,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:38,908] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:38,909] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:38,909] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:38,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-13 19:34:39,034] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-13 19:34:39,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-13 19:34:39,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-13 19:34:39,097] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:39,105] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:39,146] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:39,146] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:39,146] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:39,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-13 19:34:39,555] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:39,599] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-13 19:34:39,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-13 19:34:39,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-13 19:34:39,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-13 19:34:39,760] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-13 19:34:39,762] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:39,768] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:39,774] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:39,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:39,827] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:39,828] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:39,828] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:39,875] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:39,875] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:39,876] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:39,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-13 19:34:40,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-13 19:34:40,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-13 19:34:40,260] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:40,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-13 19:34:40,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-13 19:34:40,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-13 19:34:40,478] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:40,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:40,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-13 19:34:40,605] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:40,605] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:40,606] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:40,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-13 19:34:40,695] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:40,704] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:40,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-13 19:34:40,745] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:40,745] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:40,746] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:40,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-13 19:34:41,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-13 19:34:41,154] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:41,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-13 19:34:41,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-13 19:34:41,341] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-13 19:34:41,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-13 19:34:41,362] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:41,369] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:41,410] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-13 19:34:41,442] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:41,452] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:41,477] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:41,477] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:41,477] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:41,493] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:41,493] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:41,494] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:41,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-13 19:34:41,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-13 19:34:41,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-13 19:34:41,916] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:42,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-13 19:34:42,110] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-13 19:34:42,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-13 19:34:42,130] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:42,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-13 19:34:42,138] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:42,247] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:42,247] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:42,248] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:42,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-13 19:34:42,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-13 19:34:42,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-13 19:34:42,583] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:42,592] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:42,632] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:42,632] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:42,633] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:42,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-13 19:34:43,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-13 19:34:43,045] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:43,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-13 19:34:43,082] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:43,092] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:43,134] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:43,134] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:43,135] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:43,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-13 19:34:43,231] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-13 19:34:43,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-13 19:34:43,250] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:43,256] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:43,363] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:43,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:43,363] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:43,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-13 19:34:43,535] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-13 19:34:43,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-13 19:34:43,920] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:44,019] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-13 19:34:44,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-13 19:34:44,110] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-13 19:34:44,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-13 19:34:44,130] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:44,136] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:44,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-13 19:34:44,184] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:44,192] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:44,232] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:44,232] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:44,233] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:44,244] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:44,245] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:44,245] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:44,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-13 19:34:44,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-13 19:34:44,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-13 19:34:44,641] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:44,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-13 19:34:44,824] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-13 19:34:44,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-13 19:34:44,843] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:44,848] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:44,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-13 19:34:44,955] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:44,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:44,956] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:45,039] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-13 19:34:45,072] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:45,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-13 19:34:45,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:45,123] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:45,123] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:45,124] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:45,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-13 19:34:45,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-13 19:34:45,541] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:45,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-13 19:34:45,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-13 19:34:45,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-13 19:34:45,739] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-13 19:34:45,745] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-13 19:34:45,747] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:45,754] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:45,773] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:45,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:45,828] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:45,828] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:45,829] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:45,861] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:45,861] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:45,862] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:45,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-13 19:34:46,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-13 19:34:46,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-13 19:34:46,265] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:46,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-13 19:34:46,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-13 19:34:46,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-13 19:34:46,472] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:46,479] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:46,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-13 19:34:46,592] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:46,592] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:46,592] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:46,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-13 19:34:46,679] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:46,687] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:46,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-13 19:34:46,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:46,728] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:46,729] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:46,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-13 19:34:47,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-13 19:34:47,169] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:47,273] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-13 19:34:47,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-13 19:34:47,362] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-13 19:34:47,379] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-13 19:34:47,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:47,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:47,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-13 19:34:47,443] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:47,454] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:47,502] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:47,502] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:47,503] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:47,509] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:47,509] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:47,510] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:47,628] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-13 19:34:47,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-13 19:34:47,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-13 19:34:48,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-13 19:34:48,271] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:48,344] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-13 19:34:48,379] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:48,390] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:48,447] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:48,448] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:48,448] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:49,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-13 19:34:49,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-13 19:34:49,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-13 19:34:49,365] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:49,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-13 19:34:49,615] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:49,684] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:49,685] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:49,687] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:49,687] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:49,687] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:49,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:50,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-13 19:34:50,126] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:50,132] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:50,175] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:50,176] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:50,176] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:50,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-13 19:34:50,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-13 19:34:50,557] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-13 19:34:50,601] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:50,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-13 19:34:50,806] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:50,831] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:34:50,833] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:34:50,834] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:50,834] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:50,834] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:34:50,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:51,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-13 19:34:51,214] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:51,221] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:51,272] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:51,272] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:51,273] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:51,363] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-13 19:34:51,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-13 19:34:51,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-13 19:34:51,751] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:51,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-13 19:34:51,761] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:51,770] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:51,812] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:51,812] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:51,813] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:34:52,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-13 19:34:52,242] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:52,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-13 19:34:52,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-13 19:34:52,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-13 19:34:52,465] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:52,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:52,515] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:52,515] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:52,516] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:52,539] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-13 19:34:52,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-13 19:34:52,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-13 19:34:52,938] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:52,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-13 19:34:52,996] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:53,006] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:53,051] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:53,051] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:53,052] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:53,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-13 19:34:53,133] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-13 19:34:53,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-13 19:34:53,152] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:34:53,158] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:34:53,199] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:34:53,200] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:34:53,200] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:34:53,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-13 19:34:53,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-13 19:34:54,085] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:55,695] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:34:56,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-13 19:34:57,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-13 19:34:57,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-13 19:34:58,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-13 19:34:58,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-13 19:34:59,822] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-13 19:35:00,376] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:00,463] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:01,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:02,156] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:03,944] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:05,298] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:05,859] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:06,557] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:07,443] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:08,530] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:09,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-13 19:35:10,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-13 19:35:10,799] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:11,698] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:11,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-13 19:35:12,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-13 19:35:13,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-13 19:35:14,566] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-13 19:35:15,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-13 19:35:17,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-13 19:35:18,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:18,809] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:19,643] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:21,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:22,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:22,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:22,884] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:23,245] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:23,402] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:24,330] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:24,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-13 19:35:24,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-13 19:35:25,510] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:26,086] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:26,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-13 19:35:26,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-13 19:35:26,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-13 19:35:26,666] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:26,672] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:26,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-13 19:35:26,712] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:26,712] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:26,712] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:26,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-13 19:35:26,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-13 19:35:26,743] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:26,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:26,790] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:26,790] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:26,791] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:27,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-13 19:35:27,120] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:27,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-13 19:35:27,229] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:27,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-13 19:35:27,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-13 19:35:27,319] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-13 19:35:27,321] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:27,328] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:27,369] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:27,369] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:27,369] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:27,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-13 19:35:27,450] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-13 19:35:27,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-13 19:35:27,471] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:27,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:27,526] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:27,526] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:27,527] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:27,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-13 19:35:27,949] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:28,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-13 19:35:28,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-13 19:35:28,103] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:28,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-13 19:35:28,156] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-13 19:35:28,158] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:28,164] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:28,204] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:28,205] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:28,205] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:28,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-13 19:35:28,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-13 19:35:28,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-13 19:35:28,307] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:28,313] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:28,365] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:28,366] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:28,366] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:28,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-13 19:35:28,619] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:28,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-13 19:35:28,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-13 19:35:28,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-13 19:35:28,821] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:28,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-13 19:35:28,823] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:28,831] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:28,870] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:28,871] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:28,871] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:29,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-13 19:35:29,735] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:29,819] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-13 19:35:29,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-13 19:35:29,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-13 19:35:29,929] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-13 19:35:29,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-13 19:35:29,949] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:29,957] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:30,012] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:30,012] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:30,013] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:30,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-13 19:35:30,260] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:30,299] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:35:30,300] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:35:30,301] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:30,302] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:30,302] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:35:30,318] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-13 19:35:30,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-13 19:35:30,498] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:30,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-13 19:35:30,654] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:30,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:30,702] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:30,702] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:30,702] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:31,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-13 19:35:31,162] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:31,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:31,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-13 19:35:31,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-13 19:35:31,926] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:31,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-13 19:35:31,950] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:35:31,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:35:31,952] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:31,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:31,952] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:35:31,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-13 19:35:31,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-13 19:35:32,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-13 19:35:32,308] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:32,316] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:32,342] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-13 19:35:32,344] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:32,354] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:32,357] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:32,357] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:32,358] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:32,395] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:32,395] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:32,396] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:32,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-13 19:35:32,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-13 19:35:32,780] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:32,813] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:32,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-13 19:35:33,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-13 19:35:33,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-13 19:35:33,026] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:33,034] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:33,076] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:33,076] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:33,077] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:33,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-13 19:35:33,516] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:33,555] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-13 19:35:33,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-13 19:35:33,660] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-13 19:35:33,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-13 19:35:33,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-13 19:35:33,728] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:33,737] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:33,779] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:33,779] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:33,780] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:33,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-13 19:35:33,955] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:33,965] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:34,006] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:34,006] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:34,006] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:34,158] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-13 19:35:34,196] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:34,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-13 19:35:34,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-13 19:35:34,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-13 19:35:34,399] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-13 19:35:34,401] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:34,408] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:34,423] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:34,448] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:34,448] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:34,449] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:34,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-13 19:35:34,610] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-13 19:35:34,628] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-13 19:35:34,630] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:34,637] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:34,677] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:34,677] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:34,678] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:34,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-13 19:35:34,859] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:35,000] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-13 19:35:35,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-13 19:35:35,054] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-13 19:35:35,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-13 19:35:35,067] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:35,074] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:35,094] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:35,114] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:35,114] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:35,115] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:35,240] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-13 19:35:35,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-13 19:35:35,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-13 19:35:35,308] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:35,317] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:35,360] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:35,360] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:35,361] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:35,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-13 19:35:35,528] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:35,673] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-13 19:35:35,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-13 19:35:35,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-13 19:35:35,742] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:35,750] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:35,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-13 19:35:35,790] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:35,791] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:35,791] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:35,814] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:35,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-13 19:35:36,009] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-13 19:35:36,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-13 19:35:36,029] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:36,038] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:36,082] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:36,082] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:36,083] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:36,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-13 19:35:36,209] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:36,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-13 19:35:36,537] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:36,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-13 19:35:36,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-13 19:35:36,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-13 19:35:36,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-13 19:35:36,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-13 19:35:36,760] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:36,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-13 19:35:36,767] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:36,770] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:36,774] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:36,814] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:36,814] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:36,815] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:36,815] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:36,815] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:36,816] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:37,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-13 19:35:37,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-13 19:35:37,227] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:37,260] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:37,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-13 19:35:37,402] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-13 19:35:37,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-13 19:35:37,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-13 19:35:37,432] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:37,439] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:37,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-13 19:35:37,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-13 19:35:37,474] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:37,480] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:37,480] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:37,481] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:37,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:37,525] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:37,525] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:37,526] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:37,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-13 19:35:37,894] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:38,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-13 19:35:38,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-13 19:35:38,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-13 19:35:38,100] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:38,106] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:38,213] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:38,213] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:38,214] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:38,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-13 19:35:38,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-13 19:35:38,485] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:38,630] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-13 19:35:38,682] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-13 19:35:38,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-13 19:35:38,702] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:38,711] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:38,755] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:38,755] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:38,755] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:38,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-13 19:35:39,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-13 19:35:39,204] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:39,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
[2023-05-13 19:35:39,352] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-13 19:35:39,398] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-13 19:35:39,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-13 19:35:39,417] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:39,425] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:39,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:39,475] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:39,476] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:39,876] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-13 19:35:39,919] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:40,070] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-13 19:35:40,124] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-13 19:35:40,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-13 19:35:40,147] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:40,155] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:40,270] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:40,270] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:40,270] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:40,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-13 19:35:40,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-13 19:35:41,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
[2023-05-13 19:35:41,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-13 19:35:41,693] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:43,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-13 19:35:43,735] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:53,761] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:35:53,763] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:35:53,764] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:53,765] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:53,765] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:35:53,784] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-13 19:35:53,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-13 19:35:53,795] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:53,801] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:53,843] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:53,843] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:53,844] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:54,216] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-13 19:35:54,261] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:54,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-13 19:35:54,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-13 19:35:54,474] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-13 19:35:54,476] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:54,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:54,527] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:54,527] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:54,527] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:54,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-13 19:35:54,941] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:54,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:35:54,953] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:35:54,955] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:54,955] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:54,955] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:35:54,977] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-13 19:35:54,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-13 19:35:54,990] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:54,996] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:55,042] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:55,042] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:55,043] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:55,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-13 19:35:55,506] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:55,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-13 19:35:55,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-13 19:35:55,722] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-13 19:35:55,734] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-13 19:35:55,736] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:55,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:55,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-13 19:35:55,794] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:55,794] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:55,795] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:55,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-13 19:35:55,814] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:55,832] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:55,875] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:55,875] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:55,876] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:56,198] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-13 19:35:56,243] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:56,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-13 19:35:56,285] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:56,431] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-13 19:35:56,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-13 19:35:56,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-13 19:35:56,522] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:56,529] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:56,575] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:56,575] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:56,576] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:35:56,956] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-13 19:35:56,995] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:57,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-13 19:35:57,112] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-13 19:35:57,141] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-13 19:35:57,142] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-13 19:35:57,145] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:57,166] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:57,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-13 19:35:57,211] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:57,212] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:57,212] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:57,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-13 19:35:57,227] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:57,234] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:57,278] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:57,278] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:57,279] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:57,596] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-13 19:35:57,638] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:57,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-13 19:35:57,854] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-13 19:35:57,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-13 19:35:57,880] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:57,888] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:57,933] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:57,933] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:57,934] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:58,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-13 19:35:58,059] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:58,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-13 19:35:58,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-13 19:35:58,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-13 19:35:58,293] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:58,300] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:58,344] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:58,344] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:58,345] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:58,728] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-13 19:35:58,751] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-13 19:35:58,768] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:58,791] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:58,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-13 19:35:58,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-13 19:35:58,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-13 19:35:58,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-13 19:35:59,001] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:59,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-13 19:35:59,008] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:59,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-13 19:35:59,028] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:59,035] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:59,053] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:59,053] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:59,054] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:59,078] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:59,079] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:59,079] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:59,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-13 19:35:59,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-13 19:35:59,485] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:59,507] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:35:59,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-13 19:35:59,656] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-13 19:35:59,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-13 19:35:59,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-13 19:35:59,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-13 19:35:59,721] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:59,729] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:59,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-13 19:35:59,744] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:35:59,751] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:35:59,772] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:59,772] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:59,773] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:35:59,795] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:35:59,795] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:35:59,796] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:00,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-13 19:36:00,182] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-13 19:36:00,188] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:00,222] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:00,337] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-13 19:36:00,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-13 19:36:00,398] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-13 19:36:00,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-13 19:36:00,423] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:00,430] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:00,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-13 19:36:00,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-13 19:36:00,472] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:00,473] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:00,473] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:00,474] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:00,481] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:00,525] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:00,526] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:00,526] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:00,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-13 19:36:00,890] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:00,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-13 19:36:00,945] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:01,037] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-13 19:36:01,098] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-13 19:36:01,102] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-13 19:36:01,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-13 19:36:01,128] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:01,135] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:01,164] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-13 19:36:01,179] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:01,179] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:01,180] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:01,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-13 19:36:01,189] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:01,196] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:01,241] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:01,241] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:01,242] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:01,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-13 19:36:01,591] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:01,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-13 19:36:01,661] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:01,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-13 19:36:01,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-13 19:36:01,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-13 19:36:01,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-13 19:36:01,823] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:01,830] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:01,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-13 19:36:01,886] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:01,887] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:01,887] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:01,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-13 19:36:01,896] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:01,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:01,948] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:01,949] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:01,949] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:02,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-13 19:36:02,339] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:02,341] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-13 19:36:02,385] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:02,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-13 19:36:02,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-13 19:36:02,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-13 19:36:02,632] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:02,641] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:02,688] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:02,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:02,688] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:02,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-13 19:36:03,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-13 19:36:03,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-13 19:36:03,085] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:03,094] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:03,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-13 19:36:03,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:03,137] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:03,138] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:03,141] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:03,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-13 19:36:03,358] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-13 19:36:03,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-13 19:36:03,384] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:03,392] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:03,452] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:03,452] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:03,453] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:03,508] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-13 19:36:03,553] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:03,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-13 19:36:03,949] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:04,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-13 19:36:04,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-13 19:36:04,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-13 19:36:04,252] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:04,294] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:04,340] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:04,341] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:04,341] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:04,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-13 19:36:04,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-13 19:36:04,705] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-13 19:36:04,708] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:04,720] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:04,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-13 19:36:04,765] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:04,769] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:04,769] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:04,770] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:04,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-13 19:36:04,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-13 19:36:04,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-13 19:36:04,999] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:05,005] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:05,456] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:05,456] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:05,457] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:05,747] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-13 19:36:05,797] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:05,837] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-13 19:36:05,877] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:06,026] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-13 19:36:06,090] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-13 19:36:06,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-13 19:36:06,117] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:06,124] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:06,169] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:06,170] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:06,170] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:06,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-13 19:36:06,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-13 19:36:06,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-13 19:36:06,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:06,521] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:06,556] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-13 19:36:06,570] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:06,570] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:06,571] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:06,595] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:06,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-13 19:36:06,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-13 19:36:06,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-13 19:36:06,828] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:06,835] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:06,878] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:06,879] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:06,879] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:07,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-13 19:36:07,047] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:07,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-13 19:36:07,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-13 19:36:07,283] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-13 19:36:07,297] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:07,310] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-13 19:36:07,314] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:07,323] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:07,378] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:07,378] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:07,379] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:07,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-13 19:36:07,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-13 19:36:07,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-13 19:36:07,530] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:07,537] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:07,580] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:07,580] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:07,580] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:07,784] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-13 19:36:07,825] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:07,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-13 19:36:07,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-13 19:36:07,996] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:08,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-13 19:36:08,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-13 19:36:08,064] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:08,071] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:08,114] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:08,115] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:08,115] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:08,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-13 19:36:08,210] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-13 19:36:08,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-13 19:36:08,235] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:08,241] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:08,285] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:08,285] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:08,286] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:08,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-13 19:36:08,547] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:08,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-13 19:36:08,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-13 19:36:08,712] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:08,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-13 19:36:08,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-13 19:36:08,788] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:08,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:08,844] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:08,844] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:08,845] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:08,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-13 19:36:08,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-13 19:36:08,947] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-13 19:36:08,953] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:08,961] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:09,006] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:09,006] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:09,007] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:09,225] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-13 19:36:09,264] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:09,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-13 19:36:09,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-13 19:36:09,422] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:09,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-13 19:36:09,499] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-13 19:36:09,502] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:09,509] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:09,552] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:09,552] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:09,553] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:09,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-13 19:36:09,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-13 19:36:09,655] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-13 19:36:09,658] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:09,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:09,707] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:09,708] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:09,708] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:09,927] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-13 19:36:09,966] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:10,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-13 19:36:10,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-13 19:36:10,118] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:10,177] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-13 19:36:10,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-13 19:36:10,202] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:10,208] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:10,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:10,252] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:10,252] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:10,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-13 19:36:10,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-13 19:36:10,348] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-13 19:36:10,351] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:10,358] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:10,412] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:10,412] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:10,413] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:10,627] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-13 19:36:10,666] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:10,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-13 19:36:10,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-13 19:36:10,863] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:10,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-13 19:36:10,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-13 19:36:10,902] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:10,909] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:10,952] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:10,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:10,953] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:11,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-13 19:36:11,394] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:11,532] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-13 19:36:11,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-13 19:36:11,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-13 19:36:11,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-13 19:36:11,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-13 19:36:11,628] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:11,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-13 19:36:11,642] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:11,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:11,649] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:11,685] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:11,686] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:11,686] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:11,696] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:11,696] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:11,697] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:12,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-13 19:36:12,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-13 19:36:12,100] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:12,137] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:12,287] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-13 19:36:12,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-13 19:36:12,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-13 19:36:12,384] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:12,392] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:12,452] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:12,452] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:12,452] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:12,673] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-13 19:36:12,734] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-13 19:36:12,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-13 19:36:12,768] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:12,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:12,830] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:12,830] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:12,830] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:12,899] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-13 19:36:12,950] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:13,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-13 19:36:13,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-13 19:36:13,673] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:13,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-13 19:36:13,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-13 19:36:13,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-13 19:36:13,911] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:13,919] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:13,962] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:13,963] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:13,963] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:14,228] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-13 19:36:14,260] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-13 19:36:14,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:14,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:14,327] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:14,327] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:14,328] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:14,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-13 19:36:14,379] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:14,527] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-13 19:36:14,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-13 19:36:14,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-13 19:36:14,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:14,622] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:14,666] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:14,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:14,667] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:14,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-13 19:36:14,762] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:15,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-13 19:36:15,081] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:15,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-13 19:36:15,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-13 19:36:15,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-13 19:36:15,337] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:15,346] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:15,364] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-13 19:36:15,390] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:15,390] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:15,391] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:15,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-13 19:36:15,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-13 19:36:15,462] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:15,484] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:15,528] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:15,528] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:15,529] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:15,770] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-13 19:36:15,810] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:15,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-13 19:36:15,959] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-13 19:36:15,975] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:16,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-13 19:36:16,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-13 19:36:16,045] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:16,056] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:16,101] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:16,101] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:16,102] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:16,141] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-13 19:36:16,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-13 19:36:16,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-13 19:36:16,242] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:16,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:16,296] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:16,297] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:16,297] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:16,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-13 19:36:16,520] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:16,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-13 19:36:16,684] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-13 19:36:16,723] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:16,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-13 19:36:16,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-13 19:36:16,756] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:16,764] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:16,807] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:16,807] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:16,808] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:16,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-13 19:36:16,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-13 19:36:16,960] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-13 19:36:16,963] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:16,970] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:17,022] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:17,022] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:17,023] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:17,184] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-13 19:36:17,223] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:17,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-13 19:36:17,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-13 19:36:17,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-13 19:36:17,451] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:17,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-13 19:36:17,457] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:17,463] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 23350600569328)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-13 19:36:17,463] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-13 19:36:17,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-13 19:36:17,670] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:17,671] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-13 19:36:17,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-13 19:36:17,696] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:17,705] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:17,750] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:17,751] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:17,751] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:17,780] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:17,781] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:17,781] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:17,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-13 19:36:17,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-13 19:36:18,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-13 19:36:18,167] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:18,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-13 19:36:18,378] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-13 19:36:18,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-13 19:36:18,403] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:18,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:18,437] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-13 19:36:18,454] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:18,454] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:18,455] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:18,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-13 19:36:18,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:18,621] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:36:18,626] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:36:18,627] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:18,627] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:18,627] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:36:18,651] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-13 19:36:18,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-13 19:36:18,875] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:19,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-13 19:36:19,008] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:19,028] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-05-13 19:36:19,090] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-13 19:36:19,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-13 19:36:19,115] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:19,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:19,166] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:19,167] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:19,167] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:19,542] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-13 19:36:19,581] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-13 19:36:19,730] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-13 19:36:19,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-13 19:36:19,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-13 19:36:19,818] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:19,824] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 22388458959728)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-13 19:36:19,824] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-13 19:36:19,844] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:36:19,953] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:19,953] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:19,953] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:36:20,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-13 19:36:20,130] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-13 19:36:20,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-13 19:36:20,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-13 19:36:20,786] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:36:20,793] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:36:20,797] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:36:20,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:36:20,799] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:36:20,799] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:36:20,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-13 19:36:21,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-13 19:36:21,179] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-05-13 19:36:24,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 156
[2023-05-13 19:36:24,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 156
[2023-05-13 19:36:24,431] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 156
[2023-05-13 19:36:24,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 156
[2023-05-13 19:36:24,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 26
[2023-05-13 19:36:24,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 26
[2023-05-13 19:36:24,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 26
[2023-05-13 19:36:24,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 26
[2023-05-13 19:36:24,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 155
[2023-05-13 19:36:24,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 155
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:25,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 155
[2023-05-13 19:36:25,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 154
[2023-05-13 19:36:25,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 155
[2023-05-13 19:36:25,651] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 154
/usr/bin/ld: skipping incompatible //usrusr//binlib//ldlibcuda.so:  whenskipping  searchingincompatible  for/ usr-/lcudalib
//libcuda.sousr /whenbin /searchingld :for  skipping- lcudaincompatible
 //usrusr//binlib//ldlibc.so:  whenskipping  searchingincompatible  for/ usr-/lclib
/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:26,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 154
[2023-05-13 19:36:26,582] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 23
[2023-05-13 19:36:26,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 23
[2023-05-13 19:36:26,594] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 153
[2023-05-13 19:36:26,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 153
[2023-05-13 19:36:26,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 152
[2023-05-13 19:36:26,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 154
[2023-05-13 19:36:26,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 23
[2023-05-13 19:36:26,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 23
[2023-05-13 19:36:26,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 153
[2023-05-13 19:36:26,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 153
[2023-05-13 19:36:26,701] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 152
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:28,011] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 152
[2023-05-13 19:36:28,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 151
[2023-05-13 19:36:28,041] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 151
[2023-05-13 19:36:28,059] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 150
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:28,390] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 150
[2023-05-13 19:36:28,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 149
[2023-05-13 19:36:28,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 149
[2023-05-13 19:36:28,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 148
[2023-05-13 19:36:28,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 152
[2023-05-13 19:36:28,783] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 151
[2023-05-13 19:36:28,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 151
[2023-05-13 19:36:28,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 150
[2023-05-13 19:36:29,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 150
[2023-05-13 19:36:29,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 149
[2023-05-13 19:36:29,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 149
[2023-05-13 19:36:29,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 148
[2023-05-13 19:36:29,244] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 148
[2023-05-13 19:36:29,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 147
[2023-05-13 19:36:29,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 147
[2023-05-13 19:36:29,270] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 146
[2023-05-13 19:36:29,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 148
[2023-05-13 19:36:29,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 147
[2023-05-13 19:36:29,477] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 147
[2023-05-13 19:36:29,481] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 146
[2023-05-13 19:36:29,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 146
[2023-05-13 19:36:29,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 145
[2023-05-13 19:36:29,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 145
[2023-05-13 19:36:29,593] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 144
[2023-05-13 19:36:29,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 146
[2023-05-13 19:36:29,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 145
[2023-05-13 19:36:29,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 145
[2023-05-13 19:36:29,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 144
[2023-05-13 19:36:29,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 144
[2023-05-13 19:36:29,897] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 143
[2023-05-13 19:36:29,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 143
[2023-05-13 19:36:29,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 142
[2023-05-13 19:36:30,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 144
[2023-05-13 19:36:30,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 143
[2023-05-13 19:36:30,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 143
[2023-05-13 19:36:30,160] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 142
[2023-05-13 19:36:30,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 142
[2023-05-13 19:36:30,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 141
[2023-05-13 19:36:30,242] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 141
[2023-05-13 19:36:30,245] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 140
[2023-05-13 19:36:30,477] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 142
[2023-05-13 19:36:30,481] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 141
[2023-05-13 19:36:30,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 141
[2023-05-13 19:36:30,508] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 140
[2023-05-13 19:36:30,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 140
[2023-05-13 19:36:30,556] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 139
[2023-05-13 19:36:30,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 139
[2023-05-13 19:36:30,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 138
[2023-05-13 19:36:30,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 140
[2023-05-13 19:36:30,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 139
[2023-05-13 19:36:30,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 139
[2023-05-13 19:36:30,869] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 138
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:31,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 138
[2023-05-13 19:36:31,683] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 57
[2023-05-13 19:36:31,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 57
[2023-05-13 19:36:31,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 137
[2023-05-13 19:36:31,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 138
[2023-05-13 19:36:31,949] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 57
[2023-05-13 19:36:31,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 57
[2023-05-13 19:36:31,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 137
[2023-05-13 19:36:32,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 137
[2023-05-13 19:36:32,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 136
[2023-05-13 19:36:32,428] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 137
[2023-05-13 19:36:32,443] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 136
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibcuda.so/ libcuda.sowhen  whensearching  searchingfor  for- lcuda-
lcuda/
usr//usrbin//binld/:ld :skipping  skippingincompatible  incompatible/ usr//usrlib//liblibc.so/ libc.sowhen  whensearching  searchingfor  for- lc-
lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:36:33,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 136
[2023-05-13 19:36:33,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 135
[2023-05-13 19:36:33,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 135
[2023-05-13 19:36:33,490] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 134
[2023-05-13 19:36:33,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 136
[2023-05-13 19:36:33,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 135
[2023-05-13 19:36:33,732] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 135
[2023-05-13 19:36:33,736] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 134
[2023-05-13 19:36:33,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 134
[2023-05-13 19:36:33,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 133
[2023-05-13 19:36:33,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 133
[2023-05-13 19:36:33,825] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 132
[2023-05-13 19:36:34,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 134
[2023-05-13 19:36:34,048] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 133
[2023-05-13 19:36:34,067] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 133
[2023-05-13 19:36:34,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 132
[2023-05-13 19:36:34,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 132
[2023-05-13 19:36:34,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 131
[2023-05-13 19:36:34,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 131
[2023-05-13 19:36:34,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 130
[2023-05-13 19:36:34,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 132
[2023-05-13 19:36:34,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 131
[2023-05-13 19:36:34,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 130
[2023-05-13 19:36:35,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 131
[2023-05-13 19:36:35,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 129
[2023-05-13 19:36:36,742] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 130
[2023-05-13 19:36:37,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 129
[2023-05-13 19:36:37,828] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 130
[2023-05-13 19:36:37,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 128
[2023-05-13 19:36:38,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 129
[2023-05-13 19:36:39,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 128
[2023-05-13 19:36:40,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 129
[2023-05-13 19:36:41,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 127
[2023-05-13 19:36:42,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 128
[2023-05-13 19:36:43,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 127
[2023-05-13 19:36:44,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 128
[2023-05-13 19:36:45,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 126
[2023-05-13 19:36:45,035] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 127
[2023-05-13 19:36:45,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 127
[2023-05-13 19:36:45,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 126
[2023-05-13 19:36:46,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 126
[2023-05-13 19:36:46,884] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 125
[2023-05-13 19:36:47,351] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 125
[2023-05-13 19:36:47,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 126
[2023-05-13 19:36:47,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 124
[2023-05-13 19:36:48,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 125
[2023-05-13 19:36:49,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 124
[2023-05-13 19:36:50,146] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 125
[2023-05-13 19:36:50,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 123
[2023-05-13 19:36:51,571] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 124
[2023-05-13 19:36:52,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 123
[2023-05-13 19:36:52,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 124
[2023-05-13 19:36:52,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 122
[2023-05-13 19:36:53,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 123
[2023-05-13 19:36:54,972] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 122
[2023-05-13 19:36:55,514] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 123
[2023-05-13 19:36:56,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 121
[2023-05-13 19:36:56,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 122
[2023-05-13 19:36:56,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 121
[2023-05-13 19:36:57,654] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 122
[2023-05-13 19:36:57,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 120
[2023-05-13 19:36:59,227] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 121
[2023-05-13 19:37:00,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 121
[2023-05-13 19:37:00,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 120
[2023-05-13 19:37:01,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 120
[2023-05-13 19:37:02,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 119
[2023-05-13 19:37:02,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 120
[2023-05-13 19:37:03,626] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 119
[2023-05-13 19:37:03,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 119
[2023-05-13 19:37:04,315] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 119
[2023-05-13 19:37:05,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 118
[2023-05-13 19:37:05,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 118
/usr//usrbin//ld:bin /skipping ldincompatible: / usr/skipping libincompatible/ libcuda.so/ usr/whenlib /searchinglibcuda.so  forwhen  -searchinglcuda
 /forusr /-binlcuda/
/ld: usrskipping/bin /incompatible ld:/ skippingusr /incompatiblelib/ libc.so/ usrwhen/lib /searching libc.so forwhen  searching- lcfor
 -[2023-05-13 19:38:19,628] torch._inductor.utils: [WARNING] Detected long compilation time of 72.4011721611023 seconds for kernel name triton_
lc
[2023-05-13 19:38:20,539] torch._inductor.utils: [WARNING] 
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_ops.autotune import reduction
from torch._inductor.utils import instance_descriptor

@reduction(
    size_hints=[16384, 16],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 1, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 16384
    rnumel = 16
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp11 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 4
        r2 = (rindex // 4)
        r3 = rindex
        tmp0 = tl.load(in_ptr0 + ((2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp1 = tl.load(in_ptr0 + (1 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp3 = tl.load(in_ptr0 + (8 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp5 = tl.load(in_ptr0 + (9 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp7 = tl.load(in_ptr1 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp9 = tl.load(in_ptr2 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp6 = tmp4 + tmp5
        tmp8 = tmp6 * tmp7
        tmp10 = tmp8 * tmp9
        _tmp11 = tl.where(rmask & xmask, _tmp11 + tmp10, _tmp11)
        tl.store(out_ptr0 + (r3 + (16*x0) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp8, rmask & xmask)
    tmp11 = tl.sum(_tmp11, 1)[:, None]
    tl.store(out_ptr1 + x0, tmp11, xmask)
    _tmp13 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r3 = rindex
        tmp12 = tl.load(out_ptr0 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        _tmp13 = tl.where(rmask & xmask, _tmp13 + tmp12, _tmp13)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr2 + x0, tmp13, xmask)

[2023-05-13 19:38:21,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 118
[2023-05-13 19:38:22,061] torch._inductor.utils: [WARNING] Detected long compilation time of 73.40901589393616 seconds for kernel name triton_
[2023-05-13 19:38:22,381] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 76
[2023-05-13 19:38:23,144] torch._inductor.utils: [WARNING] 
import triton
import triton.language as tl
from torch._inductor.ir import ReductionHint
from torch._inductor.ir import TileHint
from torch._inductor.triton_ops.autotune import reduction
from torch._inductor.utils import instance_descriptor

@reduction(
    size_hints=[16384, 16],
    reduction_hint=ReductionHint.INNER,
    filename=__file__,
    meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=())]}
)
@triton.jit
def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
    xnumel = 16384
    rnumel = 16
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
    xmask = xindex < xnumel
    rbase = tl.arange(0, RBLOCK)[None, :]
    x0 = xindex
    _tmp11 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r1 = rindex % 4
        r2 = (rindex // 4)
        r3 = rindex
        tmp0 = tl.load(in_ptr0 + ((2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp1 = tl.load(in_ptr0 + (1 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp3 = tl.load(in_ptr0 + (8 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp5 = tl.load(in_ptr0 + (9 + (2*r1) + (16*r2) + (64*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp7 = tl.load(in_ptr1 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp9 = tl.load(in_ptr2 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp6 = tmp4 + tmp5
        tmp8 = tmp6 * tmp7
        tmp10 = tmp8 * tmp9
        _tmp11 = tl.where(rmask & xmask, _tmp11 + tmp10, _tmp11)
        tl.store(out_ptr0 + (r3 + (16*x0) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp8, rmask & xmask)
    tmp11 = tl.sum(_tmp11, 1)[:, None]
    tl.store(out_ptr1 + x0, tmp11, xmask)
    _tmp13 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0
    for roffset in range(0, rnumel, RBLOCK):
        rindex = roffset + rbase
        rmask = rindex < rnumel
        r3 = rindex
        tmp12 = tl.load(out_ptr0 + (r3 + (16*x0)), rmask & xmask, eviction_policy='evict_last', other=0)
        _tmp13 = tl.where(rmask & xmask, _tmp13 + tmp12, _tmp13)
    tmp13 = tl.sum(_tmp13, 1)[:, None]
    tl.store(out_ptr2 + x0, tmp13, xmask)

[2023-05-13 19:38:23,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 76
[2023-05-13 19:38:24,279] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 118
[2023-05-13 19:38:24,726] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 117
[2023-05-13 19:38:25,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 76
/[2023-05-13 19:38:27,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 76
usr[2023-05-13 19:38:30,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 117
//binusr//bin/ldld::  skippingskipping  incompatibleincompatible  //usr/usrlib//libcuda.so libwhen /searching libcuda.sofor  when- lcudasearching
 /forusr /-binlcuda/
ld/:usr /skippingbin /incompatibleld :/ usrskipping/ libincompatible/ libc.so/ usrwhen/ libsearching/ libc.sofor  when- lcsearching
 for -lc
[2023-05-13 19:38:51,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 117
[2023-05-13 19:38:51,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 117
[2023-05-13 19:38:51,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 116
[2023-05-13 19:38:51,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 116
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:38:52,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 116
[2023-05-13 19:38:53,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 115
[2023-05-13 19:38:53,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 115
[2023-05-13 19:38:53,030] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 114
[2023-05-13 19:38:53,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 116
[2023-05-13 19:38:53,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 115
[2023-05-13 19:38:53,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 115
[2023-05-13 19:38:53,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 114
[2023-05-13 19:38:53,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 114
[2023-05-13 19:38:53,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 113
[2023-05-13 19:38:53,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 113
[2023-05-13 19:38:53,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 112
[2023-05-13 19:38:53,786] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 114
[2023-05-13 19:38:53,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 113
[2023-05-13 19:38:53,790] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 112
[2023-05-13 19:38:53,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 111
[2023-05-13 19:38:53,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 113
[2023-05-13 19:38:53,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 111
[2023-05-13 19:38:53,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 112
[2023-05-13 19:38:53,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 110
[2023-05-13 19:38:54,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 112
[2023-05-13 19:38:54,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 111
[2023-05-13 19:38:54,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 110
[2023-05-13 19:38:54,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 109
[2023-05-13 19:38:54,141] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 111
[2023-05-13 19:38:54,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 109
[2023-05-13 19:38:54,146] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 110
[2023-05-13 19:38:54,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 108
[2023-05-13 19:38:54,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 110
[2023-05-13 19:38:54,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 108
[2023-05-13 19:38:54,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 109
[2023-05-13 19:38:54,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 107
[2023-05-13 19:38:54,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 109
[2023-05-13 19:38:54,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 107
[2023-05-13 19:38:54,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 108
[2023-05-13 19:38:54,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 106
[2023-05-13 19:38:54,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 108
[2023-05-13 19:38:54,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 107
[2023-05-13 19:38:54,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 106
[2023-05-13 19:38:54,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 105
[2023-05-13 19:38:54,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 107
[2023-05-13 19:38:54,805] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 105
[2023-05-13 19:38:54,806] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 106
[2023-05-13 19:38:54,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 104
[2023-05-13 19:38:55,114] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 106
[2023-05-13 19:38:55,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 105
[2023-05-13 19:38:55,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 104
[2023-05-13 19:38:55,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 103
[2023-05-13 19:38:55,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 105
[2023-05-13 19:38:55,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 104
[2023-05-13 19:38:55,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 103
[2023-05-13 19:38:55,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 102
[2023-05-13 19:38:55,445] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 104
[2023-05-13 19:38:55,448] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 103
[2023-05-13 19:38:55,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 102
[2023-05-13 19:38:55,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 101
[2023-05-13 19:38:55,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 103
[2023-05-13 19:38:55,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 102
[2023-05-13 19:38:55,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 101
[2023-05-13 19:38:55,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 100
[2023-05-13 19:38:55,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 102
[2023-05-13 19:38:55,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 100
[2023-05-13 19:38:55,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 101
[2023-05-13 19:38:55,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 99
[2023-05-13 19:38:55,810] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 99
[2023-05-13 19:38:55,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 101
[2023-05-13 19:38:55,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 98
[2023-05-13 19:38:55,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 100
[2023-05-13 19:38:56,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 100
[2023-05-13 19:38:56,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 99
[2023-05-13 19:38:56,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 99
[2023-05-13 19:38:56,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 98
[2023-05-13 19:38:56,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 98
[2023-05-13 19:38:56,566] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 97
[2023-05-13 19:38:56,575] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 97
[2023-05-13 19:38:56,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 96
[2023-05-13 19:38:56,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 98
[2023-05-13 19:38:56,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 97
[2023-05-13 19:38:56,858] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 97
[2023-05-13 19:38:56,863] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 96
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:38:57,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 96
[2023-05-13 19:38:57,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 96
[2023-05-13 19:38:59,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 95
[2023-05-13 19:38:59,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 95
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:38:59,933] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 95
[2023-05-13 19:38:59,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 94
[2023-05-13 19:38:59,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 95
[2023-05-13 19:38:59,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 94
[2023-05-13 19:38:59,956] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 94
[2023-05-13 19:38:59,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 94
[2023-05-13 19:38:59,960] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 93
[2023-05-13 19:38:59,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 93
[2023-05-13 19:39:00,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 93
[2023-05-13 19:39:00,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 93
[2023-05-13 19:39:00,241] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 92
[2023-05-13 19:39:00,241] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 92
[2023-05-13 19:39:00,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 92
[2023-05-13 19:39:00,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 92
[2023-05-13 19:39:00,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 91
[2023-05-13 19:39:00,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 91
[2023-05-13 19:39:00,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 91
[2023-05-13 19:39:00,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 90
[2023-05-13 19:39:00,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 91
[2023-05-13 19:39:00,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 90
[2023-05-13 19:39:00,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 90
[2023-05-13 19:39:00,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 90
[2023-05-13 19:39:00,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 89
[2023-05-13 19:39:00,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 89
[2023-05-13 19:39:00,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 89
[2023-05-13 19:39:00,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 88
[2023-05-13 19:39:00,819] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 89
[2023-05-13 19:39:00,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 88
[2023-05-13 19:39:00,829] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 88
[2023-05-13 19:39:00,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 87
[2023-05-13 19:39:00,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 88
[2023-05-13 19:39:00,838] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 87
[2023-05-13 19:39:01,100] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 87
[2023-05-13 19:39:01,102] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 86
[2023-05-13 19:39:01,108] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 87
[2023-05-13 19:39:01,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 86
[2023-05-13 19:39:01,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 86
[2023-05-13 19:39:01,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 85
[2023-05-13 19:39:01,124] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 86
[2023-05-13 19:39:01,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 85
[2023-05-13 19:39:01,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 85
[2023-05-13 19:39:01,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 84
[2023-05-13 19:39:01,398] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 85
[2023-05-13 19:39:01,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 84
[2023-05-13 19:39:01,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 84
[2023-05-13 19:39:01,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 83
[2023-05-13 19:39:01,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 84
[2023-05-13 19:39:01,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 83
[2023-05-13 19:39:01,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 83
[2023-05-13 19:39:01,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 82
[2023-05-13 19:39:01,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 82
[2023-05-13 19:39:01,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 83
[2023-05-13 19:39:01,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 81
[2023-05-13 19:39:01,697] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 82
[2023-05-13 19:39:01,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 82
[2023-05-13 19:39:01,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 81
[2023-05-13 19:39:01,973] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 81
[2023-05-13 19:39:01,976] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 80
[2023-05-13 19:39:01,991] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 80
[2023-05-13 19:39:01,995] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 79
[2023-05-13 19:39:02,270] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 79
[2023-05-13 19:39:02,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 78
[2023-05-13 19:39:02,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 78
[2023-05-13 19:39:02,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 77
[2023-05-13 19:39:02,466] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 81
[2023-05-13 19:39:02,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 80
[2023-05-13 19:39:02,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 80
[2023-05-13 19:39:02,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 79
[2023-05-13 19:39:02,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 77
[2023-05-13 19:39:02,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 75
[2023-05-13 19:39:02,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 75
[2023-05-13 19:39:02,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 74
[2023-05-13 19:39:02,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 79
[2023-05-13 19:39:02,760] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 78
[2023-05-13 19:39:02,774] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 78
[2023-05-13 19:39:02,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 77
[2023-05-13 19:39:03,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 77
[2023-05-13 19:39:03,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 75
[2023-05-13 19:39:03,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 75
[2023-05-13 19:39:03,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 74
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:05,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 74
[2023-05-13 19:39:05,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 74
[2023-05-13 19:39:08,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 73
[2023-05-13 19:39:08,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 73
[2023-05-13 19:39:08,797] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 73
[2023-05-13 19:39:08,799] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 73
[2023-05-13 19:39:08,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 72
[2023-05-13 19:39:08,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 72
[2023-05-13 19:39:09,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 72
[2023-05-13 19:39:09,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 71
[2023-05-13 19:39:09,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 71
[2023-05-13 19:39:09,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 70
[2023-05-13 19:39:09,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 72
[2023-05-13 19:39:09,588] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 71
[2023-05-13 19:39:09,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 71
[2023-05-13 19:39:09,608] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 70
[2023-05-13 19:39:09,777] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 70
[2023-05-13 19:39:09,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 69
[2023-05-13 19:39:09,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 69
[2023-05-13 19:39:09,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 68
[2023-05-13 19:39:09,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 70
[2023-05-13 19:39:09,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 69
[2023-05-13 19:39:09,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 69
[2023-05-13 19:39:09,906] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 68
[2023-05-13 19:39:10,072] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 68
[2023-05-13 19:39:10,074] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 67
[2023-05-13 19:39:10,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 67
[2023-05-13 19:39:10,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 66
[2023-05-13 19:39:10,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 68
[2023-05-13 19:39:10,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 67
[2023-05-13 19:39:10,198] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 67
[2023-05-13 19:39:10,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 66
[2023-05-13 19:39:10,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 66
[2023-05-13 19:39:10,368] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 65
[2023-05-13 19:39:10,383] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 65
[2023-05-13 19:39:10,388] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 64
[2023-05-13 19:39:10,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 66
[2023-05-13 19:39:10,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 65
[2023-05-13 19:39:10,497] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 65
[2023-05-13 19:39:10,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 64
[2023-05-13 19:39:10,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 64
[2023-05-13 19:39:10,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 63
[2023-05-13 19:39:10,674] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 63
[2023-05-13 19:39:10,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 62
[2023-05-13 19:39:10,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 64
[2023-05-13 19:39:10,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 63
[2023-05-13 19:39:10,796] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 63
[2023-05-13 19:39:10,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 62
[2023-05-13 19:39:10,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 62
[2023-05-13 19:39:10,950] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 61
[2023-05-13 19:39:10,963] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 61
[2023-05-13 19:39:10,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 60
[2023-05-13 19:39:11,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 62
[2023-05-13 19:39:11,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 61
[2023-05-13 19:39:11,096] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 61
[2023-05-13 19:39:11,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 60
[2023-05-13 19:39:11,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 60
[2023-05-13 19:39:11,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 59
[2023-05-13 19:39:11,253] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 59
[2023-05-13 19:39:11,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 58
[2023-05-13 19:39:11,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 60
[2023-05-13 19:39:11,382] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 59
[2023-05-13 19:39:11,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 59
[2023-05-13 19:39:11,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 58
[2023-05-13 19:39:11,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 58
[2023-05-13 19:39:11,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 56
[2023-05-13 19:39:11,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 56
[2023-05-13 19:39:11,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 55
[2023-05-13 19:39:11,677] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 58
[2023-05-13 19:39:11,680] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 56
[2023-05-13 19:39:11,701] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 56
[2023-05-13 19:39:11,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 55
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:14,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 55
[2023-05-13 19:39:14,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 55
[2023-05-13 19:39:15,755] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 54
[2023-05-13 19:39:15,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 54
[2023-05-13 19:39:15,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 53
[2023-05-13 19:39:15,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 54
[2023-05-13 19:39:16,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 53
[2023-05-13 19:39:16,014] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 52
[2023-05-13 19:39:16,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 52
[2023-05-13 19:39:16,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 51
[2023-05-13 19:39:16,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 54
[2023-05-13 19:39:16,134] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 53
[2023-05-13 19:39:16,248] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 53
[2023-05-13 19:39:16,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 52
[2023-05-13 19:39:16,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 52
[2023-05-13 19:39:16,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 51
[2023-05-13 19:39:16,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 51
[2023-05-13 19:39:16,810] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 50
[2023-05-13 19:39:16,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 50
[2023-05-13 19:39:16,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 49
[2023-05-13 19:39:17,020] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 51
[2023-05-13 19:39:17,027] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 50
[2023-05-13 19:39:17,063] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 49
[2023-05-13 19:39:17,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 48
[2023-05-13 19:39:17,079] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 48
[2023-05-13 19:39:17,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 47
[2023-05-13 19:39:17,156] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 50
[2023-05-13 19:39:17,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 49
[2023-05-13 19:39:17,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 49
[2023-05-13 19:39:17,273] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 48
[2023-05-13 19:39:17,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 48
[2023-05-13 19:39:17,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 47
[2023-05-13 19:39:17,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 47
[2023-05-13 19:39:17,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 46
[2023-05-13 19:39:17,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 46
[2023-05-13 19:39:17,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 45
[2023-05-13 19:39:17,586] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 47
[2023-05-13 19:39:17,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 46
[2023-05-13 19:39:17,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 45
[2023-05-13 19:39:17,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 44
[2023-05-13 19:39:17,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 44
[2023-05-13 19:39:17,633] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 43
[2023-05-13 19:39:17,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 46
[2023-05-13 19:39:17,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 45
[2023-05-13 19:39:17,843] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 45
[2023-05-13 19:39:17,844] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 44
[2023-05-13 19:39:17,859] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 44
[2023-05-13 19:39:17,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 43
[2023-05-13 19:39:17,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 43
[2023-05-13 19:39:17,915] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 42
[2023-05-13 19:39:18,043] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 42
[2023-05-13 19:39:18,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 41
[2023-05-13 19:39:18,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 43
[2023-05-13 19:39:18,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 42
[2023-05-13 19:39:18,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 41
[2023-05-13 19:39:18,155] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 40
[2023-05-13 19:39:18,169] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 40
[2023-05-13 19:39:18,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 39
[2023-05-13 19:39:18,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 42
[2023-05-13 19:39:18,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 41
[2023-05-13 19:39:18,398] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 41
[2023-05-13 19:39:18,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 40
[2023-05-13 19:39:18,417] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 40
[2023-05-13 19:39:18,421] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 39
[2023-05-13 19:39:18,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 39
[2023-05-13 19:39:18,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 38
[2023-05-13 19:39:18,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 38
[2023-05-13 19:39:18,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 37
[2023-05-13 19:39:18,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 37
[2023-05-13 19:39:18,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 36
[2023-05-13 19:39:18,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 36
[2023-05-13 19:39:18,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 35
[2023-05-13 19:39:18,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 35
[2023-05-13 19:39:18,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 34
[2023-05-13 19:39:19,122] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 34
[2023-05-13 19:39:19,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 33
[2023-05-13 19:39:19,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 33
[2023-05-13 19:39:19,233] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 32
[2023-05-13 19:39:19,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 32
[2023-05-13 19:39:19,251] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 31
[2023-05-13 19:39:19,379] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 39
[2023-05-13 19:39:19,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 38
[2023-05-13 19:39:19,521] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 38
[2023-05-13 19:39:19,525] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 37
[2023-05-13 19:39:19,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 37
[2023-05-13 19:39:19,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 36
[2023-05-13 19:39:19,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 36
[2023-05-13 19:39:19,657] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 35
[2023-05-13 19:39:19,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 35
[2023-05-13 19:39:19,948] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 34
[2023-05-13 19:39:20,002] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 31
[2023-05-13 19:39:20,008] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 30
[2023-05-13 19:39:20,082] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 34
[2023-05-13 19:39:20,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 33
[2023-05-13 19:39:20,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 30
[2023-05-13 19:39:20,141] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 29
[2023-05-13 19:39:20,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 33
[2023-05-13 19:39:20,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 32
[2023-05-13 19:39:20,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 32
[2023-05-13 19:39:20,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 31
[2023-05-13 19:39:20,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 29
[2023-05-13 19:39:20,249] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 28
[2023-05-13 19:39:20,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 28
[2023-05-13 19:39:20,269] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 27
[2023-05-13 19:39:20,510] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 31
[2023-05-13 19:39:20,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 30
[2023-05-13 19:39:20,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 27
[2023-05-13 19:39:20,556] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 25
[2023-05-13 19:39:20,649] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 30
[2023-05-13 19:39:20,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 29
[2023-05-13 19:39:20,685] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 25
[2023-05-13 19:39:20,688] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 24
[2023-05-13 19:39:20,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 29
[2023-05-13 19:39:20,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 28
[2023-05-13 19:39:20,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 28
[2023-05-13 19:39:20,787] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 27
[2023-05-13 19:39:20,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 24
[2023-05-13 19:39:20,796] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 22
[2023-05-13 19:39:20,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 22
[2023-05-13 19:39:20,828] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 21
[2023-05-13 19:39:21,069] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 27
[2023-05-13 19:39:21,075] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 25
[2023-05-13 19:39:21,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 25
[2023-05-13 19:39:21,210] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 24
[2023-05-13 19:39:21,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 24
[2023-05-13 19:39:21,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 22
[2023-05-13 19:39:21,353] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 22
[2023-05-13 19:39:21,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 21
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:21,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 21
[2023-05-13 19:39:21,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 20
[2023-05-13 19:39:21,828] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 20
[2023-05-13 19:39:21,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 19
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:22,389] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 21
[2023-05-13 19:39:22,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 20
[2023-05-13 19:39:22,422] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 20
[2023-05-13 19:39:22,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 19
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:23,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 19
[2023-05-13 19:39:23,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 18
[2023-05-13 19:39:23,533] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 19
[2023-05-13 19:39:23,550] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 18
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:25,451] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 18
[2023-05-13 19:39:25,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 18
[2023-05-13 19:39:26,165] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-05-13 19:39:26,181] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-05-13 19:39:26,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 17
[2023-05-13 19:39:26,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3
[2023-05-13 19:39:26,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3
[2023-05-13 19:39:26,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 17
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:27,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 17
[2023-05-13 19:39:27,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 16
[2023-05-13 19:39:27,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 17
[2023-05-13 19:39:27,724] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 16
[2023-05-13 19:39:27,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 16
[2023-05-13 19:39:27,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-05-13 19:39:28,155] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-05-13 19:39:28,160] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-05-13 19:39:28,240] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 16
[2023-05-13 19:39:28,245] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 15
[2023-05-13 19:39:28,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-05-13 19:39:28,293] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-05-13 19:39:28,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 15
[2023-05-13 19:39:28,459] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 14
[2023-05-13 19:39:28,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-05-13 19:39:28,506] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-05-13 19:39:28,582] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 14
[2023-05-13 19:39:28,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 13
[2023-05-13 19:39:28,634] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-05-13 19:39:28,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-05-13 19:39:28,786] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 13
[2023-05-13 19:39:28,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 12
[2023-05-13 19:39:28,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-05-13 19:39:28,849] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-05-13 19:39:28,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 12
[2023-05-13 19:39:28,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 11
[2023-05-13 19:39:28,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-05-13 19:39:28,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-05-13 19:39:29,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 11
[2023-05-13 19:39:29,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 10
[2023-05-13 19:39:29,190] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-05-13 19:39:29,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-05-13 19:39:29,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 10
[2023-05-13 19:39:29,251] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9
[2023-05-13 19:39:29,325] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-05-13 19:39:29,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-05-13 19:39:29,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9
[2023-05-13 19:39:29,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8
[2023-05-13 19:39:29,538] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-05-13 19:39:29,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-05-13 19:39:29,582] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8
[2023-05-13 19:39:29,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7
[2023-05-13 19:39:29,671] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-05-13 19:39:29,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-05-13 19:39:29,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7
[2023-05-13 19:39:29,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6
[2023-05-13 19:39:29,878] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-05-13 19:39:29,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-05-13 19:39:29,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6
[2023-05-13 19:39:29,922] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5
[2023-05-13 19:39:30,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-05-13 19:39:30,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-05-13 19:39:30,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5
[2023-05-13 19:39:30,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4
[2023-05-13 19:39:30,211] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-05-13 19:39:30,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-05-13 19:39:30,251] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4
[2023-05-13 19:39:30,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2
[2023-05-13 19:39:30,339] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
[2023-05-13 19:39:30,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2
[2023-05-13 19:39:30,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1
[2023-05-13 19:39:30,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1
I0513 19:39:31.001211 22392998065984 run_lib.py:146] step: 0, training_loss: 1.00149e+00
[2023-05-13 19:39:31,035] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:31,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:31,039] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:31,040] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:31,040] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:31,041] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:31,043] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:31,044] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:31,044] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:31,044] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:31,052] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-13 19:39:31,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-13 19:39:31,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-13 19:39:31,091] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:31,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-13 19:39:31,093] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:31,097] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:31,098] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:31,205] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:31,205] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:31,205] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:31,207] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:31,207] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:31,207] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:31,247] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:31,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
[2023-05-13 19:39:31,913] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-13 19:39:32,141] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:32,520] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-13 19:39:32,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-13 19:39:32,630] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:32,637] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:39:32,639] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:39:32,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:32,640] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:32,640] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:32,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-13 19:39:32,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-13 19:39:32,665] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:32,669] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:32,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-13 19:39:32,776] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:32,776] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:32,777] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:32,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-13 19:39:32,866] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-13 19:39:33,094] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-13 19:39:33,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-13 19:39:33,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-13 19:39:33,238] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:33,240] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:33,244] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:33,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:39:33,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:39:33,250] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:33,250] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:33,250] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:33,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-13 19:39:33,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-13 19:39:33,274] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:33,278] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:33,350] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:33,350] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:33,351] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:33,385] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:33,385] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:33,385] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:33,392] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-13 19:39:33,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-13 19:39:33,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-13 19:39:33,475] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-13 19:39:33,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-13 19:39:33,701] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-13 19:39:33,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-13 19:39:33,846] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:33,852] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:33,963] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:33,964] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:33,964] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:34,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-13 19:39:34,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-13 19:39:34,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-13 19:39:34,255] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:34,261] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:34,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-13 19:39:34,369] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:34,369] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:34,370] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:34,401] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-13 19:39:34,416] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-13 19:39:34,430] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:34,436] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:34,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-13 19:39:34,550] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:34,550] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:34,551] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:34,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-13 19:39:34,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-13 19:39:34,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-13 19:39:34,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-13 19:39:34,839] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:34,845] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:34,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-13 19:39:34,952] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:34,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:34,952] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:34,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-13 19:39:34,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-13 19:39:35,029] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:35,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:35,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-13 19:39:35,153] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:35,154] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:35,154] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:35,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-13 19:39:35,251] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-13 19:39:35,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-13 19:39:35,379] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-13 19:39:35,408] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:35,414] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:35,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-13 19:39:35,521] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:35,521] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:35,521] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:35,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-13 19:39:35,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-13 19:39:35,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-13 19:39:35,653] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:35,660] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:35,780] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:35,780] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:35,781] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:35,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-13 19:39:35,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-13 19:39:35,877] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-13 19:39:35,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-13 19:39:35,991] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:35,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:36,104] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:36,104] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:36,105] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:36,127] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-13 19:39:36,151] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-13 19:39:36,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-13 19:39:36,243] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-13 19:39:36,275] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:36,283] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:36,398] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:36,398] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:36,399] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:36,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-13 19:39:36,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-13 19:39:36,496] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-13 19:39:36,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-13 19:39:36,575] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:36,582] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:36,690] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:36,691] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:36,691] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:36,733] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-13 19:39:36,747] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-13 19:39:36,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-13 19:39:36,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-13 19:39:36,896] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:36,903] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:37,007] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-13 19:39:37,020] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,020] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,021] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:37,067] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-13 19:39:37,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-13 19:39:37,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-13 19:39:37,149] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,154] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:37,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:37,158] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,158] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,159] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:37,168] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-13 19:39:37,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-13 19:39:37,203] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,212] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:37,215] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:37,216] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,216] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,216] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:37,226] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-13 19:39:37,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-13 19:39:37,254] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,263] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:37,367] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-13 19:39:37,370] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,370] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,371] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:37,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-13 19:39:37,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-13 19:39:37,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:37,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:37,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,529] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:37,541] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-13 19:39:37,577] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-13 19:39:37,577] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,587] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:37,591] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:37,592] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,592] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,592] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:37,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-13 19:39:37,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-13 19:39:37,640] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:37,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:37,764] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:37,765] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:37,765] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:37,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-13 19:39:38,029] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 19:39:38,260] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-13 19:39:38,446] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-13 19:39:38,700] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-13 19:39:38,725] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-13 19:39:38,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:38,766] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:39:38,767] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:39:38,768] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:38,768] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:38,768] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:38,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-13 19:39:38,792] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-13 19:39:38,793] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:38,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:38,807] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:38,808] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:38,808] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:38,808] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:38,820] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-13 19:39:39,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-13 19:39:39,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-13 19:39:39,190] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:39,200] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:39,205] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:39,207] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:39,207] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:39,207] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:39,213] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:39,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-13 19:39:39,223] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:39:39,224] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:39:39,225] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:39,226] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:39,226] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:39,237] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-13 19:39:39,254] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-13 19:39:39,255] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:39,267] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:39,273] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:39,274] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:39,275] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:39,275] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:39,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-13 19:39:39,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-13 19:39:39,590] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:39,601] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:39,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-13 19:39:39,673] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:39,686] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:39,691] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:39,693] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:39,693] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:39,693] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:39,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-13 19:39:39,710] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:39,710] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:39,711] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:39,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 182
[2023-05-13 19:39:39,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 182
[2023-05-13 19:39:40,042] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 183
[2023-05-13 19:39:40,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-13 19:39:40,082] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,095] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:39:40,166] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 183
[2023-05-13 19:39:40,196] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,201] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:40,206] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,207] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,207] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,207] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,214] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,214] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,215] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:39:40,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 184
[2023-05-13 19:39:40,260] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 182
[2023-05-13 19:39:40,317] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 182
[2023-05-13 19:39:40,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 183
[2023-05-13 19:39:40,599] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 184
[2023-05-13 19:39:40,599] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,663] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:40,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,668] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,668] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,668] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,677] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 183
[2023-05-13 19:39:40,694] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 185
[2023-05-13 19:39:40,707] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:40,717] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,718] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,718] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,718] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 185
[2023-05-13 19:39:40,719] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 184
[2023-05-13 19:39:40,739] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:40,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,743] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,743] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,743] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 186
[2023-05-13 19:39:40,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 186
[2023-05-13 19:39:40,790] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,799] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:40,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,803] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,803] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,803] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,826] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 187
[2023-05-13 19:39:40,854] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 187
[2023-05-13 19:39:40,855] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,874] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:40,879] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,881] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,881] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,881] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,906] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 188
[2023-05-13 19:39:40,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 188
[2023-05-13 19:39:40,934] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:40,946] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:40,951] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:40,952] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:40,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:40,952] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:40,977] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 189
[2023-05-13 19:39:41,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 189
[2023-05-13 19:39:41,003] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 189
[2023-05-13 19:39:41,146] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 184
[2023-05-13 19:39:41,147] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0513 19:39:41.193089 22392998065984 run_lib.py:167] step: 0, eval_loss: 9.94398e-01
[2023-05-13 19:39:41,217] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:41,220] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:41,222] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:41,222] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:41,222] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:41,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 185
[2023-05-13 19:39:41,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 185
[2023-05-13 19:39:41,275] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,298] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:41,306] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:41,307] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:41,307] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:41,307] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:41,334] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 186
[2023-05-13 19:39:41,366] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 186
[2023-05-13 19:39:41,366] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:39:41,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:39:41,382] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:41,382] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:41,382] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:41,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 187
[2023-05-13 19:39:41,438] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 187
[2023-05-13 19:39:41,439] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:41,463] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:41,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:41,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:41,465] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:41,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 188
[2023-05-13 19:39:41,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 188
[2023-05-13 19:39:41,513] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,523] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:39:41,528] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:39:41,529] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:39:41,529] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:39:41,529] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:39:41,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 189
[2023-05-13 19:39:41,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 189
[2023-05-13 19:39:41,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:39:41,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 189
[2023-05-13 19:39:41,776] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 189
[2023-05-13 19:39:41,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 188
[2023-05-13 19:39:42,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 189
[2023-05-13 19:39:42,063] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 188
[2023-05-13 19:39:42,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 188
[2023-05-13 19:39:42,183] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 187
[2023-05-13 19:39:42,530] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 188
[2023-05-13 19:39:42,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 187
[2023-05-13 19:39:42,555] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 187
[2023-05-13 19:39:42,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 186
[2023-05-13 19:39:43,022] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 187
[2023-05-13 19:39:43,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 186
[2023-05-13 19:39:43,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 186
[2023-05-13 19:39:43,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 185
[2023-05-13 19:39:43,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 186
[2023-05-13 19:39:43,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 185
[2023-05-13 19:39:43,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 185
[2023-05-13 19:39:43,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 185
I0513 19:40:06.923189 22392998065984 run_lib.py:146] step: 50, training_loss: 9.93819e-01
I0513 19:40:31.275745 22392998065984 run_lib.py:146] step: 100, training_loss: 9.66797e-01
I0513 19:40:31.438748 22392998065984 run_lib.py:167] step: 100, eval_loss: 9.69363e-01
I0513 19:40:55.199251 22392998065984 run_lib.py:146] step: 150, training_loss: 8.93344e-01
I0513 19:41:18.696691 22392998065984 run_lib.py:146] step: 200, training_loss: 8.17185e-01
I0513 19:41:18.856409 22392998065984 run_lib.py:167] step: 200, eval_loss: 8.44613e-01
I0513 19:41:43.413455 22392998065984 run_lib.py:146] step: 250, training_loss: 7.12734e-01
I0513 19:42:07.440086 22392998065984 run_lib.py:146] step: 300, training_loss: 5.94419e-01
I0513 19:42:07.609766 22392998065984 run_lib.py:167] step: 300, eval_loss: 6.62226e-01
I0513 19:42:31.937356 22392998065984 run_lib.py:146] step: 350, training_loss: 4.92168e-01
[2023-05-13 19:42:51,215] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 19:42:51,229] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 19:42:51,231] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:51,231] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:51,232] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:42:51,237] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 19:42:51,254] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 19:42:51,256] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:51,256] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:51,256] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:42:51,264] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 190
[2023-05-13 19:42:51,293] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 190
[2023-05-13 19:42:51,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 190
[2023-05-13 19:42:51,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:51,907] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:42:51,910] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:42:51,911] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:51,911] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:51,912] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:42:51,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 190
[2023-05-13 19:42:51,914] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:51,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:42:51,944] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:42:51,945] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:51,945] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:51,945] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:42:51,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 191
[2023-05-13 19:42:52,204] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 191
[2023-05-13 19:42:52,346] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 191
[2023-05-13 19:42:52,347] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:52,380] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:42:52,489] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:52,490] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:52,490] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:42:52,578] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 191
[2023-05-13 19:42:52,579] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:52,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:42:52,614] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 192
[2023-05-13 19:42:52,720] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:52,721] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:52,721] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:42:52,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 192
[2023-05-13 19:42:53,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 192
[2023-05-13 19:42:53,336] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 192
[2023-05-13 19:42:53,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 193
[2023-05-13 19:42:53,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 193
[2023-05-13 19:42:56,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 193
[2023-05-13 19:42:56,191] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:56,430] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 193
[2023-05-13 19:42:56,462] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:42:59,926] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:42:59,927] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:42:59,928] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:42:59,928] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:42:59,929] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:42:59,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 194
[2023-05-13 19:43:00,185] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:43:00,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:43:00,187] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:00,187] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:00,188] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:00,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 194
[2023-05-13 19:43:00,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 194
[2023-05-13 19:43:00,290] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:00,296] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:00,406] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:00,406] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:00,406] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:00,529] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 195
[2023-05-13 19:43:00,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 194
[2023-05-13 19:43:00,545] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:00,552] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:00,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 195
[2023-05-13 19:43:00,660] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:00,660] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:00,661] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:00,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 195
[2023-05-13 19:43:00,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 195
[2023-05-13 19:43:01,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 196
[2023-05-13 19:43:01,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 196
[2023-05-13 19:43:01,245] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:01,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:01,320] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 196
[2023-05-13 19:43:01,373] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:01,373] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:01,374] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:01,453] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 196
[2023-05-13 19:43:01,484] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:01,491] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:01,503] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 197
[2023-05-13 19:43:01,560] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 197
[2023-05-13 19:43:01,599] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:01,599] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:01,600] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:01,720] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 197
[2023-05-13 19:43:01,772] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 197
[2023-05-13 19:43:02,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 198
[2023-05-13 19:43:02,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 198
[2023-05-13 19:43:02,247] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:02,255] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:02,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 198
[2023-05-13 19:43:02,371] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:02,371] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:02,372] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:02,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 198
[2023-05-13 19:43:02,423] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:02,429] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:02,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 199
[2023-05-13 19:43:02,537] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:02,538] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:02,538] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:02,553] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 199
[2023-05-13 19:43:02,658] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 199
[2023-05-13 19:43:02,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 199
[2023-05-13 19:43:03,071] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 200
[2023-05-13 19:43:03,197] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 200
[2023-05-13 19:43:03,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 200
[2023-05-13 19:43:03,242] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:03,250] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:03,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 200
[2023-05-13 19:43:03,361] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:03,367] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:03,367] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:03,367] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:03,368] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:03,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:03,475] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:03,475] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:03,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 201
[2023-05-13 19:43:03,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 201
[2023-05-13 19:43:03,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 201
[2023-05-13 19:43:03,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 201
[2023-05-13 19:43:04,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 202
[2023-05-13 19:43:04,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 202
[2023-05-13 19:43:04,296] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:04,302] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:04,410] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:04,410] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:04,411] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:04,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 202
[2023-05-13 19:43:04,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 203
[2023-05-13 19:43:04,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 202
[2023-05-13 19:43:04,582] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:04,583] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 203
[2023-05-13 19:43:04,589] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:04,708] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:04,708] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:04,709] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:04,840] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 203
[2023-05-13 19:43:04,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 203
[2023-05-13 19:43:05,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 204
[2023-05-13 19:43:05,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 204
[2023-05-13 19:43:05,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 204
[2023-05-13 19:43:05,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:05,556] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:05,563] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 204
[2023-05-13 19:43:05,596] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:05,604] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:05,663] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:05,663] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:05,664] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:05,716] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:05,716] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:05,717] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:05,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 205
[2023-05-13 19:43:05,836] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 205
[2023-05-13 19:43:05,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 205
[2023-05-13 19:43:05,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 205
[2023-05-13 19:43:06,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 206
[2023-05-13 19:43:06,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 206
[2023-05-13 19:43:06,460] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 206
[2023-05-13 19:43:06,492] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:06,499] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:06,536] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 206
[2023-05-13 19:43:06,569] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:06,577] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:06,606] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:06,606] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:06,607] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:06,685] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:06,685] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:06,686] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:06,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 207
[2023-05-13 19:43:06,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 207
[2023-05-13 19:43:06,809] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 207
[2023-05-13 19:43:06,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 207
[2023-05-13 19:43:07,262] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 208
[2023-05-13 19:43:07,348] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 208
[2023-05-13 19:43:07,394] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 208
[2023-05-13 19:43:07,426] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:07,431] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:43:07,434] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:43:07,435] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:07,435] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:07,436] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:07,458] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 209
[2023-05-13 19:43:07,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 208
[2023-05-13 19:43:07,514] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:07,520] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:43:07,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:43:07,525] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:07,525] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:07,525] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:07,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 209
[2023-05-13 19:43:07,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 209
[2023-05-13 19:43:07,831] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:07,855] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:43:07,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:43:07,859] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:07,860] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:07,860] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:07,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 210
[2023-05-13 19:43:07,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 209
[2023-05-13 19:43:07,935] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:07,961] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 19:43:07,965] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 19:43:07,966] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:07,966] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:07,966] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:07,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 210
[2023-05-13 19:43:08,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 210
[2023-05-13 19:43:08,262] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:08,284] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:08,393] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:08,393] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:08,394] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:08,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 210
[2023-05-13 19:43:08,396] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:08,419] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:08,515] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 211
[2023-05-13 19:43:08,527] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:08,527] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:08,528] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:08,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 211
[2023-05-13 19:43:08,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 211
[2023-05-13 19:43:09,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 211
[2023-05-13 19:43:09,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 212
[2023-05-13 19:43:09,625] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 212
[2023-05-13 19:43:11,832] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 212
[2023-05-13 19:43:11,864] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:12,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 212
[2023-05-13 19:43:12,116] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:24,049] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:43:24,050] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:43:24,051] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:24,051] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:24,052] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:24,069] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 213
[2023-05-13 19:43:24,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 213
[2023-05-13 19:43:24,424] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:24,448] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:24,450] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 19:43:24,452] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 19:43:24,453] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:24,453] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:24,453] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:24,453] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:24,454] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:24,455] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:24,455] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:24,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 213
[2023-05-13 19:43:24,479] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 214
[2023-05-13 19:43:24,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 213
[2023-05-13 19:43:24,814] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:24,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:24,842] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:24,843] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:24,843] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:24,844] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:24,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 214
[2023-05-13 19:43:24,849] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:24,867] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 214
[2023-05-13 19:43:24,871] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:24,876] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:24,877] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:24,878] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:24,878] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:24,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 215
[2023-05-13 19:43:25,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 214
[2023-05-13 19:43:25,219] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:25,241] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:25,246] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:25,248] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:25,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:25,248] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:25,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 215
[2023-05-13 19:43:25,273] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 215
[2023-05-13 19:43:25,273] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:25,308] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:25,416] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:25,417] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:25,417] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:25,540] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 216
[2023-05-13 19:43:25,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 216
[2023-05-13 19:43:25,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 215
[2023-05-13 19:43:25,620] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:25,651] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 19:43:25,760] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:25,761] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:25,761] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 19:43:25,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 216
[2023-05-13 19:43:25,942] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 216
[2023-05-13 19:43:26,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 217
[2023-05-13 19:43:26,511] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 217
[2023-05-13 19:43:26,570] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 217
[2023-05-13 19:43:26,602] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:26,608] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:26,612] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:26,613] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:26,613] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:26,613] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:26,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 218
[2023-05-13 19:43:26,660] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 217
[2023-05-13 19:43:26,692] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:26,699] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 19:43:26,704] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 19:43:26,705] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 19:43:26,705] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 19:43:26,705] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 19:43:26,731] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 218
[2023-05-13 19:43:26,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 218
[2023-05-13 19:43:26,996] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:27,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 218
[2023-05-13 19:43:27,093] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 19:43:27,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 218
[2023-05-13 19:43:27,203] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 218
[2023-05-13 19:43:27,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 218
[2023-05-13 19:43:27,504] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 194
[2023-05-13 19:43:27,520] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 194
[2023-05-13 19:43:27,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 217
[2023-05-13 19:43:27,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 218
[2023-05-13 19:43:27,605] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 194
[2023-05-13 19:43:27,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 194
[2023-05-13 19:43:27,626] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 217
[2023-05-13 19:43:28,320] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 217
[2023-05-13 19:43:28,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 216
[2023-05-13 19:43:28,449] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 217
[2023-05-13 19:43:28,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 216
[2023-05-13 19:43:28,872] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 216
[2023-05-13 19:43:28,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 215
[2023-05-13 19:43:29,133] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 216
[2023-05-13 19:43:29,172] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 215
[2023-05-13 19:43:29,290] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 215
[2023-05-13 19:43:29,331] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 214
[2023-05-13 19:43:29,640] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 215
[2023-05-13 19:43:29,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 214
[2023-05-13 19:43:29,705] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 214
[2023-05-13 19:43:29,729] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 213
[2023-05-13 19:43:29,744] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 213
[2023-05-13 19:43:29,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 212
[2023-05-13 19:43:30,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 214
[2023-05-13 19:43:30,137] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 213
[2023-05-13 19:43:30,154] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 213
[2023-05-13 19:43:30,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 212
[2023-05-13 19:43:30,395] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 212
[2023-05-13 19:43:30,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 211
[2023-05-13 19:43:30,883] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 212
[2023-05-13 19:43:30,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 211
[2023-05-13 19:43:30,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 211
[2023-05-13 19:43:30,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 210
[2023-05-13 19:43:31,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 211
[2023-05-13 19:43:31,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 210
[2023-05-13 19:43:31,452] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 210
[2023-05-13 19:43:31,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 209
[2023-05-13 19:43:31,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 210
[2023-05-13 19:43:31,932] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 209
[2023-05-13 19:43:31,934] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 209
[2023-05-13 19:43:31,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 208
[2023-05-13 19:43:32,342] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 209
[2023-05-13 19:43:32,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 208
[2023-05-13 19:43:32,421] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 208
[2023-05-13 19:43:32,424] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 207
[2023-05-13 19:43:32,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 208
[2023-05-13 19:43:32,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 207
[2023-05-13 19:43:32,539] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 207
[2023-05-13 19:43:32,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 206
[2023-05-13 19:43:32,611] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 207
[2023-05-13 19:43:32,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 206
[2023-05-13 19:43:32,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 206
[2023-05-13 19:43:32,661] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 205
[2023-05-13 19:43:32,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 206
[2023-05-13 19:43:32,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 205
[2023-05-13 19:43:32,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 205
[2023-05-13 19:43:32,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 204
[2023-05-13 19:43:32,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 205
[2023-05-13 19:43:32,862] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 204
[2023-05-13 19:43:32,886] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 204
[2023-05-13 19:43:32,888] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 203
[2023-05-13 19:43:32,981] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 204
[2023-05-13 19:43:32,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 203
[2023-05-13 19:43:32,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 203
[2023-05-13 19:43:32,995] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 202
[2023-05-13 19:43:33,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 203
[2023-05-13 19:43:33,102] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 202
[2023-05-13 19:43:33,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 202
[2023-05-13 19:43:33,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 201
[2023-05-13 19:43:33,216] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 201
[2023-05-13 19:43:33,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 202
[2023-05-13 19:43:33,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 200
[2023-05-13 19:43:33,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 201
[2023-05-13 19:43:33,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 201
[2023-05-13 19:43:33,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 200
[2023-05-13 19:43:33,336] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 200
[2023-05-13 19:43:33,339] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 199
[2023-05-13 19:43:33,442] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 199
[2023-05-13 19:43:33,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 198
[2023-05-13 19:43:33,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 200
[2023-05-13 19:43:33,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 199
[2023-05-13 19:43:33,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 198
[2023-05-13 19:43:33,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 199
[2023-05-13 19:43:33,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 197
[2023-05-13 19:43:33,568] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 198
[2023-05-13 19:43:33,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 197
[2023-05-13 19:43:33,672] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 196
[2023-05-13 19:43:33,687] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 198
[2023-05-13 19:43:33,690] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 197
[2023-05-13 19:43:33,788] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 196
[2023-05-13 19:43:33,791] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 195
[2023-05-13 19:43:33,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 197
[2023-05-13 19:43:33,801] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 196
[2023-05-13 19:43:33,893] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 195
[2023-05-13 19:43:33,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 193
[2023-05-13 19:43:33,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 196
[2023-05-13 19:43:33,921] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 195
[2023-05-13 19:43:34,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 193
[2023-05-13 19:43:34,017] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 192
[2023-05-13 19:43:34,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 195
[2023-05-13 19:43:34,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 193
[2023-05-13 19:43:34,120] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 192
[2023-05-13 19:43:34,140] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 191
[2023-05-13 19:43:34,149] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 193
[2023-05-13 19:43:34,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 192
[2023-05-13 19:43:34,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 192
[2023-05-13 19:43:34,286] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 191
[2023-05-13 19:43:34,515] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 191
[2023-05-13 19:43:34,669] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 191
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:43:39.695993 22392998065984 run_lib.py:146] step: 400, training_loss: 3.86268e-01
I0513 19:43:39.857069 22392998065984 run_lib.py:167] step: 400, eval_loss: 4.54814e-01
I0513 19:44:03.377970 22392998065984 run_lib.py:146] step: 450, training_loss: 2.87660e-01
I0513 19:44:27.647289 22392998065984 run_lib.py:146] step: 500, training_loss: 1.95786e-01
I0513 19:44:27.806308 22392998065984 run_lib.py:167] step: 500, eval_loss: 2.58431e-01
I0513 19:44:51.336029 22392998065984 run_lib.py:146] step: 550, training_loss: 1.23408e-01
I0513 19:45:14.896202 22392998065984 run_lib.py:146] step: 600, training_loss: 1.03776e-01
I0513 19:45:15.057733 22392998065984 run_lib.py:167] step: 600, eval_loss: 1.07499e-01
I0513 19:45:38.900184 22392998065984 run_lib.py:146] step: 650, training_loss: 8.35566e-02
I0513 19:46:02.743322 22392998065984 run_lib.py:146] step: 700, training_loss: 9.69125e-02
I0513 19:46:02.902650 22392998065984 run_lib.py:167] step: 700, eval_loss: 9.72904e-02
I0513 19:46:26.512241 22392998065984 run_lib.py:146] step: 750, training_loss: 7.98021e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:46:50.531962 22392998065984 run_lib.py:146] step: 800, training_loss: 9.01478e-02
I0513 19:46:50.696042 22392998065984 run_lib.py:167] step: 800, eval_loss: 9.71841e-02
I0513 19:47:14.553135 22392998065984 run_lib.py:146] step: 850, training_loss: 8.27939e-02
I0513 19:47:38.327906 22392998065984 run_lib.py:146] step: 900, training_loss: 6.94666e-02
I0513 19:47:38.494165 22392998065984 run_lib.py:167] step: 900, eval_loss: 7.93674e-02
I0513 19:48:03.023023 22392998065984 run_lib.py:146] step: 950, training_loss: 6.61266e-02
I0513 19:48:27.521306 22392998065984 run_lib.py:146] step: 1000, training_loss: 9.74909e-02
I0513 19:48:27.689153 22392998065984 run_lib.py:167] step: 1000, eval_loss: 8.68243e-02
I0513 19:48:51.342112 22392998065984 run_lib.py:146] step: 1050, training_loss: 8.13573e-02
I0513 19:49:15.909259 22392998065984 run_lib.py:146] step: 1100, training_loss: 6.84328e-02
I0513 19:49:16.076272 22392998065984 run_lib.py:167] step: 1100, eval_loss: 9.23011e-02
I0513 19:49:40.542133 22392998065984 run_lib.py:146] step: 1150, training_loss: 8.94194e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:50:04.934574 22392998065984 run_lib.py:146] step: 1200, training_loss: 7.39510e-02
I0513 19:50:05.105984 22392998065984 run_lib.py:167] step: 1200, eval_loss: 5.98601e-02
I0513 19:50:29.457512 22392998065984 run_lib.py:146] step: 1250, training_loss: 6.41809e-02
I0513 19:50:53.322237 22392998065984 run_lib.py:146] step: 1300, training_loss: 1.00911e-01
I0513 19:50:53.485992 22392998065984 run_lib.py:167] step: 1300, eval_loss: 7.23187e-02
I0513 19:51:17.030547 22392998065984 run_lib.py:146] step: 1350, training_loss: 8.00063e-02
I0513 19:51:40.603205 22392998065984 run_lib.py:146] step: 1400, training_loss: 8.24002e-02
I0513 19:51:40.764945 22392998065984 run_lib.py:167] step: 1400, eval_loss: 8.77797e-02
I0513 19:52:04.854339 22392998065984 run_lib.py:146] step: 1450, training_loss: 6.99896e-02
I0513 19:52:28.466485 22392998065984 run_lib.py:146] step: 1500, training_loss: 8.95591e-02
I0513 19:52:28.625913 22392998065984 run_lib.py:167] step: 1500, eval_loss: 6.23138e-02
I0513 19:52:52.202026 22392998065984 run_lib.py:146] step: 1550, training_loss: 7.19809e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:53:16.177484 22392998065984 run_lib.py:146] step: 1600, training_loss: 8.82749e-02
I0513 19:53:16.337225 22392998065984 run_lib.py:167] step: 1600, eval_loss: 7.18431e-02
I0513 19:53:40.171092 22392998065984 run_lib.py:146] step: 1650, training_loss: 8.53124e-02
I0513 19:54:03.717995 22392998065984 run_lib.py:146] step: 1700, training_loss: 7.29841e-02
I0513 19:54:03.876381 22392998065984 run_lib.py:167] step: 1700, eval_loss: 5.58220e-02
I0513 19:54:27.769563 22392998065984 run_lib.py:146] step: 1750, training_loss: 6.74228e-02
I0513 19:54:51.549030 22392998065984 run_lib.py:146] step: 1800, training_loss: 7.29064e-02
I0513 19:54:51.710671 22392998065984 run_lib.py:167] step: 1800, eval_loss: 8.07010e-02
I0513 19:55:15.806779 22392998065984 run_lib.py:146] step: 1850, training_loss: 6.17664e-02
I0513 19:55:40.249089 22392998065984 run_lib.py:146] step: 1900, training_loss: 8.95035e-02
I0513 19:55:40.414275 22392998065984 run_lib.py:167] step: 1900, eval_loss: 5.34272e-02
I0513 19:56:04.658774 22392998065984 run_lib.py:146] step: 1950, training_loss: 6.73184e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:56:28.198371 22392998065984 run_lib.py:146] step: 2000, training_loss: 8.74660e-02
I0513 19:56:28.357048 22392998065984 run_lib.py:167] step: 2000, eval_loss: 6.04413e-02
I0513 19:56:52.048940 22392998065984 run_lib.py:146] step: 2050, training_loss: 7.04214e-02
I0513 19:57:15.919364 22392998065984 run_lib.py:146] step: 2100, training_loss: 7.03262e-02
I0513 19:57:16.081157 22392998065984 run_lib.py:167] step: 2100, eval_loss: 6.49150e-02
I0513 19:57:39.628809 22392998065984 run_lib.py:146] step: 2150, training_loss: 5.69916e-02
I0513 19:58:03.520843 22392998065984 run_lib.py:146] step: 2200, training_loss: 7.63661e-02
I0513 19:58:03.679363 22392998065984 run_lib.py:167] step: 2200, eval_loss: 6.50825e-02
I0513 19:58:27.519546 22392998065984 run_lib.py:146] step: 2250, training_loss: 6.86175e-02
I0513 19:58:51.305135 22392998065984 run_lib.py:146] step: 2300, training_loss: 8.14173e-02
I0513 19:58:51.471054 22392998065984 run_lib.py:167] step: 2300, eval_loss: 5.65998e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 19:59:16.163952 22392998065984 run_lib.py:146] step: 2350, training_loss: 8.64388e-02
I0513 19:59:40.572546 22392998065984 run_lib.py:146] step: 2400, training_loss: 6.34093e-02
I0513 19:59:40.745127 22392998065984 run_lib.py:167] step: 2400, eval_loss: 8.14409e-02
I0513 20:00:04.898521 22392998065984 run_lib.py:146] step: 2450, training_loss: 6.48629e-02
I0513 20:00:28.794023 22392998065984 run_lib.py:146] step: 2500, training_loss: 6.06574e-02
I0513 20:00:28.960982 22392998065984 run_lib.py:167] step: 2500, eval_loss: 1.10405e-01
I0513 20:00:53.491474 22392998065984 run_lib.py:146] step: 2550, training_loss: 9.25775e-02
I0513 20:01:17.960265 22392998065984 run_lib.py:146] step: 2600, training_loss: 5.96552e-02
I0513 20:01:18.127691 22392998065984 run_lib.py:167] step: 2600, eval_loss: 6.44704e-02
I0513 20:01:42.383369 22392998065984 run_lib.py:146] step: 2650, training_loss: 7.09903e-02
I0513 20:02:06.926236 22392998065984 run_lib.py:146] step: 2700, training_loss: 7.19342e-02
I0513 20:02:07.095710 22392998065984 run_lib.py:167] step: 2700, eval_loss: 7.34688e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:02:31.425615 22392998065984 run_lib.py:146] step: 2750, training_loss: 6.19349e-02
I0513 20:02:55.079327 22392998065984 run_lib.py:146] step: 2800, training_loss: 6.03067e-02
I0513 20:02:55.239799 22392998065984 run_lib.py:167] step: 2800, eval_loss: 6.34892e-02
I0513 20:03:19.156264 22392998065984 run_lib.py:146] step: 2850, training_loss: 6.58454e-02
I0513 20:03:43.058151 22392998065984 run_lib.py:146] step: 2900, training_loss: 8.90431e-02
I0513 20:03:43.216850 22392998065984 run_lib.py:167] step: 2900, eval_loss: 5.83172e-02
I0513 20:04:06.815095 22392998065984 run_lib.py:146] step: 2950, training_loss: 7.56611e-02
I0513 20:04:30.705995 22392998065984 run_lib.py:146] step: 3000, training_loss: 7.41133e-02
I0513 20:04:30.865298 22392998065984 run_lib.py:167] step: 3000, eval_loss: 8.05443e-02
I0513 20:04:55.251728 22392998065984 run_lib.py:146] step: 3050, training_loss: 7.84829e-02
I0513 20:05:18.960395 22392998065984 run_lib.py:146] step: 3100, training_loss: 6.93821e-02
I0513 20:05:19.122948 22392998065984 run_lib.py:167] step: 3100, eval_loss: 7.39784e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:05:43.237173 22392998065984 run_lib.py:146] step: 3150, training_loss: 7.11541e-02
I0513 20:06:07.146537 22392998065984 run_lib.py:146] step: 3200, training_loss: 6.61913e-02
I0513 20:06:07.309895 22392998065984 run_lib.py:167] step: 3200, eval_loss: 6.15674e-02
I0513 20:06:30.910932 22392998065984 run_lib.py:146] step: 3250, training_loss: 7.05390e-02
I0513 20:06:54.826581 22392998065984 run_lib.py:146] step: 3300, training_loss: 6.11972e-02
I0513 20:06:54.985340 22392998065984 run_lib.py:167] step: 3300, eval_loss: 7.67007e-02
I0513 20:07:18.815581 22392998065984 run_lib.py:146] step: 3350, training_loss: 6.68325e-02
I0513 20:07:42.430822 22392998065984 run_lib.py:146] step: 3400, training_loss: 5.56366e-02
I0513 20:07:42.593640 22392998065984 run_lib.py:167] step: 3400, eval_loss: 6.36541e-02
I0513 20:08:06.200742 22392998065984 run_lib.py:146] step: 3450, training_loss: 9.35431e-02
I0513 20:08:30.361845 22392998065984 run_lib.py:146] step: 3500, training_loss: 5.08831e-02
I0513 20:08:30.524123 22392998065984 run_lib.py:167] step: 3500, eval_loss: 6.48729e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:08:54.266461 22392998065984 run_lib.py:146] step: 3550, training_loss: 6.30794e-02
I0513 20:09:17.874580 22392998065984 run_lib.py:146] step: 3600, training_loss: 9.00975e-02
I0513 20:09:18.038308 22392998065984 run_lib.py:167] step: 3600, eval_loss: 7.87416e-02
I0513 20:09:42.002073 22392998065984 run_lib.py:146] step: 3650, training_loss: 6.60475e-02
I0513 20:10:05.901616 22392998065984 run_lib.py:146] step: 3700, training_loss: 6.83101e-02
I0513 20:10:06.060285 22392998065984 run_lib.py:167] step: 3700, eval_loss: 5.97708e-02
I0513 20:10:30.046229 22392998065984 run_lib.py:146] step: 3750, training_loss: 5.88007e-02
I0513 20:10:54.133670 22392998065984 run_lib.py:146] step: 3800, training_loss: 6.15775e-02
I0513 20:10:54.295562 22392998065984 run_lib.py:167] step: 3800, eval_loss: 4.83765e-02
I0513 20:11:18.173447 22392998065984 run_lib.py:146] step: 3850, training_loss: 6.58178e-02
I0513 20:11:41.778837 22392998065984 run_lib.py:146] step: 3900, training_loss: 6.32709e-02
I0513 20:11:41.941525 22392998065984 run_lib.py:167] step: 3900, eval_loss: 6.69734e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:12:05.986652 22392998065984 run_lib.py:146] step: 3950, training_loss: 7.15930e-02
I0513 20:12:29.897190 22392998065984 run_lib.py:146] step: 4000, training_loss: 6.78684e-02
I0513 20:12:30.056798 22392998065984 run_lib.py:167] step: 4000, eval_loss: 6.09592e-02
I0513 20:12:53.691254 22392998065984 run_lib.py:146] step: 4050, training_loss: 5.21762e-02
I0513 20:13:17.625851 22392998065984 run_lib.py:146] step: 4100, training_loss: 7.19021e-02
I0513 20:13:17.784065 22392998065984 run_lib.py:167] step: 4100, eval_loss: 5.55909e-02
I0513 20:13:41.662539 22392998065984 run_lib.py:146] step: 4150, training_loss: 5.93112e-02
I0513 20:14:05.281397 22392998065984 run_lib.py:146] step: 4200, training_loss: 5.77635e-02
I0513 20:14:05.444165 22392998065984 run_lib.py:167] step: 4200, eval_loss: 7.89288e-02
I0513 20:14:29.391636 22392998065984 run_lib.py:146] step: 4250, training_loss: 6.88849e-02
I0513 20:14:53.156492 22392998065984 run_lib.py:146] step: 4300, training_loss: 8.51686e-02
I0513 20:14:53.315208 22392998065984 run_lib.py:167] step: 4300, eval_loss: 9.13922e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:15:17.206300 22392998065984 run_lib.py:146] step: 4350, training_loss: 6.76411e-02
I0513 20:15:41.189419 22392998065984 run_lib.py:146] step: 4400, training_loss: 7.03100e-02
I0513 20:15:41.358215 22392998065984 run_lib.py:167] step: 4400, eval_loss: 5.76723e-02
I0513 20:16:06.192317 22392998065984 run_lib.py:146] step: 4450, training_loss: 5.32476e-02
I0513 20:16:30.397680 22392998065984 run_lib.py:146] step: 4500, training_loss: 6.39220e-02
I0513 20:16:30.569005 22392998065984 run_lib.py:167] step: 4500, eval_loss: 6.62686e-02
I0513 20:16:54.262717 22392998065984 run_lib.py:146] step: 4550, training_loss: 5.96284e-02
I0513 20:17:18.386195 22392998065984 run_lib.py:146] step: 4600, training_loss: 8.03289e-02
I0513 20:17:18.548419 22392998065984 run_lib.py:167] step: 4600, eval_loss: 5.37739e-02
I0513 20:17:42.102018 22392998065984 run_lib.py:146] step: 4650, training_loss: 6.54106e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:18:05.775951 22392998065984 run_lib.py:146] step: 4700, training_loss: 6.92587e-02
I0513 20:18:05.936836 22392998065984 run_lib.py:167] step: 4700, eval_loss: 8.36719e-02
I0513 20:18:29.867113 22392998065984 run_lib.py:146] step: 4750, training_loss: 5.95466e-02
I0513 20:18:53.731736 22392998065984 run_lib.py:146] step: 4800, training_loss: 6.46072e-02
I0513 20:18:53.894225 22392998065984 run_lib.py:167] step: 4800, eval_loss: 7.74847e-02
I0513 20:19:17.482989 22392998065984 run_lib.py:146] step: 4850, training_loss: 6.84948e-02
I0513 20:19:41.340909 22392998065984 run_lib.py:146] step: 4900, training_loss: 6.79673e-02
I0513 20:19:41.500133 22392998065984 run_lib.py:167] step: 4900, eval_loss: 6.02076e-02
I0513 20:20:05.320802 22392998065984 run_lib.py:146] step: 4950, training_loss: 5.38809e-02
I0513 20:20:28.984452 22392998065984 run_lib.py:146] step: 5000, training_loss: 5.76810e-02
I0513 20:20:29.151522 22392998065984 run_lib.py:167] step: 5000, eval_loss: 7.47039e-02
I0513 20:20:53.660949 22392998065984 run_lib.py:146] step: 5050, training_loss: 5.71748e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:21:17.908261 22392998065984 run_lib.py:146] step: 5100, training_loss: 6.27525e-02
I0513 20:21:18.072230 22392998065984 run_lib.py:167] step: 5100, eval_loss: 5.40630e-02
I0513 20:21:41.603785 22392998065984 run_lib.py:146] step: 5150, training_loss: 7.88846e-02
I0513 20:22:05.499761 22392998065984 run_lib.py:146] step: 5200, training_loss: 7.64266e-02
I0513 20:22:05.657429 22392998065984 run_lib.py:167] step: 5200, eval_loss: 6.26224e-02
I0513 20:22:29.463342 22392998065984 run_lib.py:146] step: 5250, training_loss: 7.36898e-02
I0513 20:22:53.016431 22392998065984 run_lib.py:146] step: 5300, training_loss: 7.44459e-02
I0513 20:22:53.174512 22392998065984 run_lib.py:167] step: 5300, eval_loss: 6.24481e-02
I0513 20:23:17.433775 22392998065984 run_lib.py:146] step: 5350, training_loss: 6.26928e-02
I0513 20:23:41.906331 22392998065984 run_lib.py:146] step: 5400, training_loss: 5.74475e-02
I0513 20:23:42.072461 22392998065984 run_lib.py:167] step: 5400, eval_loss: 6.83131e-02
I0513 20:24:05.648582 22392998065984 run_lib.py:146] step: 5450, training_loss: 7.75235e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:24:29.704694 22392998065984 run_lib.py:146] step: 5500, training_loss: 7.99801e-02
I0513 20:24:29.873739 22392998065984 run_lib.py:167] step: 5500, eval_loss: 5.36158e-02
I0513 20:24:54.520164 22392998065984 run_lib.py:146] step: 5550, training_loss: 5.86470e-02
I0513 20:25:18.104440 22392998065984 run_lib.py:146] step: 5600, training_loss: 6.46420e-02
I0513 20:25:18.266117 22392998065984 run_lib.py:167] step: 5600, eval_loss: 7.48232e-02
I0513 20:25:42.124999 22392998065984 run_lib.py:146] step: 5650, training_loss: 6.89964e-02
I0513 20:26:06.629902 22392998065984 run_lib.py:146] step: 5700, training_loss: 6.65560e-02
I0513 20:26:06.799868 22392998065984 run_lib.py:167] step: 5700, eval_loss: 6.36625e-02
I0513 20:26:31.260788 22392998065984 run_lib.py:146] step: 5750, training_loss: 5.99496e-02
I0513 20:26:55.501871 22392998065984 run_lib.py:146] step: 5800, training_loss: 7.34701e-02
I0513 20:26:55.668192 22392998065984 run_lib.py:167] step: 5800, eval_loss: 5.76563e-02
I0513 20:27:20.206611 22392998065984 run_lib.py:146] step: 5850, training_loss: 5.52914e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:27:44.673071 22392998065984 run_lib.py:146] step: 5900, training_loss: 6.24694e-02
I0513 20:27:44.837030 22392998065984 run_lib.py:167] step: 5900, eval_loss: 7.16613e-02
I0513 20:28:08.395114 22392998065984 run_lib.py:146] step: 5950, training_loss: 5.78118e-02
I0513 20:28:32.320668 22392998065984 run_lib.py:146] step: 6000, training_loss: 9.26909e-02
I0513 20:28:32.478449 22392998065984 run_lib.py:167] step: 6000, eval_loss: 6.35485e-02
I0513 20:28:56.351911 22392998065984 run_lib.py:146] step: 6050, training_loss: 6.35991e-02
I0513 20:29:19.892235 22392998065984 run_lib.py:146] step: 6100, training_loss: 5.76374e-02
I0513 20:29:20.050963 22392998065984 run_lib.py:167] step: 6100, eval_loss: 6.05572e-02
I0513 20:29:43.925687 22392998065984 run_lib.py:146] step: 6150, training_loss: 6.16997e-02
I0513 20:30:07.708871 22392998065984 run_lib.py:146] step: 6200, training_loss: 7.38114e-02
I0513 20:30:07.869852 22392998065984 run_lib.py:167] step: 6200, eval_loss: 7.22488e-02
I0513 20:30:31.840473 22392998065984 run_lib.py:146] step: 6250, training_loss: 5.28728e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:30:56.123466 22392998065984 run_lib.py:146] step: 6300, training_loss: 5.90517e-02
I0513 20:30:56.282595 22392998065984 run_lib.py:167] step: 6300, eval_loss: 6.64746e-02
I0513 20:31:20.233227 22392998065984 run_lib.py:146] step: 6350, training_loss: 8.42007e-02
I0513 20:31:43.829301 22392998065984 run_lib.py:146] step: 6400, training_loss: 6.83804e-02
I0513 20:31:43.988936 22392998065984 run_lib.py:167] step: 6400, eval_loss: 7.13323e-02
I0513 20:32:07.549470 22392998065984 run_lib.py:146] step: 6450, training_loss: 6.49508e-02
I0513 20:32:31.728992 22392998065984 run_lib.py:146] step: 6500, training_loss: 6.76430e-02
I0513 20:32:31.887935 22392998065984 run_lib.py:167] step: 6500, eval_loss: 5.57857e-02
I0513 20:32:55.469668 22392998065984 run_lib.py:146] step: 6550, training_loss: 8.25085e-02
I0513 20:33:19.093847 22392998065984 run_lib.py:146] step: 6600, training_loss: 5.28177e-02
I0513 20:33:19.254507 22392998065984 run_lib.py:167] step: 6600, eval_loss: 4.75557e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:33:43.279269 22392998065984 run_lib.py:146] step: 6650, training_loss: 5.88866e-02
I0513 20:34:07.167509 22392998065984 run_lib.py:146] step: 6700, training_loss: 6.23855e-02
I0513 20:34:07.329942 22392998065984 run_lib.py:167] step: 6700, eval_loss: 4.81476e-02
I0513 20:34:30.891912 22392998065984 run_lib.py:146] step: 6750, training_loss: 7.29516e-02
I0513 20:34:54.862484 22392998065984 run_lib.py:146] step: 6800, training_loss: 7.54488e-02
I0513 20:34:55.022140 22392998065984 run_lib.py:167] step: 6800, eval_loss: 8.09478e-02
I0513 20:35:18.886935 22392998065984 run_lib.py:146] step: 6850, training_loss: 8.01819e-02
I0513 20:35:42.476052 22392998065984 run_lib.py:146] step: 6900, training_loss: 5.41974e-02
I0513 20:35:42.636637 22392998065984 run_lib.py:167] step: 6900, eval_loss: 7.52415e-02
I0513 20:36:06.523944 22392998065984 run_lib.py:146] step: 6950, training_loss: 5.98127e-02
I0513 20:36:30.378546 22392998065984 run_lib.py:146] step: 7000, training_loss: 7.36270e-02
I0513 20:36:30.537782 22392998065984 run_lib.py:167] step: 7000, eval_loss: 8.68837e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:36:54.252863 22392998065984 run_lib.py:146] step: 7050, training_loss: 6.64046e-02
I0513 20:37:18.175702 22392998065984 run_lib.py:146] step: 7100, training_loss: 8.09131e-02
I0513 20:37:18.339186 22392998065984 run_lib.py:167] step: 7100, eval_loss: 5.36991e-02
I0513 20:37:42.264306 22392998065984 run_lib.py:146] step: 7150, training_loss: 7.02783e-02
I0513 20:38:05.921159 22392998065984 run_lib.py:146] step: 7200, training_loss: 6.80917e-02
I0513 20:38:06.080593 22392998065984 run_lib.py:167] step: 7200, eval_loss: 7.17700e-02
I0513 20:38:29.558762 22392998065984 run_lib.py:146] step: 7250, training_loss: 7.35148e-02
I0513 20:38:53.686901 22392998065984 run_lib.py:146] step: 7300, training_loss: 7.96182e-02
I0513 20:38:53.844979 22392998065984 run_lib.py:167] step: 7300, eval_loss: 6.87493e-02
I0513 20:39:17.297178 22392998065984 run_lib.py:146] step: 7350, training_loss: 5.93113e-02
I0513 20:39:40.766706 22392998065984 run_lib.py:146] step: 7400, training_loss: 6.64354e-02
I0513 20:39:40.924855 22392998065984 run_lib.py:167] step: 7400, eval_loss: 9.46438e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:40:05.115657 22392998065984 run_lib.py:146] step: 7450, training_loss: 7.59600e-02
I0513 20:40:28.597648 22392998065984 run_lib.py:146] step: 7500, training_loss: 6.17495e-02
I0513 20:40:28.757360 22392998065984 run_lib.py:167] step: 7500, eval_loss: 7.70834e-02
I0513 20:40:52.292486 22392998065984 run_lib.py:146] step: 7550, training_loss: 6.07789e-02
I0513 20:41:16.192520 22392998065984 run_lib.py:146] step: 7600, training_loss: 7.17242e-02
I0513 20:41:16.351658 22392998065984 run_lib.py:167] step: 7600, eval_loss: 6.25153e-02
I0513 20:41:40.810896 22392998065984 run_lib.py:146] step: 7650, training_loss: 7.02539e-02
I0513 20:42:05.061734 22392998065984 run_lib.py:146] step: 7700, training_loss: 6.37366e-02
I0513 20:42:05.233536 22392998065984 run_lib.py:167] step: 7700, eval_loss: 7.30077e-02
I0513 20:42:29.881843 22392998065984 run_lib.py:146] step: 7750, training_loss: 8.34366e-02
I0513 20:42:54.345458 22392998065984 run_lib.py:146] step: 7800, training_loss: 5.67540e-02
[2023-05-13 20:42:54,353] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 20:42:54,368] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 20:42:54,370] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:54,370] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:54,370] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:42:54,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-13 20:42:54,403] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-13 20:42:54,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 219
[2023-05-13 20:42:54,405] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:54,405] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:54,405] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:42:54,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 219
[2023-05-13 20:42:55,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 219
[2023-05-13 20:42:55,046] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:42:55,060] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 219
[2023-05-13 20:42:55,060] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:42:55,120] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:42:55,122] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:42:55,124] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:42:55,125] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:55,125] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:55,125] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:42:55,126] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:42:55,127] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:55,127] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:55,128] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:42:55,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 220
[2023-05-13 20:42:55,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 220
[2023-05-13 20:42:55,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 220
[2023-05-13 20:42:55,514] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:42:55,548] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:42:55,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 220
[2023-05-13 20:42:55,566] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:42:55,600] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:42:55,657] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:55,657] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:55,658] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:42:55,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 221
[2023-05-13 20:42:55,717] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:42:55,717] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:42:55,718] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:42:55,764] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 221
[2023-05-13 20:42:56,157] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 221
[2023-05-13 20:42:56,225] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 221
[2023-05-13 20:42:56,393] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 222
[2023-05-13 20:42:56,465] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 222
[2023-05-13 20:42:58,901] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 222
[2023-05-13 20:42:58,931] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:42:59,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 222
[2023-05-13 20:42:59,148] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:12,476] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 20:43:12,478] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 20:43:12,479] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:12,479] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:12,479] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:12,491] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 223
[2023-05-13 20:43:12,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 223
[2023-05-13 20:43:12,852] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:12,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:12,969] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:12,969] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:12,969] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:13,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 224
[2023-05-13 20:43:13,064] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 224
[2023-05-13 20:43:13,295] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 225
[2023-05-13 20:43:13,414] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 225
[2023-05-13 20:43:13,444] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:13,451] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:13,559] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:13,560] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:13,560] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:13,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 226
[2023-05-13 20:43:13,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 226
[2023-05-13 20:43:13,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 227
[2023-05-13 20:43:13,999] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 227
[2023-05-13 20:43:14,030] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:14,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:14,145] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:14,145] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:14,146] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:14,188] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 228
[2023-05-13 20:43:14,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 228
[2023-05-13 20:43:14,314] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 20:43:14,316] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 20:43:14,317] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:14,317] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:14,317] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:14,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 223
[2023-05-13 20:43:14,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 229
[2023-05-13 20:43:14,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 229
[2023-05-13 20:43:14,623] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:14,630] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:14,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 223
[2023-05-13 20:43:14,668] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:14,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:14,750] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:14,750] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:14,751] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:14,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:14,784] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:14,784] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:14,796] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 230
[2023-05-13 20:43:14,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 224
[2023-05-13 20:43:14,848] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 230
[2023-05-13 20:43:14,876] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 224
[2023-05-13 20:43:15,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 231
[2023-05-13 20:43:15,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 225
[2023-05-13 20:43:15,212] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 231
[2023-05-13 20:43:15,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 225
[2023-05-13 20:43:15,243] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:15,249] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:15,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:15,254] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:15,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:15,362] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:15,363] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:15,369] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:15,369] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:15,370] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:15,405] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 226
[2023-05-13 20:43:15,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 232
[2023-05-13 20:43:15,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 226
[2023-05-13 20:43:15,468] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 232
[2023-05-13 20:43:15,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 227
[2023-05-13 20:43:15,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 233
[2023-05-13 20:43:15,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 227
[2023-05-13 20:43:15,828] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:15,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 233
[2023-05-13 20:43:15,834] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:15,863] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:15,869] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:15,942] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:15,943] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:15,943] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:15,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 228
[2023-05-13 20:43:15,990] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:15,990] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:15,990] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:16,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 228
[2023-05-13 20:43:16,036] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 234
[2023-05-13 20:43:16,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 234
[2023-05-13 20:43:16,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 229
[2023-05-13 20:43:16,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 235
[2023-05-13 20:43:16,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 229
[2023-05-13 20:43:16,404] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:16,410] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:16,448] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 235
[2023-05-13 20:43:16,480] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:16,486] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:16,516] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:16,517] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:16,517] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:16,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 230
[2023-05-13 20:43:16,606] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:16,606] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:16,607] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:16,607] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 230
[2023-05-13 20:43:16,650] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 236
[2023-05-13 20:43:16,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 236
[2023-05-13 20:43:16,831] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 231
[2023-05-13 20:43:16,943] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 237
[2023-05-13 20:43:16,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 231
[2023-05-13 20:43:16,974] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:16,980] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:17,086] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:17,087] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:17,087] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:17,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 232
[2023-05-13 20:43:17,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 232
[2023-05-13 20:43:17,400] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 233
[2023-05-13 20:43:17,419] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 237
[2023-05-13 20:43:17,450] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:17,455] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:43:17,458] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:43:17,459] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:17,459] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:17,459] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:17,470] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 238
[2023-05-13 20:43:17,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 233
[2023-05-13 20:43:17,543] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:17,550] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:17,660] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:17,661] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:17,661] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:17,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 234
[2023-05-13 20:43:17,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 234
[2023-05-13 20:43:17,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 238
[2023-05-13 20:43:17,856] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:17,878] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:43:17,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:43:17,883] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:17,883] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:17,883] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:17,894] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 239
[2023-05-13 20:43:17,981] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 235
[2023-05-13 20:43:18,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 235
[2023-05-13 20:43:18,125] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:18,131] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:18,236] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:18,237] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:18,237] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:18,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 236
[2023-05-13 20:43:18,326] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 236
[2023-05-13 20:43:18,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 239
[2023-05-13 20:43:18,360] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:18,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:18,504] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:18,504] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:18,505] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:18,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 240
[2023-05-13 20:43:18,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 237
[2023-05-13 20:43:18,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 237
[2023-05-13 20:43:18,692] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:18,697] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:43:18,700] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:43:18,701] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:18,701] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:18,701] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:18,711] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 238
[2023-05-13 20:43:19,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 238
[2023-05-13 20:43:19,089] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:19,094] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 240
[2023-05-13 20:43:19,108] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-13 20:43:19,112] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-13 20:43:19,113] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:19,113] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:19,113] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:19,124] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 239
[2023-05-13 20:43:19,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 241
[2023-05-13 20:43:19,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 239
[2023-05-13 20:43:19,493] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:19,512] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:19,621] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:19,621] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:19,621] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:19,665] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 240
[2023-05-13 20:43:20,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 240
[2023-05-13 20:43:20,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 241
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 20:43:22,329] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 241
[2023-05-13 20:43:22,361] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 20:43:23,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 241
[2023-05-13 20:43:23,179] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:34,043] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 20:43:34,045] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 20:43:34,047] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:34,047] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:34,047] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:34,061] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 242
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 20:43:34,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 242
[2023-05-13 20:43:34,613] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:34,653] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:34,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:34,660] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:34,660] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:34,660] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:34,674] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 243
[2023-05-13 20:43:35,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 243
[2023-05-13 20:43:35,057] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:35,083] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:35,088] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:35,090] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:35,090] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:35,090] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:35,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 244
[2023-05-13 20:43:35,569] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 244
[2023-05-13 20:43:35,569] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:35,623] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:35,739] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:35,739] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:35,740] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:35,785] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 245
[2023-05-13 20:43:35,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 245
[2023-05-13 20:43:36,085] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 246
[2023-05-13 20:43:36,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 246
[2023-05-13 20:43:36,248] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:36,254] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:36,259] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:36,261] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:36,261] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:36,261] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:36,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 247
[2023-05-13 20:43:36,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 247
[2023-05-13 20:43:36,738] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0513 20:43:36.792202 22392998065984 run_lib.py:167] step: 7800, eval_loss: 6.08601e-02
[2023-05-13 20:43:37,154] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-13 20:43:37,156] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-13 20:43:37,157] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:37,157] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:37,157] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:37,168] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 242
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-13 20:43:37,817] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 242
[2023-05-13 20:43:37,817] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:37,837] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:37,842] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:37,843] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:37,843] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:37,844] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:37,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 243
[2023-05-13 20:43:38,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 243
[2023-05-13 20:43:38,229] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:38,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:38,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:38,254] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:38,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:38,254] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:38,267] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 244
[2023-05-13 20:43:38,637] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 244
[2023-05-13 20:43:38,637] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:38,667] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-13 20:43:39,120] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:39,120] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:39,121] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-13 20:43:39,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 245
[2023-05-13 20:43:39,217] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 245
[2023-05-13 20:43:39,444] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 246
[2023-05-13 20:43:39,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 246
[2023-05-13 20:43:39,597] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-13 20:43:39,602] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-13 20:43:39,606] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-13 20:43:39,607] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-13 20:43:39,607] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-13 20:43:39,607] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-13 20:43:39,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 247
[2023-05-13 20:43:39,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 247
[2023-05-13 20:43:39,986] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:44:03.595842 22392998065984 run_lib.py:146] step: 7850, training_loss: 8.35114e-02
I0513 20:44:27.758892 22392998065984 run_lib.py:146] step: 7900, training_loss: 7.37742e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:44:28.111762 22392998065984 run_lib.py:167] step: 7900, eval_loss: 8.31817e-02
I0513 20:44:52.302481 22392998065984 run_lib.py:146] step: 7950, training_loss: 5.51035e-02
I0513 20:45:15.907413 22392998065984 run_lib.py:146] step: 8000, training_loss: 6.44228e-02
I0513 20:45:16.066394 22392998065984 run_lib.py:167] step: 8000, eval_loss: 5.73798e-02
I0513 20:45:39.594431 22392998065984 run_lib.py:146] step: 8050, training_loss: 5.72694e-02
I0513 20:46:03.440254 22392998065984 run_lib.py:146] step: 8100, training_loss: 8.53278e-02
I0513 20:46:03.598328 22392998065984 run_lib.py:167] step: 8100, eval_loss: 6.38133e-02
I0513 20:46:27.370889 22392998065984 run_lib.py:146] step: 8150, training_loss: 8.82993e-02
I0513 20:46:50.890148 22392998065984 run_lib.py:146] step: 8200, training_loss: 8.07356e-02
I0513 20:46:51.052185 22392998065984 run_lib.py:167] step: 8200, eval_loss: 6.99412e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:47:15.113918 22392998065984 run_lib.py:146] step: 8250, training_loss: 6.17543e-02
I0513 20:47:38.935875 22392998065984 run_lib.py:146] step: 8300, training_loss: 5.02851e-02
I0513 20:47:39.096397 22392998065984 run_lib.py:167] step: 8300, eval_loss: 9.14844e-02
I0513 20:48:02.603107 22392998065984 run_lib.py:146] step: 8350, training_loss: 5.33195e-02
I0513 20:48:26.462209 22392998065984 run_lib.py:146] step: 8400, training_loss: 6.20979e-02
I0513 20:48:26.622594 22392998065984 run_lib.py:167] step: 8400, eval_loss: 7.72734e-02
I0513 20:48:50.388512 22392998065984 run_lib.py:146] step: 8450, training_loss: 5.90350e-02
I0513 20:49:13.909116 22392998065984 run_lib.py:146] step: 8500, training_loss: 5.46596e-02
I0513 20:49:14.066713 22392998065984 run_lib.py:167] step: 8500, eval_loss: 6.69423e-02
I0513 20:49:37.569793 22392998065984 run_lib.py:146] step: 8550, training_loss: 6.07459e-02
I0513 20:50:01.692899 22392998065984 run_lib.py:146] step: 8600, training_loss: 5.45471e-02
I0513 20:50:01.851166 22392998065984 run_lib.py:167] step: 8600, eval_loss: 5.98582e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:50:25.498388 22392998065984 run_lib.py:146] step: 8650, training_loss: 6.06452e-02
I0513 20:50:49.039233 22392998065984 run_lib.py:146] step: 8700, training_loss: 6.42675e-02
I0513 20:50:49.202728 22392998065984 run_lib.py:167] step: 8700, eval_loss: 5.74109e-02
I0513 20:51:13.343535 22392998065984 run_lib.py:146] step: 8750, training_loss: 6.59818e-02
I0513 20:51:36.866790 22392998065984 run_lib.py:146] step: 8800, training_loss: 8.12787e-02
I0513 20:51:37.028429 22392998065984 run_lib.py:167] step: 8800, eval_loss: 4.74409e-02
I0513 20:52:00.605346 22392998065984 run_lib.py:146] step: 8850, training_loss: 5.95256e-02
I0513 20:52:24.478012 22392998065984 run_lib.py:146] step: 8900, training_loss: 7.10127e-02
I0513 20:52:24.637480 22392998065984 run_lib.py:167] step: 8900, eval_loss: 5.57094e-02
I0513 20:52:48.474823 22392998065984 run_lib.py:146] step: 8950, training_loss: 7.18736e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:53:12.292676 22392998065984 run_lib.py:146] step: 9000, training_loss: 8.06899e-02
I0513 20:53:12.461666 22392998065984 run_lib.py:167] step: 9000, eval_loss: 7.80374e-02
I0513 20:53:37.047918 22392998065984 run_lib.py:146] step: 9050, training_loss: 5.35578e-02
I0513 20:54:01.561993 22392998065984 run_lib.py:146] step: 9100, training_loss: 7.10156e-02
I0513 20:54:01.732442 22392998065984 run_lib.py:167] step: 9100, eval_loss: 5.01240e-02
I0513 20:54:25.926098 22392998065984 run_lib.py:146] step: 9150, training_loss: 6.44325e-02
I0513 20:54:50.476206 22392998065984 run_lib.py:146] step: 9200, training_loss: 8.37742e-02
I0513 20:54:50.645263 22392998065984 run_lib.py:167] step: 9200, eval_loss: 4.32153e-02
I0513 20:55:15.048534 22392998065984 run_lib.py:146] step: 9250, training_loss: 6.95498e-02
I0513 20:55:39.223426 22392998065984 run_lib.py:146] step: 9300, training_loss: 7.66536e-02
I0513 20:55:39.394171 22392998065984 run_lib.py:167] step: 9300, eval_loss: 8.16946e-02
I0513 20:56:03.591770 22392998065984 run_lib.py:146] step: 9350, training_loss: 6.44867e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:56:28.126944 22392998065984 run_lib.py:146] step: 9400, training_loss: 6.24880e-02
I0513 20:56:28.300166 22392998065984 run_lib.py:167] step: 9400, eval_loss: 6.22214e-02
I0513 20:56:52.488716 22392998065984 run_lib.py:146] step: 9450, training_loss: 6.46124e-02
I0513 20:57:16.704137 22392998065984 run_lib.py:146] step: 9500, training_loss: 7.37987e-02
I0513 20:57:16.875153 22392998065984 run_lib.py:167] step: 9500, eval_loss: 6.30148e-02
I0513 20:57:41.627386 22392998065984 run_lib.py:146] step: 9550, training_loss: 6.79544e-02
I0513 20:58:05.183180 22392998065984 run_lib.py:146] step: 9600, training_loss: 5.47703e-02
I0513 20:58:05.344681 22392998065984 run_lib.py:167] step: 9600, eval_loss: 8.38297e-02
I0513 20:58:28.880195 22392998065984 run_lib.py:146] step: 9650, training_loss: 8.00649e-02
I0513 20:58:52.759608 22392998065984 run_lib.py:146] step: 9700, training_loss: 7.10866e-02
I0513 20:58:52.922087 22392998065984 run_lib.py:167] step: 9700, eval_loss: 6.40020e-02
I0513 20:59:16.700755 22392998065984 run_lib.py:146] step: 9750, training_loss: 6.19785e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 20:59:40.710680 22392998065984 run_lib.py:146] step: 9800, training_loss: 7.52482e-02
I0513 20:59:40.880278 22392998065984 run_lib.py:167] step: 9800, eval_loss: 6.85526e-02
I0513 21:00:05.419318 22392998065984 run_lib.py:146] step: 9850, training_loss: 5.85104e-02
I0513 21:00:29.405221 22392998065984 run_lib.py:146] step: 9900, training_loss: 7.45874e-02
I0513 21:00:29.567337 22392998065984 run_lib.py:167] step: 9900, eval_loss: 6.38345e-02
I0513 21:00:53.090124 22392998065984 run_lib.py:146] step: 9950, training_loss: 6.24290e-02
I0513 21:01:17.136893 22392998065984 run_lib.py:146] step: 10000, training_loss: 4.41446e-02
I0513 21:01:40.634284 22392998065984 run_lib.py:167] step: 10000, eval_loss: 4.82808e-02
I0513 21:02:28.866659 22392998065984 run_lib.py:146] step: 10050, training_loss: 7.09895e-02
I0513 21:02:52.377901 22392998065984 run_lib.py:146] step: 10100, training_loss: 5.05062e-02
I0513 21:02:52.535551 22392998065984 run_lib.py:167] step: 10100, eval_loss: 6.08170e-02
I0513 21:03:16.896403 22392998065984 run_lib.py:146] step: 10150, training_loss: 7.06038e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:03:41.076260 22392998065984 run_lib.py:146] step: 10200, training_loss: 6.30850e-02
I0513 21:03:41.236584 22392998065984 run_lib.py:167] step: 10200, eval_loss: 6.02260e-02
I0513 21:04:04.763998 22392998065984 run_lib.py:146] step: 10250, training_loss: 5.98930e-02
I0513 21:04:28.622320 22392998065984 run_lib.py:146] step: 10300, training_loss: 6.08834e-02
I0513 21:04:28.784741 22392998065984 run_lib.py:167] step: 10300, eval_loss: 6.73638e-02
I0513 21:04:52.582952 22392998065984 run_lib.py:146] step: 10350, training_loss: 6.19803e-02
I0513 21:05:16.139109 22392998065984 run_lib.py:146] step: 10400, training_loss: 7.51814e-02
I0513 21:05:16.301377 22392998065984 run_lib.py:167] step: 10400, eval_loss: 5.63996e-02
I0513 21:05:40.167112 22392998065984 run_lib.py:146] step: 10450, training_loss: 8.12932e-02
I0513 21:06:03.715825 22392998065984 run_lib.py:146] step: 10500, training_loss: 4.60735e-02
I0513 21:06:03.873976 22392998065984 run_lib.py:167] step: 10500, eval_loss: 5.19199e-02
I0513 21:06:27.693733 22392998065984 run_lib.py:146] step: 10550, training_loss: 6.42863e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:06:51.743604 22392998065984 run_lib.py:146] step: 10600, training_loss: 5.86610e-02
I0513 21:06:51.905353 22392998065984 run_lib.py:167] step: 10600, eval_loss: 5.60566e-02
I0513 21:07:15.453077 22392998065984 run_lib.py:146] step: 10650, training_loss: 7.26965e-02
I0513 21:07:39.301820 22392998065984 run_lib.py:146] step: 10700, training_loss: 8.26647e-02
I0513 21:07:39.464276 22392998065984 run_lib.py:167] step: 10700, eval_loss: 5.13803e-02
I0513 21:08:03.343003 22392998065984 run_lib.py:146] step: 10750, training_loss: 6.50284e-02
I0513 21:08:26.892935 22392998065984 run_lib.py:146] step: 10800, training_loss: 5.55178e-02
I0513 21:08:27.052451 22392998065984 run_lib.py:167] step: 10800, eval_loss: 5.23062e-02
I0513 21:08:50.885869 22392998065984 run_lib.py:146] step: 10850, training_loss: 5.92975e-02
I0513 21:09:14.492941 22392998065984 run_lib.py:146] step: 10900, training_loss: 5.19442e-02
I0513 21:09:14.655207 22392998065984 run_lib.py:167] step: 10900, eval_loss: 5.58832e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:09:38.632817 22392998065984 run_lib.py:146] step: 10950, training_loss: 5.51396e-02
I0513 21:10:02.544847 22392998065984 run_lib.py:146] step: 11000, training_loss: 5.65517e-02
I0513 21:10:02.704734 22392998065984 run_lib.py:167] step: 11000, eval_loss: 3.84797e-02
I0513 21:10:26.196346 22392998065984 run_lib.py:146] step: 11050, training_loss: 7.96733e-02
I0513 21:10:50.737247 22392998065984 run_lib.py:146] step: 11100, training_loss: 5.34778e-02
I0513 21:10:50.904730 22392998065984 run_lib.py:167] step: 11100, eval_loss: 5.35321e-02
I0513 21:11:15.302454 22392998065984 run_lib.py:146] step: 11150, training_loss: 6.22272e-02
I0513 21:11:39.278253 22392998065984 run_lib.py:146] step: 11200, training_loss: 6.44438e-02
I0513 21:11:39.437005 22392998065984 run_lib.py:167] step: 11200, eval_loss: 7.16807e-02
I0513 21:12:03.295552 22392998065984 run_lib.py:146] step: 11250, training_loss: 7.21577e-02
I0513 21:12:26.861133 22392998065984 run_lib.py:146] step: 11300, training_loss: 6.50736e-02
I0513 21:12:27.020053 22392998065984 run_lib.py:167] step: 11300, eval_loss: 5.87662e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:12:50.865237 22392998065984 run_lib.py:146] step: 11350, training_loss: 6.84060e-02
I0513 21:13:15.147671 22392998065984 run_lib.py:146] step: 11400, training_loss: 6.98475e-02
I0513 21:13:15.314468 22392998065984 run_lib.py:167] step: 11400, eval_loss: 5.13252e-02
I0513 21:13:39.302736 22392998065984 run_lib.py:146] step: 11450, training_loss: 7.17218e-02
I0513 21:14:03.573943 22392998065984 run_lib.py:146] step: 11500, training_loss: 8.04662e-02
I0513 21:14:03.739716 22392998065984 run_lib.py:167] step: 11500, eval_loss: 7.83426e-02
I0513 21:14:27.500970 22392998065984 run_lib.py:146] step: 11550, training_loss: 6.23431e-02
I0513 21:14:51.058958 22392998065984 run_lib.py:146] step: 11600, training_loss: 5.34894e-02
I0513 21:14:51.220778 22392998065984 run_lib.py:167] step: 11600, eval_loss: 6.45440e-02
I0513 21:15:15.688910 22392998065984 run_lib.py:146] step: 11650, training_loss: 7.91426e-02
I0513 21:15:40.258454 22392998065984 run_lib.py:146] step: 11700, training_loss: 4.60042e-02
I0513 21:15:40.429065 22392998065984 run_lib.py:167] step: 11700, eval_loss: 7.44875e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:16:04.786169 22392998065984 run_lib.py:146] step: 11750, training_loss: 5.14976e-02
I0513 21:16:29.118379 22392998065984 run_lib.py:146] step: 11800, training_loss: 7.40139e-02
I0513 21:16:29.282113 22392998065984 run_lib.py:167] step: 11800, eval_loss: 6.12652e-02
I0513 21:16:52.833400 22392998065984 run_lib.py:146] step: 11850, training_loss: 5.54880e-02
I0513 21:17:16.729020 22392998065984 run_lib.py:146] step: 11900, training_loss: 6.49663e-02
I0513 21:17:16.889354 22392998065984 run_lib.py:167] step: 11900, eval_loss: 4.74882e-02
I0513 21:17:40.778954 22392998065984 run_lib.py:146] step: 11950, training_loss: 6.05188e-02
I0513 21:18:04.373343 22392998065984 run_lib.py:146] step: 12000, training_loss: 5.70959e-02
I0513 21:18:04.533157 22392998065984 run_lib.py:167] step: 12000, eval_loss: 5.59392e-02
I0513 21:18:28.474153 22392998065984 run_lib.py:146] step: 12050, training_loss: 6.26464e-02
I0513 21:18:52.315152 22392998065984 run_lib.py:146] step: 12100, training_loss: 5.19442e-02
I0513 21:18:52.474293 22392998065984 run_lib.py:167] step: 12100, eval_loss: 5.44322e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:19:16.200447 22392998065984 run_lib.py:146] step: 12150, training_loss: 7.12954e-02
I0513 21:19:40.474870 22392998065984 run_lib.py:146] step: 12200, training_loss: 7.76919e-02
I0513 21:19:40.643059 22392998065984 run_lib.py:167] step: 12200, eval_loss: 6.45734e-02
I0513 21:20:04.571888 22392998065984 run_lib.py:146] step: 12250, training_loss: 7.15773e-02
I0513 21:20:28.401785 22392998065984 run_lib.py:146] step: 12300, training_loss: 4.81174e-02
I0513 21:20:28.560687 22392998065984 run_lib.py:167] step: 12300, eval_loss: 5.54401e-02
I0513 21:20:52.385287 22392998065984 run_lib.py:146] step: 12350, training_loss: 6.10468e-02
I0513 21:21:16.021570 22392998065984 run_lib.py:146] step: 12400, training_loss: 7.71594e-02
I0513 21:21:16.192609 22392998065984 run_lib.py:167] step: 12400, eval_loss: 6.19109e-02
I0513 21:21:40.671569 22392998065984 run_lib.py:146] step: 12450, training_loss: 7.38159e-02
I0513 21:22:05.196901 22392998065984 run_lib.py:146] step: 12500, training_loss: 5.38629e-02
I0513 21:22:05.364072 22392998065984 run_lib.py:167] step: 12500, eval_loss: 5.40881e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:22:29.207690 22392998065984 run_lib.py:146] step: 12550, training_loss: 7.61207e-02
I0513 21:22:53.069800 22392998065984 run_lib.py:146] step: 12600, training_loss: 6.63002e-02
I0513 21:22:53.230380 22392998065984 run_lib.py:167] step: 12600, eval_loss: 7.23053e-02
I0513 21:23:17.212980 22392998065984 run_lib.py:146] step: 12650, training_loss: 6.46783e-02
I0513 21:23:41.815527 22392998065984 run_lib.py:146] step: 12700, training_loss: 9.28182e-02
I0513 21:23:41.984385 22392998065984 run_lib.py:167] step: 12700, eval_loss: 5.95471e-02
I0513 21:24:06.063690 22392998065984 run_lib.py:146] step: 12750, training_loss: 7.65396e-02
I0513 21:24:29.649458 22392998065984 run_lib.py:146] step: 12800, training_loss: 6.21020e-02
I0513 21:24:29.811613 22392998065984 run_lib.py:167] step: 12800, eval_loss: 7.19687e-02
I0513 21:24:53.677478 22392998065984 run_lib.py:146] step: 12850, training_loss: 8.05523e-02
I0513 21:25:17.239111 22392998065984 run_lib.py:146] step: 12900, training_loss: 7.02889e-02
I0513 21:25:17.400674 22392998065984 run_lib.py:167] step: 12900, eval_loss: 5.96302e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:25:41.529482 22392998065984 run_lib.py:146] step: 12950, training_loss: 5.93795e-02
I0513 21:26:05.485290 22392998065984 run_lib.py:146] step: 13000, training_loss: 5.53169e-02
I0513 21:26:05.648541 22392998065984 run_lib.py:167] step: 13000, eval_loss: 6.19344e-02
I0513 21:26:29.187251 22392998065984 run_lib.py:146] step: 13050, training_loss: 6.54193e-02
I0513 21:26:53.070366 22392998065984 run_lib.py:146] step: 13100, training_loss: 6.57942e-02
I0513 21:26:53.231621 22392998065984 run_lib.py:167] step: 13100, eval_loss: 7.28019e-02
I0513 21:27:17.080842 22392998065984 run_lib.py:146] step: 13150, training_loss: 5.57800e-02
I0513 21:27:40.664145 22392998065984 run_lib.py:146] step: 13200, training_loss: 5.23390e-02
I0513 21:27:40.824157 22392998065984 run_lib.py:167] step: 13200, eval_loss: 5.56748e-02
I0513 21:28:04.664202 22392998065984 run_lib.py:146] step: 13250, training_loss: 6.69123e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:28:29.059644 22392998065984 run_lib.py:146] step: 13300, training_loss: 5.90678e-02
I0513 21:28:29.229625 22392998065984 run_lib.py:167] step: 13300, eval_loss: 6.26611e-02
I0513 21:28:53.463543 22392998065984 run_lib.py:146] step: 13350, training_loss: 5.94692e-02
I0513 21:29:17.959688 22392998065984 run_lib.py:146] step: 13400, training_loss: 6.47293e-02
I0513 21:29:18.130582 22392998065984 run_lib.py:167] step: 13400, eval_loss: 5.61762e-02
I0513 21:29:42.370126 22392998065984 run_lib.py:146] step: 13450, training_loss: 6.35066e-02
I0513 21:30:06.903665 22392998065984 run_lib.py:146] step: 13500, training_loss: 6.20963e-02
I0513 21:30:07.073515 22392998065984 run_lib.py:167] step: 13500, eval_loss: 6.37889e-02
I0513 21:30:31.526346 22392998065984 run_lib.py:146] step: 13550, training_loss: 7.37184e-02
I0513 21:30:55.760335 22392998065984 run_lib.py:146] step: 13600, training_loss: 6.43650e-02
I0513 21:30:55.930786 22392998065984 run_lib.py:167] step: 13600, eval_loss: 7.24294e-02
I0513 21:31:20.469553 22392998065984 run_lib.py:146] step: 13650, training_loss: 6.73995e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:31:44.998656 22392998065984 run_lib.py:146] step: 13700, training_loss: 7.13727e-02
I0513 21:31:45.161448 22392998065984 run_lib.py:167] step: 13700, eval_loss: 5.24259e-02
I0513 21:32:08.940094 22392998065984 run_lib.py:146] step: 13750, training_loss: 6.91823e-02
I0513 21:32:32.840695 22392998065984 run_lib.py:146] step: 13800, training_loss: 5.93377e-02
I0513 21:32:33.003328 22392998065984 run_lib.py:167] step: 13800, eval_loss: 6.59031e-02
I0513 21:32:56.550578 22392998065984 run_lib.py:146] step: 13850, training_loss: 5.30988e-02
I0513 21:33:20.411382 22392998065984 run_lib.py:146] step: 13900, training_loss: 6.46707e-02
I0513 21:33:20.570421 22392998065984 run_lib.py:167] step: 13900, eval_loss: 6.26795e-02
I0513 21:33:44.441830 22392998065984 run_lib.py:146] step: 13950, training_loss: 5.74393e-02
I0513 21:34:08.034985 22392998065984 run_lib.py:146] step: 14000, training_loss: 6.79286e-02
I0513 21:34:08.193552 22392998065984 run_lib.py:167] step: 14000, eval_loss: 6.37294e-02
I0513 21:34:32.022937 22392998065984 run_lib.py:146] step: 14050, training_loss: 6.39626e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:34:56.177030 22392998065984 run_lib.py:146] step: 14100, training_loss: 6.59526e-02
I0513 21:34:56.337605 22392998065984 run_lib.py:167] step: 14100, eval_loss: 7.27151e-02
I0513 21:35:19.931492 22392998065984 run_lib.py:146] step: 14150, training_loss: 4.94044e-02
I0513 21:35:43.826707 22392998065984 run_lib.py:146] step: 14200, training_loss: 8.07939e-02
I0513 21:35:43.985918 22392998065984 run_lib.py:167] step: 14200, eval_loss: 6.97494e-02
I0513 21:36:07.584423 22392998065984 run_lib.py:146] step: 14250, training_loss: 6.22953e-02
I0513 21:36:31.988399 22392998065984 run_lib.py:146] step: 14300, training_loss: 5.85290e-02
I0513 21:36:32.158533 22392998065984 run_lib.py:167] step: 14300, eval_loss: 5.19608e-02
I0513 21:36:56.630125 22392998065984 run_lib.py:146] step: 14350, training_loss: 7.90471e-02
I0513 21:37:20.843346 22392998065984 run_lib.py:146] step: 14400, training_loss: 5.38503e-02
I0513 21:37:21.010298 22392998065984 run_lib.py:167] step: 14400, eval_loss: 5.97328e-02
I0513 21:37:45.567346 22392998065984 run_lib.py:146] step: 14450, training_loss: 7.11306e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:38:10.254548 22392998065984 run_lib.py:146] step: 14500, training_loss: 5.07609e-02
I0513 21:38:10.422598 22392998065984 run_lib.py:167] step: 14500, eval_loss: 6.76491e-02
I0513 21:38:34.658995 22392998065984 run_lib.py:146] step: 14550, training_loss: 9.14217e-02
I0513 21:38:59.248100 22392998065984 run_lib.py:146] step: 14600, training_loss: 7.38132e-02
I0513 21:38:59.414589 22392998065984 run_lib.py:167] step: 14600, eval_loss: 5.05213e-02
I0513 21:39:23.673071 22392998065984 run_lib.py:146] step: 14650, training_loss: 7.84357e-02
I0513 21:39:48.141845 22392998065984 run_lib.py:146] step: 14700, training_loss: 6.54418e-02
I0513 21:39:48.309854 22392998065984 run_lib.py:167] step: 14700, eval_loss: 6.66083e-02
I0513 21:40:12.820749 22392998065984 run_lib.py:146] step: 14750, training_loss: 6.03460e-02
I0513 21:40:37.043981 22392998065984 run_lib.py:146] step: 14800, training_loss: 7.26814e-02
I0513 21:40:37.211857 22392998065984 run_lib.py:167] step: 14800, eval_loss: 5.70214e-02
I0513 21:41:01.662089 22392998065984 run_lib.py:146] step: 14850, training_loss: 6.88339e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:41:25.480519 22392998065984 run_lib.py:146] step: 14900, training_loss: 7.28964e-02
I0513 21:41:25.644646 22392998065984 run_lib.py:167] step: 14900, eval_loss: 6.50382e-02
I0513 21:41:49.685993 22392998065984 run_lib.py:146] step: 14950, training_loss: 4.97376e-02
I0513 21:42:14.194746 22392998065984 run_lib.py:146] step: 15000, training_loss: 7.52561e-02
I0513 21:42:14.365975 22392998065984 run_lib.py:167] step: 15000, eval_loss: 6.49022e-02
I0513 21:42:38.574522 22392998065984 run_lib.py:146] step: 15050, training_loss: 8.13910e-02
I0513 21:43:03.078610 22392998065984 run_lib.py:146] step: 15100, training_loss: 5.34037e-02
I0513 21:43:03.250138 22392998065984 run_lib.py:167] step: 15100, eval_loss: 5.56582e-02
I0513 21:43:27.729470 22392998065984 run_lib.py:146] step: 15150, training_loss: 5.20436e-02
I0513 21:43:51.961342 22392998065984 run_lib.py:146] step: 15200, training_loss: 5.43383e-02
I0513 21:43:52.130795 22392998065984 run_lib.py:167] step: 15200, eval_loss: 5.49040e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:44:16.788818 22392998065984 run_lib.py:146] step: 15250, training_loss: 5.69865e-02
I0513 21:44:40.671961 22392998065984 run_lib.py:146] step: 15300, training_loss: 6.66180e-02
I0513 21:44:40.834730 22392998065984 run_lib.py:167] step: 15300, eval_loss: 5.67855e-02
I0513 21:45:04.407726 22392998065984 run_lib.py:146] step: 15350, training_loss: 1.01913e-01
I0513 21:45:28.283043 22392998065984 run_lib.py:146] step: 15400, training_loss: 6.34726e-02
I0513 21:45:28.442075 22392998065984 run_lib.py:167] step: 15400, eval_loss: 5.01194e-02
I0513 21:45:52.494325 22392998065984 run_lib.py:146] step: 15450, training_loss: 6.52450e-02
I0513 21:46:16.951531 22392998065984 run_lib.py:146] step: 15500, training_loss: 6.94844e-02
I0513 21:46:17.118059 22392998065984 run_lib.py:167] step: 15500, eval_loss: 7.45790e-02
I0513 21:46:41.624619 22392998065984 run_lib.py:146] step: 15550, training_loss: 6.25778e-02
I0513 21:47:05.888253 22392998065984 run_lib.py:146] step: 15600, training_loss: 6.05592e-02
I0513 21:47:06.054697 22392998065984 run_lib.py:167] step: 15600, eval_loss: 4.83562e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:47:30.702757 22392998065984 run_lib.py:146] step: 15650, training_loss: 5.18558e-02
I0513 21:47:54.923247 22392998065984 run_lib.py:146] step: 15700, training_loss: 5.73336e-02
I0513 21:47:55.039597 22392998065984 run_lib.py:167] step: 15700, eval_loss: 6.15451e-02
I0513 21:48:19.661031 22392998065984 run_lib.py:146] step: 15750, training_loss: 6.09525e-02
I0513 21:48:43.540799 22392998065984 run_lib.py:146] step: 15800, training_loss: 7.19146e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:48:43.968005 22392998065984 run_lib.py:167] step: 15800, eval_loss: 7.54819e-02
I0513 21:49:07.961344 22392998065984 run_lib.py:146] step: 15850, training_loss: 5.36827e-02
I0513 21:49:32.568730 22392998065984 run_lib.py:146] step: 15900, training_loss: 7.12761e-02
I0513 21:49:32.736822 22392998065984 run_lib.py:167] step: 15900, eval_loss: 6.28682e-02
I0513 21:49:57.258013 22392998065984 run_lib.py:146] step: 15950, training_loss: 7.73689e-02
I0513 21:50:21.488487 22392998065984 run_lib.py:146] step: 16000, training_loss: 7.54757e-02
I0513 21:50:21.656324 22392998065984 run_lib.py:167] step: 16000, eval_loss: 7.73140e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:50:46.361002 22392998065984 run_lib.py:146] step: 16050, training_loss: 5.46660e-02
I0513 21:51:10.912895 22392998065984 run_lib.py:146] step: 16100, training_loss: 5.87999e-02
I0513 21:51:11.085415 22392998065984 run_lib.py:167] step: 16100, eval_loss: 5.37476e-02
I0513 21:51:34.999461 22392998065984 run_lib.py:146] step: 16150, training_loss: 6.34078e-02
I0513 21:51:58.925853 22392998065984 run_lib.py:146] step: 16200, training_loss: 7.44521e-02
I0513 21:51:59.084891 22392998065984 run_lib.py:167] step: 16200, eval_loss: 6.23050e-02
I0513 21:52:22.739428 22392998065984 run_lib.py:146] step: 16250, training_loss: 8.14963e-02
I0513 21:52:46.792935 22392998065984 run_lib.py:146] step: 16300, training_loss: 5.86938e-02
I0513 21:52:46.952821 22392998065984 run_lib.py:167] step: 16300, eval_loss: 5.67197e-02
I0513 21:53:11.040569 22392998065984 run_lib.py:146] step: 16350, training_loss: 5.44497e-02
I0513 21:53:34.805554 22392998065984 run_lib.py:146] step: 16400, training_loss: 7.81092e-02
I0513 21:53:34.969633 22392998065984 run_lib.py:167] step: 16400, eval_loss: 5.98541e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:53:59.057233 22392998065984 run_lib.py:146] step: 16450, training_loss: 4.70914e-02
I0513 21:54:22.707775 22392998065984 run_lib.py:146] step: 16500, training_loss: 7.56653e-02
I0513 21:54:22.871915 22392998065984 run_lib.py:167] step: 16500, eval_loss: 5.61886e-02
I0513 21:54:46.898742 22392998065984 run_lib.py:146] step: 16550, training_loss: 5.92794e-02
I0513 21:55:10.970199 22392998065984 run_lib.py:146] step: 16600, training_loss: 7.86841e-02
I0513 21:55:11.130088 22392998065984 run_lib.py:167] step: 16600, eval_loss: 5.75188e-02
I0513 21:55:34.906760 22392998065984 run_lib.py:146] step: 16650, training_loss: 7.89880e-02
I0513 21:55:58.992284 22392998065984 run_lib.py:146] step: 16700, training_loss: 8.82279e-02
I0513 21:55:59.151393 22392998065984 run_lib.py:167] step: 16700, eval_loss: 5.68233e-02
I0513 21:56:23.155248 22392998065984 run_lib.py:146] step: 16750, training_loss: 6.91958e-02
I0513 21:56:46.898235 22392998065984 run_lib.py:146] step: 16800, training_loss: 5.78044e-02
I0513 21:56:47.058723 22392998065984 run_lib.py:167] step: 16800, eval_loss: 6.29698e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 21:57:11.263746 22392998065984 run_lib.py:146] step: 16850, training_loss: 6.49870e-02
I0513 21:57:35.300066 22392998065984 run_lib.py:146] step: 16900, training_loss: 6.63746e-02
I0513 21:57:35.461155 22392998065984 run_lib.py:167] step: 16900, eval_loss: 7.28409e-02
I0513 21:57:59.249093 22392998065984 run_lib.py:146] step: 16950, training_loss: 5.81548e-02
I0513 21:58:23.313616 22392998065984 run_lib.py:146] step: 17000, training_loss: 4.55628e-02
I0513 21:58:23.473483 22392998065984 run_lib.py:167] step: 17000, eval_loss: 6.20450e-02
I0513 21:58:47.530338 22392998065984 run_lib.py:146] step: 17050, training_loss: 6.82876e-02
I0513 21:59:11.785159 22392998065984 run_lib.py:146] step: 17100, training_loss: 5.70580e-02
I0513 21:59:11.954827 22392998065984 run_lib.py:167] step: 17100, eval_loss: 5.23752e-02
I0513 21:59:36.131635 22392998065984 run_lib.py:146] step: 17150, training_loss: 5.44402e-02
I0513 21:59:59.845451 22392998065984 run_lib.py:146] step: 17200, training_loss: 5.55575e-02
I0513 22:00:00.005234 22392998065984 run_lib.py:167] step: 17200, eval_loss: 6.93754e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:00:24.152801 22392998065984 run_lib.py:146] step: 17250, training_loss: 4.81965e-02
I0513 22:00:47.924506 22392998065984 run_lib.py:146] step: 17300, training_loss: 5.29271e-02
I0513 22:00:48.088311 22392998065984 run_lib.py:167] step: 17300, eval_loss: 5.07206e-02
I0513 22:01:12.261389 22392998065984 run_lib.py:146] step: 17350, training_loss: 7.13891e-02
I0513 22:01:36.271669 22392998065984 run_lib.py:146] step: 17400, training_loss: 7.09663e-02
I0513 22:01:36.430878 22392998065984 run_lib.py:167] step: 17400, eval_loss: 5.63504e-02
I0513 22:02:00.121060 22392998065984 run_lib.py:146] step: 17450, training_loss: 6.77062e-02
I0513 22:02:24.254918 22392998065984 run_lib.py:146] step: 17500, training_loss: 6.39244e-02
I0513 22:02:24.423812 22392998065984 run_lib.py:167] step: 17500, eval_loss: 5.58835e-02
I0513 22:02:49.157129 22392998065984 run_lib.py:146] step: 17550, training_loss: 5.39474e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:03:13.763552 22392998065984 run_lib.py:146] step: 17600, training_loss: 4.82882e-02
I0513 22:03:13.933519 22392998065984 run_lib.py:167] step: 17600, eval_loss: 6.20773e-02
I0513 22:03:38.656269 22392998065984 run_lib.py:146] step: 17650, training_loss: 6.30455e-02
I0513 22:04:03.309479 22392998065984 run_lib.py:146] step: 17700, training_loss: 5.38097e-02
I0513 22:04:03.479502 22392998065984 run_lib.py:167] step: 17700, eval_loss: 7.09281e-02
I0513 22:04:27.829470 22392998065984 run_lib.py:146] step: 17750, training_loss: 6.26400e-02
I0513 22:04:52.490644 22392998065984 run_lib.py:146] step: 17800, training_loss: 6.55683e-02
I0513 22:04:52.661851 22392998065984 run_lib.py:167] step: 17800, eval_loss: 6.11985e-02
I0513 22:05:16.990046 22392998065984 run_lib.py:146] step: 17850, training_loss: 6.80148e-02
I0513 22:05:41.450130 22392998065984 run_lib.py:146] step: 17900, training_loss: 7.95557e-02
I0513 22:05:41.609707 22392998065984 run_lib.py:167] step: 17900, eval_loss: 6.76754e-02
I0513 22:06:05.577863 22392998065984 run_lib.py:146] step: 17950, training_loss: 6.67889e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:06:29.395300 22392998065984 run_lib.py:146] step: 18000, training_loss: 4.12169e-02
I0513 22:06:29.555811 22392998065984 run_lib.py:167] step: 18000, eval_loss: 7.70099e-02
I0513 22:06:53.259451 22392998065984 run_lib.py:146] step: 18050, training_loss: 7.90385e-02
I0513 22:07:16.615625 22392998065984 run_lib.py:146] step: 18100, training_loss: 8.09109e-02
I0513 22:07:16.773922 22392998065984 run_lib.py:167] step: 18100, eval_loss: 6.48555e-02
I0513 22:07:40.477233 22392998065984 run_lib.py:146] step: 18150, training_loss: 5.58442e-02
I0513 22:08:04.130459 22392998065984 run_lib.py:146] step: 18200, training_loss: 6.19450e-02
I0513 22:08:04.288038 22392998065984 run_lib.py:167] step: 18200, eval_loss: 6.88255e-02
I0513 22:08:27.674716 22392998065984 run_lib.py:146] step: 18250, training_loss: 6.36367e-02
I0513 22:08:51.349160 22392998065984 run_lib.py:146] step: 18300, training_loss: 6.26263e-02
I0513 22:08:51.506397 22392998065984 run_lib.py:167] step: 18300, eval_loss: 5.16294e-02
I0513 22:09:15.154768 22392998065984 run_lib.py:146] step: 18350, training_loss: 7.02960e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:09:38.608008 22392998065984 run_lib.py:146] step: 18400, training_loss: 5.14347e-02
I0513 22:09:38.767271 22392998065984 run_lib.py:167] step: 18400, eval_loss: 5.56560e-02
I0513 22:10:02.454288 22392998065984 run_lib.py:146] step: 18450, training_loss: 8.13721e-02
I0513 22:10:26.138017 22392998065984 run_lib.py:146] step: 18500, training_loss: 6.33617e-02
I0513 22:10:26.295349 22392998065984 run_lib.py:167] step: 18500, eval_loss: 6.31476e-02
I0513 22:10:49.640115 22392998065984 run_lib.py:146] step: 18550, training_loss: 6.54733e-02
I0513 22:11:13.308087 22392998065984 run_lib.py:146] step: 18600, training_loss: 8.34821e-02
I0513 22:11:13.465322 22392998065984 run_lib.py:167] step: 18600, eval_loss: 5.37287e-02
I0513 22:11:36.834281 22392998065984 run_lib.py:146] step: 18650, training_loss: 6.48939e-02
I0513 22:12:00.499759 22392998065984 run_lib.py:146] step: 18700, training_loss: 7.67431e-02
I0513 22:12:00.658049 22392998065984 run_lib.py:167] step: 18700, eval_loss: 6.28010e-02
I0513 22:12:24.332282 22392998065984 run_lib.py:146] step: 18750, training_loss: 4.64893e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:12:47.856425 22392998065984 run_lib.py:146] step: 18800, training_loss: 7.70718e-02
I0513 22:12:48.015969 22392998065984 run_lib.py:167] step: 18800, eval_loss: 6.07595e-02
I0513 22:13:12.393925 22392998065984 run_lib.py:146] step: 18850, training_loss: 6.18244e-02
I0513 22:13:36.159504 22392998065984 run_lib.py:146] step: 18900, training_loss: 8.27957e-02
I0513 22:13:36.316724 22392998065984 run_lib.py:167] step: 18900, eval_loss: 5.46228e-02
I0513 22:13:59.675217 22392998065984 run_lib.py:146] step: 18950, training_loss: 5.96069e-02
I0513 22:14:23.325298 22392998065984 run_lib.py:146] step: 19000, training_loss: 5.83649e-02
I0513 22:14:23.482929 22392998065984 run_lib.py:167] step: 19000, eval_loss: 6.26955e-02
I0513 22:14:46.860926 22392998065984 run_lib.py:146] step: 19050, training_loss: 5.44211e-02
I0513 22:15:10.528133 22392998065984 run_lib.py:146] step: 19100, training_loss: 6.55287e-02
I0513 22:15:10.685482 22392998065984 run_lib.py:167] step: 19100, eval_loss: 6.72165e-02
I0513 22:15:34.333328 22392998065984 run_lib.py:146] step: 19150, training_loss: 6.31122e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:15:57.807160 22392998065984 run_lib.py:146] step: 19200, training_loss: 6.94039e-02
I0513 22:15:57.966579 22392998065984 run_lib.py:167] step: 19200, eval_loss: 5.85224e-02
I0513 22:16:21.817707 22392998065984 run_lib.py:146] step: 19250, training_loss: 7.18264e-02
I0513 22:16:45.511960 22392998065984 run_lib.py:146] step: 19300, training_loss: 5.75176e-02
I0513 22:16:45.669324 22392998065984 run_lib.py:167] step: 19300, eval_loss: 4.72977e-02
I0513 22:17:09.048372 22392998065984 run_lib.py:146] step: 19350, training_loss: 7.30380e-02
I0513 22:17:32.740675 22392998065984 run_lib.py:146] step: 19400, training_loss: 5.76272e-02
I0513 22:17:32.898580 22392998065984 run_lib.py:167] step: 19400, eval_loss: 7.56894e-02
I0513 22:17:56.286402 22392998065984 run_lib.py:146] step: 19450, training_loss: 5.98231e-02
I0513 22:18:19.965117 22392998065984 run_lib.py:146] step: 19500, training_loss: 7.44643e-02
I0513 22:18:20.123199 22392998065984 run_lib.py:167] step: 19500, eval_loss: 4.96812e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:18:43.917865 22392998065984 run_lib.py:146] step: 19550, training_loss: 5.35786e-02
I0513 22:19:07.283898 22392998065984 run_lib.py:146] step: 19600, training_loss: 7.00389e-02
I0513 22:19:07.442507 22392998065984 run_lib.py:167] step: 19600, eval_loss: 6.72353e-02
I0513 22:19:31.128776 22392998065984 run_lib.py:146] step: 19650, training_loss: 6.51439e-02
I0513 22:19:54.917906 22392998065984 run_lib.py:146] step: 19700, training_loss: 6.81412e-02
I0513 22:19:55.075217 22392998065984 run_lib.py:167] step: 19700, eval_loss: 7.29353e-02
I0513 22:20:18.856358 22392998065984 run_lib.py:146] step: 19750, training_loss: 5.76332e-02
I0513 22:20:42.959447 22392998065984 run_lib.py:146] step: 19800, training_loss: 7.27839e-02
I0513 22:20:43.116209 22392998065984 run_lib.py:167] step: 19800, eval_loss: 6.63326e-02
I0513 22:21:06.815214 22392998065984 run_lib.py:146] step: 19850, training_loss: 4.74120e-02
I0513 22:21:30.559228 22392998065984 run_lib.py:146] step: 19900, training_loss: 6.56620e-02
I0513 22:21:30.715581 22392998065984 run_lib.py:167] step: 19900, eval_loss: 7.23624e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:21:54.537753 22392998065984 run_lib.py:146] step: 19950, training_loss: 5.69783e-02
I0513 22:22:17.811156 22392998065984 run_lib.py:146] step: 20000, training_loss: 6.21072e-02
I0513 22:22:19.933015 22392998065984 run_lib.py:167] step: 20000, eval_loss: 5.17471e-02
I0513 22:22:44.688863 22392998065984 run_lib.py:146] step: 20050, training_loss: 6.62031e-02
I0513 22:23:08.257728 22392998065984 run_lib.py:146] step: 20100, training_loss: 6.45455e-02
I0513 22:23:08.414413 22392998065984 run_lib.py:167] step: 20100, eval_loss: 6.98549e-02
I0513 22:23:31.955944 22392998065984 run_lib.py:146] step: 20150, training_loss: 5.41899e-02
I0513 22:23:55.210662 22392998065984 run_lib.py:146] step: 20200, training_loss: 4.07435e-02
I0513 22:23:55.367208 22392998065984 run_lib.py:167] step: 20200, eval_loss: 6.18938e-02
I0513 22:24:19.088953 22392998065984 run_lib.py:146] step: 20250, training_loss: 6.91329e-02
I0513 22:24:42.751306 22392998065984 run_lib.py:146] step: 20300, training_loss: 8.17789e-02
I0513 22:24:42.907714 22392998065984 run_lib.py:167] step: 20300, eval_loss: 7.01081e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:25:06.307306 22392998065984 run_lib.py:146] step: 20350, training_loss: 5.63435e-02
I0513 22:25:29.913167 22392998065984 run_lib.py:146] step: 20400, training_loss: 5.07214e-02
I0513 22:25:30.070820 22392998065984 run_lib.py:167] step: 20400, eval_loss: 5.64700e-02
I0513 22:25:54.465757 22392998065984 run_lib.py:146] step: 20450, training_loss: 6.75099e-02
I0513 22:26:18.199785 22392998065984 run_lib.py:146] step: 20500, training_loss: 6.20783e-02
I0513 22:26:18.356312 22392998065984 run_lib.py:167] step: 20500, eval_loss: 7.83472e-02
I0513 22:26:42.096780 22392998065984 run_lib.py:146] step: 20550, training_loss: 5.00653e-02
I0513 22:27:06.137723 22392998065984 run_lib.py:146] step: 20600, training_loss: 4.59659e-02
I0513 22:27:06.294422 22392998065984 run_lib.py:167] step: 20600, eval_loss: 6.57424e-02
I0513 22:27:30.318193 22392998065984 run_lib.py:146] step: 20650, training_loss: 5.66125e-02
I0513 22:27:54.040673 22392998065984 run_lib.py:146] step: 20700, training_loss: 6.39255e-02
I0513 22:27:54.196827 22392998065984 run_lib.py:167] step: 20700, eval_loss: 7.25447e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:28:18.191601 22392998065984 run_lib.py:146] step: 20750, training_loss: 7.49001e-02
I0513 22:28:41.819622 22392998065984 run_lib.py:146] step: 20800, training_loss: 5.64168e-02
I0513 22:28:41.976827 22392998065984 run_lib.py:167] step: 20800, eval_loss: 7.10868e-02
I0513 22:29:05.276141 22392998065984 run_lib.py:146] step: 20850, training_loss: 6.52683e-02
I0513 22:29:28.839232 22392998065984 run_lib.py:146] step: 20900, training_loss: 8.15785e-02
I0513 22:29:28.995764 22392998065984 run_lib.py:167] step: 20900, eval_loss: 6.72830e-02
I0513 22:29:52.560569 22392998065984 run_lib.py:146] step: 20950, training_loss: 6.46040e-02
I0513 22:30:15.823555 22392998065984 run_lib.py:146] step: 21000, training_loss: 6.17297e-02
I0513 22:30:15.980697 22392998065984 run_lib.py:167] step: 21000, eval_loss: 6.12364e-02
I0513 22:30:39.538816 22392998065984 run_lib.py:146] step: 21050, training_loss: 5.36277e-02
I0513 22:31:03.096357 22392998065984 run_lib.py:146] step: 21100, training_loss: 6.76509e-02
I0513 22:31:03.252958 22392998065984 run_lib.py:167] step: 21100, eval_loss: 5.35412e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:31:26.657396 22392998065984 run_lib.py:146] step: 21150, training_loss: 8.75513e-02
I0513 22:31:49.937359 22392998065984 run_lib.py:146] step: 21200, training_loss: 5.92066e-02
I0513 22:31:50.096218 22392998065984 run_lib.py:167] step: 21200, eval_loss: 6.39835e-02
I0513 22:32:14.015452 22392998065984 run_lib.py:146] step: 21250, training_loss: 5.68914e-02
I0513 22:32:37.289970 22392998065984 run_lib.py:146] step: 21300, training_loss: 6.96594e-02
I0513 22:32:37.446391 22392998065984 run_lib.py:167] step: 21300, eval_loss: 5.86269e-02
I0513 22:33:00.717968 22392998065984 run_lib.py:146] step: 21350, training_loss: 5.86885e-02
I0513 22:33:24.268901 22392998065984 run_lib.py:146] step: 21400, training_loss: 7.17899e-02
I0513 22:33:24.425579 22392998065984 run_lib.py:167] step: 21400, eval_loss: 5.86475e-02
I0513 22:33:47.998718 22392998065984 run_lib.py:146] step: 21450, training_loss: 8.85169e-02
I0513 22:34:11.279871 22392998065984 run_lib.py:146] step: 21500, training_loss: 6.78746e-02
I0513 22:34:11.436618 22392998065984 run_lib.py:167] step: 21500, eval_loss: 6.74256e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:34:35.194186 22392998065984 run_lib.py:146] step: 21550, training_loss: 6.73683e-02
I0513 22:34:58.812636 22392998065984 run_lib.py:146] step: 21600, training_loss: 8.86144e-02
I0513 22:34:58.970265 22392998065984 run_lib.py:167] step: 21600, eval_loss: 5.15162e-02
I0513 22:35:22.248016 22392998065984 run_lib.py:146] step: 21650, training_loss: 8.18838e-02
I0513 22:35:45.779896 22392998065984 run_lib.py:146] step: 21700, training_loss: 5.52746e-02
I0513 22:35:45.937752 22392998065984 run_lib.py:167] step: 21700, eval_loss: 7.88585e-02
I0513 22:36:09.569139 22392998065984 run_lib.py:146] step: 21750, training_loss: 6.69270e-02
I0513 22:36:32.902505 22392998065984 run_lib.py:146] step: 21800, training_loss: 6.18693e-02
I0513 22:36:33.059059 22392998065984 run_lib.py:167] step: 21800, eval_loss: 5.79066e-02
I0513 22:36:56.651971 22392998065984 run_lib.py:146] step: 21850, training_loss: 5.58774e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:37:20.353509 22392998065984 run_lib.py:146] step: 21900, training_loss: 7.56660e-02
I0513 22:37:20.512208 22392998065984 run_lib.py:167] step: 21900, eval_loss: 5.35412e-02
I0513 22:37:43.969335 22392998065984 run_lib.py:146] step: 21950, training_loss: 5.72475e-02
I0513 22:38:07.277439 22392998065984 run_lib.py:146] step: 22000, training_loss: 6.96843e-02
I0513 22:38:07.434078 22392998065984 run_lib.py:167] step: 22000, eval_loss: 8.12340e-02
I0513 22:38:31.396053 22392998065984 run_lib.py:146] step: 22050, training_loss: 6.55418e-02
I0513 22:38:54.673327 22392998065984 run_lib.py:146] step: 22100, training_loss: 5.96317e-02
I0513 22:38:54.829779 22392998065984 run_lib.py:167] step: 22100, eval_loss: 5.48784e-02
I0513 22:39:18.113046 22392998065984 run_lib.py:146] step: 22150, training_loss: 6.63078e-02
I0513 22:39:41.687396 22392998065984 run_lib.py:146] step: 22200, training_loss: 5.37191e-02
I0513 22:39:41.844184 22392998065984 run_lib.py:167] step: 22200, eval_loss: 5.23319e-02
I0513 22:40:05.392113 22392998065984 run_lib.py:146] step: 22250, training_loss: 6.39095e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:40:28.951226 22392998065984 run_lib.py:146] step: 22300, training_loss: 5.60171e-02
I0513 22:40:29.109726 22392998065984 run_lib.py:167] step: 22300, eval_loss: 5.41887e-02
I0513 22:40:53.357106 22392998065984 run_lib.py:146] step: 22350, training_loss: 6.44208e-02
I0513 22:41:17.557101 22392998065984 run_lib.py:146] step: 22400, training_loss: 7.18058e-02
I0513 22:41:17.713411 22392998065984 run_lib.py:167] step: 22400, eval_loss: 4.74922e-02
I0513 22:41:41.593658 22392998065984 run_lib.py:146] step: 22450, training_loss: 6.14751e-02
I0513 22:42:05.792345 22392998065984 run_lib.py:146] step: 22500, training_loss: 6.63201e-02
I0513 22:42:05.948879 22392998065984 run_lib.py:167] step: 22500, eval_loss: 5.70359e-02
I0513 22:42:30.120438 22392998065984 run_lib.py:146] step: 22550, training_loss: 5.07851e-02
I0513 22:42:53.798499 22392998065984 run_lib.py:146] step: 22600, training_loss: 6.50885e-02
I0513 22:42:53.954835 22392998065984 run_lib.py:167] step: 22600, eval_loss: 7.76920e-02
I0513 22:43:17.537792 22392998065984 run_lib.py:146] step: 22650, training_loss: 6.03405e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:43:41.259232 22392998065984 run_lib.py:146] step: 22700, training_loss: 6.87385e-02
I0513 22:43:41.417167 22392998065984 run_lib.py:167] step: 22700, eval_loss: 6.72847e-02
I0513 22:44:04.688380 22392998065984 run_lib.py:146] step: 22750, training_loss: 5.34809e-02
I0513 22:44:27.952705 22392998065984 run_lib.py:146] step: 22800, training_loss: 6.41806e-02
I0513 22:44:28.108786 22392998065984 run_lib.py:167] step: 22800, eval_loss: 5.43510e-02
I0513 22:44:52.014506 22392998065984 run_lib.py:146] step: 22850, training_loss: 6.55282e-02
I0513 22:45:15.279446 22392998065984 run_lib.py:146] step: 22900, training_loss: 7.99720e-02
I0513 22:45:15.436065 22392998065984 run_lib.py:167] step: 22900, eval_loss: 5.91191e-02
I0513 22:45:38.703121 22392998065984 run_lib.py:146] step: 22950, training_loss: 7.57176e-02
I0513 22:46:02.578177 22392998065984 run_lib.py:146] step: 23000, training_loss: 7.15147e-02
I0513 22:46:02.734238 22392998065984 run_lib.py:167] step: 23000, eval_loss: 5.97396e-02
I0513 22:46:26.005511 22392998065984 run_lib.py:146] step: 23050, training_loss: 5.67309e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:46:49.786540 22392998065984 run_lib.py:146] step: 23100, training_loss: 5.25890e-02
I0513 22:46:49.944647 22392998065984 run_lib.py:167] step: 23100, eval_loss: 5.19611e-02
I0513 22:47:14.198047 22392998065984 run_lib.py:146] step: 23150, training_loss: 7.06068e-02
I0513 22:47:38.406398 22392998065984 run_lib.py:146] step: 23200, training_loss: 7.15398e-02
I0513 22:47:38.562977 22392998065984 run_lib.py:167] step: 23200, eval_loss: 6.39025e-02
I0513 22:48:02.446763 22392998065984 run_lib.py:146] step: 23250, training_loss: 7.32620e-02
I0513 22:48:26.631842 22392998065984 run_lib.py:146] step: 23300, training_loss: 7.95708e-02
I0513 22:48:26.788400 22392998065984 run_lib.py:167] step: 23300, eval_loss: 6.69912e-02
I0513 22:48:50.956774 22392998065984 run_lib.py:146] step: 23350, training_loss: 5.78687e-02
I0513 22:49:14.557984 22392998065984 run_lib.py:146] step: 23400, training_loss: 6.14946e-02
I0513 22:49:14.715515 22392998065984 run_lib.py:167] step: 23400, eval_loss: 7.32184e-02
I0513 22:49:38.264979 22392998065984 run_lib.py:146] step: 23450, training_loss: 7.30188e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:50:02.365234 22392998065984 run_lib.py:146] step: 23500, training_loss: 4.65570e-02
I0513 22:50:02.521847 22392998065984 run_lib.py:167] step: 23500, eval_loss: 7.36700e-02
I0513 22:50:26.255002 22392998065984 run_lib.py:146] step: 23550, training_loss: 5.54128e-02
I0513 22:50:49.986504 22392998065984 run_lib.py:146] step: 23600, training_loss: 6.05002e-02
I0513 22:50:50.066905 22392998065984 run_lib.py:167] step: 23600, eval_loss: 1.15124e-01
I0513 22:51:14.443768 22392998065984 run_lib.py:146] step: 23650, training_loss: 7.50226e-02
I0513 22:51:38.171097 22392998065984 run_lib.py:146] step: 23700, training_loss: 6.37487e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:51:38.546565 22392998065984 run_lib.py:167] step: 23700, eval_loss: 7.12875e-02
I0513 22:52:01.879792 22392998065984 run_lib.py:146] step: 23750, training_loss: 5.87082e-02
I0513 22:52:25.817218 22392998065984 run_lib.py:146] step: 23800, training_loss: 6.73360e-02
I0513 22:52:25.973981 22392998065984 run_lib.py:167] step: 23800, eval_loss: 6.40691e-02
I0513 22:52:49.093336 22392998065984 run_lib.py:146] step: 23850, training_loss: 5.81604e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:53:12.602997 22392998065984 run_lib.py:146] step: 23900, training_loss: 8.60895e-02
I0513 22:53:12.760769 22392998065984 run_lib.py:167] step: 23900, eval_loss: 6.82002e-02
I0513 22:53:36.351075 22392998065984 run_lib.py:146] step: 23950, training_loss: 5.77799e-02
I0513 22:53:59.945299 22392998065984 run_lib.py:146] step: 24000, training_loss: 7.90926e-02
I0513 22:54:00.101860 22392998065984 run_lib.py:167] step: 24000, eval_loss: 6.68878e-02
I0513 22:54:23.348938 22392998065984 run_lib.py:146] step: 24050, training_loss: 5.75725e-02
I0513 22:54:46.898749 22392998065984 run_lib.py:146] step: 24100, training_loss: 5.90462e-02
I0513 22:54:47.056272 22392998065984 run_lib.py:167] step: 24100, eval_loss: 8.52449e-02
I0513 22:55:11.040715 22392998065984 run_lib.py:146] step: 24150, training_loss: 8.02490e-02
I0513 22:55:34.663511 22392998065984 run_lib.py:146] step: 24200, training_loss: 7.71607e-02
I0513 22:55:34.819636 22392998065984 run_lib.py:167] step: 24200, eval_loss: 6.26666e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:55:58.538965 22392998065984 run_lib.py:146] step: 24250, training_loss: 5.96613e-02
I0513 22:56:22.111638 22392998065984 run_lib.py:146] step: 24300, training_loss: 6.81655e-02
I0513 22:56:22.269031 22392998065984 run_lib.py:167] step: 24300, eval_loss: 6.52475e-02
I0513 22:56:45.498312 22392998065984 run_lib.py:146] step: 24350, training_loss: 6.15936e-02
I0513 22:57:09.186193 22392998065984 run_lib.py:146] step: 24400, training_loss: 7.44195e-02
I0513 22:57:09.342876 22392998065984 run_lib.py:167] step: 24400, eval_loss: 5.83694e-02
I0513 22:57:33.669413 22392998065984 run_lib.py:146] step: 24450, training_loss: 6.07521e-02
I0513 22:57:56.952642 22392998065984 run_lib.py:146] step: 24500, training_loss: 6.17640e-02
I0513 22:57:57.108901 22392998065984 run_lib.py:167] step: 24500, eval_loss: 5.98473e-02
I0513 22:58:20.386525 22392998065984 run_lib.py:146] step: 24550, training_loss: 7.15565e-02
I0513 22:58:44.255573 22392998065984 run_lib.py:146] step: 24600, training_loss: 6.28566e-02
I0513 22:58:44.411986 22392998065984 run_lib.py:167] step: 24600, eval_loss: 5.66024e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 22:59:07.975762 22392998065984 run_lib.py:146] step: 24650, training_loss: 6.44414e-02
I0513 22:59:31.817034 22392998065984 run_lib.py:146] step: 24700, training_loss: 5.58988e-02
I0513 22:59:31.974707 22392998065984 run_lib.py:167] step: 24700, eval_loss: 6.24483e-02
I0513 22:59:56.494788 22392998065984 run_lib.py:146] step: 24750, training_loss: 6.54058e-02
I0513 23:00:20.340392 22392998065984 run_lib.py:146] step: 24800, training_loss: 6.95927e-02
I0513 23:00:20.497754 22392998065984 run_lib.py:167] step: 24800, eval_loss: 5.85764e-02
I0513 23:00:44.360660 22392998065984 run_lib.py:146] step: 24850, training_loss: 5.12445e-02
I0513 23:01:08.390533 22392998065984 run_lib.py:146] step: 24900, training_loss: 6.95502e-02
I0513 23:01:08.547016 22392998065984 run_lib.py:167] step: 24900, eval_loss: 5.55646e-02
I0513 23:01:32.552285 22392998065984 run_lib.py:146] step: 24950, training_loss: 7.52455e-02
I0513 23:01:55.979011 22392998065984 run_lib.py:146] step: 25000, training_loss: 5.16260e-02
I0513 23:01:56.135411 22392998065984 run_lib.py:167] step: 25000, eval_loss: 5.76039e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:02:19.921236 22392998065984 run_lib.py:146] step: 25050, training_loss: 5.86750e-02
I0513 23:02:43.544495 22392998065984 run_lib.py:146] step: 25100, training_loss: 6.61227e-02
I0513 23:02:43.701844 22392998065984 run_lib.py:167] step: 25100, eval_loss: 6.96815e-02
I0513 23:03:06.964107 22392998065984 run_lib.py:146] step: 25150, training_loss: 6.55058e-02
I0513 23:03:30.531087 22392998065984 run_lib.py:146] step: 25200, training_loss: 6.33669e-02
I0513 23:03:30.687655 22392998065984 run_lib.py:167] step: 25200, eval_loss: 6.36224e-02
I0513 23:03:54.232428 22392998065984 run_lib.py:146] step: 25250, training_loss: 5.18941e-02
I0513 23:04:17.499022 22392998065984 run_lib.py:146] step: 25300, training_loss: 5.14612e-02
I0513 23:04:17.655800 22392998065984 run_lib.py:167] step: 25300, eval_loss: 5.06153e-02
I0513 23:04:40.911654 22392998065984 run_lib.py:146] step: 25350, training_loss: 9.27750e-02
I0513 23:05:04.765710 22392998065984 run_lib.py:146] step: 25400, training_loss: 5.66333e-02
I0513 23:05:04.921678 22392998065984 run_lib.py:167] step: 25400, eval_loss: 6.64360e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:05:28.737178 22392998065984 run_lib.py:146] step: 25450, training_loss: 8.61266e-02
I0513 23:05:52.048599 22392998065984 run_lib.py:146] step: 25500, training_loss: 5.18984e-02
I0513 23:05:52.206496 22392998065984 run_lib.py:167] step: 25500, eval_loss: 5.89396e-02
I0513 23:06:16.111783 22392998065984 run_lib.py:146] step: 25550, training_loss: 5.26158e-02
I0513 23:06:39.388987 22392998065984 run_lib.py:146] step: 25600, training_loss: 7.58111e-02
I0513 23:06:39.546412 22392998065984 run_lib.py:167] step: 25600, eval_loss: 6.26900e-02
I0513 23:07:02.831264 22392998065984 run_lib.py:146] step: 25650, training_loss: 5.48314e-02
I0513 23:07:26.405847 22392998065984 run_lib.py:146] step: 25700, training_loss: 5.97161e-02
I0513 23:07:26.562491 22392998065984 run_lib.py:167] step: 25700, eval_loss: 4.96663e-02
I0513 23:07:50.117561 22392998065984 run_lib.py:146] step: 25750, training_loss: 5.35673e-02
I0513 23:08:13.385171 22392998065984 run_lib.py:146] step: 25800, training_loss: 5.90071e-02
I0513 23:08:13.541480 22392998065984 run_lib.py:167] step: 25800, eval_loss: 5.11212e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:08:37.786006 22392998065984 run_lib.py:146] step: 25850, training_loss: 6.52374e-02
I0513 23:09:01.945219 22392998065984 run_lib.py:146] step: 25900, training_loss: 6.77972e-02
I0513 23:09:02.102342 22392998065984 run_lib.py:167] step: 25900, eval_loss: 6.27784e-02
I0513 23:09:25.977188 22392998065984 run_lib.py:146] step: 25950, training_loss: 6.93596e-02
I0513 23:09:49.987522 22392998065984 run_lib.py:146] step: 26000, training_loss: 6.27151e-02
I0513 23:09:50.144858 22392998065984 run_lib.py:167] step: 26000, eval_loss: 5.13937e-02
I0513 23:10:13.667292 22392998065984 run_lib.py:146] step: 26050, training_loss: 6.46578e-02
I0513 23:10:37.468020 22392998065984 run_lib.py:146] step: 26100, training_loss: 4.85598e-02
I0513 23:10:37.624633 22392998065984 run_lib.py:167] step: 26100, eval_loss: 6.84025e-02
I0513 23:11:01.256385 22392998065984 run_lib.py:146] step: 26150, training_loss: 6.13716e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:11:25.256234 22392998065984 run_lib.py:146] step: 26200, training_loss: 4.67382e-02
I0513 23:11:25.414278 22392998065984 run_lib.py:167] step: 26200, eval_loss: 8.80900e-02
I0513 23:11:48.672576 22392998065984 run_lib.py:146] step: 26250, training_loss: 4.06051e-02
I0513 23:12:11.931620 22392998065984 run_lib.py:146] step: 26300, training_loss: 6.32820e-02
I0513 23:12:12.088141 22392998065984 run_lib.py:167] step: 26300, eval_loss: 5.01614e-02
I0513 23:12:35.970358 22392998065984 run_lib.py:146] step: 26350, training_loss: 5.31189e-02
I0513 23:12:59.224165 22392998065984 run_lib.py:146] step: 26400, training_loss: 5.46348e-02
I0513 23:12:59.380603 22392998065984 run_lib.py:167] step: 26400, eval_loss: 6.08377e-02
I0513 23:13:22.625689 22392998065984 run_lib.py:146] step: 26450, training_loss: 6.99310e-02
I0513 23:13:46.149998 22392998065984 run_lib.py:146] step: 26500, training_loss: 6.12009e-02
I0513 23:13:46.306331 22392998065984 run_lib.py:167] step: 26500, eval_loss: 5.58470e-02
I0513 23:14:09.848394 22392998065984 run_lib.py:146] step: 26550, training_loss: 7.02425e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:14:33.224524 22392998065984 run_lib.py:146] step: 26600, training_loss: 4.68888e-02
I0513 23:14:33.382485 22392998065984 run_lib.py:167] step: 26600, eval_loss: 5.91575e-02
I0513 23:14:56.985356 22392998065984 run_lib.py:146] step: 26650, training_loss: 6.46168e-02
I0513 23:15:20.567831 22392998065984 run_lib.py:146] step: 26700, training_loss: 5.24412e-02
I0513 23:15:20.724176 22392998065984 run_lib.py:167] step: 26700, eval_loss: 6.42215e-02
I0513 23:15:43.948275 22392998065984 run_lib.py:146] step: 26750, training_loss: 6.94791e-02
I0513 23:16:07.491620 22392998065984 run_lib.py:146] step: 26800, training_loss: 6.27560e-02
I0513 23:16:07.648288 22392998065984 run_lib.py:167] step: 26800, eval_loss: 5.27757e-02
I0513 23:16:31.194520 22392998065984 run_lib.py:146] step: 26850, training_loss: 4.98900e-02
I0513 23:16:54.460624 22392998065984 run_lib.py:146] step: 26900, training_loss: 5.82793e-02
I0513 23:16:54.617076 22392998065984 run_lib.py:167] step: 26900, eval_loss: 7.30181e-02
I0513 23:17:17.881613 22392998065984 run_lib.py:146] step: 26950, training_loss: 7.21114e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:17:41.926434 22392998065984 run_lib.py:146] step: 27000, training_loss: 6.26596e-02
I0513 23:17:42.084070 22392998065984 run_lib.py:167] step: 27000, eval_loss: 5.81664e-02
I0513 23:18:05.343609 22392998065984 run_lib.py:146] step: 27050, training_loss: 5.11477e-02
I0513 23:18:28.601192 22392998065984 run_lib.py:146] step: 27100, training_loss: 5.42778e-02
I0513 23:18:28.757473 22392998065984 run_lib.py:167] step: 27100, eval_loss: 5.82752e-02
I0513 23:18:52.643529 22392998065984 run_lib.py:146] step: 27150, training_loss: 5.75439e-02
I0513 23:19:15.902488 22392998065984 run_lib.py:146] step: 27200, training_loss: 8.33285e-02
I0513 23:19:16.059037 22392998065984 run_lib.py:167] step: 27200, eval_loss: 7.68020e-02
I0513 23:19:39.309577 22392998065984 run_lib.py:146] step: 27250, training_loss: 7.00960e-02
I0513 23:20:02.867184 22392998065984 run_lib.py:146] step: 27300, training_loss: 6.29797e-02
I0513 23:20:03.023641 22392998065984 run_lib.py:167] step: 27300, eval_loss: 7.14303e-02
I0513 23:20:26.554984 22392998065984 run_lib.py:146] step: 27350, training_loss: 4.94528e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:20:49.953702 22392998065984 run_lib.py:146] step: 27400, training_loss: 5.43679e-02
I0513 23:20:50.111729 22392998065984 run_lib.py:167] step: 27400, eval_loss: 4.66604e-02
I0513 23:21:13.678549 22392998065984 run_lib.py:146] step: 27450, training_loss: 4.78828e-02
I0513 23:21:37.274622 22392998065984 run_lib.py:146] step: 27500, training_loss: 6.34562e-02
I0513 23:21:37.430936 22392998065984 run_lib.py:167] step: 27500, eval_loss: 4.69054e-02
I0513 23:22:01.279559 22392998065984 run_lib.py:146] step: 27550, training_loss: 6.46581e-02
I0513 23:22:25.431603 22392998065984 run_lib.py:146] step: 27600, training_loss: 6.62428e-02
I0513 23:22:25.587671 22392998065984 run_lib.py:167] step: 27600, eval_loss: 5.88902e-02
I0513 23:22:49.719270 22392998065984 run_lib.py:146] step: 27650, training_loss: 6.24393e-02
I0513 23:23:13.577061 22392998065984 run_lib.py:146] step: 27700, training_loss: 8.28960e-02
I0513 23:23:13.733566 22392998065984 run_lib.py:167] step: 27700, eval_loss: 6.75885e-02
I0513 23:23:37.922006 22392998065984 run_lib.py:146] step: 27750, training_loss: 6.86415e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:24:01.850427 22392998065984 run_lib.py:146] step: 27800, training_loss: 8.05158e-02
I0513 23:24:02.007815 22392998065984 run_lib.py:167] step: 27800, eval_loss: 5.72083e-02
I0513 23:24:25.259050 22392998065984 run_lib.py:146] step: 27850, training_loss: 7.52312e-02
I0513 23:24:48.502099 22392998065984 run_lib.py:146] step: 27900, training_loss: 7.22676e-02
I0513 23:24:48.658317 22392998065984 run_lib.py:167] step: 27900, eval_loss: 5.02972e-02
I0513 23:25:12.554041 22392998065984 run_lib.py:146] step: 27950, training_loss: 5.53585e-02
I0513 23:25:35.790356 22392998065984 run_lib.py:146] step: 28000, training_loss: 7.46813e-02
I0513 23:25:35.947112 22392998065984 run_lib.py:167] step: 28000, eval_loss: 6.87148e-02
I0513 23:25:59.197198 22392998065984 run_lib.py:146] step: 28050, training_loss: 4.71011e-02
I0513 23:26:22.746109 22392998065984 run_lib.py:146] step: 28100, training_loss: 7.38425e-02
I0513 23:26:22.902088 22392998065984 run_lib.py:167] step: 28100, eval_loss: 7.13221e-02
I0513 23:26:46.443412 22392998065984 run_lib.py:146] step: 28150, training_loss: 6.39014e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:27:09.857678 22392998065984 run_lib.py:146] step: 28200, training_loss: 4.29346e-02
I0513 23:27:10.015678 22392998065984 run_lib.py:167] step: 28200, eval_loss: 6.31866e-02
I0513 23:27:33.617954 22392998065984 run_lib.py:146] step: 28250, training_loss: 5.03947e-02
I0513 23:27:57.211264 22392998065984 run_lib.py:146] step: 28300, training_loss: 6.74865e-02
I0513 23:27:57.367403 22392998065984 run_lib.py:167] step: 28300, eval_loss: 5.14589e-02
I0513 23:28:20.615900 22392998065984 run_lib.py:146] step: 28350, training_loss: 5.36459e-02
I0513 23:28:44.174964 22392998065984 run_lib.py:146] step: 28400, training_loss: 8.74034e-02
I0513 23:28:44.331549 22392998065984 run_lib.py:167] step: 28400, eval_loss: 7.37369e-02
I0513 23:29:07.899331 22392998065984 run_lib.py:146] step: 28450, training_loss: 6.46441e-02
I0513 23:29:31.163282 22392998065984 run_lib.py:146] step: 28500, training_loss: 5.85244e-02
I0513 23:29:31.319852 22392998065984 run_lib.py:167] step: 28500, eval_loss: 6.57509e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:29:55.090356 22392998065984 run_lib.py:146] step: 28550, training_loss: 6.64806e-02
I0513 23:30:18.690103 22392998065984 run_lib.py:146] step: 28600, training_loss: 4.88099e-02
I0513 23:30:18.847234 22392998065984 run_lib.py:167] step: 28600, eval_loss: 5.77489e-02
I0513 23:30:42.118220 22392998065984 run_lib.py:146] step: 28650, training_loss: 8.45262e-02
I0513 23:31:05.378058 22392998065984 run_lib.py:146] step: 28700, training_loss: 6.78552e-02
I0513 23:31:05.534900 22392998065984 run_lib.py:167] step: 28700, eval_loss: 5.17403e-02
I0513 23:31:29.387425 22392998065984 run_lib.py:146] step: 28750, training_loss: 6.13548e-02
I0513 23:31:52.642022 22392998065984 run_lib.py:146] step: 28800, training_loss: 7.43900e-02
I0513 23:31:52.798152 22392998065984 run_lib.py:167] step: 28800, eval_loss: 5.63954e-02
I0513 23:32:16.032539 22392998065984 run_lib.py:146] step: 28850, training_loss: 6.94845e-02
I0513 23:32:39.600286 22392998065984 run_lib.py:146] step: 28900, training_loss: 5.77801e-02
I0513 23:32:39.757524 22392998065984 run_lib.py:167] step: 28900, eval_loss: 9.20584e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:33:03.459690 22392998065984 run_lib.py:146] step: 28950, training_loss: 6.34914e-02
I0513 23:33:26.751397 22392998065984 run_lib.py:146] step: 29000, training_loss: 6.16389e-02
I0513 23:33:26.909465 22392998065984 run_lib.py:167] step: 29000, eval_loss: 7.32524e-02
I0513 23:33:50.491153 22392998065984 run_lib.py:146] step: 29050, training_loss: 6.34948e-02
I0513 23:34:14.075800 22392998065984 run_lib.py:146] step: 29100, training_loss: 5.37190e-02
I0513 23:34:14.232134 22392998065984 run_lib.py:167] step: 29100, eval_loss: 5.21253e-02
I0513 23:34:37.483746 22392998065984 run_lib.py:146] step: 29150, training_loss: 6.13002e-02
I0513 23:35:01.047894 22392998065984 run_lib.py:146] step: 29200, training_loss: 4.84059e-02
I0513 23:35:01.204268 22392998065984 run_lib.py:167] step: 29200, eval_loss: 6.35271e-02
I0513 23:35:24.780474 22392998065984 run_lib.py:146] step: 29250, training_loss: 7.14985e-02
I0513 23:35:48.067569 22392998065984 run_lib.py:146] step: 29300, training_loss: 6.54853e-02
I0513 23:35:48.223822 22392998065984 run_lib.py:167] step: 29300, eval_loss: 7.56196e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:36:12.284348 22392998065984 run_lib.py:146] step: 29350, training_loss: 7.04045e-02
I0513 23:36:35.995722 22392998065984 run_lib.py:146] step: 29400, training_loss: 4.75075e-02
I0513 23:36:36.152908 22392998065984 run_lib.py:167] step: 29400, eval_loss: 4.55553e-02
I0513 23:36:59.395478 22392998065984 run_lib.py:146] step: 29450, training_loss: 5.57514e-02
I0513 23:37:22.653094 22392998065984 run_lib.py:146] step: 29500, training_loss: 6.04098e-02
I0513 23:37:22.809090 22392998065984 run_lib.py:167] step: 29500, eval_loss: 6.23108e-02
I0513 23:37:46.637224 22392998065984 run_lib.py:146] step: 29550, training_loss: 5.00881e-02
I0513 23:38:09.870212 22392998065984 run_lib.py:146] step: 29600, training_loss: 4.77584e-02
I0513 23:38:10.026109 22392998065984 run_lib.py:167] step: 29600, eval_loss: 4.83259e-02
I0513 23:38:33.264596 22392998065984 run_lib.py:146] step: 29650, training_loss: 7.99433e-02
I0513 23:38:56.820509 22392998065984 run_lib.py:146] step: 29700, training_loss: 6.22477e-02
I0513 23:38:57.250061 22392998065984 run_lib.py:167] step: 29700, eval_loss: 5.86633e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:39:20.654231 22392998065984 run_lib.py:146] step: 29750, training_loss: 4.49088e-02
I0513 23:39:43.894779 22392998065984 run_lib.py:146] step: 29800, training_loss: 6.50866e-02
I0513 23:39:44.052396 22392998065984 run_lib.py:167] step: 29800, eval_loss: 7.10443e-02
I0513 23:40:07.662003 22392998065984 run_lib.py:146] step: 29850, training_loss: 6.33399e-02
I0513 23:40:31.248145 22392998065984 run_lib.py:146] step: 29900, training_loss: 5.46643e-02
I0513 23:40:31.404480 22392998065984 run_lib.py:167] step: 29900, eval_loss: 5.22801e-02
I0513 23:40:54.658282 22392998065984 run_lib.py:146] step: 29950, training_loss: 7.35921e-02
I0513 23:41:18.193546 22392998065984 run_lib.py:146] step: 30000, training_loss: 4.46625e-02
I0513 23:41:20.211170 22392998065984 run_lib.py:167] step: 30000, eval_loss: 5.86027e-02
I0513 23:41:44.972993 22392998065984 run_lib.py:146] step: 30050, training_loss: 7.28535e-02
I0513 23:42:08.245782 22392998065984 run_lib.py:146] step: 30100, training_loss: 6.23183e-02
I0513 23:42:08.402039 22392998065984 run_lib.py:167] step: 30100, eval_loss: 5.28266e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:42:32.827319 22392998065984 run_lib.py:146] step: 30150, training_loss: 8.30497e-02
I0513 23:42:56.091278 22392998065984 run_lib.py:146] step: 30200, training_loss: 6.51133e-02
I0513 23:42:56.248626 22392998065984 run_lib.py:167] step: 30200, eval_loss: 5.51127e-02
I0513 23:43:19.494222 22392998065984 run_lib.py:146] step: 30250, training_loss: 8.59991e-02
I0513 23:43:43.044833 22392998065984 run_lib.py:146] step: 30300, training_loss: 5.18301e-02
I0513 23:43:43.200947 22392998065984 run_lib.py:167] step: 30300, eval_loss: 6.14477e-02
I0513 23:44:06.739772 22392998065984 run_lib.py:146] step: 30350, training_loss: 7.34628e-02
I0513 23:44:29.982351 22392998065984 run_lib.py:146] step: 30400, training_loss: 6.36793e-02
I0513 23:44:30.138748 22392998065984 run_lib.py:167] step: 30400, eval_loss: 4.88685e-02
I0513 23:44:53.398500 22392998065984 run_lib.py:146] step: 30450, training_loss: 5.93250e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:45:17.081271 22392998065984 run_lib.py:146] step: 30500, training_loss: 5.28093e-02
I0513 23:45:17.239415 22392998065984 run_lib.py:167] step: 30500, eval_loss: 4.75182e-02
I0513 23:45:40.489799 22392998065984 run_lib.py:146] step: 30550, training_loss: 7.24299e-02
I0513 23:46:03.739403 22392998065984 run_lib.py:146] step: 30600, training_loss: 6.04382e-02
I0513 23:46:03.896129 22392998065984 run_lib.py:167] step: 30600, eval_loss: 6.66346e-02
I0513 23:46:27.820530 22392998065984 run_lib.py:146] step: 30650, training_loss: 6.16698e-02
I0513 23:46:51.075408 22392998065984 run_lib.py:146] step: 30700, training_loss: 6.82874e-02
I0513 23:46:51.232437 22392998065984 run_lib.py:167] step: 30700, eval_loss: 6.32042e-02
I0513 23:47:14.474040 22392998065984 run_lib.py:146] step: 30750, training_loss: 5.55148e-02
I0513 23:47:38.321806 22392998065984 run_lib.py:146] step: 30800, training_loss: 6.30490e-02
I0513 23:47:38.477998 22392998065984 run_lib.py:167] step: 30800, eval_loss: 7.97915e-02
I0513 23:48:01.723645 22392998065984 run_lib.py:146] step: 30850, training_loss: 9.11864e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:48:25.112464 22392998065984 run_lib.py:146] step: 30900, training_loss: 7.07497e-02
I0513 23:48:25.270615 22392998065984 run_lib.py:167] step: 30900, eval_loss: 6.45728e-02
I0513 23:48:48.900390 22392998065984 run_lib.py:146] step: 30950, training_loss: 5.82037e-02
I0513 23:49:12.163963 22392998065984 run_lib.py:146] step: 31000, training_loss: 6.72692e-02
I0513 23:49:12.320202 22392998065984 run_lib.py:167] step: 31000, eval_loss: 6.86677e-02
I0513 23:49:35.579971 22392998065984 run_lib.py:146] step: 31050, training_loss: 6.56309e-02
I0513 23:49:59.163984 22392998065984 run_lib.py:146] step: 31100, training_loss: 7.97188e-02
I0513 23:49:59.320117 22392998065984 run_lib.py:167] step: 31100, eval_loss: 6.06827e-02
I0513 23:50:22.577914 22392998065984 run_lib.py:146] step: 31150, training_loss: 5.70326e-02
I0513 23:50:45.832959 22392998065984 run_lib.py:146] step: 31200, training_loss: 5.67816e-02
I0513 23:50:45.990021 22392998065984 run_lib.py:167] step: 31200, eval_loss: 5.47509e-02
I0513 23:51:09.247913 22392998065984 run_lib.py:146] step: 31250, training_loss: 5.60572e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:51:33.282706 22392998065984 run_lib.py:146] step: 31300, training_loss: 6.26439e-02
I0513 23:51:33.440698 22392998065984 run_lib.py:167] step: 31300, eval_loss: 5.27077e-02
I0513 23:51:56.693346 22392998065984 run_lib.py:146] step: 31350, training_loss: 4.97499e-02
I0513 23:52:19.933592 22392998065984 run_lib.py:146] step: 31400, training_loss: 7.56862e-02
I0513 23:52:20.089260 22392998065984 run_lib.py:167] step: 31400, eval_loss: 5.46942e-02
I0513 23:52:43.668533 22392998065984 run_lib.py:146] step: 31450, training_loss: 6.90390e-02
I0513 23:53:06.920814 22392998065984 run_lib.py:146] step: 31500, training_loss: 6.60965e-02
I0513 23:53:07.001690 22392998065984 run_lib.py:167] step: 31500, eval_loss: 4.70735e-02
I0513 23:53:30.243695 22392998065984 run_lib.py:146] step: 31550, training_loss: 5.92537e-02
I0513 23:53:54.084658 22392998065984 run_lib.py:146] step: 31600, training_loss: 8.32103e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:53:54.453643 22392998065984 run_lib.py:167] step: 31600, eval_loss: 9.20558e-02
I0513 23:54:17.784687 22392998065984 run_lib.py:146] step: 31650, training_loss: 7.85729e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:54:41.185071 22392998065984 run_lib.py:146] step: 31700, training_loss: 6.85096e-02
I0513 23:54:41.342893 22392998065984 run_lib.py:167] step: 31700, eval_loss: 5.49878e-02
I0513 23:55:05.286042 22392998065984 run_lib.py:146] step: 31750, training_loss: 7.01295e-02
I0513 23:55:28.535065 22392998065984 run_lib.py:146] step: 31800, training_loss: 7.68626e-02
I0513 23:55:28.691176 22392998065984 run_lib.py:167] step: 31800, eval_loss: 7.48294e-02
I0513 23:55:51.941470 22392998065984 run_lib.py:146] step: 31850, training_loss: 6.10671e-02
I0513 23:56:15.790489 22392998065984 run_lib.py:146] step: 31900, training_loss: 6.94566e-02
I0513 23:56:15.948277 22392998065984 run_lib.py:167] step: 31900, eval_loss: 5.74549e-02
I0513 23:56:39.194896 22392998065984 run_lib.py:146] step: 31950, training_loss: 5.92009e-02
I0513 23:57:02.444978 22392998065984 run_lib.py:146] step: 32000, training_loss: 5.03215e-02
I0513 23:57:02.601527 22392998065984 run_lib.py:167] step: 32000, eval_loss: 5.97362e-02
I0513 23:57:25.867501 22392998065984 run_lib.py:146] step: 32050, training_loss: 5.59910e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0513 23:57:50.317831 22392998065984 run_lib.py:146] step: 32100, training_loss: 6.58629e-02
I0513 23:57:50.476270 22392998065984 run_lib.py:167] step: 32100, eval_loss: 7.16579e-02
I0513 23:58:14.341920 22392998065984 run_lib.py:146] step: 32150, training_loss: 6.39160e-02
I0513 23:58:38.247520 22392998065984 run_lib.py:146] step: 32200, training_loss: 5.20125e-02
I0513 23:58:38.403963 22392998065984 run_lib.py:167] step: 32200, eval_loss: 4.79169e-02
I0513 23:59:02.908983 22392998065984 run_lib.py:146] step: 32250, training_loss: 6.50773e-02
I0513 23:59:26.676965 22392998065984 run_lib.py:146] step: 32300, training_loss: 6.64277e-02
I0513 23:59:26.833614 22392998065984 run_lib.py:167] step: 32300, eval_loss: 7.90147e-02
I0513 23:59:50.074699 22392998065984 run_lib.py:146] step: 32350, training_loss: 5.80543e-02
I0514 00:00:13.927828 22392998065984 run_lib.py:146] step: 32400, training_loss: 7.14045e-02
I0514 00:00:14.083948 22392998065984 run_lib.py:167] step: 32400, eval_loss: 8.27112e-02
I0514 00:00:37.335950 22392998065984 run_lib.py:146] step: 32450, training_loss: 7.24242e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:01:01.218077 22392998065984 run_lib.py:146] step: 32500, training_loss: 6.71059e-02
I0514 00:01:01.376130 22392998065984 run_lib.py:167] step: 32500, eval_loss: 5.84743e-02
I0514 00:01:25.319765 22392998065984 run_lib.py:146] step: 32550, training_loss: 7.57553e-02
I0514 00:01:48.570743 22392998065984 run_lib.py:146] step: 32600, training_loss: 4.71935e-02
I0514 00:01:48.727114 22392998065984 run_lib.py:167] step: 32600, eval_loss: 5.08693e-02
I0514 00:02:11.985282 22392998065984 run_lib.py:146] step: 32650, training_loss: 7.33160e-02
I0514 00:02:35.827036 22392998065984 run_lib.py:146] step: 32700, training_loss: 5.25181e-02
I0514 00:02:35.983408 22392998065984 run_lib.py:167] step: 32700, eval_loss: 8.34105e-02
I0514 00:02:59.247463 22392998065984 run_lib.py:146] step: 32750, training_loss: 7.54721e-02
I0514 00:03:22.507996 22392998065984 run_lib.py:146] step: 32800, training_loss: 4.30923e-02
I0514 00:03:22.664240 22392998065984 run_lib.py:167] step: 32800, eval_loss: 6.78402e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:03:46.336334 22392998065984 run_lib.py:146] step: 32850, training_loss: 7.19450e-02
I0514 00:04:09.938824 22392998065984 run_lib.py:146] step: 32900, training_loss: 5.96675e-02
I0514 00:04:10.096009 22392998065984 run_lib.py:167] step: 32900, eval_loss: 7.20659e-02
I0514 00:04:33.511537 22392998065984 run_lib.py:146] step: 32950, training_loss: 5.75862e-02
I0514 00:04:57.247092 22392998065984 run_lib.py:146] step: 33000, training_loss: 5.37977e-02
I0514 00:04:57.403723 22392998065984 run_lib.py:167] step: 33000, eval_loss: 5.97584e-02
I0514 00:05:21.737201 22392998065984 run_lib.py:146] step: 33050, training_loss: 5.72358e-02
I0514 00:05:44.986918 22392998065984 run_lib.py:146] step: 33100, training_loss: 7.71896e-02
I0514 00:05:45.143508 22392998065984 run_lib.py:167] step: 33100, eval_loss: 7.01046e-02
I0514 00:06:08.416372 22392998065984 run_lib.py:146] step: 33150, training_loss: 7.03096e-02
I0514 00:06:32.264070 22392998065984 run_lib.py:146] step: 33200, training_loss: 6.27556e-02
I0514 00:06:32.419984 22392998065984 run_lib.py:167] step: 33200, eval_loss: 4.99598e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:06:55.934612 22392998065984 run_lib.py:146] step: 33250, training_loss: 5.61325e-02
I0514 00:07:19.664444 22392998065984 run_lib.py:146] step: 33300, training_loss: 6.75470e-02
I0514 00:07:19.822399 22392998065984 run_lib.py:167] step: 33300, eval_loss: 5.20488e-02
I0514 00:07:44.227131 22392998065984 run_lib.py:146] step: 33350, training_loss: 6.80108e-02
I0514 00:08:07.960504 22392998065984 run_lib.py:146] step: 33400, training_loss: 5.22147e-02
I0514 00:08:08.116944 22392998065984 run_lib.py:167] step: 33400, eval_loss: 5.71158e-02
I0514 00:08:31.858029 22392998065984 run_lib.py:146] step: 33450, training_loss: 4.83492e-02
I0514 00:08:56.168479 22392998065984 run_lib.py:146] step: 33500, training_loss: 4.71605e-02
I0514 00:08:56.324665 22392998065984 run_lib.py:167] step: 33500, eval_loss: 7.53731e-02
I0514 00:09:20.075431 22392998065984 run_lib.py:146] step: 33550, training_loss: 6.74509e-02
I0514 00:09:43.654217 22392998065984 run_lib.py:146] step: 33600, training_loss: 6.37488e-02
I0514 00:09:43.810630 22392998065984 run_lib.py:167] step: 33600, eval_loss: 4.78404e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:10:07.537913 22392998065984 run_lib.py:146] step: 33650, training_loss: 5.06586e-02
I0514 00:10:31.140877 22392998065984 run_lib.py:146] step: 33700, training_loss: 6.08407e-02
I0514 00:10:31.298549 22392998065984 run_lib.py:167] step: 33700, eval_loss: 5.71058e-02
I0514 00:10:54.548212 22392998065984 run_lib.py:146] step: 33750, training_loss: 6.83255e-02
I0514 00:11:18.512092 22392998065984 run_lib.py:146] step: 33800, training_loss: 8.09156e-02
I0514 00:11:18.668319 22392998065984 run_lib.py:167] step: 33800, eval_loss: 7.26338e-02
I0514 00:11:42.678383 22392998065984 run_lib.py:146] step: 33850, training_loss: 5.11109e-02
I0514 00:12:06.406604 22392998065984 run_lib.py:146] step: 33900, training_loss: 6.33849e-02
I0514 00:12:06.563035 22392998065984 run_lib.py:167] step: 33900, eval_loss: 4.88378e-02
I0514 00:12:30.313340 22392998065984 run_lib.py:146] step: 33950, training_loss: 7.39264e-02
I0514 00:12:54.627030 22392998065984 run_lib.py:146] step: 34000, training_loss: 7.10567e-02
I0514 00:12:54.783607 22392998065984 run_lib.py:167] step: 34000, eval_loss: 6.24077e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:13:18.359100 22392998065984 run_lib.py:146] step: 34050, training_loss: 6.71028e-02
I0514 00:13:41.609713 22392998065984 run_lib.py:146] step: 34100, training_loss: 5.62083e-02
I0514 00:13:41.767163 22392998065984 run_lib.py:167] step: 34100, eval_loss: 7.39453e-02
I0514 00:14:05.739426 22392998065984 run_lib.py:146] step: 34150, training_loss: 5.83175e-02
I0514 00:14:29.008018 22392998065984 run_lib.py:146] step: 34200, training_loss: 6.66148e-02
I0514 00:14:29.164380 22392998065984 run_lib.py:167] step: 34200, eval_loss: 6.55425e-02
I0514 00:14:52.441342 22392998065984 run_lib.py:146] step: 34250, training_loss: 5.88535e-02
I0514 00:15:16.294696 22392998065984 run_lib.py:146] step: 34300, training_loss: 7.93690e-02
I0514 00:15:16.451272 22392998065984 run_lib.py:167] step: 34300, eval_loss: 5.78925e-02
I0514 00:15:39.703801 22392998065984 run_lib.py:146] step: 34350, training_loss: 8.23929e-02
I0514 00:16:02.953725 22392998065984 run_lib.py:146] step: 34400, training_loss: 6.60942e-02
I0514 00:16:03.110281 22392998065984 run_lib.py:167] step: 34400, eval_loss: 6.90685e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:16:27.256056 22392998065984 run_lib.py:146] step: 34450, training_loss: 7.48236e-02
I0514 00:16:51.261724 22392998065984 run_lib.py:146] step: 34500, training_loss: 6.93730e-02
I0514 00:16:51.419525 22392998065984 run_lib.py:167] step: 34500, eval_loss: 6.54557e-02
I0514 00:17:14.695284 22392998065984 run_lib.py:146] step: 34550, training_loss: 6.32111e-02
I0514 00:17:37.973516 22392998065984 run_lib.py:146] step: 34600, training_loss: 8.68115e-02
I0514 00:17:38.129874 22392998065984 run_lib.py:167] step: 34600, eval_loss: 5.93016e-02
I0514 00:18:01.980351 22392998065984 run_lib.py:146] step: 34650, training_loss: 5.46207e-02
I0514 00:18:25.241832 22392998065984 run_lib.py:146] step: 34700, training_loss: 4.94978e-02
I0514 00:18:25.398397 22392998065984 run_lib.py:167] step: 34700, eval_loss: 6.57983e-02
I0514 00:18:48.663769 22392998065984 run_lib.py:146] step: 34750, training_loss: 5.32308e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:19:12.671291 22392998065984 run_lib.py:146] step: 34800, training_loss: 5.45569e-02
I0514 00:19:12.829719 22392998065984 run_lib.py:167] step: 34800, eval_loss: 7.02991e-02
I0514 00:19:36.083043 22392998065984 run_lib.py:146] step: 34850, training_loss: 5.33301e-02
I0514 00:19:59.346875 22392998065984 run_lib.py:146] step: 34900, training_loss: 6.26384e-02
I0514 00:19:59.503133 22392998065984 run_lib.py:167] step: 34900, eval_loss: 4.61164e-02
I0514 00:20:23.433374 22392998065984 run_lib.py:146] step: 34950, training_loss: 6.19291e-02
I0514 00:20:46.696741 22392998065984 run_lib.py:146] step: 35000, training_loss: 6.01753e-02
I0514 00:20:46.853269 22392998065984 run_lib.py:167] step: 35000, eval_loss: 4.39231e-02
I0514 00:21:10.121297 22392998065984 run_lib.py:146] step: 35050, training_loss: 6.67096e-02
I0514 00:21:33.962776 22392998065984 run_lib.py:146] step: 35100, training_loss: 5.32193e-02
I0514 00:21:34.118977 22392998065984 run_lib.py:167] step: 35100, eval_loss: 5.98991e-02
I0514 00:21:57.378165 22392998065984 run_lib.py:146] step: 35150, training_loss: 7.75325e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:22:20.773059 22392998065984 run_lib.py:146] step: 35200, training_loss: 5.79575e-02
I0514 00:22:20.931399 22392998065984 run_lib.py:167] step: 35200, eval_loss: 5.56548e-02
I0514 00:22:44.524046 22392998065984 run_lib.py:146] step: 35250, training_loss: 5.51538e-02
I0514 00:23:08.122641 22392998065984 run_lib.py:146] step: 35300, training_loss: 5.69283e-02
I0514 00:23:08.278973 22392998065984 run_lib.py:167] step: 35300, eval_loss: 5.51528e-02
I0514 00:23:31.547748 22392998065984 run_lib.py:146] step: 35350, training_loss: 6.34596e-02
I0514 00:23:54.815799 22392998065984 run_lib.py:146] step: 35400, training_loss: 6.08137e-02
I0514 00:23:54.972189 22392998065984 run_lib.py:167] step: 35400, eval_loss: 6.38306e-02
I0514 00:24:18.819206 22392998065984 run_lib.py:146] step: 35450, training_loss: 6.62810e-02
I0514 00:24:42.407904 22392998065984 run_lib.py:146] step: 35500, training_loss: 6.58947e-02
I0514 00:24:42.564516 22392998065984 run_lib.py:167] step: 35500, eval_loss: 6.79956e-02
I0514 00:25:06.302565 22392998065984 run_lib.py:146] step: 35550, training_loss: 6.22619e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:25:30.595949 22392998065984 run_lib.py:146] step: 35600, training_loss: 4.10517e-02
I0514 00:25:30.754023 22392998065984 run_lib.py:167] step: 35600, eval_loss: 7.22994e-02
I0514 00:25:54.033962 22392998065984 run_lib.py:146] step: 35650, training_loss: 4.61064e-02
I0514 00:26:17.310961 22392998065984 run_lib.py:146] step: 35700, training_loss: 6.83480e-02
I0514 00:26:17.467133 22392998065984 run_lib.py:167] step: 35700, eval_loss: 6.08617e-02
I0514 00:26:41.397931 22392998065984 run_lib.py:146] step: 35750, training_loss: 5.64662e-02
I0514 00:27:04.657525 22392998065984 run_lib.py:146] step: 35800, training_loss: 6.12904e-02
I0514 00:27:04.813758 22392998065984 run_lib.py:167] step: 35800, eval_loss: 4.04007e-02
I0514 00:27:28.071569 22392998065984 run_lib.py:146] step: 35850, training_loss: 5.53809e-02
I0514 00:27:51.926966 22392998065984 run_lib.py:146] step: 35900, training_loss: 8.56177e-02
I0514 00:27:52.083043 22392998065984 run_lib.py:167] step: 35900, eval_loss: 6.34468e-02
I0514 00:28:15.331296 22392998065984 run_lib.py:146] step: 35950, training_loss: 6.36147e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:28:38.718808 22392998065984 run_lib.py:146] step: 36000, training_loss: 6.60837e-02
I0514 00:28:38.876815 22392998065984 run_lib.py:167] step: 36000, eval_loss: 7.45931e-02
I0514 00:29:02.473299 22392998065984 run_lib.py:146] step: 36050, training_loss: 6.45737e-02
I0514 00:29:26.042215 22392998065984 run_lib.py:146] step: 36100, training_loss: 5.03857e-02
I0514 00:29:26.198295 22392998065984 run_lib.py:167] step: 36100, eval_loss: 7.33205e-02
I0514 00:29:49.428520 22392998065984 run_lib.py:146] step: 36150, training_loss: 9.07258e-02
I0514 00:30:12.659163 22392998065984 run_lib.py:146] step: 36200, training_loss: 5.78496e-02
I0514 00:30:12.815191 22392998065984 run_lib.py:167] step: 36200, eval_loss: 5.68398e-02
I0514 00:30:36.615544 22392998065984 run_lib.py:146] step: 36250, training_loss: 5.22887e-02
I0514 00:30:59.858477 22392998065984 run_lib.py:146] step: 36300, training_loss: 6.43452e-02
I0514 00:31:00.015491 22392998065984 run_lib.py:167] step: 36300, eval_loss: 6.38175e-02
I0514 00:31:23.257061 22392998065984 run_lib.py:146] step: 36350, training_loss: 6.25660e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:31:47.329410 22392998065984 run_lib.py:146] step: 36400, training_loss: 7.06412e-02
I0514 00:31:47.486796 22392998065984 run_lib.py:167] step: 36400, eval_loss: 6.35267e-02
I0514 00:32:10.729101 22392998065984 run_lib.py:146] step: 36450, training_loss: 4.60174e-02
I0514 00:32:33.974840 22392998065984 run_lib.py:146] step: 36500, training_loss: 8.40683e-02
I0514 00:32:34.131131 22392998065984 run_lib.py:167] step: 36500, eval_loss: 5.38951e-02
I0514 00:32:57.961963 22392998065984 run_lib.py:146] step: 36550, training_loss: 5.42073e-02
I0514 00:33:21.208657 22392998065984 run_lib.py:146] step: 36600, training_loss: 7.34273e-02
I0514 00:33:21.365262 22392998065984 run_lib.py:167] step: 36600, eval_loss: 4.97295e-02
I0514 00:33:44.598550 22392998065984 run_lib.py:146] step: 36650, training_loss: 7.24337e-02
I0514 00:34:08.462572 22392998065984 run_lib.py:146] step: 36700, training_loss: 6.70076e-02
I0514 00:34:08.618951 22392998065984 run_lib.py:167] step: 36700, eval_loss: 5.65137e-02
I0514 00:34:32.035825 22392998065984 run_lib.py:146] step: 36750, training_loss: 5.57783e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:34:55.485826 22392998065984 run_lib.py:146] step: 36800, training_loss: 6.16785e-02
I0514 00:34:55.643812 22392998065984 run_lib.py:167] step: 36800, eval_loss: 6.98251e-02
I0514 00:35:19.240840 22392998065984 run_lib.py:146] step: 36850, training_loss: 6.42313e-02
I0514 00:35:42.830283 22392998065984 run_lib.py:146] step: 36900, training_loss: 6.69641e-02
I0514 00:35:42.986972 22392998065984 run_lib.py:167] step: 36900, eval_loss: 4.91570e-02
I0514 00:36:06.235018 22392998065984 run_lib.py:146] step: 36950, training_loss: 6.17074e-02
I0514 00:36:29.500105 22392998065984 run_lib.py:146] step: 37000, training_loss: 6.23709e-02
I0514 00:36:29.656380 22392998065984 run_lib.py:167] step: 37000, eval_loss: 7.02314e-02
I0514 00:36:53.490345 22392998065984 run_lib.py:146] step: 37050, training_loss: 7.26254e-02
I0514 00:37:16.744424 22392998065984 run_lib.py:146] step: 37100, training_loss: 6.10538e-02
I0514 00:37:16.900866 22392998065984 run_lib.py:167] step: 37100, eval_loss: 5.82510e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:37:40.285979 22392998065984 run_lib.py:146] step: 37150, training_loss: 6.10074e-02
I0514 00:38:04.217783 22392998065984 run_lib.py:146] step: 37200, training_loss: 7.69636e-02
I0514 00:38:04.375561 22392998065984 run_lib.py:167] step: 37200, eval_loss: 9.22537e-02
I0514 00:38:27.632619 22392998065984 run_lib.py:146] step: 37250, training_loss: 4.66682e-02
I0514 00:38:50.897858 22392998065984 run_lib.py:146] step: 37300, training_loss: 5.68728e-02
I0514 00:38:51.054402 22392998065984 run_lib.py:167] step: 37300, eval_loss: 5.78490e-02
I0514 00:39:14.902139 22392998065984 run_lib.py:146] step: 37350, training_loss: 7.27141e-02
I0514 00:39:38.144234 22392998065984 run_lib.py:146] step: 37400, training_loss: 8.25775e-02
I0514 00:39:38.300240 22392998065984 run_lib.py:167] step: 37400, eval_loss: 5.08640e-02
I0514 00:40:01.546693 22392998065984 run_lib.py:146] step: 37450, training_loss: 5.82846e-02
I0514 00:40:25.386680 22392998065984 run_lib.py:146] step: 37500, training_loss: 8.96535e-02
I0514 00:40:25.542671 22392998065984 run_lib.py:167] step: 37500, eval_loss: 5.30351e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:40:48.940057 22392998065984 run_lib.py:146] step: 37550, training_loss: 5.54420e-02
I0514 00:41:12.195574 22392998065984 run_lib.py:146] step: 37600, training_loss: 4.78624e-02
I0514 00:41:12.352988 22392998065984 run_lib.py:167] step: 37600, eval_loss: 5.53282e-02
I0514 00:41:36.408556 22392998065984 run_lib.py:146] step: 37650, training_loss: 7.21253e-02
I0514 00:42:00.153168 22392998065984 run_lib.py:146] step: 37700, training_loss: 5.77298e-02
I0514 00:42:00.310089 22392998065984 run_lib.py:167] step: 37700, eval_loss: 6.67973e-02
I0514 00:42:23.898594 22392998065984 run_lib.py:146] step: 37750, training_loss: 7.81732e-02
I0514 00:42:47.148740 22392998065984 run_lib.py:146] step: 37800, training_loss: 5.64702e-02
I0514 00:42:47.304984 22392998065984 run_lib.py:167] step: 37800, eval_loss: 5.71633e-02
I0514 00:43:11.136272 22392998065984 run_lib.py:146] step: 37850, training_loss: 6.68010e-02
I0514 00:43:34.373050 22392998065984 run_lib.py:146] step: 37900, training_loss: 7.32552e-02
I0514 00:43:34.529212 22392998065984 run_lib.py:167] step: 37900, eval_loss: 8.31617e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:43:57.944053 22392998065984 run_lib.py:146] step: 37950, training_loss: 6.26230e-02
I0514 00:44:21.883901 22392998065984 run_lib.py:146] step: 38000, training_loss: 4.46310e-02
I0514 00:44:22.041118 22392998065984 run_lib.py:167] step: 38000, eval_loss: 5.21216e-02
I0514 00:44:45.274410 22392998065984 run_lib.py:146] step: 38050, training_loss: 6.75408e-02
I0514 00:45:08.532131 22392998065984 run_lib.py:146] step: 38100, training_loss: 7.14551e-02
I0514 00:45:08.688805 22392998065984 run_lib.py:167] step: 38100, eval_loss: 6.02435e-02
I0514 00:45:32.524597 22392998065984 run_lib.py:146] step: 38150, training_loss: 5.86341e-02
I0514 00:45:55.765268 22392998065984 run_lib.py:146] step: 38200, training_loss: 4.84263e-02
I0514 00:45:55.921726 22392998065984 run_lib.py:167] step: 38200, eval_loss: 5.60564e-02
I0514 00:46:19.171513 22392998065984 run_lib.py:146] step: 38250, training_loss: 5.89509e-02
I0514 00:46:43.033048 22392998065984 run_lib.py:146] step: 38300, training_loss: 5.35516e-02
I0514 00:46:43.189324 22392998065984 run_lib.py:167] step: 38300, eval_loss: 4.94793e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:47:06.605916 22392998065984 run_lib.py:146] step: 38350, training_loss: 8.04502e-02
I0514 00:47:29.897478 22392998065984 run_lib.py:146] step: 38400, training_loss: 5.13070e-02
I0514 00:47:30.055553 22392998065984 run_lib.py:167] step: 38400, eval_loss: 7.10994e-02
I0514 00:47:53.976128 22392998065984 run_lib.py:146] step: 38450, training_loss: 7.59933e-02
I0514 00:48:17.262649 22392998065984 run_lib.py:146] step: 38500, training_loss: 6.11172e-02
I0514 00:48:17.419842 22392998065984 run_lib.py:167] step: 38500, eval_loss: 7.22797e-02
I0514 00:48:40.695817 22392998065984 run_lib.py:146] step: 38550, training_loss: 8.51716e-02
I0514 00:49:04.283213 22392998065984 run_lib.py:146] step: 38600, training_loss: 6.20790e-02
I0514 00:49:04.439363 22392998065984 run_lib.py:167] step: 38600, eval_loss: 7.04436e-02
I0514 00:49:27.973145 22392998065984 run_lib.py:146] step: 38650, training_loss: 5.25480e-02
I0514 00:49:51.232768 22392998065984 run_lib.py:146] step: 38700, training_loss: 5.69461e-02
I0514 00:49:51.388947 22392998065984 run_lib.py:167] step: 38700, eval_loss: 5.81564e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:50:14.777624 22392998065984 run_lib.py:146] step: 38750, training_loss: 7.47527e-02
I0514 00:50:38.707263 22392998065984 run_lib.py:146] step: 38800, training_loss: 6.61864e-02
I0514 00:50:38.864549 22392998065984 run_lib.py:167] step: 38800, eval_loss: 7.23061e-02
I0514 00:51:02.117562 22392998065984 run_lib.py:146] step: 38850, training_loss: 6.52591e-02
I0514 00:51:25.372761 22392998065984 run_lib.py:146] step: 38900, training_loss: 7.66228e-02
I0514 00:51:25.528929 22392998065984 run_lib.py:167] step: 38900, eval_loss: 5.37075e-02
I0514 00:51:49.789036 22392998065984 run_lib.py:146] step: 38950, training_loss: 8.89257e-02
I0514 00:52:13.526061 22392998065984 run_lib.py:146] step: 39000, training_loss: 5.71136e-02
I0514 00:52:13.682489 22392998065984 run_lib.py:167] step: 39000, eval_loss: 6.73794e-02
I0514 00:52:37.425581 22392998065984 run_lib.py:146] step: 39050, training_loss: 6.02064e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:53:01.912300 22392998065984 run_lib.py:146] step: 39100, training_loss: 5.92577e-02
I0514 00:53:02.070831 22392998065984 run_lib.py:167] step: 39100, eval_loss: 5.66120e-02
I0514 00:53:25.340810 22392998065984 run_lib.py:146] step: 39150, training_loss: 6.41010e-02
I0514 00:53:48.609907 22392998065984 run_lib.py:146] step: 39200, training_loss: 4.63841e-02
I0514 00:53:48.766401 22392998065984 run_lib.py:167] step: 39200, eval_loss: 5.92497e-02
I0514 00:54:12.669034 22392998065984 run_lib.py:146] step: 39250, training_loss: 5.79427e-02
I0514 00:54:35.909817 22392998065984 run_lib.py:146] step: 39300, training_loss: 6.03837e-02
I0514 00:54:36.065171 22392998065984 run_lib.py:167] step: 39300, eval_loss: 6.21038e-02
I0514 00:54:59.326627 22392998065984 run_lib.py:146] step: 39350, training_loss: 5.59558e-02
I0514 00:55:22.592369 22392998065984 run_lib.py:146] step: 39400, training_loss: 7.11057e-02
I0514 00:55:22.672101 22392998065984 run_lib.py:167] step: 39400, eval_loss: 3.41728e-02
I0514 00:55:46.510039 22392998065984 run_lib.py:146] step: 39450, training_loss: 7.45510e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:56:09.997951 22392998065984 run_lib.py:146] step: 39500, training_loss: 6.39260e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:56:10.364292 22392998065984 run_lib.py:167] step: 39500, eval_loss: 7.73136e-02
I0514 00:56:34.158536 22392998065984 run_lib.py:146] step: 39550, training_loss: 8.03280e-02
I0514 00:56:58.571426 22392998065984 run_lib.py:146] step: 39600, training_loss: 5.42105e-02
I0514 00:56:58.728068 22392998065984 run_lib.py:167] step: 39600, eval_loss: 5.90913e-02
I0514 00:57:22.464355 22392998065984 run_lib.py:146] step: 39650, training_loss: 6.15682e-02
I0514 00:57:46.206346 22392998065984 run_lib.py:146] step: 39700, training_loss: 5.34766e-02
I0514 00:57:46.363112 22392998065984 run_lib.py:167] step: 39700, eval_loss: 7.24695e-02
I0514 00:58:10.682090 22392998065984 run_lib.py:146] step: 39750, training_loss: 8.29162e-02
I0514 00:58:34.420400 22392998065984 run_lib.py:146] step: 39800, training_loss: 7.30214e-02
I0514 00:58:34.576598 22392998065984 run_lib.py:167] step: 39800, eval_loss: 5.60325e-02
I0514 00:58:57.904115 22392998065984 run_lib.py:146] step: 39850, training_loss: 6.18298e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 00:59:22.107688 22392998065984 run_lib.py:146] step: 39900, training_loss: 6.01662e-02
I0514 00:59:22.265149 22392998065984 run_lib.py:167] step: 39900, eval_loss: 6.94603e-02
I0514 00:59:46.007980 22392998065984 run_lib.py:146] step: 39950, training_loss: 5.57426e-02
I0514 01:00:09.686769 22392998065984 run_lib.py:146] step: 40000, training_loss: 5.22968e-02
I0514 01:00:11.542123 22392998065984 run_lib.py:167] step: 40000, eval_loss: 5.99413e-02
I0514 01:00:37.305828 22392998065984 run_lib.py:146] step: 40050, training_loss: 6.88311e-02
I0514 01:01:01.034513 22392998065984 run_lib.py:146] step: 40100, training_loss: 5.43637e-02
I0514 01:01:01.190876 22392998065984 run_lib.py:167] step: 40100, eval_loss: 6.07972e-02
I0514 01:01:24.482394 22392998065984 run_lib.py:146] step: 40150, training_loss: 6.59783e-02
I0514 01:01:48.031658 22392998065984 run_lib.py:146] step: 40200, training_loss: 7.67209e-02
I0514 01:01:48.187819 22392998065984 run_lib.py:167] step: 40200, eval_loss: 5.39106e-02
I0514 01:02:11.729318 22392998065984 run_lib.py:146] step: 40250, training_loss: 6.75945e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:02:35.375119 22392998065984 run_lib.py:146] step: 40300, training_loss: 3.91754e-02
I0514 01:02:35.532868 22392998065984 run_lib.py:167] step: 40300, eval_loss: 7.83882e-02
I0514 01:02:59.574682 22392998065984 run_lib.py:146] step: 40350, training_loss: 6.53820e-02
I0514 01:03:23.666013 22392998065984 run_lib.py:146] step: 40400, training_loss: 8.04526e-02
I0514 01:03:23.822515 22392998065984 run_lib.py:167] step: 40400, eval_loss: 4.07064e-02
I0514 01:03:47.557074 22392998065984 run_lib.py:146] step: 40450, training_loss: 5.62184e-02
I0514 01:04:11.582352 22392998065984 run_lib.py:146] step: 40500, training_loss: 6.47988e-02
I0514 01:04:11.738596 22392998065984 run_lib.py:167] step: 40500, eval_loss: 6.69958e-02
I0514 01:04:35.766916 22392998065984 run_lib.py:146] step: 40550, training_loss: 6.05887e-02
I0514 01:04:59.494899 22392998065984 run_lib.py:146] step: 40600, training_loss: 7.31293e-02
I0514 01:04:59.651128 22392998065984 run_lib.py:167] step: 40600, eval_loss: 7.08519e-02
I0514 01:05:23.651148 22392998065984 run_lib.py:146] step: 40650, training_loss: 7.52304e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:05:47.759903 22392998065984 run_lib.py:146] step: 40700, training_loss: 5.65833e-02
I0514 01:05:47.918115 22392998065984 run_lib.py:167] step: 40700, eval_loss: 6.55756e-02
I0514 01:06:11.663672 22392998065984 run_lib.py:146] step: 40750, training_loss: 6.99533e-02
I0514 01:06:35.719543 22392998065984 run_lib.py:146] step: 40800, training_loss: 7.52209e-02
I0514 01:06:35.875895 22392998065984 run_lib.py:167] step: 40800, eval_loss: 5.15661e-02
I0514 01:06:59.921473 22392998065984 run_lib.py:146] step: 40850, training_loss: 8.01232e-02
I0514 01:07:23.532639 22392998065984 run_lib.py:146] step: 40900, training_loss: 7.10773e-02
I0514 01:07:23.689523 22392998065984 run_lib.py:167] step: 40900, eval_loss: 6.73696e-02
I0514 01:07:46.954818 22392998065984 run_lib.py:146] step: 40950, training_loss: 5.35272e-02
I0514 01:08:10.517103 22392998065984 run_lib.py:146] step: 41000, training_loss: 8.26026e-02
I0514 01:08:10.673843 22392998065984 run_lib.py:167] step: 41000, eval_loss: 5.62908e-02
I0514 01:08:34.216807 22392998065984 run_lib.py:146] step: 41050, training_loss: 5.33017e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:08:58.037375 22392998065984 run_lib.py:146] step: 41100, training_loss: 9.31115e-02
I0514 01:08:58.195003 22392998065984 run_lib.py:167] step: 41100, eval_loss: 8.18030e-02
I0514 01:09:22.269602 22392998065984 run_lib.py:146] step: 41150, training_loss: 6.98328e-02
I0514 01:09:46.333018 22392998065984 run_lib.py:146] step: 41200, training_loss: 5.43950e-02
I0514 01:09:46.489842 22392998065984 run_lib.py:167] step: 41200, eval_loss: 4.67881e-02
I0514 01:10:10.234227 22392998065984 run_lib.py:146] step: 41250, training_loss: 6.32814e-02
I0514 01:10:34.230589 22392998065984 run_lib.py:146] step: 41300, training_loss: 7.06401e-02
I0514 01:10:34.386673 22392998065984 run_lib.py:167] step: 41300, eval_loss: 6.51523e-02
I0514 01:10:58.428331 22392998065984 run_lib.py:146] step: 41350, training_loss: 7.38680e-02
I0514 01:11:22.148489 22392998065984 run_lib.py:146] step: 41400, training_loss: 4.99719e-02
I0514 01:11:22.304967 22392998065984 run_lib.py:167] step: 41400, eval_loss: 5.55025e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:11:46.449663 22392998065984 run_lib.py:146] step: 41450, training_loss: 6.88835e-02
I0514 01:12:10.054729 22392998065984 run_lib.py:146] step: 41500, training_loss: 6.13124e-02
I0514 01:12:10.212751 22392998065984 run_lib.py:167] step: 41500, eval_loss: 5.91679e-02
I0514 01:12:33.463807 22392998065984 run_lib.py:146] step: 41550, training_loss: 7.52341e-02
I0514 01:12:57.059458 22392998065984 run_lib.py:146] step: 41600, training_loss: 4.96984e-02
I0514 01:12:57.215831 22392998065984 run_lib.py:167] step: 41600, eval_loss: 5.22348e-02
I0514 01:13:20.773246 22392998065984 run_lib.py:146] step: 41650, training_loss: 4.86172e-02
I0514 01:13:44.025139 22392998065984 run_lib.py:146] step: 41700, training_loss: 7.27109e-02
I0514 01:13:44.181564 22392998065984 run_lib.py:167] step: 41700, eval_loss: 5.30641e-02
I0514 01:14:07.440407 22392998065984 run_lib.py:146] step: 41750, training_loss: 5.28039e-02
I0514 01:14:31.024752 22392998065984 run_lib.py:146] step: 41800, training_loss: 4.94089e-02
I0514 01:14:31.181440 22392998065984 run_lib.py:167] step: 41800, eval_loss: 6.16765e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:14:54.868616 22392998065984 run_lib.py:146] step: 41850, training_loss: 5.63481e-02
I0514 01:15:18.139130 22392998065984 run_lib.py:146] step: 41900, training_loss: 5.44505e-02
I0514 01:15:18.296594 22392998065984 run_lib.py:167] step: 41900, eval_loss: 4.82071e-02
I0514 01:15:41.919094 22392998065984 run_lib.py:146] step: 41950, training_loss: 7.41431e-02
I0514 01:16:05.520121 22392998065984 run_lib.py:146] step: 42000, training_loss: 6.65891e-02
I0514 01:16:05.676514 22392998065984 run_lib.py:167] step: 42000, eval_loss: 5.80934e-02
I0514 01:16:29.115173 22392998065984 run_lib.py:146] step: 42050, training_loss: 7.74566e-02
I0514 01:16:53.082901 22392998065984 run_lib.py:146] step: 42100, training_loss: 5.90446e-02
I0514 01:16:53.239546 22392998065984 run_lib.py:167] step: 42100, eval_loss: 5.85168e-02
I0514 01:17:16.791644 22392998065984 run_lib.py:146] step: 42150, training_loss: 7.60004e-02
I0514 01:17:40.036716 22392998065984 run_lib.py:146] step: 42200, training_loss: 5.31794e-02
I0514 01:17:40.193286 22392998065984 run_lib.py:167] step: 42200, eval_loss: 7.26723e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:18:03.939808 22392998065984 run_lib.py:146] step: 42250, training_loss: 6.12432e-02
I0514 01:18:27.543616 22392998065984 run_lib.py:146] step: 42300, training_loss: 5.49533e-02
I0514 01:18:27.700828 22392998065984 run_lib.py:167] step: 42300, eval_loss: 7.24867e-02
I0514 01:18:50.949568 22392998065984 run_lib.py:146] step: 42350, training_loss: 6.01941e-02
I0514 01:19:14.493017 22392998065984 run_lib.py:146] step: 42400, training_loss: 7.41170e-02
I0514 01:19:14.649274 22392998065984 run_lib.py:167] step: 42400, eval_loss: 5.96331e-02
I0514 01:19:38.201095 22392998065984 run_lib.py:146] step: 42450, training_loss: 7.75505e-02
I0514 01:20:01.472556 22392998065984 run_lib.py:146] step: 42500, training_loss: 7.32310e-02
I0514 01:20:01.629251 22392998065984 run_lib.py:167] step: 42500, eval_loss: 5.81525e-02
I0514 01:20:24.896459 22392998065984 run_lib.py:146] step: 42550, training_loss: 6.56626e-02
I0514 01:20:48.455849 22392998065984 run_lib.py:146] step: 42600, training_loss: 7.96857e-02
I0514 01:20:48.612598 22392998065984 run_lib.py:167] step: 42600, eval_loss: 6.14745e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:21:12.591527 22392998065984 run_lib.py:146] step: 42650, training_loss: 7.81641e-02
I0514 01:21:36.334903 22392998065984 run_lib.py:146] step: 42700, training_loss: 5.61834e-02
I0514 01:21:36.492727 22392998065984 run_lib.py:167] step: 42700, eval_loss: 6.38800e-02
I0514 01:22:00.559670 22392998065984 run_lib.py:146] step: 42750, training_loss: 6.18920e-02
I0514 01:22:24.463153 22392998065984 run_lib.py:146] step: 42800, training_loss: 4.82786e-02
I0514 01:22:24.619439 22392998065984 run_lib.py:167] step: 42800, eval_loss: 4.86512e-02
I0514 01:22:47.879726 22392998065984 run_lib.py:146] step: 42850, training_loss: 7.66686e-02
I0514 01:23:11.445933 22392998065984 run_lib.py:146] step: 42900, training_loss: 5.95555e-02
I0514 01:23:11.602599 22392998065984 run_lib.py:167] step: 42900, eval_loss: 6.98660e-02
I0514 01:23:35.134942 22392998065984 run_lib.py:146] step: 42950, training_loss: 9.60061e-02
I0514 01:23:58.384659 22392998065984 run_lib.py:146] step: 43000, training_loss: 7.01722e-02
I0514 01:23:58.540801 22392998065984 run_lib.py:167] step: 43000, eval_loss: 7.85099e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:24:22.270339 22392998065984 run_lib.py:146] step: 43050, training_loss: 5.91228e-02
I0514 01:24:45.839811 22392998065984 run_lib.py:146] step: 43100, training_loss: 4.26367e-02
I0514 01:24:45.997539 22392998065984 run_lib.py:167] step: 43100, eval_loss: 5.57362e-02
I0514 01:25:09.255316 22392998065984 run_lib.py:146] step: 43150, training_loss: 5.33127e-02
I0514 01:25:32.825776 22392998065984 run_lib.py:146] step: 43200, training_loss: 6.18484e-02
I0514 01:25:32.982380 22392998065984 run_lib.py:167] step: 43200, eval_loss: 3.96201e-02
I0514 01:25:56.800976 22392998065984 run_lib.py:146] step: 43250, training_loss: 5.82011e-02
I0514 01:26:20.540999 22392998065984 run_lib.py:146] step: 43300, training_loss: 5.67869e-02
I0514 01:26:20.697884 22392998065984 run_lib.py:167] step: 43300, eval_loss: 5.27694e-02
I0514 01:26:44.711184 22392998065984 run_lib.py:146] step: 43350, training_loss: 6.92536e-02
I0514 01:27:08.324877 22392998065984 run_lib.py:146] step: 43400, training_loss: 7.28216e-02
I0514 01:27:08.480788 22392998065984 run_lib.py:167] step: 43400, eval_loss: 5.77062e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:27:32.300052 22392998065984 run_lib.py:146] step: 43450, training_loss: 7.40474e-02
I0514 01:27:55.538250 22392998065984 run_lib.py:146] step: 43500, training_loss: 6.02579e-02
I0514 01:27:55.694845 22392998065984 run_lib.py:167] step: 43500, eval_loss: 5.86122e-02
I0514 01:28:19.264697 22392998065984 run_lib.py:146] step: 43550, training_loss: 4.48176e-02
I0514 01:28:42.819954 22392998065984 run_lib.py:146] step: 43600, training_loss: 5.04793e-02
I0514 01:28:42.976514 22392998065984 run_lib.py:167] step: 43600, eval_loss: 5.39219e-02
I0514 01:29:06.224119 22392998065984 run_lib.py:146] step: 43650, training_loss: 6.58227e-02
I0514 01:29:29.754936 22392998065984 run_lib.py:146] step: 43700, training_loss: 6.69185e-02
I0514 01:29:29.911559 22392998065984 run_lib.py:167] step: 43700, eval_loss: 4.48625e-02
I0514 01:29:53.457719 22392998065984 run_lib.py:146] step: 43750, training_loss: 7.99198e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:30:16.846614 22392998065984 run_lib.py:146] step: 43800, training_loss: 5.58100e-02
I0514 01:30:17.004701 22392998065984 run_lib.py:167] step: 43800, eval_loss: 5.76326e-02
I0514 01:30:40.578392 22392998065984 run_lib.py:146] step: 43850, training_loss: 7.40876e-02
I0514 01:31:04.167219 22392998065984 run_lib.py:146] step: 43900, training_loss: 5.99731e-02
I0514 01:31:04.323727 22392998065984 run_lib.py:167] step: 43900, eval_loss: 7.14401e-02
I0514 01:31:27.600326 22392998065984 run_lib.py:146] step: 43950, training_loss: 7.36662e-02
I0514 01:31:51.170360 22392998065984 run_lib.py:146] step: 44000, training_loss: 6.70251e-02
I0514 01:31:51.326956 22392998065984 run_lib.py:167] step: 44000, eval_loss: 5.14530e-02
I0514 01:32:14.899183 22392998065984 run_lib.py:146] step: 44050, training_loss: 6.50913e-02
I0514 01:32:38.185610 22392998065984 run_lib.py:146] step: 44100, training_loss: 7.89637e-02
I0514 01:32:38.342146 22392998065984 run_lib.py:167] step: 44100, eval_loss: 6.27937e-02
I0514 01:33:01.913411 22392998065984 run_lib.py:146] step: 44150, training_loss: 8.05328e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:33:25.730103 22392998065984 run_lib.py:146] step: 44200, training_loss: 5.68201e-02
I0514 01:33:25.888275 22392998065984 run_lib.py:167] step: 44200, eval_loss: 6.36016e-02
I0514 01:33:49.171331 22392998065984 run_lib.py:146] step: 44250, training_loss: 5.16799e-02
I0514 01:34:12.455192 22392998065984 run_lib.py:146] step: 44300, training_loss: 6.77227e-02
I0514 01:34:12.612180 22392998065984 run_lib.py:167] step: 44300, eval_loss: 5.74836e-02
I0514 01:34:36.219286 22392998065984 run_lib.py:146] step: 44350, training_loss: 6.42225e-02
I0514 01:34:59.777688 22392998065984 run_lib.py:146] step: 44400, training_loss: 7.92647e-02
I0514 01:34:59.934437 22392998065984 run_lib.py:167] step: 44400, eval_loss: 6.23658e-02
I0514 01:35:23.196693 22392998065984 run_lib.py:146] step: 44450, training_loss: 6.39587e-02
I0514 01:35:46.750578 22392998065984 run_lib.py:146] step: 44500, training_loss: 5.34116e-02
I0514 01:35:46.907052 22392998065984 run_lib.py:167] step: 44500, eval_loss: 6.12290e-02
I0514 01:36:10.450366 22392998065984 run_lib.py:146] step: 44550, training_loss: 5.71168e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:36:33.877983 22392998065984 run_lib.py:146] step: 44600, training_loss: 6.29099e-02
I0514 01:36:34.036273 22392998065984 run_lib.py:167] step: 44600, eval_loss: 7.65938e-02
I0514 01:36:57.658557 22392998065984 run_lib.py:146] step: 44650, training_loss: 7.79660e-02
I0514 01:37:21.287052 22392998065984 run_lib.py:146] step: 44700, training_loss: 5.46442e-02
I0514 01:37:21.443639 22392998065984 run_lib.py:167] step: 44700, eval_loss: 7.06897e-02
I0514 01:37:44.704354 22392998065984 run_lib.py:146] step: 44750, training_loss: 5.14827e-02
I0514 01:38:08.266906 22392998065984 run_lib.py:146] step: 44800, training_loss: 6.26320e-02
I0514 01:38:08.423006 22392998065984 run_lib.py:167] step: 44800, eval_loss: 5.81783e-02
I0514 01:38:31.966020 22392998065984 run_lib.py:146] step: 44850, training_loss: 5.87231e-02
I0514 01:38:55.229438 22392998065984 run_lib.py:146] step: 44900, training_loss: 5.79659e-02
I0514 01:38:55.385835 22392998065984 run_lib.py:167] step: 44900, eval_loss: 5.33723e-02
I0514 01:39:19.065391 22392998065984 run_lib.py:146] step: 44950, training_loss: 4.58000e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:39:43.149870 22392998065984 run_lib.py:146] step: 45000, training_loss: 7.89536e-02
I0514 01:39:43.307581 22392998065984 run_lib.py:167] step: 45000, eval_loss: 5.72478e-02
I0514 01:40:07.050338 22392998065984 run_lib.py:146] step: 45050, training_loss: 5.02104e-02
I0514 01:40:30.778202 22392998065984 run_lib.py:146] step: 45100, training_loss: 4.68363e-02
I0514 01:40:30.934641 22392998065984 run_lib.py:167] step: 45100, eval_loss: 5.97029e-02
I0514 01:40:55.267657 22392998065984 run_lib.py:146] step: 45150, training_loss: 8.10475e-02
I0514 01:41:18.993462 22392998065984 run_lib.py:146] step: 45200, training_loss: 4.71263e-02
I0514 01:41:19.149762 22392998065984 run_lib.py:167] step: 45200, eval_loss: 5.16347e-02
I0514 01:41:42.884993 22392998065984 run_lib.py:146] step: 45250, training_loss: 6.81867e-02
I0514 01:42:06.901133 22392998065984 run_lib.py:146] step: 45300, training_loss: 6.51650e-02
I0514 01:42:07.057496 22392998065984 run_lib.py:167] step: 45300, eval_loss: 5.13219e-02
I0514 01:42:31.078482 22392998065984 run_lib.py:146] step: 45350, training_loss: 4.27589e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:42:54.535905 22392998065984 run_lib.py:146] step: 45400, training_loss: 7.09589e-02
I0514 01:42:54.693577 22392998065984 run_lib.py:167] step: 45400, eval_loss: 5.56704e-02
I0514 01:43:18.269737 22392998065984 run_lib.py:146] step: 45450, training_loss: 6.48538e-02
I0514 01:43:41.848826 22392998065984 run_lib.py:146] step: 45500, training_loss: 6.69889e-02
I0514 01:43:42.004770 22392998065984 run_lib.py:167] step: 45500, eval_loss: 5.17477e-02
I0514 01:44:05.298171 22392998065984 run_lib.py:146] step: 45550, training_loss: 6.09097e-02
I0514 01:44:28.856494 22392998065984 run_lib.py:146] step: 45600, training_loss: 6.35007e-02
I0514 01:44:29.012740 22392998065984 run_lib.py:167] step: 45600, eval_loss: 6.40362e-02
I0514 01:44:52.583377 22392998065984 run_lib.py:146] step: 45650, training_loss: 5.45771e-02
I0514 01:45:15.858757 22392998065984 run_lib.py:146] step: 45700, training_loss: 5.38353e-02
I0514 01:45:16.015434 22392998065984 run_lib.py:167] step: 45700, eval_loss: 6.51691e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:45:39.730067 22392998065984 run_lib.py:146] step: 45750, training_loss: 4.57052e-02
I0514 01:46:03.348309 22392998065984 run_lib.py:146] step: 45800, training_loss: 5.53690e-02
I0514 01:46:03.505902 22392998065984 run_lib.py:167] step: 45800, eval_loss: 8.15859e-02
I0514 01:46:26.780574 22392998065984 run_lib.py:146] step: 45850, training_loss: 4.89082e-02
I0514 01:46:50.062194 22392998065984 run_lib.py:146] step: 45900, training_loss: 7.81375e-02
I0514 01:46:50.219710 22392998065984 run_lib.py:167] step: 45900, eval_loss: 6.32984e-02
I0514 01:47:13.796100 22392998065984 run_lib.py:146] step: 45950, training_loss: 7.01452e-02
I0514 01:47:37.340615 22392998065984 run_lib.py:146] step: 46000, training_loss: 8.04872e-02
I0514 01:47:37.497189 22392998065984 run_lib.py:167] step: 46000, eval_loss: 6.50208e-02
I0514 01:48:00.916825 22392998065984 run_lib.py:146] step: 46050, training_loss: 6.12683e-02
I0514 01:48:24.919700 22392998065984 run_lib.py:146] step: 46100, training_loss: 6.38614e-02
I0514 01:48:25.076126 22392998065984 run_lib.py:167] step: 46100, eval_loss: 5.96353e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:48:49.159112 22392998065984 run_lib.py:146] step: 46150, training_loss: 4.99820e-02
I0514 01:49:12.413579 22392998065984 run_lib.py:146] step: 46200, training_loss: 6.98202e-02
I0514 01:49:12.571195 22392998065984 run_lib.py:167] step: 46200, eval_loss: 4.64160e-02
I0514 01:49:36.156065 22392998065984 run_lib.py:146] step: 46250, training_loss: 4.74011e-02
I0514 01:49:59.758707 22392998065984 run_lib.py:146] step: 46300, training_loss: 7.05905e-02
I0514 01:49:59.915939 22392998065984 run_lib.py:167] step: 46300, eval_loss: 5.81514e-02
I0514 01:50:23.175912 22392998065984 run_lib.py:146] step: 46350, training_loss: 4.48084e-02
I0514 01:50:46.734115 22392998065984 run_lib.py:146] step: 46400, training_loss: 5.02821e-02
I0514 01:50:46.890746 22392998065984 run_lib.py:167] step: 46400, eval_loss: 9.40931e-02
I0514 01:51:10.440696 22392998065984 run_lib.py:146] step: 46450, training_loss: 7.09226e-02
I0514 01:51:33.717897 22392998065984 run_lib.py:146] step: 46500, training_loss: 7.26751e-02
I0514 01:51:33.874434 22392998065984 run_lib.py:167] step: 46500, eval_loss: 7.14539e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:51:57.814965 22392998065984 run_lib.py:146] step: 46550, training_loss: 4.90047e-02
I0514 01:52:21.629944 22392998065984 run_lib.py:146] step: 46600, training_loss: 6.97662e-02
I0514 01:52:21.787617 22392998065984 run_lib.py:167] step: 46600, eval_loss: 7.83916e-02
I0514 01:52:45.040613 22392998065984 run_lib.py:146] step: 46650, training_loss: 4.95499e-02
I0514 01:53:08.601632 22392998065984 run_lib.py:146] step: 46700, training_loss: 6.59199e-02
I0514 01:53:08.757719 22392998065984 run_lib.py:167] step: 46700, eval_loss: 6.55314e-02
I0514 01:53:32.307734 22392998065984 run_lib.py:146] step: 46750, training_loss: 6.17644e-02
I0514 01:53:55.561515 22392998065984 run_lib.py:146] step: 46800, training_loss: 7.03519e-02
I0514 01:53:55.717652 22392998065984 run_lib.py:167] step: 46800, eval_loss: 4.79560e-02
I0514 01:54:18.973427 22392998065984 run_lib.py:146] step: 46850, training_loss: 6.03687e-02
I0514 01:54:42.520119 22392998065984 run_lib.py:146] step: 46900, training_loss: 5.38996e-02
I0514 01:54:42.676858 22392998065984 run_lib.py:167] step: 46900, eval_loss: 7.29748e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:55:06.374130 22392998065984 run_lib.py:146] step: 46950, training_loss: 5.86724e-02
I0514 01:55:29.656275 22392998065984 run_lib.py:146] step: 47000, training_loss: 5.89699e-02
I0514 01:55:29.814132 22392998065984 run_lib.py:167] step: 47000, eval_loss: 5.53988e-02
I0514 01:55:53.444190 22392998065984 run_lib.py:146] step: 47050, training_loss: 7.31577e-02
I0514 01:56:17.025046 22392998065984 run_lib.py:146] step: 47100, training_loss: 7.80603e-02
I0514 01:56:17.181832 22392998065984 run_lib.py:167] step: 47100, eval_loss: 6.40450e-02
I0514 01:56:40.439129 22392998065984 run_lib.py:146] step: 47150, training_loss: 5.53637e-02
I0514 01:57:04.003009 22392998065984 run_lib.py:146] step: 47200, training_loss: 6.53431e-02
I0514 01:57:04.158455 22392998065984 run_lib.py:167] step: 47200, eval_loss: 7.36943e-02
I0514 01:57:27.720821 22392998065984 run_lib.py:146] step: 47250, training_loss: 5.64662e-02
I0514 01:57:51.002514 22392998065984 run_lib.py:146] step: 47300, training_loss: 6.64869e-02
I0514 01:57:51.082567 22392998065984 run_lib.py:167] step: 47300, eval_loss: 8.06864e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:58:14.820050 22392998065984 run_lib.py:146] step: 47350, training_loss: 6.68505e-02
I0514 01:58:38.415246 22392998065984 run_lib.py:146] step: 47400, training_loss: 7.65948e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 01:58:38.781154 22392998065984 run_lib.py:167] step: 47400, eval_loss: 6.94528e-02
I0514 01:59:02.557380 22392998065984 run_lib.py:146] step: 47450, training_loss: 6.40965e-02
I0514 01:59:26.590186 22392998065984 run_lib.py:146] step: 47500, training_loss: 7.17939e-02
I0514 01:59:26.746864 22392998065984 run_lib.py:167] step: 47500, eval_loss: 3.96739e-02
I0514 01:59:50.839278 22392998065984 run_lib.py:146] step: 47550, training_loss: 7.04088e-02
I0514 02:00:14.580682 22392998065984 run_lib.py:146] step: 47600, training_loss: 4.71405e-02
I0514 02:00:14.737128 22392998065984 run_lib.py:167] step: 47600, eval_loss: 7.05577e-02
I0514 02:00:38.485305 22392998065984 run_lib.py:146] step: 47650, training_loss: 5.40236e-02
I0514 02:01:09.066883 22392998065984 run_lib.py:146] step: 47700, training_loss: 6.85852e-02
I0514 02:01:09.223280 22392998065984 run_lib.py:167] step: 47700, eval_loss: 7.33274e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:01:32.999572 22392998065984 run_lib.py:146] step: 47750, training_loss: 4.99530e-02
I0514 02:01:56.262151 22392998065984 run_lib.py:146] step: 47800, training_loss: 9.86373e-02
I0514 02:01:56.419918 22392998065984 run_lib.py:167] step: 47800, eval_loss: 5.24803e-02
I0514 02:02:20.014643 22392998065984 run_lib.py:146] step: 47850, training_loss: 5.91310e-02
I0514 02:02:43.565261 22392998065984 run_lib.py:146] step: 47900, training_loss: 6.43894e-02
I0514 02:02:43.722299 22392998065984 run_lib.py:167] step: 47900, eval_loss: 6.05384e-02
I0514 02:03:06.987989 22392998065984 run_lib.py:146] step: 47950, training_loss: 6.94377e-02
I0514 02:03:30.565181 22392998065984 run_lib.py:146] step: 48000, training_loss: 6.21554e-02
I0514 02:03:30.721527 22392998065984 run_lib.py:167] step: 48000, eval_loss: 5.58520e-02
I0514 02:03:54.289361 22392998065984 run_lib.py:146] step: 48050, training_loss: 5.08336e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:04:19.671123 22392998065984 run_lib.py:146] step: 48100, training_loss: 5.67004e-02
I0514 02:04:19.829857 22392998065984 run_lib.py:167] step: 48100, eval_loss: 4.70258e-02
I0514 02:04:43.424282 22392998065984 run_lib.py:146] step: 48150, training_loss: 5.46261e-02
I0514 02:05:07.019191 22392998065984 run_lib.py:146] step: 48200, training_loss: 5.45144e-02
I0514 02:05:07.176012 22392998065984 run_lib.py:167] step: 48200, eval_loss: 4.70293e-02
I0514 02:05:30.437050 22392998065984 run_lib.py:146] step: 48250, training_loss: 5.35033e-02
I0514 02:05:53.997114 22392998065984 run_lib.py:146] step: 48300, training_loss: 6.34956e-02
I0514 02:05:54.153513 22392998065984 run_lib.py:167] step: 48300, eval_loss: 5.29630e-02
I0514 02:06:17.395127 22392998065984 run_lib.py:146] step: 48350, training_loss: 7.04863e-02
I0514 02:06:40.926784 22392998065984 run_lib.py:146] step: 48400, training_loss: 4.88057e-02
I0514 02:06:41.083039 22392998065984 run_lib.py:167] step: 48400, eval_loss: 5.82204e-02
I0514 02:07:04.797478 22392998065984 run_lib.py:146] step: 48450, training_loss: 5.24083e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:07:28.811385 22392998065984 run_lib.py:146] step: 48500, training_loss: 6.30382e-02
I0514 02:07:28.969620 22392998065984 run_lib.py:167] step: 48500, eval_loss: 7.34112e-02
I0514 02:07:52.584463 22392998065984 run_lib.py:146] step: 48550, training_loss: 7.23568e-02
I0514 02:08:15.848020 22392998065984 run_lib.py:146] step: 48600, training_loss: 5.26349e-02
I0514 02:08:16.004544 22392998065984 run_lib.py:167] step: 48600, eval_loss: 6.02972e-02
I0514 02:08:39.633721 22392998065984 run_lib.py:146] step: 48650, training_loss: 5.61061e-02
I0514 02:09:03.212002 22392998065984 run_lib.py:146] step: 48700, training_loss: 5.41844e-02
I0514 02:09:03.368470 22392998065984 run_lib.py:167] step: 48700, eval_loss: 6.38997e-02
I0514 02:09:26.625297 22392998065984 run_lib.py:146] step: 48750, training_loss: 5.00467e-02
I0514 02:09:50.201470 22392998065984 run_lib.py:146] step: 48800, training_loss: 5.25118e-02
I0514 02:09:50.357901 22392998065984 run_lib.py:167] step: 48800, eval_loss: 6.99314e-02
I0514 02:10:13.924514 22392998065984 run_lib.py:146] step: 48850, training_loss: 5.96446e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:10:37.336419 22392998065984 run_lib.py:146] step: 48900, training_loss: 6.36538e-02
I0514 02:10:37.495229 22392998065984 run_lib.py:167] step: 48900, eval_loss: 6.06419e-02
I0514 02:11:01.112842 22392998065984 run_lib.py:146] step: 48950, training_loss: 7.64209e-02
I0514 02:11:24.718846 22392998065984 run_lib.py:146] step: 49000, training_loss: 7.71892e-02
I0514 02:11:24.874990 22392998065984 run_lib.py:167] step: 49000, eval_loss: 6.85627e-02
I0514 02:11:48.140154 22392998065984 run_lib.py:146] step: 49050, training_loss: 5.96348e-02
I0514 02:12:11.677691 22392998065984 run_lib.py:146] step: 49100, training_loss: 7.84690e-02
I0514 02:12:11.833902 22392998065984 run_lib.py:167] step: 49100, eval_loss: 5.97818e-02
I0514 02:12:35.099884 22392998065984 run_lib.py:146] step: 49150, training_loss: 7.88423e-02
I0514 02:12:58.637539 22392998065984 run_lib.py:146] step: 49200, training_loss: 6.94216e-02
I0514 02:12:58.793999 22392998065984 run_lib.py:167] step: 49200, eval_loss: 8.20994e-02
I0514 02:13:22.033280 22392998065984 run_lib.py:146] step: 49250, training_loss: 6.70026e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:13:45.703733 22392998065984 run_lib.py:146] step: 49300, training_loss: 6.77108e-02
I0514 02:13:45.862521 22392998065984 run_lib.py:167] step: 49300, eval_loss: 5.62309e-02
I0514 02:14:09.481197 22392998065984 run_lib.py:146] step: 49350, training_loss: 6.09186e-02
I0514 02:14:32.738087 22392998065984 run_lib.py:146] step: 49400, training_loss: 6.23725e-02
I0514 02:14:32.894124 22392998065984 run_lib.py:167] step: 49400, eval_loss: 6.43329e-02
I0514 02:14:56.470673 22392998065984 run_lib.py:146] step: 49450, training_loss: 5.65730e-02
I0514 02:15:20.006736 22392998065984 run_lib.py:146] step: 49500, training_loss: 5.73560e-02
I0514 02:15:20.162855 22392998065984 run_lib.py:167] step: 49500, eval_loss: 6.56300e-02
I0514 02:15:43.403236 22392998065984 run_lib.py:146] step: 49550, training_loss: 5.69871e-02
I0514 02:16:06.948287 22392998065984 run_lib.py:146] step: 49600, training_loss: 5.54525e-02
I0514 02:16:07.104471 22392998065984 run_lib.py:167] step: 49600, eval_loss: 7.44670e-02
I0514 02:16:30.639255 22392998065984 run_lib.py:146] step: 49650, training_loss: 9.13855e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:16:54.035445 22392998065984 run_lib.py:146] step: 49700, training_loss: 5.93869e-02
I0514 02:16:54.193257 22392998065984 run_lib.py:167] step: 49700, eval_loss: 4.56253e-02
I0514 02:17:17.783224 22392998065984 run_lib.py:146] step: 49750, training_loss: 7.04739e-02
I0514 02:17:41.371098 22392998065984 run_lib.py:146] step: 49800, training_loss: 8.09340e-02
I0514 02:17:41.527310 22392998065984 run_lib.py:167] step: 49800, eval_loss: 6.68482e-02
I0514 02:18:04.776677 22392998065984 run_lib.py:146] step: 49850, training_loss: 5.83348e-02
I0514 02:18:28.332241 22392998065984 run_lib.py:146] step: 49900, training_loss: 5.84435e-02
I0514 02:18:28.488505 22392998065984 run_lib.py:167] step: 49900, eval_loss: 3.91854e-02
I0514 02:18:51.947078 22392998065984 run_lib.py:146] step: 49950, training_loss: 5.85618e-02
I0514 02:19:15.979625 22392998065984 run_lib.py:146] step: 50000, training_loss: 5.96444e-02
I0514 02:19:18.204197 22392998065984 run_lib.py:167] step: 50000, eval_loss: 6.67601e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:19:44.074419 22392998065984 run_lib.py:146] step: 50050, training_loss: 6.50216e-02
I0514 02:20:07.348862 22392998065984 run_lib.py:146] step: 50100, training_loss: 5.01421e-02
I0514 02:20:07.507033 22392998065984 run_lib.py:167] step: 50100, eval_loss: 6.35062e-02
I0514 02:20:31.086707 22392998065984 run_lib.py:146] step: 50150, training_loss: 5.67838e-02
I0514 02:20:54.674731 22392998065984 run_lib.py:146] step: 50200, training_loss: 4.86960e-02
I0514 02:20:54.831069 22392998065984 run_lib.py:167] step: 50200, eval_loss: 6.87115e-02
I0514 02:21:18.093133 22392998065984 run_lib.py:146] step: 50250, training_loss: 6.36839e-02
I0514 02:21:41.653552 22392998065984 run_lib.py:146] step: 50300, training_loss: 5.51778e-02
I0514 02:21:41.809997 22392998065984 run_lib.py:167] step: 50300, eval_loss: 5.54680e-02
I0514 02:22:05.371666 22392998065984 run_lib.py:146] step: 50350, training_loss: 7.19961e-02
I0514 02:22:28.638087 22392998065984 run_lib.py:146] step: 50400, training_loss: 5.94792e-02
I0514 02:22:28.794561 22392998065984 run_lib.py:167] step: 50400, eval_loss: 6.76019e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:22:52.828619 22392998065984 run_lib.py:146] step: 50450, training_loss: 6.35872e-02
I0514 02:23:16.889914 22392998065984 run_lib.py:146] step: 50500, training_loss: 5.40744e-02
I0514 02:23:17.047578 22392998065984 run_lib.py:167] step: 50500, eval_loss: 5.01601e-02
I0514 02:23:40.622411 22392998065984 run_lib.py:146] step: 50550, training_loss: 7.40918e-02
I0514 02:24:04.205032 22392998065984 run_lib.py:146] step: 50600, training_loss: 7.46290e-02
I0514 02:24:04.361340 22392998065984 run_lib.py:167] step: 50600, eval_loss: 7.16648e-02
I0514 02:24:27.923893 22392998065984 run_lib.py:146] step: 50650, training_loss: 6.12080e-02
I0514 02:24:51.203377 22392998065984 run_lib.py:146] step: 50700, training_loss: 5.34896e-02
I0514 02:24:51.360249 22392998065984 run_lib.py:167] step: 50700, eval_loss: 5.45186e-02
I0514 02:25:14.631297 22392998065984 run_lib.py:146] step: 50750, training_loss: 7.11737e-02
I0514 02:25:38.176798 22392998065984 run_lib.py:146] step: 50800, training_loss: 7.04230e-02
I0514 02:25:38.333319 22392998065984 run_lib.py:167] step: 50800, eval_loss: 5.50539e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:26:02.016845 22392998065984 run_lib.py:146] step: 50850, training_loss: 5.96102e-02
I0514 02:26:25.296259 22392998065984 run_lib.py:146] step: 50900, training_loss: 7.11517e-02
I0514 02:26:25.453787 22392998065984 run_lib.py:167] step: 50900, eval_loss: 6.42312e-02
I0514 02:26:49.061775 22392998065984 run_lib.py:146] step: 50950, training_loss: 6.22253e-02
I0514 02:27:12.684085 22392998065984 run_lib.py:146] step: 51000, training_loss: 6.49445e-02
I0514 02:27:12.840251 22392998065984 run_lib.py:167] step: 51000, eval_loss: 6.34024e-02
I0514 02:27:36.097709 22392998065984 run_lib.py:146] step: 51050, training_loss: 6.74577e-02
I0514 02:27:59.652209 22392998065984 run_lib.py:146] step: 51100, training_loss: 6.96187e-02
I0514 02:27:59.809075 22392998065984 run_lib.py:167] step: 51100, eval_loss: 5.04910e-02
I0514 02:28:23.363546 22392998065984 run_lib.py:146] step: 51150, training_loss: 7.58370e-02
I0514 02:28:46.624151 22392998065984 run_lib.py:146] step: 51200, training_loss: 5.89031e-02
I0514 02:28:46.780749 22392998065984 run_lib.py:167] step: 51200, eval_loss: 5.81277e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:29:10.736419 22392998065984 run_lib.py:146] step: 51250, training_loss: 5.26812e-02
I0514 02:29:34.319615 22392998065984 run_lib.py:146] step: 51300, training_loss: 7.65518e-02
I0514 02:29:34.476881 22392998065984 run_lib.py:167] step: 51300, eval_loss: 8.01420e-02
I0514 02:29:57.741722 22392998065984 run_lib.py:146] step: 51350, training_loss: 5.34519e-02
I0514 02:30:21.309580 22392998065984 run_lib.py:146] step: 51400, training_loss: 4.34769e-02
I0514 02:30:21.466640 22392998065984 run_lib.py:167] step: 51400, eval_loss: 5.19530e-02
I0514 02:30:45.037713 22392998065984 run_lib.py:146] step: 51450, training_loss: 6.02007e-02
I0514 02:31:08.309934 22392998065984 run_lib.py:146] step: 51500, training_loss: 6.48550e-02
I0514 02:31:08.466345 22392998065984 run_lib.py:167] step: 51500, eval_loss: 4.42018e-02
I0514 02:31:31.740396 22392998065984 run_lib.py:146] step: 51550, training_loss: 8.92477e-02
I0514 02:31:55.293529 22392998065984 run_lib.py:146] step: 51600, training_loss: 7.25380e-02
I0514 02:31:55.449797 22392998065984 run_lib.py:167] step: 51600, eval_loss: 4.75653e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:32:19.155650 22392998065984 run_lib.py:146] step: 51650, training_loss: 5.25498e-02
I0514 02:32:42.417737 22392998065984 run_lib.py:146] step: 51700, training_loss: 5.26933e-02
I0514 02:32:42.575358 22392998065984 run_lib.py:167] step: 51700, eval_loss: 4.72972e-02
I0514 02:33:06.175168 22392998065984 run_lib.py:146] step: 51750, training_loss: 6.89375e-02
I0514 02:33:29.770262 22392998065984 run_lib.py:146] step: 51800, training_loss: 6.77481e-02
I0514 02:33:29.927296 22392998065984 run_lib.py:167] step: 51800, eval_loss: 4.81827e-02
I0514 02:33:53.189965 22392998065984 run_lib.py:146] step: 51850, training_loss: 6.80922e-02
I0514 02:34:16.734583 22392998065984 run_lib.py:146] step: 51900, training_loss: 7.22129e-02
I0514 02:34:16.891452 22392998065984 run_lib.py:167] step: 51900, eval_loss: 5.78377e-02
I0514 02:34:40.445042 22392998065984 run_lib.py:146] step: 51950, training_loss: 6.01660e-02
I0514 02:35:03.704538 22392998065984 run_lib.py:146] step: 52000, training_loss: 6.40485e-02
I0514 02:35:03.860837 22392998065984 run_lib.py:167] step: 52000, eval_loss: 6.35305e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:35:28.061218 22392998065984 run_lib.py:146] step: 52050, training_loss: 6.78013e-02
I0514 02:35:52.035079 22392998065984 run_lib.py:146] step: 52100, training_loss: 6.71076e-02
I0514 02:35:52.192886 22392998065984 run_lib.py:167] step: 52100, eval_loss: 4.69982e-02
I0514 02:36:15.465462 22392998065984 run_lib.py:146] step: 52150, training_loss: 5.35729e-02
I0514 02:36:39.027399 22392998065984 run_lib.py:146] step: 52200, training_loss: 7.49058e-02
I0514 02:36:39.183984 22392998065984 run_lib.py:167] step: 52200, eval_loss: 4.28014e-02
I0514 02:37:02.759034 22392998065984 run_lib.py:146] step: 52250, training_loss: 4.65008e-02
I0514 02:37:26.050047 22392998065984 run_lib.py:146] step: 52300, training_loss: 6.85271e-02
I0514 02:37:26.206487 22392998065984 run_lib.py:167] step: 52300, eval_loss: 4.78130e-02
I0514 02:37:49.758844 22392998065984 run_lib.py:146] step: 52350, training_loss: 7.60279e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:38:13.504804 22392998065984 run_lib.py:146] step: 52400, training_loss: 5.99149e-02
I0514 02:38:13.662508 22392998065984 run_lib.py:167] step: 52400, eval_loss: 7.19263e-02
I0514 02:38:36.902940 22392998065984 run_lib.py:146] step: 52450, training_loss: 6.91853e-02
I0514 02:39:00.306868 22392998065984 run_lib.py:146] step: 52500, training_loss: 6.71125e-02
I0514 02:39:00.463490 22392998065984 run_lib.py:167] step: 52500, eval_loss: 6.11117e-02
I0514 02:39:24.069098 22392998065984 run_lib.py:146] step: 52550, training_loss: 5.02809e-02
I0514 02:39:47.630551 22392998065984 run_lib.py:146] step: 52600, training_loss: 6.81702e-02
I0514 02:39:47.787154 22392998065984 run_lib.py:167] step: 52600, eval_loss: 4.65711e-02
I0514 02:40:11.481317 22392998065984 run_lib.py:146] step: 52650, training_loss: 5.63026e-02
I0514 02:40:35.521005 22392998065984 run_lib.py:146] step: 52700, training_loss: 7.07522e-02
I0514 02:40:35.677054 22392998065984 run_lib.py:167] step: 52700, eval_loss: 6.11861e-02
I0514 02:40:59.691484 22392998065984 run_lib.py:146] step: 52750, training_loss: 7.65772e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:41:23.426282 22392998065984 run_lib.py:146] step: 52800, training_loss: 5.39585e-02
I0514 02:41:23.584348 22392998065984 run_lib.py:167] step: 52800, eval_loss: 5.07794e-02
I0514 02:41:47.216853 22392998065984 run_lib.py:146] step: 52850, training_loss: 6.56021e-02
I0514 02:42:10.852177 22392998065984 run_lib.py:146] step: 52900, training_loss: 5.15903e-02
I0514 02:42:11.008790 22392998065984 run_lib.py:167] step: 52900, eval_loss: 5.00978e-02
I0514 02:42:34.267763 22392998065984 run_lib.py:146] step: 52950, training_loss: 5.76294e-02
I0514 02:42:57.815972 22392998065984 run_lib.py:146] step: 53000, training_loss: 4.53754e-02
I0514 02:42:57.972778 22392998065984 run_lib.py:167] step: 53000, eval_loss: 5.86311e-02
I0514 02:43:21.540642 22392998065984 run_lib.py:146] step: 53050, training_loss: 6.58221e-02
I0514 02:43:44.799640 22392998065984 run_lib.py:146] step: 53100, training_loss: 7.28359e-02
I0514 02:43:44.955787 22392998065984 run_lib.py:167] step: 53100, eval_loss: 5.67180e-02
I0514 02:44:08.517759 22392998065984 run_lib.py:146] step: 53150, training_loss: 5.19030e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:44:32.492785 22392998065984 run_lib.py:146] step: 53200, training_loss: 7.93721e-02
I0514 02:44:32.650405 22392998065984 run_lib.py:167] step: 53200, eval_loss: 6.10115e-02
I0514 02:44:56.394608 22392998065984 run_lib.py:146] step: 53250, training_loss: 5.55222e-02
I0514 02:45:20.128958 22392998065984 run_lib.py:146] step: 53300, training_loss: 6.73843e-02
I0514 02:45:20.286116 22392998065984 run_lib.py:167] step: 53300, eval_loss: 5.94046e-02
I0514 02:45:44.362893 22392998065984 run_lib.py:146] step: 53350, training_loss: 5.47526e-02
I0514 02:46:08.364374 22392998065984 run_lib.py:146] step: 53400, training_loss: 8.66462e-02
I0514 02:46:08.521053 22392998065984 run_lib.py:167] step: 53400, eval_loss: 4.61325e-02
I0514 02:46:32.257514 22392998065984 run_lib.py:146] step: 53450, training_loss: 7.05217e-02
I0514 02:46:56.289977 22392998065984 run_lib.py:146] step: 53500, training_loss: 6.78804e-02
I0514 02:46:56.446701 22392998065984 run_lib.py:167] step: 53500, eval_loss: 7.04053e-02
I0514 02:47:20.453068 22392998065984 run_lib.py:146] step: 53550, training_loss: 7.65112e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:47:44.014050 22392998065984 run_lib.py:146] step: 53600, training_loss: 7.48504e-02
I0514 02:47:44.171712 22392998065984 run_lib.py:167] step: 53600, eval_loss: 5.42322e-02
I0514 02:48:07.763161 22392998065984 run_lib.py:146] step: 53650, training_loss: 6.09651e-02
I0514 02:48:31.344280 22392998065984 run_lib.py:146] step: 53700, training_loss: 6.74497e-02
I0514 02:48:31.500754 22392998065984 run_lib.py:167] step: 53700, eval_loss: 7.13622e-02
I0514 02:48:54.768871 22392998065984 run_lib.py:146] step: 53750, training_loss: 8.72260e-02
I0514 02:49:18.330456 22392998065984 run_lib.py:146] step: 53800, training_loss: 6.40275e-02
I0514 02:49:18.487045 22392998065984 run_lib.py:167] step: 53800, eval_loss: 5.49720e-02
I0514 02:49:42.055849 22392998065984 run_lib.py:146] step: 53850, training_loss: 5.36281e-02
I0514 02:50:05.314342 22392998065984 run_lib.py:146] step: 53900, training_loss: 8.22328e-02
I0514 02:50:05.471319 22392998065984 run_lib.py:167] step: 53900, eval_loss: 6.06676e-02
I0514 02:50:29.019664 22392998065984 run_lib.py:146] step: 53950, training_loss: 7.34309e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:50:52.762257 22392998065984 run_lib.py:146] step: 54000, training_loss: 6.75178e-02
I0514 02:50:52.919701 22392998065984 run_lib.py:167] step: 54000, eval_loss: 5.18529e-02
I0514 02:51:16.161165 22392998065984 run_lib.py:146] step: 54050, training_loss: 7.31704e-02
I0514 02:51:39.418055 22392998065984 run_lib.py:146] step: 54100, training_loss: 4.91543e-02
I0514 02:51:39.574168 22392998065984 run_lib.py:167] step: 54100, eval_loss: 7.29178e-02
I0514 02:52:03.185964 22392998065984 run_lib.py:146] step: 54150, training_loss: 6.55785e-02
I0514 02:52:26.754656 22392998065984 run_lib.py:146] step: 54200, training_loss: 6.67617e-02
I0514 02:52:26.911051 22392998065984 run_lib.py:167] step: 54200, eval_loss: 5.20758e-02
I0514 02:52:50.173120 22392998065984 run_lib.py:146] step: 54250, training_loss: 5.17471e-02
I0514 02:53:13.738236 22392998065984 run_lib.py:146] step: 54300, training_loss: 8.00093e-02
I0514 02:53:13.894695 22392998065984 run_lib.py:167] step: 54300, eval_loss: 7.78454e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:53:37.595955 22392998065984 run_lib.py:146] step: 54350, training_loss: 5.35866e-02
I0514 02:54:00.897403 22392998065984 run_lib.py:146] step: 54400, training_loss: 5.12740e-02
I0514 02:54:01.055214 22392998065984 run_lib.py:167] step: 54400, eval_loss: 5.96353e-02
I0514 02:54:24.670493 22392998065984 run_lib.py:146] step: 54450, training_loss: 5.25080e-02
I0514 02:54:48.272424 22392998065984 run_lib.py:146] step: 54500, training_loss: 5.72889e-02
I0514 02:54:48.429107 22392998065984 run_lib.py:167] step: 54500, eval_loss: 6.82432e-02
I0514 02:55:11.700203 22392998065984 run_lib.py:146] step: 54550, training_loss: 6.34586e-02
I0514 02:55:35.259223 22392998065984 run_lib.py:146] step: 54600, training_loss: 5.78338e-02
I0514 02:55:35.415564 22392998065984 run_lib.py:167] step: 54600, eval_loss: 7.73834e-02
I0514 02:55:58.971613 22392998065984 run_lib.py:146] step: 54650, training_loss: 4.92754e-02
I0514 02:56:22.578127 22392998065984 run_lib.py:146] step: 54700, training_loss: 5.79299e-02
I0514 02:56:22.734346 22392998065984 run_lib.py:167] step: 54700, eval_loss: 5.79436e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:56:46.829445 22392998065984 run_lib.py:146] step: 54750, training_loss: 5.70537e-02
I0514 02:57:10.414981 22392998065984 run_lib.py:146] step: 54800, training_loss: 4.97132e-02
I0514 02:57:10.573492 22392998065984 run_lib.py:167] step: 54800, eval_loss: 5.86446e-02
I0514 02:57:33.833974 22392998065984 run_lib.py:146] step: 54850, training_loss: 5.39888e-02
I0514 02:57:57.426461 22392998065984 run_lib.py:146] step: 54900, training_loss: 5.74052e-02
I0514 02:57:57.583336 22392998065984 run_lib.py:167] step: 54900, eval_loss: 5.72778e-02
I0514 02:58:20.860316 22392998065984 run_lib.py:146] step: 54950, training_loss: 4.65593e-02
I0514 02:58:44.417129 22392998065984 run_lib.py:146] step: 55000, training_loss: 6.10819e-02
I0514 02:58:44.573410 22392998065984 run_lib.py:167] step: 55000, eval_loss: 5.35071e-02
I0514 02:59:07.827385 22392998065984 run_lib.py:146] step: 55050, training_loss: 5.31581e-02
I0514 02:59:31.362205 22392998065984 run_lib.py:146] step: 55100, training_loss: 8.78452e-02
I0514 02:59:31.517747 22392998065984 run_lib.py:167] step: 55100, eval_loss: 5.21146e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 02:59:55.211014 22392998065984 run_lib.py:146] step: 55150, training_loss: 6.36412e-02
I0514 03:00:18.490376 22392998065984 run_lib.py:146] step: 55200, training_loss: 6.60056e-02
I0514 03:00:18.571581 22392998065984 run_lib.py:167] step: 55200, eval_loss: 1.35795e-01
I0514 03:00:42.179620 22392998065984 run_lib.py:146] step: 55250, training_loss: 4.51202e-02
I0514 03:01:05.772000 22392998065984 run_lib.py:146] step: 55300, training_loss: 6.72419e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:01:06.140087 22392998065984 run_lib.py:167] step: 55300, eval_loss: 6.07849e-02
I0514 03:01:29.450773 22392998065984 run_lib.py:146] step: 55350, training_loss: 8.01984e-02
I0514 03:01:53.050755 22392998065984 run_lib.py:146] step: 55400, training_loss: 6.58062e-02
I0514 03:01:53.207451 22392998065984 run_lib.py:167] step: 55400, eval_loss: 5.74294e-02
I0514 03:02:16.805557 22392998065984 run_lib.py:146] step: 55450, training_loss: 5.78778e-02
I0514 03:02:40.063893 22392998065984 run_lib.py:146] step: 55500, training_loss: 6.66903e-02
I0514 03:02:40.220271 22392998065984 run_lib.py:167] step: 55500, eval_loss: 7.40875e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:03:04.245439 22392998065984 run_lib.py:146] step: 55550, training_loss: 6.26810e-02
I0514 03:03:28.301449 22392998065984 run_lib.py:146] step: 55600, training_loss: 5.60835e-02
I0514 03:03:28.458787 22392998065984 run_lib.py:167] step: 55600, eval_loss: 5.31620e-02
I0514 03:03:52.196679 22392998065984 run_lib.py:146] step: 55650, training_loss: 5.47455e-02
I0514 03:04:16.233458 22392998065984 run_lib.py:146] step: 55700, training_loss: 7.12958e-02
I0514 03:04:16.390892 22392998065984 run_lib.py:167] step: 55700, eval_loss: 4.74706e-02
I0514 03:04:40.126069 22392998065984 run_lib.py:146] step: 55750, training_loss: 4.92921e-02
I0514 03:05:04.149100 22392998065984 run_lib.py:146] step: 55800, training_loss: 5.70624e-02
I0514 03:05:04.306030 22392998065984 run_lib.py:167] step: 55800, eval_loss: 5.59276e-02
I0514 03:05:28.042780 22392998065984 run_lib.py:146] step: 55850, training_loss: 6.29222e-02
I0514 03:05:52.077482 22392998065984 run_lib.py:146] step: 55900, training_loss: 6.17860e-02
I0514 03:05:52.233663 22392998065984 run_lib.py:167] step: 55900, eval_loss: 8.72655e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:06:16.136739 22392998065984 run_lib.py:146] step: 55950, training_loss: 5.67564e-02
I0514 03:06:39.462221 22392998065984 run_lib.py:146] step: 56000, training_loss: 7.04173e-02
I0514 03:06:39.621541 22392998065984 run_lib.py:167] step: 56000, eval_loss: 5.37930e-02
I0514 03:07:03.699589 22392998065984 run_lib.py:146] step: 56050, training_loss: 7.52015e-02
I0514 03:07:27.699137 22392998065984 run_lib.py:146] step: 56100, training_loss: 4.82162e-02
I0514 03:07:27.855888 22392998065984 run_lib.py:167] step: 56100, eval_loss: 5.31125e-02
I0514 03:07:51.584699 22392998065984 run_lib.py:146] step: 56150, training_loss: 6.85976e-02
I0514 03:08:15.623450 22392998065984 run_lib.py:146] step: 56200, training_loss: 6.33455e-02
I0514 03:08:15.779875 22392998065984 run_lib.py:167] step: 56200, eval_loss: 5.77599e-02
I0514 03:08:39.796280 22392998065984 run_lib.py:146] step: 56250, training_loss: 6.84347e-02
I0514 03:09:03.544868 22392998065984 run_lib.py:146] step: 56300, training_loss: 7.06948e-02
I0514 03:09:03.700947 22392998065984 run_lib.py:167] step: 56300, eval_loss: 6.58918e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:09:27.931958 22392998065984 run_lib.py:146] step: 56350, training_loss: 6.51474e-02
I0514 03:09:51.972658 22392998065984 run_lib.py:146] step: 56400, training_loss: 7.36837e-02
I0514 03:09:52.130143 22392998065984 run_lib.py:167] step: 56400, eval_loss: 6.30163e-02
I0514 03:10:15.863807 22392998065984 run_lib.py:146] step: 56450, training_loss: 5.57153e-02
I0514 03:10:39.547251 22392998065984 run_lib.py:146] step: 56500, training_loss: 5.83262e-02
I0514 03:10:39.703899 22392998065984 run_lib.py:167] step: 56500, eval_loss: 7.97369e-02
I0514 03:11:02.965004 22392998065984 run_lib.py:146] step: 56550, training_loss: 6.44910e-02
I0514 03:11:26.862243 22392998065984 run_lib.py:146] step: 56600, training_loss: 6.13315e-02
I0514 03:11:27.018636 22392998065984 run_lib.py:167] step: 56600, eval_loss: 5.15818e-02
I0514 03:11:50.763983 22392998065984 run_lib.py:146] step: 56650, training_loss: 5.35976e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:12:14.907075 22392998065984 run_lib.py:146] step: 56700, training_loss: 7.07713e-02
I0514 03:12:15.065402 22392998065984 run_lib.py:167] step: 56700, eval_loss: 4.95089e-02
I0514 03:12:38.662659 22392998065984 run_lib.py:146] step: 56750, training_loss: 6.55277e-02
I0514 03:13:01.926461 22392998065984 run_lib.py:146] step: 56800, training_loss: 4.85158e-02
I0514 03:13:02.082797 22392998065984 run_lib.py:167] step: 56800, eval_loss: 6.94973e-02
I0514 03:13:25.677759 22392998065984 run_lib.py:146] step: 56850, training_loss: 5.70228e-02
I0514 03:13:49.243275 22392998065984 run_lib.py:146] step: 56900, training_loss: 4.66265e-02
I0514 03:13:49.399627 22392998065984 run_lib.py:167] step: 56900, eval_loss: 4.87376e-02
I0514 03:14:12.861338 22392998065984 run_lib.py:146] step: 56950, training_loss: 4.28918e-02
I0514 03:14:36.890519 22392998065984 run_lib.py:146] step: 57000, training_loss: 6.70871e-02
I0514 03:14:37.047267 22392998065984 run_lib.py:167] step: 57000, eval_loss: 7.93912e-02
I0514 03:15:01.052479 22392998065984 run_lib.py:146] step: 57050, training_loss: 4.72105e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:15:24.804204 22392998065984 run_lib.py:146] step: 57100, training_loss: 4.71348e-02
I0514 03:15:24.962152 22392998065984 run_lib.py:167] step: 57100, eval_loss: 6.52045e-02
I0514 03:15:48.530299 22392998065984 run_lib.py:146] step: 57150, training_loss: 4.64893e-02
I0514 03:16:12.163161 22392998065984 run_lib.py:146] step: 57200, training_loss: 5.39747e-02
I0514 03:16:12.319359 22392998065984 run_lib.py:167] step: 57200, eval_loss: 6.53306e-02
I0514 03:16:36.073279 22392998065984 run_lib.py:146] step: 57250, training_loss: 6.49303e-02
I0514 03:17:00.125245 22392998065984 run_lib.py:146] step: 57300, training_loss: 6.18464e-02
I0514 03:17:00.281750 22392998065984 run_lib.py:167] step: 57300, eval_loss: 5.37059e-02
I0514 03:17:23.553808 22392998065984 run_lib.py:146] step: 57350, training_loss: 5.67944e-02
I0514 03:17:47.094391 22392998065984 run_lib.py:146] step: 57400, training_loss: 7.43095e-02
I0514 03:17:47.250462 22392998065984 run_lib.py:167] step: 57400, eval_loss: 5.79033e-02
I0514 03:18:10.489092 22392998065984 run_lib.py:146] step: 57450, training_loss: 7.18074e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:18:34.168586 22392998065984 run_lib.py:146] step: 57500, training_loss: 4.82372e-02
I0514 03:18:34.326298 22392998065984 run_lib.py:167] step: 57500, eval_loss: 5.71416e-02
I0514 03:18:57.907778 22392998065984 run_lib.py:146] step: 57550, training_loss: 7.31221e-02
I0514 03:19:21.146688 22392998065984 run_lib.py:146] step: 57600, training_loss: 5.08732e-02
I0514 03:19:21.303385 22392998065984 run_lib.py:167] step: 57600, eval_loss: 4.83957e-02
I0514 03:19:44.882089 22392998065984 run_lib.py:146] step: 57650, training_loss: 7.38341e-02
I0514 03:20:08.448863 22392998065984 run_lib.py:146] step: 57700, training_loss: 6.60612e-02
I0514 03:20:08.605228 22392998065984 run_lib.py:167] step: 57700, eval_loss: 5.12287e-02
I0514 03:20:31.863559 22392998065984 run_lib.py:146] step: 57750, training_loss: 6.61128e-02
I0514 03:20:55.423395 22392998065984 run_lib.py:146] step: 57800, training_loss: 5.46684e-02
I0514 03:20:55.579942 22392998065984 run_lib.py:167] step: 57800, eval_loss: 6.04038e-02
I0514 03:21:19.143246 22392998065984 run_lib.py:146] step: 57850, training_loss: 5.58478e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:21:42.557666 22392998065984 run_lib.py:146] step: 57900, training_loss: 6.46899e-02
I0514 03:21:42.715898 22392998065984 run_lib.py:167] step: 57900, eval_loss: 7.56101e-02
I0514 03:22:06.505731 22392998065984 run_lib.py:146] step: 57950, training_loss: 6.35449e-02
I0514 03:22:30.567095 22392998065984 run_lib.py:146] step: 58000, training_loss: 5.21015e-02
I0514 03:22:30.723339 22392998065984 run_lib.py:167] step: 58000, eval_loss: 5.87553e-02
I0514 03:22:54.466235 22392998065984 run_lib.py:146] step: 58050, training_loss: 6.61479e-02
I0514 03:23:18.511984 22392998065984 run_lib.py:146] step: 58100, training_loss: 6.47345e-02
I0514 03:23:18.668477 22392998065984 run_lib.py:167] step: 58100, eval_loss: 7.04135e-02
I0514 03:23:42.404615 22392998065984 run_lib.py:146] step: 58150, training_loss: 7.24576e-02
I0514 03:24:06.412721 22392998065984 run_lib.py:146] step: 58200, training_loss: 5.75614e-02
I0514 03:24:06.569720 22392998065984 run_lib.py:167] step: 58200, eval_loss: 7.07566e-02
I0514 03:24:30.314065 22392998065984 run_lib.py:146] step: 58250, training_loss: 6.35712e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:24:54.115265 22392998065984 run_lib.py:146] step: 58300, training_loss: 5.77878e-02
I0514 03:24:54.273213 22392998065984 run_lib.py:167] step: 58300, eval_loss: 6.22363e-02
I0514 03:25:17.878521 22392998065984 run_lib.py:146] step: 58350, training_loss: 5.88858e-02
I0514 03:25:41.142935 22392998065984 run_lib.py:146] step: 58400, training_loss: 6.95349e-02
I0514 03:25:41.299200 22392998065984 run_lib.py:167] step: 58400, eval_loss: 6.11550e-02
I0514 03:26:04.871245 22392998065984 run_lib.py:146] step: 58450, training_loss: 6.87422e-02
I0514 03:26:28.416228 22392998065984 run_lib.py:146] step: 58500, training_loss: 5.68115e-02
I0514 03:26:28.572328 22392998065984 run_lib.py:167] step: 58500, eval_loss: 7.00224e-02
I0514 03:26:51.831661 22392998065984 run_lib.py:146] step: 58550, training_loss: 4.60696e-02
I0514 03:27:15.355931 22392998065984 run_lib.py:146] step: 58600, training_loss: 7.83934e-02
I0514 03:27:15.512664 22392998065984 run_lib.py:167] step: 58600, eval_loss: 6.35090e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:27:39.190657 22392998065984 run_lib.py:146] step: 58650, training_loss: 6.63602e-02
I0514 03:28:02.446541 22392998065984 run_lib.py:146] step: 58700, training_loss: 5.98543e-02
I0514 03:28:02.604049 22392998065984 run_lib.py:167] step: 58700, eval_loss: 5.44810e-02
I0514 03:28:26.199688 22392998065984 run_lib.py:146] step: 58750, training_loss: 7.19636e-02
I0514 03:28:49.813598 22392998065984 run_lib.py:146] step: 58800, training_loss: 5.45727e-02
I0514 03:28:49.970229 22392998065984 run_lib.py:167] step: 58800, eval_loss: 7.11709e-02
I0514 03:29:13.212982 22392998065984 run_lib.py:146] step: 58850, training_loss: 5.03632e-02
I0514 03:29:36.752358 22392998065984 run_lib.py:146] step: 58900, training_loss: 6.87667e-02
I0514 03:29:36.908735 22392998065984 run_lib.py:167] step: 58900, eval_loss: 6.72208e-02
I0514 03:30:00.168861 22392998065984 run_lib.py:146] step: 58950, training_loss: 4.17514e-02
I0514 03:30:23.709753 22392998065984 run_lib.py:146] step: 59000, training_loss: 8.01718e-02
I0514 03:30:23.865817 22392998065984 run_lib.py:167] step: 59000, eval_loss: 5.43218e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:30:47.690170 22392998065984 run_lib.py:146] step: 59050, training_loss: 5.37791e-02
I0514 03:31:11.425680 22392998065984 run_lib.py:146] step: 59100, training_loss: 7.44465e-02
I0514 03:31:11.583370 22392998065984 run_lib.py:167] step: 59100, eval_loss: 6.09863e-02
I0514 03:31:35.629840 22392998065984 run_lib.py:146] step: 59150, training_loss: 7.17605e-02
I0514 03:31:59.361341 22392998065984 run_lib.py:146] step: 59200, training_loss: 7.43848e-02
I0514 03:31:59.517644 22392998065984 run_lib.py:167] step: 59200, eval_loss: 4.26289e-02
I0514 03:32:23.554864 22392998065984 run_lib.py:146] step: 59250, training_loss: 8.21771e-02
I0514 03:32:47.569971 22392998065984 run_lib.py:146] step: 59300, training_loss: 7.68282e-02
I0514 03:32:47.726373 22392998065984 run_lib.py:167] step: 59300, eval_loss: 5.26867e-02
I0514 03:33:11.468055 22392998065984 run_lib.py:146] step: 59350, training_loss: 5.46953e-02
I0514 03:33:35.510147 22392998065984 run_lib.py:146] step: 59400, training_loss: 6.06334e-02
I0514 03:33:35.666646 22392998065984 run_lib.py:167] step: 59400, eval_loss: 5.36749e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:33:59.657912 22392998065984 run_lib.py:146] step: 59450, training_loss: 5.42351e-02
I0514 03:34:22.931963 22392998065984 run_lib.py:146] step: 59500, training_loss: 8.07345e-02
I0514 03:34:23.089449 22392998065984 run_lib.py:167] step: 59500, eval_loss: 6.59548e-02
I0514 03:34:46.672575 22392998065984 run_lib.py:146] step: 59550, training_loss: 4.69081e-02
I0514 03:35:10.233573 22392998065984 run_lib.py:146] step: 59600, training_loss: 5.58792e-02
I0514 03:35:10.389801 22392998065984 run_lib.py:167] step: 59600, eval_loss: 8.20648e-02
I0514 03:35:33.639900 22392998065984 run_lib.py:146] step: 59650, training_loss: 5.74653e-02
I0514 03:35:57.192675 22392998065984 run_lib.py:146] step: 59700, training_loss: 6.99872e-02
I0514 03:35:57.349135 22392998065984 run_lib.py:167] step: 59700, eval_loss: 6.18057e-02
I0514 03:36:20.626996 22392998065984 run_lib.py:146] step: 59750, training_loss: 4.94086e-02
I0514 03:36:44.196406 22392998065984 run_lib.py:146] step: 59800, training_loss: 6.66320e-02
I0514 03:36:44.352861 22392998065984 run_lib.py:167] step: 59800, eval_loss: 4.98091e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:37:08.365724 22392998065984 run_lib.py:146] step: 59850, training_loss: 5.08348e-02
I0514 03:37:32.091626 22392998065984 run_lib.py:146] step: 59900, training_loss: 5.65109e-02
I0514 03:37:32.249167 22392998065984 run_lib.py:167] step: 59900, eval_loss: 6.34150e-02
I0514 03:37:56.300012 22392998065984 run_lib.py:146] step: 59950, training_loss: 5.90577e-02
I0514 03:38:20.027709 22392998065984 run_lib.py:146] step: 60000, training_loss: 4.49480e-02
I0514 03:38:27.999247 22392998065984 run_lib.py:167] step: 60000, eval_loss: 5.70868e-02
I0514 03:38:59.448256 22392998065984 run_lib.py:146] step: 60050, training_loss: 7.55662e-02
I0514 03:39:23.179625 22392998065984 run_lib.py:146] step: 60100, training_loss: 5.41338e-02
I0514 03:39:23.336294 22392998065984 run_lib.py:167] step: 60100, eval_loss: 5.27568e-02
I0514 03:39:47.078024 22392998065984 run_lib.py:146] step: 60150, training_loss: 6.30582e-02
I0514 03:40:11.281246 22392998065984 run_lib.py:146] step: 60200, training_loss: 5.11554e-02
I0514 03:40:11.437552 22392998065984 run_lib.py:167] step: 60200, eval_loss: 6.90155e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:40:35.141829 22392998065984 run_lib.py:146] step: 60250, training_loss: 5.47072e-02
I0514 03:40:58.876261 22392998065984 run_lib.py:146] step: 60300, training_loss: 7.81128e-02
I0514 03:40:59.033854 22392998065984 run_lib.py:167] step: 60300, eval_loss: 5.91183e-02
I0514 03:41:23.469540 22392998065984 run_lib.py:146] step: 60350, training_loss: 7.58391e-02
I0514 03:41:46.857111 22392998065984 run_lib.py:146] step: 60400, training_loss: 6.43948e-02
I0514 03:41:47.013636 22392998065984 run_lib.py:167] step: 60400, eval_loss: 9.19339e-02
I0514 03:42:10.288858 22392998065984 run_lib.py:146] step: 60450, training_loss: 6.47052e-02
I0514 03:42:33.872644 22392998065984 run_lib.py:146] step: 60500, training_loss: 8.04525e-02
I0514 03:42:34.029584 22392998065984 run_lib.py:167] step: 60500, eval_loss: 6.79136e-02
I0514 03:42:57.595156 22392998065984 run_lib.py:146] step: 60550, training_loss: 5.94867e-02
I0514 03:43:20.853951 22392998065984 run_lib.py:146] step: 60600, training_loss: 6.74201e-02
I0514 03:43:21.010773 22392998065984 run_lib.py:167] step: 60600, eval_loss: 7.75758e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:43:44.760774 22392998065984 run_lib.py:146] step: 60650, training_loss: 8.50109e-02
I0514 03:44:08.378793 22392998065984 run_lib.py:146] step: 60700, training_loss: 6.87016e-02
I0514 03:44:08.536624 22392998065984 run_lib.py:167] step: 60700, eval_loss: 6.81020e-02
I0514 03:44:31.793966 22392998065984 run_lib.py:146] step: 60750, training_loss: 5.48167e-02
I0514 03:44:55.065967 22392998065984 run_lib.py:146] step: 60800, training_loss: 5.60636e-02
I0514 03:44:55.222812 22392998065984 run_lib.py:167] step: 60800, eval_loss: 8.47230e-02
I0514 03:45:19.077162 22392998065984 run_lib.py:146] step: 60850, training_loss: 7.10686e-02
I0514 03:45:42.338060 22392998065984 run_lib.py:146] step: 60900, training_loss: 6.81753e-02
I0514 03:45:42.494269 22392998065984 run_lib.py:167] step: 60900, eval_loss: 5.86061e-02
I0514 03:46:05.752338 22392998065984 run_lib.py:146] step: 60950, training_loss: 6.82074e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:46:29.773252 22392998065984 run_lib.py:146] step: 61000, training_loss: 4.94527e-02
I0514 03:46:29.931122 22392998065984 run_lib.py:167] step: 61000, eval_loss: 4.25070e-02
I0514 03:46:53.676301 22392998065984 run_lib.py:146] step: 61050, training_loss: 4.95462e-02
I0514 03:47:17.065689 22392998065984 run_lib.py:146] step: 61100, training_loss: 4.88391e-02
I0514 03:47:17.222088 22392998065984 run_lib.py:167] step: 61100, eval_loss: 6.94711e-02
I0514 03:47:41.127101 22392998065984 run_lib.py:146] step: 61150, training_loss: 4.86114e-02
I0514 03:48:04.411681 22392998065984 run_lib.py:146] step: 61200, training_loss: 5.22694e-02
I0514 03:48:04.568782 22392998065984 run_lib.py:167] step: 61200, eval_loss: 5.99587e-02
I0514 03:48:28.259047 22392998065984 run_lib.py:146] step: 61250, training_loss: 8.08890e-02
I0514 03:48:51.998657 22392998065984 run_lib.py:146] step: 61300, training_loss: 5.85959e-02
I0514 03:48:52.155268 22392998065984 run_lib.py:167] step: 61300, eval_loss: 7.98102e-02
I0514 03:49:15.692749 22392998065984 run_lib.py:146] step: 61350, training_loss: 6.99130e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:49:39.197769 22392998065984 run_lib.py:146] step: 61400, training_loss: 5.53733e-02
I0514 03:49:39.355452 22392998065984 run_lib.py:167] step: 61400, eval_loss: 8.72417e-02
I0514 03:50:03.456309 22392998065984 run_lib.py:146] step: 61450, training_loss: 6.33189e-02
I0514 03:50:27.510921 22392998065984 run_lib.py:146] step: 61500, training_loss: 5.00110e-02
I0514 03:50:27.667128 22392998065984 run_lib.py:167] step: 61500, eval_loss: 4.85973e-02
I0514 03:50:51.399329 22392998065984 run_lib.py:146] step: 61550, training_loss: 6.69925e-02
I0514 03:51:15.413835 22392998065984 run_lib.py:146] step: 61600, training_loss: 6.32504e-02
I0514 03:51:15.571186 22392998065984 run_lib.py:167] step: 61600, eval_loss: 5.53068e-02
I0514 03:51:39.585240 22392998065984 run_lib.py:146] step: 61650, training_loss: 6.19244e-02
I0514 03:52:03.326678 22392998065984 run_lib.py:146] step: 61700, training_loss: 5.68212e-02
I0514 03:52:03.483128 22392998065984 run_lib.py:167] step: 61700, eval_loss: 5.28971e-02
I0514 03:52:26.834778 22392998065984 run_lib.py:146] step: 61750, training_loss: 5.31816e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:52:50.864788 22392998065984 run_lib.py:146] step: 61800, training_loss: 5.98588e-02
I0514 03:52:51.022762 22392998065984 run_lib.py:167] step: 61800, eval_loss: 5.97630e-02
I0514 03:53:14.273138 22392998065984 run_lib.py:146] step: 61850, training_loss: 5.73239e-02
I0514 03:53:37.529067 22392998065984 run_lib.py:146] step: 61900, training_loss: 5.33675e-02
I0514 03:53:37.685735 22392998065984 run_lib.py:167] step: 61900, eval_loss: 6.08060e-02
I0514 03:54:01.569894 22392998065984 run_lib.py:146] step: 61950, training_loss: 5.46122e-02
I0514 03:54:25.123129 22392998065984 run_lib.py:146] step: 62000, training_loss: 5.62131e-02
I0514 03:54:25.279952 22392998065984 run_lib.py:167] step: 62000, eval_loss: 5.21104e-02
I0514 03:54:49.019693 22392998065984 run_lib.py:146] step: 62050, training_loss: 6.47273e-02
I0514 03:55:12.611536 22392998065984 run_lib.py:146] step: 62100, training_loss: 5.06504e-02
I0514 03:55:12.767896 22392998065984 run_lib.py:167] step: 62100, eval_loss: 7.38357e-02
I0514 03:55:36.329050 22392998065984 run_lib.py:146] step: 62150, training_loss: 6.50058e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:56:00.028299 22392998065984 run_lib.py:146] step: 62200, training_loss: 6.34346e-02
I0514 03:56:00.186620 22392998065984 run_lib.py:167] step: 62200, eval_loss: 7.46841e-02
I0514 03:56:24.291769 22392998065984 run_lib.py:146] step: 62250, training_loss: 7.38801e-02
I0514 03:56:48.334731 22392998065984 run_lib.py:146] step: 62300, training_loss: 6.17762e-02
I0514 03:56:48.490939 22392998065984 run_lib.py:167] step: 62300, eval_loss: 7.06148e-02
I0514 03:57:12.233312 22392998065984 run_lib.py:146] step: 62350, training_loss: 5.80622e-02
I0514 03:57:35.608701 22392998065984 run_lib.py:146] step: 62400, training_loss: 7.17056e-02
I0514 03:57:35.764987 22392998065984 run_lib.py:167] step: 62400, eval_loss: 5.80281e-02
I0514 03:57:59.622604 22392998065984 run_lib.py:146] step: 62450, training_loss: 5.86054e-02
I0514 03:58:22.877502 22392998065984 run_lib.py:146] step: 62500, training_loss: 6.64594e-02
I0514 03:58:23.033637 22392998065984 run_lib.py:167] step: 62500, eval_loss: 5.56586e-02
I0514 03:58:46.269782 22392998065984 run_lib.py:146] step: 62550, training_loss: 4.59491e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 03:59:10.510433 22392998065984 run_lib.py:146] step: 62600, training_loss: 3.91097e-02
I0514 03:59:10.667716 22392998065984 run_lib.py:167] step: 62600, eval_loss: 6.69624e-02
I0514 03:59:34.414302 22392998065984 run_lib.py:146] step: 62650, training_loss: 6.38358e-02
I0514 03:59:57.798731 22392998065984 run_lib.py:146] step: 62700, training_loss: 5.65360e-02
I0514 03:59:57.955462 22392998065984 run_lib.py:167] step: 62700, eval_loss: 4.94032e-02
I0514 04:00:21.803324 22392998065984 run_lib.py:146] step: 62750, training_loss: 7.33210e-02
I0514 04:00:45.049026 22392998065984 run_lib.py:146] step: 62800, training_loss: 7.17784e-02
I0514 04:00:45.205420 22392998065984 run_lib.py:167] step: 62800, eval_loss: 5.73189e-02
I0514 04:01:08.469589 22392998065984 run_lib.py:146] step: 62850, training_loss: 5.34653e-02
I0514 04:01:32.019985 22392998065984 run_lib.py:146] step: 62900, training_loss: 6.41799e-02
I0514 04:01:32.176834 22392998065984 run_lib.py:167] step: 62900, eval_loss: 5.99674e-02
I0514 04:01:55.602363 22392998065984 run_lib.py:146] step: 62950, training_loss: 7.22457e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:02:19.533594 22392998065984 run_lib.py:146] step: 63000, training_loss: 6.84205e-02
I0514 04:02:19.690688 22392998065984 run_lib.py:167] step: 63000, eval_loss: 5.08099e-02
I0514 04:02:43.272651 22392998065984 run_lib.py:146] step: 63050, training_loss: 5.86559e-02
I0514 04:03:06.854693 22392998065984 run_lib.py:146] step: 63100, training_loss: 6.87312e-02
I0514 04:03:06.933157 22392998065984 run_lib.py:167] step: 63100, eval_loss: 3.41207e-02
I0514 04:03:30.196061 22392998065984 run_lib.py:146] step: 63150, training_loss: 6.45465e-02
I0514 04:03:53.459208 22392998065984 run_lib.py:146] step: 63200, training_loss: 6.44870e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:03:53.838262 22392998065984 run_lib.py:167] step: 63200, eval_loss: 7.40087e-02
I0514 04:04:18.304932 22392998065984 run_lib.py:146] step: 63250, training_loss: 5.60138e-02
I0514 04:04:42.051446 22392998065984 run_lib.py:146] step: 63300, training_loss: 6.03224e-02
I0514 04:04:42.207821 22392998065984 run_lib.py:167] step: 63300, eval_loss: 7.02255e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:05:06.100924 22392998065984 run_lib.py:146] step: 63350, training_loss: 5.05143e-02
I0514 04:05:30.514446 22392998065984 run_lib.py:146] step: 63400, training_loss: 6.85693e-02
I0514 04:05:30.671803 22392998065984 run_lib.py:167] step: 63400, eval_loss: 9.15105e-02
I0514 04:05:54.407373 22392998065984 run_lib.py:146] step: 63450, training_loss: 5.96978e-02
I0514 04:06:18.132816 22392998065984 run_lib.py:146] step: 63500, training_loss: 5.38755e-02
I0514 04:06:18.288970 22392998065984 run_lib.py:167] step: 63500, eval_loss: 5.79777e-02
I0514 04:06:42.628374 22392998065984 run_lib.py:146] step: 63550, training_loss: 8.01788e-02
I0514 04:07:06.365307 22392998065984 run_lib.py:146] step: 63600, training_loss: 7.06687e-02
I0514 04:07:06.521621 22392998065984 run_lib.py:167] step: 63600, eval_loss: 5.90154e-02
I0514 04:07:30.254756 22392998065984 run_lib.py:146] step: 63650, training_loss: 5.24382e-02
I0514 04:07:54.279917 22392998065984 run_lib.py:146] step: 63700, training_loss: 5.86184e-02
I0514 04:07:54.437849 22392998065984 run_lib.py:167] step: 63700, eval_loss: 8.62721e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:08:18.422926 22392998065984 run_lib.py:146] step: 63750, training_loss: 7.27240e-02
I0514 04:08:41.672855 22392998065984 run_lib.py:146] step: 63800, training_loss: 5.90578e-02
I0514 04:08:41.830257 22392998065984 run_lib.py:167] step: 63800, eval_loss: 7.12769e-02
I0514 04:09:05.399939 22392998065984 run_lib.py:146] step: 63850, training_loss: 4.65070e-02
I0514 04:09:28.995078 22392998065984 run_lib.py:146] step: 63900, training_loss: 5.12703e-02
I0514 04:09:29.151653 22392998065984 run_lib.py:167] step: 63900, eval_loss: 7.16837e-02
I0514 04:09:52.400392 22392998065984 run_lib.py:146] step: 63950, training_loss: 5.98484e-02
I0514 04:10:15.645348 22392998065984 run_lib.py:146] step: 64000, training_loss: 7.01578e-02
I0514 04:10:15.801847 22392998065984 run_lib.py:167] step: 64000, eval_loss: 6.59524e-02
I0514 04:10:39.655724 22392998065984 run_lib.py:146] step: 64050, training_loss: 6.01276e-02
I0514 04:11:03.309851 22392998065984 run_lib.py:146] step: 64100, training_loss: 5.81339e-02
I0514 04:11:03.465993 22392998065984 run_lib.py:167] step: 64100, eval_loss: 7.47331e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:11:27.127430 22392998065984 run_lib.py:146] step: 64150, training_loss: 7.12392e-02
I0514 04:11:51.050431 22392998065984 run_lib.py:146] step: 64200, training_loss: 6.19178e-02
I0514 04:11:51.208171 22392998065984 run_lib.py:167] step: 64200, eval_loss: 5.12467e-02
I0514 04:12:14.467414 22392998065984 run_lib.py:146] step: 64250, training_loss: 6.67665e-02
I0514 04:12:37.743218 22392998065984 run_lib.py:146] step: 64300, training_loss: 7.16576e-02
I0514 04:12:37.899893 22392998065984 run_lib.py:167] step: 64300, eval_loss: 7.72314e-02
I0514 04:13:01.726759 22392998065984 run_lib.py:146] step: 64350, training_loss: 6.20189e-02
I0514 04:13:24.971043 22392998065984 run_lib.py:146] step: 64400, training_loss: 4.75212e-02
I0514 04:13:25.127694 22392998065984 run_lib.py:167] step: 64400, eval_loss: 5.29607e-02
I0514 04:13:48.529199 22392998065984 run_lib.py:146] step: 64450, training_loss: 6.50133e-02
I0514 04:14:12.657085 22392998065984 run_lib.py:146] step: 64500, training_loss: 6.72689e-02
I0514 04:14:12.813411 22392998065984 run_lib.py:167] step: 64500, eval_loss: 4.74100e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:14:36.210838 22392998065984 run_lib.py:146] step: 64550, training_loss: 5.37032e-02
I0514 04:14:59.479327 22392998065984 run_lib.py:146] step: 64600, training_loss: 7.82954e-02
I0514 04:14:59.636980 22392998065984 run_lib.py:167] step: 64600, eval_loss: 6.66206e-02
I0514 04:15:22.899922 22392998065984 run_lib.py:146] step: 64650, training_loss: 7.22512e-02
I0514 04:15:46.831464 22392998065984 run_lib.py:146] step: 64700, training_loss: 5.29412e-02
I0514 04:15:46.988032 22392998065984 run_lib.py:167] step: 64700, eval_loss: 6.61382e-02
I0514 04:16:10.247826 22392998065984 run_lib.py:146] step: 64750, training_loss: 7.25786e-02
I0514 04:16:33.516355 22392998065984 run_lib.py:146] step: 64800, training_loss: 4.84038e-02
I0514 04:16:33.672934 22392998065984 run_lib.py:167] step: 64800, eval_loss: 4.75038e-02
I0514 04:16:57.530710 22392998065984 run_lib.py:146] step: 64850, training_loss: 5.26988e-02
I0514 04:17:21.183091 22392998065984 run_lib.py:146] step: 64900, training_loss: 7.35151e-02
I0514 04:17:21.339853 22392998065984 run_lib.py:167] step: 64900, eval_loss: 5.97111e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:17:44.792889 22392998065984 run_lib.py:146] step: 64950, training_loss: 6.11100e-02
I0514 04:18:08.736975 22392998065984 run_lib.py:146] step: 65000, training_loss: 6.39222e-02
I0514 04:18:08.894224 22392998065984 run_lib.py:167] step: 65000, eval_loss: 4.36548e-02
I0514 04:18:32.163291 22392998065984 run_lib.py:146] step: 65050, training_loss: 5.59628e-02
I0514 04:18:55.584070 22392998065984 run_lib.py:146] step: 65100, training_loss: 6.15263e-02
I0514 04:18:55.740598 22392998065984 run_lib.py:167] step: 65100, eval_loss: 6.82574e-02
I0514 04:19:19.613246 22392998065984 run_lib.py:146] step: 65150, training_loss: 5.93183e-02
I0514 04:19:42.896551 22392998065984 run_lib.py:146] step: 65200, training_loss: 5.74215e-02
I0514 04:19:43.053509 22392998065984 run_lib.py:167] step: 65200, eval_loss: 5.41511e-02
I0514 04:20:06.767001 22392998065984 run_lib.py:146] step: 65250, training_loss: 5.98413e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:20:30.896412 22392998065984 run_lib.py:146] step: 65300, training_loss: 7.18836e-02
I0514 04:20:31.404274 22392998065984 run_lib.py:167] step: 65300, eval_loss: 6.05570e-02
I0514 04:20:54.852392 22392998065984 run_lib.py:146] step: 65350, training_loss: 6.17559e-02
I0514 04:21:18.161228 22392998065984 run_lib.py:146] step: 65400, training_loss: 5.49698e-02
I0514 04:21:18.317722 22392998065984 run_lib.py:167] step: 65400, eval_loss: 6.98172e-02
I0514 04:21:41.933672 22392998065984 run_lib.py:146] step: 65450, training_loss: 6.79708e-02
I0514 04:22:05.670136 22392998065984 run_lib.py:146] step: 65500, training_loss: 6.51592e-02
I0514 04:22:05.827008 22392998065984 run_lib.py:167] step: 65500, eval_loss: 6.48687e-02
I0514 04:22:29.574159 22392998065984 run_lib.py:146] step: 65550, training_loss: 6.80612e-02
I0514 04:22:53.246211 22392998065984 run_lib.py:146] step: 65600, training_loss: 4.63394e-02
I0514 04:22:53.402467 22392998065984 run_lib.py:167] step: 65600, eval_loss: 5.09782e-02
I0514 04:23:17.706817 22392998065984 run_lib.py:146] step: 65650, training_loss: 6.46721e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:23:41.486545 22392998065984 run_lib.py:146] step: 65700, training_loss: 6.38724e-02
I0514 04:23:41.644179 22392998065984 run_lib.py:167] step: 65700, eval_loss: 4.99177e-02
I0514 04:24:04.935044 22392998065984 run_lib.py:146] step: 65750, training_loss: 7.78643e-02
I0514 04:24:28.890885 22392998065984 run_lib.py:146] step: 65800, training_loss: 7.51955e-02
I0514 04:24:29.047358 22392998065984 run_lib.py:167] step: 65800, eval_loss: 5.90886e-02
I0514 04:24:52.301062 22392998065984 run_lib.py:146] step: 65850, training_loss: 5.73243e-02
I0514 04:25:15.556138 22392998065984 run_lib.py:146] step: 65900, training_loss: 6.57285e-02
I0514 04:25:15.713133 22392998065984 run_lib.py:167] step: 65900, eval_loss: 5.27703e-02
I0514 04:25:39.539829 22392998065984 run_lib.py:146] step: 65950, training_loss: 5.74246e-02
I0514 04:26:02.912399 22392998065984 run_lib.py:146] step: 66000, training_loss: 5.99012e-02
I0514 04:26:03.068526 22392998065984 run_lib.py:167] step: 66000, eval_loss: 5.38833e-02
I0514 04:26:26.816624 22392998065984 run_lib.py:146] step: 66050, training_loss: 5.11305e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:26:51.202383 22392998065984 run_lib.py:146] step: 66100, training_loss: 4.95610e-02
I0514 04:26:51.360507 22392998065984 run_lib.py:167] step: 66100, eval_loss: 6.55490e-02
I0514 04:27:14.615815 22392998065984 run_lib.py:146] step: 66150, training_loss: 6.27736e-02
I0514 04:27:37.879285 22392998065984 run_lib.py:146] step: 66200, training_loss: 7.77942e-02
I0514 04:27:38.035712 22392998065984 run_lib.py:167] step: 66200, eval_loss: 5.96998e-02
I0514 04:28:01.596286 22392998065984 run_lib.py:146] step: 66250, training_loss: 5.27380e-02
I0514 04:28:25.157099 22392998065984 run_lib.py:146] step: 66300, training_loss: 7.60178e-02
I0514 04:28:25.313336 22392998065984 run_lib.py:167] step: 66300, eval_loss: 6.73739e-02
I0514 04:28:48.575249 22392998065984 run_lib.py:146] step: 66350, training_loss: 6.11185e-02
I0514 04:29:11.836112 22392998065984 run_lib.py:146] step: 66400, training_loss: 5.33646e-02
I0514 04:29:11.992121 22392998065984 run_lib.py:167] step: 66400, eval_loss: 4.93883e-02
I0514 04:29:35.836549 22392998065984 run_lib.py:146] step: 66450, training_loss: 5.59768e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:29:59.240996 22392998065984 run_lib.py:146] step: 66500, training_loss: 5.53476e-02
I0514 04:29:59.399234 22392998065984 run_lib.py:167] step: 66500, eval_loss: 4.90108e-02
I0514 04:30:22.672495 22392998065984 run_lib.py:146] step: 66550, training_loss: 6.73709e-02
I0514 04:30:46.593998 22392998065984 run_lib.py:146] step: 66600, training_loss: 5.56664e-02
I0514 04:30:46.750808 22392998065984 run_lib.py:167] step: 66600, eval_loss: 5.41638e-02
I0514 04:31:10.152999 22392998065984 run_lib.py:146] step: 66650, training_loss: 5.51523e-02
I0514 04:31:33.884703 22392998065984 run_lib.py:146] step: 66700, training_loss: 7.79800e-02
I0514 04:31:34.041223 22392998065984 run_lib.py:167] step: 66700, eval_loss: 4.89163e-02
I0514 04:31:58.365069 22392998065984 run_lib.py:146] step: 66750, training_loss: 6.70261e-02
I0514 04:32:22.109943 22392998065984 run_lib.py:146] step: 66800, training_loss: 5.32736e-02
I0514 04:32:22.266502 22392998065984 run_lib.py:167] step: 66800, eval_loss: 4.60523e-02
I0514 04:32:46.006916 22392998065984 run_lib.py:146] step: 66850, training_loss: 6.52793e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:33:10.220459 22392998065984 run_lib.py:146] step: 66900, training_loss: 6.86135e-02
I0514 04:33:10.377983 22392998065984 run_lib.py:167] step: 66900, eval_loss: 4.93422e-02
I0514 04:33:33.637017 22392998065984 run_lib.py:146] step: 66950, training_loss: 6.03578e-02
I0514 04:33:56.906068 22392998065984 run_lib.py:146] step: 67000, training_loss: 5.53275e-02
I0514 04:33:57.062713 22392998065984 run_lib.py:167] step: 67000, eval_loss: 4.81426e-02
I0514 04:34:20.900240 22392998065984 run_lib.py:146] step: 67050, training_loss: 6.63137e-02
I0514 04:34:44.137133 22392998065984 run_lib.py:146] step: 67100, training_loss: 5.37116e-02
I0514 04:34:44.294066 22392998065984 run_lib.py:167] step: 67100, eval_loss: 6.13838e-02
I0514 04:35:07.538872 22392998065984 run_lib.py:146] step: 67150, training_loss: 6.42987e-02
I0514 04:35:30.777992 22392998065984 run_lib.py:146] step: 67200, training_loss: 5.40230e-02
I0514 04:35:30.934114 22392998065984 run_lib.py:167] step: 67200, eval_loss: 6.49496e-02
I0514 04:35:55.173408 22392998065984 run_lib.py:146] step: 67250, training_loss: 5.38111e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:36:18.599585 22392998065984 run_lib.py:146] step: 67300, training_loss: 6.55002e-02
I0514 04:36:18.757566 22392998065984 run_lib.py:167] step: 67300, eval_loss: 5.82126e-02
I0514 04:36:42.016764 22392998065984 run_lib.py:146] step: 67350, training_loss: 6.21705e-02
I0514 04:37:05.941142 22392998065984 run_lib.py:146] step: 67400, training_loss: 8.03876e-02
I0514 04:37:06.097709 22392998065984 run_lib.py:167] step: 67400, eval_loss: 5.94416e-02
I0514 04:37:29.358122 22392998065984 run_lib.py:146] step: 67450, training_loss: 7.82822e-02
I0514 04:37:52.618738 22392998065984 run_lib.py:146] step: 67500, training_loss: 6.28564e-02
I0514 04:37:52.774946 22392998065984 run_lib.py:167] step: 67500, eval_loss: 7.92269e-02
I0514 04:38:16.595329 22392998065984 run_lib.py:146] step: 67550, training_loss: 5.62420e-02
I0514 04:38:39.847934 22392998065984 run_lib.py:146] step: 67600, training_loss: 4.92480e-02
I0514 04:38:40.004458 22392998065984 run_lib.py:167] step: 67600, eval_loss: 8.77843e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:39:03.417635 22392998065984 run_lib.py:146] step: 67650, training_loss: 4.85088e-02
I0514 04:39:27.381139 22392998065984 run_lib.py:146] step: 67700, training_loss: 7.51344e-02
I0514 04:39:27.538552 22392998065984 run_lib.py:167] step: 67700, eval_loss: 6.09933e-02
I0514 04:39:50.813127 22392998065984 run_lib.py:146] step: 67750, training_loss: 6.74213e-02
I0514 04:40:14.409144 22392998065984 run_lib.py:146] step: 67800, training_loss: 7.75324e-02
I0514 04:40:14.565680 22392998065984 run_lib.py:167] step: 67800, eval_loss: 6.31687e-02
I0514 04:40:38.871537 22392998065984 run_lib.py:146] step: 67850, training_loss: 4.42873e-02
I0514 04:41:02.148687 22392998065984 run_lib.py:146] step: 67900, training_loss: 5.81975e-02
I0514 04:41:02.304873 22392998065984 run_lib.py:167] step: 67900, eval_loss: 7.09209e-02
I0514 04:41:25.583257 22392998065984 run_lib.py:146] step: 67950, training_loss: 7.01255e-02
I0514 04:41:49.161460 22392998065984 run_lib.py:146] step: 68000, training_loss: 5.72470e-02
I0514 04:41:49.317783 22392998065984 run_lib.py:167] step: 68000, eval_loss: 6.49863e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:42:13.157042 22392998065984 run_lib.py:146] step: 68050, training_loss: 8.59375e-02
I0514 04:42:36.903946 22392998065984 run_lib.py:146] step: 68100, training_loss: 6.77528e-02
I0514 04:42:37.061848 22392998065984 run_lib.py:167] step: 68100, eval_loss: 7.48090e-02
I0514 04:43:00.805691 22392998065984 run_lib.py:146] step: 68150, training_loss: 6.41455e-02
I0514 04:43:25.183461 22392998065984 run_lib.py:146] step: 68200, training_loss: 6.62923e-02
I0514 04:43:25.339761 22392998065984 run_lib.py:167] step: 68200, eval_loss: 6.34754e-02
I0514 04:43:49.077366 22392998065984 run_lib.py:146] step: 68250, training_loss: 6.65509e-02
I0514 04:44:12.825635 22392998065984 run_lib.py:146] step: 68300, training_loss: 7.21745e-02
I0514 04:44:12.982322 22392998065984 run_lib.py:167] step: 68300, eval_loss: 6.79317e-02
I0514 04:44:37.312949 22392998065984 run_lib.py:146] step: 68350, training_loss: 7.33500e-02
I0514 04:45:01.052870 22392998065984 run_lib.py:146] step: 68400, training_loss: 7.11601e-02
I0514 04:45:01.209586 22392998065984 run_lib.py:167] step: 68400, eval_loss: 5.56904e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:45:24.862224 22392998065984 run_lib.py:146] step: 68450, training_loss: 6.18787e-02
I0514 04:45:48.795402 22392998065984 run_lib.py:146] step: 68500, training_loss: 5.96690e-02
I0514 04:45:48.952778 22392998065984 run_lib.py:167] step: 68500, eval_loss: 4.64315e-02
I0514 04:46:12.219163 22392998065984 run_lib.py:146] step: 68550, training_loss: 6.94161e-02
I0514 04:46:35.493059 22392998065984 run_lib.py:146] step: 68600, training_loss: 5.18931e-02
I0514 04:46:35.649517 22392998065984 run_lib.py:167] step: 68600, eval_loss: 6.09250e-02
I0514 04:46:59.536230 22392998065984 run_lib.py:146] step: 68650, training_loss: 6.65035e-02
I0514 04:47:22.794505 22392998065984 run_lib.py:146] step: 68700, training_loss: 7.13478e-02
I0514 04:47:22.950747 22392998065984 run_lib.py:167] step: 68700, eval_loss: 6.14989e-02
I0514 04:47:46.192093 22392998065984 run_lib.py:146] step: 68750, training_loss: 7.76254e-02
I0514 04:48:09.752839 22392998065984 run_lib.py:146] step: 68800, training_loss: 4.70588e-02
I0514 04:48:09.909213 22392998065984 run_lib.py:167] step: 68800, eval_loss: 6.12265e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:48:33.908041 22392998065984 run_lib.py:146] step: 68850, training_loss: 6.83812e-02
I0514 04:48:57.661156 22392998065984 run_lib.py:146] step: 68900, training_loss: 9.96435e-02
I0514 04:48:57.818880 22392998065984 run_lib.py:167] step: 68900, eval_loss: 5.52693e-02
I0514 04:49:21.563205 22392998065984 run_lib.py:146] step: 68950, training_loss: 5.13450e-02
I0514 04:49:45.945342 22392998065984 run_lib.py:146] step: 69000, training_loss: 4.82929e-02
I0514 04:49:46.101945 22392998065984 run_lib.py:167] step: 69000, eval_loss: 5.77373e-02
I0514 04:50:09.722579 22392998065984 run_lib.py:146] step: 69050, training_loss: 4.70471e-02
I0514 04:50:32.970263 22392998065984 run_lib.py:146] step: 69100, training_loss: 7.04123e-02
I0514 04:50:33.126375 22392998065984 run_lib.py:167] step: 69100, eval_loss: 5.12334e-02
I0514 04:50:57.000545 22392998065984 run_lib.py:146] step: 69150, training_loss: 6.16435e-02
I0514 04:51:20.279721 22392998065984 run_lib.py:146] step: 69200, training_loss: 8.00878e-02
I0514 04:51:20.436057 22392998065984 run_lib.py:167] step: 69200, eval_loss: 5.46906e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:51:44.255659 22392998065984 run_lib.py:146] step: 69250, training_loss: 6.10638e-02
I0514 04:52:08.663511 22392998065984 run_lib.py:146] step: 69300, training_loss: 4.52524e-02
I0514 04:52:08.820958 22392998065984 run_lib.py:167] step: 69300, eval_loss: 6.02652e-02
I0514 04:52:32.566313 22392998065984 run_lib.py:146] step: 69350, training_loss: 5.38042e-02
I0514 04:52:56.310924 22392998065984 run_lib.py:146] step: 69400, training_loss: 5.13954e-02
I0514 04:52:56.467873 22392998065984 run_lib.py:167] step: 69400, eval_loss: 7.26405e-02
I0514 04:53:20.794023 22392998065984 run_lib.py:146] step: 69450, training_loss: 5.75576e-02
I0514 04:53:44.523708 22392998065984 run_lib.py:146] step: 69500, training_loss: 7.38265e-02
I0514 04:53:44.680010 22392998065984 run_lib.py:167] step: 69500, eval_loss: 8.44519e-02
I0514 04:54:08.266208 22392998065984 run_lib.py:146] step: 69550, training_loss: 5.00896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:54:31.951673 22392998065984 run_lib.py:146] step: 69600, training_loss: 6.18580e-02
I0514 04:54:32.109796 22392998065984 run_lib.py:167] step: 69600, eval_loss: 7.54916e-02
I0514 04:54:55.734584 22392998065984 run_lib.py:146] step: 69650, training_loss: 5.57481e-02
I0514 04:55:18.989673 22392998065984 run_lib.py:146] step: 69700, training_loss: 4.87562e-02
I0514 04:55:19.146076 22392998065984 run_lib.py:167] step: 69700, eval_loss: 4.55387e-02
I0514 04:55:42.406478 22392998065984 run_lib.py:146] step: 69750, training_loss: 6.15672e-02
I0514 04:56:06.290618 22392998065984 run_lib.py:146] step: 69800, training_loss: 6.63754e-02
I0514 04:56:06.447199 22392998065984 run_lib.py:167] step: 69800, eval_loss: 5.94314e-02
I0514 04:56:29.718808 22392998065984 run_lib.py:146] step: 69850, training_loss: 6.36672e-02
I0514 04:56:53.203439 22392998065984 run_lib.py:146] step: 69900, training_loss: 5.76953e-02
I0514 04:56:53.360005 22392998065984 run_lib.py:167] step: 69900, eval_loss: 6.98544e-02
I0514 04:57:17.665701 22392998065984 run_lib.py:146] step: 69950, training_loss: 6.24787e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 04:57:41.059341 22392998065984 run_lib.py:146] step: 70000, training_loss: 5.72399e-02
I0514 04:57:51.754492 22392998065984 run_lib.py:167] step: 70000, eval_loss: 6.27337e-02
I0514 04:58:25.316645 22392998065984 run_lib.py:146] step: 70050, training_loss: 7.20432e-02
I0514 04:58:49.394291 22392998065984 run_lib.py:146] step: 70100, training_loss: 5.56659e-02
I0514 04:58:49.551022 22392998065984 run_lib.py:167] step: 70100, eval_loss: 4.45612e-02
I0514 04:59:13.297229 22392998065984 run_lib.py:146] step: 70150, training_loss: 5.83714e-02
I0514 04:59:37.324921 22392998065984 run_lib.py:146] step: 70200, training_loss: 6.46703e-02
I0514 04:59:37.481173 22392998065984 run_lib.py:167] step: 70200, eval_loss: 5.84268e-02
I0514 05:00:01.528510 22392998065984 run_lib.py:146] step: 70250, training_loss: 7.31589e-02
I0514 05:00:25.255304 22392998065984 run_lib.py:146] step: 70300, training_loss: 5.02697e-02
I0514 05:00:25.412128 22392998065984 run_lib.py:167] step: 70300, eval_loss: 7.90038e-02
I0514 05:00:49.426395 22392998065984 run_lib.py:146] step: 70350, training_loss: 7.91549e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:01:13.471306 22392998065984 run_lib.py:146] step: 70400, training_loss: 5.48516e-02
I0514 05:01:13.629121 22392998065984 run_lib.py:167] step: 70400, eval_loss: 6.84321e-02
I0514 05:01:36.894232 22392998065984 run_lib.py:146] step: 70450, training_loss: 6.20341e-02
I0514 05:02:00.165411 22392998065984 run_lib.py:146] step: 70500, training_loss: 5.92576e-02
I0514 05:02:00.322264 22392998065984 run_lib.py:167] step: 70500, eval_loss: 5.54447e-02
I0514 05:02:23.918250 22392998065984 run_lib.py:146] step: 70550, training_loss: 5.17393e-02
I0514 05:02:47.469050 22392998065984 run_lib.py:146] step: 70600, training_loss: 6.38948e-02
I0514 05:02:47.625827 22392998065984 run_lib.py:167] step: 70600, eval_loss: 6.46316e-02
I0514 05:03:10.880530 22392998065984 run_lib.py:146] step: 70650, training_loss: 6.06306e-02
I0514 05:03:34.620758 22392998065984 run_lib.py:146] step: 70700, training_loss: 7.97858e-02
I0514 05:03:34.777379 22392998065984 run_lib.py:167] step: 70700, eval_loss: 6.63802e-02
I0514 05:03:58.701929 22392998065984 run_lib.py:146] step: 70750, training_loss: 4.94994e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:04:22.091228 22392998065984 run_lib.py:146] step: 70800, training_loss: 4.71484e-02
I0514 05:04:22.263189 22392998065984 run_lib.py:167] step: 70800, eval_loss: 7.19919e-02
I0514 05:04:45.875648 22392998065984 run_lib.py:146] step: 70850, training_loss: 7.36201e-02
I0514 05:05:09.460139 22392998065984 run_lib.py:146] step: 70900, training_loss: 6.23766e-02
I0514 05:05:09.615438 22392998065984 run_lib.py:167] step: 70900, eval_loss: 7.00190e-02
I0514 05:05:32.883644 22392998065984 run_lib.py:146] step: 70950, training_loss: 5.36326e-02
I0514 05:05:56.454396 22392998065984 run_lib.py:146] step: 71000, training_loss: 5.53406e-02
I0514 05:05:56.532517 22392998065984 run_lib.py:167] step: 71000, eval_loss: 5.32872e-02
I0514 05:06:20.089409 22392998065984 run_lib.py:146] step: 71050, training_loss: 6.73074e-02
I0514 05:06:43.380072 22392998065984 run_lib.py:146] step: 71100, training_loss: 5.62562e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:06:43.748421 22392998065984 run_lib.py:167] step: 71100, eval_loss: 7.61100e-02
I0514 05:07:07.838885 22392998065984 run_lib.py:146] step: 71150, training_loss: 4.40489e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:07:32.046149 22392998065984 run_lib.py:146] step: 71200, training_loss: 5.03864e-02
I0514 05:07:32.204248 22392998065984 run_lib.py:167] step: 71200, eval_loss: 5.67282e-02
I0514 05:07:55.781044 22392998065984 run_lib.py:146] step: 71250, training_loss: 4.77722e-02
I0514 05:08:19.057713 22392998065984 run_lib.py:146] step: 71300, training_loss: 5.59047e-02
I0514 05:08:19.214523 22392998065984 run_lib.py:167] step: 71300, eval_loss: 6.38570e-02
I0514 05:08:43.496150 22392998065984 run_lib.py:146] step: 71350, training_loss: 6.73716e-02
I0514 05:09:07.228699 22392998065984 run_lib.py:146] step: 71400, training_loss: 5.52663e-02
I0514 05:09:07.385333 22392998065984 run_lib.py:167] step: 71400, eval_loss: 4.76513e-02
I0514 05:09:31.122667 22392998065984 run_lib.py:146] step: 71450, training_loss: 7.02568e-02
I0514 05:09:55.118973 22392998065984 run_lib.py:146] step: 71500, training_loss: 5.57797e-02
I0514 05:09:55.275391 22392998065984 run_lib.py:167] step: 71500, eval_loss: 4.95600e-02
I0514 05:10:19.327564 22392998065984 run_lib.py:146] step: 71550, training_loss: 6.85681e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:10:42.764266 22392998065984 run_lib.py:146] step: 71600, training_loss: 6.31748e-02
I0514 05:10:42.922377 22392998065984 run_lib.py:167] step: 71600, eval_loss: 5.79070e-02
I0514 05:11:06.538856 22392998065984 run_lib.py:146] step: 71650, training_loss: 6.87292e-02
I0514 05:11:30.152508 22392998065984 run_lib.py:146] step: 71700, training_loss: 7.24296e-02
I0514 05:11:30.309646 22392998065984 run_lib.py:167] step: 71700, eval_loss: 6.58801e-02
I0514 05:11:53.564620 22392998065984 run_lib.py:146] step: 71750, training_loss: 6.97385e-02
I0514 05:12:17.120866 22392998065984 run_lib.py:146] step: 71800, training_loss: 4.38075e-02
I0514 05:12:17.277570 22392998065984 run_lib.py:167] step: 71800, eval_loss: 7.15100e-02
I0514 05:12:40.820852 22392998065984 run_lib.py:146] step: 71850, training_loss: 4.90064e-02
I0514 05:13:04.237931 22392998065984 run_lib.py:146] step: 71900, training_loss: 6.60256e-02
I0514 05:13:04.393830 22392998065984 run_lib.py:167] step: 71900, eval_loss: 6.62154e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:13:28.555728 22392998065984 run_lib.py:146] step: 71950, training_loss: 5.76425e-02
I0514 05:13:52.646034 22392998065984 run_lib.py:146] step: 72000, training_loss: 5.67146e-02
I0514 05:13:52.803612 22392998065984 run_lib.py:167] step: 72000, eval_loss: 5.70370e-02
I0514 05:14:16.550652 22392998065984 run_lib.py:146] step: 72050, training_loss: 6.09443e-02
I0514 05:14:40.276746 22392998065984 run_lib.py:146] step: 72100, training_loss: 5.20261e-02
I0514 05:14:40.433717 22392998065984 run_lib.py:167] step: 72100, eval_loss: 6.51635e-02
I0514 05:15:03.985765 22392998065984 run_lib.py:146] step: 72150, training_loss: 5.79372e-02
I0514 05:15:27.264760 22392998065984 run_lib.py:146] step: 72200, training_loss: 5.38334e-02
I0514 05:15:27.421178 22392998065984 run_lib.py:167] step: 72200, eval_loss: 7.09088e-02
I0514 05:15:50.699330 22392998065984 run_lib.py:146] step: 72250, training_loss: 5.60654e-02
I0514 05:16:14.264960 22392998065984 run_lib.py:146] step: 72300, training_loss: 4.56144e-02
I0514 05:16:14.421370 22392998065984 run_lib.py:167] step: 72300, eval_loss: 5.11888e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:16:38.300627 22392998065984 run_lib.py:146] step: 72350, training_loss: 5.31444e-02
I0514 05:17:01.840867 22392998065984 run_lib.py:146] step: 72400, training_loss: 6.45366e-02
I0514 05:17:02.016397 22392998065984 run_lib.py:167] step: 72400, eval_loss: 4.68461e-02
I0514 05:17:25.607903 22392998065984 run_lib.py:146] step: 72450, training_loss: 6.37540e-02
I0514 05:17:49.179779 22392998065984 run_lib.py:146] step: 72500, training_loss: 4.98041e-02
I0514 05:17:49.336165 22392998065984 run_lib.py:167] step: 72500, eval_loss: 4.83015e-02
I0514 05:18:12.568923 22392998065984 run_lib.py:146] step: 72550, training_loss: 6.16540e-02
I0514 05:18:36.103981 22392998065984 run_lib.py:146] step: 72600, training_loss: 7.11052e-02
I0514 05:18:36.260331 22392998065984 run_lib.py:167] step: 72600, eval_loss: 5.11384e-02
I0514 05:18:59.795074 22392998065984 run_lib.py:146] step: 72650, training_loss: 5.72609e-02
I0514 05:19:23.041021 22392998065984 run_lib.py:146] step: 72700, training_loss: 7.21267e-02
I0514 05:19:23.197511 22392998065984 run_lib.py:167] step: 72700, eval_loss: 5.95520e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:19:46.905488 22392998065984 run_lib.py:146] step: 72750, training_loss: 6.40947e-02
I0514 05:20:10.491005 22392998065984 run_lib.py:146] step: 72800, training_loss: 6.83651e-02
I0514 05:20:10.648363 22392998065984 run_lib.py:167] step: 72800, eval_loss: 5.72550e-02
I0514 05:20:33.906962 22392998065984 run_lib.py:146] step: 72850, training_loss: 6.84045e-02
I0514 05:20:57.463675 22392998065984 run_lib.py:146] step: 72900, training_loss: 6.18326e-02
I0514 05:20:57.619850 22392998065984 run_lib.py:167] step: 72900, eval_loss: 5.04393e-02
I0514 05:21:21.162239 22392998065984 run_lib.py:146] step: 72950, training_loss: 6.82131e-02
I0514 05:21:44.414101 22392998065984 run_lib.py:146] step: 73000, training_loss: 6.22801e-02
I0514 05:21:44.570661 22392998065984 run_lib.py:167] step: 73000, eval_loss: 6.65531e-02
I0514 05:22:07.820476 22392998065984 run_lib.py:146] step: 73050, training_loss: 7.37186e-02
I0514 05:22:31.876610 22392998065984 run_lib.py:146] step: 73100, training_loss: 6.98515e-02
I0514 05:22:32.033329 22392998065984 run_lib.py:167] step: 73100, eval_loss: 5.54602e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:22:55.933281 22392998065984 run_lib.py:146] step: 73150, training_loss: 6.76410e-02
I0514 05:23:19.668998 22392998065984 run_lib.py:146] step: 73200, training_loss: 5.43720e-02
I0514 05:23:19.826844 22392998065984 run_lib.py:167] step: 73200, eval_loss: 4.62330e-02
I0514 05:23:43.915851 22392998065984 run_lib.py:146] step: 73250, training_loss: 6.77858e-02
I0514 05:24:07.694715 22392998065984 run_lib.py:146] step: 73300, training_loss: 6.52402e-02
I0514 05:24:07.851443 22392998065984 run_lib.py:167] step: 73300, eval_loss: 7.44012e-02
I0514 05:24:31.113883 22392998065984 run_lib.py:146] step: 73350, training_loss: 6.24588e-02
I0514 05:24:54.687173 22392998065984 run_lib.py:146] step: 73400, training_loss: 5.17766e-02
I0514 05:24:54.843649 22392998065984 run_lib.py:167] step: 73400, eval_loss: 7.34957e-02
I0514 05:25:18.410352 22392998065984 run_lib.py:146] step: 73450, training_loss: 6.85425e-02
I0514 05:25:41.701143 22392998065984 run_lib.py:146] step: 73500, training_loss: 5.72896e-02
I0514 05:25:41.857961 22392998065984 run_lib.py:167] step: 73500, eval_loss: 5.64544e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:26:05.987696 22392998065984 run_lib.py:146] step: 73550, training_loss: 7.67326e-02
I0514 05:26:30.083910 22392998065984 run_lib.py:146] step: 73600, training_loss: 5.21456e-02
I0514 05:26:30.241934 22392998065984 run_lib.py:167] step: 73600, eval_loss: 6.71517e-02
I0514 05:26:53.978426 22392998065984 run_lib.py:146] step: 73650, training_loss: 8.08800e-02
I0514 05:27:17.983764 22392998065984 run_lib.py:146] step: 73700, training_loss: 6.32335e-02
I0514 05:27:18.140233 22392998065984 run_lib.py:167] step: 73700, eval_loss: 5.70202e-02
I0514 05:27:42.200975 22392998065984 run_lib.py:146] step: 73750, training_loss: 5.15487e-02
I0514 05:28:05.932832 22392998065984 run_lib.py:146] step: 73800, training_loss: 6.84153e-02
I0514 05:28:06.089418 22392998065984 run_lib.py:167] step: 73800, eval_loss: 6.74164e-02
I0514 05:28:29.763401 22392998065984 run_lib.py:146] step: 73850, training_loss: 6.31649e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:28:53.452686 22392998065984 run_lib.py:146] step: 73900, training_loss: 6.56049e-02
I0514 05:28:53.611515 22392998065984 run_lib.py:167] step: 73900, eval_loss: 5.86153e-02
I0514 05:29:17.216047 22392998065984 run_lib.py:146] step: 73950, training_loss: 4.53737e-02
I0514 05:29:40.595212 22392998065984 run_lib.py:146] step: 74000, training_loss: 6.95816e-02
I0514 05:29:40.751612 22392998065984 run_lib.py:167] step: 74000, eval_loss: 6.59817e-02
I0514 05:30:04.837272 22392998065984 run_lib.py:146] step: 74050, training_loss: 7.23137e-02
I0514 05:30:28.878558 22392998065984 run_lib.py:146] step: 74100, training_loss: 7.25995e-02
I0514 05:30:29.034702 22392998065984 run_lib.py:167] step: 74100, eval_loss: 4.51643e-02
I0514 05:30:52.773350 22392998065984 run_lib.py:146] step: 74150, training_loss: 6.52152e-02
I0514 05:31:16.784721 22392998065984 run_lib.py:146] step: 74200, training_loss: 6.31840e-02
I0514 05:31:16.941505 22392998065984 run_lib.py:167] step: 74200, eval_loss: 5.27619e-02
I0514 05:31:40.973968 22392998065984 run_lib.py:146] step: 74250, training_loss: 7.46904e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:32:04.785646 22392998065984 run_lib.py:146] step: 74300, training_loss: 5.35887e-02
I0514 05:32:04.944101 22392998065984 run_lib.py:167] step: 74300, eval_loss: 4.63428e-02
I0514 05:32:28.547163 22392998065984 run_lib.py:146] step: 74350, training_loss: 5.90368e-02
I0514 05:32:52.131850 22392998065984 run_lib.py:146] step: 74400, training_loss: 6.00356e-02
I0514 05:32:52.288214 22392998065984 run_lib.py:167] step: 74400, eval_loss: 7.69670e-02
I0514 05:33:15.561554 22392998065984 run_lib.py:146] step: 74450, training_loss: 7.44506e-02
I0514 05:33:39.139472 22392998065984 run_lib.py:146] step: 74500, training_loss: 4.01783e-02
I0514 05:33:39.295705 22392998065984 run_lib.py:167] step: 74500, eval_loss: 5.09636e-02
I0514 05:34:02.839065 22392998065984 run_lib.py:146] step: 74550, training_loss: 5.26029e-02
I0514 05:34:26.120872 22392998065984 run_lib.py:146] step: 74600, training_loss: 5.99658e-02
I0514 05:34:26.277656 22392998065984 run_lib.py:167] step: 74600, eval_loss: 5.26784e-02
I0514 05:34:49.555441 22392998065984 run_lib.py:146] step: 74650, training_loss: 9.88386e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:35:13.247690 22392998065984 run_lib.py:146] step: 74700, training_loss: 9.69070e-02
I0514 05:35:13.405791 22392998065984 run_lib.py:167] step: 74700, eval_loss: 5.66196e-02
I0514 05:35:36.993203 22392998065984 run_lib.py:146] step: 74750, training_loss: 5.17751e-02
I0514 05:36:00.252188 22392998065984 run_lib.py:146] step: 74800, training_loss: 7.31658e-02
I0514 05:36:00.409021 22392998065984 run_lib.py:167] step: 74800, eval_loss: 7.46585e-02
I0514 05:36:24.008789 22392998065984 run_lib.py:146] step: 74850, training_loss: 6.33849e-02
I0514 05:36:47.574371 22392998065984 run_lib.py:146] step: 74900, training_loss: 6.00742e-02
I0514 05:36:47.730903 22392998065984 run_lib.py:167] step: 74900, eval_loss: 5.41348e-02
I0514 05:37:11.005506 22392998065984 run_lib.py:146] step: 74950, training_loss: 7.50230e-02
I0514 05:37:34.574115 22392998065984 run_lib.py:146] step: 75000, training_loss: 7.72537e-02
I0514 05:37:34.730602 22392998065984 run_lib.py:167] step: 75000, eval_loss: 7.62648e-02
I0514 05:37:58.369807 22392998065984 run_lib.py:146] step: 75050, training_loss: 5.74629e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:38:22.005114 22392998065984 run_lib.py:146] step: 75100, training_loss: 6.38775e-02
I0514 05:38:22.163322 22392998065984 run_lib.py:167] step: 75100, eval_loss: 5.09002e-02
I0514 05:38:45.781295 22392998065984 run_lib.py:146] step: 75150, training_loss: 4.69924e-02
I0514 05:39:09.410845 22392998065984 run_lib.py:146] step: 75200, training_loss: 5.01680e-02
I0514 05:39:09.567061 22392998065984 run_lib.py:167] step: 75200, eval_loss: 5.70441e-02
I0514 05:39:32.837640 22392998065984 run_lib.py:146] step: 75250, training_loss: 6.71639e-02
I0514 05:39:56.388571 22392998065984 run_lib.py:146] step: 75300, training_loss: 8.25184e-02
I0514 05:39:56.545109 22392998065984 run_lib.py:167] step: 75300, eval_loss: 6.42216e-02
I0514 05:40:20.084161 22392998065984 run_lib.py:146] step: 75350, training_loss: 5.28760e-02
I0514 05:40:43.344351 22392998065984 run_lib.py:146] step: 75400, training_loss: 5.35029e-02
I0514 05:40:43.500713 22392998065984 run_lib.py:167] step: 75400, eval_loss: 6.01298e-02
I0514 05:41:07.086192 22392998065984 run_lib.py:146] step: 75450, training_loss: 6.40682e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:41:30.508386 22392998065984 run_lib.py:146] step: 75500, training_loss: 6.91547e-02
I0514 05:41:30.666687 22392998065984 run_lib.py:167] step: 75500, eval_loss: 9.79916e-02
I0514 05:41:54.333550 22392998065984 run_lib.py:146] step: 75550, training_loss: 4.55833e-02
I0514 05:42:18.060839 22392998065984 run_lib.py:146] step: 75600, training_loss: 6.75687e-02
I0514 05:42:18.217767 22392998065984 run_lib.py:167] step: 75600, eval_loss: 6.54048e-02
I0514 05:42:42.270340 22392998065984 run_lib.py:146] step: 75650, training_loss: 5.09037e-02
I0514 05:43:06.314839 22392998065984 run_lib.py:146] step: 75700, training_loss: 5.93525e-02
I0514 05:43:06.471129 22392998065984 run_lib.py:167] step: 75700, eval_loss: 7.22381e-02
I0514 05:43:30.214820 22392998065984 run_lib.py:146] step: 75750, training_loss: 4.60250e-02
I0514 05:43:54.240347 22392998065984 run_lib.py:146] step: 75800, training_loss: 6.25383e-02
I0514 05:43:54.396947 22392998065984 run_lib.py:167] step: 75800, eval_loss: 8.42943e-02
I0514 05:44:17.945632 22392998065984 run_lib.py:146] step: 75850, training_loss: 6.98204e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:44:41.358702 22392998065984 run_lib.py:146] step: 75900, training_loss: 6.51876e-02
I0514 05:44:41.517172 22392998065984 run_lib.py:167] step: 75900, eval_loss: 5.00377e-02
I0514 05:45:05.129745 22392998065984 run_lib.py:146] step: 75950, training_loss: 7.81015e-02
I0514 05:45:28.720871 22392998065984 run_lib.py:146] step: 76000, training_loss: 5.90276e-02
I0514 05:45:28.877676 22392998065984 run_lib.py:167] step: 76000, eval_loss: 6.14858e-02
I0514 05:45:52.142298 22392998065984 run_lib.py:146] step: 76050, training_loss: 6.11636e-02
I0514 05:46:15.718372 22392998065984 run_lib.py:146] step: 76100, training_loss: 5.81753e-02
I0514 05:46:15.875089 22392998065984 run_lib.py:167] step: 76100, eval_loss: 5.46193e-02
I0514 05:46:39.418320 22392998065984 run_lib.py:146] step: 76150, training_loss: 6.42718e-02
I0514 05:47:02.678641 22392998065984 run_lib.py:146] step: 76200, training_loss: 6.41919e-02
I0514 05:47:02.835035 22392998065984 run_lib.py:167] step: 76200, eval_loss: 6.83276e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:47:26.660938 22392998065984 run_lib.py:146] step: 76250, training_loss: 7.03181e-02
I0514 05:47:50.738526 22392998065984 run_lib.py:146] step: 76300, training_loss: 6.37475e-02
I0514 05:47:50.895989 22392998065984 run_lib.py:167] step: 76300, eval_loss: 4.92016e-02
I0514 05:48:14.637749 22392998065984 run_lib.py:146] step: 76350, training_loss: 6.36355e-02
I0514 05:48:38.370187 22392998065984 run_lib.py:146] step: 76400, training_loss: 5.91691e-02
I0514 05:48:38.526694 22392998065984 run_lib.py:167] step: 76400, eval_loss: 7.14263e-02
I0514 05:49:02.539277 22392998065984 run_lib.py:146] step: 76450, training_loss: 6.44795e-02
I0514 05:49:26.584565 22392998065984 run_lib.py:146] step: 76500, training_loss: 5.83720e-02
I0514 05:49:26.741223 22392998065984 run_lib.py:167] step: 76500, eval_loss: 3.47480e-02
I0514 05:49:50.474743 22392998065984 run_lib.py:146] step: 76550, training_loss: 5.19961e-02
I0514 05:50:14.483700 22392998065984 run_lib.py:146] step: 76600, training_loss: 5.68499e-02
I0514 05:50:14.639910 22392998065984 run_lib.py:167] step: 76600, eval_loss: 6.48598e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:50:38.678745 22392998065984 run_lib.py:146] step: 76650, training_loss: 6.31124e-02
I0514 05:51:01.941024 22392998065984 run_lib.py:146] step: 76700, training_loss: 5.65716e-02
I0514 05:51:02.098523 22392998065984 run_lib.py:167] step: 76700, eval_loss: 7.72300e-02
I0514 05:51:25.698265 22392998065984 run_lib.py:146] step: 76750, training_loss: 5.03770e-02
I0514 05:51:49.273147 22392998065984 run_lib.py:146] step: 76800, training_loss: 4.30046e-02
I0514 05:51:49.429522 22392998065984 run_lib.py:167] step: 76800, eval_loss: 5.83518e-02
I0514 05:52:12.702376 22392998065984 run_lib.py:146] step: 76850, training_loss: 6.15313e-02
I0514 05:52:36.245223 22392998065984 run_lib.py:146] step: 76900, training_loss: 5.15914e-02
I0514 05:52:36.401757 22392998065984 run_lib.py:167] step: 76900, eval_loss: 6.28868e-02
I0514 05:52:59.971966 22392998065984 run_lib.py:146] step: 76950, training_loss: 5.51441e-02
I0514 05:53:23.245548 22392998065984 run_lib.py:146] step: 77000, training_loss: 6.68778e-02
I0514 05:53:23.401835 22392998065984 run_lib.py:167] step: 77000, eval_loss: 7.64034e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:53:47.142934 22392998065984 run_lib.py:146] step: 77050, training_loss: 6.08272e-02
I0514 05:54:11.034894 22392998065984 run_lib.py:146] step: 77100, training_loss: 5.73160e-02
I0514 05:54:11.192616 22392998065984 run_lib.py:167] step: 77100, eval_loss: 5.92205e-02
I0514 05:54:34.923637 22392998065984 run_lib.py:146] step: 77150, training_loss: 5.42993e-02
I0514 05:54:58.600068 22392998065984 run_lib.py:146] step: 77200, training_loss: 7.50022e-02
I0514 05:54:58.756794 22392998065984 run_lib.py:167] step: 77200, eval_loss: 6.31899e-02
I0514 05:55:22.333765 22392998065984 run_lib.py:146] step: 77250, training_loss: 4.26169e-02
I0514 05:55:45.868746 22392998065984 run_lib.py:146] step: 77300, training_loss: 6.37424e-02
I0514 05:55:46.025736 22392998065984 run_lib.py:167] step: 77300, eval_loss: 6.38861e-02
I0514 05:56:09.269554 22392998065984 run_lib.py:146] step: 77350, training_loss: 5.87846e-02
I0514 05:56:32.806708 22392998065984 run_lib.py:146] step: 77400, training_loss: 5.78989e-02
I0514 05:56:32.962925 22392998065984 run_lib.py:167] step: 77400, eval_loss: 6.35492e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 05:56:56.965875 22392998065984 run_lib.py:146] step: 77450, training_loss: 6.08144e-02
I0514 05:57:20.509168 22392998065984 run_lib.py:146] step: 77500, training_loss: 4.86430e-02
I0514 05:57:20.666598 22392998065984 run_lib.py:167] step: 77500, eval_loss: 5.78824e-02
I0514 05:57:44.258873 22392998065984 run_lib.py:146] step: 77550, training_loss: 5.60622e-02
I0514 05:58:07.847131 22392998065984 run_lib.py:146] step: 77600, training_loss: 8.19249e-02
I0514 05:58:08.004333 22392998065984 run_lib.py:167] step: 77600, eval_loss: 4.92094e-02
I0514 05:58:31.276543 22392998065984 run_lib.py:146] step: 77650, training_loss: 5.53820e-02
I0514 05:58:54.988807 22392998065984 run_lib.py:146] step: 77700, training_loss: 6.74744e-02
I0514 05:58:55.145361 22392998065984 run_lib.py:167] step: 77700, eval_loss: 6.12065e-02
I0514 05:59:19.184917 22392998065984 run_lib.py:146] step: 77750, training_loss: 5.06260e-02
I0514 05:59:42.918594 22392998065984 run_lib.py:146] step: 77800, training_loss: 6.88840e-02
I0514 05:59:43.074985 22392998065984 run_lib.py:167] step: 77800, eval_loss: 5.16624e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:00:06.927830 22392998065984 run_lib.py:146] step: 77850, training_loss: 5.40088e-02
I0514 06:00:30.516352 22392998065984 run_lib.py:146] step: 77900, training_loss: 4.61488e-02
I0514 06:00:30.673995 22392998065984 run_lib.py:167] step: 77900, eval_loss: 7.12378e-02
I0514 06:00:53.955554 22392998065984 run_lib.py:146] step: 77950, training_loss: 6.59872e-02
I0514 06:01:17.231999 22392998065984 run_lib.py:146] step: 78000, training_loss: 6.34537e-02
I0514 06:01:17.388599 22392998065984 run_lib.py:167] step: 78000, eval_loss: 5.31076e-02
I0514 06:01:40.959664 22392998065984 run_lib.py:146] step: 78050, training_loss: 4.72404e-02
I0514 06:02:04.512045 22392998065984 run_lib.py:146] step: 78100, training_loss: 7.53811e-02
I0514 06:02:04.668763 22392998065984 run_lib.py:167] step: 78100, eval_loss: 4.33699e-02
I0514 06:02:27.939952 22392998065984 run_lib.py:146] step: 78150, training_loss: 8.02754e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:02:51.651790 22392998065984 run_lib.py:146] step: 78200, training_loss: 6.64703e-02
I0514 06:02:51.810662 22392998065984 run_lib.py:167] step: 78200, eval_loss: 7.20217e-02
I0514 06:03:15.403769 22392998065984 run_lib.py:146] step: 78250, training_loss: 5.12591e-02
I0514 06:03:38.667156 22392998065984 run_lib.py:146] step: 78300, training_loss: 6.69884e-02
I0514 06:03:38.823505 22392998065984 run_lib.py:167] step: 78300, eval_loss: 6.48156e-02
I0514 06:04:02.444135 22392998065984 run_lib.py:146] step: 78350, training_loss: 6.66857e-02
I0514 06:04:25.989906 22392998065984 run_lib.py:146] step: 78400, training_loss: 7.44355e-02
I0514 06:04:26.146061 22392998065984 run_lib.py:167] step: 78400, eval_loss: 5.97307e-02
I0514 06:04:49.553993 22392998065984 run_lib.py:146] step: 78450, training_loss: 6.80593e-02
I0514 06:05:13.531151 22392998065984 run_lib.py:146] step: 78500, training_loss: 5.12687e-02
I0514 06:05:13.687870 22392998065984 run_lib.py:167] step: 78500, eval_loss: 6.84131e-02
I0514 06:05:37.732414 22392998065984 run_lib.py:146] step: 78550, training_loss: 6.14562e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:06:01.535617 22392998065984 run_lib.py:146] step: 78600, training_loss: 6.85767e-02
I0514 06:06:01.693746 22392998065984 run_lib.py:167] step: 78600, eval_loss: 6.22101e-02
I0514 06:06:25.325997 22392998065984 run_lib.py:146] step: 78650, training_loss: 5.54191e-02
I0514 06:06:48.934237 22392998065984 run_lib.py:146] step: 78700, training_loss: 8.34093e-02
I0514 06:06:49.090685 22392998065984 run_lib.py:167] step: 78700, eval_loss: 6.02530e-02
I0514 06:07:12.319982 22392998065984 run_lib.py:146] step: 78750, training_loss: 4.37126e-02
I0514 06:07:35.575895 22392998065984 run_lib.py:146] step: 78800, training_loss: 6.50653e-02
I0514 06:07:35.731306 22392998065984 run_lib.py:167] step: 78800, eval_loss: 6.21711e-02
I0514 06:07:59.282204 22392998065984 run_lib.py:146] step: 78850, training_loss: 7.05059e-02
I0514 06:08:22.933506 22392998065984 run_lib.py:146] step: 78900, training_loss: 5.94025e-02
I0514 06:08:23.011824 22392998065984 run_lib.py:167] step: 78900, eval_loss: 5.02896e-02
I0514 06:08:46.258989 22392998065984 run_lib.py:146] step: 78950, training_loss: 5.17966e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:09:09.971110 22392998065984 run_lib.py:146] step: 79000, training_loss: 6.42893e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:09:10.337623 22392998065984 run_lib.py:167] step: 79000, eval_loss: 6.44010e-02
I0514 06:09:33.990273 22392998065984 run_lib.py:146] step: 79050, training_loss: 7.36559e-02
I0514 06:09:57.280173 22392998065984 run_lib.py:146] step: 79100, training_loss: 6.05216e-02
I0514 06:09:57.436892 22392998065984 run_lib.py:167] step: 79100, eval_loss: 5.16508e-02
I0514 06:10:21.010726 22392998065984 run_lib.py:146] step: 79150, training_loss: 4.55306e-02
I0514 06:10:44.568877 22392998065984 run_lib.py:146] step: 79200, training_loss: 5.34620e-02
I0514 06:10:44.725281 22392998065984 run_lib.py:167] step: 79200, eval_loss: 6.97508e-02
I0514 06:11:08.007879 22392998065984 run_lib.py:146] step: 79250, training_loss: 5.30232e-02
I0514 06:11:31.578255 22392998065984 run_lib.py:146] step: 79300, training_loss: 5.25676e-02
I0514 06:11:31.734356 22392998065984 run_lib.py:167] step: 79300, eval_loss: 5.82455e-02
I0514 06:11:55.763143 22392998065984 run_lib.py:146] step: 79350, training_loss: 7.48302e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:12:19.391349 22392998065984 run_lib.py:146] step: 79400, training_loss: 6.01970e-02
I0514 06:12:19.549532 22392998065984 run_lib.py:167] step: 79400, eval_loss: 5.72736e-02
I0514 06:12:43.163684 22392998065984 run_lib.py:146] step: 79450, training_loss: 6.36933e-02
I0514 06:13:06.447394 22392998065984 run_lib.py:146] step: 79500, training_loss: 6.19774e-02
I0514 06:13:06.604497 22392998065984 run_lib.py:167] step: 79500, eval_loss: 5.85819e-02
I0514 06:13:30.198713 22392998065984 run_lib.py:146] step: 79550, training_loss: 6.27077e-02
I0514 06:13:53.492529 22392998065984 run_lib.py:146] step: 79600, training_loss: 4.47510e-02
I0514 06:13:53.649276 22392998065984 run_lib.py:167] step: 79600, eval_loss: 6.30423e-02
I0514 06:14:17.206274 22392998065984 run_lib.py:146] step: 79650, training_loss: 5.33602e-02
I0514 06:14:40.750734 22392998065984 run_lib.py:146] step: 79700, training_loss: 5.28650e-02
I0514 06:14:40.907115 22392998065984 run_lib.py:167] step: 79700, eval_loss: 8.16287e-02
I0514 06:15:04.467046 22392998065984 run_lib.py:146] step: 79750, training_loss: 5.89910e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:15:28.649523 22392998065984 run_lib.py:146] step: 79800, training_loss: 6.63875e-02
I0514 06:15:28.806886 22392998065984 run_lib.py:167] step: 79800, eval_loss: 7.07785e-02
I0514 06:15:52.904703 22392998065984 run_lib.py:146] step: 79850, training_loss: 6.40346e-02
I0514 06:16:16.491029 22392998065984 run_lib.py:146] step: 79900, training_loss: 7.46613e-02
I0514 06:16:16.649514 22392998065984 run_lib.py:167] step: 79900, eval_loss: 6.31031e-02
I0514 06:16:40.652675 22392998065984 run_lib.py:146] step: 79950, training_loss: 6.24136e-02
I0514 06:17:04.669364 22392998065984 run_lib.py:146] step: 80000, training_loss: 5.94916e-02
I0514 06:17:13.732999 22392998065984 run_lib.py:167] step: 80000, eval_loss: 6.57382e-02
I0514 06:17:45.840311 22392998065984 run_lib.py:146] step: 80050, training_loss: 5.32990e-02
I0514 06:18:09.101339 22392998065984 run_lib.py:146] step: 80100, training_loss: 8.25333e-02
I0514 06:18:09.257485 22392998065984 run_lib.py:167] step: 80100, eval_loss: 6.99427e-02
I0514 06:18:32.806808 22392998065984 run_lib.py:146] step: 80150, training_loss: 4.19870e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:18:56.607834 22392998065984 run_lib.py:146] step: 80200, training_loss: 7.07433e-02
I0514 06:18:56.765503 22392998065984 run_lib.py:167] step: 80200, eval_loss: 6.14264e-02
I0514 06:19:20.015309 22392998065984 run_lib.py:146] step: 80250, training_loss: 5.89894e-02
I0514 06:19:43.274873 22392998065984 run_lib.py:146] step: 80300, training_loss: 7.52246e-02
I0514 06:19:43.431403 22392998065984 run_lib.py:167] step: 80300, eval_loss: 5.72931e-02
I0514 06:20:07.045008 22392998065984 run_lib.py:146] step: 80350, training_loss: 6.42143e-02
I0514 06:20:30.627850 22392998065984 run_lib.py:146] step: 80400, training_loss: 5.11860e-02
I0514 06:20:30.784478 22392998065984 run_lib.py:167] step: 80400, eval_loss: 9.60844e-02
I0514 06:20:54.148472 22392998065984 run_lib.py:146] step: 80450, training_loss: 6.77686e-02
I0514 06:21:17.688275 22392998065984 run_lib.py:146] step: 80500, training_loss: 6.50788e-02
I0514 06:21:17.844464 22392998065984 run_lib.py:167] step: 80500, eval_loss: 5.83559e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:21:41.533798 22392998065984 run_lib.py:146] step: 80550, training_loss: 6.85228e-02
I0514 06:22:04.802717 22392998065984 run_lib.py:146] step: 80600, training_loss: 4.50366e-02
I0514 06:22:04.960382 22392998065984 run_lib.py:167] step: 80600, eval_loss: 5.43101e-02
I0514 06:22:28.576770 22392998065984 run_lib.py:146] step: 80650, training_loss: 6.67804e-02
I0514 06:22:52.184757 22392998065984 run_lib.py:146] step: 80700, training_loss: 6.34747e-02
I0514 06:22:52.341531 22392998065984 run_lib.py:167] step: 80700, eval_loss: 5.62002e-02
I0514 06:23:15.596655 22392998065984 run_lib.py:146] step: 80750, training_loss: 4.46630e-02
I0514 06:23:39.123244 22392998065984 run_lib.py:146] step: 80800, training_loss: 5.55798e-02
I0514 06:23:39.279466 22392998065984 run_lib.py:167] step: 80800, eval_loss: 5.77457e-02
I0514 06:24:02.848819 22392998065984 run_lib.py:146] step: 80850, training_loss: 5.82697e-02
I0514 06:24:26.106530 22392998065984 run_lib.py:146] step: 80900, training_loss: 5.38588e-02
I0514 06:24:26.262597 22392998065984 run_lib.py:167] step: 80900, eval_loss: 5.65165e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:24:49.990266 22392998065984 run_lib.py:146] step: 80950, training_loss: 6.96356e-02
I0514 06:25:13.239680 22392998065984 run_lib.py:146] step: 81000, training_loss: 4.84422e-02
I0514 06:25:13.397613 22392998065984 run_lib.py:167] step: 81000, eval_loss: 6.97782e-02
I0514 06:25:36.982264 22392998065984 run_lib.py:146] step: 81050, training_loss: 4.52462e-02
I0514 06:26:00.259344 22392998065984 run_lib.py:146] step: 81100, training_loss: 6.45885e-02
I0514 06:26:00.416405 22392998065984 run_lib.py:167] step: 81100, eval_loss: 6.99671e-02
I0514 06:26:24.451555 22392998065984 run_lib.py:146] step: 81150, training_loss: 5.95935e-02
I0514 06:26:48.437331 22392998065984 run_lib.py:146] step: 81200, training_loss: 8.01225e-02
I0514 06:26:48.593654 22392998065984 run_lib.py:167] step: 81200, eval_loss: 6.31426e-02
I0514 06:27:11.854056 22392998065984 run_lib.py:146] step: 81250, training_loss: 5.23246e-02
I0514 06:27:35.377116 22392998065984 run_lib.py:146] step: 81300, training_loss: 6.43615e-02
I0514 06:27:35.533447 22392998065984 run_lib.py:167] step: 81300, eval_loss: 5.65123e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:27:59.233204 22392998065984 run_lib.py:146] step: 81350, training_loss: 6.36066e-02
I0514 06:28:22.507718 22392998065984 run_lib.py:146] step: 81400, training_loss: 4.87544e-02
I0514 06:28:22.665165 22392998065984 run_lib.py:167] step: 81400, eval_loss: 6.25610e-02
I0514 06:28:46.260726 22392998065984 run_lib.py:146] step: 81450, training_loss: 5.70170e-02
I0514 06:29:09.896612 22392998065984 run_lib.py:146] step: 81500, training_loss: 7.11220e-02
I0514 06:29:10.053060 22392998065984 run_lib.py:167] step: 81500, eval_loss: 5.72105e-02
I0514 06:29:33.326553 22392998065984 run_lib.py:146] step: 81550, training_loss: 4.96375e-02
I0514 06:29:56.889641 22392998065984 run_lib.py:146] step: 81600, training_loss: 4.87001e-02
I0514 06:29:57.045913 22392998065984 run_lib.py:167] step: 81600, eval_loss: 6.30018e-02
I0514 06:30:20.577350 22392998065984 run_lib.py:146] step: 81650, training_loss: 6.54902e-02
I0514 06:30:44.247087 22392998065984 run_lib.py:146] step: 81700, training_loss: 5.49254e-02
I0514 06:30:44.403594 22392998065984 run_lib.py:167] step: 81700, eval_loss: 6.65566e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:31:08.155609 22392998065984 run_lib.py:146] step: 81750, training_loss: 4.73541e-02
I0514 06:31:31.767594 22392998065984 run_lib.py:146] step: 81800, training_loss: 6.65262e-02
I0514 06:31:31.924866 22392998065984 run_lib.py:167] step: 81800, eval_loss: 7.30506e-02
I0514 06:31:55.193175 22392998065984 run_lib.py:146] step: 81850, training_loss: 7.03471e-02
I0514 06:32:18.453279 22392998065984 run_lib.py:146] step: 81900, training_loss: 6.33937e-02
I0514 06:32:18.609781 22392998065984 run_lib.py:167] step: 81900, eval_loss: 7.50323e-02
I0514 06:32:42.173016 22392998065984 run_lib.py:146] step: 81950, training_loss: 5.56348e-02
I0514 06:33:05.740790 22392998065984 run_lib.py:146] step: 82000, training_loss: 6.39453e-02
I0514 06:33:05.897797 22392998065984 run_lib.py:167] step: 82000, eval_loss: 5.62340e-02
I0514 06:33:29.148962 22392998065984 run_lib.py:146] step: 82050, training_loss: 6.76757e-02
I0514 06:33:52.720891 22392998065984 run_lib.py:146] step: 82100, training_loss: 6.64971e-02
I0514 06:33:52.892344 22392998065984 run_lib.py:167] step: 82100, eval_loss: 6.36583e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:34:16.725727 22392998065984 run_lib.py:146] step: 82150, training_loss: 4.45034e-02
I0514 06:34:39.971465 22392998065984 run_lib.py:146] step: 82200, training_loss: 5.80315e-02
I0514 06:34:40.128940 22392998065984 run_lib.py:167] step: 82200, eval_loss: 4.56081e-02
I0514 06:35:03.714975 22392998065984 run_lib.py:146] step: 82250, training_loss: 5.37489e-02
I0514 06:35:27.258132 22392998065984 run_lib.py:146] step: 82300, training_loss: 7.56418e-02
I0514 06:35:27.414435 22392998065984 run_lib.py:167] step: 82300, eval_loss: 7.50482e-02
I0514 06:35:50.652203 22392998065984 run_lib.py:146] step: 82350, training_loss: 5.77720e-02
I0514 06:36:14.181899 22392998065984 run_lib.py:146] step: 82400, training_loss: 6.50174e-02
I0514 06:36:14.338024 22392998065984 run_lib.py:167] step: 82400, eval_loss: 6.43301e-02
I0514 06:36:37.880931 22392998065984 run_lib.py:146] step: 82450, training_loss: 5.90999e-02
I0514 06:37:01.000884 22392998065984 run_lib.py:146] step: 82500, training_loss: 6.99982e-02
I0514 06:37:01.157387 22392998065984 run_lib.py:167] step: 82500, eval_loss: 6.42451e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:37:25.024596 22392998065984 run_lib.py:146] step: 82550, training_loss: 6.59050e-02
I0514 06:37:48.614996 22392998065984 run_lib.py:146] step: 82600, training_loss: 5.31785e-02
I0514 06:37:48.771427 22392998065984 run_lib.py:167] step: 82600, eval_loss: 7.52267e-02
I0514 06:38:12.029336 22392998065984 run_lib.py:146] step: 82650, training_loss: 6.29582e-02
I0514 06:38:35.279702 22392998065984 run_lib.py:146] step: 82700, training_loss: 5.74714e-02
I0514 06:38:35.435896 22392998065984 run_lib.py:167] step: 82700, eval_loss: 6.65911e-02
I0514 06:38:59.005192 22392998065984 run_lib.py:146] step: 82750, training_loss: 7.60388e-02
I0514 06:39:22.573070 22392998065984 run_lib.py:146] step: 82800, training_loss: 4.26924e-02
I0514 06:39:22.729913 22392998065984 run_lib.py:167] step: 82800, eval_loss: 8.09274e-02
I0514 06:39:45.970046 22392998065984 run_lib.py:146] step: 82850, training_loss: 5.75036e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:40:09.739180 22392998065984 run_lib.py:146] step: 82900, training_loss: 5.91131e-02
I0514 06:40:09.897383 22392998065984 run_lib.py:167] step: 82900, eval_loss: 6.55677e-02
I0514 06:40:33.507655 22392998065984 run_lib.py:146] step: 82950, training_loss: 6.13998e-02
I0514 06:40:56.773125 22392998065984 run_lib.py:146] step: 83000, training_loss: 5.24173e-02
I0514 06:40:56.929573 22392998065984 run_lib.py:167] step: 83000, eval_loss: 4.49827e-02
I0514 06:41:20.508714 22392998065984 run_lib.py:146] step: 83050, training_loss: 6.57341e-02
I0514 06:41:44.067944 22392998065984 run_lib.py:146] step: 83100, training_loss: 7.90184e-02
I0514 06:41:44.224191 22392998065984 run_lib.py:167] step: 83100, eval_loss: 6.00869e-02
I0514 06:42:07.509388 22392998065984 run_lib.py:146] step: 83150, training_loss: 6.14261e-02
I0514 06:42:31.072823 22392998065984 run_lib.py:146] step: 83200, training_loss: 5.45267e-02
I0514 06:42:31.229046 22392998065984 run_lib.py:167] step: 83200, eval_loss: 4.60630e-02
I0514 06:42:54.787205 22392998065984 run_lib.py:146] step: 83250, training_loss: 6.00423e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:43:18.188250 22392998065984 run_lib.py:146] step: 83300, training_loss: 4.99452e-02
I0514 06:43:18.346258 22392998065984 run_lib.py:167] step: 83300, eval_loss: 4.47361e-02
I0514 06:43:41.943606 22392998065984 run_lib.py:146] step: 83350, training_loss: 5.06387e-02
I0514 06:44:05.587694 22392998065984 run_lib.py:146] step: 83400, training_loss: 1.09055e-01
I0514 06:44:05.744369 22392998065984 run_lib.py:167] step: 83400, eval_loss: 8.42455e-02
I0514 06:44:29.156825 22392998065984 run_lib.py:146] step: 83450, training_loss: 4.81196e-02
I0514 06:44:52.884352 22392998065984 run_lib.py:146] step: 83500, training_loss: 6.27703e-02
I0514 06:44:53.040600 22392998065984 run_lib.py:167] step: 83500, eval_loss: 6.62572e-02
I0514 06:45:16.717820 22392998065984 run_lib.py:146] step: 83550, training_loss: 7.00482e-02
I0514 06:45:40.272570 22392998065984 run_lib.py:146] step: 83600, training_loss: 5.49632e-02
I0514 06:45:40.429194 22392998065984 run_lib.py:167] step: 83600, eval_loss: 6.63891e-02
I0514 06:46:03.700055 22392998065984 run_lib.py:146] step: 83650, training_loss: 7.03409e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:46:27.401983 22392998065984 run_lib.py:146] step: 83700, training_loss: 7.21345e-02
I0514 06:46:27.565859 22392998065984 run_lib.py:167] step: 83700, eval_loss: 7.19876e-02
I0514 06:46:51.140810 22392998065984 run_lib.py:146] step: 83750, training_loss: 5.56052e-02
I0514 06:47:14.387837 22392998065984 run_lib.py:146] step: 83800, training_loss: 6.74058e-02
I0514 06:47:14.544196 22392998065984 run_lib.py:167] step: 83800, eval_loss: 5.67666e-02
I0514 06:47:38.114027 22392998065984 run_lib.py:146] step: 83850, training_loss: 5.72373e-02
I0514 06:48:01.659436 22392998065984 run_lib.py:146] step: 83900, training_loss: 4.98536e-02
I0514 06:48:01.815508 22392998065984 run_lib.py:167] step: 83900, eval_loss: 8.55313e-02
I0514 06:48:25.066435 22392998065984 run_lib.py:146] step: 83950, training_loss: 5.10279e-02
I0514 06:48:48.612639 22392998065984 run_lib.py:146] step: 84000, training_loss: 6.52765e-02
I0514 06:48:48.769814 22392998065984 run_lib.py:167] step: 84000, eval_loss: 5.23575e-02
I0514 06:49:12.361092 22392998065984 run_lib.py:146] step: 84050, training_loss: 5.47109e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:49:36.123144 22392998065984 run_lib.py:146] step: 84100, training_loss: 5.44914e-02
I0514 06:49:36.281280 22392998065984 run_lib.py:167] step: 84100, eval_loss: 6.86461e-02
I0514 06:50:00.366729 22392998065984 run_lib.py:146] step: 84150, training_loss: 6.52777e-02
I0514 06:50:24.406630 22392998065984 run_lib.py:146] step: 84200, training_loss: 4.56654e-02
I0514 06:50:24.562712 22392998065984 run_lib.py:167] step: 84200, eval_loss: 5.29446e-02
I0514 06:50:48.301711 22392998065984 run_lib.py:146] step: 84250, training_loss: 6.55686e-02
I0514 06:51:11.671811 22392998065984 run_lib.py:146] step: 84300, training_loss: 6.21256e-02
I0514 06:51:11.828471 22392998065984 run_lib.py:167] step: 84300, eval_loss: 6.77768e-02
I0514 06:51:35.360919 22392998065984 run_lib.py:146] step: 84350, training_loss: 6.03322e-02
I0514 06:51:58.920567 22392998065984 run_lib.py:146] step: 84400, training_loss: 5.06109e-02
I0514 06:51:59.077202 22392998065984 run_lib.py:167] step: 84400, eval_loss: 5.07566e-02
I0514 06:52:22.324241 22392998065984 run_lib.py:146] step: 84450, training_loss: 5.72928e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:52:46.044816 22392998065984 run_lib.py:146] step: 84500, training_loss: 5.72563e-02
I0514 06:52:46.203430 22392998065984 run_lib.py:167] step: 84500, eval_loss: 5.24278e-02
I0514 06:53:09.793486 22392998065984 run_lib.py:146] step: 84550, training_loss: 8.00860e-02
I0514 06:53:33.030738 22392998065984 run_lib.py:146] step: 84600, training_loss: 6.34847e-02
I0514 06:53:33.186809 22392998065984 run_lib.py:167] step: 84600, eval_loss: 5.28898e-02
I0514 06:53:56.834574 22392998065984 run_lib.py:146] step: 84650, training_loss: 6.58853e-02
I0514 06:54:20.827589 22392998065984 run_lib.py:146] step: 84700, training_loss: 6.42272e-02
I0514 06:54:20.983932 22392998065984 run_lib.py:167] step: 84700, eval_loss: 5.96746e-02
I0514 06:54:44.715128 22392998065984 run_lib.py:146] step: 84750, training_loss: 7.71756e-02
I0514 06:55:08.747303 22392998065984 run_lib.py:146] step: 84800, training_loss: 7.05839e-02
I0514 06:55:08.904017 22392998065984 run_lib.py:167] step: 84800, eval_loss: 5.74802e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:55:33.067020 22392998065984 run_lib.py:146] step: 84850, training_loss: 6.39701e-02
I0514 06:55:56.800151 22392998065984 run_lib.py:146] step: 84900, training_loss: 5.30125e-02
I0514 06:55:56.957759 22392998065984 run_lib.py:167] step: 84900, eval_loss: 5.58595e-02
I0514 06:56:21.030928 22392998065984 run_lib.py:146] step: 84950, training_loss: 8.21213e-02
I0514 06:56:45.074732 22392998065984 run_lib.py:146] step: 85000, training_loss: 6.55454e-02
I0514 06:56:45.230885 22392998065984 run_lib.py:167] step: 85000, eval_loss: 6.18116e-02
I0514 06:57:08.974207 22392998065984 run_lib.py:146] step: 85050, training_loss: 6.45392e-02
I0514 06:57:32.711519 22392998065984 run_lib.py:146] step: 85100, training_loss: 5.03013e-02
I0514 06:57:32.868051 22392998065984 run_lib.py:167] step: 85100, eval_loss: 4.87394e-02
I0514 06:57:56.912506 22392998065984 run_lib.py:146] step: 85150, training_loss: 6.63863e-02
I0514 06:58:20.551723 22392998065984 run_lib.py:146] step: 85200, training_loss: 8.60777e-02
I0514 06:58:20.708138 22392998065984 run_lib.py:167] step: 85200, eval_loss: 5.09847e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 06:58:44.111327 22392998065984 run_lib.py:146] step: 85250, training_loss: 6.11026e-02
I0514 06:59:07.714541 22392998065984 run_lib.py:146] step: 85300, training_loss: 5.52394e-02
I0514 06:59:07.887586 22392998065984 run_lib.py:167] step: 85300, eval_loss: 6.35814e-02
I0514 06:59:31.470980 22392998065984 run_lib.py:146] step: 85350, training_loss: 6.83323e-02
I0514 06:59:54.720100 22392998065984 run_lib.py:146] step: 85400, training_loss: 6.59355e-02
I0514 06:59:54.876220 22392998065984 run_lib.py:167] step: 85400, eval_loss: 6.81476e-02
I0514 07:00:18.437644 22392998065984 run_lib.py:146] step: 85450, training_loss: 6.44622e-02
I0514 07:00:41.997590 22392998065984 run_lib.py:146] step: 85500, training_loss: 6.01655e-02
I0514 07:00:42.153874 22392998065984 run_lib.py:167] step: 85500, eval_loss: 5.52595e-02
I0514 07:01:05.401473 22392998065984 run_lib.py:146] step: 85550, training_loss: 5.40617e-02
I0514 07:01:28.933730 22392998065984 run_lib.py:146] step: 85600, training_loss: 7.41807e-02
I0514 07:01:29.090179 22392998065984 run_lib.py:167] step: 85600, eval_loss: 3.96017e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:01:53.014782 22392998065984 run_lib.py:146] step: 85650, training_loss: 6.35408e-02
I0514 07:02:16.599667 22392998065984 run_lib.py:146] step: 85700, training_loss: 7.00052e-02
I0514 07:02:16.759030 22392998065984 run_lib.py:167] step: 85700, eval_loss: 6.21696e-02
I0514 07:02:40.356139 22392998065984 run_lib.py:146] step: 85750, training_loss: 5.32415e-02
I0514 07:03:03.858599 22392998065984 run_lib.py:146] step: 85800, training_loss: 5.74835e-02
I0514 07:03:04.014924 22392998065984 run_lib.py:167] step: 85800, eval_loss: 5.81826e-02
I0514 07:03:27.285438 22392998065984 run_lib.py:146] step: 85850, training_loss: 6.17686e-02
I0514 07:03:50.571773 22392998065984 run_lib.py:146] step: 85900, training_loss: 5.25892e-02
I0514 07:03:50.729231 22392998065984 run_lib.py:167] step: 85900, eval_loss: 8.15098e-02
I0514 07:04:14.263985 22392998065984 run_lib.py:146] step: 85950, training_loss: 5.87383e-02
I0514 07:04:37.804733 22392998065984 run_lib.py:146] step: 86000, training_loss: 8.17365e-02
I0514 07:04:37.961997 22392998065984 run_lib.py:167] step: 86000, eval_loss: 5.65895e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:05:01.691686 22392998065984 run_lib.py:146] step: 86050, training_loss: 5.23275e-02
I0514 07:05:25.770595 22392998065984 run_lib.py:146] step: 86100, training_loss: 5.78726e-02
I0514 07:05:25.927972 22392998065984 run_lib.py:167] step: 86100, eval_loss: 5.19886e-02
I0514 07:05:49.799965 22392998065984 run_lib.py:146] step: 86150, training_loss: 5.58361e-02
I0514 07:06:13.046491 22392998065984 run_lib.py:146] step: 86200, training_loss: 5.41954e-02
I0514 07:06:13.202804 22392998065984 run_lib.py:167] step: 86200, eval_loss: 5.55662e-02
I0514 07:06:36.755952 22392998065984 run_lib.py:146] step: 86250, training_loss: 7.58860e-02
I0514 07:07:00.317011 22392998065984 run_lib.py:146] step: 86300, training_loss: 6.02970e-02
I0514 07:07:00.474190 22392998065984 run_lib.py:167] step: 86300, eval_loss: 6.09075e-02
I0514 07:07:23.714765 22392998065984 run_lib.py:146] step: 86350, training_loss: 6.59422e-02
I0514 07:07:47.254087 22392998065984 run_lib.py:146] step: 86400, training_loss: 6.89950e-02
I0514 07:07:47.410268 22392998065984 run_lib.py:167] step: 86400, eval_loss: 6.74960e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:08:11.488579 22392998065984 run_lib.py:146] step: 86450, training_loss: 7.41374e-02
I0514 07:08:35.223594 22392998065984 run_lib.py:146] step: 86500, training_loss: 7.48297e-02
I0514 07:08:35.380991 22392998065984 run_lib.py:167] step: 86500, eval_loss: 5.69518e-02
I0514 07:08:59.340520 22392998065984 run_lib.py:146] step: 86550, training_loss: 6.15733e-02
I0514 07:09:22.889803 22392998065984 run_lib.py:146] step: 86600, training_loss: 7.41346e-02
I0514 07:09:23.046626 22392998065984 run_lib.py:167] step: 86600, eval_loss: 5.12083e-02
I0514 07:09:46.294586 22392998065984 run_lib.py:146] step: 86650, training_loss: 5.06108e-02
I0514 07:10:09.542435 22392998065984 run_lib.py:146] step: 86700, training_loss: 4.79222e-02
I0514 07:10:09.698036 22392998065984 run_lib.py:167] step: 86700, eval_loss: 6.14421e-02
I0514 07:10:33.518926 22392998065984 run_lib.py:146] step: 86750, training_loss: 5.72376e-02
I0514 07:10:56.769024 22392998065984 run_lib.py:146] step: 86800, training_loss: 6.39929e-02
I0514 07:10:56.884010 22392998065984 run_lib.py:167] step: 86800, eval_loss: 5.77681e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:11:20.260205 22392998065984 run_lib.py:146] step: 86850, training_loss: 4.03493e-02
I0514 07:11:43.877327 22392998065984 run_lib.py:146] step: 86900, training_loss: 5.93476e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:11:44.243669 22392998065984 run_lib.py:167] step: 86900, eval_loss: 6.84534e-02
I0514 07:12:08.335210 22392998065984 run_lib.py:146] step: 86950, training_loss: 6.51777e-02
I0514 07:12:32.073502 22392998065984 run_lib.py:146] step: 87000, training_loss: 5.13062e-02
I0514 07:12:32.229564 22392998065984 run_lib.py:167] step: 87000, eval_loss: 6.64789e-02
I0514 07:12:56.316054 22392998065984 run_lib.py:146] step: 87050, training_loss: 5.94631e-02
I0514 07:13:20.301967 22392998065984 run_lib.py:146] step: 87100, training_loss: 5.02066e-02
I0514 07:13:20.458542 22392998065984 run_lib.py:167] step: 87100, eval_loss: 5.93355e-02
I0514 07:13:44.200311 22392998065984 run_lib.py:146] step: 87150, training_loss: 5.54077e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:14:08.289389 22392998065984 run_lib.py:146] step: 87200, training_loss: 5.34448e-02
I0514 07:14:08.447513 22392998065984 run_lib.py:167] step: 87200, eval_loss: 5.35101e-02
I0514 07:14:32.043735 22392998065984 run_lib.py:146] step: 87250, training_loss: 6.30317e-02
I0514 07:14:55.301250 22392998065984 run_lib.py:146] step: 87300, training_loss: 8.00907e-02
I0514 07:14:55.457698 22392998065984 run_lib.py:167] step: 87300, eval_loss: 5.68375e-02
I0514 07:15:19.026063 22392998065984 run_lib.py:146] step: 87350, training_loss: 5.48795e-02
I0514 07:15:42.577366 22392998065984 run_lib.py:146] step: 87400, training_loss: 5.93031e-02
I0514 07:15:42.734191 22392998065984 run_lib.py:167] step: 87400, eval_loss: 6.53830e-02
I0514 07:16:05.990921 22392998065984 run_lib.py:146] step: 87450, training_loss: 5.83276e-02
I0514 07:16:29.243683 22392998065984 run_lib.py:146] step: 87500, training_loss: 4.70106e-02
I0514 07:16:29.399902 22392998065984 run_lib.py:167] step: 87500, eval_loss: 7.04722e-02
I0514 07:16:53.252318 22392998065984 run_lib.py:146] step: 87550, training_loss: 5.08746e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:17:16.635820 22392998065984 run_lib.py:146] step: 87600, training_loss: 6.24492e-02
I0514 07:17:16.795240 22392998065984 run_lib.py:167] step: 87600, eval_loss: 6.47945e-02
I0514 07:17:40.052054 22392998065984 run_lib.py:146] step: 87650, training_loss: 5.21927e-02
I0514 07:18:03.657554 22392998065984 run_lib.py:146] step: 87700, training_loss: 7.86405e-02
I0514 07:18:03.814284 22392998065984 run_lib.py:167] step: 87700, eval_loss: 7.96603e-02
I0514 07:18:27.394829 22392998065984 run_lib.py:146] step: 87750, training_loss: 6.68716e-02
I0514 07:18:50.649749 22392998065984 run_lib.py:146] step: 87800, training_loss: 3.92832e-02
I0514 07:18:50.806741 22392998065984 run_lib.py:167] step: 87800, eval_loss: 5.55107e-02
I0514 07:19:14.343643 22392998065984 run_lib.py:146] step: 87850, training_loss: 3.97922e-02
I0514 07:19:37.883250 22392998065984 run_lib.py:146] step: 87900, training_loss: 5.56724e-02
I0514 07:19:38.039849 22392998065984 run_lib.py:167] step: 87900, eval_loss: 6.75491e-02
I0514 07:20:01.288729 22392998065984 run_lib.py:146] step: 87950, training_loss: 8.56052e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:20:25.016989 22392998065984 run_lib.py:146] step: 88000, training_loss: 5.45250e-02
I0514 07:20:25.175098 22392998065984 run_lib.py:167] step: 88000, eval_loss: 5.97602e-02
I0514 07:20:48.766764 22392998065984 run_lib.py:146] step: 88050, training_loss: 5.34001e-02
I0514 07:21:12.016490 22392998065984 run_lib.py:146] step: 88100, training_loss: 5.81791e-02
I0514 07:21:12.172987 22392998065984 run_lib.py:167] step: 88100, eval_loss: 7.17253e-02
I0514 07:21:35.723632 22392998065984 run_lib.py:146] step: 88150, training_loss: 6.08220e-02
I0514 07:21:59.305182 22392998065984 run_lib.py:146] step: 88200, training_loss: 7.86181e-02
I0514 07:21:59.461878 22392998065984 run_lib.py:167] step: 88200, eval_loss: 6.56531e-02
I0514 07:22:22.892712 22392998065984 run_lib.py:146] step: 88250, training_loss: 5.37857e-02
I0514 07:22:46.381938 22392998065984 run_lib.py:146] step: 88300, training_loss: 5.19418e-02
I0514 07:22:46.538357 22392998065984 run_lib.py:167] step: 88300, eval_loss: 6.31500e-02
I0514 07:23:10.376020 22392998065984 run_lib.py:146] step: 88350, training_loss: 5.99625e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:23:33.745701 22392998065984 run_lib.py:146] step: 88400, training_loss: 5.84273e-02
I0514 07:23:33.903572 22392998065984 run_lib.py:167] step: 88400, eval_loss: 4.80267e-02
I0514 07:23:57.161977 22392998065984 run_lib.py:146] step: 88450, training_loss: 8.39216e-02
I0514 07:24:21.057880 22392998065984 run_lib.py:146] step: 88500, training_loss: 5.18227e-02
I0514 07:24:21.215306 22392998065984 run_lib.py:167] step: 88500, eval_loss: 7.18331e-02
I0514 07:24:44.465312 22392998065984 run_lib.py:146] step: 88550, training_loss: 4.11542e-02
I0514 07:25:07.708189 22392998065984 run_lib.py:146] step: 88600, training_loss: 5.39921e-02
I0514 07:25:07.864328 22392998065984 run_lib.py:167] step: 88600, eval_loss: 5.06903e-02
I0514 07:25:31.392072 22392998065984 run_lib.py:146] step: 88650, training_loss: 6.97948e-02
I0514 07:25:54.948405 22392998065984 run_lib.py:146] step: 88700, training_loss: 5.93470e-02
I0514 07:25:55.104684 22392998065984 run_lib.py:167] step: 88700, eval_loss: 6.62145e-02
I0514 07:26:18.359377 22392998065984 run_lib.py:146] step: 88750, training_loss: 8.24948e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:26:42.079500 22392998065984 run_lib.py:146] step: 88800, training_loss: 4.51395e-02
I0514 07:26:42.237310 22392998065984 run_lib.py:167] step: 88800, eval_loss: 6.72067e-02
I0514 07:27:05.817439 22392998065984 run_lib.py:146] step: 88850, training_loss: 6.61309e-02
I0514 07:27:29.097820 22392998065984 run_lib.py:146] step: 88900, training_loss: 5.86415e-02
I0514 07:27:29.254405 22392998065984 run_lib.py:167] step: 88900, eval_loss: 6.68220e-02
I0514 07:27:52.799367 22392998065984 run_lib.py:146] step: 88950, training_loss: 5.54619e-02
I0514 07:28:16.343172 22392998065984 run_lib.py:146] step: 89000, training_loss: 5.60015e-02
I0514 07:28:16.499629 22392998065984 run_lib.py:167] step: 89000, eval_loss: 6.36033e-02
I0514 07:28:39.771535 22392998065984 run_lib.py:146] step: 89050, training_loss: 5.88997e-02
I0514 07:29:03.344637 22392998065984 run_lib.py:146] step: 89100, training_loss: 7.52346e-02
I0514 07:29:03.501695 22392998065984 run_lib.py:167] step: 89100, eval_loss: 7.02636e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:29:27.222702 22392998065984 run_lib.py:146] step: 89150, training_loss: 5.46340e-02
I0514 07:29:50.952893 22392998065984 run_lib.py:146] step: 89200, training_loss: 4.73633e-02
I0514 07:29:51.110578 22392998065984 run_lib.py:167] step: 89200, eval_loss: 4.89768e-02
I0514 07:30:14.849410 22392998065984 run_lib.py:146] step: 89250, training_loss: 4.95113e-02
I0514 07:30:39.240098 22392998065984 run_lib.py:146] step: 89300, training_loss: 6.46885e-02
I0514 07:30:39.396795 22392998065984 run_lib.py:167] step: 89300, eval_loss: 4.77064e-02
I0514 07:31:03.135147 22392998065984 run_lib.py:146] step: 89350, training_loss: 6.10299e-02
I0514 07:31:26.873074 22392998065984 run_lib.py:146] step: 89400, training_loss: 4.65488e-02
I0514 07:31:27.029898 22392998065984 run_lib.py:167] step: 89400, eval_loss: 5.74634e-02
I0514 07:31:51.077758 22392998065984 run_lib.py:146] step: 89450, training_loss: 5.59631e-02
I0514 07:32:15.105379 22392998065984 run_lib.py:146] step: 89500, training_loss: 6.34589e-02
I0514 07:32:15.261738 22392998065984 run_lib.py:167] step: 89500, eval_loss: 7.65169e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:32:39.061388 22392998065984 run_lib.py:146] step: 89550, training_loss: 6.32900e-02
I0514 07:33:02.678130 22392998065984 run_lib.py:146] step: 89600, training_loss: 7.47952e-02
I0514 07:33:02.835907 22392998065984 run_lib.py:167] step: 89600, eval_loss: 6.47488e-02
I0514 07:33:26.436063 22392998065984 run_lib.py:146] step: 89650, training_loss: 4.78583e-02
I0514 07:33:49.701075 22392998065984 run_lib.py:146] step: 89700, training_loss: 5.76839e-02
I0514 07:33:49.859057 22392998065984 run_lib.py:167] step: 89700, eval_loss: 5.85586e-02
I0514 07:34:13.420597 22392998065984 run_lib.py:146] step: 89750, training_loss: 4.71445e-02
I0514 07:34:36.985391 22392998065984 run_lib.py:146] step: 89800, training_loss: 7.71739e-02
I0514 07:34:37.142118 22392998065984 run_lib.py:167] step: 89800, eval_loss: 7.76951e-02
I0514 07:35:00.406343 22392998065984 run_lib.py:146] step: 89850, training_loss: 6.47611e-02
I0514 07:35:23.674674 22392998065984 run_lib.py:146] step: 89900, training_loss: 7.06899e-02
I0514 07:35:23.830969 22392998065984 run_lib.py:167] step: 89900, eval_loss: 5.24997e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:35:47.867871 22392998065984 run_lib.py:146] step: 89950, training_loss: 6.38822e-02
I0514 07:36:11.122056 22392998065984 run_lib.py:146] step: 90000, training_loss: 6.92931e-02
I0514 07:36:12.831560 22392998065984 run_lib.py:167] step: 90000, eval_loss: 6.29908e-02
I0514 07:36:37.985754 22392998065984 run_lib.py:146] step: 90050, training_loss: 7.95558e-02
I0514 07:37:02.082922 22392998065984 run_lib.py:146] step: 90100, training_loss: 5.21496e-02
I0514 07:37:02.239811 22392998065984 run_lib.py:167] step: 90100, eval_loss: 6.53116e-02
I0514 07:37:25.974869 22392998065984 run_lib.py:146] step: 90150, training_loss: 6.30374e-02
I0514 07:37:49.711825 22392998065984 run_lib.py:146] step: 90200, training_loss: 4.29848e-02
I0514 07:37:49.868368 22392998065984 run_lib.py:167] step: 90200, eval_loss: 7.66366e-02
I0514 07:38:14.199580 22392998065984 run_lib.py:146] step: 90250, training_loss: 6.60240e-02
I0514 07:38:37.935991 22392998065984 run_lib.py:146] step: 90300, training_loss: 4.36105e-02
I0514 07:38:38.092791 22392998065984 run_lib.py:167] step: 90300, eval_loss: 5.55525e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:39:01.708207 22392998065984 run_lib.py:146] step: 90350, training_loss: 5.62818e-02
I0514 07:39:25.633378 22392998065984 run_lib.py:146] step: 90400, training_loss: 6.65299e-02
I0514 07:39:25.790762 22392998065984 run_lib.py:167] step: 90400, eval_loss: 5.36991e-02
I0514 07:39:49.032570 22392998065984 run_lib.py:146] step: 90450, training_loss: 7.75314e-02
I0514 07:40:12.287611 22392998065984 run_lib.py:146] step: 90500, training_loss: 5.00328e-02
I0514 07:40:12.444157 22392998065984 run_lib.py:167] step: 90500, eval_loss: 7.71109e-02
I0514 07:40:36.255823 22392998065984 run_lib.py:146] step: 90550, training_loss: 6.96261e-02
I0514 07:40:59.521854 22392998065984 run_lib.py:146] step: 90600, training_loss: 6.46138e-02
I0514 07:40:59.678985 22392998065984 run_lib.py:167] step: 90600, eval_loss: 4.71843e-02
I0514 07:41:22.942645 22392998065984 run_lib.py:146] step: 90650, training_loss: 6.09587e-02
I0514 07:41:46.491334 22392998065984 run_lib.py:146] step: 90700, training_loss: 5.97605e-02
I0514 07:41:46.647968 22392998065984 run_lib.py:167] step: 90700, eval_loss: 6.34035e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:42:10.321881 22392998065984 run_lib.py:146] step: 90750, training_loss: 5.32823e-02
I0514 07:42:33.563564 22392998065984 run_lib.py:146] step: 90800, training_loss: 5.54916e-02
I0514 07:42:33.721208 22392998065984 run_lib.py:167] step: 90800, eval_loss: 5.62774e-02
I0514 07:42:57.299512 22392998065984 run_lib.py:146] step: 90850, training_loss: 5.55243e-02
I0514 07:43:20.868304 22392998065984 run_lib.py:146] step: 90900, training_loss: 4.44484e-02
I0514 07:43:21.024969 22392998065984 run_lib.py:167] step: 90900, eval_loss: 5.91400e-02
I0514 07:43:44.266785 22392998065984 run_lib.py:146] step: 90950, training_loss: 6.95136e-02
I0514 07:44:07.519267 22392998065984 run_lib.py:146] step: 91000, training_loss: 6.11421e-02
I0514 07:44:07.675685 22392998065984 run_lib.py:167] step: 91000, eval_loss: 5.53659e-02
I0514 07:44:31.520616 22392998065984 run_lib.py:146] step: 91050, training_loss: 4.46031e-02
I0514 07:44:54.782728 22392998065984 run_lib.py:146] step: 91100, training_loss: 5.61394e-02
I0514 07:44:54.938757 22392998065984 run_lib.py:167] step: 91100, eval_loss: 4.51451e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:45:18.750089 22392998065984 run_lib.py:146] step: 91150, training_loss: 5.91572e-02
I0514 07:45:42.689108 22392998065984 run_lib.py:146] step: 91200, training_loss: 8.74728e-02
I0514 07:45:42.846338 22392998065984 run_lib.py:167] step: 91200, eval_loss: 4.68175e-02
I0514 07:46:06.089147 22392998065984 run_lib.py:146] step: 91250, training_loss: 6.72194e-02
I0514 07:46:29.330017 22392998065984 run_lib.py:146] step: 91300, training_loss: 6.10771e-02
I0514 07:46:29.486171 22392998065984 run_lib.py:167] step: 91300, eval_loss: 5.21935e-02
I0514 07:46:53.340313 22392998065984 run_lib.py:146] step: 91350, training_loss: 4.91126e-02
I0514 07:47:16.579477 22392998065984 run_lib.py:146] step: 91400, training_loss: 6.51305e-02
I0514 07:47:16.735863 22392998065984 run_lib.py:167] step: 91400, eval_loss: 5.73472e-02
I0514 07:47:39.979841 22392998065984 run_lib.py:146] step: 91450, training_loss: 5.27762e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:48:03.679357 22392998065984 run_lib.py:146] step: 91500, training_loss: 6.68389e-02
I0514 07:48:03.837329 22392998065984 run_lib.py:167] step: 91500, eval_loss: 5.52385e-02
I0514 07:48:27.438380 22392998065984 run_lib.py:146] step: 91550, training_loss: 7.15090e-02
I0514 07:48:50.709213 22392998065984 run_lib.py:146] step: 91600, training_loss: 6.79576e-02
I0514 07:48:50.866208 22392998065984 run_lib.py:167] step: 91600, eval_loss: 7.03877e-02
I0514 07:49:14.427627 22392998065984 run_lib.py:146] step: 91650, training_loss: 4.50861e-02
I0514 07:49:37.988155 22392998065984 run_lib.py:146] step: 91700, training_loss: 7.75145e-02
I0514 07:49:38.145288 22392998065984 run_lib.py:167] step: 91700, eval_loss: 5.83824e-02
I0514 07:50:01.417802 22392998065984 run_lib.py:146] step: 91750, training_loss: 6.66316e-02
I0514 07:50:25.123920 22392998065984 run_lib.py:146] step: 91800, training_loss: 7.57065e-02
I0514 07:50:25.280213 22392998065984 run_lib.py:167] step: 91800, eval_loss: 8.47600e-02
I0514 07:50:49.593752 22392998065984 run_lib.py:146] step: 91850, training_loss: 7.80327e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:51:13.343704 22392998065984 run_lib.py:146] step: 91900, training_loss: 5.04541e-02
I0514 07:51:13.502094 22392998065984 run_lib.py:167] step: 91900, eval_loss: 5.11951e-02
I0514 07:51:36.760923 22392998065984 run_lib.py:146] step: 91950, training_loss: 6.42825e-02
I0514 07:52:00.706714 22392998065984 run_lib.py:146] step: 92000, training_loss: 6.24762e-02
I0514 07:52:00.863392 22392998065984 run_lib.py:167] step: 92000, eval_loss: 6.14531e-02
I0514 07:52:24.119089 22392998065984 run_lib.py:146] step: 92050, training_loss: 6.91818e-02
I0514 07:52:47.377159 22392998065984 run_lib.py:146] step: 92100, training_loss: 7.36072e-02
I0514 07:52:47.533683 22392998065984 run_lib.py:167] step: 92100, eval_loss: 6.56848e-02
I0514 07:53:11.379370 22392998065984 run_lib.py:146] step: 92150, training_loss: 7.40905e-02
I0514 07:53:34.640512 22392998065984 run_lib.py:146] step: 92200, training_loss: 5.10460e-02
I0514 07:53:34.805727 22392998065984 run_lib.py:167] step: 92200, eval_loss: 4.31463e-02
I0514 07:53:58.080718 22392998065984 run_lib.py:146] step: 92250, training_loss: 7.13649e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:54:22.380234 22392998065984 run_lib.py:146] step: 92300, training_loss: 7.02586e-02
I0514 07:54:22.537760 22392998065984 run_lib.py:167] step: 92300, eval_loss: 9.77612e-02
I0514 07:54:46.278921 22392998065984 run_lib.py:146] step: 92350, training_loss: 6.61239e-02
I0514 07:55:10.013567 22392998065984 run_lib.py:146] step: 92400, training_loss: 5.07435e-02
I0514 07:55:10.170343 22392998065984 run_lib.py:167] step: 92400, eval_loss: 6.98191e-02
I0514 07:55:34.196813 22392998065984 run_lib.py:146] step: 92450, training_loss: 6.34255e-02
I0514 07:55:58.245208 22392998065984 run_lib.py:146] step: 92500, training_loss: 6.84228e-02
I0514 07:55:58.401236 22392998065984 run_lib.py:167] step: 92500, eval_loss: 1.01905e-01
I0514 07:56:22.137382 22392998065984 run_lib.py:146] step: 92550, training_loss: 5.66542e-02
I0514 07:56:45.860156 22392998065984 run_lib.py:146] step: 92600, training_loss: 5.68370e-02
I0514 07:56:46.017374 22392998065984 run_lib.py:167] step: 92600, eval_loss: 5.79641e-02
I0514 07:57:10.331542 22392998065984 run_lib.py:146] step: 92650, training_loss: 5.15866e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 07:57:33.915598 22392998065984 run_lib.py:146] step: 92700, training_loss: 6.06495e-02
I0514 07:57:34.074024 22392998065984 run_lib.py:167] step: 92700, eval_loss: 7.95317e-02
I0514 07:57:57.329318 22392998065984 run_lib.py:146] step: 92750, training_loss: 5.72500e-02
I0514 07:58:21.249316 22392998065984 run_lib.py:146] step: 92800, training_loss: 5.40234e-02
I0514 07:58:21.406719 22392998065984 run_lib.py:167] step: 92800, eval_loss: 5.57941e-02
I0514 07:58:44.660407 22392998065984 run_lib.py:146] step: 92850, training_loss: 6.73501e-02
I0514 07:59:07.948849 22392998065984 run_lib.py:146] step: 92900, training_loss: 6.22622e-02
I0514 07:59:08.105738 22392998065984 run_lib.py:167] step: 92900, eval_loss: 7.72601e-02
I0514 07:59:31.972494 22392998065984 run_lib.py:146] step: 92950, training_loss: 8.06629e-02
I0514 07:59:55.242911 22392998065984 run_lib.py:146] step: 93000, training_loss: 8.19960e-02
I0514 07:59:55.399148 22392998065984 run_lib.py:167] step: 93000, eval_loss: 5.82182e-02
I0514 08:00:18.673899 22392998065984 run_lib.py:146] step: 93050, training_loss: 7.27754e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:00:42.757822 22392998065984 run_lib.py:146] step: 93100, training_loss: 9.01065e-02
I0514 08:00:42.915485 22392998065984 run_lib.py:167] step: 93100, eval_loss: 8.64304e-02
I0514 08:01:06.179526 22392998065984 run_lib.py:146] step: 93150, training_loss: 6.91867e-02
I0514 08:01:29.454564 22392998065984 run_lib.py:146] step: 93200, training_loss: 7.35132e-02
I0514 08:01:29.611315 22392998065984 run_lib.py:167] step: 93200, eval_loss: 7.00981e-02
I0514 08:01:53.197755 22392998065984 run_lib.py:146] step: 93250, training_loss: 7.77688e-02
I0514 08:02:16.775256 22392998065984 run_lib.py:146] step: 93300, training_loss: 5.38014e-02
I0514 08:02:16.932125 22392998065984 run_lib.py:167] step: 93300, eval_loss: 6.23931e-02
I0514 08:02:40.671007 22392998065984 run_lib.py:146] step: 93350, training_loss: 6.71254e-02
I0514 08:03:04.399489 22392998065984 run_lib.py:146] step: 93400, training_loss: 6.35841e-02
I0514 08:03:04.555860 22392998065984 run_lib.py:167] step: 93400, eval_loss: 4.46222e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:03:29.024988 22392998065984 run_lib.py:146] step: 93450, training_loss: 6.22038e-02
I0514 08:03:52.768805 22392998065984 run_lib.py:146] step: 93500, training_loss: 4.24458e-02
I0514 08:03:52.926342 22392998065984 run_lib.py:167] step: 93500, eval_loss: 6.71425e-02
I0514 08:04:16.668978 22392998065984 run_lib.py:146] step: 93550, training_loss: 7.52070e-02
I0514 08:04:41.054669 22392998065984 run_lib.py:146] step: 93600, training_loss: 5.69479e-02
I0514 08:04:41.211952 22392998065984 run_lib.py:167] step: 93600, eval_loss: 5.34409e-02
I0514 08:05:04.951939 22392998065984 run_lib.py:146] step: 93650, training_loss: 6.16193e-02
I0514 08:05:28.680137 22392998065984 run_lib.py:146] step: 93700, training_loss: 6.29642e-02
I0514 08:05:28.836434 22392998065984 run_lib.py:167] step: 93700, eval_loss: 5.75738e-02
I0514 08:05:53.151489 22392998065984 run_lib.py:146] step: 93750, training_loss: 4.48499e-02
I0514 08:06:16.883092 22392998065984 run_lib.py:146] step: 93800, training_loss: 5.11356e-02
I0514 08:06:17.039957 22392998065984 run_lib.py:167] step: 93800, eval_loss: 5.11100e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:06:40.833709 22392998065984 run_lib.py:146] step: 93850, training_loss: 4.91182e-02
I0514 08:07:04.762699 22392998065984 run_lib.py:146] step: 93900, training_loss: 7.51038e-02
I0514 08:07:04.919962 22392998065984 run_lib.py:167] step: 93900, eval_loss: 7.77629e-02
I0514 08:07:28.181671 22392998065984 run_lib.py:146] step: 93950, training_loss: 5.74510e-02
I0514 08:07:51.442128 22392998065984 run_lib.py:146] step: 94000, training_loss: 5.83562e-02
I0514 08:07:51.637855 22392998065984 run_lib.py:167] step: 94000, eval_loss: 6.77799e-02
I0514 08:08:15.175539 22392998065984 run_lib.py:146] step: 94050, training_loss: 4.36768e-02
I0514 08:08:38.715172 22392998065984 run_lib.py:146] step: 94100, training_loss: 5.92952e-02
I0514 08:08:38.871384 22392998065984 run_lib.py:167] step: 94100, eval_loss: 6.06203e-02
I0514 08:09:02.143210 22392998065984 run_lib.py:146] step: 94150, training_loss: 5.84994e-02
I0514 08:09:26.030067 22392998065984 run_lib.py:146] step: 94200, training_loss: 7.05288e-02
I0514 08:09:26.187139 22392998065984 run_lib.py:167] step: 94200, eval_loss: 7.86754e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:09:50.363305 22392998065984 run_lib.py:146] step: 94250, training_loss: 4.20713e-02
I0514 08:10:14.092351 22392998065984 run_lib.py:146] step: 94300, training_loss: 5.68389e-02
I0514 08:10:14.250136 22392998065984 run_lib.py:167] step: 94300, eval_loss: 5.78847e-02
I0514 08:10:37.984648 22392998065984 run_lib.py:146] step: 94350, training_loss: 5.29616e-02
I0514 08:11:02.388010 22392998065984 run_lib.py:146] step: 94400, training_loss: 5.28012e-02
I0514 08:11:02.544640 22392998065984 run_lib.py:167] step: 94400, eval_loss: 5.70496e-02
I0514 08:11:26.281472 22392998065984 run_lib.py:146] step: 94450, training_loss: 6.40733e-02
I0514 08:11:49.702206 22392998065984 run_lib.py:146] step: 94500, training_loss: 5.40871e-02
I0514 08:11:49.858637 22392998065984 run_lib.py:167] step: 94500, eval_loss: 6.20029e-02
I0514 08:12:13.667941 22392998065984 run_lib.py:146] step: 94550, training_loss: 7.97601e-02
I0514 08:12:36.926162 22392998065984 run_lib.py:146] step: 94600, training_loss: 6.81461e-02
I0514 08:12:37.081903 22392998065984 run_lib.py:167] step: 94600, eval_loss: 7.31368e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:13:00.785130 22392998065984 run_lib.py:146] step: 94650, training_loss: 6.66053e-02
I0514 08:13:25.191075 22392998065984 run_lib.py:146] step: 94700, training_loss: 5.69874e-02
I0514 08:13:25.270215 22392998065984 run_lib.py:167] step: 94700, eval_loss: 4.09746e-02
I0514 08:13:49.015565 22392998065984 run_lib.py:146] step: 94750, training_loss: 7.20117e-02
I0514 08:14:12.759677 22392998065984 run_lib.py:146] step: 94800, training_loss: 5.33222e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:14:13.128527 22392998065984 run_lib.py:167] step: 94800, eval_loss: 6.02985e-02
I0514 08:14:36.805453 22392998065984 run_lib.py:146] step: 94850, training_loss: 5.33698e-02
I0514 08:15:00.416331 22392998065984 run_lib.py:146] step: 94900, training_loss: 5.77842e-02
I0514 08:15:00.573563 22392998065984 run_lib.py:167] step: 94900, eval_loss: 6.40729e-02
I0514 08:15:23.852680 22392998065984 run_lib.py:146] step: 94950, training_loss: 7.61903e-02
I0514 08:15:47.435108 22392998065984 run_lib.py:146] step: 95000, training_loss: 6.08633e-02
I0514 08:15:47.605676 22392998065984 run_lib.py:167] step: 95000, eval_loss: 7.64385e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:16:11.545919 22392998065984 run_lib.py:146] step: 95050, training_loss: 6.65432e-02
I0514 08:16:34.810096 22392998065984 run_lib.py:146] step: 95100, training_loss: 5.62142e-02
I0514 08:16:34.967855 22392998065984 run_lib.py:167] step: 95100, eval_loss: 8.04624e-02
I0514 08:16:58.393821 22392998065984 run_lib.py:146] step: 95150, training_loss: 5.62304e-02
I0514 08:17:22.749175 22392998065984 run_lib.py:146] step: 95200, training_loss: 4.63998e-02
I0514 08:17:22.905526 22392998065984 run_lib.py:167] step: 95200, eval_loss: 4.87522e-02
I0514 08:17:46.540829 22392998065984 run_lib.py:146] step: 95250, training_loss: 5.19518e-02
I0514 08:18:09.824140 22392998065984 run_lib.py:146] step: 95300, training_loss: 5.08693e-02
I0514 08:18:09.980914 22392998065984 run_lib.py:167] step: 95300, eval_loss: 4.10485e-02
I0514 08:18:33.838667 22392998065984 run_lib.py:146] step: 95350, training_loss: 7.83504e-02
I0514 08:18:57.274735 22392998065984 run_lib.py:146] step: 95400, training_loss: 6.34795e-02
I0514 08:18:57.431172 22392998065984 run_lib.py:167] step: 95400, eval_loss: 7.20039e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:19:21.294077 22392998065984 run_lib.py:146] step: 95450, training_loss: 5.00268e-02
I0514 08:19:45.570943 22392998065984 run_lib.py:146] step: 95500, training_loss: 7.78351e-02
I0514 08:19:45.728358 22392998065984 run_lib.py:167] step: 95500, eval_loss: 5.14756e-02
I0514 08:20:09.018241 22392998065984 run_lib.py:146] step: 95550, training_loss: 8.69708e-02
I0514 08:20:32.757157 22392998065984 run_lib.py:146] step: 95600, training_loss: 5.80579e-02
I0514 08:20:32.913864 22392998065984 run_lib.py:167] step: 95600, eval_loss: 5.93332e-02
I0514 08:20:56.726851 22392998065984 run_lib.py:146] step: 95650, training_loss: 5.96005e-02
I0514 08:21:20.284545 22392998065984 run_lib.py:146] step: 95700, training_loss: 6.12012e-02
I0514 08:21:20.441128 22392998065984 run_lib.py:167] step: 95700, eval_loss: 5.55096e-02
I0514 08:21:43.818112 22392998065984 run_lib.py:146] step: 95750, training_loss: 5.52859e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:22:07.996232 22392998065984 run_lib.py:146] step: 95800, training_loss: 5.48283e-02
I0514 08:22:08.154512 22392998065984 run_lib.py:167] step: 95800, eval_loss: 4.79151e-02
I0514 08:22:31.768439 22392998065984 run_lib.py:146] step: 95850, training_loss: 5.99305e-02
I0514 08:22:55.030992 22392998065984 run_lib.py:146] step: 95900, training_loss: 4.99512e-02
I0514 08:22:55.187433 22392998065984 run_lib.py:167] step: 95900, eval_loss: 6.23645e-02
I0514 08:23:18.459548 22392998065984 run_lib.py:146] step: 95950, training_loss: 5.35987e-02
I0514 08:23:42.308880 22392998065984 run_lib.py:146] step: 96000, training_loss: 6.28391e-02
I0514 08:23:42.465276 22392998065984 run_lib.py:167] step: 96000, eval_loss: 5.89926e-02
I0514 08:24:05.794385 22392998065984 run_lib.py:146] step: 96050, training_loss: 4.92792e-02
I0514 08:24:29.532713 22392998065984 run_lib.py:146] step: 96100, training_loss: 5.54742e-02
I0514 08:24:29.689152 22392998065984 run_lib.py:167] step: 96100, eval_loss: 5.31048e-02
I0514 08:24:54.003544 22392998065984 run_lib.py:146] step: 96150, training_loss: 5.39634e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:25:17.764571 22392998065984 run_lib.py:146] step: 96200, training_loss: 6.39968e-02
I0514 08:25:17.922508 22392998065984 run_lib.py:167] step: 96200, eval_loss: 4.67973e-02
I0514 08:25:41.196830 22392998065984 run_lib.py:146] step: 96250, training_loss: 5.93475e-02
I0514 08:26:05.124059 22392998065984 run_lib.py:146] step: 96300, training_loss: 4.31861e-02
I0514 08:26:05.280416 22392998065984 run_lib.py:167] step: 96300, eval_loss: 6.84731e-02
I0514 08:26:28.557173 22392998065984 run_lib.py:146] step: 96350, training_loss: 4.75491e-02
I0514 08:26:51.839752 22392998065984 run_lib.py:146] step: 96400, training_loss: 5.90321e-02
I0514 08:26:51.996808 22392998065984 run_lib.py:167] step: 96400, eval_loss: 6.72059e-02
I0514 08:27:15.557634 22392998065984 run_lib.py:146] step: 96450, training_loss: 6.58523e-02
I0514 08:27:39.119209 22392998065984 run_lib.py:146] step: 96500, training_loss: 4.40735e-02
I0514 08:27:39.275559 22392998065984 run_lib.py:167] step: 96500, eval_loss: 5.42855e-02
I0514 08:28:02.560357 22392998065984 run_lib.py:146] step: 96550, training_loss: 5.36858e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:28:26.497955 22392998065984 run_lib.py:146] step: 96600, training_loss: 7.41895e-02
I0514 08:28:26.678185 22392998065984 run_lib.py:167] step: 96600, eval_loss: 7.58756e-02
I0514 08:28:50.750355 22392998065984 run_lib.py:146] step: 96650, training_loss: 6.97587e-02
I0514 08:29:14.486737 22392998065984 run_lib.py:146] step: 96700, training_loss: 6.41461e-02
I0514 08:29:14.643292 22392998065984 run_lib.py:167] step: 96700, eval_loss: 5.62626e-02
I0514 08:29:38.380852 22392998065984 run_lib.py:146] step: 96750, training_loss: 7.88157e-02
I0514 08:30:02.691238 22392998065984 run_lib.py:146] step: 96800, training_loss: 6.20490e-02
I0514 08:30:02.848020 22392998065984 run_lib.py:167] step: 96800, eval_loss: 5.86562e-02
I0514 08:30:26.153528 22392998065984 run_lib.py:146] step: 96850, training_loss: 5.45700e-02
I0514 08:30:49.425940 22392998065984 run_lib.py:146] step: 96900, training_loss: 7.13624e-02
I0514 08:30:49.582415 22392998065984 run_lib.py:167] step: 96900, eval_loss: 8.07565e-02
I0514 08:31:13.458507 22392998065984 run_lib.py:146] step: 96950, training_loss: 6.75560e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:31:36.871249 22392998065984 run_lib.py:146] step: 97000, training_loss: 5.86497e-02
I0514 08:31:37.029665 22392998065984 run_lib.py:167] step: 97000, eval_loss: 6.47006e-02
I0514 08:32:00.323176 22392998065984 run_lib.py:146] step: 97050, training_loss: 7.39712e-02
I0514 08:32:23.955224 22392998065984 run_lib.py:146] step: 97100, training_loss: 7.10339e-02
I0514 08:32:24.111765 22392998065984 run_lib.py:167] step: 97100, eval_loss: 8.18874e-02
I0514 08:32:47.718097 22392998065984 run_lib.py:146] step: 97150, training_loss: 4.79724e-02
I0514 08:33:10.994346 22392998065984 run_lib.py:146] step: 97200, training_loss: 6.38769e-02
I0514 08:33:11.150592 22392998065984 run_lib.py:167] step: 97200, eval_loss: 7.26313e-02
I0514 08:33:34.709645 22392998065984 run_lib.py:146] step: 97250, training_loss: 6.05020e-02
I0514 08:33:58.276685 22392998065984 run_lib.py:146] step: 97300, training_loss: 4.28436e-02
I0514 08:33:58.433101 22392998065984 run_lib.py:167] step: 97300, eval_loss: 4.43860e-02
I0514 08:34:21.696801 22392998065984 run_lib.py:146] step: 97350, training_loss: 6.04782e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:34:45.815876 22392998065984 run_lib.py:146] step: 97400, training_loss: 4.72329e-02
I0514 08:34:45.973524 22392998065984 run_lib.py:167] step: 97400, eval_loss: 6.77985e-02
I0514 08:35:10.068834 22392998065984 run_lib.py:146] step: 97450, training_loss: 6.48518e-02
I0514 08:35:33.805351 22392998065984 run_lib.py:146] step: 97500, training_loss: 7.80680e-02
I0514 08:35:33.961922 22392998065984 run_lib.py:167] step: 97500, eval_loss: 6.07847e-02
I0514 08:35:57.708072 22392998065984 run_lib.py:146] step: 97550, training_loss: 6.09108e-02
I0514 08:36:21.892529 22392998065984 run_lib.py:146] step: 97600, training_loss: 7.89254e-02
I0514 08:36:22.049292 22392998065984 run_lib.py:167] step: 97600, eval_loss: 4.75374e-02
I0514 08:36:45.337652 22392998065984 run_lib.py:146] step: 97650, training_loss: 6.11143e-02
I0514 08:37:08.607111 22392998065984 run_lib.py:146] step: 97700, training_loss: 4.68796e-02
I0514 08:37:08.764091 22392998065984 run_lib.py:167] step: 97700, eval_loss: 6.44820e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:37:32.770609 22392998065984 run_lib.py:146] step: 97750, training_loss: 5.96673e-02
I0514 08:37:56.045480 22392998065984 run_lib.py:146] step: 97800, training_loss: 5.58549e-02
I0514 08:37:56.203240 22392998065984 run_lib.py:167] step: 97800, eval_loss: 5.32323e-02
I0514 08:38:19.475579 22392998065984 run_lib.py:146] step: 97850, training_loss: 6.72536e-02
I0514 08:38:43.069861 22392998065984 run_lib.py:146] step: 97900, training_loss: 7.78455e-02
I0514 08:38:43.226758 22392998065984 run_lib.py:167] step: 97900, eval_loss: 5.37233e-02
I0514 08:39:07.183704 22392998065984 run_lib.py:146] step: 97950, training_loss: 8.07389e-02
I0514 08:39:30.913029 22392998065984 run_lib.py:146] step: 98000, training_loss: 4.92751e-02
I0514 08:39:31.069337 22392998065984 run_lib.py:167] step: 98000, eval_loss: 5.89079e-02
I0514 08:39:55.082538 22392998065984 run_lib.py:146] step: 98050, training_loss: 6.17955e-02
I0514 08:40:19.131393 22392998065984 run_lib.py:146] step: 98100, training_loss: 6.43299e-02
I0514 08:40:19.287879 22392998065984 run_lib.py:167] step: 98100, eval_loss: 6.41942e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:40:43.205931 22392998065984 run_lib.py:146] step: 98150, training_loss: 5.00060e-02
I0514 08:41:07.142439 22392998065984 run_lib.py:146] step: 98200, training_loss: 6.08934e-02
I0514 08:41:07.315639 22392998065984 run_lib.py:167] step: 98200, eval_loss: 6.97726e-02
I0514 08:41:30.921032 22392998065984 run_lib.py:146] step: 98250, training_loss: 6.15529e-02
I0514 08:41:54.196079 22392998065984 run_lib.py:146] step: 98300, training_loss: 5.09939e-02
I0514 08:41:54.353117 22392998065984 run_lib.py:167] step: 98300, eval_loss: 7.20079e-02
I0514 08:42:17.625461 22392998065984 run_lib.py:146] step: 98350, training_loss: 7.36665e-02
I0514 08:42:41.478033 22392998065984 run_lib.py:146] step: 98400, training_loss: 4.56700e-02
I0514 08:42:41.634392 22392998065984 run_lib.py:167] step: 98400, eval_loss: 5.65147e-02
I0514 08:43:04.893483 22392998065984 run_lib.py:146] step: 98450, training_loss: 4.62488e-02
I0514 08:43:28.149306 22392998065984 run_lib.py:146] step: 98500, training_loss: 7.14300e-02
I0514 08:43:28.305906 22392998065984 run_lib.py:167] step: 98500, eval_loss: 5.35014e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:43:52.523230 22392998065984 run_lib.py:146] step: 98550, training_loss: 5.44668e-02
I0514 08:44:16.253858 22392998065984 run_lib.py:146] step: 98600, training_loss: 4.65501e-02
I0514 08:44:16.411954 22392998065984 run_lib.py:167] step: 98600, eval_loss: 5.58893e-02
I0514 08:44:40.053247 22392998065984 run_lib.py:146] step: 98650, training_loss: 5.45226e-02
I0514 08:45:03.911660 22392998065984 run_lib.py:146] step: 98700, training_loss: 4.71233e-02
I0514 08:45:04.068480 22392998065984 run_lib.py:167] step: 98700, eval_loss: 5.69315e-02
I0514 08:45:27.560064 22392998065984 run_lib.py:146] step: 98750, training_loss: 8.45042e-02
I0514 08:45:51.300183 22392998065984 run_lib.py:146] step: 98800, training_loss: 5.53565e-02
I0514 08:45:51.457275 22392998065984 run_lib.py:167] step: 98800, eval_loss: 6.63476e-02
I0514 08:46:15.484136 22392998065984 run_lib.py:146] step: 98850, training_loss: 7.62192e-02
I0514 08:46:39.525604 22392998065984 run_lib.py:146] step: 98900, training_loss: 7.75644e-02
I0514 08:46:39.681999 22392998065984 run_lib.py:167] step: 98900, eval_loss: 3.91006e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:47:03.321319 22392998065984 run_lib.py:146] step: 98950, training_loss: 4.64593e-02
I0514 08:47:26.936057 22392998065984 run_lib.py:146] step: 99000, training_loss: 6.99413e-02
I0514 08:47:27.093873 22392998065984 run_lib.py:167] step: 99000, eval_loss: 6.03230e-02
I0514 08:47:50.675069 22392998065984 run_lib.py:146] step: 99050, training_loss: 5.79273e-02
I0514 08:48:13.938595 22392998065984 run_lib.py:146] step: 99100, training_loss: 5.02119e-02
I0514 08:48:14.095093 22392998065984 run_lib.py:167] step: 99100, eval_loss: 5.86157e-02
I0514 08:48:37.605881 22392998065984 run_lib.py:146] step: 99150, training_loss: 6.40237e-02
I0514 08:49:01.139435 22392998065984 run_lib.py:146] step: 99200, training_loss: 7.09544e-02
I0514 08:49:01.296413 22392998065984 run_lib.py:167] step: 99200, eval_loss: 7.29998e-02
I0514 08:49:24.663437 22392998065984 run_lib.py:146] step: 99250, training_loss: 5.49712e-02
I0514 08:49:48.399306 22392998065984 run_lib.py:146] step: 99300, training_loss: 5.01462e-02
I0514 08:49:48.555818 22392998065984 run_lib.py:167] step: 99300, eval_loss: 6.25892e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:50:12.716846 22392998065984 run_lib.py:146] step: 99350, training_loss: 8.94956e-02
I0514 08:50:36.169291 22392998065984 run_lib.py:146] step: 99400, training_loss: 7.23823e-02
I0514 08:50:36.326871 22392998065984 run_lib.py:167] step: 99400, eval_loss: 5.56979e-02
I0514 08:51:00.064986 22392998065984 run_lib.py:146] step: 99450, training_loss: 5.85847e-02
I0514 08:51:24.108099 22392998065984 run_lib.py:146] step: 99500, training_loss: 7.58414e-02
I0514 08:51:24.264190 22392998065984 run_lib.py:167] step: 99500, eval_loss: 5.10904e-02
I0514 08:51:47.812927 22392998065984 run_lib.py:146] step: 99550, training_loss: 6.32456e-02
I0514 08:52:11.550425 22392998065984 run_lib.py:146] step: 99600, training_loss: 6.73142e-02
I0514 08:52:11.706454 22392998065984 run_lib.py:167] step: 99600, eval_loss: 6.74274e-02
I0514 08:52:35.986326 22392998065984 run_lib.py:146] step: 99650, training_loss: 7.78726e-02
I0514 08:52:59.712501 22392998065984 run_lib.py:146] step: 99700, training_loss: 6.32584e-02
I0514 08:52:59.869129 22392998065984 run_lib.py:167] step: 99700, eval_loss: 7.59435e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:53:23.340985 22392998065984 run_lib.py:146] step: 99750, training_loss: 7.27402e-02
I0514 08:53:46.954050 22392998065984 run_lib.py:146] step: 99800, training_loss: 4.14398e-02
I0514 08:53:47.112073 22392998065984 run_lib.py:167] step: 99800, eval_loss: 6.60473e-02
I0514 08:54:10.699827 22392998065984 run_lib.py:146] step: 99850, training_loss: 5.07178e-02
I0514 08:54:33.968385 22392998065984 run_lib.py:146] step: 99900, training_loss: 6.36042e-02
I0514 08:54:34.124719 22392998065984 run_lib.py:167] step: 99900, eval_loss: 5.60343e-02
I0514 08:54:57.676511 22392998065984 run_lib.py:146] step: 99950, training_loss: 6.93151e-02
I0514 08:55:21.228815 22392998065984 run_lib.py:146] step: 100000, training_loss: 7.35492e-02
I0514 08:55:22.993854 22392998065984 run_lib.py:167] step: 100000, eval_loss: 6.18400e-02
I0514 08:55:48.238254 22392998065984 run_lib.py:146] step: 100050, training_loss: 5.39643e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:56:11.946708 22392998065984 run_lib.py:146] step: 100100, training_loss: 5.91077e-02
I0514 08:56:12.104908 22392998065984 run_lib.py:167] step: 100100, eval_loss: 5.70558e-02
I0514 08:56:35.717386 22392998065984 run_lib.py:146] step: 100150, training_loss: 6.20472e-02
I0514 08:56:59.118607 22392998065984 run_lib.py:146] step: 100200, training_loss: 6.45930e-02
I0514 08:56:59.275074 22392998065984 run_lib.py:167] step: 100200, eval_loss: 5.43310e-02
I0514 08:57:23.324228 22392998065984 run_lib.py:146] step: 100250, training_loss: 6.16763e-02
I0514 08:57:46.896665 22392998065984 run_lib.py:146] step: 100300, training_loss: 6.35759e-02
I0514 08:57:47.054040 22392998065984 run_lib.py:167] step: 100300, eval_loss: 5.61754e-02
I0514 08:58:10.623607 22392998065984 run_lib.py:146] step: 100350, training_loss: 6.76818e-02
I0514 08:58:34.636781 22392998065984 run_lib.py:146] step: 100400, training_loss: 7.66762e-02
I0514 08:58:34.792866 22392998065984 run_lib.py:167] step: 100400, eval_loss: 5.65770e-02
I0514 08:58:58.853200 22392998065984 run_lib.py:146] step: 100450, training_loss: 5.27651e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 08:59:22.705149 22392998065984 run_lib.py:146] step: 100500, training_loss: 6.84427e-02
I0514 08:59:22.863462 22392998065984 run_lib.py:167] step: 100500, eval_loss: 5.16066e-02
I0514 08:59:46.918696 22392998065984 run_lib.py:146] step: 100550, training_loss: 7.28166e-02
I0514 09:00:10.652797 22392998065984 run_lib.py:146] step: 100600, training_loss: 7.20441e-02
I0514 09:00:10.810192 22392998065984 run_lib.py:167] step: 100600, eval_loss: 5.21980e-02
I0514 09:00:34.891630 22392998065984 run_lib.py:146] step: 100650, training_loss: 7.35619e-02
I0514 09:00:58.901176 22392998065984 run_lib.py:146] step: 100700, training_loss: 5.93052e-02
I0514 09:00:59.057477 22392998065984 run_lib.py:167] step: 100700, eval_loss: 5.90099e-02
I0514 09:01:22.778158 22392998065984 run_lib.py:146] step: 100750, training_loss: 7.55601e-02
I0514 09:01:46.427403 22392998065984 run_lib.py:146] step: 100800, training_loss: 5.19167e-02
I0514 09:01:46.621967 22392998065984 run_lib.py:167] step: 100800, eval_loss: 5.37338e-02
I0514 09:02:10.266542 22392998065984 run_lib.py:146] step: 100850, training_loss: 6.12998e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:02:33.972898 22392998065984 run_lib.py:146] step: 100900, training_loss: 6.82957e-02
I0514 09:02:34.131150 22392998065984 run_lib.py:167] step: 100900, eval_loss: 7.33990e-02
I0514 09:02:58.015383 22392998065984 run_lib.py:146] step: 100950, training_loss: 6.66495e-02
I0514 09:03:21.754189 22392998065984 run_lib.py:146] step: 101000, training_loss: 7.10096e-02
I0514 09:03:21.910943 22392998065984 run_lib.py:167] step: 101000, eval_loss: 4.25417e-02
I0514 09:03:45.955921 22392998065984 run_lib.py:146] step: 101050, training_loss: 8.17167e-02
I0514 09:04:10.003926 22392998065984 run_lib.py:146] step: 101100, training_loss: 6.93116e-02
I0514 09:04:10.160054 22392998065984 run_lib.py:167] step: 101100, eval_loss: 6.09298e-02
I0514 09:04:33.906786 22392998065984 run_lib.py:146] step: 101150, training_loss: 5.21752e-02
I0514 09:04:57.931686 22392998065984 run_lib.py:146] step: 101200, training_loss: 5.71999e-02
I0514 09:04:58.087995 22392998065984 run_lib.py:167] step: 101200, eval_loss: 5.52886e-02
I0514 09:05:22.129192 22392998065984 run_lib.py:146] step: 101250, training_loss: 5.31613e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:05:45.917824 22392998065984 run_lib.py:146] step: 101300, training_loss: 4.99239e-02
I0514 09:05:46.076254 22392998065984 run_lib.py:167] step: 101300, eval_loss: 5.75641e-02
I0514 09:06:10.124868 22392998065984 run_lib.py:146] step: 101350, training_loss: 6.46426e-02
I0514 09:06:33.862611 22392998065984 run_lib.py:146] step: 101400, training_loss: 6.54627e-02
I0514 09:06:34.019141 22392998065984 run_lib.py:167] step: 101400, eval_loss: 5.43305e-02
I0514 09:06:58.085894 22392998065984 run_lib.py:146] step: 101450, training_loss: 7.66106e-02
I0514 09:07:22.106812 22392998065984 run_lib.py:146] step: 101500, training_loss: 6.81357e-02
I0514 09:07:22.262963 22392998065984 run_lib.py:167] step: 101500, eval_loss: 4.36893e-02
I0514 09:07:46.010065 22392998065984 run_lib.py:146] step: 101550, training_loss: 6.58396e-02
I0514 09:08:10.061165 22392998065984 run_lib.py:146] step: 101600, training_loss: 6.68023e-02
I0514 09:08:10.217371 22392998065984 run_lib.py:167] step: 101600, eval_loss: 3.79494e-02
I0514 09:08:33.962952 22392998065984 run_lib.py:146] step: 101650, training_loss: 6.06134e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:08:58.106693 22392998065984 run_lib.py:146] step: 101700, training_loss: 5.62854e-02
I0514 09:08:58.264537 22392998065984 run_lib.py:167] step: 101700, eval_loss: 6.45482e-02
I0514 09:09:22.367933 22392998065984 run_lib.py:146] step: 101750, training_loss: 4.09246e-02
I0514 09:09:46.108727 22392998065984 run_lib.py:146] step: 101800, training_loss: 6.68940e-02
I0514 09:09:46.265470 22392998065984 run_lib.py:167] step: 101800, eval_loss: 6.82859e-02
I0514 09:10:10.308453 22392998065984 run_lib.py:146] step: 101850, training_loss: 6.07564e-02
I0514 09:10:34.350337 22392998065984 run_lib.py:146] step: 101900, training_loss: 5.49429e-02
I0514 09:10:34.506561 22392998065984 run_lib.py:167] step: 101900, eval_loss: 5.75187e-02
I0514 09:10:58.245261 22392998065984 run_lib.py:146] step: 101950, training_loss: 6.35445e-02
I0514 09:11:22.247956 22392998065984 run_lib.py:146] step: 102000, training_loss: 7.39230e-02
I0514 09:11:22.404210 22392998065984 run_lib.py:167] step: 102000, eval_loss: 5.70015e-02
I0514 09:11:46.042376 22392998065984 run_lib.py:146] step: 102050, training_loss: 5.07283e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:12:09.919160 22392998065984 run_lib.py:146] step: 102100, training_loss: 8.26573e-02
I0514 09:12:10.076871 22392998065984 run_lib.py:167] step: 102100, eval_loss: 6.40079e-02
I0514 09:12:34.138452 22392998065984 run_lib.py:146] step: 102150, training_loss: 7.29412e-02
I0514 09:12:57.878109 22392998065984 run_lib.py:146] step: 102200, training_loss: 6.01157e-02
I0514 09:12:58.034632 22392998065984 run_lib.py:167] step: 102200, eval_loss: 7.74991e-02
I0514 09:13:22.086961 22392998065984 run_lib.py:146] step: 102250, training_loss: 6.20576e-02
I0514 09:13:46.091358 22392998065984 run_lib.py:146] step: 102300, training_loss: 6.36822e-02
I0514 09:13:46.249383 22392998065984 run_lib.py:167] step: 102300, eval_loss: 5.66574e-02
I0514 09:14:09.998218 22392998065984 run_lib.py:146] step: 102350, training_loss: 6.15808e-02
I0514 09:14:34.042454 22392998065984 run_lib.py:146] step: 102400, training_loss: 7.40960e-02
I0514 09:14:34.199458 22392998065984 run_lib.py:167] step: 102400, eval_loss: 7.09379e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:14:58.350465 22392998065984 run_lib.py:146] step: 102450, training_loss: 6.31427e-02
I0514 09:15:21.605256 22392998065984 run_lib.py:146] step: 102500, training_loss: 4.46700e-02
I0514 09:15:21.762338 22392998065984 run_lib.py:167] step: 102500, eval_loss: 6.45204e-02
I0514 09:15:45.337047 22392998065984 run_lib.py:146] step: 102550, training_loss: 5.36892e-02
I0514 09:16:08.636875 22392998065984 run_lib.py:146] step: 102600, training_loss: 6.48496e-02
I0514 09:16:08.716669 22392998065984 run_lib.py:167] step: 102600, eval_loss: 4.78398e-02
I0514 09:16:32.271040 22392998065984 run_lib.py:146] step: 102650, training_loss: 7.48516e-02
I0514 09:16:55.826496 22392998065984 run_lib.py:146] step: 102700, training_loss: 4.90801e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:16:56.193372 22392998065984 run_lib.py:167] step: 102700, eval_loss: 6.82343e-02
I0514 09:17:19.750176 22392998065984 run_lib.py:146] step: 102750, training_loss: 5.75879e-02
I0514 09:17:43.340720 22392998065984 run_lib.py:146] step: 102800, training_loss: 6.30229e-02
I0514 09:17:43.497031 22392998065984 run_lib.py:167] step: 102800, eval_loss: 5.23322e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:18:06.895312 22392998065984 run_lib.py:146] step: 102850, training_loss: 4.83130e-02
I0514 09:18:30.479136 22392998065984 run_lib.py:146] step: 102900, training_loss: 4.55110e-02
I0514 09:18:30.637115 22392998065984 run_lib.py:167] step: 102900, eval_loss: 6.83343e-02
I0514 09:18:54.243871 22392998065984 run_lib.py:146] step: 102950, training_loss: 5.73183e-02
I0514 09:19:17.628861 22392998065984 run_lib.py:146] step: 103000, training_loss: 7.18568e-02
I0514 09:19:17.873075 22392998065984 run_lib.py:167] step: 103000, eval_loss: 5.59009e-02
I0514 09:19:41.870103 22392998065984 run_lib.py:146] step: 103050, training_loss: 5.25304e-02
I0514 09:20:05.876402 22392998065984 run_lib.py:146] step: 103100, training_loss: 6.00089e-02
I0514 09:20:06.033059 22392998065984 run_lib.py:167] step: 103100, eval_loss: 5.57170e-02
I0514 09:20:29.785457 22392998065984 run_lib.py:146] step: 103150, training_loss: 5.07471e-02
I0514 09:20:53.830569 22392998065984 run_lib.py:146] step: 103200, training_loss: 6.75977e-02
I0514 09:20:53.986607 22392998065984 run_lib.py:167] step: 103200, eval_loss: 7.06175e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:21:18.185956 22392998065984 run_lib.py:146] step: 103250, training_loss: 5.36446e-02
I0514 09:21:41.933219 22392998065984 run_lib.py:146] step: 103300, training_loss: 3.90994e-02
I0514 09:21:42.090826 22392998065984 run_lib.py:167] step: 103300, eval_loss: 7.27054e-02
I0514 09:22:06.174545 22392998065984 run_lib.py:146] step: 103350, training_loss: 6.57766e-02
I0514 09:22:29.914831 22392998065984 run_lib.py:146] step: 103400, training_loss: 6.49930e-02
I0514 09:22:30.071141 22392998065984 run_lib.py:167] step: 103400, eval_loss: 4.37290e-02
I0514 09:22:54.091743 22392998065984 run_lib.py:146] step: 103450, training_loss: 5.44395e-02
I0514 09:23:18.137821 22392998065984 run_lib.py:146] step: 103500, training_loss: 6.22815e-02
I0514 09:23:18.293833 22392998065984 run_lib.py:167] step: 103500, eval_loss: 5.69364e-02
I0514 09:23:42.039885 22392998065984 run_lib.py:146] step: 103550, training_loss: 5.35438e-02
I0514 09:24:06.062352 22392998065984 run_lib.py:146] step: 103600, training_loss: 6.11045e-02
I0514 09:24:06.218647 22392998065984 run_lib.py:167] step: 103600, eval_loss: 6.47568e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:24:30.124817 22392998065984 run_lib.py:146] step: 103650, training_loss: 6.32804e-02
I0514 09:24:54.203811 22392998065984 run_lib.py:146] step: 103700, training_loss: 6.51738e-02
I0514 09:24:54.361431 22392998065984 run_lib.py:167] step: 103700, eval_loss: 5.50337e-02
I0514 09:25:18.423210 22392998065984 run_lib.py:146] step: 103750, training_loss: 7.66130e-02
I0514 09:25:42.057304 22392998065984 run_lib.py:146] step: 103800, training_loss: 5.49983e-02
I0514 09:25:42.213763 22392998065984 run_lib.py:167] step: 103800, eval_loss: 5.21660e-02
I0514 09:26:05.771616 22392998065984 run_lib.py:146] step: 103850, training_loss: 5.70967e-02
I0514 09:26:29.333640 22392998065984 run_lib.py:146] step: 103900, training_loss: 6.69994e-02
I0514 09:26:29.489589 22392998065984 run_lib.py:167] step: 103900, eval_loss: 6.45051e-02
I0514 09:26:52.732027 22392998065984 run_lib.py:146] step: 103950, training_loss: 5.39775e-02
I0514 09:27:16.288160 22392998065984 run_lib.py:146] step: 104000, training_loss: 4.85546e-02
I0514 09:27:16.445626 22392998065984 run_lib.py:167] step: 104000, eval_loss: 4.35327e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:27:40.508898 22392998065984 run_lib.py:146] step: 104050, training_loss: 5.36913e-02
I0514 09:28:03.777332 22392998065984 run_lib.py:146] step: 104100, training_loss: 6.61269e-02
I0514 09:28:03.934768 22392998065984 run_lib.py:167] step: 104100, eval_loss: 5.07713e-02
I0514 09:28:27.534600 22392998065984 run_lib.py:146] step: 104150, training_loss: 4.18799e-02
I0514 09:28:50.825410 22392998065984 run_lib.py:146] step: 104200, training_loss: 5.13769e-02
I0514 09:28:50.981408 22392998065984 run_lib.py:167] step: 104200, eval_loss: 5.62880e-02
I0514 09:29:14.536810 22392998065984 run_lib.py:146] step: 104250, training_loss: 6.36113e-02
I0514 09:29:38.082562 22392998065984 run_lib.py:146] step: 104300, training_loss: 6.56439e-02
I0514 09:29:38.239530 22392998065984 run_lib.py:167] step: 104300, eval_loss: 6.40090e-02
I0514 09:30:01.500299 22392998065984 run_lib.py:146] step: 104350, training_loss: 5.26896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:30:25.369990 22392998065984 run_lib.py:146] step: 104400, training_loss: 8.38639e-02
I0514 09:30:25.528070 22392998065984 run_lib.py:167] step: 104400, eval_loss: 6.52300e-02
I0514 09:30:49.627913 22392998065984 run_lib.py:146] step: 104450, training_loss: 4.72019e-02
I0514 09:31:13.366177 22392998065984 run_lib.py:146] step: 104500, training_loss: 9.16418e-02
I0514 09:31:13.522926 22392998065984 run_lib.py:167] step: 104500, eval_loss: 5.96733e-02
I0514 09:31:37.570794 22392998065984 run_lib.py:146] step: 104550, training_loss: 5.44805e-02
I0514 09:32:01.306537 22392998065984 run_lib.py:146] step: 104600, training_loss: 5.40956e-02
I0514 09:32:01.489093 22392998065984 run_lib.py:167] step: 104600, eval_loss: 7.49136e-02
I0514 09:32:25.507588 22392998065984 run_lib.py:146] step: 104650, training_loss: 7.41769e-02
I0514 09:32:49.530376 22392998065984 run_lib.py:146] step: 104700, training_loss: 7.69480e-02
I0514 09:32:49.686615 22392998065984 run_lib.py:167] step: 104700, eval_loss: 5.08729e-02
I0514 09:33:13.431249 22392998065984 run_lib.py:146] step: 104750, training_loss: 7.28280e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:33:37.393053 22392998065984 run_lib.py:146] step: 104800, training_loss: 8.19112e-02
I0514 09:33:37.551160 22392998065984 run_lib.py:167] step: 104800, eval_loss: 4.83923e-02
I0514 09:34:01.176216 22392998065984 run_lib.py:146] step: 104850, training_loss: 6.80755e-02
I0514 09:34:24.438437 22392998065984 run_lib.py:146] step: 104900, training_loss: 6.21279e-02
I0514 09:34:24.595098 22392998065984 run_lib.py:167] step: 104900, eval_loss: 7.95286e-02
I0514 09:34:48.169394 22392998065984 run_lib.py:146] step: 104950, training_loss: 5.26454e-02
I0514 09:35:11.432377 22392998065984 run_lib.py:146] step: 105000, training_loss: 5.51224e-02
I0514 09:35:11.588527 22392998065984 run_lib.py:167] step: 105000, eval_loss: 4.64900e-02
I0514 09:35:35.143631 22392998065984 run_lib.py:146] step: 105050, training_loss: 6.15562e-02
I0514 09:35:58.694933 22392998065984 run_lib.py:146] step: 105100, training_loss: 5.92458e-02
I0514 09:35:58.851499 22392998065984 run_lib.py:167] step: 105100, eval_loss: 5.29694e-02
I0514 09:36:22.128190 22392998065984 run_lib.py:146] step: 105150, training_loss: 4.65136e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:36:46.207875 22392998065984 run_lib.py:146] step: 105200, training_loss: 7.42485e-02
I0514 09:36:46.366347 22392998065984 run_lib.py:167] step: 105200, eval_loss: 6.13997e-02
I0514 09:37:10.450359 22392998065984 run_lib.py:146] step: 105250, training_loss: 6.38018e-02
I0514 09:37:33.795600 22392998065984 run_lib.py:146] step: 105300, training_loss: 7.21717e-02
I0514 09:37:33.951865 22392998065984 run_lib.py:167] step: 105300, eval_loss: 6.16511e-02
I0514 09:37:57.520432 22392998065984 run_lib.py:146] step: 105350, training_loss: 5.37577e-02
I0514 09:38:21.423128 22392998065984 run_lib.py:146] step: 105400, training_loss: 5.38752e-02
I0514 09:38:21.579841 22392998065984 run_lib.py:167] step: 105400, eval_loss: 6.86696e-02
I0514 09:38:45.325048 22392998065984 run_lib.py:146] step: 105450, training_loss: 5.81342e-02
I0514 09:39:09.321268 22392998065984 run_lib.py:146] step: 105500, training_loss: 6.60125e-02
I0514 09:39:09.477674 22392998065984 run_lib.py:167] step: 105500, eval_loss: 5.27579e-02
I0514 09:39:33.216441 22392998065984 run_lib.py:146] step: 105550, training_loss: 6.32943e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:39:57.113850 22392998065984 run_lib.py:146] step: 105600, training_loss: 5.61840e-02
I0514 09:39:57.271983 22392998065984 run_lib.py:167] step: 105600, eval_loss: 5.95533e-02
I0514 09:40:20.841692 22392998065984 run_lib.py:146] step: 105650, training_loss: 5.12576e-02
I0514 09:40:44.087608 22392998065984 run_lib.py:146] step: 105700, training_loss: 7.39117e-02
I0514 09:40:44.243597 22392998065984 run_lib.py:167] step: 105700, eval_loss: 5.34327e-02
I0514 09:41:07.805776 22392998065984 run_lib.py:146] step: 105750, training_loss: 7.13361e-02
I0514 09:41:31.044369 22392998065984 run_lib.py:146] step: 105800, training_loss: 6.03665e-02
I0514 09:41:31.200896 22392998065984 run_lib.py:167] step: 105800, eval_loss: 5.43661e-02
I0514 09:41:54.756548 22392998065984 run_lib.py:146] step: 105850, training_loss: 6.11373e-02
I0514 09:42:18.307781 22392998065984 run_lib.py:146] step: 105900, training_loss: 5.42714e-02
I0514 09:42:18.464386 22392998065984 run_lib.py:167] step: 105900, eval_loss: 5.58108e-02
I0514 09:42:41.729204 22392998065984 run_lib.py:146] step: 105950, training_loss: 5.82756e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:43:05.812069 22392998065984 run_lib.py:146] step: 106000, training_loss: 6.92626e-02
I0514 09:43:05.970060 22392998065984 run_lib.py:167] step: 106000, eval_loss: 6.09052e-02
I0514 09:43:30.070059 22392998065984 run_lib.py:146] step: 106050, training_loss: 6.69251e-02
I0514 09:43:53.595469 22392998065984 run_lib.py:146] step: 106100, training_loss: 5.56366e-02
I0514 09:43:53.752231 22392998065984 run_lib.py:167] step: 106100, eval_loss: 4.65841e-02
I0514 09:44:17.772224 22392998065984 run_lib.py:146] step: 106150, training_loss: 5.41845e-02
I0514 09:44:41.774402 22392998065984 run_lib.py:146] step: 106200, training_loss: 5.74460e-02
I0514 09:44:41.948126 22392998065984 run_lib.py:167] step: 106200, eval_loss: 4.96407e-02
I0514 09:45:05.675756 22392998065984 run_lib.py:146] step: 106250, training_loss: 5.17218e-02
I0514 09:45:29.695505 22392998065984 run_lib.py:146] step: 106300, training_loss: 5.30425e-02
I0514 09:45:29.851577 22392998065984 run_lib.py:167] step: 106300, eval_loss: 5.00007e-02
I0514 09:45:53.594800 22392998065984 run_lib.py:146] step: 106350, training_loss: 7.28522e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:46:17.337252 22392998065984 run_lib.py:146] step: 106400, training_loss: 5.66970e-02
I0514 09:46:17.495739 22392998065984 run_lib.py:167] step: 106400, eval_loss: 5.61298e-02
I0514 09:46:41.121709 22392998065984 run_lib.py:146] step: 106450, training_loss: 6.85843e-02
I0514 09:47:04.381825 22392998065984 run_lib.py:146] step: 106500, training_loss: 7.49325e-02
I0514 09:47:04.538455 22392998065984 run_lib.py:167] step: 106500, eval_loss: 7.12056e-02
I0514 09:47:28.125367 22392998065984 run_lib.py:146] step: 106550, training_loss: 4.97726e-02
I0514 09:47:51.398580 22392998065984 run_lib.py:146] step: 106600, training_loss: 6.26000e-02
I0514 09:47:51.555518 22392998065984 run_lib.py:167] step: 106600, eval_loss: 4.94974e-02
I0514 09:48:15.091808 22392998065984 run_lib.py:146] step: 106650, training_loss: 6.88229e-02
I0514 09:48:38.649480 22392998065984 run_lib.py:146] step: 106700, training_loss: 5.73886e-02
I0514 09:48:38.806207 22392998065984 run_lib.py:167] step: 106700, eval_loss: 5.13745e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:49:02.254165 22392998065984 run_lib.py:146] step: 106750, training_loss: 4.85069e-02
I0514 09:49:25.870232 22392998065984 run_lib.py:146] step: 106800, training_loss: 5.23372e-02
I0514 09:49:26.027553 22392998065984 run_lib.py:167] step: 106800, eval_loss: 4.22200e-02
I0514 09:49:49.992815 22392998065984 run_lib.py:146] step: 106850, training_loss: 5.15741e-02
I0514 09:50:13.736612 22392998065984 run_lib.py:146] step: 106900, training_loss: 5.62698e-02
I0514 09:50:13.892940 22392998065984 run_lib.py:167] step: 106900, eval_loss: 5.18470e-02
I0514 09:50:37.925146 22392998065984 run_lib.py:146] step: 106950, training_loss: 6.23940e-02
I0514 09:51:01.977998 22392998065984 run_lib.py:146] step: 107000, training_loss: 5.91271e-02
I0514 09:51:02.134638 22392998065984 run_lib.py:167] step: 107000, eval_loss: 5.68152e-02
I0514 09:51:25.886186 22392998065984 run_lib.py:146] step: 107050, training_loss: 4.58850e-02
I0514 09:51:49.892827 22392998065984 run_lib.py:146] step: 107100, training_loss: 5.38601e-02
I0514 09:51:50.049188 22392998065984 run_lib.py:167] step: 107100, eval_loss: 5.29398e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:52:14.126994 22392998065984 run_lib.py:146] step: 107150, training_loss: 6.31970e-02
I0514 09:52:37.380167 22392998065984 run_lib.py:146] step: 107200, training_loss: 5.36509e-02
I0514 09:52:37.537841 22392998065984 run_lib.py:167] step: 107200, eval_loss: 5.82062e-02
I0514 09:53:01.133301 22392998065984 run_lib.py:146] step: 107250, training_loss: 5.09310e-02
I0514 09:53:24.415511 22392998065984 run_lib.py:146] step: 107300, training_loss: 5.23401e-02
I0514 09:53:24.571930 22392998065984 run_lib.py:167] step: 107300, eval_loss: 6.32036e-02
I0514 09:53:48.102643 22392998065984 run_lib.py:146] step: 107350, training_loss: 7.16935e-02
I0514 09:54:11.371529 22392998065984 run_lib.py:146] step: 107400, training_loss: 5.80117e-02
I0514 09:54:11.527995 22392998065984 run_lib.py:167] step: 107400, eval_loss: 7.07668e-02
I0514 09:54:35.121011 22392998065984 run_lib.py:146] step: 107450, training_loss: 5.88629e-02
I0514 09:54:58.679674 22392998065984 run_lib.py:146] step: 107500, training_loss: 7.82539e-02
I0514 09:54:58.845516 22392998065984 run_lib.py:167] step: 107500, eval_loss: 5.31840e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:55:22.474289 22392998065984 run_lib.py:146] step: 107550, training_loss: 6.29035e-02
I0514 09:55:46.522829 22392998065984 run_lib.py:146] step: 107600, training_loss: 6.02396e-02
I0514 09:55:46.680816 22392998065984 run_lib.py:167] step: 107600, eval_loss: 5.58232e-02
I0514 09:56:10.776897 22392998065984 run_lib.py:146] step: 107650, training_loss: 7.86130e-02
I0514 09:56:34.511283 22392998065984 run_lib.py:146] step: 107700, training_loss: 4.24154e-02
I0514 09:56:34.668010 22392998065984 run_lib.py:167] step: 107700, eval_loss: 5.62917e-02
I0514 09:56:58.673588 22392998065984 run_lib.py:146] step: 107750, training_loss: 7.21783e-02
I0514 09:57:22.675401 22392998065984 run_lib.py:146] step: 107800, training_loss: 5.43944e-02
I0514 09:57:22.848269 22392998065984 run_lib.py:167] step: 107800, eval_loss: 6.82302e-02
I0514 09:57:46.095749 22392998065984 run_lib.py:146] step: 107850, training_loss: 7.42166e-02
I0514 09:58:09.655824 22392998065984 run_lib.py:146] step: 107900, training_loss: 4.83518e-02
I0514 09:58:09.812166 22392998065984 run_lib.py:167] step: 107900, eval_loss: 4.74353e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 09:58:33.530111 22392998065984 run_lib.py:146] step: 107950, training_loss: 6.32798e-02
I0514 09:58:56.798602 22392998065984 run_lib.py:146] step: 108000, training_loss: 6.64249e-02
I0514 09:58:56.956414 22392998065984 run_lib.py:167] step: 108000, eval_loss: 4.91465e-02
I0514 09:59:20.557328 22392998065984 run_lib.py:146] step: 108050, training_loss: 5.74493e-02
I0514 09:59:43.825848 22392998065984 run_lib.py:146] step: 108100, training_loss: 4.98490e-02
I0514 09:59:43.982136 22392998065984 run_lib.py:167] step: 108100, eval_loss: 4.88551e-02
I0514 10:00:07.535443 22392998065984 run_lib.py:146] step: 108150, training_loss: 5.39990e-02
I0514 10:00:31.104783 22392998065984 run_lib.py:146] step: 108200, training_loss: 5.19470e-02
I0514 10:00:31.260859 22392998065984 run_lib.py:167] step: 108200, eval_loss: 6.00819e-02
I0514 10:00:54.517316 22392998065984 run_lib.py:146] step: 108250, training_loss: 4.96874e-02
I0514 10:01:18.069489 22392998065984 run_lib.py:146] step: 108300, training_loss: 5.35898e-02
I0514 10:01:18.226116 22392998065984 run_lib.py:167] step: 108300, eval_loss: 5.79022e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:01:41.629190 22392998065984 run_lib.py:146] step: 108350, training_loss: 7.45148e-02
I0514 10:02:05.244247 22392998065984 run_lib.py:146] step: 108400, training_loss: 6.23692e-02
I0514 10:02:05.401651 22392998065984 run_lib.py:167] step: 108400, eval_loss: 5.24394e-02
I0514 10:02:29.007351 22392998065984 run_lib.py:146] step: 108450, training_loss: 7.13224e-02
I0514 10:02:52.292326 22392998065984 run_lib.py:146] step: 108500, training_loss: 4.67137e-02
I0514 10:02:52.449003 22392998065984 run_lib.py:167] step: 108500, eval_loss: 5.64128e-02
I0514 10:03:16.027770 22392998065984 run_lib.py:146] step: 108550, training_loss: 5.73353e-02
I0514 10:03:39.593535 22392998065984 run_lib.py:146] step: 108600, training_loss: 6.69233e-02
I0514 10:03:39.749839 22392998065984 run_lib.py:167] step: 108600, eval_loss: 6.11434e-02
I0514 10:04:03.117407 22392998065984 run_lib.py:146] step: 108650, training_loss: 7.12286e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:04:26.823025 22392998065984 run_lib.py:146] step: 108700, training_loss: 6.17575e-02
I0514 10:04:26.981122 22392998065984 run_lib.py:167] step: 108700, eval_loss: 6.75349e-02
I0514 10:04:50.552559 22392998065984 run_lib.py:146] step: 108750, training_loss: 6.43187e-02
I0514 10:05:13.818412 22392998065984 run_lib.py:146] step: 108800, training_loss: 5.73462e-02
I0514 10:05:13.975119 22392998065984 run_lib.py:167] step: 108800, eval_loss: 5.54983e-02
I0514 10:05:37.579456 22392998065984 run_lib.py:146] step: 108850, training_loss: 5.84458e-02
I0514 10:06:00.850602 22392998065984 run_lib.py:146] step: 108900, training_loss: 4.78632e-02
I0514 10:06:01.007031 22392998065984 run_lib.py:167] step: 108900, eval_loss: 6.28121e-02
I0514 10:06:24.553702 22392998065984 run_lib.py:146] step: 108950, training_loss: 7.04049e-02
I0514 10:06:48.114745 22392998065984 run_lib.py:146] step: 109000, training_loss: 6.98084e-02
I0514 10:06:48.271657 22392998065984 run_lib.py:167] step: 109000, eval_loss: 5.60516e-02
I0514 10:07:11.522044 22392998065984 run_lib.py:146] step: 109050, training_loss: 7.21671e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:07:35.181887 22392998065984 run_lib.py:146] step: 109100, training_loss: 6.53818e-02
I0514 10:07:35.340046 22392998065984 run_lib.py:167] step: 109100, eval_loss: 4.94393e-02
I0514 10:07:58.577462 22392998065984 run_lib.py:146] step: 109150, training_loss: 6.71121e-02
I0514 10:08:22.182270 22392998065984 run_lib.py:146] step: 109200, training_loss: 5.27267e-02
I0514 10:08:22.339269 22392998065984 run_lib.py:167] step: 109200, eval_loss: 5.74511e-02
I0514 10:08:45.918681 22392998065984 run_lib.py:146] step: 109250, training_loss: 6.27084e-02
I0514 10:09:09.662871 22392998065984 run_lib.py:146] step: 109300, training_loss: 5.55026e-02
I0514 10:09:09.836553 22392998065984 run_lib.py:167] step: 109300, eval_loss: 4.39649e-02
I0514 10:09:33.845854 22392998065984 run_lib.py:146] step: 109350, training_loss: 5.90243e-02
I0514 10:09:57.818730 22392998065984 run_lib.py:146] step: 109400, training_loss: 5.86667e-02
I0514 10:09:57.991041 22392998065984 run_lib.py:167] step: 109400, eval_loss: 6.59088e-02
I0514 10:10:21.259869 22392998065984 run_lib.py:146] step: 109450, training_loss: 5.86975e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:10:45.187060 22392998065984 run_lib.py:146] step: 109500, training_loss: 7.08768e-02
I0514 10:10:45.344855 22392998065984 run_lib.py:167] step: 109500, eval_loss: 6.31368e-02
I0514 10:11:09.439602 22392998065984 run_lib.py:146] step: 109550, training_loss: 6.25637e-02
I0514 10:11:33.174612 22392998065984 run_lib.py:146] step: 109600, training_loss: 5.77054e-02
I0514 10:11:33.331287 22392998065984 run_lib.py:167] step: 109600, eval_loss: 5.88107e-02
I0514 10:11:57.344572 22392998065984 run_lib.py:146] step: 109650, training_loss: 6.48185e-02
I0514 10:12:20.879098 22392998065984 run_lib.py:146] step: 109700, training_loss: 5.44777e-02
I0514 10:12:21.035884 22392998065984 run_lib.py:167] step: 109700, eval_loss: 5.62144e-02
I0514 10:12:44.579271 22392998065984 run_lib.py:146] step: 109750, training_loss: 4.79430e-02
I0514 10:13:07.856429 22392998065984 run_lib.py:146] step: 109800, training_loss: 5.71303e-02
I0514 10:13:08.012943 22392998065984 run_lib.py:167] step: 109800, eval_loss: 6.24819e-02
I0514 10:13:31.589923 22392998065984 run_lib.py:146] step: 109850, training_loss: 5.61923e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:13:55.571936 22392998065984 run_lib.py:146] step: 109900, training_loss: 5.06303e-02
I0514 10:13:55.729764 22392998065984 run_lib.py:167] step: 109900, eval_loss: 6.20628e-02
I0514 10:14:19.005442 22392998065984 run_lib.py:146] step: 109950, training_loss: 6.63424e-02
I0514 10:14:42.601257 22392998065984 run_lib.py:146] step: 110000, training_loss: 6.29144e-02
I0514 10:14:44.526709 22392998065984 run_lib.py:167] step: 110000, eval_loss: 5.30712e-02
I0514 10:15:11.029606 22392998065984 run_lib.py:146] step: 110050, training_loss: 7.27782e-02
I0514 10:15:34.586313 22392998065984 run_lib.py:146] step: 110100, training_loss: 4.64000e-02
I0514 10:15:34.742559 22392998065984 run_lib.py:167] step: 110100, eval_loss: 5.51685e-02
I0514 10:15:58.010411 22392998065984 run_lib.py:146] step: 110150, training_loss: 5.86865e-02
I0514 10:16:21.548373 22392998065984 run_lib.py:146] step: 110200, training_loss: 4.45882e-02
I0514 10:16:21.705235 22392998065984 run_lib.py:167] step: 110200, eval_loss: 6.47411e-02
I0514 10:16:45.263060 22392998065984 run_lib.py:146] step: 110250, training_loss: 6.20490e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:17:08.982515 22392998065984 run_lib.py:146] step: 110300, training_loss: 6.03218e-02
I0514 10:17:09.140794 22392998065984 run_lib.py:167] step: 110300, eval_loss: 6.25035e-02
I0514 10:17:32.717628 22392998065984 run_lib.py:146] step: 110350, training_loss: 5.64464e-02
I0514 10:17:56.312184 22392998065984 run_lib.py:146] step: 110400, training_loss: 6.50269e-02
I0514 10:17:56.468143 22392998065984 run_lib.py:167] step: 110400, eval_loss: 5.85710e-02
I0514 10:18:19.746243 22392998065984 run_lib.py:146] step: 110450, training_loss: 5.67698e-02
I0514 10:18:43.026714 22392998065984 run_lib.py:146] step: 110500, training_loss: 5.82173e-02
I0514 10:18:43.105574 22392998065984 run_lib.py:167] step: 110500, eval_loss: 3.95961e-02
I0514 10:19:06.978243 22392998065984 run_lib.py:146] step: 110550, training_loss: 6.64035e-02
I0514 10:19:30.266862 22392998065984 run_lib.py:146] step: 110600, training_loss: 5.24181e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:19:30.648984 22392998065984 run_lib.py:167] step: 110600, eval_loss: 5.74506e-02
I0514 10:19:53.967044 22392998065984 run_lib.py:146] step: 110650, training_loss: 7.48648e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:20:17.727717 22392998065984 run_lib.py:146] step: 110700, training_loss: 4.65606e-02
I0514 10:20:17.885820 22392998065984 run_lib.py:167] step: 110700, eval_loss: 7.60680e-02
I0514 10:20:41.509636 22392998065984 run_lib.py:146] step: 110750, training_loss: 5.40901e-02
I0514 10:21:04.789096 22392998065984 run_lib.py:146] step: 110800, training_loss: 5.83667e-02
I0514 10:21:04.945669 22392998065984 run_lib.py:167] step: 110800, eval_loss: 4.92744e-02
I0514 10:21:28.523114 22392998065984 run_lib.py:146] step: 110850, training_loss: 6.38814e-02
I0514 10:21:52.111143 22392998065984 run_lib.py:146] step: 110900, training_loss: 6.47400e-02
I0514 10:21:52.268110 22392998065984 run_lib.py:167] step: 110900, eval_loss: 4.39969e-02
I0514 10:22:16.007255 22392998065984 run_lib.py:146] step: 110950, training_loss: 5.41824e-02
I0514 10:22:40.053060 22392998065984 run_lib.py:146] step: 111000, training_loss: 5.64576e-02
I0514 10:22:40.209681 22392998065984 run_lib.py:167] step: 111000, eval_loss: 4.21927e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:23:04.093068 22392998065984 run_lib.py:146] step: 111050, training_loss: 5.93039e-02
I0514 10:23:27.355832 22392998065984 run_lib.py:146] step: 111100, training_loss: 6.25639e-02
I0514 10:23:27.513375 22392998065984 run_lib.py:167] step: 111100, eval_loss: 6.69362e-02
I0514 10:23:51.104047 22392998065984 run_lib.py:146] step: 111150, training_loss: 6.16006e-02
I0514 10:24:14.691870 22392998065984 run_lib.py:146] step: 111200, training_loss: 8.22265e-02
I0514 10:24:14.848052 22392998065984 run_lib.py:167] step: 111200, eval_loss: 7.29393e-02
I0514 10:24:38.403452 22392998065984 run_lib.py:146] step: 111250, training_loss: 6.99829e-02
I0514 10:25:02.145809 22392998065984 run_lib.py:146] step: 111300, training_loss: 7.70365e-02
I0514 10:25:02.302242 22392998065984 run_lib.py:167] step: 111300, eval_loss: 7.26116e-02
I0514 10:25:26.633874 22392998065984 run_lib.py:146] step: 111350, training_loss: 5.32057e-02
I0514 10:25:50.364635 22392998065984 run_lib.py:146] step: 111400, training_loss: 6.37257e-02
I0514 10:25:50.521496 22392998065984 run_lib.py:167] step: 111400, eval_loss: 5.68603e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:26:14.281090 22392998065984 run_lib.py:146] step: 111450, training_loss: 6.84656e-02
I0514 10:26:37.890520 22392998065984 run_lib.py:146] step: 111500, training_loss: 7.23135e-02
I0514 10:26:38.053882 22392998065984 run_lib.py:167] step: 111500, eval_loss: 5.66554e-02
I0514 10:27:01.669621 22392998065984 run_lib.py:146] step: 111550, training_loss: 5.31456e-02
I0514 10:27:25.171009 22392998065984 run_lib.py:146] step: 111600, training_loss: 6.65947e-02
I0514 10:27:25.327201 22392998065984 run_lib.py:167] step: 111600, eval_loss: 7.40156e-02
I0514 10:27:48.893738 22392998065984 run_lib.py:146] step: 111650, training_loss: 6.66044e-02
I0514 10:28:12.427162 22392998065984 run_lib.py:146] step: 111700, training_loss: 5.17808e-02
I0514 10:28:12.583737 22392998065984 run_lib.py:167] step: 111700, eval_loss: 6.52896e-02
I0514 10:28:35.823626 22392998065984 run_lib.py:146] step: 111750, training_loss: 4.61713e-02
I0514 10:28:59.378522 22392998065984 run_lib.py:146] step: 111800, training_loss: 6.55197e-02
I0514 10:28:59.534733 22392998065984 run_lib.py:167] step: 111800, eval_loss: 6.80444e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:29:23.218972 22392998065984 run_lib.py:146] step: 111850, training_loss: 6.15014e-02
I0514 10:29:46.499656 22392998065984 run_lib.py:146] step: 111900, training_loss: 5.51796e-02
I0514 10:29:46.658535 22392998065984 run_lib.py:167] step: 111900, eval_loss: 4.43630e-02
I0514 10:30:10.289139 22392998065984 run_lib.py:146] step: 111950, training_loss: 6.65018e-02
I0514 10:30:33.900265 22392998065984 run_lib.py:146] step: 112000, training_loss: 6.55789e-02
I0514 10:30:34.056712 22392998065984 run_lib.py:167] step: 112000, eval_loss: 5.21991e-02
I0514 10:30:57.474562 22392998065984 run_lib.py:146] step: 112050, training_loss: 5.56276e-02
I0514 10:31:21.210300 22392998065984 run_lib.py:146] step: 112100, training_loss: 7.73112e-02
I0514 10:31:21.366822 22392998065984 run_lib.py:167] step: 112100, eval_loss: 5.39874e-02
I0514 10:31:45.730231 22392998065984 run_lib.py:146] step: 112150, training_loss: 5.70839e-02
I0514 10:32:09.415335 22392998065984 run_lib.py:146] step: 112200, training_loss: 5.00277e-02
I0514 10:32:09.571651 22392998065984 run_lib.py:167] step: 112200, eval_loss: 5.21760e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:32:33.044965 22392998065984 run_lib.py:146] step: 112250, training_loss: 6.17427e-02
I0514 10:32:56.649813 22392998065984 run_lib.py:146] step: 112300, training_loss: 6.86889e-02
I0514 10:32:57.143685 22392998065984 run_lib.py:167] step: 112300, eval_loss: 6.23634e-02
I0514 10:33:20.423151 22392998065984 run_lib.py:146] step: 112350, training_loss: 7.23569e-02
I0514 10:33:43.821051 22392998065984 run_lib.py:146] step: 112400, training_loss: 5.51117e-02
I0514 10:33:43.977202 22392998065984 run_lib.py:167] step: 112400, eval_loss: 5.44985e-02
I0514 10:34:08.022077 22392998065984 run_lib.py:146] step: 112450, training_loss: 7.06545e-02
I0514 10:34:31.898588 22392998065984 run_lib.py:146] step: 112500, training_loss: 4.99810e-02
I0514 10:34:32.054733 22392998065984 run_lib.py:167] step: 112500, eval_loss: 5.26011e-02
I0514 10:34:55.300059 22392998065984 run_lib.py:146] step: 112550, training_loss: 6.00296e-02
I0514 10:35:19.294197 22392998065984 run_lib.py:146] step: 112600, training_loss: 8.43057e-02
I0514 10:35:19.451039 22392998065984 run_lib.py:167] step: 112600, eval_loss: 7.10031e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:35:43.306405 22392998065984 run_lib.py:146] step: 112650, training_loss: 7.11493e-02
I0514 10:36:06.596195 22392998065984 run_lib.py:146] step: 112700, training_loss: 9.47903e-02
I0514 10:36:06.754051 22392998065984 run_lib.py:167] step: 112700, eval_loss: 4.64142e-02
I0514 10:36:30.355044 22392998065984 run_lib.py:146] step: 112750, training_loss: 6.83874e-02
I0514 10:36:53.935226 22392998065984 run_lib.py:146] step: 112800, training_loss: 7.43762e-02
I0514 10:36:54.091761 22392998065984 run_lib.py:167] step: 112800, eval_loss: 7.90475e-02
I0514 10:37:17.368306 22392998065984 run_lib.py:146] step: 112850, training_loss: 5.99088e-02
I0514 10:37:40.698530 22392998065984 run_lib.py:146] step: 112900, training_loss: 5.00549e-02
I0514 10:37:40.855323 22392998065984 run_lib.py:167] step: 112900, eval_loss: 7.93514e-02
I0514 10:38:04.719631 22392998065984 run_lib.py:146] step: 112950, training_loss: 6.12735e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:38:28.106166 22392998065984 run_lib.py:146] step: 113000, training_loss: 5.70121e-02
I0514 10:38:28.264102 22392998065984 run_lib.py:167] step: 113000, eval_loss: 6.30391e-02
I0514 10:38:51.662032 22392998065984 run_lib.py:146] step: 113050, training_loss: 5.17768e-02
I0514 10:39:15.275440 22392998065984 run_lib.py:146] step: 113100, training_loss: 6.62474e-02
I0514 10:39:15.432021 22392998065984 run_lib.py:167] step: 113100, eval_loss: 5.13809e-02
I0514 10:39:39.042452 22392998065984 run_lib.py:146] step: 113150, training_loss: 6.44265e-02
I0514 10:40:02.311949 22392998065984 run_lib.py:146] step: 113200, training_loss: 8.13237e-02
I0514 10:40:02.468680 22392998065984 run_lib.py:167] step: 113200, eval_loss: 5.56539e-02
I0514 10:40:26.025671 22392998065984 run_lib.py:146] step: 113250, training_loss: 4.52768e-02
I0514 10:40:49.590484 22392998065984 run_lib.py:146] step: 113300, training_loss: 6.11914e-02
I0514 10:40:49.747169 22392998065984 run_lib.py:167] step: 113300, eval_loss: 6.66979e-02
I0514 10:41:13.008316 22392998065984 run_lib.py:146] step: 113350, training_loss: 5.89009e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:41:36.813396 22392998065984 run_lib.py:146] step: 113400, training_loss: 4.79259e-02
I0514 10:41:36.971523 22392998065984 run_lib.py:167] step: 113400, eval_loss: 5.62611e-02
I0514 10:42:01.046098 22392998065984 run_lib.py:146] step: 113450, training_loss: 5.22701e-02
I0514 10:42:24.723155 22392998065984 run_lib.py:146] step: 113500, training_loss: 6.03362e-02
I0514 10:42:24.879733 22392998065984 run_lib.py:167] step: 113500, eval_loss: 5.27529e-02
I0514 10:42:48.467140 22392998065984 run_lib.py:146] step: 113550, training_loss: 5.29830e-02
I0514 10:43:12.036245 22392998065984 run_lib.py:146] step: 113600, training_loss: 5.14275e-02
I0514 10:43:12.192655 22392998065984 run_lib.py:167] step: 113600, eval_loss: 7.08733e-02
I0514 10:43:35.449793 22392998065984 run_lib.py:146] step: 113650, training_loss: 7.26394e-02
I0514 10:43:58.725832 22392998065984 run_lib.py:146] step: 113700, training_loss: 6.91929e-02
I0514 10:43:58.882005 22392998065984 run_lib.py:167] step: 113700, eval_loss: 5.69140e-02
I0514 10:44:22.687309 22392998065984 run_lib.py:146] step: 113750, training_loss: 5.59399e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:44:46.062193 22392998065984 run_lib.py:146] step: 113800, training_loss: 6.05744e-02
I0514 10:44:46.220219 22392998065984 run_lib.py:167] step: 113800, eval_loss: 5.06009e-02
I0514 10:45:09.462633 22392998065984 run_lib.py:146] step: 113850, training_loss: 5.92590e-02
I0514 10:45:33.379793 22392998065984 run_lib.py:146] step: 113900, training_loss: 5.40644e-02
I0514 10:45:33.535884 22392998065984 run_lib.py:167] step: 113900, eval_loss: 5.00887e-02
I0514 10:45:56.795227 22392998065984 run_lib.py:146] step: 113950, training_loss: 4.78980e-02
I0514 10:46:20.053316 22392998065984 run_lib.py:146] step: 114000, training_loss: 5.79827e-02
I0514 10:46:20.209958 22392998065984 run_lib.py:167] step: 114000, eval_loss: 5.20680e-02
I0514 10:46:43.752101 22392998065984 run_lib.py:146] step: 114050, training_loss: 6.95878e-02
I0514 10:47:07.334026 22392998065984 run_lib.py:146] step: 114100, training_loss: 6.35302e-02
I0514 10:47:07.490454 22392998065984 run_lib.py:167] step: 114100, eval_loss: 5.70824e-02
I0514 10:47:30.752561 22392998065984 run_lib.py:146] step: 114150, training_loss: 7.78085e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:47:54.796247 22392998065984 run_lib.py:146] step: 114200, training_loss: 4.90113e-02
I0514 10:47:54.954108 22392998065984 run_lib.py:167] step: 114200, eval_loss: 8.28492e-02
I0514 10:48:19.020422 22392998065984 run_lib.py:146] step: 114250, training_loss: 5.99211e-02
I0514 10:48:42.756709 22392998065984 run_lib.py:146] step: 114300, training_loss: 4.64949e-02
I0514 10:48:42.912989 22392998065984 run_lib.py:167] step: 114300, eval_loss: 7.04718e-02
I0514 10:49:06.995668 22392998065984 run_lib.py:146] step: 114350, training_loss: 7.91007e-02
I0514 10:49:30.999898 22392998065984 run_lib.py:146] step: 114400, training_loss: 6.43760e-02
I0514 10:49:31.156322 22392998065984 run_lib.py:167] step: 114400, eval_loss: 6.78001e-02
I0514 10:49:54.893261 22392998065984 run_lib.py:146] step: 114450, training_loss: 6.78448e-02
I0514 10:50:18.934548 22392998065984 run_lib.py:146] step: 114500, training_loss: 7.39503e-02
I0514 10:50:19.091263 22392998065984 run_lib.py:167] step: 114500, eval_loss: 6.77230e-02
I0514 10:50:43.096855 22392998065984 run_lib.py:146] step: 114550, training_loss: 5.31269e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:51:06.641210 22392998065984 run_lib.py:146] step: 114600, training_loss: 5.53336e-02
I0514 10:51:06.799498 22392998065984 run_lib.py:167] step: 114600, eval_loss: 5.32410e-02
I0514 10:51:30.071937 22392998065984 run_lib.py:146] step: 114650, training_loss: 5.17833e-02
I0514 10:51:53.966420 22392998065984 run_lib.py:146] step: 114700, training_loss: 4.78678e-02
I0514 10:51:54.122571 22392998065984 run_lib.py:167] step: 114700, eval_loss: 4.46485e-02
I0514 10:52:17.385403 22392998065984 run_lib.py:146] step: 114750, training_loss: 6.32135e-02
I0514 10:52:40.648974 22392998065984 run_lib.py:146] step: 114800, training_loss: 5.83148e-02
I0514 10:52:40.805455 22392998065984 run_lib.py:167] step: 114800, eval_loss: 5.71139e-02
I0514 10:53:04.681386 22392998065984 run_lib.py:146] step: 114850, training_loss: 4.38973e-02
I0514 10:53:28.694599 22392998065984 run_lib.py:146] step: 114900, training_loss: 6.54262e-02
I0514 10:53:28.851163 22392998065984 run_lib.py:167] step: 114900, eval_loss: 6.78722e-02
I0514 10:53:52.598353 22392998065984 run_lib.py:146] step: 114950, training_loss: 6.58819e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:54:16.397387 22392998065984 run_lib.py:146] step: 115000, training_loss: 6.82210e-02
I0514 10:54:16.556022 22392998065984 run_lib.py:167] step: 115000, eval_loss: 6.09937e-02
I0514 10:54:40.175847 22392998065984 run_lib.py:146] step: 115050, training_loss: 7.33221e-02
I0514 10:55:03.448055 22392998065984 run_lib.py:146] step: 115100, training_loss: 7.02442e-02
I0514 10:55:03.604252 22392998065984 run_lib.py:167] step: 115100, eval_loss: 6.54872e-02
I0514 10:55:27.172063 22392998065984 run_lib.py:146] step: 115150, training_loss: 5.42864e-02
I0514 10:55:50.726795 22392998065984 run_lib.py:146] step: 115200, training_loss: 6.51321e-02
I0514 10:55:50.883069 22392998065984 run_lib.py:167] step: 115200, eval_loss: 6.88159e-02
I0514 10:56:14.140288 22392998065984 run_lib.py:146] step: 115250, training_loss: 4.39783e-02
I0514 10:56:37.678128 22392998065984 run_lib.py:146] step: 115300, training_loss: 5.99929e-02
I0514 10:56:37.834341 22392998065984 run_lib.py:167] step: 115300, eval_loss: 7.64350e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 10:57:01.561974 22392998065984 run_lib.py:146] step: 115350, training_loss: 5.11195e-02
I0514 10:57:25.305896 22392998065984 run_lib.py:146] step: 115400, training_loss: 5.34856e-02
I0514 10:57:25.463461 22392998065984 run_lib.py:167] step: 115400, eval_loss: 4.89834e-02
I0514 10:57:49.196819 22392998065984 run_lib.py:146] step: 115450, training_loss: 6.08707e-02
I0514 10:58:13.453898 22392998065984 run_lib.py:146] step: 115500, training_loss: 5.39995e-02
I0514 10:58:13.610104 22392998065984 run_lib.py:167] step: 115500, eval_loss: 4.99590e-02
I0514 10:58:36.867163 22392998065984 run_lib.py:146] step: 115550, training_loss: 5.30434e-02
I0514 10:59:00.132263 22392998065984 run_lib.py:146] step: 115600, training_loss: 5.74693e-02
I0514 10:59:00.288490 22392998065984 run_lib.py:167] step: 115600, eval_loss: 6.18690e-02
I0514 10:59:24.116866 22392998065984 run_lib.py:146] step: 115650, training_loss: 7.21280e-02
I0514 10:59:47.370071 22392998065984 run_lib.py:146] step: 115700, training_loss: 5.57791e-02
I0514 10:59:47.526839 22392998065984 run_lib.py:167] step: 115700, eval_loss: 5.99495e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:00:11.043175 22392998065984 run_lib.py:146] step: 115750, training_loss: 6.13891e-02
I0514 11:00:35.126840 22392998065984 run_lib.py:146] step: 115800, training_loss: 6.72650e-02
I0514 11:00:35.284523 22392998065984 run_lib.py:167] step: 115800, eval_loss: 8.63642e-02
I0514 11:00:59.327321 22392998065984 run_lib.py:146] step: 115850, training_loss: 5.64256e-02
I0514 11:01:23.065382 22392998065984 run_lib.py:146] step: 115900, training_loss: 8.24108e-02
I0514 11:01:23.222134 22392998065984 run_lib.py:167] step: 115900, eval_loss: 5.41034e-02
I0514 11:01:47.288210 22392998065984 run_lib.py:146] step: 115950, training_loss: 7.01488e-02
I0514 11:02:11.299531 22392998065984 run_lib.py:146] step: 116000, training_loss: 5.40818e-02
I0514 11:02:11.470799 22392998065984 run_lib.py:167] step: 116000, eval_loss: 6.70594e-02
I0514 11:02:35.195073 22392998065984 run_lib.py:146] step: 116050, training_loss: 4.22366e-02
I0514 11:02:59.244907 22392998065984 run_lib.py:146] step: 116100, training_loss: 7.50828e-02
I0514 11:02:59.401195 22392998065984 run_lib.py:167] step: 116100, eval_loss: 5.89388e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:03:23.426396 22392998065984 run_lib.py:146] step: 116150, training_loss: 6.17609e-02
I0514 11:03:46.686111 22392998065984 run_lib.py:146] step: 116200, training_loss: 6.42393e-02
I0514 11:03:46.843693 22392998065984 run_lib.py:167] step: 116200, eval_loss: 5.94565e-02
I0514 11:04:10.123159 22392998065984 run_lib.py:146] step: 116250, training_loss: 6.46847e-02
I0514 11:04:33.998693 22392998065984 run_lib.py:146] step: 116300, training_loss: 6.47499e-02
I0514 11:04:34.155130 22392998065984 run_lib.py:167] step: 116300, eval_loss: 6.31674e-02
I0514 11:04:57.427576 22392998065984 run_lib.py:146] step: 116350, training_loss: 5.46338e-02
I0514 11:05:20.693502 22392998065984 run_lib.py:146] step: 116400, training_loss: 4.06288e-02
I0514 11:05:20.849862 22392998065984 run_lib.py:167] step: 116400, eval_loss: 6.61450e-02
I0514 11:05:44.690423 22392998065984 run_lib.py:146] step: 116450, training_loss: 7.20851e-02
I0514 11:06:07.959188 22392998065984 run_lib.py:146] step: 116500, training_loss: 5.66776e-02
I0514 11:06:08.115610 22392998065984 run_lib.py:167] step: 116500, eval_loss: 7.63244e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:06:31.853906 22392998065984 run_lib.py:146] step: 116550, training_loss: 5.93163e-02
I0514 11:06:55.957857 22392998065984 run_lib.py:146] step: 116600, training_loss: 6.28403e-02
I0514 11:06:56.115221 22392998065984 run_lib.py:167] step: 116600, eval_loss: 8.19985e-02
I0514 11:07:20.192023 22392998065984 run_lib.py:146] step: 116650, training_loss: 4.49548e-02
I0514 11:07:43.933374 22392998065984 run_lib.py:146] step: 116700, training_loss: 7.93540e-02
I0514 11:07:44.089659 22392998065984 run_lib.py:167] step: 116700, eval_loss: 6.66782e-02
I0514 11:08:08.133659 22392998065984 run_lib.py:146] step: 116750, training_loss: 5.69859e-02
I0514 11:08:32.136619 22392998065984 run_lib.py:146] step: 116800, training_loss: 6.98109e-02
I0514 11:08:32.292663 22392998065984 run_lib.py:167] step: 116800, eval_loss: 5.62342e-02
I0514 11:08:56.029057 22392998065984 run_lib.py:146] step: 116850, training_loss: 9.50249e-02
I0514 11:09:20.068188 22392998065984 run_lib.py:146] step: 116900, training_loss: 5.63725e-02
I0514 11:09:20.224759 22392998065984 run_lib.py:167] step: 116900, eval_loss: 5.37615e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:09:44.209139 22392998065984 run_lib.py:146] step: 116950, training_loss: 6.03895e-02
I0514 11:10:07.948398 22392998065984 run_lib.py:146] step: 117000, training_loss: 5.33621e-02
I0514 11:10:08.106265 22392998065984 run_lib.py:167] step: 117000, eval_loss: 5.45794e-02
I0514 11:10:31.848297 22392998065984 run_lib.py:146] step: 117050, training_loss: 7.67538e-02
I0514 11:10:56.201366 22392998065984 run_lib.py:146] step: 117100, training_loss: 4.63600e-02
I0514 11:10:56.357762 22392998065984 run_lib.py:167] step: 117100, eval_loss: 6.95975e-02
I0514 11:11:20.100356 22392998065984 run_lib.py:146] step: 117150, training_loss: 6.85113e-02
I0514 11:11:43.843139 22392998065984 run_lib.py:146] step: 117200, training_loss: 7.20978e-02
I0514 11:11:43.999283 22392998065984 run_lib.py:167] step: 117200, eval_loss: 6.03808e-02
I0514 11:12:08.149916 22392998065984 run_lib.py:146] step: 117250, training_loss: 5.25184e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:12:31.551228 22392998065984 run_lib.py:146] step: 117300, training_loss: 5.99815e-02
I0514 11:12:31.709487 22392998065984 run_lib.py:167] step: 117300, eval_loss: 4.58758e-02
I0514 11:12:54.967553 22392998065984 run_lib.py:146] step: 117350, training_loss: 4.82589e-02
I0514 11:13:18.913302 22392998065984 run_lib.py:146] step: 117400, training_loss: 6.98110e-02
I0514 11:13:19.070169 22392998065984 run_lib.py:167] step: 117400, eval_loss: 6.33375e-02
I0514 11:13:42.316646 22392998065984 run_lib.py:146] step: 117450, training_loss: 6.51674e-02
I0514 11:14:05.558897 22392998065984 run_lib.py:146] step: 117500, training_loss: 4.94450e-02
I0514 11:14:05.715664 22392998065984 run_lib.py:167] step: 117500, eval_loss: 7.67534e-02
I0514 11:14:29.245526 22392998065984 run_lib.py:146] step: 117550, training_loss: 6.81288e-02
I0514 11:14:52.783483 22392998065984 run_lib.py:146] step: 117600, training_loss: 6.76732e-02
I0514 11:14:52.939585 22392998065984 run_lib.py:167] step: 117600, eval_loss: 7.27051e-02
I0514 11:15:16.175742 22392998065984 run_lib.py:146] step: 117650, training_loss: 5.28421e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:15:39.645302 22392998065984 run_lib.py:146] step: 117700, training_loss: 4.28430e-02
I0514 11:15:39.803110 22392998065984 run_lib.py:167] step: 117700, eval_loss: 6.27750e-02
I0514 11:16:04.227935 22392998065984 run_lib.py:146] step: 117750, training_loss: 6.40406e-02
I0514 11:16:27.969544 22392998065984 run_lib.py:146] step: 117800, training_loss: 7.27379e-02
I0514 11:16:28.144171 22392998065984 run_lib.py:167] step: 117800, eval_loss: 7.08263e-02
I0514 11:16:51.875817 22392998065984 run_lib.py:146] step: 117850, training_loss: 4.12572e-02
I0514 11:17:16.177788 22392998065984 run_lib.py:146] step: 117900, training_loss: 9.48452e-02
I0514 11:17:16.334269 22392998065984 run_lib.py:167] step: 117900, eval_loss: 5.70387e-02
I0514 11:17:40.078248 22392998065984 run_lib.py:146] step: 117950, training_loss: 4.91346e-02
I0514 11:18:03.812455 22392998065984 run_lib.py:146] step: 118000, training_loss: 6.81514e-02
I0514 11:18:03.968615 22392998065984 run_lib.py:167] step: 118000, eval_loss: 6.51812e-02
I0514 11:18:28.164977 22392998065984 run_lib.py:146] step: 118050, training_loss: 6.72002e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:18:51.722205 22392998065984 run_lib.py:146] step: 118100, training_loss: 5.01348e-02
I0514 11:18:51.880498 22392998065984 run_lib.py:167] step: 118100, eval_loss: 5.80077e-02
I0514 11:19:15.162640 22392998065984 run_lib.py:146] step: 118150, training_loss: 6.24165e-02
I0514 11:19:39.077105 22392998065984 run_lib.py:146] step: 118200, training_loss: 4.92595e-02
I0514 11:19:39.233413 22392998065984 run_lib.py:167] step: 118200, eval_loss: 6.30741e-02
I0514 11:20:02.475100 22392998065984 run_lib.py:146] step: 118250, training_loss: 5.56007e-02
I0514 11:20:25.720973 22392998065984 run_lib.py:146] step: 118300, training_loss: 5.58334e-02
I0514 11:20:25.876459 22392998065984 run_lib.py:167] step: 118300, eval_loss: 6.06041e-02
I0514 11:20:49.426519 22392998065984 run_lib.py:146] step: 118350, training_loss: 6.15436e-02
I0514 11:21:12.985037 22392998065984 run_lib.py:146] step: 118400, training_loss: 6.26575e-02
I0514 11:21:13.063097 22392998065984 run_lib.py:167] step: 118400, eval_loss: 5.35198e-02
I0514 11:21:36.312372 22392998065984 run_lib.py:146] step: 118450, training_loss: 7.59095e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:21:59.969461 22392998065984 run_lib.py:146] step: 118500, training_loss: 6.11906e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:22:00.335540 22392998065984 run_lib.py:167] step: 118500, eval_loss: 4.84103e-02
I0514 11:22:24.745626 22392998065984 run_lib.py:146] step: 118550, training_loss: 8.14783e-02
I0514 11:22:48.086688 22392998065984 run_lib.py:146] step: 118600, training_loss: 5.09403e-02
I0514 11:22:48.243007 22392998065984 run_lib.py:167] step: 118600, eval_loss: 7.90830e-02
I0514 11:23:11.501781 22392998065984 run_lib.py:146] step: 118650, training_loss: 5.17194e-02
I0514 11:23:35.369966 22392998065984 run_lib.py:146] step: 118700, training_loss: 5.47360e-02
I0514 11:23:35.526305 22392998065984 run_lib.py:167] step: 118700, eval_loss: 7.87441e-02
I0514 11:23:58.815992 22392998065984 run_lib.py:146] step: 118750, training_loss: 5.40628e-02
I0514 11:24:22.103968 22392998065984 run_lib.py:146] step: 118800, training_loss: 4.96159e-02
I0514 11:24:22.261193 22392998065984 run_lib.py:167] step: 118800, eval_loss: 5.38561e-02
I0514 11:24:46.117875 22392998065984 run_lib.py:146] step: 118850, training_loss: 6.85254e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:25:09.534121 22392998065984 run_lib.py:146] step: 118900, training_loss: 5.42180e-02
I0514 11:25:09.692183 22392998065984 run_lib.py:167] step: 118900, eval_loss: 5.54738e-02
I0514 11:25:32.933439 22392998065984 run_lib.py:146] step: 118950, training_loss: 5.89155e-02
I0514 11:25:56.919640 22392998065984 run_lib.py:146] step: 119000, training_loss: 7.99109e-02
I0514 11:25:57.075850 22392998065984 run_lib.py:167] step: 119000, eval_loss: 6.33363e-02
I0514 11:26:20.307112 22392998065984 run_lib.py:146] step: 119050, training_loss: 5.91761e-02
I0514 11:26:43.551618 22392998065984 run_lib.py:146] step: 119100, training_loss: 4.89299e-02
I0514 11:26:43.708151 22392998065984 run_lib.py:167] step: 119100, eval_loss: 6.66858e-02
I0514 11:27:07.251639 22392998065984 run_lib.py:146] step: 119150, training_loss: 5.16021e-02
I0514 11:27:30.788547 22392998065984 run_lib.py:146] step: 119200, training_loss: 5.51184e-02
I0514 11:27:30.945628 22392998065984 run_lib.py:167] step: 119200, eval_loss: 6.51584e-02
I0514 11:27:54.174830 22392998065984 run_lib.py:146] step: 119250, training_loss: 5.14154e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:28:18.363559 22392998065984 run_lib.py:146] step: 119300, training_loss: 7.41174e-02
I0514 11:28:18.521430 22392998065984 run_lib.py:167] step: 119300, eval_loss: 5.80608e-02
I0514 11:28:42.605384 22392998065984 run_lib.py:146] step: 119350, training_loss: 7.79793e-02
I0514 11:29:06.078096 22392998065984 run_lib.py:146] step: 119400, training_loss: 7.63874e-02
I0514 11:29:06.234702 22392998065984 run_lib.py:167] step: 119400, eval_loss: 6.02676e-02
I0514 11:29:29.474560 22392998065984 run_lib.py:146] step: 119450, training_loss: 6.38327e-02
I0514 11:29:53.297274 22392998065984 run_lib.py:146] step: 119500, training_loss: 6.09364e-02
I0514 11:29:53.453373 22392998065984 run_lib.py:167] step: 119500, eval_loss: 6.95551e-02
I0514 11:30:16.703036 22392998065984 run_lib.py:146] step: 119550, training_loss: 4.66170e-02
I0514 11:30:39.990737 22392998065984 run_lib.py:146] step: 119600, training_loss: 7.20198e-02
I0514 11:30:40.147109 22392998065984 run_lib.py:167] step: 119600, eval_loss: 6.86867e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:31:04.095456 22392998065984 run_lib.py:146] step: 119650, training_loss: 4.69151e-02
I0514 11:31:27.361967 22392998065984 run_lib.py:146] step: 119700, training_loss: 6.77667e-02
I0514 11:31:27.519667 22392998065984 run_lib.py:167] step: 119700, eval_loss: 6.60346e-02
I0514 11:31:50.781292 22392998065984 run_lib.py:146] step: 119750, training_loss: 5.84325e-02
I0514 11:32:14.698262 22392998065984 run_lib.py:146] step: 119800, training_loss: 5.53463e-02
I0514 11:32:14.854646 22392998065984 run_lib.py:167] step: 119800, eval_loss: 6.50112e-02
I0514 11:32:38.101437 22392998065984 run_lib.py:146] step: 119850, training_loss: 6.47912e-02
I0514 11:33:01.351104 22392998065984 run_lib.py:146] step: 119900, training_loss: 4.98970e-02
I0514 11:33:01.508130 22392998065984 run_lib.py:167] step: 119900, eval_loss: 1.03348e-01
I0514 11:33:25.042034 22392998065984 run_lib.py:146] step: 119950, training_loss: 6.31351e-02
I0514 11:33:48.606470 22392998065984 run_lib.py:146] step: 120000, training_loss: 6.52364e-02
I0514 11:33:53.736359 22392998065984 run_lib.py:167] step: 120000, eval_loss: 7.63684e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:34:22.045739 22392998065984 run_lib.py:146] step: 120050, training_loss: 6.56844e-02
I0514 11:34:46.443836 22392998065984 run_lib.py:146] step: 120100, training_loss: 4.24706e-02
I0514 11:34:46.602302 22392998065984 run_lib.py:167] step: 120100, eval_loss: 6.62168e-02
I0514 11:35:10.345231 22392998065984 run_lib.py:146] step: 120150, training_loss: 5.32613e-02
I0514 11:35:33.730945 22392998065984 run_lib.py:146] step: 120200, training_loss: 7.04042e-02
I0514 11:35:33.887062 22392998065984 run_lib.py:167] step: 120200, eval_loss: 6.47878e-02
I0514 11:35:57.453619 22392998065984 run_lib.py:146] step: 120250, training_loss: 5.58209e-02
I0514 11:36:21.000349 22392998065984 run_lib.py:146] step: 120300, training_loss: 4.25816e-02
I0514 11:36:21.156459 22392998065984 run_lib.py:167] step: 120300, eval_loss: 6.23233e-02
I0514 11:36:44.427005 22392998065984 run_lib.py:146] step: 120350, training_loss: 4.90038e-02
I0514 11:37:07.992244 22392998065984 run_lib.py:146] step: 120400, training_loss: 7.98959e-02
I0514 11:37:08.148578 22392998065984 run_lib.py:167] step: 120400, eval_loss: 8.31145e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:37:31.846070 22392998065984 run_lib.py:146] step: 120450, training_loss: 6.07835e-02
I0514 11:37:55.121871 22392998065984 run_lib.py:146] step: 120500, training_loss: 5.90286e-02
I0514 11:37:55.279855 22392998065984 run_lib.py:167] step: 120500, eval_loss: 5.74741e-02
I0514 11:38:19.290333 22392998065984 run_lib.py:146] step: 120550, training_loss: 5.79054e-02
I0514 11:38:43.106171 22392998065984 run_lib.py:146] step: 120600, training_loss: 6.69523e-02
I0514 11:38:43.262819 22392998065984 run_lib.py:167] step: 120600, eval_loss: 4.91787e-02
I0514 11:39:06.536353 22392998065984 run_lib.py:146] step: 120650, training_loss: 7.01724e-02
I0514 11:39:29.789958 22392998065984 run_lib.py:146] step: 120700, training_loss: 6.35033e-02
I0514 11:39:29.946067 22392998065984 run_lib.py:167] step: 120700, eval_loss: 7.72975e-02
I0514 11:39:53.771012 22392998065984 run_lib.py:146] step: 120750, training_loss: 6.44223e-02
I0514 11:40:17.027183 22392998065984 run_lib.py:146] step: 120800, training_loss: 6.11906e-02
I0514 11:40:17.183770 22392998065984 run_lib.py:167] step: 120800, eval_loss: 4.80700e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:40:40.579817 22392998065984 run_lib.py:146] step: 120850, training_loss: 9.26709e-02
I0514 11:41:04.517255 22392998065984 run_lib.py:146] step: 120900, training_loss: 4.16204e-02
I0514 11:41:04.675053 22392998065984 run_lib.py:167] step: 120900, eval_loss: 5.19942e-02
I0514 11:41:27.948628 22392998065984 run_lib.py:146] step: 120950, training_loss: 5.80042e-02
I0514 11:41:51.687158 22392998065984 run_lib.py:146] step: 121000, training_loss: 6.58526e-02
I0514 11:41:51.844990 22392998065984 run_lib.py:167] step: 121000, eval_loss: 6.53876e-02
I0514 11:42:15.854765 22392998065984 run_lib.py:146] step: 121050, training_loss: 6.63086e-02
I0514 11:42:39.893791 22392998065984 run_lib.py:146] step: 121100, training_loss: 6.93772e-02
I0514 11:42:40.050258 22392998065984 run_lib.py:167] step: 121100, eval_loss: 7.09679e-02
I0514 11:43:03.781532 22392998065984 run_lib.py:146] step: 121150, training_loss: 5.71324e-02
I0514 11:43:27.780210 22392998065984 run_lib.py:146] step: 121200, training_loss: 5.05617e-02
I0514 11:43:27.936424 22392998065984 run_lib.py:167] step: 121200, eval_loss: 5.95552e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:43:51.802453 22392998065984 run_lib.py:146] step: 121250, training_loss: 5.57668e-02
I0514 11:44:15.076922 22392998065984 run_lib.py:146] step: 121300, training_loss: 4.77867e-02
I0514 11:44:15.234842 22392998065984 run_lib.py:167] step: 121300, eval_loss: 8.92975e-02
I0514 11:44:39.072237 22392998065984 run_lib.py:146] step: 121350, training_loss: 6.98732e-02
I0514 11:45:03.113442 22392998065984 run_lib.py:146] step: 121400, training_loss: 5.38074e-02
I0514 11:45:03.269696 22392998065984 run_lib.py:167] step: 121400, eval_loss: 5.89104e-02
I0514 11:45:27.010247 22392998065984 run_lib.py:146] step: 121450, training_loss: 6.18903e-02
I0514 11:45:50.730025 22392998065984 run_lib.py:146] step: 121500, training_loss: 7.25180e-02
I0514 11:45:50.886640 22392998065984 run_lib.py:167] step: 121500, eval_loss: 1.01042e-01
I0514 11:46:15.210869 22392998065984 run_lib.py:146] step: 121550, training_loss: 5.65242e-02
I0514 11:46:38.828051 22392998065984 run_lib.py:146] step: 121600, training_loss: 8.22285e-02
I0514 11:46:38.984732 22392998065984 run_lib.py:167] step: 121600, eval_loss: 6.38262e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:47:02.525130 22392998065984 run_lib.py:146] step: 121650, training_loss: 6.25698e-02
I0514 11:47:26.464511 22392998065984 run_lib.py:146] step: 121700, training_loss: 6.43689e-02
I0514 11:47:26.626832 22392998065984 run_lib.py:167] step: 121700, eval_loss: 5.53012e-02
I0514 11:47:49.890486 22392998065984 run_lib.py:146] step: 121750, training_loss: 6.72158e-02
I0514 11:48:13.298078 22392998065984 run_lib.py:146] step: 121800, training_loss: 6.58719e-02
I0514 11:48:13.454289 22392998065984 run_lib.py:167] step: 121800, eval_loss: 7.22271e-02
I0514 11:48:37.473158 22392998065984 run_lib.py:146] step: 121850, training_loss: 6.59979e-02
I0514 11:49:01.521092 22392998065984 run_lib.py:146] step: 121900, training_loss: 4.62431e-02
I0514 11:49:01.677650 22392998065984 run_lib.py:167] step: 121900, eval_loss: 4.82331e-02
I0514 11:49:25.413817 22392998065984 run_lib.py:146] step: 121950, training_loss: 5.04961e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:49:49.600372 22392998065984 run_lib.py:146] step: 122000, training_loss: 6.13344e-02
I0514 11:49:49.758312 22392998065984 run_lib.py:167] step: 122000, eval_loss: 5.75235e-02
I0514 11:50:13.861844 22392998065984 run_lib.py:146] step: 122050, training_loss: 4.79475e-02
I0514 11:50:37.599711 22392998065984 run_lib.py:146] step: 122100, training_loss: 6.19201e-02
I0514 11:50:37.756293 22392998065984 run_lib.py:167] step: 122100, eval_loss: 6.06864e-02
I0514 11:51:01.796433 22392998065984 run_lib.py:146] step: 122150, training_loss: 5.87045e-02
I0514 11:51:25.837728 22392998065984 run_lib.py:146] step: 122200, training_loss: 5.75702e-02
I0514 11:51:25.993897 22392998065984 run_lib.py:167] step: 122200, eval_loss: 6.00018e-02
I0514 11:51:49.400276 22392998065984 run_lib.py:146] step: 122250, training_loss: 5.76698e-02
I0514 11:52:12.659784 22392998065984 run_lib.py:146] step: 122300, training_loss: 5.34557e-02
I0514 11:52:12.816464 22392998065984 run_lib.py:167] step: 122300, eval_loss: 6.22549e-02
I0514 11:52:36.641510 22392998065984 run_lib.py:146] step: 122350, training_loss: 6.66196e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:53:00.044290 22392998065984 run_lib.py:146] step: 122400, training_loss: 7.35665e-02
I0514 11:53:00.202173 22392998065984 run_lib.py:167] step: 122400, eval_loss: 7.44873e-02
I0514 11:53:23.623884 22392998065984 run_lib.py:146] step: 122450, training_loss: 5.57664e-02
I0514 11:53:48.005596 22392998065984 run_lib.py:146] step: 122500, training_loss: 5.99706e-02
I0514 11:53:48.162544 22392998065984 run_lib.py:167] step: 122500, eval_loss: 6.00552e-02
I0514 11:54:11.535015 22392998065984 run_lib.py:146] step: 122550, training_loss: 1.00012e-01
I0514 11:54:34.804475 22392998065984 run_lib.py:146] step: 122600, training_loss: 6.22152e-02
I0514 11:54:34.960852 22392998065984 run_lib.py:167] step: 122600, eval_loss: 6.33166e-02
I0514 11:54:58.824851 22392998065984 run_lib.py:146] step: 122650, training_loss: 7.89818e-02
I0514 11:55:22.099817 22392998065984 run_lib.py:146] step: 122700, training_loss: 5.26616e-02
I0514 11:55:22.257219 22392998065984 run_lib.py:167] step: 122700, eval_loss: 7.39686e-02
I0514 11:55:45.526193 22392998065984 run_lib.py:146] step: 122750, training_loss: 5.06473e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:56:09.381036 22392998065984 run_lib.py:146] step: 122800, training_loss: 7.73545e-02
I0514 11:56:09.538589 22392998065984 run_lib.py:167] step: 122800, eval_loss: 6.65607e-02
I0514 11:56:33.132614 22392998065984 run_lib.py:146] step: 122850, training_loss: 7.04311e-02
I0514 11:56:56.396794 22392998065984 run_lib.py:146] step: 122900, training_loss: 6.07923e-02
I0514 11:56:56.553513 22392998065984 run_lib.py:167] step: 122900, eval_loss: 7.20833e-02
I0514 11:57:20.107625 22392998065984 run_lib.py:146] step: 122950, training_loss: 5.48685e-02
I0514 11:57:43.676092 22392998065984 run_lib.py:146] step: 123000, training_loss: 5.98407e-02
I0514 11:57:43.832650 22392998065984 run_lib.py:167] step: 123000, eval_loss: 5.23785e-02
I0514 11:58:07.088735 22392998065984 run_lib.py:146] step: 123050, training_loss: 5.96767e-02
I0514 11:58:30.651544 22392998065984 run_lib.py:146] step: 123100, training_loss: 6.06792e-02
I0514 11:58:30.808621 22392998065984 run_lib.py:167] step: 123100, eval_loss: 6.36997e-02
I0514 11:58:54.356175 22392998065984 run_lib.py:146] step: 123150, training_loss: 6.03039e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 11:59:18.111784 22392998065984 run_lib.py:146] step: 123200, training_loss: 6.24743e-02
I0514 11:59:18.269802 22392998065984 run_lib.py:167] step: 123200, eval_loss: 5.65930e-02
I0514 11:59:42.008159 22392998065984 run_lib.py:146] step: 123250, training_loss: 6.19416e-02
I0514 12:00:05.998996 22392998065984 run_lib.py:146] step: 123300, training_loss: 5.55859e-02
I0514 12:00:06.155701 22392998065984 run_lib.py:167] step: 123300, eval_loss: 6.08987e-02
I0514 12:00:29.416553 22392998065984 run_lib.py:146] step: 123350, training_loss: 6.00310e-02
I0514 12:00:52.680643 22392998065984 run_lib.py:146] step: 123400, training_loss: 6.34204e-02
I0514 12:00:52.837692 22392998065984 run_lib.py:167] step: 123400, eval_loss: 7.40954e-02
I0514 12:01:16.690431 22392998065984 run_lib.py:146] step: 123450, training_loss: 6.25503e-02
I0514 12:01:39.979661 22392998065984 run_lib.py:146] step: 123500, training_loss: 7.20262e-02
I0514 12:01:40.138125 22392998065984 run_lib.py:167] step: 123500, eval_loss: 5.87056e-02
I0514 12:02:03.563370 22392998065984 run_lib.py:146] step: 123550, training_loss: 8.23100e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:02:27.688710 22392998065984 run_lib.py:146] step: 123600, training_loss: 7.40402e-02
I0514 12:02:27.846478 22392998065984 run_lib.py:167] step: 123600, eval_loss: 7.12644e-02
I0514 12:02:51.930576 22392998065984 run_lib.py:146] step: 123650, training_loss: 6.84859e-02
I0514 12:03:15.667357 22392998065984 run_lib.py:146] step: 123700, training_loss: 5.01479e-02
I0514 12:03:15.823879 22392998065984 run_lib.py:167] step: 123700, eval_loss: 6.88541e-02
I0514 12:03:39.838282 22392998065984 run_lib.py:146] step: 123750, training_loss: 6.70945e-02
I0514 12:04:03.878725 22392998065984 run_lib.py:146] step: 123800, training_loss: 5.18085e-02
I0514 12:04:04.035485 22392998065984 run_lib.py:167] step: 123800, eval_loss: 7.54512e-02
I0514 12:04:27.779471 22392998065984 run_lib.py:146] step: 123850, training_loss: 6.74909e-02
I0514 12:04:51.804255 22392998065984 run_lib.py:146] step: 123900, training_loss: 5.19443e-02
I0514 12:04:51.960933 22392998065984 run_lib.py:167] step: 123900, eval_loss: 5.50078e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:05:16.120208 22392998065984 run_lib.py:146] step: 123950, training_loss: 7.16963e-02
I0514 12:05:39.371592 22392998065984 run_lib.py:146] step: 124000, training_loss: 5.15495e-02
I0514 12:05:39.529035 22392998065984 run_lib.py:167] step: 124000, eval_loss: 6.13242e-02
I0514 12:06:02.774775 22392998065984 run_lib.py:146] step: 124050, training_loss: 7.07176e-02
I0514 12:06:26.693695 22392998065984 run_lib.py:146] step: 124100, training_loss: 6.22023e-02
I0514 12:06:26.850497 22392998065984 run_lib.py:167] step: 124100, eval_loss: 6.69803e-02
I0514 12:06:50.126008 22392998065984 run_lib.py:146] step: 124150, training_loss: 5.83916e-02
I0514 12:07:13.394023 22392998065984 run_lib.py:146] step: 124200, training_loss: 6.34709e-02
I0514 12:07:13.550584 22392998065984 run_lib.py:167] step: 124200, eval_loss: 6.50659e-02
I0514 12:07:37.414164 22392998065984 run_lib.py:146] step: 124250, training_loss: 6.99351e-02
I0514 12:08:00.679574 22392998065984 run_lib.py:146] step: 124300, training_loss: 4.61512e-02
I0514 12:08:00.836402 22392998065984 run_lib.py:167] step: 124300, eval_loss: 5.78339e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:08:24.353235 22392998065984 run_lib.py:146] step: 124350, training_loss: 4.67488e-02
I0514 12:08:48.294124 22392998065984 run_lib.py:146] step: 124400, training_loss: 5.56184e-02
I0514 12:08:48.452605 22392998065984 run_lib.py:167] step: 124400, eval_loss: 5.98054e-02
I0514 12:09:12.031934 22392998065984 run_lib.py:146] step: 124450, training_loss: 5.32045e-02
I0514 12:09:35.283105 22392998065984 run_lib.py:146] step: 124500, training_loss: 4.56567e-02
I0514 12:09:35.462713 22392998065984 run_lib.py:167] step: 124500, eval_loss: 3.90918e-02
I0514 12:09:59.025322 22392998065984 run_lib.py:146] step: 124550, training_loss: 5.43546e-02
I0514 12:10:22.565454 22392998065984 run_lib.py:146] step: 124600, training_loss: 5.81380e-02
I0514 12:10:22.721873 22392998065984 run_lib.py:167] step: 124600, eval_loss: 8.83533e-02
I0514 12:10:45.972218 22392998065984 run_lib.py:146] step: 124650, training_loss: 5.67877e-02
I0514 12:11:09.505524 22392998065984 run_lib.py:146] step: 124700, training_loss: 5.91847e-02
I0514 12:11:09.662048 22392998065984 run_lib.py:167] step: 124700, eval_loss: 6.41400e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:11:33.542902 22392998065984 run_lib.py:146] step: 124750, training_loss: 4.48649e-02
I0514 12:11:57.271876 22392998065984 run_lib.py:146] step: 124800, training_loss: 5.24791e-02
I0514 12:11:57.429459 22392998065984 run_lib.py:167] step: 124800, eval_loss: 7.19628e-02
I0514 12:12:21.174311 22392998065984 run_lib.py:146] step: 124850, training_loss: 4.64485e-02
I0514 12:12:45.564815 22392998065984 run_lib.py:146] step: 124900, training_loss: 5.40421e-02
I0514 12:12:45.721380 22392998065984 run_lib.py:167] step: 124900, eval_loss: 5.10589e-02
I0514 12:13:09.255406 22392998065984 run_lib.py:146] step: 124950, training_loss: 7.58334e-02
I0514 12:13:32.508072 22392998065984 run_lib.py:146] step: 125000, training_loss: 5.84272e-02
I0514 12:13:32.664333 22392998065984 run_lib.py:167] step: 125000, eval_loss: 6.76221e-02
I0514 12:13:56.546464 22392998065984 run_lib.py:146] step: 125050, training_loss: 6.35076e-02
I0514 12:14:19.827502 22392998065984 run_lib.py:146] step: 125100, training_loss: 5.78833e-02
I0514 12:14:19.983911 22392998065984 run_lib.py:167] step: 125100, eval_loss: 5.11392e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:14:43.400008 22392998065984 run_lib.py:146] step: 125150, training_loss: 5.67343e-02
I0514 12:15:07.005001 22392998065984 run_lib.py:146] step: 125200, training_loss: 5.28822e-02
I0514 12:15:07.162663 22392998065984 run_lib.py:167] step: 125200, eval_loss: 4.85482e-02
I0514 12:15:30.768894 22392998065984 run_lib.py:146] step: 125250, training_loss: 6.63263e-02
I0514 12:15:54.052118 22392998065984 run_lib.py:146] step: 125300, training_loss: 7.30501e-02
I0514 12:15:54.208724 22392998065984 run_lib.py:167] step: 125300, eval_loss: 6.05473e-02
I0514 12:16:17.805801 22392998065984 run_lib.py:146] step: 125350, training_loss: 4.44679e-02
I0514 12:16:41.382254 22392998065984 run_lib.py:146] step: 125400, training_loss: 5.65195e-02
I0514 12:16:41.538617 22392998065984 run_lib.py:167] step: 125400, eval_loss: 6.78110e-02
I0514 12:17:04.812295 22392998065984 run_lib.py:146] step: 125450, training_loss: 5.70373e-02
I0514 12:17:28.400521 22392998065984 run_lib.py:146] step: 125500, training_loss: 6.57140e-02
I0514 12:17:28.556987 22392998065984 run_lib.py:167] step: 125500, eval_loss: 4.55793e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:17:52.673042 22392998065984 run_lib.py:146] step: 125550, training_loss: 5.54229e-02
I0514 12:18:16.398676 22392998065984 run_lib.py:146] step: 125600, training_loss: 5.25908e-02
I0514 12:18:16.556658 22392998065984 run_lib.py:167] step: 125600, eval_loss: 5.78603e-02
I0514 12:18:40.295183 22392998065984 run_lib.py:146] step: 125650, training_loss: 5.72241e-02
I0514 12:19:04.642546 22392998065984 run_lib.py:146] step: 125700, training_loss: 6.64160e-02
I0514 12:19:04.798804 22392998065984 run_lib.py:167] step: 125700, eval_loss: 6.39820e-02
I0514 12:19:28.525598 22392998065984 run_lib.py:146] step: 125750, training_loss: 6.24518e-02
I0514 12:19:52.247995 22392998065984 run_lib.py:146] step: 125800, training_loss: 6.65848e-02
I0514 12:19:52.405192 22392998065984 run_lib.py:167] step: 125800, eval_loss: 5.63765e-02
I0514 12:20:16.733078 22392998065984 run_lib.py:146] step: 125850, training_loss: 5.13481e-02
I0514 12:20:40.462328 22392998065984 run_lib.py:146] step: 125900, training_loss: 6.35202e-02
I0514 12:20:40.618303 22392998065984 run_lib.py:167] step: 125900, eval_loss: 6.14454e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:21:04.057922 22392998065984 run_lib.py:146] step: 125950, training_loss: 4.05126e-02
I0514 12:21:27.991042 22392998065984 run_lib.py:146] step: 126000, training_loss: 6.02703e-02
I0514 12:21:28.148399 22392998065984 run_lib.py:167] step: 126000, eval_loss: 4.95228e-02
I0514 12:21:51.417253 22392998065984 run_lib.py:146] step: 126050, training_loss: 4.44013e-02
I0514 12:22:14.697768 22392998065984 run_lib.py:146] step: 126100, training_loss: 6.93849e-02
I0514 12:22:14.854833 22392998065984 run_lib.py:167] step: 126100, eval_loss: 8.23068e-02
I0514 12:22:38.414519 22392998065984 run_lib.py:146] step: 126150, training_loss: 5.63413e-02
I0514 12:23:01.979771 22392998065984 run_lib.py:146] step: 126200, training_loss: 5.54569e-02
I0514 12:23:02.135257 22392998065984 run_lib.py:167] step: 126200, eval_loss: 6.79968e-02
I0514 12:23:25.398252 22392998065984 run_lib.py:146] step: 126250, training_loss: 6.61207e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:23:49.058928 22392998065984 run_lib.py:146] step: 126300, training_loss: 7.33633e-02
I0514 12:23:49.160263 22392998065984 run_lib.py:167] step: 126300, eval_loss: 1.51755e-01
I0514 12:24:13.125051 22392998065984 run_lib.py:146] step: 126350, training_loss: 4.55609e-02
I0514 12:24:36.864522 22392998065984 run_lib.py:146] step: 126400, training_loss: 5.45740e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:24:37.229014 22392998065984 run_lib.py:167] step: 126400, eval_loss: 6.55536e-02
I0514 12:25:00.893930 22392998065984 run_lib.py:146] step: 126450, training_loss: 8.75644e-02
I0514 12:25:24.503944 22392998065984 run_lib.py:146] step: 126500, training_loss: 6.08087e-02
I0514 12:25:24.660635 22392998065984 run_lib.py:167] step: 126500, eval_loss: 5.83177e-02
I0514 12:25:47.940129 22392998065984 run_lib.py:146] step: 126550, training_loss: 6.55606e-02
I0514 12:26:11.224128 22392998065984 run_lib.py:146] step: 126600, training_loss: 5.41937e-02
I0514 12:26:11.380853 22392998065984 run_lib.py:167] step: 126600, eval_loss: 6.47315e-02
I0514 12:26:35.221632 22392998065984 run_lib.py:146] step: 126650, training_loss: 6.16042e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:26:58.778828 22392998065984 run_lib.py:146] step: 126700, training_loss: 5.80685e-02
I0514 12:26:58.955326 22392998065984 run_lib.py:167] step: 126700, eval_loss: 6.37308e-02
I0514 12:27:22.683353 22392998065984 run_lib.py:146] step: 126750, training_loss: 6.18423e-02
I0514 12:27:47.085200 22392998065984 run_lib.py:146] step: 126800, training_loss: 5.14661e-02
I0514 12:27:47.241615 22392998065984 run_lib.py:167] step: 126800, eval_loss: 5.66713e-02
I0514 12:28:10.979443 22392998065984 run_lib.py:146] step: 126850, training_loss: 6.28413e-02
I0514 12:28:34.708547 22392998065984 run_lib.py:146] step: 126900, training_loss: 5.65983e-02
I0514 12:28:34.865125 22392998065984 run_lib.py:167] step: 126900, eval_loss: 4.93447e-02
I0514 12:28:58.908256 22392998065984 run_lib.py:146] step: 126950, training_loss: 5.92317e-02
I0514 12:29:22.953831 22392998065984 run_lib.py:146] step: 127000, training_loss: 5.14630e-02
I0514 12:29:23.110874 22392998065984 run_lib.py:167] step: 127000, eval_loss: 5.99799e-02
I0514 12:29:46.849397 22392998065984 run_lib.py:146] step: 127050, training_loss: 8.07383e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:30:10.790310 22392998065984 run_lib.py:146] step: 127100, training_loss: 6.80047e-02
I0514 12:30:10.948375 22392998065984 run_lib.py:167] step: 127100, eval_loss: 6.57333e-02
I0514 12:30:34.546397 22392998065984 run_lib.py:146] step: 127150, training_loss: 6.06472e-02
I0514 12:30:57.807903 22392998065984 run_lib.py:146] step: 127200, training_loss: 7.59032e-02
I0514 12:30:57.964211 22392998065984 run_lib.py:167] step: 127200, eval_loss: 7.37113e-02
I0514 12:31:21.522232 22392998065984 run_lib.py:146] step: 127250, training_loss: 4.34294e-02
I0514 12:31:45.061420 22392998065984 run_lib.py:146] step: 127300, training_loss: 7.15304e-02
I0514 12:31:45.217935 22392998065984 run_lib.py:167] step: 127300, eval_loss: 4.64023e-02
I0514 12:32:08.494731 22392998065984 run_lib.py:146] step: 127350, training_loss: 6.74435e-02
I0514 12:32:31.771986 22392998065984 run_lib.py:146] step: 127400, training_loss: 5.57885e-02
I0514 12:32:31.928066 22392998065984 run_lib.py:167] step: 127400, eval_loss: 6.60684e-02
I0514 12:32:55.777147 22392998065984 run_lib.py:146] step: 127450, training_loss: 6.28949e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:33:19.192922 22392998065984 run_lib.py:146] step: 127500, training_loss: 5.47277e-02
I0514 12:33:19.350781 22392998065984 run_lib.py:167] step: 127500, eval_loss: 5.95926e-02
I0514 12:33:42.609143 22392998065984 run_lib.py:146] step: 127550, training_loss: 5.47101e-02
I0514 12:34:06.560604 22392998065984 run_lib.py:146] step: 127600, training_loss: 5.26012e-02
I0514 12:34:06.717044 22392998065984 run_lib.py:167] step: 127600, eval_loss: 6.21780e-02
I0514 12:34:29.964501 22392998065984 run_lib.py:146] step: 127650, training_loss: 6.00017e-02
I0514 12:34:53.215048 22392998065984 run_lib.py:146] step: 127700, training_loss: 4.76084e-02
I0514 12:34:53.371291 22392998065984 run_lib.py:167] step: 127700, eval_loss: 7.13843e-02
I0514 12:35:16.915854 22392998065984 run_lib.py:146] step: 127750, training_loss: 7.67491e-02
I0514 12:35:40.465691 22392998065984 run_lib.py:146] step: 127800, training_loss: 4.15505e-02
I0514 12:35:40.621960 22392998065984 run_lib.py:167] step: 127800, eval_loss: 6.30212e-02
I0514 12:36:03.882153 22392998065984 run_lib.py:146] step: 127850, training_loss: 5.51525e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:36:27.629545 22392998065984 run_lib.py:146] step: 127900, training_loss: 5.60379e-02
I0514 12:36:27.787154 22392998065984 run_lib.py:167] step: 127900, eval_loss: 8.36803e-02
I0514 12:36:51.388903 22392998065984 run_lib.py:146] step: 127950, training_loss: 6.78896e-02
I0514 12:37:14.666155 22392998065984 run_lib.py:146] step: 128000, training_loss: 7.39617e-02
I0514 12:37:14.822844 22392998065984 run_lib.py:167] step: 128000, eval_loss: 5.73454e-02
I0514 12:37:38.512670 22392998065984 run_lib.py:146] step: 128050, training_loss: 5.62030e-02
I0514 12:38:02.397086 22392998065984 run_lib.py:146] step: 128100, training_loss: 7.65159e-02
I0514 12:38:02.553969 22392998065984 run_lib.py:167] step: 128100, eval_loss: 4.45362e-02
I0514 12:38:25.820887 22392998065984 run_lib.py:146] step: 128150, training_loss: 5.26720e-02
I0514 12:38:49.307863 22392998065984 run_lib.py:146] step: 128200, training_loss: 6.73490e-02
I0514 12:38:49.465184 22392998065984 run_lib.py:167] step: 128200, eval_loss: 6.70697e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:39:13.943238 22392998065984 run_lib.py:146] step: 128250, training_loss: 6.22936e-02
I0514 12:39:37.675096 22392998065984 run_lib.py:146] step: 128300, training_loss: 4.91116e-02
I0514 12:39:37.832736 22392998065984 run_lib.py:167] step: 128300, eval_loss: 6.27378e-02
I0514 12:40:01.584615 22392998065984 run_lib.py:146] step: 128350, training_loss: 4.65952e-02
I0514 12:40:25.748266 22392998065984 run_lib.py:146] step: 128400, training_loss: 4.45698e-02
I0514 12:40:25.904701 22392998065984 run_lib.py:167] step: 128400, eval_loss: 5.50146e-02
I0514 12:40:49.156122 22392998065984 run_lib.py:146] step: 128450, training_loss: 4.09879e-02
I0514 12:41:12.408532 22392998065984 run_lib.py:146] step: 128500, training_loss: 5.15873e-02
I0514 12:41:12.581067 22392998065984 run_lib.py:167] step: 128500, eval_loss: 8.18362e-02
I0514 12:41:36.128793 22392998065984 run_lib.py:146] step: 128550, training_loss: 6.60459e-02
I0514 12:41:59.693685 22392998065984 run_lib.py:146] step: 128600, training_loss: 6.03327e-02
I0514 12:41:59.849741 22392998065984 run_lib.py:167] step: 128600, eval_loss: 5.41640e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:42:23.429736 22392998065984 run_lib.py:146] step: 128650, training_loss: 6.41692e-02
I0514 12:42:47.498742 22392998065984 run_lib.py:146] step: 128700, training_loss: 9.33653e-02
I0514 12:42:47.656697 22392998065984 run_lib.py:167] step: 128700, eval_loss: 5.95395e-02
I0514 12:43:11.738168 22392998065984 run_lib.py:146] step: 128750, training_loss: 5.70734e-02
I0514 12:43:35.466471 22392998065984 run_lib.py:146] step: 128800, training_loss: 7.21131e-02
I0514 12:43:35.622929 22392998065984 run_lib.py:167] step: 128800, eval_loss: 7.61216e-02
I0514 12:43:59.633857 22392998065984 run_lib.py:146] step: 128850, training_loss: 3.83968e-02
I0514 12:44:23.251215 22392998065984 run_lib.py:146] step: 128900, training_loss: 7.08273e-02
I0514 12:44:23.407847 22392998065984 run_lib.py:167] step: 128900, eval_loss: 8.38733e-02
I0514 12:44:46.641878 22392998065984 run_lib.py:146] step: 128950, training_loss: 6.73956e-02
I0514 12:45:09.895654 22392998065984 run_lib.py:146] step: 129000, training_loss: 6.66123e-02
I0514 12:45:10.051661 22392998065984 run_lib.py:167] step: 129000, eval_loss: 6.55756e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:45:34.094307 22392998065984 run_lib.py:146] step: 129050, training_loss: 5.33281e-02
I0514 12:45:57.374615 22392998065984 run_lib.py:146] step: 129100, training_loss: 6.41228e-02
I0514 12:45:57.532061 22392998065984 run_lib.py:167] step: 129100, eval_loss: 4.66893e-02
I0514 12:46:20.800815 22392998065984 run_lib.py:146] step: 129150, training_loss: 5.13155e-02
I0514 12:46:44.692139 22392998065984 run_lib.py:146] step: 129200, training_loss: 5.57642e-02
I0514 12:46:44.848678 22392998065984 run_lib.py:167] step: 129200, eval_loss: 5.36430e-02
I0514 12:47:08.100336 22392998065984 run_lib.py:146] step: 129250, training_loss: 6.26999e-02
I0514 12:47:31.360696 22392998065984 run_lib.py:146] step: 129300, training_loss: 7.58602e-02
I0514 12:47:31.517641 22392998065984 run_lib.py:167] step: 129300, eval_loss: 8.20975e-02
I0514 12:47:55.070473 22392998065984 run_lib.py:146] step: 129350, training_loss: 7.19059e-02
I0514 12:48:18.632506 22392998065984 run_lib.py:146] step: 129400, training_loss: 6.18566e-02
I0514 12:48:18.788864 22392998065984 run_lib.py:167] step: 129400, eval_loss: 4.73431e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:48:42.208168 22392998065984 run_lib.py:146] step: 129450, training_loss: 6.40057e-02
I0514 12:49:05.834638 22392998065984 run_lib.py:146] step: 129500, training_loss: 8.38930e-02
I0514 12:49:05.992429 22392998065984 run_lib.py:167] step: 129500, eval_loss: 7.63042e-02
I0514 12:49:29.584997 22392998065984 run_lib.py:146] step: 129550, training_loss: 4.52064e-02
I0514 12:49:52.843595 22392998065984 run_lib.py:146] step: 129600, training_loss: 6.60293e-02
I0514 12:49:53.000062 22392998065984 run_lib.py:167] step: 129600, eval_loss: 4.65028e-02
I0514 12:50:16.563750 22392998065984 run_lib.py:146] step: 129650, training_loss: 5.07062e-02
I0514 12:50:40.105156 22392998065984 run_lib.py:146] step: 129700, training_loss: 6.60747e-02
I0514 12:50:40.261244 22392998065984 run_lib.py:167] step: 129700, eval_loss: 5.55627e-02
I0514 12:51:03.527488 22392998065984 run_lib.py:146] step: 129750, training_loss: 4.95139e-02
I0514 12:51:26.793833 22392998065984 run_lib.py:146] step: 129800, training_loss: 5.53517e-02
I0514 12:51:26.950442 22392998065984 run_lib.py:167] step: 129800, eval_loss: 6.85532e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:51:50.969239 22392998065984 run_lib.py:146] step: 129850, training_loss: 5.62941e-02
I0514 12:52:14.304845 22392998065984 run_lib.py:146] step: 129900, training_loss: 6.56703e-02
I0514 12:52:14.462444 22392998065984 run_lib.py:167] step: 129900, eval_loss: 4.56993e-02
I0514 12:52:37.866462 22392998065984 run_lib.py:146] step: 129950, training_loss: 6.67434e-02
I0514 12:53:02.207175 22392998065984 run_lib.py:146] step: 130000, training_loss: 4.71567e-02
I0514 12:53:08.253329 22392998065984 run_lib.py:167] step: 130000, eval_loss: 5.97205e-02
I0514 12:53:37.409842 22392998065984 run_lib.py:146] step: 130050, training_loss: 5.39136e-02
I0514 12:54:00.953263 22392998065984 run_lib.py:146] step: 130100, training_loss: 4.43980e-02
I0514 12:54:01.164393 22392998065984 run_lib.py:167] step: 130100, eval_loss: 5.66106e-02
I0514 12:54:24.407008 22392998065984 run_lib.py:146] step: 130150, training_loss: 7.04137e-02
I0514 12:54:47.946050 22392998065984 run_lib.py:146] step: 130200, training_loss: 6.90859e-02
I0514 12:54:48.102417 22392998065984 run_lib.py:167] step: 130200, eval_loss: 6.44564e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:55:11.847710 22392998065984 run_lib.py:146] step: 130250, training_loss: 6.24813e-02
I0514 12:55:35.120927 22392998065984 run_lib.py:146] step: 130300, training_loss: 5.90815e-02
I0514 12:55:35.278066 22392998065984 run_lib.py:167] step: 130300, eval_loss: 5.16081e-02
I0514 12:55:58.856984 22392998065984 run_lib.py:146] step: 130350, training_loss: 5.72531e-02
I0514 12:56:22.411156 22392998065984 run_lib.py:146] step: 130400, training_loss: 6.14169e-02
I0514 12:56:22.567805 22392998065984 run_lib.py:167] step: 130400, eval_loss: 5.80265e-02
I0514 12:56:45.996519 22392998065984 run_lib.py:146] step: 130450, training_loss: 9.06128e-02
I0514 12:57:09.577784 22392998065984 run_lib.py:146] step: 130500, training_loss: 5.26948e-02
I0514 12:57:09.734556 22392998065984 run_lib.py:167] step: 130500, eval_loss: 6.03299e-02
I0514 12:57:33.474823 22392998065984 run_lib.py:146] step: 130550, training_loss: 6.52803e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 12:57:57.590304 22392998065984 run_lib.py:146] step: 130600, training_loss: 5.59430e-02
I0514 12:57:57.748152 22392998065984 run_lib.py:167] step: 130600, eval_loss: 7.81826e-02
I0514 12:58:21.359556 22392998065984 run_lib.py:146] step: 130650, training_loss: 5.71582e-02
I0514 12:58:44.642762 22392998065984 run_lib.py:146] step: 130700, training_loss: 6.61281e-02
I0514 12:58:44.799359 22392998065984 run_lib.py:167] step: 130700, eval_loss: 6.60222e-02
I0514 12:59:08.423215 22392998065984 run_lib.py:146] step: 130750, training_loss: 5.09022e-02
I0514 12:59:32.324847 22392998065984 run_lib.py:146] step: 130800, training_loss: 5.56070e-02
I0514 12:59:32.481468 22392998065984 run_lib.py:167] step: 130800, eval_loss: 6.65564e-02
I0514 12:59:56.676372 22392998065984 run_lib.py:146] step: 130850, training_loss: 7.23718e-02
I0514 13:00:20.837677 22392998065984 run_lib.py:146] step: 130900, training_loss: 7.10244e-02
I0514 13:00:20.994451 22392998065984 run_lib.py:167] step: 130900, eval_loss: 6.58715e-02
I0514 13:00:44.879742 22392998065984 run_lib.py:146] step: 130950, training_loss: 4.86342e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:01:09.066122 22392998065984 run_lib.py:146] step: 131000, training_loss: 5.02485e-02
I0514 13:01:09.224249 22392998065984 run_lib.py:167] step: 131000, eval_loss: 6.52855e-02
I0514 13:01:32.829401 22392998065984 run_lib.py:146] step: 131050, training_loss: 4.86213e-02
I0514 13:01:56.286968 22392998065984 run_lib.py:146] step: 131100, training_loss: 7.55362e-02
I0514 13:01:56.445060 22392998065984 run_lib.py:167] step: 131100, eval_loss: 5.32570e-02
I0514 13:02:20.077524 22392998065984 run_lib.py:146] step: 131150, training_loss: 6.00646e-02
I0514 13:02:43.681807 22392998065984 run_lib.py:146] step: 131200, training_loss: 5.95212e-02
I0514 13:02:43.838042 22392998065984 run_lib.py:167] step: 131200, eval_loss: 7.53912e-02
I0514 13:03:07.165420 22392998065984 run_lib.py:146] step: 131250, training_loss: 5.51547e-02
I0514 13:03:30.753416 22392998065984 run_lib.py:146] step: 131300, training_loss: 7.64908e-02
I0514 13:03:30.909993 22392998065984 run_lib.py:167] step: 131300, eval_loss: 4.60537e-02
I0514 13:03:54.487471 22392998065984 run_lib.py:146] step: 131350, training_loss: 6.02265e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:04:17.879589 22392998065984 run_lib.py:146] step: 131400, training_loss: 5.31116e-02
I0514 13:04:18.037388 22392998065984 run_lib.py:167] step: 131400, eval_loss: 8.81963e-02
I0514 13:04:41.622148 22392998065984 run_lib.py:146] step: 131450, training_loss: 7.65800e-02
I0514 13:05:04.890639 22392998065984 run_lib.py:146] step: 131500, training_loss: 6.42051e-02
I0514 13:05:05.046952 22392998065984 run_lib.py:167] step: 131500, eval_loss: 5.67541e-02
I0514 13:05:28.640384 22392998065984 run_lib.py:146] step: 131550, training_loss: 5.60655e-02
I0514 13:05:51.901326 22392998065984 run_lib.py:146] step: 131600, training_loss: 5.08843e-02
I0514 13:05:52.058530 22392998065984 run_lib.py:167] step: 131600, eval_loss: 9.22164e-02
I0514 13:06:15.609455 22392998065984 run_lib.py:146] step: 131650, training_loss: 5.40303e-02
I0514 13:06:39.161806 22392998065984 run_lib.py:146] step: 131700, training_loss: 6.51259e-02
I0514 13:06:39.331614 22392998065984 run_lib.py:167] step: 131700, eval_loss: 8.56652e-02
I0514 13:07:02.595344 22392998065984 run_lib.py:146] step: 131750, training_loss: 5.51749e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:07:26.762096 22392998065984 run_lib.py:146] step: 131800, training_loss: 4.99214e-02
I0514 13:07:26.992306 22392998065984 run_lib.py:167] step: 131800, eval_loss: 4.57598e-02
I0514 13:07:51.167503 22392998065984 run_lib.py:146] step: 131850, training_loss: 5.96385e-02
I0514 13:08:15.059427 22392998065984 run_lib.py:146] step: 131900, training_loss: 6.40079e-02
I0514 13:08:15.266320 22392998065984 run_lib.py:167] step: 131900, eval_loss: 5.36771e-02
I0514 13:08:39.472629 22392998065984 run_lib.py:146] step: 131950, training_loss: 7.08409e-02
I0514 13:09:03.182039 22392998065984 run_lib.py:146] step: 132000, training_loss: 5.58454e-02
I0514 13:09:03.366976 22392998065984 run_lib.py:167] step: 132000, eval_loss: 8.05001e-02
I0514 13:09:26.600469 22392998065984 run_lib.py:146] step: 132050, training_loss: 5.84921e-02
I0514 13:09:50.161467 22392998065984 run_lib.py:146] step: 132100, training_loss: 6.06363e-02
I0514 13:09:50.318305 22392998065984 run_lib.py:167] step: 132100, eval_loss: 4.97414e-02
I0514 13:10:13.866369 22392998065984 run_lib.py:146] step: 132150, training_loss: 7.64847e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:10:37.776171 22392998065984 run_lib.py:146] step: 132200, training_loss: 6.86750e-02
I0514 13:10:37.934176 22392998065984 run_lib.py:167] step: 132200, eval_loss: 5.57585e-02
I0514 13:11:02.168160 22392998065984 run_lib.py:146] step: 132250, training_loss: 6.79645e-02
I0514 13:11:26.042881 22392998065984 run_lib.py:146] step: 132300, training_loss: 6.52703e-02
I0514 13:11:26.198965 22392998065984 run_lib.py:167] step: 132300, eval_loss: 4.86430e-02
I0514 13:11:50.387762 22392998065984 run_lib.py:146] step: 132350, training_loss: 7.07311e-02
I0514 13:12:14.040672 22392998065984 run_lib.py:146] step: 132400, training_loss: 6.21375e-02
I0514 13:12:14.279995 22392998065984 run_lib.py:167] step: 132400, eval_loss: 4.85517e-02
I0514 13:12:37.872174 22392998065984 run_lib.py:146] step: 132450, training_loss: 6.91988e-02
I0514 13:13:01.449182 22392998065984 run_lib.py:146] step: 132500, training_loss: 5.09602e-02
I0514 13:13:01.605716 22392998065984 run_lib.py:167] step: 132500, eval_loss: 7.36909e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:13:25.040446 22392998065984 run_lib.py:146] step: 132550, training_loss: 5.13380e-02
I0514 13:13:49.279662 22392998065984 run_lib.py:146] step: 132600, training_loss: 5.64917e-02
I0514 13:13:49.437844 22392998065984 run_lib.py:167] step: 132600, eval_loss: 5.70463e-02
I0514 13:14:13.217640 22392998065984 run_lib.py:146] step: 132650, training_loss: 5.98705e-02
I0514 13:14:36.514539 22392998065984 run_lib.py:146] step: 132700, training_loss: 5.95970e-02
I0514 13:14:36.671317 22392998065984 run_lib.py:167] step: 132700, eval_loss: 6.70044e-02
I0514 13:15:00.256605 22392998065984 run_lib.py:146] step: 132750, training_loss: 6.05200e-02
I0514 13:15:23.817059 22392998065984 run_lib.py:146] step: 132800, training_loss: 5.62709e-02
I0514 13:15:23.973337 22392998065984 run_lib.py:167] step: 132800, eval_loss: 5.21226e-02
I0514 13:15:47.245973 22392998065984 run_lib.py:146] step: 132850, training_loss: 6.95068e-02
I0514 13:16:10.839766 22392998065984 run_lib.py:146] step: 132900, training_loss: 5.30638e-02
I0514 13:16:10.996331 22392998065984 run_lib.py:167] step: 132900, eval_loss: 4.38520e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:16:34.811526 22392998065984 run_lib.py:146] step: 132950, training_loss: 6.67777e-02
I0514 13:16:58.694187 22392998065984 run_lib.py:146] step: 133000, training_loss: 7.37908e-02
I0514 13:16:58.887839 22392998065984 run_lib.py:167] step: 133000, eval_loss: 6.22264e-02
I0514 13:17:22.698157 22392998065984 run_lib.py:146] step: 133050, training_loss: 6.24170e-02
I0514 13:17:45.961318 22392998065984 run_lib.py:146] step: 133100, training_loss: 5.20546e-02
I0514 13:17:46.118012 22392998065984 run_lib.py:167] step: 133100, eval_loss: 6.76435e-02
I0514 13:18:09.712907 22392998065984 run_lib.py:146] step: 133150, training_loss: 4.99738e-02
I0514 13:18:32.971437 22392998065984 run_lib.py:146] step: 133200, training_loss: 7.92216e-02
I0514 13:18:33.127548 22392998065984 run_lib.py:167] step: 133200, eval_loss: 5.02064e-02
I0514 13:18:56.720359 22392998065984 run_lib.py:146] step: 133250, training_loss: 6.11596e-02
I0514 13:19:20.296728 22392998065984 run_lib.py:146] step: 133300, training_loss: 4.93060e-02
I0514 13:19:20.473329 22392998065984 run_lib.py:167] step: 133300, eval_loss: 4.68918e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:19:43.928699 22392998065984 run_lib.py:146] step: 133350, training_loss: 4.64865e-02
I0514 13:20:07.559151 22392998065984 run_lib.py:146] step: 133400, training_loss: 5.76939e-02
I0514 13:20:07.716694 22392998065984 run_lib.py:167] step: 133400, eval_loss: 5.76763e-02
I0514 13:20:31.311656 22392998065984 run_lib.py:146] step: 133450, training_loss: 4.74401e-02
I0514 13:20:54.594043 22392998065984 run_lib.py:146] step: 133500, training_loss: 8.31643e-02
I0514 13:20:54.751035 22392998065984 run_lib.py:167] step: 133500, eval_loss: 5.51854e-02
I0514 13:21:18.325031 22392998065984 run_lib.py:146] step: 133550, training_loss: 7.44841e-02
I0514 13:21:41.952301 22392998065984 run_lib.py:146] step: 133600, training_loss: 4.64626e-02
I0514 13:21:42.109795 22392998065984 run_lib.py:167] step: 133600, eval_loss: 4.95005e-02
I0514 13:22:05.375890 22392998065984 run_lib.py:146] step: 133650, training_loss: 6.34993e-02
I0514 13:22:28.953676 22392998065984 run_lib.py:146] step: 133700, training_loss: 6.64851e-02
I0514 13:22:29.109922 22392998065984 run_lib.py:167] step: 133700, eval_loss: 7.54550e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:22:52.871542 22392998065984 run_lib.py:146] step: 133750, training_loss: 6.86788e-02
I0514 13:23:16.351254 22392998065984 run_lib.py:146] step: 133800, training_loss: 6.39055e-02
I0514 13:23:16.508818 22392998065984 run_lib.py:167] step: 133800, eval_loss: 7.17815e-02
I0514 13:23:40.715626 22392998065984 run_lib.py:146] step: 133850, training_loss: 4.51178e-02
I0514 13:24:04.593586 22392998065984 run_lib.py:146] step: 133900, training_loss: 5.13788e-02
I0514 13:24:04.750233 22392998065984 run_lib.py:167] step: 133900, eval_loss: 4.77496e-02
I0514 13:24:28.923013 22392998065984 run_lib.py:146] step: 133950, training_loss: 5.25127e-02
I0514 13:24:53.097140 22392998065984 run_lib.py:146] step: 134000, training_loss: 5.29285e-02
I0514 13:24:53.253406 22392998065984 run_lib.py:167] step: 134000, eval_loss: 5.62920e-02
I0514 13:25:17.145266 22392998065984 run_lib.py:146] step: 134050, training_loss: 5.99687e-02
I0514 13:25:41.400043 22392998065984 run_lib.py:146] step: 134100, training_loss: 6.42511e-02
I0514 13:25:41.555678 22392998065984 run_lib.py:167] step: 134100, eval_loss: 5.42355e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:26:05.145333 22392998065984 run_lib.py:146] step: 134150, training_loss: 6.36192e-02
I0514 13:26:28.768638 22392998065984 run_lib.py:146] step: 134200, training_loss: 4.43220e-02
I0514 13:26:28.850313 22392998065984 run_lib.py:167] step: 134200, eval_loss: 4.31226e-02
I0514 13:26:52.455225 22392998065984 run_lib.py:146] step: 134250, training_loss: 5.69158e-02
I0514 13:27:15.810309 22392998065984 run_lib.py:146] step: 134300, training_loss: 6.43178e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:27:16.196361 22392998065984 run_lib.py:167] step: 134300, eval_loss: 5.97413e-02
I0514 13:27:39.828677 22392998065984 run_lib.py:146] step: 134350, training_loss: 5.21585e-02
I0514 13:28:03.429271 22392998065984 run_lib.py:146] step: 134400, training_loss: 5.71709e-02
I0514 13:28:03.876592 22392998065984 run_lib.py:167] step: 134400, eval_loss: 6.68785e-02
I0514 13:28:27.146210 22392998065984 run_lib.py:146] step: 134450, training_loss: 6.44421e-02
I0514 13:28:50.725431 22392998065984 run_lib.py:146] step: 134500, training_loss: 5.61423e-02
I0514 13:28:51.011759 22392998065984 run_lib.py:167] step: 134500, eval_loss: 5.47892e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:29:15.280898 22392998065984 run_lib.py:146] step: 134550, training_loss: 5.89304e-02
I0514 13:29:38.814094 22392998065984 run_lib.py:146] step: 134600, training_loss: 7.46508e-02
I0514 13:29:39.040890 22392998065984 run_lib.py:167] step: 134600, eval_loss: 6.25784e-02
I0514 13:30:02.638330 22392998065984 run_lib.py:146] step: 134650, training_loss: 5.85476e-02
I0514 13:30:25.896366 22392998065984 run_lib.py:146] step: 134700, training_loss: 4.69034e-02
I0514 13:30:26.350871 22392998065984 run_lib.py:167] step: 134700, eval_loss: 5.38497e-02
I0514 13:30:49.613561 22392998065984 run_lib.py:146] step: 134750, training_loss: 5.10436e-02
I0514 13:31:13.196331 22392998065984 run_lib.py:146] step: 134800, training_loss: 6.73532e-02
I0514 13:31:13.381465 22392998065984 run_lib.py:167] step: 134800, eval_loss: 6.13582e-02
I0514 13:31:36.630564 22392998065984 run_lib.py:146] step: 134850, training_loss: 6.19235e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:32:00.401144 22392998065984 run_lib.py:146] step: 134900, training_loss: 8.15697e-02
I0514 13:32:00.592125 22392998065984 run_lib.py:167] step: 134900, eval_loss: 6.58701e-02
I0514 13:32:24.448784 22392998065984 run_lib.py:146] step: 134950, training_loss: 5.93489e-02
I0514 13:32:48.661424 22392998065984 run_lib.py:146] step: 135000, training_loss: 6.09646e-02
I0514 13:32:48.817974 22392998065984 run_lib.py:167] step: 135000, eval_loss: 4.84702e-02
I0514 13:33:12.478200 22392998065984 run_lib.py:146] step: 135050, training_loss: 6.18553e-02
I0514 13:33:35.879678 22392998065984 run_lib.py:146] step: 135100, training_loss: 6.60307e-02
I0514 13:33:36.036648 22392998065984 run_lib.py:167] step: 135100, eval_loss: 8.03635e-02
I0514 13:33:59.629134 22392998065984 run_lib.py:146] step: 135150, training_loss: 5.29812e-02
I0514 13:34:23.271472 22392998065984 run_lib.py:146] step: 135200, training_loss: 6.11770e-02
I0514 13:34:23.428139 22392998065984 run_lib.py:167] step: 135200, eval_loss: 6.97723e-02
I0514 13:34:46.677096 22392998065984 run_lib.py:146] step: 135250, training_loss: 7.72223e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:35:10.657439 22392998065984 run_lib.py:146] step: 135300, training_loss: 7.18799e-02
I0514 13:35:10.815353 22392998065984 run_lib.py:167] step: 135300, eval_loss: 6.89202e-02
I0514 13:35:35.046712 22392998065984 run_lib.py:146] step: 135350, training_loss: 7.84819e-02
I0514 13:35:59.022790 22392998065984 run_lib.py:146] step: 135400, training_loss: 7.38200e-02
I0514 13:35:59.179177 22392998065984 run_lib.py:167] step: 135400, eval_loss: 6.03548e-02
I0514 13:36:23.425863 22392998065984 run_lib.py:146] step: 135450, training_loss: 4.71301e-02
I0514 13:36:47.569546 22392998065984 run_lib.py:146] step: 135500, training_loss: 7.39286e-02
I0514 13:36:47.847318 22392998065984 run_lib.py:167] step: 135500, eval_loss: 6.60708e-02
I0514 13:37:11.707772 22392998065984 run_lib.py:146] step: 135550, training_loss: 6.39610e-02
I0514 13:37:35.927492 22392998065984 run_lib.py:146] step: 135600, training_loss: 6.99794e-02
I0514 13:37:36.156464 22392998065984 run_lib.py:167] step: 135600, eval_loss: 5.10496e-02
I0514 13:38:00.015454 22392998065984 run_lib.py:146] step: 135650, training_loss: 5.68383e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:38:24.066056 22392998065984 run_lib.py:146] step: 135700, training_loss: 5.69450e-02
I0514 13:38:24.258943 22392998065984 run_lib.py:167] step: 135700, eval_loss: 5.31417e-02
I0514 13:38:47.864393 22392998065984 run_lib.py:146] step: 135750, training_loss: 5.96447e-02
I0514 13:39:11.124428 22392998065984 run_lib.py:146] step: 135800, training_loss: 4.76622e-02
I0514 13:39:11.280983 22392998065984 run_lib.py:167] step: 135800, eval_loss: 5.04214e-02
I0514 13:39:34.881050 22392998065984 run_lib.py:146] step: 135850, training_loss: 5.77715e-02
I0514 13:39:58.173116 22392998065984 run_lib.py:146] step: 135900, training_loss: 6.74572e-02
I0514 13:39:58.329663 22392998065984 run_lib.py:167] step: 135900, eval_loss: 5.70581e-02
I0514 13:40:21.909490 22392998065984 run_lib.py:146] step: 135950, training_loss: 5.68609e-02
I0514 13:40:45.494498 22392998065984 run_lib.py:146] step: 136000, training_loss: 6.60243e-02
I0514 13:40:45.650813 22392998065984 run_lib.py:167] step: 136000, eval_loss: 5.21673e-02
I0514 13:41:08.939290 22392998065984 run_lib.py:146] step: 136050, training_loss: 6.19550e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:41:32.655436 22392998065984 run_lib.py:146] step: 136100, training_loss: 5.12571e-02
I0514 13:41:32.814352 22392998065984 run_lib.py:167] step: 136100, eval_loss: 8.19922e-02
I0514 13:41:56.416046 22392998065984 run_lib.py:146] step: 136150, training_loss: 7.35172e-02
I0514 13:42:19.695151 22392998065984 run_lib.py:146] step: 136200, training_loss: 6.77782e-02
I0514 13:42:19.851481 22392998065984 run_lib.py:167] step: 136200, eval_loss: 5.97535e-02
I0514 13:42:43.432058 22392998065984 run_lib.py:146] step: 136250, training_loss: 6.57778e-02
I0514 13:43:06.961836 22392998065984 run_lib.py:146] step: 136300, training_loss: 6.79913e-02
I0514 13:43:07.118287 22392998065984 run_lib.py:167] step: 136300, eval_loss: 4.77750e-02
I0514 13:43:30.387581 22392998065984 run_lib.py:146] step: 136350, training_loss: 7.38106e-02
I0514 13:43:53.969714 22392998065984 run_lib.py:146] step: 136400, training_loss: 5.32752e-02
I0514 13:43:54.126473 22392998065984 run_lib.py:167] step: 136400, eval_loss: 4.90942e-02
I0514 13:44:17.422185 22392998065984 run_lib.py:146] step: 136450, training_loss: 6.75147e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:44:41.192122 22392998065984 run_lib.py:146] step: 136500, training_loss: 6.47996e-02
I0514 13:44:41.350049 22392998065984 run_lib.py:167] step: 136500, eval_loss: 6.66019e-02
I0514 13:45:04.944069 22392998065984 run_lib.py:146] step: 136550, training_loss: 5.25373e-02
I0514 13:45:28.210788 22392998065984 run_lib.py:146] step: 136600, training_loss: 6.71125e-02
I0514 13:45:28.366950 22392998065984 run_lib.py:167] step: 136600, eval_loss: 5.27369e-02
I0514 13:45:51.922413 22392998065984 run_lib.py:146] step: 136650, training_loss: 7.23861e-02
I0514 13:46:15.196229 22392998065984 run_lib.py:146] step: 136700, training_loss: 7.15375e-02
I0514 13:46:15.352670 22392998065984 run_lib.py:167] step: 136700, eval_loss: 5.57583e-02
I0514 13:46:38.903599 22392998065984 run_lib.py:146] step: 136750, training_loss: 5.58227e-02
I0514 13:47:02.475115 22392998065984 run_lib.py:146] step: 136800, training_loss: 6.00000e-02
I0514 13:47:02.631566 22392998065984 run_lib.py:167] step: 136800, eval_loss: 5.28145e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:47:26.041380 22392998065984 run_lib.py:146] step: 136850, training_loss: 5.48793e-02
I0514 13:47:50.455393 22392998065984 run_lib.py:146] step: 136900, training_loss: 8.04723e-02
I0514 13:47:50.612863 22392998065984 run_lib.py:167] step: 136900, eval_loss: 7.74985e-02
I0514 13:48:14.815066 22392998065984 run_lib.py:146] step: 136950, training_loss: 7.85384e-02
I0514 13:48:38.763859 22392998065984 run_lib.py:146] step: 137000, training_loss: 5.17275e-02
I0514 13:48:38.920655 22392998065984 run_lib.py:167] step: 137000, eval_loss: 7.01366e-02
I0514 13:49:03.148023 22392998065984 run_lib.py:146] step: 137050, training_loss: 6.79530e-02
I0514 13:49:27.242157 22392998065984 run_lib.py:146] step: 137100, training_loss: 5.84549e-02
I0514 13:49:27.398707 22392998065984 run_lib.py:167] step: 137100, eval_loss: 5.83369e-02
I0514 13:49:50.712615 22392998065984 run_lib.py:146] step: 137150, training_loss: 6.82840e-02
I0514 13:50:14.322076 22392998065984 run_lib.py:146] step: 137200, training_loss: 5.69086e-02
I0514 13:50:14.478529 22392998065984 run_lib.py:167] step: 137200, eval_loss: 5.82066e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:50:37.908435 22392998065984 run_lib.py:146] step: 137250, training_loss: 6.45629e-02
I0514 13:51:01.567484 22392998065984 run_lib.py:146] step: 137300, training_loss: 8.36481e-02
I0514 13:51:01.725425 22392998065984 run_lib.py:167] step: 137300, eval_loss: 6.89057e-02
I0514 13:51:25.355057 22392998065984 run_lib.py:146] step: 137350, training_loss: 5.63075e-02
I0514 13:51:48.613405 22392998065984 run_lib.py:146] step: 137400, training_loss: 6.74330e-02
I0514 13:51:48.769738 22392998065984 run_lib.py:167] step: 137400, eval_loss: 8.87563e-02
I0514 13:52:12.462398 22392998065984 run_lib.py:146] step: 137450, training_loss: 5.17353e-02
I0514 13:52:36.361753 22392998065984 run_lib.py:146] step: 137500, training_loss: 4.29926e-02
I0514 13:52:36.518431 22392998065984 run_lib.py:167] step: 137500, eval_loss: 4.77143e-02
I0514 13:53:00.716232 22392998065984 run_lib.py:146] step: 137550, training_loss: 4.79922e-02
I0514 13:53:24.963519 22392998065984 run_lib.py:146] step: 137600, training_loss: 5.71930e-02
I0514 13:53:25.119768 22392998065984 run_lib.py:167] step: 137600, eval_loss: 5.90876e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:53:48.963941 22392998065984 run_lib.py:146] step: 137650, training_loss: 6.80549e-02
I0514 13:54:12.624170 22392998065984 run_lib.py:146] step: 137700, training_loss: 5.36594e-02
I0514 13:54:12.782198 22392998065984 run_lib.py:167] step: 137700, eval_loss: 6.59985e-02
I0514 13:54:36.399961 22392998065984 run_lib.py:146] step: 137750, training_loss: 5.85622e-02
I0514 13:54:59.693256 22392998065984 run_lib.py:146] step: 137800, training_loss: 5.90088e-02
I0514 13:54:59.849960 22392998065984 run_lib.py:167] step: 137800, eval_loss: 6.25445e-02
I0514 13:55:23.429484 22392998065984 run_lib.py:146] step: 137850, training_loss: 5.22271e-02
I0514 13:55:47.088831 22392998065984 run_lib.py:146] step: 137900, training_loss: 9.74741e-02
I0514 13:55:47.245624 22392998065984 run_lib.py:167] step: 137900, eval_loss: 5.90557e-02
I0514 13:56:10.628731 22392998065984 run_lib.py:146] step: 137950, training_loss: 6.18949e-02
I0514 13:56:34.198027 22392998065984 run_lib.py:146] step: 138000, training_loss: 6.55580e-02
I0514 13:56:34.391371 22392998065984 run_lib.py:167] step: 138000, eval_loss: 4.69428e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 13:56:58.156371 22392998065984 run_lib.py:146] step: 138050, training_loss: 6.98271e-02
I0514 13:57:21.573064 22392998065984 run_lib.py:146] step: 138100, training_loss: 6.25075e-02
I0514 13:57:21.818488 22392998065984 run_lib.py:167] step: 138100, eval_loss: 6.15054e-02
I0514 13:57:45.415994 22392998065984 run_lib.py:146] step: 138150, training_loss: 5.56509e-02
I0514 13:58:08.687104 22392998065984 run_lib.py:146] step: 138200, training_loss: 6.13376e-02
I0514 13:58:08.877383 22392998065984 run_lib.py:167] step: 138200, eval_loss: 6.13987e-02
I0514 13:58:32.417060 22392998065984 run_lib.py:146] step: 138250, training_loss: 5.47144e-02
I0514 13:58:55.691037 22392998065984 run_lib.py:146] step: 138300, training_loss: 5.20503e-02
I0514 13:58:55.927856 22392998065984 run_lib.py:167] step: 138300, eval_loss: 7.36459e-02
I0514 13:59:19.397171 22392998065984 run_lib.py:146] step: 138350, training_loss: 5.45886e-02
I0514 13:59:42.938782 22392998065984 run_lib.py:146] step: 138400, training_loss: 5.84207e-02
I0514 13:59:43.170731 22392998065984 run_lib.py:167] step: 138400, eval_loss: 5.10409e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:00:07.049042 22392998065984 run_lib.py:146] step: 138450, training_loss: 5.55109e-02
I0514 14:00:31.260774 22392998065984 run_lib.py:146] step: 138500, training_loss: 6.65767e-02
I0514 14:00:31.489622 22392998065984 run_lib.py:167] step: 138500, eval_loss: 4.91119e-02
I0514 14:00:55.685417 22392998065984 run_lib.py:146] step: 138550, training_loss: 5.53468e-02
I0514 14:01:19.577171 22392998065984 run_lib.py:146] step: 138600, training_loss: 5.61202e-02
I0514 14:01:19.733487 22392998065984 run_lib.py:167] step: 138600, eval_loss: 5.56022e-02
I0514 14:01:43.822848 22392998065984 run_lib.py:146] step: 138650, training_loss: 6.84016e-02
I0514 14:02:07.403551 22392998065984 run_lib.py:146] step: 138700, training_loss: 6.15287e-02
I0514 14:02:07.560050 22392998065984 run_lib.py:167] step: 138700, eval_loss: 8.66355e-02
I0514 14:02:30.822613 22392998065984 run_lib.py:146] step: 138750, training_loss: 5.50974e-02
I0514 14:02:54.390530 22392998065984 run_lib.py:146] step: 138800, training_loss: 5.60900e-02
I0514 14:02:54.599997 22392998065984 run_lib.py:167] step: 138800, eval_loss: 4.03509e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:03:18.557655 22392998065984 run_lib.py:146] step: 138850, training_loss: 6.94240e-02
I0514 14:03:42.760201 22392998065984 run_lib.py:146] step: 138900, training_loss: 5.51193e-02
I0514 14:03:42.918150 22392998065984 run_lib.py:167] step: 138900, eval_loss: 5.77414e-02
I0514 14:04:07.157722 22392998065984 run_lib.py:146] step: 138950, training_loss: 5.87523e-02
I0514 14:04:30.979257 22392998065984 run_lib.py:146] step: 139000, training_loss: 8.67256e-02
I0514 14:04:31.193901 22392998065984 run_lib.py:167] step: 139000, eval_loss: 6.97225e-02
I0514 14:04:54.786714 22392998065984 run_lib.py:146] step: 139050, training_loss: 6.06416e-02
I0514 14:05:18.364837 22392998065984 run_lib.py:146] step: 139100, training_loss: 4.38451e-02
I0514 14:05:18.521185 22392998065984 run_lib.py:167] step: 139100, eval_loss: 6.11240e-02
I0514 14:05:42.033180 22392998065984 run_lib.py:146] step: 139150, training_loss: 6.10939e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:06:06.305310 22392998065984 run_lib.py:146] step: 139200, training_loss: 7.83491e-02
I0514 14:06:06.463600 22392998065984 run_lib.py:167] step: 139200, eval_loss: 5.09098e-02
I0514 14:06:29.738179 22392998065984 run_lib.py:146] step: 139250, training_loss: 6.22812e-02
I0514 14:06:53.981015 22392998065984 run_lib.py:146] step: 139300, training_loss: 7.39503e-02
I0514 14:06:54.137494 22392998065984 run_lib.py:167] step: 139300, eval_loss: 6.38129e-02
I0514 14:07:18.340227 22392998065984 run_lib.py:146] step: 139350, training_loss: 4.89173e-02
I0514 14:07:42.265573 22392998065984 run_lib.py:146] step: 139400, training_loss: 7.57871e-02
I0514 14:07:42.421734 22392998065984 run_lib.py:167] step: 139400, eval_loss: 5.05978e-02
I0514 14:08:06.606208 22392998065984 run_lib.py:146] step: 139450, training_loss: 6.81287e-02
I0514 14:08:30.764188 22392998065984 run_lib.py:146] step: 139500, training_loss: 5.72035e-02
I0514 14:08:30.921524 22392998065984 run_lib.py:167] step: 139500, eval_loss: 7.35008e-02
I0514 14:08:54.820333 22392998065984 run_lib.py:146] step: 139550, training_loss: 6.08035e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:09:19.008607 22392998065984 run_lib.py:146] step: 139600, training_loss: 5.62009e-02
I0514 14:09:19.166657 22392998065984 run_lib.py:167] step: 139600, eval_loss: 6.52982e-02
I0514 14:09:43.332277 22392998065984 run_lib.py:146] step: 139650, training_loss: 6.41496e-02
I0514 14:10:07.237355 22392998065984 run_lib.py:146] step: 139700, training_loss: 4.95965e-02
I0514 14:10:07.393969 22392998065984 run_lib.py:167] step: 139700, eval_loss: 7.97992e-02
I0514 14:10:31.631953 22392998065984 run_lib.py:146] step: 139750, training_loss: 6.48327e-02
I0514 14:10:55.513111 22392998065984 run_lib.py:146] step: 139800, training_loss: 4.89607e-02
I0514 14:10:55.669943 22392998065984 run_lib.py:167] step: 139800, eval_loss: 6.05635e-02
I0514 14:11:19.824970 22392998065984 run_lib.py:146] step: 139850, training_loss: 6.83218e-02
I0514 14:11:44.023353 22392998065984 run_lib.py:146] step: 139900, training_loss: 5.98243e-02
I0514 14:11:44.179547 22392998065984 run_lib.py:167] step: 139900, eval_loss: 5.35837e-02
I0514 14:12:08.059172 22392998065984 run_lib.py:146] step: 139950, training_loss: 5.78326e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:12:32.141257 22392998065984 run_lib.py:146] step: 140000, training_loss: 6.40639e-02
I0514 14:12:45.004840 22392998065984 run_lib.py:167] step: 140000, eval_loss: 6.23435e-02
I0514 14:13:19.307299 22392998065984 run_lib.py:146] step: 140050, training_loss: 5.31936e-02
I0514 14:13:43.196262 22392998065984 run_lib.py:146] step: 140100, training_loss: 5.41632e-02
I0514 14:13:43.352440 22392998065984 run_lib.py:167] step: 140100, eval_loss: 5.55901e-02
I0514 14:14:06.610908 22392998065984 run_lib.py:146] step: 140150, training_loss: 4.92102e-02
I0514 14:14:29.900702 22392998065984 run_lib.py:146] step: 140200, training_loss: 5.04860e-02
I0514 14:14:30.057277 22392998065984 run_lib.py:167] step: 140200, eval_loss: 7.54038e-02
I0514 14:14:53.951316 22392998065984 run_lib.py:146] step: 140250, training_loss: 8.31706e-02
I0514 14:15:17.225754 22392998065984 run_lib.py:146] step: 140300, training_loss: 5.08971e-02
I0514 14:15:17.382308 22392998065984 run_lib.py:167] step: 140300, eval_loss: 6.43910e-02
I0514 14:15:40.655750 22392998065984 run_lib.py:146] step: 140350, training_loss: 5.56071e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:16:05.196217 22392998065984 run_lib.py:146] step: 140400, training_loss: 8.34669e-02
I0514 14:16:05.353811 22392998065984 run_lib.py:167] step: 140400, eval_loss: 5.82430e-02
I0514 14:16:29.247159 22392998065984 run_lib.py:146] step: 140450, training_loss: 6.07542e-02
I0514 14:16:52.827882 22392998065984 run_lib.py:146] step: 140500, training_loss: 5.50789e-02
I0514 14:16:52.984668 22392998065984 run_lib.py:167] step: 140500, eval_loss: 4.62294e-02
I0514 14:17:16.565303 22392998065984 run_lib.py:146] step: 140550, training_loss: 6.17222e-02
I0514 14:17:40.154395 22392998065984 run_lib.py:146] step: 140600, training_loss: 7.47401e-02
I0514 14:17:40.311505 22392998065984 run_lib.py:167] step: 140600, eval_loss: 6.17211e-02
I0514 14:18:03.595411 22392998065984 run_lib.py:146] step: 140650, training_loss: 6.13002e-02
I0514 14:18:27.380591 22392998065984 run_lib.py:146] step: 140700, training_loss: 5.52951e-02
I0514 14:18:27.690918 22392998065984 run_lib.py:167] step: 140700, eval_loss: 5.96547e-02
I0514 14:18:51.430832 22392998065984 run_lib.py:146] step: 140750, training_loss: 5.12591e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:19:14.856990 22392998065984 run_lib.py:146] step: 140800, training_loss: 6.99291e-02
I0514 14:19:15.014858 22392998065984 run_lib.py:167] step: 140800, eval_loss: 4.48885e-02
I0514 14:19:38.293521 22392998065984 run_lib.py:146] step: 140850, training_loss: 6.51578e-02
I0514 14:20:02.227018 22392998065984 run_lib.py:146] step: 140900, training_loss: 5.40036e-02
I0514 14:20:02.383299 22392998065984 run_lib.py:167] step: 140900, eval_loss: 6.17906e-02
I0514 14:20:25.660413 22392998065984 run_lib.py:146] step: 140950, training_loss: 5.71456e-02
I0514 14:20:48.934781 22392998065984 run_lib.py:146] step: 141000, training_loss: 7.71593e-02
I0514 14:20:49.091221 22392998065984 run_lib.py:167] step: 141000, eval_loss: 4.88247e-02
I0514 14:21:12.954096 22392998065984 run_lib.py:146] step: 141050, training_loss: 9.07002e-02
I0514 14:21:36.256957 22392998065984 run_lib.py:146] step: 141100, training_loss: 6.94468e-02
I0514 14:21:36.413428 22392998065984 run_lib.py:167] step: 141100, eval_loss: 5.83296e-02
I0514 14:21:59.543808 22392998065984 run_lib.py:146] step: 141150, training_loss: 5.68405e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:22:24.027235 22392998065984 run_lib.py:146] step: 141200, training_loss: 5.36919e-02
I0514 14:22:24.184925 22392998065984 run_lib.py:167] step: 141200, eval_loss: 6.31793e-02
I0514 14:22:48.423240 22392998065984 run_lib.py:146] step: 141250, training_loss: 3.95962e-02
I0514 14:23:12.353459 22392998065984 run_lib.py:146] step: 141300, training_loss: 4.66171e-02
I0514 14:23:12.510125 22392998065984 run_lib.py:167] step: 141300, eval_loss: 5.73253e-02
I0514 14:23:36.731949 22392998065984 run_lib.py:146] step: 141350, training_loss: 8.38300e-02
I0514 14:24:00.901672 22392998065984 run_lib.py:146] step: 141400, training_loss: 6.06181e-02
I0514 14:24:01.058594 22392998065984 run_lib.py:167] step: 141400, eval_loss: 7.53716e-02
I0514 14:24:24.936512 22392998065984 run_lib.py:146] step: 141450, training_loss: 4.73462e-02
I0514 14:24:49.144491 22392998065984 run_lib.py:146] step: 141500, training_loss: 7.89773e-02
I0514 14:24:49.304833 22392998065984 run_lib.py:167] step: 141500, eval_loss: 8.68681e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:25:13.523010 22392998065984 run_lib.py:146] step: 141550, training_loss: 6.45341e-02
I0514 14:25:36.790885 22392998065984 run_lib.py:146] step: 141600, training_loss: 5.22254e-02
I0514 14:25:36.948502 22392998065984 run_lib.py:167] step: 141600, eval_loss: 8.11114e-02
I0514 14:26:00.218046 22392998065984 run_lib.py:146] step: 141650, training_loss: 6.13487e-02
I0514 14:26:24.172170 22392998065984 run_lib.py:146] step: 141700, training_loss: 7.00455e-02
I0514 14:26:24.328612 22392998065984 run_lib.py:167] step: 141700, eval_loss: 6.95533e-02
I0514 14:26:47.592163 22392998065984 run_lib.py:146] step: 141750, training_loss: 7.89224e-02
I0514 14:27:10.856818 22392998065984 run_lib.py:146] step: 141800, training_loss: 5.11479e-02
I0514 14:27:11.013381 22392998065984 run_lib.py:167] step: 141800, eval_loss: 5.98981e-02
I0514 14:27:34.861749 22392998065984 run_lib.py:146] step: 141850, training_loss: 5.85714e-02
I0514 14:27:58.107888 22392998065984 run_lib.py:146] step: 141900, training_loss: 5.99949e-02
I0514 14:27:58.264053 22392998065984 run_lib.py:167] step: 141900, eval_loss: 7.30392e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:28:21.868238 22392998065984 run_lib.py:146] step: 141950, training_loss: 5.34119e-02
I0514 14:28:46.092221 22392998065984 run_lib.py:146] step: 142000, training_loss: 5.06314e-02
I0514 14:28:46.249106 22392998065984 run_lib.py:167] step: 142000, eval_loss: 7.29984e-02
I0514 14:29:10.428431 22392998065984 run_lib.py:146] step: 142050, training_loss: 6.47720e-02
I0514 14:29:34.308980 22392998065984 run_lib.py:146] step: 142100, training_loss: 6.90087e-02
I0514 14:29:34.386957 22392998065984 run_lib.py:167] step: 142100, eval_loss: 9.62231e-02
I0514 14:29:58.581596 22392998065984 run_lib.py:146] step: 142150, training_loss: 4.64497e-02
I0514 14:30:22.748791 22392998065984 run_lib.py:146] step: 142200, training_loss: 8.52969e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:30:23.143245 22392998065984 run_lib.py:167] step: 142200, eval_loss: 5.47532e-02
I0514 14:30:46.450802 22392998065984 run_lib.py:146] step: 142250, training_loss: 5.33384e-02
I0514 14:31:10.081632 22392998065984 run_lib.py:146] step: 142300, training_loss: 5.90986e-02
I0514 14:31:10.238018 22392998065984 run_lib.py:167] step: 142300, eval_loss: 6.23904e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:31:33.965120 22392998065984 run_lib.py:146] step: 142350, training_loss: 6.44081e-02
I0514 14:31:57.255808 22392998065984 run_lib.py:146] step: 142400, training_loss: 5.54266e-02
I0514 14:31:57.413671 22392998065984 run_lib.py:167] step: 142400, eval_loss: 6.83482e-02
I0514 14:32:20.856694 22392998065984 run_lib.py:146] step: 142450, training_loss: 6.22270e-02
I0514 14:32:45.429771 22392998065984 run_lib.py:146] step: 142500, training_loss: 5.27242e-02
I0514 14:32:45.586109 22392998065984 run_lib.py:167] step: 142500, eval_loss: 5.58343e-02
I0514 14:33:09.477260 22392998065984 run_lib.py:146] step: 142550, training_loss: 5.22191e-02
I0514 14:33:33.359129 22392998065984 run_lib.py:146] step: 142600, training_loss: 5.92190e-02
I0514 14:33:33.515423 22392998065984 run_lib.py:167] step: 142600, eval_loss: 5.61058e-02
I0514 14:33:57.992718 22392998065984 run_lib.py:146] step: 142650, training_loss: 5.20479e-02
I0514 14:34:21.891230 22392998065984 run_lib.py:146] step: 142700, training_loss: 5.89767e-02
I0514 14:34:22.047710 22392998065984 run_lib.py:167] step: 142700, eval_loss: 5.54614e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:34:45.657973 22392998065984 run_lib.py:146] step: 142750, training_loss: 6.41194e-02
I0514 14:35:09.613993 22392998065984 run_lib.py:146] step: 142800, training_loss: 5.31871e-02
I0514 14:35:09.772008 22392998065984 run_lib.py:167] step: 142800, eval_loss: 8.02589e-02
I0514 14:35:33.030514 22392998065984 run_lib.py:146] step: 142850, training_loss: 6.75922e-02
I0514 14:35:56.372722 22392998065984 run_lib.py:146] step: 142900, training_loss: 8.70769e-02
I0514 14:35:56.529196 22392998065984 run_lib.py:167] step: 142900, eval_loss: 5.10336e-02
I0514 14:36:20.107196 22392998065984 run_lib.py:146] step: 142950, training_loss: 6.55911e-02
I0514 14:36:43.657175 22392998065984 run_lib.py:146] step: 143000, training_loss: 5.79713e-02
I0514 14:36:43.813854 22392998065984 run_lib.py:167] step: 143000, eval_loss: 9.87672e-02
I0514 14:37:07.108261 22392998065984 run_lib.py:146] step: 143050, training_loss: 6.37067e-02
I0514 14:37:30.691400 22392998065984 run_lib.py:146] step: 143100, training_loss: 3.87757e-02
I0514 14:37:30.847750 22392998065984 run_lib.py:167] step: 143100, eval_loss: 7.14284e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:37:55.110158 22392998065984 run_lib.py:146] step: 143150, training_loss: 5.39203e-02
I0514 14:38:18.998603 22392998065984 run_lib.py:146] step: 143200, training_loss: 4.69177e-02
I0514 14:38:19.156129 22392998065984 run_lib.py:167] step: 143200, eval_loss: 6.13667e-02
I0514 14:38:43.402581 22392998065984 run_lib.py:146] step: 143250, training_loss: 7.50599e-02
I0514 14:39:07.547128 22392998065984 run_lib.py:146] step: 143300, training_loss: 5.46818e-02
I0514 14:39:07.713778 22392998065984 run_lib.py:167] step: 143300, eval_loss: 6.67806e-02
I0514 14:39:31.301826 22392998065984 run_lib.py:146] step: 143350, training_loss: 4.41488e-02
I0514 14:39:54.570243 22392998065984 run_lib.py:146] step: 143400, training_loss: 6.36485e-02
I0514 14:39:54.726651 22392998065984 run_lib.py:167] step: 143400, eval_loss: 8.28272e-02
I0514 14:40:18.580567 22392998065984 run_lib.py:146] step: 143450, training_loss: 6.95583e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:40:42.033742 22392998065984 run_lib.py:146] step: 143500, training_loss: 6.43024e-02
I0514 14:40:42.192026 22392998065984 run_lib.py:167] step: 143500, eval_loss: 5.27121e-02
I0514 14:41:06.087178 22392998065984 run_lib.py:146] step: 143550, training_loss: 4.95904e-02
I0514 14:41:30.317629 22392998065984 run_lib.py:146] step: 143600, training_loss: 4.65401e-02
I0514 14:41:30.474907 22392998065984 run_lib.py:167] step: 143600, eval_loss: 7.46341e-02
I0514 14:41:54.673593 22392998065984 run_lib.py:146] step: 143650, training_loss: 6.33990e-02
I0514 14:42:18.565317 22392998065984 run_lib.py:146] step: 143700, training_loss: 4.94846e-02
I0514 14:42:18.722001 22392998065984 run_lib.py:167] step: 143700, eval_loss: 7.28567e-02
I0514 14:42:42.919100 22392998065984 run_lib.py:146] step: 143750, training_loss: 6.30623e-02
I0514 14:43:07.091164 22392998065984 run_lib.py:146] step: 143800, training_loss: 5.63520e-02
I0514 14:43:07.247353 22392998065984 run_lib.py:167] step: 143800, eval_loss: 5.63777e-02
I0514 14:43:31.135604 22392998065984 run_lib.py:146] step: 143850, training_loss: 4.16375e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:43:55.411498 22392998065984 run_lib.py:146] step: 143900, training_loss: 5.43084e-02
I0514 14:43:55.570481 22392998065984 run_lib.py:167] step: 143900, eval_loss: 4.07120e-02
I0514 14:44:19.158078 22392998065984 run_lib.py:146] step: 143950, training_loss: 5.38285e-02
I0514 14:44:42.422833 22392998065984 run_lib.py:146] step: 144000, training_loss: 7.08678e-02
I0514 14:44:42.579545 22392998065984 run_lib.py:167] step: 144000, eval_loss: 6.78206e-02
I0514 14:45:06.124582 22392998065984 run_lib.py:146] step: 144050, training_loss: 6.70941e-02
I0514 14:45:29.675897 22392998065984 run_lib.py:146] step: 144100, training_loss: 6.23053e-02
I0514 14:45:29.832155 22392998065984 run_lib.py:167] step: 144100, eval_loss: 7.80727e-02
I0514 14:45:53.109406 22392998065984 run_lib.py:146] step: 144150, training_loss: 6.18465e-02
I0514 14:46:16.366150 22392998065984 run_lib.py:146] step: 144200, training_loss: 6.76635e-02
I0514 14:46:16.523257 22392998065984 run_lib.py:167] step: 144200, eval_loss: 5.22025e-02
I0514 14:46:40.413068 22392998065984 run_lib.py:146] step: 144250, training_loss: 5.91524e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:47:04.098961 22392998065984 run_lib.py:146] step: 144300, training_loss: 6.07449e-02
I0514 14:47:04.258878 22392998065984 run_lib.py:167] step: 144300, eval_loss: 5.64989e-02
I0514 14:47:28.155371 22392998065984 run_lib.py:146] step: 144350, training_loss: 6.41381e-02
I0514 14:47:52.400615 22392998065984 run_lib.py:146] step: 144400, training_loss: 7.31866e-02
I0514 14:47:52.558176 22392998065984 run_lib.py:167] step: 144400, eval_loss: 6.98201e-02
I0514 14:48:16.762769 22392998065984 run_lib.py:146] step: 144450, training_loss: 4.85453e-02
I0514 14:48:40.660893 22392998065984 run_lib.py:146] step: 144500, training_loss: 4.99379e-02
I0514 14:48:40.817428 22392998065984 run_lib.py:167] step: 144500, eval_loss: 5.85394e-02
I0514 14:49:04.563362 22392998065984 run_lib.py:146] step: 144550, training_loss: 4.93780e-02
I0514 14:49:28.099112 22392998065984 run_lib.py:146] step: 144600, training_loss: 4.91049e-02
I0514 14:49:28.255186 22392998065984 run_lib.py:167] step: 144600, eval_loss: 5.53721e-02
I0514 14:49:51.528333 22392998065984 run_lib.py:146] step: 144650, training_loss: 7.48701e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:50:15.340906 22392998065984 run_lib.py:146] step: 144700, training_loss: 5.71593e-02
I0514 14:50:15.499371 22392998065984 run_lib.py:167] step: 144700, eval_loss: 6.53334e-02
I0514 14:50:39.061600 22392998065984 run_lib.py:146] step: 144750, training_loss: 5.37789e-02
I0514 14:51:02.354768 22392998065984 run_lib.py:146] step: 144800, training_loss: 5.09519e-02
I0514 14:51:02.511968 22392998065984 run_lib.py:167] step: 144800, eval_loss: 6.16862e-02
I0514 14:51:26.102125 22392998065984 run_lib.py:146] step: 144850, training_loss: 5.83745e-02
I0514 14:51:49.676464 22392998065984 run_lib.py:146] step: 144900, training_loss: 5.67754e-02
I0514 14:51:49.832911 22392998065984 run_lib.py:167] step: 144900, eval_loss: 5.36353e-02
I0514 14:52:13.090574 22392998065984 run_lib.py:146] step: 144950, training_loss: 5.32292e-02
I0514 14:52:36.911599 22392998065984 run_lib.py:146] step: 145000, training_loss: 7.08712e-02
I0514 14:52:37.067898 22392998065984 run_lib.py:167] step: 145000, eval_loss: 6.78613e-02
I0514 14:53:01.526134 22392998065984 run_lib.py:146] step: 145050, training_loss: 5.43668e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:53:25.107075 22392998065984 run_lib.py:146] step: 145100, training_loss: 5.51572e-02
I0514 14:53:25.265532 22392998065984 run_lib.py:167] step: 145100, eval_loss: 4.53678e-02
I0514 14:53:48.534370 22392998065984 run_lib.py:146] step: 145150, training_loss: 8.25174e-02
I0514 14:54:12.467777 22392998065984 run_lib.py:146] step: 145200, training_loss: 6.26920e-02
I0514 14:54:12.624794 22392998065984 run_lib.py:167] step: 145200, eval_loss: 6.70406e-02
I0514 14:54:35.896560 22392998065984 run_lib.py:146] step: 145250, training_loss: 6.28052e-02
I0514 14:54:59.235721 22392998065984 run_lib.py:146] step: 145300, training_loss: 5.72975e-02
I0514 14:54:59.392019 22392998065984 run_lib.py:167] step: 145300, eval_loss: 6.04383e-02
I0514 14:55:22.966831 22392998065984 run_lib.py:146] step: 145350, training_loss: 6.41124e-02
I0514 14:55:46.538329 22392998065984 run_lib.py:146] step: 145400, training_loss: 7.03698e-02
I0514 14:55:46.695441 22392998065984 run_lib.py:167] step: 145400, eval_loss: 4.84795e-02
I0514 14:56:10.004460 22392998065984 run_lib.py:146] step: 145450, training_loss: 6.67700e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:56:33.797606 22392998065984 run_lib.py:146] step: 145500, training_loss: 5.28454e-02
I0514 14:56:33.956082 22392998065984 run_lib.py:167] step: 145500, eval_loss: 6.23008e-02
I0514 14:56:57.595105 22392998065984 run_lib.py:146] step: 145550, training_loss: 5.86122e-02
I0514 14:57:20.875685 22392998065984 run_lib.py:146] step: 145600, training_loss: 5.52387e-02
I0514 14:57:21.032108 22392998065984 run_lib.py:167] step: 145600, eval_loss: 6.78377e-02
I0514 14:57:44.710101 22392998065984 run_lib.py:146] step: 145650, training_loss: 8.82415e-02
I0514 14:58:08.280992 22392998065984 run_lib.py:146] step: 145700, training_loss: 7.33810e-02
I0514 14:58:08.437369 22392998065984 run_lib.py:167] step: 145700, eval_loss: 6.62408e-02
I0514 14:58:31.707304 22392998065984 run_lib.py:146] step: 145750, training_loss: 6.33097e-02
I0514 14:58:54.971050 22392998065984 run_lib.py:146] step: 145800, training_loss: 4.71667e-02
I0514 14:58:55.127252 22392998065984 run_lib.py:167] step: 145800, eval_loss: 7.69915e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 14:59:19.108151 22392998065984 run_lib.py:146] step: 145850, training_loss: 6.74882e-02
I0514 14:59:42.369783 22392998065984 run_lib.py:146] step: 145900, training_loss: 5.38018e-02
I0514 14:59:42.527453 22392998065984 run_lib.py:167] step: 145900, eval_loss: 4.77372e-02
I0514 15:00:05.797926 22392998065984 run_lib.py:146] step: 145950, training_loss: 5.74505e-02
I0514 15:00:29.400771 22392998065984 run_lib.py:146] step: 146000, training_loss: 8.28998e-02
I0514 15:00:29.557382 22392998065984 run_lib.py:167] step: 146000, eval_loss: 5.31080e-02
I0514 15:00:53.193524 22392998065984 run_lib.py:146] step: 146050, training_loss: 7.72670e-02
I0514 15:01:16.472754 22392998065984 run_lib.py:146] step: 146100, training_loss: 6.99461e-02
I0514 15:01:16.629430 22392998065984 run_lib.py:167] step: 146100, eval_loss: 5.98903e-02
I0514 15:01:40.214261 22392998065984 run_lib.py:146] step: 146150, training_loss: 5.28083e-02
I0514 15:02:03.788306 22392998065984 run_lib.py:146] step: 146200, training_loss: 6.62751e-02
I0514 15:02:03.944674 22392998065984 run_lib.py:167] step: 146200, eval_loss: 6.79399e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:02:27.352244 22392998065984 run_lib.py:146] step: 146250, training_loss: 5.15537e-02
I0514 15:02:50.981037 22392998065984 run_lib.py:146] step: 146300, training_loss: 5.73054e-02
I0514 15:02:51.138900 22392998065984 run_lib.py:167] step: 146300, eval_loss: 4.32584e-02
I0514 15:03:14.735723 22392998065984 run_lib.py:146] step: 146350, training_loss: 5.47259e-02
I0514 15:03:38.038402 22392998065984 run_lib.py:146] step: 146400, training_loss: 6.06164e-02
I0514 15:03:38.195057 22392998065984 run_lib.py:167] step: 146400, eval_loss: 8.71004e-02
I0514 15:04:01.821448 22392998065984 run_lib.py:146] step: 146450, training_loss: 4.68884e-02
I0514 15:04:25.780503 22392998065984 run_lib.py:146] step: 146500, training_loss: 6.34193e-02
I0514 15:04:25.937377 22392998065984 run_lib.py:167] step: 146500, eval_loss: 6.84053e-02
I0514 15:04:49.187086 22392998065984 run_lib.py:146] step: 146550, training_loss: 5.09847e-02
I0514 15:05:12.454150 22392998065984 run_lib.py:146] step: 146600, training_loss: 6.88906e-02
I0514 15:05:12.610902 22392998065984 run_lib.py:167] step: 146600, eval_loss: 4.62682e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:05:36.638831 22392998065984 run_lib.py:146] step: 146650, training_loss: 6.73304e-02
I0514 15:05:59.915259 22392998065984 run_lib.py:146] step: 146700, training_loss: 6.01216e-02
I0514 15:06:00.073843 22392998065984 run_lib.py:167] step: 146700, eval_loss: 5.28265e-02
I0514 15:06:23.339707 22392998065984 run_lib.py:146] step: 146750, training_loss: 6.83042e-02
I0514 15:06:47.585761 22392998065984 run_lib.py:146] step: 146800, training_loss: 6.38414e-02
I0514 15:06:47.743117 22392998065984 run_lib.py:167] step: 146800, eval_loss: 7.02864e-02
I0514 15:07:11.801928 22392998065984 run_lib.py:146] step: 146850, training_loss: 7.04805e-02
I0514 15:07:35.069198 22392998065984 run_lib.py:146] step: 146900, training_loss: 6.63833e-02
I0514 15:07:35.225649 22392998065984 run_lib.py:167] step: 146900, eval_loss: 6.82042e-02
I0514 15:07:58.799205 22392998065984 run_lib.py:146] step: 146950, training_loss: 6.96201e-02
I0514 15:08:22.379996 22392998065984 run_lib.py:146] step: 147000, training_loss: 6.03011e-02
I0514 15:08:22.537048 22392998065984 run_lib.py:167] step: 147000, eval_loss: 5.31419e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:08:45.979962 22392998065984 run_lib.py:146] step: 147050, training_loss: 7.05175e-02
I0514 15:09:09.644748 22392998065984 run_lib.py:146] step: 147100, training_loss: 6.59647e-02
I0514 15:09:09.803123 22392998065984 run_lib.py:167] step: 147100, eval_loss: 5.77324e-02
I0514 15:09:33.463788 22392998065984 run_lib.py:146] step: 147150, training_loss: 6.51013e-02
I0514 15:09:57.343017 22392998065984 run_lib.py:146] step: 147200, training_loss: 5.92253e-02
I0514 15:09:57.516598 22392998065984 run_lib.py:167] step: 147200, eval_loss: 6.62160e-02
I0514 15:10:21.960945 22392998065984 run_lib.py:146] step: 147250, training_loss: 4.67957e-02
I0514 15:10:46.342792 22392998065984 run_lib.py:146] step: 147300, training_loss: 7.51633e-02
I0514 15:10:46.504920 22392998065984 run_lib.py:167] step: 147300, eval_loss: 8.25726e-02
I0514 15:11:10.541304 22392998065984 run_lib.py:146] step: 147350, training_loss: 6.58290e-02
I0514 15:11:34.587255 22392998065984 run_lib.py:146] step: 147400, training_loss: 7.39237e-02
I0514 15:11:34.752030 22392998065984 run_lib.py:167] step: 147400, eval_loss: 8.01173e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:11:59.584056 22392998065984 run_lib.py:146] step: 147450, training_loss: 7.86674e-02
I0514 15:12:23.660174 22392998065984 run_lib.py:146] step: 147500, training_loss: 6.82612e-02
I0514 15:12:23.826550 22392998065984 run_lib.py:167] step: 147500, eval_loss: 6.50224e-02
I0514 15:12:47.989223 22392998065984 run_lib.py:146] step: 147550, training_loss: 6.81032e-02
I0514 15:13:12.415249 22392998065984 run_lib.py:146] step: 147600, training_loss: 4.37110e-02
I0514 15:13:12.580270 22392998065984 run_lib.py:167] step: 147600, eval_loss: 5.76961e-02
I0514 15:13:37.051936 22392998065984 run_lib.py:146] step: 147650, training_loss: 8.31888e-02
I0514 15:14:01.159172 22392998065984 run_lib.py:146] step: 147700, training_loss: 6.16512e-02
I0514 15:14:01.319673 22392998065984 run_lib.py:167] step: 147700, eval_loss: 7.45587e-02
I0514 15:14:25.538725 22392998065984 run_lib.py:146] step: 147750, training_loss: 6.54540e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:14:49.897996 22392998065984 run_lib.py:146] step: 147800, training_loss: 5.54488e-02
I0514 15:14:50.057974 22392998065984 run_lib.py:167] step: 147800, eval_loss: 6.66755e-02
I0514 15:15:13.849127 22392998065984 run_lib.py:146] step: 147850, training_loss: 5.21159e-02
I0514 15:15:38.021744 22392998065984 run_lib.py:146] step: 147900, training_loss: 6.32152e-02
I0514 15:15:38.178881 22392998065984 run_lib.py:167] step: 147900, eval_loss: 4.64877e-02
I0514 15:16:02.015387 22392998065984 run_lib.py:146] step: 147950, training_loss: 6.32302e-02
I0514 15:16:26.110064 22392998065984 run_lib.py:146] step: 148000, training_loss: 4.82503e-02
I0514 15:16:26.266992 22392998065984 run_lib.py:167] step: 148000, eval_loss: 7.64162e-02
I0514 15:16:50.715886 22392998065984 run_lib.py:146] step: 148050, training_loss: 7.13440e-02
I0514 15:17:14.904583 22392998065984 run_lib.py:146] step: 148100, training_loss: 6.15325e-02
I0514 15:17:15.061523 22392998065984 run_lib.py:167] step: 148100, eval_loss: 5.79827e-02
I0514 15:17:38.507600 22392998065984 run_lib.py:146] step: 148150, training_loss: 7.01605e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:18:02.163558 22392998065984 run_lib.py:146] step: 148200, training_loss: 6.00943e-02
I0514 15:18:02.340710 22392998065984 run_lib.py:167] step: 148200, eval_loss: 5.64438e-02
I0514 15:18:26.512565 22392998065984 run_lib.py:146] step: 148250, training_loss: 8.20774e-02
I0514 15:18:50.028514 22392998065984 run_lib.py:146] step: 148300, training_loss: 6.10004e-02
I0514 15:18:50.188579 22392998065984 run_lib.py:167] step: 148300, eval_loss: 5.10497e-02
I0514 15:19:13.592097 22392998065984 run_lib.py:146] step: 148350, training_loss: 6.71398e-02
I0514 15:19:37.937377 22392998065984 run_lib.py:146] step: 148400, training_loss: 6.24826e-02
I0514 15:19:38.095293 22392998065984 run_lib.py:167] step: 148400, eval_loss: 5.71066e-02
I0514 15:20:02.511089 22392998065984 run_lib.py:146] step: 148450, training_loss: 4.12618e-02
I0514 15:20:26.220678 22392998065984 run_lib.py:146] step: 148500, training_loss: 4.89937e-02
I0514 15:20:26.379144 22392998065984 run_lib.py:167] step: 148500, eval_loss: 4.93940e-02
I0514 15:20:50.690970 22392998065984 run_lib.py:146] step: 148550, training_loss: 5.56501e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:21:14.953342 22392998065984 run_lib.py:146] step: 148600, training_loss: 7.77649e-02
I0514 15:21:15.114586 22392998065984 run_lib.py:167] step: 148600, eval_loss: 8.48656e-02
I0514 15:21:39.067258 22392998065984 run_lib.py:146] step: 148650, training_loss: 6.02144e-02
I0514 15:22:03.305495 22392998065984 run_lib.py:146] step: 148700, training_loss: 7.79716e-02
I0514 15:22:03.466413 22392998065984 run_lib.py:167] step: 148700, eval_loss: 4.74192e-02
I0514 15:22:27.658851 22392998065984 run_lib.py:146] step: 148750, training_loss: 6.50793e-02
I0514 15:22:51.564943 22392998065984 run_lib.py:146] step: 148800, training_loss: 5.06973e-02
I0514 15:22:51.724319 22392998065984 run_lib.py:167] step: 148800, eval_loss: 6.57473e-02
I0514 15:23:15.821653 22392998065984 run_lib.py:146] step: 148850, training_loss: 5.16862e-02
I0514 15:23:40.097050 22392998065984 run_lib.py:146] step: 148900, training_loss: 7.30367e-02
I0514 15:23:40.256802 22392998065984 run_lib.py:167] step: 148900, eval_loss: 6.84725e-02
I0514 15:24:04.351020 22392998065984 run_lib.py:146] step: 148950, training_loss: 4.35278e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:24:28.566090 22392998065984 run_lib.py:146] step: 149000, training_loss: 6.30281e-02
I0514 15:24:28.727058 22392998065984 run_lib.py:167] step: 149000, eval_loss: 6.45974e-02
I0514 15:24:53.580042 22392998065984 run_lib.py:146] step: 149050, training_loss: 7.92585e-02
I0514 15:25:17.592126 22392998065984 run_lib.py:146] step: 149100, training_loss: 5.41170e-02
I0514 15:25:17.752377 22392998065984 run_lib.py:167] step: 149100, eval_loss: 4.45663e-02
I0514 15:25:41.678636 22392998065984 run_lib.py:146] step: 149150, training_loss: 4.89940e-02
I0514 15:26:05.897280 22392998065984 run_lib.py:146] step: 149200, training_loss: 7.58016e-02
I0514 15:26:06.065603 22392998065984 run_lib.py:167] step: 149200, eval_loss: 6.36876e-02
I0514 15:26:30.276525 22392998065984 run_lib.py:146] step: 149250, training_loss: 6.94667e-02
I0514 15:26:54.153364 22392998065984 run_lib.py:146] step: 149300, training_loss: 4.09520e-02
I0514 15:26:54.312019 22392998065984 run_lib.py:167] step: 149300, eval_loss: 5.56298e-02
I0514 15:27:18.541756 22392998065984 run_lib.py:146] step: 149350, training_loss: 5.52585e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:27:43.111289 22392998065984 run_lib.py:146] step: 149400, training_loss: 5.89256e-02
I0514 15:27:43.279485 22392998065984 run_lib.py:167] step: 149400, eval_loss: 5.63256e-02
I0514 15:28:07.068444 22392998065984 run_lib.py:146] step: 149450, training_loss: 6.24522e-02
I0514 15:28:31.027571 22392998065984 run_lib.py:146] step: 149500, training_loss: 5.58154e-02
I0514 15:28:31.194311 22392998065984 run_lib.py:167] step: 149500, eval_loss: 4.94260e-02
I0514 15:28:55.052853 22392998065984 run_lib.py:146] step: 149550, training_loss: 6.56231e-02
I0514 15:29:18.532237 22392998065984 run_lib.py:146] step: 149600, training_loss: 6.41669e-02
I0514 15:29:18.690312 22392998065984 run_lib.py:167] step: 149600, eval_loss: 4.14329e-02
I0514 15:29:42.146750 22392998065984 run_lib.py:146] step: 149650, training_loss: 4.29515e-02
I0514 15:30:06.196293 22392998065984 run_lib.py:146] step: 149700, training_loss: 6.61746e-02
I0514 15:30:06.354600 22392998065984 run_lib.py:167] step: 149700, eval_loss: 6.02554e-02
I0514 15:30:29.800158 22392998065984 run_lib.py:146] step: 149750, training_loss: 5.60847e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:30:53.383981 22392998065984 run_lib.py:146] step: 149800, training_loss: 5.25335e-02
I0514 15:30:53.544640 22392998065984 run_lib.py:167] step: 149800, eval_loss: 6.15414e-02
I0514 15:31:17.623098 22392998065984 run_lib.py:146] step: 149850, training_loss: 4.23678e-02
I0514 15:31:41.070478 22392998065984 run_lib.py:146] step: 149900, training_loss: 6.13764e-02
I0514 15:31:41.227705 22392998065984 run_lib.py:167] step: 149900, eval_loss: 5.14645e-02
I0514 15:32:04.683822 22392998065984 run_lib.py:146] step: 149950, training_loss: 7.09264e-02
I0514 15:32:28.413353 22392998065984 run_lib.py:146] step: 150000, training_loss: 5.62857e-02
I0514 15:32:35.208247 22392998065984 run_lib.py:167] step: 150000, eval_loss: 7.17768e-02
I0514 15:33:05.364562 22392998065984 run_lib.py:146] step: 150050, training_loss: 6.94884e-02
I0514 15:33:28.810060 22392998065984 run_lib.py:146] step: 150100, training_loss: 6.09537e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:33:29.234135 22392998065984 run_lib.py:167] step: 150100, eval_loss: 6.63057e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:33:53.528372 22392998065984 run_lib.py:146] step: 150150, training_loss: 6.59661e-02
I0514 15:34:17.085791 22392998065984 run_lib.py:146] step: 150200, training_loss: 6.72338e-02
I0514 15:34:17.247329 22392998065984 run_lib.py:167] step: 150200, eval_loss: 4.83528e-02
I0514 15:34:40.794749 22392998065984 run_lib.py:146] step: 150250, training_loss: 4.34487e-02
I0514 15:35:04.880591 22392998065984 run_lib.py:146] step: 150300, training_loss: 5.52339e-02
I0514 15:35:05.040333 22392998065984 run_lib.py:167] step: 150300, eval_loss: 5.74131e-02
I0514 15:35:28.509866 22392998065984 run_lib.py:146] step: 150350, training_loss: 6.07679e-02
I0514 15:35:51.981275 22392998065984 run_lib.py:146] step: 150400, training_loss: 5.71098e-02
I0514 15:35:52.139523 22392998065984 run_lib.py:167] step: 150400, eval_loss: 4.98496e-02
I0514 15:36:16.169592 22392998065984 run_lib.py:146] step: 150450, training_loss: 5.30691e-02
I0514 15:36:39.656800 22392998065984 run_lib.py:146] step: 150500, training_loss: 7.17898e-02
I0514 15:36:39.814852 22392998065984 run_lib.py:167] step: 150500, eval_loss: 5.56038e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:37:03.641437 22392998065984 run_lib.py:146] step: 150550, training_loss: 5.66515e-02
I0514 15:37:27.424014 22392998065984 run_lib.py:146] step: 150600, training_loss: 5.28555e-02
I0514 15:37:27.583920 22392998065984 run_lib.py:167] step: 150600, eval_loss: 6.48179e-02
I0514 15:37:51.346637 22392998065984 run_lib.py:146] step: 150650, training_loss: 6.18107e-02
I0514 15:38:14.780859 22392998065984 run_lib.py:146] step: 150700, training_loss: 5.03932e-02
I0514 15:38:14.938858 22392998065984 run_lib.py:167] step: 150700, eval_loss: 6.70520e-02
I0514 15:38:39.040946 22392998065984 run_lib.py:146] step: 150750, training_loss: 7.63819e-02
I0514 15:39:03.656425 22392998065984 run_lib.py:146] step: 150800, training_loss: 5.53047e-02
I0514 15:39:03.815371 22392998065984 run_lib.py:167] step: 150800, eval_loss: 7.24293e-02
I0514 15:39:27.289615 22392998065984 run_lib.py:146] step: 150850, training_loss: 5.56888e-02
I0514 15:39:50.764045 22392998065984 run_lib.py:146] step: 150900, training_loss: 6.80031e-02
I0514 15:39:50.923209 22392998065984 run_lib.py:167] step: 150900, eval_loss: 6.52875e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:40:15.134928 22392998065984 run_lib.py:146] step: 150950, training_loss: 7.02107e-02
I0514 15:40:38.614961 22392998065984 run_lib.py:146] step: 151000, training_loss: 5.17169e-02
I0514 15:40:38.775199 22392998065984 run_lib.py:167] step: 151000, eval_loss: 5.71980e-02
I0514 15:41:02.616555 22392998065984 run_lib.py:146] step: 151050, training_loss: 6.86449e-02
I0514 15:41:27.305727 22392998065984 run_lib.py:146] step: 151100, training_loss: 6.08418e-02
I0514 15:41:27.471783 22392998065984 run_lib.py:167] step: 151100, eval_loss: 6.91024e-02
I0514 15:41:51.582334 22392998065984 run_lib.py:146] step: 151150, training_loss: 4.70808e-02
I0514 15:42:15.694268 22392998065984 run_lib.py:146] step: 151200, training_loss: 4.37479e-02
I0514 15:42:15.861696 22392998065984 run_lib.py:167] step: 151200, eval_loss: 5.51928e-02
I0514 15:42:40.263875 22392998065984 run_lib.py:146] step: 151250, training_loss: 5.82479e-02
I0514 15:43:04.627884 22392998065984 run_lib.py:146] step: 151300, training_loss: 7.39715e-02
I0514 15:43:04.793913 22392998065984 run_lib.py:167] step: 151300, eval_loss: 7.82803e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:43:29.024983 22392998065984 run_lib.py:146] step: 151350, training_loss: 6.85122e-02
I0514 15:43:53.479891 22392998065984 run_lib.py:146] step: 151400, training_loss: 7.22135e-02
I0514 15:43:53.647085 22392998065984 run_lib.py:167] step: 151400, eval_loss: 4.54633e-02
I0514 15:44:18.044498 22392998065984 run_lib.py:146] step: 151450, training_loss: 6.69296e-02
I0514 15:44:42.138646 22392998065984 run_lib.py:146] step: 151500, training_loss: 6.50835e-02
I0514 15:44:42.304806 22392998065984 run_lib.py:167] step: 151500, eval_loss: 6.32890e-02
I0514 15:45:06.407359 22392998065984 run_lib.py:146] step: 151550, training_loss: 6.17602e-02
I0514 15:45:30.391219 22392998065984 run_lib.py:146] step: 151600, training_loss: 4.68370e-02
I0514 15:45:30.550156 22392998065984 run_lib.py:167] step: 151600, eval_loss: 5.05999e-02
I0514 15:45:53.998231 22392998065984 run_lib.py:146] step: 151650, training_loss: 5.61163e-02
I0514 15:46:17.457441 22392998065984 run_lib.py:146] step: 151700, training_loss: 4.65998e-02
I0514 15:46:17.615535 22392998065984 run_lib.py:167] step: 151700, eval_loss: 7.47590e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:46:42.409388 22392998065984 run_lib.py:146] step: 151750, training_loss: 6.48911e-02
I0514 15:47:05.881811 22392998065984 run_lib.py:146] step: 151800, training_loss: 6.37426e-02
I0514 15:47:06.056609 22392998065984 run_lib.py:167] step: 151800, eval_loss: 6.91751e-02
I0514 15:47:29.512455 22392998065984 run_lib.py:146] step: 151850, training_loss: 5.04967e-02
I0514 15:47:53.529631 22392998065984 run_lib.py:146] step: 151900, training_loss: 5.27821e-02
I0514 15:47:53.687569 22392998065984 run_lib.py:167] step: 151900, eval_loss: 6.03586e-02
I0514 15:48:17.141172 22392998065984 run_lib.py:146] step: 151950, training_loss: 4.22890e-02
I0514 15:48:40.592074 22392998065984 run_lib.py:146] step: 152000, training_loss: 5.22407e-02
I0514 15:48:40.792352 22392998065984 run_lib.py:167] step: 152000, eval_loss: 6.13245e-02
I0514 15:49:04.498425 22392998065984 run_lib.py:146] step: 152050, training_loss: 7.07882e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:49:28.392746 22392998065984 run_lib.py:146] step: 152100, training_loss: 6.02348e-02
I0514 15:49:28.552486 22392998065984 run_lib.py:167] step: 152100, eval_loss: 4.57993e-02
I0514 15:49:52.020471 22392998065984 run_lib.py:146] step: 152150, training_loss: 5.71024e-02
I0514 15:50:15.815908 22392998065984 run_lib.py:146] step: 152200, training_loss: 5.61112e-02
I0514 15:50:15.973982 22392998065984 run_lib.py:167] step: 152200, eval_loss: 5.61081e-02
I0514 15:50:39.747094 22392998065984 run_lib.py:146] step: 152250, training_loss: 4.79129e-02
I0514 15:51:03.282399 22392998065984 run_lib.py:146] step: 152300, training_loss: 5.51943e-02
I0514 15:51:03.449668 22392998065984 run_lib.py:167] step: 152300, eval_loss: 6.12726e-02
I0514 15:51:27.340033 22392998065984 run_lib.py:146] step: 152350, training_loss: 5.42938e-02
I0514 15:51:51.076998 22392998065984 run_lib.py:146] step: 152400, training_loss: 6.31282e-02
I0514 15:51:51.235574 22392998065984 run_lib.py:167] step: 152400, eval_loss: 6.60387e-02
I0514 15:52:14.840930 22392998065984 run_lib.py:146] step: 152450, training_loss: 5.17351e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:52:38.474795 22392998065984 run_lib.py:146] step: 152500, training_loss: 8.77640e-02
I0514 15:52:38.634951 22392998065984 run_lib.py:167] step: 152500, eval_loss: 5.24157e-02
I0514 15:53:02.743249 22392998065984 run_lib.py:146] step: 152550, training_loss: 5.56336e-02
I0514 15:53:26.195177 22392998065984 run_lib.py:146] step: 152600, training_loss: 4.93697e-02
I0514 15:53:26.353524 22392998065984 run_lib.py:167] step: 152600, eval_loss: 4.87251e-02
I0514 15:53:49.836538 22392998065984 run_lib.py:146] step: 152650, training_loss: 5.34249e-02
I0514 15:54:13.857648 22392998065984 run_lib.py:146] step: 152700, training_loss: 5.25347e-02
I0514 15:54:14.016215 22392998065984 run_lib.py:167] step: 152700, eval_loss: 6.61081e-02
I0514 15:54:37.443145 22392998065984 run_lib.py:146] step: 152750, training_loss: 9.53450e-02
I0514 15:55:00.888837 22392998065984 run_lib.py:146] step: 152800, training_loss: 6.72402e-02
I0514 15:55:01.047236 22392998065984 run_lib.py:167] step: 152800, eval_loss: 5.56647e-02
I0514 15:55:25.051380 22392998065984 run_lib.py:146] step: 152850, training_loss: 7.36013e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:55:49.610993 22392998065984 run_lib.py:146] step: 152900, training_loss: 5.59518e-02
I0514 15:55:49.779407 22392998065984 run_lib.py:167] step: 152900, eval_loss: 6.78222e-02
I0514 15:56:13.875884 22392998065984 run_lib.py:146] step: 152950, training_loss: 4.62635e-02
I0514 15:56:38.310560 22392998065984 run_lib.py:146] step: 153000, training_loss: 3.88127e-02
I0514 15:56:38.478370 22392998065984 run_lib.py:167] step: 153000, eval_loss: 4.41434e-02
I0514 15:57:02.875495 22392998065984 run_lib.py:146] step: 153050, training_loss: 5.87087e-02
I0514 15:57:26.976866 22392998065984 run_lib.py:146] step: 153100, training_loss: 7.60676e-02
I0514 15:57:27.143593 22392998065984 run_lib.py:167] step: 153100, eval_loss: 5.44589e-02
I0514 15:57:51.567288 22392998065984 run_lib.py:146] step: 153150, training_loss: 6.94300e-02
I0514 15:58:15.942309 22392998065984 run_lib.py:146] step: 153200, training_loss: 6.80950e-02
I0514 15:58:16.108991 22392998065984 run_lib.py:167] step: 153200, eval_loss: 5.64471e-02
I0514 15:58:40.232978 22392998065984 run_lib.py:146] step: 153250, training_loss: 5.79609e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 15:59:04.107473 22392998065984 run_lib.py:146] step: 153300, training_loss: 6.45421e-02
I0514 15:59:04.267924 22392998065984 run_lib.py:167] step: 153300, eval_loss: 6.27139e-02
I0514 15:59:28.376205 22392998065984 run_lib.py:146] step: 153350, training_loss: 5.24157e-02
I0514 15:59:51.839492 22392998065984 run_lib.py:146] step: 153400, training_loss: 3.95396e-02
I0514 15:59:51.998236 22392998065984 run_lib.py:167] step: 153400, eval_loss: 7.02127e-02
I0514 16:00:15.455492 22392998065984 run_lib.py:146] step: 153450, training_loss: 5.80501e-02
I0514 16:00:39.512111 22392998065984 run_lib.py:146] step: 153500, training_loss: 4.08091e-02
I0514 16:00:39.670599 22392998065984 run_lib.py:167] step: 153500, eval_loss: 5.75430e-02
I0514 16:01:03.120299 22392998065984 run_lib.py:146] step: 153550, training_loss: 4.47346e-02
I0514 16:01:26.560853 22392998065984 run_lib.py:146] step: 153600, training_loss: 6.61075e-02
I0514 16:01:26.718646 22392998065984 run_lib.py:167] step: 153600, eval_loss: 6.87037e-02
I0514 16:01:50.453985 22392998065984 run_lib.py:146] step: 153650, training_loss: 4.47524e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:02:14.389095 22392998065984 run_lib.py:146] step: 153700, training_loss: 5.74936e-02
I0514 16:02:14.551007 22392998065984 run_lib.py:167] step: 153700, eval_loss: 5.57173e-02
I0514 16:02:38.020184 22392998065984 run_lib.py:146] step: 153750, training_loss: 7.06012e-02
I0514 16:03:01.836629 22392998065984 run_lib.py:146] step: 153800, training_loss: 5.65994e-02
I0514 16:03:01.994643 22392998065984 run_lib.py:167] step: 153800, eval_loss: 5.46117e-02
I0514 16:03:25.739195 22392998065984 run_lib.py:146] step: 153850, training_loss: 5.22451e-02
I0514 16:03:49.201959 22392998065984 run_lib.py:146] step: 153900, training_loss: 8.12563e-02
I0514 16:03:49.361478 22392998065984 run_lib.py:167] step: 153900, eval_loss: 6.12050e-02
I0514 16:04:13.100322 22392998065984 run_lib.py:146] step: 153950, training_loss: 5.60697e-02
I0514 16:04:36.814565 22392998065984 run_lib.py:146] step: 154000, training_loss: 5.54781e-02
I0514 16:04:36.987943 22392998065984 run_lib.py:167] step: 154000, eval_loss: 6.53805e-02
I0514 16:05:00.455237 22392998065984 run_lib.py:146] step: 154050, training_loss: 6.31019e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:05:24.997757 22392998065984 run_lib.py:146] step: 154100, training_loss: 6.02431e-02
I0514 16:05:25.165673 22392998065984 run_lib.py:167] step: 154100, eval_loss: 6.81276e-02
I0514 16:05:49.581571 22392998065984 run_lib.py:146] step: 154150, training_loss: 5.51487e-02
I0514 16:06:13.180198 22392998065984 run_lib.py:146] step: 154200, training_loss: 5.86333e-02
I0514 16:06:13.339250 22392998065984 run_lib.py:167] step: 154200, eval_loss: 4.06623e-02
I0514 16:06:36.798835 22392998065984 run_lib.py:146] step: 154250, training_loss: 6.13280e-02
I0514 16:07:00.816834 22392998065984 run_lib.py:146] step: 154300, training_loss: 6.12594e-02
I0514 16:07:00.975014 22392998065984 run_lib.py:167] step: 154300, eval_loss: 6.76673e-02
I0514 16:07:24.449507 22392998065984 run_lib.py:146] step: 154350, training_loss: 5.19844e-02
I0514 16:07:47.928201 22392998065984 run_lib.py:146] step: 154400, training_loss: 4.80921e-02
I0514 16:07:48.088668 22392998065984 run_lib.py:167] step: 154400, eval_loss: 4.43976e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:08:12.126650 22392998065984 run_lib.py:146] step: 154450, training_loss: 6.02371e-02
I0514 16:08:36.545054 22392998065984 run_lib.py:146] step: 154500, training_loss: 6.15895e-02
I0514 16:08:36.713049 22392998065984 run_lib.py:167] step: 154500, eval_loss: 6.17703e-02
I0514 16:09:00.801545 22392998065984 run_lib.py:146] step: 154550, training_loss: 6.09369e-02
I0514 16:09:25.229130 22392998065984 run_lib.py:146] step: 154600, training_loss: 6.75788e-02
I0514 16:09:25.395636 22392998065984 run_lib.py:167] step: 154600, eval_loss: 6.17403e-02
I0514 16:09:49.773739 22392998065984 run_lib.py:146] step: 154650, training_loss: 5.48184e-02
I0514 16:10:13.892178 22392998065984 run_lib.py:146] step: 154700, training_loss: 6.97171e-02
I0514 16:10:14.061473 22392998065984 run_lib.py:167] step: 154700, eval_loss: 5.13544e-02
I0514 16:10:38.472898 22392998065984 run_lib.py:146] step: 154750, training_loss: 7.95171e-02
I0514 16:11:02.832645 22392998065984 run_lib.py:146] step: 154800, training_loss: 5.94434e-02
I0514 16:11:02.998700 22392998065984 run_lib.py:167] step: 154800, eval_loss: 7.45426e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:11:27.234248 22392998065984 run_lib.py:146] step: 154850, training_loss: 6.45151e-02
I0514 16:11:51.689582 22392998065984 run_lib.py:146] step: 154900, training_loss: 5.11540e-02
I0514 16:11:51.857425 22392998065984 run_lib.py:167] step: 154900, eval_loss: 5.42077e-02
I0514 16:12:16.274832 22392998065984 run_lib.py:146] step: 154950, training_loss: 5.82677e-02
I0514 16:12:40.358705 22392998065984 run_lib.py:146] step: 155000, training_loss: 5.35008e-02
I0514 16:12:40.526307 22392998065984 run_lib.py:167] step: 155000, eval_loss: 6.49816e-02
I0514 16:13:04.651005 22392998065984 run_lib.py:146] step: 155050, training_loss: 5.22804e-02
I0514 16:13:29.331699 22392998065984 run_lib.py:146] step: 155100, training_loss: 4.68473e-02
I0514 16:13:29.499548 22392998065984 run_lib.py:167] step: 155100, eval_loss: 4.99948e-02
I0514 16:13:53.604663 22392998065984 run_lib.py:146] step: 155150, training_loss: 6.50315e-02
I0514 16:14:17.728060 22392998065984 run_lib.py:146] step: 155200, training_loss: 6.14487e-02
I0514 16:14:17.894487 22392998065984 run_lib.py:167] step: 155200, eval_loss: 5.63406e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:14:42.436774 22392998065984 run_lib.py:146] step: 155250, training_loss: 6.00282e-02
I0514 16:15:05.909387 22392998065984 run_lib.py:146] step: 155300, training_loss: 7.93018e-02
I0514 16:15:06.069143 22392998065984 run_lib.py:167] step: 155300, eval_loss: 8.20256e-02
I0514 16:15:29.549046 22392998065984 run_lib.py:146] step: 155350, training_loss: 7.25574e-02
I0514 16:15:53.772942 22392998065984 run_lib.py:146] step: 155400, training_loss: 6.01178e-02
I0514 16:15:53.939586 22392998065984 run_lib.py:167] step: 155400, eval_loss: 7.06494e-02
I0514 16:16:18.283949 22392998065984 run_lib.py:146] step: 155450, training_loss: 5.09760e-02
I0514 16:16:42.388484 22392998065984 run_lib.py:146] step: 155500, training_loss: 7.85251e-02
I0514 16:16:42.555270 22392998065984 run_lib.py:167] step: 155500, eval_loss: 5.62715e-02
I0514 16:17:06.976764 22392998065984 run_lib.py:146] step: 155550, training_loss: 6.04114e-02
I0514 16:17:31.354197 22392998065984 run_lib.py:146] step: 155600, training_loss: 8.50787e-02
I0514 16:17:31.552448 22392998065984 run_lib.py:167] step: 155600, eval_loss: 5.00850e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:17:55.801271 22392998065984 run_lib.py:146] step: 155650, training_loss: 5.65856e-02
I0514 16:18:20.259706 22392998065984 run_lib.py:146] step: 155700, training_loss: 6.35696e-02
I0514 16:18:20.428174 22392998065984 run_lib.py:167] step: 155700, eval_loss: 8.03473e-02
I0514 16:18:44.808385 22392998065984 run_lib.py:146] step: 155750, training_loss: 4.86265e-02
I0514 16:19:08.932002 22392998065984 run_lib.py:146] step: 155800, training_loss: 7.51990e-02
I0514 16:19:09.098685 22392998065984 run_lib.py:167] step: 155800, eval_loss: 5.09516e-02
I0514 16:19:33.211202 22392998065984 run_lib.py:146] step: 155850, training_loss: 5.92447e-02
I0514 16:19:57.859570 22392998065984 run_lib.py:146] step: 155900, training_loss: 5.92349e-02
I0514 16:19:58.026181 22392998065984 run_lib.py:167] step: 155900, eval_loss: 6.41279e-02
I0514 16:20:22.122355 22392998065984 run_lib.py:146] step: 155950, training_loss: 6.65601e-02
I0514 16:20:45.764625 22392998065984 run_lib.py:146] step: 156000, training_loss: 5.36718e-02
I0514 16:20:45.923306 22392998065984 run_lib.py:167] step: 156000, eval_loss: 5.92037e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:21:10.200102 22392998065984 run_lib.py:146] step: 156050, training_loss: 5.00448e-02
I0514 16:21:33.651744 22392998065984 run_lib.py:146] step: 156100, training_loss: 6.43741e-02
I0514 16:21:33.811146 22392998065984 run_lib.py:167] step: 156100, eval_loss: 5.73760e-02
I0514 16:21:57.250694 22392998065984 run_lib.py:146] step: 156150, training_loss: 5.85511e-02
I0514 16:22:20.984270 22392998065984 run_lib.py:146] step: 156200, training_loss: 5.99958e-02
I0514 16:22:21.142379 22392998065984 run_lib.py:167] step: 156200, eval_loss: 7.54896e-02
I0514 16:22:44.856519 22392998065984 run_lib.py:146] step: 156250, training_loss: 6.95758e-02
I0514 16:23:08.302715 22392998065984 run_lib.py:146] step: 156300, training_loss: 6.95985e-02
I0514 16:23:08.476055 22392998065984 run_lib.py:167] step: 156300, eval_loss: 7.52354e-02
I0514 16:23:32.234594 22392998065984 run_lib.py:146] step: 156350, training_loss: 5.74016e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:23:56.090526 22392998065984 run_lib.py:146] step: 156400, training_loss: 4.61297e-02
I0514 16:23:56.251247 22392998065984 run_lib.py:167] step: 156400, eval_loss: 7.04875e-02
I0514 16:24:19.724646 22392998065984 run_lib.py:146] step: 156450, training_loss: 5.13688e-02
I0514 16:24:43.544363 22392998065984 run_lib.py:146] step: 156500, training_loss: 6.53659e-02
I0514 16:24:43.702289 22392998065984 run_lib.py:167] step: 156500, eval_loss: 5.87813e-02
I0514 16:25:07.466591 22392998065984 run_lib.py:146] step: 156550, training_loss: 4.96419e-02
I0514 16:25:30.924631 22392998065984 run_lib.py:146] step: 156600, training_loss: 6.57063e-02
I0514 16:25:31.082913 22392998065984 run_lib.py:167] step: 156600, eval_loss: 6.59462e-02
I0514 16:25:54.512342 22392998065984 run_lib.py:146] step: 156650, training_loss: 6.10460e-02
I0514 16:26:18.531289 22392998065984 run_lib.py:146] step: 156700, training_loss: 4.96821e-02
I0514 16:26:18.690287 22392998065984 run_lib.py:167] step: 156700, eval_loss: 6.78903e-02
I0514 16:26:42.132871 22392998065984 run_lib.py:146] step: 156750, training_loss: 7.74388e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:27:05.753427 22392998065984 run_lib.py:146] step: 156800, training_loss: 4.65230e-02
I0514 16:27:05.913584 22392998065984 run_lib.py:167] step: 156800, eval_loss: 6.06431e-02
I0514 16:27:29.999980 22392998065984 run_lib.py:146] step: 156850, training_loss: 6.93394e-02
I0514 16:27:53.449256 22392998065984 run_lib.py:146] step: 156900, training_loss: 6.00753e-02
I0514 16:27:53.607285 22392998065984 run_lib.py:167] step: 156900, eval_loss: 4.94965e-02
I0514 16:28:17.054049 22392998065984 run_lib.py:146] step: 156950, training_loss: 6.70807e-02
I0514 16:28:41.068768 22392998065984 run_lib.py:146] step: 157000, training_loss: 5.98270e-02
I0514 16:28:41.227890 22392998065984 run_lib.py:167] step: 157000, eval_loss: 6.33992e-02
I0514 16:29:04.851143 22392998065984 run_lib.py:146] step: 157050, training_loss: 5.72159e-02
I0514 16:29:28.946513 22392998065984 run_lib.py:146] step: 157100, training_loss: 5.02695e-02
I0514 16:29:29.114647 22392998065984 run_lib.py:167] step: 157100, eval_loss: 6.63994e-02
I0514 16:29:53.519834 22392998065984 run_lib.py:146] step: 157150, training_loss: 5.37788e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:30:17.787956 22392998065984 run_lib.py:146] step: 157200, training_loss: 6.80041e-02
I0514 16:30:17.971142 22392998065984 run_lib.py:167] step: 157200, eval_loss: 5.18930e-02
I0514 16:30:41.415099 22392998065984 run_lib.py:146] step: 157250, training_loss: 5.67917e-02
I0514 16:31:05.204848 22392998065984 run_lib.py:146] step: 157300, training_loss: 5.50948e-02
I0514 16:31:05.362556 22392998065984 run_lib.py:167] step: 157300, eval_loss: 5.17051e-02
I0514 16:31:29.108561 22392998065984 run_lib.py:146] step: 157350, training_loss: 4.88101e-02
I0514 16:31:52.557718 22392998065984 run_lib.py:146] step: 157400, training_loss: 6.77001e-02
I0514 16:31:52.716296 22392998065984 run_lib.py:167] step: 157400, eval_loss: 7.99710e-02
I0514 16:32:16.157889 22392998065984 run_lib.py:146] step: 157450, training_loss: 5.22773e-02
I0514 16:32:40.164834 22392998065984 run_lib.py:146] step: 157500, training_loss: 5.00143e-02
I0514 16:32:40.322977 22392998065984 run_lib.py:167] step: 157500, eval_loss: 4.63989e-02
I0514 16:33:03.911090 22392998065984 run_lib.py:146] step: 157550, training_loss: 7.06793e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:33:27.689551 22392998065984 run_lib.py:146] step: 157600, training_loss: 5.21674e-02
I0514 16:33:27.849919 22392998065984 run_lib.py:167] step: 157600, eval_loss: 6.38237e-02
I0514 16:33:51.922027 22392998065984 run_lib.py:146] step: 157650, training_loss: 7.67964e-02
I0514 16:34:15.390826 22392998065984 run_lib.py:146] step: 157700, training_loss: 5.37105e-02
I0514 16:34:15.558640 22392998065984 run_lib.py:167] step: 157700, eval_loss: 4.92199e-02
I0514 16:34:39.484957 22392998065984 run_lib.py:146] step: 157750, training_loss: 5.37904e-02
I0514 16:35:04.053961 22392998065984 run_lib.py:146] step: 157800, training_loss: 4.56435e-02
I0514 16:35:04.219594 22392998065984 run_lib.py:167] step: 157800, eval_loss: 6.56058e-02
I0514 16:35:28.313954 22392998065984 run_lib.py:146] step: 157850, training_loss: 4.83528e-02
I0514 16:35:52.420067 22392998065984 run_lib.py:146] step: 157900, training_loss: 5.76033e-02
I0514 16:35:52.527213 22392998065984 run_lib.py:167] step: 157900, eval_loss: 6.97654e-02
I0514 16:36:17.026141 22392998065984 run_lib.py:146] step: 157950, training_loss: 3.99525e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:36:41.525436 22392998065984 run_lib.py:146] step: 158000, training_loss: 4.60120e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:36:41.940094 22392998065984 run_lib.py:167] step: 158000, eval_loss: 6.16060e-02
I0514 16:37:05.414116 22392998065984 run_lib.py:146] step: 158050, training_loss: 5.31226e-02
I0514 16:37:29.233663 22392998065984 run_lib.py:146] step: 158100, training_loss: 5.26216e-02
I0514 16:37:29.391764 22392998065984 run_lib.py:167] step: 158100, eval_loss: 6.88867e-02
I0514 16:37:53.146524 22392998065984 run_lib.py:146] step: 158150, training_loss: 5.99160e-02
I0514 16:38:16.582380 22392998065984 run_lib.py:146] step: 158200, training_loss: 5.41067e-02
I0514 16:38:16.741096 22392998065984 run_lib.py:167] step: 158200, eval_loss: 6.23057e-02
I0514 16:38:40.202194 22392998065984 run_lib.py:146] step: 158250, training_loss: 3.70641e-02
I0514 16:39:04.239227 22392998065984 run_lib.py:146] step: 158300, training_loss: 5.88632e-02
I0514 16:39:04.405719 22392998065984 run_lib.py:167] step: 158300, eval_loss: 7.01095e-02
I0514 16:39:28.506150 22392998065984 run_lib.py:146] step: 158350, training_loss: 5.95546e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:39:52.361332 22392998065984 run_lib.py:146] step: 158400, training_loss: 5.59411e-02
I0514 16:39:52.521224 22392998065984 run_lib.py:167] step: 158400, eval_loss: 5.07319e-02
I0514 16:40:16.602114 22392998065984 run_lib.py:146] step: 158450, training_loss: 6.07891e-02
I0514 16:40:40.072538 22392998065984 run_lib.py:146] step: 158500, training_loss: 5.17353e-02
I0514 16:40:40.257549 22392998065984 run_lib.py:167] step: 158500, eval_loss: 7.00389e-02
I0514 16:41:03.717023 22392998065984 run_lib.py:146] step: 158550, training_loss: 6.53641e-02
I0514 16:41:27.454715 22392998065984 run_lib.py:146] step: 158600, training_loss: 5.94000e-02
I0514 16:41:27.612928 22392998065984 run_lib.py:167] step: 158600, eval_loss: 7.65061e-02
I0514 16:41:51.325160 22392998065984 run_lib.py:146] step: 158650, training_loss: 7.83671e-02
I0514 16:42:14.758445 22392998065984 run_lib.py:146] step: 158700, training_loss: 7.50610e-02
I0514 16:42:14.916413 22392998065984 run_lib.py:167] step: 158700, eval_loss: 5.26964e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:42:38.796376 22392998065984 run_lib.py:146] step: 158750, training_loss: 6.41796e-02
I0514 16:43:02.563142 22392998065984 run_lib.py:146] step: 158800, training_loss: 5.32553e-02
I0514 16:43:02.736887 22392998065984 run_lib.py:167] step: 158800, eval_loss: 5.97504e-02
I0514 16:43:26.216516 22392998065984 run_lib.py:146] step: 158850, training_loss: 5.15550e-02
I0514 16:43:50.085633 22392998065984 run_lib.py:146] step: 158900, training_loss: 7.58599e-02
I0514 16:43:50.248704 22392998065984 run_lib.py:167] step: 158900, eval_loss: 6.17508e-02
I0514 16:44:13.965375 22392998065984 run_lib.py:146] step: 158950, training_loss: 7.19903e-02
I0514 16:44:38.165628 22392998065984 run_lib.py:146] step: 159000, training_loss: 5.68476e-02
I0514 16:44:38.334415 22392998065984 run_lib.py:167] step: 159000, eval_loss: 6.56137e-02
I0514 16:45:03.079207 22392998065984 run_lib.py:146] step: 159050, training_loss: 5.13238e-02
I0514 16:45:27.538843 22392998065984 run_lib.py:146] step: 159100, training_loss: 1.00423e-01
I0514 16:45:27.707297 22392998065984 run_lib.py:167] step: 159100, eval_loss: 7.72518e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:45:51.908049 22392998065984 run_lib.py:146] step: 159150, training_loss: 6.41199e-02
I0514 16:46:15.491333 22392998065984 run_lib.py:146] step: 159200, training_loss: 6.80872e-02
I0514 16:46:15.652331 22392998065984 run_lib.py:167] step: 159200, eval_loss: 6.28506e-02
I0514 16:46:39.902716 22392998065984 run_lib.py:146] step: 159250, training_loss: 6.96926e-02
I0514 16:47:03.488235 22392998065984 run_lib.py:146] step: 159300, training_loss: 7.10522e-02
I0514 16:47:03.647869 22392998065984 run_lib.py:167] step: 159300, eval_loss: 7.18620e-02
I0514 16:47:27.244472 22392998065984 run_lib.py:146] step: 159350, training_loss: 7.54651e-02
I0514 16:47:51.092627 22392998065984 run_lib.py:146] step: 159400, training_loss: 5.87971e-02
I0514 16:47:51.251536 22392998065984 run_lib.py:167] step: 159400, eval_loss: 5.61280e-02
I0514 16:48:15.081845 22392998065984 run_lib.py:146] step: 159450, training_loss: 4.84027e-02
I0514 16:48:38.574103 22392998065984 run_lib.py:146] step: 159500, training_loss: 5.11889e-02
I0514 16:48:38.732875 22392998065984 run_lib.py:167] step: 159500, eval_loss: 6.13400e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:49:02.975900 22392998065984 run_lib.py:146] step: 159550, training_loss: 7.28921e-02
I0514 16:49:26.761311 22392998065984 run_lib.py:146] step: 159600, training_loss: 6.47718e-02
I0514 16:49:26.920690 22392998065984 run_lib.py:167] step: 159600, eval_loss: 7.07464e-02
I0514 16:49:50.644470 22392998065984 run_lib.py:146] step: 159650, training_loss: 5.73969e-02
I0514 16:50:15.062124 22392998065984 run_lib.py:146] step: 159700, training_loss: 6.51069e-02
I0514 16:50:15.228405 22392998065984 run_lib.py:167] step: 159700, eval_loss: 9.21536e-02
I0514 16:50:39.603804 22392998065984 run_lib.py:146] step: 159750, training_loss: 7.95706e-02
I0514 16:51:03.728775 22392998065984 run_lib.py:146] step: 159800, training_loss: 5.56943e-02
I0514 16:51:03.895873 22392998065984 run_lib.py:167] step: 159800, eval_loss: 5.98359e-02
I0514 16:51:28.130878 22392998065984 run_lib.py:146] step: 159850, training_loss: 6.74622e-02
I0514 16:51:51.888151 22392998065984 run_lib.py:146] step: 159900, training_loss: 6.15922e-02
I0514 16:51:52.046444 22392998065984 run_lib.py:167] step: 159900, eval_loss: 5.20216e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:52:15.643351 22392998065984 run_lib.py:146] step: 159950, training_loss: 6.39259e-02
I0514 16:52:39.094210 22392998065984 run_lib.py:146] step: 160000, training_loss: 6.49725e-02
I0514 16:52:41.058144 22392998065984 run_lib.py:167] step: 160000, eval_loss: 6.49611e-02
I0514 16:53:06.268592 22392998065984 run_lib.py:146] step: 160050, training_loss: 5.45854e-02
I0514 16:53:29.720959 22392998065984 run_lib.py:146] step: 160100, training_loss: 7.38313e-02
I0514 16:53:29.878997 22392998065984 run_lib.py:167] step: 160100, eval_loss: 6.67895e-02
I0514 16:53:53.625002 22392998065984 run_lib.py:146] step: 160150, training_loss: 6.31931e-02
I0514 16:54:17.355892 22392998065984 run_lib.py:146] step: 160200, training_loss: 5.85691e-02
I0514 16:54:17.514577 22392998065984 run_lib.py:167] step: 160200, eval_loss: 5.14464e-02
I0514 16:54:40.975996 22392998065984 run_lib.py:146] step: 160250, training_loss: 5.96024e-02
I0514 16:55:04.725320 22392998065984 run_lib.py:146] step: 160300, training_loss: 5.93039e-02
I0514 16:55:04.884166 22392998065984 run_lib.py:167] step: 160300, eval_loss: 6.40233e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:55:28.818886 22392998065984 run_lib.py:146] step: 160350, training_loss: 5.96108e-02
I0514 16:55:52.589153 22392998065984 run_lib.py:146] step: 160400, training_loss: 6.80304e-02
I0514 16:55:52.753249 22392998065984 run_lib.py:167] step: 160400, eval_loss: 5.47339e-02
I0514 16:56:16.564161 22392998065984 run_lib.py:146] step: 160450, training_loss: 5.85372e-02
I0514 16:56:40.042760 22392998065984 run_lib.py:146] step: 160500, training_loss: 6.17392e-02
I0514 16:56:40.200683 22392998065984 run_lib.py:167] step: 160500, eval_loss: 7.83979e-02
I0514 16:57:03.923580 22392998065984 run_lib.py:146] step: 160550, training_loss: 7.61812e-02
I0514 16:57:27.684162 22392998065984 run_lib.py:146] step: 160600, training_loss: 6.32222e-02
I0514 16:57:27.842261 22392998065984 run_lib.py:167] step: 160600, eval_loss: 5.27143e-02
I0514 16:57:51.311684 22392998065984 run_lib.py:146] step: 160650, training_loss: 4.92573e-02
I0514 16:58:14.918143 22392998065984 run_lib.py:146] step: 160700, training_loss: 6.21942e-02
I0514 16:58:15.076158 22392998065984 run_lib.py:167] step: 160700, eval_loss: 7.46244e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 16:58:38.810179 22392998065984 run_lib.py:146] step: 160750, training_loss: 5.89949e-02
I0514 16:59:02.609171 22392998065984 run_lib.py:146] step: 160800, training_loss: 5.99551e-02
I0514 16:59:02.768126 22392998065984 run_lib.py:167] step: 160800, eval_loss: 5.35059e-02
I0514 16:59:26.503302 22392998065984 run_lib.py:146] step: 160850, training_loss: 6.24536e-02
I0514 16:59:49.953278 22392998065984 run_lib.py:146] step: 160900, training_loss: 5.56884e-02
I0514 16:59:50.111544 22392998065984 run_lib.py:167] step: 160900, eval_loss: 5.61190e-02
I0514 17:00:13.850610 22392998065984 run_lib.py:146] step: 160950, training_loss: 6.90798e-02
I0514 17:00:37.564992 22392998065984 run_lib.py:146] step: 161000, training_loss: 5.71379e-02
I0514 17:00:37.723374 22392998065984 run_lib.py:167] step: 161000, eval_loss: 7.01624e-02
I0514 17:01:01.185981 22392998065984 run_lib.py:146] step: 161050, training_loss: 5.99084e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:01:25.068702 22392998065984 run_lib.py:146] step: 161100, training_loss: 5.24087e-02
I0514 17:01:25.228359 22392998065984 run_lib.py:167] step: 161100, eval_loss: 5.21512e-02
I0514 17:01:48.697901 22392998065984 run_lib.py:146] step: 161150, training_loss: 6.50903e-02
I0514 17:02:12.474231 22392998065984 run_lib.py:146] step: 161200, training_loss: 6.23485e-02
I0514 17:02:12.633195 22392998065984 run_lib.py:167] step: 161200, eval_loss: 7.40995e-02
I0514 17:02:36.397612 22392998065984 run_lib.py:146] step: 161250, training_loss: 7.19389e-02
I0514 17:02:59.864361 22392998065984 run_lib.py:146] step: 161300, training_loss: 7.67619e-02
I0514 17:03:00.022721 22392998065984 run_lib.py:167] step: 161300, eval_loss: 7.34673e-02
I0514 17:03:23.745567 22392998065984 run_lib.py:146] step: 161350, training_loss: 5.23856e-02
I0514 17:03:47.674301 22392998065984 run_lib.py:146] step: 161400, training_loss: 4.79672e-02
I0514 17:03:48.135843 22392998065984 run_lib.py:167] step: 161400, eval_loss: 7.36741e-02
I0514 17:04:12.264698 22392998065984 run_lib.py:146] step: 161450, training_loss: 7.43409e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:04:36.530328 22392998065984 run_lib.py:146] step: 161500, training_loss: 4.33333e-02
I0514 17:04:36.690304 22392998065984 run_lib.py:167] step: 161500, eval_loss: 5.64768e-02
I0514 17:05:00.138214 22392998065984 run_lib.py:146] step: 161550, training_loss: 5.61355e-02
I0514 17:05:23.930153 22392998065984 run_lib.py:146] step: 161600, training_loss: 5.84228e-02
I0514 17:05:24.088212 22392998065984 run_lib.py:167] step: 161600, eval_loss: 5.62347e-02
I0514 17:05:47.842753 22392998065984 run_lib.py:146] step: 161650, training_loss: 5.76585e-02
I0514 17:06:11.281517 22392998065984 run_lib.py:146] step: 161700, training_loss: 5.70973e-02
I0514 17:06:11.439582 22392998065984 run_lib.py:167] step: 161700, eval_loss: 6.75242e-02
I0514 17:06:35.186420 22392998065984 run_lib.py:146] step: 161750, training_loss: 7.05240e-02
I0514 17:06:58.916542 22392998065984 run_lib.py:146] step: 161800, training_loss: 7.02265e-02
I0514 17:06:59.074745 22392998065984 run_lib.py:167] step: 161800, eval_loss: 4.87048e-02
I0514 17:07:22.520345 22392998065984 run_lib.py:146] step: 161850, training_loss: 6.55794e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:07:46.473008 22392998065984 run_lib.py:146] step: 161900, training_loss: 6.67107e-02
I0514 17:07:46.632577 22392998065984 run_lib.py:167] step: 161900, eval_loss: 5.30915e-02
I0514 17:08:10.067495 22392998065984 run_lib.py:146] step: 161950, training_loss: 5.83524e-02
I0514 17:08:33.836578 22392998065984 run_lib.py:146] step: 162000, training_loss: 4.46783e-02
I0514 17:08:34.001723 22392998065984 run_lib.py:167] step: 162000, eval_loss: 8.40095e-02
I0514 17:08:57.749370 22392998065984 run_lib.py:146] step: 162050, training_loss: 5.56650e-02
I0514 17:09:21.200709 22392998065984 run_lib.py:146] step: 162100, training_loss: 9.00501e-02
I0514 17:09:21.358721 22392998065984 run_lib.py:167] step: 162100, eval_loss: 6.05088e-02
I0514 17:09:45.079862 22392998065984 run_lib.py:146] step: 162150, training_loss: 5.03909e-02
I0514 17:10:08.528758 22392998065984 run_lib.py:146] step: 162200, training_loss: 7.58668e-02
I0514 17:10:08.687399 22392998065984 run_lib.py:167] step: 162200, eval_loss: 5.10718e-02
I0514 17:10:32.419700 22392998065984 run_lib.py:146] step: 162250, training_loss: 6.03900e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:10:56.356913 22392998065984 run_lib.py:146] step: 162300, training_loss: 5.13418e-02
I0514 17:10:56.516833 22392998065984 run_lib.py:167] step: 162300, eval_loss: 6.67963e-02
I0514 17:11:19.991207 22392998065984 run_lib.py:146] step: 162350, training_loss: 6.16065e-02
I0514 17:11:43.750700 22392998065984 run_lib.py:146] step: 162400, training_loss: 5.51242e-02
I0514 17:11:43.908761 22392998065984 run_lib.py:167] step: 162400, eval_loss: 5.56007e-02
I0514 17:12:07.630335 22392998065984 run_lib.py:146] step: 162450, training_loss: 6.29912e-02
I0514 17:12:31.090267 22392998065984 run_lib.py:146] step: 162500, training_loss: 5.71975e-02
I0514 17:12:31.250193 22392998065984 run_lib.py:167] step: 162500, eval_loss: 6.59274e-02
I0514 17:12:55.026023 22392998065984 run_lib.py:146] step: 162550, training_loss: 5.28414e-02
I0514 17:13:18.892187 22392998065984 run_lib.py:146] step: 162600, training_loss: 6.25777e-02
I0514 17:13:19.051987 22392998065984 run_lib.py:167] step: 162600, eval_loss: 7.57775e-02
I0514 17:13:42.657690 22392998065984 run_lib.py:146] step: 162650, training_loss: 4.18202e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:14:06.663483 22392998065984 run_lib.py:146] step: 162700, training_loss: 5.21475e-02
I0514 17:14:06.823729 22392998065984 run_lib.py:167] step: 162700, eval_loss: 5.83432e-02
I0514 17:14:30.603368 22392998065984 run_lib.py:146] step: 162750, training_loss: 6.02056e-02
I0514 17:14:54.105664 22392998065984 run_lib.py:146] step: 162800, training_loss: 4.42507e-02
I0514 17:14:54.264761 22392998065984 run_lib.py:167] step: 162800, eval_loss: 6.66477e-02
I0514 17:15:18.651321 22392998065984 run_lib.py:146] step: 162850, training_loss: 6.09222e-02
I0514 17:15:42.768743 22392998065984 run_lib.py:146] step: 162900, training_loss: 5.42695e-02
I0514 17:15:42.935129 22392998065984 run_lib.py:167] step: 162900, eval_loss: 8.02320e-02
I0514 17:16:06.816376 22392998065984 run_lib.py:146] step: 162950, training_loss: 6.56635e-02
I0514 17:16:30.260168 22392998065984 run_lib.py:146] step: 163000, training_loss: 5.41696e-02
I0514 17:16:30.447402 22392998065984 run_lib.py:167] step: 163000, eval_loss: 6.65572e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:16:54.366451 22392998065984 run_lib.py:146] step: 163050, training_loss: 7.50406e-02
I0514 17:17:18.128837 22392998065984 run_lib.py:146] step: 163100, training_loss: 5.01827e-02
I0514 17:17:18.306555 22392998065984 run_lib.py:167] step: 163100, eval_loss: 6.10913e-02
I0514 17:17:41.751491 22392998065984 run_lib.py:146] step: 163150, training_loss: 5.73239e-02
I0514 17:18:05.542070 22392998065984 run_lib.py:146] step: 163200, training_loss: 4.84316e-02
I0514 17:18:05.701293 22392998065984 run_lib.py:167] step: 163200, eval_loss: 5.95910e-02
I0514 17:18:29.423463 22392998065984 run_lib.py:146] step: 163250, training_loss: 5.32707e-02
I0514 17:18:52.916462 22392998065984 run_lib.py:146] step: 163300, training_loss: 4.80493e-02
I0514 17:18:53.074364 22392998065984 run_lib.py:167] step: 163300, eval_loss: 9.10095e-02
I0514 17:19:16.841956 22392998065984 run_lib.py:146] step: 163350, training_loss: 5.40499e-02
I0514 17:19:40.558985 22392998065984 run_lib.py:146] step: 163400, training_loss: 6.25957e-02
I0514 17:19:40.716880 22392998065984 run_lib.py:167] step: 163400, eval_loss: 5.62926e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:20:04.328010 22392998065984 run_lib.py:146] step: 163450, training_loss: 5.66867e-02
I0514 17:20:28.133340 22392998065984 run_lib.py:146] step: 163500, training_loss: 6.48074e-02
I0514 17:20:28.294050 22392998065984 run_lib.py:167] step: 163500, eval_loss: 6.56180e-02
I0514 17:20:52.045945 22392998065984 run_lib.py:146] step: 163550, training_loss: 7.25896e-02
I0514 17:21:15.538342 22392998065984 run_lib.py:146] step: 163600, training_loss: 6.58463e-02
I0514 17:21:15.711702 22392998065984 run_lib.py:167] step: 163600, eval_loss: 6.53017e-02
I0514 17:21:39.747417 22392998065984 run_lib.py:146] step: 163650, training_loss: 6.21998e-02
I0514 17:22:03.874176 22392998065984 run_lib.py:146] step: 163700, training_loss: 4.79685e-02
I0514 17:22:04.040766 22392998065984 run_lib.py:167] step: 163700, eval_loss: 6.36723e-02
I0514 17:22:28.405663 22392998065984 run_lib.py:146] step: 163750, training_loss: 4.99162e-02
I0514 17:22:52.797637 22392998065984 run_lib.py:146] step: 163800, training_loss: 8.36869e-02
I0514 17:22:52.963854 22392998065984 run_lib.py:167] step: 163800, eval_loss: 4.77211e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:23:16.932474 22392998065984 run_lib.py:146] step: 163850, training_loss: 6.15664e-02
I0514 17:23:40.696661 22392998065984 run_lib.py:146] step: 163900, training_loss: 7.36030e-02
I0514 17:23:40.859535 22392998065984 run_lib.py:167] step: 163900, eval_loss: 6.20202e-02
I0514 17:24:04.303504 22392998065984 run_lib.py:146] step: 163950, training_loss: 5.76375e-02
I0514 17:24:28.105335 22392998065984 run_lib.py:146] step: 164000, training_loss: 5.53805e-02
I0514 17:24:28.264652 22392998065984 run_lib.py:167] step: 164000, eval_loss: 4.99390e-02
I0514 17:24:51.961165 22392998065984 run_lib.py:146] step: 164050, training_loss: 4.98929e-02
I0514 17:25:15.448708 22392998065984 run_lib.py:146] step: 164100, training_loss: 5.41088e-02
I0514 17:25:15.606848 22392998065984 run_lib.py:167] step: 164100, eval_loss: 6.76032e-02
I0514 17:25:39.358088 22392998065984 run_lib.py:146] step: 164150, training_loss: 5.59793e-02
I0514 17:26:03.078938 22392998065984 run_lib.py:146] step: 164200, training_loss: 6.01328e-02
I0514 17:26:03.236515 22392998065984 run_lib.py:167] step: 164200, eval_loss: 6.81694e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:26:27.256953 22392998065984 run_lib.py:146] step: 164250, training_loss: 5.68212e-02
I0514 17:26:51.696757 22392998065984 run_lib.py:146] step: 164300, training_loss: 5.72298e-02
I0514 17:26:51.865748 22392998065984 run_lib.py:167] step: 164300, eval_loss: 8.11312e-02
I0514 17:27:16.274112 22392998065984 run_lib.py:146] step: 164350, training_loss: 5.50837e-02
I0514 17:27:40.390436 22392998065984 run_lib.py:146] step: 164400, training_loss: 4.94205e-02
I0514 17:27:40.557179 22392998065984 run_lib.py:167] step: 164400, eval_loss: 5.77995e-02
I0514 17:28:04.927309 22392998065984 run_lib.py:146] step: 164450, training_loss: 5.45466e-02
I0514 17:28:29.288662 22392998065984 run_lib.py:146] step: 164500, training_loss: 7.47661e-02
I0514 17:28:29.455587 22392998065984 run_lib.py:167] step: 164500, eval_loss: 5.58740e-02
I0514 17:28:53.338425 22392998065984 run_lib.py:146] step: 164550, training_loss: 5.36817e-02
I0514 17:29:17.736976 22392998065984 run_lib.py:146] step: 164600, training_loss: 6.92201e-02
I0514 17:29:17.902958 22392998065984 run_lib.py:167] step: 164600, eval_loss: 5.23174e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:29:41.642091 22392998065984 run_lib.py:146] step: 164650, training_loss: 6.88567e-02
I0514 17:30:05.424973 22392998065984 run_lib.py:146] step: 164700, training_loss: 6.52530e-02
I0514 17:30:05.585194 22392998065984 run_lib.py:167] step: 164700, eval_loss: 6.10609e-02
I0514 17:30:29.051068 22392998065984 run_lib.py:146] step: 164750, training_loss: 7.54065e-02
I0514 17:30:52.847202 22392998065984 run_lib.py:146] step: 164800, training_loss: 4.77611e-02
I0514 17:30:53.070802 22392998065984 run_lib.py:167] step: 164800, eval_loss: 7.40131e-02
I0514 17:31:16.773025 22392998065984 run_lib.py:146] step: 164850, training_loss: 5.08097e-02
I0514 17:31:40.230400 22392998065984 run_lib.py:146] step: 164900, training_loss: 6.42968e-02
I0514 17:31:40.390371 22392998065984 run_lib.py:167] step: 164900, eval_loss: 6.32630e-02
I0514 17:32:04.130200 22392998065984 run_lib.py:146] step: 164950, training_loss: 4.40001e-02
I0514 17:32:27.835587 22392998065984 run_lib.py:146] step: 165000, training_loss: 5.17022e-02
I0514 17:32:27.993458 22392998065984 run_lib.py:167] step: 165000, eval_loss: 5.90595e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:32:52.245560 22392998065984 run_lib.py:146] step: 165050, training_loss: 5.40323e-02
I0514 17:33:16.685190 22392998065984 run_lib.py:146] step: 165100, training_loss: 5.83006e-02
I0514 17:33:16.853581 22392998065984 run_lib.py:167] step: 165100, eval_loss: 5.49751e-02
I0514 17:33:41.262281 22392998065984 run_lib.py:146] step: 165150, training_loss: 6.79702e-02
I0514 17:34:05.393676 22392998065984 run_lib.py:146] step: 165200, training_loss: 7.45170e-02
I0514 17:34:05.561656 22392998065984 run_lib.py:167] step: 165200, eval_loss: 5.38372e-02
I0514 17:34:29.948620 22392998065984 run_lib.py:146] step: 165250, training_loss: 7.59178e-02
I0514 17:34:54.312422 22392998065984 run_lib.py:146] step: 165300, training_loss: 5.22881e-02
I0514 17:34:54.479237 22392998065984 run_lib.py:167] step: 165300, eval_loss: 7.83511e-02
I0514 17:35:18.593835 22392998065984 run_lib.py:146] step: 165350, training_loss: 5.98302e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:35:43.090175 22392998065984 run_lib.py:146] step: 165400, training_loss: 6.59746e-02
I0514 17:35:43.251456 22392998065984 run_lib.py:167] step: 165400, eval_loss: 5.06688e-02
I0514 17:36:06.716906 22392998065984 run_lib.py:146] step: 165450, training_loss: 6.40124e-02
I0514 17:36:30.522201 22392998065984 run_lib.py:146] step: 165500, training_loss: 7.81637e-02
I0514 17:36:30.681222 22392998065984 run_lib.py:167] step: 165500, eval_loss: 5.47022e-02
I0514 17:36:54.144061 22392998065984 run_lib.py:146] step: 165550, training_loss: 6.01767e-02
I0514 17:37:17.912894 22392998065984 run_lib.py:146] step: 165600, training_loss: 6.01641e-02
I0514 17:37:18.071447 22392998065984 run_lib.py:167] step: 165600, eval_loss: 4.40629e-02
I0514 17:37:41.802141 22392998065984 run_lib.py:146] step: 165650, training_loss: 5.82156e-02
I0514 17:38:05.252301 22392998065984 run_lib.py:146] step: 165700, training_loss: 6.05988e-02
I0514 17:38:05.409433 22392998065984 run_lib.py:167] step: 165700, eval_loss: 6.05181e-02
I0514 17:38:29.176895 22392998065984 run_lib.py:146] step: 165750, training_loss: 8.49403e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:38:53.051290 22392998065984 run_lib.py:146] step: 165800, training_loss: 5.89687e-02
I0514 17:38:53.139950 22392998065984 run_lib.py:167] step: 165800, eval_loss: 7.09811e-02
I0514 17:39:16.581468 22392998065984 run_lib.py:146] step: 165850, training_loss: 5.91216e-02
I0514 17:39:40.380554 22392998065984 run_lib.py:146] step: 165900, training_loss: 5.91775e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:39:40.799190 22392998065984 run_lib.py:167] step: 165900, eval_loss: 4.74967e-02
I0514 17:40:04.576139 22392998065984 run_lib.py:146] step: 165950, training_loss: 5.89537e-02
I0514 17:40:28.038908 22392998065984 run_lib.py:146] step: 166000, training_loss: 7.73999e-02
I0514 17:40:28.197096 22392998065984 run_lib.py:167] step: 166000, eval_loss: 7.63978e-02
I0514 17:40:51.985846 22392998065984 run_lib.py:146] step: 166050, training_loss: 6.68180e-02
I0514 17:41:15.696875 22392998065984 run_lib.py:146] step: 166100, training_loss: 4.17023e-02
I0514 17:41:15.854703 22392998065984 run_lib.py:167] step: 166100, eval_loss: 8.25288e-02
I0514 17:41:39.328308 22392998065984 run_lib.py:146] step: 166150, training_loss: 5.04625e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:42:03.294959 22392998065984 run_lib.py:146] step: 166200, training_loss: 6.70135e-02
I0514 17:42:03.454913 22392998065984 run_lib.py:167] step: 166200, eval_loss: 6.15484e-02
I0514 17:42:27.448680 22392998065984 run_lib.py:146] step: 166250, training_loss: 5.39249e-02
I0514 17:42:51.866053 22392998065984 run_lib.py:146] step: 166300, training_loss: 5.79473e-02
I0514 17:42:52.032993 22392998065984 run_lib.py:167] step: 166300, eval_loss: 6.97668e-02
I0514 17:43:16.456254 22392998065984 run_lib.py:146] step: 166350, training_loss: 5.16300e-02
I0514 17:43:40.570048 22392998065984 run_lib.py:146] step: 166400, training_loss: 6.06082e-02
I0514 17:43:40.736597 22392998065984 run_lib.py:167] step: 166400, eval_loss: 9.45294e-02
I0514 17:44:05.120780 22392998065984 run_lib.py:146] step: 166450, training_loss: 5.36114e-02
I0514 17:44:29.236048 22392998065984 run_lib.py:146] step: 166500, training_loss: 5.05320e-02
I0514 17:44:29.403303 22392998065984 run_lib.py:167] step: 166500, eval_loss: 5.64822e-02
I0514 17:44:53.822864 22392998065984 run_lib.py:146] step: 166550, training_loss: 7.05448e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:45:18.416313 22392998065984 run_lib.py:146] step: 166600, training_loss: 5.71728e-02
I0514 17:45:18.584450 22392998065984 run_lib.py:167] step: 166600, eval_loss: 5.10295e-02
I0514 17:45:42.691060 22392998065984 run_lib.py:146] step: 166650, training_loss: 5.68809e-02
I0514 17:46:07.134629 22392998065984 run_lib.py:146] step: 166700, training_loss: 6.37924e-02
I0514 17:46:07.301797 22392998065984 run_lib.py:167] step: 166700, eval_loss: 7.35225e-02
I0514 17:46:31.669558 22392998065984 run_lib.py:146] step: 166750, training_loss: 4.41819e-02
I0514 17:46:55.784345 22392998065984 run_lib.py:146] step: 166800, training_loss: 5.06430e-02
I0514 17:46:55.950727 22392998065984 run_lib.py:167] step: 166800, eval_loss: 6.49576e-02
I0514 17:47:20.371772 22392998065984 run_lib.py:146] step: 166850, training_loss: 6.19901e-02
I0514 17:47:44.739372 22392998065984 run_lib.py:146] step: 166900, training_loss: 5.28022e-02
I0514 17:47:44.905845 22392998065984 run_lib.py:167] step: 166900, eval_loss: 6.66519e-02
I0514 17:48:08.993562 22392998065984 run_lib.py:146] step: 166950, training_loss: 4.65974e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:48:33.032128 22392998065984 run_lib.py:146] step: 167000, training_loss: 5.20630e-02
I0514 17:48:33.200655 22392998065984 run_lib.py:167] step: 167000, eval_loss: 5.24815e-02
I0514 17:48:56.980826 22392998065984 run_lib.py:146] step: 167050, training_loss: 6.65139e-02
I0514 17:49:20.445368 22392998065984 run_lib.py:146] step: 167100, training_loss: 6.19785e-02
I0514 17:49:20.603827 22392998065984 run_lib.py:167] step: 167100, eval_loss: 5.44566e-02
I0514 17:49:44.656466 22392998065984 run_lib.py:146] step: 167150, training_loss: 6.22378e-02
I0514 17:50:08.399146 22392998065984 run_lib.py:146] step: 167200, training_loss: 6.85164e-02
I0514 17:50:08.558021 22392998065984 run_lib.py:167] step: 167200, eval_loss: 8.69645e-02
I0514 17:50:32.280655 22392998065984 run_lib.py:146] step: 167250, training_loss: 5.41629e-02
I0514 17:50:55.744155 22392998065984 run_lib.py:146] step: 167300, training_loss: 5.42561e-02
I0514 17:50:55.906858 22392998065984 run_lib.py:167] step: 167300, eval_loss: 5.36769e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:51:20.395286 22392998065984 run_lib.py:146] step: 167350, training_loss: 5.00052e-02
I0514 17:51:44.192889 22392998065984 run_lib.py:146] step: 167400, training_loss: 4.64397e-02
I0514 17:51:44.352698 22392998065984 run_lib.py:167] step: 167400, eval_loss: 4.91248e-02
I0514 17:52:07.798435 22392998065984 run_lib.py:146] step: 167450, training_loss: 6.25432e-02
I0514 17:52:31.583903 22392998065984 run_lib.py:146] step: 167500, training_loss: 5.22397e-02
I0514 17:52:31.742100 22392998065984 run_lib.py:167] step: 167500, eval_loss: 7.44935e-02
I0514 17:52:55.468390 22392998065984 run_lib.py:146] step: 167550, training_loss: 6.78322e-02
I0514 17:53:18.794239 22392998065984 run_lib.py:146] step: 167600, training_loss: 5.50294e-02
I0514 17:53:18.951826 22392998065984 run_lib.py:167] step: 167600, eval_loss: 6.00710e-02
I0514 17:53:42.560755 22392998065984 run_lib.py:146] step: 167650, training_loss: 6.07594e-02
I0514 17:54:06.153651 22392998065984 run_lib.py:146] step: 167700, training_loss: 4.76830e-02
I0514 17:54:06.312307 22392998065984 run_lib.py:167] step: 167700, eval_loss: 6.55557e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:54:29.860531 22392998065984 run_lib.py:146] step: 167750, training_loss: 6.30316e-02
I0514 17:54:53.707222 22392998065984 run_lib.py:146] step: 167800, training_loss: 5.20824e-02
I0514 17:54:53.866600 22392998065984 run_lib.py:167] step: 167800, eval_loss: 5.88622e-02
I0514 17:55:18.004039 22392998065984 run_lib.py:146] step: 167850, training_loss: 5.69044e-02
I0514 17:55:42.447222 22392998065984 run_lib.py:146] step: 167900, training_loss: 6.40140e-02
I0514 17:55:42.614341 22392998065984 run_lib.py:167] step: 167900, eval_loss: 5.62141e-02
I0514 17:56:07.065389 22392998065984 run_lib.py:146] step: 167950, training_loss: 5.26723e-02
I0514 17:56:31.203386 22392998065984 run_lib.py:146] step: 168000, training_loss: 7.14129e-02
I0514 17:56:31.370529 22392998065984 run_lib.py:167] step: 168000, eval_loss: 6.01181e-02
I0514 17:56:55.775286 22392998065984 run_lib.py:146] step: 168050, training_loss: 5.93600e-02
I0514 17:57:19.923608 22392998065984 run_lib.py:146] step: 168100, training_loss: 5.66442e-02
I0514 17:57:20.090723 22392998065984 run_lib.py:167] step: 168100, eval_loss: 6.69000e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 17:57:44.398113 22392998065984 run_lib.py:146] step: 168150, training_loss: 6.65691e-02
I0514 17:58:08.186202 22392998065984 run_lib.py:146] step: 168200, training_loss: 5.67507e-02
I0514 17:58:08.347867 22392998065984 run_lib.py:167] step: 168200, eval_loss: 7.28773e-02
I0514 17:58:31.829051 22392998065984 run_lib.py:146] step: 168250, training_loss: 7.41446e-02
I0514 17:58:55.669362 22392998065984 run_lib.py:146] step: 168300, training_loss: 5.25290e-02
I0514 17:58:55.828282 22392998065984 run_lib.py:167] step: 168300, eval_loss: 6.41835e-02
I0514 17:59:19.557863 22392998065984 run_lib.py:146] step: 168350, training_loss: 6.61557e-02
I0514 17:59:43.065220 22392998065984 run_lib.py:146] step: 168400, training_loss: 5.39485e-02
I0514 17:59:43.224651 22392998065984 run_lib.py:167] step: 168400, eval_loss: 5.12175e-02
I0514 18:00:07.006721 22392998065984 run_lib.py:146] step: 168450, training_loss: 6.44149e-02
I0514 18:00:30.760167 22392998065984 run_lib.py:146] step: 168500, training_loss: 6.44964e-02
I0514 18:00:30.918751 22392998065984 run_lib.py:167] step: 168500, eval_loss: 6.36901e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:00:54.537835 22392998065984 run_lib.py:146] step: 168550, training_loss: 6.44787e-02
I0514 18:01:18.328833 22392998065984 run_lib.py:146] step: 168600, training_loss: 7.12321e-02
I0514 18:01:18.488380 22392998065984 run_lib.py:167] step: 168600, eval_loss: 4.99803e-02
I0514 18:01:41.953755 22392998065984 run_lib.py:146] step: 168650, training_loss: 6.23815e-02
I0514 18:02:05.722098 22392998065984 run_lib.py:146] step: 168700, training_loss: 6.49525e-02
I0514 18:02:05.881127 22392998065984 run_lib.py:167] step: 168700, eval_loss: 7.04194e-02
I0514 18:02:29.660732 22392998065984 run_lib.py:146] step: 168750, training_loss: 8.49389e-02
I0514 18:02:53.120272 22392998065984 run_lib.py:146] step: 168800, training_loss: 6.30096e-02
I0514 18:02:53.278793 22392998065984 run_lib.py:167] step: 168800, eval_loss: 4.00205e-02
I0514 18:03:17.010496 22392998065984 run_lib.py:146] step: 168850, training_loss: 6.20386e-02
I0514 18:03:40.477097 22392998065984 run_lib.py:146] step: 168900, training_loss: 7.45840e-02
I0514 18:03:40.635096 22392998065984 run_lib.py:167] step: 168900, eval_loss: 5.75269e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:04:04.517607 22392998065984 run_lib.py:146] step: 168950, training_loss: 7.37001e-02
I0514 18:04:28.130356 22392998065984 run_lib.py:146] step: 169000, training_loss: 5.46525e-02
I0514 18:04:28.288963 22392998065984 run_lib.py:167] step: 169000, eval_loss: 5.43975e-02
I0514 18:04:52.100679 22392998065984 run_lib.py:146] step: 169050, training_loss: 5.81884e-02
I0514 18:05:15.902430 22392998065984 run_lib.py:146] step: 169100, training_loss: 6.26178e-02
I0514 18:05:16.060029 22392998065984 run_lib.py:167] step: 169100, eval_loss: 6.49853e-02
I0514 18:05:39.761061 22392998065984 run_lib.py:146] step: 169150, training_loss: 4.89539e-02
I0514 18:06:03.222014 22392998065984 run_lib.py:146] step: 169200, training_loss: 6.41255e-02
I0514 18:06:03.380868 22392998065984 run_lib.py:167] step: 169200, eval_loss: 5.22176e-02
I0514 18:06:27.178111 22392998065984 run_lib.py:146] step: 169250, training_loss: 7.67913e-02
I0514 18:06:50.786419 22392998065984 run_lib.py:146] step: 169300, training_loss: 5.51059e-02
I0514 18:06:50.943713 22392998065984 run_lib.py:167] step: 169300, eval_loss: 6.72987e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:07:15.015969 22392998065984 run_lib.py:146] step: 169350, training_loss: 5.46171e-02
I0514 18:07:38.933051 22392998065984 run_lib.py:146] step: 169400, training_loss: 4.64722e-02
I0514 18:07:39.091670 22392998065984 run_lib.py:167] step: 169400, eval_loss: 7.78802e-02
I0514 18:08:02.404672 22392998065984 run_lib.py:146] step: 169450, training_loss: 4.40142e-02
I0514 18:08:26.057839 22392998065984 run_lib.py:146] step: 169500, training_loss: 6.06030e-02
I0514 18:08:26.217260 22392998065984 run_lib.py:167] step: 169500, eval_loss: 5.29484e-02
I0514 18:08:49.976393 22392998065984 run_lib.py:146] step: 169550, training_loss: 5.26910e-02
I0514 18:09:13.979790 22392998065984 run_lib.py:146] step: 169600, training_loss: 5.01464e-02
I0514 18:09:14.145770 22392998065984 run_lib.py:167] step: 169600, eval_loss: 3.93159e-02
I0514 18:09:38.425118 22392998065984 run_lib.py:146] step: 169650, training_loss: 6.38136e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:10:02.103948 22392998065984 run_lib.py:146] step: 169700, training_loss: 6.58081e-02
I0514 18:10:02.265556 22392998065984 run_lib.py:167] step: 169700, eval_loss: 7.59927e-02
I0514 18:10:25.937432 22392998065984 run_lib.py:146] step: 169750, training_loss: 5.33658e-02
I0514 18:10:49.666677 22392998065984 run_lib.py:146] step: 169800, training_loss: 6.74987e-02
I0514 18:10:49.825437 22392998065984 run_lib.py:167] step: 169800, eval_loss: 4.53974e-02
I0514 18:11:13.213903 22392998065984 run_lib.py:146] step: 169850, training_loss: 5.34914e-02
I0514 18:11:36.948163 22392998065984 run_lib.py:146] step: 169900, training_loss: 5.64977e-02
I0514 18:11:37.107000 22392998065984 run_lib.py:167] step: 169900, eval_loss: 6.02542e-02
I0514 18:12:00.790993 22392998065984 run_lib.py:146] step: 169950, training_loss: 5.89504e-02
I0514 18:12:24.131177 22392998065984 run_lib.py:146] step: 170000, training_loss: 6.03820e-02
I0514 18:12:25.762297 22392998065984 run_lib.py:167] step: 170000, eval_loss: 5.93020e-02
I0514 18:12:50.862535 22392998065984 run_lib.py:146] step: 170050, training_loss: 6.64570e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:13:14.861408 22392998065984 run_lib.py:146] step: 170100, training_loss: 4.66486e-02
I0514 18:13:15.021797 22392998065984 run_lib.py:167] step: 170100, eval_loss: 4.63644e-02
I0514 18:13:38.829100 22392998065984 run_lib.py:146] step: 170150, training_loss: 5.13733e-02
I0514 18:14:02.451092 22392998065984 run_lib.py:146] step: 170200, training_loss: 4.58796e-02
I0514 18:14:02.612736 22392998065984 run_lib.py:167] step: 170200, eval_loss: 5.37345e-02
I0514 18:14:26.243753 22392998065984 run_lib.py:146] step: 170250, training_loss: 4.53330e-02
I0514 18:14:50.435372 22392998065984 run_lib.py:146] step: 170300, training_loss: 5.68156e-02
I0514 18:14:50.595101 22392998065984 run_lib.py:167] step: 170300, eval_loss: 7.00782e-02
I0514 18:15:14.220059 22392998065984 run_lib.py:146] step: 170350, training_loss: 5.88193e-02
I0514 18:15:37.831656 22392998065984 run_lib.py:146] step: 170400, training_loss: 8.01429e-02
I0514 18:15:37.991022 22392998065984 run_lib.py:167] step: 170400, eval_loss: 6.82540e-02
I0514 18:16:01.918174 22392998065984 run_lib.py:146] step: 170450, training_loss: 6.95419e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:16:26.185405 22392998065984 run_lib.py:146] step: 170500, training_loss: 4.71468e-02
I0514 18:16:26.354923 22392998065984 run_lib.py:167] step: 170500, eval_loss: 5.44286e-02
I0514 18:16:50.547885 22392998065984 run_lib.py:146] step: 170550, training_loss: 6.85911e-02
I0514 18:17:15.053290 22392998065984 run_lib.py:146] step: 170600, training_loss: 7.02466e-02
I0514 18:17:15.220791 22392998065984 run_lib.py:167] step: 170600, eval_loss: 6.42763e-02
I0514 18:17:39.784800 22392998065984 run_lib.py:146] step: 170650, training_loss: 5.65950e-02
I0514 18:18:04.020236 22392998065984 run_lib.py:146] step: 170700, training_loss: 5.56557e-02
I0514 18:18:04.189477 22392998065984 run_lib.py:167] step: 170700, eval_loss: 5.37877e-02
I0514 18:18:28.685459 22392998065984 run_lib.py:146] step: 170750, training_loss: 5.57089e-02
I0514 18:18:53.269138 22392998065984 run_lib.py:146] step: 170800, training_loss: 6.28759e-02
I0514 18:18:53.437931 22392998065984 run_lib.py:167] step: 170800, eval_loss: 5.86834e-02
I0514 18:19:17.706797 22392998065984 run_lib.py:146] step: 170850, training_loss: 5.26267e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:19:41.981208 22392998065984 run_lib.py:146] step: 170900, training_loss: 5.95195e-02
I0514 18:19:42.142524 22392998065984 run_lib.py:167] step: 170900, eval_loss: 5.38629e-02
I0514 18:20:06.012809 22392998065984 run_lib.py:146] step: 170950, training_loss: 6.01671e-02
I0514 18:20:29.574505 22392998065984 run_lib.py:146] step: 171000, training_loss: 5.42980e-02
I0514 18:20:29.733186 22392998065984 run_lib.py:167] step: 171000, eval_loss: 5.61826e-02
I0514 18:20:53.328347 22392998065984 run_lib.py:146] step: 171050, training_loss: 5.97941e-02
I0514 18:21:17.486833 22392998065984 run_lib.py:146] step: 171100, training_loss: 5.35676e-02
I0514 18:21:17.646534 22392998065984 run_lib.py:167] step: 171100, eval_loss: 6.19759e-02
I0514 18:21:41.223259 22392998065984 run_lib.py:146] step: 171150, training_loss: 5.47241e-02
I0514 18:22:04.786528 22392998065984 run_lib.py:146] step: 171200, training_loss: 5.68441e-02
I0514 18:22:04.945594 22392998065984 run_lib.py:167] step: 171200, eval_loss: 7.57207e-02
I0514 18:22:28.841459 22392998065984 run_lib.py:146] step: 171250, training_loss: 4.94273e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:22:52.912207 22392998065984 run_lib.py:146] step: 171300, training_loss: 6.88608e-02
I0514 18:22:53.072946 22392998065984 run_lib.py:167] step: 171300, eval_loss: 7.40851e-02
I0514 18:23:16.566813 22392998065984 run_lib.py:146] step: 171350, training_loss: 7.17993e-02
I0514 18:23:40.450502 22392998065984 run_lib.py:146] step: 171400, training_loss: 5.95244e-02
I0514 18:23:40.609108 22392998065984 run_lib.py:167] step: 171400, eval_loss: 4.55733e-02
I0514 18:24:04.494819 22392998065984 run_lib.py:146] step: 171450, training_loss: 6.86443e-02
I0514 18:24:28.077051 22392998065984 run_lib.py:146] step: 171500, training_loss: 5.65992e-02
I0514 18:24:28.254236 22392998065984 run_lib.py:167] step: 171500, eval_loss: 6.18534e-02
I0514 18:24:52.142400 22392998065984 run_lib.py:146] step: 171550, training_loss: 5.79924e-02
I0514 18:25:16.028822 22392998065984 run_lib.py:146] step: 171600, training_loss: 7.17960e-02
I0514 18:25:16.188742 22392998065984 run_lib.py:167] step: 171600, eval_loss: 5.42960e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:25:39.955459 22392998065984 run_lib.py:146] step: 171650, training_loss: 6.33414e-02
I0514 18:26:04.469021 22392998065984 run_lib.py:146] step: 171700, training_loss: 4.08454e-02
I0514 18:26:04.637171 22392998065984 run_lib.py:167] step: 171700, eval_loss: 7.42686e-02
I0514 18:26:29.227326 22392998065984 run_lib.py:146] step: 171750, training_loss: 5.68092e-02
I0514 18:26:53.387948 22392998065984 run_lib.py:146] step: 171800, training_loss: 7.23699e-02
I0514 18:26:53.547808 22392998065984 run_lib.py:167] step: 171800, eval_loss: 5.84011e-02
I0514 18:27:17.119042 22392998065984 run_lib.py:146] step: 171850, training_loss: 6.88308e-02
I0514 18:27:41.271438 22392998065984 run_lib.py:146] step: 171900, training_loss: 4.57389e-02
I0514 18:27:41.430607 22392998065984 run_lib.py:167] step: 171900, eval_loss: 5.13546e-02
I0514 18:28:04.999608 22392998065984 run_lib.py:146] step: 171950, training_loss: 5.92548e-02
I0514 18:28:28.593796 22392998065984 run_lib.py:146] step: 172000, training_loss: 6.82626e-02
I0514 18:28:28.754871 22392998065984 run_lib.py:167] step: 172000, eval_loss: 5.52889e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:28:52.767089 22392998065984 run_lib.py:146] step: 172050, training_loss: 6.63939e-02
I0514 18:29:16.687992 22392998065984 run_lib.py:146] step: 172100, training_loss: 5.84579e-02
I0514 18:29:16.854901 22392998065984 run_lib.py:167] step: 172100, eval_loss: 4.44491e-02
I0514 18:29:40.421609 22392998065984 run_lib.py:146] step: 172150, training_loss: 4.32446e-02
I0514 18:30:04.288247 22392998065984 run_lib.py:146] step: 172200, training_loss: 5.61551e-02
I0514 18:30:04.448123 22392998065984 run_lib.py:167] step: 172200, eval_loss: 6.11188e-02
I0514 18:30:28.245547 22392998065984 run_lib.py:146] step: 172250, training_loss: 4.75036e-02
I0514 18:30:51.859009 22392998065984 run_lib.py:146] step: 172300, training_loss: 5.83742e-02
I0514 18:30:52.018086 22392998065984 run_lib.py:167] step: 172300, eval_loss: 7.93106e-02
I0514 18:31:15.884880 22392998065984 run_lib.py:146] step: 172350, training_loss: 5.19051e-02
I0514 18:31:39.783387 22392998065984 run_lib.py:146] step: 172400, training_loss: 7.98889e-02
I0514 18:31:39.946002 22392998065984 run_lib.py:167] step: 172400, eval_loss: 6.49075e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:32:03.929209 22392998065984 run_lib.py:146] step: 172450, training_loss: 8.17847e-02
I0514 18:32:28.212122 22392998065984 run_lib.py:146] step: 172500, training_loss: 4.98953e-02
I0514 18:32:28.373323 22392998065984 run_lib.py:167] step: 172500, eval_loss: 5.52185e-02
I0514 18:32:52.273995 22392998065984 run_lib.py:146] step: 172550, training_loss: 5.43925e-02
I0514 18:33:15.854911 22392998065984 run_lib.py:146] step: 172600, training_loss: 4.65231e-02
I0514 18:33:16.014609 22392998065984 run_lib.py:167] step: 172600, eval_loss: 5.44448e-02
I0514 18:33:39.626588 22392998065984 run_lib.py:146] step: 172650, training_loss: 4.65974e-02
I0514 18:34:03.526940 22392998065984 run_lib.py:146] step: 172700, training_loss: 8.36008e-02
I0514 18:34:03.686868 22392998065984 run_lib.py:167] step: 172700, eval_loss: 4.55582e-02
I0514 18:34:27.613118 22392998065984 run_lib.py:146] step: 172750, training_loss: 5.95185e-02
I0514 18:34:51.242784 22392998065984 run_lib.py:146] step: 172800, training_loss: 4.37981e-02
I0514 18:34:51.404592 22392998065984 run_lib.py:167] step: 172800, eval_loss: 5.41369e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:35:15.809545 22392998065984 run_lib.py:146] step: 172850, training_loss: 5.44056e-02
I0514 18:35:40.381692 22392998065984 run_lib.py:146] step: 172900, training_loss: 5.16237e-02
I0514 18:35:40.550917 22392998065984 run_lib.py:167] step: 172900, eval_loss: 5.52842e-02
I0514 18:36:04.754257 22392998065984 run_lib.py:146] step: 172950, training_loss: 6.94842e-02
I0514 18:36:29.277622 22392998065984 run_lib.py:146] step: 173000, training_loss: 5.37456e-02
I0514 18:36:29.445244 22392998065984 run_lib.py:167] step: 173000, eval_loss: 5.14139e-02
I0514 18:36:53.972671 22392998065984 run_lib.py:146] step: 173050, training_loss: 5.96486e-02
I0514 18:37:18.195369 22392998065984 run_lib.py:146] step: 173100, training_loss: 5.26546e-02
I0514 18:37:18.362988 22392998065984 run_lib.py:167] step: 173100, eval_loss: 5.87192e-02
I0514 18:37:42.856231 22392998065984 run_lib.py:146] step: 173150, training_loss: 5.87213e-02
I0514 18:38:07.395117 22392998065984 run_lib.py:146] step: 173200, training_loss: 6.95831e-02
I0514 18:38:07.563570 22392998065984 run_lib.py:167] step: 173200, eval_loss: 6.28620e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:38:31.543632 22392998065984 run_lib.py:146] step: 173250, training_loss: 5.92743e-02
I0514 18:38:55.609891 22392998065984 run_lib.py:146] step: 173300, training_loss: 5.92262e-02
I0514 18:38:55.789554 22392998065984 run_lib.py:167] step: 173300, eval_loss: 6.43692e-02
I0514 18:39:20.061461 22392998065984 run_lib.py:146] step: 173350, training_loss: 5.56728e-02
I0514 18:39:43.526895 22392998065984 run_lib.py:146] step: 173400, training_loss: 6.08950e-02
I0514 18:39:43.685257 22392998065984 run_lib.py:167] step: 173400, eval_loss: 4.98143e-02
I0514 18:40:07.068461 22392998065984 run_lib.py:146] step: 173450, training_loss: 5.04985e-02
I0514 18:40:31.016249 22392998065984 run_lib.py:146] step: 173500, training_loss: 6.57058e-02
I0514 18:40:31.174063 22392998065984 run_lib.py:167] step: 173500, eval_loss: 4.35191e-02
I0514 18:40:54.552108 22392998065984 run_lib.py:146] step: 173550, training_loss: 6.73954e-02
I0514 18:41:17.931305 22392998065984 run_lib.py:146] step: 173600, training_loss: 6.42314e-02
I0514 18:41:18.088286 22392998065984 run_lib.py:167] step: 173600, eval_loss: 3.62982e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:41:41.896977 22392998065984 run_lib.py:146] step: 173650, training_loss: 6.83625e-02
I0514 18:42:05.620328 22392998065984 run_lib.py:146] step: 173700, training_loss: 6.35862e-02
I0514 18:42:05.703479 22392998065984 run_lib.py:167] step: 173700, eval_loss: 1.15807e-01
I0514 18:42:29.075669 22392998065984 run_lib.py:146] step: 173750, training_loss: 8.08842e-02
I0514 18:42:52.718792 22392998065984 run_lib.py:146] step: 173800, training_loss: 5.84813e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:42:53.107965 22392998065984 run_lib.py:167] step: 173800, eval_loss: 5.52310e-02
I0514 18:43:16.825872 22392998065984 run_lib.py:146] step: 173850, training_loss: 5.70226e-02
I0514 18:43:40.183978 22392998065984 run_lib.py:146] step: 173900, training_loss: 5.60621e-02
I0514 18:43:40.341305 22392998065984 run_lib.py:167] step: 173900, eval_loss: 6.43488e-02
I0514 18:44:04.017488 22392998065984 run_lib.py:146] step: 173950, training_loss: 4.68169e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:44:27.793912 22392998065984 run_lib.py:146] step: 174000, training_loss: 5.53035e-02
I0514 18:44:27.952898 22392998065984 run_lib.py:167] step: 174000, eval_loss: 6.30296e-02
I0514 18:44:51.298259 22392998065984 run_lib.py:146] step: 174050, training_loss: 6.07060e-02
I0514 18:45:14.972426 22392998065984 run_lib.py:146] step: 174100, training_loss: 6.34525e-02
I0514 18:45:15.130284 22392998065984 run_lib.py:167] step: 174100, eval_loss: 6.13008e-02
I0514 18:45:38.832300 22392998065984 run_lib.py:146] step: 174150, training_loss: 5.45830e-02
I0514 18:46:02.188027 22392998065984 run_lib.py:146] step: 174200, training_loss: 4.72074e-02
I0514 18:46:02.345038 22392998065984 run_lib.py:167] step: 174200, eval_loss: 6.26967e-02
I0514 18:46:25.688253 22392998065984 run_lib.py:146] step: 174250, training_loss: 5.82730e-02
I0514 18:46:49.600669 22392998065984 run_lib.py:146] step: 174300, training_loss: 7.09376e-02
I0514 18:46:49.757672 22392998065984 run_lib.py:167] step: 174300, eval_loss: 6.96498e-02
I0514 18:47:13.108789 22392998065984 run_lib.py:146] step: 174350, training_loss: 5.51317e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:47:36.611521 22392998065984 run_lib.py:146] step: 174400, training_loss: 6.57503e-02
I0514 18:47:36.771140 22392998065984 run_lib.py:167] step: 174400, eval_loss: 6.04202e-02
I0514 18:48:00.463242 22392998065984 run_lib.py:146] step: 174450, training_loss: 6.58902e-02
I0514 18:48:24.188576 22392998065984 run_lib.py:146] step: 174500, training_loss: 4.97394e-02
I0514 18:48:24.346208 22392998065984 run_lib.py:167] step: 174500, eval_loss: 4.46835e-02
I0514 18:48:47.704229 22392998065984 run_lib.py:146] step: 174550, training_loss: 6.48775e-02
I0514 18:49:11.339391 22392998065984 run_lib.py:146] step: 174600, training_loss: 5.70060e-02
I0514 18:49:11.497238 22392998065984 run_lib.py:167] step: 174600, eval_loss: 7.76770e-02
I0514 18:49:35.186115 22392998065984 run_lib.py:146] step: 174650, training_loss: 5.42191e-02
I0514 18:49:58.575249 22392998065984 run_lib.py:146] step: 174700, training_loss: 5.17105e-02
I0514 18:49:58.732791 22392998065984 run_lib.py:167] step: 174700, eval_loss: 6.16755e-02
I0514 18:50:22.402432 22392998065984 run_lib.py:146] step: 174750, training_loss: 6.01668e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:50:46.174245 22392998065984 run_lib.py:146] step: 174800, training_loss: 7.30089e-02
I0514 18:50:46.333591 22392998065984 run_lib.py:167] step: 174800, eval_loss: 5.86252e-02
I0514 18:51:09.692076 22392998065984 run_lib.py:146] step: 174850, training_loss: 6.15618e-02
I0514 18:51:33.346935 22392998065984 run_lib.py:146] step: 174900, training_loss: 5.83981e-02
I0514 18:51:33.504433 22392998065984 run_lib.py:167] step: 174900, eval_loss: 5.94526e-02
I0514 18:51:57.182493 22392998065984 run_lib.py:146] step: 174950, training_loss: 5.58831e-02
I0514 18:52:20.559317 22392998065984 run_lib.py:146] step: 175000, training_loss: 6.17272e-02
I0514 18:52:20.716701 22392998065984 run_lib.py:167] step: 175000, eval_loss: 5.01426e-02
I0514 18:52:44.099970 22392998065984 run_lib.py:146] step: 175050, training_loss: 6.28749e-02
I0514 18:53:08.058826 22392998065984 run_lib.py:146] step: 175100, training_loss: 6.34463e-02
I0514 18:53:08.216054 22392998065984 run_lib.py:167] step: 175100, eval_loss: 7.15744e-02
I0514 18:53:31.608982 22392998065984 run_lib.py:146] step: 175150, training_loss: 5.57037e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:53:55.093112 22392998065984 run_lib.py:146] step: 175200, training_loss: 7.40834e-02
I0514 18:53:55.252612 22392998065984 run_lib.py:167] step: 175200, eval_loss: 5.47718e-02
I0514 18:54:19.277124 22392998065984 run_lib.py:146] step: 175250, training_loss: 6.18475e-02
I0514 18:54:42.660240 22392998065984 run_lib.py:146] step: 175300, training_loss: 6.02967e-02
I0514 18:54:42.817995 22392998065984 run_lib.py:167] step: 175300, eval_loss: 6.01237e-02
I0514 18:55:06.200768 22392998065984 run_lib.py:146] step: 175350, training_loss: 5.84285e-02
I0514 18:55:29.845143 22392998065984 run_lib.py:146] step: 175400, training_loss: 6.45327e-02
I0514 18:55:30.002831 22392998065984 run_lib.py:167] step: 175400, eval_loss: 7.06144e-02
I0514 18:55:53.648690 22392998065984 run_lib.py:146] step: 175450, training_loss: 5.10602e-02
I0514 18:56:17.017519 22392998065984 run_lib.py:146] step: 175500, training_loss: 6.36352e-02
I0514 18:56:17.174876 22392998065984 run_lib.py:167] step: 175500, eval_loss: 5.84644e-02
I0514 18:56:40.825546 22392998065984 run_lib.py:146] step: 175550, training_loss: 5.97700e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:57:04.820904 22392998065984 run_lib.py:146] step: 175600, training_loss: 5.09414e-02
I0514 18:57:04.979380 22392998065984 run_lib.py:167] step: 175600, eval_loss: 6.98575e-02
I0514 18:57:28.342800 22392998065984 run_lib.py:146] step: 175650, training_loss: 4.90796e-02
I0514 18:57:52.030688 22392998065984 run_lib.py:146] step: 175700, training_loss: 5.46730e-02
I0514 18:57:52.187971 22392998065984 run_lib.py:167] step: 175700, eval_loss: 7.29473e-02
I0514 18:58:15.844810 22392998065984 run_lib.py:146] step: 175750, training_loss: 5.13093e-02
I0514 18:58:39.202880 22392998065984 run_lib.py:146] step: 175800, training_loss: 6.20893e-02
I0514 18:58:39.360647 22392998065984 run_lib.py:167] step: 175800, eval_loss: 4.68710e-02
I0514 18:59:02.984200 22392998065984 run_lib.py:146] step: 175850, training_loss: 4.51430e-02
I0514 18:59:26.659992 22392998065984 run_lib.py:146] step: 175900, training_loss: 7.78528e-02
I0514 18:59:26.817603 22392998065984 run_lib.py:167] step: 175900, eval_loss: 5.34597e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 18:59:50.281524 22392998065984 run_lib.py:146] step: 175950, training_loss: 5.37974e-02
I0514 19:00:13.651616 22392998065984 run_lib.py:146] step: 176000, training_loss: 6.31454e-02
I0514 19:00:13.810637 22392998065984 run_lib.py:167] step: 176000, eval_loss: 5.76258e-02
I0514 19:00:37.823268 22392998065984 run_lib.py:146] step: 176050, training_loss: 5.72880e-02
I0514 19:01:01.190404 22392998065984 run_lib.py:146] step: 176100, training_loss: 6.81842e-02
I0514 19:01:01.348270 22392998065984 run_lib.py:167] step: 176100, eval_loss: 6.26414e-02
I0514 19:01:24.694344 22392998065984 run_lib.py:146] step: 176150, training_loss: 5.90667e-02
I0514 19:01:48.326442 22392998065984 run_lib.py:146] step: 176200, training_loss: 6.63675e-02
I0514 19:01:48.483953 22392998065984 run_lib.py:167] step: 176200, eval_loss: 5.07922e-02
I0514 19:02:12.152592 22392998065984 run_lib.py:146] step: 176250, training_loss: 5.68337e-02
I0514 19:02:35.523811 22392998065984 run_lib.py:146] step: 176300, training_loss: 7.49869e-02
I0514 19:02:35.681063 22392998065984 run_lib.py:167] step: 176300, eval_loss: 6.55339e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:02:59.454175 22392998065984 run_lib.py:146] step: 176350, training_loss: 5.41330e-02
I0514 19:03:23.199279 22392998065984 run_lib.py:146] step: 176400, training_loss: 6.30765e-02
I0514 19:03:23.358350 22392998065984 run_lib.py:167] step: 176400, eval_loss: 5.58704e-02
I0514 19:03:46.723328 22392998065984 run_lib.py:146] step: 176450, training_loss: 7.08270e-02
I0514 19:04:10.424514 22392998065984 run_lib.py:146] step: 176500, training_loss: 5.15263e-02
I0514 19:04:10.581726 22392998065984 run_lib.py:167] step: 176500, eval_loss: 7.63144e-02
I0514 19:04:34.242977 22392998065984 run_lib.py:146] step: 176550, training_loss: 7.50463e-02
I0514 19:04:57.598565 22392998065984 run_lib.py:146] step: 176600, training_loss: 5.78531e-02
I0514 19:04:57.755743 22392998065984 run_lib.py:167] step: 176600, eval_loss: 4.03887e-02
I0514 19:05:21.379844 22392998065984 run_lib.py:146] step: 176650, training_loss: 6.00644e-02
I0514 19:05:45.052147 22392998065984 run_lib.py:146] step: 176700, training_loss: 5.30295e-02
I0514 19:05:45.209696 22392998065984 run_lib.py:167] step: 176700, eval_loss: 5.56071e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:06:08.680034 22392998065984 run_lib.py:146] step: 176750, training_loss: 5.75233e-02
I0514 19:06:32.054056 22392998065984 run_lib.py:146] step: 176800, training_loss: 7.36382e-02
I0514 19:06:32.213215 22392998065984 run_lib.py:167] step: 176800, eval_loss: 6.79627e-02
I0514 19:06:56.243572 22392998065984 run_lib.py:146] step: 176850, training_loss: 6.53316e-02
I0514 19:07:19.615791 22392998065984 run_lib.py:146] step: 176900, training_loss: 5.75844e-02
I0514 19:07:19.772948 22392998065984 run_lib.py:167] step: 176900, eval_loss: 6.75608e-02
I0514 19:07:43.123650 22392998065984 run_lib.py:146] step: 176950, training_loss: 6.78875e-02
I0514 19:08:06.783882 22392998065984 run_lib.py:146] step: 177000, training_loss: 6.99905e-02
I0514 19:08:06.941154 22392998065984 run_lib.py:167] step: 177000, eval_loss: 4.64364e-02
I0514 19:08:30.621222 22392998065984 run_lib.py:146] step: 177050, training_loss: 5.90816e-02
I0514 19:08:53.998672 22392998065984 run_lib.py:146] step: 177100, training_loss: 7.64193e-02
I0514 19:08:54.156175 22392998065984 run_lib.py:167] step: 177100, eval_loss: 6.74907e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:09:17.969815 22392998065984 run_lib.py:146] step: 177150, training_loss: 5.90342e-02
I0514 19:09:41.710005 22392998065984 run_lib.py:146] step: 177200, training_loss: 4.84939e-02
I0514 19:09:41.868787 22392998065984 run_lib.py:167] step: 177200, eval_loss: 6.52770e-02
I0514 19:10:05.253402 22392998065984 run_lib.py:146] step: 177250, training_loss: 8.16113e-02
I0514 19:10:28.911874 22392998065984 run_lib.py:146] step: 177300, training_loss: 7.68325e-02
I0514 19:10:29.069441 22392998065984 run_lib.py:167] step: 177300, eval_loss: 5.50487e-02
I0514 19:10:52.745731 22392998065984 run_lib.py:146] step: 177350, training_loss: 5.83626e-02
I0514 19:11:16.122907 22392998065984 run_lib.py:146] step: 177400, training_loss: 4.73492e-02
I0514 19:11:16.280703 22392998065984 run_lib.py:167] step: 177400, eval_loss: 5.78523e-02
I0514 19:11:39.930284 22392998065984 run_lib.py:146] step: 177450, training_loss: 4.32680e-02
I0514 19:12:03.593454 22392998065984 run_lib.py:146] step: 177500, training_loss: 6.78013e-02
I0514 19:12:03.750793 22392998065984 run_lib.py:167] step: 177500, eval_loss: 8.55018e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:12:27.224739 22392998065984 run_lib.py:146] step: 177550, training_loss: 5.92198e-02
I0514 19:12:50.620028 22392998065984 run_lib.py:146] step: 177600, training_loss: 6.23338e-02
I0514 19:12:50.781122 22392998065984 run_lib.py:167] step: 177600, eval_loss: 4.87287e-02
I0514 19:13:14.786126 22392998065984 run_lib.py:146] step: 177650, training_loss: 6.51402e-02
I0514 19:13:38.152419 22392998065984 run_lib.py:146] step: 177700, training_loss: 6.01189e-02
I0514 19:13:38.310050 22392998065984 run_lib.py:167] step: 177700, eval_loss: 5.74659e-02
I0514 19:14:01.678499 22392998065984 run_lib.py:146] step: 177750, training_loss: 7.84934e-02
I0514 19:14:25.324011 22392998065984 run_lib.py:146] step: 177800, training_loss: 5.53364e-02
I0514 19:14:25.481283 22392998065984 run_lib.py:167] step: 177800, eval_loss: 5.60756e-02
I0514 19:14:49.151979 22392998065984 run_lib.py:146] step: 177850, training_loss: 4.98555e-02
I0514 19:15:12.537900 22392998065984 run_lib.py:146] step: 177900, training_loss: 5.62132e-02
I0514 19:15:12.695107 22392998065984 run_lib.py:167] step: 177900, eval_loss: 6.56410e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:15:36.491800 22392998065984 run_lib.py:146] step: 177950, training_loss: 4.61825e-02
I0514 19:16:00.192173 22392998065984 run_lib.py:146] step: 178000, training_loss: 6.62438e-02
I0514 19:16:00.350455 22392998065984 run_lib.py:167] step: 178000, eval_loss: 7.39339e-02
I0514 19:16:23.712849 22392998065984 run_lib.py:146] step: 178050, training_loss: 5.83187e-02
I0514 19:16:47.359399 22392998065984 run_lib.py:146] step: 178100, training_loss: 6.20136e-02
I0514 19:16:47.516798 22392998065984 run_lib.py:167] step: 178100, eval_loss: 5.22163e-02
I0514 19:17:11.197644 22392998065984 run_lib.py:146] step: 178150, training_loss: 4.95762e-02
I0514 19:17:34.569536 22392998065984 run_lib.py:146] step: 178200, training_loss: 5.92118e-02
I0514 19:17:34.726901 22392998065984 run_lib.py:167] step: 178200, eval_loss: 6.41272e-02
I0514 19:17:58.398646 22392998065984 run_lib.py:146] step: 178250, training_loss: 5.08708e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:18:22.166562 22392998065984 run_lib.py:146] step: 178300, training_loss: 6.01656e-02
I0514 19:18:22.325650 22392998065984 run_lib.py:167] step: 178300, eval_loss: 7.25423e-02
I0514 19:18:45.688899 22392998065984 run_lib.py:146] step: 178350, training_loss: 4.89819e-02
I0514 19:19:09.064845 22392998065984 run_lib.py:146] step: 178400, training_loss: 6.95204e-02
I0514 19:19:09.222496 22392998065984 run_lib.py:167] step: 178400, eval_loss: 5.97808e-02
I0514 19:19:33.223780 22392998065984 run_lib.py:146] step: 178450, training_loss: 5.85266e-02
I0514 19:19:56.588187 22392998065984 run_lib.py:146] step: 178500, training_loss: 7.00466e-02
I0514 19:19:56.745398 22392998065984 run_lib.py:167] step: 178500, eval_loss: 6.30906e-02
I0514 19:20:20.114054 22392998065984 run_lib.py:146] step: 178550, training_loss: 6.77020e-02
I0514 19:20:43.761342 22392998065984 run_lib.py:146] step: 178600, training_loss: 5.71581e-02
I0514 19:20:43.918965 22392998065984 run_lib.py:167] step: 178600, eval_loss: 4.79155e-02
I0514 19:21:07.612203 22392998065984 run_lib.py:146] step: 178650, training_loss: 5.26159e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:21:31.119580 22392998065984 run_lib.py:146] step: 178700, training_loss: 5.33355e-02
I0514 19:21:31.279015 22392998065984 run_lib.py:167] step: 178700, eval_loss: 5.21240e-02
I0514 19:21:54.969224 22392998065984 run_lib.py:146] step: 178750, training_loss: 5.54875e-02
I0514 19:22:18.688503 22392998065984 run_lib.py:146] step: 178800, training_loss: 6.46828e-02
I0514 19:22:18.846119 22392998065984 run_lib.py:167] step: 178800, eval_loss: 5.72807e-02
I0514 19:22:42.230704 22392998065984 run_lib.py:146] step: 178850, training_loss: 5.15433e-02
I0514 19:23:05.902883 22392998065984 run_lib.py:146] step: 178900, training_loss: 5.95264e-02
I0514 19:23:06.059984 22392998065984 run_lib.py:167] step: 178900, eval_loss: 6.91472e-02
I0514 19:23:29.742740 22392998065984 run_lib.py:146] step: 178950, training_loss: 5.26098e-02
I0514 19:23:53.124058 22392998065984 run_lib.py:146] step: 179000, training_loss: 6.88241e-02
I0514 19:23:53.281350 22392998065984 run_lib.py:167] step: 179000, eval_loss: 5.51297e-02
I0514 19:24:16.927210 22392998065984 run_lib.py:146] step: 179050, training_loss: 5.67885e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:24:40.730468 22392998065984 run_lib.py:146] step: 179100, training_loss: 5.39071e-02
I0514 19:24:40.888753 22392998065984 run_lib.py:167] step: 179100, eval_loss: 6.04542e-02
I0514 19:25:04.244818 22392998065984 run_lib.py:146] step: 179150, training_loss: 7.51170e-02
I0514 19:25:27.612134 22392998065984 run_lib.py:146] step: 179200, training_loss: 6.66469e-02
I0514 19:25:27.769804 22392998065984 run_lib.py:167] step: 179200, eval_loss: 5.18799e-02
I0514 19:25:51.717504 22392998065984 run_lib.py:146] step: 179250, training_loss: 6.49295e-02
I0514 19:26:15.086671 22392998065984 run_lib.py:146] step: 179300, training_loss: 4.97944e-02
I0514 19:26:15.244420 22392998065984 run_lib.py:167] step: 179300, eval_loss: 6.21464e-02
I0514 19:26:38.580628 22392998065984 run_lib.py:146] step: 179350, training_loss: 5.36725e-02
I0514 19:27:02.198547 22392998065984 run_lib.py:146] step: 179400, training_loss: 6.75496e-02
I0514 19:27:02.355650 22392998065984 run_lib.py:167] step: 179400, eval_loss: 4.92532e-02
I0514 19:27:25.995410 22392998065984 run_lib.py:146] step: 179450, training_loss: 6.16592e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:27:49.469427 22392998065984 run_lib.py:146] step: 179500, training_loss: 5.14287e-02
I0514 19:27:49.641480 22392998065984 run_lib.py:167] step: 179500, eval_loss: 4.59139e-02
I0514 19:28:13.324445 22392998065984 run_lib.py:146] step: 179550, training_loss: 5.38754e-02
I0514 19:28:37.023961 22392998065984 run_lib.py:146] step: 179600, training_loss: 7.19884e-02
I0514 19:28:37.181694 22392998065984 run_lib.py:167] step: 179600, eval_loss: 6.48744e-02
I0514 19:29:00.548640 22392998065984 run_lib.py:146] step: 179650, training_loss: 6.42793e-02
I0514 19:29:24.189950 22392998065984 run_lib.py:146] step: 179700, training_loss: 7.95480e-02
I0514 19:29:24.347302 22392998065984 run_lib.py:167] step: 179700, eval_loss: 6.04919e-02
I0514 19:29:48.017935 22392998065984 run_lib.py:146] step: 179750, training_loss: 5.09090e-02
I0514 19:30:11.393152 22392998065984 run_lib.py:146] step: 179800, training_loss: 6.93209e-02
I0514 19:30:11.550497 22392998065984 run_lib.py:167] step: 179800, eval_loss: 6.06103e-02
I0514 19:30:35.197550 22392998065984 run_lib.py:146] step: 179850, training_loss: 5.77058e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:30:58.977797 22392998065984 run_lib.py:146] step: 179900, training_loss: 6.06161e-02
I0514 19:30:59.136232 22392998065984 run_lib.py:167] step: 179900, eval_loss: 8.07735e-02
I0514 19:31:22.478792 22392998065984 run_lib.py:146] step: 179950, training_loss: 5.57583e-02
I0514 19:31:45.824759 22392998065984 run_lib.py:146] step: 180000, training_loss: 6.73097e-02
I0514 19:31:47.596581 22392998065984 run_lib.py:167] step: 180000, eval_loss: 7.94531e-02
I0514 19:32:13.102029 22392998065984 run_lib.py:146] step: 180050, training_loss: 5.88621e-02
I0514 19:32:36.466455 22392998065984 run_lib.py:146] step: 180100, training_loss: 6.81056e-02
I0514 19:32:36.623728 22392998065984 run_lib.py:167] step: 180100, eval_loss: 8.28192e-02
I0514 19:32:59.989251 22392998065984 run_lib.py:146] step: 180150, training_loss: 4.70740e-02
I0514 19:33:23.938348 22392998065984 run_lib.py:146] step: 180200, training_loss: 5.60730e-02
I0514 19:33:24.096002 22392998065984 run_lib.py:167] step: 180200, eval_loss: 5.90936e-02
I0514 19:33:47.347388 22392998065984 run_lib.py:146] step: 180250, training_loss: 5.31891e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:34:10.909301 22392998065984 run_lib.py:146] step: 180300, training_loss: 5.66674e-02
I0514 19:34:11.068354 22392998065984 run_lib.py:167] step: 180300, eval_loss: 5.33817e-02
I0514 19:34:35.080723 22392998065984 run_lib.py:146] step: 180350, training_loss: 4.36021e-02
I0514 19:34:58.448728 22392998065984 run_lib.py:146] step: 180400, training_loss: 6.06171e-02
I0514 19:34:58.606117 22392998065984 run_lib.py:167] step: 180400, eval_loss: 4.39675e-02
I0514 19:35:21.971950 22392998065984 run_lib.py:146] step: 180450, training_loss: 5.66876e-02
I0514 19:35:45.921162 22392998065984 run_lib.py:146] step: 180500, training_loss: 6.75272e-02
I0514 19:35:46.078727 22392998065984 run_lib.py:167] step: 180500, eval_loss: 6.16110e-02
I0514 19:36:09.455815 22392998065984 run_lib.py:146] step: 180550, training_loss: 5.26350e-02
I0514 19:36:32.835737 22392998065984 run_lib.py:146] step: 180600, training_loss: 4.91668e-02
I0514 19:36:32.993000 22392998065984 run_lib.py:167] step: 180600, eval_loss: 6.83739e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:36:57.106344 22392998065984 run_lib.py:146] step: 180650, training_loss: 5.53822e-02
I0514 19:37:20.469821 22392998065984 run_lib.py:146] step: 180700, training_loss: 7.46216e-02
I0514 19:37:20.628421 22392998065984 run_lib.py:167] step: 180700, eval_loss: 6.14204e-02
I0514 19:37:43.982659 22392998065984 run_lib.py:146] step: 180750, training_loss: 7.10360e-02
I0514 19:38:07.673248 22392998065984 run_lib.py:146] step: 180800, training_loss: 5.51529e-02
I0514 19:38:07.830414 22392998065984 run_lib.py:167] step: 180800, eval_loss: 4.96183e-02
I0514 19:38:31.439466 22392998065984 run_lib.py:146] step: 180850, training_loss: 5.88148e-02
I0514 19:38:54.819976 22392998065984 run_lib.py:146] step: 180900, training_loss: 5.14432e-02
I0514 19:38:54.977816 22392998065984 run_lib.py:167] step: 180900, eval_loss: 3.89505e-02
I0514 19:39:18.326102 22392998065984 run_lib.py:146] step: 180950, training_loss: 6.64007e-02
I0514 19:39:42.240030 22392998065984 run_lib.py:146] step: 181000, training_loss: 4.60829e-02
I0514 19:39:42.397138 22392998065984 run_lib.py:167] step: 181000, eval_loss: 7.52418e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:40:05.863618 22392998065984 run_lib.py:146] step: 181050, training_loss: 6.64119e-02
I0514 19:40:29.230345 22392998065984 run_lib.py:146] step: 181100, training_loss: 5.43314e-02
I0514 19:40:29.400269 22392998065984 run_lib.py:167] step: 181100, eval_loss: 5.49377e-02
I0514 19:40:53.410241 22392998065984 run_lib.py:146] step: 181150, training_loss: 5.75440e-02
I0514 19:41:16.770852 22392998065984 run_lib.py:146] step: 181200, training_loss: 5.84555e-02
I0514 19:41:16.928762 22392998065984 run_lib.py:167] step: 181200, eval_loss: 6.67283e-02
I0514 19:41:40.277238 22392998065984 run_lib.py:146] step: 181250, training_loss: 6.23106e-02
I0514 19:42:04.205690 22392998065984 run_lib.py:146] step: 181300, training_loss: 7.48290e-02
I0514 19:42:04.363128 22392998065984 run_lib.py:167] step: 181300, eval_loss: 6.08646e-02
I0514 19:42:27.720453 22392998065984 run_lib.py:146] step: 181350, training_loss: 6.08046e-02
I0514 19:42:51.093506 22392998065984 run_lib.py:146] step: 181400, training_loss: 7.22994e-02
I0514 19:42:51.250541 22392998065984 run_lib.py:167] step: 181400, eval_loss: 6.33144e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:43:15.031485 22392998065984 run_lib.py:146] step: 181450, training_loss: 4.07026e-02
I0514 19:43:38.387959 22392998065984 run_lib.py:146] step: 181500, training_loss: 6.63328e-02
I0514 19:43:38.545629 22392998065984 run_lib.py:167] step: 181500, eval_loss: 6.08523e-02
I0514 19:44:01.911576 22392998065984 run_lib.py:146] step: 181550, training_loss: 5.59974e-02
I0514 19:44:25.855916 22392998065984 run_lib.py:146] step: 181600, training_loss: 6.15077e-02
I0514 19:44:25.935466 22392998065984 run_lib.py:167] step: 181600, eval_loss: 5.35879e-02
I0514 19:44:49.283558 22392998065984 run_lib.py:146] step: 181650, training_loss: 6.34314e-02
I0514 19:45:12.633375 22392998065984 run_lib.py:146] step: 181700, training_loss: 6.37465e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:45:13.013781 22392998065984 run_lib.py:167] step: 181700, eval_loss: 5.83512e-02
I0514 19:45:36.397195 22392998065984 run_lib.py:146] step: 181750, training_loss: 7.65062e-02
I0514 19:46:00.436398 22392998065984 run_lib.py:146] step: 181800, training_loss: 5.46365e-02
I0514 19:46:00.612222 22392998065984 run_lib.py:167] step: 181800, eval_loss: 7.83135e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:46:24.092964 22392998065984 run_lib.py:146] step: 181850, training_loss: 6.07418e-02
I0514 19:46:47.462546 22392998065984 run_lib.py:146] step: 181900, training_loss: 6.66404e-02
I0514 19:46:47.621561 22392998065984 run_lib.py:167] step: 181900, eval_loss: 6.29496e-02
I0514 19:47:11.580134 22392998065984 run_lib.py:146] step: 181950, training_loss: 5.69947e-02
I0514 19:47:34.946381 22392998065984 run_lib.py:146] step: 182000, training_loss: 5.51096e-02
I0514 19:47:35.103902 22392998065984 run_lib.py:167] step: 182000, eval_loss: 6.33820e-02
I0514 19:47:58.492918 22392998065984 run_lib.py:146] step: 182050, training_loss: 5.62600e-02
I0514 19:48:22.435950 22392998065984 run_lib.py:146] step: 182100, training_loss: 4.11950e-02
I0514 19:48:22.593529 22392998065984 run_lib.py:167] step: 182100, eval_loss: 5.59987e-02
I0514 19:48:45.943718 22392998065984 run_lib.py:146] step: 182150, training_loss: 6.76130e-02
I0514 19:49:09.301674 22392998065984 run_lib.py:146] step: 182200, training_loss: 4.42946e-02
I0514 19:49:09.459788 22392998065984 run_lib.py:167] step: 182200, eval_loss: 6.54604e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:49:33.599776 22392998065984 run_lib.py:146] step: 182250, training_loss: 5.82386e-02
I0514 19:49:56.995706 22392998065984 run_lib.py:146] step: 182300, training_loss: 6.56473e-02
I0514 19:49:57.154955 22392998065984 run_lib.py:167] step: 182300, eval_loss: 6.24040e-02
I0514 19:50:20.539905 22392998065984 run_lib.py:146] step: 182350, training_loss: 4.92847e-02
I0514 19:50:44.488753 22392998065984 run_lib.py:146] step: 182400, training_loss: 6.23789e-02
I0514 19:50:44.646303 22392998065984 run_lib.py:167] step: 182400, eval_loss: 6.03039e-02
I0514 19:51:08.015608 22392998065984 run_lib.py:146] step: 182450, training_loss: 6.14465e-02
I0514 19:51:31.387384 22392998065984 run_lib.py:146] step: 182500, training_loss: 7.49829e-02
I0514 19:51:31.545194 22392998065984 run_lib.py:167] step: 182500, eval_loss: 7.49428e-02
I0514 19:51:54.915491 22392998065984 run_lib.py:146] step: 182550, training_loss: 6.81922e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:52:18.953682 22392998065984 run_lib.py:146] step: 182600, training_loss: 5.71746e-02
I0514 19:52:19.112840 22392998065984 run_lib.py:167] step: 182600, eval_loss: 6.59071e-02
I0514 19:52:42.479264 22392998065984 run_lib.py:146] step: 182650, training_loss: 4.75858e-02
I0514 19:53:05.853139 22392998065984 run_lib.py:146] step: 182700, training_loss: 7.61006e-02
I0514 19:53:06.016718 22392998065984 run_lib.py:167] step: 182700, eval_loss: 7.05707e-02
I0514 19:53:29.685058 22392998065984 run_lib.py:146] step: 182750, training_loss: 4.55459e-02
I0514 19:53:53.040072 22392998065984 run_lib.py:146] step: 182800, training_loss: 5.78605e-02
I0514 19:53:53.197712 22392998065984 run_lib.py:167] step: 182800, eval_loss: 5.95926e-02
I0514 19:54:16.594212 22392998065984 run_lib.py:146] step: 182850, training_loss: 7.86905e-02
I0514 19:54:40.513706 22392998065984 run_lib.py:146] step: 182900, training_loss: 6.92296e-02
I0514 19:54:40.671537 22392998065984 run_lib.py:167] step: 182900, eval_loss: 5.19500e-02
I0514 19:55:04.047069 22392998065984 run_lib.py:146] step: 182950, training_loss: 5.07665e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:55:27.534934 22392998065984 run_lib.py:146] step: 183000, training_loss: 9.24639e-02
I0514 19:55:27.694731 22392998065984 run_lib.py:167] step: 183000, eval_loss: 6.21971e-02
I0514 19:55:51.708925 22392998065984 run_lib.py:146] step: 183050, training_loss: 5.20202e-02
I0514 19:56:15.052711 22392998065984 run_lib.py:146] step: 183100, training_loss: 5.14863e-02
I0514 19:56:15.210565 22392998065984 run_lib.py:167] step: 183100, eval_loss: 4.75836e-02
I0514 19:56:38.565056 22392998065984 run_lib.py:146] step: 183150, training_loss: 4.91823e-02
I0514 19:57:02.506536 22392998065984 run_lib.py:146] step: 183200, training_loss: 5.75394e-02
I0514 19:57:02.664101 22392998065984 run_lib.py:167] step: 183200, eval_loss: 6.00373e-02
I0514 19:57:26.037935 22392998065984 run_lib.py:146] step: 183250, training_loss: 4.72806e-02
I0514 19:57:49.410390 22392998065984 run_lib.py:146] step: 183300, training_loss: 4.68837e-02
I0514 19:57:49.567954 22392998065984 run_lib.py:167] step: 183300, eval_loss: 5.49878e-02
I0514 19:58:13.251785 22392998065984 run_lib.py:146] step: 183350, training_loss: 5.58183e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 19:58:36.999477 22392998065984 run_lib.py:146] step: 183400, training_loss: 5.69131e-02
I0514 19:58:37.158651 22392998065984 run_lib.py:167] step: 183400, eval_loss: 5.81891e-02
I0514 19:59:00.512866 22392998065984 run_lib.py:146] step: 183450, training_loss: 5.42412e-02
I0514 19:59:23.881765 22392998065984 run_lib.py:146] step: 183500, training_loss: 4.66049e-02
I0514 19:59:24.039252 22392998065984 run_lib.py:167] step: 183500, eval_loss: 5.31346e-02
I0514 19:59:48.033892 22392998065984 run_lib.py:146] step: 183550, training_loss: 4.56096e-02
I0514 20:00:11.430537 22392998065984 run_lib.py:146] step: 183600, training_loss: 4.40547e-02
I0514 20:00:11.588442 22392998065984 run_lib.py:167] step: 183600, eval_loss: 5.72584e-02
I0514 20:00:34.965120 22392998065984 run_lib.py:146] step: 183650, training_loss: 6.27911e-02
I0514 20:00:58.923608 22392998065984 run_lib.py:146] step: 183700, training_loss: 6.30013e-02
I0514 20:00:59.081363 22392998065984 run_lib.py:167] step: 183700, eval_loss: 8.65350e-02
I0514 20:01:22.437328 22392998065984 run_lib.py:146] step: 183750, training_loss: 6.95029e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:01:45.899438 22392998065984 run_lib.py:146] step: 183800, training_loss: 6.15364e-02
I0514 20:01:46.058382 22392998065984 run_lib.py:167] step: 183800, eval_loss: 5.84407e-02
I0514 20:02:10.079912 22392998065984 run_lib.py:146] step: 183850, training_loss: 4.51257e-02
I0514 20:02:33.440792 22392998065984 run_lib.py:146] step: 183900, training_loss: 5.11639e-02
I0514 20:02:33.598350 22392998065984 run_lib.py:167] step: 183900, eval_loss: 4.97902e-02
I0514 20:02:56.953880 22392998065984 run_lib.py:146] step: 183950, training_loss: 5.82060e-02
I0514 20:03:20.883158 22392998065984 run_lib.py:146] step: 184000, training_loss: 6.95747e-02
I0514 20:03:21.040963 22392998065984 run_lib.py:167] step: 184000, eval_loss: 6.55028e-02
I0514 20:03:44.422059 22392998065984 run_lib.py:146] step: 184050, training_loss: 6.31925e-02
I0514 20:04:08.008318 22392998065984 run_lib.py:146] step: 184100, training_loss: 6.46100e-02
I0514 20:04:08.167377 22392998065984 run_lib.py:167] step: 184100, eval_loss: 5.10517e-02
I0514 20:04:32.123545 22392998065984 run_lib.py:146] step: 184150, training_loss: 5.38017e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:04:55.596050 22392998065984 run_lib.py:146] step: 184200, training_loss: 6.61171e-02
I0514 20:04:55.755092 22392998065984 run_lib.py:167] step: 184200, eval_loss: 6.77600e-02
I0514 20:05:19.129477 22392998065984 run_lib.py:146] step: 184250, training_loss: 7.40393e-02
I0514 20:05:42.819281 22392998065984 run_lib.py:146] step: 184300, training_loss: 3.96608e-02
I0514 20:05:42.984100 22392998065984 run_lib.py:167] step: 184300, eval_loss: 5.60198e-02
I0514 20:06:06.656615 22392998065984 run_lib.py:146] step: 184350, training_loss: 6.07108e-02
I0514 20:06:30.041038 22392998065984 run_lib.py:146] step: 184400, training_loss: 7.47755e-02
I0514 20:06:30.199032 22392998065984 run_lib.py:167] step: 184400, eval_loss: 6.95166e-02
I0514 20:06:53.582504 22392998065984 run_lib.py:146] step: 184450, training_loss: 4.56384e-02
I0514 20:07:17.533336 22392998065984 run_lib.py:146] step: 184500, training_loss: 5.43986e-02
I0514 20:07:17.690947 22392998065984 run_lib.py:167] step: 184500, eval_loss: 5.78234e-02
I0514 20:07:41.058467 22392998065984 run_lib.py:146] step: 184550, training_loss: 6.22240e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:08:04.528587 22392998065984 run_lib.py:146] step: 184600, training_loss: 5.65681e-02
I0514 20:08:04.687709 22392998065984 run_lib.py:167] step: 184600, eval_loss: 5.51031e-02
I0514 20:08:28.754701 22392998065984 run_lib.py:146] step: 184650, training_loss: 4.78545e-02
I0514 20:08:52.147379 22392998065984 run_lib.py:146] step: 184700, training_loss: 6.07420e-02
I0514 20:08:52.305256 22392998065984 run_lib.py:167] step: 184700, eval_loss: 5.75737e-02
I0514 20:09:15.683972 22392998065984 run_lib.py:146] step: 184750, training_loss: 6.62688e-02
I0514 20:09:39.642632 22392998065984 run_lib.py:146] step: 184800, training_loss: 5.07401e-02
I0514 20:09:39.800745 22392998065984 run_lib.py:167] step: 184800, eval_loss: 4.42224e-02
I0514 20:10:03.189439 22392998065984 run_lib.py:146] step: 184850, training_loss: 6.40803e-02
I0514 20:10:26.571900 22392998065984 run_lib.py:146] step: 184900, training_loss: 5.28977e-02
I0514 20:10:26.729690 22392998065984 run_lib.py:167] step: 184900, eval_loss: 5.86138e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:10:50.866416 22392998065984 run_lib.py:146] step: 184950, training_loss: 7.11646e-02
I0514 20:11:14.217883 22392998065984 run_lib.py:146] step: 185000, training_loss: 4.41728e-02
I0514 20:11:14.376758 22392998065984 run_lib.py:167] step: 185000, eval_loss: 6.49135e-02
I0514 20:11:37.740164 22392998065984 run_lib.py:146] step: 185050, training_loss: 6.17999e-02
I0514 20:12:01.430029 22392998065984 run_lib.py:146] step: 185100, training_loss: 7.74439e-02
I0514 20:12:01.587857 22392998065984 run_lib.py:167] step: 185100, eval_loss: 5.42274e-02
I0514 20:12:25.226932 22392998065984 run_lib.py:146] step: 185150, training_loss: 7.57848e-02
I0514 20:12:48.602759 22392998065984 run_lib.py:146] step: 185200, training_loss: 4.59945e-02
I0514 20:12:48.760967 22392998065984 run_lib.py:167] step: 185200, eval_loss: 6.66383e-02
I0514 20:13:12.122568 22392998065984 run_lib.py:146] step: 185250, training_loss: 4.57964e-02
I0514 20:13:36.052403 22392998065984 run_lib.py:146] step: 185300, training_loss: 5.05689e-02
I0514 20:13:36.210108 22392998065984 run_lib.py:167] step: 185300, eval_loss: 7.31262e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:13:59.681681 22392998065984 run_lib.py:146] step: 185350, training_loss: 7.14500e-02
I0514 20:14:23.074910 22392998065984 run_lib.py:146] step: 185400, training_loss: 5.78836e-02
I0514 20:14:23.233987 22392998065984 run_lib.py:167] step: 185400, eval_loss: 4.93520e-02
I0514 20:14:47.226120 22392998065984 run_lib.py:146] step: 185450, training_loss: 5.88661e-02
I0514 20:15:10.590559 22392998065984 run_lib.py:146] step: 185500, training_loss: 5.03837e-02
I0514 20:15:10.748014 22392998065984 run_lib.py:167] step: 185500, eval_loss: 5.80112e-02
I0514 20:15:34.110480 22392998065984 run_lib.py:146] step: 185550, training_loss: 6.55676e-02
I0514 20:15:58.059237 22392998065984 run_lib.py:146] step: 185600, training_loss: 5.74031e-02
I0514 20:15:58.216787 22392998065984 run_lib.py:167] step: 185600, eval_loss: 6.06067e-02
I0514 20:16:21.586551 22392998065984 run_lib.py:146] step: 185650, training_loss: 4.78594e-02
I0514 20:16:44.956698 22392998065984 run_lib.py:146] step: 185700, training_loss: 5.22705e-02
I0514 20:16:45.114390 22392998065984 run_lib.py:167] step: 185700, eval_loss: 4.94950e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:17:09.244294 22392998065984 run_lib.py:146] step: 185750, training_loss: 6.49363e-02
I0514 20:17:32.621839 22392998065984 run_lib.py:146] step: 185800, training_loss: 6.14953e-02
I0514 20:17:32.780526 22392998065984 run_lib.py:167] step: 185800, eval_loss: 4.89671e-02
I0514 20:17:56.164416 22392998065984 run_lib.py:146] step: 185850, training_loss: 6.25401e-02
I0514 20:18:19.867386 22392998065984 run_lib.py:146] step: 185900, training_loss: 5.91408e-02
I0514 20:18:20.043881 22392998065984 run_lib.py:167] step: 185900, eval_loss: 6.35157e-02
I0514 20:18:43.698552 22392998065984 run_lib.py:146] step: 185950, training_loss: 5.61574e-02
I0514 20:19:07.087748 22392998065984 run_lib.py:146] step: 186000, training_loss: 7.56913e-02
I0514 20:19:07.245731 22392998065984 run_lib.py:167] step: 186000, eval_loss: 5.10356e-02
I0514 20:19:30.636867 22392998065984 run_lib.py:146] step: 186050, training_loss: 5.53926e-02
I0514 20:19:54.594547 22392998065984 run_lib.py:146] step: 186100, training_loss: 4.64475e-02
I0514 20:19:54.752290 22392998065984 run_lib.py:167] step: 186100, eval_loss: 5.49054e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:20:18.245741 22392998065984 run_lib.py:146] step: 186150, training_loss: 6.68903e-02
I0514 20:20:41.605675 22392998065984 run_lib.py:146] step: 186200, training_loss: 5.31671e-02
I0514 20:20:41.764687 22392998065984 run_lib.py:167] step: 186200, eval_loss: 5.13046e-02
I0514 20:21:05.766725 22392998065984 run_lib.py:146] step: 186250, training_loss: 6.20264e-02
I0514 20:21:29.129602 22392998065984 run_lib.py:146] step: 186300, training_loss: 5.82124e-02
I0514 20:21:29.287422 22392998065984 run_lib.py:167] step: 186300, eval_loss: 6.09581e-02
I0514 20:21:52.652697 22392998065984 run_lib.py:146] step: 186350, training_loss: 5.81829e-02
I0514 20:22:16.608807 22392998065984 run_lib.py:146] step: 186400, training_loss: 5.93466e-02
I0514 20:22:16.766834 22392998065984 run_lib.py:167] step: 186400, eval_loss: 6.60394e-02
I0514 20:22:40.145900 22392998065984 run_lib.py:146] step: 186450, training_loss: 5.58884e-02
I0514 20:23:03.516420 22392998065984 run_lib.py:146] step: 186500, training_loss: 5.41271e-02
I0514 20:23:03.674097 22392998065984 run_lib.py:167] step: 186500, eval_loss: 4.98152e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:23:27.808384 22392998065984 run_lib.py:146] step: 186550, training_loss: 7.34849e-02
I0514 20:23:51.180978 22392998065984 run_lib.py:146] step: 186600, training_loss: 6.04545e-02
I0514 20:23:51.340021 22392998065984 run_lib.py:167] step: 186600, eval_loss: 4.32863e-02
I0514 20:24:14.702596 22392998065984 run_lib.py:146] step: 186650, training_loss: 7.10222e-02
I0514 20:24:38.361103 22392998065984 run_lib.py:146] step: 186700, training_loss: 4.98233e-02
I0514 20:24:38.518831 22392998065984 run_lib.py:167] step: 186700, eval_loss: 5.75792e-02
I0514 20:25:02.197651 22392998065984 run_lib.py:146] step: 186750, training_loss: 6.44577e-02
I0514 20:25:25.585840 22392998065984 run_lib.py:146] step: 186800, training_loss: 6.43097e-02
I0514 20:25:25.743527 22392998065984 run_lib.py:167] step: 186800, eval_loss: 5.62203e-02
I0514 20:25:49.432956 22392998065984 run_lib.py:146] step: 186850, training_loss: 4.95042e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:26:13.172667 22392998065984 run_lib.py:146] step: 186900, training_loss: 6.09597e-02
I0514 20:26:13.332309 22392998065984 run_lib.py:167] step: 186900, eval_loss: 7.30939e-02
I0514 20:26:36.705072 22392998065984 run_lib.py:146] step: 186950, training_loss: 4.49760e-02
I0514 20:27:00.085702 22392998065984 run_lib.py:146] step: 187000, training_loss: 7.02589e-02
I0514 20:27:00.243528 22392998065984 run_lib.py:167] step: 187000, eval_loss: 7.61981e-02
I0514 20:27:24.235244 22392998065984 run_lib.py:146] step: 187050, training_loss: 5.06640e-02
I0514 20:27:47.595222 22392998065984 run_lib.py:146] step: 187100, training_loss: 8.00753e-02
I0514 20:27:47.752548 22392998065984 run_lib.py:167] step: 187100, eval_loss: 6.58175e-02
I0514 20:28:11.125720 22392998065984 run_lib.py:146] step: 187150, training_loss: 4.68997e-02
I0514 20:28:35.060556 22392998065984 run_lib.py:146] step: 187200, training_loss: 6.93961e-02
I0514 20:28:35.218038 22392998065984 run_lib.py:167] step: 187200, eval_loss: 6.20623e-02
I0514 20:28:58.575254 22392998065984 run_lib.py:146] step: 187250, training_loss: 6.17253e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:29:22.045608 22392998065984 run_lib.py:146] step: 187300, training_loss: 6.73265e-02
I0514 20:29:22.205104 22392998065984 run_lib.py:167] step: 187300, eval_loss: 5.35163e-02
I0514 20:29:46.225720 22392998065984 run_lib.py:146] step: 187350, training_loss: 6.76633e-02
I0514 20:30:09.606522 22392998065984 run_lib.py:146] step: 187400, training_loss: 4.56104e-02
I0514 20:30:09.764014 22392998065984 run_lib.py:167] step: 187400, eval_loss: 4.09666e-02
I0514 20:30:33.144383 22392998065984 run_lib.py:146] step: 187450, training_loss: 4.83662e-02
I0514 20:30:57.151427 22392998065984 run_lib.py:146] step: 187500, training_loss: 6.33507e-02
I0514 20:30:57.318426 22392998065984 run_lib.py:167] step: 187500, eval_loss: 5.71265e-02
I0514 20:31:21.786002 22392998065984 run_lib.py:146] step: 187550, training_loss: 4.93025e-02
I0514 20:31:45.822036 22392998065984 run_lib.py:146] step: 187600, training_loss: 4.05706e-02
I0514 20:31:45.978731 22392998065984 run_lib.py:167] step: 187600, eval_loss: 6.79020e-02
I0514 20:32:10.270136 22392998065984 run_lib.py:146] step: 187650, training_loss: 5.89841e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:32:34.568007 22392998065984 run_lib.py:146] step: 187700, training_loss: 6.75372e-02
I0514 20:32:34.726110 22392998065984 run_lib.py:167] step: 187700, eval_loss: 5.47326e-02
I0514 20:32:58.026161 22392998065984 run_lib.py:146] step: 187750, training_loss: 5.15782e-02
I0514 20:33:21.374424 22392998065984 run_lib.py:146] step: 187800, training_loss: 6.77790e-02
I0514 20:33:21.531742 22392998065984 run_lib.py:167] step: 187800, eval_loss: 5.93628e-02
I0514 20:33:45.621482 22392998065984 run_lib.py:146] step: 187850, training_loss: 5.26177e-02
I0514 20:34:09.122822 22392998065984 run_lib.py:146] step: 187900, training_loss: 6.72816e-02
I0514 20:34:09.280234 22392998065984 run_lib.py:167] step: 187900, eval_loss: 5.68534e-02
I0514 20:34:32.794744 22392998065984 run_lib.py:146] step: 187950, training_loss: 6.93270e-02
I0514 20:34:56.679356 22392998065984 run_lib.py:146] step: 188000, training_loss: 6.00854e-02
I0514 20:34:56.835890 22392998065984 run_lib.py:167] step: 188000, eval_loss: 6.87886e-02
I0514 20:35:20.092012 22392998065984 run_lib.py:146] step: 188050, training_loss: 6.29753e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:35:43.508599 22392998065984 run_lib.py:146] step: 188100, training_loss: 5.76260e-02
I0514 20:35:43.666681 22392998065984 run_lib.py:167] step: 188100, eval_loss: 8.90969e-02
I0514 20:36:08.198887 22392998065984 run_lib.py:146] step: 188150, training_loss: 6.70768e-02
I0514 20:36:32.099772 22392998065984 run_lib.py:146] step: 188200, training_loss: 5.27389e-02
I0514 20:36:32.256223 22392998065984 run_lib.py:167] step: 188200, eval_loss: 5.41583e-02
I0514 20:36:56.182370 22392998065984 run_lib.py:146] step: 188250, training_loss: 7.28846e-02
I0514 20:37:20.382910 22392998065984 run_lib.py:146] step: 188300, training_loss: 6.52058e-02
I0514 20:37:20.539604 22392998065984 run_lib.py:167] step: 188300, eval_loss: 5.53205e-02
I0514 20:37:44.774692 22392998065984 run_lib.py:146] step: 188350, training_loss: 5.60457e-02
I0514 20:38:08.675816 22392998065984 run_lib.py:146] step: 188400, training_loss: 6.39007e-02
I0514 20:38:08.832226 22392998065984 run_lib.py:167] step: 188400, eval_loss: 6.37630e-02
I0514 20:38:33.018328 22392998065984 run_lib.py:146] step: 188450, training_loss: 4.32783e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:38:56.979912 22392998065984 run_lib.py:146] step: 188500, training_loss: 7.02214e-02
I0514 20:38:57.152596 22392998065984 run_lib.py:167] step: 188500, eval_loss: 6.85751e-02
I0514 20:39:20.435825 22392998065984 run_lib.py:146] step: 188550, training_loss: 4.97795e-02
I0514 20:39:43.716685 22392998065984 run_lib.py:146] step: 188600, training_loss: 5.86738e-02
I0514 20:39:43.873302 22392998065984 run_lib.py:167] step: 188600, eval_loss: 5.45865e-02
I0514 20:40:07.764369 22392998065984 run_lib.py:146] step: 188650, training_loss: 5.53603e-02
I0514 20:40:31.043526 22392998065984 run_lib.py:146] step: 188700, training_loss: 6.42288e-02
I0514 20:40:31.200700 22392998065984 run_lib.py:167] step: 188700, eval_loss: 6.64541e-02
I0514 20:40:54.488306 22392998065984 run_lib.py:146] step: 188750, training_loss: 6.27217e-02
I0514 20:41:18.378534 22392998065984 run_lib.py:146] step: 188800, training_loss: 5.43604e-02
I0514 20:41:18.535532 22392998065984 run_lib.py:167] step: 188800, eval_loss: 7.07409e-02
I0514 20:41:42.010331 22392998065984 run_lib.py:146] step: 188850, training_loss: 6.77118e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:42:05.486259 22392998065984 run_lib.py:146] step: 188900, training_loss: 5.29813e-02
I0514 20:42:05.644344 22392998065984 run_lib.py:167] step: 188900, eval_loss: 6.66173e-02
I0514 20:42:29.595895 22392998065984 run_lib.py:146] step: 188950, training_loss: 6.10826e-02
I0514 20:42:52.860922 22392998065984 run_lib.py:146] step: 189000, training_loss: 6.53938e-02
I0514 20:42:53.017888 22392998065984 run_lib.py:167] step: 189000, eval_loss: 5.90385e-02
I0514 20:43:16.299721 22392998065984 run_lib.py:146] step: 189050, training_loss: 5.52526e-02
I0514 20:43:40.178172 22392998065984 run_lib.py:146] step: 189100, training_loss: 6.82970e-02
I0514 20:43:40.334434 22392998065984 run_lib.py:167] step: 189100, eval_loss: 5.77379e-02
I0514 20:44:03.613233 22392998065984 run_lib.py:146] step: 189150, training_loss: 5.05789e-02
I0514 20:44:26.888028 22392998065984 run_lib.py:146] step: 189200, training_loss: 4.26959e-02
I0514 20:44:27.045169 22392998065984 run_lib.py:167] step: 189200, eval_loss: 5.70176e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:44:50.806099 22392998065984 run_lib.py:146] step: 189250, training_loss: 6.92910e-02
I0514 20:45:14.504986 22392998065984 run_lib.py:146] step: 189300, training_loss: 5.63322e-02
I0514 20:45:14.663190 22392998065984 run_lib.py:167] step: 189300, eval_loss: 5.06753e-02
I0514 20:45:37.976050 22392998065984 run_lib.py:146] step: 189350, training_loss: 7.24928e-02
I0514 20:46:01.268623 22392998065984 run_lib.py:146] step: 189400, training_loss: 5.66957e-02
I0514 20:46:01.424430 22392998065984 run_lib.py:167] step: 189400, eval_loss: 5.34610e-02
I0514 20:46:25.359233 22392998065984 run_lib.py:146] step: 189450, training_loss: 7.03431e-02
I0514 20:46:48.673182 22392998065984 run_lib.py:146] step: 189500, training_loss: 7.91238e-02
I0514 20:46:48.752299 22392998065984 run_lib.py:167] step: 189500, eval_loss: 8.28853e-02
I0514 20:47:12.072434 22392998065984 run_lib.py:146] step: 189550, training_loss: 6.03044e-02
I0514 20:47:36.003140 22392998065984 run_lib.py:146] step: 189600, training_loss: 6.48313e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:47:36.370658 22392998065984 run_lib.py:167] step: 189600, eval_loss: 6.93916e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:48:00.032737 22392998065984 run_lib.py:146] step: 189650, training_loss: 5.66475e-02
I0514 20:48:23.993465 22392998065984 run_lib.py:146] step: 189700, training_loss: 6.64117e-02
I0514 20:48:24.151728 22392998065984 run_lib.py:167] step: 189700, eval_loss: 5.54416e-02
I0514 20:48:48.717460 22392998065984 run_lib.py:146] step: 189750, training_loss: 5.82316e-02
I0514 20:49:12.284137 22392998065984 run_lib.py:146] step: 189800, training_loss: 7.53321e-02
I0514 20:49:12.440875 22392998065984 run_lib.py:167] step: 189800, eval_loss: 5.39014e-02
I0514 20:49:35.709064 22392998065984 run_lib.py:146] step: 189850, training_loss: 6.80714e-02
I0514 20:49:59.266681 22392998065984 run_lib.py:146] step: 189900, training_loss: 4.81879e-02
I0514 20:49:59.422755 22392998065984 run_lib.py:167] step: 189900, eval_loss: 5.49601e-02
I0514 20:50:23.006735 22392998065984 run_lib.py:146] step: 189950, training_loss: 6.84004e-02
I0514 20:50:46.254025 22392998065984 run_lib.py:146] step: 190000, training_loss: 5.39964e-02
I0514 20:50:47.993668 22392998065984 run_lib.py:167] step: 190000, eval_loss: 5.85761e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:51:13.573107 22392998065984 run_lib.py:146] step: 190050, training_loss: 5.27705e-02
I0514 20:51:37.859663 22392998065984 run_lib.py:146] step: 190100, training_loss: 8.00691e-02
I0514 20:51:38.017333 22392998065984 run_lib.py:167] step: 190100, eval_loss: 7.10375e-02
I0514 20:52:01.397713 22392998065984 run_lib.py:146] step: 190150, training_loss: 4.88483e-02
I0514 20:52:25.017253 22392998065984 run_lib.py:146] step: 190200, training_loss: 6.90651e-02
I0514 20:52:25.173467 22392998065984 run_lib.py:167] step: 190200, eval_loss: 6.99474e-02
I0514 20:52:48.765636 22392998065984 run_lib.py:146] step: 190250, training_loss: 4.99372e-02
I0514 20:53:12.033452 22392998065984 run_lib.py:146] step: 190300, training_loss: 7.28185e-02
I0514 20:53:12.206325 22392998065984 run_lib.py:167] step: 190300, eval_loss: 7.46386e-02
I0514 20:53:35.777686 22392998065984 run_lib.py:146] step: 190350, training_loss: 5.06471e-02
I0514 20:53:59.380454 22392998065984 run_lib.py:146] step: 190400, training_loss: 6.33074e-02
I0514 20:53:59.536875 22392998065984 run_lib.py:167] step: 190400, eval_loss: 5.97036e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:54:22.951970 22392998065984 run_lib.py:146] step: 190450, training_loss: 6.38871e-02
I0514 20:54:46.568938 22392998065984 run_lib.py:146] step: 190500, training_loss: 6.35663e-02
I0514 20:54:46.727050 22392998065984 run_lib.py:167] step: 190500, eval_loss: 7.53532e-02
I0514 20:55:10.928570 22392998065984 run_lib.py:146] step: 190550, training_loss: 9.36866e-02
I0514 20:55:34.828993 22392998065984 run_lib.py:146] step: 190600, training_loss: 5.08931e-02
I0514 20:55:34.985421 22392998065984 run_lib.py:167] step: 190600, eval_loss: 6.71495e-02
I0514 20:55:59.198568 22392998065984 run_lib.py:146] step: 190650, training_loss: 4.93530e-02
I0514 20:56:23.121921 22392998065984 run_lib.py:146] step: 190700, training_loss: 7.58952e-02
I0514 20:56:23.278634 22392998065984 run_lib.py:167] step: 190700, eval_loss: 6.23538e-02
I0514 20:56:47.502726 22392998065984 run_lib.py:146] step: 190750, training_loss: 4.58793e-02
I0514 20:57:11.409075 22392998065984 run_lib.py:146] step: 190800, training_loss: 4.99531e-02
I0514 20:57:11.566223 22392998065984 run_lib.py:167] step: 190800, eval_loss: 5.10915e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 20:57:35.383643 22392998065984 run_lib.py:146] step: 190850, training_loss: 6.41579e-02
I0514 20:57:58.968431 22392998065984 run_lib.py:146] step: 190900, training_loss: 6.08372e-02
I0514 20:57:59.126462 22392998065984 run_lib.py:167] step: 190900, eval_loss: 6.47542e-02
I0514 20:58:22.381924 22392998065984 run_lib.py:146] step: 190950, training_loss: 6.91727e-02
I0514 20:58:45.985316 22392998065984 run_lib.py:146] step: 191000, training_loss: 6.75898e-02
I0514 20:58:46.142114 22392998065984 run_lib.py:167] step: 191000, eval_loss: 4.78043e-02
I0514 20:59:09.717509 22392998065984 run_lib.py:146] step: 191050, training_loss: 6.41741e-02
I0514 20:59:33.136529 22392998065984 run_lib.py:146] step: 191100, training_loss: 5.68505e-02
I0514 20:59:33.292786 22392998065984 run_lib.py:167] step: 191100, eval_loss: 5.99254e-02
I0514 20:59:57.045129 22392998065984 run_lib.py:146] step: 191150, training_loss: 5.09490e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:00:20.791092 22392998065984 run_lib.py:146] step: 191200, training_loss: 5.43449e-02
I0514 21:00:20.949139 22392998065984 run_lib.py:167] step: 191200, eval_loss: 6.77547e-02
I0514 21:00:44.246938 22392998065984 run_lib.py:146] step: 191250, training_loss: 4.99981e-02
I0514 21:01:07.858328 22392998065984 run_lib.py:146] step: 191300, training_loss: 4.48779e-02
I0514 21:01:08.014555 22392998065984 run_lib.py:167] step: 191300, eval_loss: 7.84425e-02
I0514 21:01:31.614217 22392998065984 run_lib.py:146] step: 191350, training_loss: 5.93817e-02
I0514 21:01:54.896145 22392998065984 run_lib.py:146] step: 191400, training_loss: 6.19869e-02
I0514 21:01:55.052635 22392998065984 run_lib.py:167] step: 191400, eval_loss: 4.32888e-02
I0514 21:02:18.652791 22392998065984 run_lib.py:146] step: 191450, training_loss: 4.96895e-02
I0514 21:02:41.940236 22392998065984 run_lib.py:146] step: 191500, training_loss: 5.56523e-02
I0514 21:02:42.097245 22392998065984 run_lib.py:167] step: 191500, eval_loss: 6.66035e-02
I0514 21:03:05.679864 22392998065984 run_lib.py:146] step: 191550, training_loss: 6.59920e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:03:29.568677 22392998065984 run_lib.py:146] step: 191600, training_loss: 7.91188e-02
I0514 21:03:29.726001 22392998065984 run_lib.py:167] step: 191600, eval_loss: 7.88119e-02
I0514 21:03:53.636258 22392998065984 run_lib.py:146] step: 191650, training_loss: 5.70665e-02
I0514 21:04:17.935992 22392998065984 run_lib.py:146] step: 191700, training_loss: 6.29489e-02
I0514 21:04:18.093306 22392998065984 run_lib.py:167] step: 191700, eval_loss: 5.16166e-02
I0514 21:04:42.003403 22392998065984 run_lib.py:146] step: 191750, training_loss: 5.09890e-02
I0514 21:05:06.185868 22392998065984 run_lib.py:146] step: 191800, training_loss: 5.09002e-02
I0514 21:05:06.341996 22392998065984 run_lib.py:167] step: 191800, eval_loss: 6.07172e-02
I0514 21:05:30.567736 22392998065984 run_lib.py:146] step: 191850, training_loss: 6.30642e-02
I0514 21:05:54.470480 22392998065984 run_lib.py:146] step: 191900, training_loss: 5.70443e-02
I0514 21:05:54.627059 22392998065984 run_lib.py:167] step: 191900, eval_loss: 6.06773e-02
I0514 21:06:18.831870 22392998065984 run_lib.py:146] step: 191950, training_loss: 6.44144e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:06:43.013455 22392998065984 run_lib.py:146] step: 192000, training_loss: 6.21926e-02
I0514 21:06:43.173157 22392998065984 run_lib.py:167] step: 192000, eval_loss: 6.23877e-02
I0514 21:07:06.462162 22392998065984 run_lib.py:146] step: 192050, training_loss: 3.94414e-02
I0514 21:07:30.126297 22392998065984 run_lib.py:146] step: 192100, training_loss: 5.64300e-02
I0514 21:07:30.283216 22392998065984 run_lib.py:167] step: 192100, eval_loss: 6.48823e-02
I0514 21:07:53.873091 22392998065984 run_lib.py:146] step: 192150, training_loss: 6.40737e-02
I0514 21:08:17.154238 22392998065984 run_lib.py:146] step: 192200, training_loss: 5.53808e-02
I0514 21:08:17.310993 22392998065984 run_lib.py:167] step: 192200, eval_loss: 5.92445e-02
I0514 21:08:40.907339 22392998065984 run_lib.py:146] step: 192250, training_loss: 5.42618e-02
I0514 21:09:04.223250 22392998065984 run_lib.py:146] step: 192300, training_loss: 6.17764e-02
I0514 21:09:04.379560 22392998065984 run_lib.py:167] step: 192300, eval_loss: 5.77878e-02
I0514 21:09:27.988585 22392998065984 run_lib.py:146] step: 192350, training_loss: 5.08636e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:09:51.846674 22392998065984 run_lib.py:146] step: 192400, training_loss: 5.26146e-02
I0514 21:09:52.004724 22392998065984 run_lib.py:167] step: 192400, eval_loss: 5.89842e-02
I0514 21:10:15.406209 22392998065984 run_lib.py:146] step: 192450, training_loss: 6.92499e-02
I0514 21:10:39.146353 22392998065984 run_lib.py:146] step: 192500, training_loss: 6.38165e-02
I0514 21:10:39.303627 22392998065984 run_lib.py:167] step: 192500, eval_loss: 5.39866e-02
I0514 21:11:02.969549 22392998065984 run_lib.py:146] step: 192550, training_loss: 5.29238e-02
I0514 21:11:26.343664 22392998065984 run_lib.py:146] step: 192600, training_loss: 5.82252e-02
I0514 21:11:26.500466 22392998065984 run_lib.py:167] step: 192600, eval_loss: 5.73296e-02
I0514 21:11:50.180846 22392998065984 run_lib.py:146] step: 192650, training_loss: 5.40976e-02
I0514 21:12:13.964564 22392998065984 run_lib.py:146] step: 192700, training_loss: 5.97784e-02
I0514 21:12:14.121311 22392998065984 run_lib.py:167] step: 192700, eval_loss: 6.26014e-02
I0514 21:12:38.462493 22392998065984 run_lib.py:146] step: 192750, training_loss: 5.88638e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:13:02.485127 22392998065984 run_lib.py:146] step: 192800, training_loss: 6.11068e-02
I0514 21:13:02.643485 22392998065984 run_lib.py:167] step: 192800, eval_loss: 7.37560e-02
I0514 21:13:25.968195 22392998065984 run_lib.py:146] step: 192850, training_loss: 5.84422e-02
I0514 21:13:49.686023 22392998065984 run_lib.py:146] step: 192900, training_loss: 5.72149e-02
I0514 21:13:49.842873 22392998065984 run_lib.py:167] step: 192900, eval_loss: 4.48129e-02
I0514 21:14:13.517405 22392998065984 run_lib.py:146] step: 192950, training_loss: 4.23371e-02
I0514 21:14:36.903373 22392998065984 run_lib.py:146] step: 193000, training_loss: 5.69182e-02
I0514 21:14:37.059920 22392998065984 run_lib.py:167] step: 193000, eval_loss: 5.97305e-02
I0514 21:15:00.673543 22392998065984 run_lib.py:146] step: 193050, training_loss: 7.89882e-02
I0514 21:15:24.244703 22392998065984 run_lib.py:146] step: 193100, training_loss: 4.64015e-02
I0514 21:15:24.400872 22392998065984 run_lib.py:167] step: 193100, eval_loss: 8.35241e-02
I0514 21:15:47.686896 22392998065984 run_lib.py:146] step: 193150, training_loss: 4.68463e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:16:11.468489 22392998065984 run_lib.py:146] step: 193200, training_loss: 6.29112e-02
I0514 21:16:11.626729 22392998065984 run_lib.py:167] step: 193200, eval_loss: 6.83173e-02
I0514 21:16:34.947148 22392998065984 run_lib.py:146] step: 193250, training_loss: 5.97661e-02
I0514 21:16:58.604959 22392998065984 run_lib.py:146] step: 193300, training_loss: 8.04588e-02
I0514 21:16:58.761893 22392998065984 run_lib.py:167] step: 193300, eval_loss: 4.48183e-02
I0514 21:17:22.350496 22392998065984 run_lib.py:146] step: 193350, training_loss: 5.86763e-02
I0514 21:17:45.631478 22392998065984 run_lib.py:146] step: 193400, training_loss: 7.26632e-02
I0514 21:17:45.788026 22392998065984 run_lib.py:167] step: 193400, eval_loss: 5.87525e-02
I0514 21:18:09.382179 22392998065984 run_lib.py:146] step: 193450, training_loss: 7.46070e-02
I0514 21:18:32.645149 22392998065984 run_lib.py:146] step: 193500, training_loss: 4.49145e-02
I0514 21:18:32.801857 22392998065984 run_lib.py:167] step: 193500, eval_loss: 7.78477e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:18:56.525780 22392998065984 run_lib.py:146] step: 193550, training_loss: 5.37903e-02
I0514 21:19:20.164059 22392998065984 run_lib.py:146] step: 193600, training_loss: 5.56244e-02
I0514 21:19:20.321650 22392998065984 run_lib.py:167] step: 193600, eval_loss: 5.99251e-02
I0514 21:19:43.585886 22392998065984 run_lib.py:146] step: 193650, training_loss: 5.41283e-02
I0514 21:20:07.185503 22392998065984 run_lib.py:146] step: 193700, training_loss: 5.80490e-02
I0514 21:20:07.341743 22392998065984 run_lib.py:167] step: 193700, eval_loss: 4.24462e-02
I0514 21:20:30.918868 22392998065984 run_lib.py:146] step: 193750, training_loss: 4.88596e-02
I0514 21:20:54.249318 22392998065984 run_lib.py:146] step: 193800, training_loss: 8.62731e-02
I0514 21:20:54.405878 22392998065984 run_lib.py:167] step: 193800, eval_loss: 5.48752e-02
I0514 21:21:18.502411 22392998065984 run_lib.py:146] step: 193850, training_loss: 5.91380e-02
I0514 21:21:42.625321 22392998065984 run_lib.py:146] step: 193900, training_loss: 7.00190e-02
I0514 21:21:42.782151 22392998065984 run_lib.py:167] step: 193900, eval_loss: 5.79488e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:22:06.626030 22392998065984 run_lib.py:146] step: 193950, training_loss: 4.89377e-02
I0514 21:22:30.249615 22392998065984 run_lib.py:146] step: 194000, training_loss: 7.08497e-02
I0514 21:22:30.407023 22392998065984 run_lib.py:167] step: 194000, eval_loss: 5.94913e-02
I0514 21:22:53.689094 22392998065984 run_lib.py:146] step: 194050, training_loss: 6.65388e-02
I0514 21:23:17.318448 22392998065984 run_lib.py:146] step: 194100, training_loss: 4.98503e-02
I0514 21:23:17.475293 22392998065984 run_lib.py:167] step: 194100, eval_loss: 6.36778e-02
I0514 21:23:41.054230 22392998065984 run_lib.py:146] step: 194150, training_loss: 5.71581e-02
I0514 21:24:04.335548 22392998065984 run_lib.py:146] step: 194200, training_loss: 6.65542e-02
I0514 21:24:04.491852 22392998065984 run_lib.py:167] step: 194200, eval_loss: 4.55831e-02
I0514 21:24:28.060407 22392998065984 run_lib.py:146] step: 194250, training_loss: 5.20114e-02
I0514 21:24:51.357428 22392998065984 run_lib.py:146] step: 194300, training_loss: 4.48730e-02
I0514 21:24:51.514528 22392998065984 run_lib.py:167] step: 194300, eval_loss: 6.50586e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:25:15.349440 22392998065984 run_lib.py:146] step: 194350, training_loss: 6.19879e-02
I0514 21:25:39.512356 22392998065984 run_lib.py:146] step: 194400, training_loss: 4.92088e-02
I0514 21:25:39.670284 22392998065984 run_lib.py:167] step: 194400, eval_loss: 6.52179e-02
I0514 21:26:03.512445 22392998065984 run_lib.py:146] step: 194450, training_loss: 6.63520e-02
I0514 21:26:27.661972 22392998065984 run_lib.py:146] step: 194500, training_loss: 6.18736e-02
I0514 21:26:27.818151 22392998065984 run_lib.py:167] step: 194500, eval_loss: 5.79450e-02
I0514 21:26:51.944059 22392998065984 run_lib.py:146] step: 194550, training_loss: 7.45553e-02
I0514 21:27:15.770585 22392998065984 run_lib.py:146] step: 194600, training_loss: 5.88411e-02
I0514 21:27:15.927391 22392998065984 run_lib.py:167] step: 194600, eval_loss: 6.20999e-02
I0514 21:27:40.038726 22392998065984 run_lib.py:146] step: 194650, training_loss: 4.72628e-02
I0514 21:28:04.174654 22392998065984 run_lib.py:146] step: 194700, training_loss: 6.75400e-02
I0514 21:28:04.331128 22392998065984 run_lib.py:167] step: 194700, eval_loss: 6.70440e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:28:27.962059 22392998065984 run_lib.py:146] step: 194750, training_loss: 6.02493e-02
I0514 21:28:51.598062 22392998065984 run_lib.py:146] step: 194800, training_loss: 5.03539e-02
I0514 21:28:51.755409 22392998065984 run_lib.py:167] step: 194800, eval_loss: 5.01606e-02
I0514 21:29:15.029452 22392998065984 run_lib.py:146] step: 194850, training_loss: 6.59303e-02
I0514 21:29:38.613873 22392998065984 run_lib.py:146] step: 194900, training_loss: 4.88368e-02
I0514 21:29:38.770237 22392998065984 run_lib.py:167] step: 194900, eval_loss: 6.13670e-02
I0514 21:30:02.332253 22392998065984 run_lib.py:146] step: 194950, training_loss: 4.93620e-02
I0514 21:30:25.617143 22392998065984 run_lib.py:146] step: 195000, training_loss: 4.92790e-02
I0514 21:30:25.773695 22392998065984 run_lib.py:167] step: 195000, eval_loss: 7.30478e-02
I0514 21:30:49.370525 22392998065984 run_lib.py:146] step: 195050, training_loss: 6.09168e-02
I0514 21:31:12.660961 22392998065984 run_lib.py:146] step: 195100, training_loss: 5.00379e-02
I0514 21:31:12.818558 22392998065984 run_lib.py:167] step: 195100, eval_loss: 5.23873e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:31:36.548732 22392998065984 run_lib.py:146] step: 195150, training_loss: 7.43170e-02
I0514 21:32:00.350460 22392998065984 run_lib.py:146] step: 195200, training_loss: 6.27052e-02
I0514 21:32:00.508249 22392998065984 run_lib.py:167] step: 195200, eval_loss: 6.42934e-02
I0514 21:32:24.333744 22392998065984 run_lib.py:146] step: 195250, training_loss: 6.32953e-02
I0514 21:32:47.984852 22392998065984 run_lib.py:146] step: 195300, training_loss: 5.63301e-02
I0514 21:32:48.141605 22392998065984 run_lib.py:167] step: 195300, eval_loss: 6.80765e-02
I0514 21:33:11.689944 22392998065984 run_lib.py:146] step: 195350, training_loss: 5.64981e-02
I0514 21:33:34.948952 22392998065984 run_lib.py:146] step: 195400, training_loss: 5.38017e-02
I0514 21:33:35.105711 22392998065984 run_lib.py:167] step: 195400, eval_loss: 4.44115e-02
I0514 21:33:58.694370 22392998065984 run_lib.py:146] step: 195450, training_loss: 5.05034e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:34:22.404072 22392998065984 run_lib.py:146] step: 195500, training_loss: 5.58019e-02
I0514 21:34:22.562811 22392998065984 run_lib.py:167] step: 195500, eval_loss: 6.83097e-02
I0514 21:34:45.850997 22392998065984 run_lib.py:146] step: 195550, training_loss: 5.39131e-02
I0514 21:35:09.459060 22392998065984 run_lib.py:146] step: 195600, training_loss: 7.60909e-02
I0514 21:35:09.616189 22392998065984 run_lib.py:167] step: 195600, eval_loss: 5.20656e-02
I0514 21:35:33.223170 22392998065984 run_lib.py:146] step: 195650, training_loss: 7.36174e-02
I0514 21:35:56.498789 22392998065984 run_lib.py:146] step: 195700, training_loss: 5.62912e-02
I0514 21:35:56.655900 22392998065984 run_lib.py:167] step: 195700, eval_loss: 7.71774e-02
I0514 21:36:20.224367 22392998065984 run_lib.py:146] step: 195750, training_loss: 6.20021e-02
I0514 21:36:43.502287 22392998065984 run_lib.py:146] step: 195800, training_loss: 5.60426e-02
I0514 21:36:43.658820 22392998065984 run_lib.py:167] step: 195800, eval_loss: 5.87722e-02
I0514 21:37:07.225346 22392998065984 run_lib.py:146] step: 195850, training_loss: 5.38295e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:37:30.653983 22392998065984 run_lib.py:146] step: 195900, training_loss: 5.33620e-02
I0514 21:37:30.812145 22392998065984 run_lib.py:167] step: 195900, eval_loss: 4.91855e-02
I0514 21:37:54.471694 22392998065984 run_lib.py:146] step: 195950, training_loss: 6.42323e-02
I0514 21:38:18.115241 22392998065984 run_lib.py:146] step: 196000, training_loss: 5.44544e-02
I0514 21:38:18.271998 22392998065984 run_lib.py:167] step: 196000, eval_loss: 6.93288e-02
I0514 21:38:41.550861 22392998065984 run_lib.py:146] step: 196050, training_loss: 6.18421e-02
I0514 21:39:05.144477 22392998065984 run_lib.py:146] step: 196100, training_loss: 6.26804e-02
I0514 21:39:05.300908 22392998065984 run_lib.py:167] step: 196100, eval_loss: 5.73701e-02
I0514 21:39:28.894021 22392998065984 run_lib.py:146] step: 196150, training_loss: 4.70091e-02
I0514 21:39:52.165025 22392998065984 run_lib.py:146] step: 196200, training_loss: 5.22336e-02
I0514 21:39:52.321593 22392998065984 run_lib.py:167] step: 196200, eval_loss: 4.66000e-02
I0514 21:40:15.993236 22392998065984 run_lib.py:146] step: 196250, training_loss: 5.59578e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:40:39.759492 22392998065984 run_lib.py:146] step: 196300, training_loss: 5.73986e-02
I0514 21:40:39.917774 22392998065984 run_lib.py:167] step: 196300, eval_loss: 7.01359e-02
I0514 21:41:03.187558 22392998065984 run_lib.py:146] step: 196350, training_loss: 5.79504e-02
I0514 21:41:26.797123 22392998065984 run_lib.py:146] step: 196400, training_loss: 5.58050e-02
I0514 21:41:26.953785 22392998065984 run_lib.py:167] step: 196400, eval_loss: 6.85368e-02
I0514 21:41:50.518358 22392998065984 run_lib.py:146] step: 196450, training_loss: 6.26789e-02
I0514 21:42:13.803651 22392998065984 run_lib.py:146] step: 196500, training_loss: 6.33134e-02
I0514 21:42:13.960092 22392998065984 run_lib.py:167] step: 196500, eval_loss: 6.36439e-02
I0514 21:42:37.553735 22392998065984 run_lib.py:146] step: 196550, training_loss: 5.78011e-02
I0514 21:43:00.823896 22392998065984 run_lib.py:146] step: 196600, training_loss: 5.97348e-02
I0514 21:43:00.994264 22392998065984 run_lib.py:167] step: 196600, eval_loss: 6.11611e-02
I0514 21:43:24.568931 22392998065984 run_lib.py:146] step: 196650, training_loss: 7.51604e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:43:47.970158 22392998065984 run_lib.py:146] step: 196700, training_loss: 7.19418e-02
I0514 21:43:48.129189 22392998065984 run_lib.py:167] step: 196700, eval_loss: 5.03945e-02
I0514 21:44:11.760142 22392998065984 run_lib.py:146] step: 196750, training_loss: 5.74821e-02
I0514 21:44:35.398870 22392998065984 run_lib.py:146] step: 196800, training_loss: 6.10749e-02
I0514 21:44:35.555771 22392998065984 run_lib.py:167] step: 196800, eval_loss: 7.14428e-02
I0514 21:44:58.840908 22392998065984 run_lib.py:146] step: 196850, training_loss: 5.31453e-02
I0514 21:45:22.431118 22392998065984 run_lib.py:146] step: 196900, training_loss: 6.18009e-02
I0514 21:45:22.587707 22392998065984 run_lib.py:167] step: 196900, eval_loss: 5.30213e-02
I0514 21:45:46.199858 22392998065984 run_lib.py:146] step: 196950, training_loss: 5.39918e-02
I0514 21:46:09.502803 22392998065984 run_lib.py:146] step: 197000, training_loss: 7.60478e-02
I0514 21:46:09.660587 22392998065984 run_lib.py:167] step: 197000, eval_loss: 5.53776e-02
I0514 21:46:33.271372 22392998065984 run_lib.py:146] step: 197050, training_loss: 5.66558e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:46:57.086296 22392998065984 run_lib.py:146] step: 197100, training_loss: 5.12485e-02
I0514 21:46:57.244685 22392998065984 run_lib.py:167] step: 197100, eval_loss: 6.45131e-02
I0514 21:47:20.556283 22392998065984 run_lib.py:146] step: 197150, training_loss: 6.03082e-02
I0514 21:47:44.204141 22392998065984 run_lib.py:146] step: 197200, training_loss: 5.79432e-02
I0514 21:47:44.360785 22392998065984 run_lib.py:167] step: 197200, eval_loss: 8.45331e-02
I0514 21:48:07.960796 22392998065984 run_lib.py:146] step: 197250, training_loss: 5.30599e-02
I0514 21:48:31.258502 22392998065984 run_lib.py:146] step: 197300, training_loss: 7.09894e-02
I0514 21:48:31.414623 22392998065984 run_lib.py:167] step: 197300, eval_loss: 5.32258e-02
I0514 21:48:55.049666 22392998065984 run_lib.py:146] step: 197350, training_loss: 5.14520e-02
I0514 21:49:18.943124 22392998065984 run_lib.py:146] step: 197400, training_loss: 6.47700e-02
I0514 21:49:19.023447 22392998065984 run_lib.py:167] step: 197400, eval_loss: 2.36173e-02
I0514 21:49:43.239656 22392998065984 run_lib.py:146] step: 197450, training_loss: 5.78304e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:50:07.113234 22392998065984 run_lib.py:146] step: 197500, training_loss: 8.12919e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:50:07.554743 22392998065984 run_lib.py:167] step: 197500, eval_loss: 9.49043e-02
I0514 21:50:30.960866 22392998065984 run_lib.py:146] step: 197550, training_loss: 4.72251e-02
I0514 21:50:55.210086 22392998065984 run_lib.py:146] step: 197600, training_loss: 5.51868e-02
I0514 21:50:55.366390 22392998065984 run_lib.py:167] step: 197600, eval_loss: 5.99119e-02
I0514 21:51:19.261454 22392998065984 run_lib.py:146] step: 197650, training_loss: 5.10964e-02
I0514 21:51:43.461462 22392998065984 run_lib.py:146] step: 197700, training_loss: 7.78190e-02
I0514 21:51:43.618265 22392998065984 run_lib.py:167] step: 197700, eval_loss: 5.06885e-02
I0514 21:52:07.757111 22392998065984 run_lib.py:146] step: 197750, training_loss: 4.96422e-02
I0514 21:52:31.574918 22392998065984 run_lib.py:146] step: 197800, training_loss: 4.48752e-02
I0514 21:52:31.731544 22392998065984 run_lib.py:167] step: 197800, eval_loss: 7.23787e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:52:55.953786 22392998065984 run_lib.py:146] step: 197850, training_loss: 6.70978e-02
I0514 21:53:20.134619 22392998065984 run_lib.py:146] step: 197900, training_loss: 4.95565e-02
I0514 21:53:20.292421 22392998065984 run_lib.py:167] step: 197900, eval_loss: 6.70662e-02
I0514 21:53:44.135495 22392998065984 run_lib.py:146] step: 197950, training_loss: 7.09286e-02
I0514 21:54:08.283541 22392998065984 run_lib.py:146] step: 198000, training_loss: 5.19902e-02
I0514 21:54:08.439806 22392998065984 run_lib.py:167] step: 198000, eval_loss: 5.94295e-02
I0514 21:54:32.592992 22392998065984 run_lib.py:146] step: 198050, training_loss: 6.87328e-02
I0514 21:54:56.405333 22392998065984 run_lib.py:146] step: 198100, training_loss: 5.70066e-02
I0514 21:54:56.561983 22392998065984 run_lib.py:167] step: 198100, eval_loss: 5.81770e-02
I0514 21:55:20.657442 22392998065984 run_lib.py:146] step: 198150, training_loss: 5.40770e-02
I0514 21:55:44.488836 22392998065984 run_lib.py:146] step: 198200, training_loss: 5.41381e-02
I0514 21:55:44.645078 22392998065984 run_lib.py:167] step: 198200, eval_loss: 5.08447e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:56:08.795126 22392998065984 run_lib.py:146] step: 198250, training_loss: 6.11362e-02
I0514 21:56:32.389969 22392998065984 run_lib.py:146] step: 198300, training_loss: 6.36307e-02
I0514 21:56:32.547549 22392998065984 run_lib.py:167] step: 198300, eval_loss: 6.36742e-02
I0514 21:56:55.809452 22392998065984 run_lib.py:146] step: 198350, training_loss: 5.85860e-02
I0514 21:57:19.424277 22392998065984 run_lib.py:146] step: 198400, training_loss: 7.75697e-02
I0514 21:57:19.581086 22392998065984 run_lib.py:167] step: 198400, eval_loss: 6.55756e-02
I0514 21:57:42.852342 22392998065984 run_lib.py:146] step: 198450, training_loss: 6.91849e-02
I0514 21:58:06.441181 22392998065984 run_lib.py:146] step: 198500, training_loss: 5.92792e-02
I0514 21:58:06.598664 22392998065984 run_lib.py:167] step: 198500, eval_loss: 4.97717e-02
I0514 21:58:30.174203 22392998065984 run_lib.py:146] step: 198550, training_loss: 6.38876e-02
I0514 21:58:53.457473 22392998065984 run_lib.py:146] step: 198600, training_loss: 7.75955e-02
I0514 21:58:53.614766 22392998065984 run_lib.py:167] step: 198600, eval_loss: 4.78566e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 21:59:17.452257 22392998065984 run_lib.py:146] step: 198650, training_loss: 5.77140e-02
I0514 21:59:41.069433 22392998065984 run_lib.py:146] step: 198700, training_loss: 5.95090e-02
I0514 21:59:41.227332 22392998065984 run_lib.py:167] step: 198700, eval_loss: 4.95961e-02
I0514 22:00:04.486609 22392998065984 run_lib.py:146] step: 198750, training_loss: 4.90689e-02
I0514 22:00:28.084741 22392998065984 run_lib.py:146] step: 198800, training_loss: 3.52560e-02
I0514 22:00:28.260361 22392998065984 run_lib.py:167] step: 198800, eval_loss: 4.85211e-02
I0514 22:00:51.821169 22392998065984 run_lib.py:146] step: 198850, training_loss: 5.84287e-02
I0514 22:01:15.092261 22392998065984 run_lib.py:146] step: 198900, training_loss: 5.60818e-02
I0514 22:01:15.249137 22392998065984 run_lib.py:167] step: 198900, eval_loss: 5.44384e-02
I0514 22:01:38.833037 22392998065984 run_lib.py:146] step: 198950, training_loss: 8.19592e-02
I0514 22:02:02.131106 22392998065984 run_lib.py:146] step: 199000, training_loss: 6.98701e-02
I0514 22:02:02.288085 22392998065984 run_lib.py:167] step: 199000, eval_loss: 6.15446e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:02:25.997977 22392998065984 run_lib.py:146] step: 199050, training_loss: 5.08159e-02
I0514 22:02:49.609966 22392998065984 run_lib.py:146] step: 199100, training_loss: 7.43077e-02
I0514 22:02:49.768095 22392998065984 run_lib.py:167] step: 199100, eval_loss: 6.98753e-02
I0514 22:03:13.047283 22392998065984 run_lib.py:146] step: 199150, training_loss: 5.83862e-02
I0514 22:03:36.656937 22392998065984 run_lib.py:146] step: 199200, training_loss: 4.25781e-02
I0514 22:03:36.813975 22392998065984 run_lib.py:167] step: 199200, eval_loss: 5.86625e-02
I0514 22:04:00.106649 22392998065984 run_lib.py:146] step: 199250, training_loss: 5.10698e-02
I0514 22:04:23.675355 22392998065984 run_lib.py:146] step: 199300, training_loss: 5.78129e-02
I0514 22:04:23.832747 22392998065984 run_lib.py:167] step: 199300, eval_loss: 4.66799e-02
I0514 22:04:47.420029 22392998065984 run_lib.py:146] step: 199350, training_loss: 4.59590e-02
I0514 22:05:10.709780 22392998065984 run_lib.py:146] step: 199400, training_loss: 6.33748e-02
I0514 22:05:10.866813 22392998065984 run_lib.py:167] step: 199400, eval_loss: 6.79212e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:05:35.029740 22392998065984 run_lib.py:146] step: 199450, training_loss: 6.23186e-02
I0514 22:05:59.191859 22392998065984 run_lib.py:146] step: 199500, training_loss: 6.63017e-02
I0514 22:05:59.350379 22392998065984 run_lib.py:167] step: 199500, eval_loss: 6.31571e-02
I0514 22:06:22.887908 22392998065984 run_lib.py:146] step: 199550, training_loss: 4.89856e-02
I0514 22:06:46.453905 22392998065984 run_lib.py:146] step: 199600, training_loss: 6.30333e-02
I0514 22:06:46.610898 22392998065984 run_lib.py:167] step: 199600, eval_loss: 6.76116e-02
I0514 22:07:10.197544 22392998065984 run_lib.py:146] step: 199650, training_loss: 6.83649e-02
I0514 22:07:33.624193 22392998065984 run_lib.py:146] step: 199700, training_loss: 6.12035e-02
I0514 22:07:33.780853 22392998065984 run_lib.py:167] step: 199700, eval_loss: 7.17682e-02
I0514 22:07:57.747102 22392998065984 run_lib.py:146] step: 199750, training_loss: 6.49849e-02
I0514 22:08:21.778330 22392998065984 run_lib.py:146] step: 199800, training_loss: 4.72658e-02
I0514 22:08:21.934781 22392998065984 run_lib.py:167] step: 199800, eval_loss: 6.28262e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:08:45.655522 22392998065984 run_lib.py:146] step: 199850, training_loss: 6.89685e-02
I0514 22:09:09.301765 22392998065984 run_lib.py:146] step: 199900, training_loss: 4.59149e-02
I0514 22:09:09.459066 22392998065984 run_lib.py:167] step: 199900, eval_loss: 7.33983e-02
I0514 22:09:32.737756 22392998065984 run_lib.py:146] step: 199950, training_loss: 6.18972e-02
I0514 22:09:56.332337 22392998065984 run_lib.py:146] step: 200000, training_loss: 5.52037e-02
I0514 22:10:03.085957 22392998065984 run_lib.py:167] step: 200000, eval_loss: 7.15508e-02
I0514 22:10:34.265844 22392998065984 run_lib.py:146] step: 200050, training_loss: 6.40828e-02
I0514 22:10:57.525153 22392998065984 run_lib.py:146] step: 200100, training_loss: 5.79203e-02
I0514 22:10:57.682229 22392998065984 run_lib.py:167] step: 200100, eval_loss: 5.59225e-02
I0514 22:11:21.475793 22392998065984 run_lib.py:146] step: 200150, training_loss: 8.49486e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:11:45.611424 22392998065984 run_lib.py:146] step: 200200, training_loss: 5.10182e-02
I0514 22:11:45.769766 22392998065984 run_lib.py:167] step: 200200, eval_loss: 6.44337e-02
I0514 22:12:09.078973 22392998065984 run_lib.py:146] step: 200250, training_loss: 4.97615e-02
I0514 22:12:32.695168 22392998065984 run_lib.py:146] step: 200300, training_loss: 6.61360e-02
I0514 22:12:32.851983 22392998065984 run_lib.py:167] step: 200300, eval_loss: 6.23175e-02
I0514 22:12:56.449697 22392998065984 run_lib.py:146] step: 200350, training_loss: 7.36632e-02
I0514 22:13:19.709024 22392998065984 run_lib.py:146] step: 200400, training_loss: 5.99380e-02
I0514 22:13:19.865467 22392998065984 run_lib.py:167] step: 200400, eval_loss: 6.02905e-02
I0514 22:13:43.424635 22392998065984 run_lib.py:146] step: 200450, training_loss: 4.97569e-02
I0514 22:14:07.295056 22392998065984 run_lib.py:146] step: 200500, training_loss: 6.10471e-02
I0514 22:14:07.451813 22392998065984 run_lib.py:167] step: 200500, eval_loss: 5.80592e-02
I0514 22:14:30.740285 22392998065984 run_lib.py:146] step: 200550, training_loss: 6.54952e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:14:54.716194 22392998065984 run_lib.py:146] step: 200600, training_loss: 6.19610e-02
I0514 22:14:54.874485 22392998065984 run_lib.py:167] step: 200600, eval_loss: 5.75087e-02
I0514 22:15:19.010074 22392998065984 run_lib.py:146] step: 200650, training_loss: 5.41230e-02
I0514 22:15:42.800972 22392998065984 run_lib.py:146] step: 200700, training_loss: 5.98844e-02
I0514 22:15:42.957129 22392998065984 run_lib.py:167] step: 200700, eval_loss: 5.38446e-02
I0514 22:16:06.769643 22392998065984 run_lib.py:146] step: 200750, training_loss: 6.73799e-02
I0514 22:16:30.885184 22392998065984 run_lib.py:146] step: 200800, training_loss: 5.40723e-02
I0514 22:16:31.042093 22392998065984 run_lib.py:167] step: 200800, eval_loss: 5.47761e-02
I0514 22:16:55.089138 22392998065984 run_lib.py:146] step: 200850, training_loss: 5.27165e-02
I0514 22:17:18.895903 22392998065984 run_lib.py:146] step: 200900, training_loss: 6.61874e-02
I0514 22:17:19.052499 22392998065984 run_lib.py:167] step: 200900, eval_loss: 6.88796e-02
I0514 22:17:43.173976 22392998065984 run_lib.py:146] step: 200950, training_loss: 4.33631e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:18:07.117656 22392998065984 run_lib.py:146] step: 201000, training_loss: 5.68562e-02
I0514 22:18:07.275995 22392998065984 run_lib.py:167] step: 201000, eval_loss: 6.31588e-02
I0514 22:18:30.555878 22392998065984 run_lib.py:146] step: 201050, training_loss: 6.20687e-02
I0514 22:18:54.166034 22392998065984 run_lib.py:146] step: 201100, training_loss: 5.39723e-02
I0514 22:18:54.322960 22392998065984 run_lib.py:167] step: 201100, eval_loss: 5.82796e-02
I0514 22:19:17.907914 22392998065984 run_lib.py:146] step: 201150, training_loss: 5.73692e-02
I0514 22:19:41.609025 22392998065984 run_lib.py:146] step: 201200, training_loss: 6.01745e-02
I0514 22:19:41.766289 22392998065984 run_lib.py:167] step: 201200, eval_loss: 4.88814e-02
I0514 22:20:05.906087 22392998065984 run_lib.py:146] step: 201250, training_loss: 4.89543e-02
I0514 22:20:30.016465 22392998065984 run_lib.py:146] step: 201300, training_loss: 7.57535e-02
I0514 22:20:30.172563 22392998065984 run_lib.py:167] step: 201300, eval_loss: 7.84902e-02
I0514 22:20:53.995843 22392998065984 run_lib.py:146] step: 201350, training_loss: 6.82033e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:21:17.943193 22392998065984 run_lib.py:146] step: 201400, training_loss: 5.34623e-02
I0514 22:21:18.101499 22392998065984 run_lib.py:167] step: 201400, eval_loss: 8.14583e-02
I0514 22:21:41.707774 22392998065984 run_lib.py:146] step: 201450, training_loss: 4.88074e-02
I0514 22:22:04.962674 22392998065984 run_lib.py:146] step: 201500, training_loss: 4.69452e-02
I0514 22:22:05.119602 22392998065984 run_lib.py:167] step: 201500, eval_loss: 5.86151e-02
I0514 22:22:28.557771 22392998065984 run_lib.py:146] step: 201550, training_loss: 6.78262e-02
I0514 22:22:52.681492 22392998065984 run_lib.py:146] step: 201600, training_loss: 7.04724e-02
I0514 22:22:52.838220 22392998065984 run_lib.py:167] step: 201600, eval_loss: 5.56398e-02
I0514 22:23:16.927314 22392998065984 run_lib.py:146] step: 201650, training_loss: 5.63785e-02
I0514 22:23:40.753582 22392998065984 run_lib.py:146] step: 201700, training_loss: 5.86782e-02
I0514 22:23:40.909950 22392998065984 run_lib.py:167] step: 201700, eval_loss: 7.73232e-02
I0514 22:24:05.035047 22392998065984 run_lib.py:146] step: 201750, training_loss: 5.64484e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:24:28.869117 22392998065984 run_lib.py:146] step: 201800, training_loss: 4.68833e-02
I0514 22:24:29.027105 22392998065984 run_lib.py:167] step: 201800, eval_loss: 5.71777e-02
I0514 22:24:52.309933 22392998065984 run_lib.py:146] step: 201850, training_loss: 6.89712e-02
I0514 22:25:15.916865 22392998065984 run_lib.py:146] step: 201900, training_loss: 6.27214e-02
I0514 22:25:16.073336 22392998065984 run_lib.py:167] step: 201900, eval_loss: 6.86409e-02
I0514 22:25:39.669425 22392998065984 run_lib.py:146] step: 201950, training_loss: 5.77639e-02
I0514 22:26:02.938720 22392998065984 run_lib.py:146] step: 202000, training_loss: 5.43158e-02
I0514 22:26:03.095448 22392998065984 run_lib.py:167] step: 202000, eval_loss: 6.09895e-02
I0514 22:26:26.676516 22392998065984 run_lib.py:146] step: 202050, training_loss: 6.07994e-02
I0514 22:26:50.267735 22392998065984 run_lib.py:146] step: 202100, training_loss: 6.79848e-02
I0514 22:26:50.424069 22392998065984 run_lib.py:167] step: 202100, eval_loss: 4.92731e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:27:13.830341 22392998065984 run_lib.py:146] step: 202150, training_loss: 7.81441e-02
I0514 22:27:37.495510 22392998065984 run_lib.py:146] step: 202200, training_loss: 4.79125e-02
I0514 22:27:37.653129 22392998065984 run_lib.py:167] step: 202200, eval_loss: 6.11527e-02
I0514 22:28:00.931198 22392998065984 run_lib.py:146] step: 202250, training_loss: 5.47939e-02
I0514 22:28:24.533181 22392998065984 run_lib.py:146] step: 202300, training_loss: 7.90869e-02
I0514 22:28:24.689938 22392998065984 run_lib.py:167] step: 202300, eval_loss: 6.94375e-02
I0514 22:28:47.964102 22392998065984 run_lib.py:146] step: 202350, training_loss: 6.92383e-02
I0514 22:29:11.556197 22392998065984 run_lib.py:146] step: 202400, training_loss: 5.63981e-02
I0514 22:29:11.712820 22392998065984 run_lib.py:167] step: 202400, eval_loss: 6.21969e-02
I0514 22:29:35.289553 22392998065984 run_lib.py:146] step: 202450, training_loss: 4.74679e-02
I0514 22:29:58.560856 22392998065984 run_lib.py:146] step: 202500, training_loss: 5.83746e-02
I0514 22:29:58.716955 22392998065984 run_lib.py:167] step: 202500, eval_loss: 6.59133e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:30:22.521663 22392998065984 run_lib.py:146] step: 202550, training_loss: 4.94844e-02
I0514 22:30:46.108219 22392998065984 run_lib.py:146] step: 202600, training_loss: 6.25010e-02
I0514 22:30:46.265462 22392998065984 run_lib.py:167] step: 202600, eval_loss: 6.89159e-02
I0514 22:31:09.520382 22392998065984 run_lib.py:146] step: 202650, training_loss: 4.13544e-02
I0514 22:31:33.117126 22392998065984 run_lib.py:146] step: 202700, training_loss: 5.22480e-02
I0514 22:31:33.274112 22392998065984 run_lib.py:167] step: 202700, eval_loss: 6.77181e-02
I0514 22:31:56.834375 22392998065984 run_lib.py:146] step: 202750, training_loss: 5.32182e-02
I0514 22:32:20.119405 22392998065984 run_lib.py:146] step: 202800, training_loss: 5.56531e-02
I0514 22:32:20.275865 22392998065984 run_lib.py:167] step: 202800, eval_loss: 6.41891e-02
I0514 22:32:43.864334 22392998065984 run_lib.py:146] step: 202850, training_loss: 5.81296e-02
I0514 22:33:07.444552 22392998065984 run_lib.py:146] step: 202900, training_loss: 6.05625e-02
I0514 22:33:07.600784 22392998065984 run_lib.py:167] step: 202900, eval_loss: 4.56279e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:33:31.005406 22392998065984 run_lib.py:146] step: 202950, training_loss: 4.32094e-02
I0514 22:33:54.722840 22392998065984 run_lib.py:146] step: 203000, training_loss: 4.52010e-02
I0514 22:33:54.880400 22392998065984 run_lib.py:167] step: 203000, eval_loss: 5.52871e-02
I0514 22:34:18.707886 22392998065984 run_lib.py:146] step: 203050, training_loss: 6.29122e-02
I0514 22:34:42.853376 22392998065984 run_lib.py:146] step: 203100, training_loss: 6.35957e-02
I0514 22:34:43.009662 22392998065984 run_lib.py:167] step: 203100, eval_loss: 6.95695e-02
I0514 22:35:06.848887 22392998065984 run_lib.py:146] step: 203150, training_loss: 5.63986e-02
I0514 22:35:30.801635 22392998065984 run_lib.py:146] step: 203200, training_loss: 6.16481e-02
I0514 22:35:30.958578 22392998065984 run_lib.py:167] step: 203200, eval_loss: 6.47099e-02
I0514 22:35:54.533970 22392998065984 run_lib.py:146] step: 203250, training_loss: 5.45765e-02
I0514 22:36:17.798530 22392998065984 run_lib.py:146] step: 203300, training_loss: 8.00424e-02
I0514 22:36:17.966154 22392998065984 run_lib.py:167] step: 203300, eval_loss: 5.88124e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:36:42.009092 22392998065984 run_lib.py:146] step: 203350, training_loss: 7.46032e-02
I0514 22:37:06.169517 22392998065984 run_lib.py:146] step: 203400, training_loss: 5.61788e-02
I0514 22:37:06.326924 22392998065984 run_lib.py:167] step: 203400, eval_loss: 6.30660e-02
I0514 22:37:30.236984 22392998065984 run_lib.py:146] step: 203450, training_loss: 5.34821e-02
I0514 22:37:54.391890 22392998065984 run_lib.py:146] step: 203500, training_loss: 5.88921e-02
I0514 22:37:54.548611 22392998065984 run_lib.py:167] step: 203500, eval_loss: 6.11895e-02
I0514 22:38:18.189538 22392998065984 run_lib.py:146] step: 203550, training_loss: 8.05017e-02
I0514 22:38:41.487587 22392998065984 run_lib.py:146] step: 203600, training_loss: 6.07001e-02
I0514 22:38:41.644201 22392998065984 run_lib.py:167] step: 203600, eval_loss: 6.73115e-02
I0514 22:39:05.247445 22392998065984 run_lib.py:146] step: 203650, training_loss: 6.45838e-02
I0514 22:39:28.850692 22392998065984 run_lib.py:146] step: 203700, training_loss: 6.00796e-02
I0514 22:39:29.007166 22392998065984 run_lib.py:167] step: 203700, eval_loss: 5.77351e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:39:52.781806 22392998065984 run_lib.py:146] step: 203750, training_loss: 7.22535e-02
I0514 22:40:16.056448 22392998065984 run_lib.py:146] step: 203800, training_loss: 5.63455e-02
I0514 22:40:16.214570 22392998065984 run_lib.py:167] step: 203800, eval_loss: 6.57703e-02
I0514 22:40:39.823190 22392998065984 run_lib.py:146] step: 203850, training_loss: 6.63128e-02
I0514 22:41:03.422801 22392998065984 run_lib.py:146] step: 203900, training_loss: 6.37584e-02
I0514 22:41:03.579787 22392998065984 run_lib.py:167] step: 203900, eval_loss: 4.84271e-02
I0514 22:41:26.884570 22392998065984 run_lib.py:146] step: 203950, training_loss: 5.19437e-02
I0514 22:41:50.466583 22392998065984 run_lib.py:146] step: 204000, training_loss: 7.01592e-02
I0514 22:41:50.623205 22392998065984 run_lib.py:167] step: 204000, eval_loss: 5.62181e-02
I0514 22:42:14.239681 22392998065984 run_lib.py:146] step: 204050, training_loss: 5.32084e-02
I0514 22:42:37.557072 22392998065984 run_lib.py:146] step: 204100, training_loss: 5.84110e-02
I0514 22:42:37.714090 22392998065984 run_lib.py:167] step: 204100, eval_loss: 5.09334e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:43:01.688549 22392998065984 run_lib.py:146] step: 204150, training_loss: 4.90033e-02
I0514 22:43:25.390736 22392998065984 run_lib.py:146] step: 204200, training_loss: 3.73127e-02
I0514 22:43:25.548545 22392998065984 run_lib.py:167] step: 204200, eval_loss: 5.04951e-02
I0514 22:43:48.826291 22392998065984 run_lib.py:146] step: 204250, training_loss: 6.81854e-02
I0514 22:44:12.421343 22392998065984 run_lib.py:146] step: 204300, training_loss: 4.64700e-02
I0514 22:44:12.577798 22392998065984 run_lib.py:167] step: 204300, eval_loss: 7.00454e-02
I0514 22:44:36.179022 22392998065984 run_lib.py:146] step: 204350, training_loss: 5.71084e-02
I0514 22:44:59.468569 22392998065984 run_lib.py:146] step: 204400, training_loss: 4.99841e-02
I0514 22:44:59.625254 22392998065984 run_lib.py:167] step: 204400, eval_loss: 5.77990e-02
I0514 22:45:23.214308 22392998065984 run_lib.py:146] step: 204450, training_loss: 6.23284e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:45:46.941446 22392998065984 run_lib.py:146] step: 204500, training_loss: 6.53644e-02
I0514 22:45:47.099863 22392998065984 run_lib.py:167] step: 204500, eval_loss: 5.88010e-02
I0514 22:46:10.391374 22392998065984 run_lib.py:146] step: 204550, training_loss: 6.41846e-02
I0514 22:46:33.688807 22392998065984 run_lib.py:146] step: 204600, training_loss: 4.57660e-02
I0514 22:46:33.845870 22392998065984 run_lib.py:167] step: 204600, eval_loss: 8.45457e-02
I0514 22:46:57.817461 22392998065984 run_lib.py:146] step: 204650, training_loss: 4.33074e-02
I0514 22:47:21.083675 22392998065984 run_lib.py:146] step: 204700, training_loss: 5.01645e-02
I0514 22:47:21.239981 22392998065984 run_lib.py:167] step: 204700, eval_loss: 6.30338e-02
I0514 22:47:44.506793 22392998065984 run_lib.py:146] step: 204750, training_loss: 4.21963e-02
I0514 22:48:08.075345 22392998065984 run_lib.py:146] step: 204800, training_loss: 6.42513e-02
I0514 22:48:08.231739 22392998065984 run_lib.py:167] step: 204800, eval_loss: 6.38755e-02
I0514 22:48:31.810663 22392998065984 run_lib.py:146] step: 204850, training_loss: 5.54330e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:48:55.399281 22392998065984 run_lib.py:146] step: 204900, training_loss: 4.11083e-02
I0514 22:48:55.557595 22392998065984 run_lib.py:167] step: 204900, eval_loss: 6.74677e-02
I0514 22:49:19.754607 22392998065984 run_lib.py:146] step: 204950, training_loss: 6.37116e-02
I0514 22:49:43.909645 22392998065984 run_lib.py:146] step: 205000, training_loss: 7.96770e-02
I0514 22:49:44.078257 22392998065984 run_lib.py:167] step: 205000, eval_loss: 5.18135e-02
I0514 22:50:07.891837 22392998065984 run_lib.py:146] step: 205050, training_loss: 6.52986e-02
I0514 22:50:32.022648 22392998065984 run_lib.py:146] step: 205100, training_loss: 6.92863e-02
I0514 22:50:32.205735 22392998065984 run_lib.py:167] step: 205100, eval_loss: 6.82214e-02
I0514 22:50:56.167878 22392998065984 run_lib.py:146] step: 205150, training_loss: 7.76394e-02
I0514 22:51:19.435828 22392998065984 run_lib.py:146] step: 205200, training_loss: 6.85329e-02
I0514 22:51:19.591284 22392998065984 run_lib.py:167] step: 205200, eval_loss: 6.48274e-02
I0514 22:51:43.153508 22392998065984 run_lib.py:146] step: 205250, training_loss: 5.96758e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:52:06.906006 22392998065984 run_lib.py:146] step: 205300, training_loss: 8.17956e-02
I0514 22:52:06.985066 22392998065984 run_lib.py:167] step: 205300, eval_loss: 6.54219e-02
I0514 22:52:30.252792 22392998065984 run_lib.py:146] step: 205350, training_loss: 6.22375e-02
I0514 22:52:53.517772 22392998065984 run_lib.py:146] step: 205400, training_loss: 5.98762e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:52:53.886542 22392998065984 run_lib.py:167] step: 205400, eval_loss: 6.51858e-02
I0514 22:53:17.837440 22392998065984 run_lib.py:146] step: 205450, training_loss: 5.43734e-02
I0514 22:53:41.127010 22392998065984 run_lib.py:146] step: 205500, training_loss: 5.05896e-02
I0514 22:53:41.291765 22392998065984 run_lib.py:167] step: 205500, eval_loss: 5.60102e-02
I0514 22:54:04.595687 22392998065984 run_lib.py:146] step: 205550, training_loss: 6.59146e-02
I0514 22:54:28.199306 22392998065984 run_lib.py:146] step: 205600, training_loss: 4.54176e-02
I0514 22:54:28.355970 22392998065984 run_lib.py:167] step: 205600, eval_loss: 7.51609e-02
I0514 22:54:51.945447 22392998065984 run_lib.py:146] step: 205650, training_loss: 5.55288e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:55:15.366185 22392998065984 run_lib.py:146] step: 205700, training_loss: 8.19246e-02
I0514 22:55:15.524647 22392998065984 run_lib.py:167] step: 205700, eval_loss: 5.58536e-02
I0514 22:55:39.161015 22392998065984 run_lib.py:146] step: 205750, training_loss: 7.53774e-02
I0514 22:56:02.784336 22392998065984 run_lib.py:146] step: 205800, training_loss: 5.15329e-02
I0514 22:56:02.940782 22392998065984 run_lib.py:167] step: 205800, eval_loss: 4.41606e-02
I0514 22:56:26.223600 22392998065984 run_lib.py:146] step: 205850, training_loss: 7.74690e-02
I0514 22:56:49.796588 22392998065984 run_lib.py:146] step: 205900, training_loss: 5.35159e-02
I0514 22:56:49.953414 22392998065984 run_lib.py:167] step: 205900, eval_loss: 4.08290e-02
I0514 22:57:13.526178 22392998065984 run_lib.py:146] step: 205950, training_loss: 8.52302e-02
I0514 22:57:36.810643 22392998065984 run_lib.py:146] step: 206000, training_loss: 5.25988e-02
I0514 22:57:36.967549 22392998065984 run_lib.py:167] step: 206000, eval_loss: 4.64016e-02
I0514 22:58:00.521533 22392998065984 run_lib.py:146] step: 206050, training_loss: 7.65832e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 22:58:24.315052 22392998065984 run_lib.py:146] step: 206100, training_loss: 4.90456e-02
I0514 22:58:24.472743 22392998065984 run_lib.py:167] step: 206100, eval_loss: 7.35135e-02
I0514 22:58:47.728836 22392998065984 run_lib.py:146] step: 206150, training_loss: 6.18205e-02
I0514 22:59:11.018350 22392998065984 run_lib.py:146] step: 206200, training_loss: 5.88583e-02
I0514 22:59:11.174664 22392998065984 run_lib.py:167] step: 206200, eval_loss: 4.23106e-02
I0514 22:59:34.799352 22392998065984 run_lib.py:146] step: 206250, training_loss: 5.78026e-02
I0514 22:59:58.372169 22392998065984 run_lib.py:146] step: 206300, training_loss: 5.16890e-02
I0514 22:59:58.528601 22392998065984 run_lib.py:167] step: 206300, eval_loss: 7.52456e-02
I0514 23:00:21.792865 22392998065984 run_lib.py:146] step: 206350, training_loss: 4.70006e-02
I0514 23:00:45.352810 22392998065984 run_lib.py:146] step: 206400, training_loss: 5.68571e-02
I0514 23:00:45.510199 22392998065984 run_lib.py:167] step: 206400, eval_loss: 6.10320e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:01:09.215696 22392998065984 run_lib.py:146] step: 206450, training_loss: 5.03361e-02
I0514 23:01:32.510718 22392998065984 run_lib.py:146] step: 206500, training_loss: 5.09909e-02
I0514 23:01:32.668086 22392998065984 run_lib.py:167] step: 206500, eval_loss: 5.64196e-02
I0514 23:01:56.305549 22392998065984 run_lib.py:146] step: 206550, training_loss: 5.40206e-02
I0514 23:02:19.931677 22392998065984 run_lib.py:146] step: 206600, training_loss: 6.35889e-02
I0514 23:02:20.180311 22392998065984 run_lib.py:167] step: 206600, eval_loss: 5.82120e-02
I0514 23:02:43.441996 22392998065984 run_lib.py:146] step: 206650, training_loss: 5.30389e-02
I0514 23:03:07.011870 22392998065984 run_lib.py:146] step: 206700, training_loss: 6.62004e-02
I0514 23:03:07.168399 22392998065984 run_lib.py:167] step: 206700, eval_loss: 4.97268e-02
I0514 23:03:30.740442 22392998065984 run_lib.py:146] step: 206750, training_loss: 4.21557e-02
I0514 23:03:54.034138 22392998065984 run_lib.py:146] step: 206800, training_loss: 6.45918e-02
I0514 23:03:54.190687 22392998065984 run_lib.py:167] step: 206800, eval_loss: 6.33511e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:04:18.061858 22392998065984 run_lib.py:146] step: 206850, training_loss: 6.04256e-02
I0514 23:04:42.201267 22392998065984 run_lib.py:146] step: 206900, training_loss: 4.50872e-02
I0514 23:04:42.358818 22392998065984 run_lib.py:167] step: 206900, eval_loss: 5.45121e-02
I0514 23:05:06.186696 22392998065984 run_lib.py:146] step: 206950, training_loss: 8.10115e-02
I0514 23:05:30.006390 22392998065984 run_lib.py:146] step: 207000, training_loss: 6.63320e-02
I0514 23:05:30.162871 22392998065984 run_lib.py:167] step: 207000, eval_loss: 4.61850e-02
I0514 23:05:54.311256 22392998065984 run_lib.py:146] step: 207050, training_loss: 4.78532e-02
I0514 23:06:18.404122 22392998065984 run_lib.py:146] step: 207100, training_loss: 5.62898e-02
I0514 23:06:18.560875 22392998065984 run_lib.py:167] step: 207100, eval_loss: 5.18094e-02
I0514 23:06:42.394911 22392998065984 run_lib.py:146] step: 207150, training_loss: 5.96881e-02
I0514 23:07:06.503481 22392998065984 run_lib.py:146] step: 207200, training_loss: 3.72111e-02
I0514 23:07:06.660699 22392998065984 run_lib.py:167] step: 207200, eval_loss: 6.82534e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:07:30.925290 22392998065984 run_lib.py:146] step: 207250, training_loss: 5.74306e-02
I0514 23:07:54.732372 22392998065984 run_lib.py:146] step: 207300, training_loss: 5.40605e-02
I0514 23:07:54.906747 22392998065984 run_lib.py:167] step: 207300, eval_loss: 4.93766e-02
I0514 23:08:18.819120 22392998065984 run_lib.py:146] step: 207350, training_loss: 4.45876e-02
I0514 23:08:42.395900 22392998065984 run_lib.py:146] step: 207400, training_loss: 5.02187e-02
I0514 23:08:42.552035 22392998065984 run_lib.py:167] step: 207400, eval_loss: 3.79869e-02
I0514 23:09:05.810435 22392998065984 run_lib.py:146] step: 207450, training_loss: 5.73409e-02
I0514 23:09:29.370832 22392998065984 run_lib.py:146] step: 207500, training_loss: 6.52765e-02
I0514 23:09:29.527230 22392998065984 run_lib.py:167] step: 207500, eval_loss: 5.64343e-02
I0514 23:09:53.103100 22392998065984 run_lib.py:146] step: 207550, training_loss: 5.28389e-02
I0514 23:10:16.378790 22392998065984 run_lib.py:146] step: 207600, training_loss: 5.24386e-02
I0514 23:10:16.535707 22392998065984 run_lib.py:167] step: 207600, eval_loss: 6.40798e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:10:40.539813 22392998065984 run_lib.py:146] step: 207650, training_loss: 5.07842e-02
I0514 23:11:04.184100 22392998065984 run_lib.py:146] step: 207700, training_loss: 8.33665e-02
I0514 23:11:04.341715 22392998065984 run_lib.py:167] step: 207700, eval_loss: 6.34798e-02
I0514 23:11:27.634373 22392998065984 run_lib.py:146] step: 207750, training_loss: 6.76664e-02
I0514 23:11:50.927591 22392998065984 run_lib.py:146] step: 207800, training_loss: 4.91399e-02
I0514 23:11:51.084285 22392998065984 run_lib.py:167] step: 207800, eval_loss: 6.56268e-02
I0514 23:12:14.960433 22392998065984 run_lib.py:146] step: 207850, training_loss: 5.04804e-02
I0514 23:12:38.240670 22392998065984 run_lib.py:146] step: 207900, training_loss: 5.46478e-02
I0514 23:12:38.397354 22392998065984 run_lib.py:167] step: 207900, eval_loss: 6.10973e-02
I0514 23:13:01.672894 22392998065984 run_lib.py:146] step: 207950, training_loss: 6.48259e-02
I0514 23:13:25.260579 22392998065984 run_lib.py:146] step: 208000, training_loss: 4.84306e-02
I0514 23:13:25.417561 22392998065984 run_lib.py:167] step: 208000, eval_loss: 6.19888e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:13:49.516660 22392998065984 run_lib.py:146] step: 208050, training_loss: 6.96688e-02
I0514 23:14:13.334975 22392998065984 run_lib.py:146] step: 208100, training_loss: 5.10262e-02
I0514 23:14:13.492576 22392998065984 run_lib.py:167] step: 208100, eval_loss: 6.15558e-02
I0514 23:14:37.665523 22392998065984 run_lib.py:146] step: 208150, training_loss: 5.90070e-02
I0514 23:15:01.798639 22392998065984 run_lib.py:146] step: 208200, training_loss: 5.73271e-02
I0514 23:15:01.965700 22392998065984 run_lib.py:167] step: 208200, eval_loss: 5.78517e-02
I0514 23:15:25.766482 22392998065984 run_lib.py:146] step: 208250, training_loss: 6.91454e-02
I0514 23:15:49.906935 22392998065984 run_lib.py:146] step: 208300, training_loss: 5.46520e-02
I0514 23:15:50.063515 22392998065984 run_lib.py:167] step: 208300, eval_loss: 6.11349e-02
I0514 23:16:14.152115 22392998065984 run_lib.py:146] step: 208350, training_loss: 7.15877e-02
I0514 23:16:37.974311 22392998065984 run_lib.py:146] step: 208400, training_loss: 5.33951e-02
I0514 23:16:38.131218 22392998065984 run_lib.py:167] step: 208400, eval_loss: 5.49882e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:17:01.939872 22392998065984 run_lib.py:146] step: 208450, training_loss: 7.45291e-02
I0514 23:17:25.561590 22392998065984 run_lib.py:146] step: 208500, training_loss: 4.96459e-02
I0514 23:17:25.718749 22392998065984 run_lib.py:167] step: 208500, eval_loss: 4.80096e-02
I0514 23:17:48.994716 22392998065984 run_lib.py:146] step: 208550, training_loss: 7.41523e-02
I0514 23:18:12.566867 22392998065984 run_lib.py:146] step: 208600, training_loss: 5.60759e-02
I0514 23:18:12.723441 22392998065984 run_lib.py:167] step: 208600, eval_loss: 6.80726e-02
I0514 23:18:36.289174 22392998065984 run_lib.py:146] step: 208650, training_loss: 6.29423e-02
I0514 23:18:59.581989 22392998065984 run_lib.py:146] step: 208700, training_loss: 6.93748e-02
I0514 23:18:59.738571 22392998065984 run_lib.py:167] step: 208700, eval_loss: 7.20444e-02
I0514 23:19:23.005815 22392998065984 run_lib.py:146] step: 208750, training_loss: 6.59536e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:19:46.718146 22392998065984 run_lib.py:146] step: 208800, training_loss: 4.73803e-02
I0514 23:19:46.876509 22392998065984 run_lib.py:167] step: 208800, eval_loss: 7.25951e-02
I0514 23:20:10.493044 22392998065984 run_lib.py:146] step: 208850, training_loss: 4.46399e-02
I0514 23:20:33.760123 22392998065984 run_lib.py:146] step: 208900, training_loss: 5.95057e-02
I0514 23:20:33.916630 22392998065984 run_lib.py:167] step: 208900, eval_loss: 6.28066e-02
I0514 23:20:57.510313 22392998065984 run_lib.py:146] step: 208950, training_loss: 6.97547e-02
I0514 23:21:21.092764 22392998065984 run_lib.py:146] step: 209000, training_loss: 4.94251e-02
I0514 23:21:21.249497 22392998065984 run_lib.py:167] step: 209000, eval_loss: 5.21810e-02
I0514 23:21:44.527058 22392998065984 run_lib.py:146] step: 209050, training_loss: 6.32205e-02
I0514 23:22:08.105556 22392998065984 run_lib.py:146] step: 209100, training_loss: 6.51002e-02
I0514 23:22:08.261950 22392998065984 run_lib.py:167] step: 209100, eval_loss: 5.85227e-02
I0514 23:22:31.825612 22392998065984 run_lib.py:146] step: 209150, training_loss: 5.83735e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:22:55.416190 22392998065984 run_lib.py:146] step: 209200, training_loss: 6.55450e-02
I0514 23:22:55.574030 22392998065984 run_lib.py:167] step: 209200, eval_loss: 8.01305e-02
I0514 23:23:19.745744 22392998065984 run_lib.py:146] step: 209250, training_loss: 7.03874e-02
I0514 23:23:43.877739 22392998065984 run_lib.py:146] step: 209300, training_loss: 5.07759e-02
I0514 23:23:44.033982 22392998065984 run_lib.py:167] step: 209300, eval_loss: 6.47017e-02
I0514 23:24:07.629652 22392998065984 run_lib.py:146] step: 209350, training_loss: 6.96297e-02
I0514 23:24:31.206305 22392998065984 run_lib.py:146] step: 209400, training_loss: 5.79332e-02
I0514 23:24:31.362821 22392998065984 run_lib.py:167] step: 209400, eval_loss: 7.36927e-02
I0514 23:24:54.915771 22392998065984 run_lib.py:146] step: 209450, training_loss: 6.30246e-02
I0514 23:25:18.163938 22392998065984 run_lib.py:146] step: 209500, training_loss: 5.76905e-02
I0514 23:25:18.320591 22392998065984 run_lib.py:167] step: 209500, eval_loss: 7.27341e-02
I0514 23:25:41.575719 22392998065984 run_lib.py:146] step: 209550, training_loss: 4.79524e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:26:05.637538 22392998065984 run_lib.py:146] step: 209600, training_loss: 5.98099e-02
I0514 23:26:05.795140 22392998065984 run_lib.py:167] step: 209600, eval_loss: 4.99085e-02
I0514 23:26:29.069789 22392998065984 run_lib.py:146] step: 209650, training_loss: 7.54396e-02
I0514 23:26:52.346751 22392998065984 run_lib.py:146] step: 209700, training_loss: 5.91415e-02
I0514 23:26:52.503365 22392998065984 run_lib.py:167] step: 209700, eval_loss: 6.19783e-02
I0514 23:27:16.097416 22392998065984 run_lib.py:146] step: 209750, training_loss: 5.08076e-02
I0514 23:27:39.684844 22392998065984 run_lib.py:146] step: 209800, training_loss: 6.78894e-02
I0514 23:27:40.078917 22392998065984 run_lib.py:167] step: 209800, eval_loss: 6.43798e-02
I0514 23:28:03.359026 22392998065984 run_lib.py:146] step: 209850, training_loss: 7.40072e-02
I0514 23:28:26.941871 22392998065984 run_lib.py:146] step: 209900, training_loss: 6.41777e-02
I0514 23:28:27.098906 22392998065984 run_lib.py:167] step: 209900, eval_loss: 5.33387e-02
I0514 23:28:50.661772 22392998065984 run_lib.py:146] step: 209950, training_loss: 6.54870e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:29:14.435843 22392998065984 run_lib.py:146] step: 210000, training_loss: 5.39181e-02
I0514 23:29:20.401949 22392998065984 run_lib.py:167] step: 210000, eval_loss: 6.20246e-02
I0514 23:29:51.233063 22392998065984 run_lib.py:146] step: 210050, training_loss: 6.57415e-02
I0514 23:30:15.042832 22392998065984 run_lib.py:146] step: 210100, training_loss: 6.26399e-02
I0514 23:30:15.198904 22392998065984 run_lib.py:167] step: 210100, eval_loss: 7.10942e-02
I0514 23:30:39.022405 22392998065984 run_lib.py:146] step: 210150, training_loss: 7.22540e-02
I0514 23:31:03.431092 22392998065984 run_lib.py:146] step: 210200, training_loss: 4.74850e-02
I0514 23:31:03.587301 22392998065984 run_lib.py:167] step: 210200, eval_loss: 6.28776e-02
I0514 23:31:27.413446 22392998065984 run_lib.py:146] step: 210250, training_loss: 5.69284e-02
I0514 23:31:51.228839 22392998065984 run_lib.py:146] step: 210300, training_loss: 4.59347e-02
I0514 23:31:51.385010 22392998065984 run_lib.py:167] step: 210300, eval_loss: 5.89063e-02
I0514 23:32:15.512892 22392998065984 run_lib.py:146] step: 210350, training_loss: 4.85627e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:32:39.756346 22392998065984 run_lib.py:146] step: 210400, training_loss: 7.00998e-02
I0514 23:32:39.914891 22392998065984 run_lib.py:167] step: 210400, eval_loss: 7.01218e-02
I0514 23:33:03.742295 22392998065984 run_lib.py:146] step: 210450, training_loss: 6.51520e-02
I0514 23:33:27.562676 22392998065984 run_lib.py:146] step: 210500, training_loss: 5.83095e-02
I0514 23:33:27.719108 22392998065984 run_lib.py:167] step: 210500, eval_loss: 4.73668e-02
I0514 23:33:52.209637 22392998065984 run_lib.py:146] step: 210550, training_loss: 4.97394e-02
I0514 23:34:16.033274 22392998065984 run_lib.py:146] step: 210600, training_loss: 6.12317e-02
I0514 23:34:16.190481 22392998065984 run_lib.py:167] step: 210600, eval_loss: 5.48065e-02
I0514 23:34:40.007532 22392998065984 run_lib.py:146] step: 210650, training_loss: 5.16772e-02
I0514 23:35:04.404863 22392998065984 run_lib.py:146] step: 210700, training_loss: 5.63591e-02
I0514 23:35:04.561391 22392998065984 run_lib.py:167] step: 210700, eval_loss: 5.72417e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:35:28.436764 22392998065984 run_lib.py:146] step: 210750, training_loss: 6.51016e-02
I0514 23:35:51.987856 22392998065984 run_lib.py:146] step: 210800, training_loss: 6.51831e-02
I0514 23:35:52.145722 22392998065984 run_lib.py:167] step: 210800, eval_loss: 4.77336e-02
I0514 23:36:16.089004 22392998065984 run_lib.py:146] step: 210850, training_loss: 5.08362e-02
I0514 23:36:39.370634 22392998065984 run_lib.py:146] step: 210900, training_loss: 5.22070e-02
I0514 23:36:39.527035 22392998065984 run_lib.py:167] step: 210900, eval_loss: 9.89151e-02
I0514 23:37:02.817888 22392998065984 run_lib.py:146] step: 210950, training_loss: 7.46525e-02
I0514 23:37:26.684921 22392998065984 run_lib.py:146] step: 211000, training_loss: 7.70037e-02
I0514 23:37:26.841266 22392998065984 run_lib.py:167] step: 211000, eval_loss: 5.27526e-02
I0514 23:37:50.108770 22392998065984 run_lib.py:146] step: 211050, training_loss: 8.28800e-02
I0514 23:38:13.400249 22392998065984 run_lib.py:146] step: 211100, training_loss: 7.40433e-02
I0514 23:38:13.557068 22392998065984 run_lib.py:167] step: 211100, eval_loss: 5.27473e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:38:37.337034 22392998065984 run_lib.py:146] step: 211150, training_loss: 4.68891e-02
I0514 23:39:00.977462 22392998065984 run_lib.py:146] step: 211200, training_loss: 7.25553e-02
I0514 23:39:01.134710 22392998065984 run_lib.py:167] step: 211200, eval_loss: 6.54043e-02
I0514 23:39:24.414722 22392998065984 run_lib.py:146] step: 211250, training_loss: 5.77595e-02
I0514 23:39:48.129867 22392998065984 run_lib.py:146] step: 211300, training_loss: 5.44873e-02
I0514 23:39:48.286469 22392998065984 run_lib.py:167] step: 211300, eval_loss: 5.16437e-02
I0514 23:40:12.677073 22392998065984 run_lib.py:146] step: 211350, training_loss: 6.00867e-02
I0514 23:40:36.496525 22392998065984 run_lib.py:146] step: 211400, training_loss: 6.96784e-02
I0514 23:40:36.683146 22392998065984 run_lib.py:167] step: 211400, eval_loss: 6.10305e-02
I0514 23:41:00.477795 22392998065984 run_lib.py:146] step: 211450, training_loss: 5.79903e-02
I0514 23:41:24.875815 22392998065984 run_lib.py:146] step: 211500, training_loss: 5.11924e-02
I0514 23:41:25.032747 22392998065984 run_lib.py:167] step: 211500, eval_loss: 7.28699e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:41:48.817458 22392998065984 run_lib.py:146] step: 211550, training_loss: 6.17541e-02
I0514 23:42:12.092832 22392998065984 run_lib.py:146] step: 211600, training_loss: 4.93511e-02
I0514 23:42:12.250518 22392998065984 run_lib.py:167] step: 211600, eval_loss: 5.11711e-02
I0514 23:42:36.211226 22392998065984 run_lib.py:146] step: 211650, training_loss: 7.53262e-02
I0514 23:42:59.491492 22392998065984 run_lib.py:146] step: 211700, training_loss: 5.07254e-02
I0514 23:42:59.647680 22392998065984 run_lib.py:167] step: 211700, eval_loss: 6.12790e-02
I0514 23:43:22.928557 22392998065984 run_lib.py:146] step: 211750, training_loss: 8.16221e-02
I0514 23:43:46.785418 22392998065984 run_lib.py:146] step: 211800, training_loss: 5.44982e-02
I0514 23:43:46.971218 22392998065984 run_lib.py:167] step: 211800, eval_loss: 7.09250e-02
I0514 23:44:10.272605 22392998065984 run_lib.py:146] step: 211850, training_loss: 5.77412e-02
I0514 23:44:33.565321 22392998065984 run_lib.py:146] step: 211900, training_loss: 8.39733e-02
I0514 23:44:33.721809 22392998065984 run_lib.py:167] step: 211900, eval_loss: 7.24792e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:44:57.657678 22392998065984 run_lib.py:146] step: 211950, training_loss: 5.33519e-02
I0514 23:45:21.832736 22392998065984 run_lib.py:146] step: 212000, training_loss: 5.14613e-02
I0514 23:45:21.990487 22392998065984 run_lib.py:167] step: 212000, eval_loss: 4.89761e-02
I0514 23:45:45.823221 22392998065984 run_lib.py:146] step: 212050, training_loss: 6.21672e-02
I0514 23:46:09.643463 22392998065984 run_lib.py:146] step: 212100, training_loss: 5.06026e-02
I0514 23:46:09.800209 22392998065984 run_lib.py:167] step: 212100, eval_loss: 5.94175e-02
I0514 23:46:34.218096 22392998065984 run_lib.py:146] step: 212150, training_loss: 7.47201e-02
I0514 23:46:58.028887 22392998065984 run_lib.py:146] step: 212200, training_loss: 7.11357e-02
I0514 23:46:58.185447 22392998065984 run_lib.py:167] step: 212200, eval_loss: 7.23593e-02
I0514 23:47:22.016948 22392998065984 run_lib.py:146] step: 212250, training_loss: 5.12349e-02
I0514 23:47:46.413784 22392998065984 run_lib.py:146] step: 212300, training_loss: 5.39422e-02
I0514 23:47:46.571242 22392998065984 run_lib.py:167] step: 212300, eval_loss: 7.30052e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:48:10.560531 22392998065984 run_lib.py:146] step: 212350, training_loss: 4.16586e-02
I0514 23:48:34.375381 22392998065984 run_lib.py:146] step: 212400, training_loss: 7.48896e-02
I0514 23:48:34.532933 22392998065984 run_lib.py:167] step: 212400, eval_loss: 5.66198e-02
I0514 23:48:59.039981 22392998065984 run_lib.py:146] step: 212450, training_loss: 5.61529e-02
I0514 23:49:22.861761 22392998065984 run_lib.py:146] step: 212500, training_loss: 5.75861e-02
I0514 23:49:23.018191 22392998065984 run_lib.py:167] step: 212500, eval_loss: 5.87991e-02
I0514 23:49:46.849552 22392998065984 run_lib.py:146] step: 212550, training_loss: 6.66311e-02
I0514 23:50:10.748941 22392998065984 run_lib.py:146] step: 212600, training_loss: 5.75278e-02
I0514 23:50:10.905459 22392998065984 run_lib.py:167] step: 212600, eval_loss: 6.10029e-02
I0514 23:50:34.183464 22392998065984 run_lib.py:146] step: 212650, training_loss: 7.15216e-02
I0514 23:50:57.465884 22392998065984 run_lib.py:146] step: 212700, training_loss: 6.07114e-02
I0514 23:50:57.622494 22392998065984 run_lib.py:167] step: 212700, eval_loss: 3.93838e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:51:21.630683 22392998065984 run_lib.py:146] step: 212750, training_loss: 5.52601e-02
I0514 23:51:45.808658 22392998065984 run_lib.py:146] step: 212800, training_loss: 5.61093e-02
I0514 23:51:45.966061 22392998065984 run_lib.py:167] step: 212800, eval_loss: 7.81111e-02
I0514 23:52:09.800558 22392998065984 run_lib.py:146] step: 212850, training_loss: 5.34981e-02
I0514 23:52:33.621861 22392998065984 run_lib.py:146] step: 212900, training_loss: 7.97136e-02
I0514 23:52:33.778161 22392998065984 run_lib.py:167] step: 212900, eval_loss: 5.97902e-02
I0514 23:52:58.181754 22392998065984 run_lib.py:146] step: 212950, training_loss: 4.56466e-02
I0514 23:53:22.003169 22392998065984 run_lib.py:146] step: 213000, training_loss: 5.59455e-02
I0514 23:53:22.167833 22392998065984 run_lib.py:167] step: 213000, eval_loss: 5.77422e-02
I0514 23:53:45.976876 22392998065984 run_lib.py:146] step: 213050, training_loss: 5.33689e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:54:10.535308 22392998065984 run_lib.py:146] step: 213100, training_loss: 4.84106e-02
I0514 23:54:10.692734 22392998065984 run_lib.py:167] step: 213100, eval_loss: 4.66853e-02
I0514 23:54:34.488308 22392998065984 run_lib.py:146] step: 213150, training_loss: 4.65766e-02
I0514 23:54:58.294036 22392998065984 run_lib.py:146] step: 213200, training_loss: 4.62201e-02
I0514 23:54:58.373550 22392998065984 run_lib.py:167] step: 213200, eval_loss: 6.88115e-02
I0514 23:55:22.872741 22392998065984 run_lib.py:146] step: 213250, training_loss: 5.69657e-02
I0514 23:55:46.678538 22392998065984 run_lib.py:146] step: 213300, training_loss: 5.74858e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:55:47.045638 22392998065984 run_lib.py:167] step: 213300, eval_loss: 6.39303e-02
I0514 23:56:10.405090 22392998065984 run_lib.py:146] step: 213350, training_loss: 5.72138e-02
I0514 23:56:34.364529 22392998065984 run_lib.py:146] step: 213400, training_loss: 5.82079e-02
I0514 23:56:34.520954 22392998065984 run_lib.py:167] step: 213400, eval_loss: 5.22029e-02
I0514 23:56:57.801708 22392998065984 run_lib.py:146] step: 213450, training_loss: 5.05867e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0514 23:57:21.232965 22392998065984 run_lib.py:146] step: 213500, training_loss: 6.05027e-02
I0514 23:57:21.391486 22392998065984 run_lib.py:167] step: 213500, eval_loss: 7.56009e-02
I0514 23:57:45.007593 22392998065984 run_lib.py:146] step: 213550, training_loss: 4.62392e-02
I0514 23:58:08.678144 22392998065984 run_lib.py:146] step: 213600, training_loss: 7.47664e-02
I0514 23:58:08.834723 22392998065984 run_lib.py:167] step: 213600, eval_loss: 6.42718e-02
I0514 23:58:32.220000 22392998065984 run_lib.py:146] step: 213650, training_loss: 4.52861e-02
I0514 23:58:55.498526 22392998065984 run_lib.py:146] step: 213700, training_loss: 5.98198e-02
I0514 23:58:55.654675 22392998065984 run_lib.py:167] step: 213700, eval_loss: 5.28815e-02
I0514 23:59:19.522755 22392998065984 run_lib.py:146] step: 213750, training_loss: 6.22220e-02
I0514 23:59:42.809556 22392998065984 run_lib.py:146] step: 213800, training_loss: 6.11591e-02
I0514 23:59:42.965925 22392998065984 run_lib.py:167] step: 213800, eval_loss: 5.34754e-02
I0515 00:00:06.266278 22392998065984 run_lib.py:146] step: 213850, training_loss: 5.98628e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:00:30.622154 22392998065984 run_lib.py:146] step: 213900, training_loss: 4.97427e-02
I0515 00:00:30.780157 22392998065984 run_lib.py:167] step: 213900, eval_loss: 6.58694e-02
I0515 00:00:54.612274 22392998065984 run_lib.py:146] step: 213950, training_loss: 4.95473e-02
I0515 00:01:18.432870 22392998065984 run_lib.py:146] step: 214000, training_loss: 6.70415e-02
I0515 00:01:18.604373 22392998065984 run_lib.py:167] step: 214000, eval_loss: 5.17350e-02
I0515 00:01:43.030183 22392998065984 run_lib.py:146] step: 214050, training_loss: 5.06554e-02
I0515 00:02:06.854965 22392998065984 run_lib.py:146] step: 214100, training_loss: 5.65089e-02
I0515 00:02:07.011980 22392998065984 run_lib.py:167] step: 214100, eval_loss: 6.70338e-02
I0515 00:02:30.835124 22392998065984 run_lib.py:146] step: 214150, training_loss: 4.72700e-02
I0515 00:02:55.231574 22392998065984 run_lib.py:146] step: 214200, training_loss: 5.92096e-02
I0515 00:02:55.388111 22392998065984 run_lib.py:167] step: 214200, eval_loss: 5.38507e-02
I0515 00:03:19.214966 22392998065984 run_lib.py:146] step: 214250, training_loss: 5.35146e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:03:43.181782 22392998065984 run_lib.py:146] step: 214300, training_loss: 5.67268e-02
I0515 00:03:43.340470 22392998065984 run_lib.py:167] step: 214300, eval_loss: 5.04693e-02
I0515 00:04:07.415416 22392998065984 run_lib.py:146] step: 214350, training_loss: 6.77012e-02
I0515 00:04:31.045987 22392998065984 run_lib.py:146] step: 214400, training_loss: 5.01738e-02
I0515 00:04:31.202584 22392998065984 run_lib.py:167] step: 214400, eval_loss: 7.11244e-02
I0515 00:04:54.477919 22392998065984 run_lib.py:146] step: 214450, training_loss: 5.54429e-02
I0515 00:05:17.754482 22392998065984 run_lib.py:146] step: 214500, training_loss: 5.79727e-02
I0515 00:05:17.910996 22392998065984 run_lib.py:167] step: 214500, eval_loss: 5.69825e-02
I0515 00:05:41.792051 22392998065984 run_lib.py:146] step: 214550, training_loss: 4.60613e-02
I0515 00:06:05.079182 22392998065984 run_lib.py:146] step: 214600, training_loss: 7.70716e-02
I0515 00:06:05.235557 22392998065984 run_lib.py:167] step: 214600, eval_loss: 5.55702e-02
I0515 00:06:28.510464 22392998065984 run_lib.py:146] step: 214650, training_loss: 6.58252e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:06:52.593696 22392998065984 run_lib.py:146] step: 214700, training_loss: 5.00181e-02
I0515 00:06:52.752356 22392998065984 run_lib.py:167] step: 214700, eval_loss: 6.33207e-02
I0515 00:07:16.032346 22392998065984 run_lib.py:146] step: 214750, training_loss: 6.30779e-02
I0515 00:07:39.305330 22392998065984 run_lib.py:146] step: 214800, training_loss: 6.20240e-02
I0515 00:07:39.461791 22392998065984 run_lib.py:167] step: 214800, eval_loss: 5.41823e-02
I0515 00:08:03.335104 22392998065984 run_lib.py:146] step: 214850, training_loss: 6.02861e-02
I0515 00:08:26.595179 22392998065984 run_lib.py:146] step: 214900, training_loss: 5.34111e-02
I0515 00:08:26.752270 22392998065984 run_lib.py:167] step: 214900, eval_loss: 4.54660e-02
I0515 00:08:50.018599 22392998065984 run_lib.py:146] step: 214950, training_loss: 4.97801e-02
I0515 00:09:13.887555 22392998065984 run_lib.py:146] step: 215000, training_loss: 5.19101e-02
I0515 00:09:14.043851 22392998065984 run_lib.py:167] step: 215000, eval_loss: 5.85540e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:09:37.477512 22392998065984 run_lib.py:146] step: 215050, training_loss: 6.59930e-02
I0515 00:10:01.298788 22392998065984 run_lib.py:146] step: 215100, training_loss: 5.65777e-02
I0515 00:10:01.456254 22392998065984 run_lib.py:167] step: 215100, eval_loss: 6.58145e-02
I0515 00:10:25.592190 22392998065984 run_lib.py:146] step: 215150, training_loss: 5.06624e-02
I0515 00:10:49.772689 22392998065984 run_lib.py:146] step: 215200, training_loss: 4.66042e-02
I0515 00:10:49.928854 22392998065984 run_lib.py:167] step: 215200, eval_loss: 7.71118e-02
I0515 00:11:13.748852 22392998065984 run_lib.py:146] step: 215250, training_loss: 7.65062e-02
I0515 00:11:37.557826 22392998065984 run_lib.py:146] step: 215300, training_loss: 4.87957e-02
I0515 00:11:37.714456 22392998065984 run_lib.py:167] step: 215300, eval_loss: 6.20611e-02
I0515 00:12:01.666909 22392998065984 run_lib.py:146] step: 215350, training_loss: 6.44115e-02
I0515 00:12:24.972568 22392998065984 run_lib.py:146] step: 215400, training_loss: 4.50400e-02
I0515 00:12:25.128696 22392998065984 run_lib.py:167] step: 215400, eval_loss: 4.98294e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:12:48.557578 22392998065984 run_lib.py:146] step: 215450, training_loss: 5.59114e-02
I0515 00:13:12.508668 22392998065984 run_lib.py:146] step: 215500, training_loss: 5.06883e-02
I0515 00:13:12.666208 22392998065984 run_lib.py:167] step: 215500, eval_loss: 5.61441e-02
I0515 00:13:35.924203 22392998065984 run_lib.py:146] step: 215550, training_loss: 6.41634e-02
I0515 00:13:59.205625 22392998065984 run_lib.py:146] step: 215600, training_loss: 3.68094e-02
I0515 00:13:59.362298 22392998065984 run_lib.py:167] step: 215600, eval_loss: 7.91604e-02
I0515 00:14:23.226035 22392998065984 run_lib.py:146] step: 215650, training_loss: 5.41943e-02
I0515 00:14:46.494120 22392998065984 run_lib.py:146] step: 215700, training_loss: 5.06250e-02
I0515 00:14:46.651197 22392998065984 run_lib.py:167] step: 215700, eval_loss: 5.70726e-02
I0515 00:15:09.920617 22392998065984 run_lib.py:146] step: 215750, training_loss: 6.67555e-02
I0515 00:15:33.787961 22392998065984 run_lib.py:146] step: 215800, training_loss: 5.45230e-02
I0515 00:15:33.944326 22392998065984 run_lib.py:167] step: 215800, eval_loss: 6.45250e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:15:57.604313 22392998065984 run_lib.py:146] step: 215850, training_loss: 5.71575e-02
I0515 00:16:21.421979 22392998065984 run_lib.py:146] step: 215900, training_loss: 5.60974e-02
I0515 00:16:21.580020 22392998065984 run_lib.py:167] step: 215900, eval_loss: 8.89242e-02
I0515 00:16:45.734040 22392998065984 run_lib.py:146] step: 215950, training_loss: 4.58725e-02
I0515 00:17:09.904262 22392998065984 run_lib.py:146] step: 216000, training_loss: 6.65534e-02
I0515 00:17:10.061298 22392998065984 run_lib.py:167] step: 216000, eval_loss: 6.78857e-02
I0515 00:17:33.892801 22392998065984 run_lib.py:146] step: 216050, training_loss: 4.85216e-02
I0515 00:17:57.991371 22392998065984 run_lib.py:146] step: 216100, training_loss: 5.03469e-02
I0515 00:17:58.147389 22392998065984 run_lib.py:167] step: 216100, eval_loss: 5.31622e-02
I0515 00:18:22.261731 22392998065984 run_lib.py:146] step: 216150, training_loss: 5.10973e-02
I0515 00:18:46.073810 22392998065984 run_lib.py:146] step: 216200, training_loss: 6.19129e-02
I0515 00:18:46.229940 22392998065984 run_lib.py:167] step: 216200, eval_loss: 5.66784e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:19:10.217091 22392998065984 run_lib.py:146] step: 216250, training_loss: 5.32578e-02
I0515 00:19:34.699954 22392998065984 run_lib.py:146] step: 216300, training_loss: 5.98821e-02
I0515 00:19:34.857307 22392998065984 run_lib.py:167] step: 216300, eval_loss: 6.12614e-02
I0515 00:19:58.671300 22392998065984 run_lib.py:146] step: 216350, training_loss: 4.88018e-02
I0515 00:20:22.484371 22392998065984 run_lib.py:146] step: 216400, training_loss: 5.72996e-02
I0515 00:20:22.640875 22392998065984 run_lib.py:167] step: 216400, eval_loss: 6.45199e-02
I0515 00:20:47.057387 22392998065984 run_lib.py:146] step: 216450, training_loss: 6.94015e-02
I0515 00:21:10.871727 22392998065984 run_lib.py:146] step: 216500, training_loss: 5.61737e-02
I0515 00:21:11.028681 22392998065984 run_lib.py:167] step: 216500, eval_loss: 6.35627e-02
I0515 00:21:34.854655 22392998065984 run_lib.py:146] step: 216550, training_loss: 5.02671e-02
I0515 00:21:59.245949 22392998065984 run_lib.py:146] step: 216600, training_loss: 3.94454e-02
I0515 00:21:59.402641 22392998065984 run_lib.py:167] step: 216600, eval_loss: 4.25076e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:22:22.922513 22392998065984 run_lib.py:146] step: 216650, training_loss: 5.64483e-02
I0515 00:22:46.179844 22392998065984 run_lib.py:146] step: 216700, training_loss: 7.02016e-02
I0515 00:22:46.337129 22392998065984 run_lib.py:167] step: 216700, eval_loss: 5.05022e-02
I0515 00:23:09.951577 22392998065984 run_lib.py:146] step: 216750, training_loss: 7.20917e-02
I0515 00:23:33.531646 22392998065984 run_lib.py:146] step: 216800, training_loss: 6.37626e-02
I0515 00:23:33.687719 22392998065984 run_lib.py:167] step: 216800, eval_loss: 7.61335e-02
I0515 00:23:56.937063 22392998065984 run_lib.py:146] step: 216850, training_loss: 6.43416e-02
I0515 00:24:20.464141 22392998065984 run_lib.py:146] step: 216900, training_loss: 6.21428e-02
I0515 00:24:20.620527 22392998065984 run_lib.py:167] step: 216900, eval_loss: 6.04759e-02
I0515 00:24:44.161295 22392998065984 run_lib.py:146] step: 216950, training_loss: 4.91207e-02
I0515 00:25:07.412128 22392998065984 run_lib.py:146] step: 217000, training_loss: 4.74502e-02
I0515 00:25:07.568083 22392998065984 run_lib.py:167] step: 217000, eval_loss: 7.60022e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:25:30.984493 22392998065984 run_lib.py:146] step: 217050, training_loss: 7.60291e-02
I0515 00:25:54.976184 22392998065984 run_lib.py:146] step: 217100, training_loss: 5.54268e-02
I0515 00:25:55.133548 22392998065984 run_lib.py:167] step: 217100, eval_loss: 4.75674e-02
I0515 00:26:18.426318 22392998065984 run_lib.py:146] step: 217150, training_loss: 5.49844e-02
I0515 00:26:41.728675 22392998065984 run_lib.py:146] step: 217200, training_loss: 6.56373e-02
I0515 00:26:41.885418 22392998065984 run_lib.py:167] step: 217200, eval_loss: 6.05141e-02
I0515 00:27:05.726689 22392998065984 run_lib.py:146] step: 217250, training_loss: 5.19935e-02
I0515 00:27:29.003203 22392998065984 run_lib.py:146] step: 217300, training_loss: 4.21567e-02
I0515 00:27:29.159968 22392998065984 run_lib.py:167] step: 217300, eval_loss: 4.73892e-02
I0515 00:27:52.802839 22392998065984 run_lib.py:146] step: 217350, training_loss: 7.10182e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:28:17.283553 22392998065984 run_lib.py:146] step: 217400, training_loss: 6.46951e-02
I0515 00:28:17.441978 22392998065984 run_lib.py:167] step: 217400, eval_loss: 5.02716e-02
I0515 00:28:40.711355 22392998065984 run_lib.py:146] step: 217450, training_loss: 4.90520e-02
I0515 00:29:03.991754 22392998065984 run_lib.py:146] step: 217500, training_loss: 7.17827e-02
I0515 00:29:04.148345 22392998065984 run_lib.py:167] step: 217500, eval_loss: 5.69308e-02
I0515 00:29:28.053560 22392998065984 run_lib.py:146] step: 217550, training_loss: 4.66818e-02
I0515 00:29:51.308273 22392998065984 run_lib.py:146] step: 217600, training_loss: 4.69947e-02
I0515 00:29:51.464714 22392998065984 run_lib.py:167] step: 217600, eval_loss: 5.37616e-02
I0515 00:30:14.712405 22392998065984 run_lib.py:146] step: 217650, training_loss: 7.68614e-02
I0515 00:30:38.266189 22392998065984 run_lib.py:146] step: 217700, training_loss: 7.37562e-02
I0515 00:30:38.422417 22392998065984 run_lib.py:167] step: 217700, eval_loss: 6.51397e-02
I0515 00:31:01.987686 22392998065984 run_lib.py:146] step: 217750, training_loss: 6.23852e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:31:25.568836 22392998065984 run_lib.py:146] step: 217800, training_loss: 4.42909e-02
I0515 00:31:25.727130 22392998065984 run_lib.py:167] step: 217800, eval_loss: 8.08678e-02
I0515 00:31:49.871954 22392998065984 run_lib.py:146] step: 217850, training_loss: 5.76876e-02
I0515 00:32:14.025392 22392998065984 run_lib.py:146] step: 217900, training_loss: 4.44853e-02
I0515 00:32:14.181656 22392998065984 run_lib.py:167] step: 217900, eval_loss: 6.72123e-02
I0515 00:32:38.016653 22392998065984 run_lib.py:146] step: 217950, training_loss: 7.52322e-02
I0515 00:33:01.835751 22392998065984 run_lib.py:146] step: 218000, training_loss: 6.93995e-02
I0515 00:33:01.992988 22392998065984 run_lib.py:167] step: 218000, eval_loss: 6.85091e-02
I0515 00:33:25.946046 22392998065984 run_lib.py:146] step: 218050, training_loss: 5.50365e-02
I0515 00:33:49.232267 22392998065984 run_lib.py:146] step: 218100, training_loss: 5.75099e-02
I0515 00:33:49.389662 22392998065984 run_lib.py:167] step: 218100, eval_loss: 5.74176e-02
I0515 00:34:12.675234 22392998065984 run_lib.py:146] step: 218150, training_loss: 6.06409e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:34:36.991353 22392998065984 run_lib.py:146] step: 218200, training_loss: 6.28764e-02
I0515 00:34:37.149249 22392998065984 run_lib.py:167] step: 218200, eval_loss: 5.40182e-02
I0515 00:35:00.962808 22392998065984 run_lib.py:146] step: 218250, training_loss: 5.19350e-02
I0515 00:35:24.397422 22392998065984 run_lib.py:146] step: 218300, training_loss: 4.55996e-02
I0515 00:35:24.553949 22392998065984 run_lib.py:167] step: 218300, eval_loss: 5.34176e-02
I0515 00:35:48.164853 22392998065984 run_lib.py:146] step: 218350, training_loss: 7.23729e-02
I0515 00:36:11.758029 22392998065984 run_lib.py:146] step: 218400, training_loss: 6.22730e-02
I0515 00:36:11.914647 22392998065984 run_lib.py:167] step: 218400, eval_loss: 7.34129e-02
I0515 00:36:35.191061 22392998065984 run_lib.py:146] step: 218450, training_loss: 6.42618e-02
I0515 00:36:58.975683 22392998065984 run_lib.py:146] step: 218500, training_loss: 6.13931e-02
I0515 00:36:59.146050 22392998065984 run_lib.py:167] step: 218500, eval_loss: 6.30815e-02
I0515 00:37:23.262574 22392998065984 run_lib.py:146] step: 218550, training_loss: 5.15923e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:37:47.234156 22392998065984 run_lib.py:146] step: 218600, training_loss: 8.53463e-02
I0515 00:37:47.392314 22392998065984 run_lib.py:167] step: 218600, eval_loss: 6.39047e-02
I0515 00:38:11.543918 22392998065984 run_lib.py:146] step: 218650, training_loss: 6.17359e-02
I0515 00:38:35.723645 22392998065984 run_lib.py:146] step: 218700, training_loss: 6.76356e-02
I0515 00:38:35.879987 22392998065984 run_lib.py:167] step: 218700, eval_loss: 5.88971e-02
I0515 00:38:59.715251 22392998065984 run_lib.py:146] step: 218750, training_loss: 5.40635e-02
I0515 00:39:23.541631 22392998065984 run_lib.py:146] step: 218800, training_loss: 6.10610e-02
I0515 00:39:23.698758 22392998065984 run_lib.py:167] step: 218800, eval_loss: 5.94477e-02
I0515 00:39:48.106254 22392998065984 run_lib.py:146] step: 218850, training_loss: 4.61523e-02
I0515 00:40:11.915472 22392998065984 run_lib.py:146] step: 218900, training_loss: 6.65660e-02
I0515 00:40:12.071788 22392998065984 run_lib.py:167] step: 218900, eval_loss: 6.49740e-02
I0515 00:40:35.899838 22392998065984 run_lib.py:146] step: 218950, training_loss: 5.29729e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:41:00.148494 22392998065984 run_lib.py:146] step: 219000, training_loss: 4.76770e-02
I0515 00:41:00.306514 22392998065984 run_lib.py:167] step: 219000, eval_loss: 8.01946e-02
I0515 00:41:23.564785 22392998065984 run_lib.py:146] step: 219050, training_loss: 7.84839e-02
I0515 00:41:46.843916 22392998065984 run_lib.py:146] step: 219100, training_loss: 5.47707e-02
I0515 00:41:47.000608 22392998065984 run_lib.py:167] step: 219100, eval_loss: 6.52845e-02
I0515 00:42:10.565825 22392998065984 run_lib.py:146] step: 219150, training_loss: 6.88339e-02
I0515 00:42:34.119910 22392998065984 run_lib.py:146] step: 219200, training_loss: 6.34334e-02
I0515 00:42:34.276330 22392998065984 run_lib.py:167] step: 219200, eval_loss: 7.73790e-02
I0515 00:42:57.552903 22392998065984 run_lib.py:146] step: 219250, training_loss: 6.38146e-02
I0515 00:43:21.126399 22392998065984 run_lib.py:146] step: 219300, training_loss: 5.48735e-02
I0515 00:43:21.282673 22392998065984 run_lib.py:167] step: 219300, eval_loss: 6.07204e-02
I0515 00:43:44.726397 22392998065984 run_lib.py:146] step: 219350, training_loss: 6.53946e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:44:08.342409 22392998065984 run_lib.py:146] step: 219400, training_loss: 6.80737e-02
I0515 00:44:08.500842 22392998065984 run_lib.py:167] step: 219400, eval_loss: 5.91087e-02
I0515 00:44:32.124341 22392998065984 run_lib.py:146] step: 219450, training_loss: 7.19927e-02
I0515 00:44:55.737050 22392998065984 run_lib.py:146] step: 219500, training_loss: 6.52445e-02
I0515 00:44:55.893930 22392998065984 run_lib.py:167] step: 219500, eval_loss: 5.21137e-02
I0515 00:45:19.165668 22392998065984 run_lib.py:146] step: 219550, training_loss: 5.73361e-02
I0515 00:45:42.439257 22392998065984 run_lib.py:146] step: 219600, training_loss: 6.23845e-02
I0515 00:45:42.595806 22392998065984 run_lib.py:167] step: 219600, eval_loss: 6.43200e-02
I0515 00:46:06.456631 22392998065984 run_lib.py:146] step: 219650, training_loss: 8.88444e-02
I0515 00:46:29.744282 22392998065984 run_lib.py:146] step: 219700, training_loss: 6.94013e-02
I0515 00:46:29.900625 22392998065984 run_lib.py:167] step: 219700, eval_loss: 5.04420e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:46:53.329856 22392998065984 run_lib.py:146] step: 219750, training_loss: 5.28154e-02
I0515 00:47:17.298474 22392998065984 run_lib.py:146] step: 219800, training_loss: 7.03635e-02
I0515 00:47:17.455719 22392998065984 run_lib.py:167] step: 219800, eval_loss: 6.30576e-02
I0515 00:47:40.724205 22392998065984 run_lib.py:146] step: 219850, training_loss: 3.93434e-02
I0515 00:48:03.995503 22392998065984 run_lib.py:146] step: 219900, training_loss: 7.09649e-02
I0515 00:48:04.152411 22392998065984 run_lib.py:167] step: 219900, eval_loss: 8.15389e-02
I0515 00:48:27.720764 22392998065984 run_lib.py:146] step: 219950, training_loss: 4.88656e-02
I0515 00:48:51.286714 22392998065984 run_lib.py:146] step: 220000, training_loss: 6.25388e-02
I0515 00:48:53.140305 22392998065984 run_lib.py:167] step: 220000, eval_loss: 5.47634e-02
I0515 00:49:18.191130 22392998065984 run_lib.py:146] step: 220050, training_loss: 3.82903e-02
I0515 00:49:41.435990 22392998065984 run_lib.py:146] step: 220100, training_loss: 7.13820e-02
I0515 00:49:41.592371 22392998065984 run_lib.py:167] step: 220100, eval_loss: 6.41096e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:50:05.877436 22392998065984 run_lib.py:146] step: 220150, training_loss: 7.28753e-02
I0515 00:50:30.042606 22392998065984 run_lib.py:146] step: 220200, training_loss: 6.65052e-02
I0515 00:50:30.199784 22392998065984 run_lib.py:167] step: 220200, eval_loss: 7.43179e-02
I0515 00:50:54.031427 22392998065984 run_lib.py:146] step: 220250, training_loss: 6.36868e-02
I0515 00:51:18.203195 22392998065984 run_lib.py:146] step: 220300, training_loss: 5.95508e-02
I0515 00:51:18.376364 22392998065984 run_lib.py:167] step: 220300, eval_loss: 5.25350e-02
I0515 00:51:42.191220 22392998065984 run_lib.py:146] step: 220350, training_loss: 5.21270e-02
I0515 00:52:06.300675 22392998065984 run_lib.py:146] step: 220400, training_loss: 5.45239e-02
I0515 00:52:06.457909 22392998065984 run_lib.py:167] step: 220400, eval_loss: 7.12824e-02
I0515 00:52:30.593925 22392998065984 run_lib.py:146] step: 220450, training_loss: 6.44941e-02
I0515 00:52:54.424391 22392998065984 run_lib.py:146] step: 220500, training_loss: 6.57284e-02
I0515 00:52:54.580893 22392998065984 run_lib.py:167] step: 220500, eval_loss: 5.91926e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:53:18.551941 22392998065984 run_lib.py:146] step: 220550, training_loss: 4.70828e-02
I0515 00:53:42.181386 22392998065984 run_lib.py:146] step: 220600, training_loss: 6.48908e-02
I0515 00:53:42.339014 22392998065984 run_lib.py:167] step: 220600, eval_loss: 4.49008e-02
I0515 00:54:05.614159 22392998065984 run_lib.py:146] step: 220650, training_loss: 4.21481e-02
I0515 00:54:29.693560 22392998065984 run_lib.py:146] step: 220700, training_loss: 6.08722e-02
I0515 00:54:29.849871 22392998065984 run_lib.py:167] step: 220700, eval_loss: 7.53599e-02
I0515 00:54:53.680156 22392998065984 run_lib.py:146] step: 220750, training_loss: 5.89719e-02
I0515 00:55:17.816207 22392998065984 run_lib.py:146] step: 220800, training_loss: 4.38157e-02
I0515 00:55:17.972609 22392998065984 run_lib.py:167] step: 220800, eval_loss: 6.24536e-02
I0515 00:55:42.078563 22392998065984 run_lib.py:146] step: 220850, training_loss: 5.63972e-02
I0515 00:56:05.886534 22392998065984 run_lib.py:146] step: 220900, training_loss: 5.36909e-02
I0515 00:56:06.042644 22392998065984 run_lib.py:167] step: 220900, eval_loss: 5.58453e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:56:30.380899 22392998065984 run_lib.py:146] step: 220950, training_loss: 5.82143e-02
I0515 00:56:53.806270 22392998065984 run_lib.py:146] step: 221000, training_loss: 8.08264e-02
I0515 00:56:53.963716 22392998065984 run_lib.py:167] step: 221000, eval_loss: 8.23520e-02
I0515 00:57:17.578019 22392998065984 run_lib.py:146] step: 221050, training_loss: 6.19075e-02
I0515 00:57:41.159002 22392998065984 run_lib.py:146] step: 221100, training_loss: 5.69491e-02
I0515 00:57:41.238276 22392998065984 run_lib.py:167] step: 221100, eval_loss: 5.12744e-02
I0515 00:58:04.512185 22392998065984 run_lib.py:146] step: 221150, training_loss: 5.38388e-02
I0515 00:58:28.080259 22392998065984 run_lib.py:146] step: 221200, training_loss: 6.74492e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:58:28.460613 22392998065984 run_lib.py:167] step: 221200, eval_loss: 6.82965e-02
I0515 00:58:52.694216 22392998065984 run_lib.py:146] step: 221250, training_loss: 4.66803e-02
I0515 00:59:16.242813 22392998065984 run_lib.py:146] step: 221300, training_loss: 4.35039e-02
I0515 00:59:16.399292 22392998065984 run_lib.py:167] step: 221300, eval_loss: 7.98896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 00:59:40.173250 22392998065984 run_lib.py:146] step: 221350, training_loss: 7.38350e-02
I0515 01:00:03.806339 22392998065984 run_lib.py:146] step: 221400, training_loss: 3.85258e-02
I0515 01:00:03.963861 22392998065984 run_lib.py:167] step: 221400, eval_loss: 4.76439e-02
I0515 01:00:27.448236 22392998065984 run_lib.py:146] step: 221450, training_loss: 4.63994e-02
I0515 01:00:51.344523 22392998065984 run_lib.py:146] step: 221500, training_loss: 4.46948e-02
I0515 01:00:51.500822 22392998065984 run_lib.py:167] step: 221500, eval_loss: 6.11137e-02
I0515 01:01:14.787238 22392998065984 run_lib.py:146] step: 221550, training_loss: 7.12806e-02
I0515 01:01:38.368762 22392998065984 run_lib.py:146] step: 221600, training_loss: 7.62599e-02
I0515 01:01:38.525316 22392998065984 run_lib.py:167] step: 221600, eval_loss: 4.52797e-02
I0515 01:02:02.102093 22392998065984 run_lib.py:146] step: 221650, training_loss: 3.79114e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:02:25.564254 22392998065984 run_lib.py:146] step: 221700, training_loss: 6.83888e-02
I0515 01:02:25.722854 22392998065984 run_lib.py:167] step: 221700, eval_loss: 6.87517e-02
I0515 01:02:49.895574 22392998065984 run_lib.py:146] step: 221750, training_loss: 3.48664e-02
I0515 01:03:14.041158 22392998065984 run_lib.py:146] step: 221800, training_loss: 4.86970e-02
I0515 01:03:14.197372 22392998065984 run_lib.py:167] step: 221800, eval_loss: 5.52584e-02
I0515 01:03:37.926360 22392998065984 run_lib.py:146] step: 221850, training_loss: 5.06589e-02
I0515 01:04:01.524756 22392998065984 run_lib.py:146] step: 221900, training_loss: 5.69087e-02
I0515 01:04:01.681181 22392998065984 run_lib.py:167] step: 221900, eval_loss: 6.76300e-02
I0515 01:04:24.956162 22392998065984 run_lib.py:146] step: 221950, training_loss: 6.93416e-02
I0515 01:04:48.504779 22392998065984 run_lib.py:146] step: 222000, training_loss: 5.20808e-02
I0515 01:04:48.662228 22392998065984 run_lib.py:167] step: 222000, eval_loss: 5.18629e-02
I0515 01:05:12.188980 22392998065984 run_lib.py:146] step: 222050, training_loss: 5.72036e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:05:35.733003 22392998065984 run_lib.py:146] step: 222100, training_loss: 5.71970e-02
I0515 01:05:35.890943 22392998065984 run_lib.py:167] step: 222100, eval_loss: 5.80784e-02
I0515 01:06:00.031279 22392998065984 run_lib.py:146] step: 222150, training_loss: 6.03785e-02
I0515 01:06:24.244289 22392998065984 run_lib.py:146] step: 222200, training_loss: 5.63706e-02
I0515 01:06:24.401198 22392998065984 run_lib.py:167] step: 222200, eval_loss: 6.64541e-02
I0515 01:06:48.224572 22392998065984 run_lib.py:146] step: 222250, training_loss: 6.06778e-02
I0515 01:07:12.325309 22392998065984 run_lib.py:146] step: 222300, training_loss: 5.84883e-02
I0515 01:07:12.481635 22392998065984 run_lib.py:167] step: 222300, eval_loss: 4.92865e-02
I0515 01:07:36.304844 22392998065984 run_lib.py:146] step: 222350, training_loss: 6.90492e-02
I0515 01:08:00.423684 22392998065984 run_lib.py:146] step: 222400, training_loss: 8.18907e-02
I0515 01:08:00.580540 22392998065984 run_lib.py:167] step: 222400, eval_loss: 6.13958e-02
I0515 01:08:24.672633 22392998065984 run_lib.py:146] step: 222450, training_loss: 4.16319e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:08:48.640336 22392998065984 run_lib.py:146] step: 222500, training_loss: 5.81929e-02
I0515 01:08:48.810942 22392998065984 run_lib.py:167] step: 222500, eval_loss: 5.41109e-02
I0515 01:09:12.988449 22392998065984 run_lib.py:146] step: 222550, training_loss: 5.20901e-02
I0515 01:09:36.659337 22392998065984 run_lib.py:146] step: 222600, training_loss: 4.48841e-02
I0515 01:09:36.816177 22392998065984 run_lib.py:167] step: 222600, eval_loss: 6.04373e-02
I0515 01:10:00.094579 22392998065984 run_lib.py:146] step: 222650, training_loss: 5.45923e-02
I0515 01:10:23.676940 22392998065984 run_lib.py:146] step: 222700, training_loss: 5.50647e-02
I0515 01:10:23.834147 22392998065984 run_lib.py:167] step: 222700, eval_loss: 6.80353e-02
I0515 01:10:47.118931 22392998065984 run_lib.py:146] step: 222750, training_loss: 6.03315e-02
I0515 01:11:10.717301 22392998065984 run_lib.py:146] step: 222800, training_loss: 3.96377e-02
I0515 01:11:10.873903 22392998065984 run_lib.py:167] step: 222800, eval_loss: 5.52431e-02
I0515 01:11:34.466767 22392998065984 run_lib.py:146] step: 222850, training_loss: 5.83423e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:11:57.891223 22392998065984 run_lib.py:146] step: 222900, training_loss: 6.64208e-02
I0515 01:11:58.053241 22392998065984 run_lib.py:167] step: 222900, eval_loss: 6.73900e-02
I0515 01:12:21.670685 22392998065984 run_lib.py:146] step: 222950, training_loss: 5.15546e-02
I0515 01:12:45.264579 22392998065984 run_lib.py:146] step: 223000, training_loss: 8.66737e-02
I0515 01:12:45.420778 22392998065984 run_lib.py:167] step: 223000, eval_loss: 7.54812e-02
I0515 01:13:08.682197 22392998065984 run_lib.py:146] step: 223050, training_loss: 7.13581e-02
I0515 01:13:32.224041 22392998065984 run_lib.py:146] step: 223100, training_loss: 6.02970e-02
I0515 01:13:32.380911 22392998065984 run_lib.py:167] step: 223100, eval_loss: 6.81823e-02
I0515 01:13:55.657418 22392998065984 run_lib.py:146] step: 223150, training_loss: 6.87158e-02
I0515 01:14:19.236115 22392998065984 run_lib.py:146] step: 223200, training_loss: 6.33227e-02
I0515 01:14:19.392854 22392998065984 run_lib.py:167] step: 223200, eval_loss: 6.24973e-02
I0515 01:14:42.975988 22392998065984 run_lib.py:146] step: 223250, training_loss: 4.59021e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:15:06.580267 22392998065984 run_lib.py:146] step: 223300, training_loss: 5.99612e-02
I0515 01:15:06.739211 22392998065984 run_lib.py:167] step: 223300, eval_loss: 5.40165e-02
I0515 01:15:30.457791 22392998065984 run_lib.py:146] step: 223350, training_loss: 4.91977e-02
I0515 01:15:54.142100 22392998065984 run_lib.py:146] step: 223400, training_loss: 5.96308e-02
I0515 01:15:54.299428 22392998065984 run_lib.py:167] step: 223400, eval_loss: 5.13901e-02
I0515 01:16:17.640208 22392998065984 run_lib.py:146] step: 223450, training_loss: 4.71958e-02
I0515 01:16:41.253415 22392998065984 run_lib.py:146] step: 223500, training_loss: 6.28180e-02
I0515 01:16:41.410313 22392998065984 run_lib.py:167] step: 223500, eval_loss: 7.23678e-02
I0515 01:17:04.783812 22392998065984 run_lib.py:146] step: 223550, training_loss: 5.16402e-02
I0515 01:17:28.404761 22392998065984 run_lib.py:146] step: 223600, training_loss: 5.15764e-02
I0515 01:17:28.561549 22392998065984 run_lib.py:167] step: 223600, eval_loss: 6.57501e-02
I0515 01:17:52.167060 22392998065984 run_lib.py:146] step: 223650, training_loss: 5.46538e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:18:15.636228 22392998065984 run_lib.py:146] step: 223700, training_loss: 5.32202e-02
I0515 01:18:15.795124 22392998065984 run_lib.py:167] step: 223700, eval_loss: 4.23214e-02
I0515 01:18:39.463719 22392998065984 run_lib.py:146] step: 223750, training_loss: 5.89514e-02
I0515 01:19:03.662909 22392998065984 run_lib.py:146] step: 223800, training_loss: 6.05097e-02
I0515 01:19:03.831737 22392998065984 run_lib.py:167] step: 223800, eval_loss: 8.27311e-02
I0515 01:19:27.292090 22392998065984 run_lib.py:146] step: 223850, training_loss: 4.93861e-02
I0515 01:19:50.967029 22392998065984 run_lib.py:146] step: 223900, training_loss: 6.00786e-02
I0515 01:19:51.124251 22392998065984 run_lib.py:167] step: 223900, eval_loss: 7.30247e-02
I0515 01:20:14.752830 22392998065984 run_lib.py:146] step: 223950, training_loss: 5.06475e-02
I0515 01:20:38.119421 22392998065984 run_lib.py:146] step: 224000, training_loss: 4.05319e-02
I0515 01:20:38.277067 22392998065984 run_lib.py:167] step: 224000, eval_loss: 6.80051e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:21:02.023508 22392998065984 run_lib.py:146] step: 224050, training_loss: 5.26853e-02
I0515 01:21:25.378057 22392998065984 run_lib.py:146] step: 224100, training_loss: 7.07383e-02
I0515 01:21:25.536826 22392998065984 run_lib.py:167] step: 224100, eval_loss: 7.58345e-02
I0515 01:21:49.221663 22392998065984 run_lib.py:146] step: 224150, training_loss: 5.83933e-02
I0515 01:22:12.896131 22392998065984 run_lib.py:146] step: 224200, training_loss: 6.39670e-02
I0515 01:22:13.053160 22392998065984 run_lib.py:167] step: 224200, eval_loss: 6.42772e-02
I0515 01:22:36.387822 22392998065984 run_lib.py:146] step: 224250, training_loss: 6.22895e-02
I0515 01:23:00.032878 22392998065984 run_lib.py:146] step: 224300, training_loss: 6.20724e-02
I0515 01:23:00.190196 22392998065984 run_lib.py:167] step: 224300, eval_loss: 5.83026e-02
I0515 01:23:23.538125 22392998065984 run_lib.py:146] step: 224350, training_loss: 5.48588e-02
I0515 01:23:47.180633 22392998065984 run_lib.py:146] step: 224400, training_loss: 6.14355e-02
I0515 01:23:47.338720 22392998065984 run_lib.py:167] step: 224400, eval_loss: 5.85992e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:24:11.076712 22392998065984 run_lib.py:146] step: 224450, training_loss: 5.52137e-02
I0515 01:24:34.437695 22392998065984 run_lib.py:146] step: 224500, training_loss: 6.07924e-02
I0515 01:24:34.596377 22392998065984 run_lib.py:167] step: 224500, eval_loss: 6.31217e-02
I0515 01:24:58.297835 22392998065984 run_lib.py:146] step: 224550, training_loss: 5.83622e-02
I0515 01:25:21.969386 22392998065984 run_lib.py:146] step: 224600, training_loss: 4.51533e-02
I0515 01:25:22.126362 22392998065984 run_lib.py:167] step: 224600, eval_loss: 6.14802e-02
I0515 01:25:45.474103 22392998065984 run_lib.py:146] step: 224650, training_loss: 5.33231e-02
I0515 01:26:09.082276 22392998065984 run_lib.py:146] step: 224700, training_loss: 6.90143e-02
I0515 01:26:09.239219 22392998065984 run_lib.py:167] step: 224700, eval_loss: 6.11853e-02
I0515 01:26:32.895905 22392998065984 run_lib.py:146] step: 224750, training_loss: 3.59473e-02
I0515 01:26:56.265504 22392998065984 run_lib.py:146] step: 224800, training_loss: 4.84097e-02
I0515 01:26:56.422933 22392998065984 run_lib.py:167] step: 224800, eval_loss: 7.01589e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:27:20.230542 22392998065984 run_lib.py:146] step: 224850, training_loss: 4.45780e-02
I0515 01:27:43.612988 22392998065984 run_lib.py:146] step: 224900, training_loss: 7.49645e-02
I0515 01:27:43.772306 22392998065984 run_lib.py:167] step: 224900, eval_loss: 6.19095e-02
I0515 01:28:07.427667 22392998065984 run_lib.py:146] step: 224950, training_loss: 5.88741e-02
I0515 01:28:31.067369 22392998065984 run_lib.py:146] step: 225000, training_loss: 4.59597e-02
I0515 01:28:31.224474 22392998065984 run_lib.py:167] step: 225000, eval_loss: 6.05931e-02
I0515 01:28:54.575161 22392998065984 run_lib.py:146] step: 225050, training_loss: 4.92843e-02
I0515 01:29:18.209526 22392998065984 run_lib.py:146] step: 225100, training_loss: 5.48226e-02
I0515 01:29:18.366841 22392998065984 run_lib.py:167] step: 225100, eval_loss: 6.13106e-02
I0515 01:29:42.015799 22392998065984 run_lib.py:146] step: 225150, training_loss: 5.55322e-02
I0515 01:30:05.357766 22392998065984 run_lib.py:146] step: 225200, training_loss: 5.95667e-02
I0515 01:30:05.514745 22392998065984 run_lib.py:167] step: 225200, eval_loss: 8.34602e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:30:29.354034 22392998065984 run_lib.py:146] step: 225250, training_loss: 5.94551e-02
I0515 01:30:52.705873 22392998065984 run_lib.py:146] step: 225300, training_loss: 6.31429e-02
I0515 01:30:52.864574 22392998065984 run_lib.py:167] step: 225300, eval_loss: 4.43456e-02
I0515 01:31:16.557104 22392998065984 run_lib.py:146] step: 225350, training_loss: 4.75008e-02
I0515 01:31:40.205167 22392998065984 run_lib.py:146] step: 225400, training_loss: 6.18210e-02
I0515 01:31:40.362890 22392998065984 run_lib.py:167] step: 225400, eval_loss: 5.73886e-02
I0515 01:32:03.734293 22392998065984 run_lib.py:146] step: 225450, training_loss: 5.17966e-02
I0515 01:32:27.402050 22392998065984 run_lib.py:146] step: 225500, training_loss: 4.92049e-02
I0515 01:32:27.558676 22392998065984 run_lib.py:167] step: 225500, eval_loss: 7.05145e-02
I0515 01:32:51.188778 22392998065984 run_lib.py:146] step: 225550, training_loss: 5.41198e-02
I0515 01:33:14.557033 22392998065984 run_lib.py:146] step: 225600, training_loss: 5.50419e-02
I0515 01:33:14.714182 22392998065984 run_lib.py:167] step: 225600, eval_loss: 5.92560e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:33:38.519400 22392998065984 run_lib.py:146] step: 225650, training_loss: 7.22724e-02
I0515 01:34:01.952887 22392998065984 run_lib.py:146] step: 225700, training_loss: 6.05372e-02
I0515 01:34:02.111465 22392998065984 run_lib.py:167] step: 225700, eval_loss: 5.59782e-02
I0515 01:34:25.822281 22392998065984 run_lib.py:146] step: 225750, training_loss: 5.25734e-02
I0515 01:34:49.480909 22392998065984 run_lib.py:146] step: 225800, training_loss: 6.17704e-02
I0515 01:34:49.638339 22392998065984 run_lib.py:167] step: 225800, eval_loss: 5.40854e-02
I0515 01:35:12.987166 22392998065984 run_lib.py:146] step: 225850, training_loss: 4.93374e-02
I0515 01:35:36.611465 22392998065984 run_lib.py:146] step: 225900, training_loss: 5.70596e-02
I0515 01:35:36.768562 22392998065984 run_lib.py:167] step: 225900, eval_loss: 4.84802e-02
I0515 01:36:00.113226 22392998065984 run_lib.py:146] step: 225950, training_loss: 5.04269e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:36:23.853442 22392998065984 run_lib.py:146] step: 226000, training_loss: 6.14041e-02
I0515 01:36:24.012593 22392998065984 run_lib.py:167] step: 226000, eval_loss: 5.18462e-02
I0515 01:36:47.690024 22392998065984 run_lib.py:146] step: 226050, training_loss: 4.83406e-02
I0515 01:37:11.051101 22392998065984 run_lib.py:146] step: 226100, training_loss: 4.63501e-02
I0515 01:37:11.208393 22392998065984 run_lib.py:167] step: 226100, eval_loss: 5.59867e-02
I0515 01:37:34.883435 22392998065984 run_lib.py:146] step: 226150, training_loss: 5.03672e-02
I0515 01:37:58.519684 22392998065984 run_lib.py:146] step: 226200, training_loss: 5.77002e-02
I0515 01:37:58.677109 22392998065984 run_lib.py:167] step: 226200, eval_loss: 5.69721e-02
I0515 01:38:22.050371 22392998065984 run_lib.py:146] step: 226250, training_loss: 5.01813e-02
I0515 01:38:45.713682 22392998065984 run_lib.py:146] step: 226300, training_loss: 6.72139e-02
I0515 01:38:45.870916 22392998065984 run_lib.py:167] step: 226300, eval_loss: 6.47437e-02
I0515 01:39:09.511442 22392998065984 run_lib.py:146] step: 226350, training_loss: 7.47593e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:39:32.969650 22392998065984 run_lib.py:146] step: 226400, training_loss: 5.05020e-02
I0515 01:39:33.128701 22392998065984 run_lib.py:167] step: 226400, eval_loss: 6.39241e-02
I0515 01:39:56.855550 22392998065984 run_lib.py:146] step: 226450, training_loss: 6.32879e-02
I0515 01:40:20.240198 22392998065984 run_lib.py:146] step: 226500, training_loss: 4.49305e-02
I0515 01:40:20.397403 22392998065984 run_lib.py:167] step: 226500, eval_loss: 6.95202e-02
I0515 01:40:44.062858 22392998065984 run_lib.py:146] step: 226550, training_loss: 7.27713e-02
I0515 01:41:07.734062 22392998065984 run_lib.py:146] step: 226600, training_loss: 5.38827e-02
I0515 01:41:07.891368 22392998065984 run_lib.py:167] step: 226600, eval_loss: 6.85053e-02
I0515 01:41:31.263524 22392998065984 run_lib.py:146] step: 226650, training_loss: 5.76107e-02
I0515 01:41:54.897097 22392998065984 run_lib.py:146] step: 226700, training_loss: 5.27488e-02
I0515 01:41:55.054020 22392998065984 run_lib.py:167] step: 226700, eval_loss: 4.45137e-02
I0515 01:42:18.681200 22392998065984 run_lib.py:146] step: 226750, training_loss: 4.97489e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:42:42.163957 22392998065984 run_lib.py:146] step: 226800, training_loss: 6.94345e-02
I0515 01:42:42.323040 22392998065984 run_lib.py:167] step: 226800, eval_loss: 5.35500e-02
I0515 01:43:06.008741 22392998065984 run_lib.py:146] step: 226850, training_loss: 5.79345e-02
I0515 01:43:29.369353 22392998065984 run_lib.py:146] step: 226900, training_loss: 7.05195e-02
I0515 01:43:29.526809 22392998065984 run_lib.py:167] step: 226900, eval_loss: 6.06179e-02
I0515 01:43:53.247003 22392998065984 run_lib.py:146] step: 226950, training_loss: 5.53632e-02
I0515 01:44:16.890066 22392998065984 run_lib.py:146] step: 227000, training_loss: 6.82517e-02
I0515 01:44:17.062010 22392998065984 run_lib.py:167] step: 227000, eval_loss: 6.05883e-02
I0515 01:44:40.427259 22392998065984 run_lib.py:146] step: 227050, training_loss: 5.60052e-02
I0515 01:45:04.075896 22392998065984 run_lib.py:146] step: 227100, training_loss: 5.63493e-02
I0515 01:45:04.233331 22392998065984 run_lib.py:167] step: 227100, eval_loss: 7.55532e-02
I0515 01:45:27.856884 22392998065984 run_lib.py:146] step: 227150, training_loss: 4.64987e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:45:51.290578 22392998065984 run_lib.py:146] step: 227200, training_loss: 5.59085e-02
I0515 01:45:51.449413 22392998065984 run_lib.py:167] step: 227200, eval_loss: 4.60742e-02
I0515 01:46:15.122845 22392998065984 run_lib.py:146] step: 227250, training_loss: 6.59669e-02
I0515 01:46:38.472155 22392998065984 run_lib.py:146] step: 227300, training_loss: 4.94564e-02
I0515 01:46:38.629357 22392998065984 run_lib.py:167] step: 227300, eval_loss: 6.83842e-02
I0515 01:47:02.262347 22392998065984 run_lib.py:146] step: 227350, training_loss: 5.28666e-02
I0515 01:47:25.902486 22392998065984 run_lib.py:146] step: 227400, training_loss: 7.22084e-02
I0515 01:47:26.059325 22392998065984 run_lib.py:167] step: 227400, eval_loss: 6.74038e-02
I0515 01:47:49.401528 22392998065984 run_lib.py:146] step: 227450, training_loss: 4.61519e-02
I0515 01:48:13.152836 22392998065984 run_lib.py:146] step: 227500, training_loss: 6.89180e-02
I0515 01:48:13.311247 22392998065984 run_lib.py:167] step: 227500, eval_loss: 5.13304e-02
I0515 01:48:37.147478 22392998065984 run_lib.py:146] step: 227550, training_loss: 8.26062e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:49:00.775007 22392998065984 run_lib.py:146] step: 227600, training_loss: 5.11711e-02
I0515 01:49:00.935804 22392998065984 run_lib.py:167] step: 227600, eval_loss: 6.13190e-02
I0515 01:49:24.743832 22392998065984 run_lib.py:146] step: 227650, training_loss: 5.48450e-02
I0515 01:49:48.227647 22392998065984 run_lib.py:146] step: 227700, training_loss: 6.57158e-02
I0515 01:49:48.385424 22392998065984 run_lib.py:167] step: 227700, eval_loss: 6.54193e-02
I0515 01:50:12.098520 22392998065984 run_lib.py:146] step: 227750, training_loss: 4.82737e-02
I0515 01:50:35.735300 22392998065984 run_lib.py:146] step: 227800, training_loss: 4.63549e-02
I0515 01:50:35.892544 22392998065984 run_lib.py:167] step: 227800, eval_loss: 5.35820e-02
I0515 01:50:59.248978 22392998065984 run_lib.py:146] step: 227850, training_loss: 5.70185e-02
I0515 01:51:22.926371 22392998065984 run_lib.py:146] step: 227900, training_loss: 4.78105e-02
I0515 01:51:23.083490 22392998065984 run_lib.py:167] step: 227900, eval_loss: 5.55045e-02
I0515 01:51:46.734934 22392998065984 run_lib.py:146] step: 227950, training_loss: 4.96920e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:52:10.838795 22392998065984 run_lib.py:146] step: 228000, training_loss: 5.89124e-02
I0515 01:52:11.001566 22392998065984 run_lib.py:167] step: 228000, eval_loss: 5.05084e-02
I0515 01:52:34.708495 22392998065984 run_lib.py:146] step: 228050, training_loss: 4.37246e-02
I0515 01:52:58.356741 22392998065984 run_lib.py:146] step: 228100, training_loss: 7.79151e-02
I0515 01:52:58.513864 22392998065984 run_lib.py:167] step: 228100, eval_loss: 6.52688e-02
I0515 01:53:21.871092 22392998065984 run_lib.py:146] step: 228150, training_loss: 5.29961e-02
I0515 01:53:45.538460 22392998065984 run_lib.py:146] step: 228200, training_loss: 6.52290e-02
I0515 01:53:45.695610 22392998065984 run_lib.py:167] step: 228200, eval_loss: 6.87134e-02
I0515 01:54:09.085649 22392998065984 run_lib.py:146] step: 228250, training_loss: 6.28884e-02
I0515 01:54:32.723395 22392998065984 run_lib.py:146] step: 228300, training_loss: 4.58966e-02
I0515 01:54:32.880837 22392998065984 run_lib.py:167] step: 228300, eval_loss: 4.80606e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:54:56.661284 22392998065984 run_lib.py:146] step: 228350, training_loss: 5.45614e-02
I0515 01:55:20.026012 22392998065984 run_lib.py:146] step: 228400, training_loss: 6.28261e-02
I0515 01:55:20.184529 22392998065984 run_lib.py:167] step: 228400, eval_loss: 5.01538e-02
I0515 01:55:43.840929 22392998065984 run_lib.py:146] step: 228450, training_loss: 7.97611e-02
I0515 01:56:07.205620 22392998065984 run_lib.py:146] step: 228500, training_loss: 7.23336e-02
I0515 01:56:07.363028 22392998065984 run_lib.py:167] step: 228500, eval_loss: 4.84273e-02
I0515 01:56:31.048906 22392998065984 run_lib.py:146] step: 228550, training_loss: 7.36403e-02
I0515 01:56:54.690459 22392998065984 run_lib.py:146] step: 228600, training_loss: 6.10523e-02
I0515 01:56:54.847349 22392998065984 run_lib.py:167] step: 228600, eval_loss: 5.86106e-02
I0515 01:57:18.216157 22392998065984 run_lib.py:146] step: 228650, training_loss: 4.97832e-02
I0515 01:57:41.883810 22392998065984 run_lib.py:146] step: 228700, training_loss: 4.15086e-02
I0515 01:57:42.041297 22392998065984 run_lib.py:167] step: 228700, eval_loss: 6.35644e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 01:58:05.822675 22392998065984 run_lib.py:146] step: 228750, training_loss: 5.77035e-02
I0515 01:58:29.189711 22392998065984 run_lib.py:146] step: 228800, training_loss: 6.06405e-02
I0515 01:58:29.352869 22392998065984 run_lib.py:167] step: 228800, eval_loss: 6.14534e-02
I0515 01:58:53.042522 22392998065984 run_lib.py:146] step: 228850, training_loss: 4.86217e-02
I0515 01:59:16.671294 22392998065984 run_lib.py:146] step: 228900, training_loss: 5.56870e-02
I0515 01:59:16.827199 22392998065984 run_lib.py:167] step: 228900, eval_loss: 5.54678e-02
I0515 01:59:40.192324 22392998065984 run_lib.py:146] step: 228950, training_loss: 5.64647e-02
I0515 02:00:03.833268 22392998065984 run_lib.py:146] step: 229000, training_loss: 4.33528e-02
I0515 02:00:03.912075 22392998065984 run_lib.py:167] step: 229000, eval_loss: 6.64469e-02
I0515 02:00:27.251026 22392998065984 run_lib.py:146] step: 229050, training_loss: 4.79883e-02
I0515 02:00:50.884229 22392998065984 run_lib.py:146] step: 229100, training_loss: 5.87629e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:00:51.260745 22392998065984 run_lib.py:167] step: 229100, eval_loss: 4.41695e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:01:15.135174 22392998065984 run_lib.py:146] step: 229150, training_loss: 7.51679e-02
I0515 02:01:38.490494 22392998065984 run_lib.py:146] step: 229200, training_loss: 6.37033e-02
I0515 02:01:38.672832 22392998065984 run_lib.py:167] step: 229200, eval_loss: 6.14446e-02
I0515 02:02:02.336972 22392998065984 run_lib.py:146] step: 229250, training_loss: 5.61543e-02
I0515 02:02:25.688248 22392998065984 run_lib.py:146] step: 229300, training_loss: 6.18890e-02
I0515 02:02:25.846022 22392998065984 run_lib.py:167] step: 229300, eval_loss: 6.35537e-02
I0515 02:02:49.488517 22392998065984 run_lib.py:146] step: 229350, training_loss: 5.34550e-02
I0515 02:03:13.126268 22392998065984 run_lib.py:146] step: 229400, training_loss: 5.53150e-02
I0515 02:03:13.283916 22392998065984 run_lib.py:167] step: 229400, eval_loss: 5.11359e-02
I0515 02:03:36.643701 22392998065984 run_lib.py:146] step: 229450, training_loss: 6.77290e-02
I0515 02:04:00.287486 22392998065984 run_lib.py:146] step: 229500, training_loss: 8.11405e-02
I0515 02:04:00.445049 22392998065984 run_lib.py:167] step: 229500, eval_loss: 5.16831e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:04:24.277686 22392998065984 run_lib.py:146] step: 229550, training_loss: 8.97572e-02
I0515 02:04:47.662121 22392998065984 run_lib.py:146] step: 229600, training_loss: 5.66614e-02
I0515 02:04:47.821017 22392998065984 run_lib.py:167] step: 229600, eval_loss: 6.40922e-02
I0515 02:05:11.534862 22392998065984 run_lib.py:146] step: 229650, training_loss: 4.90247e-02
I0515 02:05:35.163629 22392998065984 run_lib.py:146] step: 229700, training_loss: 6.09956e-02
I0515 02:05:35.321127 22392998065984 run_lib.py:167] step: 229700, eval_loss: 5.40880e-02
I0515 02:05:58.690297 22392998065984 run_lib.py:146] step: 229750, training_loss: 6.46470e-02
I0515 02:06:22.355472 22392998065984 run_lib.py:146] step: 229800, training_loss: 5.52292e-02
I0515 02:06:22.513299 22392998065984 run_lib.py:167] step: 229800, eval_loss: 6.57558e-02
I0515 02:06:45.876885 22392998065984 run_lib.py:146] step: 229850, training_loss: 5.14968e-02
I0515 02:07:09.531599 22392998065984 run_lib.py:146] step: 229900, training_loss: 5.47695e-02
I0515 02:07:09.689103 22392998065984 run_lib.py:167] step: 229900, eval_loss: 6.62234e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:07:33.606297 22392998065984 run_lib.py:146] step: 229950, training_loss: 5.68673e-02
I0515 02:07:56.962725 22392998065984 run_lib.py:146] step: 230000, training_loss: 6.30032e-02
I0515 02:07:58.761579 22392998065984 run_lib.py:167] step: 230000, eval_loss: 6.49890e-02
I0515 02:08:24.249027 22392998065984 run_lib.py:146] step: 230050, training_loss: 6.30228e-02
I0515 02:08:47.617772 22392998065984 run_lib.py:146] step: 230100, training_loss: 7.84189e-02
I0515 02:08:47.775582 22392998065984 run_lib.py:167] step: 230100, eval_loss: 6.17921e-02
I0515 02:09:11.157117 22392998065984 run_lib.py:146] step: 230150, training_loss: 6.27493e-02
I0515 02:09:34.803402 22392998065984 run_lib.py:146] step: 230200, training_loss: 5.38899e-02
I0515 02:09:34.961205 22392998065984 run_lib.py:167] step: 230200, eval_loss: 5.72302e-02
I0515 02:09:58.615885 22392998065984 run_lib.py:146] step: 230250, training_loss: 4.89427e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:10:22.117770 22392998065984 run_lib.py:146] step: 230300, training_loss: 5.71579e-02
I0515 02:10:22.277071 22392998065984 run_lib.py:167] step: 230300, eval_loss: 5.56873e-02
I0515 02:10:45.963396 22392998065984 run_lib.py:146] step: 230350, training_loss: 5.51395e-02
I0515 02:11:09.680253 22392998065984 run_lib.py:146] step: 230400, training_loss: 6.72463e-02
I0515 02:11:09.837420 22392998065984 run_lib.py:167] step: 230400, eval_loss: 5.48922e-02
I0515 02:11:33.198417 22392998065984 run_lib.py:146] step: 230450, training_loss: 4.74199e-02
I0515 02:11:56.836620 22392998065984 run_lib.py:146] step: 230500, training_loss: 5.24375e-02
I0515 02:11:57.030102 22392998065984 run_lib.py:167] step: 230500, eval_loss: 5.65777e-02
I0515 02:12:20.681700 22392998065984 run_lib.py:146] step: 230550, training_loss: 4.67259e-02
I0515 02:12:44.088593 22392998065984 run_lib.py:146] step: 230600, training_loss: 6.15912e-02
I0515 02:12:44.246352 22392998065984 run_lib.py:167] step: 230600, eval_loss: 7.65889e-02
I0515 02:13:07.616329 22392998065984 run_lib.py:146] step: 230650, training_loss: 5.74056e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:13:31.649442 22392998065984 run_lib.py:146] step: 230700, training_loss: 5.56821e-02
I0515 02:13:31.808372 22392998065984 run_lib.py:167] step: 230700, eval_loss: 6.39441e-02
I0515 02:13:55.180139 22392998065984 run_lib.py:146] step: 230750, training_loss: 5.16101e-02
I0515 02:14:18.537044 22392998065984 run_lib.py:146] step: 230800, training_loss: 6.41203e-02
I0515 02:14:18.694160 22392998065984 run_lib.py:167] step: 230800, eval_loss: 5.44877e-02
I0515 02:14:42.726694 22392998065984 run_lib.py:146] step: 230850, training_loss: 4.82745e-02
I0515 02:15:06.109561 22392998065984 run_lib.py:146] step: 230900, training_loss: 5.52120e-02
I0515 02:15:06.266892 22392998065984 run_lib.py:167] step: 230900, eval_loss: 5.66060e-02
I0515 02:15:29.637293 22392998065984 run_lib.py:146] step: 230950, training_loss: 7.49302e-02
I0515 02:15:53.278748 22392998065984 run_lib.py:146] step: 231000, training_loss: 6.19866e-02
I0515 02:15:53.436817 22392998065984 run_lib.py:167] step: 231000, eval_loss: 6.00704e-02
I0515 02:16:17.104666 22392998065984 run_lib.py:146] step: 231050, training_loss: 6.73935e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:16:40.610752 22392998065984 run_lib.py:146] step: 231100, training_loss: 5.59630e-02
I0515 02:16:40.769918 22392998065984 run_lib.py:167] step: 231100, eval_loss: 6.16466e-02
I0515 02:17:04.448183 22392998065984 run_lib.py:146] step: 231150, training_loss: 5.41783e-02
I0515 02:17:28.127567 22392998065984 run_lib.py:146] step: 231200, training_loss: 5.54180e-02
I0515 02:17:28.284655 22392998065984 run_lib.py:167] step: 231200, eval_loss: 5.92379e-02
I0515 02:17:51.641293 22392998065984 run_lib.py:146] step: 231250, training_loss: 6.32355e-02
I0515 02:18:15.289168 22392998065984 run_lib.py:146] step: 231300, training_loss: 6.42455e-02
I0515 02:18:15.446603 22392998065984 run_lib.py:167] step: 231300, eval_loss: 6.84476e-02
I0515 02:18:39.118551 22392998065984 run_lib.py:146] step: 231350, training_loss: 5.86167e-02
I0515 02:19:02.505188 22392998065984 run_lib.py:146] step: 231400, training_loss: 6.73967e-02
I0515 02:19:02.663395 22392998065984 run_lib.py:167] step: 231400, eval_loss: 6.87393e-02
I0515 02:19:26.313712 22392998065984 run_lib.py:146] step: 231450, training_loss: 6.92174e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:19:50.131870 22392998065984 run_lib.py:146] step: 231500, training_loss: 5.16649e-02
I0515 02:19:50.290505 22392998065984 run_lib.py:167] step: 231500, eval_loss: 6.90787e-02
I0515 02:20:13.659253 22392998065984 run_lib.py:146] step: 231550, training_loss: 7.97754e-02
I0515 02:20:37.017176 22392998065984 run_lib.py:146] step: 231600, training_loss: 6.54070e-02
I0515 02:20:37.174712 22392998065984 run_lib.py:167] step: 231600, eval_loss: 4.75919e-02
I0515 02:21:01.127300 22392998065984 run_lib.py:146] step: 231650, training_loss: 5.04531e-02
I0515 02:21:24.486033 22392998065984 run_lib.py:146] step: 231700, training_loss: 5.49838e-02
I0515 02:21:24.643257 22392998065984 run_lib.py:167] step: 231700, eval_loss: 6.13416e-02
I0515 02:21:48.004422 22392998065984 run_lib.py:146] step: 231750, training_loss: 5.71176e-02
I0515 02:22:11.660309 22392998065984 run_lib.py:146] step: 231800, training_loss: 4.46111e-02
I0515 02:22:11.818382 22392998065984 run_lib.py:167] step: 231800, eval_loss: 6.87998e-02
I0515 02:22:35.479396 22392998065984 run_lib.py:146] step: 231850, training_loss: 5.94552e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:22:58.934047 22392998065984 run_lib.py:146] step: 231900, training_loss: 5.67806e-02
I0515 02:22:59.093009 22392998065984 run_lib.py:167] step: 231900, eval_loss: 5.84430e-02
I0515 02:23:22.749924 22392998065984 run_lib.py:146] step: 231950, training_loss: 4.39057e-02
I0515 02:23:46.437155 22392998065984 run_lib.py:146] step: 232000, training_loss: 5.84273e-02
I0515 02:23:46.594635 22392998065984 run_lib.py:167] step: 232000, eval_loss: 7.71621e-02
I0515 02:24:09.969303 22392998065984 run_lib.py:146] step: 232050, training_loss: 5.59294e-02
I0515 02:24:33.612036 22392998065984 run_lib.py:146] step: 232100, training_loss: 5.29278e-02
I0515 02:24:33.782105 22392998065984 run_lib.py:167] step: 232100, eval_loss: 4.73326e-02
I0515 02:24:57.437055 22392998065984 run_lib.py:146] step: 232150, training_loss: 7.17813e-02
I0515 02:25:20.791594 22392998065984 run_lib.py:146] step: 232200, training_loss: 5.44158e-02
I0515 02:25:20.949120 22392998065984 run_lib.py:167] step: 232200, eval_loss: 5.33136e-02
I0515 02:25:44.596308 22392998065984 run_lib.py:146] step: 232250, training_loss: 4.68827e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:26:08.420045 22392998065984 run_lib.py:146] step: 232300, training_loss: 6.29328e-02
I0515 02:26:08.578547 22392998065984 run_lib.py:167] step: 232300, eval_loss: 6.31013e-02
I0515 02:26:31.932866 22392998065984 run_lib.py:146] step: 232350, training_loss: 5.43091e-02
I0515 02:26:55.312517 22392998065984 run_lib.py:146] step: 232400, training_loss: 7.81183e-02
I0515 02:26:55.469814 22392998065984 run_lib.py:167] step: 232400, eval_loss: 4.00966e-02
I0515 02:27:19.433273 22392998065984 run_lib.py:146] step: 232450, training_loss: 6.04360e-02
I0515 02:27:42.785740 22392998065984 run_lib.py:146] step: 232500, training_loss: 5.99962e-02
I0515 02:27:42.943307 22392998065984 run_lib.py:167] step: 232500, eval_loss: 4.76692e-02
I0515 02:28:06.299697 22392998065984 run_lib.py:146] step: 232550, training_loss: 4.74712e-02
I0515 02:28:29.927086 22392998065984 run_lib.py:146] step: 232600, training_loss: 4.01315e-02
I0515 02:28:30.084881 22392998065984 run_lib.py:167] step: 232600, eval_loss: 5.72227e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:28:53.861174 22392998065984 run_lib.py:146] step: 232650, training_loss: 4.15849e-02
I0515 02:29:17.246355 22392998065984 run_lib.py:146] step: 232700, training_loss: 6.00550e-02
I0515 02:29:17.405592 22392998065984 run_lib.py:167] step: 232700, eval_loss: 6.96137e-02
I0515 02:29:41.089470 22392998065984 run_lib.py:146] step: 232750, training_loss: 5.95001e-02
I0515 02:30:04.810053 22392998065984 run_lib.py:146] step: 232800, training_loss: 4.74138e-02
I0515 02:30:04.967549 22392998065984 run_lib.py:167] step: 232800, eval_loss: 6.81793e-02
I0515 02:30:28.349349 22392998065984 run_lib.py:146] step: 232850, training_loss: 6.44944e-02
I0515 02:30:52.002101 22392998065984 run_lib.py:146] step: 232900, training_loss: 5.74800e-02
I0515 02:30:52.159767 22392998065984 run_lib.py:167] step: 232900, eval_loss: 5.82536e-02
I0515 02:31:15.830680 22392998065984 run_lib.py:146] step: 232950, training_loss: 7.28926e-02
I0515 02:31:39.177965 22392998065984 run_lib.py:146] step: 233000, training_loss: 5.06100e-02
I0515 02:31:39.334911 22392998065984 run_lib.py:167] step: 233000, eval_loss: 5.94854e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:32:03.112492 22392998065984 run_lib.py:146] step: 233050, training_loss: 5.38038e-02
I0515 02:32:26.809666 22392998065984 run_lib.py:146] step: 233100, training_loss: 4.93978e-02
I0515 02:32:26.968234 22392998065984 run_lib.py:167] step: 233100, eval_loss: 8.25270e-02
I0515 02:32:50.328682 22392998065984 run_lib.py:146] step: 233150, training_loss: 5.57207e-02
I0515 02:33:13.696691 22392998065984 run_lib.py:146] step: 233200, training_loss: 5.78680e-02
I0515 02:33:13.854266 22392998065984 run_lib.py:167] step: 233200, eval_loss: 6.27528e-02
I0515 02:33:37.789867 22392998065984 run_lib.py:146] step: 233250, training_loss: 4.77485e-02
I0515 02:34:01.152146 22392998065984 run_lib.py:146] step: 233300, training_loss: 4.98378e-02
I0515 02:34:01.309216 22392998065984 run_lib.py:167] step: 233300, eval_loss: 6.07186e-02
I0515 02:34:24.659373 22392998065984 run_lib.py:146] step: 233350, training_loss: 4.73415e-02
I0515 02:34:48.594534 22392998065984 run_lib.py:146] step: 233400, training_loss: 6.57945e-02
I0515 02:34:48.751452 22392998065984 run_lib.py:167] step: 233400, eval_loss: 7.19084e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:35:12.222204 22392998065984 run_lib.py:146] step: 233450, training_loss: 5.87562e-02
I0515 02:35:35.569118 22392998065984 run_lib.py:146] step: 233500, training_loss: 6.20552e-02
I0515 02:35:35.728377 22392998065984 run_lib.py:167] step: 233500, eval_loss: 4.87753e-02
I0515 02:35:59.426096 22392998065984 run_lib.py:146] step: 233550, training_loss: 6.30220e-02
I0515 02:36:23.118268 22392998065984 run_lib.py:146] step: 233600, training_loss: 5.53766e-02
I0515 02:36:23.275947 22392998065984 run_lib.py:167] step: 233600, eval_loss: 6.56861e-02
I0515 02:36:46.624842 22392998065984 run_lib.py:146] step: 233650, training_loss: 4.56364e-02
I0515 02:37:10.264723 22392998065984 run_lib.py:146] step: 233700, training_loss: 5.07861e-02
I0515 02:37:10.443052 22392998065984 run_lib.py:167] step: 233700, eval_loss: 5.46103e-02
I0515 02:37:34.115871 22392998065984 run_lib.py:146] step: 233750, training_loss: 5.10658e-02
I0515 02:37:57.464258 22392998065984 run_lib.py:146] step: 233800, training_loss: 5.22019e-02
I0515 02:37:57.621820 22392998065984 run_lib.py:167] step: 233800, eval_loss: 5.49124e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:38:21.380659 22392998065984 run_lib.py:146] step: 233850, training_loss: 6.28138e-02
I0515 02:38:45.078731 22392998065984 run_lib.py:146] step: 233900, training_loss: 5.08819e-02
I0515 02:38:45.237090 22392998065984 run_lib.py:167] step: 233900, eval_loss: 6.21094e-02
I0515 02:39:08.596228 22392998065984 run_lib.py:146] step: 233950, training_loss: 6.14699e-02
I0515 02:39:31.962905 22392998065984 run_lib.py:146] step: 234000, training_loss: 7.21004e-02
I0515 02:39:32.120264 22392998065984 run_lib.py:167] step: 234000, eval_loss: 6.79678e-02
I0515 02:39:56.065618 22392998065984 run_lib.py:146] step: 234050, training_loss: 5.33581e-02
I0515 02:40:19.447303 22392998065984 run_lib.py:146] step: 234100, training_loss: 6.19434e-02
I0515 02:40:19.604857 22392998065984 run_lib.py:167] step: 234100, eval_loss: 5.64891e-02
I0515 02:40:42.984525 22392998065984 run_lib.py:146] step: 234150, training_loss: 5.24592e-02
I0515 02:41:06.624335 22392998065984 run_lib.py:146] step: 234200, training_loss: 6.17609e-02
I0515 02:41:06.781831 22392998065984 run_lib.py:167] step: 234200, eval_loss: 6.60327e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:41:30.555780 22392998065984 run_lib.py:146] step: 234250, training_loss: 7.41136e-02
I0515 02:41:53.923292 22392998065984 run_lib.py:146] step: 234300, training_loss: 7.02250e-02
I0515 02:41:54.082150 22392998065984 run_lib.py:167] step: 234300, eval_loss: 5.59586e-02
I0515 02:42:17.759507 22392998065984 run_lib.py:146] step: 234350, training_loss: 6.93669e-02
I0515 02:42:41.472384 22392998065984 run_lib.py:146] step: 234400, training_loss: 5.75998e-02
I0515 02:42:41.629774 22392998065984 run_lib.py:167] step: 234400, eval_loss: 5.32546e-02
I0515 02:43:05.009108 22392998065984 run_lib.py:146] step: 234450, training_loss: 5.65621e-02
I0515 02:43:28.655705 22392998065984 run_lib.py:146] step: 234500, training_loss: 6.20337e-02
I0515 02:43:28.812957 22392998065984 run_lib.py:167] step: 234500, eval_loss: 6.70536e-02
I0515 02:43:52.471243 22392998065984 run_lib.py:146] step: 234550, training_loss: 5.08550e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:44:15.924739 22392998065984 run_lib.py:146] step: 234600, training_loss: 4.78558e-02
I0515 02:44:16.084011 22392998065984 run_lib.py:167] step: 234600, eval_loss: 6.03008e-02
I0515 02:44:39.770343 22392998065984 run_lib.py:146] step: 234650, training_loss: 7.51857e-02
I0515 02:45:03.481306 22392998065984 run_lib.py:146] step: 234700, training_loss: 6.33829e-02
I0515 02:45:03.639621 22392998065984 run_lib.py:167] step: 234700, eval_loss: 6.11689e-02
I0515 02:45:26.983644 22392998065984 run_lib.py:146] step: 234750, training_loss: 5.71946e-02
I0515 02:45:50.614633 22392998065984 run_lib.py:146] step: 234800, training_loss: 6.21092e-02
I0515 02:45:50.771706 22392998065984 run_lib.py:167] step: 234800, eval_loss: 4.34970e-02
I0515 02:46:14.415344 22392998065984 run_lib.py:146] step: 234850, training_loss: 5.23864e-02
I0515 02:46:37.764613 22392998065984 run_lib.py:146] step: 234900, training_loss: 4.77219e-02
I0515 02:46:37.921709 22392998065984 run_lib.py:167] step: 234900, eval_loss: 5.44386e-02
I0515 02:47:01.271467 22392998065984 run_lib.py:146] step: 234950, training_loss: 4.72773e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:47:25.402103 22392998065984 run_lib.py:146] step: 235000, training_loss: 4.77962e-02
I0515 02:47:25.560452 22392998065984 run_lib.py:167] step: 235000, eval_loss: 4.80969e-02
I0515 02:47:48.907450 22392998065984 run_lib.py:146] step: 235050, training_loss: 6.19379e-02
I0515 02:48:12.258426 22392998065984 run_lib.py:146] step: 235100, training_loss: 4.91615e-02
I0515 02:48:12.415974 22392998065984 run_lib.py:167] step: 235100, eval_loss: 5.46558e-02
I0515 02:48:36.091716 22392998065984 run_lib.py:146] step: 235150, training_loss: 6.47949e-02
I0515 02:48:59.757364 22392998065984 run_lib.py:146] step: 235200, training_loss: 6.54602e-02
I0515 02:48:59.914359 22392998065984 run_lib.py:167] step: 235200, eval_loss: 6.04910e-02
I0515 02:49:23.271939 22392998065984 run_lib.py:146] step: 235250, training_loss: 1.04848e-01
I0515 02:49:46.930603 22392998065984 run_lib.py:146] step: 235300, training_loss: 6.24670e-02
I0515 02:49:47.112402 22392998065984 run_lib.py:167] step: 235300, eval_loss: 5.60172e-02
I0515 02:50:10.766811 22392998065984 run_lib.py:146] step: 235350, training_loss: 6.33206e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:50:34.228638 22392998065984 run_lib.py:146] step: 235400, training_loss: 4.81011e-02
I0515 02:50:34.387825 22392998065984 run_lib.py:167] step: 235400, eval_loss: 9.65609e-02
I0515 02:50:58.084155 22392998065984 run_lib.py:146] step: 235450, training_loss: 8.25007e-02
I0515 02:51:21.823759 22392998065984 run_lib.py:146] step: 235500, training_loss: 4.65645e-02
I0515 02:51:22.021778 22392998065984 run_lib.py:167] step: 235500, eval_loss: 7.46175e-02
I0515 02:51:45.399051 22392998065984 run_lib.py:146] step: 235550, training_loss: 4.80279e-02
I0515 02:52:09.039841 22392998065984 run_lib.py:146] step: 235600, training_loss: 6.17058e-02
I0515 02:52:09.197067 22392998065984 run_lib.py:167] step: 235600, eval_loss: 6.80821e-02
I0515 02:52:32.863091 22392998065984 run_lib.py:146] step: 235650, training_loss: 4.72952e-02
I0515 02:52:56.244237 22392998065984 run_lib.py:146] step: 235700, training_loss: 6.51270e-02
I0515 02:52:56.401488 22392998065984 run_lib.py:167] step: 235700, eval_loss: 5.79161e-02
I0515 02:53:20.049529 22392998065984 run_lib.py:146] step: 235750, training_loss: 6.39454e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:53:43.514437 22392998065984 run_lib.py:146] step: 235800, training_loss: 5.21825e-02
I0515 02:53:43.673668 22392998065984 run_lib.py:167] step: 235800, eval_loss: 5.20797e-02
I0515 02:54:07.368355 22392998065984 run_lib.py:146] step: 235850, training_loss: 5.80733e-02
I0515 02:54:30.729629 22392998065984 run_lib.py:146] step: 235900, training_loss: 5.28057e-02
I0515 02:54:30.887202 22392998065984 run_lib.py:167] step: 235900, eval_loss: 5.46304e-02
I0515 02:54:54.550384 22392998065984 run_lib.py:146] step: 235950, training_loss: 6.29867e-02
I0515 02:55:18.201639 22392998065984 run_lib.py:146] step: 236000, training_loss: 5.31125e-02
I0515 02:55:18.358963 22392998065984 run_lib.py:167] step: 236000, eval_loss: 7.10233e-02
I0515 02:55:41.706846 22392998065984 run_lib.py:146] step: 236050, training_loss: 4.10326e-02
I0515 02:56:05.314541 22392998065984 run_lib.py:146] step: 236100, training_loss: 5.98345e-02
I0515 02:56:05.472150 22392998065984 run_lib.py:167] step: 236100, eval_loss: 6.28182e-02
I0515 02:56:29.107819 22392998065984 run_lib.py:146] step: 236150, training_loss: 6.77757e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 02:56:52.578937 22392998065984 run_lib.py:146] step: 236200, training_loss: 5.16182e-02
I0515 02:56:52.738193 22392998065984 run_lib.py:167] step: 236200, eval_loss: 5.99636e-02
I0515 02:57:16.438785 22392998065984 run_lib.py:146] step: 236250, training_loss: 5.38254e-02
I0515 02:57:40.146953 22392998065984 run_lib.py:146] step: 236300, training_loss: 8.40243e-02
I0515 02:57:40.304384 22392998065984 run_lib.py:167] step: 236300, eval_loss: 4.56453e-02
I0515 02:58:03.652635 22392998065984 run_lib.py:146] step: 236350, training_loss: 5.26086e-02
I0515 02:58:27.271337 22392998065984 run_lib.py:146] step: 236400, training_loss: 7.35647e-02
I0515 02:58:27.428971 22392998065984 run_lib.py:167] step: 236400, eval_loss: 5.30454e-02
I0515 02:58:51.080162 22392998065984 run_lib.py:146] step: 236450, training_loss: 5.61189e-02
I0515 02:59:14.451680 22392998065984 run_lib.py:146] step: 236500, training_loss: 4.69555e-02
I0515 02:59:14.609708 22392998065984 run_lib.py:167] step: 236500, eval_loss: 6.80767e-02
I0515 02:59:38.272540 22392998065984 run_lib.py:146] step: 236550, training_loss: 5.99819e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:00:02.096344 22392998065984 run_lib.py:146] step: 236600, training_loss: 6.26157e-02
I0515 03:00:02.255170 22392998065984 run_lib.py:167] step: 236600, eval_loss: 5.57288e-02
I0515 03:00:25.607905 22392998065984 run_lib.py:146] step: 236650, training_loss: 5.90404e-02
I0515 03:00:48.959803 22392998065984 run_lib.py:146] step: 236700, training_loss: 5.64497e-02
I0515 03:00:49.117283 22392998065984 run_lib.py:167] step: 236700, eval_loss: 5.46401e-02
I0515 03:01:12.764972 22392998065984 run_lib.py:146] step: 236750, training_loss: 4.92851e-02
I0515 03:01:36.423355 22392998065984 run_lib.py:146] step: 236800, training_loss: 4.67333e-02
I0515 03:01:36.579668 22392998065984 run_lib.py:167] step: 236800, eval_loss: 6.97164e-02
I0515 03:01:59.946127 22392998065984 run_lib.py:146] step: 236850, training_loss: 4.23024e-02
I0515 03:02:23.586055 22392998065984 run_lib.py:146] step: 236900, training_loss: 5.54728e-02
I0515 03:02:23.678687 22392998065984 run_lib.py:167] step: 236900, eval_loss: 5.72375e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:02:47.422398 22392998065984 run_lib.py:146] step: 236950, training_loss: 6.19070e-02
I0515 03:03:10.795032 22392998065984 run_lib.py:146] step: 237000, training_loss: 5.46320e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:03:11.161212 22392998065984 run_lib.py:167] step: 237000, eval_loss: 5.86114e-02
I0515 03:03:34.844207 22392998065984 run_lib.py:146] step: 237050, training_loss: 5.17246e-02
I0515 03:03:58.541814 22392998065984 run_lib.py:146] step: 237100, training_loss: 5.20830e-02
I0515 03:03:58.699283 22392998065984 run_lib.py:167] step: 237100, eval_loss: 7.28068e-02
I0515 03:04:22.081759 22392998065984 run_lib.py:146] step: 237150, training_loss: 6.62947e-02
I0515 03:04:45.730549 22392998065984 run_lib.py:146] step: 237200, training_loss: 4.65431e-02
I0515 03:04:45.888339 22392998065984 run_lib.py:167] step: 237200, eval_loss: 6.36636e-02
I0515 03:05:09.554760 22392998065984 run_lib.py:146] step: 237250, training_loss: 4.10256e-02
I0515 03:05:32.902002 22392998065984 run_lib.py:146] step: 237300, training_loss: 5.25322e-02
I0515 03:05:33.068997 22392998065984 run_lib.py:167] step: 237300, eval_loss: 4.92129e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:05:56.885209 22392998065984 run_lib.py:146] step: 237350, training_loss: 6.44091e-02
I0515 03:06:20.593430 22392998065984 run_lib.py:146] step: 237400, training_loss: 4.81691e-02
I0515 03:06:20.751751 22392998065984 run_lib.py:167] step: 237400, eval_loss: 5.72200e-02
I0515 03:06:44.129495 22392998065984 run_lib.py:146] step: 237450, training_loss: 4.88748e-02
I0515 03:07:07.493719 22392998065984 run_lib.py:146] step: 237500, training_loss: 6.94726e-02
I0515 03:07:07.651580 22392998065984 run_lib.py:167] step: 237500, eval_loss: 5.73968e-02
I0515 03:07:31.267459 22392998065984 run_lib.py:146] step: 237550, training_loss: 5.77710e-02
I0515 03:07:54.943799 22392998065984 run_lib.py:146] step: 237600, training_loss: 5.75966e-02
I0515 03:07:55.100932 22392998065984 run_lib.py:167] step: 237600, eval_loss: 6.15691e-02
I0515 03:08:18.460588 22392998065984 run_lib.py:146] step: 237650, training_loss: 4.07958e-02
I0515 03:08:42.075908 22392998065984 run_lib.py:146] step: 237700, training_loss: 5.70486e-02
I0515 03:08:42.233208 22392998065984 run_lib.py:167] step: 237700, eval_loss: 5.71082e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:09:05.989964 22392998065984 run_lib.py:146] step: 237750, training_loss: 5.96883e-02
I0515 03:09:29.347631 22392998065984 run_lib.py:146] step: 237800, training_loss: 5.12136e-02
I0515 03:09:29.506084 22392998065984 run_lib.py:167] step: 237800, eval_loss: 6.95693e-02
I0515 03:09:53.167439 22392998065984 run_lib.py:146] step: 237850, training_loss: 6.90228e-02
I0515 03:10:16.848780 22392998065984 run_lib.py:146] step: 237900, training_loss: 6.18924e-02
I0515 03:10:17.006049 22392998065984 run_lib.py:167] step: 237900, eval_loss: 5.56557e-02
I0515 03:10:40.363422 22392998065984 run_lib.py:146] step: 237950, training_loss: 6.67922e-02
I0515 03:11:04.001447 22392998065984 run_lib.py:146] step: 238000, training_loss: 5.36210e-02
I0515 03:11:04.159047 22392998065984 run_lib.py:167] step: 238000, eval_loss: 4.64344e-02
I0515 03:11:27.828966 22392998065984 run_lib.py:146] step: 238050, training_loss: 5.91888e-02
I0515 03:11:51.204843 22392998065984 run_lib.py:146] step: 238100, training_loss: 6.92329e-02
I0515 03:11:51.362078 22392998065984 run_lib.py:167] step: 238100, eval_loss: 7.35742e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:12:15.201440 22392998065984 run_lib.py:146] step: 238150, training_loss: 5.26752e-02
I0515 03:12:38.490935 22392998065984 run_lib.py:146] step: 238200, training_loss: 6.23206e-02
I0515 03:12:38.648664 22392998065984 run_lib.py:167] step: 238200, eval_loss: 6.11458e-02
I0515 03:13:02.286264 22392998065984 run_lib.py:146] step: 238250, training_loss: 5.37655e-02
I0515 03:13:25.601893 22392998065984 run_lib.py:146] step: 238300, training_loss: 5.52066e-02
I0515 03:13:25.758937 22392998065984 run_lib.py:167] step: 238300, eval_loss: 4.36826e-02
I0515 03:13:49.354465 22392998065984 run_lib.py:146] step: 238350, training_loss: 7.80602e-02
I0515 03:14:12.942422 22392998065984 run_lib.py:146] step: 238400, training_loss: 4.88982e-02
I0515 03:14:13.099203 22392998065984 run_lib.py:167] step: 238400, eval_loss: 7.42762e-02
I0515 03:14:36.405373 22392998065984 run_lib.py:146] step: 238450, training_loss: 5.72693e-02
I0515 03:15:00.006703 22392998065984 run_lib.py:146] step: 238500, training_loss: 6.30706e-02
I0515 03:15:00.183254 22392998065984 run_lib.py:167] step: 238500, eval_loss: 6.54847e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:15:23.963307 22392998065984 run_lib.py:146] step: 238550, training_loss: 4.96336e-02
I0515 03:15:47.621275 22392998065984 run_lib.py:146] step: 238600, training_loss: 5.96654e-02
I0515 03:15:47.780117 22392998065984 run_lib.py:167] step: 238600, eval_loss: 7.38126e-02
I0515 03:16:11.513379 22392998065984 run_lib.py:146] step: 238650, training_loss: 5.28530e-02
I0515 03:16:35.462129 22392998065984 run_lib.py:146] step: 238700, training_loss: 5.91101e-02
I0515 03:16:35.618862 22392998065984 run_lib.py:167] step: 238700, eval_loss: 5.29778e-02
I0515 03:16:59.325783 22392998065984 run_lib.py:146] step: 238750, training_loss: 6.21670e-02
I0515 03:17:22.948819 22392998065984 run_lib.py:146] step: 238800, training_loss: 4.06899e-02
I0515 03:17:23.105519 22392998065984 run_lib.py:167] step: 238800, eval_loss: 4.33732e-02
I0515 03:17:46.669829 22392998065984 run_lib.py:146] step: 238850, training_loss: 5.26812e-02
I0515 03:18:09.840402 22392998065984 run_lib.py:146] step: 238900, training_loss: 4.74285e-02
I0515 03:18:09.997058 22392998065984 run_lib.py:167] step: 238900, eval_loss: 5.90814e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:18:34.533475 22392998065984 run_lib.py:146] step: 238950, training_loss: 5.03664e-02
I0515 03:18:58.784388 22392998065984 run_lib.py:146] step: 239000, training_loss: 5.84761e-02
I0515 03:18:58.941365 22392998065984 run_lib.py:167] step: 239000, eval_loss: 5.94982e-02
I0515 03:19:22.904553 22392998065984 run_lib.py:146] step: 239050, training_loss: 5.15500e-02
I0515 03:19:46.861892 22392998065984 run_lib.py:146] step: 239100, training_loss: 6.51422e-02
I0515 03:19:47.018647 22392998065984 run_lib.py:167] step: 239100, eval_loss: 7.45037e-02
I0515 03:20:11.300855 22392998065984 run_lib.py:146] step: 239150, training_loss: 7.19645e-02
I0515 03:20:34.935212 22392998065984 run_lib.py:146] step: 239200, training_loss: 5.32139e-02
I0515 03:20:35.091959 22392998065984 run_lib.py:167] step: 239200, eval_loss: 5.78395e-02
I0515 03:20:58.385460 22392998065984 run_lib.py:146] step: 239250, training_loss: 7.20769e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:21:22.144456 22392998065984 run_lib.py:146] step: 239300, training_loss: 6.38707e-02
I0515 03:21:22.302993 22392998065984 run_lib.py:167] step: 239300, eval_loss: 5.02008e-02
I0515 03:21:45.955670 22392998065984 run_lib.py:146] step: 239350, training_loss: 5.53480e-02
I0515 03:22:09.263334 22392998065984 run_lib.py:146] step: 239400, training_loss: 5.70591e-02
I0515 03:22:09.420774 22392998065984 run_lib.py:167] step: 239400, eval_loss: 4.92709e-02
I0515 03:22:33.042818 22392998065984 run_lib.py:146] step: 239450, training_loss: 4.70682e-02
I0515 03:22:56.635653 22392998065984 run_lib.py:146] step: 239500, training_loss: 6.19683e-02
I0515 03:22:56.792340 22392998065984 run_lib.py:167] step: 239500, eval_loss: 3.99431e-02
I0515 03:23:20.085250 22392998065984 run_lib.py:146] step: 239550, training_loss: 4.69975e-02
I0515 03:23:43.698152 22392998065984 run_lib.py:146] step: 239600, training_loss: 5.25645e-02
I0515 03:23:43.855353 22392998065984 run_lib.py:167] step: 239600, eval_loss: 4.80189e-02
I0515 03:24:07.462566 22392998065984 run_lib.py:146] step: 239650, training_loss: 5.60981e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:24:31.129055 22392998065984 run_lib.py:146] step: 239700, training_loss: 4.67796e-02
I0515 03:24:31.287321 22392998065984 run_lib.py:167] step: 239700, eval_loss: 5.21015e-02
I0515 03:24:55.078835 22392998065984 run_lib.py:146] step: 239750, training_loss: 5.64851e-02
I0515 03:25:18.706230 22392998065984 run_lib.py:146] step: 239800, training_loss: 6.59601e-02
I0515 03:25:18.862990 22392998065984 run_lib.py:167] step: 239800, eval_loss: 5.13212e-02
I0515 03:25:42.162971 22392998065984 run_lib.py:146] step: 239850, training_loss: 5.80831e-02
I0515 03:26:05.460643 22392998065984 run_lib.py:146] step: 239900, training_loss: 4.69566e-02
I0515 03:26:05.617814 22392998065984 run_lib.py:167] step: 239900, eval_loss: 4.51742e-02
I0515 03:26:29.547036 22392998065984 run_lib.py:146] step: 239950, training_loss: 5.62889e-02
I0515 03:26:52.835554 22392998065984 run_lib.py:146] step: 240000, training_loss: 4.98773e-02
I0515 03:26:54.535825 22392998065984 run_lib.py:167] step: 240000, eval_loss: 5.96966e-02
I0515 03:27:19.320096 22392998065984 run_lib.py:146] step: 240050, training_loss: 5.06261e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:27:43.360613 22392998065984 run_lib.py:146] step: 240100, training_loss: 5.60111e-02
I0515 03:27:43.519119 22392998065984 run_lib.py:167] step: 240100, eval_loss: 5.93985e-02
I0515 03:28:06.797551 22392998065984 run_lib.py:146] step: 240150, training_loss: 6.49149e-02
I0515 03:28:30.087594 22392998065984 run_lib.py:146] step: 240200, training_loss: 6.32074e-02
I0515 03:28:30.244167 22392998065984 run_lib.py:167] step: 240200, eval_loss: 7.09546e-02
I0515 03:28:54.191377 22392998065984 run_lib.py:146] step: 240250, training_loss: 6.02682e-02
I0515 03:29:17.476574 22392998065984 run_lib.py:146] step: 240300, training_loss: 6.34210e-02
I0515 03:29:17.633503 22392998065984 run_lib.py:167] step: 240300, eval_loss: 5.06959e-02
I0515 03:29:40.913059 22392998065984 run_lib.py:146] step: 240350, training_loss: 5.65904e-02
I0515 03:30:04.821037 22392998065984 run_lib.py:146] step: 240400, training_loss: 6.42445e-02
I0515 03:30:04.977847 22392998065984 run_lib.py:167] step: 240400, eval_loss: 7.61016e-02
I0515 03:30:28.290023 22392998065984 run_lib.py:146] step: 240450, training_loss: 4.82365e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:30:51.724075 22392998065984 run_lib.py:146] step: 240500, training_loss: 4.85935e-02
I0515 03:30:51.882496 22392998065984 run_lib.py:167] step: 240500, eval_loss: 5.55701e-02
I0515 03:31:15.850395 22392998065984 run_lib.py:146] step: 240550, training_loss: 5.99876e-02
I0515 03:31:39.126411 22392998065984 run_lib.py:146] step: 240600, training_loss: 5.15774e-02
I0515 03:31:39.282873 22392998065984 run_lib.py:167] step: 240600, eval_loss: 5.59657e-02
I0515 03:32:02.554180 22392998065984 run_lib.py:146] step: 240650, training_loss: 5.97213e-02
I0515 03:32:26.146515 22392998065984 run_lib.py:146] step: 240700, training_loss: 8.36421e-02
I0515 03:32:26.303040 22392998065984 run_lib.py:167] step: 240700, eval_loss: 3.73751e-02
I0515 03:32:49.901130 22392998065984 run_lib.py:146] step: 240750, training_loss: 5.17811e-02
I0515 03:33:13.196505 22392998065984 run_lib.py:146] step: 240800, training_loss: 5.65411e-02
I0515 03:33:13.354176 22392998065984 run_lib.py:167] step: 240800, eval_loss: 7.28272e-02
I0515 03:33:36.643874 22392998065984 run_lib.py:146] step: 240850, training_loss: 5.38746e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:34:01.002216 22392998065984 run_lib.py:146] step: 240900, training_loss: 5.85125e-02
I0515 03:34:01.160182 22392998065984 run_lib.py:167] step: 240900, eval_loss: 6.30080e-02
I0515 03:34:24.442588 22392998065984 run_lib.py:146] step: 240950, training_loss: 4.68265e-02
I0515 03:34:47.723988 22392998065984 run_lib.py:146] step: 241000, training_loss: 6.70664e-02
I0515 03:34:47.880762 22392998065984 run_lib.py:167] step: 241000, eval_loss: 5.93815e-02
I0515 03:35:11.766016 22392998065984 run_lib.py:146] step: 241050, training_loss: 6.51753e-02
I0515 03:35:35.050895 22392998065984 run_lib.py:146] step: 241100, training_loss: 7.13093e-02
I0515 03:35:35.207787 22392998065984 run_lib.py:167] step: 241100, eval_loss: 6.94175e-02
I0515 03:35:58.482887 22392998065984 run_lib.py:146] step: 241150, training_loss: 6.55124e-02
I0515 03:36:22.356986 22392998065984 run_lib.py:146] step: 241200, training_loss: 5.96497e-02
I0515 03:36:22.513637 22392998065984 run_lib.py:167] step: 241200, eval_loss: 6.39166e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:36:46.305378 22392998065984 run_lib.py:146] step: 241250, training_loss: 5.93741e-02
I0515 03:37:10.203768 22392998065984 run_lib.py:146] step: 241300, training_loss: 3.95464e-02
I0515 03:37:10.362021 22392998065984 run_lib.py:167] step: 241300, eval_loss: 6.23993e-02
I0515 03:37:34.920749 22392998065984 run_lib.py:146] step: 241350, training_loss: 4.84187e-02
I0515 03:37:58.647543 22392998065984 run_lib.py:146] step: 241400, training_loss: 4.99540e-02
I0515 03:37:58.803789 22392998065984 run_lib.py:167] step: 241400, eval_loss: 5.27172e-02
I0515 03:38:22.087602 22392998065984 run_lib.py:146] step: 241450, training_loss: 6.34871e-02
I0515 03:38:45.684661 22392998065984 run_lib.py:146] step: 241500, training_loss: 5.69506e-02
I0515 03:38:45.841219 22392998065984 run_lib.py:167] step: 241500, eval_loss: 6.03468e-02
I0515 03:39:09.409041 22392998065984 run_lib.py:146] step: 241550, training_loss: 5.81567e-02
I0515 03:39:32.695162 22392998065984 run_lib.py:146] step: 241600, training_loss: 4.86011e-02
I0515 03:39:32.851699 22392998065984 run_lib.py:167] step: 241600, eval_loss: 4.89343e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:39:56.439243 22392998065984 run_lib.py:146] step: 241650, training_loss: 6.83726e-02
I0515 03:40:21.020028 22392998065984 run_lib.py:146] step: 241700, training_loss: 5.24619e-02
I0515 03:40:21.177544 22392998065984 run_lib.py:167] step: 241700, eval_loss: 6.14329e-02
I0515 03:40:44.489536 22392998065984 run_lib.py:146] step: 241750, training_loss: 4.76995e-02
I0515 03:41:07.797371 22392998065984 run_lib.py:146] step: 241800, training_loss: 7.27474e-02
I0515 03:41:07.954509 22392998065984 run_lib.py:167] step: 241800, eval_loss: 5.19437e-02
I0515 03:41:31.884012 22392998065984 run_lib.py:146] step: 241850, training_loss: 5.19112e-02
I0515 03:41:55.184353 22392998065984 run_lib.py:146] step: 241900, training_loss: 5.44548e-02
I0515 03:41:55.341550 22392998065984 run_lib.py:167] step: 241900, eval_loss: 5.03559e-02
I0515 03:42:18.624874 22392998065984 run_lib.py:146] step: 241950, training_loss: 5.83480e-02
I0515 03:42:42.530452 22392998065984 run_lib.py:146] step: 242000, training_loss: 5.24745e-02
I0515 03:42:42.687201 22392998065984 run_lib.py:167] step: 242000, eval_loss: 6.05676e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:43:06.124381 22392998065984 run_lib.py:146] step: 242050, training_loss: 4.73586e-02
I0515 03:43:29.425024 22392998065984 run_lib.py:146] step: 242100, training_loss: 5.75039e-02
I0515 03:43:29.583155 22392998065984 run_lib.py:167] step: 242100, eval_loss: 6.79395e-02
I0515 03:43:53.840750 22392998065984 run_lib.py:146] step: 242150, training_loss: 5.63981e-02
I0515 03:44:17.196802 22392998065984 run_lib.py:146] step: 242200, training_loss: 4.76836e-02
I0515 03:44:17.354581 22392998065984 run_lib.py:167] step: 242200, eval_loss: 7.90920e-02
I0515 03:44:40.733918 22392998065984 run_lib.py:146] step: 242250, training_loss: 8.11301e-02
I0515 03:45:04.406087 22392998065984 run_lib.py:146] step: 242300, training_loss: 4.77004e-02
I0515 03:45:04.563541 22392998065984 run_lib.py:167] step: 242300, eval_loss: 7.44107e-02
I0515 03:45:28.300569 22392998065984 run_lib.py:146] step: 242350, training_loss: 6.36233e-02
I0515 03:45:51.651102 22392998065984 run_lib.py:146] step: 242400, training_loss: 7.69136e-02
I0515 03:45:51.808932 22392998065984 run_lib.py:167] step: 242400, eval_loss: 6.99177e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:46:15.281882 22392998065984 run_lib.py:146] step: 242450, training_loss: 4.88955e-02
I0515 03:46:39.297827 22392998065984 run_lib.py:146] step: 242500, training_loss: 5.32742e-02
I0515 03:46:39.456418 22392998065984 run_lib.py:167] step: 242500, eval_loss: 5.48133e-02
I0515 03:47:02.799433 22392998065984 run_lib.py:146] step: 242550, training_loss: 5.66848e-02
I0515 03:47:26.141721 22392998065984 run_lib.py:146] step: 242600, training_loss: 5.33330e-02
I0515 03:47:26.299879 22392998065984 run_lib.py:167] step: 242600, eval_loss: 6.11982e-02
I0515 03:47:50.221428 22392998065984 run_lib.py:146] step: 242650, training_loss: 6.10680e-02
I0515 03:48:13.592026 22392998065984 run_lib.py:146] step: 242700, training_loss: 8.57915e-02
I0515 03:48:13.750075 22392998065984 run_lib.py:167] step: 242700, eval_loss: 5.53267e-02
I0515 03:48:37.114773 22392998065984 run_lib.py:146] step: 242750, training_loss: 5.22464e-02
I0515 03:49:01.053259 22392998065984 run_lib.py:146] step: 242800, training_loss: 5.17884e-02
I0515 03:49:01.210788 22392998065984 run_lib.py:167] step: 242800, eval_loss: 6.26521e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:49:24.662314 22392998065984 run_lib.py:146] step: 242850, training_loss: 5.45742e-02
I0515 03:49:47.994975 22392998065984 run_lib.py:146] step: 242900, training_loss: 6.53557e-02
I0515 03:49:48.153506 22392998065984 run_lib.py:167] step: 242900, eval_loss: 6.02099e-02
I0515 03:50:12.160311 22392998065984 run_lib.py:146] step: 242950, training_loss: 5.60747e-02
I0515 03:50:35.523773 22392998065984 run_lib.py:146] step: 243000, training_loss: 5.76601e-02
I0515 03:50:35.681346 22392998065984 run_lib.py:167] step: 243000, eval_loss: 4.84326e-02
I0515 03:50:59.048017 22392998065984 run_lib.py:146] step: 243050, training_loss: 6.58671e-02
I0515 03:51:22.699002 22392998065984 run_lib.py:146] step: 243100, training_loss: 4.92162e-02
I0515 03:51:22.856600 22392998065984 run_lib.py:167] step: 243100, eval_loss: 5.43769e-02
I0515 03:51:46.486756 22392998065984 run_lib.py:146] step: 243150, training_loss: 6.85049e-02
I0515 03:52:09.837265 22392998065984 run_lib.py:146] step: 243200, training_loss: 5.50636e-02
I0515 03:52:09.994334 22392998065984 run_lib.py:167] step: 243200, eval_loss: 6.37670e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:52:33.458855 22392998065984 run_lib.py:146] step: 243250, training_loss: 5.28081e-02
I0515 03:52:57.483141 22392998065984 run_lib.py:146] step: 243300, training_loss: 8.54198e-02
I0515 03:52:57.641628 22392998065984 run_lib.py:167] step: 243300, eval_loss: 5.16157e-02
I0515 03:53:21.000875 22392998065984 run_lib.py:146] step: 243350, training_loss: 6.07617e-02
I0515 03:53:44.368411 22392998065984 run_lib.py:146] step: 243400, training_loss: 5.34274e-02
I0515 03:53:44.526391 22392998065984 run_lib.py:167] step: 243400, eval_loss: 6.81468e-02
I0515 03:54:08.460114 22392998065984 run_lib.py:146] step: 243450, training_loss: 5.23490e-02
I0515 03:54:31.824065 22392998065984 run_lib.py:146] step: 243500, training_loss: 5.60974e-02
I0515 03:54:31.982153 22392998065984 run_lib.py:167] step: 243500, eval_loss: 5.51333e-02
I0515 03:54:55.338015 22392998065984 run_lib.py:146] step: 243550, training_loss: 3.87174e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:55:19.373127 22392998065984 run_lib.py:146] step: 243600, training_loss: 6.82346e-02
I0515 03:55:19.532591 22392998065984 run_lib.py:167] step: 243600, eval_loss: 7.12908e-02
I0515 03:55:42.888117 22392998065984 run_lib.py:146] step: 243650, training_loss: 4.89536e-02
I0515 03:56:06.240950 22392998065984 run_lib.py:146] step: 243700, training_loss: 5.65303e-02
I0515 03:56:06.398416 22392998065984 run_lib.py:167] step: 243700, eval_loss: 6.30583e-02
I0515 03:56:30.382905 22392998065984 run_lib.py:146] step: 243750, training_loss: 6.01680e-02
I0515 03:56:53.732872 22392998065984 run_lib.py:146] step: 243800, training_loss: 6.08419e-02
I0515 03:56:53.890277 22392998065984 run_lib.py:167] step: 243800, eval_loss: 4.97680e-02
I0515 03:57:17.237144 22392998065984 run_lib.py:146] step: 243850, training_loss: 6.02485e-02
I0515 03:57:40.905650 22392998065984 run_lib.py:146] step: 243900, training_loss: 6.16579e-02
I0515 03:57:41.063446 22392998065984 run_lib.py:167] step: 243900, eval_loss: 6.53886e-02
I0515 03:58:04.706914 22392998065984 run_lib.py:146] step: 243950, training_loss: 5.48739e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 03:58:28.163279 22392998065984 run_lib.py:146] step: 244000, training_loss: 5.81165e-02
I0515 03:58:28.330772 22392998065984 run_lib.py:167] step: 244000, eval_loss: 5.67291e-02
I0515 03:58:51.694472 22392998065984 run_lib.py:146] step: 244050, training_loss: 5.45458e-02
I0515 03:59:15.703606 22392998065984 run_lib.py:146] step: 244100, training_loss: 6.43361e-02
I0515 03:59:15.861307 22392998065984 run_lib.py:167] step: 244100, eval_loss: 7.48945e-02
I0515 03:59:39.234116 22392998065984 run_lib.py:146] step: 244150, training_loss: 6.30890e-02
I0515 04:00:02.607840 22392998065984 run_lib.py:146] step: 244200, training_loss: 5.68222e-02
I0515 04:00:02.765380 22392998065984 run_lib.py:167] step: 244200, eval_loss: 5.82811e-02
I0515 04:00:26.675520 22392998065984 run_lib.py:146] step: 244250, training_loss: 5.37514e-02
I0515 04:00:50.046944 22392998065984 run_lib.py:146] step: 244300, training_loss: 7.10601e-02
I0515 04:00:50.204772 22392998065984 run_lib.py:167] step: 244300, eval_loss: 5.12123e-02
I0515 04:01:13.563951 22392998065984 run_lib.py:146] step: 244350, training_loss: 5.82746e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:01:37.631624 22392998065984 run_lib.py:146] step: 244400, training_loss: 5.52370e-02
I0515 04:01:37.791651 22392998065984 run_lib.py:167] step: 244400, eval_loss: 4.79608e-02
I0515 04:02:01.131971 22392998065984 run_lib.py:146] step: 244450, training_loss: 6.60765e-02
I0515 04:02:24.481660 22392998065984 run_lib.py:146] step: 244500, training_loss: 5.95488e-02
I0515 04:02:24.639542 22392998065984 run_lib.py:167] step: 244500, eval_loss: 7.07712e-02
I0515 04:02:48.577001 22392998065984 run_lib.py:146] step: 244550, training_loss: 4.86573e-02
I0515 04:03:11.933509 22392998065984 run_lib.py:146] step: 244600, training_loss: 7.83531e-02
I0515 04:03:12.091150 22392998065984 run_lib.py:167] step: 244600, eval_loss: 5.10499e-02
I0515 04:03:35.449850 22392998065984 run_lib.py:146] step: 244650, training_loss: 5.86011e-02
I0515 04:03:59.358918 22392998065984 run_lib.py:146] step: 244700, training_loss: 5.45612e-02
I0515 04:03:59.515093 22392998065984 run_lib.py:167] step: 244700, eval_loss: 5.74852e-02
I0515 04:04:22.858286 22392998065984 run_lib.py:146] step: 244750, training_loss: 5.51875e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:04:46.322077 22392998065984 run_lib.py:146] step: 244800, training_loss: 7.77831e-02
I0515 04:04:46.405407 22392998065984 run_lib.py:167] step: 244800, eval_loss: 6.69218e-02
I0515 04:05:09.753557 22392998065984 run_lib.py:146] step: 244850, training_loss: 5.12681e-02
I0515 04:05:33.782457 22392998065984 run_lib.py:146] step: 244900, training_loss: 5.07565e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:05:34.196404 22392998065984 run_lib.py:167] step: 244900, eval_loss: 5.45938e-02
I0515 04:05:57.560871 22392998065984 run_lib.py:146] step: 244950, training_loss: 8.00744e-02
I0515 04:06:20.922510 22392998065984 run_lib.py:146] step: 245000, training_loss: 5.84271e-02
I0515 04:06:21.080206 22392998065984 run_lib.py:167] step: 245000, eval_loss: 5.45946e-02
I0515 04:06:45.083770 22392998065984 run_lib.py:146] step: 245050, training_loss: 6.00405e-02
I0515 04:07:08.448871 22392998065984 run_lib.py:146] step: 245100, training_loss: 5.95557e-02
I0515 04:07:08.606580 22392998065984 run_lib.py:167] step: 245100, eval_loss: 6.70073e-02
I0515 04:07:31.967496 22392998065984 run_lib.py:146] step: 245150, training_loss: 6.55034e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:07:56.154156 22392998065984 run_lib.py:146] step: 245200, training_loss: 5.69526e-02
I0515 04:07:56.312739 22392998065984 run_lib.py:167] step: 245200, eval_loss: 5.70373e-02
I0515 04:08:19.672532 22392998065984 run_lib.py:146] step: 245250, training_loss: 5.70529e-02
I0515 04:08:43.031720 22392998065984 run_lib.py:146] step: 245300, training_loss: 6.77137e-02
I0515 04:08:43.188909 22392998065984 run_lib.py:167] step: 245300, eval_loss: 6.61040e-02
I0515 04:09:07.113266 22392998065984 run_lib.py:146] step: 245350, training_loss: 5.25616e-02
I0515 04:09:30.460347 22392998065984 run_lib.py:146] step: 245400, training_loss: 6.29691e-02
I0515 04:09:30.618215 22392998065984 run_lib.py:167] step: 245400, eval_loss: 5.72451e-02
I0515 04:09:53.970687 22392998065984 run_lib.py:146] step: 245450, training_loss: 6.14351e-02
I0515 04:10:17.910306 22392998065984 run_lib.py:146] step: 245500, training_loss: 4.47104e-02
I0515 04:10:18.067415 22392998065984 run_lib.py:167] step: 245500, eval_loss: 7.44130e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:10:41.513793 22392998065984 run_lib.py:146] step: 245550, training_loss: 4.01316e-02
I0515 04:11:04.877288 22392998065984 run_lib.py:146] step: 245600, training_loss: 6.03441e-02
I0515 04:11:05.036055 22392998065984 run_lib.py:167] step: 245600, eval_loss: 5.44309e-02
I0515 04:11:28.717467 22392998065984 run_lib.py:146] step: 245650, training_loss: 5.31189e-02
I0515 04:11:52.359172 22392998065984 run_lib.py:146] step: 245700, training_loss: 5.12883e-02
I0515 04:11:52.516310 22392998065984 run_lib.py:167] step: 245700, eval_loss: 7.37500e-02
I0515 04:12:15.852951 22392998065984 run_lib.py:146] step: 245750, training_loss: 3.82152e-02
I0515 04:12:39.194344 22392998065984 run_lib.py:146] step: 245800, training_loss: 5.48544e-02
I0515 04:12:39.369128 22392998065984 run_lib.py:167] step: 245800, eval_loss: 5.13701e-02
I0515 04:13:03.303664 22392998065984 run_lib.py:146] step: 245850, training_loss: 6.03014e-02
I0515 04:13:26.685466 22392998065984 run_lib.py:146] step: 245900, training_loss: 6.52351e-02
I0515 04:13:26.843318 22392998065984 run_lib.py:167] step: 245900, eval_loss: 6.31503e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:13:50.318829 22392998065984 run_lib.py:146] step: 245950, training_loss: 4.42675e-02
I0515 04:14:14.365461 22392998065984 run_lib.py:146] step: 246000, training_loss: 5.20363e-02
I0515 04:14:14.524651 22392998065984 run_lib.py:167] step: 246000, eval_loss: 5.30656e-02
I0515 04:14:37.867464 22392998065984 run_lib.py:146] step: 246050, training_loss: 4.43956e-02
I0515 04:15:01.205827 22392998065984 run_lib.py:146] step: 246100, training_loss: 6.18658e-02
I0515 04:15:01.362729 22392998065984 run_lib.py:167] step: 246100, eval_loss: 7.21624e-02
I0515 04:15:25.277675 22392998065984 run_lib.py:146] step: 246150, training_loss: 5.72179e-02
I0515 04:15:48.629838 22392998065984 run_lib.py:146] step: 246200, training_loss: 7.41300e-02
I0515 04:15:48.787017 22392998065984 run_lib.py:167] step: 246200, eval_loss: 4.98157e-02
I0515 04:16:12.143855 22392998065984 run_lib.py:146] step: 246250, training_loss: 6.08877e-02
I0515 04:16:36.067013 22392998065984 run_lib.py:146] step: 246300, training_loss: 5.32739e-02
I0515 04:16:36.224666 22392998065984 run_lib.py:167] step: 246300, eval_loss: 6.90362e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:16:59.697916 22392998065984 run_lib.py:146] step: 246350, training_loss: 6.73151e-02
I0515 04:17:23.060155 22392998065984 run_lib.py:146] step: 246400, training_loss: 5.70395e-02
I0515 04:17:23.219433 22392998065984 run_lib.py:167] step: 246400, eval_loss: 6.64029e-02
I0515 04:17:47.763213 22392998065984 run_lib.py:146] step: 246450, training_loss: 5.32522e-02
I0515 04:18:11.691832 22392998065984 run_lib.py:146] step: 246500, training_loss: 6.29800e-02
I0515 04:18:11.848765 22392998065984 run_lib.py:167] step: 246500, eval_loss: 5.24321e-02
I0515 04:18:35.522323 22392998065984 run_lib.py:146] step: 246550, training_loss: 5.40519e-02
I0515 04:18:58.857107 22392998065984 run_lib.py:146] step: 246600, training_loss: 6.10486e-02
I0515 04:18:59.014523 22392998065984 run_lib.py:167] step: 246600, eval_loss: 7.94650e-02
I0515 04:19:23.081674 22392998065984 run_lib.py:146] step: 246650, training_loss: 6.29437e-02
I0515 04:19:46.424743 22392998065984 run_lib.py:146] step: 246700, training_loss: 4.03458e-02
I0515 04:19:46.581936 22392998065984 run_lib.py:167] step: 246700, eval_loss: 6.59571e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:20:10.043110 22392998065984 run_lib.py:146] step: 246750, training_loss: 5.94585e-02
I0515 04:20:34.076489 22392998065984 run_lib.py:146] step: 246800, training_loss: 5.49874e-02
I0515 04:20:34.235272 22392998065984 run_lib.py:167] step: 246800, eval_loss: 6.80895e-02
I0515 04:20:57.582871 22392998065984 run_lib.py:146] step: 246850, training_loss: 6.15115e-02
I0515 04:21:20.923433 22392998065984 run_lib.py:146] step: 246900, training_loss: 6.42553e-02
I0515 04:21:21.080549 22392998065984 run_lib.py:167] step: 246900, eval_loss: 5.39618e-02
I0515 04:21:44.969134 22392998065984 run_lib.py:146] step: 246950, training_loss: 7.37116e-02
I0515 04:22:08.306278 22392998065984 run_lib.py:146] step: 247000, training_loss: 5.62508e-02
I0515 04:22:08.463373 22392998065984 run_lib.py:167] step: 247000, eval_loss: 7.01968e-02
I0515 04:22:31.800076 22392998065984 run_lib.py:146] step: 247050, training_loss: 5.29753e-02
I0515 04:22:55.711902 22392998065984 run_lib.py:146] step: 247100, training_loss: 4.07181e-02
I0515 04:22:55.869044 22392998065984 run_lib.py:167] step: 247100, eval_loss: 7.45435e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:23:19.316195 22392998065984 run_lib.py:146] step: 247150, training_loss: 5.27538e-02
I0515 04:23:42.662045 22392998065984 run_lib.py:146] step: 247200, training_loss: 5.70357e-02
I0515 04:23:42.820758 22392998065984 run_lib.py:167] step: 247200, eval_loss: 5.63577e-02
I0515 04:24:06.804208 22392998065984 run_lib.py:146] step: 247250, training_loss: 7.22101e-02
I0515 04:24:30.150617 22392998065984 run_lib.py:146] step: 247300, training_loss: 5.25332e-02
I0515 04:24:30.307783 22392998065984 run_lib.py:167] step: 247300, eval_loss: 5.52870e-02
I0515 04:24:53.664358 22392998065984 run_lib.py:146] step: 247350, training_loss: 5.25243e-02
I0515 04:25:17.020485 22392998065984 run_lib.py:146] step: 247400, training_loss: 5.96638e-02
I0515 04:25:17.177641 22392998065984 run_lib.py:167] step: 247400, eval_loss: 6.76524e-02
I0515 04:25:41.092254 22392998065984 run_lib.py:146] step: 247450, training_loss: 5.91274e-02
I0515 04:26:04.436174 22392998065984 run_lib.py:146] step: 247500, training_loss: 6.68724e-02
I0515 04:26:04.593582 22392998065984 run_lib.py:167] step: 247500, eval_loss: 5.30659e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:26:28.088855 22392998065984 run_lib.py:146] step: 247550, training_loss: 5.38561e-02
I0515 04:26:52.135280 22392998065984 run_lib.py:146] step: 247600, training_loss: 6.24869e-02
I0515 04:26:52.294019 22392998065984 run_lib.py:167] step: 247600, eval_loss: 5.94337e-02
I0515 04:27:15.656338 22392998065984 run_lib.py:146] step: 247650, training_loss: 5.43823e-02
I0515 04:27:39.059557 22392998065984 run_lib.py:146] step: 247700, training_loss: 4.85497e-02
I0515 04:27:39.217222 22392998065984 run_lib.py:167] step: 247700, eval_loss: 6.68736e-02
I0515 04:28:03.662173 22392998065984 run_lib.py:146] step: 247750, training_loss: 5.99925e-02
I0515 04:28:27.080119 22392998065984 run_lib.py:146] step: 247800, training_loss: 5.32785e-02
I0515 04:28:27.239203 22392998065984 run_lib.py:167] step: 247800, eval_loss: 4.40552e-02
I0515 04:28:50.642861 22392998065984 run_lib.py:146] step: 247850, training_loss: 6.49876e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:29:14.926260 22392998065984 run_lib.py:146] step: 247900, training_loss: 5.31937e-02
I0515 04:29:15.085384 22392998065984 run_lib.py:167] step: 247900, eval_loss: 5.21220e-02
I0515 04:29:38.547744 22392998065984 run_lib.py:146] step: 247950, training_loss: 5.53879e-02
I0515 04:30:02.008122 22392998065984 run_lib.py:146] step: 248000, training_loss: 5.15888e-02
I0515 04:30:02.166355 22392998065984 run_lib.py:167] step: 248000, eval_loss: 6.06574e-02
I0515 04:30:25.978992 22392998065984 run_lib.py:146] step: 248050, training_loss: 5.56897e-02
I0515 04:30:50.046725 22392998065984 run_lib.py:146] step: 248100, training_loss: 4.76876e-02
I0515 04:30:50.206212 22392998065984 run_lib.py:167] step: 248100, eval_loss: 5.56847e-02
I0515 04:31:13.684847 22392998065984 run_lib.py:146] step: 248150, training_loss: 4.76653e-02
I0515 04:31:37.219539 22392998065984 run_lib.py:146] step: 248200, training_loss: 7.12216e-02
I0515 04:31:37.378444 22392998065984 run_lib.py:167] step: 248200, eval_loss: 7.43879e-02
I0515 04:32:01.717391 22392998065984 run_lib.py:146] step: 248250, training_loss: 4.62228e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:32:25.638539 22392998065984 run_lib.py:146] step: 248300, training_loss: 5.13089e-02
I0515 04:32:25.800711 22392998065984 run_lib.py:167] step: 248300, eval_loss: 6.89663e-02
I0515 04:32:49.308437 22392998065984 run_lib.py:146] step: 248350, training_loss: 5.14705e-02
I0515 04:33:13.535511 22392998065984 run_lib.py:146] step: 248400, training_loss: 6.64786e-02
I0515 04:33:13.694428 22392998065984 run_lib.py:167] step: 248400, eval_loss: 6.89543e-02
I0515 04:33:37.533866 22392998065984 run_lib.py:146] step: 248450, training_loss: 5.71411e-02
I0515 04:34:01.251008 22392998065984 run_lib.py:146] step: 248500, training_loss: 5.39301e-02
I0515 04:34:01.411514 22392998065984 run_lib.py:167] step: 248500, eval_loss: 5.14217e-02
I0515 04:34:25.523130 22392998065984 run_lib.py:146] step: 248550, training_loss: 6.39081e-02
I0515 04:34:49.163476 22392998065984 run_lib.py:146] step: 248600, training_loss: 6.90447e-02
I0515 04:34:49.321706 22392998065984 run_lib.py:167] step: 248600, eval_loss: 7.19173e-02
I0515 04:35:12.839060 22392998065984 run_lib.py:146] step: 248650, training_loss: 4.48542e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:35:37.131078 22392998065984 run_lib.py:146] step: 248700, training_loss: 5.34280e-02
I0515 04:35:37.288899 22392998065984 run_lib.py:167] step: 248700, eval_loss: 6.25628e-02
I0515 04:36:00.685103 22392998065984 run_lib.py:146] step: 248750, training_loss: 5.37275e-02
I0515 04:36:24.107521 22392998065984 run_lib.py:146] step: 248800, training_loss: 5.54083e-02
I0515 04:36:24.267058 22392998065984 run_lib.py:167] step: 248800, eval_loss: 6.75925e-02
I0515 04:36:48.036885 22392998065984 run_lib.py:146] step: 248850, training_loss: 5.85720e-02
I0515 04:37:11.786568 22392998065984 run_lib.py:146] step: 248900, training_loss: 5.21841e-02
I0515 04:37:11.943706 22392998065984 run_lib.py:167] step: 248900, eval_loss: 7.64222e-02
I0515 04:37:35.375394 22392998065984 run_lib.py:146] step: 248950, training_loss: 6.80159e-02
I0515 04:37:59.094308 22392998065984 run_lib.py:146] step: 249000, training_loss: 5.51949e-02
I0515 04:37:59.251756 22392998065984 run_lib.py:167] step: 249000, eval_loss: 5.73639e-02
I0515 04:38:23.068794 22392998065984 run_lib.py:146] step: 249050, training_loss: 5.61037e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:38:46.953273 22392998065984 run_lib.py:146] step: 249100, training_loss: 4.65049e-02
I0515 04:38:47.113847 22392998065984 run_lib.py:167] step: 249100, eval_loss: 7.64486e-02
I0515 04:39:10.578602 22392998065984 run_lib.py:146] step: 249150, training_loss: 7.19509e-02
I0515 04:39:34.717029 22392998065984 run_lib.py:146] step: 249200, training_loss: 6.87518e-02
I0515 04:39:34.874405 22392998065984 run_lib.py:167] step: 249200, eval_loss: 4.49813e-02
I0515 04:39:58.290067 22392998065984 run_lib.py:146] step: 249250, training_loss: 5.67385e-02
I0515 04:40:21.740867 22392998065984 run_lib.py:146] step: 249300, training_loss: 4.46032e-02
I0515 04:40:21.898190 22392998065984 run_lib.py:167] step: 249300, eval_loss: 6.24022e-02
I0515 04:40:45.920725 22392998065984 run_lib.py:146] step: 249350, training_loss: 6.59246e-02
I0515 04:41:09.390003 22392998065984 run_lib.py:146] step: 249400, training_loss: 5.12382e-02
I0515 04:41:09.547052 22392998065984 run_lib.py:167] step: 249400, eval_loss: 6.06670e-02
I0515 04:41:33.003137 22392998065984 run_lib.py:146] step: 249450, training_loss: 5.09103e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:41:57.306782 22392998065984 run_lib.py:146] step: 249500, training_loss: 8.17283e-02
I0515 04:41:57.467489 22392998065984 run_lib.py:167] step: 249500, eval_loss: 6.37430e-02
I0515 04:42:20.913107 22392998065984 run_lib.py:146] step: 249550, training_loss: 9.18913e-02
I0515 04:42:44.343196 22392998065984 run_lib.py:146] step: 249600, training_loss: 6.23878e-02
I0515 04:42:44.503041 22392998065984 run_lib.py:167] step: 249600, eval_loss: 7.25268e-02
I0515 04:43:08.894560 22392998065984 run_lib.py:146] step: 249650, training_loss: 5.87179e-02
I0515 04:43:32.754011 22392998065984 run_lib.py:146] step: 249700, training_loss: 5.28175e-02
I0515 04:43:32.911452 22392998065984 run_lib.py:167] step: 249700, eval_loss: 4.57345e-02
I0515 04:43:56.795898 22392998065984 run_lib.py:146] step: 249750, training_loss: 5.89235e-02
I0515 04:44:20.636370 22392998065984 run_lib.py:146] step: 249800, training_loss: 5.95519e-02
I0515 04:44:20.795580 22392998065984 run_lib.py:167] step: 249800, eval_loss: 4.83590e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:44:44.684507 22392998065984 run_lib.py:146] step: 249850, training_loss: 4.91332e-02
I0515 04:45:08.553308 22392998065984 run_lib.py:146] step: 249900, training_loss: 4.67449e-02
I0515 04:45:08.714745 22392998065984 run_lib.py:167] step: 249900, eval_loss: 5.95882e-02
I0515 04:45:32.173932 22392998065984 run_lib.py:146] step: 249950, training_loss: 4.53314e-02
I0515 04:45:56.307621 22392998065984 run_lib.py:146] step: 250000, training_loss: 6.20133e-02
I0515 04:45:58.075849 22392998065984 run_lib.py:167] step: 250000, eval_loss: 6.50936e-02
I0515 04:46:23.035991 22392998065984 run_lib.py:146] step: 250050, training_loss: 6.09879e-02
I0515 04:46:46.803664 22392998065984 run_lib.py:146] step: 250100, training_loss: 5.65325e-02
I0515 04:46:46.961710 22392998065984 run_lib.py:167] step: 250100, eval_loss: 6.84291e-02
I0515 04:47:10.706431 22392998065984 run_lib.py:146] step: 250150, training_loss: 7.14666e-02
I0515 04:47:34.217137 22392998065984 run_lib.py:146] step: 250200, training_loss: 6.00359e-02
I0515 04:47:34.374500 22392998065984 run_lib.py:167] step: 250200, eval_loss: 8.08045e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:47:58.329133 22392998065984 run_lib.py:146] step: 250250, training_loss: 4.59344e-02
I0515 04:48:22.137963 22392998065984 run_lib.py:146] step: 250300, training_loss: 7.85009e-02
I0515 04:48:22.296694 22392998065984 run_lib.py:167] step: 250300, eval_loss: 5.37407e-02
I0515 04:48:45.923982 22392998065984 run_lib.py:146] step: 250350, training_loss: 6.93045e-02
I0515 04:49:09.842844 22392998065984 run_lib.py:146] step: 250400, training_loss: 5.57600e-02
I0515 04:49:10.000214 22392998065984 run_lib.py:167] step: 250400, eval_loss: 6.04275e-02
I0515 04:49:33.875936 22392998065984 run_lib.py:146] step: 250450, training_loss: 4.43857e-02
I0515 04:49:57.340783 22392998065984 run_lib.py:146] step: 250500, training_loss: 5.17199e-02
I0515 04:49:57.498023 22392998065984 run_lib.py:167] step: 250500, eval_loss: 5.19696e-02
I0515 04:50:21.380112 22392998065984 run_lib.py:146] step: 250550, training_loss: 5.44332e-02
I0515 04:50:45.054095 22392998065984 run_lib.py:146] step: 250600, training_loss: 6.04915e-02
I0515 04:50:45.215864 22392998065984 run_lib.py:167] step: 250600, eval_loss: 6.99617e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:51:09.331895 22392998065984 run_lib.py:146] step: 250650, training_loss: 6.57711e-02
I0515 04:51:33.202870 22392998065984 run_lib.py:146] step: 250700, training_loss: 5.69299e-02
I0515 04:51:33.365656 22392998065984 run_lib.py:167] step: 250700, eval_loss: 7.01900e-02
I0515 04:51:57.743509 22392998065984 run_lib.py:146] step: 250750, training_loss: 7.16470e-02
I0515 04:52:22.039653 22392998065984 run_lib.py:146] step: 250800, training_loss: 4.91925e-02
I0515 04:52:22.199485 22392998065984 run_lib.py:167] step: 250800, eval_loss: 6.29275e-02
I0515 04:52:46.118342 22392998065984 run_lib.py:146] step: 250850, training_loss: 4.67021e-02
I0515 04:53:10.368068 22392998065984 run_lib.py:146] step: 250900, training_loss: 7.05276e-02
I0515 04:53:10.531821 22392998065984 run_lib.py:167] step: 250900, eval_loss: 4.69008e-02
I0515 04:53:34.761381 22392998065984 run_lib.py:146] step: 250950, training_loss: 5.78946e-02
I0515 04:53:58.700347 22392998065984 run_lib.py:146] step: 251000, training_loss: 6.15917e-02
I0515 04:53:58.859023 22392998065984 run_lib.py:167] step: 251000, eval_loss: 6.06496e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:54:23.288158 22392998065984 run_lib.py:146] step: 251050, training_loss: 7.81276e-02
I0515 04:54:47.718191 22392998065984 run_lib.py:146] step: 251100, training_loss: 6.94848e-02
I0515 04:54:47.884484 22392998065984 run_lib.py:167] step: 251100, eval_loss: 6.07905e-02
I0515 04:55:11.847745 22392998065984 run_lib.py:146] step: 251150, training_loss: 9.07260e-02
I0515 04:55:36.191260 22392998065984 run_lib.py:146] step: 251200, training_loss: 6.58092e-02
I0515 04:55:36.354727 22392998065984 run_lib.py:167] step: 251200, eval_loss: 7.28618e-02
I0515 04:56:00.543107 22392998065984 run_lib.py:146] step: 251250, training_loss: 8.25461e-02
I0515 04:56:24.416169 22392998065984 run_lib.py:146] step: 251300, training_loss: 7.59122e-02
I0515 04:56:24.574971 22392998065984 run_lib.py:167] step: 251300, eval_loss: 6.35944e-02
I0515 04:56:48.456382 22392998065984 run_lib.py:146] step: 251350, training_loss: 7.34327e-02
I0515 04:57:12.637611 22392998065984 run_lib.py:146] step: 251400, training_loss: 4.02153e-02
I0515 04:57:12.800721 22392998065984 run_lib.py:167] step: 251400, eval_loss: 5.53258e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 04:57:37.133592 22392998065984 run_lib.py:146] step: 251450, training_loss: 4.28110e-02
I0515 04:58:01.051319 22392998065984 run_lib.py:146] step: 251500, training_loss: 5.60512e-02
I0515 04:58:01.211315 22392998065984 run_lib.py:167] step: 251500, eval_loss: 5.26235e-02
I0515 04:58:25.482455 22392998065984 run_lib.py:146] step: 251550, training_loss: 5.03195e-02
I0515 04:58:49.690804 22392998065984 run_lib.py:146] step: 251600, training_loss: 4.09107e-02
I0515 04:58:49.849968 22392998065984 run_lib.py:167] step: 251600, eval_loss: 7.08514e-02
I0515 04:59:13.767627 22392998065984 run_lib.py:146] step: 251650, training_loss: 6.14725e-02
I0515 04:59:37.978451 22392998065984 run_lib.py:146] step: 251700, training_loss: 5.03450e-02
I0515 04:59:38.141079 22392998065984 run_lib.py:167] step: 251700, eval_loss: 6.09083e-02
I0515 05:00:02.344303 22392998065984 run_lib.py:146] step: 251750, training_loss: 6.22313e-02
I0515 05:00:26.267111 22392998065984 run_lib.py:146] step: 251800, training_loss: 5.11170e-02
I0515 05:00:26.431235 22392998065984 run_lib.py:167] step: 251800, eval_loss: 4.60060e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:00:50.908846 22392998065984 run_lib.py:146] step: 251850, training_loss: 5.40674e-02
I0515 05:01:15.206647 22392998065984 run_lib.py:146] step: 251900, training_loss: 5.75764e-02
I0515 05:01:15.375519 22392998065984 run_lib.py:167] step: 251900, eval_loss: 6.06818e-02
I0515 05:01:39.351561 22392998065984 run_lib.py:146] step: 251950, training_loss: 4.85099e-02
I0515 05:02:03.584887 22392998065984 run_lib.py:146] step: 252000, training_loss: 6.90134e-02
I0515 05:02:03.743613 22392998065984 run_lib.py:167] step: 252000, eval_loss: 6.72193e-02
I0515 05:02:27.979424 22392998065984 run_lib.py:146] step: 252050, training_loss: 4.72354e-02
I0515 05:02:51.949862 22392998065984 run_lib.py:146] step: 252100, training_loss: 6.37726e-02
I0515 05:02:52.131059 22392998065984 run_lib.py:167] step: 252100, eval_loss: 5.08235e-02
I0515 05:03:16.374300 22392998065984 run_lib.py:146] step: 252150, training_loss: 5.62263e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:03:40.891498 22392998065984 run_lib.py:146] step: 252200, training_loss: 5.07053e-02
I0515 05:03:41.060502 22392998065984 run_lib.py:167] step: 252200, eval_loss: 5.18077e-02
I0515 05:04:05.100541 22392998065984 run_lib.py:146] step: 252250, training_loss: 4.61898e-02
I0515 05:04:29.051437 22392998065984 run_lib.py:146] step: 252300, training_loss: 8.57233e-02
I0515 05:04:29.210068 22392998065984 run_lib.py:167] step: 252300, eval_loss: 6.17053e-02
I0515 05:04:53.586534 22392998065984 run_lib.py:146] step: 252350, training_loss: 6.30673e-02
I0515 05:05:17.893078 22392998065984 run_lib.py:146] step: 252400, training_loss: 6.39207e-02
I0515 05:05:18.057133 22392998065984 run_lib.py:167] step: 252400, eval_loss: 5.30384e-02
I0515 05:05:42.063597 22392998065984 run_lib.py:146] step: 252450, training_loss: 7.12440e-02
I0515 05:06:06.309267 22392998065984 run_lib.py:146] step: 252500, training_loss: 6.56015e-02
I0515 05:06:06.476922 22392998065984 run_lib.py:167] step: 252500, eval_loss: 5.04786e-02
I0515 05:06:30.757232 22392998065984 run_lib.py:146] step: 252550, training_loss: 7.59445e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:06:54.962532 22392998065984 run_lib.py:146] step: 252600, training_loss: 5.42793e-02
I0515 05:06:55.121808 22392998065984 run_lib.py:167] step: 252600, eval_loss: 6.70789e-02
I0515 05:07:19.470423 22392998065984 run_lib.py:146] step: 252650, training_loss: 6.48585e-02
I0515 05:07:43.928551 22392998065984 run_lib.py:146] step: 252700, training_loss: 7.31677e-02
I0515 05:07:44.015123 22392998065984 run_lib.py:167] step: 252700, eval_loss: 5.24221e-02
I0515 05:08:07.984495 22392998065984 run_lib.py:146] step: 252750, training_loss: 5.11707e-02
I0515 05:08:32.228008 22392998065984 run_lib.py:146] step: 252800, training_loss: 6.35271e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:08:32.678193 22392998065984 run_lib.py:167] step: 252800, eval_loss: 8.44281e-02
I0515 05:08:56.983195 22392998065984 run_lib.py:146] step: 252850, training_loss: 6.10024e-02
I0515 05:09:20.957205 22392998065984 run_lib.py:146] step: 252900, training_loss: 6.10200e-02
I0515 05:09:21.120352 22392998065984 run_lib.py:167] step: 252900, eval_loss: 6.21262e-02
I0515 05:09:45.463231 22392998065984 run_lib.py:146] step: 252950, training_loss: 5.67362e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:10:09.972944 22392998065984 run_lib.py:146] step: 253000, training_loss: 4.08784e-02
I0515 05:10:10.133210 22392998065984 run_lib.py:167] step: 253000, eval_loss: 5.20585e-02
I0515 05:10:34.140267 22392998065984 run_lib.py:146] step: 253050, training_loss: 6.25000e-02
I0515 05:10:58.097411 22392998065984 run_lib.py:146] step: 253100, training_loss: 4.58200e-02
I0515 05:10:58.265196 22392998065984 run_lib.py:167] step: 253100, eval_loss: 6.87662e-02
I0515 05:11:22.570741 22392998065984 run_lib.py:146] step: 253150, training_loss: 5.55697e-02
I0515 05:11:46.781072 22392998065984 run_lib.py:146] step: 253200, training_loss: 6.40390e-02
I0515 05:11:46.961381 22392998065984 run_lib.py:167] step: 253200, eval_loss: 7.35502e-02
I0515 05:12:10.872004 22392998065984 run_lib.py:146] step: 253250, training_loss: 5.51247e-02
I0515 05:12:35.105633 22392998065984 run_lib.py:146] step: 253300, training_loss: 4.66742e-02
I0515 05:12:35.264024 22392998065984 run_lib.py:167] step: 253300, eval_loss: 5.91194e-02
I0515 05:12:59.562525 22392998065984 run_lib.py:146] step: 253350, training_loss: 4.83013e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:13:23.647417 22392998065984 run_lib.py:146] step: 253400, training_loss: 5.81202e-02
I0515 05:13:23.807423 22392998065984 run_lib.py:167] step: 253400, eval_loss: 4.57952e-02
I0515 05:13:48.150781 22392998065984 run_lib.py:146] step: 253450, training_loss: 5.64877e-02
I0515 05:14:12.459671 22392998065984 run_lib.py:146] step: 253500, training_loss: 6.64474e-02
I0515 05:14:12.627355 22392998065984 run_lib.py:167] step: 253500, eval_loss: 6.03300e-02
I0515 05:14:36.598937 22392998065984 run_lib.py:146] step: 253550, training_loss: 5.89311e-02
I0515 05:15:00.839315 22392998065984 run_lib.py:146] step: 253600, training_loss: 7.16776e-02
I0515 05:15:00.997606 22392998065984 run_lib.py:167] step: 253600, eval_loss: 5.69901e-02
I0515 05:15:25.313585 22392998065984 run_lib.py:146] step: 253650, training_loss: 8.69089e-02
I0515 05:15:49.243057 22392998065984 run_lib.py:146] step: 253700, training_loss: 4.66362e-02
I0515 05:15:49.424125 22392998065984 run_lib.py:167] step: 253700, eval_loss: 7.63679e-02
I0515 05:16:13.640941 22392998065984 run_lib.py:146] step: 253750, training_loss: 4.25750e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:16:38.106557 22392998065984 run_lib.py:146] step: 253800, training_loss: 6.54321e-02
I0515 05:16:38.287794 22392998065984 run_lib.py:167] step: 253800, eval_loss: 5.29554e-02
I0515 05:17:02.277170 22392998065984 run_lib.py:146] step: 253850, training_loss: 4.39022e-02
I0515 05:17:26.491117 22392998065984 run_lib.py:146] step: 253900, training_loss: 7.33986e-02
I0515 05:17:26.665370 22392998065984 run_lib.py:167] step: 253900, eval_loss: 6.63210e-02
I0515 05:17:50.607182 22392998065984 run_lib.py:146] step: 253950, training_loss: 5.38467e-02
I0515 05:18:14.864224 22392998065984 run_lib.py:146] step: 254000, training_loss: 6.84827e-02
I0515 05:18:15.040194 22392998065984 run_lib.py:167] step: 254000, eval_loss: 5.92471e-02
I0515 05:18:38.968923 22392998065984 run_lib.py:146] step: 254050, training_loss: 3.87168e-02
I0515 05:19:03.162656 22392998065984 run_lib.py:146] step: 254100, training_loss: 6.11085e-02
I0515 05:19:03.321238 22392998065984 run_lib.py:167] step: 254100, eval_loss: 6.03371e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:19:27.713961 22392998065984 run_lib.py:146] step: 254150, training_loss: 6.77019e-02
I0515 05:19:51.720245 22392998065984 run_lib.py:146] step: 254200, training_loss: 4.57420e-02
I0515 05:19:51.880229 22392998065984 run_lib.py:167] step: 254200, eval_loss: 5.95157e-02
I0515 05:20:16.191939 22392998065984 run_lib.py:146] step: 254250, training_loss: 6.48750e-02
I0515 05:20:40.595717 22392998065984 run_lib.py:146] step: 254300, training_loss: 5.47048e-02
I0515 05:20:40.774552 22392998065984 run_lib.py:167] step: 254300, eval_loss: 5.85335e-02
I0515 05:21:04.799572 22392998065984 run_lib.py:146] step: 254350, training_loss: 6.83807e-02
I0515 05:21:28.995871 22392998065984 run_lib.py:146] step: 254400, training_loss: 6.64413e-02
I0515 05:21:29.162534 22392998065984 run_lib.py:167] step: 254400, eval_loss: 8.36561e-02
I0515 05:21:53.467716 22392998065984 run_lib.py:146] step: 254450, training_loss: 4.57042e-02
I0515 05:22:17.423317 22392998065984 run_lib.py:146] step: 254500, training_loss: 7.05557e-02
I0515 05:22:17.590588 22392998065984 run_lib.py:167] step: 254500, eval_loss: 5.06015e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:22:42.019937 22392998065984 run_lib.py:146] step: 254550, training_loss: 6.34739e-02
I0515 05:23:06.368993 22392998065984 run_lib.py:146] step: 254600, training_loss: 6.85904e-02
I0515 05:23:06.538637 22392998065984 run_lib.py:167] step: 254600, eval_loss: 5.97761e-02
I0515 05:23:30.484452 22392998065984 run_lib.py:146] step: 254650, training_loss: 6.05591e-02
I0515 05:23:54.787921 22392998065984 run_lib.py:146] step: 254700, training_loss: 5.50459e-02
I0515 05:23:54.945510 22392998065984 run_lib.py:167] step: 254700, eval_loss: 5.35658e-02
I0515 05:24:18.893866 22392998065984 run_lib.py:146] step: 254750, training_loss: 5.82421e-02
I0515 05:24:43.175214 22392998065984 run_lib.py:146] step: 254800, training_loss: 3.93857e-02
I0515 05:24:43.342869 22392998065984 run_lib.py:167] step: 254800, eval_loss: 7.43243e-02
I0515 05:25:07.282589 22392998065984 run_lib.py:146] step: 254850, training_loss: 5.81281e-02
I0515 05:25:31.581120 22392998065984 run_lib.py:146] step: 254900, training_loss: 6.36691e-02
I0515 05:25:31.748923 22392998065984 run_lib.py:167] step: 254900, eval_loss: 6.37883e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:25:56.290597 22392998065984 run_lib.py:146] step: 254950, training_loss: 7.00039e-02
I0515 05:26:20.245753 22392998065984 run_lib.py:146] step: 255000, training_loss: 5.23630e-02
I0515 05:26:20.404851 22392998065984 run_lib.py:167] step: 255000, eval_loss: 6.01283e-02
I0515 05:26:44.741507 22392998065984 run_lib.py:146] step: 255050, training_loss: 5.81968e-02
I0515 05:27:09.052716 22392998065984 run_lib.py:146] step: 255100, training_loss: 8.25751e-02
I0515 05:27:09.220209 22392998065984 run_lib.py:167] step: 255100, eval_loss: 5.85903e-02
I0515 05:27:33.096076 22392998065984 run_lib.py:146] step: 255150, training_loss: 5.36062e-02
I0515 05:27:57.377009 22392998065984 run_lib.py:146] step: 255200, training_loss: 7.47939e-02
I0515 05:27:57.534689 22392998065984 run_lib.py:167] step: 255200, eval_loss: 5.30805e-02
I0515 05:28:21.807692 22392998065984 run_lib.py:146] step: 255250, training_loss: 7.03874e-02
I0515 05:28:45.793324 22392998065984 run_lib.py:146] step: 255300, training_loss: 5.67491e-02
I0515 05:28:45.962448 22392998065984 run_lib.py:167] step: 255300, eval_loss: 6.43601e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:29:10.446306 22392998065984 run_lib.py:146] step: 255350, training_loss: 6.80235e-02
I0515 05:29:34.461014 22392998065984 run_lib.py:146] step: 255400, training_loss: 4.81301e-02
I0515 05:29:34.620135 22392998065984 run_lib.py:167] step: 255400, eval_loss: 6.47825e-02
I0515 05:29:58.957290 22392998065984 run_lib.py:146] step: 255450, training_loss: 7.66858e-02
I0515 05:30:23.118503 22392998065984 run_lib.py:146] step: 255500, training_loss: 4.79915e-02
I0515 05:30:23.275975 22392998065984 run_lib.py:167] step: 255500, eval_loss: 7.25846e-02
I0515 05:30:47.217475 22392998065984 run_lib.py:146] step: 255550, training_loss: 4.06179e-02
I0515 05:31:11.468575 22392998065984 run_lib.py:146] step: 255600, training_loss: 4.95250e-02
I0515 05:31:11.626722 22392998065984 run_lib.py:167] step: 255600, eval_loss: 5.77272e-02
I0515 05:31:35.566785 22392998065984 run_lib.py:146] step: 255650, training_loss: 5.43159e-02
I0515 05:31:59.743446 22392998065984 run_lib.py:146] step: 255700, training_loss: 6.19313e-02
I0515 05:31:59.901370 22392998065984 run_lib.py:167] step: 255700, eval_loss: 4.39397e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:32:24.352910 22392998065984 run_lib.py:146] step: 255750, training_loss: 5.42728e-02
I0515 05:32:48.309304 22392998065984 run_lib.py:146] step: 255800, training_loss: 5.76443e-02
I0515 05:32:48.468742 22392998065984 run_lib.py:167] step: 255800, eval_loss: 6.94526e-02
I0515 05:33:12.826120 22392998065984 run_lib.py:146] step: 255850, training_loss: 6.59802e-02
I0515 05:33:37.081903 22392998065984 run_lib.py:146] step: 255900, training_loss: 6.63042e-02
I0515 05:33:37.241123 22392998065984 run_lib.py:167] step: 255900, eval_loss: 5.88567e-02
I0515 05:34:01.180325 22392998065984 run_lib.py:146] step: 255950, training_loss: 7.37497e-02
I0515 05:34:25.432193 22392998065984 run_lib.py:146] step: 256000, training_loss: 4.93441e-02
I0515 05:34:25.624174 22392998065984 run_lib.py:167] step: 256000, eval_loss: 6.62547e-02
I0515 05:34:49.922559 22392998065984 run_lib.py:146] step: 256050, training_loss: 6.87158e-02
I0515 05:35:13.879652 22392998065984 run_lib.py:146] step: 256100, training_loss: 5.80852e-02
I0515 05:35:14.037604 22392998065984 run_lib.py:167] step: 256100, eval_loss: 5.67151e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:35:38.521563 22392998065984 run_lib.py:146] step: 256150, training_loss: 5.32924e-02
I0515 05:36:02.798882 22392998065984 run_lib.py:146] step: 256200, training_loss: 7.32034e-02
I0515 05:36:02.957965 22392998065984 run_lib.py:167] step: 256200, eval_loss: 6.31535e-02
I0515 05:36:26.869756 22392998065984 run_lib.py:146] step: 256250, training_loss: 6.59190e-02
I0515 05:36:51.101845 22392998065984 run_lib.py:146] step: 256300, training_loss: 6.75106e-02
I0515 05:36:51.268438 22392998065984 run_lib.py:167] step: 256300, eval_loss: 5.63844e-02
I0515 05:37:15.246697 22392998065984 run_lib.py:146] step: 256350, training_loss: 6.00952e-02
I0515 05:37:39.461655 22392998065984 run_lib.py:146] step: 256400, training_loss: 7.45090e-02
I0515 05:37:39.628660 22392998065984 run_lib.py:167] step: 256400, eval_loss: 5.85361e-02
I0515 05:38:03.700032 22392998065984 run_lib.py:146] step: 256450, training_loss: 8.89158e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:38:28.080849 22392998065984 run_lib.py:146] step: 256500, training_loss: 6.38682e-02
I0515 05:38:28.240313 22392998065984 run_lib.py:167] step: 256500, eval_loss: 5.59410e-02
I0515 05:38:52.623860 22392998065984 run_lib.py:146] step: 256550, training_loss: 3.45231e-02
I0515 05:39:16.803323 22392998065984 run_lib.py:146] step: 256600, training_loss: 5.97866e-02
I0515 05:39:16.961939 22392998065984 run_lib.py:167] step: 256600, eval_loss: 6.87520e-02
I0515 05:39:41.275252 22392998065984 run_lib.py:146] step: 256650, training_loss: 6.18674e-02
I0515 05:40:05.502640 22392998065984 run_lib.py:146] step: 256700, training_loss: 5.16409e-02
I0515 05:40:05.661215 22392998065984 run_lib.py:167] step: 256700, eval_loss: 6.32580e-02
I0515 05:40:29.688547 22392998065984 run_lib.py:146] step: 256750, training_loss: 6.36372e-02
I0515 05:40:53.915587 22392998065984 run_lib.py:146] step: 256800, training_loss: 4.43191e-02
I0515 05:40:54.077147 22392998065984 run_lib.py:167] step: 256800, eval_loss: 6.50855e-02
I0515 05:41:18.329585 22392998065984 run_lib.py:146] step: 256850, training_loss: 5.48672e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:41:42.543897 22392998065984 run_lib.py:146] step: 256900, training_loss: 6.62581e-02
I0515 05:41:42.708917 22392998065984 run_lib.py:167] step: 256900, eval_loss: 5.38478e-02
I0515 05:42:07.040402 22392998065984 run_lib.py:146] step: 256950, training_loss: 7.24524e-02
I0515 05:42:31.356016 22392998065984 run_lib.py:146] step: 257000, training_loss: 6.87764e-02
I0515 05:42:31.520257 22392998065984 run_lib.py:167] step: 257000, eval_loss: 6.06071e-02
I0515 05:42:55.548382 22392998065984 run_lib.py:146] step: 257050, training_loss: 5.12167e-02
I0515 05:43:19.822577 22392998065984 run_lib.py:146] step: 257100, training_loss: 6.30781e-02
I0515 05:43:19.980274 22392998065984 run_lib.py:167] step: 257100, eval_loss: 5.07961e-02
I0515 05:43:43.995316 22392998065984 run_lib.py:146] step: 257150, training_loss: 6.38676e-02
I0515 05:44:08.301332 22392998065984 run_lib.py:146] step: 257200, training_loss: 6.12786e-02
I0515 05:44:08.483928 22392998065984 run_lib.py:167] step: 257200, eval_loss: 6.17453e-02
I0515 05:44:32.401849 22392998065984 run_lib.py:146] step: 257250, training_loss: 5.74097e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:44:56.843262 22392998065984 run_lib.py:146] step: 257300, training_loss: 6.24626e-02
I0515 05:44:57.003287 22392998065984 run_lib.py:167] step: 257300, eval_loss: 5.35690e-02
I0515 05:45:21.381608 22392998065984 run_lib.py:146] step: 257350, training_loss: 4.48570e-02
I0515 05:45:45.444012 22392998065984 run_lib.py:146] step: 257400, training_loss: 5.86437e-02
I0515 05:45:45.619030 22392998065984 run_lib.py:167] step: 257400, eval_loss: 7.58442e-02
I0515 05:46:09.939542 22392998065984 run_lib.py:146] step: 257450, training_loss: 5.91300e-02
I0515 05:46:34.242651 22392998065984 run_lib.py:146] step: 257500, training_loss: 6.30624e-02
I0515 05:46:34.411208 22392998065984 run_lib.py:167] step: 257500, eval_loss: 5.45558e-02
I0515 05:46:58.401879 22392998065984 run_lib.py:146] step: 257550, training_loss: 8.35859e-02
I0515 05:47:22.590445 22392998065984 run_lib.py:146] step: 257600, training_loss: 6.42449e-02
I0515 05:47:22.767622 22392998065984 run_lib.py:167] step: 257600, eval_loss: 5.10575e-02
I0515 05:47:46.991771 22392998065984 run_lib.py:146] step: 257650, training_loss: 5.35308e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:48:11.121626 22392998065984 run_lib.py:146] step: 257700, training_loss: 6.76180e-02
I0515 05:48:11.291407 22392998065984 run_lib.py:167] step: 257700, eval_loss: 6.00010e-02
I0515 05:48:35.619482 22392998065984 run_lib.py:146] step: 257750, training_loss: 6.94718e-02
I0515 05:48:59.937672 22392998065984 run_lib.py:146] step: 257800, training_loss: 6.76914e-02
I0515 05:49:00.106223 22392998065984 run_lib.py:167] step: 257800, eval_loss: 7.28599e-02
I0515 05:49:24.087220 22392998065984 run_lib.py:146] step: 257850, training_loss: 4.79158e-02
I0515 05:49:48.338281 22392998065984 run_lib.py:146] step: 257900, training_loss: 6.91021e-02
I0515 05:49:48.496638 22392998065984 run_lib.py:167] step: 257900, eval_loss: 5.68236e-02
I0515 05:50:12.863576 22392998065984 run_lib.py:146] step: 257950, training_loss: 5.70595e-02
I0515 05:50:36.850780 22392998065984 run_lib.py:146] step: 258000, training_loss: 6.36860e-02
I0515 05:50:37.014352 22392998065984 run_lib.py:167] step: 258000, eval_loss: 7.52099e-02
I0515 05:51:00.956151 22392998065984 run_lib.py:146] step: 258050, training_loss: 5.94223e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:51:25.396430 22392998065984 run_lib.py:146] step: 258100, training_loss: 6.10340e-02
I0515 05:51:25.556290 22392998065984 run_lib.py:167] step: 258100, eval_loss: 4.99412e-02
I0515 05:51:49.938272 22392998065984 run_lib.py:146] step: 258150, training_loss: 5.05637e-02
I0515 05:52:13.929537 22392998065984 run_lib.py:146] step: 258200, training_loss: 6.31185e-02
I0515 05:52:14.104074 22392998065984 run_lib.py:167] step: 258200, eval_loss: 6.79686e-02
I0515 05:52:38.409150 22392998065984 run_lib.py:146] step: 258250, training_loss: 5.60008e-02
I0515 05:53:02.668720 22392998065984 run_lib.py:146] step: 258300, training_loss: 4.49574e-02
I0515 05:53:02.836512 22392998065984 run_lib.py:167] step: 258300, eval_loss: 6.50951e-02
I0515 05:53:26.761780 22392998065984 run_lib.py:146] step: 258350, training_loss: 6.66732e-02
I0515 05:53:51.021523 22392998065984 run_lib.py:146] step: 258400, training_loss: 6.24048e-02
I0515 05:53:51.179938 22392998065984 run_lib.py:167] step: 258400, eval_loss: 5.83978e-02
I0515 05:54:15.309463 22392998065984 run_lib.py:146] step: 258450, training_loss: 7.42135e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:54:39.594231 22392998065984 run_lib.py:146] step: 258500, training_loss: 5.04662e-02
I0515 05:54:39.763709 22392998065984 run_lib.py:167] step: 258500, eval_loss: 7.97270e-02
I0515 05:55:04.072092 22392998065984 run_lib.py:146] step: 258550, training_loss: 5.64391e-02
I0515 05:55:28.385782 22392998065984 run_lib.py:146] step: 258600, training_loss: 4.81515e-02
I0515 05:55:28.565397 22392998065984 run_lib.py:167] step: 258600, eval_loss: 7.64753e-02
I0515 05:55:52.533323 22392998065984 run_lib.py:146] step: 258650, training_loss: 5.47957e-02
I0515 05:56:16.744274 22392998065984 run_lib.py:146] step: 258700, training_loss: 5.55088e-02
I0515 05:56:16.924472 22392998065984 run_lib.py:167] step: 258700, eval_loss: 5.51562e-02
I0515 05:56:41.214890 22392998065984 run_lib.py:146] step: 258750, training_loss: 5.28859e-02
I0515 05:57:05.187170 22392998065984 run_lib.py:146] step: 258800, training_loss: 6.61721e-02
I0515 05:57:05.370679 22392998065984 run_lib.py:167] step: 258800, eval_loss: 5.02809e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 05:57:29.818588 22392998065984 run_lib.py:146] step: 258850, training_loss: 6.19858e-02
I0515 05:57:53.762495 22392998065984 run_lib.py:146] step: 258900, training_loss: 4.57937e-02
I0515 05:57:53.933671 22392998065984 run_lib.py:167] step: 258900, eval_loss: 5.15757e-02
I0515 05:58:18.181260 22392998065984 run_lib.py:146] step: 258950, training_loss: 6.00477e-02
I0515 05:58:42.142837 22392998065984 run_lib.py:146] step: 259000, training_loss: 4.54832e-02
I0515 05:58:42.302327 22392998065984 run_lib.py:167] step: 259000, eval_loss: 5.31399e-02
I0515 05:59:06.575593 22392998065984 run_lib.py:146] step: 259050, training_loss: 5.18318e-02
I0515 05:59:30.886635 22392998065984 run_lib.py:146] step: 259100, training_loss: 6.79453e-02
I0515 05:59:31.047307 22392998065984 run_lib.py:167] step: 259100, eval_loss: 4.99824e-02
I0515 05:59:55.005573 22392998065984 run_lib.py:146] step: 259150, training_loss: 8.14034e-02
I0515 06:00:19.183329 22392998065984 run_lib.py:146] step: 259200, training_loss: 6.14123e-02
I0515 06:00:19.349506 22392998065984 run_lib.py:167] step: 259200, eval_loss: 5.31878e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:00:43.865866 22392998065984 run_lib.py:146] step: 259250, training_loss: 5.45686e-02
I0515 06:01:07.914183 22392998065984 run_lib.py:146] step: 259300, training_loss: 6.99291e-02
I0515 06:01:08.073906 22392998065984 run_lib.py:167] step: 259300, eval_loss: 4.79564e-02
I0515 06:01:32.424542 22392998065984 run_lib.py:146] step: 259350, training_loss: 5.90134e-02
I0515 06:01:56.729634 22392998065984 run_lib.py:146] step: 259400, training_loss: 6.72512e-02
I0515 06:01:56.897342 22392998065984 run_lib.py:167] step: 259400, eval_loss: 5.31262e-02
I0515 06:02:20.879240 22392998065984 run_lib.py:146] step: 259450, training_loss: 5.58744e-02
I0515 06:02:45.186410 22392998065984 run_lib.py:146] step: 259500, training_loss: 7.01527e-02
I0515 06:02:45.344732 22392998065984 run_lib.py:167] step: 259500, eval_loss: 5.66437e-02
I0515 06:03:09.648453 22392998065984 run_lib.py:146] step: 259550, training_loss: 6.94848e-02
I0515 06:03:33.623273 22392998065984 run_lib.py:146] step: 259600, training_loss: 4.79806e-02
I0515 06:03:33.781715 22392998065984 run_lib.py:167] step: 259600, eval_loss: 6.54531e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:03:58.359380 22392998065984 run_lib.py:146] step: 259650, training_loss: 7.23677e-02
I0515 06:04:22.709268 22392998065984 run_lib.py:146] step: 259700, training_loss: 4.88954e-02
I0515 06:04:22.885634 22392998065984 run_lib.py:167] step: 259700, eval_loss: 8.57186e-02
I0515 06:04:46.861686 22392998065984 run_lib.py:146] step: 259750, training_loss: 4.49657e-02
I0515 06:05:11.116457 22392998065984 run_lib.py:146] step: 259800, training_loss: 4.75911e-02
I0515 06:05:11.274609 22392998065984 run_lib.py:167] step: 259800, eval_loss: 6.88269e-02
I0515 06:05:35.204758 22392998065984 run_lib.py:146] step: 259850, training_loss: 3.84705e-02
I0515 06:05:59.410524 22392998065984 run_lib.py:146] step: 259900, training_loss: 4.52064e-02
I0515 06:05:59.569385 22392998065984 run_lib.py:167] step: 259900, eval_loss: 6.19091e-02
I0515 06:06:23.610229 22392998065984 run_lib.py:146] step: 259950, training_loss: 6.38446e-02
I0515 06:06:47.901618 22392998065984 run_lib.py:146] step: 260000, training_loss: 6.15031e-02
I0515 06:06:49.582517 22392998065984 run_lib.py:167] step: 260000, eval_loss: 5.42981e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:07:15.511364 22392998065984 run_lib.py:146] step: 260050, training_loss: 4.20184e-02
I0515 06:07:39.794749 22392998065984 run_lib.py:146] step: 260100, training_loss: 4.96268e-02
I0515 06:07:39.970575 22392998065984 run_lib.py:167] step: 260100, eval_loss: 5.85023e-02
I0515 06:08:03.896797 22392998065984 run_lib.py:146] step: 260150, training_loss: 5.14264e-02
I0515 06:08:28.167048 22392998065984 run_lib.py:146] step: 260200, training_loss: 6.78539e-02
I0515 06:08:28.341717 22392998065984 run_lib.py:167] step: 260200, eval_loss: 6.20987e-02
I0515 06:08:52.695964 22392998065984 run_lib.py:146] step: 260250, training_loss: 5.99884e-02
I0515 06:09:16.643930 22392998065984 run_lib.py:146] step: 260300, training_loss: 5.87868e-02
I0515 06:09:16.807916 22392998065984 run_lib.py:167] step: 260300, eval_loss: 4.84125e-02
I0515 06:09:41.059624 22392998065984 run_lib.py:146] step: 260350, training_loss: 3.82347e-02
I0515 06:10:05.369155 22392998065984 run_lib.py:146] step: 260400, training_loss: 6.10214e-02
I0515 06:10:05.528865 22392998065984 run_lib.py:167] step: 260400, eval_loss: 6.02425e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:10:29.641029 22392998065984 run_lib.py:146] step: 260450, training_loss: 7.27265e-02
I0515 06:10:53.955373 22392998065984 run_lib.py:146] step: 260500, training_loss: 6.19430e-02
I0515 06:10:54.114114 22392998065984 run_lib.py:167] step: 260500, eval_loss: 5.71318e-02
I0515 06:11:18.442116 22392998065984 run_lib.py:146] step: 260550, training_loss: 4.00924e-02
I0515 06:11:42.385535 22392998065984 run_lib.py:146] step: 260600, training_loss: 5.88847e-02
I0515 06:11:42.488992 22392998065984 run_lib.py:167] step: 260600, eval_loss: 5.20163e-02
I0515 06:12:06.394271 22392998065984 run_lib.py:146] step: 260650, training_loss: 5.14376e-02
I0515 06:12:30.569787 22392998065984 run_lib.py:146] step: 260700, training_loss: 5.57524e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:12:31.001348 22392998065984 run_lib.py:167] step: 260700, eval_loss: 4.54983e-02
I0515 06:12:55.407358 22392998065984 run_lib.py:146] step: 260750, training_loss: 7.95084e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:13:19.557262 22392998065984 run_lib.py:146] step: 260800, training_loss: 9.02996e-02
I0515 06:13:19.758933 22392998065984 run_lib.py:167] step: 260800, eval_loss: 5.64044e-02
I0515 06:13:44.059273 22392998065984 run_lib.py:146] step: 260850, training_loss: 4.33382e-02
I0515 06:14:08.405911 22392998065984 run_lib.py:146] step: 260900, training_loss: 5.38800e-02
I0515 06:14:08.575658 22392998065984 run_lib.py:167] step: 260900, eval_loss: 5.17014e-02
I0515 06:14:32.522279 22392998065984 run_lib.py:146] step: 260950, training_loss: 5.97352e-02
I0515 06:14:56.799556 22392998065984 run_lib.py:146] step: 261000, training_loss: 6.80442e-02
I0515 06:14:56.981707 22392998065984 run_lib.py:167] step: 261000, eval_loss: 6.57887e-02
I0515 06:15:21.176092 22392998065984 run_lib.py:146] step: 261050, training_loss: 6.16625e-02
I0515 06:15:45.086519 22392998065984 run_lib.py:146] step: 261100, training_loss: 5.46312e-02
I0515 06:15:45.254923 22392998065984 run_lib.py:167] step: 261100, eval_loss: 5.05900e-02
I0515 06:16:09.505511 22392998065984 run_lib.py:146] step: 261150, training_loss: 5.69402e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:16:33.873163 22392998065984 run_lib.py:146] step: 261200, training_loss: 5.61442e-02
I0515 06:16:34.033035 22392998065984 run_lib.py:167] step: 261200, eval_loss: 4.88123e-02
I0515 06:16:58.008617 22392998065984 run_lib.py:146] step: 261250, training_loss: 6.86896e-02
I0515 06:17:22.338499 22392998065984 run_lib.py:146] step: 261300, training_loss: 4.40760e-02
I0515 06:17:22.496762 22392998065984 run_lib.py:167] step: 261300, eval_loss: 5.22130e-02
I0515 06:17:46.778642 22392998065984 run_lib.py:146] step: 261350, training_loss: 4.97151e-02
I0515 06:18:10.683132 22392998065984 run_lib.py:146] step: 261400, training_loss: 5.24762e-02
I0515 06:18:10.850294 22392998065984 run_lib.py:167] step: 261400, eval_loss: 6.19187e-02
I0515 06:18:34.793107 22392998065984 run_lib.py:146] step: 261450, training_loss: 6.03097e-02
I0515 06:18:59.045380 22392998065984 run_lib.py:146] step: 261500, training_loss: 7.38054e-02
I0515 06:18:59.204564 22392998065984 run_lib.py:167] step: 261500, eval_loss: 6.80417e-02
I0515 06:19:23.436308 22392998065984 run_lib.py:146] step: 261550, training_loss: 5.00994e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:19:47.571437 22392998065984 run_lib.py:146] step: 261600, training_loss: 4.62832e-02
I0515 06:19:47.740604 22392998065984 run_lib.py:167] step: 261600, eval_loss: 6.33680e-02
I0515 06:20:12.028171 22392998065984 run_lib.py:146] step: 261650, training_loss: 5.95666e-02
I0515 06:20:36.357200 22392998065984 run_lib.py:146] step: 261700, training_loss: 4.40866e-02
I0515 06:20:36.537763 22392998065984 run_lib.py:167] step: 261700, eval_loss: 5.60063e-02
I0515 06:21:00.461123 22392998065984 run_lib.py:146] step: 261750, training_loss: 6.15114e-02
I0515 06:21:24.717359 22392998065984 run_lib.py:146] step: 261800, training_loss: 6.00932e-02
I0515 06:21:24.875563 22392998065984 run_lib.py:167] step: 261800, eval_loss: 6.07544e-02
I0515 06:21:49.148295 22392998065984 run_lib.py:146] step: 261850, training_loss: 5.66276e-02
I0515 06:22:13.091228 22392998065984 run_lib.py:146] step: 261900, training_loss: 7.20849e-02
I0515 06:22:13.254606 22392998065984 run_lib.py:167] step: 261900, eval_loss: 6.24664e-02
I0515 06:22:37.435223 22392998065984 run_lib.py:146] step: 261950, training_loss: 4.36239e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:23:01.836057 22392998065984 run_lib.py:146] step: 262000, training_loss: 4.96556e-02
I0515 06:23:02.014343 22392998065984 run_lib.py:167] step: 262000, eval_loss: 6.41025e-02
I0515 06:23:25.868675 22392998065984 run_lib.py:146] step: 262050, training_loss: 3.87468e-02
I0515 06:23:50.152704 22392998065984 run_lib.py:146] step: 262100, training_loss: 5.77585e-02
I0515 06:23:50.328200 22392998065984 run_lib.py:167] step: 262100, eval_loss: 5.46821e-02
I0515 06:24:14.494120 22392998065984 run_lib.py:146] step: 262150, training_loss: 6.24289e-02
I0515 06:24:38.424626 22392998065984 run_lib.py:146] step: 262200, training_loss: 5.18950e-02
I0515 06:24:38.604501 22392998065984 run_lib.py:167] step: 262200, eval_loss: 4.07576e-02
I0515 06:25:02.482531 22392998065984 run_lib.py:146] step: 262250, training_loss: 6.44414e-02
I0515 06:25:26.948205 22392998065984 run_lib.py:146] step: 262300, training_loss: 5.71242e-02
I0515 06:25:27.111759 22392998065984 run_lib.py:167] step: 262300, eval_loss: 5.94333e-02
I0515 06:25:51.051123 22392998065984 run_lib.py:146] step: 262350, training_loss: 6.10149e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:26:15.201986 22392998065984 run_lib.py:146] step: 262400, training_loss: 7.07338e-02
I0515 06:26:15.377916 22392998065984 run_lib.py:167] step: 262400, eval_loss: 5.93989e-02
I0515 06:26:39.715423 22392998065984 run_lib.py:146] step: 262450, training_loss: 7.02881e-02
I0515 06:27:03.988280 22392998065984 run_lib.py:146] step: 262500, training_loss: 6.72798e-02
I0515 06:27:04.151626 22392998065984 run_lib.py:167] step: 262500, eval_loss: 5.23756e-02
I0515 06:27:28.024971 22392998065984 run_lib.py:146] step: 262550, training_loss: 6.16304e-02
I0515 06:27:52.275858 22392998065984 run_lib.py:146] step: 262600, training_loss: 4.76032e-02
I0515 06:27:52.448021 22392998065984 run_lib.py:167] step: 262600, eval_loss: 7.44570e-02
I0515 06:28:16.728559 22392998065984 run_lib.py:146] step: 262650, training_loss: 5.46662e-02
I0515 06:28:40.614363 22392998065984 run_lib.py:146] step: 262700, training_loss: 5.89855e-02
I0515 06:28:40.772687 22392998065984 run_lib.py:167] step: 262700, eval_loss: 6.82414e-02
I0515 06:29:05.028781 22392998065984 run_lib.py:146] step: 262750, training_loss: 6.00314e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:29:29.517276 22392998065984 run_lib.py:146] step: 262800, training_loss: 5.65294e-02
I0515 06:29:29.694907 22392998065984 run_lib.py:167] step: 262800, eval_loss: 8.43717e-02
I0515 06:29:53.707512 22392998065984 run_lib.py:146] step: 262850, training_loss: 6.10568e-02
I0515 06:30:18.049109 22392998065984 run_lib.py:146] step: 262900, training_loss: 6.88381e-02
I0515 06:30:18.207768 22392998065984 run_lib.py:167] step: 262900, eval_loss: 4.34269e-02
I0515 06:30:42.430793 22392998065984 run_lib.py:146] step: 262950, training_loss: 4.64907e-02
I0515 06:31:06.314966 22392998065984 run_lib.py:146] step: 263000, training_loss: 5.31615e-02
I0515 06:31:06.472997 22392998065984 run_lib.py:167] step: 263000, eval_loss: 6.99373e-02
I0515 06:31:30.420515 22392998065984 run_lib.py:146] step: 263050, training_loss: 9.38475e-02
I0515 06:31:55.016979 22392998065984 run_lib.py:146] step: 263100, training_loss: 5.72225e-02
I0515 06:31:55.175261 22392998065984 run_lib.py:167] step: 263100, eval_loss: 5.86056e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:32:19.253649 22392998065984 run_lib.py:146] step: 263150, training_loss: 5.77388e-02
I0515 06:32:43.167129 22392998065984 run_lib.py:146] step: 263200, training_loss: 6.06247e-02
I0515 06:32:43.326888 22392998065984 run_lib.py:167] step: 263200, eval_loss: 4.79026e-02
I0515 06:33:07.680986 22392998065984 run_lib.py:146] step: 263250, training_loss: 7.37766e-02
I0515 06:33:31.998756 22392998065984 run_lib.py:146] step: 263300, training_loss: 8.05748e-02
I0515 06:33:32.166289 22392998065984 run_lib.py:167] step: 263300, eval_loss: 6.99210e-02
I0515 06:33:56.209401 22392998065984 run_lib.py:146] step: 263350, training_loss: 5.19572e-02
I0515 06:34:20.455646 22392998065984 run_lib.py:146] step: 263400, training_loss: 4.28080e-02
I0515 06:34:20.622958 22392998065984 run_lib.py:167] step: 263400, eval_loss: 7.37885e-02
I0515 06:34:44.865851 22392998065984 run_lib.py:146] step: 263450, training_loss: 5.66553e-02
I0515 06:35:08.838864 22392998065984 run_lib.py:146] step: 263500, training_loss: 4.91801e-02
I0515 06:35:08.996679 22392998065984 run_lib.py:167] step: 263500, eval_loss: 7.53980e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:35:33.450453 22392998065984 run_lib.py:146] step: 263550, training_loss: 5.73965e-02
I0515 06:35:57.699185 22392998065984 run_lib.py:146] step: 263600, training_loss: 4.76444e-02
I0515 06:35:57.858133 22392998065984 run_lib.py:167] step: 263600, eval_loss: 5.69250e-02
I0515 06:36:21.852204 22392998065984 run_lib.py:146] step: 263650, training_loss: 6.69370e-02
I0515 06:36:46.133774 22392998065984 run_lib.py:146] step: 263700, training_loss: 4.47242e-02
I0515 06:36:46.313809 22392998065984 run_lib.py:167] step: 263700, eval_loss: 6.56202e-02
I0515 06:37:10.588089 22392998065984 run_lib.py:146] step: 263750, training_loss: 5.95366e-02
I0515 06:37:34.533345 22392998065984 run_lib.py:146] step: 263800, training_loss: 5.49664e-02
I0515 06:37:34.691123 22392998065984 run_lib.py:167] step: 263800, eval_loss: 6.77439e-02
I0515 06:37:58.614129 22392998065984 run_lib.py:146] step: 263850, training_loss: 4.83977e-02
I0515 06:38:23.175389 22392998065984 run_lib.py:146] step: 263900, training_loss: 4.97842e-02
I0515 06:38:23.332680 22392998065984 run_lib.py:167] step: 263900, eval_loss: 4.93381e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:38:47.435669 22392998065984 run_lib.py:146] step: 263950, training_loss: 5.73804e-02
I0515 06:39:11.405509 22392998065984 run_lib.py:146] step: 264000, training_loss: 5.45754e-02
I0515 06:39:11.593940 22392998065984 run_lib.py:167] step: 264000, eval_loss: 6.89766e-02
I0515 06:39:35.860855 22392998065984 run_lib.py:146] step: 264050, training_loss: 6.07577e-02
I0515 06:40:00.085561 22392998065984 run_lib.py:146] step: 264100, training_loss: 5.69069e-02
I0515 06:40:00.252702 22392998065984 run_lib.py:167] step: 264100, eval_loss: 6.85640e-02
I0515 06:40:24.174048 22392998065984 run_lib.py:146] step: 264150, training_loss: 4.82031e-02
I0515 06:40:48.415394 22392998065984 run_lib.py:146] step: 264200, training_loss: 5.93820e-02
I0515 06:40:48.573122 22392998065984 run_lib.py:167] step: 264200, eval_loss: 5.52728e-02
I0515 06:41:12.789422 22392998065984 run_lib.py:146] step: 264250, training_loss: 5.34013e-02
I0515 06:41:36.688426 22392998065984 run_lib.py:146] step: 264300, training_loss: 5.33909e-02
I0515 06:41:36.855531 22392998065984 run_lib.py:167] step: 264300, eval_loss: 5.79651e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:42:01.387087 22392998065984 run_lib.py:146] step: 264350, training_loss: 5.18477e-02
I0515 06:42:25.724472 22392998065984 run_lib.py:146] step: 264400, training_loss: 8.54994e-02
I0515 06:42:25.884706 22392998065984 run_lib.py:167] step: 264400, eval_loss: 5.29659e-02
I0515 06:42:49.835449 22392998065984 run_lib.py:146] step: 264450, training_loss: 4.47231e-02
I0515 06:43:14.031797 22392998065984 run_lib.py:146] step: 264500, training_loss: 5.30927e-02
I0515 06:43:14.190133 22392998065984 run_lib.py:167] step: 264500, eval_loss: 5.12239e-02
I0515 06:43:38.376387 22392998065984 run_lib.py:146] step: 264550, training_loss: 5.16609e-02
I0515 06:44:02.297508 22392998065984 run_lib.py:146] step: 264600, training_loss: 6.62464e-02
I0515 06:44:02.479669 22392998065984 run_lib.py:167] step: 264600, eval_loss: 5.62041e-02
I0515 06:44:26.436341 22392998065984 run_lib.py:146] step: 264650, training_loss: 7.06711e-02
I0515 06:44:50.954589 22392998065984 run_lib.py:146] step: 264700, training_loss: 6.48236e-02
I0515 06:44:51.112788 22392998065984 run_lib.py:167] step: 264700, eval_loss: 5.44426e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:45:15.234107 22392998065984 run_lib.py:146] step: 264750, training_loss: 4.84020e-02
I0515 06:45:39.141519 22392998065984 run_lib.py:146] step: 264800, training_loss: 6.44215e-02
I0515 06:45:39.310653 22392998065984 run_lib.py:167] step: 264800, eval_loss: 5.77969e-02
I0515 06:46:03.517409 22392998065984 run_lib.py:146] step: 264850, training_loss: 5.48930e-02
I0515 06:46:27.776250 22392998065984 run_lib.py:146] step: 264900, training_loss: 6.35046e-02
I0515 06:46:27.944533 22392998065984 run_lib.py:167] step: 264900, eval_loss: 5.16606e-02
I0515 06:46:51.874527 22392998065984 run_lib.py:146] step: 264950, training_loss: 6.96946e-02
I0515 06:47:16.095138 22392998065984 run_lib.py:146] step: 265000, training_loss: 6.03560e-02
I0515 06:47:16.252713 22392998065984 run_lib.py:167] step: 265000, eval_loss: 6.36176e-02
I0515 06:47:40.448466 22392998065984 run_lib.py:146] step: 265050, training_loss: 3.69770e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:48:04.536184 22392998065984 run_lib.py:146] step: 265100, training_loss: 6.65331e-02
I0515 06:48:04.696099 22392998065984 run_lib.py:167] step: 265100, eval_loss: 5.72107e-02
I0515 06:48:29.011790 22392998065984 run_lib.py:146] step: 265150, training_loss: 5.77480e-02
I0515 06:48:53.322290 22392998065984 run_lib.py:146] step: 265200, training_loss: 5.78990e-02
I0515 06:48:53.489943 22392998065984 run_lib.py:167] step: 265200, eval_loss: 6.29043e-02
I0515 06:49:17.412473 22392998065984 run_lib.py:146] step: 265250, training_loss: 6.57450e-02
I0515 06:49:41.389357 22392998065984 run_lib.py:146] step: 265300, training_loss: 6.03604e-02
I0515 06:49:41.557040 22392998065984 run_lib.py:167] step: 265300, eval_loss: 5.80277e-02
I0515 06:50:06.074979 22392998065984 run_lib.py:146] step: 265350, training_loss: 4.20020e-02
I0515 06:50:30.027528 22392998065984 run_lib.py:146] step: 265400, training_loss: 4.07931e-02
I0515 06:50:30.195041 22392998065984 run_lib.py:167] step: 265400, eval_loss: 6.03013e-02
I0515 06:50:54.189213 22392998065984 run_lib.py:146] step: 265450, training_loss: 7.03650e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:51:18.919453 22392998065984 run_lib.py:146] step: 265500, training_loss: 5.55251e-02
I0515 06:51:19.089664 22392998065984 run_lib.py:167] step: 265500, eval_loss: 4.75593e-02
I0515 06:51:43.042767 22392998065984 run_lib.py:146] step: 265550, training_loss: 6.34040e-02
I0515 06:52:07.037120 22392998065984 run_lib.py:146] step: 265600, training_loss: 4.15344e-02
I0515 06:52:07.204539 22392998065984 run_lib.py:167] step: 265600, eval_loss: 5.90845e-02
I0515 06:52:31.896812 22392998065984 run_lib.py:146] step: 265650, training_loss: 6.91613e-02
I0515 06:52:55.842169 22392998065984 run_lib.py:146] step: 265700, training_loss: 5.34076e-02
I0515 06:52:56.009942 22392998065984 run_lib.py:167] step: 265700, eval_loss: 7.77473e-02
I0515 06:53:19.915204 22392998065984 run_lib.py:146] step: 265750, training_loss: 5.51202e-02
I0515 06:53:44.166316 22392998065984 run_lib.py:146] step: 265800, training_loss: 4.90113e-02
I0515 06:53:44.333323 22392998065984 run_lib.py:167] step: 265800, eval_loss: 6.11231e-02
I0515 06:54:08.605708 22392998065984 run_lib.py:146] step: 265850, training_loss: 6.25806e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:54:32.674793 22392998065984 run_lib.py:146] step: 265900, training_loss: 5.20680e-02
I0515 06:54:32.836405 22392998065984 run_lib.py:167] step: 265900, eval_loss: 4.58667e-02
I0515 06:54:57.111714 22392998065984 run_lib.py:146] step: 265950, training_loss: 7.32633e-02
I0515 06:55:21.391032 22392998065984 run_lib.py:146] step: 266000, training_loss: 6.02946e-02
I0515 06:55:21.554460 22392998065984 run_lib.py:167] step: 266000, eval_loss: 7.77638e-02
I0515 06:55:45.538927 22392998065984 run_lib.py:146] step: 266050, training_loss: 5.56982e-02
I0515 06:56:09.821208 22392998065984 run_lib.py:146] step: 266100, training_loss: 4.53425e-02
I0515 06:56:09.979866 22392998065984 run_lib.py:167] step: 266100, eval_loss: 4.75323e-02
I0515 06:56:34.193178 22392998065984 run_lib.py:146] step: 266150, training_loss: 6.90934e-02
I0515 06:56:58.071039 22392998065984 run_lib.py:146] step: 266200, training_loss: 5.32952e-02
I0515 06:56:58.233759 22392998065984 run_lib.py:167] step: 266200, eval_loss: 7.07514e-02
I0515 06:57:22.148648 22392998065984 run_lib.py:146] step: 266250, training_loss: 5.01360e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 06:57:46.869313 22392998065984 run_lib.py:146] step: 266300, training_loss: 4.86054e-02
I0515 06:57:47.046639 22392998065984 run_lib.py:167] step: 266300, eval_loss: 8.83636e-02
I0515 06:58:11.022089 22392998065984 run_lib.py:146] step: 266350, training_loss: 7.07631e-02
I0515 06:58:34.942730 22392998065984 run_lib.py:146] step: 266400, training_loss: 4.22305e-02
I0515 06:58:35.110841 22392998065984 run_lib.py:167] step: 266400, eval_loss: 5.79531e-02
I0515 06:58:59.676113 22392998065984 run_lib.py:146] step: 266450, training_loss: 6.10870e-02
I0515 06:59:23.596603 22392998065984 run_lib.py:146] step: 266500, training_loss: 7.80864e-02
I0515 06:59:23.755346 22392998065984 run_lib.py:167] step: 266500, eval_loss: 6.77906e-02
I0515 06:59:47.703334 22392998065984 run_lib.py:146] step: 266550, training_loss: 6.17995e-02
I0515 07:00:11.927372 22392998065984 run_lib.py:146] step: 266600, training_loss: 6.53377e-02
I0515 07:00:12.102023 22392998065984 run_lib.py:167] step: 266600, eval_loss: 7.42701e-02
I0515 07:00:36.295614 22392998065984 run_lib.py:146] step: 266650, training_loss: 6.04423e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:01:00.286428 22392998065984 run_lib.py:146] step: 266700, training_loss: 6.42848e-02
I0515 07:01:00.447742 22392998065984 run_lib.py:167] step: 266700, eval_loss: 6.61030e-02
I0515 07:01:24.790464 22392998065984 run_lib.py:146] step: 266750, training_loss: 5.48642e-02
I0515 07:01:49.074951 22392998065984 run_lib.py:146] step: 266800, training_loss: 5.96834e-02
I0515 07:01:49.233895 22392998065984 run_lib.py:167] step: 266800, eval_loss: 4.95825e-02
I0515 07:02:13.202730 22392998065984 run_lib.py:146] step: 266850, training_loss: 4.46521e-02
I0515 07:02:37.106313 22392998065984 run_lib.py:146] step: 266900, training_loss: 4.93616e-02
I0515 07:02:37.265399 22392998065984 run_lib.py:167] step: 266900, eval_loss: 6.11657e-02
I0515 07:03:01.774826 22392998065984 run_lib.py:146] step: 266950, training_loss: 6.66770e-02
I0515 07:03:25.805489 22392998065984 run_lib.py:146] step: 267000, training_loss: 6.46766e-02
I0515 07:03:25.963267 22392998065984 run_lib.py:167] step: 267000, eval_loss: 7.21197e-02
I0515 07:03:49.881558 22392998065984 run_lib.py:146] step: 267050, training_loss: 6.12059e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:04:14.770319 22392998065984 run_lib.py:146] step: 267100, training_loss: 5.77910e-02
I0515 07:04:14.929816 22392998065984 run_lib.py:167] step: 267100, eval_loss: 5.26374e-02
I0515 07:04:38.848345 22392998065984 run_lib.py:146] step: 267150, training_loss: 5.03664e-02
I0515 07:05:02.793576 22392998065984 run_lib.py:146] step: 267200, training_loss: 5.64057e-02
I0515 07:05:02.955373 22392998065984 run_lib.py:167] step: 267200, eval_loss: 5.17004e-02
I0515 07:05:27.231029 22392998065984 run_lib.py:146] step: 267250, training_loss: 8.20922e-02
I0515 07:05:51.459614 22392998065984 run_lib.py:146] step: 267300, training_loss: 6.31922e-02
I0515 07:05:51.644462 22392998065984 run_lib.py:167] step: 267300, eval_loss: 8.27020e-02
I0515 07:06:15.566491 22392998065984 run_lib.py:146] step: 267350, training_loss: 7.15816e-02
I0515 07:06:39.777158 22392998065984 run_lib.py:146] step: 267400, training_loss: 6.45225e-02
I0515 07:06:39.935401 22392998065984 run_lib.py:167] step: 267400, eval_loss: 5.04811e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:07:04.349387 22392998065984 run_lib.py:146] step: 267450, training_loss: 7.68850e-02
I0515 07:07:28.250368 22392998065984 run_lib.py:146] step: 267500, training_loss: 5.07290e-02
I0515 07:07:28.429271 22392998065984 run_lib.py:167] step: 267500, eval_loss: 6.49036e-02
I0515 07:07:52.780037 22392998065984 run_lib.py:146] step: 267550, training_loss: 5.01243e-02
I0515 07:08:17.037226 22392998065984 run_lib.py:146] step: 267600, training_loss: 6.47099e-02
I0515 07:08:17.200764 22392998065984 run_lib.py:167] step: 267600, eval_loss: 7.45739e-02
I0515 07:08:41.120303 22392998065984 run_lib.py:146] step: 267650, training_loss: 6.97860e-02
I0515 07:09:05.332394 22392998065984 run_lib.py:146] step: 267700, training_loss: 7.09624e-02
I0515 07:09:05.512215 22392998065984 run_lib.py:167] step: 267700, eval_loss: 5.20083e-02
I0515 07:09:29.707359 22392998065984 run_lib.py:146] step: 267750, training_loss: 4.62789e-02
I0515 07:09:53.599792 22392998065984 run_lib.py:146] step: 267800, training_loss: 4.75645e-02
I0515 07:09:53.758070 22392998065984 run_lib.py:167] step: 267800, eval_loss: 5.41119e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:10:17.913216 22392998065984 run_lib.py:146] step: 267850, training_loss: 4.60339e-02
I0515 07:10:42.555987 22392998065984 run_lib.py:146] step: 267900, training_loss: 6.96896e-02
I0515 07:10:42.720541 22392998065984 run_lib.py:167] step: 267900, eval_loss: 5.01917e-02
I0515 07:11:06.746497 22392998065984 run_lib.py:146] step: 267950, training_loss: 5.08635e-02
I0515 07:11:30.716805 22392998065984 run_lib.py:146] step: 268000, training_loss: 7.23101e-02
I0515 07:11:30.874933 22392998065984 run_lib.py:167] step: 268000, eval_loss: 6.68582e-02
I0515 07:11:55.281595 22392998065984 run_lib.py:146] step: 268050, training_loss: 5.30861e-02
I0515 07:12:19.522558 22392998065984 run_lib.py:146] step: 268100, training_loss: 5.69190e-02
I0515 07:12:19.680853 22392998065984 run_lib.py:167] step: 268100, eval_loss: 4.37536e-02
I0515 07:12:43.629824 22392998065984 run_lib.py:146] step: 268150, training_loss: 6.18567e-02
I0515 07:13:07.838429 22392998065984 run_lib.py:146] step: 268200, training_loss: 5.38959e-02
I0515 07:13:07.996767 22392998065984 run_lib.py:167] step: 268200, eval_loss: 4.69334e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:13:32.435282 22392998065984 run_lib.py:146] step: 268250, training_loss: 5.01690e-02
I0515 07:13:56.342521 22392998065984 run_lib.py:146] step: 268300, training_loss: 5.71602e-02
I0515 07:13:56.511121 22392998065984 run_lib.py:167] step: 268300, eval_loss: 5.96630e-02
I0515 07:14:20.777425 22392998065984 run_lib.py:146] step: 268350, training_loss: 5.71394e-02
I0515 07:14:45.076076 22392998065984 run_lib.py:146] step: 268400, training_loss: 6.39554e-02
I0515 07:14:45.234083 22392998065984 run_lib.py:167] step: 268400, eval_loss: 6.67998e-02
I0515 07:15:09.086866 22392998065984 run_lib.py:146] step: 268450, training_loss: 4.67552e-02
I0515 07:15:33.266571 22392998065984 run_lib.py:146] step: 268500, training_loss: 5.13868e-02
I0515 07:15:33.353456 22392998065984 run_lib.py:167] step: 268500, eval_loss: 9.09548e-02
I0515 07:15:57.660137 22392998065984 run_lib.py:146] step: 268550, training_loss: 4.97636e-02
I0515 07:16:21.579299 22392998065984 run_lib.py:146] step: 268600, training_loss: 6.52433e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:16:22.043941 22392998065984 run_lib.py:167] step: 268600, eval_loss: 6.36198e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:16:46.144003 22392998065984 run_lib.py:146] step: 268650, training_loss: 5.24548e-02
I0515 07:17:10.824419 22392998065984 run_lib.py:146] step: 268700, training_loss: 6.72965e-02
I0515 07:17:10.984490 22392998065984 run_lib.py:167] step: 268700, eval_loss: 5.36364e-02
I0515 07:17:34.982673 22392998065984 run_lib.py:146] step: 268750, training_loss: 8.33122e-02
I0515 07:17:58.948065 22392998065984 run_lib.py:146] step: 268800, training_loss: 5.59631e-02
I0515 07:17:59.115713 22392998065984 run_lib.py:167] step: 268800, eval_loss: 5.14101e-02
I0515 07:18:23.345955 22392998065984 run_lib.py:146] step: 268850, training_loss: 5.18212e-02
I0515 07:18:47.542361 22392998065984 run_lib.py:146] step: 268900, training_loss: 6.22968e-02
I0515 07:18:47.706073 22392998065984 run_lib.py:167] step: 268900, eval_loss: 7.61730e-02
I0515 07:19:11.630114 22392998065984 run_lib.py:146] step: 268950, training_loss: 6.95291e-02
I0515 07:19:35.914805 22392998065984 run_lib.py:146] step: 269000, training_loss: 5.93672e-02
I0515 07:19:36.080349 22392998065984 run_lib.py:167] step: 269000, eval_loss: 7.15639e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:20:00.563479 22392998065984 run_lib.py:146] step: 269050, training_loss: 6.15932e-02
I0515 07:20:24.514955 22392998065984 run_lib.py:146] step: 269100, training_loss: 4.77640e-02
I0515 07:20:24.675316 22392998065984 run_lib.py:167] step: 269100, eval_loss: 8.04009e-02
I0515 07:20:48.989019 22392998065984 run_lib.py:146] step: 269150, training_loss: 5.14129e-02
I0515 07:21:13.224510 22392998065984 run_lib.py:146] step: 269200, training_loss: 5.27285e-02
I0515 07:21:13.382123 22392998065984 run_lib.py:167] step: 269200, eval_loss: 5.94365e-02
I0515 07:21:37.297969 22392998065984 run_lib.py:146] step: 269250, training_loss: 4.25713e-02
I0515 07:22:01.553076 22392998065984 run_lib.py:146] step: 269300, training_loss: 4.81530e-02
I0515 07:22:01.720271 22392998065984 run_lib.py:167] step: 269300, eval_loss: 5.76963e-02
I0515 07:22:25.880532 22392998065984 run_lib.py:146] step: 269350, training_loss: 5.18641e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:22:50.021485 22392998065984 run_lib.py:146] step: 269400, training_loss: 5.60340e-02
I0515 07:22:50.181665 22392998065984 run_lib.py:167] step: 269400, eval_loss: 6.46647e-02
I0515 07:23:14.465785 22392998065984 run_lib.py:146] step: 269450, training_loss: 5.05492e-02
I0515 07:23:38.804792 22392998065984 run_lib.py:146] step: 269500, training_loss: 5.95076e-02
I0515 07:23:38.985739 22392998065984 run_lib.py:167] step: 269500, eval_loss: 6.15142e-02
I0515 07:24:03.107144 22392998065984 run_lib.py:146] step: 269550, training_loss: 5.41966e-02
I0515 07:24:27.013870 22392998065984 run_lib.py:146] step: 269600, training_loss: 5.61361e-02
I0515 07:24:27.172972 22392998065984 run_lib.py:167] step: 269600, eval_loss: 6.23575e-02
I0515 07:24:51.678074 22392998065984 run_lib.py:146] step: 269650, training_loss: 6.30127e-02
I0515 07:25:15.602141 22392998065984 run_lib.py:146] step: 269700, training_loss: 7.01904e-02
I0515 07:25:15.781546 22392998065984 run_lib.py:167] step: 269700, eval_loss: 6.65032e-02
I0515 07:25:39.703759 22392998065984 run_lib.py:146] step: 269750, training_loss: 5.54087e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:26:04.143040 22392998065984 run_lib.py:146] step: 269800, training_loss: 4.87022e-02
I0515 07:26:04.318696 22392998065984 run_lib.py:167] step: 269800, eval_loss: 6.68490e-02
I0515 07:26:28.656425 22392998065984 run_lib.py:146] step: 269850, training_loss: 6.21600e-02
I0515 07:26:52.598610 22392998065984 run_lib.py:146] step: 269900, training_loss: 5.50774e-02
I0515 07:26:52.756500 22392998065984 run_lib.py:167] step: 269900, eval_loss: 5.73775e-02
I0515 07:27:17.066328 22392998065984 run_lib.py:146] step: 269950, training_loss: 6.14182e-02
I0515 07:27:41.313533 22392998065984 run_lib.py:146] step: 270000, training_loss: 5.21569e-02
I0515 07:27:42.925841 22392998065984 run_lib.py:167] step: 270000, eval_loss: 6.59982e-02
I0515 07:28:08.316923 22392998065984 run_lib.py:146] step: 270050, training_loss: 5.98039e-02
I0515 07:28:32.879101 22392998065984 run_lib.py:146] step: 270100, training_loss: 6.80860e-02
I0515 07:28:33.046234 22392998065984 run_lib.py:167] step: 270100, eval_loss: 5.74481e-02
I0515 07:28:57.010584 22392998065984 run_lib.py:146] step: 270150, training_loss: 5.85504e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:29:21.138718 22392998065984 run_lib.py:146] step: 270200, training_loss: 6.61402e-02
I0515 07:29:21.307710 22392998065984 run_lib.py:167] step: 270200, eval_loss: 4.69880e-02
I0515 07:29:45.978376 22392998065984 run_lib.py:146] step: 270250, training_loss: 4.83667e-02
I0515 07:30:09.914215 22392998065984 run_lib.py:146] step: 270300, training_loss: 6.02132e-02
I0515 07:30:10.094604 22392998065984 run_lib.py:167] step: 270300, eval_loss: 5.30276e-02
I0515 07:30:34.023762 22392998065984 run_lib.py:146] step: 270350, training_loss: 5.75142e-02
I0515 07:30:58.243686 22392998065984 run_lib.py:146] step: 270400, training_loss: 7.12096e-02
I0515 07:30:58.423222 22392998065984 run_lib.py:167] step: 270400, eval_loss: 6.46761e-02
I0515 07:31:22.571936 22392998065984 run_lib.py:146] step: 270450, training_loss: 5.35176e-02
I0515 07:31:46.532773 22392998065984 run_lib.py:146] step: 270500, training_loss: 4.97086e-02
I0515 07:31:46.697263 22392998065984 run_lib.py:167] step: 270500, eval_loss: 8.01439e-02
I0515 07:32:10.654560 22392998065984 run_lib.py:146] step: 270550, training_loss: 5.79839e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:32:35.289430 22392998065984 run_lib.py:146] step: 270600, training_loss: 6.50194e-02
I0515 07:32:35.449012 22392998065984 run_lib.py:167] step: 270600, eval_loss: 5.72449e-02
I0515 07:32:59.451206 22392998065984 run_lib.py:146] step: 270650, training_loss: 5.74391e-02
I0515 07:33:23.335586 22392998065984 run_lib.py:146] step: 270700, training_loss: 5.58044e-02
I0515 07:33:23.498993 22392998065984 run_lib.py:167] step: 270700, eval_loss: 5.24188e-02
I0515 07:33:48.281668 22392998065984 run_lib.py:146] step: 270750, training_loss: 5.30412e-02
I0515 07:34:12.194966 22392998065984 run_lib.py:146] step: 270800, training_loss: 4.12042e-02
I0515 07:34:12.375702 22392998065984 run_lib.py:167] step: 270800, eval_loss: 6.12410e-02
I0515 07:34:36.324824 22392998065984 run_lib.py:146] step: 270850, training_loss: 7.02814e-02
I0515 07:35:00.946670 22392998065984 run_lib.py:146] step: 270900, training_loss: 5.22389e-02
I0515 07:35:01.104126 22392998065984 run_lib.py:167] step: 270900, eval_loss: 6.04654e-02
I0515 07:35:24.984535 22392998065984 run_lib.py:146] step: 270950, training_loss: 5.54670e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:35:49.086282 22392998065984 run_lib.py:146] step: 271000, training_loss: 5.01067e-02
I0515 07:35:49.246247 22392998065984 run_lib.py:167] step: 271000, eval_loss: 6.01829e-02
I0515 07:36:13.912954 22392998065984 run_lib.py:146] step: 271050, training_loss: 6.18015e-02
I0515 07:36:37.893891 22392998065984 run_lib.py:146] step: 271100, training_loss: 6.12463e-02
I0515 07:36:38.060819 22392998065984 run_lib.py:167] step: 271100, eval_loss: 4.93197e-02
I0515 07:37:01.972000 22392998065984 run_lib.py:146] step: 271150, training_loss: 5.27949e-02
I0515 07:37:26.470325 22392998065984 run_lib.py:146] step: 271200, training_loss: 4.08517e-02
I0515 07:37:26.637204 22392998065984 run_lib.py:167] step: 271200, eval_loss: 7.08978e-02
I0515 07:37:50.521693 22392998065984 run_lib.py:146] step: 271250, training_loss: 5.92123e-02
I0515 07:38:14.420604 22392998065984 run_lib.py:146] step: 271300, training_loss: 4.72664e-02
I0515 07:38:14.579131 22392998065984 run_lib.py:167] step: 271300, eval_loss: 6.25856e-02
I0515 07:38:38.793159 22392998065984 run_lib.py:146] step: 271350, training_loss: 4.19409e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:39:03.294701 22392998065984 run_lib.py:146] step: 271400, training_loss: 6.89406e-02
I0515 07:39:03.463171 22392998065984 run_lib.py:167] step: 271400, eval_loss: 4.60107e-02
I0515 07:39:27.405288 22392998065984 run_lib.py:146] step: 271450, training_loss: 5.28450e-02
I0515 07:39:51.378298 22392998065984 run_lib.py:146] step: 271500, training_loss: 6.07242e-02
I0515 07:39:51.545613 22392998065984 run_lib.py:167] step: 271500, eval_loss: 5.90681e-02
I0515 07:40:16.061149 22392998065984 run_lib.py:146] step: 271550, training_loss: 6.64859e-02
I0515 07:40:40.011052 22392998065984 run_lib.py:146] step: 271600, training_loss: 4.93815e-02
I0515 07:40:40.178133 22392998065984 run_lib.py:167] step: 271600, eval_loss: 6.55874e-02
I0515 07:41:04.131069 22392998065984 run_lib.py:146] step: 271650, training_loss: 5.52274e-02
I0515 07:41:28.743445 22392998065984 run_lib.py:146] step: 271700, training_loss: 5.42784e-02
I0515 07:41:28.923371 22392998065984 run_lib.py:167] step: 271700, eval_loss: 5.06819e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:41:53.016692 22392998065984 run_lib.py:146] step: 271750, training_loss: 5.79842e-02
I0515 07:42:16.999285 22392998065984 run_lib.py:146] step: 271800, training_loss: 4.95686e-02
I0515 07:42:17.171631 22392998065984 run_lib.py:167] step: 271800, eval_loss: 8.11922e-02
I0515 07:42:41.943664 22392998065984 run_lib.py:146] step: 271850, training_loss: 4.64000e-02
I0515 07:43:05.909786 22392998065984 run_lib.py:146] step: 271900, training_loss: 5.41060e-02
I0515 07:43:06.070365 22392998065984 run_lib.py:167] step: 271900, eval_loss: 5.59633e-02
I0515 07:43:30.036044 22392998065984 run_lib.py:146] step: 271950, training_loss: 4.23355e-02
I0515 07:43:54.679803 22392998065984 run_lib.py:146] step: 272000, training_loss: 6.05462e-02
I0515 07:43:54.837685 22392998065984 run_lib.py:167] step: 272000, eval_loss: 6.65542e-02
I0515 07:44:18.794941 22392998065984 run_lib.py:146] step: 272050, training_loss: 6.96365e-02
I0515 07:44:42.762189 22392998065984 run_lib.py:146] step: 272100, training_loss: 5.02545e-02
I0515 07:44:42.919796 22392998065984 run_lib.py:167] step: 272100, eval_loss: 5.90781e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:45:07.514349 22392998065984 run_lib.py:146] step: 272150, training_loss: 6.06988e-02
I0515 07:45:31.847004 22392998065984 run_lib.py:146] step: 272200, training_loss: 6.02228e-02
I0515 07:45:32.014269 22392998065984 run_lib.py:167] step: 272200, eval_loss: 5.85334e-02
I0515 07:45:55.942429 22392998065984 run_lib.py:146] step: 272250, training_loss: 5.49205e-02
I0515 07:46:19.848216 22392998065984 run_lib.py:146] step: 272300, training_loss: 6.43811e-02
I0515 07:46:20.006808 22392998065984 run_lib.py:167] step: 272300, eval_loss: 4.89315e-02
I0515 07:46:44.596183 22392998065984 run_lib.py:146] step: 272350, training_loss: 4.73475e-02
I0515 07:47:08.579715 22392998065984 run_lib.py:146] step: 272400, training_loss: 4.33107e-02
I0515 07:47:08.746998 22392998065984 run_lib.py:167] step: 272400, eval_loss: 5.18932e-02
I0515 07:47:32.699130 22392998065984 run_lib.py:146] step: 272450, training_loss: 5.67897e-02
I0515 07:47:57.195031 22392998065984 run_lib.py:146] step: 272500, training_loss: 5.27230e-02
I0515 07:47:57.352974 22392998065984 run_lib.py:167] step: 272500, eval_loss: 5.69721e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:48:21.456407 22392998065984 run_lib.py:146] step: 272550, training_loss: 5.64117e-02
I0515 07:48:45.273830 22392998065984 run_lib.py:146] step: 272600, training_loss: 7.60567e-02
I0515 07:48:45.442369 22392998065984 run_lib.py:167] step: 272600, eval_loss: 5.32360e-02
I0515 07:49:10.145241 22392998065984 run_lib.py:146] step: 272650, training_loss: 6.00473e-02
I0515 07:49:33.968394 22392998065984 run_lib.py:146] step: 272700, training_loss: 5.93593e-02
I0515 07:49:34.126181 22392998065984 run_lib.py:167] step: 272700, eval_loss: 6.18135e-02
I0515 07:49:57.999926 22392998065984 run_lib.py:146] step: 272750, training_loss: 6.06251e-02
I0515 07:50:22.580898 22392998065984 run_lib.py:146] step: 272800, training_loss: 5.50055e-02
I0515 07:50:22.751837 22392998065984 run_lib.py:167] step: 272800, eval_loss: 4.80151e-02
I0515 07:50:46.671952 22392998065984 run_lib.py:146] step: 272850, training_loss: 5.82451e-02
I0515 07:51:10.588754 22392998065984 run_lib.py:146] step: 272900, training_loss: 4.42148e-02
I0515 07:51:10.747259 22392998065984 run_lib.py:167] step: 272900, eval_loss: 6.60142e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:51:35.208023 22392998065984 run_lib.py:146] step: 272950, training_loss: 5.53569e-02
I0515 07:51:59.484688 22392998065984 run_lib.py:146] step: 273000, training_loss: 5.05104e-02
I0515 07:51:59.643807 22392998065984 run_lib.py:167] step: 273000, eval_loss: 6.27190e-02
I0515 07:52:23.562319 22392998065984 run_lib.py:146] step: 273050, training_loss: 5.48217e-02
I0515 07:52:47.507235 22392998065984 run_lib.py:146] step: 273100, training_loss: 7.67259e-02
I0515 07:52:47.665873 22392998065984 run_lib.py:167] step: 273100, eval_loss: 5.67985e-02
I0515 07:53:12.296516 22392998065984 run_lib.py:146] step: 273150, training_loss: 5.59018e-02
I0515 07:53:36.212615 22392998065984 run_lib.py:146] step: 273200, training_loss: 6.82748e-02
I0515 07:53:36.376185 22392998065984 run_lib.py:167] step: 273200, eval_loss: 5.78554e-02
I0515 07:54:00.274670 22392998065984 run_lib.py:146] step: 273250, training_loss: 5.21471e-02
I0515 07:54:24.788694 22392998065984 run_lib.py:146] step: 273300, training_loss: 5.37086e-02
I0515 07:54:24.947006 22392998065984 run_lib.py:167] step: 273300, eval_loss: 7.30663e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:54:49.036681 22392998065984 run_lib.py:146] step: 273350, training_loss: 6.75241e-02
I0515 07:55:13.082024 22392998065984 run_lib.py:146] step: 273400, training_loss: 4.03598e-02
I0515 07:55:13.247088 22392998065984 run_lib.py:167] step: 273400, eval_loss: 4.90166e-02
I0515 07:55:37.933529 22392998065984 run_lib.py:146] step: 273450, training_loss: 6.75451e-02
I0515 07:56:01.877034 22392998065984 run_lib.py:146] step: 273500, training_loss: 5.49641e-02
I0515 07:56:02.035567 22392998065984 run_lib.py:167] step: 273500, eval_loss: 6.23891e-02
I0515 07:56:25.958509 22392998065984 run_lib.py:146] step: 273550, training_loss: 6.14130e-02
I0515 07:56:50.555046 22392998065984 run_lib.py:146] step: 273600, training_loss: 4.77449e-02
I0515 07:56:50.722327 22392998065984 run_lib.py:167] step: 273600, eval_loss: 6.45909e-02
I0515 07:57:14.618961 22392998065984 run_lib.py:146] step: 273650, training_loss: 4.83793e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 07:57:38.747355 22392998065984 run_lib.py:146] step: 273700, training_loss: 7.32765e-02
I0515 07:57:38.910897 22392998065984 run_lib.py:167] step: 273700, eval_loss: 6.23660e-02
I0515 07:58:03.318470 22392998065984 run_lib.py:146] step: 273750, training_loss: 6.17330e-02
I0515 07:58:27.646666 22392998065984 run_lib.py:146] step: 273800, training_loss: 5.03720e-02
I0515 07:58:27.805372 22392998065984 run_lib.py:167] step: 273800, eval_loss: 5.49574e-02
I0515 07:58:51.906897 22392998065984 run_lib.py:146] step: 273850, training_loss: 5.89916e-02
I0515 07:59:15.901337 22392998065984 run_lib.py:146] step: 273900, training_loss: 6.69016e-02
I0515 07:59:16.068895 22392998065984 run_lib.py:167] step: 273900, eval_loss: 7.30346e-02
I0515 07:59:40.559343 22392998065984 run_lib.py:146] step: 273950, training_loss: 5.68786e-02
I0515 08:00:04.498837 22392998065984 run_lib.py:146] step: 274000, training_loss: 5.58935e-02
I0515 08:00:04.657861 22392998065984 run_lib.py:167] step: 274000, eval_loss: 4.87032e-02
I0515 08:00:28.584468 22392998065984 run_lib.py:146] step: 274050, training_loss: 6.47733e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:00:53.205952 22392998065984 run_lib.py:146] step: 274100, training_loss: 4.18588e-02
I0515 08:00:53.366298 22392998065984 run_lib.py:167] step: 274100, eval_loss: 5.79452e-02
I0515 08:01:17.308533 22392998065984 run_lib.py:146] step: 274150, training_loss: 5.37142e-02
I0515 08:01:41.305663 22392998065984 run_lib.py:146] step: 274200, training_loss: 6.73465e-02
I0515 08:01:41.481326 22392998065984 run_lib.py:167] step: 274200, eval_loss: 5.26097e-02
I0515 08:02:06.064344 22392998065984 run_lib.py:146] step: 274250, training_loss: 5.17114e-02
I0515 08:02:29.987270 22392998065984 run_lib.py:146] step: 274300, training_loss: 6.99240e-02
I0515 08:02:30.144666 22392998065984 run_lib.py:167] step: 274300, eval_loss: 7.29504e-02
I0515 08:02:54.114710 22392998065984 run_lib.py:146] step: 274350, training_loss: 6.39795e-02
I0515 08:03:18.653237 22392998065984 run_lib.py:146] step: 274400, training_loss: 6.69509e-02
I0515 08:03:18.820239 22392998065984 run_lib.py:167] step: 274400, eval_loss: 6.96715e-02
I0515 08:03:42.728506 22392998065984 run_lib.py:146] step: 274450, training_loss: 6.39456e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:04:06.847578 22392998065984 run_lib.py:146] step: 274500, training_loss: 8.09371e-02
I0515 08:04:07.016591 22392998065984 run_lib.py:167] step: 274500, eval_loss: 4.36246e-02
I0515 08:04:31.687455 22392998065984 run_lib.py:146] step: 274550, training_loss: 5.53295e-02
I0515 08:04:55.670212 22392998065984 run_lib.py:146] step: 274600, training_loss: 5.85866e-02
I0515 08:04:55.838511 22392998065984 run_lib.py:167] step: 274600, eval_loss: 4.44867e-02
I0515 08:05:19.787511 22392998065984 run_lib.py:146] step: 274650, training_loss: 7.15798e-02
I0515 08:05:44.003491 22392998065984 run_lib.py:146] step: 274700, training_loss: 5.34924e-02
I0515 08:05:44.161654 22392998065984 run_lib.py:167] step: 274700, eval_loss: 7.24639e-02
I0515 08:06:08.377431 22392998065984 run_lib.py:146] step: 274750, training_loss: 6.97998e-02
I0515 08:06:32.316881 22392998065984 run_lib.py:146] step: 274800, training_loss: 6.85821e-02
I0515 08:06:32.475423 22392998065984 run_lib.py:167] step: 274800, eval_loss: 6.80838e-02
I0515 08:06:56.419631 22392998065984 run_lib.py:146] step: 274850, training_loss: 6.02591e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:07:21.020892 22392998065984 run_lib.py:146] step: 274900, training_loss: 4.38697e-02
I0515 08:07:21.180552 22392998065984 run_lib.py:167] step: 274900, eval_loss: 5.97468e-02
I0515 08:07:45.059527 22392998065984 run_lib.py:146] step: 274950, training_loss: 5.65069e-02
I0515 08:08:09.028608 22392998065984 run_lib.py:146] step: 275000, training_loss: 6.25397e-02
I0515 08:08:09.208537 22392998065984 run_lib.py:167] step: 275000, eval_loss: 5.78980e-02
I0515 08:08:33.803941 22392998065984 run_lib.py:146] step: 275050, training_loss: 6.15982e-02
I0515 08:08:57.681288 22392998065984 run_lib.py:146] step: 275100, training_loss: 4.65695e-02
I0515 08:08:57.839307 22392998065984 run_lib.py:167] step: 275100, eval_loss: 4.51157e-02
I0515 08:09:21.712094 22392998065984 run_lib.py:146] step: 275150, training_loss: 4.45942e-02
I0515 08:09:46.214033 22392998065984 run_lib.py:146] step: 275200, training_loss: 4.72030e-02
I0515 08:09:46.393140 22392998065984 run_lib.py:167] step: 275200, eval_loss: 5.69349e-02
I0515 08:10:10.266179 22392998065984 run_lib.py:146] step: 275250, training_loss: 4.54339e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:10:34.396907 22392998065984 run_lib.py:146] step: 275300, training_loss: 6.56702e-02
I0515 08:10:34.556895 22392998065984 run_lib.py:167] step: 275300, eval_loss: 5.96818e-02
I0515 08:10:58.786840 22392998065984 run_lib.py:146] step: 275350, training_loss: 5.74756e-02
I0515 08:11:22.953369 22392998065984 run_lib.py:146] step: 275400, training_loss: 5.30560e-02
I0515 08:11:23.111377 22392998065984 run_lib.py:167] step: 275400, eval_loss: 4.78126e-02
I0515 08:11:47.013165 22392998065984 run_lib.py:146] step: 275450, training_loss: 6.76390e-02
I0515 08:12:11.217945 22392998065984 run_lib.py:146] step: 275500, training_loss: 5.80704e-02
I0515 08:12:11.375324 22392998065984 run_lib.py:167] step: 275500, eval_loss: 6.56084e-02
I0515 08:12:35.767852 22392998065984 run_lib.py:146] step: 275550, training_loss: 5.44794e-02
I0515 08:12:59.690718 22392998065984 run_lib.py:146] step: 275600, training_loss: 6.34920e-02
I0515 08:12:59.857922 22392998065984 run_lib.py:167] step: 275600, eval_loss: 6.37473e-02
I0515 08:13:23.759617 22392998065984 run_lib.py:146] step: 275650, training_loss: 5.05408e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:13:48.577857 22392998065984 run_lib.py:146] step: 275700, training_loss: 8.96675e-02
I0515 08:13:48.737887 22392998065984 run_lib.py:167] step: 275700, eval_loss: 6.51154e-02
I0515 08:14:12.693298 22392998065984 run_lib.py:146] step: 275750, training_loss: 6.22932e-02
I0515 08:14:36.721606 22392998065984 run_lib.py:146] step: 275800, training_loss: 5.30525e-02
I0515 08:14:36.898787 22392998065984 run_lib.py:167] step: 275800, eval_loss: 6.56568e-02
I0515 08:15:01.497895 22392998065984 run_lib.py:146] step: 275850, training_loss: 6.86313e-02
I0515 08:15:25.494954 22392998065984 run_lib.py:146] step: 275900, training_loss: 6.39675e-02
I0515 08:15:25.662706 22392998065984 run_lib.py:167] step: 275900, eval_loss: 5.20631e-02
I0515 08:15:49.563225 22392998065984 run_lib.py:146] step: 275950, training_loss: 4.91130e-02
I0515 08:16:14.078177 22392998065984 run_lib.py:146] step: 276000, training_loss: 5.62209e-02
I0515 08:16:14.251084 22392998065984 run_lib.py:167] step: 276000, eval_loss: 3.80163e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:16:38.327155 22392998065984 run_lib.py:146] step: 276050, training_loss: 6.77195e-02
I0515 08:17:02.331311 22392998065984 run_lib.py:146] step: 276100, training_loss: 5.59659e-02
I0515 08:17:02.491822 22392998065984 run_lib.py:167] step: 276100, eval_loss: 5.31752e-02
I0515 08:17:26.853487 22392998065984 run_lib.py:146] step: 276150, training_loss: 6.65211e-02
I0515 08:17:51.129309 22392998065984 run_lib.py:146] step: 276200, training_loss: 4.95078e-02
I0515 08:17:51.298331 22392998065984 run_lib.py:167] step: 276200, eval_loss: 5.49730e-02
I0515 08:18:15.259951 22392998065984 run_lib.py:146] step: 276250, training_loss: 5.26195e-02
I0515 08:18:39.507631 22392998065984 run_lib.py:146] step: 276300, training_loss: 6.53608e-02
I0515 08:18:39.673571 22392998065984 run_lib.py:167] step: 276300, eval_loss: 6.82097e-02
I0515 08:19:03.924263 22392998065984 run_lib.py:146] step: 276350, training_loss: 6.31477e-02
I0515 08:19:27.937818 22392998065984 run_lib.py:146] step: 276400, training_loss: 5.97772e-02
I0515 08:19:28.043056 22392998065984 run_lib.py:167] step: 276400, eval_loss: 8.74710e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:19:52.521099 22392998065984 run_lib.py:146] step: 276450, training_loss: 6.65610e-02
I0515 08:20:16.913514 22392998065984 run_lib.py:146] step: 276500, training_loss: 4.07739e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:20:17.363570 22392998065984 run_lib.py:167] step: 276500, eval_loss: 6.10402e-02
I0515 08:20:41.371340 22392998065984 run_lib.py:146] step: 276550, training_loss: 4.70262e-02
I0515 08:21:05.324257 22392998065984 run_lib.py:146] step: 276600, training_loss: 4.61035e-02
I0515 08:21:05.504376 22392998065984 run_lib.py:167] step: 276600, eval_loss: 6.91489e-02
I0515 08:21:30.138546 22392998065984 run_lib.py:146] step: 276650, training_loss: 5.41100e-02
I0515 08:21:54.072210 22392998065984 run_lib.py:146] step: 276700, training_loss: 7.70160e-02
I0515 08:21:54.252003 22392998065984 run_lib.py:167] step: 276700, eval_loss: 7.19801e-02
I0515 08:22:18.190961 22392998065984 run_lib.py:146] step: 276750, training_loss: 8.47122e-02
I0515 08:22:42.389040 22392998065984 run_lib.py:146] step: 276800, training_loss: 7.67207e-02
I0515 08:22:42.547310 22392998065984 run_lib.py:167] step: 276800, eval_loss: 5.80454e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:23:06.946990 22392998065984 run_lib.py:146] step: 276850, training_loss: 5.09277e-02
I0515 08:23:30.774351 22392998065984 run_lib.py:146] step: 276900, training_loss: 5.41731e-02
I0515 08:23:30.934872 22392998065984 run_lib.py:167] step: 276900, eval_loss: 5.01070e-02
I0515 08:23:55.399005 22392998065984 run_lib.py:146] step: 276950, training_loss: 4.56931e-02
I0515 08:24:19.586426 22392998065984 run_lib.py:146] step: 277000, training_loss: 6.33248e-02
I0515 08:24:19.745288 22392998065984 run_lib.py:167] step: 277000, eval_loss: 7.01729e-02
I0515 08:24:43.657896 22392998065984 run_lib.py:146] step: 277050, training_loss: 6.26276e-02
I0515 08:25:07.991199 22392998065984 run_lib.py:146] step: 277100, training_loss: 6.81522e-02
I0515 08:25:08.148597 22392998065984 run_lib.py:167] step: 277100, eval_loss: 4.43576e-02
I0515 08:25:32.362535 22392998065984 run_lib.py:146] step: 277150, training_loss: 5.69299e-02
I0515 08:25:56.269895 22392998065984 run_lib.py:146] step: 277200, training_loss: 6.41345e-02
I0515 08:25:56.430343 22392998065984 run_lib.py:167] step: 277200, eval_loss: 5.62320e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:26:20.870929 22392998065984 run_lib.py:146] step: 277250, training_loss: 6.34763e-02
I0515 08:26:45.186562 22392998065984 run_lib.py:146] step: 277300, training_loss: 7.52242e-02
I0515 08:26:45.352706 22392998065984 run_lib.py:167] step: 277300, eval_loss: 6.35262e-02
I0515 08:27:09.244346 22392998065984 run_lib.py:146] step: 277350, training_loss: 5.50943e-02
I0515 08:27:33.117333 22392998065984 run_lib.py:146] step: 277400, training_loss: 6.51271e-02
I0515 08:27:33.275259 22392998065984 run_lib.py:167] step: 277400, eval_loss: 4.79915e-02
I0515 08:27:57.795546 22392998065984 run_lib.py:146] step: 277450, training_loss: 6.09467e-02
I0515 08:28:21.706594 22392998065984 run_lib.py:146] step: 277500, training_loss: 6.92821e-02
I0515 08:28:21.870193 22392998065984 run_lib.py:167] step: 277500, eval_loss: 6.76163e-02
I0515 08:28:45.768362 22392998065984 run_lib.py:146] step: 277550, training_loss: 5.75269e-02
I0515 08:29:09.941405 22392998065984 run_lib.py:146] step: 277600, training_loss: 5.35418e-02
I0515 08:29:10.116265 22392998065984 run_lib.py:167] step: 277600, eval_loss: 6.72460e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:29:34.525776 22392998065984 run_lib.py:146] step: 277650, training_loss: 5.52689e-02
I0515 08:29:58.430338 22392998065984 run_lib.py:146] step: 277700, training_loss: 6.52482e-02
I0515 08:29:58.595432 22392998065984 run_lib.py:167] step: 277700, eval_loss: 6.06089e-02
I0515 08:30:22.839673 22392998065984 run_lib.py:146] step: 277750, training_loss: 5.59743e-02
I0515 08:30:47.161349 22392998065984 run_lib.py:146] step: 277800, training_loss: 7.45834e-02
I0515 08:30:47.320278 22392998065984 run_lib.py:167] step: 277800, eval_loss: 5.61185e-02
I0515 08:31:11.319276 22392998065984 run_lib.py:146] step: 277850, training_loss: 5.91998e-02
I0515 08:31:35.565572 22392998065984 run_lib.py:146] step: 277900, training_loss: 6.18001e-02
I0515 08:31:35.725094 22392998065984 run_lib.py:167] step: 277900, eval_loss: 4.61861e-02
I0515 08:31:59.934287 22392998065984 run_lib.py:146] step: 277950, training_loss: 5.40514e-02
I0515 08:32:23.708873 22392998065984 run_lib.py:146] step: 278000, training_loss: 4.46967e-02
I0515 08:32:23.876032 22392998065984 run_lib.py:167] step: 278000, eval_loss: 4.41239e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:32:48.436624 22392998065984 run_lib.py:146] step: 278050, training_loss: 5.81268e-02
I0515 08:33:12.779953 22392998065984 run_lib.py:146] step: 278100, training_loss: 4.95024e-02
I0515 08:33:12.947612 22392998065984 run_lib.py:167] step: 278100, eval_loss: 6.92572e-02
I0515 08:33:36.885279 22392998065984 run_lib.py:146] step: 278150, training_loss: 6.24623e-02
I0515 08:34:00.839495 22392998065984 run_lib.py:146] step: 278200, training_loss: 6.21081e-02
I0515 08:34:01.002992 22392998065984 run_lib.py:167] step: 278200, eval_loss: 6.18875e-02
I0515 08:34:25.539279 22392998065984 run_lib.py:146] step: 278250, training_loss: 4.60010e-02
I0515 08:34:49.502789 22392998065984 run_lib.py:146] step: 278300, training_loss: 5.82591e-02
I0515 08:34:49.666668 22392998065984 run_lib.py:167] step: 278300, eval_loss: 4.95726e-02
I0515 08:35:13.626503 22392998065984 run_lib.py:146] step: 278350, training_loss: 4.45065e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:35:38.484317 22392998065984 run_lib.py:146] step: 278400, training_loss: 7.71814e-02
I0515 08:35:38.644907 22392998065984 run_lib.py:167] step: 278400, eval_loss: 5.49620e-02
I0515 08:36:02.632648 22392998065984 run_lib.py:146] step: 278450, training_loss: 6.04874e-02
I0515 08:36:26.551772 22392998065984 run_lib.py:146] step: 278500, training_loss: 3.31772e-02
I0515 08:36:26.730700 22392998065984 run_lib.py:167] step: 278500, eval_loss: 5.80814e-02
I0515 08:36:51.056357 22392998065984 run_lib.py:146] step: 278550, training_loss: 6.65391e-02
I0515 08:37:15.446323 22392998065984 run_lib.py:146] step: 278600, training_loss: 6.73837e-02
I0515 08:37:15.604669 22392998065984 run_lib.py:167] step: 278600, eval_loss: 4.87918e-02
I0515 08:37:39.558354 22392998065984 run_lib.py:146] step: 278650, training_loss: 5.53776e-02
I0515 08:38:03.804904 22392998065984 run_lib.py:146] step: 278700, training_loss: 5.72468e-02
I0515 08:38:03.972689 22392998065984 run_lib.py:167] step: 278700, eval_loss: 5.87711e-02
I0515 08:38:28.217681 22392998065984 run_lib.py:146] step: 278750, training_loss: 5.70816e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:38:52.328688 22392998065984 run_lib.py:146] step: 278800, training_loss: 6.12155e-02
I0515 08:38:52.497752 22392998065984 run_lib.py:167] step: 278800, eval_loss: 7.33858e-02
I0515 08:39:16.663302 22392998065984 run_lib.py:146] step: 278850, training_loss: 5.18060e-02
I0515 08:39:40.697611 22392998065984 run_lib.py:146] step: 278900, training_loss: 4.99559e-02
I0515 08:39:40.855613 22392998065984 run_lib.py:167] step: 278900, eval_loss: 6.41462e-02
I0515 08:40:04.781588 22392998065984 run_lib.py:146] step: 278950, training_loss: 6.06763e-02
I0515 08:40:28.700099 22392998065984 run_lib.py:146] step: 279000, training_loss: 6.27157e-02
I0515 08:40:28.859006 22392998065984 run_lib.py:167] step: 279000, eval_loss: 5.68513e-02
I0515 08:40:53.468976 22392998065984 run_lib.py:146] step: 279050, training_loss: 5.71008e-02
I0515 08:41:17.393855 22392998065984 run_lib.py:146] step: 279100, training_loss: 4.76524e-02
I0515 08:41:17.561386 22392998065984 run_lib.py:167] step: 279100, eval_loss: 6.50473e-02
I0515 08:41:41.450678 22392998065984 run_lib.py:146] step: 279150, training_loss: 6.41637e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:42:06.326500 22392998065984 run_lib.py:146] step: 279200, training_loss: 5.49303e-02
I0515 08:42:06.496504 22392998065984 run_lib.py:167] step: 279200, eval_loss: 5.87448e-02
I0515 08:42:30.400432 22392998065984 run_lib.py:146] step: 279250, training_loss: 5.53014e-02
I0515 08:42:54.340899 22392998065984 run_lib.py:146] step: 279300, training_loss: 5.48178e-02
I0515 08:42:54.503523 22392998065984 run_lib.py:167] step: 279300, eval_loss: 4.55121e-02
I0515 08:43:18.721046 22392998065984 run_lib.py:146] step: 279350, training_loss: 4.97041e-02
I0515 08:43:42.957048 22392998065984 run_lib.py:146] step: 279400, training_loss: 6.41850e-02
I0515 08:43:43.116439 22392998065984 run_lib.py:167] step: 279400, eval_loss: 6.17021e-02
I0515 08:44:07.033727 22392998065984 run_lib.py:146] step: 279450, training_loss: 4.79009e-02
I0515 08:44:31.219055 22392998065984 run_lib.py:146] step: 279500, training_loss: 5.23500e-02
I0515 08:44:31.393928 22392998065984 run_lib.py:167] step: 279500, eval_loss: 6.56096e-02
I0515 08:44:55.555259 22392998065984 run_lib.py:146] step: 279550, training_loss: 6.78997e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:45:19.693407 22392998065984 run_lib.py:146] step: 279600, training_loss: 5.53681e-02
I0515 08:45:19.858268 22392998065984 run_lib.py:167] step: 279600, eval_loss: 5.94263e-02
I0515 08:45:44.217679 22392998065984 run_lib.py:146] step: 279650, training_loss: 5.38481e-02
I0515 08:46:08.645791 22392998065984 run_lib.py:146] step: 279700, training_loss: 5.90516e-02
I0515 08:46:08.813787 22392998065984 run_lib.py:167] step: 279700, eval_loss: 5.74376e-02
I0515 08:46:32.720610 22392998065984 run_lib.py:146] step: 279750, training_loss: 6.75709e-02
I0515 08:46:56.637536 22392998065984 run_lib.py:146] step: 279800, training_loss: 5.75867e-02
I0515 08:46:56.795641 22392998065984 run_lib.py:167] step: 279800, eval_loss: 6.60961e-02
I0515 08:47:21.414637 22392998065984 run_lib.py:146] step: 279850, training_loss: 5.16650e-02
I0515 08:47:45.322277 22392998065984 run_lib.py:146] step: 279900, training_loss: 5.31727e-02
I0515 08:47:45.480811 22392998065984 run_lib.py:167] step: 279900, eval_loss: 5.89829e-02
I0515 08:48:09.439114 22392998065984 run_lib.py:146] step: 279950, training_loss: 6.70263e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:48:34.489744 22392998065984 run_lib.py:146] step: 280000, training_loss: 8.56018e-02
I0515 08:48:36.196804 22392998065984 run_lib.py:167] step: 280000, eval_loss: 5.83846e-02
I0515 08:49:01.684997 22392998065984 run_lib.py:146] step: 280050, training_loss: 6.56659e-02
I0515 08:49:25.913593 22392998065984 run_lib.py:146] step: 280100, training_loss: 6.72547e-02
I0515 08:49:26.077340 22392998065984 run_lib.py:167] step: 280100, eval_loss: 5.77439e-02
I0515 08:49:49.983690 22392998065984 run_lib.py:146] step: 280150, training_loss: 5.77031e-02
I0515 08:50:14.221090 22392998065984 run_lib.py:146] step: 280200, training_loss: 6.01115e-02
I0515 08:50:14.384344 22392998065984 run_lib.py:167] step: 280200, eval_loss: 4.99462e-02
I0515 08:50:38.581635 22392998065984 run_lib.py:146] step: 280250, training_loss: 6.06960e-02
I0515 08:51:02.490263 22392998065984 run_lib.py:146] step: 280300, training_loss: 5.62619e-02
I0515 08:51:02.666879 22392998065984 run_lib.py:167] step: 280300, eval_loss: 5.18743e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:51:27.031460 22392998065984 run_lib.py:146] step: 280350, training_loss: 5.06628e-02
I0515 08:51:51.278587 22392998065984 run_lib.py:146] step: 280400, training_loss: 6.25105e-02
I0515 08:51:51.454621 22392998065984 run_lib.py:167] step: 280400, eval_loss: 4.93773e-02
I0515 08:52:15.385296 22392998065984 run_lib.py:146] step: 280450, training_loss: 5.56226e-02
I0515 08:52:39.693145 22392998065984 run_lib.py:146] step: 280500, training_loss: 5.27175e-02
I0515 08:52:39.866604 22392998065984 run_lib.py:167] step: 280500, eval_loss: 5.48726e-02
I0515 08:53:04.072630 22392998065984 run_lib.py:146] step: 280550, training_loss: 5.74166e-02
I0515 08:53:28.013461 22392998065984 run_lib.py:146] step: 280600, training_loss: 6.65745e-02
I0515 08:53:28.185106 22392998065984 run_lib.py:167] step: 280600, eval_loss: 5.20906e-02
I0515 08:53:52.386796 22392998065984 run_lib.py:146] step: 280650, training_loss: 5.95415e-02
I0515 08:54:16.321426 22392998065984 run_lib.py:146] step: 280700, training_loss: 5.30271e-02
I0515 08:54:16.479737 22392998065984 run_lib.py:167] step: 280700, eval_loss: 6.88979e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:54:40.832248 22392998065984 run_lib.py:146] step: 280750, training_loss: 5.22180e-02
I0515 08:55:05.100077 22392998065984 run_lib.py:146] step: 280800, training_loss: 6.97185e-02
I0515 08:55:05.259905 22392998065984 run_lib.py:167] step: 280800, eval_loss: 6.08003e-02
I0515 08:55:29.241516 22392998065984 run_lib.py:146] step: 280850, training_loss: 5.84520e-02
I0515 08:55:53.519751 22392998065984 run_lib.py:146] step: 280900, training_loss: 6.45120e-02
I0515 08:55:53.678061 22392998065984 run_lib.py:167] step: 280900, eval_loss: 6.35117e-02
I0515 08:56:17.588150 22392998065984 run_lib.py:146] step: 280950, training_loss: 5.04545e-02
I0515 08:56:41.786192 22392998065984 run_lib.py:146] step: 281000, training_loss: 6.05972e-02
I0515 08:56:41.944762 22392998065984 run_lib.py:167] step: 281000, eval_loss: 4.35626e-02
I0515 08:57:06.175903 22392998065984 run_lib.py:146] step: 281050, training_loss: 6.80356e-02
I0515 08:57:30.089213 22392998065984 run_lib.py:146] step: 281100, training_loss: 5.12806e-02
I0515 08:57:30.256796 22392998065984 run_lib.py:167] step: 281100, eval_loss: 6.32372e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 08:57:54.620582 22392998065984 run_lib.py:146] step: 281150, training_loss: 6.57751e-02
I0515 08:58:18.916674 22392998065984 run_lib.py:146] step: 281200, training_loss: 5.81992e-02
I0515 08:58:19.084002 22392998065984 run_lib.py:167] step: 281200, eval_loss: 6.91879e-02
I0515 08:58:43.093051 22392998065984 run_lib.py:146] step: 281250, training_loss: 5.51234e-02
I0515 08:59:07.377207 22392998065984 run_lib.py:146] step: 281300, training_loss: 4.31649e-02
I0515 08:59:07.535231 22392998065984 run_lib.py:167] step: 281300, eval_loss: 4.69710e-02
I0515 08:59:31.755597 22392998065984 run_lib.py:146] step: 281350, training_loss: 5.21273e-02
I0515 08:59:55.634401 22392998065984 run_lib.py:146] step: 281400, training_loss: 5.40995e-02
I0515 08:59:55.793085 22392998065984 run_lib.py:167] step: 281400, eval_loss: 6.45404e-02
I0515 09:00:20.046778 22392998065984 run_lib.py:146] step: 281450, training_loss: 5.79690e-02
I0515 09:00:43.966437 22392998065984 run_lib.py:146] step: 281500, training_loss: 5.26239e-02
I0515 09:00:44.157523 22392998065984 run_lib.py:167] step: 281500, eval_loss: 5.72013e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:01:08.556818 22392998065984 run_lib.py:146] step: 281550, training_loss: 5.48876e-02
I0515 09:01:32.814878 22392998065984 run_lib.py:146] step: 281600, training_loss: 5.79058e-02
I0515 09:01:32.979854 22392998065984 run_lib.py:167] step: 281600, eval_loss: 6.31184e-02
I0515 09:01:56.978225 22392998065984 run_lib.py:146] step: 281650, training_loss: 4.94453e-02
I0515 09:02:21.287873 22392998065984 run_lib.py:146] step: 281700, training_loss: 5.95541e-02
I0515 09:02:21.456043 22392998065984 run_lib.py:167] step: 281700, eval_loss: 6.50600e-02
I0515 09:02:45.358752 22392998065984 run_lib.py:146] step: 281750, training_loss: 5.87091e-02
I0515 09:03:09.525656 22392998065984 run_lib.py:146] step: 281800, training_loss: 6.12705e-02
I0515 09:03:09.684341 22392998065984 run_lib.py:167] step: 281800, eval_loss: 5.95738e-02
I0515 09:03:33.884454 22392998065984 run_lib.py:146] step: 281850, training_loss: 6.36837e-02
I0515 09:03:57.814025 22392998065984 run_lib.py:146] step: 281900, training_loss: 5.50607e-02
I0515 09:03:57.981310 22392998065984 run_lib.py:167] step: 281900, eval_loss: 5.04671e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:04:22.333454 22392998065984 run_lib.py:146] step: 281950, training_loss: 8.17590e-02
I0515 09:04:46.601211 22392998065984 run_lib.py:146] step: 282000, training_loss: 5.20831e-02
I0515 09:04:46.768356 22392998065984 run_lib.py:167] step: 282000, eval_loss: 6.73694e-02
I0515 09:05:10.811468 22392998065984 run_lib.py:146] step: 282050, training_loss: 6.42075e-02
I0515 09:05:35.048196 22392998065984 run_lib.py:146] step: 282100, training_loss: 6.70365e-02
I0515 09:05:35.208320 22392998065984 run_lib.py:167] step: 282100, eval_loss: 6.03624e-02
I0515 09:05:59.519943 22392998065984 run_lib.py:146] step: 282150, training_loss: 4.12205e-02
I0515 09:06:23.402654 22392998065984 run_lib.py:146] step: 282200, training_loss: 5.42498e-02
I0515 09:06:23.561827 22392998065984 run_lib.py:167] step: 282200, eval_loss: 5.86237e-02
I0515 09:06:47.798172 22392998065984 run_lib.py:146] step: 282250, training_loss: 6.81422e-02
I0515 09:07:11.958417 22392998065984 run_lib.py:146] step: 282300, training_loss: 5.57557e-02
I0515 09:07:12.117449 22392998065984 run_lib.py:167] step: 282300, eval_loss: 6.76775e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:07:36.209184 22392998065984 run_lib.py:146] step: 282350, training_loss: 5.07563e-02
I0515 09:08:00.514610 22392998065984 run_lib.py:146] step: 282400, training_loss: 5.25327e-02
I0515 09:08:00.679669 22392998065984 run_lib.py:167] step: 282400, eval_loss: 4.95810e-02
I0515 09:08:24.595318 22392998065984 run_lib.py:146] step: 282450, training_loss: 4.74906e-02
I0515 09:08:48.809815 22392998065984 run_lib.py:146] step: 282500, training_loss: 6.54350e-02
I0515 09:08:48.973737 22392998065984 run_lib.py:167] step: 282500, eval_loss: 6.07240e-02
I0515 09:09:12.899069 22392998065984 run_lib.py:146] step: 282550, training_loss: 5.41519e-02
I0515 09:09:37.083760 22392998065984 run_lib.py:146] step: 282600, training_loss: 5.47792e-02
I0515 09:09:37.241914 22392998065984 run_lib.py:167] step: 282600, eval_loss: 6.02993e-02
I0515 09:10:01.423552 22392998065984 run_lib.py:146] step: 282650, training_loss: 4.03573e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:10:25.469043 22392998065984 run_lib.py:146] step: 282700, training_loss: 6.16863e-02
I0515 09:10:25.630301 22392998065984 run_lib.py:167] step: 282700, eval_loss: 6.81221e-02
I0515 09:10:50.005316 22392998065984 run_lib.py:146] step: 282750, training_loss: 6.31895e-02
I0515 09:11:14.479388 22392998065984 run_lib.py:146] step: 282800, training_loss: 5.51594e-02
I0515 09:11:14.642055 22392998065984 run_lib.py:167] step: 282800, eval_loss: 5.36823e-02
I0515 09:11:38.524988 22392998065984 run_lib.py:146] step: 282850, training_loss: 5.06715e-02
I0515 09:12:02.814606 22392998065984 run_lib.py:146] step: 282900, training_loss: 5.69975e-02
I0515 09:12:02.972440 22392998065984 run_lib.py:167] step: 282900, eval_loss: 7.00360e-02
I0515 09:12:27.207583 22392998065984 run_lib.py:146] step: 282950, training_loss: 6.58620e-02
I0515 09:12:51.148564 22392998065984 run_lib.py:146] step: 283000, training_loss: 4.99640e-02
I0515 09:12:51.307361 22392998065984 run_lib.py:167] step: 283000, eval_loss: 6.14824e-02
I0515 09:13:15.540285 22392998065984 run_lib.py:146] step: 283050, training_loss: 6.92910e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:13:40.073330 22392998065984 run_lib.py:146] step: 283100, training_loss: 5.54528e-02
I0515 09:13:40.297000 22392998065984 run_lib.py:167] step: 283100, eval_loss: 5.73911e-02
I0515 09:14:04.246983 22392998065984 run_lib.py:146] step: 283150, training_loss: 4.94512e-02
I0515 09:14:28.563019 22392998065984 run_lib.py:146] step: 283200, training_loss: 4.29747e-02
I0515 09:14:28.722172 22392998065984 run_lib.py:167] step: 283200, eval_loss: 5.77189e-02
I0515 09:14:52.649033 22392998065984 run_lib.py:146] step: 283250, training_loss: 5.74788e-02
I0515 09:15:16.936560 22392998065984 run_lib.py:146] step: 283300, training_loss: 6.09751e-02
I0515 09:15:17.105165 22392998065984 run_lib.py:167] step: 283300, eval_loss: 6.17448e-02
I0515 09:15:41.022439 22392998065984 run_lib.py:146] step: 283350, training_loss: 5.11996e-02
I0515 09:16:05.206267 22392998065984 run_lib.py:146] step: 283400, training_loss: 4.78896e-02
I0515 09:16:05.364585 22392998065984 run_lib.py:167] step: 283400, eval_loss: 7.57607e-02
I0515 09:16:29.662642 22392998065984 run_lib.py:146] step: 283450, training_loss: 6.23765e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:16:53.697671 22392998065984 run_lib.py:146] step: 283500, training_loss: 6.16320e-02
I0515 09:16:53.861325 22392998065984 run_lib.py:167] step: 283500, eval_loss: 6.31283e-02
I0515 09:17:18.057433 22392998065984 run_lib.py:146] step: 283550, training_loss: 6.06113e-02
I0515 09:17:42.343847 22392998065984 run_lib.py:146] step: 283600, training_loss: 6.53636e-02
I0515 09:17:42.502772 22392998065984 run_lib.py:167] step: 283600, eval_loss: 6.15358e-02
I0515 09:18:06.439149 22392998065984 run_lib.py:146] step: 283650, training_loss: 4.83559e-02
I0515 09:18:30.654690 22392998065984 run_lib.py:146] step: 283700, training_loss: 6.08763e-02
I0515 09:18:30.814353 22392998065984 run_lib.py:167] step: 283700, eval_loss: 5.13272e-02
I0515 09:18:55.162345 22392998065984 run_lib.py:146] step: 283750, training_loss: 7.21201e-02
I0515 09:19:19.017969 22392998065984 run_lib.py:146] step: 283800, training_loss: 5.23135e-02
I0515 09:19:19.176044 22392998065984 run_lib.py:167] step: 283800, eval_loss: 8.10179e-02
I0515 09:19:43.379622 22392998065984 run_lib.py:146] step: 283850, training_loss: 6.41561e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:20:07.823129 22392998065984 run_lib.py:146] step: 283900, training_loss: 9.29296e-02
I0515 09:20:07.987898 22392998065984 run_lib.py:167] step: 283900, eval_loss: 4.88080e-02
I0515 09:20:31.919996 22392998065984 run_lib.py:146] step: 283950, training_loss: 4.87328e-02
I0515 09:20:56.171661 22392998065984 run_lib.py:146] step: 284000, training_loss: 6.58941e-02
I0515 09:20:56.331042 22392998065984 run_lib.py:167] step: 284000, eval_loss: 5.51844e-02
I0515 09:21:20.257107 22392998065984 run_lib.py:146] step: 284050, training_loss: 5.12415e-02
I0515 09:21:44.432505 22392998065984 run_lib.py:146] step: 284100, training_loss: 7.05311e-02
I0515 09:21:44.591411 22392998065984 run_lib.py:167] step: 284100, eval_loss: 6.60939e-02
I0515 09:22:08.793380 22392998065984 run_lib.py:146] step: 284150, training_loss: 5.95672e-02
I0515 09:22:32.686918 22392998065984 run_lib.py:146] step: 284200, training_loss: 5.89095e-02
I0515 09:22:32.844658 22392998065984 run_lib.py:167] step: 284200, eval_loss: 6.16605e-02
I0515 09:22:57.031095 22392998065984 run_lib.py:146] step: 284250, training_loss: 5.56742e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:23:21.196535 22392998065984 run_lib.py:146] step: 284300, training_loss: 6.35280e-02
I0515 09:23:21.293206 22392998065984 run_lib.py:167] step: 284300, eval_loss: 1.09857e-01
I0515 09:23:45.600984 22392998065984 run_lib.py:146] step: 284350, training_loss: 5.28604e-02
I0515 09:24:09.817149 22392998065984 run_lib.py:146] step: 284400, training_loss: 3.64177e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:24:10.254325 22392998065984 run_lib.py:167] step: 284400, eval_loss: 6.23271e-02
I0515 09:24:34.198165 22392998065984 run_lib.py:146] step: 284450, training_loss: 6.92478e-02
I0515 09:24:58.478517 22392998065984 run_lib.py:146] step: 284500, training_loss: 7.94448e-02
I0515 09:24:58.647376 22392998065984 run_lib.py:167] step: 284500, eval_loss: 5.69006e-02
I0515 09:25:22.892076 22392998065984 run_lib.py:146] step: 284550, training_loss: 6.07108e-02
I0515 09:25:46.797635 22392998065984 run_lib.py:146] step: 284600, training_loss: 6.36468e-02
I0515 09:25:46.955778 22392998065984 run_lib.py:167] step: 284600, eval_loss: 6.77303e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:26:11.384281 22392998065984 run_lib.py:146] step: 284650, training_loss: 5.83167e-02
I0515 09:26:35.676806 22392998065984 run_lib.py:146] step: 284700, training_loss: 5.17979e-02
I0515 09:26:35.847656 22392998065984 run_lib.py:167] step: 284700, eval_loss: 6.61465e-02
I0515 09:26:59.784093 22392998065984 run_lib.py:146] step: 284750, training_loss: 4.38825e-02
I0515 09:27:24.044792 22392998065984 run_lib.py:146] step: 284800, training_loss: 5.32116e-02
I0515 09:27:24.208795 22392998065984 run_lib.py:167] step: 284800, eval_loss: 6.01427e-02
I0515 09:27:48.136741 22392998065984 run_lib.py:146] step: 284850, training_loss: 5.13492e-02
I0515 09:28:12.347998 22392998065984 run_lib.py:146] step: 284900, training_loss: 4.97282e-02
I0515 09:28:12.507501 22392998065984 run_lib.py:167] step: 284900, eval_loss: 4.82257e-02
I0515 09:28:36.714902 22392998065984 run_lib.py:146] step: 284950, training_loss: 5.53921e-02
I0515 09:29:00.644918 22392998065984 run_lib.py:146] step: 285000, training_loss: 5.85839e-02
I0515 09:29:00.812787 22392998065984 run_lib.py:167] step: 285000, eval_loss: 7.04226e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:29:25.166709 22392998065984 run_lib.py:146] step: 285050, training_loss: 7.00039e-02
I0515 09:29:49.115976 22392998065984 run_lib.py:146] step: 285100, training_loss: 8.11556e-02
I0515 09:29:49.276169 22392998065984 run_lib.py:167] step: 285100, eval_loss: 5.94532e-02
I0515 09:30:13.542123 22392998065984 run_lib.py:146] step: 285150, training_loss: 4.92742e-02
I0515 09:30:37.818135 22392998065984 run_lib.py:146] step: 285200, training_loss: 5.66744e-02
I0515 09:30:37.975587 22392998065984 run_lib.py:167] step: 285200, eval_loss: 5.96938e-02
I0515 09:31:01.887444 22392998065984 run_lib.py:146] step: 285250, training_loss: 6.25288e-02
I0515 09:31:26.139010 22392998065984 run_lib.py:146] step: 285300, training_loss: 4.53842e-02
I0515 09:31:26.298040 22392998065984 run_lib.py:167] step: 285300, eval_loss: 5.08708e-02
I0515 09:31:50.509478 22392998065984 run_lib.py:146] step: 285350, training_loss: 4.58881e-02
I0515 09:32:14.399089 22392998065984 run_lib.py:146] step: 285400, training_loss: 5.89775e-02
I0515 09:32:14.557913 22392998065984 run_lib.py:167] step: 285400, eval_loss: 5.04480e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:32:38.947542 22392998065984 run_lib.py:146] step: 285450, training_loss: 6.37321e-02
I0515 09:33:02.790766 22392998065984 run_lib.py:146] step: 285500, training_loss: 5.27495e-02
I0515 09:33:02.950586 22392998065984 run_lib.py:167] step: 285500, eval_loss: 7.94994e-02
I0515 09:33:27.179477 22392998065984 run_lib.py:146] step: 285550, training_loss: 4.84350e-02
I0515 09:33:51.397704 22392998065984 run_lib.py:146] step: 285600, training_loss: 6.61490e-02
I0515 09:33:51.556645 22392998065984 run_lib.py:167] step: 285600, eval_loss: 5.13831e-02
I0515 09:34:15.466296 22392998065984 run_lib.py:146] step: 285650, training_loss: 4.77210e-02
I0515 09:34:39.664288 22392998065984 run_lib.py:146] step: 285700, training_loss: 5.47733e-02
I0515 09:34:39.823404 22392998065984 run_lib.py:167] step: 285700, eval_loss: 6.82240e-02
I0515 09:35:07.935313 22392998065984 run_lib.py:146] step: 285750, training_loss: 5.52809e-02
I0515 09:35:31.879037 22392998065984 run_lib.py:146] step: 285800, training_loss: 6.34523e-02
I0515 09:35:32.040109 22392998065984 run_lib.py:167] step: 285800, eval_loss: 6.26884e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:35:56.860376 22392998065984 run_lib.py:146] step: 285850, training_loss: 4.33011e-02
I0515 09:36:20.840305 22392998065984 run_lib.py:146] step: 285900, training_loss: 5.79110e-02
I0515 09:36:21.008020 22392998065984 run_lib.py:167] step: 285900, eval_loss: 6.18951e-02
I0515 09:36:45.344200 22392998065984 run_lib.py:146] step: 285950, training_loss: 4.01208e-02
I0515 09:37:09.568477 22392998065984 run_lib.py:146] step: 286000, training_loss: 4.36560e-02
I0515 09:37:09.735528 22392998065984 run_lib.py:167] step: 286000, eval_loss: 7.10588e-02
I0515 09:37:33.654644 22392998065984 run_lib.py:146] step: 286050, training_loss: 8.44428e-02
I0515 09:37:57.848405 22392998065984 run_lib.py:146] step: 286100, training_loss: 7.32730e-02
I0515 09:37:58.029897 22392998065984 run_lib.py:167] step: 286100, eval_loss: 4.38125e-02
I0515 09:38:22.179937 22392998065984 run_lib.py:146] step: 286150, training_loss: 7.22310e-02
I0515 09:38:46.109907 22392998065984 run_lib.py:146] step: 286200, training_loss: 5.53526e-02
I0515 09:38:46.277419 22392998065984 run_lib.py:167] step: 286200, eval_loss: 5.85744e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:39:10.678314 22392998065984 run_lib.py:146] step: 286250, training_loss: 6.01838e-02
I0515 09:39:34.568854 22392998065984 run_lib.py:146] step: 286300, training_loss: 5.48557e-02
I0515 09:39:34.746658 22392998065984 run_lib.py:167] step: 286300, eval_loss: 6.85330e-02
I0515 09:39:59.060225 22392998065984 run_lib.py:146] step: 286350, training_loss: 5.43630e-02
I0515 09:40:23.260242 22392998065984 run_lib.py:146] step: 286400, training_loss: 5.31559e-02
I0515 09:40:23.417840 22392998065984 run_lib.py:167] step: 286400, eval_loss: 5.44866e-02
I0515 09:40:47.352467 22392998065984 run_lib.py:146] step: 286450, training_loss: 5.59651e-02
I0515 09:41:11.540545 22392998065984 run_lib.py:146] step: 286500, training_loss: 3.97286e-02
I0515 09:41:11.697841 22392998065984 run_lib.py:167] step: 286500, eval_loss: 7.34236e-02
I0515 09:41:35.913882 22392998065984 run_lib.py:146] step: 286550, training_loss: 4.86657e-02
I0515 09:41:59.848421 22392998065984 run_lib.py:146] step: 286600, training_loss: 6.48777e-02
I0515 09:42:00.006226 22392998065984 run_lib.py:167] step: 286600, eval_loss: 5.64931e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:42:24.520269 22392998065984 run_lib.py:146] step: 286650, training_loss: 3.70043e-02
I0515 09:42:48.868161 22392998065984 run_lib.py:146] step: 286700, training_loss: 5.95147e-02
I0515 09:42:49.049017 22392998065984 run_lib.py:167] step: 286700, eval_loss: 4.99010e-02
I0515 09:43:12.970167 22392998065984 run_lib.py:146] step: 286750, training_loss: 5.79256e-02
I0515 09:43:37.222051 22392998065984 run_lib.py:146] step: 286800, training_loss: 6.27965e-02
I0515 09:43:37.379654 22392998065984 run_lib.py:167] step: 286800, eval_loss: 6.64918e-02
I0515 09:44:01.339781 22392998065984 run_lib.py:146] step: 286850, training_loss: 5.60688e-02
I0515 09:44:25.565766 22392998065984 run_lib.py:146] step: 286900, training_loss: 4.29843e-02
I0515 09:44:25.732500 22392998065984 run_lib.py:167] step: 286900, eval_loss: 5.21614e-02
I0515 09:44:49.888247 22392998065984 run_lib.py:146] step: 286950, training_loss: 7.40231e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:45:13.942379 22392998065984 run_lib.py:146] step: 287000, training_loss: 6.09949e-02
I0515 09:45:14.102192 22392998065984 run_lib.py:167] step: 287000, eval_loss: 7.90700e-02
I0515 09:45:38.442234 22392998065984 run_lib.py:146] step: 287050, training_loss: 5.15124e-02
I0515 09:46:02.429327 22392998065984 run_lib.py:146] step: 287100, training_loss: 4.90046e-02
I0515 09:46:02.941385 22392998065984 run_lib.py:167] step: 287100, eval_loss: 5.83830e-02
I0515 09:46:26.897498 22392998065984 run_lib.py:146] step: 287150, training_loss: 5.31165e-02
I0515 09:46:51.113179 22392998065984 run_lib.py:146] step: 287200, training_loss: 6.16655e-02
I0515 09:46:51.281329 22392998065984 run_lib.py:167] step: 287200, eval_loss: 5.57161e-02
I0515 09:47:15.239148 22392998065984 run_lib.py:146] step: 287250, training_loss: 6.04805e-02
I0515 09:47:39.440326 22392998065984 run_lib.py:146] step: 287300, training_loss: 5.40142e-02
I0515 09:47:39.598604 22392998065984 run_lib.py:167] step: 287300, eval_loss: 5.17587e-02
I0515 09:48:03.802157 22392998065984 run_lib.py:146] step: 287350, training_loss: 4.91464e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:48:27.912923 22392998065984 run_lib.py:146] step: 287400, training_loss: 6.51581e-02
I0515 09:48:28.073110 22392998065984 run_lib.py:167] step: 287400, eval_loss: 5.96498e-02
I0515 09:48:52.354146 22392998065984 run_lib.py:146] step: 287450, training_loss: 6.80015e-02
I0515 09:49:16.254070 22392998065984 run_lib.py:146] step: 287500, training_loss: 5.69564e-02
I0515 09:49:16.418388 22392998065984 run_lib.py:167] step: 287500, eval_loss: 6.07889e-02
I0515 09:49:40.653061 22392998065984 run_lib.py:146] step: 287550, training_loss: 6.65599e-02
I0515 09:50:04.935531 22392998065984 run_lib.py:146] step: 287600, training_loss: 5.88786e-02
I0515 09:50:05.098748 22392998065984 run_lib.py:167] step: 287600, eval_loss: 5.24624e-02
I0515 09:50:28.970131 22392998065984 run_lib.py:146] step: 287650, training_loss: 4.63961e-02
I0515 09:50:53.203393 22392998065984 run_lib.py:146] step: 287700, training_loss: 5.54748e-02
I0515 09:50:53.362281 22392998065984 run_lib.py:167] step: 287700, eval_loss: 5.57373e-02
I0515 09:51:17.517854 22392998065984 run_lib.py:146] step: 287750, training_loss: 6.36452e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:51:41.594216 22392998065984 run_lib.py:146] step: 287800, training_loss: 5.14768e-02
I0515 09:51:41.759927 22392998065984 run_lib.py:167] step: 287800, eval_loss: 4.84752e-02
I0515 09:52:06.037254 22392998065984 run_lib.py:146] step: 287850, training_loss: 7.89806e-02
I0515 09:52:30.236889 22392998065984 run_lib.py:146] step: 287900, training_loss: 5.85654e-02
I0515 09:52:30.413109 22392998065984 run_lib.py:167] step: 287900, eval_loss: 4.87275e-02
I0515 09:52:54.360484 22392998065984 run_lib.py:146] step: 287950, training_loss: 4.65227e-02
I0515 09:53:18.602553 22392998065984 run_lib.py:146] step: 288000, training_loss: 4.63691e-02
I0515 09:53:18.762550 22392998065984 run_lib.py:167] step: 288000, eval_loss: 5.17800e-02
I0515 09:53:42.715305 22392998065984 run_lib.py:146] step: 288050, training_loss: 6.37509e-02
I0515 09:54:07.012546 22392998065984 run_lib.py:146] step: 288100, training_loss: 5.79590e-02
I0515 09:54:07.170136 22392998065984 run_lib.py:167] step: 288100, eval_loss: 3.89628e-02
I0515 09:54:31.365519 22392998065984 run_lib.py:146] step: 288150, training_loss: 6.23015e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:54:55.355559 22392998065984 run_lib.py:146] step: 288200, training_loss: 4.76947e-02
I0515 09:54:55.516458 22392998065984 run_lib.py:167] step: 288200, eval_loss: 6.03340e-02
I0515 09:55:19.754461 22392998065984 run_lib.py:146] step: 288250, training_loss: 5.95639e-02
I0515 09:55:43.660945 22392998065984 run_lib.py:146] step: 288300, training_loss: 5.72269e-02
I0515 09:55:43.820096 22392998065984 run_lib.py:167] step: 288300, eval_loss: 5.88029e-02
I0515 09:56:08.129414 22392998065984 run_lib.py:146] step: 288350, training_loss: 5.91488e-02
I0515 09:56:32.329797 22392998065984 run_lib.py:146] step: 288400, training_loss: 4.87651e-02
I0515 09:56:32.488154 22392998065984 run_lib.py:167] step: 288400, eval_loss: 6.61262e-02
I0515 09:56:56.397631 22392998065984 run_lib.py:146] step: 288450, training_loss: 5.76182e-02
I0515 09:57:20.599210 22392998065984 run_lib.py:146] step: 288500, training_loss: 5.69666e-02
I0515 09:57:20.778804 22392998065984 run_lib.py:167] step: 288500, eval_loss: 5.64262e-02
I0515 09:57:44.971517 22392998065984 run_lib.py:146] step: 288550, training_loss: 4.16895e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 09:58:09.053439 22392998065984 run_lib.py:146] step: 288600, training_loss: 6.27274e-02
I0515 09:58:09.235007 22392998065984 run_lib.py:167] step: 288600, eval_loss: 6.14181e-02
I0515 09:58:33.520727 22392998065984 run_lib.py:146] step: 288650, training_loss: 5.43252e-02
I0515 09:58:57.810014 22392998065984 run_lib.py:146] step: 288700, training_loss: 6.58392e-02
I0515 09:58:57.969178 22392998065984 run_lib.py:167] step: 288700, eval_loss: 4.89439e-02
I0515 09:59:21.927423 22392998065984 run_lib.py:146] step: 288750, training_loss: 6.02893e-02
I0515 09:59:46.137858 22392998065984 run_lib.py:146] step: 288800, training_loss: 4.16722e-02
I0515 09:59:46.296606 22392998065984 run_lib.py:167] step: 288800, eval_loss: 6.49505e-02
I0515 10:00:10.232702 22392998065984 run_lib.py:146] step: 288850, training_loss: 5.15436e-02
I0515 10:00:34.419739 22392998065984 run_lib.py:146] step: 288900, training_loss: 6.03057e-02
I0515 10:00:34.578065 22392998065984 run_lib.py:167] step: 288900, eval_loss: 6.20954e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:00:59.012048 22392998065984 run_lib.py:146] step: 288950, training_loss: 5.59812e-02
I0515 10:01:22.977511 22392998065984 run_lib.py:146] step: 289000, training_loss: 4.81087e-02
I0515 10:01:23.146443 22392998065984 run_lib.py:167] step: 289000, eval_loss: 7.14954e-02
I0515 10:01:47.433164 22392998065984 run_lib.py:146] step: 289050, training_loss: 5.02534e-02
I0515 10:02:11.347554 22392998065984 run_lib.py:146] step: 289100, training_loss: 4.47722e-02
I0515 10:02:11.506323 22392998065984 run_lib.py:167] step: 289100, eval_loss: 7.60262e-02
I0515 10:02:35.805407 22392998065984 run_lib.py:146] step: 289150, training_loss: 5.48570e-02
I0515 10:03:00.063449 22392998065984 run_lib.py:146] step: 289200, training_loss: 5.65386e-02
I0515 10:03:00.228141 22392998065984 run_lib.py:167] step: 289200, eval_loss: 6.79774e-02
I0515 10:03:24.159090 22392998065984 run_lib.py:146] step: 289250, training_loss: 4.61255e-02
I0515 10:03:48.384270 22392998065984 run_lib.py:146] step: 289300, training_loss: 7.21792e-02
I0515 10:03:48.547365 22392998065984 run_lib.py:167] step: 289300, eval_loss: 8.26019e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:04:12.977195 22392998065984 run_lib.py:146] step: 289350, training_loss: 5.06084e-02
I0515 10:04:36.667098 22392998065984 run_lib.py:146] step: 289400, training_loss: 5.78226e-02
I0515 10:04:36.831339 22392998065984 run_lib.py:167] step: 289400, eval_loss: 4.82208e-02
I0515 10:05:01.160925 22392998065984 run_lib.py:146] step: 289450, training_loss: 6.27451e-02
I0515 10:05:25.507591 22392998065984 run_lib.py:146] step: 289500, training_loss: 5.73908e-02
I0515 10:05:25.687651 22392998065984 run_lib.py:167] step: 289500, eval_loss: 7.23909e-02
I0515 10:05:49.651885 22392998065984 run_lib.py:146] step: 289550, training_loss: 6.16052e-02
I0515 10:06:13.898252 22392998065984 run_lib.py:146] step: 289600, training_loss: 5.66006e-02
I0515 10:06:14.057104 22392998065984 run_lib.py:167] step: 289600, eval_loss: 4.76762e-02
I0515 10:06:37.977383 22392998065984 run_lib.py:146] step: 289650, training_loss: 4.59889e-02
I0515 10:07:02.150116 22392998065984 run_lib.py:146] step: 289700, training_loss: 5.99643e-02
I0515 10:07:02.309198 22392998065984 run_lib.py:167] step: 289700, eval_loss: 6.51519e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:07:26.620468 22392998065984 run_lib.py:146] step: 289750, training_loss: 5.52445e-02
I0515 10:07:50.463744 22392998065984 run_lib.py:146] step: 289800, training_loss: 5.66152e-02
I0515 10:07:50.632305 22392998065984 run_lib.py:167] step: 289800, eval_loss: 4.91042e-02
I0515 10:08:14.728060 22392998065984 run_lib.py:146] step: 289850, training_loss: 5.21346e-02
I0515 10:08:38.705137 22392998065984 run_lib.py:146] step: 289900, training_loss: 5.43622e-02
I0515 10:08:38.868334 22392998065984 run_lib.py:167] step: 289900, eval_loss: 6.30482e-02
I0515 10:09:03.198796 22392998065984 run_lib.py:146] step: 289950, training_loss: 4.58033e-02
I0515 10:09:27.336217 22392998065984 run_lib.py:146] step: 290000, training_loss: 6.07801e-02
I0515 10:09:28.977691 22392998065984 run_lib.py:167] step: 290000, eval_loss: 7.44400e-02
I0515 10:09:54.338795 22392998065984 run_lib.py:146] step: 290050, training_loss: 7.63311e-02
I0515 10:10:18.811954 22392998065984 run_lib.py:146] step: 290100, training_loss: 4.81008e-02
I0515 10:10:18.971176 22392998065984 run_lib.py:167] step: 290100, eval_loss: 6.15823e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:10:43.038331 22392998065984 run_lib.py:146] step: 290150, training_loss: 6.13267e-02
I0515 10:11:06.925223 22392998065984 run_lib.py:146] step: 290200, training_loss: 5.16533e-02
I0515 10:11:07.091360 22392998065984 run_lib.py:167] step: 290200, eval_loss: 8.07732e-02
I0515 10:11:31.371999 22392998065984 run_lib.py:146] step: 290250, training_loss: 6.54144e-02
I0515 10:11:55.722642 22392998065984 run_lib.py:146] step: 290300, training_loss: 4.84883e-02
I0515 10:11:55.899976 22392998065984 run_lib.py:167] step: 290300, eval_loss: 7.02517e-02
I0515 10:12:19.812106 22392998065984 run_lib.py:146] step: 290350, training_loss: 6.77518e-02
I0515 10:12:44.028196 22392998065984 run_lib.py:146] step: 290400, training_loss: 7.96358e-02
I0515 10:12:44.188059 22392998065984 run_lib.py:167] step: 290400, eval_loss: 3.43482e-02
I0515 10:13:08.499462 22392998065984 run_lib.py:146] step: 290450, training_loss: 6.45093e-02
I0515 10:13:32.446755 22392998065984 run_lib.py:146] step: 290500, training_loss: 5.42210e-02
I0515 10:13:32.610683 22392998065984 run_lib.py:167] step: 290500, eval_loss: 7.36225e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:13:57.310051 22392998065984 run_lib.py:146] step: 290550, training_loss: 5.00175e-02
I0515 10:14:21.585243 22392998065984 run_lib.py:146] step: 290600, training_loss: 5.22253e-02
I0515 10:14:21.756715 22392998065984 run_lib.py:167] step: 290600, eval_loss: 5.85663e-02
I0515 10:14:45.701320 22392998065984 run_lib.py:146] step: 290650, training_loss: 5.40495e-02
I0515 10:15:09.640729 22392998065984 run_lib.py:146] step: 290700, training_loss: 4.24184e-02
I0515 10:15:09.815367 22392998065984 run_lib.py:167] step: 290700, eval_loss: 6.69551e-02
I0515 10:15:34.322786 22392998065984 run_lib.py:146] step: 290750, training_loss: 5.95184e-02
I0515 10:15:58.303814 22392998065984 run_lib.py:146] step: 290800, training_loss: 6.71782e-02
I0515 10:15:58.471090 22392998065984 run_lib.py:167] step: 290800, eval_loss: 4.87064e-02
I0515 10:16:22.383511 22392998065984 run_lib.py:146] step: 290850, training_loss: 4.92554e-02
I0515 10:16:46.920127 22392998065984 run_lib.py:146] step: 290900, training_loss: 6.32906e-02
I0515 10:16:47.080938 22392998065984 run_lib.py:167] step: 290900, eval_loss: 6.23519e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:17:11.197712 22392998065984 run_lib.py:146] step: 290950, training_loss: 5.36607e-02
I0515 10:17:35.081819 22392998065984 run_lib.py:146] step: 291000, training_loss: 4.70323e-02
I0515 10:17:35.245095 22392998065984 run_lib.py:167] step: 291000, eval_loss: 7.00178e-02
I0515 10:17:59.811436 22392998065984 run_lib.py:146] step: 291050, training_loss: 7.47612e-02
I0515 10:18:23.749900 22392998065984 run_lib.py:146] step: 291100, training_loss: 3.86088e-02
I0515 10:18:23.909019 22392998065984 run_lib.py:167] step: 291100, eval_loss: 7.10934e-02
I0515 10:18:47.808750 22392998065984 run_lib.py:146] step: 291150, training_loss: 7.08369e-02
I0515 10:19:12.112213 22392998065984 run_lib.py:146] step: 291200, training_loss: 5.55256e-02
I0515 10:19:12.283556 22392998065984 run_lib.py:167] step: 291200, eval_loss: 6.88209e-02
I0515 10:19:36.481071 22392998065984 run_lib.py:146] step: 291250, training_loss: 6.29472e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:20:00.523622 22392998065984 run_lib.py:146] step: 291300, training_loss: 5.66159e-02
I0515 10:20:00.684001 22392998065984 run_lib.py:167] step: 291300, eval_loss: 5.36361e-02
I0515 10:20:25.101633 22392998065984 run_lib.py:146] step: 291350, training_loss: 6.20809e-02
I0515 10:20:49.499280 22392998065984 run_lib.py:146] step: 291400, training_loss: 4.60081e-02
I0515 10:20:49.669831 22392998065984 run_lib.py:167] step: 291400, eval_loss: 5.43511e-02
I0515 10:21:13.624906 22392998065984 run_lib.py:146] step: 291450, training_loss: 6.01311e-02
I0515 10:21:37.552978 22392998065984 run_lib.py:146] step: 291500, training_loss: 4.56247e-02
I0515 10:21:37.710676 22392998065984 run_lib.py:167] step: 291500, eval_loss: 6.06509e-02
I0515 10:22:02.270623 22392998065984 run_lib.py:146] step: 291550, training_loss: 6.60532e-02
I0515 10:22:26.233078 22392998065984 run_lib.py:146] step: 291600, training_loss: 7.71404e-02
I0515 10:22:26.392539 22392998065984 run_lib.py:167] step: 291600, eval_loss: 6.60338e-02
I0515 10:22:50.386682 22392998065984 run_lib.py:146] step: 291650, training_loss: 6.93476e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:23:15.118626 22392998065984 run_lib.py:146] step: 291700, training_loss: 7.09197e-02
I0515 10:23:15.287126 22392998065984 run_lib.py:167] step: 291700, eval_loss: 7.56416e-02
I0515 10:23:39.183091 22392998065984 run_lib.py:146] step: 291750, training_loss: 6.90517e-02
I0515 10:24:03.139242 22392998065984 run_lib.py:146] step: 291800, training_loss: 6.60465e-02
I0515 10:24:03.296944 22392998065984 run_lib.py:167] step: 291800, eval_loss: 6.33055e-02
I0515 10:24:27.897307 22392998065984 run_lib.py:146] step: 291850, training_loss: 4.26874e-02
I0515 10:24:51.853571 22392998065984 run_lib.py:146] step: 291900, training_loss: 4.93674e-02
I0515 10:24:52.011260 22392998065984 run_lib.py:167] step: 291900, eval_loss: 6.19298e-02
I0515 10:25:15.975120 22392998065984 run_lib.py:146] step: 291950, training_loss: 6.94862e-02
I0515 10:25:40.202784 22392998065984 run_lib.py:146] step: 292000, training_loss: 4.29892e-02
I0515 10:25:40.370388 22392998065984 run_lib.py:167] step: 292000, eval_loss: 6.50753e-02
I0515 10:26:04.500426 22392998065984 run_lib.py:146] step: 292050, training_loss: 7.31216e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:26:28.587471 22392998065984 run_lib.py:146] step: 292100, training_loss: 5.29635e-02
I0515 10:26:28.755361 22392998065984 run_lib.py:167] step: 292100, eval_loss: 7.42694e-02
I0515 10:26:53.059131 22392998065984 run_lib.py:146] step: 292150, training_loss: 4.30710e-02
I0515 10:27:17.313148 22392998065984 run_lib.py:146] step: 292200, training_loss: 6.90817e-02
I0515 10:27:17.690800 22392998065984 run_lib.py:167] step: 292200, eval_loss: 6.67028e-02
I0515 10:27:41.652711 22392998065984 run_lib.py:146] step: 292250, training_loss: 6.65080e-02
I0515 10:28:05.632519 22392998065984 run_lib.py:146] step: 292300, training_loss: 4.29259e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:28:06.082324 22392998065984 run_lib.py:167] step: 292300, eval_loss: 6.67328e-02
I0515 10:28:30.689960 22392998065984 run_lib.py:146] step: 292350, training_loss: 6.09642e-02
I0515 10:28:54.661677 22392998065984 run_lib.py:146] step: 292400, training_loss: 4.31612e-02
I0515 10:28:54.828677 22392998065984 run_lib.py:167] step: 292400, eval_loss: 5.09684e-02
I0515 10:29:18.779036 22392998065984 run_lib.py:146] step: 292450, training_loss: 4.67428e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:29:43.537419 22392998065984 run_lib.py:146] step: 292500, training_loss: 5.91551e-02
I0515 10:29:43.702339 22392998065984 run_lib.py:167] step: 292500, eval_loss: 7.18938e-02
I0515 10:30:07.690563 22392998065984 run_lib.py:146] step: 292550, training_loss: 5.57644e-02
I0515 10:30:31.608194 22392998065984 run_lib.py:146] step: 292600, training_loss: 5.28579e-02
I0515 10:30:31.765806 22392998065984 run_lib.py:167] step: 292600, eval_loss: 4.86907e-02
I0515 10:30:55.982733 22392998065984 run_lib.py:146] step: 292650, training_loss: 6.41821e-02
I0515 10:31:20.260636 22392998065984 run_lib.py:146] step: 292700, training_loss: 7.47119e-02
I0515 10:31:20.435248 22392998065984 run_lib.py:167] step: 292700, eval_loss: 5.98924e-02
I0515 10:31:44.438198 22392998065984 run_lib.py:146] step: 292750, training_loss: 5.41567e-02
I0515 10:32:08.734987 22392998065984 run_lib.py:146] step: 292800, training_loss: 5.89107e-02
I0515 10:32:08.913057 22392998065984 run_lib.py:167] step: 292800, eval_loss: 5.72668e-02
I0515 10:32:33.130122 22392998065984 run_lib.py:146] step: 292850, training_loss: 5.32305e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:32:57.304621 22392998065984 run_lib.py:146] step: 292900, training_loss: 6.18337e-02
I0515 10:32:57.474298 22392998065984 run_lib.py:167] step: 292900, eval_loss: 7.19666e-02
I0515 10:33:21.841022 22392998065984 run_lib.py:146] step: 292950, training_loss: 5.20310e-02
I0515 10:33:46.106235 22392998065984 run_lib.py:146] step: 293000, training_loss: 5.03448e-02
I0515 10:33:46.285202 22392998065984 run_lib.py:167] step: 293000, eval_loss: 4.95940e-02
I0515 10:34:10.258094 22392998065984 run_lib.py:146] step: 293050, training_loss: 5.86821e-02
I0515 10:34:34.514438 22392998065984 run_lib.py:146] step: 293100, training_loss: 6.69141e-02
I0515 10:34:34.681730 22392998065984 run_lib.py:167] step: 293100, eval_loss: 6.00418e-02
I0515 10:34:58.926715 22392998065984 run_lib.py:146] step: 293150, training_loss: 4.85679e-02
I0515 10:35:22.921543 22392998065984 run_lib.py:146] step: 293200, training_loss: 6.97630e-02
I0515 10:35:23.080027 22392998065984 run_lib.py:167] step: 293200, eval_loss: 5.02888e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:35:47.206446 22392998065984 run_lib.py:146] step: 293250, training_loss: 6.11263e-02
I0515 10:36:11.890725 22392998065984 run_lib.py:146] step: 293300, training_loss: 4.51837e-02
I0515 10:36:12.058789 22392998065984 run_lib.py:167] step: 293300, eval_loss: 5.33662e-02
I0515 10:36:36.034143 22392998065984 run_lib.py:146] step: 293350, training_loss: 5.74559e-02
I0515 10:36:59.979672 22392998065984 run_lib.py:146] step: 293400, training_loss: 7.22708e-02
I0515 10:37:00.137578 22392998065984 run_lib.py:167] step: 293400, eval_loss: 6.22589e-02
I0515 10:37:24.736216 22392998065984 run_lib.py:146] step: 293450, training_loss: 5.77847e-02
I0515 10:37:48.681484 22392998065984 run_lib.py:146] step: 293500, training_loss: 6.58409e-02
I0515 10:37:48.848464 22392998065984 run_lib.py:167] step: 293500, eval_loss: 6.83480e-02
I0515 10:38:12.815846 22392998065984 run_lib.py:146] step: 293550, training_loss: 6.20956e-02
I0515 10:38:37.042636 22392998065984 run_lib.py:146] step: 293600, training_loss: 6.78829e-02
I0515 10:38:37.200958 22392998065984 run_lib.py:167] step: 293600, eval_loss: 6.40424e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:39:01.613367 22392998065984 run_lib.py:146] step: 293650, training_loss: 5.70983e-02
I0515 10:39:25.635831 22392998065984 run_lib.py:146] step: 293700, training_loss: 5.29931e-02
I0515 10:39:25.795302 22392998065984 run_lib.py:167] step: 293700, eval_loss: 7.29729e-02
I0515 10:39:50.087968 22392998065984 run_lib.py:146] step: 293750, training_loss: 8.27386e-02
I0515 10:40:14.306030 22392998065984 run_lib.py:146] step: 293800, training_loss: 7.75733e-02
I0515 10:40:14.464529 22392998065984 run_lib.py:167] step: 293800, eval_loss: 7.98363e-02
I0515 10:40:38.445899 22392998065984 run_lib.py:146] step: 293850, training_loss: 4.63869e-02
I0515 10:41:02.395035 22392998065984 run_lib.py:146] step: 293900, training_loss: 4.70803e-02
I0515 10:41:02.575388 22392998065984 run_lib.py:167] step: 293900, eval_loss: 8.99059e-02
I0515 10:41:26.990097 22392998065984 run_lib.py:146] step: 293950, training_loss: 8.21408e-02
I0515 10:41:50.861063 22392998065984 run_lib.py:146] step: 294000, training_loss: 6.90249e-02
I0515 10:41:51.029844 22392998065984 run_lib.py:167] step: 294000, eval_loss: 4.85329e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:42:15.069090 22392998065984 run_lib.py:146] step: 294050, training_loss: 5.89824e-02
I0515 10:42:39.691089 22392998065984 run_lib.py:146] step: 294100, training_loss: 6.66625e-02
I0515 10:42:39.849628 22392998065984 run_lib.py:167] step: 294100, eval_loss: 6.21778e-02
I0515 10:43:03.765538 22392998065984 run_lib.py:146] step: 294150, training_loss: 5.03105e-02
I0515 10:43:27.696830 22392998065984 run_lib.py:146] step: 294200, training_loss: 7.35251e-02
I0515 10:43:27.863226 22392998065984 run_lib.py:167] step: 294200, eval_loss: 6.90335e-02
I0515 10:43:52.398322 22392998065984 run_lib.py:146] step: 294250, training_loss: 5.89778e-02
I0515 10:44:16.292348 22392998065984 run_lib.py:146] step: 294300, training_loss: 4.33418e-02
I0515 10:44:16.449722 22392998065984 run_lib.py:167] step: 294300, eval_loss: 4.95547e-02
I0515 10:44:40.340934 22392998065984 run_lib.py:146] step: 294350, training_loss: 4.43055e-02
I0515 10:45:04.540995 22392998065984 run_lib.py:146] step: 294400, training_loss: 1.03583e-01
I0515 10:45:04.708631 22392998065984 run_lib.py:167] step: 294400, eval_loss: 5.54958e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:45:29.148620 22392998065984 run_lib.py:146] step: 294450, training_loss: 7.45999e-02
I0515 10:45:53.118873 22392998065984 run_lib.py:146] step: 294500, training_loss: 6.49197e-02
I0515 10:45:53.283050 22392998065984 run_lib.py:167] step: 294500, eval_loss: 5.12545e-02
I0515 10:46:17.576623 22392998065984 run_lib.py:146] step: 294550, training_loss: 5.45052e-02
I0515 10:46:41.841898 22392998065984 run_lib.py:146] step: 294600, training_loss: 6.27711e-02
I0515 10:46:42.040605 22392998065984 run_lib.py:167] step: 294600, eval_loss: 5.72703e-02
I0515 10:47:05.950613 22392998065984 run_lib.py:146] step: 294650, training_loss: 6.67849e-02
I0515 10:47:30.186272 22392998065984 run_lib.py:146] step: 294700, training_loss: 5.36332e-02
I0515 10:47:30.345598 22392998065984 run_lib.py:167] step: 294700, eval_loss: 6.13705e-02
I0515 10:47:54.540587 22392998065984 run_lib.py:146] step: 294750, training_loss: 5.29116e-02
I0515 10:48:18.409901 22392998065984 run_lib.py:146] step: 294800, training_loss: 5.53865e-02
I0515 10:48:18.568172 22392998065984 run_lib.py:167] step: 294800, eval_loss: 5.23639e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:48:42.680732 22392998065984 run_lib.py:146] step: 294850, training_loss: 7.05503e-02
I0515 10:49:07.470109 22392998065984 run_lib.py:146] step: 294900, training_loss: 4.82735e-02
I0515 10:49:07.632364 22392998065984 run_lib.py:167] step: 294900, eval_loss: 6.43627e-02
I0515 10:49:31.622816 22392998065984 run_lib.py:146] step: 294950, training_loss: 8.57446e-02
I0515 10:49:55.551067 22392998065984 run_lib.py:146] step: 295000, training_loss: 7.36176e-02
I0515 10:49:55.710915 22392998065984 run_lib.py:167] step: 295000, eval_loss: 6.35807e-02
I0515 10:50:20.399896 22392998065984 run_lib.py:146] step: 295050, training_loss: 5.78826e-02
I0515 10:50:44.359592 22392998065984 run_lib.py:146] step: 295100, training_loss: 7.89845e-02
I0515 10:50:44.517137 22392998065984 run_lib.py:167] step: 295100, eval_loss: 6.72736e-02
I0515 10:51:08.509207 22392998065984 run_lib.py:146] step: 295150, training_loss: 4.84923e-02
I0515 10:51:33.018271 22392998065984 run_lib.py:146] step: 295200, training_loss: 4.68435e-02
I0515 10:51:33.176003 22392998065984 run_lib.py:167] step: 295200, eval_loss: 7.50266e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:51:57.285088 22392998065984 run_lib.py:146] step: 295250, training_loss: 6.53853e-02
I0515 10:52:21.233994 22392998065984 run_lib.py:146] step: 295300, training_loss: 5.93476e-02
I0515 10:52:21.393388 22392998065984 run_lib.py:167] step: 295300, eval_loss: 5.55471e-02
I0515 10:52:45.714442 22392998065984 run_lib.py:146] step: 295350, training_loss: 5.86105e-02
I0515 10:53:10.089561 22392998065984 run_lib.py:146] step: 295400, training_loss: 5.73923e-02
I0515 10:53:10.257873 22392998065984 run_lib.py:167] step: 295400, eval_loss: 6.37395e-02
I0515 10:53:34.215954 22392998065984 run_lib.py:146] step: 295450, training_loss: 4.80068e-02
I0515 10:53:58.420293 22392998065984 run_lib.py:146] step: 295500, training_loss: 7.61164e-02
I0515 10:53:58.578470 22392998065984 run_lib.py:167] step: 295500, eval_loss: 5.24188e-02
I0515 10:54:22.924934 22392998065984 run_lib.py:146] step: 295550, training_loss: 4.92669e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:54:47.093552 22392998065984 run_lib.py:146] step: 295600, training_loss: 6.82749e-02
I0515 10:54:47.253218 22392998065984 run_lib.py:167] step: 295600, eval_loss: 5.84580e-02
I0515 10:55:11.149979 22392998065984 run_lib.py:146] step: 295650, training_loss: 3.93427e-02
I0515 10:55:35.800199 22392998065984 run_lib.py:146] step: 295700, training_loss: 8.61218e-02
I0515 10:55:35.958255 22392998065984 run_lib.py:167] step: 295700, eval_loss: 6.75159e-02
I0515 10:55:59.865911 22392998065984 run_lib.py:146] step: 295750, training_loss: 4.46414e-02
I0515 10:56:23.778354 22392998065984 run_lib.py:146] step: 295800, training_loss: 5.40976e-02
I0515 10:56:23.936918 22392998065984 run_lib.py:167] step: 295800, eval_loss: 8.12281e-02
I0515 10:56:48.533741 22392998065984 run_lib.py:146] step: 295850, training_loss: 6.47218e-02
I0515 10:57:12.458038 22392998065984 run_lib.py:146] step: 295900, training_loss: 5.81107e-02
I0515 10:57:12.616516 22392998065984 run_lib.py:167] step: 295900, eval_loss: 8.52690e-02
I0515 10:57:36.564182 22392998065984 run_lib.py:146] step: 295950, training_loss: 6.10042e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 10:58:01.315797 22392998065984 run_lib.py:146] step: 296000, training_loss: 5.64205e-02
I0515 10:58:01.475130 22392998065984 run_lib.py:167] step: 296000, eval_loss: 5.83157e-02
I0515 10:58:25.558469 22392998065984 run_lib.py:146] step: 296050, training_loss: 5.27585e-02
I0515 10:58:49.532309 22392998065984 run_lib.py:146] step: 296100, training_loss: 5.07753e-02
I0515 10:58:49.699840 22392998065984 run_lib.py:167] step: 296100, eval_loss: 5.28000e-02
I0515 10:59:13.979974 22392998065984 run_lib.py:146] step: 296150, training_loss: 6.41479e-02
I0515 10:59:38.196854 22392998065984 run_lib.py:146] step: 296200, training_loss: 4.13451e-02
I0515 10:59:38.355211 22392998065984 run_lib.py:167] step: 296200, eval_loss: 4.92777e-02
I0515 11:00:02.274509 22392998065984 run_lib.py:146] step: 296250, training_loss: 5.48992e-02
I0515 11:00:26.471158 22392998065984 run_lib.py:146] step: 296300, training_loss: 6.26237e-02
I0515 11:00:26.629592 22392998065984 run_lib.py:167] step: 296300, eval_loss: 7.69217e-02
I0515 11:00:50.850674 22392998065984 run_lib.py:146] step: 296350, training_loss: 5.91802e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:01:14.951297 22392998065984 run_lib.py:146] step: 296400, training_loss: 4.07641e-02
I0515 11:01:15.119401 22392998065984 run_lib.py:167] step: 296400, eval_loss: 4.61936e-02
I0515 11:01:39.077926 22392998065984 run_lib.py:146] step: 296450, training_loss: 4.24627e-02
I0515 11:02:03.686769 22392998065984 run_lib.py:146] step: 296500, training_loss: 7.07404e-02
I0515 11:02:03.845745 22392998065984 run_lib.py:167] step: 296500, eval_loss: 5.35032e-02
I0515 11:02:27.845734 22392998065984 run_lib.py:146] step: 296550, training_loss: 4.67848e-02
I0515 11:02:51.767801 22392998065984 run_lib.py:146] step: 296600, training_loss: 5.79077e-02
I0515 11:02:51.926206 22392998065984 run_lib.py:167] step: 296600, eval_loss: 6.97543e-02
I0515 11:03:16.431898 22392998065984 run_lib.py:146] step: 296650, training_loss: 5.22059e-02
I0515 11:03:40.320852 22392998065984 run_lib.py:146] step: 296700, training_loss: 5.47179e-02
I0515 11:03:40.479219 22392998065984 run_lib.py:167] step: 296700, eval_loss: 6.72279e-02
I0515 11:04:04.390232 22392998065984 run_lib.py:146] step: 296750, training_loss: 5.68205e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:04:29.133382 22392998065984 run_lib.py:146] step: 296800, training_loss: 6.06803e-02
I0515 11:04:29.292594 22392998065984 run_lib.py:167] step: 296800, eval_loss: 6.30101e-02
I0515 11:04:53.217335 22392998065984 run_lib.py:146] step: 296850, training_loss: 6.20393e-02
I0515 11:05:17.160874 22392998065984 run_lib.py:146] step: 296900, training_loss: 4.71029e-02
I0515 11:05:17.319729 22392998065984 run_lib.py:167] step: 296900, eval_loss: 7.40996e-02
I0515 11:05:41.466510 22392998065984 run_lib.py:146] step: 296950, training_loss: 6.64684e-02
I0515 11:06:05.659062 22392998065984 run_lib.py:146] step: 297000, training_loss: 4.99613e-02
I0515 11:06:05.817832 22392998065984 run_lib.py:167] step: 297000, eval_loss: 6.39484e-02
I0515 11:06:29.751108 22392998065984 run_lib.py:146] step: 297050, training_loss: 3.93115e-02
I0515 11:06:53.955695 22392998065984 run_lib.py:146] step: 297100, training_loss: 7.49652e-02
I0515 11:06:54.135415 22392998065984 run_lib.py:167] step: 297100, eval_loss: 5.15541e-02
I0515 11:07:18.286849 22392998065984 run_lib.py:146] step: 297150, training_loss: 4.69677e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:07:42.513262 22392998065984 run_lib.py:146] step: 297200, training_loss: 3.72299e-02
I0515 11:07:42.682542 22392998065984 run_lib.py:167] step: 297200, eval_loss: 6.02842e-02
I0515 11:08:06.632007 22392998065984 run_lib.py:146] step: 297250, training_loss: 4.25231e-02
I0515 11:08:31.332330 22392998065984 run_lib.py:146] step: 297300, training_loss: 4.71788e-02
I0515 11:08:31.490301 22392998065984 run_lib.py:167] step: 297300, eval_loss: 6.78004e-02
I0515 11:08:55.403324 22392998065984 run_lib.py:146] step: 297350, training_loss: 5.53886e-02
I0515 11:09:19.304916 22392998065984 run_lib.py:146] step: 297400, training_loss: 6.44467e-02
I0515 11:09:19.487782 22392998065984 run_lib.py:167] step: 297400, eval_loss: 5.49664e-02
I0515 11:09:44.060717 22392998065984 run_lib.py:146] step: 297450, training_loss: 5.67914e-02
I0515 11:10:07.969772 22392998065984 run_lib.py:146] step: 297500, training_loss: 6.05124e-02
I0515 11:10:08.128641 22392998065984 run_lib.py:167] step: 297500, eval_loss: 9.09707e-02
I0515 11:10:31.937615 22392998065984 run_lib.py:146] step: 297550, training_loss: 4.91665e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:10:56.862652 22392998065984 run_lib.py:146] step: 297600, training_loss: 4.94091e-02
I0515 11:10:57.022183 22392998065984 run_lib.py:167] step: 297600, eval_loss: 7.83316e-02
I0515 11:11:21.017918 22392998065984 run_lib.py:146] step: 297650, training_loss: 4.36260e-02
I0515 11:11:44.949024 22392998065984 run_lib.py:146] step: 297700, training_loss: 5.09760e-02
I0515 11:11:45.115949 22392998065984 run_lib.py:167] step: 297700, eval_loss: 6.74845e-02
I0515 11:12:09.712768 22392998065984 run_lib.py:146] step: 297750, training_loss: 7.67552e-02
I0515 11:12:33.901829 22392998065984 run_lib.py:146] step: 297800, training_loss: 5.97286e-02
I0515 11:12:34.061073 22392998065984 run_lib.py:167] step: 297800, eval_loss: 8.24620e-02
I0515 11:12:58.412975 22392998065984 run_lib.py:146] step: 297850, training_loss: 4.36720e-02
I0515 11:13:23.038271 22392998065984 run_lib.py:146] step: 297900, training_loss: 5.87330e-02
I0515 11:13:23.221110 22392998065984 run_lib.py:167] step: 297900, eval_loss: 7.51716e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:13:47.982499 22392998065984 run_lib.py:146] step: 297950, training_loss: 6.69294e-02
I0515 11:14:12.408566 22392998065984 run_lib.py:146] step: 298000, training_loss: 4.78225e-02
I0515 11:14:12.578186 22392998065984 run_lib.py:167] step: 298000, eval_loss: 4.73022e-02
I0515 11:14:37.044785 22392998065984 run_lib.py:146] step: 298050, training_loss: 6.82039e-02
I0515 11:15:02.106455 22392998065984 run_lib.py:146] step: 298100, training_loss: 5.24552e-02
I0515 11:15:02.267734 22392998065984 run_lib.py:167] step: 298100, eval_loss: 5.12517e-02
I0515 11:15:26.644910 22392998065984 run_lib.py:146] step: 298150, training_loss: 5.96903e-02
I0515 11:15:50.980549 22392998065984 run_lib.py:146] step: 298200, training_loss: 5.56409e-02
I0515 11:15:51.140868 22392998065984 run_lib.py:167] step: 298200, eval_loss: 5.08287e-02
I0515 11:16:16.105686 22392998065984 run_lib.py:146] step: 298250, training_loss: 4.82308e-02
I0515 11:16:40.342306 22392998065984 run_lib.py:146] step: 298300, training_loss: 5.24963e-02
I0515 11:16:40.512535 22392998065984 run_lib.py:167] step: 298300, eval_loss: 5.49312e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:17:04.890702 22392998065984 run_lib.py:146] step: 298350, training_loss: 4.54867e-02
I0515 11:17:29.955750 22392998065984 run_lib.py:146] step: 298400, training_loss: 6.19311e-02
I0515 11:17:30.121444 22392998065984 run_lib.py:167] step: 298400, eval_loss: 4.26720e-02
I0515 11:17:54.503239 22392998065984 run_lib.py:146] step: 298450, training_loss: 7.64291e-02
I0515 11:18:18.791496 22392998065984 run_lib.py:146] step: 298500, training_loss: 5.54203e-02
I0515 11:18:18.952793 22392998065984 run_lib.py:167] step: 298500, eval_loss: 4.88195e-02
I0515 11:18:43.954640 22392998065984 run_lib.py:146] step: 298550, training_loss: 5.93784e-02
I0515 11:19:08.202766 22392998065984 run_lib.py:146] step: 298600, training_loss: 5.63853e-02
I0515 11:19:08.362827 22392998065984 run_lib.py:167] step: 298600, eval_loss: 6.05265e-02
I0515 11:19:32.648428 22392998065984 run_lib.py:146] step: 298650, training_loss: 6.67062e-02
I0515 11:19:57.695044 22392998065984 run_lib.py:146] step: 298700, training_loss: 7.12458e-02
I0515 11:19:57.855246 22392998065984 run_lib.py:167] step: 298700, eval_loss: 6.57554e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:20:22.173962 22392998065984 run_lib.py:146] step: 298750, training_loss: 7.50405e-02
I0515 11:20:46.461524 22392998065984 run_lib.py:146] step: 298800, training_loss: 5.03161e-02
I0515 11:20:46.626590 22392998065984 run_lib.py:167] step: 298800, eval_loss: 5.53724e-02
I0515 11:21:11.149955 22392998065984 run_lib.py:146] step: 298850, training_loss: 4.54411e-02
I0515 11:21:35.585074 22392998065984 run_lib.py:146] step: 298900, training_loss: 6.43804e-02
I0515 11:21:35.746679 22392998065984 run_lib.py:167] step: 298900, eval_loss: 4.80029e-02
I0515 11:22:00.058404 22392998065984 run_lib.py:146] step: 298950, training_loss: 4.80335e-02
I0515 11:22:24.519026 22392998065984 run_lib.py:146] step: 299000, training_loss: 6.24560e-02
I0515 11:22:24.684690 22392998065984 run_lib.py:167] step: 299000, eval_loss: 6.18355e-02
I0515 11:22:49.853108 22392998065984 run_lib.py:146] step: 299050, training_loss: 5.46073e-02
I0515 11:23:14.153986 22392998065984 run_lib.py:146] step: 299100, training_loss: 4.81623e-02
I0515 11:23:14.332406 22392998065984 run_lib.py:167] step: 299100, eval_loss: 6.46402e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:23:38.614815 22392998065984 run_lib.py:146] step: 299150, training_loss: 7.45049e-02
I0515 11:24:03.449733 22392998065984 run_lib.py:146] step: 299200, training_loss: 6.80987e-02
I0515 11:24:03.616033 22392998065984 run_lib.py:167] step: 299200, eval_loss: 9.16956e-02
I0515 11:24:28.065885 22392998065984 run_lib.py:146] step: 299250, training_loss: 6.18961e-02
I0515 11:24:52.367576 22392998065984 run_lib.py:146] step: 299300, training_loss: 5.37651e-02
I0515 11:24:52.528477 22392998065984 run_lib.py:167] step: 299300, eval_loss: 5.28938e-02
I0515 11:25:17.157897 22392998065984 run_lib.py:146] step: 299350, training_loss: 6.92733e-02
I0515 11:25:41.135889 22392998065984 run_lib.py:146] step: 299400, training_loss: 4.97921e-02
I0515 11:25:41.298710 22392998065984 run_lib.py:167] step: 299400, eval_loss: 6.37173e-02
I0515 11:26:05.452283 22392998065984 run_lib.py:146] step: 299450, training_loss: 6.30097e-02
I0515 11:26:30.561993 22392998065984 run_lib.py:146] step: 299500, training_loss: 6.08318e-02
I0515 11:26:30.723782 22392998065984 run_lib.py:167] step: 299500, eval_loss: 3.99709e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:26:55.105823 22392998065984 run_lib.py:146] step: 299550, training_loss: 5.56997e-02
I0515 11:27:19.325455 22392998065984 run_lib.py:146] step: 299600, training_loss: 4.72257e-02
I0515 11:27:19.489159 22392998065984 run_lib.py:167] step: 299600, eval_loss: 7.36151e-02
I0515 11:27:44.614590 22392998065984 run_lib.py:146] step: 299650, training_loss: 6.07501e-02
I0515 11:28:08.826106 22392998065984 run_lib.py:146] step: 299700, training_loss: 6.22003e-02
I0515 11:28:08.986251 22392998065984 run_lib.py:167] step: 299700, eval_loss: 5.26906e-02
I0515 11:28:33.217903 22392998065984 run_lib.py:146] step: 299750, training_loss: 4.59124e-02
I0515 11:28:57.529554 22392998065984 run_lib.py:146] step: 299800, training_loss: 6.59589e-02
I0515 11:28:57.691915 22392998065984 run_lib.py:167] step: 299800, eval_loss: 6.28226e-02
I0515 11:29:22.727629 22392998065984 run_lib.py:146] step: 299850, training_loss: 6.38707e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:29:47.148776 22392998065984 run_lib.py:146] step: 299900, training_loss: 6.18579e-02
I0515 11:29:47.311517 22392998065984 run_lib.py:167] step: 299900, eval_loss: 5.85797e-02
I0515 11:30:11.580261 22392998065984 run_lib.py:146] step: 299950, training_loss: 3.92518e-02
I0515 11:30:36.377651 22392998065984 run_lib.py:146] step: 300000, training_loss: 6.03401e-02
I0515 11:30:38.251109 22392998065984 run_lib.py:167] step: 300000, eval_loss: 4.94291e-02
I0515 11:31:04.138592 22392998065984 run_lib.py:146] step: 300050, training_loss: 4.95845e-02
I0515 11:31:28.795506 22392998065984 run_lib.py:146] step: 300100, training_loss: 7.70656e-02
I0515 11:31:28.906767 22392998065984 run_lib.py:167] step: 300100, eval_loss: 7.49873e-02
I0515 11:31:53.544519 22392998065984 run_lib.py:146] step: 300150, training_loss: 7.42301e-02
I0515 11:32:17.873289 22392998065984 run_lib.py:146] step: 300200, training_loss: 5.59423e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:32:18.320586 22392998065984 run_lib.py:167] step: 300200, eval_loss: 5.74082e-02
I0515 11:32:43.048966 22392998065984 run_lib.py:146] step: 300250, training_loss: 5.25435e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:33:07.684059 22392998065984 run_lib.py:146] step: 300300, training_loss: 5.70156e-02
I0515 11:33:07.848361 22392998065984 run_lib.py:167] step: 300300, eval_loss: 5.79214e-02
I0515 11:33:32.028922 22392998065984 run_lib.py:146] step: 300350, training_loss: 7.17685e-02
I0515 11:33:56.962162 22392998065984 run_lib.py:146] step: 300400, training_loss: 5.42747e-02
I0515 11:33:57.126206 22392998065984 run_lib.py:167] step: 300400, eval_loss: 6.95554e-02
I0515 11:34:21.900645 22392998065984 run_lib.py:146] step: 300450, training_loss: 6.35816e-02
I0515 11:34:46.156026 22392998065984 run_lib.py:146] step: 300500, training_loss: 4.51723e-02
I0515 11:34:46.329698 22392998065984 run_lib.py:167] step: 300500, eval_loss: 6.60997e-02
I0515 11:35:10.623133 22392998065984 run_lib.py:146] step: 300550, training_loss: 5.50625e-02
I0515 11:35:35.222585 22392998065984 run_lib.py:146] step: 300600, training_loss: 5.69056e-02
I0515 11:35:35.382963 22392998065984 run_lib.py:167] step: 300600, eval_loss: 5.31353e-02
I0515 11:35:59.979839 22392998065984 run_lib.py:146] step: 300650, training_loss: 5.78756e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:36:24.483863 22392998065984 run_lib.py:146] step: 300700, training_loss: 8.19086e-02
I0515 11:36:24.645833 22392998065984 run_lib.py:167] step: 300700, eval_loss: 6.32632e-02
I0515 11:36:49.393229 22392998065984 run_lib.py:146] step: 300750, training_loss: 5.41272e-02
I0515 11:37:14.194653 22392998065984 run_lib.py:146] step: 300800, training_loss: 5.86636e-02
I0515 11:37:14.361763 22392998065984 run_lib.py:167] step: 300800, eval_loss: 5.51389e-02
I0515 11:37:38.702526 22392998065984 run_lib.py:146] step: 300850, training_loss: 5.62694e-02
I0515 11:38:03.362594 22392998065984 run_lib.py:146] step: 300900, training_loss: 5.99898e-02
I0515 11:38:03.521283 22392998065984 run_lib.py:167] step: 300900, eval_loss: 6.30446e-02
I0515 11:38:28.099309 22392998065984 run_lib.py:146] step: 300950, training_loss: 4.91290e-02
I0515 11:38:52.342659 22392998065984 run_lib.py:146] step: 301000, training_loss: 5.52033e-02
I0515 11:38:52.504202 22392998065984 run_lib.py:167] step: 301000, eval_loss: 7.21856e-02
I0515 11:39:17.058380 22392998065984 run_lib.py:146] step: 301050, training_loss: 6.28289e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:39:41.911618 22392998065984 run_lib.py:146] step: 301100, training_loss: 4.30397e-02
I0515 11:39:42.074677 22392998065984 run_lib.py:167] step: 301100, eval_loss: 7.75072e-02
I0515 11:40:06.352569 22392998065984 run_lib.py:146] step: 301150, training_loss: 6.47583e-02
I0515 11:40:30.996702 22392998065984 run_lib.py:146] step: 301200, training_loss: 6.28943e-02
I0515 11:40:31.156658 22392998065984 run_lib.py:167] step: 301200, eval_loss: 7.52426e-02
I0515 11:40:55.842601 22392998065984 run_lib.py:146] step: 301250, training_loss: 8.91394e-02
I0515 11:41:20.072737 22392998065984 run_lib.py:146] step: 301300, training_loss: 7.07629e-02
I0515 11:41:20.275684 22392998065984 run_lib.py:167] step: 301300, eval_loss: 6.67594e-02
I0515 11:41:44.549502 22392998065984 run_lib.py:146] step: 301350, training_loss: 5.37085e-02
I0515 11:42:09.439213 22392998065984 run_lib.py:146] step: 301400, training_loss: 5.48708e-02
I0515 11:42:09.610666 22392998065984 run_lib.py:167] step: 301400, eval_loss: 6.14355e-02
I0515 11:42:33.891913 22392998065984 run_lib.py:146] step: 301450, training_loss: 5.49678e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:42:58.321314 22392998065984 run_lib.py:146] step: 301500, training_loss: 8.85356e-02
I0515 11:42:58.505224 22392998065984 run_lib.py:167] step: 301500, eval_loss: 8.69738e-02
I0515 11:43:23.140526 22392998065984 run_lib.py:146] step: 301550, training_loss: 6.80824e-02
I0515 11:43:47.848334 22392998065984 run_lib.py:146] step: 301600, training_loss: 5.26815e-02
I0515 11:43:48.018759 22392998065984 run_lib.py:167] step: 301600, eval_loss: 5.17092e-02
I0515 11:44:12.327231 22392998065984 run_lib.py:146] step: 301650, training_loss: 5.55947e-02
I0515 11:44:36.941886 22392998065984 run_lib.py:146] step: 301700, training_loss: 6.63386e-02
I0515 11:44:37.106973 22392998065984 run_lib.py:167] step: 301700, eval_loss: 5.51840e-02
I0515 11:45:01.647157 22392998065984 run_lib.py:146] step: 301750, training_loss: 8.15662e-02
I0515 11:45:25.914915 22392998065984 run_lib.py:146] step: 301800, training_loss: 5.53502e-02
I0515 11:45:26.075497 22392998065984 run_lib.py:167] step: 301800, eval_loss: 5.87302e-02
I0515 11:45:50.680219 22392998065984 run_lib.py:146] step: 301850, training_loss: 5.67728e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:46:15.355370 22392998065984 run_lib.py:146] step: 301900, training_loss: 6.59304e-02
I0515 11:46:15.519862 22392998065984 run_lib.py:167] step: 301900, eval_loss: 5.03475e-02
I0515 11:46:39.842639 22392998065984 run_lib.py:146] step: 301950, training_loss: 6.03670e-02
I0515 11:47:04.592727 22392998065984 run_lib.py:146] step: 302000, training_loss: 4.21274e-02
I0515 11:47:04.758329 22392998065984 run_lib.py:167] step: 302000, eval_loss: 7.10826e-02
I0515 11:47:29.594067 22392998065984 run_lib.py:146] step: 302050, training_loss: 5.22875e-02
I0515 11:47:53.900128 22392998065984 run_lib.py:146] step: 302100, training_loss: 7.49476e-02
I0515 11:47:54.060625 22392998065984 run_lib.py:167] step: 302100, eval_loss: 6.58840e-02
I0515 11:48:18.430280 22392998065984 run_lib.py:146] step: 302150, training_loss: 4.13269e-02
I0515 11:48:43.427336 22392998065984 run_lib.py:146] step: 302200, training_loss: 4.13151e-02
I0515 11:48:43.604382 22392998065984 run_lib.py:167] step: 302200, eval_loss: 5.13876e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:49:08.223661 22392998065984 run_lib.py:146] step: 302250, training_loss: 6.90702e-02
I0515 11:49:32.499358 22392998065984 run_lib.py:146] step: 302300, training_loss: 4.35715e-02
I0515 11:49:32.664488 22392998065984 run_lib.py:167] step: 302300, eval_loss: 7.86998e-02
I0515 11:49:57.524559 22392998065984 run_lib.py:146] step: 302350, training_loss: 5.81808e-02
I0515 11:50:22.248513 22392998065984 run_lib.py:146] step: 302400, training_loss: 5.76266e-02
I0515 11:50:22.419425 22392998065984 run_lib.py:167] step: 302400, eval_loss: 6.34202e-02
I0515 11:50:46.674493 22392998065984 run_lib.py:146] step: 302450, training_loss: 5.16612e-02
I0515 11:51:11.489290 22392998065984 run_lib.py:146] step: 302500, training_loss: 4.66979e-02
I0515 11:51:11.649742 22392998065984 run_lib.py:167] step: 302500, eval_loss: 6.26728e-02
I0515 11:51:36.523069 22392998065984 run_lib.py:146] step: 302550, training_loss: 5.37962e-02
I0515 11:52:01.066493 22392998065984 run_lib.py:146] step: 302600, training_loss: 5.63169e-02
I0515 11:52:01.226796 22392998065984 run_lib.py:167] step: 302600, eval_loss: 7.58468e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:52:26.144946 22392998065984 run_lib.py:146] step: 302650, training_loss: 5.94561e-02
I0515 11:52:50.842473 22392998065984 run_lib.py:146] step: 302700, training_loss: 5.26283e-02
I0515 11:52:51.008585 22392998065984 run_lib.py:167] step: 302700, eval_loss: 6.29527e-02
I0515 11:53:15.354494 22392998065984 run_lib.py:146] step: 302750, training_loss: 4.37200e-02
I0515 11:53:39.933204 22392998065984 run_lib.py:146] step: 302800, training_loss: 8.58354e-02
I0515 11:53:40.094243 22392998065984 run_lib.py:167] step: 302800, eval_loss: 6.95996e-02
I0515 11:54:04.728027 22392998065984 run_lib.py:146] step: 302850, training_loss: 6.44967e-02
I0515 11:54:29.011100 22392998065984 run_lib.py:146] step: 302900, training_loss: 6.38537e-02
I0515 11:54:29.170878 22392998065984 run_lib.py:167] step: 302900, eval_loss: 7.66980e-02
I0515 11:54:53.501452 22392998065984 run_lib.py:146] step: 302950, training_loss: 6.59948e-02
I0515 11:55:18.462828 22392998065984 run_lib.py:146] step: 303000, training_loss: 5.94834e-02
I0515 11:55:18.623791 22392998065984 run_lib.py:167] step: 303000, eval_loss: 4.25421e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:55:43.078476 22392998065984 run_lib.py:146] step: 303050, training_loss: 6.04928e-02
I0515 11:56:07.416783 22392998065984 run_lib.py:146] step: 303100, training_loss: 5.50826e-02
I0515 11:56:07.579067 22392998065984 run_lib.py:167] step: 303100, eval_loss: 6.25918e-02
I0515 11:56:32.592521 22392998065984 run_lib.py:146] step: 303150, training_loss: 5.75351e-02
I0515 11:56:56.932977 22392998065984 run_lib.py:146] step: 303200, training_loss: 4.49129e-02
I0515 11:56:57.103071 22392998065984 run_lib.py:167] step: 303200, eval_loss: 4.92662e-02
I0515 11:57:21.423439 22392998065984 run_lib.py:146] step: 303250, training_loss: 7.12743e-02
I0515 11:57:46.040846 22392998065984 run_lib.py:146] step: 303300, training_loss: 5.53074e-02
I0515 11:57:46.223259 22392998065984 run_lib.py:167] step: 303300, eval_loss: 5.54156e-02
I0515 11:58:10.824213 22392998065984 run_lib.py:146] step: 303350, training_loss: 5.01980e-02
I0515 11:58:35.129603 22392998065984 run_lib.py:146] step: 303400, training_loss: 4.71420e-02
I0515 11:58:35.290507 22392998065984 run_lib.py:167] step: 303400, eval_loss: 4.72375e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 11:59:00.298735 22392998065984 run_lib.py:146] step: 303450, training_loss: 4.79688e-02
I0515 11:59:25.040898 22392998065984 run_lib.py:146] step: 303500, training_loss: 6.98355e-02
I0515 11:59:25.203276 22392998065984 run_lib.py:167] step: 303500, eval_loss: 7.37394e-02
I0515 11:59:49.664902 22392998065984 run_lib.py:146] step: 303550, training_loss: 5.43090e-02
I0515 12:00:14.440409 22392998065984 run_lib.py:146] step: 303600, training_loss: 5.48087e-02
I0515 12:00:14.609058 22392998065984 run_lib.py:167] step: 303600, eval_loss: 5.21511e-02
I0515 12:00:39.395883 22392998065984 run_lib.py:146] step: 303650, training_loss: 6.69543e-02
I0515 12:01:03.733906 22392998065984 run_lib.py:146] step: 303700, training_loss: 5.36324e-02
I0515 12:01:03.902963 22392998065984 run_lib.py:167] step: 303700, eval_loss: 7.11891e-02
I0515 12:01:28.199800 22392998065984 run_lib.py:146] step: 303750, training_loss: 4.85411e-02
I0515 12:01:53.317936 22392998065984 run_lib.py:146] step: 303800, training_loss: 5.87817e-02
I0515 12:01:53.486833 22392998065984 run_lib.py:167] step: 303800, eval_loss: 6.43326e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:02:18.091634 22392998065984 run_lib.py:146] step: 303850, training_loss: 5.71096e-02
I0515 12:02:42.442243 22392998065984 run_lib.py:146] step: 303900, training_loss: 5.47492e-02
I0515 12:02:42.628425 22392998065984 run_lib.py:167] step: 303900, eval_loss: 4.17214e-02
I0515 12:03:07.694861 22392998065984 run_lib.py:146] step: 303950, training_loss: 6.72897e-02
I0515 12:03:32.018090 22392998065984 run_lib.py:146] step: 304000, training_loss: 5.05636e-02
I0515 12:03:32.202555 22392998065984 run_lib.py:167] step: 304000, eval_loss: 5.79032e-02
I0515 12:03:56.591094 22392998065984 run_lib.py:146] step: 304050, training_loss: 4.96482e-02
I0515 12:04:21.236755 22392998065984 run_lib.py:146] step: 304100, training_loss: 7.20838e-02
I0515 12:04:21.397267 22392998065984 run_lib.py:167] step: 304100, eval_loss: 5.00010e-02
I0515 12:04:46.067492 22392998065984 run_lib.py:146] step: 304150, training_loss: 5.26896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:05:10.541181 22392998065984 run_lib.py:146] step: 304200, training_loss: 6.13847e-02
I0515 12:05:10.711849 22392998065984 run_lib.py:167] step: 304200, eval_loss: 5.72424e-02
I0515 12:05:35.078182 22392998065984 run_lib.py:146] step: 304250, training_loss: 5.01058e-02
I0515 12:05:59.597343 22392998065984 run_lib.py:146] step: 304300, training_loss: 6.94029e-02
I0515 12:05:59.758685 22392998065984 run_lib.py:167] step: 304300, eval_loss: 6.53253e-02
I0515 12:06:23.930747 22392998065984 run_lib.py:146] step: 304350, training_loss: 5.42471e-02
I0515 12:06:48.627409 22392998065984 run_lib.py:146] step: 304400, training_loss: 5.73242e-02
I0515 12:06:48.786661 22392998065984 run_lib.py:167] step: 304400, eval_loss: 5.24475e-02
I0515 12:07:13.386765 22392998065984 run_lib.py:146] step: 304450, training_loss: 6.39344e-02
I0515 12:07:37.543831 22392998065984 run_lib.py:146] step: 304500, training_loss: 4.76523e-02
I0515 12:07:37.713516 22392998065984 run_lib.py:167] step: 304500, eval_loss: 8.00043e-02
I0515 12:08:02.007743 22392998065984 run_lib.py:146] step: 304550, training_loss: 4.30321e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:08:27.123432 22392998065984 run_lib.py:146] step: 304600, training_loss: 5.77689e-02
I0515 12:08:27.288674 22392998065984 run_lib.py:167] step: 304600, eval_loss: 6.43937e-02
I0515 12:08:51.642557 22392998065984 run_lib.py:146] step: 304650, training_loss: 7.23598e-02
I0515 12:09:16.050858 22392998065984 run_lib.py:146] step: 304700, training_loss: 5.38537e-02
I0515 12:09:16.219769 22392998065984 run_lib.py:167] step: 304700, eval_loss: 4.45969e-02
I0515 12:09:41.329002 22392998065984 run_lib.py:146] step: 304750, training_loss: 5.01283e-02
I0515 12:10:05.582182 22392998065984 run_lib.py:146] step: 304800, training_loss: 5.63720e-02
I0515 12:10:05.750629 22392998065984 run_lib.py:167] step: 304800, eval_loss: 5.24729e-02
I0515 12:10:30.041715 22392998065984 run_lib.py:146] step: 304850, training_loss: 4.12542e-02
I0515 12:10:54.585493 22392998065984 run_lib.py:146] step: 304900, training_loss: 6.85391e-02
I0515 12:10:54.767519 22392998065984 run_lib.py:167] step: 304900, eval_loss: 6.80001e-02
I0515 12:11:19.361439 22392998065984 run_lib.py:146] step: 304950, training_loss: 7.14555e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:11:43.870883 22392998065984 run_lib.py:146] step: 305000, training_loss: 5.29385e-02
I0515 12:11:44.033358 22392998065984 run_lib.py:167] step: 305000, eval_loss: 5.83215e-02
I0515 12:12:08.505195 22392998065984 run_lib.py:146] step: 305050, training_loss: 4.99767e-02
I0515 12:12:32.844384 22392998065984 run_lib.py:146] step: 305100, training_loss: 5.76641e-02
I0515 12:12:33.004778 22392998065984 run_lib.py:167] step: 305100, eval_loss: 5.73909e-02
I0515 12:12:57.314996 22392998065984 run_lib.py:146] step: 305150, training_loss: 6.43567e-02
I0515 12:13:21.936607 22392998065984 run_lib.py:146] step: 305200, training_loss: 5.64134e-02
I0515 12:13:22.095929 22392998065984 run_lib.py:167] step: 305200, eval_loss: 4.45339e-02
I0515 12:13:46.834467 22392998065984 run_lib.py:146] step: 305250, training_loss: 6.43947e-02
I0515 12:14:11.109639 22392998065984 run_lib.py:146] step: 305300, training_loss: 5.04956e-02
I0515 12:14:11.269218 22392998065984 run_lib.py:167] step: 305300, eval_loss: 5.76153e-02
I0515 12:14:35.575445 22392998065984 run_lib.py:146] step: 305350, training_loss: 5.42932e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:15:00.914366 22392998065984 run_lib.py:146] step: 305400, training_loss: 5.04507e-02
I0515 12:15:01.083829 22392998065984 run_lib.py:167] step: 305400, eval_loss: 6.68795e-02
I0515 12:15:25.304055 22392998065984 run_lib.py:146] step: 305450, training_loss: 6.57355e-02
I0515 12:15:49.793336 22392998065984 run_lib.py:146] step: 305500, training_loss: 5.00824e-02
I0515 12:15:49.960484 22392998065984 run_lib.py:167] step: 305500, eval_loss: 7.00921e-02
I0515 12:16:15.329629 22392998065984 run_lib.py:146] step: 305550, training_loss: 6.70682e-02
I0515 12:16:39.730973 22392998065984 run_lib.py:146] step: 305600, training_loss: 5.33597e-02
I0515 12:16:39.892925 22392998065984 run_lib.py:167] step: 305600, eval_loss: 7.35575e-02
I0515 12:17:04.137088 22392998065984 run_lib.py:146] step: 305650, training_loss: 6.01497e-02
I0515 12:17:28.788298 22392998065984 run_lib.py:146] step: 305700, training_loss: 4.01754e-02
I0515 12:17:28.957998 22392998065984 run_lib.py:167] step: 305700, eval_loss: 6.77792e-02
I0515 12:17:53.603105 22392998065984 run_lib.py:146] step: 305750, training_loss: 6.24347e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:18:18.206842 22392998065984 run_lib.py:146] step: 305800, training_loss: 6.24465e-02
I0515 12:18:18.370004 22392998065984 run_lib.py:167] step: 305800, eval_loss: 5.56984e-02
I0515 12:18:43.075210 22392998065984 run_lib.py:146] step: 305850, training_loss: 5.54257e-02
I0515 12:19:07.774839 22392998065984 run_lib.py:146] step: 305900, training_loss: 4.83164e-02
I0515 12:19:07.949142 22392998065984 run_lib.py:167] step: 305900, eval_loss: 4.48704e-02
I0515 12:19:32.264675 22392998065984 run_lib.py:146] step: 305950, training_loss: 4.69246e-02
I0515 12:19:56.905233 22392998065984 run_lib.py:146] step: 306000, training_loss: 6.58591e-02
I0515 12:19:57.066481 22392998065984 run_lib.py:167] step: 306000, eval_loss: 5.67671e-02
I0515 12:20:21.780005 22392998065984 run_lib.py:146] step: 306050, training_loss: 6.81439e-02
I0515 12:20:46.145884 22392998065984 run_lib.py:146] step: 306100, training_loss: 5.78842e-02
I0515 12:20:47.914263 22392998065984 run_lib.py:167] step: 306100, eval_loss: 6.06647e-02
I0515 12:21:12.170928 22392998065984 run_lib.py:146] step: 306150, training_loss: 6.47021e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:21:37.439258 22392998065984 run_lib.py:146] step: 306200, training_loss: 5.07806e-02
I0515 12:21:37.612380 22392998065984 run_lib.py:167] step: 306200, eval_loss: 3.78724e-02
I0515 12:22:01.941674 22392998065984 run_lib.py:146] step: 306250, training_loss: 7.54545e-02
I0515 12:22:26.100009 22392998065984 run_lib.py:146] step: 306300, training_loss: 5.79629e-02
I0515 12:22:26.261424 22392998065984 run_lib.py:167] step: 306300, eval_loss: 7.15665e-02
I0515 12:22:51.145720 22392998065984 run_lib.py:146] step: 306350, training_loss: 5.64031e-02
I0515 12:23:15.455376 22392998065984 run_lib.py:146] step: 306400, training_loss: 5.39643e-02
I0515 12:23:15.626450 22392998065984 run_lib.py:167] step: 306400, eval_loss: 6.87291e-02
I0515 12:23:39.731026 22392998065984 run_lib.py:146] step: 306450, training_loss: 4.95480e-02
I0515 12:24:04.346394 22392998065984 run_lib.py:146] step: 306500, training_loss: 5.49361e-02
I0515 12:24:04.507360 22392998065984 run_lib.py:167] step: 306500, eval_loss: 6.70016e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:24:29.353537 22392998065984 run_lib.py:146] step: 306550, training_loss: 6.79625e-02
I0515 12:24:53.782521 22392998065984 run_lib.py:146] step: 306600, training_loss: 5.89498e-02
I0515 12:24:53.954227 22392998065984 run_lib.py:167] step: 306600, eval_loss: 4.67443e-02
I0515 12:25:18.624738 22392998065984 run_lib.py:146] step: 306650, training_loss: 6.29850e-02
I0515 12:25:43.317711 22392998065984 run_lib.py:146] step: 306700, training_loss: 5.78215e-02
I0515 12:25:43.478661 22392998065984 run_lib.py:167] step: 306700, eval_loss: 6.05332e-02
I0515 12:26:07.825871 22392998065984 run_lib.py:146] step: 306750, training_loss: 6.60672e-02
I0515 12:26:32.429248 22392998065984 run_lib.py:146] step: 306800, training_loss: 7.57495e-02
I0515 12:26:32.590680 22392998065984 run_lib.py:167] step: 306800, eval_loss: 5.20679e-02
I0515 12:26:57.275959 22392998065984 run_lib.py:146] step: 306850, training_loss: 6.41778e-02
I0515 12:27:21.612056 22392998065984 run_lib.py:146] step: 306900, training_loss: 5.32108e-02
I0515 12:27:21.772247 22392998065984 run_lib.py:167] step: 306900, eval_loss: 4.50702e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:27:46.676875 22392998065984 run_lib.py:146] step: 306950, training_loss: 6.05562e-02
I0515 12:28:11.235505 22392998065984 run_lib.py:146] step: 307000, training_loss: 7.56319e-02
I0515 12:28:11.421880 22392998065984 run_lib.py:167] step: 307000, eval_loss: 6.33692e-02
I0515 12:28:35.414546 22392998065984 run_lib.py:146] step: 307050, training_loss: 6.15095e-02
I0515 12:28:59.733449 22392998065984 run_lib.py:146] step: 307100, training_loss: 5.65297e-02
I0515 12:28:59.894517 22392998065984 run_lib.py:167] step: 307100, eval_loss: 6.19663e-02
I0515 12:29:24.891843 22392998065984 run_lib.py:146] step: 307150, training_loss: 4.83638e-02
I0515 12:29:49.227770 22392998065984 run_lib.py:146] step: 307200, training_loss: 6.39118e-02
I0515 12:29:49.393657 22392998065984 run_lib.py:167] step: 307200, eval_loss: 7.43659e-02
I0515 12:30:13.677497 22392998065984 run_lib.py:146] step: 307250, training_loss: 4.01726e-02
I0515 12:30:38.760767 22392998065984 run_lib.py:146] step: 307300, training_loss: 4.90391e-02
I0515 12:30:38.926692 22392998065984 run_lib.py:167] step: 307300, eval_loss: 5.98932e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:31:03.379316 22392998065984 run_lib.py:146] step: 307350, training_loss: 5.52211e-02
I0515 12:31:27.758543 22392998065984 run_lib.py:146] step: 307400, training_loss: 5.73421e-02
I0515 12:31:27.930664 22392998065984 run_lib.py:167] step: 307400, eval_loss: 5.84062e-02
I0515 12:31:52.650162 22392998065984 run_lib.py:146] step: 307450, training_loss: 5.16948e-02
I0515 12:32:17.319298 22392998065984 run_lib.py:146] step: 307500, training_loss: 6.10911e-02
I0515 12:32:17.481517 22392998065984 run_lib.py:167] step: 307500, eval_loss: 5.23506e-02
I0515 12:32:41.773491 22392998065984 run_lib.py:146] step: 307550, training_loss: 5.28105e-02
I0515 12:33:06.392922 22392998065984 run_lib.py:146] step: 307600, training_loss: 6.67068e-02
I0515 12:33:06.578441 22392998065984 run_lib.py:167] step: 307600, eval_loss: 5.81693e-02
I0515 12:33:31.232203 22392998065984 run_lib.py:146] step: 307650, training_loss: 6.63026e-02
I0515 12:33:55.706802 22392998065984 run_lib.py:146] step: 307700, training_loss: 6.86483e-02
I0515 12:33:55.868228 22392998065984 run_lib.py:167] step: 307700, eval_loss: 6.71384e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:34:20.631206 22392998065984 run_lib.py:146] step: 307750, training_loss: 4.90004e-02
I0515 12:34:44.979886 22392998065984 run_lib.py:146] step: 307800, training_loss: 5.46560e-02
I0515 12:34:45.142695 22392998065984 run_lib.py:167] step: 307800, eval_loss: 7.22376e-02
I0515 12:35:09.344528 22392998065984 run_lib.py:146] step: 307850, training_loss: 6.40413e-02
I0515 12:35:33.670367 22392998065984 run_lib.py:146] step: 307900, training_loss: 6.78919e-02
I0515 12:35:33.829514 22392998065984 run_lib.py:167] step: 307900, eval_loss: 5.65918e-02
I0515 12:35:58.812452 22392998065984 run_lib.py:146] step: 307950, training_loss: 6.58559e-02
I0515 12:36:23.027910 22392998065984 run_lib.py:146] step: 308000, training_loss: 6.02858e-02
I0515 12:36:23.117122 22392998065984 run_lib.py:167] step: 308000, eval_loss: 4.84770e-02
I0515 12:36:47.537153 22392998065984 run_lib.py:146] step: 308050, training_loss: 4.86299e-02
I0515 12:37:12.462764 22392998065984 run_lib.py:146] step: 308100, training_loss: 5.23071e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:37:12.974440 22392998065984 run_lib.py:167] step: 308100, eval_loss: 5.77822e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:37:37.311393 22392998065984 run_lib.py:146] step: 308150, training_loss: 7.35114e-02
I0515 12:38:01.127529 22392998065984 run_lib.py:146] step: 308200, training_loss: 4.32361e-02
I0515 12:38:01.292190 22392998065984 run_lib.py:167] step: 308200, eval_loss: 6.14012e-02
I0515 12:38:25.601197 22392998065984 run_lib.py:146] step: 308250, training_loss: 6.57735e-02
I0515 12:38:50.211786 22392998065984 run_lib.py:146] step: 308300, training_loss: 6.63652e-02
I0515 12:38:50.370673 22392998065984 run_lib.py:167] step: 308300, eval_loss: 6.54658e-02
I0515 12:39:14.173558 22392998065984 run_lib.py:146] step: 308350, training_loss: 5.16535e-02
I0515 12:39:38.265589 22392998065984 run_lib.py:146] step: 308400, training_loss: 5.20206e-02
I0515 12:39:38.425732 22392998065984 run_lib.py:167] step: 308400, eval_loss: 5.72968e-02
I0515 12:40:02.490023 22392998065984 run_lib.py:146] step: 308450, training_loss: 6.16732e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:40:26.447684 22392998065984 run_lib.py:146] step: 308500, training_loss: 8.62260e-02
I0515 12:40:26.611153 22392998065984 run_lib.py:167] step: 308500, eval_loss: 3.84433e-02
I0515 12:40:51.331509 22392998065984 run_lib.py:146] step: 308550, training_loss: 5.38182e-02
I0515 12:41:16.035142 22392998065984 run_lib.py:146] step: 308600, training_loss: 4.79492e-02
I0515 12:41:16.212528 22392998065984 run_lib.py:167] step: 308600, eval_loss: 5.97352e-02
I0515 12:41:40.476816 22392998065984 run_lib.py:146] step: 308650, training_loss: 5.67035e-02
I0515 12:42:05.570554 22392998065984 run_lib.py:146] step: 308700, training_loss: 7.99351e-02
I0515 12:42:05.742072 22392998065984 run_lib.py:167] step: 308700, eval_loss: 6.46040e-02
I0515 12:42:30.395013 22392998065984 run_lib.py:146] step: 308750, training_loss: 5.51061e-02
I0515 12:42:54.795785 22392998065984 run_lib.py:146] step: 308800, training_loss: 5.88916e-02
I0515 12:42:54.963698 22392998065984 run_lib.py:167] step: 308800, eval_loss: 4.70358e-02
I0515 12:43:19.366310 22392998065984 run_lib.py:146] step: 308850, training_loss: 6.27329e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:43:44.525050 22392998065984 run_lib.py:146] step: 308900, training_loss: 5.02155e-02
I0515 12:43:44.688670 22392998065984 run_lib.py:167] step: 308900, eval_loss: 5.14683e-02
I0515 12:44:08.996412 22392998065984 run_lib.py:146] step: 308950, training_loss: 4.39707e-02
I0515 12:44:33.296298 22392998065984 run_lib.py:146] step: 309000, training_loss: 5.54891e-02
I0515 12:44:33.459593 22392998065984 run_lib.py:167] step: 309000, eval_loss: 6.82806e-02
I0515 12:44:58.528614 22392998065984 run_lib.py:146] step: 309050, training_loss: 6.34652e-02
I0515 12:45:22.931064 22392998065984 run_lib.py:146] step: 309100, training_loss: 5.61500e-02
I0515 12:45:23.092604 22392998065984 run_lib.py:167] step: 309100, eval_loss: 7.70870e-02
I0515 12:45:47.364827 22392998065984 run_lib.py:146] step: 309150, training_loss: 5.72183e-02
I0515 12:46:11.911959 22392998065984 run_lib.py:146] step: 309200, training_loss: 5.16940e-02
I0515 12:46:12.072035 22392998065984 run_lib.py:167] step: 309200, eval_loss: 5.30971e-02
I0515 12:46:36.711419 22392998065984 run_lib.py:146] step: 309250, training_loss: 4.16640e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:47:01.166066 22392998065984 run_lib.py:146] step: 309300, training_loss: 5.54601e-02
I0515 12:47:01.331224 22392998065984 run_lib.py:167] step: 309300, eval_loss: 7.74664e-02
I0515 12:47:26.039821 22392998065984 run_lib.py:146] step: 309350, training_loss: 5.53277e-02
I0515 12:47:50.734144 22392998065984 run_lib.py:146] step: 309400, training_loss: 6.69576e-02
I0515 12:47:50.896225 22392998065984 run_lib.py:167] step: 309400, eval_loss: 4.51953e-02
I0515 12:48:15.148044 22392998065984 run_lib.py:146] step: 309450, training_loss: 6.34337e-02
I0515 12:48:39.753512 22392998065984 run_lib.py:146] step: 309500, training_loss: 6.63436e-02
I0515 12:48:39.945387 22392998065984 run_lib.py:167] step: 309500, eval_loss: 7.38914e-02
I0515 12:49:04.574162 22392998065984 run_lib.py:146] step: 309550, training_loss: 6.54156e-02
I0515 12:49:28.904864 22392998065984 run_lib.py:146] step: 309600, training_loss: 6.03153e-02
I0515 12:49:29.065612 22392998065984 run_lib.py:167] step: 309600, eval_loss: 5.57313e-02
I0515 12:49:53.335453 22392998065984 run_lib.py:146] step: 309650, training_loss: 6.83962e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:50:18.565736 22392998065984 run_lib.py:146] step: 309700, training_loss: 4.71740e-02
I0515 12:50:18.736765 22392998065984 run_lib.py:167] step: 309700, eval_loss: 7.09751e-02
I0515 12:50:43.037003 22392998065984 run_lib.py:146] step: 309750, training_loss: 5.21887e-02
I0515 12:51:07.371340 22392998065984 run_lib.py:146] step: 309800, training_loss: 7.49560e-02
I0515 12:51:07.559636 22392998065984 run_lib.py:167] step: 309800, eval_loss: 5.22042e-02
I0515 12:51:32.801903 22392998065984 run_lib.py:146] step: 309850, training_loss: 7.11424e-02
I0515 12:51:57.333878 22392998065984 run_lib.py:146] step: 309900, training_loss: 6.23344e-02
I0515 12:51:57.495271 22392998065984 run_lib.py:167] step: 309900, eval_loss: 5.49444e-02
I0515 12:52:21.820390 22392998065984 run_lib.py:146] step: 309950, training_loss: 5.97091e-02
I0515 12:52:46.818648 22392998065984 run_lib.py:146] step: 310000, training_loss: 4.75287e-02
I0515 12:52:49.066152 22392998065984 run_lib.py:167] step: 310000, eval_loss: 8.33108e-02
I0515 12:53:14.782147 22392998065984 run_lib.py:146] step: 310050, training_loss: 6.96816e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:53:39.642119 22392998065984 run_lib.py:146] step: 310100, training_loss: 5.79153e-02
I0515 12:53:39.805796 22392998065984 run_lib.py:167] step: 310100, eval_loss: 8.46466e-02
I0515 12:54:03.932097 22392998065984 run_lib.py:146] step: 310150, training_loss: 5.60381e-02
I0515 12:54:28.293701 22392998065984 run_lib.py:146] step: 310200, training_loss: 6.37159e-02
I0515 12:54:28.471210 22392998065984 run_lib.py:167] step: 310200, eval_loss: 5.89330e-02
I0515 12:54:53.379487 22392998065984 run_lib.py:146] step: 310250, training_loss: 4.09381e-02
I0515 12:55:17.851535 22392998065984 run_lib.py:146] step: 310300, training_loss: 4.19856e-02
I0515 12:55:18.025529 22392998065984 run_lib.py:167] step: 310300, eval_loss: 6.02851e-02
I0515 12:55:42.660018 22392998065984 run_lib.py:146] step: 310350, training_loss: 5.29072e-02
I0515 12:56:06.993514 22392998065984 run_lib.py:146] step: 310400, training_loss: 5.99289e-02
I0515 12:56:07.165799 22392998065984 run_lib.py:167] step: 310400, eval_loss: 4.83833e-02
I0515 12:56:31.911071 22392998065984 run_lib.py:146] step: 310450, training_loss: 5.16023e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:56:56.906288 22392998065984 run_lib.py:146] step: 310500, training_loss: 6.37676e-02
I0515 12:56:57.071805 22392998065984 run_lib.py:167] step: 310500, eval_loss: 6.15269e-02
I0515 12:57:21.448673 22392998065984 run_lib.py:146] step: 310550, training_loss: 5.34642e-02
I0515 12:57:46.092824 22392998065984 run_lib.py:146] step: 310600, training_loss: 5.22888e-02
I0515 12:57:46.264365 22392998065984 run_lib.py:167] step: 310600, eval_loss: 8.01224e-02
I0515 12:58:10.939988 22392998065984 run_lib.py:146] step: 310650, training_loss: 5.99649e-02
I0515 12:58:35.378252 22392998065984 run_lib.py:146] step: 310700, training_loss: 6.32362e-02
I0515 12:58:35.549583 22392998065984 run_lib.py:167] step: 310700, eval_loss: 6.79806e-02
I0515 12:59:00.364289 22392998065984 run_lib.py:146] step: 310750, training_loss: 6.74021e-02
I0515 12:59:24.736191 22392998065984 run_lib.py:146] step: 310800, training_loss: 4.92430e-02
I0515 12:59:24.897499 22392998065984 run_lib.py:167] step: 310800, eval_loss: 6.61323e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 12:59:49.728390 22392998065984 run_lib.py:146] step: 310850, training_loss: 4.75843e-02
I0515 13:00:14.555867 22392998065984 run_lib.py:146] step: 310900, training_loss: 4.03540e-02
I0515 13:00:14.717800 22392998065984 run_lib.py:167] step: 310900, eval_loss: 5.13335e-02
I0515 13:00:39.138603 22392998065984 run_lib.py:146] step: 310950, training_loss: 4.52794e-02
I0515 13:01:03.856436 22392998065984 run_lib.py:146] step: 311000, training_loss: 6.10519e-02
I0515 13:01:04.022853 22392998065984 run_lib.py:167] step: 311000, eval_loss: 5.72400e-02
I0515 13:01:28.774023 22392998065984 run_lib.py:146] step: 311050, training_loss: 6.30641e-02
I0515 13:01:53.102743 22392998065984 run_lib.py:146] step: 311100, training_loss: 5.05715e-02
I0515 13:01:53.267668 22392998065984 run_lib.py:167] step: 311100, eval_loss: 7.51602e-02
I0515 13:02:17.918778 22392998065984 run_lib.py:146] step: 311150, training_loss: 4.81105e-02
I0515 13:02:42.307609 22392998065984 run_lib.py:146] step: 311200, training_loss: 6.27588e-02
I0515 13:02:42.472634 22392998065984 run_lib.py:167] step: 311200, eval_loss: 7.53561e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:03:07.259963 22392998065984 run_lib.py:146] step: 311250, training_loss: 7.34071e-02
I0515 13:03:31.926834 22392998065984 run_lib.py:146] step: 311300, training_loss: 5.74147e-02
I0515 13:03:32.098372 22392998065984 run_lib.py:167] step: 311300, eval_loss: 5.94442e-02
I0515 13:03:56.567712 22392998065984 run_lib.py:146] step: 311350, training_loss: 6.26552e-02
I0515 13:04:21.259298 22392998065984 run_lib.py:146] step: 311400, training_loss: 5.94998e-02
I0515 13:04:21.428747 22392998065984 run_lib.py:167] step: 311400, eval_loss: 5.53083e-02
I0515 13:04:46.241826 22392998065984 run_lib.py:146] step: 311450, training_loss: 5.08584e-02
I0515 13:05:10.547478 22392998065984 run_lib.py:146] step: 311500, training_loss: 5.65348e-02
I0515 13:05:10.717199 22392998065984 run_lib.py:167] step: 311500, eval_loss: 5.88962e-02
I0515 13:05:35.303891 22392998065984 run_lib.py:146] step: 311550, training_loss: 5.80687e-02
I0515 13:05:59.591486 22392998065984 run_lib.py:146] step: 311600, training_loss: 5.12826e-02
I0515 13:05:59.760717 22392998065984 run_lib.py:167] step: 311600, eval_loss: 6.30855e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:06:24.622235 22392998065984 run_lib.py:146] step: 311650, training_loss: 4.01853e-02
I0515 13:06:49.303960 22392998065984 run_lib.py:146] step: 311700, training_loss: 6.02552e-02
I0515 13:06:49.465987 22392998065984 run_lib.py:167] step: 311700, eval_loss: 5.93047e-02
I0515 13:07:13.704397 22392998065984 run_lib.py:146] step: 311750, training_loss: 8.11544e-02
I0515 13:07:38.370957 22392998065984 run_lib.py:146] step: 311800, training_loss: 6.39401e-02
I0515 13:07:38.544027 22392998065984 run_lib.py:167] step: 311800, eval_loss: 5.60389e-02
I0515 13:08:03.107914 22392998065984 run_lib.py:146] step: 311850, training_loss: 6.68735e-02
I0515 13:08:27.409559 22392998065984 run_lib.py:146] step: 311900, training_loss: 7.23846e-02
I0515 13:08:27.570710 22392998065984 run_lib.py:167] step: 311900, eval_loss: 4.68607e-02
I0515 13:08:52.147139 22392998065984 run_lib.py:146] step: 311950, training_loss: 7.18018e-02
I0515 13:09:16.409636 22392998065984 run_lib.py:146] step: 312000, training_loss: 4.79283e-02
I0515 13:09:16.571537 22392998065984 run_lib.py:167] step: 312000, eval_loss: 5.43405e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:09:41.258958 22392998065984 run_lib.py:146] step: 312050, training_loss: 4.71352e-02
I0515 13:10:05.814155 22392998065984 run_lib.py:146] step: 312100, training_loss: 6.84676e-02
I0515 13:10:05.975538 22392998065984 run_lib.py:167] step: 312100, eval_loss: 4.94739e-02
I0515 13:10:30.325603 22392998065984 run_lib.py:146] step: 312150, training_loss: 7.43762e-02
I0515 13:10:54.974098 22392998065984 run_lib.py:146] step: 312200, training_loss: 4.28422e-02
I0515 13:10:55.144798 22392998065984 run_lib.py:167] step: 312200, eval_loss: 7.75581e-02
I0515 13:11:19.856157 22392998065984 run_lib.py:146] step: 312250, training_loss: 4.21913e-02
I0515 13:11:44.169438 22392998065984 run_lib.py:146] step: 312300, training_loss: 6.32892e-02
I0515 13:11:44.331888 22392998065984 run_lib.py:167] step: 312300, eval_loss: 4.46533e-02
I0515 13:12:08.967180 22392998065984 run_lib.py:146] step: 312350, training_loss: 5.53447e-02
I0515 13:12:33.739882 22392998065984 run_lib.py:146] step: 312400, training_loss: 6.13372e-02
I0515 13:12:33.900166 22392998065984 run_lib.py:167] step: 312400, eval_loss: 6.29714e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:12:58.496146 22392998065984 run_lib.py:146] step: 312450, training_loss: 6.46310e-02
I0515 13:13:23.273418 22392998065984 run_lib.py:146] step: 312500, training_loss: 5.75457e-02
I0515 13:13:23.438168 22392998065984 run_lib.py:167] step: 312500, eval_loss: 5.83595e-02
I0515 13:13:47.792030 22392998065984 run_lib.py:146] step: 312550, training_loss: 6.52489e-02
I0515 13:14:12.469339 22392998065984 run_lib.py:146] step: 312600, training_loss: 4.32085e-02
I0515 13:14:12.634816 22392998065984 run_lib.py:167] step: 312600, eval_loss: 4.96011e-02
I0515 13:14:37.272678 22392998065984 run_lib.py:146] step: 312650, training_loss: 4.70027e-02
I0515 13:15:01.603739 22392998065984 run_lib.py:146] step: 312700, training_loss: 4.92362e-02
I0515 13:15:01.768448 22392998065984 run_lib.py:167] step: 312700, eval_loss: 6.40559e-02
I0515 13:15:26.371519 22392998065984 run_lib.py:146] step: 312750, training_loss: 6.24451e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:15:50.801644 22392998065984 run_lib.py:146] step: 312800, training_loss: 5.82196e-02
I0515 13:15:50.963393 22392998065984 run_lib.py:167] step: 312800, eval_loss: 5.43154e-02
I0515 13:16:15.697235 22392998065984 run_lib.py:146] step: 312850, training_loss: 5.50326e-02
I0515 13:16:40.448110 22392998065984 run_lib.py:146] step: 312900, training_loss: 6.44092e-02
I0515 13:16:40.610886 22392998065984 run_lib.py:167] step: 312900, eval_loss: 7.13885e-02
I0515 13:17:04.804148 22392998065984 run_lib.py:146] step: 312950, training_loss: 5.16227e-02
I0515 13:17:29.429655 22392998065984 run_lib.py:146] step: 313000, training_loss: 5.09933e-02
I0515 13:17:29.594379 22392998065984 run_lib.py:167] step: 313000, eval_loss: 5.68953e-02
I0515 13:17:54.392647 22392998065984 run_lib.py:146] step: 313050, training_loss: 5.44051e-02
I0515 13:18:18.682470 22392998065984 run_lib.py:146] step: 313100, training_loss: 5.45987e-02
I0515 13:18:18.849019 22392998065984 run_lib.py:167] step: 313100, eval_loss: 7.16900e-02
I0515 13:18:43.381133 22392998065984 run_lib.py:146] step: 313150, training_loss: 5.58782e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:19:08.406506 22392998065984 run_lib.py:146] step: 313200, training_loss: 4.49905e-02
I0515 13:19:08.568342 22392998065984 run_lib.py:167] step: 313200, eval_loss: 5.09117e-02
I0515 13:19:32.904840 22392998065984 run_lib.py:146] step: 313250, training_loss: 6.62020e-02
I0515 13:19:57.722876 22392998065984 run_lib.py:146] step: 313300, training_loss: 6.78146e-02
I0515 13:19:57.887441 22392998065984 run_lib.py:167] step: 313300, eval_loss: 5.66776e-02
I0515 13:20:22.130868 22392998065984 run_lib.py:146] step: 313350, training_loss: 5.28034e-02
I0515 13:20:46.778992 22392998065984 run_lib.py:146] step: 313400, training_loss: 5.62887e-02
I0515 13:20:46.966263 22392998065984 run_lib.py:167] step: 313400, eval_loss: 6.09638e-02
I0515 13:21:11.645709 22392998065984 run_lib.py:146] step: 313450, training_loss: 6.57921e-02
I0515 13:21:35.936308 22392998065984 run_lib.py:146] step: 313500, training_loss: 4.96958e-02
I0515 13:21:36.096650 22392998065984 run_lib.py:167] step: 313500, eval_loss: 7.59094e-02
I0515 13:22:00.702945 22392998065984 run_lib.py:146] step: 313550, training_loss: 5.87886e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:22:25.121523 22392998065984 run_lib.py:146] step: 313600, training_loss: 5.99852e-02
I0515 13:22:25.291942 22392998065984 run_lib.py:167] step: 313600, eval_loss: 5.85815e-02
I0515 13:22:49.988115 22392998065984 run_lib.py:146] step: 313650, training_loss: 4.74245e-02
I0515 13:23:14.739039 22392998065984 run_lib.py:146] step: 313700, training_loss: 5.90285e-02
I0515 13:23:14.910582 22392998065984 run_lib.py:167] step: 313700, eval_loss: 5.48670e-02
I0515 13:23:39.267389 22392998065984 run_lib.py:146] step: 313750, training_loss: 7.30049e-02
I0515 13:24:03.752172 22392998065984 run_lib.py:146] step: 313800, training_loss: 7.72783e-02
I0515 13:24:03.922837 22392998065984 run_lib.py:167] step: 313800, eval_loss: 5.24093e-02
I0515 13:24:28.545998 22392998065984 run_lib.py:146] step: 313850, training_loss: 3.73919e-02
I0515 13:24:52.834315 22392998065984 run_lib.py:146] step: 313900, training_loss: 7.71570e-02
I0515 13:24:52.996301 22392998065984 run_lib.py:167] step: 313900, eval_loss: 6.95647e-02
I0515 13:25:17.736747 22392998065984 run_lib.py:146] step: 313950, training_loss: 8.50418e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:25:42.486364 22392998065984 run_lib.py:146] step: 314000, training_loss: 6.90216e-02
I0515 13:25:42.651731 22392998065984 run_lib.py:167] step: 314000, eval_loss: 6.78884e-02
I0515 13:26:07.040333 22392998065984 run_lib.py:146] step: 314050, training_loss: 6.74482e-02
I0515 13:26:31.803615 22392998065984 run_lib.py:146] step: 314100, training_loss: 5.36269e-02
I0515 13:26:31.966350 22392998065984 run_lib.py:167] step: 314100, eval_loss: 4.82885e-02
I0515 13:26:56.303654 22392998065984 run_lib.py:146] step: 314150, training_loss: 5.23424e-02
I0515 13:27:20.966732 22392998065984 run_lib.py:146] step: 314200, training_loss: 6.44665e-02
I0515 13:27:21.138567 22392998065984 run_lib.py:167] step: 314200, eval_loss: 7.35580e-02
I0515 13:27:45.734409 22392998065984 run_lib.py:146] step: 314250, training_loss: 5.76606e-02
I0515 13:28:09.919001 22392998065984 run_lib.py:146] step: 314300, training_loss: 5.76369e-02
I0515 13:28:10.102332 22392998065984 run_lib.py:167] step: 314300, eval_loss: 6.12445e-02
I0515 13:28:34.675660 22392998065984 run_lib.py:146] step: 314350, training_loss: 4.23757e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:28:59.012024 22392998065984 run_lib.py:146] step: 314400, training_loss: 5.31429e-02
I0515 13:28:59.174386 22392998065984 run_lib.py:167] step: 314400, eval_loss: 4.91872e-02
I0515 13:29:24.034343 22392998065984 run_lib.py:146] step: 314450, training_loss: 6.89034e-02
I0515 13:29:48.786699 22392998065984 run_lib.py:146] step: 314500, training_loss: 7.34561e-02
I0515 13:29:48.948167 22392998065984 run_lib.py:167] step: 314500, eval_loss: 6.71370e-02
I0515 13:30:13.286103 22392998065984 run_lib.py:146] step: 314550, training_loss: 4.78466e-02
I0515 13:30:37.891485 22392998065984 run_lib.py:146] step: 314600, training_loss: 5.22299e-02
I0515 13:30:38.050700 22392998065984 run_lib.py:167] step: 314600, eval_loss: 4.42956e-02
I0515 13:31:02.675146 22392998065984 run_lib.py:146] step: 314650, training_loss: 4.80027e-02
I0515 13:31:26.957264 22392998065984 run_lib.py:146] step: 314700, training_loss: 5.02078e-02
I0515 13:31:27.127066 22392998065984 run_lib.py:167] step: 314700, eval_loss: 5.98884e-02
I0515 13:31:51.722000 22392998065984 run_lib.py:146] step: 314750, training_loss: 5.18948e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:32:16.623442 22392998065984 run_lib.py:146] step: 314800, training_loss: 6.08432e-02
I0515 13:32:16.795907 22392998065984 run_lib.py:167] step: 314800, eval_loss: 6.09332e-02
I0515 13:32:41.113998 22392998065984 run_lib.py:146] step: 314850, training_loss: 5.57104e-02
I0515 13:33:05.881940 22392998065984 run_lib.py:146] step: 314900, training_loss: 7.52089e-02
I0515 13:33:06.051131 22392998065984 run_lib.py:167] step: 314900, eval_loss: 5.81021e-02
I0515 13:33:30.368314 22392998065984 run_lib.py:146] step: 314950, training_loss: 4.05423e-02
I0515 13:33:54.975466 22392998065984 run_lib.py:146] step: 315000, training_loss: 5.57800e-02
I0515 13:33:55.159301 22392998065984 run_lib.py:167] step: 315000, eval_loss: 7.61316e-02
I0515 13:34:19.908537 22392998065984 run_lib.py:146] step: 315050, training_loss: 4.95505e-02
I0515 13:34:44.268178 22392998065984 run_lib.py:146] step: 315100, training_loss: 5.29467e-02
I0515 13:34:44.437302 22392998065984 run_lib.py:167] step: 315100, eval_loss: 4.02093e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:35:09.183855 22392998065984 run_lib.py:146] step: 315150, training_loss: 5.32808e-02
I0515 13:35:33.469119 22392998065984 run_lib.py:146] step: 315200, training_loss: 5.75722e-02
I0515 13:35:33.638303 22392998065984 run_lib.py:167] step: 315200, eval_loss: 6.69004e-02
I0515 13:35:58.579502 22392998065984 run_lib.py:146] step: 315250, training_loss: 5.09387e-02
I0515 13:36:23.272351 22392998065984 run_lib.py:146] step: 315300, training_loss: 3.82445e-02
I0515 13:36:23.434352 22392998065984 run_lib.py:167] step: 315300, eval_loss: 6.10003e-02
I0515 13:36:47.733269 22392998065984 run_lib.py:146] step: 315350, training_loss: 5.04463e-02
I0515 13:37:12.358727 22392998065984 run_lib.py:146] step: 315400, training_loss: 4.48332e-02
I0515 13:37:12.527574 22392998065984 run_lib.py:167] step: 315400, eval_loss: 6.84829e-02
I0515 13:37:37.128431 22392998065984 run_lib.py:146] step: 315450, training_loss: 5.11877e-02
I0515 13:38:01.370680 22392998065984 run_lib.py:146] step: 315500, training_loss: 6.00478e-02
I0515 13:38:01.536023 22392998065984 run_lib.py:167] step: 315500, eval_loss: 4.90625e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:38:26.417861 22392998065984 run_lib.py:146] step: 315550, training_loss: 6.60059e-02
I0515 13:38:51.145337 22392998065984 run_lib.py:146] step: 315600, training_loss: 5.75925e-02
I0515 13:38:51.310136 22392998065984 run_lib.py:167] step: 315600, eval_loss: 5.91045e-02
I0515 13:39:15.744130 22392998065984 run_lib.py:146] step: 315650, training_loss: 5.55011e-02
I0515 13:39:40.446914 22392998065984 run_lib.py:146] step: 315700, training_loss: 5.23360e-02
I0515 13:39:40.609929 22392998065984 run_lib.py:167] step: 315700, eval_loss: 5.45517e-02
I0515 13:40:05.227214 22392998065984 run_lib.py:146] step: 315750, training_loss: 6.61699e-02
I0515 13:40:29.438540 22392998065984 run_lib.py:146] step: 315800, training_loss: 5.85472e-02
I0515 13:40:29.599384 22392998065984 run_lib.py:167] step: 315800, eval_loss: 5.88769e-02
I0515 13:40:54.112614 22392998065984 run_lib.py:146] step: 315850, training_loss: 5.14350e-02
I0515 13:41:18.389821 22392998065984 run_lib.py:146] step: 315900, training_loss: 6.03188e-02
I0515 13:41:18.476060 22392998065984 run_lib.py:167] step: 315900, eval_loss: 3.49412e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:41:43.274261 22392998065984 run_lib.py:146] step: 315950, training_loss: 5.19184e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:42:08.063946 22392998065984 run_lib.py:146] step: 316000, training_loss: 6.16961e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:42:08.508247 22392998065984 run_lib.py:167] step: 316000, eval_loss: 5.79394e-02
I0515 13:42:32.959277 22392998065984 run_lib.py:146] step: 316050, training_loss: 6.61407e-02
I0515 13:42:57.867879 22392998065984 run_lib.py:146] step: 316100, training_loss: 7.50444e-02
I0515 13:42:58.028349 22392998065984 run_lib.py:167] step: 316100, eval_loss: 6.07763e-02
I0515 13:43:22.357707 22392998065984 run_lib.py:146] step: 316150, training_loss: 5.73907e-02
I0515 13:43:46.962794 22392998065984 run_lib.py:146] step: 316200, training_loss: 4.35335e-02
I0515 13:43:47.123119 22392998065984 run_lib.py:167] step: 316200, eval_loss: 5.87810e-02
I0515 13:44:11.767870 22392998065984 run_lib.py:146] step: 316250, training_loss: 4.73316e-02
I0515 13:44:36.027658 22392998065984 run_lib.py:146] step: 316300, training_loss: 5.37568e-02
I0515 13:44:36.193433 22392998065984 run_lib.py:167] step: 316300, eval_loss: 6.93927e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:45:00.787093 22392998065984 run_lib.py:146] step: 316350, training_loss: 4.88099e-02
I0515 13:45:25.191931 22392998065984 run_lib.py:146] step: 316400, training_loss: 6.57348e-02
I0515 13:45:25.352813 22392998065984 run_lib.py:167] step: 316400, eval_loss: 6.62203e-02
I0515 13:45:49.753226 22392998065984 run_lib.py:146] step: 316450, training_loss: 4.77010e-02
I0515 13:46:14.319688 22392998065984 run_lib.py:146] step: 316500, training_loss: 6.98185e-02
I0515 13:46:14.494050 22392998065984 run_lib.py:167] step: 316500, eval_loss: 5.84133e-02
I0515 13:46:39.165909 22392998065984 run_lib.py:146] step: 316550, training_loss: 6.44907e-02
I0515 13:47:03.494747 22392998065984 run_lib.py:146] step: 316600, training_loss: 6.50456e-02
I0515 13:47:03.660135 22392998065984 run_lib.py:167] step: 316600, eval_loss: 5.75435e-02
I0515 13:47:28.258405 22392998065984 run_lib.py:146] step: 316650, training_loss: 4.98480e-02
I0515 13:47:52.598320 22392998065984 run_lib.py:146] step: 316700, training_loss: 6.13946e-02
I0515 13:47:52.761725 22392998065984 run_lib.py:167] step: 316700, eval_loss: 4.84327e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:48:17.685246 22392998065984 run_lib.py:146] step: 316750, training_loss: 4.36190e-02
I0515 13:48:42.414346 22392998065984 run_lib.py:146] step: 316800, training_loss: 4.83805e-02
I0515 13:48:42.580505 22392998065984 run_lib.py:167] step: 316800, eval_loss: 5.70966e-02
I0515 13:49:07.034856 22392998065984 run_lib.py:146] step: 316850, training_loss: 5.58187e-02
I0515 13:49:31.813332 22392998065984 run_lib.py:146] step: 316900, training_loss: 6.28830e-02
I0515 13:49:31.977206 22392998065984 run_lib.py:167] step: 316900, eval_loss: 5.07374e-02
I0515 13:49:56.199274 22392998065984 run_lib.py:146] step: 316950, training_loss: 6.63811e-02
I0515 13:50:20.933405 22392998065984 run_lib.py:146] step: 317000, training_loss: 7.03168e-02
I0515 13:50:21.099714 22392998065984 run_lib.py:167] step: 317000, eval_loss: 6.32074e-02
I0515 13:50:45.793226 22392998065984 run_lib.py:146] step: 317050, training_loss: 5.99564e-02
I0515 13:51:10.031320 22392998065984 run_lib.py:146] step: 317100, training_loss: 6.47816e-02
I0515 13:51:10.191255 22392998065984 run_lib.py:167] step: 317100, eval_loss: 6.59225e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:51:35.182764 22392998065984 run_lib.py:146] step: 317150, training_loss: 7.92141e-02
I0515 13:51:59.844475 22392998065984 run_lib.py:146] step: 317200, training_loss: 5.81040e-02
I0515 13:52:00.012282 22392998065984 run_lib.py:167] step: 317200, eval_loss: 6.02132e-02
I0515 13:52:24.338926 22392998065984 run_lib.py:146] step: 317250, training_loss: 5.49356e-02
I0515 13:52:48.880997 22392998065984 run_lib.py:146] step: 317300, training_loss: 5.61935e-02
I0515 13:52:49.041094 22392998065984 run_lib.py:167] step: 317300, eval_loss: 5.44041e-02
I0515 13:53:13.630746 22392998065984 run_lib.py:146] step: 317350, training_loss: 6.62316e-02
I0515 13:53:37.895425 22392998065984 run_lib.py:146] step: 317400, training_loss: 5.12252e-02
I0515 13:53:38.056383 22392998065984 run_lib.py:167] step: 317400, eval_loss: 6.28999e-02
I0515 13:54:02.638094 22392998065984 run_lib.py:146] step: 317450, training_loss: 5.65006e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:54:27.108608 22392998065984 run_lib.py:146] step: 317500, training_loss: 5.13933e-02
I0515 13:54:27.279972 22392998065984 run_lib.py:167] step: 317500, eval_loss: 5.55661e-02
I0515 13:54:51.955870 22392998065984 run_lib.py:146] step: 317550, training_loss: 6.05078e-02
I0515 13:55:16.853712 22392998065984 run_lib.py:146] step: 317600, training_loss: 7.22796e-02
I0515 13:55:17.014693 22392998065984 run_lib.py:167] step: 317600, eval_loss: 5.73050e-02
I0515 13:55:41.325562 22392998065984 run_lib.py:146] step: 317650, training_loss: 5.12399e-02
I0515 13:56:05.926038 22392998065984 run_lib.py:146] step: 317700, training_loss: 4.84227e-02
I0515 13:56:06.090438 22392998065984 run_lib.py:167] step: 317700, eval_loss: 5.34327e-02
I0515 13:56:30.400456 22392998065984 run_lib.py:146] step: 317750, training_loss: 6.15138e-02
I0515 13:56:55.029583 22392998065984 run_lib.py:146] step: 317800, training_loss: 5.80381e-02
I0515 13:56:55.191804 22392998065984 run_lib.py:167] step: 317800, eval_loss: 5.92665e-02
I0515 13:57:19.778743 22392998065984 run_lib.py:146] step: 317850, training_loss: 8.29331e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 13:57:44.235598 22392998065984 run_lib.py:146] step: 317900, training_loss: 5.11452e-02
I0515 13:57:44.419888 22392998065984 run_lib.py:167] step: 317900, eval_loss: 6.29707e-02
I0515 13:58:09.074504 22392998065984 run_lib.py:146] step: 317950, training_loss: 5.16205e-02
I0515 13:58:33.775218 22392998065984 run_lib.py:146] step: 318000, training_loss: 7.70442e-02
I0515 13:58:33.941200 22392998065984 run_lib.py:167] step: 318000, eval_loss: 5.87168e-02
I0515 13:58:58.144912 22392998065984 run_lib.py:146] step: 318050, training_loss: 6.95667e-02
I0515 13:59:22.690388 22392998065984 run_lib.py:146] step: 318100, training_loss: 6.19035e-02
I0515 13:59:22.863358 22392998065984 run_lib.py:167] step: 318100, eval_loss: 6.75378e-02
I0515 13:59:47.427270 22392998065984 run_lib.py:146] step: 318150, training_loss: 5.27984e-02
I0515 14:00:11.674040 22392998065984 run_lib.py:146] step: 318200, training_loss: 9.26117e-02
I0515 14:00:11.844435 22392998065984 run_lib.py:167] step: 318200, eval_loss: 6.77356e-02
I0515 14:00:36.360240 22392998065984 run_lib.py:146] step: 318250, training_loss: 5.90408e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:01:00.790613 22392998065984 run_lib.py:146] step: 318300, training_loss: 6.11924e-02
I0515 14:01:00.973581 22392998065984 run_lib.py:167] step: 318300, eval_loss: 4.70174e-02
I0515 14:01:25.617983 22392998065984 run_lib.py:146] step: 318350, training_loss: 4.42099e-02
I0515 14:01:50.385580 22392998065984 run_lib.py:146] step: 318400, training_loss: 5.49406e-02
I0515 14:01:50.545984 22392998065984 run_lib.py:167] step: 318400, eval_loss: 5.72325e-02
I0515 14:02:15.005147 22392998065984 run_lib.py:146] step: 318450, training_loss: 4.95101e-02
I0515 14:02:39.693930 22392998065984 run_lib.py:146] step: 318500, training_loss: 4.69553e-02
I0515 14:02:39.853248 22392998065984 run_lib.py:167] step: 318500, eval_loss: 6.29974e-02
I0515 14:03:04.089993 22392998065984 run_lib.py:146] step: 318550, training_loss: 5.70823e-02
I0515 14:03:28.717747 22392998065984 run_lib.py:146] step: 318600, training_loss: 4.83278e-02
I0515 14:03:28.877761 22392998065984 run_lib.py:167] step: 318600, eval_loss: 5.61872e-02
I0515 14:03:53.461516 22392998065984 run_lib.py:146] step: 318650, training_loss: 5.92833e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:04:17.935224 22392998065984 run_lib.py:146] step: 318700, training_loss: 4.52788e-02
I0515 14:04:18.098682 22392998065984 run_lib.py:167] step: 318700, eval_loss: 5.03818e-02
I0515 14:04:42.745130 22392998065984 run_lib.py:146] step: 318750, training_loss: 5.13246e-02
I0515 14:05:07.471498 22392998065984 run_lib.py:146] step: 318800, training_loss: 6.44650e-02
I0515 14:05:07.632579 22392998065984 run_lib.py:167] step: 318800, eval_loss: 5.11413e-02
I0515 14:05:31.928941 22392998065984 run_lib.py:146] step: 318850, training_loss: 9.53579e-02
I0515 14:05:56.529284 22392998065984 run_lib.py:146] step: 318900, training_loss: 4.93183e-02
I0515 14:05:56.696059 22392998065984 run_lib.py:167] step: 318900, eval_loss: 5.19806e-02
I0515 14:06:21.315882 22392998065984 run_lib.py:146] step: 318950, training_loss: 6.16765e-02
I0515 14:06:45.620367 22392998065984 run_lib.py:146] step: 319000, training_loss: 5.54136e-02
I0515 14:06:45.788980 22392998065984 run_lib.py:167] step: 319000, eval_loss: 5.65855e-02
I0515 14:07:10.373094 22392998065984 run_lib.py:146] step: 319050, training_loss: 4.20682e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:07:34.895694 22392998065984 run_lib.py:146] step: 319100, training_loss: 8.12081e-02
I0515 14:07:35.057545 22392998065984 run_lib.py:167] step: 319100, eval_loss: 6.70332e-02
I0515 14:07:59.971790 22392998065984 run_lib.py:146] step: 319150, training_loss: 4.80651e-02
I0515 14:08:24.840473 22392998065984 run_lib.py:146] step: 319200, training_loss: 5.61715e-02
I0515 14:08:25.000097 22392998065984 run_lib.py:167] step: 319200, eval_loss: 6.05748e-02
I0515 14:08:49.254487 22392998065984 run_lib.py:146] step: 319250, training_loss: 5.04214e-02
I0515 14:09:13.926836 22392998065984 run_lib.py:146] step: 319300, training_loss: 7.04968e-02
I0515 14:09:14.097512 22392998065984 run_lib.py:167] step: 319300, eval_loss: 5.12397e-02
I0515 14:09:38.449154 22392998065984 run_lib.py:146] step: 319350, training_loss: 5.17072e-02
I0515 14:10:03.086121 22392998065984 run_lib.py:146] step: 319400, training_loss: 4.88949e-02
I0515 14:10:03.245422 22392998065984 run_lib.py:167] step: 319400, eval_loss: 6.16071e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:10:28.101117 22392998065984 run_lib.py:146] step: 319450, training_loss: 6.05963e-02
I0515 14:10:52.427856 22392998065984 run_lib.py:146] step: 319500, training_loss: 4.59024e-02
I0515 14:10:52.591311 22392998065984 run_lib.py:167] step: 319500, eval_loss: 5.85960e-02
I0515 14:11:17.380133 22392998065984 run_lib.py:146] step: 319550, training_loss: 6.61197e-02
I0515 14:11:42.164887 22392998065984 run_lib.py:146] step: 319600, training_loss: 5.75525e-02
I0515 14:11:42.324932 22392998065984 run_lib.py:167] step: 319600, eval_loss: 5.78360e-02
I0515 14:12:06.658750 22392998065984 run_lib.py:146] step: 319650, training_loss: 5.80137e-02
I0515 14:12:31.244669 22392998065984 run_lib.py:146] step: 319700, training_loss: 6.06161e-02
I0515 14:12:31.404633 22392998065984 run_lib.py:167] step: 319700, eval_loss: 5.36210e-02
I0515 14:12:56.063884 22392998065984 run_lib.py:146] step: 319750, training_loss: 5.14852e-02
I0515 14:13:20.370615 22392998065984 run_lib.py:146] step: 319800, training_loss: 5.57688e-02
I0515 14:13:20.539777 22392998065984 run_lib.py:167] step: 319800, eval_loss: 6.29969e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:13:45.369418 22392998065984 run_lib.py:146] step: 319850, training_loss: 4.27225e-02
I0515 14:14:09.668282 22392998065984 run_lib.py:146] step: 319900, training_loss: 5.41266e-02
I0515 14:14:09.831445 22392998065984 run_lib.py:167] step: 319900, eval_loss: 5.45067e-02
I0515 14:14:34.608573 22392998065984 run_lib.py:146] step: 319950, training_loss: 7.63327e-02
I0515 14:14:59.250804 22392998065984 run_lib.py:146] step: 320000, training_loss: 5.49316e-02
I0515 14:15:01.098332 22392998065984 run_lib.py:167] step: 320000, eval_loss: 5.84236e-02
I0515 14:15:27.163751 22392998065984 run_lib.py:146] step: 320050, training_loss: 4.78737e-02
I0515 14:15:51.750028 22392998065984 run_lib.py:146] step: 320100, training_loss: 4.62634e-02
I0515 14:15:51.930500 22392998065984 run_lib.py:167] step: 320100, eval_loss: 7.13750e-02
I0515 14:16:16.580286 22392998065984 run_lib.py:146] step: 320150, training_loss: 4.43092e-02
I0515 14:16:40.906322 22392998065984 run_lib.py:146] step: 320200, training_loss: 5.91827e-02
I0515 14:16:41.080006 22392998065984 run_lib.py:167] step: 320200, eval_loss: 5.02846e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:17:05.891063 22392998065984 run_lib.py:146] step: 320250, training_loss: 7.04946e-02
I0515 14:17:30.585453 22392998065984 run_lib.py:146] step: 320300, training_loss: 5.86352e-02
I0515 14:17:30.748623 22392998065984 run_lib.py:167] step: 320300, eval_loss: 5.95716e-02
I0515 14:17:55.023477 22392998065984 run_lib.py:146] step: 320350, training_loss: 5.40711e-02
I0515 14:18:19.659308 22392998065984 run_lib.py:146] step: 320400, training_loss: 6.09784e-02
I0515 14:18:19.821211 22392998065984 run_lib.py:167] step: 320400, eval_loss: 4.71257e-02
I0515 14:18:44.455937 22392998065984 run_lib.py:146] step: 320450, training_loss: 5.15779e-02
I0515 14:19:08.714138 22392998065984 run_lib.py:146] step: 320500, training_loss: 5.17941e-02
I0515 14:19:08.879245 22392998065984 run_lib.py:167] step: 320500, eval_loss: 5.28907e-02
I0515 14:19:33.448390 22392998065984 run_lib.py:146] step: 320550, training_loss: 5.48595e-02
I0515 14:19:58.031219 22392998065984 run_lib.py:146] step: 320600, training_loss: 6.31785e-02
I0515 14:19:58.193101 22392998065984 run_lib.py:167] step: 320600, eval_loss: 6.02877e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:20:22.621494 22392998065984 run_lib.py:146] step: 320650, training_loss: 6.64216e-02
I0515 14:20:46.868637 22392998065984 run_lib.py:146] step: 320700, training_loss: 4.06805e-02
I0515 14:20:47.033597 22392998065984 run_lib.py:167] step: 320700, eval_loss: 6.08922e-02
I0515 14:21:12.180377 22392998065984 run_lib.py:146] step: 320750, training_loss: 5.58802e-02
I0515 14:21:36.599184 22392998065984 run_lib.py:146] step: 320800, training_loss: 5.56182e-02
I0515 14:21:36.766952 22392998065984 run_lib.py:167] step: 320800, eval_loss: 6.14937e-02
I0515 14:22:01.032893 22392998065984 run_lib.py:146] step: 320850, training_loss: 5.81829e-02
I0515 14:22:25.639007 22392998065984 run_lib.py:146] step: 320900, training_loss: 6.01021e-02
I0515 14:22:25.816825 22392998065984 run_lib.py:167] step: 320900, eval_loss: 5.53961e-02
I0515 14:22:50.442742 22392998065984 run_lib.py:146] step: 320950, training_loss: 6.89458e-02
I0515 14:23:14.732876 22392998065984 run_lib.py:146] step: 321000, training_loss: 4.91230e-02
I0515 14:23:14.909485 22392998065984 run_lib.py:167] step: 321000, eval_loss: 5.75093e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:23:39.693418 22392998065984 run_lib.py:146] step: 321050, training_loss: 6.15899e-02
I0515 14:24:04.254326 22392998065984 run_lib.py:146] step: 321100, training_loss: 7.35831e-02
I0515 14:24:04.420010 22392998065984 run_lib.py:167] step: 321100, eval_loss: 7.64384e-02
I0515 14:24:28.799566 22392998065984 run_lib.py:146] step: 321150, training_loss: 4.70036e-02
I0515 14:24:53.422031 22392998065984 run_lib.py:146] step: 321200, training_loss: 6.56116e-02
I0515 14:24:53.584443 22392998065984 run_lib.py:167] step: 321200, eval_loss: 6.92271e-02
I0515 14:25:18.245333 22392998065984 run_lib.py:146] step: 321250, training_loss: 6.38343e-02
I0515 14:25:42.598640 22392998065984 run_lib.py:146] step: 321300, training_loss: 5.94280e-02
I0515 14:25:42.759460 22392998065984 run_lib.py:167] step: 321300, eval_loss: 6.72172e-02
I0515 14:26:07.358329 22392998065984 run_lib.py:146] step: 321350, training_loss: 7.47052e-02
I0515 14:26:32.092750 22392998065984 run_lib.py:146] step: 321400, training_loss: 4.27523e-02
I0515 14:26:32.253089 22392998065984 run_lib.py:167] step: 321400, eval_loss: 5.04185e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:26:56.723539 22392998065984 run_lib.py:146] step: 321450, training_loss: 4.79820e-02
I0515 14:27:20.974661 22392998065984 run_lib.py:146] step: 321500, training_loss: 7.96409e-02
I0515 14:27:21.139194 22392998065984 run_lib.py:167] step: 321500, eval_loss: 7.74943e-02
I0515 14:27:46.322938 22392998065984 run_lib.py:146] step: 321550, training_loss: 5.82665e-02
I0515 14:28:10.563537 22392998065984 run_lib.py:146] step: 321600, training_loss: 5.89912e-02
I0515 14:28:10.732177 22392998065984 run_lib.py:167] step: 321600, eval_loss: 5.86204e-02
I0515 14:28:35.085403 22392998065984 run_lib.py:146] step: 321650, training_loss: 6.33406e-02
I0515 14:28:59.871500 22392998065984 run_lib.py:146] step: 321700, training_loss: 4.66301e-02
I0515 14:29:00.032270 22392998065984 run_lib.py:167] step: 321700, eval_loss: 7.03724e-02
I0515 14:29:24.614890 22392998065984 run_lib.py:146] step: 321750, training_loss: 6.04795e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:29:48.999509 22392998065984 run_lib.py:146] step: 321800, training_loss: 5.15763e-02
I0515 14:29:49.183877 22392998065984 run_lib.py:167] step: 321800, eval_loss: 6.57503e-02
I0515 14:30:14.048532 22392998065984 run_lib.py:146] step: 321850, training_loss: 5.62493e-02
I0515 14:30:38.716480 22392998065984 run_lib.py:146] step: 321900, training_loss: 6.56318e-02
I0515 14:30:38.878708 22392998065984 run_lib.py:167] step: 321900, eval_loss: 7.19235e-02
I0515 14:31:03.231322 22392998065984 run_lib.py:146] step: 321950, training_loss: 5.80527e-02
I0515 14:31:27.830601 22392998065984 run_lib.py:146] step: 322000, training_loss: 6.22219e-02
I0515 14:31:28.000034 22392998065984 run_lib.py:167] step: 322000, eval_loss: 5.80455e-02
I0515 14:31:52.642519 22392998065984 run_lib.py:146] step: 322050, training_loss: 5.68118e-02
I0515 14:32:16.937720 22392998065984 run_lib.py:146] step: 322100, training_loss: 6.45981e-02
I0515 14:32:17.099023 22392998065984 run_lib.py:167] step: 322100, eval_loss: 5.99661e-02
I0515 14:32:41.706165 22392998065984 run_lib.py:146] step: 322150, training_loss: 4.87763e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:33:06.521005 22392998065984 run_lib.py:146] step: 322200, training_loss: 5.32121e-02
I0515 14:33:06.693620 22392998065984 run_lib.py:167] step: 322200, eval_loss: 5.55378e-02
I0515 14:33:31.073591 22392998065984 run_lib.py:146] step: 322250, training_loss: 6.71435e-02
I0515 14:33:55.579420 22392998065984 run_lib.py:146] step: 322300, training_loss: 7.05204e-02
I0515 14:33:55.749075 22392998065984 run_lib.py:167] step: 322300, eval_loss: 5.96621e-02
I0515 14:34:20.788446 22392998065984 run_lib.py:146] step: 322350, training_loss: 5.06494e-02
I0515 14:34:45.151369 22392998065984 run_lib.py:146] step: 322400, training_loss: 5.04203e-02
I0515 14:34:45.313543 22392998065984 run_lib.py:167] step: 322400, eval_loss: 6.42755e-02
I0515 14:35:09.608055 22392998065984 run_lib.py:146] step: 322450, training_loss: 4.50467e-02
I0515 14:35:34.582933 22392998065984 run_lib.py:146] step: 322500, training_loss: 9.16253e-02
I0515 14:35:34.742038 22392998065984 run_lib.py:167] step: 322500, eval_loss: 6.75120e-02
I0515 14:35:58.967052 22392998065984 run_lib.py:146] step: 322550, training_loss: 7.26680e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:36:23.441953 22392998065984 run_lib.py:146] step: 322600, training_loss: 5.56668e-02
I0515 14:36:23.605448 22392998065984 run_lib.py:167] step: 322600, eval_loss: 6.24111e-02
I0515 14:36:48.514139 22392998065984 run_lib.py:146] step: 322650, training_loss: 7.81443e-02
I0515 14:37:13.553396 22392998065984 run_lib.py:146] step: 322700, training_loss: 4.42518e-02
I0515 14:37:13.715115 22392998065984 run_lib.py:167] step: 322700, eval_loss: 5.33178e-02
I0515 14:37:37.856175 22392998065984 run_lib.py:146] step: 322750, training_loss: 5.63712e-02
I0515 14:38:02.386089 22392998065984 run_lib.py:146] step: 322800, training_loss: 4.09339e-02
I0515 14:38:02.574558 22392998065984 run_lib.py:167] step: 322800, eval_loss: 5.48305e-02
I0515 14:38:27.203377 22392998065984 run_lib.py:146] step: 322850, training_loss: 6.16980e-02
I0515 14:38:51.447405 22392998065984 run_lib.py:146] step: 322900, training_loss: 5.34535e-02
I0515 14:38:51.616126 22392998065984 run_lib.py:167] step: 322900, eval_loss: 7.66433e-02
I0515 14:39:16.319672 22392998065984 run_lib.py:146] step: 322950, training_loss: 5.97880e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:39:41.301783 22392998065984 run_lib.py:146] step: 323000, training_loss: 7.06965e-02
I0515 14:39:41.462994 22392998065984 run_lib.py:167] step: 323000, eval_loss: 6.06016e-02
I0515 14:40:05.751925 22392998065984 run_lib.py:146] step: 323050, training_loss: 7.12105e-02
I0515 14:40:30.417967 22392998065984 run_lib.py:146] step: 323100, training_loss: 5.93943e-02
I0515 14:40:30.600259 22392998065984 run_lib.py:167] step: 323100, eval_loss: 5.42547e-02
I0515 14:40:55.223962 22392998065984 run_lib.py:146] step: 323150, training_loss: 7.64775e-02
I0515 14:41:19.532503 22392998065984 run_lib.py:146] step: 323200, training_loss: 6.73294e-02
I0515 14:41:19.691826 22392998065984 run_lib.py:167] step: 323200, eval_loss: 6.13579e-02
I0515 14:41:44.033325 22392998065984 run_lib.py:146] step: 323250, training_loss: 5.41328e-02
I0515 14:42:08.927255 22392998065984 run_lib.py:146] step: 323300, training_loss: 6.63245e-02
I0515 14:42:09.097412 22392998065984 run_lib.py:167] step: 323300, eval_loss: 5.82842e-02
I0515 14:42:33.432380 22392998065984 run_lib.py:146] step: 323350, training_loss: 7.82167e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:42:57.884161 22392998065984 run_lib.py:146] step: 323400, training_loss: 5.79871e-02
I0515 14:42:58.045976 22392998065984 run_lib.py:167] step: 323400, eval_loss: 5.68947e-02
I0515 14:43:22.952057 22392998065984 run_lib.py:146] step: 323450, training_loss: 5.48613e-02
I0515 14:43:47.674053 22392998065984 run_lib.py:146] step: 323500, training_loss: 5.96384e-02
I0515 14:43:47.838786 22392998065984 run_lib.py:167] step: 323500, eval_loss: 4.78111e-02
I0515 14:44:12.097233 22392998065984 run_lib.py:146] step: 323550, training_loss: 7.33894e-02
I0515 14:44:36.758615 22392998065984 run_lib.py:146] step: 323600, training_loss: 6.29479e-02
I0515 14:44:36.919228 22392998065984 run_lib.py:167] step: 323600, eval_loss: 5.76032e-02
I0515 14:45:01.520986 22392998065984 run_lib.py:146] step: 323650, training_loss: 5.51471e-02
I0515 14:45:25.807557 22392998065984 run_lib.py:146] step: 323700, training_loss: 7.30771e-02
I0515 14:45:25.975473 22392998065984 run_lib.py:167] step: 323700, eval_loss: 5.00866e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:45:50.749305 22392998065984 run_lib.py:146] step: 323750, training_loss: 6.73729e-02
I0515 14:46:15.500469 22392998065984 run_lib.py:146] step: 323800, training_loss: 3.83600e-02
I0515 14:46:15.616194 22392998065984 run_lib.py:167] step: 323800, eval_loss: 8.38540e-02
I0515 14:46:39.912142 22392998065984 run_lib.py:146] step: 323850, training_loss: 4.54691e-02
I0515 14:47:04.616884 22392998065984 run_lib.py:146] step: 323900, training_loss: 6.16526e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:47:05.055115 22392998065984 run_lib.py:167] step: 323900, eval_loss: 6.80887e-02
I0515 14:47:30.033344 22392998065984 run_lib.py:146] step: 323950, training_loss: 5.60243e-02
I0515 14:47:54.386308 22392998065984 run_lib.py:146] step: 324000, training_loss: 7.04066e-02
I0515 14:47:54.555781 22392998065984 run_lib.py:167] step: 324000, eval_loss: 7.79977e-02
I0515 14:48:18.843807 22392998065984 run_lib.py:146] step: 324050, training_loss: 7.11310e-02
I0515 14:48:43.843149 22392998065984 run_lib.py:146] step: 324100, training_loss: 6.88521e-02
I0515 14:48:44.014180 22392998065984 run_lib.py:167] step: 324100, eval_loss: 7.94474e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:49:08.462619 22392998065984 run_lib.py:146] step: 324150, training_loss: 6.07857e-02
I0515 14:49:32.789445 22392998065984 run_lib.py:146] step: 324200, training_loss: 8.82194e-02
I0515 14:49:32.952283 22392998065984 run_lib.py:167] step: 324200, eval_loss: 7.53856e-02
I0515 14:49:57.709537 22392998065984 run_lib.py:146] step: 324250, training_loss: 6.53359e-02
I0515 14:50:22.384799 22392998065984 run_lib.py:146] step: 324300, training_loss: 5.17144e-02
I0515 14:50:22.545893 22392998065984 run_lib.py:167] step: 324300, eval_loss: 6.31904e-02
I0515 14:50:46.843207 22392998065984 run_lib.py:146] step: 324350, training_loss: 6.73117e-02
I0515 14:51:11.399890 22392998065984 run_lib.py:146] step: 324400, training_loss: 6.92902e-02
I0515 14:51:11.561662 22392998065984 run_lib.py:167] step: 324400, eval_loss: 5.55070e-02
I0515 14:51:36.253240 22392998065984 run_lib.py:146] step: 324450, training_loss: 5.41193e-02
I0515 14:52:00.505822 22392998065984 run_lib.py:146] step: 324500, training_loss: 5.13842e-02
I0515 14:52:00.675207 22392998065984 run_lib.py:167] step: 324500, eval_loss: 6.41381e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:52:25.469963 22392998065984 run_lib.py:146] step: 324550, training_loss: 5.36447e-02
I0515 14:52:50.251384 22392998065984 run_lib.py:146] step: 324600, training_loss: 6.48698e-02
I0515 14:52:50.413280 22392998065984 run_lib.py:167] step: 324600, eval_loss: 6.63859e-02
I0515 14:53:14.892934 22392998065984 run_lib.py:146] step: 324650, training_loss: 5.10987e-02
I0515 14:53:39.472628 22392998065984 run_lib.py:146] step: 324700, training_loss: 5.84102e-02
I0515 14:53:39.633631 22392998065984 run_lib.py:167] step: 324700, eval_loss: 5.96937e-02
I0515 14:54:04.134769 22392998065984 run_lib.py:146] step: 324750, training_loss: 4.79526e-02
I0515 14:54:28.393788 22392998065984 run_lib.py:146] step: 324800, training_loss: 5.84460e-02
I0515 14:54:28.559434 22392998065984 run_lib.py:167] step: 324800, eval_loss: 7.46470e-02
I0515 14:54:52.803644 22392998065984 run_lib.py:146] step: 324850, training_loss: 6.61446e-02
I0515 14:55:17.726966 22392998065984 run_lib.py:146] step: 324900, training_loss: 5.11769e-02
I0515 14:55:17.903936 22392998065984 run_lib.py:167] step: 324900, eval_loss: 6.94873e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:55:42.338687 22392998065984 run_lib.py:146] step: 324950, training_loss: 5.13700e-02
I0515 14:56:06.530736 22392998065984 run_lib.py:146] step: 325000, training_loss: 5.35379e-02
I0515 14:56:06.709459 22392998065984 run_lib.py:167] step: 325000, eval_loss: 5.85651e-02
I0515 14:56:31.577010 22392998065984 run_lib.py:146] step: 325050, training_loss: 4.08509e-02
I0515 14:56:56.168675 22392998065984 run_lib.py:146] step: 325100, training_loss: 4.43343e-02
I0515 14:56:56.329916 22392998065984 run_lib.py:167] step: 325100, eval_loss: 4.85504e-02
I0515 14:57:20.649559 22392998065984 run_lib.py:146] step: 325150, training_loss: 6.26287e-02
I0515 14:57:45.415874 22392998065984 run_lib.py:146] step: 325200, training_loss: 5.89528e-02
I0515 14:57:45.591570 22392998065984 run_lib.py:167] step: 325200, eval_loss: 6.21640e-02
I0515 14:58:10.193907 22392998065984 run_lib.py:146] step: 325250, training_loss: 4.67514e-02
I0515 14:58:34.537492 22392998065984 run_lib.py:146] step: 325300, training_loss: 5.21366e-02
I0515 14:58:34.706515 22392998065984 run_lib.py:167] step: 325300, eval_loss: 6.93571e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 14:58:59.460487 22392998065984 run_lib.py:146] step: 325350, training_loss: 5.91130e-02
I0515 14:59:24.134040 22392998065984 run_lib.py:146] step: 325400, training_loss: 7.10257e-02
I0515 14:59:24.313221 22392998065984 run_lib.py:167] step: 325400, eval_loss: 4.93013e-02
I0515 14:59:48.656047 22392998065984 run_lib.py:146] step: 325450, training_loss: 4.16255e-02
I0515 15:00:13.394471 22392998065984 run_lib.py:146] step: 325500, training_loss: 5.28044e-02
I0515 15:00:13.563533 22392998065984 run_lib.py:167] step: 325500, eval_loss: 6.32736e-02
I0515 15:00:38.159580 22392998065984 run_lib.py:146] step: 325550, training_loss: 5.61166e-02
I0515 15:01:02.423927 22392998065984 run_lib.py:146] step: 325600, training_loss: 5.93233e-02
I0515 15:01:02.598374 22392998065984 run_lib.py:167] step: 325600, eval_loss: 6.39417e-02
I0515 15:01:26.844787 22392998065984 run_lib.py:146] step: 325650, training_loss: 6.96840e-02
I0515 15:01:51.753826 22392998065984 run_lib.py:146] step: 325700, training_loss: 5.34994e-02
I0515 15:01:51.912652 22392998065984 run_lib.py:167] step: 325700, eval_loss: 4.00682e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:02:16.496331 22392998065984 run_lib.py:146] step: 325750, training_loss: 4.69797e-02
I0515 15:02:40.835132 22392998065984 run_lib.py:146] step: 325800, training_loss: 5.00917e-02
I0515 15:02:41.001027 22392998065984 run_lib.py:167] step: 325800, eval_loss: 6.31590e-02
I0515 15:03:06.044377 22392998065984 run_lib.py:146] step: 325850, training_loss: 5.51731e-02
I0515 15:03:30.397976 22392998065984 run_lib.py:146] step: 325900, training_loss: 4.39569e-02
I0515 15:03:30.566313 22392998065984 run_lib.py:167] step: 325900, eval_loss: 6.86522e-02
I0515 15:03:54.918715 22392998065984 run_lib.py:146] step: 325950, training_loss: 4.99144e-02
I0515 15:04:19.629865 22392998065984 run_lib.py:146] step: 326000, training_loss: 6.57036e-02
I0515 15:04:19.795243 22392998065984 run_lib.py:167] step: 326000, eval_loss: 7.19360e-02
I0515 15:04:44.382447 22392998065984 run_lib.py:146] step: 326050, training_loss: 7.17044e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:05:08.746793 22392998065984 run_lib.py:146] step: 326100, training_loss: 7.33708e-02
I0515 15:05:08.911848 22392998065984 run_lib.py:167] step: 326100, eval_loss: 6.46986e-02
I0515 15:05:33.690022 22392998065984 run_lib.py:146] step: 326150, training_loss: 5.54488e-02
I0515 15:05:58.373465 22392998065984 run_lib.py:146] step: 326200, training_loss: 6.04213e-02
I0515 15:05:58.535706 22392998065984 run_lib.py:167] step: 326200, eval_loss: 4.24299e-02
I0515 15:06:22.712858 22392998065984 run_lib.py:146] step: 326250, training_loss: 5.53846e-02
I0515 15:06:46.949023 22392998065984 run_lib.py:146] step: 326300, training_loss: 7.03896e-02
I0515 15:06:47.118630 22392998065984 run_lib.py:167] step: 326300, eval_loss: 5.61027e-02
I0515 15:07:11.648302 22392998065984 run_lib.py:146] step: 326350, training_loss: 7.52821e-02
I0515 15:07:36.084049 22392998065984 run_lib.py:146] step: 326400, training_loss: 5.86546e-02
I0515 15:07:36.245658 22392998065984 run_lib.py:167] step: 326400, eval_loss: 6.15305e-02
I0515 15:08:00.634480 22392998065984 run_lib.py:146] step: 326450, training_loss: 5.01805e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:08:25.852348 22392998065984 run_lib.py:146] step: 326500, training_loss: 5.31064e-02
I0515 15:08:26.014630 22392998065984 run_lib.py:167] step: 326500, eval_loss: 4.84462e-02
I0515 15:08:50.201934 22392998065984 run_lib.py:146] step: 326550, training_loss: 8.72135e-02
I0515 15:09:14.387280 22392998065984 run_lib.py:146] step: 326600, training_loss: 5.30882e-02
I0515 15:09:14.550571 22392998065984 run_lib.py:167] step: 326600, eval_loss: 6.79952e-02
I0515 15:09:39.548565 22392998065984 run_lib.py:146] step: 326650, training_loss: 6.59957e-02
I0515 15:10:04.076828 22392998065984 run_lib.py:146] step: 326700, training_loss: 6.10361e-02
I0515 15:10:04.248231 22392998065984 run_lib.py:167] step: 326700, eval_loss: 7.24595e-02
I0515 15:10:28.612160 22392998065984 run_lib.py:146] step: 326750, training_loss: 6.32283e-02
I0515 15:10:53.537942 22392998065984 run_lib.py:146] step: 326800, training_loss: 4.85109e-02
I0515 15:10:53.697208 22392998065984 run_lib.py:167] step: 326800, eval_loss: 6.20004e-02
I0515 15:11:17.960671 22392998065984 run_lib.py:146] step: 326850, training_loss: 5.79877e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:11:42.385303 22392998065984 run_lib.py:146] step: 326900, training_loss: 5.19470e-02
I0515 15:11:42.547219 22392998065984 run_lib.py:167] step: 326900, eval_loss: 5.89643e-02
I0515 15:12:07.259716 22392998065984 run_lib.py:146] step: 326950, training_loss: 3.94835e-02
I0515 15:12:31.971204 22392998065984 run_lib.py:146] step: 327000, training_loss: 4.74407e-02
I0515 15:12:32.140494 22392998065984 run_lib.py:167] step: 327000, eval_loss: 7.62178e-02
I0515 15:12:56.410686 22392998065984 run_lib.py:146] step: 327050, training_loss: 6.23332e-02
I0515 15:13:20.996861 22392998065984 run_lib.py:146] step: 327100, training_loss: 5.58244e-02
I0515 15:13:21.165646 22392998065984 run_lib.py:167] step: 327100, eval_loss: 6.84575e-02
I0515 15:13:45.726836 22392998065984 run_lib.py:146] step: 327150, training_loss: 8.84200e-02
I0515 15:14:10.049045 22392998065984 run_lib.py:146] step: 327200, training_loss: 6.04467e-02
I0515 15:14:10.209340 22392998065984 run_lib.py:167] step: 327200, eval_loss: 4.50654e-02
I0515 15:14:34.504252 22392998065984 run_lib.py:146] step: 327250, training_loss: 6.48800e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:15:00.055454 22392998065984 run_lib.py:146] step: 327300, training_loss: 4.14917e-02
I0515 15:15:00.230346 22392998065984 run_lib.py:167] step: 327300, eval_loss: 5.97982e-02
I0515 15:15:24.524924 22392998065984 run_lib.py:146] step: 327350, training_loss: 6.05235e-02
I0515 15:15:48.927540 22392998065984 run_lib.py:146] step: 327400, training_loss: 6.57498e-02
I0515 15:15:49.103951 22392998065984 run_lib.py:167] step: 327400, eval_loss: 4.72845e-02
I0515 15:16:14.097587 22392998065984 run_lib.py:146] step: 327450, training_loss: 4.13822e-02
I0515 15:16:38.349714 22392998065984 run_lib.py:146] step: 327500, training_loss: 5.30400e-02
I0515 15:16:38.523608 22392998065984 run_lib.py:167] step: 327500, eval_loss: 7.21879e-02
I0515 15:17:02.821036 22392998065984 run_lib.py:146] step: 327550, training_loss: 4.59209e-02
I0515 15:17:27.699874 22392998065984 run_lib.py:146] step: 327600, training_loss: 6.34500e-02
I0515 15:17:27.858900 22392998065984 run_lib.py:167] step: 327600, eval_loss: 5.87988e-02
I0515 15:17:52.207303 22392998065984 run_lib.py:146] step: 327650, training_loss: 6.06884e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:18:16.827641 22392998065984 run_lib.py:146] step: 327700, training_loss: 5.90153e-02
I0515 15:18:17.003988 22392998065984 run_lib.py:167] step: 327700, eval_loss: 4.67350e-02
I0515 15:18:41.777115 22392998065984 run_lib.py:146] step: 327750, training_loss: 5.94946e-02
I0515 15:19:06.448934 22392998065984 run_lib.py:146] step: 327800, training_loss: 7.07376e-02
I0515 15:19:06.613338 22392998065984 run_lib.py:167] step: 327800, eval_loss: 4.71997e-02
I0515 15:19:30.923858 22392998065984 run_lib.py:146] step: 327850, training_loss: 4.43436e-02
I0515 15:19:55.555872 22392998065984 run_lib.py:146] step: 327900, training_loss: 4.38847e-02
I0515 15:19:55.721332 22392998065984 run_lib.py:167] step: 327900, eval_loss: 6.43632e-02
I0515 15:20:20.381095 22392998065984 run_lib.py:146] step: 327950, training_loss: 6.20849e-02
I0515 15:20:44.623101 22392998065984 run_lib.py:146] step: 328000, training_loss: 5.86907e-02
I0515 15:20:44.782577 22392998065984 run_lib.py:167] step: 328000, eval_loss: 6.45302e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:21:09.252749 22392998065984 run_lib.py:146] step: 328050, training_loss: 8.62764e-02
I0515 15:21:34.331622 22392998065984 run_lib.py:146] step: 328100, training_loss: 6.40304e-02
I0515 15:21:34.494511 22392998065984 run_lib.py:167] step: 328100, eval_loss: 5.62523e-02
I0515 15:21:58.869044 22392998065984 run_lib.py:146] step: 328150, training_loss: 6.72163e-02
I0515 15:22:23.271233 22392998065984 run_lib.py:146] step: 328200, training_loss: 4.83660e-02
I0515 15:22:23.431523 22392998065984 run_lib.py:167] step: 328200, eval_loss: 6.70311e-02
I0515 15:22:48.425485 22392998065984 run_lib.py:146] step: 328250, training_loss: 6.56814e-02
I0515 15:23:12.688626 22392998065984 run_lib.py:146] step: 328300, training_loss: 5.80090e-02
I0515 15:23:12.849945 22392998065984 run_lib.py:167] step: 328300, eval_loss: 8.51535e-02
I0515 15:23:37.177010 22392998065984 run_lib.py:146] step: 328350, training_loss: 7.08607e-02
I0515 15:24:02.169501 22392998065984 run_lib.py:146] step: 328400, training_loss: 6.46768e-02
I0515 15:24:02.345566 22392998065984 run_lib.py:167] step: 328400, eval_loss: 6.01217e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:24:26.830366 22392998065984 run_lib.py:146] step: 328450, training_loss: 5.72484e-02
I0515 15:24:51.105273 22392998065984 run_lib.py:146] step: 328500, training_loss: 5.45877e-02
I0515 15:24:51.276127 22392998065984 run_lib.py:167] step: 328500, eval_loss: 7.08028e-02
I0515 15:25:16.374625 22392998065984 run_lib.py:146] step: 328550, training_loss: 6.01954e-02
I0515 15:25:40.753349 22392998065984 run_lib.py:146] step: 328600, training_loss: 6.55036e-02
I0515 15:25:40.916802 22392998065984 run_lib.py:167] step: 328600, eval_loss: 7.51436e-02
I0515 15:26:05.329277 22392998065984 run_lib.py:146] step: 328650, training_loss: 6.05604e-02
I0515 15:26:29.982021 22392998065984 run_lib.py:146] step: 328700, training_loss: 3.67915e-02
I0515 15:26:30.143181 22392998065984 run_lib.py:167] step: 328700, eval_loss: 5.90306e-02
I0515 15:26:54.879155 22392998065984 run_lib.py:146] step: 328750, training_loss: 5.08316e-02
I0515 15:27:19.105254 22392998065984 run_lib.py:146] step: 328800, training_loss: 9.17275e-02
I0515 15:27:19.265212 22392998065984 run_lib.py:167] step: 328800, eval_loss: 5.31319e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:27:44.072232 22392998065984 run_lib.py:146] step: 328850, training_loss: 4.97250e-02
I0515 15:28:08.709845 22392998065984 run_lib.py:146] step: 328900, training_loss: 5.35866e-02
I0515 15:28:08.876452 22392998065984 run_lib.py:167] step: 328900, eval_loss: 5.64844e-02
I0515 15:28:33.212137 22392998065984 run_lib.py:146] step: 328950, training_loss: 6.18768e-02
I0515 15:28:57.544170 22392998065984 run_lib.py:146] step: 329000, training_loss: 5.96738e-02
I0515 15:28:57.704204 22392998065984 run_lib.py:167] step: 329000, eval_loss: 7.28499e-02
I0515 15:29:22.726441 22392998065984 run_lib.py:146] step: 329050, training_loss: 6.60304e-02
I0515 15:29:47.025627 22392998065984 run_lib.py:146] step: 329100, training_loss: 7.42544e-02
I0515 15:29:47.192178 22392998065984 run_lib.py:167] step: 329100, eval_loss: 7.86956e-02
I0515 15:30:11.451832 22392998065984 run_lib.py:146] step: 329150, training_loss: 6.77000e-02
I0515 15:30:36.344838 22392998065984 run_lib.py:146] step: 329200, training_loss: 5.53647e-02
I0515 15:30:36.514004 22392998065984 run_lib.py:167] step: 329200, eval_loss: 6.27522e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:31:00.942828 22392998065984 run_lib.py:146] step: 329250, training_loss: 5.50483e-02
I0515 15:31:25.199618 22392998065984 run_lib.py:146] step: 329300, training_loss: 6.24406e-02
I0515 15:31:25.368372 22392998065984 run_lib.py:167] step: 329300, eval_loss: 6.50380e-02
I0515 15:31:50.447297 22392998065984 run_lib.py:146] step: 329350, training_loss: 6.44338e-02
I0515 15:32:14.708983 22392998065984 run_lib.py:146] step: 329400, training_loss: 7.25961e-02
I0515 15:32:14.878803 22392998065984 run_lib.py:167] step: 329400, eval_loss: 7.09310e-02
I0515 15:32:39.133843 22392998065984 run_lib.py:146] step: 329450, training_loss: 7.34031e-02
I0515 15:33:04.049181 22392998065984 run_lib.py:146] step: 329500, training_loss: 4.90179e-02
I0515 15:33:04.214022 22392998065984 run_lib.py:167] step: 329500, eval_loss: 5.82967e-02
I0515 15:33:28.481716 22392998065984 run_lib.py:146] step: 329550, training_loss: 4.20171e-02
I0515 15:33:52.744324 22392998065984 run_lib.py:146] step: 329600, training_loss: 6.18188e-02
I0515 15:33:52.908797 22392998065984 run_lib.py:167] step: 329600, eval_loss: 9.18170e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:34:17.838834 22392998065984 run_lib.py:146] step: 329650, training_loss: 7.19804e-02
I0515 15:34:42.514256 22392998065984 run_lib.py:146] step: 329700, training_loss: 5.19366e-02
I0515 15:34:42.679123 22392998065984 run_lib.py:167] step: 329700, eval_loss: 6.19631e-02
I0515 15:35:06.914499 22392998065984 run_lib.py:146] step: 329750, training_loss: 5.03193e-02
I0515 15:35:31.321131 22392998065984 run_lib.py:146] step: 329800, training_loss: 3.72504e-02
I0515 15:35:31.482340 22392998065984 run_lib.py:167] step: 329800, eval_loss: 6.69239e-02
I0515 15:35:55.898199 22392998065984 run_lib.py:146] step: 329850, training_loss: 6.91697e-02
I0515 15:36:19.992052 22392998065984 run_lib.py:146] step: 329900, training_loss: 5.55171e-02
I0515 15:36:20.157067 22392998065984 run_lib.py:167] step: 329900, eval_loss: 5.45559e-02
I0515 15:36:44.380504 22392998065984 run_lib.py:146] step: 329950, training_loss: 6.51469e-02
I0515 15:37:09.477904 22392998065984 run_lib.py:146] step: 330000, training_loss: 6.99859e-02
I0515 15:37:11.413270 22392998065984 run_lib.py:167] step: 330000, eval_loss: 7.73950e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:37:37.463508 22392998065984 run_lib.py:146] step: 330050, training_loss: 6.07977e-02
I0515 15:38:02.286189 22392998065984 run_lib.py:146] step: 330100, training_loss: 6.17806e-02
I0515 15:38:02.450308 22392998065984 run_lib.py:167] step: 330100, eval_loss: 7.05010e-02
I0515 15:38:27.176688 22392998065984 run_lib.py:146] step: 330150, training_loss: 5.40300e-02
I0515 15:38:51.443672 22392998065984 run_lib.py:146] step: 330200, training_loss: 5.99743e-02
I0515 15:38:51.605600 22392998065984 run_lib.py:167] step: 330200, eval_loss: 7.07641e-02
I0515 15:39:15.859614 22392998065984 run_lib.py:146] step: 330250, training_loss: 6.93142e-02
I0515 15:39:40.827146 22392998065984 run_lib.py:146] step: 330300, training_loss: 6.00571e-02
I0515 15:39:40.993608 22392998065984 run_lib.py:167] step: 330300, eval_loss: 5.34640e-02
I0515 15:40:05.298946 22392998065984 run_lib.py:146] step: 330350, training_loss: 4.18105e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:40:29.730655 22392998065984 run_lib.py:146] step: 330400, training_loss: 5.53594e-02
I0515 15:40:29.897353 22392998065984 run_lib.py:167] step: 330400, eval_loss: 6.19473e-02
I0515 15:40:55.024161 22392998065984 run_lib.py:146] step: 330450, training_loss: 5.08726e-02
I0515 15:41:19.359059 22392998065984 run_lib.py:146] step: 330500, training_loss: 4.53309e-02
I0515 15:41:19.519299 22392998065984 run_lib.py:167] step: 330500, eval_loss: 4.53517e-02
I0515 15:41:43.829396 22392998065984 run_lib.py:146] step: 330550, training_loss: 8.34916e-02
I0515 15:42:08.746529 22392998065984 run_lib.py:146] step: 330600, training_loss: 5.29966e-02
I0515 15:42:08.916232 22392998065984 run_lib.py:167] step: 330600, eval_loss: 3.83611e-02
I0515 15:42:33.139407 22392998065984 run_lib.py:146] step: 330650, training_loss: 5.90687e-02
I0515 15:42:57.447999 22392998065984 run_lib.py:146] step: 330700, training_loss: 5.42733e-02
I0515 15:42:57.607725 22392998065984 run_lib.py:167] step: 330700, eval_loss: 5.50701e-02
I0515 15:43:22.220138 22392998065984 run_lib.py:146] step: 330750, training_loss: 5.97197e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:43:47.016726 22392998065984 run_lib.py:146] step: 330800, training_loss: 7.35382e-02
I0515 15:43:47.183546 22392998065984 run_lib.py:167] step: 330800, eval_loss: 5.13456e-02
I0515 15:44:11.372494 22392998065984 run_lib.py:146] step: 330850, training_loss: 4.50318e-02
I0515 15:44:36.142298 22392998065984 run_lib.py:146] step: 330900, training_loss: 6.60572e-02
I0515 15:44:36.307473 22392998065984 run_lib.py:167] step: 330900, eval_loss: 5.50969e-02
I0515 15:45:00.989685 22392998065984 run_lib.py:146] step: 330950, training_loss: 6.81131e-02
I0515 15:45:25.254741 22392998065984 run_lib.py:146] step: 331000, training_loss: 4.48884e-02
I0515 15:45:25.414690 22392998065984 run_lib.py:167] step: 331000, eval_loss: 7.21515e-02
I0515 15:45:50.005222 22392998065984 run_lib.py:146] step: 331050, training_loss: 7.04280e-02
I0515 15:46:14.566843 22392998065984 run_lib.py:146] step: 331100, training_loss: 4.03767e-02
I0515 15:46:14.728864 22392998065984 run_lib.py:167] step: 331100, eval_loss: 4.65243e-02
I0515 15:46:38.978976 22392998065984 run_lib.py:146] step: 331150, training_loss: 5.38041e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:47:03.430850 22392998065984 run_lib.py:146] step: 331200, training_loss: 4.06860e-02
I0515 15:47:03.597996 22392998065984 run_lib.py:167] step: 331200, eval_loss: 6.40426e-02
I0515 15:47:28.666526 22392998065984 run_lib.py:146] step: 331250, training_loss: 6.31393e-02
I0515 15:47:52.926869 22392998065984 run_lib.py:146] step: 331300, training_loss: 7.41998e-02
I0515 15:47:53.109718 22392998065984 run_lib.py:167] step: 331300, eval_loss: 4.34325e-02
I0515 15:48:17.453408 22392998065984 run_lib.py:146] step: 331350, training_loss: 4.78994e-02
I0515 15:48:42.456738 22392998065984 run_lib.py:146] step: 331400, training_loss: 3.87864e-02
I0515 15:48:42.627202 22392998065984 run_lib.py:167] step: 331400, eval_loss: 4.23694e-02
I0515 15:49:06.893940 22392998065984 run_lib.py:146] step: 331450, training_loss: 5.33820e-02
I0515 15:49:31.164668 22392998065984 run_lib.py:146] step: 331500, training_loss: 5.24528e-02
I0515 15:49:31.327142 22392998065984 run_lib.py:167] step: 331500, eval_loss: 6.11103e-02
I0515 15:49:55.874679 22392998065984 run_lib.py:146] step: 331550, training_loss: 5.91015e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:50:20.680316 22392998065984 run_lib.py:146] step: 331600, training_loss: 5.11270e-02
I0515 15:50:20.850470 22392998065984 run_lib.py:167] step: 331600, eval_loss: 5.48760e-02
I0515 15:50:45.194980 22392998065984 run_lib.py:146] step: 331650, training_loss: 7.03489e-02
I0515 15:51:09.945672 22392998065984 run_lib.py:146] step: 331700, training_loss: 4.83315e-02
I0515 15:51:10.059135 22392998065984 run_lib.py:167] step: 331700, eval_loss: 9.76429e-02
I0515 15:51:34.697370 22392998065984 run_lib.py:146] step: 331750, training_loss: 6.02243e-02
I0515 15:51:58.894302 22392998065984 run_lib.py:146] step: 331800, training_loss: 6.53336e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:51:59.345445 22392998065984 run_lib.py:167] step: 331800, eval_loss: 5.40574e-02
I0515 15:52:24.068971 22392998065984 run_lib.py:146] step: 331850, training_loss: 4.75995e-02
I0515 15:52:48.756883 22392998065984 run_lib.py:146] step: 331900, training_loss: 5.09440e-02
I0515 15:52:48.917530 22392998065984 run_lib.py:167] step: 331900, eval_loss: 6.19322e-02
I0515 15:53:13.226844 22392998065984 run_lib.py:146] step: 331950, training_loss: 5.72024e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:53:37.692811 22392998065984 run_lib.py:146] step: 332000, training_loss: 5.46309e-02
I0515 15:53:37.866441 22392998065984 run_lib.py:167] step: 332000, eval_loss: 5.43405e-02
I0515 15:54:02.829413 22392998065984 run_lib.py:146] step: 332050, training_loss: 5.46850e-02
I0515 15:54:27.073260 22392998065984 run_lib.py:146] step: 332100, training_loss: 5.51282e-02
I0515 15:54:27.232538 22392998065984 run_lib.py:167] step: 332100, eval_loss: 5.13315e-02
I0515 15:54:51.606761 22392998065984 run_lib.py:146] step: 332150, training_loss: 5.29089e-02
I0515 15:55:16.543608 22392998065984 run_lib.py:146] step: 332200, training_loss: 4.65593e-02
I0515 15:55:16.703258 22392998065984 run_lib.py:167] step: 332200, eval_loss: 4.56023e-02
I0515 15:55:41.012591 22392998065984 run_lib.py:146] step: 332250, training_loss: 5.52579e-02
I0515 15:56:05.331916 22392998065984 run_lib.py:146] step: 332300, training_loss: 5.56232e-02
I0515 15:56:05.491870 22392998065984 run_lib.py:167] step: 332300, eval_loss: 6.75701e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:56:30.288582 22392998065984 run_lib.py:146] step: 332350, training_loss: 5.18395e-02
I0515 15:56:55.043036 22392998065984 run_lib.py:146] step: 332400, training_loss: 6.52691e-02
I0515 15:56:55.205342 22392998065984 run_lib.py:167] step: 332400, eval_loss: 5.99396e-02
I0515 15:57:19.615443 22392998065984 run_lib.py:146] step: 332450, training_loss: 5.87244e-02
I0515 15:57:44.288747 22392998065984 run_lib.py:146] step: 332500, training_loss: 6.07197e-02
I0515 15:57:44.457206 22392998065984 run_lib.py:167] step: 332500, eval_loss: 5.13655e-02
I0515 15:58:09.119805 22392998065984 run_lib.py:146] step: 332550, training_loss: 4.90500e-02
I0515 15:58:33.417246 22392998065984 run_lib.py:146] step: 332600, training_loss: 5.65600e-02
I0515 15:58:33.577273 22392998065984 run_lib.py:167] step: 332600, eval_loss: 5.83476e-02
I0515 15:58:58.154457 22392998065984 run_lib.py:146] step: 332650, training_loss: 6.45373e-02
I0515 15:59:22.846982 22392998065984 run_lib.py:146] step: 332700, training_loss: 4.59054e-02
I0515 15:59:23.007018 22392998065984 run_lib.py:167] step: 332700, eval_loss: 7.02604e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 15:59:47.436660 22392998065984 run_lib.py:146] step: 332750, training_loss: 5.92018e-02
I0515 16:00:11.801850 22392998065984 run_lib.py:146] step: 332800, training_loss: 4.87252e-02
I0515 16:00:11.964903 22392998065984 run_lib.py:167] step: 332800, eval_loss: 6.22985e-02
I0515 16:00:36.925318 22392998065984 run_lib.py:146] step: 332850, training_loss: 6.96523e-02
I0515 16:01:01.198529 22392998065984 run_lib.py:146] step: 332900, training_loss: 5.10363e-02
I0515 16:01:01.358370 22392998065984 run_lib.py:167] step: 332900, eval_loss: 5.38278e-02
I0515 16:01:25.656276 22392998065984 run_lib.py:146] step: 332950, training_loss: 6.11755e-02
I0515 16:01:50.552052 22392998065984 run_lib.py:146] step: 333000, training_loss: 5.64861e-02
I0515 16:01:50.712539 22392998065984 run_lib.py:167] step: 333000, eval_loss: 5.98416e-02
I0515 16:02:15.043636 22392998065984 run_lib.py:146] step: 333050, training_loss: 5.75994e-02
I0515 16:02:39.369848 22392998065984 run_lib.py:146] step: 333100, training_loss: 4.45639e-02
I0515 16:02:39.547918 22392998065984 run_lib.py:167] step: 333100, eval_loss: 6.45435e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:03:04.358551 22392998065984 run_lib.py:146] step: 333150, training_loss: 6.15162e-02
I0515 16:03:29.108731 22392998065984 run_lib.py:146] step: 333200, training_loss: 6.30674e-02
I0515 16:03:29.274002 22392998065984 run_lib.py:167] step: 333200, eval_loss: 4.99366e-02
I0515 16:03:53.650422 22392998065984 run_lib.py:146] step: 333250, training_loss: 5.01974e-02
I0515 16:04:18.280633 22392998065984 run_lib.py:146] step: 333300, training_loss: 6.27686e-02
I0515 16:04:18.440456 22392998065984 run_lib.py:167] step: 333300, eval_loss: 5.55833e-02
I0515 16:04:43.109086 22392998065984 run_lib.py:146] step: 333350, training_loss: 4.01486e-02
I0515 16:05:07.437486 22392998065984 run_lib.py:146] step: 333400, training_loss: 4.42181e-02
I0515 16:05:07.606495 22392998065984 run_lib.py:167] step: 333400, eval_loss: 6.57460e-02
I0515 16:05:31.910581 22392998065984 run_lib.py:146] step: 333450, training_loss: 4.54878e-02
I0515 16:05:56.869266 22392998065984 run_lib.py:146] step: 333500, training_loss: 5.42480e-02
I0515 16:05:57.029675 22392998065984 run_lib.py:167] step: 333500, eval_loss: 8.02910e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:06:21.466281 22392998065984 run_lib.py:146] step: 333550, training_loss: 5.37150e-02
I0515 16:06:45.497981 22392998065984 run_lib.py:146] step: 333600, training_loss: 6.39570e-02
I0515 16:06:45.661547 22392998065984 run_lib.py:167] step: 333600, eval_loss: 6.39428e-02
I0515 16:07:10.607368 22392998065984 run_lib.py:146] step: 333650, training_loss: 5.47530e-02
I0515 16:07:34.977557 22392998065984 run_lib.py:146] step: 333700, training_loss: 6.42275e-02
I0515 16:07:35.149249 22392998065984 run_lib.py:167] step: 333700, eval_loss: 6.36737e-02
I0515 16:07:59.456153 22392998065984 run_lib.py:146] step: 333750, training_loss: 6.09306e-02
I0515 16:08:24.176922 22392998065984 run_lib.py:146] step: 333800, training_loss: 7.05634e-02
I0515 16:08:24.337138 22392998065984 run_lib.py:167] step: 333800, eval_loss: 4.77783e-02
I0515 16:08:48.606320 22392998065984 run_lib.py:146] step: 333850, training_loss: 5.59412e-02
I0515 16:09:12.814195 22392998065984 run_lib.py:146] step: 333900, training_loss: 6.10604e-02
I0515 16:09:12.978169 22392998065984 run_lib.py:167] step: 333900, eval_loss: 5.74549e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:09:37.765225 22392998065984 run_lib.py:146] step: 333950, training_loss: 4.39700e-02
I0515 16:10:02.218749 22392998065984 run_lib.py:146] step: 334000, training_loss: 6.05607e-02
I0515 16:10:02.384348 22392998065984 run_lib.py:167] step: 334000, eval_loss: 5.97382e-02
I0515 16:10:26.508570 22392998065984 run_lib.py:146] step: 334050, training_loss: 6.89998e-02
I0515 16:10:51.534172 22392998065984 run_lib.py:146] step: 334100, training_loss: 4.12704e-02
I0515 16:10:51.746579 22392998065984 run_lib.py:167] step: 334100, eval_loss: 4.75485e-02
I0515 16:11:16.505411 22392998065984 run_lib.py:146] step: 334150, training_loss: 4.82391e-02
I0515 16:11:40.864448 22392998065984 run_lib.py:146] step: 334200, training_loss: 4.85889e-02
I0515 16:11:41.034873 22392998065984 run_lib.py:167] step: 334200, eval_loss: 5.79127e-02
I0515 16:12:05.352502 22392998065984 run_lib.py:146] step: 334250, training_loss: 7.45530e-02
I0515 16:12:30.322209 22392998065984 run_lib.py:146] step: 334300, training_loss: 5.32287e-02
I0515 16:12:30.492614 22392998065984 run_lib.py:167] step: 334300, eval_loss: 4.88090e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:12:54.968394 22392998065984 run_lib.py:146] step: 334350, training_loss: 5.99881e-02
I0515 16:13:19.345464 22392998065984 run_lib.py:146] step: 334400, training_loss: 4.21300e-02
I0515 16:13:19.507626 22392998065984 run_lib.py:167] step: 334400, eval_loss: 6.01401e-02
I0515 16:13:44.596773 22392998065984 run_lib.py:146] step: 334450, training_loss: 7.52940e-02
I0515 16:14:08.967495 22392998065984 run_lib.py:146] step: 334500, training_loss: 6.47985e-02
I0515 16:14:09.136126 22392998065984 run_lib.py:167] step: 334500, eval_loss: 4.99554e-02
I0515 16:14:33.431129 22392998065984 run_lib.py:146] step: 334550, training_loss: 7.06462e-02
I0515 16:14:58.376477 22392998065984 run_lib.py:146] step: 334600, training_loss: 5.73605e-02
I0515 16:14:58.547163 22392998065984 run_lib.py:167] step: 334600, eval_loss: 3.66316e-02
I0515 16:15:22.899036 22392998065984 run_lib.py:146] step: 334650, training_loss: 5.04620e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:15:47.336121 22392998065984 run_lib.py:146] step: 334700, training_loss: 4.84723e-02
I0515 16:15:47.522952 22392998065984 run_lib.py:167] step: 334700, eval_loss: 6.42399e-02
I0515 16:16:12.674788 22392998065984 run_lib.py:146] step: 334750, training_loss: 5.50801e-02
I0515 16:16:37.087190 22392998065984 run_lib.py:146] step: 334800, training_loss: 5.44729e-02
I0515 16:16:37.258038 22392998065984 run_lib.py:167] step: 334800, eval_loss: 7.55446e-02
I0515 16:17:01.419660 22392998065984 run_lib.py:146] step: 334850, training_loss: 4.89152e-02
I0515 16:17:26.007105 22392998065984 run_lib.py:146] step: 334900, training_loss: 5.51056e-02
I0515 16:17:26.179007 22392998065984 run_lib.py:167] step: 334900, eval_loss: 6.14379e-02
I0515 16:17:50.918186 22392998065984 run_lib.py:146] step: 334950, training_loss: 6.08000e-02
I0515 16:18:15.267314 22392998065984 run_lib.py:146] step: 335000, training_loss: 4.89615e-02
I0515 16:18:15.448970 22392998065984 run_lib.py:167] step: 335000, eval_loss: 5.96138e-02
I0515 16:18:39.732710 22392998065984 run_lib.py:146] step: 335050, training_loss: 5.37799e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:19:05.004711 22392998065984 run_lib.py:146] step: 335100, training_loss: 4.48572e-02
I0515 16:19:05.177432 22392998065984 run_lib.py:167] step: 335100, eval_loss: 5.70481e-02
I0515 16:19:29.649396 22392998065984 run_lib.py:146] step: 335150, training_loss: 4.57358e-02
I0515 16:19:53.936239 22392998065984 run_lib.py:146] step: 335200, training_loss: 5.57431e-02
I0515 16:19:54.098017 22392998065984 run_lib.py:167] step: 335200, eval_loss: 6.20033e-02
I0515 16:20:19.004405 22392998065984 run_lib.py:146] step: 335250, training_loss: 6.28072e-02
I0515 16:20:43.246211 22392998065984 run_lib.py:146] step: 335300, training_loss: 5.84004e-02
I0515 16:20:43.406204 22392998065984 run_lib.py:167] step: 335300, eval_loss: 7.15732e-02
I0515 16:21:07.809331 22392998065984 run_lib.py:146] step: 335350, training_loss: 6.33070e-02
I0515 16:21:32.910070 22392998065984 run_lib.py:146] step: 335400, training_loss: 7.14805e-02
I0515 16:21:33.078822 22392998065984 run_lib.py:167] step: 335400, eval_loss: 9.57912e-02
I0515 16:21:57.336281 22392998065984 run_lib.py:146] step: 335450, training_loss: 5.98611e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:22:21.819538 22392998065984 run_lib.py:146] step: 335500, training_loss: 5.06834e-02
I0515 16:22:21.990427 22392998065984 run_lib.py:167] step: 335500, eval_loss: 5.91104e-02
I0515 16:22:47.165310 22392998065984 run_lib.py:146] step: 335550, training_loss: 6.13581e-02
I0515 16:23:11.726460 22392998065984 run_lib.py:146] step: 335600, training_loss: 5.55329e-02
I0515 16:23:11.897069 22392998065984 run_lib.py:167] step: 335600, eval_loss: 5.25326e-02
I0515 16:23:36.156637 22392998065984 run_lib.py:146] step: 335650, training_loss: 6.43464e-02
I0515 16:24:00.752612 22392998065984 run_lib.py:146] step: 335700, training_loss: 5.98713e-02
I0515 16:24:00.937055 22392998065984 run_lib.py:167] step: 335700, eval_loss: 8.09657e-02
I0515 16:24:25.664494 22392998065984 run_lib.py:146] step: 335750, training_loss: 6.09108e-02
I0515 16:24:49.874757 22392998065984 run_lib.py:146] step: 335800, training_loss: 5.02698e-02
I0515 16:24:50.035301 22392998065984 run_lib.py:167] step: 335800, eval_loss: 8.20741e-02
I0515 16:25:14.586387 22392998065984 run_lib.py:146] step: 335850, training_loss: 6.98448e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:25:39.473913 22392998065984 run_lib.py:146] step: 335900, training_loss: 7.46724e-02
I0515 16:25:39.635561 22392998065984 run_lib.py:167] step: 335900, eval_loss: 6.71439e-02
I0515 16:26:04.064708 22392998065984 run_lib.py:146] step: 335950, training_loss: 6.71251e-02
I0515 16:26:28.353154 22392998065984 run_lib.py:146] step: 336000, training_loss: 4.94599e-02
I0515 16:26:28.512022 22392998065984 run_lib.py:167] step: 336000, eval_loss: 4.79374e-02
I0515 16:26:53.472602 22392998065984 run_lib.py:146] step: 336050, training_loss: 5.50976e-02
I0515 16:27:17.727744 22392998065984 run_lib.py:146] step: 336100, training_loss: 6.36258e-02
I0515 16:27:17.887849 22392998065984 run_lib.py:167] step: 336100, eval_loss: 7.27650e-02
I0515 16:27:42.153889 22392998065984 run_lib.py:146] step: 336150, training_loss: 5.60128e-02
I0515 16:28:07.058177 22392998065984 run_lib.py:146] step: 336200, training_loss: 5.01930e-02
I0515 16:28:07.239183 22392998065984 run_lib.py:167] step: 336200, eval_loss: 4.63810e-02
I0515 16:28:31.517435 22392998065984 run_lib.py:146] step: 336250, training_loss: 4.92112e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:28:56.052740 22392998065984 run_lib.py:146] step: 336300, training_loss: 4.04540e-02
I0515 16:28:56.215845 22392998065984 run_lib.py:167] step: 336300, eval_loss: 4.51378e-02
I0515 16:29:21.199134 22392998065984 run_lib.py:146] step: 336350, training_loss: 4.14040e-02
I0515 16:29:45.488360 22392998065984 run_lib.py:146] step: 336400, training_loss: 3.79302e-02
I0515 16:29:45.658802 22392998065984 run_lib.py:167] step: 336400, eval_loss: 6.01936e-02
I0515 16:30:09.958703 22392998065984 run_lib.py:146] step: 336450, training_loss: 4.15124e-02
I0515 16:30:34.904546 22392998065984 run_lib.py:146] step: 336500, training_loss: 7.61731e-02
I0515 16:30:35.064172 22392998065984 run_lib.py:167] step: 336500, eval_loss: 8.42599e-02
I0515 16:30:59.385125 22392998065984 run_lib.py:146] step: 336550, training_loss: 7.74068e-02
I0515 16:31:23.663241 22392998065984 run_lib.py:146] step: 336600, training_loss: 5.70971e-02
I0515 16:31:23.823039 22392998065984 run_lib.py:167] step: 336600, eval_loss: 5.40894e-02
I0515 16:31:48.339348 22392998065984 run_lib.py:146] step: 336650, training_loss: 6.35992e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:32:13.329208 22392998065984 run_lib.py:146] step: 336700, training_loss: 5.72030e-02
I0515 16:32:13.512285 22392998065984 run_lib.py:167] step: 336700, eval_loss: 5.11794e-02
I0515 16:32:37.548562 22392998065984 run_lib.py:146] step: 336750, training_loss: 5.77782e-02
I0515 16:33:01.772861 22392998065984 run_lib.py:146] step: 336800, training_loss: 5.61519e-02
I0515 16:33:01.932738 22392998065984 run_lib.py:167] step: 336800, eval_loss: 7.14347e-02
I0515 16:33:27.000465 22392998065984 run_lib.py:146] step: 336850, training_loss: 6.31085e-02
I0515 16:33:51.328445 22392998065984 run_lib.py:146] step: 336900, training_loss: 7.00834e-02
I0515 16:33:51.497184 22392998065984 run_lib.py:167] step: 336900, eval_loss: 5.65489e-02
I0515 16:34:15.782972 22392998065984 run_lib.py:146] step: 336950, training_loss: 7.20091e-02
I0515 16:34:40.675234 22392998065984 run_lib.py:146] step: 337000, training_loss: 8.20976e-02
I0515 16:34:40.834093 22392998065984 run_lib.py:167] step: 337000, eval_loss: 5.00604e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:35:05.327300 22392998065984 run_lib.py:146] step: 337050, training_loss: 5.24281e-02
I0515 16:35:29.704300 22392998065984 run_lib.py:146] step: 337100, training_loss: 4.70613e-02
I0515 16:35:29.868642 22392998065984 run_lib.py:167] step: 337100, eval_loss: 7.59907e-02
I0515 16:35:54.940051 22392998065984 run_lib.py:146] step: 337150, training_loss: 6.37417e-02
I0515 16:36:19.304373 22392998065984 run_lib.py:146] step: 337200, training_loss: 6.22356e-02
I0515 16:36:19.486715 22392998065984 run_lib.py:167] step: 337200, eval_loss: 4.83786e-02
I0515 16:36:43.748436 22392998065984 run_lib.py:146] step: 337250, training_loss: 5.84250e-02
I0515 16:37:08.665341 22392998065984 run_lib.py:146] step: 337300, training_loss: 5.24580e-02
I0515 16:37:08.838215 22392998065984 run_lib.py:167] step: 337300, eval_loss: 8.18631e-02
I0515 16:37:33.112720 22392998065984 run_lib.py:146] step: 337350, training_loss: 4.99615e-02
I0515 16:37:57.371754 22392998065984 run_lib.py:146] step: 337400, training_loss: 7.92563e-02
I0515 16:37:57.542694 22392998065984 run_lib.py:167] step: 337400, eval_loss: 7.45559e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:38:22.483366 22392998065984 run_lib.py:146] step: 337450, training_loss: 5.26486e-02
I0515 16:38:47.345438 22392998065984 run_lib.py:146] step: 337500, training_loss: 5.72923e-02
I0515 16:38:47.521747 22392998065984 run_lib.py:167] step: 337500, eval_loss: 5.94424e-02
I0515 16:39:11.880931 22392998065984 run_lib.py:146] step: 337550, training_loss: 7.60171e-02
I0515 16:39:36.166821 22392998065984 run_lib.py:146] step: 337600, training_loss: 5.60661e-02
I0515 16:39:36.341891 22392998065984 run_lib.py:167] step: 337600, eval_loss: 6.62019e-02
I0515 16:40:01.537877 22392998065984 run_lib.py:146] step: 337650, training_loss: 5.65473e-02
I0515 16:40:25.789871 22392998065984 run_lib.py:146] step: 337700, training_loss: 5.86662e-02
I0515 16:40:25.958798 22392998065984 run_lib.py:167] step: 337700, eval_loss: 6.13433e-02
I0515 16:40:50.270451 22392998065984 run_lib.py:146] step: 337750, training_loss: 4.99324e-02
I0515 16:41:15.200972 22392998065984 run_lib.py:146] step: 337800, training_loss: 6.81645e-02
I0515 16:41:15.361565 22392998065984 run_lib.py:167] step: 337800, eval_loss: 5.18883e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:41:39.867616 22392998065984 run_lib.py:146] step: 337850, training_loss: 6.19780e-02
I0515 16:42:04.213632 22392998065984 run_lib.py:146] step: 337900, training_loss: 6.62899e-02
I0515 16:42:04.383996 22392998065984 run_lib.py:167] step: 337900, eval_loss: 5.04308e-02
I0515 16:42:29.307229 22392998065984 run_lib.py:146] step: 337950, training_loss: 5.10332e-02
I0515 16:42:53.547104 22392998065984 run_lib.py:146] step: 338000, training_loss: 5.30063e-02
I0515 16:42:53.707397 22392998065984 run_lib.py:167] step: 338000, eval_loss: 7.20420e-02
I0515 16:43:18.074284 22392998065984 run_lib.py:146] step: 338050, training_loss: 5.83767e-02
I0515 16:43:43.106069 22392998065984 run_lib.py:146] step: 338100, training_loss: 4.35066e-02
I0515 16:43:43.267449 22392998065984 run_lib.py:167] step: 338100, eval_loss: 5.78173e-02
I0515 16:44:07.550783 22392998065984 run_lib.py:146] step: 338150, training_loss: 5.79217e-02
I0515 16:44:31.743737 22392998065984 run_lib.py:146] step: 338200, training_loss: 4.89432e-02
I0515 16:44:31.905796 22392998065984 run_lib.py:167] step: 338200, eval_loss: 4.91331e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:44:56.588979 22392998065984 run_lib.py:146] step: 338250, training_loss: 5.08497e-02
I0515 16:45:21.382453 22392998065984 run_lib.py:146] step: 338300, training_loss: 5.57858e-02
I0515 16:45:21.545996 22392998065984 run_lib.py:167] step: 338300, eval_loss: 6.21377e-02
I0515 16:45:45.990647 22392998065984 run_lib.py:146] step: 338350, training_loss: 5.08115e-02
I0515 16:46:10.565390 22392998065984 run_lib.py:146] step: 338400, training_loss: 5.92585e-02
I0515 16:46:10.734877 22392998065984 run_lib.py:167] step: 338400, eval_loss: 4.41540e-02
I0515 16:46:35.220193 22392998065984 run_lib.py:146] step: 338450, training_loss: 4.29107e-02
I0515 16:46:59.543393 22392998065984 run_lib.py:146] step: 338500, training_loss: 6.41010e-02
I0515 16:46:59.713364 22392998065984 run_lib.py:167] step: 338500, eval_loss: 5.72641e-02
I0515 16:47:24.008011 22392998065984 run_lib.py:146] step: 338550, training_loss: 5.69048e-02
I0515 16:47:48.896619 22392998065984 run_lib.py:146] step: 338600, training_loss: 4.12367e-02
I0515 16:47:49.055483 22392998065984 run_lib.py:167] step: 338600, eval_loss: 5.91608e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:48:13.537858 22392998065984 run_lib.py:146] step: 338650, training_loss: 5.53481e-02
I0515 16:48:37.896857 22392998065984 run_lib.py:146] step: 338700, training_loss: 6.24775e-02
I0515 16:48:38.080568 22392998065984 run_lib.py:167] step: 338700, eval_loss: 6.08165e-02
I0515 16:49:03.105824 22392998065984 run_lib.py:146] step: 338750, training_loss: 6.72608e-02
I0515 16:49:27.402037 22392998065984 run_lib.py:146] step: 338800, training_loss: 7.07898e-02
I0515 16:49:27.570605 22392998065984 run_lib.py:167] step: 338800, eval_loss: 4.97433e-02
I0515 16:49:51.850665 22392998065984 run_lib.py:146] step: 338850, training_loss: 5.78957e-02
I0515 16:50:16.763767 22392998065984 run_lib.py:146] step: 338900, training_loss: 6.73314e-02
I0515 16:50:16.948572 22392998065984 run_lib.py:167] step: 338900, eval_loss: 5.77306e-02
I0515 16:50:41.266560 22392998065984 run_lib.py:146] step: 338950, training_loss: 5.14990e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:51:05.778114 22392998065984 run_lib.py:146] step: 339000, training_loss: 6.02198e-02
I0515 16:51:05.949797 22392998065984 run_lib.py:167] step: 339000, eval_loss: 5.08508e-02
I0515 16:51:30.439135 22392998065984 run_lib.py:146] step: 339050, training_loss: 4.90079e-02
I0515 16:51:55.134017 22392998065984 run_lib.py:146] step: 339100, training_loss: 4.34490e-02
I0515 16:51:55.294594 22392998065984 run_lib.py:167] step: 339100, eval_loss: 4.52002e-02
I0515 16:52:19.721665 22392998065984 run_lib.py:146] step: 339150, training_loss: 6.37945e-02
I0515 16:52:44.332580 22392998065984 run_lib.py:146] step: 339200, training_loss: 6.05315e-02
I0515 16:52:44.503617 22392998065984 run_lib.py:167] step: 339200, eval_loss: 5.37956e-02
I0515 16:53:09.214480 22392998065984 run_lib.py:146] step: 339250, training_loss: 5.44155e-02
I0515 16:53:33.493161 22392998065984 run_lib.py:146] step: 339300, training_loss: 6.65522e-02
I0515 16:53:33.653068 22392998065984 run_lib.py:167] step: 339300, eval_loss: 6.96704e-02
I0515 16:53:58.021603 22392998065984 run_lib.py:146] step: 339350, training_loss: 5.66423e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:54:23.285713 22392998065984 run_lib.py:146] step: 339400, training_loss: 7.19035e-02
I0515 16:54:23.450362 22392998065984 run_lib.py:167] step: 339400, eval_loss: 6.77378e-02
I0515 16:54:47.734420 22392998065984 run_lib.py:146] step: 339450, training_loss: 6.41710e-02
I0515 16:55:12.091226 22392998065984 run_lib.py:146] step: 339500, training_loss: 5.24316e-02
I0515 16:55:12.259827 22392998065984 run_lib.py:167] step: 339500, eval_loss: 6.52895e-02
I0515 16:55:37.331824 22392998065984 run_lib.py:146] step: 339550, training_loss: 7.82193e-02
I0515 16:56:01.649782 22392998065984 run_lib.py:146] step: 339600, training_loss: 4.18909e-02
I0515 16:56:01.740221 22392998065984 run_lib.py:167] step: 339600, eval_loss: 3.86722e-02
I0515 16:56:26.040267 22392998065984 run_lib.py:146] step: 339650, training_loss: 5.70454e-02
I0515 16:56:50.952094 22392998065984 run_lib.py:146] step: 339700, training_loss: 4.63052e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:56:51.385183 22392998065984 run_lib.py:167] step: 339700, eval_loss: 5.34878e-02
I0515 16:57:15.781005 22392998065984 run_lib.py:146] step: 339750, training_loss: 7.05814e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 16:57:40.323442 22392998065984 run_lib.py:146] step: 339800, training_loss: 5.98989e-02
I0515 16:57:40.489644 22392998065984 run_lib.py:167] step: 339800, eval_loss: 6.29304e-02
I0515 16:58:05.134180 22392998065984 run_lib.py:146] step: 339850, training_loss: 4.20446e-02
I0515 16:58:30.019495 22392998065984 run_lib.py:146] step: 339900, training_loss: 6.18502e-02
I0515 16:58:30.180569 22392998065984 run_lib.py:167] step: 339900, eval_loss: 4.81608e-02
I0515 16:58:54.456939 22392998065984 run_lib.py:146] step: 339950, training_loss: 5.18368e-02
I0515 16:59:18.990844 22392998065984 run_lib.py:146] step: 340000, training_loss: 4.96035e-02
I0515 16:59:20.673805 22392998065984 run_lib.py:167] step: 340000, eval_loss: 6.35465e-02
I0515 16:59:46.723253 22392998065984 run_lib.py:146] step: 340050, training_loss: 4.87082e-02
I0515 17:00:10.932402 22392998065984 run_lib.py:146] step: 340100, training_loss: 5.42379e-02
I0515 17:00:11.094253 22392998065984 run_lib.py:167] step: 340100, eval_loss: 5.27452e-02
I0515 17:00:35.719072 22392998065984 run_lib.py:146] step: 340150, training_loss: 5.09030e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:01:00.495784 22392998065984 run_lib.py:146] step: 340200, training_loss: 4.48196e-02
I0515 17:01:00.658618 22392998065984 run_lib.py:167] step: 340200, eval_loss: 5.59126e-02
I0515 17:01:25.013487 22392998065984 run_lib.py:146] step: 340250, training_loss: 7.60672e-02
I0515 17:01:49.716811 22392998065984 run_lib.py:146] step: 340300, training_loss: 7.21627e-02
I0515 17:01:49.897691 22392998065984 run_lib.py:167] step: 340300, eval_loss: 5.43545e-02
I0515 17:02:14.506439 22392998065984 run_lib.py:146] step: 340350, training_loss: 4.97221e-02
I0515 17:02:38.760442 22392998065984 run_lib.py:146] step: 340400, training_loss: 4.25836e-02
I0515 17:02:38.919567 22392998065984 run_lib.py:167] step: 340400, eval_loss: 5.13838e-02
I0515 17:03:03.490202 22392998065984 run_lib.py:146] step: 340450, training_loss: 5.18376e-02
I0515 17:03:28.066157 22392998065984 run_lib.py:146] step: 340500, training_loss: 5.62870e-02
I0515 17:03:28.240037 22392998065984 run_lib.py:167] step: 340500, eval_loss: 7.02577e-02
I0515 17:03:52.504923 22392998065984 run_lib.py:146] step: 340550, training_loss: 6.70915e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:04:17.301808 22392998065984 run_lib.py:146] step: 340600, training_loss: 5.88666e-02
I0515 17:04:17.484087 22392998065984 run_lib.py:167] step: 340600, eval_loss: 5.26477e-02
I0515 17:04:41.836384 22392998065984 run_lib.py:146] step: 340650, training_loss: 6.42342e-02
I0515 17:05:06.524246 22392998065984 run_lib.py:146] step: 340700, training_loss: 6.12702e-02
I0515 17:05:06.691442 22392998065984 run_lib.py:167] step: 340700, eval_loss: 8.02241e-02
I0515 17:05:31.273721 22392998065984 run_lib.py:146] step: 340750, training_loss: 6.72071e-02
I0515 17:05:55.555368 22392998065984 run_lib.py:146] step: 340800, training_loss: 4.27821e-02
I0515 17:05:55.724949 22392998065984 run_lib.py:167] step: 340800, eval_loss: 8.04406e-02
I0515 17:06:20.353252 22392998065984 run_lib.py:146] step: 340850, training_loss: 5.12752e-02
I0515 17:06:44.612265 22392998065984 run_lib.py:146] step: 340900, training_loss: 4.82322e-02
I0515 17:06:44.793941 22392998065984 run_lib.py:167] step: 340900, eval_loss: 5.57654e-02
I0515 17:07:09.382633 22392998065984 run_lib.py:146] step: 340950, training_loss: 6.35774e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:07:34.249208 22392998065984 run_lib.py:146] step: 341000, training_loss: 4.95814e-02
I0515 17:07:34.410930 22392998065984 run_lib.py:167] step: 341000, eval_loss: 7.26110e-02
I0515 17:07:58.596391 22392998065984 run_lib.py:146] step: 341050, training_loss: 6.24668e-02
I0515 17:08:23.386264 22392998065984 run_lib.py:146] step: 341100, training_loss: 4.41049e-02
I0515 17:08:23.546096 22392998065984 run_lib.py:167] step: 341100, eval_loss: 6.09901e-02
I0515 17:08:48.183059 22392998065984 run_lib.py:146] step: 341150, training_loss: 7.44818e-02
I0515 17:09:12.445757 22392998065984 run_lib.py:146] step: 341200, training_loss: 6.02223e-02
I0515 17:09:12.617645 22392998065984 run_lib.py:167] step: 341200, eval_loss: 5.76875e-02
I0515 17:09:37.212955 22392998065984 run_lib.py:146] step: 341250, training_loss: 7.27911e-02
I0515 17:10:01.826956 22392998065984 run_lib.py:146] step: 341300, training_loss: 4.74257e-02
I0515 17:10:01.986714 22392998065984 run_lib.py:167] step: 341300, eval_loss: 6.54688e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:10:26.525171 22392998065984 run_lib.py:146] step: 341350, training_loss: 6.30069e-02
I0515 17:10:51.281805 22392998065984 run_lib.py:146] step: 341400, training_loss: 8.32761e-02
I0515 17:10:51.448074 22392998065984 run_lib.py:167] step: 341400, eval_loss: 6.14711e-02
I0515 17:11:15.756965 22392998065984 run_lib.py:146] step: 341450, training_loss: 4.64040e-02
I0515 17:11:40.450924 22392998065984 run_lib.py:146] step: 341500, training_loss: 4.80476e-02
I0515 17:11:40.616905 22392998065984 run_lib.py:167] step: 341500, eval_loss: 6.07031e-02
I0515 17:12:05.165441 22392998065984 run_lib.py:146] step: 341550, training_loss: 6.22981e-02
I0515 17:12:29.423154 22392998065984 run_lib.py:146] step: 341600, training_loss: 9.84567e-02
I0515 17:12:29.601279 22392998065984 run_lib.py:167] step: 341600, eval_loss: 7.54213e-02
I0515 17:12:54.245064 22392998065984 run_lib.py:146] step: 341650, training_loss: 5.10143e-02
I0515 17:13:18.543322 22392998065984 run_lib.py:146] step: 341700, training_loss: 4.79335e-02
I0515 17:13:18.703532 22392998065984 run_lib.py:167] step: 341700, eval_loss: 6.36504e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:13:43.476570 22392998065984 run_lib.py:146] step: 341750, training_loss: 5.18458e-02
I0515 17:14:08.207575 22392998065984 run_lib.py:146] step: 341800, training_loss: 5.24484e-02
I0515 17:14:08.374664 22392998065984 run_lib.py:167] step: 341800, eval_loss: 6.98934e-02
I0515 17:14:32.691498 22392998065984 run_lib.py:146] step: 341850, training_loss: 6.80416e-02
I0515 17:14:57.357738 22392998065984 run_lib.py:146] step: 341900, training_loss: 4.80337e-02
I0515 17:14:57.517467 22392998065984 run_lib.py:167] step: 341900, eval_loss: 5.05874e-02
I0515 17:15:22.156794 22392998065984 run_lib.py:146] step: 341950, training_loss: 5.52152e-02
I0515 17:15:46.385762 22392998065984 run_lib.py:146] step: 342000, training_loss: 5.51920e-02
I0515 17:15:46.547673 22392998065984 run_lib.py:167] step: 342000, eval_loss: 6.93613e-02
I0515 17:16:11.107935 22392998065984 run_lib.py:146] step: 342050, training_loss: 5.96207e-02
I0515 17:16:35.726860 22392998065984 run_lib.py:146] step: 342100, training_loss: 5.82073e-02
I0515 17:16:35.886604 22392998065984 run_lib.py:167] step: 342100, eval_loss: 5.66669e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:17:00.360821 22392998065984 run_lib.py:146] step: 342150, training_loss: 6.12328e-02
I0515 17:17:24.975983 22392998065984 run_lib.py:146] step: 342200, training_loss: 5.98494e-02
I0515 17:17:25.158056 22392998065984 run_lib.py:167] step: 342200, eval_loss: 5.51230e-02
I0515 17:17:49.893448 22392998065984 run_lib.py:146] step: 342250, training_loss: 6.59977e-02
I0515 17:18:14.171051 22392998065984 run_lib.py:146] step: 342300, training_loss: 5.51255e-02
I0515 17:18:14.353873 22392998065984 run_lib.py:167] step: 342300, eval_loss: 5.89879e-02
I0515 17:18:38.958116 22392998065984 run_lib.py:146] step: 342350, training_loss: 6.30609e-02
I0515 17:19:03.190892 22392998065984 run_lib.py:146] step: 342400, training_loss: 6.41535e-02
I0515 17:19:03.367768 22392998065984 run_lib.py:167] step: 342400, eval_loss: 6.74077e-02
I0515 17:19:28.177622 22392998065984 run_lib.py:146] step: 342450, training_loss: 4.92648e-02
I0515 17:19:52.728291 22392998065984 run_lib.py:146] step: 342500, training_loss: 5.10288e-02
I0515 17:19:52.899126 22392998065984 run_lib.py:167] step: 342500, eval_loss: 4.47320e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:20:17.343058 22392998065984 run_lib.py:146] step: 342550, training_loss: 5.44658e-02
I0515 17:20:42.052796 22392998065984 run_lib.py:146] step: 342600, training_loss: 4.99362e-02
I0515 17:20:42.218344 22392998065984 run_lib.py:167] step: 342600, eval_loss: 6.23634e-02
I0515 17:21:06.548722 22392998065984 run_lib.py:146] step: 342650, training_loss: 5.07088e-02
I0515 17:21:31.161786 22392998065984 run_lib.py:146] step: 342700, training_loss: 4.35595e-02
I0515 17:21:31.323061 22392998065984 run_lib.py:167] step: 342700, eval_loss: 6.20212e-02
I0515 17:21:55.906311 22392998065984 run_lib.py:146] step: 342750, training_loss: 7.22515e-02
I0515 17:22:20.209348 22392998065984 run_lib.py:146] step: 342800, training_loss: 5.40022e-02
I0515 17:22:20.375034 22392998065984 run_lib.py:167] step: 342800, eval_loss: 6.59811e-02
I0515 17:22:45.104979 22392998065984 run_lib.py:146] step: 342850, training_loss: 6.65939e-02
I0515 17:23:09.738595 22392998065984 run_lib.py:146] step: 342900, training_loss: 6.47716e-02
I0515 17:23:09.907042 22392998065984 run_lib.py:167] step: 342900, eval_loss: 5.36811e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:23:34.361884 22392998065984 run_lib.py:146] step: 342950, training_loss: 6.14937e-02
I0515 17:23:59.033882 22392998065984 run_lib.py:146] step: 343000, training_loss: 5.77310e-02
I0515 17:23:59.196789 22392998065984 run_lib.py:167] step: 343000, eval_loss: 5.75337e-02
I0515 17:24:23.919883 22392998065984 run_lib.py:146] step: 343050, training_loss: 4.64398e-02
I0515 17:24:48.290925 22392998065984 run_lib.py:146] step: 343100, training_loss: 7.70904e-02
I0515 17:24:48.450973 22392998065984 run_lib.py:167] step: 343100, eval_loss: 4.70448e-02
I0515 17:25:13.115719 22392998065984 run_lib.py:146] step: 343150, training_loss: 5.21725e-02
I0515 17:25:37.398889 22392998065984 run_lib.py:146] step: 343200, training_loss: 5.21483e-02
I0515 17:25:37.571851 22392998065984 run_lib.py:167] step: 343200, eval_loss: 5.84901e-02
I0515 17:26:02.135245 22392998065984 run_lib.py:146] step: 343250, training_loss: 6.10472e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:26:26.889711 22392998065984 run_lib.py:146] step: 343300, training_loss: 6.27029e-02
I0515 17:26:27.061915 22392998065984 run_lib.py:167] step: 343300, eval_loss: 7.28965e-02
I0515 17:26:51.391899 22392998065984 run_lib.py:146] step: 343350, training_loss: 4.73643e-02
I0515 17:27:16.064896 22392998065984 run_lib.py:146] step: 343400, training_loss: 6.23675e-02
I0515 17:27:16.225123 22392998065984 run_lib.py:167] step: 343400, eval_loss: 5.82508e-02
I0515 17:27:40.515992 22392998065984 run_lib.py:146] step: 343450, training_loss: 7.40728e-02
I0515 17:28:05.110148 22392998065984 run_lib.py:146] step: 343500, training_loss: 5.76676e-02
I0515 17:28:05.288910 22392998065984 run_lib.py:167] step: 343500, eval_loss: 5.69517e-02
I0515 17:28:30.040382 22392998065984 run_lib.py:146] step: 343550, training_loss: 7.52752e-02
I0515 17:28:54.372674 22392998065984 run_lib.py:146] step: 343600, training_loss: 5.19403e-02
I0515 17:28:54.546359 22392998065984 run_lib.py:167] step: 343600, eval_loss: 7.32226e-02
I0515 17:29:19.146413 22392998065984 run_lib.py:146] step: 343650, training_loss: 7.21494e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:29:44.076159 22392998065984 run_lib.py:146] step: 343700, training_loss: 5.26769e-02
I0515 17:29:44.239520 22392998065984 run_lib.py:167] step: 343700, eval_loss: 6.69007e-02
I0515 17:30:08.625597 22392998065984 run_lib.py:146] step: 343750, training_loss: 4.55474e-02
I0515 17:30:33.332335 22392998065984 run_lib.py:146] step: 343800, training_loss: 4.76039e-02
I0515 17:30:33.491799 22392998065984 run_lib.py:167] step: 343800, eval_loss: 5.78635e-02
I0515 17:30:58.188693 22392998065984 run_lib.py:146] step: 343850, training_loss: 5.46226e-02
I0515 17:31:22.506270 22392998065984 run_lib.py:146] step: 343900, training_loss: 5.23699e-02
I0515 17:31:22.674608 22392998065984 run_lib.py:167] step: 343900, eval_loss: 5.59612e-02
I0515 17:31:47.255486 22392998065984 run_lib.py:146] step: 343950, training_loss: 5.21838e-02
I0515 17:32:11.522656 22392998065984 run_lib.py:146] step: 344000, training_loss: 5.72630e-02
I0515 17:32:11.703753 22392998065984 run_lib.py:167] step: 344000, eval_loss: 7.71064e-02
I0515 17:32:36.390409 22392998065984 run_lib.py:146] step: 344050, training_loss: 6.14576e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:33:01.219938 22392998065984 run_lib.py:146] step: 344100, training_loss: 5.60006e-02
I0515 17:33:01.391455 22392998065984 run_lib.py:167] step: 344100, eval_loss: 5.95008e-02
I0515 17:33:25.641146 22392998065984 run_lib.py:146] step: 344150, training_loss: 7.44576e-02
I0515 17:33:50.264447 22392998065984 run_lib.py:146] step: 344200, training_loss: 5.38585e-02
I0515 17:33:50.431156 22392998065984 run_lib.py:167] step: 344200, eval_loss: 5.15423e-02
I0515 17:34:14.775745 22392998065984 run_lib.py:146] step: 344250, training_loss: 7.14619e-02
I0515 17:34:39.355761 22392998065984 run_lib.py:146] step: 344300, training_loss: 5.72494e-02
I0515 17:34:39.524938 22392998065984 run_lib.py:167] step: 344300, eval_loss: 6.73400e-02
I0515 17:35:04.053845 22392998065984 run_lib.py:146] step: 344350, training_loss: 5.22310e-02
I0515 17:35:28.312852 22392998065984 run_lib.py:146] step: 344400, training_loss: 4.43672e-02
I0515 17:35:28.483175 22392998065984 run_lib.py:167] step: 344400, eval_loss: 4.92381e-02
I0515 17:35:53.010694 22392998065984 run_lib.py:146] step: 344450, training_loss: 6.70211e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:36:17.859195 22392998065984 run_lib.py:146] step: 344500, training_loss: 3.42375e-02
I0515 17:36:18.031832 22392998065984 run_lib.py:167] step: 344500, eval_loss: 5.67327e-02
I0515 17:36:42.240917 22392998065984 run_lib.py:146] step: 344550, training_loss: 5.79396e-02
I0515 17:37:06.710134 22392998065984 run_lib.py:146] step: 344600, training_loss: 5.22691e-02
I0515 17:37:06.871196 22392998065984 run_lib.py:167] step: 344600, eval_loss: 7.70549e-02
I0515 17:37:31.498894 22392998065984 run_lib.py:146] step: 344650, training_loss: 5.22311e-02
I0515 17:37:55.773904 22392998065984 run_lib.py:146] step: 344700, training_loss: 6.39030e-02
I0515 17:37:55.933323 22392998065984 run_lib.py:167] step: 344700, eval_loss: 6.46447e-02
I0515 17:38:20.525002 22392998065984 run_lib.py:146] step: 344750, training_loss: 5.73527e-02
I0515 17:38:44.805995 22392998065984 run_lib.py:146] step: 344800, training_loss: 3.74683e-02
I0515 17:38:44.967175 22392998065984 run_lib.py:167] step: 344800, eval_loss: 5.13222e-02
I0515 17:39:09.598623 22392998065984 run_lib.py:146] step: 344850, training_loss: 4.07886e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:39:34.461757 22392998065984 run_lib.py:146] step: 344900, training_loss: 6.16531e-02
I0515 17:39:34.624163 22392998065984 run_lib.py:167] step: 344900, eval_loss: 8.13058e-02
I0515 17:39:58.860286 22392998065984 run_lib.py:146] step: 344950, training_loss: 6.55277e-02
I0515 17:40:23.370572 22392998065984 run_lib.py:146] step: 345000, training_loss: 4.74122e-02
I0515 17:40:23.540946 22392998065984 run_lib.py:167] step: 345000, eval_loss: 7.17755e-02
I0515 17:40:47.879497 22392998065984 run_lib.py:146] step: 345050, training_loss: 6.46944e-02
I0515 17:41:12.782156 22392998065984 run_lib.py:146] step: 345100, training_loss: 6.98847e-02
I0515 17:41:12.954799 22392998065984 run_lib.py:167] step: 345100, eval_loss: 6.02432e-02
I0515 17:41:37.535690 22392998065984 run_lib.py:146] step: 345150, training_loss: 4.77048e-02
I0515 17:42:01.812965 22392998065984 run_lib.py:146] step: 345200, training_loss: 5.12112e-02
I0515 17:42:01.977852 22392998065984 run_lib.py:167] step: 345200, eval_loss: 7.79274e-02
I0515 17:42:26.630424 22392998065984 run_lib.py:146] step: 345250, training_loss: 4.41496e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:42:51.540313 22392998065984 run_lib.py:146] step: 345300, training_loss: 5.42273e-02
I0515 17:42:51.705409 22392998065984 run_lib.py:167] step: 345300, eval_loss: 6.85105e-02
I0515 17:43:15.945909 22392998065984 run_lib.py:146] step: 345350, training_loss: 5.85351e-02
I0515 17:43:40.610664 22392998065984 run_lib.py:146] step: 345400, training_loss: 6.22440e-02
I0515 17:43:40.770721 22392998065984 run_lib.py:167] step: 345400, eval_loss: 7.02538e-02
I0515 17:44:05.440334 22392998065984 run_lib.py:146] step: 345450, training_loss: 5.58149e-02
I0515 17:44:29.710261 22392998065984 run_lib.py:146] step: 345500, training_loss: 6.05808e-02
I0515 17:44:29.870344 22392998065984 run_lib.py:167] step: 345500, eval_loss: 6.69165e-02
I0515 17:44:54.533651 22392998065984 run_lib.py:146] step: 345550, training_loss: 4.81690e-02
I0515 17:45:19.283972 22392998065984 run_lib.py:146] step: 345600, training_loss: 6.01416e-02
I0515 17:45:19.461764 22392998065984 run_lib.py:167] step: 345600, eval_loss: 6.57822e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:45:43.922640 22392998065984 run_lib.py:146] step: 345650, training_loss: 5.94248e-02
I0515 17:46:08.678891 22392998065984 run_lib.py:146] step: 345700, training_loss: 4.52658e-02
I0515 17:46:08.841119 22392998065984 run_lib.py:167] step: 345700, eval_loss: 5.69370e-02
I0515 17:46:33.224641 22392998065984 run_lib.py:146] step: 345750, training_loss: 6.20601e-02
I0515 17:46:57.948231 22392998065984 run_lib.py:146] step: 345800, training_loss: 5.44850e-02
I0515 17:46:58.131263 22392998065984 run_lib.py:167] step: 345800, eval_loss: 5.33071e-02
I0515 17:47:22.404257 22392998065984 run_lib.py:146] step: 345850, training_loss: 4.94483e-02
I0515 17:47:46.995691 22392998065984 run_lib.py:146] step: 345900, training_loss: 4.95869e-02
I0515 17:47:47.164598 22392998065984 run_lib.py:167] step: 345900, eval_loss: 8.12093e-02
I0515 17:48:11.783338 22392998065984 run_lib.py:146] step: 345950, training_loss: 8.57043e-02
I0515 17:48:36.042898 22392998065984 run_lib.py:146] step: 346000, training_loss: 5.23581e-02
I0515 17:48:36.224191 22392998065984 run_lib.py:167] step: 346000, eval_loss: 1.07093e-01
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:49:00.972061 22392998065984 run_lib.py:146] step: 346050, training_loss: 5.02234e-02
I0515 17:49:25.782784 22392998065984 run_lib.py:146] step: 346100, training_loss: 7.30702e-02
I0515 17:49:25.949835 22392998065984 run_lib.py:167] step: 346100, eval_loss: 5.00432e-02
I0515 17:49:50.272299 22392998065984 run_lib.py:146] step: 346150, training_loss: 5.52688e-02
I0515 17:50:14.941422 22392998065984 run_lib.py:146] step: 346200, training_loss: 6.07860e-02
I0515 17:50:15.106886 22392998065984 run_lib.py:167] step: 346200, eval_loss: 6.14978e-02
I0515 17:50:39.744216 22392998065984 run_lib.py:146] step: 346250, training_loss: 5.13230e-02
I0515 17:51:03.926359 22392998065984 run_lib.py:146] step: 346300, training_loss: 5.50290e-02
I0515 17:51:04.093309 22392998065984 run_lib.py:167] step: 346300, eval_loss: 6.78867e-02
I0515 17:51:28.667248 22392998065984 run_lib.py:146] step: 346350, training_loss: 4.94349e-02
I0515 17:51:53.295773 22392998065984 run_lib.py:146] step: 346400, training_loss: 5.28102e-02
I0515 17:51:53.455116 22392998065984 run_lib.py:167] step: 346400, eval_loss: 6.86369e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:52:17.938141 22392998065984 run_lib.py:146] step: 346450, training_loss: 4.82566e-02
I0515 17:52:42.532377 22392998065984 run_lib.py:146] step: 346500, training_loss: 5.18928e-02
I0515 17:52:42.694313 22392998065984 run_lib.py:167] step: 346500, eval_loss: 6.97995e-02
I0515 17:53:07.059391 22392998065984 run_lib.py:146] step: 346550, training_loss: 6.18901e-02
I0515 17:53:31.833239 22392998065984 run_lib.py:146] step: 346600, training_loss: 6.24429e-02
I0515 17:53:32.003049 22392998065984 run_lib.py:167] step: 346600, eval_loss: 6.08687e-02
I0515 17:53:56.640854 22392998065984 run_lib.py:146] step: 346650, training_loss: 5.75175e-02
I0515 17:54:20.883786 22392998065984 run_lib.py:146] step: 346700, training_loss: 5.65833e-02
I0515 17:54:21.043950 22392998065984 run_lib.py:167] step: 346700, eval_loss: 5.29469e-02
I0515 17:54:45.656017 22392998065984 run_lib.py:146] step: 346750, training_loss: 3.87278e-02
I0515 17:55:09.948619 22392998065984 run_lib.py:146] step: 346800, training_loss: 6.39409e-02
I0515 17:55:10.119225 22392998065984 run_lib.py:167] step: 346800, eval_loss: 6.05392e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:55:34.948070 22392998065984 run_lib.py:146] step: 346850, training_loss: 4.89961e-02
I0515 17:55:59.489266 22392998065984 run_lib.py:146] step: 346900, training_loss: 5.49714e-02
I0515 17:55:59.652563 22392998065984 run_lib.py:167] step: 346900, eval_loss: 4.47830e-02
I0515 17:56:23.825460 22392998065984 run_lib.py:146] step: 346950, training_loss: 5.39048e-02
I0515 17:56:48.534185 22392998065984 run_lib.py:146] step: 347000, training_loss: 5.07824e-02
I0515 17:56:48.695508 22392998065984 run_lib.py:167] step: 347000, eval_loss: 6.30797e-02
I0515 17:57:13.317506 22392998065984 run_lib.py:146] step: 347050, training_loss: 3.75406e-02
I0515 17:57:37.572024 22392998065984 run_lib.py:146] step: 347100, training_loss: 5.80749e-02
I0515 17:57:37.735107 22392998065984 run_lib.py:167] step: 347100, eval_loss: 6.94507e-02
I0515 17:58:02.355017 22392998065984 run_lib.py:146] step: 347150, training_loss: 5.21393e-02
I0515 17:58:26.948539 22392998065984 run_lib.py:146] step: 347200, training_loss: 6.22680e-02
I0515 17:58:27.109256 22392998065984 run_lib.py:167] step: 347200, eval_loss: 4.86646e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 17:58:51.594966 22392998065984 run_lib.py:146] step: 347250, training_loss: 7.42510e-02
I0515 17:59:16.384184 22392998065984 run_lib.py:146] step: 347300, training_loss: 4.26869e-02
I0515 17:59:16.557947 22392998065984 run_lib.py:167] step: 347300, eval_loss: 9.67643e-02
I0515 17:59:40.913029 22392998065984 run_lib.py:146] step: 347350, training_loss: 6.88999e-02
I0515 18:00:05.575156 22392998065984 run_lib.py:146] step: 347400, training_loss: 4.96588e-02
I0515 18:00:05.735852 22392998065984 run_lib.py:167] step: 347400, eval_loss: 6.64611e-02
I0515 18:00:30.332304 22392998065984 run_lib.py:146] step: 347450, training_loss: 6.54780e-02
I0515 18:00:54.605481 22392998065984 run_lib.py:146] step: 347500, training_loss: 5.14737e-02
I0515 18:00:54.691152 22392998065984 run_lib.py:167] step: 347500, eval_loss: 7.83777e-02
I0515 18:01:19.340317 22392998065984 run_lib.py:146] step: 347550, training_loss: 5.51902e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:01:43.782395 22392998065984 run_lib.py:146] step: 347600, training_loss: 6.11417e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:01:44.226172 22392998065984 run_lib.py:167] step: 347600, eval_loss: 7.11203e-02
I0515 18:02:08.975193 22392998065984 run_lib.py:146] step: 347650, training_loss: 6.64011e-02
I0515 18:02:33.819792 22392998065984 run_lib.py:146] step: 347700, training_loss: 5.99858e-02
I0515 18:02:33.982753 22392998065984 run_lib.py:167] step: 347700, eval_loss: 5.84966e-02
I0515 18:02:58.374385 22392998065984 run_lib.py:146] step: 347750, training_loss: 5.81557e-02
I0515 18:03:23.024824 22392998065984 run_lib.py:146] step: 347800, training_loss: 6.37928e-02
I0515 18:03:23.187188 22392998065984 run_lib.py:167] step: 347800, eval_loss: 6.68992e-02
I0515 18:03:47.898165 22392998065984 run_lib.py:146] step: 347850, training_loss: 6.47104e-02
I0515 18:04:12.229462 22392998065984 run_lib.py:146] step: 347900, training_loss: 5.77903e-02
I0515 18:04:12.389774 22392998065984 run_lib.py:167] step: 347900, eval_loss: 5.84030e-02
I0515 18:04:37.010232 22392998065984 run_lib.py:146] step: 347950, training_loss: 5.23020e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:05:01.883926 22392998065984 run_lib.py:146] step: 348000, training_loss: 4.74260e-02
I0515 18:05:02.052552 22392998065984 run_lib.py:167] step: 348000, eval_loss: 6.32815e-02
I0515 18:05:26.409835 22392998065984 run_lib.py:146] step: 348050, training_loss: 5.90573e-02
I0515 18:05:51.116275 22392998065984 run_lib.py:146] step: 348100, training_loss: 3.99808e-02
I0515 18:05:51.281844 22392998065984 run_lib.py:167] step: 348100, eval_loss: 6.70263e-02
I0515 18:06:15.503987 22392998065984 run_lib.py:146] step: 348150, training_loss: 6.60440e-02
I0515 18:06:40.171546 22392998065984 run_lib.py:146] step: 348200, training_loss: 4.92871e-02
I0515 18:06:40.340486 22392998065984 run_lib.py:167] step: 348200, eval_loss: 7.40944e-02
I0515 18:07:04.983931 22392998065984 run_lib.py:146] step: 348250, training_loss: 6.84906e-02
I0515 18:07:29.225794 22392998065984 run_lib.py:146] step: 348300, training_loss: 6.29452e-02
I0515 18:07:29.399397 22392998065984 run_lib.py:167] step: 348300, eval_loss: 5.66635e-02
I0515 18:07:54.004212 22392998065984 run_lib.py:146] step: 348350, training_loss: 5.77964e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:08:18.538564 22392998065984 run_lib.py:146] step: 348400, training_loss: 5.58582e-02
I0515 18:08:18.707229 22392998065984 run_lib.py:167] step: 348400, eval_loss: 6.62126e-02
I0515 18:08:43.381526 22392998065984 run_lib.py:146] step: 348450, training_loss: 4.21992e-02
I0515 18:09:07.980679 22392998065984 run_lib.py:146] step: 348500, training_loss: 5.88180e-02
I0515 18:09:08.158833 22392998065984 run_lib.py:167] step: 348500, eval_loss: 6.55484e-02
I0515 18:09:32.476119 22392998065984 run_lib.py:146] step: 348550, training_loss: 5.56698e-02
I0515 18:09:57.077066 22392998065984 run_lib.py:146] step: 348600, training_loss: 6.03679e-02
I0515 18:09:57.237197 22392998065984 run_lib.py:167] step: 348600, eval_loss: 5.36379e-02
I0515 18:10:21.891992 22392998065984 run_lib.py:146] step: 348650, training_loss: 5.09838e-02
I0515 18:10:46.147024 22392998065984 run_lib.py:146] step: 348700, training_loss: 5.49982e-02
I0515 18:10:46.324041 22392998065984 run_lib.py:167] step: 348700, eval_loss: 6.57564e-02
I0515 18:11:10.887586 22392998065984 run_lib.py:146] step: 348750, training_loss: 8.89863e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:11:35.676474 22392998065984 run_lib.py:146] step: 348800, training_loss: 4.06844e-02
I0515 18:11:35.838138 22392998065984 run_lib.py:167] step: 348800, eval_loss: 6.29930e-02
I0515 18:12:00.174930 22392998065984 run_lib.py:146] step: 348850, training_loss: 4.90845e-02
I0515 18:12:24.796907 22392998065984 run_lib.py:146] step: 348900, training_loss: 6.06796e-02
I0515 18:12:24.961256 22392998065984 run_lib.py:167] step: 348900, eval_loss: 6.93404e-02
I0515 18:12:49.286949 22392998065984 run_lib.py:146] step: 348950, training_loss: 4.80375e-02
I0515 18:13:13.824872 22392998065984 run_lib.py:146] step: 349000, training_loss: 7.79475e-02
I0515 18:13:13.985174 22392998065984 run_lib.py:167] step: 349000, eval_loss: 6.03445e-02
I0515 18:13:38.767970 22392998065984 run_lib.py:146] step: 349050, training_loss: 4.35390e-02
I0515 18:14:02.930779 22392998065984 run_lib.py:146] step: 349100, training_loss: 7.06963e-02
I0515 18:14:03.095979 22392998065984 run_lib.py:167] step: 349100, eval_loss: 6.53542e-02
I0515 18:14:27.617266 22392998065984 run_lib.py:146] step: 349150, training_loss: 6.53742e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:14:52.059971 22392998065984 run_lib.py:146] step: 349200, training_loss: 6.97123e-02
I0515 18:14:52.222171 22392998065984 run_lib.py:167] step: 349200, eval_loss: 7.27242e-02
I0515 18:15:16.908583 22392998065984 run_lib.py:146] step: 349250, training_loss: 6.45526e-02
I0515 18:15:41.660753 22392998065984 run_lib.py:146] step: 349300, training_loss: 4.92674e-02
I0515 18:15:41.831497 22392998065984 run_lib.py:167] step: 349300, eval_loss: 6.24886e-02
I0515 18:16:06.091736 22392998065984 run_lib.py:146] step: 349350, training_loss: 3.92830e-02
I0515 18:16:30.627403 22392998065984 run_lib.py:146] step: 349400, training_loss: 5.65085e-02
I0515 18:16:30.787553 22392998065984 run_lib.py:167] step: 349400, eval_loss: 5.86691e-02
I0515 18:16:55.345021 22392998065984 run_lib.py:146] step: 349450, training_loss: 6.40523e-02
I0515 18:17:19.575028 22392998065984 run_lib.py:146] step: 349500, training_loss: 4.92262e-02
I0515 18:17:19.736335 22392998065984 run_lib.py:167] step: 349500, eval_loss: 5.38097e-02
I0515 18:17:44.377056 22392998065984 run_lib.py:146] step: 349550, training_loss: 6.34495e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:18:09.309031 22392998065984 run_lib.py:146] step: 349600, training_loss: 6.55327e-02
I0515 18:18:09.472293 22392998065984 run_lib.py:167] step: 349600, eval_loss: 5.89472e-02
I0515 18:18:33.816719 22392998065984 run_lib.py:146] step: 349650, training_loss: 5.82722e-02
I0515 18:18:58.501965 22392998065984 run_lib.py:146] step: 349700, training_loss: 5.15399e-02
I0515 18:18:58.661645 22392998065984 run_lib.py:167] step: 349700, eval_loss: 6.66496e-02
I0515 18:19:23.340581 22392998065984 run_lib.py:146] step: 349750, training_loss: 5.10776e-02
I0515 18:19:47.685258 22392998065984 run_lib.py:146] step: 349800, training_loss: 4.73765e-02
I0515 18:19:47.846296 22392998065984 run_lib.py:167] step: 349800, eval_loss: 6.61222e-02
I0515 18:20:12.418167 22392998065984 run_lib.py:146] step: 349850, training_loss: 4.13413e-02
I0515 18:20:36.717114 22392998065984 run_lib.py:146] step: 349900, training_loss: 6.49831e-02
I0515 18:20:36.879008 22392998065984 run_lib.py:167] step: 349900, eval_loss: 5.63356e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:21:01.770977 22392998065984 run_lib.py:146] step: 349950, training_loss: 5.45922e-02
I0515 18:21:26.217093 22392998065984 run_lib.py:146] step: 350000, training_loss: 6.70370e-02
I0515 18:21:28.495759 22392998065984 run_lib.py:167] step: 350000, eval_loss: 6.84248e-02
I0515 18:21:54.496348 22392998065984 run_lib.py:146] step: 350050, training_loss: 5.87792e-02
I0515 18:22:19.098257 22392998065984 run_lib.py:146] step: 350100, training_loss: 6.74427e-02
I0515 18:22:19.268128 22392998065984 run_lib.py:167] step: 350100, eval_loss: 5.78714e-02
I0515 18:22:43.830744 22392998065984 run_lib.py:146] step: 350150, training_loss: 5.50088e-02
I0515 18:23:08.153459 22392998065984 run_lib.py:146] step: 350200, training_loss: 4.25000e-02
I0515 18:23:08.315620 22392998065984 run_lib.py:167] step: 350200, eval_loss: 5.85298e-02
I0515 18:23:33.034774 22392998065984 run_lib.py:146] step: 350250, training_loss: 7.33200e-02
I0515 18:23:57.596738 22392998065984 run_lib.py:146] step: 350300, training_loss: 6.48305e-02
I0515 18:23:57.767211 22392998065984 run_lib.py:167] step: 350300, eval_loss: 6.25255e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:24:22.309077 22392998065984 run_lib.py:146] step: 350350, training_loss: 5.61748e-02
I0515 18:24:47.424153 22392998065984 run_lib.py:146] step: 350400, training_loss: 4.81181e-02
I0515 18:24:47.584721 22392998065984 run_lib.py:167] step: 350400, eval_loss: 5.15735e-02
I0515 18:25:12.298475 22392998065984 run_lib.py:146] step: 350450, training_loss: 5.18447e-02
I0515 18:25:36.641111 22392998065984 run_lib.py:146] step: 350500, training_loss: 4.63326e-02
I0515 18:25:36.800840 22392998065984 run_lib.py:167] step: 350500, eval_loss: 6.07195e-02
I0515 18:26:01.444218 22392998065984 run_lib.py:146] step: 350550, training_loss: 5.72637e-02
I0515 18:26:25.717660 22392998065984 run_lib.py:146] step: 350600, training_loss: 4.77696e-02
I0515 18:26:25.897229 22392998065984 run_lib.py:167] step: 350600, eval_loss: 5.97343e-02
I0515 18:26:50.477893 22392998065984 run_lib.py:146] step: 350650, training_loss: 7.23958e-02
I0515 18:27:14.795665 22392998065984 run_lib.py:146] step: 350700, training_loss: 4.83985e-02
I0515 18:27:14.957206 22392998065984 run_lib.py:167] step: 350700, eval_loss: 7.78452e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:27:39.870416 22392998065984 run_lib.py:146] step: 350750, training_loss: 4.69638e-02
I0515 18:28:04.543463 22392998065984 run_lib.py:146] step: 350800, training_loss: 6.62119e-02
I0515 18:28:04.713005 22392998065984 run_lib.py:167] step: 350800, eval_loss: 7.03831e-02
I0515 18:28:29.159489 22392998065984 run_lib.py:146] step: 350850, training_loss: 7.49268e-02
I0515 18:28:53.834259 22392998065984 run_lib.py:146] step: 350900, training_loss: 4.88823e-02
I0515 18:28:54.004079 22392998065984 run_lib.py:167] step: 350900, eval_loss: 6.10571e-02
I0515 18:29:18.657259 22392998065984 run_lib.py:146] step: 350950, training_loss: 5.03947e-02
I0515 18:29:42.963702 22392998065984 run_lib.py:146] step: 351000, training_loss: 5.18588e-02
I0515 18:29:43.123781 22392998065984 run_lib.py:167] step: 351000, eval_loss: 5.77403e-02
I0515 18:30:07.730199 22392998065984 run_lib.py:146] step: 351050, training_loss: 6.62284e-02
I0515 18:30:32.324698 22392998065984 run_lib.py:146] step: 351100, training_loss: 7.60575e-02
I0515 18:30:32.493805 22392998065984 run_lib.py:167] step: 351100, eval_loss: 6.83808e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:30:56.870387 22392998065984 run_lib.py:146] step: 351150, training_loss: 7.38871e-02
I0515 18:31:21.431008 22392998065984 run_lib.py:146] step: 351200, training_loss: 4.79577e-02
I0515 18:31:21.593927 22392998065984 run_lib.py:167] step: 351200, eval_loss: 6.64938e-02
I0515 18:31:46.318033 22392998065984 run_lib.py:146] step: 351250, training_loss: 4.94986e-02
I0515 18:32:10.734938 22392998065984 run_lib.py:146] step: 351300, training_loss: 6.60031e-02
I0515 18:32:10.897546 22392998065984 run_lib.py:167] step: 351300, eval_loss: 5.58028e-02
I0515 18:32:35.639512 22392998065984 run_lib.py:146] step: 351350, training_loss: 6.88863e-02
I0515 18:33:00.234835 22392998065984 run_lib.py:146] step: 351400, training_loss: 6.64092e-02
I0515 18:33:00.396018 22392998065984 run_lib.py:167] step: 351400, eval_loss: 6.70017e-02
I0515 18:33:24.668006 22392998065984 run_lib.py:146] step: 351450, training_loss: 5.41870e-02
I0515 18:33:48.992388 22392998065984 run_lib.py:146] step: 351500, training_loss: 5.61593e-02
I0515 18:33:49.153120 22392998065984 run_lib.py:167] step: 351500, eval_loss: 4.82260e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:34:14.033712 22392998065984 run_lib.py:146] step: 351550, training_loss: 4.36128e-02
I0515 18:34:38.658807 22392998065984 run_lib.py:146] step: 351600, training_loss: 5.82791e-02
I0515 18:34:38.824929 22392998065984 run_lib.py:167] step: 351600, eval_loss: 7.10892e-02
I0515 18:35:03.208975 22392998065984 run_lib.py:146] step: 351650, training_loss: 5.74899e-02
I0515 18:35:27.896025 22392998065984 run_lib.py:146] step: 351700, training_loss: 5.72229e-02
I0515 18:35:28.056208 22392998065984 run_lib.py:167] step: 351700, eval_loss: 5.16294e-02
I0515 18:35:52.661859 22392998065984 run_lib.py:146] step: 351750, training_loss: 5.96980e-02
I0515 18:36:16.995424 22392998065984 run_lib.py:146] step: 351800, training_loss: 3.70311e-02
I0515 18:36:17.170783 22392998065984 run_lib.py:167] step: 351800, eval_loss: 7.20766e-02
I0515 18:36:41.791571 22392998065984 run_lib.py:146] step: 351850, training_loss: 5.93947e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:37:06.576950 22392998065984 run_lib.py:146] step: 351900, training_loss: 5.31734e-02
I0515 18:37:06.745926 22392998065984 run_lib.py:167] step: 351900, eval_loss: 5.57656e-02
I0515 18:37:31.114685 22392998065984 run_lib.py:146] step: 351950, training_loss: 5.83962e-02
I0515 18:37:55.857715 22392998065984 run_lib.py:146] step: 352000, training_loss: 5.63048e-02
I0515 18:37:56.025106 22392998065984 run_lib.py:167] step: 352000, eval_loss: 5.59875e-02
I0515 18:38:20.757827 22392998065984 run_lib.py:146] step: 352050, training_loss: 7.19699e-02
I0515 18:38:45.108816 22392998065984 run_lib.py:146] step: 352100, training_loss: 5.56347e-02
I0515 18:38:45.268856 22392998065984 run_lib.py:167] step: 352100, eval_loss: 5.82394e-02
I0515 18:39:09.918546 22392998065984 run_lib.py:146] step: 352150, training_loss: 6.92245e-02
I0515 18:39:34.192190 22392998065984 run_lib.py:146] step: 352200, training_loss: 6.08493e-02
I0515 18:39:34.363177 22392998065984 run_lib.py:167] step: 352200, eval_loss: 5.77641e-02
I0515 18:39:58.951689 22392998065984 run_lib.py:146] step: 352250, training_loss: 6.12817e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:40:23.344356 22392998065984 run_lib.py:146] step: 352300, training_loss: 5.89532e-02
I0515 18:40:23.508435 22392998065984 run_lib.py:167] step: 352300, eval_loss: 6.08616e-02
I0515 18:40:48.346217 22392998065984 run_lib.py:146] step: 352350, training_loss: 6.80574e-02
I0515 18:41:13.077727 22392998065984 run_lib.py:146] step: 352400, training_loss: 5.53756e-02
I0515 18:41:13.251362 22392998065984 run_lib.py:167] step: 352400, eval_loss: 5.91787e-02
I0515 18:41:37.581228 22392998065984 run_lib.py:146] step: 352450, training_loss: 5.61077e-02
I0515 18:42:02.172390 22392998065984 run_lib.py:146] step: 352500, training_loss: 5.81538e-02
I0515 18:42:02.340814 22392998065984 run_lib.py:167] step: 352500, eval_loss: 6.54155e-02
I0515 18:42:26.920021 22392998065984 run_lib.py:146] step: 352550, training_loss: 5.59935e-02
I0515 18:42:51.285922 22392998065984 run_lib.py:146] step: 352600, training_loss: 5.23982e-02
I0515 18:42:51.467156 22392998065984 run_lib.py:167] step: 352600, eval_loss: 5.80575e-02
I0515 18:43:16.000773 22392998065984 run_lib.py:146] step: 352650, training_loss: 5.32123e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:43:40.775991 22392998065984 run_lib.py:146] step: 352700, training_loss: 5.66156e-02
I0515 18:43:40.939188 22392998065984 run_lib.py:167] step: 352700, eval_loss: 5.83492e-02
I0515 18:44:05.299790 22392998065984 run_lib.py:146] step: 352750, training_loss: 5.42740e-02
I0515 18:44:30.011781 22392998065984 run_lib.py:146] step: 352800, training_loss: 5.33069e-02
I0515 18:44:30.182168 22392998065984 run_lib.py:167] step: 352800, eval_loss: 5.34244e-02
I0515 18:44:54.783903 22392998065984 run_lib.py:146] step: 352850, training_loss: 4.81670e-02
I0515 18:45:19.057432 22392998065984 run_lib.py:146] step: 352900, training_loss: 7.63254e-02
I0515 18:45:19.218708 22392998065984 run_lib.py:167] step: 352900, eval_loss: 6.63301e-02
I0515 18:45:43.845192 22392998065984 run_lib.py:146] step: 352950, training_loss: 5.95058e-02
I0515 18:46:08.454897 22392998065984 run_lib.py:146] step: 353000, training_loss: 5.30828e-02
I0515 18:46:08.613716 22392998065984 run_lib.py:167] step: 353000, eval_loss: 5.66906e-02
I0515 18:46:32.868510 22392998065984 run_lib.py:146] step: 353050, training_loss: 7.11034e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:46:57.712743 22392998065984 run_lib.py:146] step: 353100, training_loss: 5.15224e-02
I0515 18:46:57.879962 22392998065984 run_lib.py:167] step: 353100, eval_loss: 6.82009e-02
I0515 18:47:22.318987 22392998065984 run_lib.py:146] step: 353150, training_loss: 6.24986e-02
I0515 18:47:47.356206 22392998065984 run_lib.py:146] step: 353200, training_loss: 6.16932e-02
I0515 18:47:47.526798 22392998065984 run_lib.py:167] step: 353200, eval_loss: 5.77645e-02
I0515 18:48:11.855306 22392998065984 run_lib.py:146] step: 353250, training_loss: 5.24479e-02
I0515 18:48:36.434823 22392998065984 run_lib.py:146] step: 353300, training_loss: 5.22293e-02
I0515 18:48:36.611026 22392998065984 run_lib.py:167] step: 353300, eval_loss: 6.43390e-02
I0515 18:49:01.206053 22392998065984 run_lib.py:146] step: 353350, training_loss: 4.71773e-02
I0515 18:49:25.521342 22392998065984 run_lib.py:146] step: 353400, training_loss: 5.40031e-02
I0515 18:49:25.691024 22392998065984 run_lib.py:167] step: 353400, eval_loss: 5.75821e-02
I0515 18:49:50.288381 22392998065984 run_lib.py:146] step: 353450, training_loss: 6.33846e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:50:15.168891 22392998065984 run_lib.py:146] step: 353500, training_loss: 4.33812e-02
I0515 18:50:15.339823 22392998065984 run_lib.py:167] step: 353500, eval_loss: 6.28006e-02
I0515 18:50:39.747995 22392998065984 run_lib.py:146] step: 353550, training_loss: 6.62752e-02
I0515 18:51:04.402620 22392998065984 run_lib.py:146] step: 353600, training_loss: 6.04110e-02
I0515 18:51:04.577271 22392998065984 run_lib.py:167] step: 353600, eval_loss: 6.39463e-02
I0515 18:51:29.197038 22392998065984 run_lib.py:146] step: 353650, training_loss: 6.44228e-02
I0515 18:51:53.464395 22392998065984 run_lib.py:146] step: 353700, training_loss: 4.52386e-02
I0515 18:51:53.625981 22392998065984 run_lib.py:167] step: 353700, eval_loss: 8.00576e-02
I0515 18:52:18.237143 22392998065984 run_lib.py:146] step: 353750, training_loss: 5.89135e-02
I0515 18:52:42.784214 22392998065984 run_lib.py:146] step: 353800, training_loss: 5.55191e-02
I0515 18:52:42.944402 22392998065984 run_lib.py:167] step: 353800, eval_loss: 7.97168e-02
I0515 18:53:07.249166 22392998065984 run_lib.py:146] step: 353850, training_loss: 5.69671e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:53:32.128500 22392998065984 run_lib.py:146] step: 353900, training_loss: 5.57760e-02
I0515 18:53:32.292042 22392998065984 run_lib.py:167] step: 353900, eval_loss: 7.34712e-02
I0515 18:53:56.579678 22392998065984 run_lib.py:146] step: 353950, training_loss: 6.41680e-02
I0515 18:54:21.271994 22392998065984 run_lib.py:146] step: 354000, training_loss: 6.10454e-02
I0515 18:54:21.455029 22392998065984 run_lib.py:167] step: 354000, eval_loss: 5.51817e-02
I0515 18:54:45.768262 22392998065984 run_lib.py:146] step: 354050, training_loss: 6.09034e-02
I0515 18:55:10.644841 22392998065984 run_lib.py:146] step: 354100, training_loss: 6.28751e-02
I0515 18:55:10.812670 22392998065984 run_lib.py:167] step: 354100, eval_loss: 6.47444e-02
I0515 18:55:35.329358 22392998065984 run_lib.py:146] step: 354150, training_loss: 5.53838e-02
I0515 18:55:59.611630 22392998065984 run_lib.py:146] step: 354200, training_loss: 5.59827e-02
I0515 18:55:59.793118 22392998065984 run_lib.py:167] step: 354200, eval_loss: 6.22942e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:56:24.687694 22392998065984 run_lib.py:146] step: 354250, training_loss: 5.98222e-02
I0515 18:56:49.358683 22392998065984 run_lib.py:146] step: 354300, training_loss: 7.09738e-02
I0515 18:56:49.519194 22392998065984 run_lib.py:167] step: 354300, eval_loss: 4.99431e-02
I0515 18:57:13.725637 22392998065984 run_lib.py:146] step: 354350, training_loss: 6.51762e-02
I0515 18:57:38.576810 22392998065984 run_lib.py:146] step: 354400, training_loss: 4.58879e-02
I0515 18:57:38.749563 22392998065984 run_lib.py:167] step: 354400, eval_loss: 4.82625e-02
I0515 18:58:03.441502 22392998065984 run_lib.py:146] step: 354450, training_loss: 5.37124e-02
I0515 18:58:27.787572 22392998065984 run_lib.py:146] step: 354500, training_loss: 5.21594e-02
I0515 18:58:27.948693 22392998065984 run_lib.py:167] step: 354500, eval_loss: 5.09441e-02
I0515 18:58:52.626167 22392998065984 run_lib.py:146] step: 354550, training_loss: 5.70733e-02
I0515 18:59:17.244688 22392998065984 run_lib.py:146] step: 354600, training_loss: 3.57294e-02
I0515 18:59:17.432401 22392998065984 run_lib.py:167] step: 354600, eval_loss: 5.55940e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 18:59:41.884280 22392998065984 run_lib.py:146] step: 354650, training_loss: 6.70917e-02
I0515 19:00:06.627870 22392998065984 run_lib.py:146] step: 354700, training_loss: 3.91890e-02
I0515 19:00:06.799987 22392998065984 run_lib.py:167] step: 354700, eval_loss: 5.19712e-02
I0515 19:00:31.119228 22392998065984 run_lib.py:146] step: 354750, training_loss: 4.54423e-02
I0515 19:00:55.769283 22392998065984 run_lib.py:146] step: 354800, training_loss: 5.12988e-02
I0515 19:00:55.944370 22392998065984 run_lib.py:167] step: 354800, eval_loss: 5.96779e-02
I0515 19:01:20.286358 22392998065984 run_lib.py:146] step: 354850, training_loss: 5.32920e-02
I0515 19:01:44.976335 22392998065984 run_lib.py:146] step: 354900, training_loss: 6.86401e-02
I0515 19:01:45.145738 22392998065984 run_lib.py:167] step: 354900, eval_loss: 6.20435e-02
I0515 19:02:09.753025 22392998065984 run_lib.py:146] step: 354950, training_loss: 6.53963e-02
I0515 19:02:34.100789 22392998065984 run_lib.py:146] step: 355000, training_loss: 4.90539e-02
I0515 19:02:34.259888 22392998065984 run_lib.py:167] step: 355000, eval_loss: 5.10245e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:02:59.091800 22392998065984 run_lib.py:146] step: 355050, training_loss: 6.04659e-02
I0515 19:03:23.873829 22392998065984 run_lib.py:146] step: 355100, training_loss: 4.90183e-02
I0515 19:03:24.039826 22392998065984 run_lib.py:167] step: 355100, eval_loss: 6.37875e-02
I0515 19:03:48.552366 22392998065984 run_lib.py:146] step: 355150, training_loss: 5.88403e-02
I0515 19:04:13.309163 22392998065984 run_lib.py:146] step: 355200, training_loss: 6.05300e-02
I0515 19:04:13.481729 22392998065984 run_lib.py:167] step: 355200, eval_loss: 6.70988e-02
I0515 19:04:38.244670 22392998065984 run_lib.py:146] step: 355250, training_loss: 5.36908e-02
I0515 19:05:02.486666 22392998065984 run_lib.py:146] step: 355300, training_loss: 5.27965e-02
I0515 19:05:02.655708 22392998065984 run_lib.py:167] step: 355300, eval_loss: 5.71988e-02
I0515 19:05:27.228480 22392998065984 run_lib.py:146] step: 355350, training_loss: 6.45705e-02
I0515 19:05:51.872384 22392998065984 run_lib.py:146] step: 355400, training_loss: 4.70431e-02
I0515 19:05:51.958038 22392998065984 run_lib.py:167] step: 355400, eval_loss: 3.33167e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:06:16.468708 22392998065984 run_lib.py:146] step: 355450, training_loss: 4.85669e-02
I0515 19:06:41.116724 22392998065984 run_lib.py:146] step: 355500, training_loss: 4.18031e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:06:41.554034 22392998065984 run_lib.py:167] step: 355500, eval_loss: 6.30053e-02
I0515 19:07:06.506829 22392998065984 run_lib.py:146] step: 355550, training_loss: 5.28414e-02
I0515 19:07:30.761786 22392998065984 run_lib.py:146] step: 355600, training_loss: 5.47786e-02
I0515 19:07:30.924777 22392998065984 run_lib.py:167] step: 355600, eval_loss: 6.54707e-02
I0515 19:07:55.115745 22392998065984 run_lib.py:146] step: 355650, training_loss: 4.86819e-02
I0515 19:08:19.808962 22392998065984 run_lib.py:146] step: 355700, training_loss: 5.49048e-02
I0515 19:08:19.985847 22392998065984 run_lib.py:167] step: 355700, eval_loss: 6.66232e-02
I0515 19:08:44.538743 22392998065984 run_lib.py:146] step: 355750, training_loss: 7.81429e-02
I0515 19:09:08.804716 22392998065984 run_lib.py:146] step: 355800, training_loss: 5.63734e-02
I0515 19:09:08.966137 22392998065984 run_lib.py:167] step: 355800, eval_loss: 5.87938e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:09:33.769558 22392998065984 run_lib.py:146] step: 355850, training_loss: 5.44921e-02
I0515 19:09:58.424741 22392998065984 run_lib.py:146] step: 355900, training_loss: 4.80009e-02
I0515 19:09:58.611939 22392998065984 run_lib.py:167] step: 355900, eval_loss: 5.51794e-02
I0515 19:10:23.036737 22392998065984 run_lib.py:146] step: 355950, training_loss: 6.05054e-02
I0515 19:10:47.635836 22392998065984 run_lib.py:146] step: 356000, training_loss: 5.37754e-02
I0515 19:10:47.796091 22392998065984 run_lib.py:167] step: 356000, eval_loss: 6.32897e-02
I0515 19:11:12.518663 22392998065984 run_lib.py:146] step: 356050, training_loss: 5.64626e-02
I0515 19:11:36.825988 22392998065984 run_lib.py:146] step: 356100, training_loss: 5.93787e-02
I0515 19:11:36.985877 22392998065984 run_lib.py:167] step: 356100, eval_loss: 6.85580e-02
I0515 19:12:01.621831 22392998065984 run_lib.py:146] step: 356150, training_loss: 6.11774e-02
I0515 19:12:26.115883 22392998065984 run_lib.py:146] step: 356200, training_loss: 5.10851e-02
I0515 19:12:26.297910 22392998065984 run_lib.py:167] step: 356200, eval_loss: 5.41457e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:12:50.999912 22392998065984 run_lib.py:146] step: 356250, training_loss: 7.19810e-02
I0515 19:13:15.722002 22392998065984 run_lib.py:146] step: 356300, training_loss: 5.65352e-02
I0515 19:13:15.885497 22392998065984 run_lib.py:167] step: 356300, eval_loss: 5.98932e-02
I0515 19:13:40.712363 22392998065984 run_lib.py:146] step: 356350, training_loss: 4.67457e-02
I0515 19:14:05.042234 22392998065984 run_lib.py:146] step: 356400, training_loss: 5.81456e-02
I0515 19:14:05.208806 22392998065984 run_lib.py:167] step: 356400, eval_loss: 5.08865e-02
I0515 19:14:29.581251 22392998065984 run_lib.py:146] step: 356450, training_loss: 5.73388e-02
I0515 19:14:54.177046 22392998065984 run_lib.py:146] step: 356500, training_loss: 6.82831e-02
I0515 19:14:54.337363 22392998065984 run_lib.py:167] step: 356500, eval_loss: 6.09225e-02
I0515 19:15:19.036534 22392998065984 run_lib.py:146] step: 356550, training_loss: 5.36652e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:15:43.441724 22392998065984 run_lib.py:146] step: 356600, training_loss: 4.60599e-02
I0515 19:15:43.613396 22392998065984 run_lib.py:167] step: 356600, eval_loss: 5.18472e-02
I0515 19:16:08.282375 22392998065984 run_lib.py:146] step: 356650, training_loss: 7.15788e-02
I0515 19:16:33.179156 22392998065984 run_lib.py:146] step: 356700, training_loss: 6.15101e-02
I0515 19:16:33.351511 22392998065984 run_lib.py:167] step: 356700, eval_loss: 6.41709e-02
I0515 19:16:57.757169 22392998065984 run_lib.py:146] step: 356750, training_loss: 6.11338e-02
I0515 19:17:22.486705 22392998065984 run_lib.py:146] step: 356800, training_loss: 4.63293e-02
I0515 19:17:22.667892 22392998065984 run_lib.py:167] step: 356800, eval_loss: 7.96783e-02
I0515 19:17:47.297635 22392998065984 run_lib.py:146] step: 356850, training_loss: 6.05040e-02
I0515 19:18:11.382091 22392998065984 run_lib.py:146] step: 356900, training_loss: 5.35301e-02
I0515 19:18:11.548605 22392998065984 run_lib.py:167] step: 356900, eval_loss: 5.48377e-02
I0515 19:18:36.046868 22392998065984 run_lib.py:146] step: 356950, training_loss: 6.65160e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:19:00.783838 22392998065984 run_lib.py:146] step: 357000, training_loss: 5.96082e-02
I0515 19:19:00.951072 22392998065984 run_lib.py:167] step: 357000, eval_loss: 4.62784e-02
I0515 19:19:25.286747 22392998065984 run_lib.py:146] step: 357050, training_loss: 7.12751e-02
I0515 19:19:49.626991 22392998065984 run_lib.py:146] step: 357100, training_loss: 9.40686e-02
I0515 19:19:49.790049 22392998065984 run_lib.py:167] step: 357100, eval_loss: 4.99012e-02
I0515 19:20:14.743196 22392998065984 run_lib.py:146] step: 357150, training_loss: 6.39805e-02
I0515 19:20:39.074044 22392998065984 run_lib.py:146] step: 357200, training_loss: 4.54613e-02
I0515 19:20:39.234565 22392998065984 run_lib.py:167] step: 357200, eval_loss: 6.24498e-02
I0515 19:21:03.532315 22392998065984 run_lib.py:146] step: 357250, training_loss: 5.46158e-02
I0515 19:21:28.137190 22392998065984 run_lib.py:146] step: 357300, training_loss: 5.94787e-02
I0515 19:21:28.298440 22392998065984 run_lib.py:167] step: 357300, eval_loss: 6.27834e-02
I0515 19:21:52.911272 22392998065984 run_lib.py:146] step: 357350, training_loss: 5.86453e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:22:17.360863 22392998065984 run_lib.py:146] step: 357400, training_loss: 7.29268e-02
I0515 19:22:17.523382 22392998065984 run_lib.py:167] step: 357400, eval_loss: 6.66827e-02
I0515 19:22:42.169996 22392998065984 run_lib.py:146] step: 357450, training_loss: 5.63873e-02
I0515 19:23:06.885688 22392998065984 run_lib.py:146] step: 357500, training_loss: 6.24163e-02
I0515 19:23:07.046571 22392998065984 run_lib.py:167] step: 357500, eval_loss: 6.37856e-02
I0515 19:23:31.353672 22392998065984 run_lib.py:146] step: 357550, training_loss: 6.67003e-02
I0515 19:23:55.916923 22392998065984 run_lib.py:146] step: 357600, training_loss: 5.71964e-02
I0515 19:23:56.080660 22392998065984 run_lib.py:167] step: 357600, eval_loss: 7.44571e-02
I0515 19:24:20.739485 22392998065984 run_lib.py:146] step: 357650, training_loss: 5.23117e-02
I0515 19:24:45.049244 22392998065984 run_lib.py:146] step: 357700, training_loss: 5.42257e-02
I0515 19:24:45.225783 22392998065984 run_lib.py:167] step: 357700, eval_loss: 4.83749e-02
I0515 19:25:09.860907 22392998065984 run_lib.py:146] step: 357750, training_loss: 4.54287e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:25:34.710356 22392998065984 run_lib.py:146] step: 357800, training_loss: 5.49962e-02
I0515 19:25:34.883029 22392998065984 run_lib.py:167] step: 357800, eval_loss: 5.49769e-02
I0515 19:25:59.148430 22392998065984 run_lib.py:146] step: 357850, training_loss: 6.26575e-02
I0515 19:26:23.423779 22392998065984 run_lib.py:146] step: 357900, training_loss: 5.09177e-02
I0515 19:26:23.595187 22392998065984 run_lib.py:167] step: 357900, eval_loss: 6.16316e-02
I0515 19:26:49.134735 22392998065984 run_lib.py:146] step: 357950, training_loss: 4.84335e-02
I0515 19:27:13.605309 22392998065984 run_lib.py:146] step: 358000, training_loss: 6.61327e-02
I0515 19:27:13.768189 22392998065984 run_lib.py:167] step: 358000, eval_loss: 6.49042e-02
I0515 19:27:38.116908 22392998065984 run_lib.py:146] step: 358050, training_loss: 5.40734e-02
I0515 19:28:02.826827 22392998065984 run_lib.py:146] step: 358100, training_loss: 5.39216e-02
I0515 19:28:02.998618 22392998065984 run_lib.py:167] step: 358100, eval_loss: 6.15688e-02
I0515 19:28:27.617729 22392998065984 run_lib.py:146] step: 358150, training_loss: 5.62105e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:28:52.069364 22392998065984 run_lib.py:146] step: 358200, training_loss: 4.29950e-02
I0515 19:28:52.231237 22392998065984 run_lib.py:167] step: 358200, eval_loss: 5.84660e-02
I0515 19:29:16.928756 22392998065984 run_lib.py:146] step: 358250, training_loss: 4.76094e-02
I0515 19:29:41.602862 22392998065984 run_lib.py:146] step: 358300, training_loss: 7.20465e-02
I0515 19:29:41.765526 22392998065984 run_lib.py:167] step: 358300, eval_loss: 5.30847e-02
I0515 19:30:06.033115 22392998065984 run_lib.py:146] step: 358350, training_loss: 7.07324e-02
I0515 19:30:30.644124 22392998065984 run_lib.py:146] step: 358400, training_loss: 5.95233e-02
I0515 19:30:30.816170 22392998065984 run_lib.py:167] step: 358400, eval_loss: 6.44455e-02
I0515 19:30:55.575797 22392998065984 run_lib.py:146] step: 358450, training_loss: 5.65998e-02
I0515 19:31:19.898634 22392998065984 run_lib.py:146] step: 358500, training_loss: 4.84309e-02
I0515 19:31:20.070205 22392998065984 run_lib.py:167] step: 358500, eval_loss: 7.05352e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:31:44.876846 22392998065984 run_lib.py:146] step: 358550, training_loss: 5.86817e-02
I0515 19:32:09.559863 22392998065984 run_lib.py:146] step: 358600, training_loss: 5.23366e-02
I0515 19:32:09.744449 22392998065984 run_lib.py:167] step: 358600, eval_loss: 4.72357e-02
I0515 19:32:33.984655 22392998065984 run_lib.py:146] step: 358650, training_loss: 4.88731e-02
I0515 19:32:58.151075 22392998065984 run_lib.py:146] step: 358700, training_loss: 5.53762e-02
I0515 19:32:58.334146 22392998065984 run_lib.py:167] step: 358700, eval_loss: 6.37176e-02
I0515 19:33:23.426022 22392998065984 run_lib.py:146] step: 358750, training_loss: 5.76849e-02
I0515 19:33:47.739237 22392998065984 run_lib.py:146] step: 358800, training_loss: 6.24757e-02
I0515 19:33:47.900427 22392998065984 run_lib.py:167] step: 358800, eval_loss: 8.12900e-02
I0515 19:34:12.219503 22392998065984 run_lib.py:146] step: 358850, training_loss: 8.25765e-02
I0515 19:34:36.863240 22392998065984 run_lib.py:146] step: 358900, training_loss: 6.16845e-02
I0515 19:34:37.025008 22392998065984 run_lib.py:167] step: 358900, eval_loss: 4.58327e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:35:01.884366 22392998065984 run_lib.py:146] step: 358950, training_loss: 4.04606e-02
I0515 19:35:26.246096 22392998065984 run_lib.py:146] step: 359000, training_loss: 7.51372e-02
I0515 19:35:26.417783 22392998065984 run_lib.py:167] step: 359000, eval_loss: 7.18445e-02
I0515 19:35:51.129000 22392998065984 run_lib.py:146] step: 359050, training_loss: 6.88561e-02
I0515 19:36:15.954639 22392998065984 run_lib.py:146] step: 359100, training_loss: 5.97376e-02
I0515 19:36:16.114087 22392998065984 run_lib.py:167] step: 359100, eval_loss: 6.57037e-02
I0515 19:36:40.452957 22392998065984 run_lib.py:146] step: 359150, training_loss: 4.40803e-02
I0515 19:37:05.056384 22392998065984 run_lib.py:146] step: 359200, training_loss: 5.46665e-02
I0515 19:37:05.225856 22392998065984 run_lib.py:167] step: 359200, eval_loss: 5.16497e-02
I0515 19:37:30.014243 22392998065984 run_lib.py:146] step: 359250, training_loss: 4.37664e-02
I0515 19:37:54.288038 22392998065984 run_lib.py:146] step: 359300, training_loss: 9.20488e-02
I0515 19:37:54.458943 22392998065984 run_lib.py:167] step: 359300, eval_loss: 4.84084e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:38:19.381356 22392998065984 run_lib.py:146] step: 359350, training_loss: 4.99561e-02
I0515 19:38:44.118172 22392998065984 run_lib.py:146] step: 359400, training_loss: 4.39600e-02
I0515 19:38:44.285095 22392998065984 run_lib.py:167] step: 359400, eval_loss: 6.63198e-02
I0515 19:39:08.622671 22392998065984 run_lib.py:146] step: 359450, training_loss: 4.62854e-02
I0515 19:39:33.210526 22392998065984 run_lib.py:146] step: 359500, training_loss: 4.87266e-02
I0515 19:39:33.373403 22392998065984 run_lib.py:167] step: 359500, eval_loss: 5.94716e-02
I0515 19:39:58.346284 22392998065984 run_lib.py:146] step: 359550, training_loss: 5.71082e-02
I0515 19:40:22.598068 22392998065984 run_lib.py:146] step: 359600, training_loss: 4.51934e-02
I0515 19:40:22.791337 22392998065984 run_lib.py:167] step: 359600, eval_loss: 4.99769e-02
I0515 19:40:47.057269 22392998065984 run_lib.py:146] step: 359650, training_loss: 4.75579e-02
I0515 19:41:11.632362 22392998065984 run_lib.py:146] step: 359700, training_loss: 5.65594e-02
I0515 19:41:11.791845 22392998065984 run_lib.py:167] step: 359700, eval_loss: 5.26919e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:41:36.638823 22392998065984 run_lib.py:146] step: 359750, training_loss: 6.07705e-02
I0515 19:42:01.012801 22392998065984 run_lib.py:146] step: 359800, training_loss: 4.54258e-02
I0515 19:42:01.179359 22392998065984 run_lib.py:167] step: 359800, eval_loss: 5.50173e-02
I0515 19:42:25.830640 22392998065984 run_lib.py:146] step: 359850, training_loss: 3.98456e-02
I0515 19:42:50.450914 22392998065984 run_lib.py:146] step: 359900, training_loss: 3.81377e-02
I0515 19:42:50.612096 22392998065984 run_lib.py:167] step: 359900, eval_loss: 6.96144e-02
I0515 19:43:14.914444 22392998065984 run_lib.py:146] step: 359950, training_loss: 6.09888e-02
I0515 19:43:39.505239 22392998065984 run_lib.py:146] step: 360000, training_loss: 8.55401e-02
I0515 19:43:41.538758 22392998065984 run_lib.py:167] step: 360000, eval_loss: 6.70561e-02
I0515 19:44:07.287264 22392998065984 run_lib.py:146] step: 360050, training_loss: 5.44061e-02
I0515 19:44:31.583561 22392998065984 run_lib.py:146] step: 360100, training_loss: 4.96291e-02
I0515 19:44:31.755481 22392998065984 run_lib.py:167] step: 360100, eval_loss: 6.09346e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:44:57.169313 22392998065984 run_lib.py:146] step: 360150, training_loss: 5.81299e-02
I0515 19:45:21.571624 22392998065984 run_lib.py:146] step: 360200, training_loss: 4.83761e-02
I0515 19:45:21.734620 22392998065984 run_lib.py:167] step: 360200, eval_loss: 5.14489e-02
I0515 19:45:45.907989 22392998065984 run_lib.py:146] step: 360250, training_loss: 6.34781e-02
I0515 19:46:10.728069 22392998065984 run_lib.py:146] step: 360300, training_loss: 7.19069e-02
I0515 19:46:10.897490 22392998065984 run_lib.py:167] step: 360300, eval_loss: 5.91995e-02
I0515 19:46:35.505970 22392998065984 run_lib.py:146] step: 360350, training_loss: 6.10390e-02
I0515 19:46:59.805904 22392998065984 run_lib.py:146] step: 360400, training_loss: 5.29184e-02
I0515 19:46:59.965078 22392998065984 run_lib.py:167] step: 360400, eval_loss: 5.55757e-02
I0515 19:47:24.651499 22392998065984 run_lib.py:146] step: 360450, training_loss: 7.27076e-02
I0515 19:47:49.200590 22392998065984 run_lib.py:146] step: 360500, training_loss: 6.54037e-02
I0515 19:47:49.370537 22392998065984 run_lib.py:167] step: 360500, eval_loss: 8.23050e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:48:13.915642 22392998065984 run_lib.py:146] step: 360550, training_loss: 4.93838e-02
I0515 19:48:38.250158 22392998065984 run_lib.py:146] step: 360600, training_loss: 5.56332e-02
I0515 19:48:38.416190 22392998065984 run_lib.py:167] step: 360600, eval_loss: 7.00949e-02
I0515 19:49:03.709039 22392998065984 run_lib.py:146] step: 360650, training_loss: 4.67527e-02
I0515 19:49:28.073936 22392998065984 run_lib.py:146] step: 360700, training_loss: 5.47933e-02
I0515 19:49:28.234639 22392998065984 run_lib.py:167] step: 360700, eval_loss: 6.35821e-02
I0515 19:49:52.630289 22392998065984 run_lib.py:146] step: 360750, training_loss: 6.94073e-02
I0515 19:50:17.679765 22392998065984 run_lib.py:146] step: 360800, training_loss: 4.82817e-02
I0515 19:50:17.840570 22392998065984 run_lib.py:167] step: 360800, eval_loss: 7.45365e-02
I0515 19:50:42.111490 22392998065984 run_lib.py:146] step: 360850, training_loss: 4.43080e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:51:06.551820 22392998065984 run_lib.py:146] step: 360900, training_loss: 5.84927e-02
I0515 19:51:06.716500 22392998065984 run_lib.py:167] step: 360900, eval_loss: 5.89759e-02
I0515 19:51:31.928346 22392998065984 run_lib.py:146] step: 360950, training_loss: 5.76870e-02
I0515 19:51:56.196681 22392998065984 run_lib.py:146] step: 361000, training_loss: 6.35325e-02
I0515 19:51:56.357100 22392998065984 run_lib.py:167] step: 361000, eval_loss: 5.65206e-02
I0515 19:52:20.736295 22392998065984 run_lib.py:146] step: 361050, training_loss: 5.79155e-02
I0515 19:52:45.362295 22392998065984 run_lib.py:146] step: 361100, training_loss: 7.09890e-02
I0515 19:52:45.521607 22392998065984 run_lib.py:167] step: 361100, eval_loss: 8.20344e-02
I0515 19:53:10.155954 22392998065984 run_lib.py:146] step: 361150, training_loss: 6.05222e-02
I0515 19:53:34.516849 22392998065984 run_lib.py:146] step: 361200, training_loss: 5.54231e-02
I0515 19:53:34.682063 22392998065984 run_lib.py:167] step: 361200, eval_loss: 6.53441e-02
I0515 19:53:59.309803 22392998065984 run_lib.py:146] step: 361250, training_loss: 5.07204e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:54:24.076065 22392998065984 run_lib.py:146] step: 361300, training_loss: 6.69613e-02
I0515 19:54:24.246925 22392998065984 run_lib.py:167] step: 361300, eval_loss: 5.86668e-02
I0515 19:54:48.602517 22392998065984 run_lib.py:146] step: 361350, training_loss: 4.97867e-02
I0515 19:55:13.052972 22392998065984 run_lib.py:146] step: 361400, training_loss: 6.69608e-02
I0515 19:55:13.220913 22392998065984 run_lib.py:167] step: 361400, eval_loss: 5.97858e-02
I0515 19:55:38.256785 22392998065984 run_lib.py:146] step: 361450, training_loss: 6.78814e-02
I0515 19:56:02.579042 22392998065984 run_lib.py:146] step: 361500, training_loss: 7.76576e-02
I0515 19:56:02.737885 22392998065984 run_lib.py:167] step: 361500, eval_loss: 7.20690e-02
I0515 19:56:27.050906 22392998065984 run_lib.py:146] step: 361550, training_loss: 4.62149e-02
I0515 19:56:51.959406 22392998065984 run_lib.py:146] step: 361600, training_loss: 5.05561e-02
I0515 19:56:52.120342 22392998065984 run_lib.py:167] step: 361600, eval_loss: 8.60148e-02
I0515 19:57:16.402905 22392998065984 run_lib.py:146] step: 361650, training_loss: 6.00422e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 19:57:40.937096 22392998065984 run_lib.py:146] step: 361700, training_loss: 6.34940e-02
I0515 19:57:41.107712 22392998065984 run_lib.py:167] step: 361700, eval_loss: 5.52216e-02
I0515 19:58:06.185489 22392998065984 run_lib.py:146] step: 361750, training_loss: 6.41367e-02
I0515 19:58:30.496048 22392998065984 run_lib.py:146] step: 361800, training_loss: 5.46710e-02
I0515 19:58:30.664837 22392998065984 run_lib.py:167] step: 361800, eval_loss: 6.78674e-02
I0515 19:58:54.974148 22392998065984 run_lib.py:146] step: 361850, training_loss: 5.54366e-02
I0515 19:59:19.572902 22392998065984 run_lib.py:146] step: 361900, training_loss: 6.17691e-02
I0515 19:59:19.732856 22392998065984 run_lib.py:167] step: 361900, eval_loss: 4.91473e-02
I0515 19:59:44.290826 22392998065984 run_lib.py:146] step: 361950, training_loss: 7.46925e-02
I0515 20:00:08.666950 22392998065984 run_lib.py:146] step: 362000, training_loss: 4.72058e-02
I0515 20:00:08.828017 22392998065984 run_lib.py:167] step: 362000, eval_loss: 5.65205e-02
I0515 20:00:33.461490 22392998065984 run_lib.py:146] step: 362050, training_loss: 4.99416e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:00:58.136926 22392998065984 run_lib.py:146] step: 362100, training_loss: 5.78781e-02
I0515 20:00:58.307696 22392998065984 run_lib.py:167] step: 362100, eval_loss: 5.28116e-02
I0515 20:01:22.502216 22392998065984 run_lib.py:146] step: 362150, training_loss: 4.80030e-02
I0515 20:01:46.442195 22392998065984 run_lib.py:146] step: 362200, training_loss: 7.18871e-02
I0515 20:01:46.601894 22392998065984 run_lib.py:167] step: 362200, eval_loss: 5.40906e-02
I0515 20:02:11.273985 22392998065984 run_lib.py:146] step: 362250, training_loss: 5.90250e-02
I0515 20:02:35.147518 22392998065984 run_lib.py:146] step: 362300, training_loss: 5.25320e-02
I0515 20:02:35.306575 22392998065984 run_lib.py:167] step: 362300, eval_loss: 6.88514e-02
I0515 20:02:59.512838 22392998065984 run_lib.py:146] step: 362350, training_loss: 6.97953e-02
I0515 20:03:24.566788 22392998065984 run_lib.py:146] step: 362400, training_loss: 6.04091e-02
I0515 20:03:24.742440 22392998065984 run_lib.py:167] step: 362400, eval_loss: 7.04303e-02
I0515 20:03:49.094296 22392998065984 run_lib.py:146] step: 362450, training_loss: 6.58257e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:04:13.585033 22392998065984 run_lib.py:146] step: 362500, training_loss: 7.81626e-02
I0515 20:04:13.753018 22392998065984 run_lib.py:167] step: 362500, eval_loss: 6.23321e-02
I0515 20:04:38.733486 22392998065984 run_lib.py:146] step: 362550, training_loss: 6.76685e-02
I0515 20:05:03.026242 22392998065984 run_lib.py:146] step: 362600, training_loss: 4.71778e-02
I0515 20:05:03.191212 22392998065984 run_lib.py:167] step: 362600, eval_loss: 5.93606e-02
I0515 20:05:27.389480 22392998065984 run_lib.py:146] step: 362650, training_loss: 5.76014e-02
I0515 20:05:52.077248 22392998065984 run_lib.py:146] step: 362700, training_loss: 5.50049e-02
I0515 20:05:52.246819 22392998065984 run_lib.py:167] step: 362700, eval_loss: 7.66124e-02
I0515 20:06:16.820158 22392998065984 run_lib.py:146] step: 362750, training_loss: 4.93875e-02
I0515 20:06:41.128314 22392998065984 run_lib.py:146] step: 362800, training_loss: 6.90619e-02
I0515 20:06:41.304226 22392998065984 run_lib.py:167] step: 362800, eval_loss: 8.37078e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:07:06.084938 22392998065984 run_lib.py:146] step: 362850, training_loss: 5.02126e-02
I0515 20:07:30.488730 22392998065984 run_lib.py:146] step: 362900, training_loss: 5.17861e-02
I0515 20:07:30.654871 22392998065984 run_lib.py:167] step: 362900, eval_loss: 7.62943e-02
I0515 20:07:55.040452 22392998065984 run_lib.py:146] step: 362950, training_loss: 5.25333e-02
I0515 20:08:19.477594 22392998065984 run_lib.py:146] step: 363000, training_loss: 5.06150e-02
I0515 20:08:19.643285 22392998065984 run_lib.py:167] step: 363000, eval_loss: 6.10715e-02
I0515 20:08:44.634740 22392998065984 run_lib.py:146] step: 363050, training_loss: 6.17295e-02
I0515 20:09:08.953299 22392998065984 run_lib.py:146] step: 363100, training_loss: 5.92930e-02
I0515 20:09:09.198349 22392998065984 run_lib.py:167] step: 363100, eval_loss: 7.22537e-02
I0515 20:09:33.493060 22392998065984 run_lib.py:146] step: 363150, training_loss: 4.03985e-02
I0515 20:09:58.592500 22392998065984 run_lib.py:146] step: 363200, training_loss: 6.71455e-02
I0515 20:09:58.754148 22392998065984 run_lib.py:167] step: 363200, eval_loss: 5.22957e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:10:23.216734 22392998065984 run_lib.py:146] step: 363250, training_loss: 6.20503e-02
I0515 20:10:47.559255 22392998065984 run_lib.py:146] step: 363300, training_loss: 4.52361e-02
I0515 20:10:47.651334 22392998065984 run_lib.py:167] step: 363300, eval_loss: 7.00312e-02
I0515 20:11:12.797606 22392998065984 run_lib.py:146] step: 363350, training_loss: 4.92647e-02
I0515 20:11:37.139863 22392998065984 run_lib.py:146] step: 363400, training_loss: 6.28587e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:11:37.567098 22392998065984 run_lib.py:167] step: 363400, eval_loss: 6.61101e-02
I0515 20:12:01.730808 22392998065984 run_lib.py:146] step: 363450, training_loss: 5.67020e-02
I0515 20:12:26.902644 22392998065984 run_lib.py:146] step: 363500, training_loss: 5.84591e-02
I0515 20:12:27.070109 22392998065984 run_lib.py:167] step: 363500, eval_loss: 4.67240e-02
I0515 20:12:51.368160 22392998065984 run_lib.py:146] step: 363550, training_loss: 7.32206e-02
I0515 20:13:15.699380 22392998065984 run_lib.py:146] step: 363600, training_loss: 6.73157e-02
I0515 20:13:15.859464 22392998065984 run_lib.py:167] step: 363600, eval_loss: 6.85582e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:13:40.675266 22392998065984 run_lib.py:146] step: 363650, training_loss: 4.34669e-02
I0515 20:14:05.291635 22392998065984 run_lib.py:146] step: 363700, training_loss: 5.65289e-02
I0515 20:14:05.464420 22392998065984 run_lib.py:167] step: 363700, eval_loss: 7.23001e-02
I0515 20:14:29.882875 22392998065984 run_lib.py:146] step: 363750, training_loss: 7.30265e-02
I0515 20:14:54.262117 22392998065984 run_lib.py:146] step: 363800, training_loss: 5.01877e-02
I0515 20:14:54.423714 22392998065984 run_lib.py:167] step: 363800, eval_loss: 6.21779e-02
I0515 20:15:19.499358 22392998065984 run_lib.py:146] step: 363850, training_loss: 5.39804e-02
I0515 20:15:43.868762 22392998065984 run_lib.py:146] step: 363900, training_loss: 5.27001e-02
I0515 20:15:44.027931 22392998065984 run_lib.py:167] step: 363900, eval_loss: 5.24233e-02
I0515 20:16:08.317540 22392998065984 run_lib.py:146] step: 363950, training_loss: 5.30140e-02
I0515 20:16:33.452395 22392998065984 run_lib.py:146] step: 364000, training_loss: 5.47285e-02
I0515 20:16:33.614623 22392998065984 run_lib.py:167] step: 364000, eval_loss: 7.85371e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:16:58.095514 22392998065984 run_lib.py:146] step: 364050, training_loss: 6.75535e-02
I0515 20:17:22.496392 22392998065984 run_lib.py:146] step: 364100, training_loss: 5.39496e-02
I0515 20:17:22.657459 22392998065984 run_lib.py:167] step: 364100, eval_loss: 4.60536e-02
I0515 20:17:47.715771 22392998065984 run_lib.py:146] step: 364150, training_loss: 4.48158e-02
I0515 20:18:12.002054 22392998065984 run_lib.py:146] step: 364200, training_loss: 6.29557e-02
I0515 20:18:12.179300 22392998065984 run_lib.py:167] step: 364200, eval_loss: 7.00158e-02
I0515 20:18:36.404014 22392998065984 run_lib.py:146] step: 364250, training_loss: 5.59642e-02
I0515 20:19:01.272284 22392998065984 run_lib.py:146] step: 364300, training_loss: 5.65044e-02
I0515 20:19:01.442307 22392998065984 run_lib.py:167] step: 364300, eval_loss: 4.97749e-02
I0515 20:19:25.727912 22392998065984 run_lib.py:146] step: 364350, training_loss: 6.09942e-02
I0515 20:19:50.099692 22392998065984 run_lib.py:146] step: 364400, training_loss: 6.05409e-02
I0515 20:19:50.284329 22392998065984 run_lib.py:167] step: 364400, eval_loss: 5.09879e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:20:15.156621 22392998065984 run_lib.py:146] step: 364450, training_loss: 5.88280e-02
I0515 20:20:39.883044 22392998065984 run_lib.py:146] step: 364500, training_loss: 4.34258e-02
I0515 20:20:40.045578 22392998065984 run_lib.py:167] step: 364500, eval_loss: 5.35976e-02
I0515 20:21:04.290488 22392998065984 run_lib.py:146] step: 364550, training_loss: 6.34453e-02
I0515 20:21:28.577196 22392998065984 run_lib.py:146] step: 364600, training_loss: 6.99600e-02
I0515 20:21:28.740090 22392998065984 run_lib.py:167] step: 364600, eval_loss: 4.66874e-02
I0515 20:21:53.766577 22392998065984 run_lib.py:146] step: 364650, training_loss: 5.37734e-02
I0515 20:22:18.009821 22392998065984 run_lib.py:146] step: 364700, training_loss: 7.55145e-02
I0515 20:22:18.181071 22392998065984 run_lib.py:167] step: 364700, eval_loss: 4.88432e-02
I0515 20:22:42.396129 22392998065984 run_lib.py:146] step: 364750, training_loss: 6.61474e-02
I0515 20:23:07.285011 22392998065984 run_lib.py:146] step: 364800, training_loss: 6.02815e-02
I0515 20:23:07.446137 22392998065984 run_lib.py:167] step: 364800, eval_loss: 8.14250e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:23:31.906162 22392998065984 run_lib.py:146] step: 364850, training_loss: 5.58389e-02
I0515 20:23:56.161122 22392998065984 run_lib.py:146] step: 364900, training_loss: 3.99404e-02
I0515 20:23:56.327350 22392998065984 run_lib.py:167] step: 364900, eval_loss: 6.57315e-02
I0515 20:24:21.425751 22392998065984 run_lib.py:146] step: 364950, training_loss: 7.81897e-02
I0515 20:24:45.598029 22392998065984 run_lib.py:146] step: 365000, training_loss: 5.96210e-02
I0515 20:24:45.758689 22392998065984 run_lib.py:167] step: 365000, eval_loss: 7.90786e-02
I0515 20:25:10.128967 22392998065984 run_lib.py:146] step: 365050, training_loss: 3.91454e-02
I0515 20:25:35.030579 22392998065984 run_lib.py:146] step: 365100, training_loss: 5.30470e-02
I0515 20:25:35.207904 22392998065984 run_lib.py:167] step: 365100, eval_loss: 6.37591e-02
I0515 20:25:59.492110 22392998065984 run_lib.py:146] step: 365150, training_loss: 4.27413e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:26:24.039662 22392998065984 run_lib.py:146] step: 365200, training_loss: 8.91254e-02
I0515 20:26:24.205787 22392998065984 run_lib.py:167] step: 365200, eval_loss: 3.89279e-02
I0515 20:26:48.946286 22392998065984 run_lib.py:146] step: 365250, training_loss: 6.76124e-02
I0515 20:27:13.719165 22392998065984 run_lib.py:146] step: 365300, training_loss: 5.13665e-02
I0515 20:27:13.901134 22392998065984 run_lib.py:167] step: 365300, eval_loss: 6.95094e-02
I0515 20:27:38.296647 22392998065984 run_lib.py:146] step: 365350, training_loss: 4.54174e-02
I0515 20:28:02.705291 22392998065984 run_lib.py:146] step: 365400, training_loss: 5.27313e-02
I0515 20:28:02.870721 22392998065984 run_lib.py:167] step: 365400, eval_loss: 7.00170e-02
I0515 20:28:27.850755 22392998065984 run_lib.py:146] step: 365450, training_loss: 6.12162e-02
I0515 20:28:52.120355 22392998065984 run_lib.py:146] step: 365500, training_loss: 5.79534e-02
I0515 20:28:52.291112 22392998065984 run_lib.py:167] step: 365500, eval_loss: 6.07387e-02
I0515 20:29:16.541214 22392998065984 run_lib.py:146] step: 365550, training_loss: 6.09205e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:29:41.663403 22392998065984 run_lib.py:146] step: 365600, training_loss: 6.61901e-02
I0515 20:29:41.829766 22392998065984 run_lib.py:167] step: 365600, eval_loss: 6.09729e-02
I0515 20:30:06.228201 22392998065984 run_lib.py:146] step: 365650, training_loss: 5.08909e-02
I0515 20:30:30.627739 22392998065984 run_lib.py:146] step: 365700, training_loss: 5.47345e-02
I0515 20:30:30.795725 22392998065984 run_lib.py:167] step: 365700, eval_loss: 6.40998e-02
I0515 20:30:55.938445 22392998065984 run_lib.py:146] step: 365750, training_loss: 5.94231e-02
I0515 20:31:20.271276 22392998065984 run_lib.py:146] step: 365800, training_loss: 7.54404e-02
I0515 20:31:20.434185 22392998065984 run_lib.py:167] step: 365800, eval_loss: 6.52132e-02
I0515 20:31:44.747299 22392998065984 run_lib.py:146] step: 365850, training_loss: 5.73105e-02
I0515 20:32:09.730290 22392998065984 run_lib.py:146] step: 365900, training_loss: 8.87849e-02
I0515 20:32:09.892489 22392998065984 run_lib.py:167] step: 365900, eval_loss: 5.07238e-02
I0515 20:32:34.238020 22392998065984 run_lib.py:146] step: 365950, training_loss: 5.36063e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:32:58.808960 22392998065984 run_lib.py:146] step: 366000, training_loss: 4.43350e-02
I0515 20:32:59.020730 22392998065984 run_lib.py:167] step: 366000, eval_loss: 5.84917e-02
I0515 20:33:23.727999 22392998065984 run_lib.py:146] step: 366050, training_loss: 6.32277e-02
I0515 20:33:48.444445 22392998065984 run_lib.py:146] step: 366100, training_loss: 6.11545e-02
I0515 20:33:48.621204 22392998065984 run_lib.py:167] step: 366100, eval_loss: 6.21896e-02
I0515 20:34:12.904496 22392998065984 run_lib.py:146] step: 366150, training_loss: 6.17842e-02
I0515 20:34:37.481996 22392998065984 run_lib.py:146] step: 366200, training_loss: 3.93569e-02
I0515 20:34:37.650303 22392998065984 run_lib.py:167] step: 366200, eval_loss: 6.54368e-02
I0515 20:35:02.222348 22392998065984 run_lib.py:146] step: 366250, training_loss: 6.80775e-02
I0515 20:35:26.482322 22392998065984 run_lib.py:146] step: 366300, training_loss: 5.39540e-02
I0515 20:35:26.643425 22392998065984 run_lib.py:167] step: 366300, eval_loss: 5.44659e-02
I0515 20:35:50.928100 22392998065984 run_lib.py:146] step: 366350, training_loss: 5.71386e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:36:16.182176 22392998065984 run_lib.py:146] step: 366400, training_loss: 5.11260e-02
I0515 20:36:16.367930 22392998065984 run_lib.py:167] step: 366400, eval_loss: 6.45401e-02
I0515 20:36:40.667423 22392998065984 run_lib.py:146] step: 366450, training_loss: 5.95584e-02
I0515 20:37:05.149780 22392998065984 run_lib.py:146] step: 366500, training_loss: 6.27296e-02
I0515 20:37:05.312275 22392998065984 run_lib.py:167] step: 366500, eval_loss: 6.76513e-02
I0515 20:37:30.343747 22392998065984 run_lib.py:146] step: 366550, training_loss: 5.67880e-02
I0515 20:37:54.603495 22392998065984 run_lib.py:146] step: 366600, training_loss: 5.69994e-02
I0515 20:37:54.763604 22392998065984 run_lib.py:167] step: 366600, eval_loss: 5.08143e-02
I0515 20:38:19.029500 22392998065984 run_lib.py:146] step: 366650, training_loss: 5.46311e-02
I0515 20:38:43.980628 22392998065984 run_lib.py:146] step: 366700, training_loss: 6.71173e-02
I0515 20:38:44.148676 22392998065984 run_lib.py:167] step: 366700, eval_loss: 5.50826e-02
I0515 20:39:08.325798 22392998065984 run_lib.py:146] step: 366750, training_loss: 4.98963e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:39:32.745397 22392998065984 run_lib.py:146] step: 366800, training_loss: 4.93259e-02
I0515 20:39:32.907064 22392998065984 run_lib.py:167] step: 366800, eval_loss: 5.40277e-02
I0515 20:39:58.134435 22392998065984 run_lib.py:146] step: 366850, training_loss: 6.42491e-02
I0515 20:40:22.522882 22392998065984 run_lib.py:146] step: 366900, training_loss: 7.01196e-02
I0515 20:40:22.683773 22392998065984 run_lib.py:167] step: 366900, eval_loss: 5.42851e-02
I0515 20:40:46.952344 22392998065984 run_lib.py:146] step: 366950, training_loss: 4.47612e-02
I0515 20:41:11.615253 22392998065984 run_lib.py:146] step: 367000, training_loss: 4.45815e-02
I0515 20:41:11.776343 22392998065984 run_lib.py:167] step: 367000, eval_loss: 8.07054e-02
I0515 20:41:36.416213 22392998065984 run_lib.py:146] step: 367050, training_loss: 7.37531e-02
I0515 20:42:00.686992 22392998065984 run_lib.py:146] step: 367100, training_loss: 6.44005e-02
I0515 20:42:00.846418 22392998065984 run_lib.py:167] step: 367100, eval_loss: 9.00486e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:42:25.265836 22392998065984 run_lib.py:146] step: 367150, training_loss: 4.95347e-02
I0515 20:42:50.313354 22392998065984 run_lib.py:146] step: 367200, training_loss: 4.95697e-02
I0515 20:42:50.477633 22392998065984 run_lib.py:167] step: 367200, eval_loss: 6.92939e-02
I0515 20:43:14.852973 22392998065984 run_lib.py:146] step: 367250, training_loss: 7.15994e-02
I0515 20:43:39.210139 22392998065984 run_lib.py:146] step: 367300, training_loss: 4.70115e-02
I0515 20:43:39.378592 22392998065984 run_lib.py:167] step: 367300, eval_loss: 4.95883e-02
I0515 20:44:04.324457 22392998065984 run_lib.py:146] step: 367350, training_loss: 8.07182e-02
I0515 20:44:28.625857 22392998065984 run_lib.py:146] step: 367400, training_loss: 6.48253e-02
I0515 20:44:28.796846 22392998065984 run_lib.py:167] step: 367400, eval_loss: 5.38215e-02
I0515 20:44:53.078994 22392998065984 run_lib.py:146] step: 367450, training_loss: 6.01625e-02
I0515 20:45:17.964224 22392998065984 run_lib.py:146] step: 367500, training_loss: 6.05563e-02
I0515 20:45:18.123993 22392998065984 run_lib.py:167] step: 367500, eval_loss: 5.21343e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:45:42.578490 22392998065984 run_lib.py:146] step: 367550, training_loss: 5.25957e-02
I0515 20:46:07.011264 22392998065984 run_lib.py:146] step: 367600, training_loss: 7.92929e-02
I0515 20:46:07.174941 22392998065984 run_lib.py:167] step: 367600, eval_loss: 5.98018e-02
I0515 20:46:32.255539 22392998065984 run_lib.py:146] step: 367650, training_loss: 4.60887e-02
I0515 20:46:56.617728 22392998065984 run_lib.py:146] step: 367700, training_loss: 5.80006e-02
I0515 20:46:56.779449 22392998065984 run_lib.py:167] step: 367700, eval_loss: 5.58986e-02
I0515 20:47:21.017841 22392998065984 run_lib.py:146] step: 367750, training_loss: 5.50644e-02
I0515 20:47:45.760565 22392998065984 run_lib.py:146] step: 367800, training_loss: 6.55713e-02
I0515 20:47:45.929640 22392998065984 run_lib.py:167] step: 367800, eval_loss: 5.67792e-02
I0515 20:48:10.592853 22392998065984 run_lib.py:146] step: 367850, training_loss: 4.94083e-02
I0515 20:48:34.908538 22392998065984 run_lib.py:146] step: 367900, training_loss: 8.04081e-02
I0515 20:48:35.070085 22392998065984 run_lib.py:167] step: 367900, eval_loss: 6.77228e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:48:59.969445 22392998065984 run_lib.py:146] step: 367950, training_loss: 4.96643e-02
I0515 20:49:24.679539 22392998065984 run_lib.py:146] step: 368000, training_loss: 6.26762e-02
I0515 20:49:24.841388 22392998065984 run_lib.py:167] step: 368000, eval_loss: 7.44651e-02
I0515 20:49:49.252443 22392998065984 run_lib.py:146] step: 368050, training_loss: 6.44434e-02
I0515 20:50:13.554418 22392998065984 run_lib.py:146] step: 368100, training_loss: 6.50034e-02
I0515 20:50:13.731157 22392998065984 run_lib.py:167] step: 368100, eval_loss: 6.21535e-02
I0515 20:50:38.661921 22392998065984 run_lib.py:146] step: 368150, training_loss: 5.90115e-02
I0515 20:51:02.977180 22392998065984 run_lib.py:146] step: 368200, training_loss: 6.91140e-02
I0515 20:51:03.149303 22392998065984 run_lib.py:167] step: 368200, eval_loss: 8.51284e-02
I0515 20:51:27.441970 22392998065984 run_lib.py:146] step: 368250, training_loss: 5.53325e-02
I0515 20:51:52.390495 22392998065984 run_lib.py:146] step: 368300, training_loss: 5.55451e-02
I0515 20:51:52.549488 22392998065984 run_lib.py:167] step: 368300, eval_loss: 4.41037e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:52:16.973838 22392998065984 run_lib.py:146] step: 368350, training_loss: 5.12212e-02
I0515 20:52:41.293121 22392998065984 run_lib.py:146] step: 368400, training_loss: 5.05134e-02
I0515 20:52:41.469566 22392998065984 run_lib.py:167] step: 368400, eval_loss: 5.27143e-02
I0515 20:53:06.525965 22392998065984 run_lib.py:146] step: 368450, training_loss: 5.14666e-02
I0515 20:53:30.785075 22392998065984 run_lib.py:146] step: 368500, training_loss: 4.66240e-02
I0515 20:53:30.949613 22392998065984 run_lib.py:167] step: 368500, eval_loss: 6.16198e-02
I0515 20:53:55.249979 22392998065984 run_lib.py:146] step: 368550, training_loss: 6.35460e-02
I0515 20:54:19.816007 22392998065984 run_lib.py:146] step: 368600, training_loss: 5.87967e-02
I0515 20:54:19.978224 22392998065984 run_lib.py:167] step: 368600, eval_loss: 7.98012e-02
I0515 20:54:44.579388 22392998065984 run_lib.py:146] step: 368650, training_loss: 5.09218e-02
I0515 20:55:08.871835 22392998065984 run_lib.py:146] step: 368700, training_loss: 4.74386e-02
I0515 20:55:09.032308 22392998065984 run_lib.py:167] step: 368700, eval_loss: 5.51854e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:55:33.919924 22392998065984 run_lib.py:146] step: 368750, training_loss: 4.75339e-02
I0515 20:55:58.794039 22392998065984 run_lib.py:146] step: 368800, training_loss: 6.90291e-02
I0515 20:55:58.960482 22392998065984 run_lib.py:167] step: 368800, eval_loss: 5.42391e-02
I0515 20:56:23.251875 22392998065984 run_lib.py:146] step: 368850, training_loss: 5.12098e-02
I0515 20:56:47.523104 22392998065984 run_lib.py:146] step: 368900, training_loss: 4.90538e-02
I0515 20:56:47.688392 22392998065984 run_lib.py:167] step: 368900, eval_loss: 6.54499e-02
I0515 20:57:12.778407 22392998065984 run_lib.py:146] step: 368950, training_loss: 4.83780e-02
I0515 20:57:37.105319 22392998065984 run_lib.py:146] step: 369000, training_loss: 6.67326e-02
I0515 20:57:37.277323 22392998065984 run_lib.py:167] step: 369000, eval_loss: 6.76859e-02
I0515 20:58:01.572797 22392998065984 run_lib.py:146] step: 369050, training_loss: 6.46902e-02
I0515 20:58:26.617311 22392998065984 run_lib.py:146] step: 369100, training_loss: 4.90900e-02
I0515 20:58:26.789742 22392998065984 run_lib.py:167] step: 369100, eval_loss: 6.01374e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 20:58:51.371572 22392998065984 run_lib.py:146] step: 369150, training_loss: 6.30705e-02
I0515 20:59:15.869166 22392998065984 run_lib.py:146] step: 369200, training_loss: 5.84192e-02
I0515 20:59:16.032525 22392998065984 run_lib.py:167] step: 369200, eval_loss: 4.73244e-02
I0515 20:59:41.178401 22392998065984 run_lib.py:146] step: 369250, training_loss: 6.19598e-02
I0515 21:00:05.510837 22392998065984 run_lib.py:146] step: 369300, training_loss: 5.97630e-02
I0515 21:00:05.671664 22392998065984 run_lib.py:167] step: 369300, eval_loss: 4.16032e-02
I0515 21:00:30.027492 22392998065984 run_lib.py:146] step: 369350, training_loss: 5.74035e-02
I0515 21:00:54.612591 22392998065984 run_lib.py:146] step: 369400, training_loss: 5.78703e-02
I0515 21:00:54.782685 22392998065984 run_lib.py:167] step: 369400, eval_loss: 6.73684e-02
I0515 21:01:19.376595 22392998065984 run_lib.py:146] step: 369450, training_loss: 3.30727e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:01:43.944336 22392998065984 run_lib.py:146] step: 369500, training_loss: 4.49942e-02
I0515 21:01:44.109480 22392998065984 run_lib.py:167] step: 369500, eval_loss: 9.55692e-02
I0515 21:02:08.948904 22392998065984 run_lib.py:146] step: 369550, training_loss: 5.21189e-02
I0515 21:02:33.637902 22392998065984 run_lib.py:146] step: 369600, training_loss: 5.01217e-02
I0515 21:02:33.796869 22392998065984 run_lib.py:167] step: 369600, eval_loss: 6.22387e-02
I0515 21:02:58.073396 22392998065984 run_lib.py:146] step: 369650, training_loss: 5.46586e-02
I0515 21:03:22.398060 22392998065984 run_lib.py:146] step: 369700, training_loss: 6.29312e-02
I0515 21:03:22.582771 22392998065984 run_lib.py:167] step: 369700, eval_loss: 5.82354e-02
I0515 21:03:47.659622 22392998065984 run_lib.py:146] step: 369750, training_loss: 9.08117e-02
I0515 21:04:11.955368 22392998065984 run_lib.py:146] step: 369800, training_loss: 6.47238e-02
I0515 21:04:12.143201 22392998065984 run_lib.py:167] step: 369800, eval_loss: 6.47574e-02
I0515 21:04:36.468895 22392998065984 run_lib.py:146] step: 369850, training_loss: 6.68893e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:05:01.701290 22392998065984 run_lib.py:146] step: 369900, training_loss: 6.00555e-02
I0515 21:05:01.865942 22392998065984 run_lib.py:167] step: 369900, eval_loss: 5.18817e-02
I0515 21:05:26.160867 22392998065984 run_lib.py:146] step: 369950, training_loss: 6.50449e-02
I0515 21:05:50.605335 22392998065984 run_lib.py:146] step: 370000, training_loss: 5.38730e-02
I0515 21:05:52.395246 22392998065984 run_lib.py:167] step: 370000, eval_loss: 4.84764e-02
I0515 21:06:19.327019 22392998065984 run_lib.py:146] step: 370050, training_loss: 4.97075e-02
I0515 21:06:43.610294 22392998065984 run_lib.py:146] step: 370100, training_loss: 6.16224e-02
I0515 21:06:43.769923 22392998065984 run_lib.py:167] step: 370100, eval_loss: 5.06342e-02
I0515 21:07:08.079291 22392998065984 run_lib.py:146] step: 370150, training_loss: 6.37609e-02
I0515 21:07:33.017218 22392998065984 run_lib.py:146] step: 370200, training_loss: 6.04636e-02
I0515 21:07:33.199279 22392998065984 run_lib.py:167] step: 370200, eval_loss: 5.67620e-02
I0515 21:07:57.536282 22392998065984 run_lib.py:146] step: 370250, training_loss: 5.12518e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:08:21.992267 22392998065984 run_lib.py:146] step: 370300, training_loss: 5.30919e-02
I0515 21:08:22.160299 22392998065984 run_lib.py:167] step: 370300, eval_loss: 6.65273e-02
I0515 21:08:47.273659 22392998065984 run_lib.py:146] step: 370350, training_loss: 5.43114e-02
I0515 21:09:11.538336 22392998065984 run_lib.py:146] step: 370400, training_loss: 6.91476e-02
I0515 21:09:11.708862 22392998065984 run_lib.py:167] step: 370400, eval_loss: 5.63707e-02
I0515 21:09:36.033951 22392998065984 run_lib.py:146] step: 370450, training_loss: 6.21515e-02
I0515 21:10:00.642941 22392998065984 run_lib.py:146] step: 370500, training_loss: 3.68447e-02
I0515 21:10:00.811845 22392998065984 run_lib.py:167] step: 370500, eval_loss: 4.99351e-02
I0515 21:10:25.413123 22392998065984 run_lib.py:146] step: 370550, training_loss: 7.50961e-02
I0515 21:10:49.682357 22392998065984 run_lib.py:146] step: 370600, training_loss: 5.46103e-02
I0515 21:10:49.844957 22392998065984 run_lib.py:167] step: 370600, eval_loss: 5.55339e-02
I0515 21:11:14.440954 22392998065984 run_lib.py:146] step: 370650, training_loss: 6.25584e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:11:39.294363 22392998065984 run_lib.py:146] step: 370700, training_loss: 6.01255e-02
I0515 21:11:39.461543 22392998065984 run_lib.py:167] step: 370700, eval_loss: 6.37804e-02
I0515 21:12:03.696752 22392998065984 run_lib.py:146] step: 370750, training_loss: 6.29376e-02
I0515 21:12:28.380770 22392998065984 run_lib.py:146] step: 370800, training_loss: 6.96571e-02
I0515 21:12:28.540639 22392998065984 run_lib.py:167] step: 370800, eval_loss: 5.94558e-02
I0515 21:12:53.200330 22392998065984 run_lib.py:146] step: 370850, training_loss: 4.44559e-02
I0515 21:13:17.480191 22392998065984 run_lib.py:146] step: 370900, training_loss: 7.25999e-02
I0515 21:13:17.652144 22392998065984 run_lib.py:167] step: 370900, eval_loss: 5.52552e-02
I0515 21:13:41.922998 22392998065984 run_lib.py:146] step: 370950, training_loss: 5.88905e-02
I0515 21:14:06.840161 22392998065984 run_lib.py:146] step: 371000, training_loss: 5.40303e-02
I0515 21:14:07.002631 22392998065984 run_lib.py:167] step: 371000, eval_loss: 5.77271e-02
I0515 21:14:31.372896 22392998065984 run_lib.py:146] step: 371050, training_loss: 6.03084e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:14:55.863028 22392998065984 run_lib.py:146] step: 371100, training_loss: 5.73860e-02
I0515 21:14:56.032502 22392998065984 run_lib.py:167] step: 371100, eval_loss: 6.97750e-02
I0515 21:15:21.165125 22392998065984 run_lib.py:146] step: 371150, training_loss: 5.33800e-02
I0515 21:15:45.417373 22392998065984 run_lib.py:146] step: 371200, training_loss: 5.80909e-02
I0515 21:15:45.505101 22392998065984 run_lib.py:167] step: 371200, eval_loss: 8.27296e-02
I0515 21:16:09.782567 22392998065984 run_lib.py:146] step: 371250, training_loss: 7.42410e-02
I0515 21:16:34.364350 22392998065984 run_lib.py:146] step: 371300, training_loss: 6.28993e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:16:34.809194 22392998065984 run_lib.py:167] step: 371300, eval_loss: 5.09966e-02
I0515 21:16:59.969301 22392998065984 run_lib.py:146] step: 371350, training_loss: 4.14650e-02
I0515 21:17:24.195445 22392998065984 run_lib.py:146] step: 371400, training_loss: 7.04023e-02
I0515 21:17:24.357032 22392998065984 run_lib.py:167] step: 371400, eval_loss: 7.65808e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:17:49.180441 22392998065984 run_lib.py:146] step: 371450, training_loss: 5.47685e-02
I0515 21:18:13.903550 22392998065984 run_lib.py:146] step: 371500, training_loss: 4.92476e-02
I0515 21:18:14.070894 22392998065984 run_lib.py:167] step: 371500, eval_loss: 7.92606e-02
I0515 21:18:38.437646 22392998065984 run_lib.py:146] step: 371550, training_loss: 5.53256e-02
I0515 21:19:03.139451 22392998065984 run_lib.py:146] step: 371600, training_loss: 5.02566e-02
I0515 21:19:03.308330 22392998065984 run_lib.py:167] step: 371600, eval_loss: 5.98042e-02
I0515 21:19:28.177824 22392998065984 run_lib.py:146] step: 371650, training_loss: 6.05074e-02
I0515 21:19:52.550431 22392998065984 run_lib.py:146] step: 371700, training_loss: 5.64912e-02
I0515 21:19:52.721737 22392998065984 run_lib.py:167] step: 371700, eval_loss: 5.09707e-02
I0515 21:20:17.378566 22392998065984 run_lib.py:146] step: 371750, training_loss: 5.53931e-02
I0515 21:20:42.051867 22392998065984 run_lib.py:146] step: 371800, training_loss: 5.01671e-02
I0515 21:20:42.213407 22392998065984 run_lib.py:167] step: 371800, eval_loss: 6.11483e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:21:06.695983 22392998065984 run_lib.py:146] step: 371850, training_loss: 4.67323e-02
I0515 21:21:31.075587 22392998065984 run_lib.py:146] step: 371900, training_loss: 4.66147e-02
I0515 21:21:31.244033 22392998065984 run_lib.py:167] step: 371900, eval_loss: 6.72800e-02
I0515 21:21:56.496892 22392998065984 run_lib.py:146] step: 371950, training_loss: 6.46147e-02
I0515 21:22:20.706561 22392998065984 run_lib.py:146] step: 372000, training_loss: 5.78024e-02
I0515 21:22:20.871884 22392998065984 run_lib.py:167] step: 372000, eval_loss: 4.81509e-02
I0515 21:22:45.230796 22392998065984 run_lib.py:146] step: 372050, training_loss: 7.77083e-02
I0515 21:23:10.263643 22392998065984 run_lib.py:146] step: 372100, training_loss: 7.80320e-02
I0515 21:23:10.429270 22392998065984 run_lib.py:167] step: 372100, eval_loss: 5.64827e-02
I0515 21:23:34.760490 22392998065984 run_lib.py:146] step: 372150, training_loss: 5.86496e-02
I0515 21:23:59.089986 22392998065984 run_lib.py:146] step: 372200, training_loss: 8.32743e-02
I0515 21:23:59.258945 22392998065984 run_lib.py:167] step: 372200, eval_loss: 6.27666e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:24:24.115831 22392998065984 run_lib.py:146] step: 372250, training_loss: 5.45453e-02
I0515 21:24:48.954374 22392998065984 run_lib.py:146] step: 372300, training_loss: 6.41901e-02
I0515 21:24:49.125526 22392998065984 run_lib.py:167] step: 372300, eval_loss: 5.78460e-02
I0515 21:25:13.511112 22392998065984 run_lib.py:146] step: 372350, training_loss: 4.79020e-02
I0515 21:25:38.236882 22392998065984 run_lib.py:146] step: 372400, training_loss: 6.04598e-02
I0515 21:25:38.397162 22392998065984 run_lib.py:167] step: 372400, eval_loss: 6.67516e-02
I0515 21:26:03.244826 22392998065984 run_lib.py:146] step: 372450, training_loss: 6.27643e-02
I0515 21:26:27.609541 22392998065984 run_lib.py:146] step: 372500, training_loss: 5.80864e-02
I0515 21:26:27.792007 22392998065984 run_lib.py:167] step: 372500, eval_loss: 7.50310e-02
I0515 21:26:52.456010 22392998065984 run_lib.py:146] step: 372550, training_loss: 6.97608e-02
I0515 21:27:17.197459 22392998065984 run_lib.py:146] step: 372600, training_loss: 6.60926e-02
I0515 21:27:17.369520 22392998065984 run_lib.py:167] step: 372600, eval_loss: 5.49058e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:27:41.965031 22392998065984 run_lib.py:146] step: 372650, training_loss: 5.32468e-02
I0515 21:28:06.182860 22392998065984 run_lib.py:146] step: 372700, training_loss: 6.96370e-02
I0515 21:28:06.343331 22392998065984 run_lib.py:167] step: 372700, eval_loss: 5.77913e-02
I0515 21:28:31.483319 22392998065984 run_lib.py:146] step: 372750, training_loss: 5.67764e-02
I0515 21:28:55.901821 22392998065984 run_lib.py:146] step: 372800, training_loss: 6.09784e-02
I0515 21:28:56.085676 22392998065984 run_lib.py:167] step: 372800, eval_loss: 5.09240e-02
I0515 21:29:20.689652 22392998065984 run_lib.py:146] step: 372850, training_loss: 5.09059e-02
I0515 21:29:45.221618 22392998065984 run_lib.py:146] step: 372900, training_loss: 7.16316e-02
I0515 21:29:45.383598 22392998065984 run_lib.py:167] step: 372900, eval_loss: 6.41207e-02
I0515 21:30:09.394321 22392998065984 run_lib.py:146] step: 372950, training_loss: 7.53167e-02
I0515 21:30:33.219935 22392998065984 run_lib.py:146] step: 373000, training_loss: 5.03392e-02
I0515 21:30:33.381174 22392998065984 run_lib.py:167] step: 373000, eval_loss: 4.89890e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:30:57.690099 22392998065984 run_lib.py:146] step: 373050, training_loss: 7.42695e-02
I0515 21:31:22.020773 22392998065984 run_lib.py:146] step: 373100, training_loss: 4.96649e-02
I0515 21:31:22.184502 22392998065984 run_lib.py:167] step: 373100, eval_loss: 6.99356e-02
I0515 21:31:46.006259 22392998065984 run_lib.py:146] step: 373150, training_loss: 5.65352e-02
I0515 21:32:10.187137 22392998065984 run_lib.py:146] step: 373200, training_loss: 6.48862e-02
I0515 21:32:10.347987 22392998065984 run_lib.py:167] step: 373200, eval_loss: 6.58982e-02
I0515 21:32:35.104395 22392998065984 run_lib.py:146] step: 373250, training_loss: 7.42114e-02
I0515 21:32:59.556413 22392998065984 run_lib.py:146] step: 373300, training_loss: 6.05277e-02
I0515 21:32:59.725918 22392998065984 run_lib.py:167] step: 373300, eval_loss: 5.63480e-02
I0515 21:33:24.438398 22392998065984 run_lib.py:146] step: 373350, training_loss: 6.37778e-02
I0515 21:33:48.951126 22392998065984 run_lib.py:146] step: 373400, training_loss: 6.22466e-02
I0515 21:33:49.114119 22392998065984 run_lib.py:167] step: 373400, eval_loss: 7.18461e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:34:13.069576 22392998065984 run_lib.py:146] step: 373450, training_loss: 6.39515e-02
I0515 21:34:37.136159 22392998065984 run_lib.py:146] step: 373500, training_loss: 4.31071e-02
I0515 21:34:37.308562 22392998065984 run_lib.py:167] step: 373500, eval_loss: 7.48528e-02
I0515 21:35:02.478830 22392998065984 run_lib.py:146] step: 373550, training_loss: 8.36391e-02
I0515 21:35:27.035315 22392998065984 run_lib.py:146] step: 373600, training_loss: 5.85055e-02
I0515 21:35:27.204857 22392998065984 run_lib.py:167] step: 373600, eval_loss: 6.70862e-02
I0515 21:35:51.274260 22392998065984 run_lib.py:146] step: 373650, training_loss: 6.17436e-02
I0515 21:36:15.692491 22392998065984 run_lib.py:146] step: 373700, training_loss: 6.92282e-02
I0515 21:36:15.850884 22392998065984 run_lib.py:167] step: 373700, eval_loss: 6.97122e-02
I0515 21:36:40.012635 22392998065984 run_lib.py:146] step: 373750, training_loss: 4.94248e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:37:04.290344 22392998065984 run_lib.py:146] step: 373800, training_loss: 5.86911e-02
I0515 21:37:04.469704 22392998065984 run_lib.py:167] step: 373800, eval_loss: 6.36148e-02
I0515 21:37:28.688016 22392998065984 run_lib.py:146] step: 373850, training_loss: 4.65002e-02
I0515 21:37:53.301826 22392998065984 run_lib.py:146] step: 373900, training_loss: 6.45598e-02
I0515 21:37:53.462218 22392998065984 run_lib.py:167] step: 373900, eval_loss: 5.19159e-02
I0515 21:38:17.329205 22392998065984 run_lib.py:146] step: 373950, training_loss: 5.55156e-02
I0515 21:38:41.570359 22392998065984 run_lib.py:146] step: 374000, training_loss: 6.63825e-02
I0515 21:38:41.732342 22392998065984 run_lib.py:167] step: 374000, eval_loss: 5.44686e-02
I0515 21:39:05.858874 22392998065984 run_lib.py:146] step: 374050, training_loss: 5.88581e-02
I0515 21:39:29.700779 22392998065984 run_lib.py:146] step: 374100, training_loss: 6.53943e-02
I0515 21:39:29.860938 22392998065984 run_lib.py:167] step: 374100, eval_loss: 5.30536e-02
I0515 21:39:54.415592 22392998065984 run_lib.py:146] step: 374150, training_loss: 7.73621e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:40:19.108060 22392998065984 run_lib.py:146] step: 374200, training_loss: 5.13324e-02
I0515 21:40:19.270849 22392998065984 run_lib.py:167] step: 374200, eval_loss: 4.94232e-02
I0515 21:40:43.384957 22392998065984 run_lib.py:146] step: 374250, training_loss: 5.16505e-02
I0515 21:41:07.997087 22392998065984 run_lib.py:146] step: 374300, training_loss: 6.81086e-02
I0515 21:41:08.166309 22392998065984 run_lib.py:167] step: 374300, eval_loss: 6.22129e-02
I0515 21:41:32.511411 22392998065984 run_lib.py:146] step: 374350, training_loss: 5.83090e-02
I0515 21:41:56.322458 22392998065984 run_lib.py:146] step: 374400, training_loss: 6.32275e-02
I0515 21:41:56.483577 22392998065984 run_lib.py:167] step: 374400, eval_loss: 4.90063e-02
I0515 21:42:20.563386 22392998065984 run_lib.py:146] step: 374450, training_loss: 5.70210e-02
I0515 21:42:45.071918 22392998065984 run_lib.py:146] step: 374500, training_loss: 7.42850e-02
I0515 21:42:45.232467 22392998065984 run_lib.py:167] step: 374500, eval_loss: 6.31303e-02
I0515 21:43:09.177370 22392998065984 run_lib.py:146] step: 374550, training_loss: 5.58100e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:43:33.634924 22392998065984 run_lib.py:146] step: 374600, training_loss: 4.60389e-02
I0515 21:43:33.805828 22392998065984 run_lib.py:167] step: 374600, eval_loss: 7.16539e-02
I0515 21:43:58.672456 22392998065984 run_lib.py:146] step: 374650, training_loss: 5.77934e-02
I0515 21:44:23.550177 22392998065984 run_lib.py:146] step: 374700, training_loss: 4.43721e-02
I0515 21:44:23.720334 22392998065984 run_lib.py:167] step: 374700, eval_loss: 6.91117e-02
I0515 21:44:48.227937 22392998065984 run_lib.py:146] step: 374750, training_loss: 5.58884e-02
I0515 21:45:12.763444 22392998065984 run_lib.py:146] step: 374800, training_loss: 3.50904e-02
I0515 21:45:12.924460 22392998065984 run_lib.py:167] step: 374800, eval_loss: 7.85327e-02
I0515 21:45:37.074302 22392998065984 run_lib.py:146] step: 374850, training_loss: 5.00472e-02
I0515 21:46:00.955156 22392998065984 run_lib.py:146] step: 374900, training_loss: 6.46190e-02
I0515 21:46:01.116454 22392998065984 run_lib.py:167] step: 374900, eval_loss: 4.53800e-02
I0515 21:46:25.293246 22392998065984 run_lib.py:146] step: 374950, training_loss: 6.69519e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:46:49.659273 22392998065984 run_lib.py:146] step: 375000, training_loss: 5.49005e-02
I0515 21:46:49.823595 22392998065984 run_lib.py:167] step: 375000, eval_loss: 7.47200e-02
I0515 21:47:13.669145 22392998065984 run_lib.py:146] step: 375050, training_loss: 5.89732e-02
I0515 21:47:37.828817 22392998065984 run_lib.py:146] step: 375100, training_loss: 5.91975e-02
I0515 21:47:37.988918 22392998065984 run_lib.py:167] step: 375100, eval_loss: 7.22937e-02
I0515 21:48:02.115569 22392998065984 run_lib.py:146] step: 375150, training_loss: 4.58682e-02
I0515 21:48:25.913475 22392998065984 run_lib.py:146] step: 375200, training_loss: 6.45235e-02
I0515 21:48:26.075733 22392998065984 run_lib.py:167] step: 375200, eval_loss: 5.36943e-02
I0515 21:48:50.206896 22392998065984 run_lib.py:146] step: 375250, training_loss: 4.03648e-02
I0515 21:49:15.276159 22392998065984 run_lib.py:146] step: 375300, training_loss: 6.55661e-02
I0515 21:49:15.439090 22392998065984 run_lib.py:167] step: 375300, eval_loss: 5.44997e-02
I0515 21:49:39.432323 22392998065984 run_lib.py:146] step: 375350, training_loss: 6.13278e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:50:03.803396 22392998065984 run_lib.py:146] step: 375400, training_loss: 4.86200e-02
I0515 21:50:03.967916 22392998065984 run_lib.py:167] step: 375400, eval_loss: 6.02058e-02
I0515 21:50:28.258225 22392998065984 run_lib.py:146] step: 375450, training_loss: 4.96287e-02
I0515 21:50:52.702782 22392998065984 run_lib.py:146] step: 375500, training_loss: 3.90098e-02
I0515 21:50:52.863758 22392998065984 run_lib.py:167] step: 375500, eval_loss: 5.95595e-02
I0515 21:51:16.963356 22392998065984 run_lib.py:146] step: 375550, training_loss: 5.35594e-02
I0515 21:51:41.740375 22392998065984 run_lib.py:146] step: 375600, training_loss: 7.16497e-02
I0515 21:51:41.909801 22392998065984 run_lib.py:167] step: 375600, eval_loss: 5.64897e-02
I0515 21:52:06.674817 22392998065984 run_lib.py:146] step: 375650, training_loss: 6.21200e-02
I0515 21:52:30.537816 22392998065984 run_lib.py:146] step: 375700, training_loss: 6.72155e-02
I0515 21:52:30.708057 22392998065984 run_lib.py:167] step: 375700, eval_loss: 5.87699e-02
I0515 21:52:55.266213 22392998065984 run_lib.py:146] step: 375750, training_loss: 7.17164e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:53:20.403205 22392998065984 run_lib.py:146] step: 375800, training_loss: 5.92169e-02
I0515 21:53:20.574867 22392998065984 run_lib.py:167] step: 375800, eval_loss: 5.94365e-02
I0515 21:53:44.725394 22392998065984 run_lib.py:146] step: 375850, training_loss: 4.90103e-02
I0515 21:54:09.576879 22392998065984 run_lib.py:146] step: 375900, training_loss: 5.11482e-02
I0515 21:54:09.746841 22392998065984 run_lib.py:167] step: 375900, eval_loss: 4.83068e-02
I0515 21:54:34.125373 22392998065984 run_lib.py:146] step: 375950, training_loss: 6.71748e-02
I0515 21:54:58.116938 22392998065984 run_lib.py:146] step: 376000, training_loss: 7.01946e-02
I0515 21:54:58.286573 22392998065984 run_lib.py:167] step: 376000, eval_loss: 5.51789e-02
I0515 21:55:23.100755 22392998065984 run_lib.py:146] step: 376050, training_loss: 4.80825e-02
I0515 21:55:48.036856 22392998065984 run_lib.py:146] step: 376100, training_loss: 5.61490e-02
I0515 21:55:48.207456 22392998065984 run_lib.py:167] step: 376100, eval_loss: 4.67560e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:56:12.899305 22392998065984 run_lib.py:146] step: 376150, training_loss: 6.43977e-02
I0515 21:56:36.730882 22392998065984 run_lib.py:146] step: 376200, training_loss: 6.31213e-02
I0515 21:56:36.893243 22392998065984 run_lib.py:167] step: 376200, eval_loss: 6.85248e-02
I0515 21:57:01.298396 22392998065984 run_lib.py:146] step: 376250, training_loss: 5.59016e-02
I0515 21:57:26.326409 22392998065984 run_lib.py:146] step: 376300, training_loss: 7.38985e-02
I0515 21:57:26.488419 22392998065984 run_lib.py:167] step: 376300, eval_loss: 4.79577e-02
I0515 21:57:50.434224 22392998065984 run_lib.py:146] step: 376350, training_loss: 6.73676e-02
I0515 21:58:15.168314 22392998065984 run_lib.py:146] step: 376400, training_loss: 6.10518e-02
I0515 21:58:15.338883 22392998065984 run_lib.py:167] step: 376400, eval_loss: 7.56549e-02
I0515 21:58:40.218869 22392998065984 run_lib.py:146] step: 376450, training_loss: 6.84302e-02
I0515 21:59:04.715624 22392998065984 run_lib.py:146] step: 376500, training_loss: 4.93486e-02
I0515 21:59:04.876753 22392998065984 run_lib.py:167] step: 376500, eval_loss: 6.43986e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 21:59:29.232849 22392998065984 run_lib.py:146] step: 376550, training_loss: 5.38120e-02
I0515 21:59:53.355276 22392998065984 run_lib.py:146] step: 376600, training_loss: 7.06974e-02
I0515 21:59:53.517188 22392998065984 run_lib.py:167] step: 376600, eval_loss: 6.11859e-02
I0515 22:00:17.400066 22392998065984 run_lib.py:146] step: 376650, training_loss: 8.90457e-02
I0515 22:00:41.919957 22392998065984 run_lib.py:146] step: 376700, training_loss: 6.47316e-02
I0515 22:00:42.082374 22392998065984 run_lib.py:167] step: 376700, eval_loss: 6.42296e-02
I0515 22:01:06.981885 22392998065984 run_lib.py:146] step: 376750, training_loss: 5.32758e-02
I0515 22:01:30.949149 22392998065984 run_lib.py:146] step: 376800, training_loss: 6.51974e-02
I0515 22:01:31.112122 22392998065984 run_lib.py:167] step: 376800, eval_loss: 7.15489e-02
I0515 22:01:56.177647 22392998065984 run_lib.py:146] step: 376850, training_loss: 5.69450e-02
I0515 22:02:20.400879 22392998065984 run_lib.py:146] step: 376900, training_loss: 5.15809e-02
I0515 22:02:20.561282 22392998065984 run_lib.py:167] step: 376900, eval_loss: 6.23275e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:02:44.742451 22392998065984 run_lib.py:146] step: 376950, training_loss: 5.56869e-02
I0515 22:03:08.648919 22392998065984 run_lib.py:146] step: 377000, training_loss: 4.73745e-02
I0515 22:03:08.811181 22392998065984 run_lib.py:167] step: 377000, eval_loss: 5.77476e-02
I0515 22:03:33.253747 22392998065984 run_lib.py:146] step: 377050, training_loss: 5.44047e-02
I0515 22:03:58.426285 22392998065984 run_lib.py:146] step: 377100, training_loss: 6.63273e-02
I0515 22:03:58.597231 22392998065984 run_lib.py:167] step: 377100, eval_loss: 7.13087e-02
I0515 22:04:23.136187 22392998065984 run_lib.py:146] step: 377150, training_loss: 5.13414e-02
I0515 22:04:47.923869 22392998065984 run_lib.py:146] step: 377200, training_loss: 6.16297e-02
I0515 22:04:48.093665 22392998065984 run_lib.py:167] step: 377200, eval_loss: 5.32066e-02
I0515 22:05:13.094295 22392998065984 run_lib.py:146] step: 377250, training_loss: 5.61340e-02
I0515 22:05:37.025932 22392998065984 run_lib.py:146] step: 377300, training_loss: 7.50885e-02
I0515 22:05:37.185647 22392998065984 run_lib.py:167] step: 377300, eval_loss: 5.75023e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:06:01.871384 22392998065984 run_lib.py:146] step: 377350, training_loss: 5.15898e-02
I0515 22:06:26.041199 22392998065984 run_lib.py:146] step: 377400, training_loss: 5.62275e-02
I0515 22:06:26.204070 22392998065984 run_lib.py:167] step: 377400, eval_loss: 7.21911e-02
I0515 22:06:50.190374 22392998065984 run_lib.py:146] step: 377450, training_loss: 6.55970e-02
I0515 22:07:14.335675 22392998065984 run_lib.py:146] step: 377500, training_loss: 4.64228e-02
I0515 22:07:14.495962 22392998065984 run_lib.py:167] step: 377500, eval_loss: 5.50110e-02
I0515 22:07:38.950411 22392998065984 run_lib.py:146] step: 377550, training_loss: 8.21737e-02
I0515 22:08:02.774196 22392998065984 run_lib.py:146] step: 377600, training_loss: 5.16144e-02
I0515 22:08:02.936216 22392998065984 run_lib.py:167] step: 377600, eval_loss: 6.72591e-02
I0515 22:08:27.118301 22392998065984 run_lib.py:146] step: 377650, training_loss: 4.45251e-02
I0515 22:08:51.198410 22392998065984 run_lib.py:146] step: 377700, training_loss: 4.94271e-02
I0515 22:08:51.359387 22392998065984 run_lib.py:167] step: 377700, eval_loss: 5.57418e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:09:15.377405 22392998065984 run_lib.py:146] step: 377750, training_loss: 4.97518e-02
I0515 22:09:39.177011 22392998065984 run_lib.py:146] step: 377800, training_loss: 6.27623e-02
I0515 22:09:39.338217 22392998065984 run_lib.py:167] step: 377800, eval_loss: 4.95808e-02
I0515 22:10:03.543401 22392998065984 run_lib.py:146] step: 377850, training_loss: 5.32175e-02
I0515 22:10:27.641201 22392998065984 run_lib.py:146] step: 377900, training_loss: 5.11968e-02
I0515 22:10:27.801376 22392998065984 run_lib.py:167] step: 377900, eval_loss: 6.53196e-02
I0515 22:10:51.653533 22392998065984 run_lib.py:146] step: 377950, training_loss: 6.09737e-02
I0515 22:11:16.036801 22392998065984 run_lib.py:146] step: 378000, training_loss: 7.17561e-02
I0515 22:11:16.198030 22392998065984 run_lib.py:167] step: 378000, eval_loss: 5.51068e-02
I0515 22:11:40.313416 22392998065984 run_lib.py:146] step: 378050, training_loss: 6.95891e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:12:04.450821 22392998065984 run_lib.py:146] step: 378100, training_loss: 5.29857e-02
I0515 22:12:04.614845 22392998065984 run_lib.py:167] step: 378100, eval_loss: 5.73012e-02
I0515 22:12:28.882180 22392998065984 run_lib.py:146] step: 378150, training_loss: 5.30693e-02
I0515 22:12:53.340723 22392998065984 run_lib.py:146] step: 378200, training_loss: 4.78832e-02
I0515 22:12:53.502023 22392998065984 run_lib.py:167] step: 378200, eval_loss: 6.84850e-02
I0515 22:13:17.456473 22392998065984 run_lib.py:146] step: 378250, training_loss: 4.34998e-02
I0515 22:13:41.612078 22392998065984 run_lib.py:146] step: 378300, training_loss: 7.28827e-02
I0515 22:13:41.788307 22392998065984 run_lib.py:167] step: 378300, eval_loss: 4.98177e-02
I0515 22:14:06.175890 22392998065984 run_lib.py:146] step: 378350, training_loss: 6.40918e-02
I0515 22:14:30.026303 22392998065984 run_lib.py:146] step: 378400, training_loss: 5.53947e-02
I0515 22:14:30.187400 22392998065984 run_lib.py:167] step: 378400, eval_loss: 5.44994e-02
I0515 22:14:54.340801 22392998065984 run_lib.py:146] step: 378450, training_loss: 5.60853e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:15:18.847882 22392998065984 run_lib.py:146] step: 378500, training_loss: 7.31478e-02
I0515 22:15:19.011939 22392998065984 run_lib.py:167] step: 378500, eval_loss: 6.60121e-02
I0515 22:15:43.139503 22392998065984 run_lib.py:146] step: 378550, training_loss: 6.11049e-02
I0515 22:16:06.958402 22392998065984 run_lib.py:146] step: 378600, training_loss: 5.00108e-02
I0515 22:16:07.119690 22392998065984 run_lib.py:167] step: 378600, eval_loss: 7.25529e-02
I0515 22:16:31.989757 22392998065984 run_lib.py:146] step: 378650, training_loss: 7.86841e-02
I0515 22:16:56.277769 22392998065984 run_lib.py:146] step: 378700, training_loss: 6.02289e-02
I0515 22:16:56.447118 22392998065984 run_lib.py:167] step: 378700, eval_loss: 5.58350e-02
I0515 22:17:20.572172 22392998065984 run_lib.py:146] step: 378750, training_loss: 5.31156e-02
I0515 22:17:44.917345 22392998065984 run_lib.py:146] step: 378800, training_loss: 5.32819e-02
I0515 22:17:45.079449 22392998065984 run_lib.py:167] step: 378800, eval_loss: 6.71004e-02
I0515 22:18:09.502726 22392998065984 run_lib.py:146] step: 378850, training_loss: 4.98497e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:18:33.885892 22392998065984 run_lib.py:146] step: 378900, training_loss: 4.93296e-02
I0515 22:18:34.046713 22392998065984 run_lib.py:167] step: 378900, eval_loss: 5.39125e-02
I0515 22:18:58.946117 22392998065984 run_lib.py:146] step: 378950, training_loss: 5.15145e-02
I0515 22:19:23.196692 22392998065984 run_lib.py:146] step: 379000, training_loss: 7.15348e-02
I0515 22:19:23.356284 22392998065984 run_lib.py:167] step: 379000, eval_loss: 5.22990e-02
I0515 22:19:47.336864 22392998065984 run_lib.py:146] step: 379050, training_loss: 5.95430e-02
I0515 22:20:11.645512 22392998065984 run_lib.py:146] step: 379100, training_loss: 5.34953e-02
I0515 22:20:11.735528 22392998065984 run_lib.py:167] step: 379100, eval_loss: 8.48365e-02
I0515 22:20:35.942224 22392998065984 run_lib.py:146] step: 379150, training_loss: 5.49542e-02
I0515 22:20:59.779028 22392998065984 run_lib.py:146] step: 379200, training_loss: 6.16521e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:21:00.220881 22392998065984 run_lib.py:167] step: 379200, eval_loss: 5.26086e-02
I0515 22:21:24.757693 22392998065984 run_lib.py:146] step: 379250, training_loss: 6.04567e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:21:49.811610 22392998065984 run_lib.py:146] step: 379300, training_loss: 6.19855e-02
I0515 22:21:49.984431 22392998065984 run_lib.py:167] step: 379300, eval_loss: 5.98171e-02
I0515 22:22:14.128999 22392998065984 run_lib.py:146] step: 379350, training_loss: 6.66374e-02
I0515 22:22:37.963266 22392998065984 run_lib.py:146] step: 379400, training_loss: 4.61612e-02
I0515 22:22:38.124179 22392998065984 run_lib.py:167] step: 379400, eval_loss: 4.72809e-02
I0515 22:23:03.701457 22392998065984 run_lib.py:146] step: 379450, training_loss: 4.73060e-02
I0515 22:23:27.704229 22392998065984 run_lib.py:146] step: 379500, training_loss: 5.19019e-02
I0515 22:23:27.866694 22392998065984 run_lib.py:167] step: 379500, eval_loss: 7.07740e-02
I0515 22:23:51.733883 22392998065984 run_lib.py:146] step: 379550, training_loss: 5.74716e-02
I0515 22:24:16.156910 22392998065984 run_lib.py:146] step: 379600, training_loss: 5.33947e-02
I0515 22:24:16.323189 22392998065984 run_lib.py:167] step: 379600, eval_loss: 6.01861e-02
I0515 22:24:41.497572 22392998065984 run_lib.py:146] step: 379650, training_loss: 6.08686e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:25:05.523720 22392998065984 run_lib.py:146] step: 379700, training_loss: 7.47241e-02
I0515 22:25:05.688201 22392998065984 run_lib.py:167] step: 379700, eval_loss: 8.07507e-02
I0515 22:25:29.929721 22392998065984 run_lib.py:146] step: 379750, training_loss: 4.82299e-02
I0515 22:25:54.244506 22392998065984 run_lib.py:146] step: 379800, training_loss: 6.12240e-02
I0515 22:25:54.403337 22392998065984 run_lib.py:167] step: 379800, eval_loss: 6.21769e-02
I0515 22:26:18.268382 22392998065984 run_lib.py:146] step: 379850, training_loss: 6.21084e-02
I0515 22:26:42.715059 22392998065984 run_lib.py:146] step: 379900, training_loss: 5.52268e-02
I0515 22:26:42.878036 22392998065984 run_lib.py:167] step: 379900, eval_loss: 6.28981e-02
I0515 22:27:07.436307 22392998065984 run_lib.py:146] step: 379950, training_loss: 4.53805e-02
I0515 22:27:31.616075 22392998065984 run_lib.py:146] step: 380000, training_loss: 7.00230e-02
I0515 22:27:33.776714 22392998065984 run_lib.py:167] step: 380000, eval_loss: 7.56082e-02
I0515 22:28:00.024724 22392998065984 run_lib.py:146] step: 380050, training_loss: 6.17647e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:28:24.549804 22392998065984 run_lib.py:146] step: 380100, training_loss: 5.41683e-02
I0515 22:28:24.712824 22392998065984 run_lib.py:167] step: 380100, eval_loss: 5.70653e-02
I0515 22:28:48.584106 22392998065984 run_lib.py:146] step: 380150, training_loss: 7.64752e-02
I0515 22:29:13.237329 22392998065984 run_lib.py:146] step: 380200, training_loss: 5.88261e-02
I0515 22:29:13.399144 22392998065984 run_lib.py:167] step: 380200, eval_loss: 5.94812e-02
I0515 22:29:38.195350 22392998065984 run_lib.py:146] step: 380250, training_loss: 5.44378e-02
I0515 22:30:02.077211 22392998065984 run_lib.py:146] step: 380300, training_loss: 4.48160e-02
I0515 22:30:02.241728 22392998065984 run_lib.py:167] step: 380300, eval_loss: 5.76750e-02
I0515 22:30:26.384489 22392998065984 run_lib.py:146] step: 380350, training_loss: 7.78694e-02
I0515 22:30:50.213011 22392998065984 run_lib.py:146] step: 380400, training_loss: 4.98429e-02
I0515 22:30:50.372488 22392998065984 run_lib.py:167] step: 380400, eval_loss: 6.50891e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:31:15.502461 22392998065984 run_lib.py:146] step: 380450, training_loss: 8.09234e-02
I0515 22:31:39.724162 22392998065984 run_lib.py:146] step: 380500, training_loss: 6.83977e-02
I0515 22:31:39.902406 22392998065984 run_lib.py:167] step: 380500, eval_loss: 5.06967e-02
I0515 22:32:03.949092 22392998065984 run_lib.py:146] step: 380550, training_loss: 7.00626e-02
I0515 22:32:28.213045 22392998065984 run_lib.py:146] step: 380600, training_loss: 7.57930e-02
I0515 22:32:28.374748 22392998065984 run_lib.py:167] step: 380600, eval_loss: 6.75288e-02
I0515 22:32:52.622486 22392998065984 run_lib.py:146] step: 380650, training_loss: 5.00640e-02
I0515 22:33:16.481397 22392998065984 run_lib.py:146] step: 380700, training_loss: 5.81096e-02
I0515 22:33:16.646830 22392998065984 run_lib.py:167] step: 380700, eval_loss: 5.20402e-02
I0515 22:33:41.422211 22392998065984 run_lib.py:146] step: 380750, training_loss: 5.82117e-02
I0515 22:34:05.933941 22392998065984 run_lib.py:146] step: 380800, training_loss: 5.46371e-02
I0515 22:34:06.104741 22392998065984 run_lib.py:167] step: 380800, eval_loss: 6.26052e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:34:31.041867 22392998065984 run_lib.py:146] step: 380850, training_loss: 5.05812e-02
I0515 22:34:55.203192 22392998065984 run_lib.py:146] step: 380900, training_loss: 7.33901e-02
I0515 22:34:55.365161 22392998065984 run_lib.py:167] step: 380900, eval_loss: 6.89588e-02
I0515 22:35:19.564308 22392998065984 run_lib.py:146] step: 380950, training_loss: 7.31894e-02
I0515 22:35:43.865113 22392998065984 run_lib.py:146] step: 381000, training_loss: 5.30167e-02
I0515 22:35:44.027701 22392998065984 run_lib.py:167] step: 381000, eval_loss: 6.77594e-02
I0515 22:36:08.442716 22392998065984 run_lib.py:146] step: 381050, training_loss: 6.73950e-02
I0515 22:36:32.316039 22392998065984 run_lib.py:146] step: 381100, training_loss: 5.21984e-02
I0515 22:36:32.477901 22392998065984 run_lib.py:167] step: 381100, eval_loss: 6.37199e-02
I0515 22:36:56.642173 22392998065984 run_lib.py:146] step: 381150, training_loss: 4.69354e-02
I0515 22:37:20.459677 22392998065984 run_lib.py:146] step: 381200, training_loss: 7.21850e-02
I0515 22:37:20.620391 22392998065984 run_lib.py:167] step: 381200, eval_loss: 5.57694e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:37:44.939556 22392998065984 run_lib.py:146] step: 381250, training_loss: 7.71104e-02
I0515 22:38:09.086479 22392998065984 run_lib.py:146] step: 381300, training_loss: 7.52226e-02
I0515 22:38:09.248566 22392998065984 run_lib.py:167] step: 381300, eval_loss: 5.22470e-02
I0515 22:38:33.082252 22392998065984 run_lib.py:146] step: 381350, training_loss: 6.58276e-02
I0515 22:38:57.510026 22392998065984 run_lib.py:146] step: 381400, training_loss: 4.45717e-02
I0515 22:38:57.669830 22392998065984 run_lib.py:167] step: 381400, eval_loss: 6.42975e-02
I0515 22:39:22.207842 22392998065984 run_lib.py:146] step: 381450, training_loss: 5.46734e-02
I0515 22:39:46.451985 22392998065984 run_lib.py:146] step: 381500, training_loss: 3.89993e-02
I0515 22:39:46.613022 22392998065984 run_lib.py:167] step: 381500, eval_loss: 4.68522e-02
I0515 22:40:10.785506 22392998065984 run_lib.py:146] step: 381550, training_loss: 5.36856e-02
I0515 22:40:34.933900 22392998065984 run_lib.py:146] step: 381600, training_loss: 4.12678e-02
I0515 22:40:35.094739 22392998065984 run_lib.py:167] step: 381600, eval_loss: 6.83059e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:40:59.651723 22392998065984 run_lib.py:146] step: 381650, training_loss: 5.21695e-02
I0515 22:41:24.108670 22392998065984 run_lib.py:146] step: 381700, training_loss: 4.84892e-02
I0515 22:41:24.280328 22392998065984 run_lib.py:167] step: 381700, eval_loss: 6.00139e-02
I0515 22:41:48.300061 22392998065984 run_lib.py:146] step: 381750, training_loss: 5.53899e-02
I0515 22:42:12.850506 22392998065984 run_lib.py:146] step: 381800, training_loss: 5.84789e-02
I0515 22:42:13.019722 22392998065984 run_lib.py:167] step: 381800, eval_loss: 7.39308e-02
I0515 22:42:37.941015 22392998065984 run_lib.py:146] step: 381850, training_loss: 6.92189e-02
I0515 22:43:02.826270 22392998065984 run_lib.py:146] step: 381900, training_loss: 5.86930e-02
I0515 22:43:02.988320 22392998065984 run_lib.py:167] step: 381900, eval_loss: 6.14146e-02
I0515 22:43:27.288341 22392998065984 run_lib.py:146] step: 381950, training_loss: 6.54602e-02
I0515 22:43:51.356096 22392998065984 run_lib.py:146] step: 382000, training_loss: 5.70202e-02
I0515 22:43:51.517518 22392998065984 run_lib.py:167] step: 382000, eval_loss: 7.40041e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:44:16.418368 22392998065984 run_lib.py:146] step: 382050, training_loss: 5.89782e-02
I0515 22:44:40.650698 22392998065984 run_lib.py:146] step: 382100, training_loss: 7.61369e-02
I0515 22:44:40.814604 22392998065984 run_lib.py:167] step: 382100, eval_loss: 6.44016e-02
I0515 22:45:05.313801 22392998065984 run_lib.py:146] step: 382150, training_loss: 5.00382e-02
I0515 22:45:29.858667 22392998065984 run_lib.py:146] step: 382200, training_loss: 5.57965e-02
I0515 22:45:30.029323 22392998065984 run_lib.py:167] step: 382200, eval_loss: 6.16604e-02
I0515 22:45:54.819756 22392998065984 run_lib.py:146] step: 382250, training_loss: 6.74204e-02
I0515 22:46:19.215355 22392998065984 run_lib.py:146] step: 382300, training_loss: 5.61873e-02
I0515 22:46:19.376990 22392998065984 run_lib.py:167] step: 382300, eval_loss: 5.53613e-02
I0515 22:46:44.268705 22392998065984 run_lib.py:146] step: 382350, training_loss: 5.44294e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:47:09.049158 22392998065984 run_lib.py:146] step: 382400, training_loss: 5.64069e-02
I0515 22:47:09.212882 22392998065984 run_lib.py:167] step: 382400, eval_loss: 5.98087e-02
I0515 22:47:33.523159 22392998065984 run_lib.py:146] step: 382450, training_loss: 5.95182e-02
I0515 22:47:58.243069 22392998065984 run_lib.py:146] step: 382500, training_loss: 5.11915e-02
I0515 22:47:58.414654 22392998065984 run_lib.py:167] step: 382500, eval_loss: 5.00877e-02
I0515 22:48:23.137041 22392998065984 run_lib.py:146] step: 382550, training_loss: 4.16047e-02
I0515 22:48:47.442437 22392998065984 run_lib.py:146] step: 382600, training_loss: 5.46884e-02
I0515 22:48:47.604668 22392998065984 run_lib.py:167] step: 382600, eval_loss: 6.04521e-02
I0515 22:49:12.345030 22392998065984 run_lib.py:146] step: 382650, training_loss: 7.77671e-02
I0515 22:49:36.752929 22392998065984 run_lib.py:146] step: 382700, training_loss: 6.33827e-02
I0515 22:49:36.917565 22392998065984 run_lib.py:167] step: 382700, eval_loss: 7.14590e-02
I0515 22:50:01.589721 22392998065984 run_lib.py:146] step: 382750, training_loss: 4.90375e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:50:26.121789 22392998065984 run_lib.py:146] step: 382800, training_loss: 5.09564e-02
I0515 22:50:26.294151 22392998065984 run_lib.py:167] step: 382800, eval_loss: 7.31540e-02
I0515 22:50:50.810488 22392998065984 run_lib.py:146] step: 382850, training_loss: 6.03965e-02
I0515 22:51:15.580182 22392998065984 run_lib.py:146] step: 382900, training_loss: 6.23920e-02
I0515 22:51:15.749500 22392998065984 run_lib.py:167] step: 382900, eval_loss: 4.90226e-02
I0515 22:51:40.051511 22392998065984 run_lib.py:146] step: 382950, training_loss: 5.31312e-02
I0515 22:52:04.738810 22392998065984 run_lib.py:146] step: 383000, training_loss: 9.12761e-02
I0515 22:52:04.910033 22392998065984 run_lib.py:167] step: 383000, eval_loss: 5.95857e-02
I0515 22:52:29.587611 22392998065984 run_lib.py:146] step: 383050, training_loss: 6.76751e-02
I0515 22:52:53.888919 22392998065984 run_lib.py:146] step: 383100, training_loss: 7.45244e-02
I0515 22:52:54.058783 22392998065984 run_lib.py:167] step: 383100, eval_loss: 5.68081e-02
I0515 22:53:18.731307 22392998065984 run_lib.py:146] step: 383150, training_loss: 4.19540e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:53:43.644129 22392998065984 run_lib.py:146] step: 383200, training_loss: 5.62505e-02
I0515 22:53:43.815595 22392998065984 run_lib.py:167] step: 383200, eval_loss: 7.19825e-02
I0515 22:54:08.347346 22392998065984 run_lib.py:146] step: 383250, training_loss: 4.20082e-02
I0515 22:54:33.203115 22392998065984 run_lib.py:146] step: 383300, training_loss: 4.02650e-02
I0515 22:54:33.365779 22392998065984 run_lib.py:167] step: 383300, eval_loss: 5.49073e-02
I0515 22:54:57.884182 22392998065984 run_lib.py:146] step: 383350, training_loss: 6.87967e-02
I0515 22:55:22.381325 22392998065984 run_lib.py:146] step: 383400, training_loss: 4.79727e-02
I0515 22:55:22.544113 22392998065984 run_lib.py:167] step: 383400, eval_loss: 8.95211e-02
I0515 22:55:47.264679 22392998065984 run_lib.py:146] step: 383450, training_loss: 4.74633e-02
I0515 22:56:11.654077 22392998065984 run_lib.py:146] step: 383500, training_loss: 5.93158e-02
I0515 22:56:11.825143 22392998065984 run_lib.py:167] step: 383500, eval_loss: 9.32159e-02
I0515 22:56:36.661260 22392998065984 run_lib.py:146] step: 383550, training_loss: 5.50613e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 22:57:01.095352 22392998065984 run_lib.py:146] step: 383600, training_loss: 4.92318e-02
I0515 22:57:01.268004 22392998065984 run_lib.py:167] step: 383600, eval_loss: 6.42271e-02
I0515 22:57:25.987127 22392998065984 run_lib.py:146] step: 383650, training_loss: 6.35343e-02
I0515 22:57:50.686008 22392998065984 run_lib.py:146] step: 383700, training_loss: 5.15766e-02
I0515 22:57:50.847453 22392998065984 run_lib.py:167] step: 383700, eval_loss: 5.06845e-02
I0515 22:58:15.208800 22392998065984 run_lib.py:146] step: 383750, training_loss: 6.99102e-02
I0515 22:58:39.989018 22392998065984 run_lib.py:146] step: 383800, training_loss: 5.25920e-02
I0515 22:58:40.172795 22392998065984 run_lib.py:167] step: 383800, eval_loss: 5.53082e-02
I0515 22:59:04.903681 22392998065984 run_lib.py:146] step: 383850, training_loss: 6.46639e-02
I0515 22:59:29.322710 22392998065984 run_lib.py:146] step: 383900, training_loss: 5.04095e-02
I0515 22:59:29.494429 22392998065984 run_lib.py:167] step: 383900, eval_loss: 6.19554e-02
I0515 22:59:54.380198 22392998065984 run_lib.py:146] step: 383950, training_loss: 4.62328e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:00:19.316420 22392998065984 run_lib.py:146] step: 384000, training_loss: 6.50106e-02
I0515 23:00:19.479935 22392998065984 run_lib.py:167] step: 384000, eval_loss: 6.49936e-02
I0515 23:00:43.975741 22392998065984 run_lib.py:146] step: 384050, training_loss: 7.36026e-02
I0515 23:01:08.852014 22392998065984 run_lib.py:146] step: 384100, training_loss: 5.66151e-02
I0515 23:01:09.017315 22392998065984 run_lib.py:167] step: 384100, eval_loss: 4.28254e-02
I0515 23:01:33.575824 22392998065984 run_lib.py:146] step: 384150, training_loss: 5.31207e-02
I0515 23:01:58.007199 22392998065984 run_lib.py:146] step: 384200, training_loss: 6.38743e-02
I0515 23:01:58.177312 22392998065984 run_lib.py:167] step: 384200, eval_loss: 7.95667e-02
I0515 23:02:22.904555 22392998065984 run_lib.py:146] step: 384250, training_loss: 5.37567e-02
I0515 23:02:47.290823 22392998065984 run_lib.py:146] step: 384300, training_loss: 7.55010e-02
I0515 23:02:47.462110 22392998065984 run_lib.py:167] step: 384300, eval_loss: 5.01011e-02
I0515 23:03:12.112244 22392998065984 run_lib.py:146] step: 384350, training_loss: 6.70810e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:03:36.656069 22392998065984 run_lib.py:146] step: 384400, training_loss: 6.91258e-02
I0515 23:03:36.819901 22392998065984 run_lib.py:167] step: 384400, eval_loss: 8.16202e-02
I0515 23:04:01.559390 22392998065984 run_lib.py:146] step: 384450, training_loss: 4.94215e-02
I0515 23:04:26.216064 22392998065984 run_lib.py:146] step: 384500, training_loss: 5.46632e-02
I0515 23:04:26.390494 22392998065984 run_lib.py:167] step: 384500, eval_loss: 7.28405e-02
I0515 23:04:50.697183 22392998065984 run_lib.py:146] step: 384550, training_loss: 4.45617e-02
I0515 23:05:15.291092 22392998065984 run_lib.py:146] step: 384600, training_loss: 5.80035e-02
I0515 23:05:15.453663 22392998065984 run_lib.py:167] step: 384600, eval_loss: 5.47597e-02
I0515 23:05:40.178314 22392998065984 run_lib.py:146] step: 384650, training_loss: 5.16061e-02
I0515 23:06:04.649290 22392998065984 run_lib.py:146] step: 384700, training_loss: 5.47033e-02
I0515 23:06:04.820093 22392998065984 run_lib.py:167] step: 384700, eval_loss: 8.64736e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:06:29.763156 22392998065984 run_lib.py:146] step: 384750, training_loss: 6.30059e-02
I0515 23:06:54.598419 22392998065984 run_lib.py:146] step: 384800, training_loss: 4.56475e-02
I0515 23:06:54.769044 22392998065984 run_lib.py:167] step: 384800, eval_loss: 5.38002e-02
I0515 23:07:19.178479 22392998065984 run_lib.py:146] step: 384850, training_loss: 4.84799e-02
I0515 23:07:43.945678 22392998065984 run_lib.py:146] step: 384900, training_loss: 5.32108e-02
I0515 23:07:44.116020 22392998065984 run_lib.py:167] step: 384900, eval_loss: 8.15385e-02
I0515 23:08:08.819398 22392998065984 run_lib.py:146] step: 384950, training_loss: 6.05236e-02
I0515 23:08:33.200542 22392998065984 run_lib.py:146] step: 385000, training_loss: 5.48733e-02
I0515 23:08:33.362704 22392998065984 run_lib.py:167] step: 385000, eval_loss: 5.92630e-02
I0515 23:08:58.076382 22392998065984 run_lib.py:146] step: 385050, training_loss: 4.95409e-02
I0515 23:09:22.435834 22392998065984 run_lib.py:146] step: 385100, training_loss: 5.01685e-02
I0515 23:09:22.619495 22392998065984 run_lib.py:167] step: 385100, eval_loss: 5.66400e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:09:47.504338 22392998065984 run_lib.py:146] step: 385150, training_loss: 6.63555e-02
I0515 23:10:12.056603 22392998065984 run_lib.py:146] step: 385200, training_loss: 6.84866e-02
I0515 23:10:12.217710 22392998065984 run_lib.py:167] step: 385200, eval_loss: 5.85440e-02
I0515 23:10:37.071202 22392998065984 run_lib.py:146] step: 385250, training_loss: 6.35010e-02
I0515 23:11:01.923271 22392998065984 run_lib.py:146] step: 385300, training_loss: 6.15019e-02
I0515 23:11:02.092990 22392998065984 run_lib.py:167] step: 385300, eval_loss: 5.13702e-02
I0515 23:11:26.429266 22392998065984 run_lib.py:146] step: 385350, training_loss: 5.82384e-02
I0515 23:11:51.170293 22392998065984 run_lib.py:146] step: 385400, training_loss: 7.24784e-02
I0515 23:11:51.343835 22392998065984 run_lib.py:167] step: 385400, eval_loss: 6.66945e-02
I0515 23:12:16.192438 22392998065984 run_lib.py:146] step: 385450, training_loss: 6.10428e-02
I0515 23:12:40.576490 22392998065984 run_lib.py:146] step: 385500, training_loss: 4.52950e-02
I0515 23:12:40.736961 22392998065984 run_lib.py:167] step: 385500, eval_loss: 4.72399e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:13:05.612535 22392998065984 run_lib.py:146] step: 385550, training_loss: 6.03237e-02
I0515 23:13:30.588469 22392998065984 run_lib.py:146] step: 385600, training_loss: 5.81813e-02
I0515 23:13:30.755027 22392998065984 run_lib.py:167] step: 385600, eval_loss: 5.65406e-02
I0515 23:13:55.146543 22392998065984 run_lib.py:146] step: 385650, training_loss: 6.94159e-02
I0515 23:14:19.909257 22392998065984 run_lib.py:146] step: 385700, training_loss: 5.22225e-02
I0515 23:14:20.080585 22392998065984 run_lib.py:167] step: 385700, eval_loss: 6.06458e-02
I0515 23:14:44.875914 22392998065984 run_lib.py:146] step: 385750, training_loss: 4.84334e-02
I0515 23:15:09.188551 22392998065984 run_lib.py:146] step: 385800, training_loss: 5.36381e-02
I0515 23:15:09.363353 22392998065984 run_lib.py:167] step: 385800, eval_loss: 6.72220e-02
I0515 23:15:34.093914 22392998065984 run_lib.py:146] step: 385850, training_loss: 4.93240e-02
I0515 23:15:58.481294 22392998065984 run_lib.py:146] step: 385900, training_loss: 5.77542e-02
I0515 23:15:58.656585 22392998065984 run_lib.py:167] step: 385900, eval_loss: 7.65983e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:16:23.324265 22392998065984 run_lib.py:146] step: 385950, training_loss: 4.01477e-02
I0515 23:16:48.170684 22392998065984 run_lib.py:146] step: 386000, training_loss: 5.30864e-02
I0515 23:16:48.341782 22392998065984 run_lib.py:167] step: 386000, eval_loss: 5.19673e-02
I0515 23:17:12.810420 22392998065984 run_lib.py:146] step: 386050, training_loss: 7.44015e-02
I0515 23:17:37.457379 22392998065984 run_lib.py:146] step: 386100, training_loss: 4.89464e-02
I0515 23:17:37.627076 22392998065984 run_lib.py:167] step: 386100, eval_loss: 6.19301e-02
I0515 23:18:01.942334 22392998065984 run_lib.py:146] step: 386150, training_loss: 6.35346e-02
I0515 23:18:26.592921 22392998065984 run_lib.py:146] step: 386200, training_loss: 7.41058e-02
I0515 23:18:26.764795 22392998065984 run_lib.py:167] step: 386200, eval_loss: 6.41889e-02
I0515 23:18:51.340363 22392998065984 run_lib.py:146] step: 386250, training_loss: 5.29714e-02
I0515 23:19:15.674827 22392998065984 run_lib.py:146] step: 386300, training_loss: 5.22539e-02
I0515 23:19:15.847188 22392998065984 run_lib.py:167] step: 386300, eval_loss: 7.06700e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:19:40.556145 22392998065984 run_lib.py:146] step: 386350, training_loss: 5.68758e-02
I0515 23:20:05.404064 22392998065984 run_lib.py:146] step: 386400, training_loss: 5.43882e-02
I0515 23:20:05.578057 22392998065984 run_lib.py:167] step: 386400, eval_loss: 7.51912e-02
I0515 23:20:29.922242 22392998065984 run_lib.py:146] step: 386450, training_loss: 6.84423e-02
I0515 23:20:54.583961 22392998065984 run_lib.py:146] step: 386500, training_loss: 5.05546e-02
I0515 23:20:54.746218 22392998065984 run_lib.py:167] step: 386500, eval_loss: 7.25209e-02
I0515 23:21:19.405290 22392998065984 run_lib.py:146] step: 386550, training_loss: 4.52453e-02
I0515 23:21:43.756646 22392998065984 run_lib.py:146] step: 386600, training_loss: 4.38247e-02
I0515 23:21:43.922939 22392998065984 run_lib.py:167] step: 386600, eval_loss: 6.09612e-02
I0515 23:22:08.583523 22392998065984 run_lib.py:146] step: 386650, training_loss: 4.32603e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:22:33.171431 22392998065984 run_lib.py:146] step: 386700, training_loss: 5.56074e-02
I0515 23:22:33.420668 22392998065984 run_lib.py:167] step: 386700, eval_loss: 5.06307e-02
I0515 23:22:58.357281 22392998065984 run_lib.py:146] step: 386750, training_loss: 5.58494e-02
I0515 23:23:23.121817 22392998065984 run_lib.py:146] step: 386800, training_loss: 4.45995e-02
I0515 23:23:23.307528 22392998065984 run_lib.py:167] step: 386800, eval_loss: 5.64034e-02
I0515 23:23:48.097819 22392998065984 run_lib.py:146] step: 386850, training_loss: 5.92659e-02
I0515 23:24:12.927716 22392998065984 run_lib.py:146] step: 386900, training_loss: 4.92712e-02
I0515 23:24:13.091076 22392998065984 run_lib.py:167] step: 386900, eval_loss: 5.95946e-02
I0515 23:24:37.433187 22392998065984 run_lib.py:146] step: 386950, training_loss: 6.39010e-02
I0515 23:25:02.124617 22392998065984 run_lib.py:146] step: 387000, training_loss: 5.94854e-02
I0515 23:25:02.215615 22392998065984 run_lib.py:167] step: 387000, eval_loss: 7.95194e-02
I0515 23:25:27.002726 22392998065984 run_lib.py:146] step: 387050, training_loss: 4.71114e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:25:51.498836 22392998065984 run_lib.py:146] step: 387100, training_loss: 3.99662e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:25:51.960604 22392998065984 run_lib.py:167] step: 387100, eval_loss: 6.53163e-02
I0515 23:26:16.718301 22392998065984 run_lib.py:146] step: 387150, training_loss: 5.92350e-02
I0515 23:26:41.432593 22392998065984 run_lib.py:146] step: 387200, training_loss: 4.20064e-02
I0515 23:26:41.606171 22392998065984 run_lib.py:167] step: 387200, eval_loss: 7.49177e-02
I0515 23:27:05.880355 22392998065984 run_lib.py:146] step: 387250, training_loss: 5.12276e-02
I0515 23:27:30.590505 22392998065984 run_lib.py:146] step: 387300, training_loss: 5.17956e-02
I0515 23:27:30.775009 22392998065984 run_lib.py:167] step: 387300, eval_loss: 5.12295e-02
I0515 23:27:55.466409 22392998065984 run_lib.py:146] step: 387350, training_loss: 6.28688e-02
I0515 23:28:19.877733 22392998065984 run_lib.py:146] step: 387400, training_loss: 5.53678e-02
I0515 23:28:20.047752 22392998065984 run_lib.py:167] step: 387400, eval_loss: 6.54280e-02
I0515 23:28:44.785850 22392998065984 run_lib.py:146] step: 387450, training_loss: 5.64842e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:29:09.295090 22392998065984 run_lib.py:146] step: 387500, training_loss: 5.68935e-02
I0515 23:29:09.466462 22392998065984 run_lib.py:167] step: 387500, eval_loss: 4.44540e-02
I0515 23:29:34.354382 22392998065984 run_lib.py:146] step: 387550, training_loss: 5.84252e-02
I0515 23:29:58.756535 22392998065984 run_lib.py:146] step: 387600, training_loss: 6.31171e-02
I0515 23:29:58.918586 22392998065984 run_lib.py:167] step: 387600, eval_loss: 7.53019e-02
I0515 23:30:23.708689 22392998065984 run_lib.py:146] step: 387650, training_loss: 6.74025e-02
I0515 23:30:48.723823 22392998065984 run_lib.py:146] step: 387700, training_loss: 5.70154e-02
I0515 23:30:48.894098 22392998065984 run_lib.py:167] step: 387700, eval_loss: 6.03800e-02
I0515 23:31:13.313298 22392998065984 run_lib.py:146] step: 387750, training_loss: 5.75031e-02
I0515 23:31:38.050700 22392998065984 run_lib.py:146] step: 387800, training_loss: 6.90476e-02
I0515 23:31:38.222615 22392998065984 run_lib.py:167] step: 387800, eval_loss: 6.50962e-02
I0515 23:32:02.957817 22392998065984 run_lib.py:146] step: 387850, training_loss: 4.78129e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:32:27.456300 22392998065984 run_lib.py:146] step: 387900, training_loss: 6.29666e-02
I0515 23:32:27.624124 22392998065984 run_lib.py:167] step: 387900, eval_loss: 6.05586e-02
I0515 23:32:52.436021 22392998065984 run_lib.py:146] step: 387950, training_loss: 7.02491e-02
I0515 23:33:17.191635 22392998065984 run_lib.py:146] step: 388000, training_loss: 5.27350e-02
I0515 23:33:17.362547 22392998065984 run_lib.py:167] step: 388000, eval_loss: 5.28749e-02
I0515 23:33:41.825413 22392998065984 run_lib.py:146] step: 388050, training_loss: 5.80454e-02
I0515 23:34:06.570467 22392998065984 run_lib.py:146] step: 388100, training_loss: 5.72980e-02
I0515 23:34:06.732030 22392998065984 run_lib.py:167] step: 388100, eval_loss: 5.93413e-02
I0515 23:34:31.470990 22392998065984 run_lib.py:146] step: 388150, training_loss: 8.41627e-02
I0515 23:34:55.843009 22392998065984 run_lib.py:146] step: 388200, training_loss: 7.47384e-02
I0515 23:34:56.004551 22392998065984 run_lib.py:167] step: 388200, eval_loss: 6.99805e-02
I0515 23:35:20.810165 22392998065984 run_lib.py:146] step: 388250, training_loss: 5.66885e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:35:45.342728 22392998065984 run_lib.py:146] step: 388300, training_loss: 7.07992e-02
I0515 23:35:45.772510 22392998065984 run_lib.py:167] step: 388300, eval_loss: 5.41899e-02
I0515 23:36:10.673957 22392998065984 run_lib.py:146] step: 388350, training_loss: 5.65819e-02
I0515 23:36:34.992790 22392998065984 run_lib.py:146] step: 388400, training_loss: 5.26631e-02
I0515 23:36:35.154161 22392998065984 run_lib.py:167] step: 388400, eval_loss: 5.83871e-02
I0515 23:36:59.652422 22392998065984 run_lib.py:146] step: 388450, training_loss: 6.07888e-02
I0515 23:37:23.958978 22392998065984 run_lib.py:146] step: 388500, training_loss: 6.14727e-02
I0515 23:37:24.128123 22392998065984 run_lib.py:167] step: 388500, eval_loss: 6.57007e-02
I0515 23:37:48.463854 22392998065984 run_lib.py:146] step: 388550, training_loss: 4.67070e-02
I0515 23:38:13.144876 22392998065984 run_lib.py:146] step: 388600, training_loss: 5.53211e-02
I0515 23:38:13.329851 22392998065984 run_lib.py:167] step: 388600, eval_loss: 6.39843e-02
I0515 23:38:37.938796 22392998065984 run_lib.py:146] step: 388650, training_loss: 6.01310e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:39:02.993377 22392998065984 run_lib.py:146] step: 388700, training_loss: 8.33900e-02
I0515 23:39:03.166385 22392998065984 run_lib.py:167] step: 388700, eval_loss: 4.98764e-02
I0515 23:39:28.074097 22392998065984 run_lib.py:146] step: 388750, training_loss: 4.51576e-02
I0515 23:39:52.959208 22392998065984 run_lib.py:146] step: 388800, training_loss: 4.39443e-02
I0515 23:39:53.129232 22392998065984 run_lib.py:167] step: 388800, eval_loss: 5.83389e-02
I0515 23:40:17.477291 22392998065984 run_lib.py:146] step: 388850, training_loss: 6.53680e-02
I0515 23:40:42.082314 22392998065984 run_lib.py:146] step: 388900, training_loss: 5.98397e-02
I0515 23:40:42.252535 22392998065984 run_lib.py:167] step: 388900, eval_loss: 7.40939e-02
I0515 23:41:06.840101 22392998065984 run_lib.py:146] step: 388950, training_loss: 6.50440e-02
I0515 23:41:31.191672 22392998065984 run_lib.py:146] step: 389000, training_loss: 5.87212e-02
I0515 23:41:31.363039 22392998065984 run_lib.py:167] step: 389000, eval_loss: 5.46108e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:41:56.166934 22392998065984 run_lib.py:146] step: 389050, training_loss: 7.18424e-02
I0515 23:42:20.666077 22392998065984 run_lib.py:146] step: 389100, training_loss: 6.26887e-02
I0515 23:42:20.829497 22392998065984 run_lib.py:167] step: 389100, eval_loss: 4.70876e-02
I0515 23:42:45.658689 22392998065984 run_lib.py:146] step: 389150, training_loss: 6.72897e-02
I0515 23:43:10.353806 22392998065984 run_lib.py:146] step: 389200, training_loss: 4.94457e-02
I0515 23:43:10.536025 22392998065984 run_lib.py:167] step: 389200, eval_loss: 5.83053e-02
I0515 23:43:34.824283 22392998065984 run_lib.py:146] step: 389250, training_loss: 5.53239e-02
I0515 23:43:59.402117 22392998065984 run_lib.py:146] step: 389300, training_loss: 6.73886e-02
I0515 23:43:59.562653 22392998065984 run_lib.py:167] step: 389300, eval_loss: 4.85728e-02
I0515 23:44:23.908371 22392998065984 run_lib.py:146] step: 389350, training_loss: 6.76415e-02
I0515 23:44:48.547421 22392998065984 run_lib.py:146] step: 389400, training_loss: 5.74702e-02
I0515 23:44:48.707996 22392998065984 run_lib.py:167] step: 389400, eval_loss: 6.14299e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:45:13.454590 22392998065984 run_lib.py:146] step: 389450, training_loss: 4.65021e-02
I0515 23:45:37.744163 22392998065984 run_lib.py:146] step: 389500, training_loss: 5.07755e-02
I0515 23:45:37.917491 22392998065984 run_lib.py:167] step: 389500, eval_loss: 6.21651e-02
I0515 23:46:02.735929 22392998065984 run_lib.py:146] step: 389550, training_loss: 5.65589e-02
I0515 23:46:27.422819 22392998065984 run_lib.py:146] step: 389600, training_loss: 6.25353e-02
I0515 23:46:27.583962 22392998065984 run_lib.py:167] step: 389600, eval_loss: 6.15741e-02
I0515 23:46:51.925935 22392998065984 run_lib.py:146] step: 389650, training_loss: 5.34680e-02
I0515 23:47:16.689015 22392998065984 run_lib.py:146] step: 389700, training_loss: 6.25828e-02
I0515 23:47:16.849726 22392998065984 run_lib.py:167] step: 389700, eval_loss: 7.87131e-02
I0515 23:47:41.511991 22392998065984 run_lib.py:146] step: 389750, training_loss: 4.74845e-02
I0515 23:48:05.878625 22392998065984 run_lib.py:146] step: 389800, training_loss: 7.24291e-02
I0515 23:48:06.048227 22392998065984 run_lib.py:167] step: 389800, eval_loss: 6.04051e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:48:31.116569 22392998065984 run_lib.py:146] step: 389850, training_loss: 4.31823e-02
I0515 23:48:55.615203 22392998065984 run_lib.py:146] step: 389900, training_loss: 4.43169e-02
I0515 23:48:55.821922 22392998065984 run_lib.py:167] step: 389900, eval_loss: 6.23590e-02
I0515 23:49:20.310312 22392998065984 run_lib.py:146] step: 389950, training_loss: 4.24209e-02
I0515 23:49:44.861301 22392998065984 run_lib.py:146] step: 390000, training_loss: 6.30937e-02
I0515 23:49:46.768034 22392998065984 run_lib.py:167] step: 390000, eval_loss: 5.29377e-02
I0515 23:50:13.456197 22392998065984 run_lib.py:146] step: 390050, training_loss: 4.76844e-02
I0515 23:50:37.857487 22392998065984 run_lib.py:146] step: 390100, training_loss: 6.38813e-02
I0515 23:50:38.023463 22392998065984 run_lib.py:167] step: 390100, eval_loss: 6.17043e-02
I0515 23:51:02.364546 22392998065984 run_lib.py:146] step: 390150, training_loss: 6.36297e-02
I0515 23:51:27.284159 22392998065984 run_lib.py:146] step: 390200, training_loss: 4.03582e-02
I0515 23:51:27.450870 22392998065984 run_lib.py:167] step: 390200, eval_loss: 5.46855e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:51:51.989564 22392998065984 run_lib.py:146] step: 390250, training_loss: 4.64647e-02
I0515 23:52:16.486690 22392998065984 run_lib.py:146] step: 390300, training_loss: 5.26773e-02
I0515 23:52:16.654000 22392998065984 run_lib.py:167] step: 390300, eval_loss: 7.37700e-02
I0515 23:52:41.650422 22392998065984 run_lib.py:146] step: 390350, training_loss: 5.53274e-02
I0515 23:53:06.020102 22392998065984 run_lib.py:146] step: 390400, training_loss: 5.38786e-02
I0515 23:53:06.202193 22392998065984 run_lib.py:167] step: 390400, eval_loss: 6.34796e-02
I0515 23:53:30.520236 22392998065984 run_lib.py:146] step: 390450, training_loss: 6.75358e-02
I0515 23:53:55.602937 22392998065984 run_lib.py:146] step: 390500, training_loss: 7.24358e-02
I0515 23:53:55.773382 22392998065984 run_lib.py:167] step: 390500, eval_loss: 5.96989e-02
I0515 23:54:20.050097 22392998065984 run_lib.py:146] step: 390550, training_loss: 5.22053e-02
I0515 23:54:44.381686 22392998065984 run_lib.py:146] step: 390600, training_loss: 7.81162e-02
I0515 23:54:44.545220 22392998065984 run_lib.py:167] step: 390600, eval_loss: 6.39520e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:55:09.682500 22392998065984 run_lib.py:146] step: 390650, training_loss: 4.83297e-02
I0515 23:55:33.978642 22392998065984 run_lib.py:146] step: 390700, training_loss: 4.33208e-02
I0515 23:55:34.141065 22392998065984 run_lib.py:167] step: 390700, eval_loss: 6.51795e-02
I0515 23:55:58.510381 22392998065984 run_lib.py:146] step: 390750, training_loss: 3.82650e-02
I0515 23:56:23.284753 22392998065984 run_lib.py:146] step: 390800, training_loss: 4.57055e-02
I0515 23:56:23.446589 22392998065984 run_lib.py:167] step: 390800, eval_loss: 7.35359e-02
I0515 23:56:48.059151 22392998065984 run_lib.py:146] step: 390850, training_loss: 5.29377e-02
I0515 23:57:12.414902 22392998065984 run_lib.py:146] step: 390900, training_loss: 5.03806e-02
I0515 23:57:12.584758 22392998065984 run_lib.py:167] step: 390900, eval_loss: 5.02427e-02
I0515 23:57:36.861516 22392998065984 run_lib.py:146] step: 390950, training_loss: 6.60631e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0515 23:58:02.155365 22392998065984 run_lib.py:146] step: 391000, training_loss: 4.84399e-02
I0515 23:58:02.327974 22392998065984 run_lib.py:167] step: 391000, eval_loss: 6.85967e-02
I0515 23:58:26.549717 22392998065984 run_lib.py:146] step: 391050, training_loss: 5.47225e-02
I0515 23:58:50.959871 22392998065984 run_lib.py:146] step: 391100, training_loss: 5.48569e-02
I0515 23:58:51.120435 22392998065984 run_lib.py:167] step: 391100, eval_loss: 4.92688e-02
I0515 23:59:16.192963 22392998065984 run_lib.py:146] step: 391150, training_loss: 6.52294e-02
I0515 23:59:40.514826 22392998065984 run_lib.py:146] step: 391200, training_loss: 5.09238e-02
I0515 23:59:40.677214 22392998065984 run_lib.py:167] step: 391200, eval_loss: 6.42905e-02
I0516 00:00:04.974870 22392998065984 run_lib.py:146] step: 391250, training_loss: 5.34832e-02
I0516 00:00:29.920037 22392998065984 run_lib.py:146] step: 391300, training_loss: 6.29824e-02
I0516 00:00:30.089055 22392998065984 run_lib.py:167] step: 391300, eval_loss: 6.56630e-02
I0516 00:00:54.337248 22392998065984 run_lib.py:146] step: 391350, training_loss: 4.52905e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:01:18.845424 22392998065984 run_lib.py:146] step: 391400, training_loss: 5.12959e-02
I0516 00:01:19.012687 22392998065984 run_lib.py:167] step: 391400, eval_loss: 6.53840e-02
I0516 00:01:44.220690 22392998065984 run_lib.py:146] step: 391450, training_loss: 5.40719e-02
I0516 00:02:08.778575 22392998065984 run_lib.py:146] step: 391500, training_loss: 6.71440e-02
I0516 00:02:08.992817 22392998065984 run_lib.py:167] step: 391500, eval_loss: 5.72660e-02
I0516 00:02:33.182435 22392998065984 run_lib.py:146] step: 391550, training_loss: 3.93633e-02
I0516 00:02:57.814888 22392998065984 run_lib.py:146] step: 391600, training_loss: 5.52899e-02
I0516 00:02:57.976711 22392998065984 run_lib.py:167] step: 391600, eval_loss: 6.11184e-02
I0516 00:03:22.697733 22392998065984 run_lib.py:146] step: 391650, training_loss: 5.08247e-02
I0516 00:03:47.083294 22392998065984 run_lib.py:146] step: 391700, training_loss: 6.86282e-02
I0516 00:03:47.253578 22392998065984 run_lib.py:167] step: 391700, eval_loss: 6.59607e-02
I0516 00:04:11.960441 22392998065984 run_lib.py:146] step: 391750, training_loss: 4.79896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:04:36.654002 22392998065984 run_lib.py:146] step: 391800, training_loss: 5.90683e-02
I0516 00:04:36.825572 22392998065984 run_lib.py:167] step: 391800, eval_loss: 5.59451e-02
I0516 00:05:01.270790 22392998065984 run_lib.py:146] step: 391850, training_loss: 5.19092e-02
I0516 00:05:25.733356 22392998065984 run_lib.py:146] step: 391900, training_loss: 6.62603e-02
I0516 00:05:25.893153 22392998065984 run_lib.py:167] step: 391900, eval_loss: 8.69027e-02
I0516 00:05:50.971539 22392998065984 run_lib.py:146] step: 391950, training_loss: 4.89959e-02
I0516 00:06:15.339589 22392998065984 run_lib.py:146] step: 392000, training_loss: 5.18945e-02
I0516 00:06:15.511718 22392998065984 run_lib.py:167] step: 392000, eval_loss: 4.59570e-02
I0516 00:06:39.755159 22392998065984 run_lib.py:146] step: 392050, training_loss: 4.46944e-02
I0516 00:07:04.703461 22392998065984 run_lib.py:146] step: 392100, training_loss: 5.78392e-02
I0516 00:07:04.874663 22392998065984 run_lib.py:167] step: 392100, eval_loss: 5.10044e-02
I0516 00:07:29.168088 22392998065984 run_lib.py:146] step: 392150, training_loss: 5.84235e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:07:53.493074 22392998065984 run_lib.py:146] step: 392200, training_loss: 6.48675e-02
I0516 00:07:53.657385 22392998065984 run_lib.py:167] step: 392200, eval_loss: 7.33537e-02
I0516 00:08:18.805069 22392998065984 run_lib.py:146] step: 392250, training_loss: 5.60948e-02
I0516 00:08:43.113059 22392998065984 run_lib.py:146] step: 392300, training_loss: 6.58050e-02
I0516 00:08:43.275434 22392998065984 run_lib.py:167] step: 392300, eval_loss: 8.09113e-02
I0516 00:09:07.274951 22392998065984 run_lib.py:146] step: 392350, training_loss: 5.38347e-02
I0516 00:09:32.035604 22392998065984 run_lib.py:146] step: 392400, training_loss: 7.36738e-02
I0516 00:09:32.204819 22392998065984 run_lib.py:167] step: 392400, eval_loss: 6.89288e-02
I0516 00:09:56.843252 22392998065984 run_lib.py:146] step: 392450, training_loss: 5.37076e-02
I0516 00:10:21.096037 22392998065984 run_lib.py:146] step: 392500, training_loss: 4.69373e-02
I0516 00:10:21.255709 22392998065984 run_lib.py:167] step: 392500, eval_loss: 7.65433e-02
I0516 00:10:46.096477 22392998065984 run_lib.py:146] step: 392550, training_loss: 6.16682e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:11:11.076394 22392998065984 run_lib.py:146] step: 392600, training_loss: 4.82434e-02
I0516 00:11:11.239962 22392998065984 run_lib.py:167] step: 392600, eval_loss: 8.07161e-02
I0516 00:11:35.013115 22392998065984 run_lib.py:146] step: 392650, training_loss: 6.08024e-02
I0516 00:11:59.293584 22392998065984 run_lib.py:146] step: 392700, training_loss: 6.66674e-02
I0516 00:11:59.453332 22392998065984 run_lib.py:167] step: 392700, eval_loss: 5.69399e-02
I0516 00:12:24.129176 22392998065984 run_lib.py:146] step: 392750, training_loss: 4.11850e-02
I0516 00:12:48.049891 22392998065984 run_lib.py:146] step: 392800, training_loss: 5.37866e-02
I0516 00:12:48.212240 22392998065984 run_lib.py:167] step: 392800, eval_loss: 5.13810e-02
I0516 00:13:12.167158 22392998065984 run_lib.py:146] step: 392850, training_loss: 4.54703e-02
I0516 00:13:36.710833 22392998065984 run_lib.py:146] step: 392900, training_loss: 5.59015e-02
I0516 00:13:36.873810 22392998065984 run_lib.py:167] step: 392900, eval_loss: 5.98522e-02
I0516 00:14:01.638783 22392998065984 run_lib.py:146] step: 392950, training_loss: 6.61534e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:14:26.244147 22392998065984 run_lib.py:146] step: 393000, training_loss: 5.42963e-02
I0516 00:14:26.411870 22392998065984 run_lib.py:167] step: 393000, eval_loss: 5.05826e-02
I0516 00:14:51.483342 22392998065984 run_lib.py:146] step: 393050, training_loss: 4.68938e-02
I0516 00:15:15.774371 22392998065984 run_lib.py:146] step: 393100, training_loss: 5.64893e-02
I0516 00:15:15.945122 22392998065984 run_lib.py:167] step: 393100, eval_loss: 5.96538e-02
I0516 00:15:40.345797 22392998065984 run_lib.py:146] step: 393150, training_loss: 3.88923e-02
I0516 00:16:04.859624 22392998065984 run_lib.py:146] step: 393200, training_loss: 5.97758e-02
I0516 00:16:05.022348 22392998065984 run_lib.py:167] step: 393200, eval_loss: 5.27110e-02
I0516 00:16:29.629375 22392998065984 run_lib.py:146] step: 393250, training_loss: 5.55302e-02
I0516 00:16:53.885785 22392998065984 run_lib.py:146] step: 393300, training_loss: 7.37014e-02
I0516 00:16:54.045837 22392998065984 run_lib.py:167] step: 393300, eval_loss: 6.71652e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:17:18.892189 22392998065984 run_lib.py:146] step: 393350, training_loss: 5.56624e-02
I0516 00:17:43.167298 22392998065984 run_lib.py:146] step: 393400, training_loss: 5.63022e-02
I0516 00:17:43.329343 22392998065984 run_lib.py:167] step: 393400, eval_loss: 7.89651e-02
I0516 00:18:07.265235 22392998065984 run_lib.py:146] step: 393450, training_loss: 8.04582e-02
I0516 00:18:31.097687 22392998065984 run_lib.py:146] step: 393500, training_loss: 4.59808e-02
I0516 00:18:31.259622 22392998065984 run_lib.py:167] step: 393500, eval_loss: 5.45971e-02
I0516 00:18:56.146014 22392998065984 run_lib.py:146] step: 393550, training_loss: 6.87318e-02
I0516 00:19:20.396687 22392998065984 run_lib.py:146] step: 393600, training_loss: 6.60034e-02
I0516 00:19:20.558550 22392998065984 run_lib.py:167] step: 393600, eval_loss: 5.70339e-02
I0516 00:19:44.422956 22392998065984 run_lib.py:146] step: 393650, training_loss: 5.71027e-02
I0516 00:20:09.487490 22392998065984 run_lib.py:146] step: 393700, training_loss: 4.92506e-02
I0516 00:20:09.655476 22392998065984 run_lib.py:167] step: 393700, eval_loss: 5.47791e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:20:34.246737 22392998065984 run_lib.py:146] step: 393750, training_loss: 5.83359e-02
I0516 00:20:58.656037 22392998065984 run_lib.py:146] step: 393800, training_loss: 5.11621e-02
I0516 00:20:58.827242 22392998065984 run_lib.py:167] step: 393800, eval_loss: 5.29552e-02
I0516 00:21:23.990102 22392998065984 run_lib.py:146] step: 393850, training_loss: 6.15114e-02
I0516 00:21:48.434714 22392998065984 run_lib.py:146] step: 393900, training_loss: 5.67578e-02
I0516 00:21:48.605350 22392998065984 run_lib.py:167] step: 393900, eval_loss: 5.26275e-02
I0516 00:22:12.965330 22392998065984 run_lib.py:146] step: 393950, training_loss: 5.40190e-02
I0516 00:22:37.993780 22392998065984 run_lib.py:146] step: 394000, training_loss: 5.34678e-02
I0516 00:22:38.164914 22392998065984 run_lib.py:167] step: 394000, eval_loss: 5.62268e-02
I0516 00:23:02.491384 22392998065984 run_lib.py:146] step: 394050, training_loss: 6.38994e-02
I0516 00:23:26.835566 22392998065984 run_lib.py:146] step: 394100, training_loss: 6.48144e-02
I0516 00:23:26.995757 22392998065984 run_lib.py:167] step: 394100, eval_loss: 5.05179e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:23:51.547004 22392998065984 run_lib.py:146] step: 394150, training_loss: 5.96083e-02
I0516 00:24:16.707620 22392998065984 run_lib.py:146] step: 394200, training_loss: 7.27149e-02
I0516 00:24:16.879611 22392998065984 run_lib.py:167] step: 394200, eval_loss: 5.03555e-02
I0516 00:24:41.259884 22392998065984 run_lib.py:146] step: 394250, training_loss: 4.59939e-02
I0516 00:25:05.479066 22392998065984 run_lib.py:146] step: 394300, training_loss: 5.39386e-02
I0516 00:25:05.638956 22392998065984 run_lib.py:167] step: 394300, eval_loss: 7.39253e-02
I0516 00:25:30.302380 22392998065984 run_lib.py:146] step: 394350, training_loss: 5.77004e-02
I0516 00:25:54.708583 22392998065984 run_lib.py:146] step: 394400, training_loss: 6.26801e-02
I0516 00:25:54.884157 22392998065984 run_lib.py:167] step: 394400, eval_loss: 4.02092e-02
I0516 00:26:19.111032 22392998065984 run_lib.py:146] step: 394450, training_loss: 6.08634e-02
I0516 00:26:44.293355 22392998065984 run_lib.py:146] step: 394500, training_loss: 5.52219e-02
I0516 00:26:44.454099 22392998065984 run_lib.py:167] step: 394500, eval_loss: 7.83689e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:27:08.565912 22392998065984 run_lib.py:146] step: 394550, training_loss: 5.48881e-02
I0516 00:27:32.349643 22392998065984 run_lib.py:146] step: 394600, training_loss: 5.15859e-02
I0516 00:27:32.511374 22392998065984 run_lib.py:167] step: 394600, eval_loss: 4.57324e-02
I0516 00:27:57.049000 22392998065984 run_lib.py:146] step: 394650, training_loss: 4.38334e-02
I0516 00:28:21.124802 22392998065984 run_lib.py:146] step: 394700, training_loss: 5.68237e-02
I0516 00:28:21.294181 22392998065984 run_lib.py:167] step: 394700, eval_loss: 5.78149e-02
I0516 00:28:45.767731 22392998065984 run_lib.py:146] step: 394750, training_loss: 7.67614e-02
I0516 00:29:10.810185 22392998065984 run_lib.py:146] step: 394800, training_loss: 6.37422e-02
I0516 00:29:10.980506 22392998065984 run_lib.py:167] step: 394800, eval_loss: 6.73924e-02
I0516 00:29:35.211856 22392998065984 run_lib.py:146] step: 394850, training_loss: 7.09732e-02
I0516 00:29:59.022243 22392998065984 run_lib.py:146] step: 394900, training_loss: 4.84506e-02
I0516 00:29:59.122727 22392998065984 run_lib.py:167] step: 394900, eval_loss: 8.57913e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:30:23.333651 22392998065984 run_lib.py:146] step: 394950, training_loss: 5.69761e-02
I0516 00:30:47.836180 22392998065984 run_lib.py:146] step: 395000, training_loss: 4.76623e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:30:48.271573 22392998065984 run_lib.py:167] step: 395000, eval_loss: 6.75998e-02
I0516 00:31:12.738131 22392998065984 run_lib.py:146] step: 395050, training_loss: 4.98744e-02
I0516 00:31:37.172362 22392998065984 run_lib.py:146] step: 395100, training_loss: 7.02421e-02
I0516 00:31:37.341916 22392998065984 run_lib.py:167] step: 395100, eval_loss: 5.44173e-02
I0516 00:32:02.522556 22392998065984 run_lib.py:146] step: 395150, training_loss: 9.31280e-02
I0516 00:32:26.876091 22392998065984 run_lib.py:146] step: 395200, training_loss: 6.41956e-02
I0516 00:32:27.036209 22392998065984 run_lib.py:167] step: 395200, eval_loss: 6.67686e-02
I0516 00:32:50.910596 22392998065984 run_lib.py:146] step: 395250, training_loss: 7.13522e-02
I0516 00:33:15.206935 22392998065984 run_lib.py:146] step: 395300, training_loss: 4.07170e-02
I0516 00:33:15.481115 22392998065984 run_lib.py:167] step: 395300, eval_loss: 6.88988e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:33:39.562819 22392998065984 run_lib.py:146] step: 395350, training_loss: 6.71544e-02
I0516 00:34:03.397610 22392998065984 run_lib.py:146] step: 395400, training_loss: 4.68744e-02
I0516 00:34:03.557595 22392998065984 run_lib.py:167] step: 395400, eval_loss: 6.28124e-02
I0516 00:34:28.139470 22392998065984 run_lib.py:146] step: 395450, training_loss: 5.70721e-02
I0516 00:34:51.940893 22392998065984 run_lib.py:146] step: 395500, training_loss: 4.68950e-02
I0516 00:34:52.100213 22392998065984 run_lib.py:167] step: 395500, eval_loss: 5.74570e-02
I0516 00:35:15.863758 22392998065984 run_lib.py:146] step: 395550, training_loss: 5.46918e-02
I0516 00:35:40.254312 22392998065984 run_lib.py:146] step: 395600, training_loss: 6.21242e-02
I0516 00:35:40.416252 22392998065984 run_lib.py:167] step: 395600, eval_loss: 8.19919e-02
I0516 00:36:04.176654 22392998065984 run_lib.py:146] step: 395650, training_loss: 6.64208e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:36:28.109811 22392998065984 run_lib.py:146] step: 395700, training_loss: 4.37585e-02
I0516 00:36:28.274060 22392998065984 run_lib.py:167] step: 395700, eval_loss: 4.54597e-02
I0516 00:36:52.567070 22392998065984 run_lib.py:146] step: 395750, training_loss: 4.95678e-02
I0516 00:37:16.819510 22392998065984 run_lib.py:146] step: 395800, training_loss: 6.64306e-02
I0516 00:37:16.988530 22392998065984 run_lib.py:167] step: 395800, eval_loss: 5.73015e-02
I0516 00:37:41.437109 22392998065984 run_lib.py:146] step: 395850, training_loss: 7.87915e-02
I0516 00:38:05.878189 22392998065984 run_lib.py:146] step: 395900, training_loss: 5.67812e-02
I0516 00:38:06.047443 22392998065984 run_lib.py:167] step: 395900, eval_loss: 4.60939e-02
I0516 00:38:31.157140 22392998065984 run_lib.py:146] step: 395950, training_loss: 6.73175e-02
I0516 00:38:55.595506 22392998065984 run_lib.py:146] step: 396000, training_loss: 7.12636e-02
I0516 00:38:55.765345 22392998065984 run_lib.py:167] step: 396000, eval_loss: 5.72479e-02
I0516 00:39:19.718560 22392998065984 run_lib.py:146] step: 396050, training_loss: 6.28917e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:39:44.976125 22392998065984 run_lib.py:146] step: 396100, training_loss: 5.57504e-02
I0516 00:39:45.139157 22392998065984 run_lib.py:167] step: 396100, eval_loss: 4.64249e-02
I0516 00:40:08.981455 22392998065984 run_lib.py:146] step: 396150, training_loss: 5.71498e-02
I0516 00:40:33.142202 22392998065984 run_lib.py:146] step: 396200, training_loss: 4.86328e-02
I0516 00:40:33.301249 22392998065984 run_lib.py:167] step: 396200, eval_loss: 7.49415e-02
I0516 00:40:58.350046 22392998065984 run_lib.py:146] step: 396250, training_loss: 5.62049e-02
I0516 00:41:22.718767 22392998065984 run_lib.py:146] step: 396300, training_loss: 5.23813e-02
I0516 00:41:22.888605 22392998065984 run_lib.py:167] step: 396300, eval_loss: 5.72544e-02
I0516 00:41:47.235152 22392998065984 run_lib.py:146] step: 396350, training_loss: 6.02762e-02
I0516 00:42:12.162403 22392998065984 run_lib.py:146] step: 396400, training_loss: 7.41628e-02
I0516 00:42:12.331206 22392998065984 run_lib.py:167] step: 396400, eval_loss: 9.88563e-02
I0516 00:42:36.655401 22392998065984 run_lib.py:146] step: 396450, training_loss: 5.43448e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:43:01.213074 22392998065984 run_lib.py:146] step: 396500, training_loss: 5.46733e-02
I0516 00:43:01.376312 22392998065984 run_lib.py:167] step: 396500, eval_loss: 7.22128e-02
I0516 00:43:25.825059 22392998065984 run_lib.py:146] step: 396550, training_loss: 7.92319e-02
I0516 00:43:50.698993 22392998065984 run_lib.py:146] step: 396600, training_loss: 5.26560e-02
I0516 00:43:50.868121 22392998065984 run_lib.py:167] step: 396600, eval_loss: 6.96523e-02
I0516 00:44:15.312174 22392998065984 run_lib.py:146] step: 396650, training_loss: 4.47398e-02
I0516 00:44:39.644332 22392998065984 run_lib.py:146] step: 396700, training_loss: 4.57689e-02
I0516 00:44:39.804764 22392998065984 run_lib.py:167] step: 396700, eval_loss: 6.75885e-02
I0516 00:45:04.773899 22392998065984 run_lib.py:146] step: 396750, training_loss: 5.45526e-02
I0516 00:45:29.101012 22392998065984 run_lib.py:146] step: 396800, training_loss: 4.98806e-02
I0516 00:45:29.271488 22392998065984 run_lib.py:167] step: 396800, eval_loss: 5.54962e-02
I0516 00:45:53.588181 22392998065984 run_lib.py:146] step: 396850, training_loss: 5.60320e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:46:18.648212 22392998065984 run_lib.py:146] step: 396900, training_loss: 6.05342e-02
I0516 00:46:18.808990 22392998065984 run_lib.py:167] step: 396900, eval_loss: 7.36121e-02
I0516 00:46:43.206757 22392998065984 run_lib.py:146] step: 396950, training_loss: 4.19317e-02
I0516 00:47:07.610715 22392998065984 run_lib.py:146] step: 397000, training_loss: 5.62558e-02
I0516 00:47:07.771232 22392998065984 run_lib.py:167] step: 397000, eval_loss: 6.12696e-02
I0516 00:47:32.827089 22392998065984 run_lib.py:146] step: 397050, training_loss: 6.75462e-02
I0516 00:47:56.826115 22392998065984 run_lib.py:146] step: 397100, training_loss: 6.04003e-02
I0516 00:47:57.002212 22392998065984 run_lib.py:167] step: 397100, eval_loss: 6.73558e-02
I0516 00:48:21.257843 22392998065984 run_lib.py:146] step: 397150, training_loss: 5.14146e-02
I0516 00:48:46.073295 22392998065984 run_lib.py:146] step: 397200, training_loss: 7.58945e-02
I0516 00:48:46.233733 22392998065984 run_lib.py:167] step: 397200, eval_loss: 7.22963e-02
I0516 00:49:10.920249 22392998065984 run_lib.py:146] step: 397250, training_loss: 4.90186e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:49:35.517449 22392998065984 run_lib.py:146] step: 397300, training_loss: 4.57567e-02
I0516 00:49:35.689180 22392998065984 run_lib.py:167] step: 397300, eval_loss: 6.70837e-02
I0516 00:50:00.499133 22392998065984 run_lib.py:146] step: 397350, training_loss: 4.73620e-02
I0516 00:50:25.266210 22392998065984 run_lib.py:146] step: 397400, training_loss: 6.47841e-02
I0516 00:50:25.436838 22392998065984 run_lib.py:167] step: 397400, eval_loss: 5.57914e-02
I0516 00:50:49.695004 22392998065984 run_lib.py:146] step: 397450, training_loss: 6.02127e-02
I0516 00:51:13.937556 22392998065984 run_lib.py:146] step: 397500, training_loss: 4.65795e-02
I0516 00:51:14.099730 22392998065984 run_lib.py:167] step: 397500, eval_loss: 4.91582e-02
I0516 00:51:39.197599 22392998065984 run_lib.py:146] step: 397550, training_loss: 7.98448e-02
I0516 00:52:03.476512 22392998065984 run_lib.py:146] step: 397600, training_loss: 5.06123e-02
I0516 00:52:03.647979 22392998065984 run_lib.py:167] step: 397600, eval_loss: 8.19539e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:52:28.115138 22392998065984 run_lib.py:146] step: 397650, training_loss: 6.19206e-02
I0516 00:52:52.913567 22392998065984 run_lib.py:146] step: 397700, training_loss: 6.05843e-02
I0516 00:52:53.085227 22392998065984 run_lib.py:167] step: 397700, eval_loss: 5.49689e-02
I0516 00:53:17.129227 22392998065984 run_lib.py:146] step: 397750, training_loss: 6.62250e-02
I0516 00:53:41.204559 22392998065984 run_lib.py:146] step: 397800, training_loss: 5.13140e-02
I0516 00:53:41.366431 22392998065984 run_lib.py:167] step: 397800, eval_loss: 6.84588e-02
I0516 00:54:05.784914 22392998065984 run_lib.py:146] step: 397850, training_loss: 6.38573e-02
I0516 00:54:29.564761 22392998065984 run_lib.py:146] step: 397900, training_loss: 6.25221e-02
I0516 00:54:29.724602 22392998065984 run_lib.py:167] step: 397900, eval_loss: 6.03315e-02
I0516 00:54:53.487541 22392998065984 run_lib.py:146] step: 397950, training_loss: 6.35000e-02
I0516 00:55:18.510896 22392998065984 run_lib.py:146] step: 398000, training_loss: 4.60873e-02
I0516 00:55:18.676730 22392998065984 run_lib.py:167] step: 398000, eval_loss: 7.43599e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:55:42.705044 22392998065984 run_lib.py:146] step: 398050, training_loss: 5.82301e-02
I0516 00:56:06.552275 22392998065984 run_lib.py:146] step: 398100, training_loss: 5.90996e-02
I0516 00:56:06.714556 22392998065984 run_lib.py:167] step: 398100, eval_loss: 7.05168e-02
I0516 00:56:30.856199 22392998065984 run_lib.py:146] step: 398150, training_loss: 6.82853e-02
I0516 00:56:55.035813 22392998065984 run_lib.py:146] step: 398200, training_loss: 4.49978e-02
I0516 00:56:55.204804 22392998065984 run_lib.py:167] step: 398200, eval_loss: 5.05890e-02
I0516 00:57:19.324167 22392998065984 run_lib.py:146] step: 398250, training_loss: 5.36853e-02
I0516 00:57:43.113939 22392998065984 run_lib.py:146] step: 398300, training_loss: 5.39295e-02
I0516 00:57:43.273464 22392998065984 run_lib.py:167] step: 398300, eval_loss: 6.61883e-02
I0516 00:58:07.628874 22392998065984 run_lib.py:146] step: 398350, training_loss: 5.04584e-02
I0516 00:58:31.430256 22392998065984 run_lib.py:146] step: 398400, training_loss: 4.47171e-02
I0516 00:58:31.591822 22392998065984 run_lib.py:167] step: 398400, eval_loss: 5.81586e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 00:58:55.670789 22392998065984 run_lib.py:146] step: 398450, training_loss: 5.47421e-02
I0516 00:59:20.229260 22392998065984 run_lib.py:146] step: 398500, training_loss: 7.76560e-02
I0516 00:59:20.389714 22392998065984 run_lib.py:167] step: 398500, eval_loss: 6.12454e-02
I0516 00:59:44.243343 22392998065984 run_lib.py:146] step: 398550, training_loss: 5.88612e-02
I0516 01:00:08.699597 22392998065984 run_lib.py:146] step: 398600, training_loss: 5.61144e-02
I0516 01:00:08.869687 22392998065984 run_lib.py:167] step: 398600, eval_loss: 6.09088e-02
I0516 01:00:33.558832 22392998065984 run_lib.py:146] step: 398650, training_loss: 4.72276e-02
I0516 01:00:57.365646 22392998065984 run_lib.py:146] step: 398700, training_loss: 6.36308e-02
I0516 01:00:57.526057 22392998065984 run_lib.py:167] step: 398700, eval_loss: 5.39268e-02
I0516 01:01:21.332178 22392998065984 run_lib.py:146] step: 398750, training_loss: 6.78237e-02
I0516 01:01:45.767145 22392998065984 run_lib.py:146] step: 398800, training_loss: 5.66598e-02
I0516 01:01:45.926664 22392998065984 run_lib.py:167] step: 398800, eval_loss: 5.52891e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:02:09.833730 22392998065984 run_lib.py:146] step: 398850, training_loss: 5.35873e-02
I0516 01:02:33.690835 22392998065984 run_lib.py:146] step: 398900, training_loss: 5.90579e-02
I0516 01:02:33.853031 22392998065984 run_lib.py:167] step: 398900, eval_loss: 6.16964e-02
I0516 01:02:58.309063 22392998065984 run_lib.py:146] step: 398950, training_loss: 6.89172e-02
I0516 01:03:23.131452 22392998065984 run_lib.py:146] step: 399000, training_loss: 4.97991e-02
I0516 01:03:23.301478 22392998065984 run_lib.py:167] step: 399000, eval_loss: 6.56893e-02
I0516 01:03:47.657681 22392998065984 run_lib.py:146] step: 399050, training_loss: 5.33080e-02
I0516 01:04:12.490250 22392998065984 run_lib.py:146] step: 399100, training_loss: 5.68210e-02
I0516 01:04:12.650503 22392998065984 run_lib.py:167] step: 399100, eval_loss: 5.52632e-02
I0516 01:04:36.781579 22392998065984 run_lib.py:146] step: 399150, training_loss: 4.88494e-02
I0516 01:05:01.285806 22392998065984 run_lib.py:146] step: 399200, training_loss: 5.32189e-02
I0516 01:05:01.455154 22392998065984 run_lib.py:167] step: 399200, eval_loss: 5.75429e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:05:25.796246 22392998065984 run_lib.py:146] step: 399250, training_loss: 4.95928e-02
I0516 01:05:51.125963 22392998065984 run_lib.py:146] step: 399300, training_loss: 6.83068e-02
I0516 01:05:51.300260 22392998065984 run_lib.py:167] step: 399300, eval_loss: 6.81088e-02
I0516 01:06:15.767019 22392998065984 run_lib.py:146] step: 399350, training_loss: 5.77070e-02
I0516 01:06:40.196539 22392998065984 run_lib.py:146] step: 399400, training_loss: 4.76243e-02
I0516 01:06:40.364901 22392998065984 run_lib.py:167] step: 399400, eval_loss: 5.68315e-02
I0516 01:07:05.133965 22392998065984 run_lib.py:146] step: 399450, training_loss: 4.75091e-02
I0516 01:07:28.945498 22392998065984 run_lib.py:146] step: 399500, training_loss: 5.24281e-02
I0516 01:07:29.105642 22392998065984 run_lib.py:167] step: 399500, eval_loss: 5.96967e-02
I0516 01:07:52.861848 22392998065984 run_lib.py:146] step: 399550, training_loss: 4.53089e-02
I0516 01:08:17.280071 22392998065984 run_lib.py:146] step: 399600, training_loss: 5.01794e-02
I0516 01:08:17.439980 22392998065984 run_lib.py:167] step: 399600, eval_loss: 5.43882e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:08:41.476262 22392998065984 run_lib.py:146] step: 399650, training_loss: 6.79532e-02
I0516 01:09:05.397591 22392998065984 run_lib.py:146] step: 399700, training_loss: 4.46748e-02
I0516 01:09:05.568627 22392998065984 run_lib.py:167] step: 399700, eval_loss: 6.30138e-02
I0516 01:09:30.467214 22392998065984 run_lib.py:146] step: 399750, training_loss: 4.52393e-02
I0516 01:09:55.178675 22392998065984 run_lib.py:146] step: 399800, training_loss: 6.65581e-02
I0516 01:09:55.347624 22392998065984 run_lib.py:167] step: 399800, eval_loss: 5.89987e-02
I0516 01:10:19.768837 22392998065984 run_lib.py:146] step: 399850, training_loss: 6.36214e-02
I0516 01:10:44.205862 22392998065984 run_lib.py:146] step: 399900, training_loss: 5.67011e-02
I0516 01:10:44.375058 22392998065984 run_lib.py:167] step: 399900, eval_loss: 5.95763e-02
I0516 01:11:09.185146 22392998065984 run_lib.py:146] step: 399950, training_loss: 6.11045e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:11:33.221896 22392998065984 run_lib.py:146] step: 400000, training_loss: 5.70891e-02
I0516 01:11:34.974532 22392998065984 run_lib.py:167] step: 400000, eval_loss: 6.78843e-02
I0516 01:12:01.303092 22392998065984 run_lib.py:146] step: 400050, training_loss: 5.92253e-02
I0516 01:12:26.044102 22392998065984 run_lib.py:146] step: 400100, training_loss: 5.65591e-02
I0516 01:12:26.210973 22392998065984 run_lib.py:167] step: 400100, eval_loss: 6.75527e-02
I0516 01:12:49.960541 22392998065984 run_lib.py:146] step: 400150, training_loss: 6.14119e-02
I0516 01:13:14.064137 22392998065984 run_lib.py:146] step: 400200, training_loss: 5.20791e-02
I0516 01:13:14.234323 22392998065984 run_lib.py:167] step: 400200, eval_loss: 5.37847e-02
I0516 01:13:38.950015 22392998065984 run_lib.py:146] step: 400250, training_loss: 6.30267e-02
I0516 01:14:03.028559 22392998065984 run_lib.py:146] step: 400300, training_loss: 4.82093e-02
I0516 01:14:03.197948 22392998065984 run_lib.py:167] step: 400300, eval_loss: 5.92958e-02
I0516 01:14:28.050989 22392998065984 run_lib.py:146] step: 400350, training_loss: 5.50165e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:14:53.065603 22392998065984 run_lib.py:146] step: 400400, training_loss: 5.72559e-02
I0516 01:14:53.228598 22392998065984 run_lib.py:167] step: 400400, eval_loss: 5.07372e-02
I0516 01:15:17.085745 22392998065984 run_lib.py:146] step: 400450, training_loss: 4.97767e-02
I0516 01:15:41.043702 22392998065984 run_lib.py:146] step: 400500, training_loss: 6.72103e-02
I0516 01:15:41.203710 22392998065984 run_lib.py:167] step: 400500, eval_loss: 5.60514e-02
I0516 01:16:06.366764 22392998065984 run_lib.py:146] step: 400550, training_loss: 4.82922e-02
I0516 01:16:30.739126 22392998065984 run_lib.py:146] step: 400600, training_loss: 4.60312e-02
I0516 01:16:30.900271 22392998065984 run_lib.py:167] step: 400600, eval_loss: 5.74439e-02
I0516 01:16:55.042341 22392998065984 run_lib.py:146] step: 400650, training_loss: 4.83828e-02
I0516 01:17:20.226388 22392998065984 run_lib.py:146] step: 400700, training_loss: 5.54895e-02
I0516 01:17:20.388575 22392998065984 run_lib.py:167] step: 400700, eval_loss: 6.58786e-02
I0516 01:17:45.015694 22392998065984 run_lib.py:146] step: 400750, training_loss: 5.49098e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:18:09.445124 22392998065984 run_lib.py:146] step: 400800, training_loss: 7.01897e-02
I0516 01:18:09.609247 22392998065984 run_lib.py:167] step: 400800, eval_loss: 6.50122e-02
I0516 01:18:33.866524 22392998065984 run_lib.py:146] step: 400850, training_loss: 6.61126e-02
I0516 01:18:58.609995 22392998065984 run_lib.py:146] step: 400900, training_loss: 5.76671e-02
I0516 01:18:58.774108 22392998065984 run_lib.py:167] step: 400900, eval_loss: 6.89251e-02
I0516 01:19:22.757967 22392998065984 run_lib.py:146] step: 400950, training_loss: 5.68184e-02
I0516 01:19:47.040145 22392998065984 run_lib.py:146] step: 401000, training_loss: 4.67364e-02
I0516 01:19:47.201577 22392998065984 run_lib.py:167] step: 401000, eval_loss: 6.07188e-02
I0516 01:20:11.668431 22392998065984 run_lib.py:146] step: 401050, training_loss: 5.80270e-02
I0516 01:20:35.464276 22392998065984 run_lib.py:146] step: 401100, training_loss: 4.60316e-02
I0516 01:20:35.626020 22392998065984 run_lib.py:167] step: 401100, eval_loss: 4.70298e-02
I0516 01:20:59.718097 22392998065984 run_lib.py:146] step: 401150, training_loss: 5.40618e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:21:24.348634 22392998065984 run_lib.py:146] step: 401200, training_loss: 4.89503e-02
I0516 01:21:24.521564 22392998065984 run_lib.py:167] step: 401200, eval_loss: 6.40417e-02
I0516 01:21:48.624104 22392998065984 run_lib.py:146] step: 401250, training_loss: 5.77770e-02
I0516 01:22:12.432867 22392998065984 run_lib.py:146] step: 401300, training_loss: 7.61497e-02
I0516 01:22:12.593060 22392998065984 run_lib.py:167] step: 401300, eval_loss: 7.09478e-02
I0516 01:22:36.979487 22392998065984 run_lib.py:146] step: 401350, training_loss: 5.69696e-02
I0516 01:23:01.075123 22392998065984 run_lib.py:146] step: 401400, training_loss: 4.44202e-02
I0516 01:23:01.235181 22392998065984 run_lib.py:167] step: 401400, eval_loss: 5.34365e-02
I0516 01:23:25.018527 22392998065984 run_lib.py:146] step: 401450, training_loss: 6.68734e-02
I0516 01:23:50.222737 22392998065984 run_lib.py:146] step: 401500, training_loss: 6.11285e-02
I0516 01:23:50.387064 22392998065984 run_lib.py:167] step: 401500, eval_loss: 6.75245e-02
I0516 01:24:14.775909 22392998065984 run_lib.py:146] step: 401550, training_loss: 5.71781e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:24:39.209826 22392998065984 run_lib.py:146] step: 401600, training_loss: 6.19626e-02
I0516 01:24:39.373344 22392998065984 run_lib.py:167] step: 401600, eval_loss: 4.90524e-02
I0516 01:25:04.142993 22392998065984 run_lib.py:146] step: 401650, training_loss: 5.72068e-02
I0516 01:25:29.039807 22392998065984 run_lib.py:146] step: 401700, training_loss: 4.41897e-02
I0516 01:25:29.217575 22392998065984 run_lib.py:167] step: 401700, eval_loss: 6.16979e-02
I0516 01:25:53.517156 22392998065984 run_lib.py:146] step: 401750, training_loss: 6.02587e-02
I0516 01:26:18.112674 22392998065984 run_lib.py:146] step: 401800, training_loss: 6.67828e-02
I0516 01:26:18.281059 22392998065984 run_lib.py:167] step: 401800, eval_loss: 7.08683e-02
I0516 01:26:42.853136 22392998065984 run_lib.py:146] step: 401850, training_loss: 4.73823e-02
I0516 01:27:07.094415 22392998065984 run_lib.py:146] step: 401900, training_loss: 5.18819e-02
I0516 01:27:07.255418 22392998065984 run_lib.py:167] step: 401900, eval_loss: 6.39059e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:27:32.081728 22392998065984 run_lib.py:146] step: 401950, training_loss: 4.91189e-02
I0516 01:27:56.738833 22392998065984 run_lib.py:146] step: 402000, training_loss: 4.75270e-02
I0516 01:27:56.900759 22392998065984 run_lib.py:167] step: 402000, eval_loss: 5.38020e-02
I0516 01:28:21.257778 22392998065984 run_lib.py:146] step: 402050, training_loss: 5.68941e-02
I0516 01:28:45.910797 22392998065984 run_lib.py:146] step: 402100, training_loss: 4.08780e-02
I0516 01:28:46.079307 22392998065984 run_lib.py:167] step: 402100, eval_loss: 6.43249e-02
I0516 01:29:10.690335 22392998065984 run_lib.py:146] step: 402150, training_loss: 4.72044e-02
I0516 01:29:34.948404 22392998065984 run_lib.py:146] step: 402200, training_loss: 4.88087e-02
I0516 01:29:35.119445 22392998065984 run_lib.py:167] step: 402200, eval_loss: 5.53670e-02
I0516 01:29:59.388574 22392998065984 run_lib.py:146] step: 402250, training_loss: 7.02346e-02
I0516 01:30:24.204971 22392998065984 run_lib.py:146] step: 402300, training_loss: 6.25918e-02
I0516 01:30:24.364049 22392998065984 run_lib.py:167] step: 402300, eval_loss: 5.69005e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:30:48.805174 22392998065984 run_lib.py:146] step: 402350, training_loss: 5.43789e-02
I0516 01:31:13.036573 22392998065984 run_lib.py:146] step: 402400, training_loss: 7.23953e-02
I0516 01:31:13.206594 22392998065984 run_lib.py:167] step: 402400, eval_loss: 6.75837e-02
I0516 01:31:37.937188 22392998065984 run_lib.py:146] step: 402450, training_loss: 4.47819e-02
I0516 01:32:02.662616 22392998065984 run_lib.py:146] step: 402500, training_loss: 5.34446e-02
I0516 01:32:02.827325 22392998065984 run_lib.py:167] step: 402500, eval_loss: 7.63663e-02
I0516 01:32:27.133724 22392998065984 run_lib.py:146] step: 402550, training_loss: 4.70112e-02
I0516 01:32:51.862586 22392998065984 run_lib.py:146] step: 402600, training_loss: 6.07049e-02
I0516 01:32:52.023452 22392998065984 run_lib.py:167] step: 402600, eval_loss: 4.39262e-02
I0516 01:33:16.730226 22392998065984 run_lib.py:146] step: 402650, training_loss: 7.39232e-02
I0516 01:33:41.035622 22392998065984 run_lib.py:146] step: 402700, training_loss: 7.13605e-02
I0516 01:33:41.204842 22392998065984 run_lib.py:167] step: 402700, eval_loss: 7.83154e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:34:06.212295 22392998065984 run_lib.py:146] step: 402750, training_loss: 5.18176e-02
I0516 01:34:30.820058 22392998065984 run_lib.py:146] step: 402800, training_loss: 5.49335e-02
I0516 01:34:30.932543 22392998065984 run_lib.py:167] step: 402800, eval_loss: 5.08155e-02
I0516 01:34:55.300590 22392998065984 run_lib.py:146] step: 402850, training_loss: 8.23460e-02
I0516 01:35:19.947378 22392998065984 run_lib.py:146] step: 402900, training_loss: 4.28750e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:35:20.416046 22392998065984 run_lib.py:167] step: 402900, eval_loss: 6.49879e-02
I0516 01:35:45.083688 22392998065984 run_lib.py:146] step: 402950, training_loss: 4.35963e-02
I0516 01:36:09.355753 22392998065984 run_lib.py:146] step: 403000, training_loss: 6.10180e-02
I0516 01:36:09.517128 22392998065984 run_lib.py:167] step: 403000, eval_loss: 6.73123e-02
I0516 01:36:34.185654 22392998065984 run_lib.py:146] step: 403050, training_loss: 5.84982e-02
I0516 01:36:58.793106 22392998065984 run_lib.py:146] step: 403100, training_loss: 7.02494e-02
I0516 01:36:58.953451 22392998065984 run_lib.py:167] step: 403100, eval_loss: 5.53850e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:37:23.449529 22392998065984 run_lib.py:146] step: 403150, training_loss: 6.32136e-02
I0516 01:37:47.869896 22392998065984 run_lib.py:146] step: 403200, training_loss: 6.02900e-02
I0516 01:37:48.040042 22392998065984 run_lib.py:167] step: 403200, eval_loss: 5.36896e-02
I0516 01:38:12.844670 22392998065984 run_lib.py:146] step: 403250, training_loss: 6.44557e-02
I0516 01:38:37.487447 22392998065984 run_lib.py:146] step: 403300, training_loss: 6.57049e-02
I0516 01:38:37.650221 22392998065984 run_lib.py:167] step: 403300, eval_loss: 5.30760e-02
I0516 01:39:01.931368 22392998065984 run_lib.py:146] step: 403350, training_loss: 5.39388e-02
I0516 01:39:26.533711 22392998065984 run_lib.py:146] step: 403400, training_loss: 6.29230e-02
I0516 01:39:26.703636 22392998065984 run_lib.py:167] step: 403400, eval_loss: 4.67344e-02
I0516 01:39:51.343124 22392998065984 run_lib.py:146] step: 403450, training_loss: 4.71402e-02
I0516 01:40:15.725859 22392998065984 run_lib.py:146] step: 403500, training_loss: 5.08225e-02
I0516 01:40:15.893196 22392998065984 run_lib.py:167] step: 403500, eval_loss: 5.31987e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:40:40.705662 22392998065984 run_lib.py:146] step: 403550, training_loss: 5.34696e-02
I0516 01:41:05.459749 22392998065984 run_lib.py:146] step: 403600, training_loss: 4.50028e-02
I0516 01:41:05.624193 22392998065984 run_lib.py:167] step: 403600, eval_loss: 5.90113e-02
I0516 01:41:29.986866 22392998065984 run_lib.py:146] step: 403650, training_loss: 6.65267e-02
I0516 01:41:54.663315 22392998065984 run_lib.py:146] step: 403700, training_loss: 7.42951e-02
I0516 01:41:54.830590 22392998065984 run_lib.py:167] step: 403700, eval_loss: 9.31347e-02
I0516 01:42:19.466603 22392998065984 run_lib.py:146] step: 403750, training_loss: 5.22322e-02
I0516 01:42:43.813688 22392998065984 run_lib.py:146] step: 403800, training_loss: 4.42825e-02
I0516 01:42:43.984160 22392998065984 run_lib.py:167] step: 403800, eval_loss: 7.38439e-02
I0516 01:43:08.571975 22392998065984 run_lib.py:146] step: 403850, training_loss: 5.69147e-02
I0516 01:43:33.137968 22392998065984 run_lib.py:146] step: 403900, training_loss: 5.91685e-02
I0516 01:43:33.307228 22392998065984 run_lib.py:167] step: 403900, eval_loss: 5.47981e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:43:57.766567 22392998065984 run_lib.py:146] step: 403950, training_loss: 3.85309e-02
I0516 01:44:21.993134 22392998065984 run_lib.py:146] step: 404000, training_loss: 5.72584e-02
I0516 01:44:22.158370 22392998065984 run_lib.py:167] step: 404000, eval_loss: 5.60356e-02
I0516 01:44:46.818499 22392998065984 run_lib.py:146] step: 404050, training_loss: 5.20350e-02
I0516 01:45:11.490692 22392998065984 run_lib.py:146] step: 404100, training_loss: 5.72704e-02
I0516 01:45:11.652561 22392998065984 run_lib.py:167] step: 404100, eval_loss: 6.65946e-02
I0516 01:45:36.003490 22392998065984 run_lib.py:146] step: 404150, training_loss: 4.57184e-02
I0516 01:46:00.653571 22392998065984 run_lib.py:146] step: 404200, training_loss: 5.63159e-02
I0516 01:46:00.815738 22392998065984 run_lib.py:167] step: 404200, eval_loss: 5.63223e-02
I0516 01:46:25.462378 22392998065984 run_lib.py:146] step: 404250, training_loss: 6.93483e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:46:49.977813 22392998065984 run_lib.py:146] step: 404300, training_loss: 4.49816e-02
I0516 01:46:50.150259 22392998065984 run_lib.py:167] step: 404300, eval_loss: 6.66560e-02
I0516 01:47:14.829453 22392998065984 run_lib.py:146] step: 404350, training_loss: 4.96062e-02
I0516 01:47:39.636155 22392998065984 run_lib.py:146] step: 404400, training_loss: 6.34243e-02
I0516 01:47:39.800730 22392998065984 run_lib.py:167] step: 404400, eval_loss: 6.78402e-02
I0516 01:48:04.115037 22392998065984 run_lib.py:146] step: 404450, training_loss: 4.22361e-02
I0516 01:48:28.755914 22392998065984 run_lib.py:146] step: 404500, training_loss: 6.47612e-02
I0516 01:48:28.924950 22392998065984 run_lib.py:167] step: 404500, eval_loss: 6.45064e-02
I0516 01:48:53.628306 22392998065984 run_lib.py:146] step: 404550, training_loss: 5.17665e-02
I0516 01:49:17.917669 22392998065984 run_lib.py:146] step: 404600, training_loss: 6.15206e-02
I0516 01:49:18.086644 22392998065984 run_lib.py:167] step: 404600, eval_loss: 7.56638e-02
I0516 01:49:42.583570 22392998065984 run_lib.py:146] step: 404650, training_loss: 4.38230e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:50:07.298069 22392998065984 run_lib.py:146] step: 404700, training_loss: 4.71659e-02
I0516 01:50:07.463258 22392998065984 run_lib.py:167] step: 404700, eval_loss: 5.89058e-02
I0516 01:50:31.781725 22392998065984 run_lib.py:146] step: 404750, training_loss: 5.54732e-02
I0516 01:50:56.516530 22392998065984 run_lib.py:146] step: 404800, training_loss: 7.03744e-02
I0516 01:50:56.682278 22392998065984 run_lib.py:167] step: 404800, eval_loss: 5.81079e-02
I0516 01:51:21.269298 22392998065984 run_lib.py:146] step: 404850, training_loss: 6.42255e-02
I0516 01:51:45.558160 22392998065984 run_lib.py:146] step: 404900, training_loss: 5.49318e-02
I0516 01:51:45.719793 22392998065984 run_lib.py:167] step: 404900, eval_loss: 5.62533e-02
I0516 01:52:09.976489 22392998065984 run_lib.py:146] step: 404950, training_loss: 5.66967e-02
I0516 01:52:34.600592 22392998065984 run_lib.py:146] step: 405000, training_loss: 5.03642e-02
I0516 01:52:34.769070 22392998065984 run_lib.py:167] step: 405000, eval_loss: 6.05731e-02
I0516 01:52:59.402130 22392998065984 run_lib.py:146] step: 405050, training_loss: 5.15330e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:53:23.888534 22392998065984 run_lib.py:146] step: 405100, training_loss: 3.64233e-02
I0516 01:53:24.058694 22392998065984 run_lib.py:167] step: 405100, eval_loss: 5.06489e-02
I0516 01:53:48.904131 22392998065984 run_lib.py:146] step: 405150, training_loss: 6.68214e-02
I0516 01:54:13.565611 22392998065984 run_lib.py:146] step: 405200, training_loss: 5.31439e-02
I0516 01:54:13.732364 22392998065984 run_lib.py:167] step: 405200, eval_loss: 4.78497e-02
I0516 01:54:38.082452 22392998065984 run_lib.py:146] step: 405250, training_loss: 4.99014e-02
I0516 01:55:02.902365 22392998065984 run_lib.py:146] step: 405300, training_loss: 4.99880e-02
I0516 01:55:03.070803 22392998065984 run_lib.py:167] step: 405300, eval_loss: 5.15421e-02
I0516 01:55:27.662797 22392998065984 run_lib.py:146] step: 405350, training_loss: 5.36525e-02
I0516 01:55:51.998444 22392998065984 run_lib.py:146] step: 405400, training_loss: 6.78509e-02
I0516 01:55:52.163835 22392998065984 run_lib.py:167] step: 405400, eval_loss: 5.43406e-02
I0516 01:56:16.874473 22392998065984 run_lib.py:146] step: 405450, training_loss: 5.48714e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:56:41.737990 22392998065984 run_lib.py:146] step: 405500, training_loss: 5.25382e-02
I0516 01:56:41.902597 22392998065984 run_lib.py:167] step: 405500, eval_loss: 6.10532e-02
I0516 01:57:06.262389 22392998065984 run_lib.py:146] step: 405550, training_loss: 6.65643e-02
I0516 01:57:31.060411 22392998065984 run_lib.py:146] step: 405600, training_loss: 5.68836e-02
I0516 01:57:31.242190 22392998065984 run_lib.py:167] step: 405600, eval_loss: 7.16195e-02
I0516 01:57:55.831459 22392998065984 run_lib.py:146] step: 405650, training_loss: 4.11004e-02
I0516 01:58:20.141231 22392998065984 run_lib.py:146] step: 405700, training_loss: 6.92560e-02
I0516 01:58:20.310133 22392998065984 run_lib.py:167] step: 405700, eval_loss: 6.92000e-02
I0516 01:58:44.644504 22392998065984 run_lib.py:146] step: 405750, training_loss: 6.72603e-02
I0516 01:59:09.305269 22392998065984 run_lib.py:146] step: 405800, training_loss: 5.70119e-02
I0516 01:59:09.482965 22392998065984 run_lib.py:167] step: 405800, eval_loss: 5.59665e-02
I0516 01:59:34.064693 22392998065984 run_lib.py:146] step: 405850, training_loss: 6.06025e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 01:59:58.542495 22392998065984 run_lib.py:146] step: 405900, training_loss: 6.45808e-02
I0516 01:59:58.709609 22392998065984 run_lib.py:167] step: 405900, eval_loss: 6.25485e-02
I0516 02:00:23.416439 22392998065984 run_lib.py:146] step: 405950, training_loss: 5.23889e-02
I0516 02:00:57.946926 22392998065984 run_lib.py:146] step: 406000, training_loss: 5.61049e-02
I0516 02:00:58.108807 22392998065984 run_lib.py:167] step: 406000, eval_loss: 6.24674e-02
I0516 02:01:22.381408 22392998065984 run_lib.py:146] step: 406050, training_loss: 6.27733e-02
I0516 02:01:47.096225 22392998065984 run_lib.py:146] step: 406100, training_loss: 6.05568e-02
I0516 02:01:47.262338 22392998065984 run_lib.py:167] step: 406100, eval_loss: 5.72752e-02
I0516 02:02:11.898257 22392998065984 run_lib.py:146] step: 406150, training_loss: 6.29417e-02
I0516 02:02:36.209621 22392998065984 run_lib.py:146] step: 406200, training_loss: 6.36045e-02
I0516 02:02:36.380419 22392998065984 run_lib.py:167] step: 406200, eval_loss: 7.34461e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:03:01.240179 22392998065984 run_lib.py:146] step: 406250, training_loss: 5.95026e-02
I0516 02:03:25.879313 22392998065984 run_lib.py:146] step: 406300, training_loss: 4.04184e-02
I0516 02:03:26.045578 22392998065984 run_lib.py:167] step: 406300, eval_loss: 5.84089e-02
I0516 02:03:50.286186 22392998065984 run_lib.py:146] step: 406350, training_loss: 4.82543e-02
I0516 02:04:14.970515 22392998065984 run_lib.py:146] step: 406400, training_loss: 5.03411e-02
I0516 02:04:15.131820 22392998065984 run_lib.py:167] step: 406400, eval_loss: 7.36558e-02
I0516 02:04:39.801098 22392998065984 run_lib.py:146] step: 406450, training_loss: 4.90071e-02
I0516 02:05:04.094109 22392998065984 run_lib.py:146] step: 406500, training_loss: 4.98059e-02
I0516 02:05:13.892682 22392998065984 run_lib.py:167] step: 406500, eval_loss: 6.46702e-02
I0516 02:05:38.473286 22392998065984 run_lib.py:146] step: 406550, training_loss: 7.19649e-02
I0516 02:06:02.725256 22392998065984 run_lib.py:146] step: 406600, training_loss: 6.58223e-02
I0516 02:06:02.902196 22392998065984 run_lib.py:167] step: 406600, eval_loss: 5.40092e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:06:29.246855 22392998065984 run_lib.py:146] step: 406650, training_loss: 4.53613e-02
I0516 02:06:53.653674 22392998065984 run_lib.py:146] step: 406700, training_loss: 4.28164e-02
I0516 02:06:53.816378 22392998065984 run_lib.py:167] step: 406700, eval_loss: 5.36084e-02
I0516 02:07:18.526246 22392998065984 run_lib.py:146] step: 406750, training_loss: 4.81267e-02
I0516 02:07:43.211836 22392998065984 run_lib.py:146] step: 406800, training_loss: 5.23995e-02
I0516 02:07:43.373114 22392998065984 run_lib.py:167] step: 406800, eval_loss: 4.92895e-02
I0516 02:08:07.538012 22392998065984 run_lib.py:146] step: 406850, training_loss: 4.91948e-02
I0516 02:08:32.147489 22392998065984 run_lib.py:146] step: 406900, training_loss: 5.31612e-02
I0516 02:08:32.307570 22392998065984 run_lib.py:167] step: 406900, eval_loss: 7.36472e-02
I0516 02:08:56.931582 22392998065984 run_lib.py:146] step: 406950, training_loss: 4.24153e-02
I0516 02:09:21.205186 22392998065984 run_lib.py:146] step: 407000, training_loss: 5.31786e-02
I0516 02:09:21.366675 22392998065984 run_lib.py:167] step: 407000, eval_loss: 4.63602e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:09:46.177086 22392998065984 run_lib.py:146] step: 407050, training_loss: 4.28356e-02
I0516 02:10:11.025413 22392998065984 run_lib.py:146] step: 407100, training_loss: 4.82624e-02
I0516 02:10:11.195497 22392998065984 run_lib.py:167] step: 407100, eval_loss: 7.75268e-02
I0516 02:10:35.443290 22392998065984 run_lib.py:146] step: 407150, training_loss: 4.41867e-02
I0516 02:11:00.098658 22392998065984 run_lib.py:146] step: 407200, training_loss: 5.76895e-02
I0516 02:11:00.264579 22392998065984 run_lib.py:167] step: 407200, eval_loss: 5.64988e-02
I0516 02:11:24.964777 22392998065984 run_lib.py:146] step: 407250, training_loss: 5.74310e-02
I0516 02:11:49.233565 22392998065984 run_lib.py:146] step: 407300, training_loss: 5.09612e-02
I0516 02:11:49.402015 22392998065984 run_lib.py:167] step: 407300, eval_loss: 7.63315e-02
I0516 02:12:13.986184 22392998065984 run_lib.py:146] step: 407350, training_loss: 5.58262e-02
I0516 02:12:38.639106 22392998065984 run_lib.py:146] step: 407400, training_loss: 6.21469e-02
I0516 02:12:38.800086 22392998065984 run_lib.py:167] step: 407400, eval_loss: 7.12763e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:13:03.349547 22392998065984 run_lib.py:146] step: 407450, training_loss: 5.55130e-02
I0516 02:13:27.658379 22392998065984 run_lib.py:146] step: 407500, training_loss: 5.42898e-02
I0516 02:13:27.831010 22392998065984 run_lib.py:167] step: 407500, eval_loss: 5.92429e-02
I0516 02:13:52.545906 22392998065984 run_lib.py:146] step: 407550, training_loss: 5.89174e-02
I0516 02:14:17.261648 22392998065984 run_lib.py:146] step: 407600, training_loss: 4.91247e-02
I0516 02:14:17.430294 22392998065984 run_lib.py:167] step: 407600, eval_loss: 5.28816e-02
I0516 02:14:41.643303 22392998065984 run_lib.py:146] step: 407650, training_loss: 5.28741e-02
I0516 02:15:06.224044 22392998065984 run_lib.py:146] step: 407700, training_loss: 4.77256e-02
I0516 02:15:06.385241 22392998065984 run_lib.py:167] step: 407700, eval_loss: 4.95738e-02
I0516 02:15:31.043498 22392998065984 run_lib.py:146] step: 407750, training_loss: 5.34092e-02
I0516 02:15:55.361425 22392998065984 run_lib.py:146] step: 407800, training_loss: 5.16187e-02
I0516 02:15:55.532423 22392998065984 run_lib.py:167] step: 407800, eval_loss: 6.61132e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:16:20.381279 22392998065984 run_lib.py:146] step: 407850, training_loss: 6.37442e-02
I0516 02:16:45.071791 22392998065984 run_lib.py:146] step: 407900, training_loss: 5.99269e-02
I0516 02:16:45.241019 22392998065984 run_lib.py:167] step: 407900, eval_loss: 6.48917e-02
I0516 02:17:09.602166 22392998065984 run_lib.py:146] step: 407950, training_loss: 4.93097e-02
I0516 02:17:34.247943 22392998065984 run_lib.py:146] step: 408000, training_loss: 5.07591e-02
I0516 02:17:34.421370 22392998065984 run_lib.py:167] step: 408000, eval_loss: 6.81644e-02
I0516 02:17:59.049871 22392998065984 run_lib.py:146] step: 408050, training_loss: 4.72555e-02
I0516 02:18:23.369259 22392998065984 run_lib.py:146] step: 408100, training_loss: 7.57470e-02
I0516 02:18:23.547822 22392998065984 run_lib.py:167] step: 408100, eval_loss: 6.35386e-02
I0516 02:18:48.177204 22392998065984 run_lib.py:146] step: 408150, training_loss: 4.33513e-02
I0516 02:19:12.751957 22392998065984 run_lib.py:146] step: 408200, training_loss: 5.44481e-02
I0516 02:19:12.934375 22392998065984 run_lib.py:167] step: 408200, eval_loss: 5.26233e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:19:37.348840 22392998065984 run_lib.py:146] step: 408250, training_loss: 6.15272e-02
I0516 02:20:01.625743 22392998065984 run_lib.py:146] step: 408300, training_loss: 6.05149e-02
I0516 02:20:01.796674 22392998065984 run_lib.py:167] step: 408300, eval_loss: 6.66529e-02
I0516 02:20:26.452825 22392998065984 run_lib.py:146] step: 408350, training_loss: 5.67342e-02
I0516 02:20:51.092301 22392998065984 run_lib.py:146] step: 408400, training_loss: 5.72586e-02
I0516 02:20:51.252250 22392998065984 run_lib.py:167] step: 408400, eval_loss: 5.85687e-02
I0516 02:21:15.498552 22392998065984 run_lib.py:146] step: 408450, training_loss: 7.23898e-02
I0516 02:21:40.039077 22392998065984 run_lib.py:146] step: 408500, training_loss: 5.20320e-02
I0516 02:21:40.207295 22392998065984 run_lib.py:167] step: 408500, eval_loss: 6.36258e-02
I0516 02:22:04.791307 22392998065984 run_lib.py:146] step: 408550, training_loss: 3.86928e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:22:29.236884 22392998065984 run_lib.py:146] step: 408600, training_loss: 3.42779e-02
I0516 02:22:29.409852 22392998065984 run_lib.py:167] step: 408600, eval_loss: 5.19364e-02
I0516 02:22:54.058930 22392998065984 run_lib.py:146] step: 408650, training_loss: 4.83560e-02
I0516 02:23:18.722784 22392998065984 run_lib.py:146] step: 408700, training_loss: 5.24016e-02
I0516 02:23:18.885928 22392998065984 run_lib.py:167] step: 408700, eval_loss: 7.63780e-02
I0516 02:23:43.217284 22392998065984 run_lib.py:146] step: 408750, training_loss: 5.96708e-02
I0516 02:24:07.781975 22392998065984 run_lib.py:146] step: 408800, training_loss: 4.92656e-02
I0516 02:24:07.953352 22392998065984 run_lib.py:167] step: 408800, eval_loss: 4.73376e-02
I0516 02:24:32.570297 22392998065984 run_lib.py:146] step: 408850, training_loss: 6.05889e-02
I0516 02:24:56.859941 22392998065984 run_lib.py:146] step: 408900, training_loss: 6.16812e-02
I0516 02:24:57.020226 22392998065984 run_lib.py:167] step: 408900, eval_loss: 5.28443e-02
I0516 02:25:21.620983 22392998065984 run_lib.py:146] step: 408950, training_loss: 5.55048e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:25:46.424090 22392998065984 run_lib.py:146] step: 409000, training_loss: 6.88413e-02
I0516 02:25:46.608256 22392998065984 run_lib.py:167] step: 409000, eval_loss: 7.12726e-02
I0516 02:26:10.895007 22392998065984 run_lib.py:146] step: 409050, training_loss: 4.89588e-02
I0516 02:26:34.787159 22392998065984 run_lib.py:146] step: 409100, training_loss: 6.61659e-02
I0516 02:26:34.947462 22392998065984 run_lib.py:167] step: 409100, eval_loss: 6.73658e-02
I0516 02:26:59.600425 22392998065984 run_lib.py:146] step: 409150, training_loss: 5.77973e-02
I0516 02:27:24.337111 22392998065984 run_lib.py:146] step: 409200, training_loss: 6.29388e-02
I0516 02:27:24.503942 22392998065984 run_lib.py:167] step: 409200, eval_loss: 6.91380e-02
I0516 02:27:48.705074 22392998065984 run_lib.py:146] step: 409250, training_loss: 6.40758e-02
I0516 02:28:13.297679 22392998065984 run_lib.py:146] step: 409300, training_loss: 5.82909e-02
I0516 02:28:13.457661 22392998065984 run_lib.py:167] step: 409300, eval_loss: 5.50320e-02
I0516 02:28:38.107287 22392998065984 run_lib.py:146] step: 409350, training_loss: 6.75189e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:29:02.528980 22392998065984 run_lib.py:146] step: 409400, training_loss: 4.85850e-02
I0516 02:29:02.694710 22392998065984 run_lib.py:167] step: 409400, eval_loss: 5.65153e-02
I0516 02:29:27.351598 22392998065984 run_lib.py:146] step: 409450, training_loss: 4.74264e-02
I0516 02:29:52.044385 22392998065984 run_lib.py:146] step: 409500, training_loss: 4.98959e-02
I0516 02:29:52.215626 22392998065984 run_lib.py:167] step: 409500, eval_loss: 6.56967e-02
I0516 02:30:16.533953 22392998065984 run_lib.py:146] step: 409550, training_loss: 5.86089e-02
I0516 02:30:41.316268 22392998065984 run_lib.py:146] step: 409600, training_loss: 5.25475e-02
I0516 02:30:41.491457 22392998065984 run_lib.py:167] step: 409600, eval_loss: 5.64792e-02
I0516 02:31:06.088561 22392998065984 run_lib.py:146] step: 409650, training_loss: 6.05063e-02
I0516 02:31:30.384445 22392998065984 run_lib.py:146] step: 409700, training_loss: 5.21480e-02
I0516 02:31:30.556926 22392998065984 run_lib.py:167] step: 409700, eval_loss: 5.34991e-02
I0516 02:31:55.289438 22392998065984 run_lib.py:146] step: 409750, training_loss: 4.92924e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:32:20.046112 22392998065984 run_lib.py:146] step: 409800, training_loss: 6.45790e-02
I0516 02:32:20.213008 22392998065984 run_lib.py:167] step: 409800, eval_loss: 9.11546e-02
I0516 02:32:44.447800 22392998065984 run_lib.py:146] step: 409850, training_loss: 6.04883e-02
I0516 02:33:09.192330 22392998065984 run_lib.py:146] step: 409900, training_loss: 6.79657e-02
I0516 02:33:09.354777 22392998065984 run_lib.py:167] step: 409900, eval_loss: 4.04521e-02
I0516 02:33:33.879533 22392998065984 run_lib.py:146] step: 409950, training_loss: 5.72780e-02
I0516 02:33:58.118810 22392998065984 run_lib.py:146] step: 410000, training_loss: 5.05353e-02
I0516 02:34:00.010257 22392998065984 run_lib.py:167] step: 410000, eval_loss: 5.85770e-02
I0516 02:34:26.411761 22392998065984 run_lib.py:146] step: 410050, training_loss: 6.38919e-02
I0516 02:34:50.775304 22392998065984 run_lib.py:146] step: 410100, training_loss: 4.52003e-02
I0516 02:34:50.962905 22392998065984 run_lib.py:167] step: 410100, eval_loss: 7.81497e-02
I0516 02:35:15.615938 22392998065984 run_lib.py:146] step: 410150, training_loss: 5.56217e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:35:40.519007 22392998065984 run_lib.py:146] step: 410200, training_loss: 5.08871e-02
I0516 02:35:40.689256 22392998065984 run_lib.py:167] step: 410200, eval_loss: 6.18262e-02
I0516 02:36:05.058498 22392998065984 run_lib.py:146] step: 410250, training_loss: 4.40888e-02
I0516 02:36:29.635939 22392998065984 run_lib.py:146] step: 410300, training_loss: 5.19061e-02
I0516 02:36:29.795808 22392998065984 run_lib.py:167] step: 410300, eval_loss: 5.78124e-02
I0516 02:36:54.354350 22392998065984 run_lib.py:146] step: 410350, training_loss: 4.77919e-02
I0516 02:37:18.657319 22392998065984 run_lib.py:146] step: 410400, training_loss: 6.53803e-02
I0516 02:37:18.828580 22392998065984 run_lib.py:167] step: 410400, eval_loss: 5.54603e-02
I0516 02:37:43.571392 22392998065984 run_lib.py:146] step: 410450, training_loss: 4.60659e-02
I0516 02:38:08.169735 22392998065984 run_lib.py:146] step: 410500, training_loss: 6.85141e-02
I0516 02:38:08.338373 22392998065984 run_lib.py:167] step: 410500, eval_loss: 4.65896e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:38:32.793429 22392998065984 run_lib.py:146] step: 410550, training_loss: 6.01883e-02
I0516 02:38:57.603192 22392998065984 run_lib.py:146] step: 410600, training_loss: 6.43498e-02
I0516 02:38:57.785184 22392998065984 run_lib.py:167] step: 410600, eval_loss: 5.61402e-02
I0516 02:39:22.030313 22392998065984 run_lib.py:146] step: 410650, training_loss: 6.42281e-02
I0516 02:39:46.740403 22392998065984 run_lib.py:146] step: 410700, training_loss: 4.87524e-02
I0516 02:39:46.851337 22392998065984 run_lib.py:167] step: 410700, eval_loss: 5.09240e-02
I0516 02:40:11.468416 22392998065984 run_lib.py:146] step: 410750, training_loss: 6.06119e-02
I0516 02:40:35.702496 22392998065984 run_lib.py:146] step: 410800, training_loss: 5.36188e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:40:36.165455 22392998065984 run_lib.py:167] step: 410800, eval_loss: 5.25806e-02
I0516 02:41:00.817731 22392998065984 run_lib.py:146] step: 410850, training_loss: 6.48215e-02
I0516 02:41:25.417127 22392998065984 run_lib.py:146] step: 410900, training_loss: 5.12325e-02
I0516 02:41:25.578843 22392998065984 run_lib.py:167] step: 410900, eval_loss: 4.69849e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:41:50.048675 22392998065984 run_lib.py:146] step: 410950, training_loss: 6.30731e-02
I0516 02:42:14.749475 22392998065984 run_lib.py:146] step: 411000, training_loss: 5.54871e-02
I0516 02:42:14.912461 22392998065984 run_lib.py:167] step: 411000, eval_loss: 7.00313e-02
I0516 02:42:39.260002 22392998065984 run_lib.py:146] step: 411050, training_loss: 4.74334e-02
I0516 02:43:03.915194 22392998065984 run_lib.py:146] step: 411100, training_loss: 5.42923e-02
I0516 02:43:04.085243 22392998065984 run_lib.py:167] step: 411100, eval_loss: 5.69151e-02
I0516 02:43:28.693504 22392998065984 run_lib.py:146] step: 411150, training_loss: 7.00493e-02
I0516 02:43:52.961116 22392998065984 run_lib.py:146] step: 411200, training_loss: 6.35725e-02
I0516 02:43:53.129880 22392998065984 run_lib.py:167] step: 411200, eval_loss: 4.56057e-02
I0516 02:44:17.741715 22392998065984 run_lib.py:146] step: 411250, training_loss: 8.65805e-02
I0516 02:44:42.388961 22392998065984 run_lib.py:146] step: 411300, training_loss: 5.10282e-02
I0516 02:44:42.557559 22392998065984 run_lib.py:167] step: 411300, eval_loss: 4.31367e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:45:07.068291 22392998065984 run_lib.py:146] step: 411350, training_loss: 5.29965e-02
I0516 02:45:31.809815 22392998065984 run_lib.py:146] step: 411400, training_loss: 5.58405e-02
I0516 02:45:31.970956 22392998065984 run_lib.py:167] step: 411400, eval_loss: 6.30732e-02
I0516 02:45:56.666600 22392998065984 run_lib.py:146] step: 411450, training_loss: 5.01328e-02
I0516 02:46:20.927323 22392998065984 run_lib.py:146] step: 411500, training_loss: 5.25037e-02
I0516 02:46:21.097908 22392998065984 run_lib.py:167] step: 411500, eval_loss: 5.98681e-02
I0516 02:46:45.696399 22392998065984 run_lib.py:146] step: 411550, training_loss: 5.20518e-02
I0516 02:47:09.988434 22392998065984 run_lib.py:146] step: 411600, training_loss: 4.72090e-02
I0516 02:47:10.157857 22392998065984 run_lib.py:167] step: 411600, eval_loss: 6.64420e-02
I0516 02:47:34.759799 22392998065984 run_lib.py:146] step: 411650, training_loss: 4.79561e-02
I0516 02:47:59.028573 22392998065984 run_lib.py:146] step: 411700, training_loss: 4.99033e-02
I0516 02:47:59.198057 22392998065984 run_lib.py:167] step: 411700, eval_loss: 4.68773e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:48:23.979315 22392998065984 run_lib.py:146] step: 411750, training_loss: 5.62531e-02
I0516 02:48:48.544104 22392998065984 run_lib.py:146] step: 411800, training_loss: 6.13039e-02
I0516 02:48:48.706400 22392998065984 run_lib.py:167] step: 411800, eval_loss: 6.03262e-02
I0516 02:49:13.068557 22392998065984 run_lib.py:146] step: 411850, training_loss: 5.84110e-02
I0516 02:49:37.812299 22392998065984 run_lib.py:146] step: 411900, training_loss: 5.14761e-02
I0516 02:49:37.972797 22392998065984 run_lib.py:167] step: 411900, eval_loss: 7.36895e-02
I0516 02:50:02.506586 22392998065984 run_lib.py:146] step: 411950, training_loss: 5.36734e-02
I0516 02:50:26.882665 22392998065984 run_lib.py:146] step: 412000, training_loss: 8.23497e-02
I0516 02:50:27.051518 22392998065984 run_lib.py:167] step: 412000, eval_loss: 7.40995e-02
I0516 02:50:51.675299 22392998065984 run_lib.py:146] step: 412050, training_loss: 6.50509e-02
I0516 02:51:16.259114 22392998065984 run_lib.py:146] step: 412100, training_loss: 5.59987e-02
I0516 02:51:16.428686 22392998065984 run_lib.py:167] step: 412100, eval_loss: 8.62322e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:51:40.928999 22392998065984 run_lib.py:146] step: 412150, training_loss: 6.62784e-02
I0516 02:52:05.505562 22392998065984 run_lib.py:146] step: 412200, training_loss: 4.75766e-02
I0516 02:52:05.686045 22392998065984 run_lib.py:167] step: 412200, eval_loss: 5.81571e-02
I0516 02:52:30.296256 22392998065984 run_lib.py:146] step: 412250, training_loss: 6.29672e-02
I0516 02:52:54.824915 22392998065984 run_lib.py:146] step: 412300, training_loss: 6.36035e-02
I0516 02:52:55.008351 22392998065984 run_lib.py:167] step: 412300, eval_loss: 6.78996e-02
I0516 02:53:19.731682 22392998065984 run_lib.py:146] step: 412350, training_loss: 6.79892e-02
I0516 02:53:44.060280 22392998065984 run_lib.py:146] step: 412400, training_loss: 5.25878e-02
I0516 02:53:44.222745 22392998065984 run_lib.py:167] step: 412400, eval_loss: 5.89698e-02
I0516 02:54:08.849628 22392998065984 run_lib.py:146] step: 412450, training_loss: 6.86597e-02
I0516 02:54:33.113582 22392998065984 run_lib.py:146] step: 412500, training_loss: 4.66659e-02
I0516 02:54:33.290820 22392998065984 run_lib.py:167] step: 412500, eval_loss: 6.48992e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:54:58.066910 22392998065984 run_lib.py:146] step: 412550, training_loss: 6.52768e-02
I0516 02:55:22.726208 22392998065984 run_lib.py:146] step: 412600, training_loss: 6.26293e-02
I0516 02:55:22.896040 22392998065984 run_lib.py:167] step: 412600, eval_loss: 6.05240e-02
I0516 02:55:47.173156 22392998065984 run_lib.py:146] step: 412650, training_loss: 5.21648e-02
I0516 02:56:11.839334 22392998065984 run_lib.py:146] step: 412700, training_loss: 5.47737e-02
I0516 02:56:12.000333 22392998065984 run_lib.py:167] step: 412700, eval_loss: 5.73078e-02
I0516 02:56:36.596391 22392998065984 run_lib.py:146] step: 412750, training_loss: 4.91575e-02
I0516 02:57:00.869663 22392998065984 run_lib.py:146] step: 412800, training_loss: 5.40943e-02
I0516 02:57:01.029554 22392998065984 run_lib.py:167] step: 412800, eval_loss: 4.83469e-02
I0516 02:57:25.642670 22392998065984 run_lib.py:146] step: 412850, training_loss: 6.29867e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 02:57:50.462967 22392998065984 run_lib.py:146] step: 412900, training_loss: 5.48756e-02
I0516 02:57:50.624565 22392998065984 run_lib.py:167] step: 412900, eval_loss: 5.60417e-02
I0516 02:58:14.790802 22392998065984 run_lib.py:146] step: 412950, training_loss: 3.97641e-02
I0516 02:58:39.207758 22392998065984 run_lib.py:146] step: 413000, training_loss: 5.34812e-02
I0516 02:58:39.368127 22392998065984 run_lib.py:167] step: 413000, eval_loss: 6.05626e-02
I0516 02:59:03.788577 22392998065984 run_lib.py:146] step: 413050, training_loss: 5.47213e-02
I0516 02:59:28.103898 22392998065984 run_lib.py:146] step: 413100, training_loss: 4.56090e-02
I0516 02:59:28.263384 22392998065984 run_lib.py:167] step: 413100, eval_loss: 5.64683e-02
I0516 02:59:52.910959 22392998065984 run_lib.py:146] step: 413150, training_loss: 5.56762e-02
I0516 03:00:17.130102 22392998065984 run_lib.py:146] step: 413200, training_loss: 5.00907e-02
I0516 03:00:17.291615 22392998065984 run_lib.py:167] step: 413200, eval_loss: 5.55181e-02
I0516 03:00:41.820015 22392998065984 run_lib.py:146] step: 413250, training_loss: 4.86664e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:01:06.260389 22392998065984 run_lib.py:146] step: 413300, training_loss: 5.76793e-02
I0516 03:01:06.446066 22392998065984 run_lib.py:167] step: 413300, eval_loss: 7.28627e-02
I0516 03:01:31.092118 22392998065984 run_lib.py:146] step: 413350, training_loss: 3.93818e-02
I0516 03:01:55.745326 22392998065984 run_lib.py:146] step: 413400, training_loss: 3.97900e-02
I0516 03:01:55.927243 22392998065984 run_lib.py:167] step: 413400, eval_loss: 6.82238e-02
I0516 03:02:20.184444 22392998065984 run_lib.py:146] step: 413450, training_loss: 6.97450e-02
I0516 03:02:44.736528 22392998065984 run_lib.py:146] step: 413500, training_loss: 4.96517e-02
I0516 03:02:44.895458 22392998065984 run_lib.py:167] step: 413500, eval_loss: 7.29858e-02
I0516 03:03:09.508445 22392998065984 run_lib.py:146] step: 413550, training_loss: 5.05990e-02
I0516 03:03:33.811581 22392998065984 run_lib.py:146] step: 413600, training_loss: 4.12028e-02
I0516 03:03:33.986731 22392998065984 run_lib.py:167] step: 413600, eval_loss: 5.44266e-02
I0516 03:03:58.792165 22392998065984 run_lib.py:146] step: 413650, training_loss: 6.51003e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:04:23.688466 22392998065984 run_lib.py:146] step: 413700, training_loss: 5.59155e-02
I0516 03:04:23.859918 22392998065984 run_lib.py:167] step: 413700, eval_loss: 6.71700e-02
I0516 03:04:48.129525 22392998065984 run_lib.py:146] step: 413750, training_loss: 5.24623e-02
I0516 03:05:12.868529 22392998065984 run_lib.py:146] step: 413800, training_loss: 9.81998e-02
I0516 03:05:13.076958 22392998065984 run_lib.py:167] step: 413800, eval_loss: 4.63174e-02
I0516 03:05:37.702726 22392998065984 run_lib.py:146] step: 413850, training_loss: 4.49702e-02
I0516 03:06:01.891068 22392998065984 run_lib.py:146] step: 413900, training_loss: 6.83692e-02
I0516 03:06:02.062426 22392998065984 run_lib.py:167] step: 413900, eval_loss: 6.29043e-02
I0516 03:06:26.682966 22392998065984 run_lib.py:146] step: 413950, training_loss: 4.66153e-02
I0516 03:06:50.990560 22392998065984 run_lib.py:146] step: 414000, training_loss: 5.17891e-02
I0516 03:06:51.152220 22392998065984 run_lib.py:167] step: 414000, eval_loss: 4.75132e-02
I0516 03:07:15.787158 22392998065984 run_lib.py:146] step: 414050, training_loss: 4.83935e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:07:39.911402 22392998065984 run_lib.py:146] step: 414100, training_loss: 4.21409e-02
I0516 03:07:40.088303 22392998065984 run_lib.py:167] step: 414100, eval_loss: 5.11162e-02
I0516 03:08:04.416474 22392998065984 run_lib.py:146] step: 414150, training_loss: 5.24546e-02
I0516 03:08:29.024492 22392998065984 run_lib.py:146] step: 414200, training_loss: 7.42939e-02
I0516 03:08:29.186399 22392998065984 run_lib.py:167] step: 414200, eval_loss: 5.91394e-02
I0516 03:08:53.650986 22392998065984 run_lib.py:146] step: 414250, training_loss: 5.81966e-02
I0516 03:09:18.510066 22392998065984 run_lib.py:146] step: 414300, training_loss: 5.09571e-02
I0516 03:09:18.671863 22392998065984 run_lib.py:167] step: 414300, eval_loss: 5.90388e-02
I0516 03:09:43.322748 22392998065984 run_lib.py:146] step: 414350, training_loss: 6.11559e-02
I0516 03:10:07.632371 22392998065984 run_lib.py:146] step: 414400, training_loss: 5.16066e-02
I0516 03:10:07.794484 22392998065984 run_lib.py:167] step: 414400, eval_loss: 6.09532e-02
I0516 03:10:32.567181 22392998065984 run_lib.py:146] step: 414450, training_loss: 5.09413e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:10:57.530781 22392998065984 run_lib.py:146] step: 414500, training_loss: 4.50448e-02
I0516 03:10:57.692748 22392998065984 run_lib.py:167] step: 414500, eval_loss: 3.73251e-02
I0516 03:11:22.198889 22392998065984 run_lib.py:146] step: 414550, training_loss: 5.74390e-02
I0516 03:11:46.894326 22392998065984 run_lib.py:146] step: 414600, training_loss: 5.09319e-02
I0516 03:11:47.063886 22392998065984 run_lib.py:167] step: 414600, eval_loss: 6.90751e-02
I0516 03:12:11.723048 22392998065984 run_lib.py:146] step: 414650, training_loss: 5.83534e-02
I0516 03:12:36.009616 22392998065984 run_lib.py:146] step: 414700, training_loss: 4.53434e-02
I0516 03:12:36.185400 22392998065984 run_lib.py:167] step: 414700, eval_loss: 5.77054e-02
I0516 03:13:00.812446 22392998065984 run_lib.py:146] step: 414750, training_loss: 6.49456e-02
I0516 03:13:25.202306 22392998065984 run_lib.py:146] step: 414800, training_loss: 4.67777e-02
I0516 03:13:25.371990 22392998065984 run_lib.py:167] step: 414800, eval_loss: 5.15826e-02
I0516 03:13:49.860435 22392998065984 run_lib.py:146] step: 414850, training_loss: 5.66444e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:14:14.498296 22392998065984 run_lib.py:146] step: 414900, training_loss: 5.40649e-02
I0516 03:14:14.669145 22392998065984 run_lib.py:167] step: 414900, eval_loss: 4.85638e-02
I0516 03:14:39.321264 22392998065984 run_lib.py:146] step: 414950, training_loss: 4.90506e-02
I0516 03:15:03.758461 22392998065984 run_lib.py:146] step: 415000, training_loss: 5.63761e-02
I0516 03:15:03.920063 22392998065984 run_lib.py:167] step: 415000, eval_loss: 5.98907e-02
I0516 03:15:28.164286 22392998065984 run_lib.py:146] step: 415050, training_loss: 5.49613e-02
I0516 03:15:52.953014 22392998065984 run_lib.py:146] step: 415100, training_loss: 5.98101e-02
I0516 03:15:53.120152 22392998065984 run_lib.py:167] step: 415100, eval_loss: 5.59822e-02
I0516 03:16:17.881572 22392998065984 run_lib.py:146] step: 415150, training_loss: 6.51525e-02
I0516 03:16:41.869193 22392998065984 run_lib.py:146] step: 415200, training_loss: 5.85455e-02
I0516 03:16:42.030302 22392998065984 run_lib.py:167] step: 415200, eval_loss: 5.55625e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:17:06.368121 22392998065984 run_lib.py:146] step: 415250, training_loss: 5.22187e-02
I0516 03:17:30.772941 22392998065984 run_lib.py:146] step: 415300, training_loss: 5.51807e-02
I0516 03:17:30.937863 22392998065984 run_lib.py:167] step: 415300, eval_loss: 6.19798e-02
I0516 03:17:54.907003 22392998065984 run_lib.py:146] step: 415350, training_loss: 5.67207e-02
I0516 03:18:19.065214 22392998065984 run_lib.py:146] step: 415400, training_loss: 4.89571e-02
I0516 03:18:19.241361 22392998065984 run_lib.py:167] step: 415400, eval_loss: 5.80872e-02
I0516 03:18:43.655152 22392998065984 run_lib.py:146] step: 415450, training_loss: 6.13867e-02
I0516 03:19:07.476919 22392998065984 run_lib.py:146] step: 415500, training_loss: 5.25651e-02
I0516 03:19:07.637752 22392998065984 run_lib.py:167] step: 415500, eval_loss: 4.98504e-02
I0516 03:19:32.213424 22392998065984 run_lib.py:146] step: 415550, training_loss: 5.11540e-02
I0516 03:19:56.903139 22392998065984 run_lib.py:146] step: 415600, training_loss: 7.59945e-02
I0516 03:19:57.063537 22392998065984 run_lib.py:167] step: 415600, eval_loss: 5.45846e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:20:21.158959 22392998065984 run_lib.py:146] step: 415650, training_loss: 5.30812e-02
I0516 03:20:45.807862 22392998065984 run_lib.py:146] step: 415700, training_loss: 8.11435e-02
I0516 03:20:45.984280 22392998065984 run_lib.py:167] step: 415700, eval_loss: 6.14440e-02
I0516 03:21:10.715074 22392998065984 run_lib.py:146] step: 415750, training_loss: 5.64177e-02
I0516 03:21:35.476512 22392998065984 run_lib.py:146] step: 415800, training_loss: 5.66948e-02
I0516 03:21:35.639209 22392998065984 run_lib.py:167] step: 415800, eval_loss: 5.08399e-02
I0516 03:21:59.833533 22392998065984 run_lib.py:146] step: 415850, training_loss: 5.78932e-02
I0516 03:22:24.479653 22392998065984 run_lib.py:146] step: 415900, training_loss: 4.98856e-02
I0516 03:22:24.640075 22392998065984 run_lib.py:167] step: 415900, eval_loss: 6.16211e-02
I0516 03:22:49.256908 22392998065984 run_lib.py:146] step: 415950, training_loss: 7.98744e-02
I0516 03:23:13.538677 22392998065984 run_lib.py:146] step: 416000, training_loss: 6.76899e-02
I0516 03:23:13.700972 22392998065984 run_lib.py:167] step: 416000, eval_loss: 8.86460e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:23:38.472179 22392998065984 run_lib.py:146] step: 416050, training_loss: 5.85814e-02
I0516 03:24:03.018216 22392998065984 run_lib.py:146] step: 416100, training_loss: 6.27530e-02
I0516 03:24:03.181219 22392998065984 run_lib.py:167] step: 416100, eval_loss: 8.65270e-02
I0516 03:24:27.163201 22392998065984 run_lib.py:146] step: 416150, training_loss: 6.08953e-02
I0516 03:24:51.882989 22392998065984 run_lib.py:146] step: 416200, training_loss: 5.82544e-02
I0516 03:24:52.042793 22392998065984 run_lib.py:167] step: 416200, eval_loss: 7.02706e-02
I0516 03:25:16.667146 22392998065984 run_lib.py:146] step: 416250, training_loss: 6.31447e-02
I0516 03:25:40.976730 22392998065984 run_lib.py:146] step: 416300, training_loss: 6.96031e-02
I0516 03:25:41.160492 22392998065984 run_lib.py:167] step: 416300, eval_loss: 4.96591e-02
I0516 03:26:05.779380 22392998065984 run_lib.py:146] step: 416350, training_loss: 6.08795e-02
I0516 03:26:30.276943 22392998065984 run_lib.py:146] step: 416400, training_loss: 4.07169e-02
I0516 03:26:30.436336 22392998065984 run_lib.py:167] step: 416400, eval_loss: 7.24960e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:26:54.927053 22392998065984 run_lib.py:146] step: 416450, training_loss: 5.36721e-02
I0516 03:27:19.632905 22392998065984 run_lib.py:146] step: 416500, training_loss: 6.12190e-02
I0516 03:27:19.808932 22392998065984 run_lib.py:167] step: 416500, eval_loss: 6.01927e-02
I0516 03:27:44.280821 22392998065984 run_lib.py:146] step: 416550, training_loss: 8.38970e-02
I0516 03:28:08.720803 22392998065984 run_lib.py:146] step: 416600, training_loss: 5.87462e-02
I0516 03:28:08.890593 22392998065984 run_lib.py:167] step: 416600, eval_loss: 6.44190e-02
I0516 03:28:33.185442 22392998065984 run_lib.py:146] step: 416650, training_loss: 5.45353e-02
I0516 03:28:57.799175 22392998065984 run_lib.py:146] step: 416700, training_loss: 5.83181e-02
I0516 03:28:57.959684 22392998065984 run_lib.py:167] step: 416700, eval_loss: 5.11440e-02
I0516 03:29:22.637706 22392998065984 run_lib.py:146] step: 416750, training_loss: 4.10585e-02
I0516 03:29:47.005648 22392998065984 run_lib.py:146] step: 416800, training_loss: 4.69395e-02
I0516 03:29:47.166627 22392998065984 run_lib.py:167] step: 416800, eval_loss: 5.61945e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:30:11.784001 22392998065984 run_lib.py:146] step: 416850, training_loss: 8.02691e-02
I0516 03:30:36.421355 22392998065984 run_lib.py:146] step: 416900, training_loss: 5.21470e-02
I0516 03:30:36.583758 22392998065984 run_lib.py:167] step: 416900, eval_loss: 6.57742e-02
I0516 03:31:00.927605 22392998065984 run_lib.py:146] step: 416950, training_loss: 5.83949e-02
I0516 03:31:25.727077 22392998065984 run_lib.py:146] step: 417000, training_loss: 4.48168e-02
I0516 03:31:25.910251 22392998065984 run_lib.py:167] step: 417000, eval_loss: 4.26990e-02
I0516 03:31:50.517951 22392998065984 run_lib.py:146] step: 417050, training_loss: 7.52092e-02
I0516 03:32:14.839030 22392998065984 run_lib.py:146] step: 417100, training_loss: 4.97517e-02
I0516 03:32:14.998561 22392998065984 run_lib.py:167] step: 417100, eval_loss: 5.98699e-02
I0516 03:32:39.749688 22392998065984 run_lib.py:146] step: 417150, training_loss: 4.82921e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:33:04.478260 22392998065984 run_lib.py:146] step: 417200, training_loss: 4.88978e-02
I0516 03:33:04.648877 22392998065984 run_lib.py:167] step: 417200, eval_loss: 6.99964e-02
I0516 03:33:29.006659 22392998065984 run_lib.py:146] step: 417250, training_loss: 4.98576e-02
I0516 03:33:53.608367 22392998065984 run_lib.py:146] step: 417300, training_loss: 5.56392e-02
I0516 03:33:53.773183 22392998065984 run_lib.py:167] step: 417300, eval_loss: 5.92390e-02
I0516 03:34:18.530292 22392998065984 run_lib.py:146] step: 417350, training_loss: 5.14495e-02
I0516 03:34:42.815985 22392998065984 run_lib.py:146] step: 417400, training_loss: 6.60108e-02
I0516 03:34:42.986424 22392998065984 run_lib.py:167] step: 417400, eval_loss: 5.17361e-02
I0516 03:35:07.285303 22392998065984 run_lib.py:146] step: 417450, training_loss: 4.97535e-02
I0516 03:35:31.859192 22392998065984 run_lib.py:146] step: 417500, training_loss: 5.16062e-02
I0516 03:35:32.024941 22392998065984 run_lib.py:167] step: 417500, eval_loss: 6.15301e-02
I0516 03:35:56.808175 22392998065984 run_lib.py:146] step: 417550, training_loss: 5.28527e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:36:21.282867 22392998065984 run_lib.py:146] step: 417600, training_loss: 7.49478e-02
I0516 03:36:21.450862 22392998065984 run_lib.py:167] step: 417600, eval_loss: 4.72018e-02
I0516 03:36:46.227128 22392998065984 run_lib.py:146] step: 417650, training_loss: 6.19507e-02
I0516 03:37:10.932976 22392998065984 run_lib.py:146] step: 417700, training_loss: 4.92208e-02
I0516 03:37:11.093060 22392998065984 run_lib.py:167] step: 417700, eval_loss: 5.47427e-02
I0516 03:37:35.308114 22392998065984 run_lib.py:146] step: 417750, training_loss: 5.92928e-02
I0516 03:37:59.961069 22392998065984 run_lib.py:146] step: 417800, training_loss: 5.60017e-02
I0516 03:38:00.131103 22392998065984 run_lib.py:167] step: 417800, eval_loss: 5.43462e-02
I0516 03:38:24.765617 22392998065984 run_lib.py:146] step: 417850, training_loss: 4.61953e-02
I0516 03:38:49.034587 22392998065984 run_lib.py:146] step: 417900, training_loss: 5.27174e-02
I0516 03:38:49.193644 22392998065984 run_lib.py:167] step: 417900, eval_loss: 6.93601e-02
I0516 03:39:13.784340 22392998065984 run_lib.py:146] step: 417950, training_loss: 7.17506e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:39:38.619344 22392998065984 run_lib.py:146] step: 418000, training_loss: 5.20466e-02
I0516 03:39:38.782013 22392998065984 run_lib.py:167] step: 418000, eval_loss: 5.39866e-02
I0516 03:40:03.097091 22392998065984 run_lib.py:146] step: 418050, training_loss: 4.25180e-02
I0516 03:40:27.660741 22392998065984 run_lib.py:146] step: 418100, training_loss: 5.37777e-02
I0516 03:40:27.820983 22392998065984 run_lib.py:167] step: 418100, eval_loss: 6.16957e-02
I0516 03:40:52.544887 22392998065984 run_lib.py:146] step: 418150, training_loss: 4.52152e-02
I0516 03:41:16.865157 22392998065984 run_lib.py:146] step: 418200, training_loss: 7.07361e-02
I0516 03:41:17.042260 22392998065984 run_lib.py:167] step: 418200, eval_loss: 5.15121e-02
I0516 03:41:41.365288 22392998065984 run_lib.py:146] step: 418250, training_loss: 5.39820e-02
I0516 03:42:05.979605 22392998065984 run_lib.py:146] step: 418300, training_loss: 6.03092e-02
I0516 03:42:06.141805 22392998065984 run_lib.py:167] step: 418300, eval_loss: 5.33442e-02
I0516 03:42:30.756355 22392998065984 run_lib.py:146] step: 418350, training_loss: 4.66338e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:42:55.252384 22392998065984 run_lib.py:146] step: 418400, training_loss: 4.20518e-02
I0516 03:42:55.422104 22392998065984 run_lib.py:167] step: 418400, eval_loss: 5.43886e-02
I0516 03:43:20.250748 22392998065984 run_lib.py:146] step: 418450, training_loss: 5.06469e-02
I0516 03:43:44.772207 22392998065984 run_lib.py:146] step: 418500, training_loss: 6.32534e-02
I0516 03:43:44.931630 22392998065984 run_lib.py:167] step: 418500, eval_loss: 7.04399e-02
I0516 03:44:09.311018 22392998065984 run_lib.py:146] step: 418550, training_loss: 5.18499e-02
I0516 03:44:34.092951 22392998065984 run_lib.py:146] step: 418600, training_loss: 6.36028e-02
I0516 03:44:34.189805 22392998065984 run_lib.py:167] step: 418600, eval_loss: 1.05369e-01
I0516 03:44:58.883731 22392998065984 run_lib.py:146] step: 418650, training_loss: 7.34065e-02
I0516 03:45:23.173485 22392998065984 run_lib.py:146] step: 418700, training_loss: 5.92501e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:45:23.606618 22392998065984 run_lib.py:167] step: 418700, eval_loss: 5.58215e-02
I0516 03:45:48.347487 22392998065984 run_lib.py:146] step: 418750, training_loss: 5.50837e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:46:13.252606 22392998065984 run_lib.py:146] step: 418800, training_loss: 4.91814e-02
I0516 03:46:13.415520 22392998065984 run_lib.py:167] step: 418800, eval_loss: 4.75625e-02
I0516 03:46:37.766999 22392998065984 run_lib.py:146] step: 418850, training_loss: 4.96392e-02
I0516 03:47:02.525106 22392998065984 run_lib.py:146] step: 418900, training_loss: 5.51078e-02
I0516 03:47:02.685674 22392998065984 run_lib.py:167] step: 418900, eval_loss: 5.62628e-02
I0516 03:47:27.320326 22392998065984 run_lib.py:146] step: 418950, training_loss: 6.86586e-02
I0516 03:47:51.677536 22392998065984 run_lib.py:146] step: 419000, training_loss: 5.78771e-02
I0516 03:47:51.845582 22392998065984 run_lib.py:167] step: 419000, eval_loss: 6.16370e-02
I0516 03:48:16.407159 22392998065984 run_lib.py:146] step: 419050, training_loss: 5.52436e-02
I0516 03:48:40.671746 22392998065984 run_lib.py:146] step: 419100, training_loss: 5.83594e-02
I0516 03:48:40.831547 22392998065984 run_lib.py:167] step: 419100, eval_loss: 6.96336e-02
I0516 03:49:05.586340 22392998065984 run_lib.py:146] step: 419150, training_loss: 6.17230e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:49:30.075956 22392998065984 run_lib.py:146] step: 419200, training_loss: 3.33583e-02
I0516 03:49:30.243644 22392998065984 run_lib.py:167] step: 419200, eval_loss: 6.63217e-02
I0516 03:49:55.147480 22392998065984 run_lib.py:146] step: 419250, training_loss: 6.48338e-02
I0516 03:50:19.902906 22392998065984 run_lib.py:146] step: 419300, training_loss: 7.44947e-02
I0516 03:50:20.073721 22392998065984 run_lib.py:167] step: 419300, eval_loss: 5.45731e-02
I0516 03:50:44.346734 22392998065984 run_lib.py:146] step: 419350, training_loss: 4.93426e-02
I0516 03:51:08.910015 22392998065984 run_lib.py:146] step: 419400, training_loss: 5.85920e-02
I0516 03:51:09.088154 22392998065984 run_lib.py:167] step: 419400, eval_loss: 7.02538e-02
I0516 03:51:33.795526 22392998065984 run_lib.py:146] step: 419450, training_loss: 6.77565e-02
I0516 03:51:58.044950 22392998065984 run_lib.py:146] step: 419500, training_loss: 4.47749e-02
I0516 03:51:58.204325 22392998065984 run_lib.py:167] step: 419500, eval_loss: 4.77954e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:52:22.932213 22392998065984 run_lib.py:146] step: 419550, training_loss: 4.78789e-02
I0516 03:52:47.647425 22392998065984 run_lib.py:146] step: 419600, training_loss: 5.28294e-02
I0516 03:52:47.818675 22392998065984 run_lib.py:167] step: 419600, eval_loss: 4.70357e-02
I0516 03:53:12.291708 22392998065984 run_lib.py:146] step: 419650, training_loss: 4.78731e-02
I0516 03:53:36.877302 22392998065984 run_lib.py:146] step: 419700, training_loss: 5.42721e-02
I0516 03:53:37.054244 22392998065984 run_lib.py:167] step: 419700, eval_loss: 6.82086e-02
I0516 03:54:01.838105 22392998065984 run_lib.py:146] step: 419750, training_loss: 6.03054e-02
I0516 03:54:26.097279 22392998065984 run_lib.py:146] step: 419800, training_loss: 6.05125e-02
I0516 03:54:26.275661 22392998065984 run_lib.py:167] step: 419800, eval_loss: 6.49947e-02
I0516 03:54:50.575472 22392998065984 run_lib.py:146] step: 419850, training_loss: 5.00136e-02
I0516 03:55:15.119014 22392998065984 run_lib.py:146] step: 419900, training_loss: 7.89186e-02
I0516 03:55:15.290760 22392998065984 run_lib.py:167] step: 419900, eval_loss: 6.18267e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:55:40.002263 22392998065984 run_lib.py:146] step: 419950, training_loss: 6.38015e-02
I0516 03:56:04.324060 22392998065984 run_lib.py:146] step: 420000, training_loss: 5.57363e-02
I0516 03:56:06.095581 22392998065984 run_lib.py:167] step: 420000, eval_loss: 7.15834e-02
I0516 03:56:32.712989 22392998065984 run_lib.py:146] step: 420050, training_loss: 5.30756e-02
I0516 03:56:56.988497 22392998065984 run_lib.py:146] step: 420100, training_loss: 3.57076e-02
I0516 03:56:57.148872 22392998065984 run_lib.py:167] step: 420100, eval_loss: 7.00231e-02
I0516 03:57:21.478288 22392998065984 run_lib.py:146] step: 420150, training_loss: 5.76185e-02
I0516 03:57:46.878391 22392998065984 run_lib.py:146] step: 420200, training_loss: 6.58793e-02
I0516 03:57:47.047175 22392998065984 run_lib.py:167] step: 420200, eval_loss: 5.66658e-02
I0516 03:58:11.400872 22392998065984 run_lib.py:146] step: 420250, training_loss: 5.33816e-02
I0516 03:58:35.762187 22392998065984 run_lib.py:146] step: 420300, training_loss: 4.27500e-02
I0516 03:58:35.933124 22392998065984 run_lib.py:167] step: 420300, eval_loss: 6.32689e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 03:59:01.169657 22392998065984 run_lib.py:146] step: 420350, training_loss: 5.58526e-02
I0516 03:59:25.439574 22392998065984 run_lib.py:146] step: 420400, training_loss: 5.96706e-02
I0516 03:59:25.620014 22392998065984 run_lib.py:167] step: 420400, eval_loss: 4.55125e-02
I0516 03:59:50.001627 22392998065984 run_lib.py:146] step: 420450, training_loss: 5.97752e-02
I0516 04:00:14.624967 22392998065984 run_lib.py:146] step: 420500, training_loss: 5.98160e-02
I0516 04:00:14.785233 22392998065984 run_lib.py:167] step: 420500, eval_loss: 4.69163e-02
I0516 04:00:39.381322 22392998065984 run_lib.py:146] step: 420550, training_loss: 4.69329e-02
I0516 04:01:03.668993 22392998065984 run_lib.py:146] step: 420600, training_loss: 5.64637e-02
I0516 04:01:03.846903 22392998065984 run_lib.py:167] step: 420600, eval_loss: 6.77585e-02
I0516 04:01:28.474674 22392998065984 run_lib.py:146] step: 420650, training_loss: 5.30834e-02
I0516 04:01:53.039559 22392998065984 run_lib.py:146] step: 420700, training_loss: 5.03345e-02
I0516 04:01:53.209742 22392998065984 run_lib.py:167] step: 420700, eval_loss: 5.16895e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:02:17.732304 22392998065984 run_lib.py:146] step: 420750, training_loss: 7.22138e-02
I0516 04:02:41.972260 22392998065984 run_lib.py:146] step: 420800, training_loss: 6.26558e-02
I0516 04:02:42.160338 22392998065984 run_lib.py:167] step: 420800, eval_loss: 5.31325e-02
I0516 04:03:07.181623 22392998065984 run_lib.py:146] step: 420850, training_loss: 5.93042e-02
I0516 04:03:31.514243 22392998065984 run_lib.py:146] step: 420900, training_loss: 3.93508e-02
I0516 04:03:31.679549 22392998065984 run_lib.py:167] step: 420900, eval_loss: 6.35632e-02
I0516 04:03:55.929659 22392998065984 run_lib.py:146] step: 420950, training_loss: 6.65986e-02
I0516 04:04:20.868636 22392998065984 run_lib.py:146] step: 421000, training_loss: 6.29009e-02
I0516 04:04:21.028003 22392998065984 run_lib.py:167] step: 421000, eval_loss: 6.54447e-02
I0516 04:04:45.375734 22392998065984 run_lib.py:146] step: 421050, training_loss: 4.14283e-02
I0516 04:05:09.654416 22392998065984 run_lib.py:146] step: 421100, training_loss: 7.03544e-02
I0516 04:05:09.815227 22392998065984 run_lib.py:167] step: 421100, eval_loss: 5.04263e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:05:35.132483 22392998065984 run_lib.py:146] step: 421150, training_loss: 5.18942e-02
I0516 04:05:59.542186 22392998065984 run_lib.py:146] step: 421200, training_loss: 8.50167e-02
I0516 04:05:59.703625 22392998065984 run_lib.py:167] step: 421200, eval_loss: 5.02082e-02
I0516 04:06:24.162029 22392998065984 run_lib.py:146] step: 421250, training_loss: 5.67661e-02
I0516 04:06:49.234364 22392998065984 run_lib.py:146] step: 421300, training_loss: 4.80434e-02
I0516 04:06:49.404557 22392998065984 run_lib.py:167] step: 421300, eval_loss: 6.00244e-02
I0516 04:07:13.679638 22392998065984 run_lib.py:146] step: 421350, training_loss: 5.68970e-02
I0516 04:07:37.741747 22392998065984 run_lib.py:146] step: 421400, training_loss: 5.84471e-02
I0516 04:07:37.901439 22392998065984 run_lib.py:167] step: 421400, eval_loss: 6.06910e-02
I0516 04:08:02.336336 22392998065984 run_lib.py:146] step: 421450, training_loss: 5.41629e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:08:27.050219 22392998065984 run_lib.py:146] step: 421500, training_loss: 4.81240e-02
I0516 04:08:27.221559 22392998065984 run_lib.py:167] step: 421500, eval_loss: 6.10717e-02
I0516 04:08:51.556993 22392998065984 run_lib.py:146] step: 421550, training_loss: 3.99355e-02
I0516 04:09:16.293590 22392998065984 run_lib.py:146] step: 421600, training_loss: 5.18150e-02
I0516 04:09:16.464513 22392998065984 run_lib.py:167] step: 421600, eval_loss: 6.84834e-02
I0516 04:09:41.182415 22392998065984 run_lib.py:146] step: 421650, training_loss: 5.94301e-02
I0516 04:10:05.548118 22392998065984 run_lib.py:146] step: 421700, training_loss: 6.15040e-02
I0516 04:10:05.708607 22392998065984 run_lib.py:167] step: 421700, eval_loss: 5.53669e-02
I0516 04:10:29.992120 22392998065984 run_lib.py:146] step: 421750, training_loss: 7.41082e-02
I0516 04:10:54.887434 22392998065984 run_lib.py:146] step: 421800, training_loss: 7.37386e-02
I0516 04:10:55.064366 22392998065984 run_lib.py:167] step: 421800, eval_loss: 8.69070e-02
I0516 04:11:19.322370 22392998065984 run_lib.py:146] step: 421850, training_loss: 5.91877e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:11:43.777420 22392998065984 run_lib.py:146] step: 421900, training_loss: 7.08563e-02
I0516 04:11:43.962817 22392998065984 run_lib.py:167] step: 421900, eval_loss: 6.15537e-02
I0516 04:12:08.960757 22392998065984 run_lib.py:146] step: 421950, training_loss: 6.18646e-02
I0516 04:12:33.310363 22392998065984 run_lib.py:146] step: 422000, training_loss: 6.78508e-02
I0516 04:12:33.480280 22392998065984 run_lib.py:167] step: 422000, eval_loss: 4.98909e-02
I0516 04:12:57.857061 22392998065984 run_lib.py:146] step: 422050, training_loss: 5.52959e-02
I0516 04:13:22.768557 22392998065984 run_lib.py:146] step: 422100, training_loss: 5.50399e-02
I0516 04:13:22.928933 22392998065984 run_lib.py:167] step: 422100, eval_loss: 6.47779e-02
I0516 04:13:47.222336 22392998065984 run_lib.py:146] step: 422150, training_loss: 4.81321e-02
I0516 04:14:11.502853 22392998065984 run_lib.py:146] step: 422200, training_loss: 6.19445e-02
I0516 04:14:11.673636 22392998065984 run_lib.py:167] step: 422200, eval_loss: 6.16417e-02
I0516 04:14:36.336704 22392998065984 run_lib.py:146] step: 422250, training_loss: 7.48936e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:15:01.081155 22392998065984 run_lib.py:146] step: 422300, training_loss: 5.67203e-02
I0516 04:15:01.253917 22392998065984 run_lib.py:167] step: 422300, eval_loss: 6.12033e-02
I0516 04:15:25.627501 22392998065984 run_lib.py:146] step: 422350, training_loss: 5.67387e-02
I0516 04:15:50.032437 22392998065984 run_lib.py:146] step: 422400, training_loss: 5.00986e-02
I0516 04:15:50.201853 22392998065984 run_lib.py:167] step: 422400, eval_loss: 4.91332e-02
I0516 04:16:15.243251 22392998065984 run_lib.py:146] step: 422450, training_loss: 5.41018e-02
I0516 04:16:39.553622 22392998065984 run_lib.py:146] step: 422500, training_loss: 3.95330e-02
I0516 04:16:39.723026 22392998065984 run_lib.py:167] step: 422500, eval_loss: 4.20204e-02
I0516 04:17:04.016803 22392998065984 run_lib.py:146] step: 422550, training_loss: 6.04924e-02
I0516 04:17:29.139869 22392998065984 run_lib.py:146] step: 422600, training_loss: 4.27165e-02
I0516 04:17:29.307572 22392998065984 run_lib.py:167] step: 422600, eval_loss: 5.25214e-02
I0516 04:17:53.565429 22392998065984 run_lib.py:146] step: 422650, training_loss: 5.63125e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:18:18.120705 22392998065984 run_lib.py:146] step: 422700, training_loss: 4.95908e-02
I0516 04:18:18.291077 22392998065984 run_lib.py:167] step: 422700, eval_loss: 6.53685e-02
I0516 04:18:43.525647 22392998065984 run_lib.py:146] step: 422750, training_loss: 5.89324e-02
I0516 04:19:07.912481 22392998065984 run_lib.py:146] step: 422800, training_loss: 6.12399e-02
I0516 04:19:08.072048 22392998065984 run_lib.py:167] step: 422800, eval_loss: 6.45576e-02
I0516 04:19:32.431439 22392998065984 run_lib.py:146] step: 422850, training_loss: 8.51726e-02
I0516 04:19:57.428493 22392998065984 run_lib.py:146] step: 422900, training_loss: 6.67224e-02
I0516 04:19:57.596979 22392998065984 run_lib.py:167] step: 422900, eval_loss: 5.21047e-02
I0516 04:20:21.921286 22392998065984 run_lib.py:146] step: 422950, training_loss: 5.47797e-02
I0516 04:20:46.199046 22392998065984 run_lib.py:146] step: 423000, training_loss: 7.51733e-02
I0516 04:20:46.378174 22392998065984 run_lib.py:167] step: 423000, eval_loss: 6.01807e-02
I0516 04:21:10.927908 22392998065984 run_lib.py:146] step: 423050, training_loss: 5.67619e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:21:35.534460 22392998065984 run_lib.py:146] step: 423100, training_loss: 6.50771e-02
I0516 04:21:35.697350 22392998065984 run_lib.py:167] step: 423100, eval_loss: 6.20580e-02
I0516 04:21:59.655217 22392998065984 run_lib.py:146] step: 423150, training_loss: 4.35582e-02
I0516 04:22:24.390594 22392998065984 run_lib.py:146] step: 423200, training_loss: 4.92981e-02
I0516 04:22:24.551089 22392998065984 run_lib.py:167] step: 423200, eval_loss: 8.28398e-02
I0516 04:22:49.134123 22392998065984 run_lib.py:146] step: 423250, training_loss: 4.86676e-02
I0516 04:23:13.387430 22392998065984 run_lib.py:146] step: 423300, training_loss: 5.71136e-02
I0516 04:23:13.563728 22392998065984 run_lib.py:167] step: 423300, eval_loss: 6.44010e-02
I0516 04:23:37.839453 22392998065984 run_lib.py:146] step: 423350, training_loss: 4.98529e-02
I0516 04:24:02.731994 22392998065984 run_lib.py:146] step: 423400, training_loss: 5.77663e-02
I0516 04:24:02.902626 22392998065984 run_lib.py:167] step: 423400, eval_loss: 6.44361e-02
I0516 04:24:27.138550 22392998065984 run_lib.py:146] step: 423450, training_loss: 6.03087e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:24:51.561609 22392998065984 run_lib.py:146] step: 423500, training_loss: 6.05915e-02
I0516 04:24:51.726419 22392998065984 run_lib.py:167] step: 423500, eval_loss: 6.64241e-02
I0516 04:25:16.581138 22392998065984 run_lib.py:146] step: 423550, training_loss: 5.92440e-02
I0516 04:25:40.689477 22392998065984 run_lib.py:146] step: 423600, training_loss: 7.26117e-02
I0516 04:25:40.852409 22392998065984 run_lib.py:167] step: 423600, eval_loss: 4.64357e-02
I0516 04:26:04.958810 22392998065984 run_lib.py:146] step: 423650, training_loss: 4.75439e-02
I0516 04:26:29.877379 22392998065984 run_lib.py:146] step: 423700, training_loss: 5.14487e-02
I0516 04:26:30.060373 22392998065984 run_lib.py:167] step: 423700, eval_loss: 6.06456e-02
I0516 04:26:54.323236 22392998065984 run_lib.py:146] step: 423750, training_loss: 6.34146e-02
I0516 04:27:18.542143 22392998065984 run_lib.py:146] step: 423800, training_loss: 6.83782e-02
I0516 04:27:18.725797 22392998065984 run_lib.py:167] step: 423800, eval_loss: 7.80086e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:27:43.521470 22392998065984 run_lib.py:146] step: 423850, training_loss: 6.34922e-02
I0516 04:28:08.407632 22392998065984 run_lib.py:146] step: 423900, training_loss: 4.37004e-02
I0516 04:28:08.575393 22392998065984 run_lib.py:167] step: 423900, eval_loss: 6.60449e-02
I0516 04:28:32.788667 22392998065984 run_lib.py:146] step: 423950, training_loss: 6.40962e-02
I0516 04:28:57.634495 22392998065984 run_lib.py:146] step: 424000, training_loss: 6.60519e-02
I0516 04:28:57.803494 22392998065984 run_lib.py:167] step: 424000, eval_loss: 7.05407e-02
I0516 04:29:22.380055 22392998065984 run_lib.py:146] step: 424050, training_loss: 7.80116e-02
I0516 04:29:46.575395 22392998065984 run_lib.py:146] step: 424100, training_loss: 6.42501e-02
I0516 04:29:46.736497 22392998065984 run_lib.py:167] step: 424100, eval_loss: 6.93898e-02
I0516 04:30:10.992374 22392998065984 run_lib.py:146] step: 424150, training_loss: 5.99923e-02
I0516 04:30:36.050194 22392998065984 run_lib.py:146] step: 424200, training_loss: 5.25429e-02
I0516 04:30:36.210590 22392998065984 run_lib.py:167] step: 424200, eval_loss: 7.04443e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:31:00.654321 22392998065984 run_lib.py:146] step: 424250, training_loss: 3.88969e-02
I0516 04:31:24.868104 22392998065984 run_lib.py:146] step: 424300, training_loss: 6.50207e-02
I0516 04:31:25.034458 22392998065984 run_lib.py:167] step: 424300, eval_loss: 6.93831e-02
I0516 04:31:50.044983 22392998065984 run_lib.py:146] step: 424350, training_loss: 8.37854e-02
I0516 04:32:14.234246 22392998065984 run_lib.py:146] step: 424400, training_loss: 4.11973e-02
I0516 04:32:14.394237 22392998065984 run_lib.py:167] step: 424400, eval_loss: 6.04975e-02
I0516 04:32:38.600155 22392998065984 run_lib.py:146] step: 424450, training_loss: 6.54113e-02
I0516 04:33:03.424340 22392998065984 run_lib.py:146] step: 424500, training_loss: 4.33307e-02
I0516 04:33:03.589278 22392998065984 run_lib.py:167] step: 424500, eval_loss: 5.84759e-02
I0516 04:33:27.790862 22392998065984 run_lib.py:146] step: 424550, training_loss: 5.45850e-02
I0516 04:33:52.138385 22392998065984 run_lib.py:146] step: 424600, training_loss: 5.40427e-02
I0516 04:33:52.300738 22392998065984 run_lib.py:167] step: 424600, eval_loss: 6.11156e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:34:16.829969 22392998065984 run_lib.py:146] step: 424650, training_loss: 8.50653e-02
I0516 04:34:40.958548 22392998065984 run_lib.py:146] step: 424700, training_loss: 4.62894e-02
I0516 04:34:41.120444 22392998065984 run_lib.py:167] step: 424700, eval_loss: 7.03912e-02
I0516 04:35:04.812068 22392998065984 run_lib.py:146] step: 424750, training_loss: 7.76139e-02
I0516 04:35:29.205539 22392998065984 run_lib.py:146] step: 424800, training_loss: 5.19983e-02
I0516 04:35:29.364613 22392998065984 run_lib.py:167] step: 424800, eval_loss: 5.96083e-02
I0516 04:35:53.736572 22392998065984 run_lib.py:146] step: 424850, training_loss: 4.25985e-02
I0516 04:36:18.168278 22392998065984 run_lib.py:146] step: 424900, training_loss: 5.07204e-02
I0516 04:36:18.340343 22392998065984 run_lib.py:167] step: 424900, eval_loss: 7.08471e-02
I0516 04:36:42.116036 22392998065984 run_lib.py:146] step: 424950, training_loss: 6.28410e-02
I0516 04:37:06.466245 22392998065984 run_lib.py:146] step: 425000, training_loss: 4.51398e-02
I0516 04:37:06.624947 22392998065984 run_lib.py:167] step: 425000, eval_loss: 5.30471e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:37:30.399897 22392998065984 run_lib.py:146] step: 425050, training_loss: 5.41246e-02
I0516 04:37:54.056674 22392998065984 run_lib.py:146] step: 425100, training_loss: 6.72014e-02
I0516 04:37:54.216299 22392998065984 run_lib.py:167] step: 425100, eval_loss: 5.79379e-02
I0516 04:38:18.851144 22392998065984 run_lib.py:146] step: 425150, training_loss: 6.02862e-02
I0516 04:38:42.717151 22392998065984 run_lib.py:146] step: 425200, training_loss: 5.75387e-02
I0516 04:38:42.875553 22392998065984 run_lib.py:167] step: 425200, eval_loss: 6.97795e-02
I0516 04:39:06.630372 22392998065984 run_lib.py:146] step: 425250, training_loss: 5.28810e-02
I0516 04:39:31.595372 22392998065984 run_lib.py:146] step: 425300, training_loss: 5.45039e-02
I0516 04:39:31.754359 22392998065984 run_lib.py:167] step: 425300, eval_loss: 4.83928e-02
I0516 04:39:56.060928 22392998065984 run_lib.py:146] step: 425350, training_loss: 3.89526e-02
I0516 04:40:20.340418 22392998065984 run_lib.py:146] step: 425400, training_loss: 7.88813e-02
I0516 04:40:20.502332 22392998065984 run_lib.py:167] step: 425400, eval_loss: 4.45191e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:40:45.273724 22392998065984 run_lib.py:146] step: 425450, training_loss: 4.01861e-02
I0516 04:41:09.921703 22392998065984 run_lib.py:146] step: 425500, training_loss: 5.15016e-02
I0516 04:41:10.081015 22392998065984 run_lib.py:167] step: 425500, eval_loss: 5.92756e-02
I0516 04:41:34.379778 22392998065984 run_lib.py:146] step: 425550, training_loss: 5.34518e-02
I0516 04:41:59.044933 22392998065984 run_lib.py:146] step: 425600, training_loss: 4.82316e-02
I0516 04:41:59.202794 22392998065984 run_lib.py:167] step: 425600, eval_loss: 5.72577e-02
I0516 04:42:23.807009 22392998065984 run_lib.py:146] step: 425650, training_loss: 5.66486e-02
I0516 04:42:48.116621 22392998065984 run_lib.py:146] step: 425700, training_loss: 5.65864e-02
I0516 04:42:48.275212 22392998065984 run_lib.py:167] step: 425700, eval_loss: 5.69860e-02
I0516 04:43:12.624427 22392998065984 run_lib.py:146] step: 425750, training_loss: 5.71878e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:43:37.607237 22392998065984 run_lib.py:146] step: 425800, training_loss: 4.96005e-02
I0516 04:43:37.767716 22392998065984 run_lib.py:167] step: 425800, eval_loss: 6.82550e-02
I0516 04:44:01.715450 22392998065984 run_lib.py:146] step: 425850, training_loss: 5.63965e-02
I0516 04:44:25.929395 22392998065984 run_lib.py:146] step: 425900, training_loss: 5.38622e-02
I0516 04:44:26.090675 22392998065984 run_lib.py:167] step: 425900, eval_loss: 4.40868e-02
I0516 04:44:51.057650 22392998065984 run_lib.py:146] step: 425950, training_loss: 5.16404e-02
I0516 04:45:15.256705 22392998065984 run_lib.py:146] step: 426000, training_loss: 5.77053e-02
I0516 04:45:15.420186 22392998065984 run_lib.py:167] step: 426000, eval_loss: 6.05569e-02
I0516 04:45:39.131078 22392998065984 run_lib.py:146] step: 426050, training_loss: 5.76413e-02
I0516 04:46:03.460750 22392998065984 run_lib.py:146] step: 426100, training_loss: 5.17704e-02
I0516 04:46:03.621021 22392998065984 run_lib.py:167] step: 426100, eval_loss: 5.69870e-02
I0516 04:46:27.265017 22392998065984 run_lib.py:146] step: 426150, training_loss: 5.57602e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:46:51.203323 22392998065984 run_lib.py:146] step: 426200, training_loss: 6.14510e-02
I0516 04:46:51.366893 22392998065984 run_lib.py:167] step: 426200, eval_loss: 6.13214e-02
I0516 04:47:16.038554 22392998065984 run_lib.py:146] step: 426250, training_loss: 5.29246e-02
I0516 04:47:40.462004 22392998065984 run_lib.py:146] step: 426300, training_loss: 4.72996e-02
I0516 04:47:40.623949 22392998065984 run_lib.py:167] step: 426300, eval_loss: 7.27262e-02
I0516 04:48:04.505485 22392998065984 run_lib.py:146] step: 426350, training_loss: 6.64906e-02
I0516 04:48:28.637955 22392998065984 run_lib.py:146] step: 426400, training_loss: 6.94633e-02
I0516 04:48:28.798020 22392998065984 run_lib.py:167] step: 426400, eval_loss: 6.30397e-02
I0516 04:48:53.185716 22392998065984 run_lib.py:146] step: 426450, training_loss: 6.69911e-02
I0516 04:49:17.354340 22392998065984 run_lib.py:146] step: 426500, training_loss: 4.74063e-02
I0516 04:49:17.443002 22392998065984 run_lib.py:167] step: 426500, eval_loss: 6.16754e-02
I0516 04:49:41.128803 22392998065984 run_lib.py:146] step: 426550, training_loss: 6.00787e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:50:05.684639 22392998065984 run_lib.py:146] step: 426600, training_loss: 4.92105e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:50:06.080549 22392998065984 run_lib.py:167] step: 426600, eval_loss: 7.74024e-02
I0516 04:50:30.348319 22392998065984 run_lib.py:146] step: 426650, training_loss: 6.39062e-02
I0516 04:50:54.617208 22392998065984 run_lib.py:146] step: 426700, training_loss: 5.57959e-02
I0516 04:50:54.776442 22392998065984 run_lib.py:167] step: 426700, eval_loss: 7.15395e-02
I0516 04:51:19.742492 22392998065984 run_lib.py:146] step: 426750, training_loss: 5.27942e-02
I0516 04:51:43.376838 22392998065984 run_lib.py:146] step: 426800, training_loss: 5.06167e-02
I0516 04:51:43.536841 22392998065984 run_lib.py:167] step: 426800, eval_loss: 7.98601e-02
I0516 04:52:07.186117 22392998065984 run_lib.py:146] step: 426850, training_loss: 5.89240e-02
I0516 04:52:31.582407 22392998065984 run_lib.py:146] step: 426900, training_loss: 5.80044e-02
I0516 04:52:31.744105 22392998065984 run_lib.py:167] step: 426900, eval_loss: 7.53065e-02
I0516 04:52:55.483731 22392998065984 run_lib.py:146] step: 426950, training_loss: 5.31247e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:53:19.670347 22392998065984 run_lib.py:146] step: 427000, training_loss: 5.28881e-02
I0516 04:53:19.829952 22392998065984 run_lib.py:167] step: 427000, eval_loss: 5.40341e-02
I0516 04:53:43.965676 22392998065984 run_lib.py:146] step: 427050, training_loss: 6.52106e-02
I0516 04:54:08.077234 22392998065984 run_lib.py:146] step: 427100, training_loss: 5.57160e-02
I0516 04:54:08.240792 22392998065984 run_lib.py:167] step: 427100, eval_loss: 5.91431e-02
I0516 04:54:32.308788 22392998065984 run_lib.py:146] step: 427150, training_loss: 6.78817e-02
I0516 04:54:56.360057 22392998065984 run_lib.py:146] step: 427200, training_loss: 4.88636e-02
I0516 04:54:56.522319 22392998065984 run_lib.py:167] step: 427200, eval_loss: 9.45509e-02
I0516 04:55:20.779393 22392998065984 run_lib.py:146] step: 427250, training_loss: 5.40580e-02
I0516 04:55:44.926283 22392998065984 run_lib.py:146] step: 427300, training_loss: 6.73908e-02
I0516 04:55:45.089646 22392998065984 run_lib.py:167] step: 427300, eval_loss: 7.36451e-02
I0516 04:56:09.713592 22392998065984 run_lib.py:146] step: 427350, training_loss: 6.20713e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:56:34.150899 22392998065984 run_lib.py:146] step: 427400, training_loss: 3.74449e-02
I0516 04:56:34.311171 22392998065984 run_lib.py:167] step: 427400, eval_loss: 7.39715e-02
I0516 04:56:57.944692 22392998065984 run_lib.py:146] step: 427450, training_loss: 6.44513e-02
I0516 04:57:21.688335 22392998065984 run_lib.py:146] step: 427500, training_loss: 4.87855e-02
I0516 04:57:21.846815 22392998065984 run_lib.py:167] step: 427500, eval_loss: 5.48560e-02
I0516 04:57:46.180543 22392998065984 run_lib.py:146] step: 427550, training_loss: 4.90894e-02
I0516 04:58:09.837682 22392998065984 run_lib.py:146] step: 427600, training_loss: 6.73435e-02
I0516 04:58:09.996114 22392998065984 run_lib.py:167] step: 427600, eval_loss: 6.58980e-02
I0516 04:58:33.819043 22392998065984 run_lib.py:146] step: 427650, training_loss: 7.63534e-02
I0516 04:58:58.659440 22392998065984 run_lib.py:146] step: 427700, training_loss: 5.31431e-02
I0516 04:58:58.818132 22392998065984 run_lib.py:167] step: 427700, eval_loss: 6.55919e-02
I0516 04:59:22.794801 22392998065984 run_lib.py:146] step: 427750, training_loss: 4.84209e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 04:59:46.639235 22392998065984 run_lib.py:146] step: 427800, training_loss: 4.60557e-02
I0516 04:59:46.799742 22392998065984 run_lib.py:167] step: 427800, eval_loss: 7.35534e-02
I0516 05:00:10.972507 22392998065984 run_lib.py:146] step: 427850, training_loss: 4.62893e-02
I0516 05:00:34.962425 22392998065984 run_lib.py:146] step: 427900, training_loss: 5.81685e-02
I0516 05:00:35.120381 22392998065984 run_lib.py:167] step: 427900, eval_loss: 7.07541e-02
I0516 05:00:58.769685 22392998065984 run_lib.py:146] step: 427950, training_loss: 6.01125e-02
I0516 05:01:23.037437 22392998065984 run_lib.py:146] step: 428000, training_loss: 5.93856e-02
I0516 05:01:23.195760 22392998065984 run_lib.py:167] step: 428000, eval_loss: 5.15290e-02
I0516 05:01:47.726364 22392998065984 run_lib.py:146] step: 428050, training_loss: 5.05674e-02
I0516 05:02:11.981087 22392998065984 run_lib.py:146] step: 428100, training_loss: 5.79230e-02
I0516 05:02:12.142094 22392998065984 run_lib.py:167] step: 428100, eval_loss: 7.47959e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:02:36.828310 22392998065984 run_lib.py:146] step: 428150, training_loss: 4.24412e-02
I0516 05:03:00.948660 22392998065984 run_lib.py:146] step: 428200, training_loss: 6.19447e-02
I0516 05:03:01.110232 22392998065984 run_lib.py:167] step: 428200, eval_loss: 6.80891e-02
I0516 05:03:24.829642 22392998065984 run_lib.py:146] step: 428250, training_loss: 4.14862e-02
I0516 05:03:48.561403 22392998065984 run_lib.py:146] step: 428300, training_loss: 5.37220e-02
I0516 05:03:48.721687 22392998065984 run_lib.py:167] step: 428300, eval_loss: 6.62713e-02
I0516 05:04:13.204610 22392998065984 run_lib.py:146] step: 428350, training_loss: 5.86546e-02
I0516 05:04:37.129099 22392998065984 run_lib.py:146] step: 428400, training_loss: 6.21778e-02
I0516 05:04:37.290050 22392998065984 run_lib.py:167] step: 428400, eval_loss: 5.86616e-02
I0516 05:05:01.012322 22392998065984 run_lib.py:146] step: 428450, training_loss: 6.21564e-02
I0516 05:05:25.346762 22392998065984 run_lib.py:146] step: 428500, training_loss: 5.04930e-02
I0516 05:05:25.506097 22392998065984 run_lib.py:167] step: 428500, eval_loss: 8.17337e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:05:49.466637 22392998065984 run_lib.py:146] step: 428550, training_loss: 5.69386e-02
I0516 05:06:13.732646 22392998065984 run_lib.py:146] step: 428600, training_loss: 5.68421e-02
I0516 05:06:13.894074 22392998065984 run_lib.py:167] step: 428600, eval_loss: 6.69369e-02
I0516 05:06:38.485362 22392998065984 run_lib.py:146] step: 428650, training_loss: 5.85146e-02
I0516 05:07:03.065203 22392998065984 run_lib.py:146] step: 428700, training_loss: 6.08271e-02
I0516 05:07:03.226043 22392998065984 run_lib.py:167] step: 428700, eval_loss: 5.95368e-02
I0516 05:07:27.182872 22392998065984 run_lib.py:146] step: 428750, training_loss: 4.69211e-02
I0516 05:07:51.210031 22392998065984 run_lib.py:146] step: 428800, training_loss: 6.23025e-02
I0516 05:07:51.370058 22392998065984 run_lib.py:167] step: 428800, eval_loss: 8.40620e-02
I0516 05:08:15.541651 22392998065984 run_lib.py:146] step: 428850, training_loss: 5.69326e-02
I0516 05:08:39.760832 22392998065984 run_lib.py:146] step: 428900, training_loss: 5.76432e-02
I0516 05:08:39.933420 22392998065984 run_lib.py:167] step: 428900, eval_loss: 5.67128e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:09:04.432929 22392998065984 run_lib.py:146] step: 428950, training_loss: 6.07085e-02
I0516 05:09:28.917419 22392998065984 run_lib.py:146] step: 429000, training_loss: 5.48593e-02
I0516 05:09:29.082962 22392998065984 run_lib.py:167] step: 429000, eval_loss: 7.12484e-02
I0516 05:09:53.366938 22392998065984 run_lib.py:146] step: 429050, training_loss: 6.78537e-02
I0516 05:10:17.600057 22392998065984 run_lib.py:146] step: 429100, training_loss: 6.48850e-02
I0516 05:10:17.760948 22392998065984 run_lib.py:167] step: 429100, eval_loss: 5.85265e-02
I0516 05:10:42.732422 22392998065984 run_lib.py:146] step: 429150, training_loss: 5.05362e-02
I0516 05:11:06.941184 22392998065984 run_lib.py:146] step: 429200, training_loss: 6.20959e-02
I0516 05:11:07.100763 22392998065984 run_lib.py:167] step: 429200, eval_loss: 5.74863e-02
I0516 05:11:31.339256 22392998065984 run_lib.py:146] step: 429250, training_loss: 5.81550e-02
I0516 05:11:56.348274 22392998065984 run_lib.py:146] step: 429300, training_loss: 5.07817e-02
I0516 05:11:56.509863 22392998065984 run_lib.py:167] step: 429300, eval_loss: 6.40414e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:12:20.942698 22392998065984 run_lib.py:146] step: 429350, training_loss: 5.37492e-02
I0516 05:12:45.256813 22392998065984 run_lib.py:146] step: 429400, training_loss: 4.98977e-02
I0516 05:12:45.428828 22392998065984 run_lib.py:167] step: 429400, eval_loss: 5.01654e-02
I0516 05:13:10.417783 22392998065984 run_lib.py:146] step: 429450, training_loss: 6.95794e-02
I0516 05:13:34.658243 22392998065984 run_lib.py:146] step: 429500, training_loss: 6.73807e-02
I0516 05:13:34.827744 22392998065984 run_lib.py:167] step: 429500, eval_loss: 6.66654e-02
I0516 05:13:58.942278 22392998065984 run_lib.py:146] step: 429550, training_loss: 6.89573e-02
I0516 05:14:23.686342 22392998065984 run_lib.py:146] step: 429600, training_loss: 5.21734e-02
I0516 05:14:23.848338 22392998065984 run_lib.py:167] step: 429600, eval_loss: 7.24274e-02
I0516 05:14:48.027700 22392998065984 run_lib.py:146] step: 429650, training_loss: 4.53940e-02
I0516 05:15:11.920582 22392998065984 run_lib.py:146] step: 429700, training_loss: 6.41595e-02
I0516 05:15:12.081307 22392998065984 run_lib.py:167] step: 429700, eval_loss: 5.95439e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:15:36.942339 22392998065984 run_lib.py:146] step: 429750, training_loss: 5.87594e-02
I0516 05:16:01.747498 22392998065984 run_lib.py:146] step: 429800, training_loss: 6.50703e-02
I0516 05:16:01.918426 22392998065984 run_lib.py:167] step: 429800, eval_loss: 6.51977e-02
I0516 05:16:25.955896 22392998065984 run_lib.py:146] step: 429850, training_loss: 8.40173e-02
I0516 05:16:50.772526 22392998065984 run_lib.py:146] step: 429900, training_loss: 5.40840e-02
I0516 05:16:50.940669 22392998065984 run_lib.py:167] step: 429900, eval_loss: 5.94887e-02
I0516 05:17:15.503184 22392998065984 run_lib.py:146] step: 429950, training_loss: 7.92828e-02
I0516 05:17:39.911938 22392998065984 run_lib.py:146] step: 430000, training_loss: 5.96885e-02
I0516 05:17:41.650165 22392998065984 run_lib.py:167] step: 430000, eval_loss: 5.46631e-02
I0516 05:18:07.700145 22392998065984 run_lib.py:146] step: 430050, training_loss: 5.75026e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:18:32.054613 22392998065984 run_lib.py:146] step: 430100, training_loss: 5.38342e-02
I0516 05:18:32.218005 22392998065984 run_lib.py:167] step: 430100, eval_loss: 5.54441e-02
I0516 05:18:56.001288 22392998065984 run_lib.py:146] step: 430150, training_loss: 5.36434e-02
I0516 05:19:20.497465 22392998065984 run_lib.py:146] step: 430200, training_loss: 5.99142e-02
I0516 05:19:20.666984 22392998065984 run_lib.py:167] step: 430200, eval_loss: 5.49478e-02
I0516 05:19:45.363708 22392998065984 run_lib.py:146] step: 430250, training_loss: 5.45744e-02
I0516 05:20:09.772594 22392998065984 run_lib.py:146] step: 430300, training_loss: 4.90309e-02
I0516 05:20:09.942663 22392998065984 run_lib.py:167] step: 430300, eval_loss: 8.60159e-02
I0516 05:20:34.298287 22392998065984 run_lib.py:146] step: 430350, training_loss: 4.54001e-02
I0516 05:20:58.593800 22392998065984 run_lib.py:146] step: 430400, training_loss: 5.76053e-02
I0516 05:20:58.753733 22392998065984 run_lib.py:167] step: 430400, eval_loss: 5.15190e-02
I0516 05:21:22.456035 22392998065984 run_lib.py:146] step: 430450, training_loss: 5.77671e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:21:46.459944 22392998065984 run_lib.py:146] step: 430500, training_loss: 5.20959e-02
I0516 05:21:46.630293 22392998065984 run_lib.py:167] step: 430500, eval_loss: 7.81167e-02
I0516 05:22:11.871731 22392998065984 run_lib.py:146] step: 430550, training_loss: 7.17800e-02
I0516 05:22:36.246128 22392998065984 run_lib.py:146] step: 430600, training_loss: 4.52928e-02
I0516 05:22:36.405994 22392998065984 run_lib.py:167] step: 430600, eval_loss: 7.81940e-02
I0516 05:23:00.107044 22392998065984 run_lib.py:146] step: 430650, training_loss: 5.94467e-02
I0516 05:23:24.709830 22392998065984 run_lib.py:146] step: 430700, training_loss: 4.15612e-02
I0516 05:23:24.871665 22392998065984 run_lib.py:167] step: 430700, eval_loss: 4.90260e-02
I0516 05:23:48.708276 22392998065984 run_lib.py:146] step: 430750, training_loss: 4.43320e-02
I0516 05:24:12.651401 22392998065984 run_lib.py:146] step: 430800, training_loss: 5.92061e-02
I0516 05:24:12.813662 22392998065984 run_lib.py:167] step: 430800, eval_loss: 5.06322e-02
I0516 05:24:36.820027 22392998065984 run_lib.py:146] step: 430850, training_loss: 5.31384e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:25:01.143743 22392998065984 run_lib.py:146] step: 430900, training_loss: 6.53648e-02
I0516 05:25:01.305220 22392998065984 run_lib.py:167] step: 430900, eval_loss: 6.07974e-02
I0516 05:25:25.391983 22392998065984 run_lib.py:146] step: 430950, training_loss: 5.60829e-02
I0516 05:25:49.609280 22392998065984 run_lib.py:146] step: 431000, training_loss: 5.13586e-02
I0516 05:25:49.769639 22392998065984 run_lib.py:167] step: 431000, eval_loss: 5.62466e-02
I0516 05:26:13.778124 22392998065984 run_lib.py:146] step: 431050, training_loss: 6.54066e-02
I0516 05:26:38.124435 22392998065984 run_lib.py:146] step: 431100, training_loss: 4.98734e-02
I0516 05:26:38.294950 22392998065984 run_lib.py:167] step: 431100, eval_loss: 5.02761e-02
I0516 05:27:02.617235 22392998065984 run_lib.py:146] step: 431150, training_loss: 5.16080e-02
I0516 05:27:27.025912 22392998065984 run_lib.py:146] step: 431200, training_loss: 5.74297e-02
I0516 05:27:27.187622 22392998065984 run_lib.py:167] step: 431200, eval_loss: 6.72262e-02
I0516 05:27:50.908910 22392998065984 run_lib.py:146] step: 431250, training_loss: 5.69874e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:28:14.822869 22392998065984 run_lib.py:146] step: 431300, training_loss: 4.29900e-02
I0516 05:28:14.984723 22392998065984 run_lib.py:167] step: 431300, eval_loss: 6.30199e-02
I0516 05:28:39.495508 22392998065984 run_lib.py:146] step: 431350, training_loss: 6.12938e-02
I0516 05:29:03.385989 22392998065984 run_lib.py:146] step: 431400, training_loss: 4.55431e-02
I0516 05:29:03.555260 22392998065984 run_lib.py:167] step: 431400, eval_loss: 7.36853e-02
I0516 05:29:27.428097 22392998065984 run_lib.py:146] step: 431450, training_loss: 8.55078e-02
I0516 05:29:52.498768 22392998065984 run_lib.py:146] step: 431500, training_loss: 5.33178e-02
I0516 05:29:52.667072 22392998065984 run_lib.py:167] step: 431500, eval_loss: 8.23285e-02
I0516 05:30:17.036815 22392998065984 run_lib.py:146] step: 431550, training_loss: 4.98122e-02
I0516 05:30:41.406970 22392998065984 run_lib.py:146] step: 431600, training_loss: 6.03259e-02
I0516 05:30:41.576288 22392998065984 run_lib.py:167] step: 431600, eval_loss: 7.57072e-02
I0516 05:31:06.238556 22392998065984 run_lib.py:146] step: 431650, training_loss: 6.97688e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:31:30.595767 22392998065984 run_lib.py:146] step: 431700, training_loss: 5.45792e-02
I0516 05:31:30.758231 22392998065984 run_lib.py:167] step: 431700, eval_loss: 6.99590e-02
I0516 05:31:54.475366 22392998065984 run_lib.py:146] step: 431750, training_loss: 5.53333e-02
I0516 05:32:18.590817 22392998065984 run_lib.py:146] step: 431800, training_loss: 5.63169e-02
I0516 05:32:18.750949 22392998065984 run_lib.py:167] step: 431800, eval_loss: 6.78004e-02
I0516 05:32:43.306196 22392998065984 run_lib.py:146] step: 431850, training_loss: 5.08431e-02
I0516 05:33:07.731566 22392998065984 run_lib.py:146] step: 431900, training_loss: 4.37679e-02
I0516 05:33:07.893394 22392998065984 run_lib.py:167] step: 431900, eval_loss: 5.82201e-02
I0516 05:33:32.056224 22392998065984 run_lib.py:146] step: 431950, training_loss: 4.90806e-02
I0516 05:33:57.052442 22392998065984 run_lib.py:146] step: 432000, training_loss: 6.11829e-02
I0516 05:33:57.221502 22392998065984 run_lib.py:167] step: 432000, eval_loss: 6.21747e-02
I0516 05:34:21.664223 22392998065984 run_lib.py:146] step: 432050, training_loss: 6.18274e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:34:45.793309 22392998065984 run_lib.py:146] step: 432100, training_loss: 6.47643e-02
I0516 05:34:45.963748 22392998065984 run_lib.py:167] step: 432100, eval_loss: 5.80233e-02
I0516 05:35:10.836698 22392998065984 run_lib.py:146] step: 432150, training_loss: 6.22090e-02
I0516 05:35:34.609574 22392998065984 run_lib.py:146] step: 432200, training_loss: 6.27654e-02
I0516 05:35:34.771508 22392998065984 run_lib.py:167] step: 432200, eval_loss: 7.87072e-02
I0516 05:35:58.521128 22392998065984 run_lib.py:146] step: 432250, training_loss: 6.79504e-02
I0516 05:36:22.866874 22392998065984 run_lib.py:146] step: 432300, training_loss: 6.83343e-02
I0516 05:36:23.026638 22392998065984 run_lib.py:167] step: 432300, eval_loss: 5.78781e-02
I0516 05:36:46.768442 22392998065984 run_lib.py:146] step: 432350, training_loss: 5.36965e-02
I0516 05:37:11.027193 22392998065984 run_lib.py:146] step: 432400, training_loss: 5.75525e-02
I0516 05:37:11.198490 22392998065984 run_lib.py:167] step: 432400, eval_loss: 5.84758e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:37:36.406534 22392998065984 run_lib.py:146] step: 432450, training_loss: 5.04757e-02
I0516 05:38:00.796782 22392998065984 run_lib.py:146] step: 432500, training_loss: 6.79055e-02
I0516 05:38:00.969188 22392998065984 run_lib.py:167] step: 432500, eval_loss: 6.89698e-02
I0516 05:38:25.357237 22392998065984 run_lib.py:146] step: 432550, training_loss: 4.98724e-02
I0516 05:38:50.037277 22392998065984 run_lib.py:146] step: 432600, training_loss: 4.48290e-02
I0516 05:38:50.206161 22392998065984 run_lib.py:167] step: 432600, eval_loss: 6.90514e-02
I0516 05:39:14.596982 22392998065984 run_lib.py:146] step: 432650, training_loss: 8.68291e-02
I0516 05:39:38.978596 22392998065984 run_lib.py:146] step: 432700, training_loss: 5.41244e-02
I0516 05:39:39.148205 22392998065984 run_lib.py:167] step: 432700, eval_loss: 7.43310e-02
I0516 05:40:03.821920 22392998065984 run_lib.py:146] step: 432750, training_loss: 5.37652e-02
I0516 05:40:28.499672 22392998065984 run_lib.py:146] step: 432800, training_loss: 7.17264e-02
I0516 05:40:28.668335 22392998065984 run_lib.py:167] step: 432800, eval_loss: 6.21221e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:40:53.053570 22392998065984 run_lib.py:146] step: 432850, training_loss: 5.12874e-02
I0516 05:41:16.783144 22392998065984 run_lib.py:146] step: 432900, training_loss: 5.75951e-02
I0516 05:41:16.946471 22392998065984 run_lib.py:167] step: 432900, eval_loss: 6.43151e-02
I0516 05:41:41.367824 22392998065984 run_lib.py:146] step: 432950, training_loss: 8.69506e-02
I0516 05:42:05.092648 22392998065984 run_lib.py:146] step: 433000, training_loss: 4.95037e-02
I0516 05:42:05.254031 22392998065984 run_lib.py:167] step: 433000, eval_loss: 5.23746e-02
I0516 05:42:29.046350 22392998065984 run_lib.py:146] step: 433050, training_loss: 6.40754e-02
I0516 05:42:53.317372 22392998065984 run_lib.py:146] step: 433100, training_loss: 7.60197e-02
I0516 05:42:53.478360 22392998065984 run_lib.py:167] step: 433100, eval_loss: 6.35159e-02
I0516 05:43:17.218932 22392998065984 run_lib.py:146] step: 433150, training_loss: 5.07766e-02
I0516 05:43:40.999484 22392998065984 run_lib.py:146] step: 433200, training_loss: 6.08021e-02
I0516 05:43:41.158974 22392998065984 run_lib.py:167] step: 433200, eval_loss: 5.98126e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:44:05.798226 22392998065984 run_lib.py:146] step: 433250, training_loss: 6.36353e-02
I0516 05:44:29.542409 22392998065984 run_lib.py:146] step: 433300, training_loss: 6.27680e-02
I0516 05:44:29.703576 22392998065984 run_lib.py:167] step: 433300, eval_loss: 6.26653e-02
I0516 05:44:53.422094 22392998065984 run_lib.py:146] step: 433350, training_loss: 6.95290e-02
I0516 05:45:17.465712 22392998065984 run_lib.py:146] step: 433400, training_loss: 3.51699e-02
I0516 05:45:17.624893 22392998065984 run_lib.py:167] step: 433400, eval_loss: 6.59393e-02
I0516 05:45:42.065138 22392998065984 run_lib.py:146] step: 433450, training_loss: 4.77438e-02
I0516 05:46:06.412403 22392998065984 run_lib.py:146] step: 433500, training_loss: 7.29497e-02
I0516 05:46:06.582151 22392998065984 run_lib.py:167] step: 433500, eval_loss: 7.77501e-02
I0516 05:46:31.154358 22392998065984 run_lib.py:146] step: 433550, training_loss: 4.96054e-02
I0516 05:46:55.777690 22392998065984 run_lib.py:146] step: 433600, training_loss: 5.22935e-02
I0516 05:46:55.945949 22392998065984 run_lib.py:167] step: 433600, eval_loss: 6.05020e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:47:20.368780 22392998065984 run_lib.py:146] step: 433650, training_loss: 6.21018e-02
I0516 05:47:44.642959 22392998065984 run_lib.py:146] step: 433700, training_loss: 6.15398e-02
I0516 05:47:44.804274 22392998065984 run_lib.py:167] step: 433700, eval_loss: 6.11158e-02
I0516 05:48:09.960945 22392998065984 run_lib.py:146] step: 433750, training_loss: 5.99617e-02
I0516 05:48:34.201715 22392998065984 run_lib.py:146] step: 433800, training_loss: 4.11398e-02
I0516 05:48:34.366354 22392998065984 run_lib.py:167] step: 433800, eval_loss: 6.20869e-02
I0516 05:48:58.506601 22392998065984 run_lib.py:146] step: 433850, training_loss: 6.57135e-02
I0516 05:49:23.395281 22392998065984 run_lib.py:146] step: 433900, training_loss: 4.94572e-02
I0516 05:49:23.561332 22392998065984 run_lib.py:167] step: 433900, eval_loss: 4.85382e-02
I0516 05:49:47.793567 22392998065984 run_lib.py:146] step: 433950, training_loss: 6.25287e-02
I0516 05:50:12.000905 22392998065984 run_lib.py:146] step: 434000, training_loss: 5.32826e-02
I0516 05:50:12.162292 22392998065984 run_lib.py:167] step: 434000, eval_loss: 6.23313e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:50:37.346503 22392998065984 run_lib.py:146] step: 434050, training_loss: 6.01239e-02
I0516 05:51:01.569874 22392998065984 run_lib.py:146] step: 434100, training_loss: 4.29213e-02
I0516 05:51:01.733933 22392998065984 run_lib.py:167] step: 434100, eval_loss: 6.05303e-02
I0516 05:51:25.831520 22392998065984 run_lib.py:146] step: 434150, training_loss: 5.18398e-02
I0516 05:51:50.442036 22392998065984 run_lib.py:146] step: 434200, training_loss: 4.50393e-02
I0516 05:51:50.604931 22392998065984 run_lib.py:167] step: 434200, eval_loss: 6.84877e-02
I0516 05:52:15.344902 22392998065984 run_lib.py:146] step: 434250, training_loss: 6.89737e-02
I0516 05:52:39.627256 22392998065984 run_lib.py:146] step: 434300, training_loss: 5.59816e-02
I0516 05:52:39.796352 22392998065984 run_lib.py:167] step: 434300, eval_loss: 7.01987e-02
I0516 05:53:04.412157 22392998065984 run_lib.py:146] step: 434350, training_loss: 5.43282e-02
I0516 05:53:29.065541 22392998065984 run_lib.py:146] step: 434400, training_loss: 5.95855e-02
I0516 05:53:29.173021 22392998065984 run_lib.py:167] step: 434400, eval_loss: 1.23981e-01
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:53:53.869241 22392998065984 run_lib.py:146] step: 434450, training_loss: 3.31869e-02
I0516 05:54:18.001795 22392998065984 run_lib.py:146] step: 434500, training_loss: 5.44316e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:54:18.434335 22392998065984 run_lib.py:167] step: 434500, eval_loss: 6.75287e-02
I0516 05:54:43.228062 22392998065984 run_lib.py:146] step: 434550, training_loss: 4.57926e-02
I0516 05:55:07.444260 22392998065984 run_lib.py:146] step: 434600, training_loss: 4.13654e-02
I0516 05:55:07.603835 22392998065984 run_lib.py:167] step: 434600, eval_loss: 4.92822e-02
I0516 05:55:31.334088 22392998065984 run_lib.py:146] step: 434650, training_loss: 7.31232e-02
I0516 05:55:55.679834 22392998065984 run_lib.py:146] step: 434700, training_loss: 5.51723e-02
I0516 05:55:55.838961 22392998065984 run_lib.py:167] step: 434700, eval_loss: 7.10806e-02
I0516 05:56:19.561096 22392998065984 run_lib.py:146] step: 434750, training_loss: 6.57070e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:56:43.744647 22392998065984 run_lib.py:146] step: 434800, training_loss: 5.19024e-02
I0516 05:56:43.906124 22392998065984 run_lib.py:167] step: 434800, eval_loss: 5.31635e-02
I0516 05:57:08.348176 22392998065984 run_lib.py:146] step: 434850, training_loss: 3.91013e-02
I0516 05:57:32.056504 22392998065984 run_lib.py:146] step: 434900, training_loss: 5.06591e-02
I0516 05:57:32.216060 22392998065984 run_lib.py:167] step: 434900, eval_loss: 6.83627e-02
I0516 05:57:56.001214 22392998065984 run_lib.py:146] step: 434950, training_loss: 5.29806e-02
I0516 05:58:20.347866 22392998065984 run_lib.py:146] step: 435000, training_loss: 5.86321e-02
I0516 05:58:20.507293 22392998065984 run_lib.py:167] step: 435000, eval_loss: 6.56835e-02
I0516 05:58:44.222285 22392998065984 run_lib.py:146] step: 435050, training_loss: 4.63123e-02
I0516 05:59:07.921546 22392998065984 run_lib.py:146] step: 435100, training_loss: 6.94466e-02
I0516 05:59:08.082173 22392998065984 run_lib.py:167] step: 435100, eval_loss: 6.47192e-02
I0516 05:59:32.135346 22392998065984 run_lib.py:146] step: 435150, training_loss: 6.01660e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 05:59:56.305278 22392998065984 run_lib.py:146] step: 435200, training_loss: 5.76732e-02
I0516 05:59:56.468578 22392998065984 run_lib.py:167] step: 435200, eval_loss: 7.93589e-02
I0516 06:00:20.175840 22392998065984 run_lib.py:146] step: 435250, training_loss: 5.40329e-02
I0516 06:00:44.495626 22392998065984 run_lib.py:146] step: 435300, training_loss: 7.02982e-02
I0516 06:00:44.666442 22392998065984 run_lib.py:167] step: 435300, eval_loss: 7.50998e-02
I0516 06:01:09.867769 22392998065984 run_lib.py:146] step: 435350, training_loss: 5.30025e-02
I0516 06:01:33.785397 22392998065984 run_lib.py:146] step: 435400, training_loss: 6.63574e-02
I0516 06:01:33.945177 22392998065984 run_lib.py:167] step: 435400, eval_loss: 5.38688e-02
I0516 06:01:57.680628 22392998065984 run_lib.py:146] step: 435450, training_loss: 5.24158e-02
I0516 06:02:22.128026 22392998065984 run_lib.py:146] step: 435500, training_loss: 5.30677e-02
I0516 06:02:22.287561 22392998065984 run_lib.py:167] step: 435500, eval_loss: 9.72137e-02
I0516 06:02:46.486461 22392998065984 run_lib.py:146] step: 435550, training_loss: 6.27130e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 06:03:11.042855 22392998065984 run_lib.py:146] step: 435600, training_loss: 4.86827e-02
I0516 06:03:11.212995 22392998065984 run_lib.py:167] step: 435600, eval_loss: 6.34039e-02
I0516 06:03:36.320902 22392998065984 run_lib.py:146] step: 435650, training_loss: 6.88543e-02
I0516 06:04:00.398320 22392998065984 run_lib.py:146] step: 435700, training_loss: 5.10818e-02
I0516 06:04:00.558649 22392998065984 run_lib.py:167] step: 435700, eval_loss: 5.71421e-02
I0516 06:04:24.344228 22392998065984 run_lib.py:146] step: 435750, training_loss: 4.84626e-02
I0516 06:04:48.705000 22392998065984 run_lib.py:146] step: 435800, training_loss: 4.96934e-02
I0516 06:04:48.873291 22392998065984 run_lib.py:167] step: 435800, eval_loss: 6.05292e-02
I0516 06:05:13.202493 22392998065984 run_lib.py:146] step: 435850, training_loss: 3.37396e-02
I0516 06:05:37.560376 22392998065984 run_lib.py:146] step: 435900, training_loss: 4.70900e-02
I0516 06:05:37.729809 22392998065984 run_lib.py:167] step: 435900, eval_loss: 5.41832e-02
I0516 06:06:02.383401 22392998065984 run_lib.py:146] step: 435950, training_loss: 8.04050e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 06:06:26.779008 22392998065984 run_lib.py:146] step: 436000, training_loss: 4.60872e-02
I0516 06:06:26.940406 22392998065984 run_lib.py:167] step: 436000, eval_loss: 6.48192e-02
I0516 06:06:50.729761 22392998065984 run_lib.py:146] step: 436050, training_loss: 5.21173e-02
I0516 06:07:14.867988 22392998065984 run_lib.py:146] step: 436100, training_loss: 5.59963e-02
I0516 06:07:15.140781 22392998065984 run_lib.py:167] step: 436100, eval_loss: 5.87797e-02
I0516 06:07:39.216800 22392998065984 run_lib.py:146] step: 436150, training_loss: 6.38361e-02
I0516 06:08:02.947381 22392998065984 run_lib.py:146] step: 436200, training_loss: 7.91565e-02
I0516 06:08:03.107930 22392998065984 run_lib.py:167] step: 436200, eval_loss: 5.77929e-02
I0516 06:08:27.113414 22392998065984 run_lib.py:146] step: 436250, training_loss: 5.06614e-02
I0516 06:08:52.149274 22392998065984 run_lib.py:146] step: 436300, training_loss: 4.91170e-02
I0516 06:08:52.317899 22392998065984 run_lib.py:167] step: 436300, eval_loss: 6.66201e-02
I0516 06:09:16.745006 22392998065984 run_lib.py:146] step: 436350, training_loss: 5.04437e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 06:09:41.043046 22392998065984 run_lib.py:146] step: 436400, training_loss: 6.96183e-02
I0516 06:09:41.206108 22392998065984 run_lib.py:167] step: 436400, eval_loss: 7.06194e-02
I0516 06:10:05.638367 22392998065984 run_lib.py:146] step: 436450, training_loss: 5.08003e-02
I0516 06:10:29.336608 22392998065984 run_lib.py:146] step: 436500, training_loss: 6.37658e-02
I0516 06:10:29.496033 22392998065984 run_lib.py:167] step: 436500, eval_loss: 6.23111e-02
I0516 06:10:53.214540 22392998065984 run_lib.py:146] step: 436550, training_loss: 7.01786e-02
I0516 06:11:17.602647 22392998065984 run_lib.py:146] step: 436600, training_loss: 6.67296e-02
I0516 06:11:17.762793 22392998065984 run_lib.py:167] step: 436600, eval_loss: 5.07966e-02
I0516 06:11:41.493401 22392998065984 run_lib.py:146] step: 436650, training_loss: 5.21247e-02
I0516 06:12:05.309484 22392998065984 run_lib.py:146] step: 436700, training_loss: 5.44826e-02
I0516 06:12:05.469953 22392998065984 run_lib.py:167] step: 436700, eval_loss: 5.36472e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 06:12:29.760764 22392998065984 run_lib.py:146] step: 436750, training_loss: 4.74261e-02
I0516 06:12:54.466249 22392998065984 run_lib.py:146] step: 436800, training_loss: 5.33923e-02
I0516 06:12:54.636085 22392998065984 run_lib.py:167] step: 436800, eval_loss: 4.89763e-02
I0516 06:13:19.012200 22392998065984 run_lib.py:146] step: 436850, training_loss: 5.73390e-02
I0516 06:13:43.732236 22392998065984 run_lib.py:146] step: 436900, training_loss: 5.40132e-02
I0516 06:13:43.897770 22392998065984 run_lib.py:167] step: 436900, eval_loss: 4.36636e-02
I0516 06:14:07.968492 22392998065984 run_lib.py:146] step: 436950, training_loss: 5.43795e-02
I0516 06:14:31.851939 22392998065984 run_lib.py:146] step: 437000, training_loss: 5.36883e-02
I0516 06:14:32.020287 22392998065984 run_lib.py:167] step: 437000, eval_loss: 6.31710e-02
I0516 06:14:55.859354 22392998065984 run_lib.py:146] step: 437050, training_loss: 5.33892e-02
I0516 06:15:20.158004 22392998065984 run_lib.py:146] step: 437100, training_loss: 6.57628e-02
I0516 06:15:20.318338 22392998065984 run_lib.py:167] step: 437100, eval_loss: 9.42673e-02
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
I0516 06:15:44.438243 22392998065984 run_lib.py:146] step: 437150, training_loss: 5.11015e-02
I0516 06:16:08.824145 22392998065984 run_lib.py:146] step: 437200, training_loss: 7.46989e-02
I0516 06:16:08.996147 22392998065984 run_lib.py:167] step: 437200, eval_loss: 5.16739e-02
I0516 06:16:34.090655 22392998065984 run_lib.py:146] step: 437250, training_loss: 5.42595e-02
slurmstepd: error: *** JOB 53174409 ON gl1501 CANCELLED AT 2023-05-16T06:16:49 ***
