2023-05-17 21:54:25.525704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-17 21:54:33.935689: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-17 21:55:18.996382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-17 21:55:18.997911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-17 21:55:18.997929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/absl/flags/_validators.py:254: UserWarning: Flag --eval_folder has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
I0517 21:58:13.090402 22647664891712 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
I0517 21:58:13.092791 22647664891712 resolver.py:419] Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'.
I0517 21:58:33.423323 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 40.00MB
I0517 21:58:53.122976 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 80.00MB
I0517 21:59:12.843604 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 120.00MB
I0517 21:59:32.800844 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 160.00MB
I0517 21:59:51.705529 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 200.00MB
I0517 22:00:11.505414 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 240.00MB
I0517 22:00:27.778278 22647664891712 resolver.py:157] Downloading https://tfhub.dev/tensorflow/tfgan/eval/inception/1: 273.09MB
I0517 22:00:27.779193 22647664891712 resolver.py:157] Downloaded https://tfhub.dev/tensorflow/tfgan/eval/inception/1, Total size: 273.09MB
I0517 22:00:27.779564 22647664891712 resolver.py:434] Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'.
2023-05-17 22:01:15.615667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43102 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:1f:00.0, compute capability: 8.6
I0517 22:01:17.783678 22647664891712 evaluation_fromsample.py:48] begin checkpoint: 5
I0517 22:01:17.783957 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:01:17.785312 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 0
I0517 22:01:19.303771 22647664891712 xla_bridge.py:440] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0517 22:01:19.303936 22647664891712 xla_bridge.py:440] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0517 22:01:19.609612 22647664891712 xla_bridge.py:440] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0517 22:01:19.609763 22647664891712 xla_bridge.py:440] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0517 22:01:19.609825 22647664891712 xla_bridge.py:448] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0517 22:01:21.411072 22647664891712 deprecation.py:350] From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
2023-05-17 22:01:51.028787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
2023-05-17 22:01:54.150636: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2023-05-17 22:02:01.163419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.
  structure[0], [func(*x) for x in entries],
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:627: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS
I0517 22:02:02.122457 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 1
I0517 22:02:03.846415 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 10
I0517 22:02:05.684660 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 11
I0517 22:02:07.335095 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 12
I0517 22:02:08.905269 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 13
I0517 22:02:10.471016 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 14
I0517 22:02:12.074451 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 15
I0517 22:02:13.647049 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 16
I0517 22:02:15.239759 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 17
I0517 22:02:16.822923 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 18
I0517 22:02:18.426785 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 19
I0517 22:02:19.982998 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 2
I0517 22:02:21.572766 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 20
I0517 22:02:23.159456 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 21
I0517 22:02:24.774116 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 22
I0517 22:02:26.371014 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 23
I0517 22:02:27.930224 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 24
I0517 22:02:29.526065 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 25
I0517 22:02:31.089944 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 26
I0517 22:02:32.692361 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 27
I0517 22:02:34.287271 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 28
I0517 22:02:35.842074 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 29
I0517 22:02:37.485187 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 3
I0517 22:02:39.045478 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 30
I0517 22:02:40.653767 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 31
I0517 22:02:42.289141 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 32
I0517 22:02:43.850615 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 33
I0517 22:02:45.442069 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 34
I0517 22:02:47.006166 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 35
I0517 22:02:48.586271 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 36
I0517 22:02:50.152367 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 37
I0517 22:02:51.866690 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 38
I0517 22:02:53.457340 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 39
I0517 22:02:55.022788 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 4
I0517 22:02:56.584812 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 40
I0517 22:02:58.160110 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 41
I0517 22:02:59.788602 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 42
I0517 22:03:01.249568 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 43
I0517 22:03:02.726907 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 44
I0517 22:03:04.218101 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 45
I0517 22:03:05.688750 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 46
I0517 22:03:07.190132 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 47
I0517 22:03:08.666950 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 48
I0517 22:03:10.152419 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 5
I0517 22:03:11.629974 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 6
I0517 22:03:13.107821 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 7
I0517 22:03:14.584941 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 8
I0517 22:03:16.102995 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 9
I0517 22:03:46.833092 22647664891712 evaluation_fromsample.py:105] ckpt-5 --- FID: 4.890587e+00
I0517 22:03:46.835598 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:03:46.836521 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 0
I0517 22:03:48.316267 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 1
I0517 22:03:49.799692 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 10
I0517 22:03:51.308360 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 11
I0517 22:03:52.776378 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 12
I0517 22:03:54.259910 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 13
I0517 22:03:55.748105 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 14
I0517 22:03:57.219083 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 15
I0517 22:03:58.695337 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 16
I0517 22:04:00.175834 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 17
I0517 22:04:01.630108 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 18
I0517 22:04:03.094830 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 19
I0517 22:04:04.565941 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 2
I0517 22:04:06.049418 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 20
I0517 22:04:07.525171 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 21
I0517 22:04:08.996569 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 22
I0517 22:04:10.448462 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 23
I0517 22:04:11.925075 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 24
I0517 22:04:13.412940 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 25
I0517 22:04:14.937811 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 26
I0517 22:04:16.417870 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 27
I0517 22:04:17.905073 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 28
I0517 22:04:19.376113 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 29
I0517 22:04:20.839262 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 3
I0517 22:04:22.326064 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 30
I0517 22:04:23.800807 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 31
I0517 22:04:25.274754 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 32
I0517 22:04:26.855800 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 33
I0517 22:04:28.366969 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 34
I0517 22:04:29.830767 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 35
I0517 22:04:31.299257 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 36
I0517 22:04:32.823712 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 37
I0517 22:04:34.527157 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 38
I0517 22:04:35.986848 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 39
I0517 22:04:37.502766 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 4
I0517 22:04:38.995379 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 40
I0517 22:04:40.528424 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 41
I0517 22:04:42.078759 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 42
I0517 22:04:43.664968 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 43
I0517 22:04:45.129561 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 44
I0517 22:04:46.610749 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 45
I0517 22:04:48.094311 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 46
I0517 22:04:49.574500 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 47
I0517 22:04:51.050476 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 48
I0517 22:04:52.575131 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 5
I0517 22:04:54.055987 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 6
I0517 22:04:55.554957 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 7
I0517 22:04:57.063057 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 8
I0517 22:04:58.586931 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 9
I0517 22:05:12.999015 22647664891712 evaluation_fromsample.py:105] ckpt-10 --- FID: 3.263686e+00
I0517 22:05:13.001512 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:05:13.002447 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 0
I0517 22:05:14.487675 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 1
I0517 22:05:16.148877 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 10
I0517 22:05:17.620689 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 11
I0517 22:05:19.102275 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 12
I0517 22:05:20.584451 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 13
I0517 22:05:22.054124 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 14
I0517 22:05:23.525105 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 15
I0517 22:05:24.997138 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 16
I0517 22:05:26.481941 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 17
I0517 22:05:27.989857 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 18
I0517 22:05:29.465620 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 19
I0517 22:05:30.952841 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 2
I0517 22:05:32.525583 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 20
I0517 22:05:34.085142 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 21
I0517 22:05:35.745010 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 22
I0517 22:05:37.232259 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 23
I0517 22:05:38.762773 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 24
I0517 22:05:40.245269 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 25
I0517 22:05:41.716530 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 26
I0517 22:05:43.198882 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 27
I0517 22:05:44.670696 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 28
I0517 22:05:46.148079 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 29
I0517 22:05:47.654568 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 3
I0517 22:05:49.817668 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 30
I0517 22:05:51.299497 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 31
I0517 22:05:52.783815 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 32
I0517 22:05:54.252147 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 33
I0517 22:05:55.752627 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 34
I0517 22:05:57.236469 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 35
I0517 22:05:58.892056 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 36
I0517 22:06:00.403629 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 37
I0517 22:06:01.867184 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 38
I0517 22:06:03.375346 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 39
I0517 22:06:04.844442 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 4
I0517 22:06:06.335534 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 40
I0517 22:06:07.854665 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 41
I0517 22:06:09.345222 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 42
I0517 22:06:10.850564 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 43
I0517 22:06:12.346962 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 44
I0517 22:06:13.812178 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 45
I0517 22:06:15.325125 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 46
I0517 22:06:16.775937 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 47
I0517 22:06:18.279037 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 48
I0517 22:06:19.735030 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 5
I0517 22:06:21.204553 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 6
I0517 22:06:22.669319 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 7
I0517 22:06:24.158973 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 8
I0517 22:06:25.668413 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 9
I0517 22:06:39.587468 22647664891712 evaluation_fromsample.py:105] ckpt-15 --- FID: 2.763940e+00
I0517 22:06:39.589993 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:06:39.590941 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 0
I0517 22:06:41.113048 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 1
I0517 22:06:42.639349 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 10
I0517 22:06:44.113633 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 11
I0517 22:06:45.583177 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 12
I0517 22:06:47.079202 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 13
I0517 22:06:48.559262 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 14
I0517 22:06:50.032487 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 15
I0517 22:06:51.570078 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 16
I0517 22:06:53.044050 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 17
I0517 22:06:54.520081 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 18
I0517 22:06:55.979603 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 19
I0517 22:06:57.463662 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 2
I0517 22:06:58.936043 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 20
I0517 22:07:00.428313 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 21
I0517 22:07:01.899655 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 22
I0517 22:07:03.366268 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 23
I0517 22:07:04.839592 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 24
I0517 22:07:06.360206 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 25
I0517 22:07:07.826776 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 26
I0517 22:07:09.409849 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 27
I0517 22:07:10.910516 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 28
I0517 22:07:12.374703 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 29
I0517 22:07:13.865221 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 3
I0517 22:07:15.338825 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 30
I0517 22:07:16.846754 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 31
I0517 22:07:18.384064 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 32
I0517 22:07:19.848506 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 33
I0517 22:07:21.337037 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 34
I0517 22:07:22.856172 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 35
I0517 22:07:24.329364 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 36
I0517 22:07:25.893144 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 37
I0517 22:07:27.781310 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 38
I0517 22:07:29.250516 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 39
I0517 22:07:30.764183 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 4
I0517 22:07:32.237628 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 40
I0517 22:07:33.749839 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 41
I0517 22:07:35.227830 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 42
I0517 22:07:36.692389 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 43
I0517 22:07:38.155204 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 44
I0517 22:07:39.623854 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 45
I0517 22:07:41.098171 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 46
I0517 22:07:42.564723 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 47
I0517 22:07:44.042384 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 48
I0517 22:07:45.527972 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 5
I0517 22:07:47.033774 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 6
I0517 22:07:48.500795 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 7
I0517 22:07:50.006085 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 8
I0517 22:07:51.483700 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 9
I0517 22:08:05.137751 22647664891712 evaluation_fromsample.py:105] ckpt-20 --- FID: 2.751354e+00
I0517 22:08:05.140143 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:08:05.140994 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 0
I0517 22:08:06.621578 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 1
I0517 22:08:08.095191 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 10
I0517 22:08:09.562706 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 11
I0517 22:08:11.023030 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 12
I0517 22:08:12.495714 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 13
I0517 22:08:13.984103 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 14
I0517 22:08:15.485220 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 15
I0517 22:08:16.990467 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 16
I0517 22:08:18.462597 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 17
I0517 22:08:19.948862 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 18
I0517 22:08:21.410725 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 19
I0517 22:08:22.894312 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 2
I0517 22:08:24.378568 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 20
I0517 22:08:25.851902 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 21
I0517 22:08:27.329579 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 22
I0517 22:08:28.806226 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 23
I0517 22:08:30.274847 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 24
I0517 22:08:31.746585 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 25
I0517 22:08:33.206045 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 26
I0517 22:08:34.685578 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 27
I0517 22:08:36.162019 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 28
I0517 22:08:37.622977 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 29
I0517 22:08:39.094084 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 3
I0517 22:08:40.608074 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 30
I0517 22:08:42.114868 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 31
I0517 22:08:43.594993 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 32
I0517 22:08:45.065936 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 33
I0517 22:08:46.805616 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 34
I0517 22:08:48.284573 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 35
I0517 22:08:49.963992 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 36
I0517 22:08:51.493758 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 37
I0517 22:08:52.976577 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 38
I0517 22:08:54.539570 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 39
I0517 22:08:56.013639 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 4
I0517 22:08:57.495232 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 40
I0517 22:08:58.955993 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 41
I0517 22:09:00.484696 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 42
I0517 22:09:02.074681 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 43
I0517 22:09:03.584902 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 44
I0517 22:09:05.167699 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 45
I0517 22:09:06.635572 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 46
I0517 22:09:08.126946 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 47
I0517 22:09:09.603933 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 48
I0517 22:09:11.092904 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 5
I0517 22:09:12.576674 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 6
I0517 22:09:14.065556 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 7
I0517 22:09:15.547781 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 8
I0517 22:09:17.048938 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 9
I0517 22:09:31.607877 22647664891712 evaluation_fromsample.py:105] ckpt-25 --- FID: 2.832034e+00
I0517 22:09:31.609822 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:09:31.610957 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 0
I0517 22:09:33.144428 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 1
I0517 22:09:34.603700 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 10
I0517 22:09:36.090703 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 11
I0517 22:09:37.616117 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 12
I0517 22:09:39.090724 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 13
I0517 22:09:40.640656 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 14
I0517 22:09:42.118510 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 15
I0517 22:09:43.603182 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 16
I0517 22:09:45.105502 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 17
I0517 22:09:46.619051 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 18
I0517 22:09:48.095625 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 19
I0517 22:09:49.625439 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 2
I0517 22:09:51.103300 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 20
I0517 22:09:52.634365 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 21
I0517 22:09:54.100228 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 22
I0517 22:09:55.567112 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 23
I0517 22:09:57.055935 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 24
I0517 22:09:58.567619 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 25
I0517 22:10:00.035933 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 26
I0517 22:10:01.507049 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 27
I0517 22:10:03.087810 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 28
I0517 22:10:04.617481 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 29
I0517 22:10:06.087470 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 3
I0517 22:10:07.563404 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 30
I0517 22:10:09.036698 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 31
I0517 22:10:10.664452 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 32
I0517 22:10:12.256048 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 33
I0517 22:10:13.741019 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 34
I0517 22:10:15.275355 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 35
I0517 22:10:16.753975 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 36
I0517 22:10:18.242354 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 37
I0517 22:10:19.715112 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 38
I0517 22:10:21.195248 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 39
I0517 22:10:22.662337 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 4
I0517 22:10:24.137997 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 40
I0517 22:10:25.620055 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 41
I0517 22:10:27.084614 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 42
I0517 22:10:28.558168 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 43
I0517 22:10:30.024747 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 44
I0517 22:10:31.488798 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 45
I0517 22:10:32.970286 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 46
I0517 22:10:34.437595 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 47
I0517 22:10:35.910988 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 48
I0517 22:10:37.472263 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 5
I0517 22:10:39.000710 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 6
I0517 22:10:40.537830 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 7
I0517 22:10:42.032458 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 8
I0517 22:10:43.513245 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 9
I0517 22:10:57.579472 22647664891712 evaluation_fromsample.py:105] ckpt-30 --- FID: 2.980644e+00
I0517 22:10:57.581009 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:10:57.582009 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 0
I0517 22:10:59.038011 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 1
I0517 22:11:00.534188 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 10
I0517 22:11:02.435029 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 11
I0517 22:11:03.973872 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 12
I0517 22:11:05.457717 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 13
I0517 22:11:06.944581 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 14
I0517 22:11:08.416296 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 15
I0517 22:11:09.885062 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 16
I0517 22:11:11.398233 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 17
I0517 22:11:12.865631 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 18
I0517 22:11:14.441035 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 19
I0517 22:11:15.939957 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 2
I0517 22:11:17.422007 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 20
I0517 22:11:18.911914 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 21
I0517 22:11:20.393447 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 22
I0517 22:11:21.859170 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 23
I0517 22:11:23.312997 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 24
I0517 22:11:25.018443 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 25
I0517 22:11:26.529258 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 26
I0517 22:11:28.150108 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 27
I0517 22:11:29.620244 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 28
I0517 22:11:31.082829 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 29
I0517 22:11:32.574245 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 3
I0517 22:11:34.042782 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 30
I0517 22:11:35.537059 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 31
I0517 22:11:37.014957 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 32
I0517 22:11:38.532284 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 33
I0517 22:11:40.036661 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 34
I0517 22:11:41.514543 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 35
I0517 22:11:42.984961 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 36
I0517 22:11:44.533885 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 37
I0517 22:11:46.039784 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 38
I0517 22:11:47.493702 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 39
I0517 22:11:48.968947 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 4
I0517 22:11:50.448382 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 40
I0517 22:11:51.916711 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 41
I0517 22:11:53.387075 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 42
I0517 22:11:54.850790 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 43
I0517 22:11:56.334898 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 44
I0517 22:11:57.806176 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 45
I0517 22:11:59.332480 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 46
I0517 22:12:00.840367 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 47
I0517 22:12:02.310409 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 48
I0517 22:12:03.777735 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 5
I0517 22:12:05.235967 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 6
I0517 22:12:06.735868 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 7
I0517 22:12:08.198549 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 8
I0517 22:12:09.722318 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 9
I0517 22:12:23.222948 22647664891712 evaluation_fromsample.py:105] ckpt-35 --- FID: 3.172755e+00
I0517 22:12:23.224551 22647664891712 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0
I0517 22:12:23.225490 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 0
I0517 22:12:24.708788 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 1
I0517 22:12:26.178836 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 10
I0517 22:12:27.659222 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 11
I0517 22:12:29.142639 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 12
I0517 22:12:30.605166 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 13
I0517 22:12:32.096460 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 14
I0517 22:12:33.604108 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 15
I0517 22:12:35.112802 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 16
I0517 22:12:36.592291 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 17
I0517 22:12:38.067728 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 18
I0517 22:12:39.525725 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 19
I0517 22:12:41.009332 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 2
I0517 22:12:42.674776 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 20
I0517 22:12:44.154462 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 21
I0517 22:12:45.637146 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 22
I0517 22:12:47.103846 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 23
I0517 22:12:48.575109 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 24
I0517 22:12:50.128750 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 25
I0517 22:12:51.595763 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 26
I0517 22:12:53.069146 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 27
I0517 22:12:54.539189 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 28
I0517 22:12:56.003309 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 29
I0517 22:12:57.493943 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 3
I0517 22:12:58.956975 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 30
I0517 22:13:00.432314 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 31
I0517 22:13:01.893177 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 32
I0517 22:13:03.396847 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 33
I0517 22:13:04.886129 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 34
I0517 22:13:06.372332 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 35
I0517 22:13:07.865748 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 36
I0517 22:13:09.394509 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 37
I0517 22:13:10.854679 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 38
I0517 22:13:12.329972 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 39
I0517 22:13:13.802187 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 4
I0517 22:13:15.285138 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 40
I0517 22:13:16.763367 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 41
I0517 22:13:18.229834 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 42
I0517 22:13:19.893391 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 43
I0517 22:13:21.414624 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 44
I0517 22:13:22.914198 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 45
I0517 22:13:24.390891 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 46
I0517 22:13:25.888389 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 47
I0517 22:13:27.356810 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 48
I0517 22:13:28.895050 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 5
I0517 22:13:30.351921 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 6
I0517 22:13:31.856294 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 7
I0517 22:13:33.320693 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 8
I0517 22:13:34.810632 22647664891712 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 9
I0517 22:13:48.482814 22647664891712 evaluation_fromsample.py:105] ckpt-40 --- FID: 3.332352e+00
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
2023-05-17 22:14:08.884462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-17 22:14:08.996413: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-17 22:14:11.076625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-17 22:14:11.076730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-17 22:14:11.076743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
I0517 22:14:34.790509 23033969231680 main_interval.py:85] (0.442,)
I0517 22:14:46.848144 23033969231680 sampling.py:98] dpm_solver
I0517 22:14:46.848458 23033969231680 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
I0517 22:14:49.687715 23033969231680 main_interval.py:152] begin checkpoint: 5
I0517 22:14:49.687987 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_5.pth
I0517 22:15:17.906867 23033969231680 main_interval.py:156] 1 is converged model
I0517 22:15:17.920397 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0517 22:15:45.074178 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0517 22:15:45.074597 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 0
[2023-05-17 22:15:45,706] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:15:46,460] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-17 22:15:46,473] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-17 22:15:46,475] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:15:46,475] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:15:46,665] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:15:55,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:02,681] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-17 22:16:02,681] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:05,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-17 22:16:05,408] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-17 22:16:05,411] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-17 22:16:07,742] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:07,782] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:07,782] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:07,784] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:07,860] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:09,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-17 22:16:09,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:11,609] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-17 22:16:11,621] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:11,656] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:11,658] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:11,659] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:11,659] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:11,659] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:11,685] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:12,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-17 22:16:12,758] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:12,763] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:12,801] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:12,802] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:12,802] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:12,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-17 22:16:12,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-17 22:16:13,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-17 22:16:13,125] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-17 22:16:13,136] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:13,142] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:13,181] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:13,181] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:13,181] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:13,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-17 22:16:13,289] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-17 22:16:13,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-17 22:16:13,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-17 22:16:13,512] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:13,518] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:13,555] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:13,556] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:13,556] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:13,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-17 22:16:13,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-17 22:16:13,757] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-17 22:16:13,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-17 22:16:13,884] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:13,890] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:13,928] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:13,928] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:13,929] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:13,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-17 22:16:14,035] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-17 22:16:14,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-17 22:16:14,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-17 22:16:14,316] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:14,322] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:14,360] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:14,360] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:14,361] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:14,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-17 22:16:14,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-17 22:16:14,561] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-17 22:16:14,682] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-17 22:16:14,692] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:14,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:14,736] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:14,736] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:14,736] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:14,778] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-17 22:16:14,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-17 22:16:14,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-17 22:16:15,053] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-17 22:16:15,064] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:15,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:15,112] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:15,112] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:15,113] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1444352  self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:15,155] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-17 22:16:15,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-17 22:16:15,314] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-17 22:16:15,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-17 22:16:15,443] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:15,449] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:15,512] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:15,512] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:15,512] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1510400  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

                      self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

       1        1024  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:15,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-05-17 22:16:16,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-05-17 22:16:16,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:17,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-17 22:16:17,779] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:17,809] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:17,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:17,811] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:17,811] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:17,811] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:17,819] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-17 22:16:18,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-17 22:16:18,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:18,386] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:18,427] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:18,428] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:18,428] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2492416  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     1709056  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:18,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:19,906] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-17 22:16:19,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-17 22:16:20,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-17 22:16:20,531] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:20,554] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:20,555] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:20,556] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:20,556] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:20,557] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:20,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-17 22:16:21,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-17 22:16:21,123] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:21,128] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:21,259] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:21,259] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:21,260] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:21,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-05-17 22:16:21,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-05-17 22:16:22,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so /whenusr /searchingbin /forld :- lcudaskipping
 /incompatibleusr //binusr//ldlib:/ libcuda.soskipping  whenincompatible  searching/ usrfor/ lib-/lcudalibc.so
 /whenusr /searchingbin /forld :- lcskipping
 incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:29,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-17 22:16:29,386] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:31,186] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:31,188] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:31,189] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:31,189] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:31,189] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:31,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-17 22:16:31,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-17 22:16:31,210] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:31,214] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:31,254] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:31,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:31,254] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:31,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-17 22:16:32,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-17 22:16:32,175] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-17 22:16:32,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-17 22:16:32,750] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:32,769] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:32,875] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:32,875] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:32,876] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:32,917] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-17 22:16:32,965] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-17 22:16:33,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-17 22:16:33,301] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-17 22:16:33,331] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:33,337] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:33,376] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:33,376] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:33,376] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:33,492] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-17 22:16:33,624] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-17 22:16:33,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-17 22:16:33,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-17 22:16:33,670] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:33,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:33,780] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:33,780] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:33,781] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:33,822] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-17 22:16:33,869] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-17 22:16:34,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-17 22:16:34,478] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-17 22:16:34,508] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:34,514] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:34,552] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:34,553] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:34,554] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:34,670] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-17 22:16:34,806] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-17 22:16:34,836] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-17 22:16:34,852] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-17 22:16:34,854] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:34,858] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:34,964] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:34,964] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:34,965] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:35,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-17 22:16:35,052] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-17 22:16:35,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-17 22:16:35,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-17 22:16:35,417] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:35,423] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:35,460] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:35,461] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:35,461] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:35,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-17 22:16:35,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-17 22:16:35,737] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-17 22:16:35,752] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-17 22:16:35,754] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:35,758] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:35,866] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:35,866] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:35,866] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:35,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-17 22:16:35,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-17 22:16:36,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-17 22:16:36,291] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-17 22:16:36,321] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:36,327] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:36,365] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:36,365] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:36,366] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:36,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-17 22:16:36,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-17 22:16:36,642] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-17 22:16:36,658] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-17 22:16:36,659] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:36,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:36,770] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:36,770] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:36,771] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:36,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-17 22:16:36,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-17 22:16:37,086] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-17 22:16:37,200] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-17 22:16:37,231] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:37,238] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:37,275] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:37,275] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:37,276] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:37,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-17 22:16:37,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-17 22:16:37,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-17 22:16:37,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-17 22:16:37,569] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:37,573] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:37,678] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:37,678] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:37,678] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:37,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-17 22:16:37,767] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-17 22:16:37,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-17 22:16:38,103] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-17 22:16:38,134] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:38,140] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:38,177] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:38,178] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:38,178] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:38,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-17 22:16:38,426] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-17 22:16:38,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-17 22:16:38,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-17 22:16:38,471] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:38,475] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:38,580] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:38,580] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:38,581] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:38,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-17 22:16:38,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-17 22:16:38,891] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-17 22:16:39,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-17 22:16:39,035] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:39,042] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:39,092] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:39,092] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:39,092] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2623488  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:39,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:40,613] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-17 22:16:40,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-17 22:16:41,306] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-17 22:16:41,309] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:41,328] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:41,329] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:41,330] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:41,330] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:41,330] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:41,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
[2023-05-17 22:16:41,907] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-17 22:16:41,907] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:41,913] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:41,951] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:41,951] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:41,951] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:42,081] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:43,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-17 22:16:43,246] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-17 22:16:43,822] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-17 22:16:43,824] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:43,834] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:43,872] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:43,873] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:43,873] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:43,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-17 22:16:44,131] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-17 22:16:44,160] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-17 22:16:44,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-17 22:16:44,178] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:44,183] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:44,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:44,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:44,221] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:44,336] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-17 22:16:44,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-17 22:16:44,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-17 22:16:44,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-17 22:16:44,515] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:44,520] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:44,558] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:44,559] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:44,559] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:44,677] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-17 22:16:44,811] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-17 22:16:44,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-17 22:16:44,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-17 22:16:44,859] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:44,864] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:44,901] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:44,902] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:44,902] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:45,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-17 22:16:45,150] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-17 22:16:45,180] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-17 22:16:45,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-17 22:16:45,197] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:45,203] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:45,240] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:45,241] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:45,241] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:45,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-17 22:16:45,490] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-17 22:16:45,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-17 22:16:45,535] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-17 22:16:45,537] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:45,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:45,581] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:45,581] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:45,582] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:45,699] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-17 22:16:45,833] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-17 22:16:45,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-17 22:16:45,880] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-17 22:16:45,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:45,891] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:45,929] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:45,929] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:45,929] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:46,045] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-17 22:16:46,178] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-17 22:16:46,207] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-17 22:16:46,222] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-17 22:16:46,224] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:46,229] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:46,279] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:46,279] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:46,280] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2623488  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:46,413] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:48,119] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-17 22:16:48,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-17 22:16:48,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-17 22:16:48,752] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:48,781] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:16:48,782] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:16:48,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:48,784] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:48,784] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:16:48,794] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-17 22:16:49,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-17 22:16:49,354] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:49,360] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:49,399] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:49,399] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:49,400] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:49,535] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:16:50,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-17 22:16:50,740] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-17 22:16:51,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-17 22:16:51,315] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:51,324] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:51,362] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:51,363] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:51,363] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:51,489] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-17 22:16:51,627] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-17 22:16:51,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-17 22:16:51,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-17 22:16:51,677] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:51,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:51,721] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:51,722] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:51,722] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:51,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-17 22:16:51,978] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-17 22:16:52,009] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-17 22:16:52,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-17 22:16:52,027] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:52,033] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:52,071] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:52,072] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:52,072] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:52,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-17 22:16:52,325] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-17 22:16:52,354] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-17 22:16:52,370] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-17 22:16:52,372] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:52,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:52,415] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:52,415] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:52,416] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:52,537] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-17 22:16:52,680] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-17 22:16:52,716] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-17 22:16:52,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-17 22:16:52,737] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:52,745] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:52,784] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:52,784] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:52,785] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:52,902] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-17 22:16:53,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-17 22:16:53,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-17 22:16:53,104] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-17 22:16:53,106] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:53,114] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:53,155] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:53,155] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:53,156] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:53,275] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-17 22:16:53,411] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-17 22:16:53,441] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-17 22:16:53,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-17 22:16:53,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:53,466] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:53,507] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:53,507] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:53,508] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:53,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-17 22:16:53,766] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-17 22:16:53,798] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-17 22:16:53,815] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-17 22:16:53,817] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:53,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:53,861] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:53,862] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:53,862] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:53,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-17 22:16:54,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-17 22:16:54,147] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-17 22:16:54,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-17 22:16:54,165] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:16:54,170] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:16:54,278] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:16:54,279] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:16:54,279] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:16:54,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-17 22:16:54,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-17 22:16:55,227] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:17:00,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-17 22:17:00,033] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:03,689] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-17 22:17:03,692] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-17 22:17:03,694] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:03,694] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:03,695] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:03,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-17 22:17:03,728] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-17 22:17:03,729] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:03,736] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:03,778] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:03,778] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:03,779] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2360320  self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:03,905] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-17 22:17:04,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-17 22:17:04,091] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-17 22:17:04,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-17 22:17:04,111] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:04,117] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:04,158] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:04,158] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:04,159] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:04,278] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
/usr/bin/ld: skipping incompatible /usr/lib/libcuda.so when searching for -lcuda
/usr/bin/ld: skipping incompatible /usr/lib/libc.so when searching for -lc
[2023-05-17 22:17:05,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-17 22:17:05,487] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-17 22:17:05,518] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-17 22:17:05,520] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:05,558] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:05,601] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:05,601] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:05,601] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:05,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-17 22:17:05,859] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-17 22:17:05,898] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-17 22:17:05,919] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-17 22:17:05,922] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:05,927] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:05,968] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:05,968] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:05,968] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:06,093] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-17 22:17:06,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-17 22:17:06,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-17 22:17:06,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-17 22:17:06,307] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:06,314] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:06,355] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:06,355] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:06,356] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:06,473] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-17 22:17:06,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-17 22:17:06,653] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-17 22:17:06,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-17 22:17:06,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:06,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:06,724] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:06,724] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:06,725] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:06,841] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-17 22:17:06,980] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-17 22:17:07,018] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-17 22:17:07,039] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-17 22:17:07,041] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:07,047] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:07,087] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:07,088] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:07,088] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:07,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-17 22:17:07,347] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-17 22:17:07,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-17 22:17:07,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-17 22:17:07,410] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:07,416] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:07,456] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:07,457] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:07,457] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:07,574] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-17 22:17:07,715] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-17 22:17:07,754] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-17 22:17:07,775] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-17 22:17:07,778] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:07,783] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:07,824] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:07,824] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:07,825] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:07,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-17 22:17:08,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-17 22:17:08,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-17 22:17:08,153] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-17 22:17:08,156] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:08,161] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:08,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:08,201] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:08,202] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:08,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-17 22:17:08,463] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-17 22:17:08,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-17 22:17:08,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-17 22:17:08,526] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:08,532] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:08,585] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:08,585] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:08,586] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2623488  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:08,718] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-17 22:17:10,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-17 22:17:10,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-17 22:17:10,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-17 22:17:10,198] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:10,206] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:10,249] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:10,249] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:10,250] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:10,377] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-17 22:17:11,173] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-17 22:17:11,219] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-17 22:17:11,250] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-17 22:17:11,253] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:11,272] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:11,313] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:11,314] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:11,314] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:11,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-17 22:17:11,576] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-17 22:17:11,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-17 22:17:11,636] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-17 22:17:11,639] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:11,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:11,685] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:11,685] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:11,686] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:11,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-17 22:17:11,945] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-17 22:17:11,983] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-17 22:17:12,005] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-17 22:17:12,007] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:12,013] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:12,053] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:12,053] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:12,054] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:12,170] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-17 22:17:12,316] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-17 22:17:12,355] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-17 22:17:12,378] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-17 22:17:12,381] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:12,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:12,428] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:12,429] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:12,429] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:12,546] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-17 22:17:12,689] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-17 22:17:12,727] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-17 22:17:12,748] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-17 22:17:12,751] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:12,756] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:12,798] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:12,798] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:12,799] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:12,916] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-17 22:17:13,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-17 22:17:13,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-17 22:17:13,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-17 22:17:13,120] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:13,125] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:13,167] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:13,167] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:13,168] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:13,287] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-17 22:17:13,431] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-17 22:17:13,472] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-17 22:17:13,493] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-17 22:17:13,496] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:13,501] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:13,543] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:13,543] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:13,543] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:13,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-17 22:17:13,804] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-17 22:17:13,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-17 22:17:13,864] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-17 22:17:13,866] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:13,872] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:13,913] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:13,913] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:13,914] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:14,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-17 22:17:14,174] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-17 22:17:14,214] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-17 22:17:14,236] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-17 22:17:14,238] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:14,244] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:14,297] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:14,297] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:14,297] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2623488  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     2889728  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:14,431] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-17 22:17:15,391] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-17 22:17:15,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-17 22:17:15,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-17 22:17:15,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:15,472] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:15,513] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:15,513] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:15,514] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:15,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-17 22:17:16,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-17 22:17:16,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-17 22:17:16,662] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-17 22:17:16,664] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:16,681] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:16,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:16,727] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:16,728] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:16,847] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-17 22:17:16,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-17 22:17:17,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-17 22:17:17,056] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-17 22:17:17,058] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:17,065] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:17,109] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:17,109] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:17,110] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:17,229] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-17 22:17:17,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-17 22:17:17,412] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-17 22:17:17,434] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-17 22:17:17,436] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:17,442] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:17,483] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:17,483] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:17,484] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:17,601] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-17 22:17:17,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-17 22:17:17,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-17 22:17:17,802] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-17 22:17:17,805] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:17,810] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:17,851] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:17,851] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:17,852] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:17,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-17 22:17:18,111] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-17 22:17:18,151] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-17 22:17:18,174] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-17 22:17:18,176] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:18,182] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:18,223] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:18,223] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:18,223] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:18,341] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-17 22:17:18,484] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-17 22:17:18,523] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-17 22:17:18,545] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-17 22:17:18,548] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:18,554] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:18,594] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:18,594] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:18,595] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     2885632  self_Conv_2_weight      

                      self_Conv_2_bias        

                      self_Conv_1_weight      

                      self_Conv_1_bias        

       1     5251072  self_GroupNorm_1_weight 

                      self_GroupNorm_1_bias   

                      self_Dense_0_weight     

                      self_Dense_0_bias       

                      self_Conv_0_weight      

                      self_Conv_0_bias        

                      self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:18,712] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-17 22:17:18,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-17 22:17:18,890] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-17 22:17:18,911] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-17 22:17:18,914] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:18,917] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 23029162532048)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-17 22:17:18,917] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-17 22:17:18,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:19,062] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:19,062] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:19,062] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:19,107] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-17 22:17:19,159] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-17 22:17:19,384] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-17 22:17:19,508] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-17 22:17:19,538] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:19,543] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-17 22:17:19,548] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-17 22:17:19,549] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:19,549] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:19,549] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:19,562] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-17 22:17:20,186] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-17 22:17:20,187] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:20,802] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-17 22:17:20,806] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-17 22:17:20,808] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:20,808] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:20,808] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:20,819] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-17 22:17:20,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-17 22:17:20,880] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:20,896] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-17 22:17:20,899] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-17 22:17:20,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:20,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:20,900] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:20,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
[2023-05-17 22:17:20,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-17 22:17:20,940] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:20,948] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-17 22:17:20,952] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-17 22:17:20,952] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:20,952] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:20,953] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:20,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-17 22:17:20,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-17 22:17:20,990] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:21,090] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-17 22:17:21,095] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-17 22:17:21,096] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:21,096] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:21,096] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:21,109] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-17 22:17:21,139] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-17 22:17:21,139] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:21,383] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-17 22:17:21,388] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-17 22:17:21,389] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:21,390] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:21,390] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

 Index    Size (b)    Param Names   


[2023-05-17 22:17:21,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-17 22:17:21,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-17 22:17:21,436] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:33,232] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:33,341] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:33,341] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:33,342] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:33,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-17 22:17:33,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-17 22:17:33,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-17 22:17:33,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-17 22:17:33,830] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:33,836] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:33,943] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:33,943] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:33,944] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:33,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-17 22:17:34,033] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-17 22:17:34,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-17 22:17:34,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-17 22:17:34,400] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:34,406] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:34,510] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:34,510] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:34,511] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:34,552] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-17 22:17:34,599] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-17 22:17:34,822] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-17 22:17:35,428] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-17 22:17:35,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:35,465] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:35,571] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:35,571] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:35,571] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:35,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-17 22:17:35,693] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-17 22:17:35,918] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-17 22:17:36,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-17 22:17:36,063] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:36,070] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:36,180] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:36,180] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:36,181] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:36,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-17 22:17:36,271] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-17 22:17:36,494] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-17 22:17:36,606] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-17 22:17:36,636] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:36,642] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:36,748] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:36,748] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:36,749] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:36,789] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-17 22:17:36,838] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-17 22:17:37,062] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-17 22:17:37,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-17 22:17:37,207] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:37,213] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:37,317] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:37,317] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:37,318] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:37,359] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-17 22:17:37,406] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-17 22:17:37,629] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-17 22:17:37,741] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-17 22:17:37,771] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:37,777] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:37,885] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:37,885] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:37,885] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:37,926] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-17 22:17:37,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-17 22:17:38,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-17 22:17:38,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-17 22:17:38,343] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:38,359] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:38,464] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:38,464] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:38,465] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:38,505] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-17 22:17:38,560] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-17 22:17:38,782] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-17 22:17:38,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-17 22:17:38,943] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-17 22:17:38,967] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-17 22:17:39,073] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-17 22:17:39,073] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-17 22:17:39,073] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments

   Index    Size (b)  Param Names             

       0     1052672  self_NIN_3_b            

                      self_NIN_3_W            

                      self_NIN_2_b            

                      self_NIN_2_W            

                      self_NIN_1_b            

                      self_NIN_1_W            

                      self_NIN_0_b            

                      self_NIN_0_W            

       1        2048  self_GroupNorm_0_weight 

                      self_GroupNorm_0_bias   

[2023-05-17 22:17:39,115] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-17 22:17:39,163] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-17 22:17:39,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-17 22:17:39,500] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-17 22:17:39,530] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0517 22:18:00.554929 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 1
I0517 22:18:36.389002 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 2
I0517 22:19:12.316861 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 3
I0517 22:19:48.335123 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 4
I0517 22:20:24.363675 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 5
I0517 22:21:00.384409 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 6
I0517 22:21:36.454425 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 7
I0517 22:22:12.492479 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 8
I0517 22:22:48.529394 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 9
I0517 22:23:24.571512 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 10
I0517 22:24:00.608122 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 11
I0517 22:24:36.648564 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 12
I0517 22:25:12.693367 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 13
I0517 22:25:48.763402 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 14
I0517 22:26:24.802162 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 15
I0517 22:27:00.844535 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 16
I0517 22:27:37.048545 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 17
I0517 22:28:13.084771 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 18
I0517 22:28:49.123609 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 19
I0517 22:29:25.188591 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 20
I0517 22:30:01.226033 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 21
I0517 22:30:37.258080 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 22
I0517 22:31:13.283768 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 23
I0517 22:31:49.341860 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 24
I0517 22:32:25.378397 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 25
I0517 22:33:01.453234 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 26
I0517 22:33:37.515604 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 27
I0517 22:34:13.547106 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 28
I0517 22:34:49.581623 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 29
I0517 22:35:25.622926 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 30
I0517 22:36:01.659806 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 31
I0517 22:36:37.683339 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 32
I0517 22:37:13.806746 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 33
I0517 22:37:49.860962 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 34
I0517 22:38:25.890502 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 35
I0517 22:39:01.919161 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 36
I0517 22:39:37.968419 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 37
I0517 22:40:14.011925 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 38
I0517 22:40:50.046667 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 39
I0517 22:41:26.090300 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 40
I0517 22:42:02.152627 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 41
I0517 22:42:38.192771 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 42
I0517 22:43:14.213047 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 43
I0517 22:43:50.249164 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 44
I0517 22:44:26.299046 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 45
I0517 22:45:02.324571 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 46
I0517 22:45:38.381162 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 47
I0517 22:46:14.408770 23033969231680 main_interval.py:215] sampling -- ckpt: 5, round: 48
I0517 22:46:50.476866 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth
W0517 22:46:50.477283 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth. Returned the same state as input
I0517 22:46:50.487703 23033969231680 main_interval.py:156] 1 is converged model
I0517 22:46:50.495271 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0517 22:47:45.726268 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0517 22:47:45.803865 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 0
I0517 22:48:21.881499 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 1
I0517 22:48:57.793577 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 2
I0517 22:49:33.788635 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 3
I0517 22:50:09.807741 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 4
I0517 22:50:45.841438 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 5
I0517 22:51:21.875728 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 6
I0517 22:51:57.909678 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 7
I0517 22:52:34.075320 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 8
I0517 22:53:10.098881 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 9
I0517 22:53:46.176015 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 10
I0517 22:54:22.201845 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 11
I0517 22:54:58.230033 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 12
I0517 22:55:34.266924 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 13
I0517 22:56:10.301363 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 14
I0517 22:56:46.380997 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 15
I0517 22:57:22.417366 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 16
I0517 22:57:58.450289 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 17
I0517 22:58:34.479684 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 18
I0517 22:59:10.506047 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 19
I0517 22:59:46.532074 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 20
I0517 23:00:22.613132 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 21
I0517 23:00:58.651154 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 22
I0517 23:01:34.675088 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 23
I0517 23:02:10.828634 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 24
I0517 23:02:46.908161 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 25
I0517 23:03:22.963029 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 26
I0517 23:03:59.042605 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 27
I0517 23:04:35.071943 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 28
I0517 23:05:11.113825 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 29
I0517 23:05:47.141651 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 30
I0517 23:06:23.220689 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 31
I0517 23:06:59.247808 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 32
I0517 23:07:35.350212 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 33
I0517 23:08:11.372383 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 34
I0517 23:08:47.440147 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 35
I0517 23:09:23.470464 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 36
I0517 23:09:59.491679 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 37
I0517 23:10:35.517305 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 38
I0517 23:11:11.553959 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 39
I0517 23:11:47.592613 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 40
I0517 23:12:23.621814 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 41
I0517 23:12:59.704703 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 42
I0517 23:13:35.777678 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 43
I0517 23:14:11.816850 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 44
I0517 23:14:47.849627 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 45
I0517 23:15:23.870560 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 46
I0517 23:15:59.921952 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 47
I0517 23:16:35.954731 23033969231680 main_interval.py:215] sampling -- ckpt: 10, round: 48
I0517 23:17:12.033168 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth
W0517 23:17:12.033656 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth. Returned the same state as input
I0517 23:17:12.044073 23033969231680 main_interval.py:156] 1 is converged model
I0517 23:17:12.044203 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0517 23:17:33.885076 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0517 23:17:33.885548 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 0
I0517 23:18:10.083797 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 1
I0517 23:18:46.068516 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 2
I0517 23:19:22.091436 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 3
I0517 23:19:58.140295 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 4
I0517 23:20:34.168210 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 5
I0517 23:21:10.193415 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 6
I0517 23:21:46.216259 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 7
I0517 23:22:22.284381 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 8
I0517 23:22:58.321160 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 9
I0517 23:23:34.361480 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 10
I0517 23:24:10.390076 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 11
I0517 23:24:46.469901 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 12
I0517 23:25:22.509845 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 13
I0517 23:25:58.550099 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 14
I0517 23:26:34.577924 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 15
I0517 23:27:10.703471 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 16
I0517 23:27:46.740567 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 17
I0517 23:28:22.776715 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 18
I0517 23:28:58.816201 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 19
I0517 23:29:34.892131 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 20
I0517 23:30:10.918434 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 21
I0517 23:30:46.946896 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 22
I0517 23:31:22.988366 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 23
I0517 23:31:59.026262 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 24
I0517 23:32:35.212333 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 25
I0517 23:33:11.257731 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 26
I0517 23:33:47.298045 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 27
I0517 23:34:23.352240 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 28
I0517 23:34:59.390448 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 29
I0517 23:35:35.442816 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 30
I0517 23:36:11.526731 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 31
I0517 23:36:47.554769 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 32
I0517 23:37:23.583434 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 33
I0517 23:37:59.613337 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 34
I0517 23:38:35.653459 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 35
I0517 23:39:11.737348 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 36
I0517 23:39:47.733797 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 37
I0517 23:40:23.729643 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 38
I0517 23:40:59.732636 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 39
I0517 23:41:35.769721 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 40
I0517 23:42:12.054906 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 41
I0517 23:42:48.110452 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 42
I0517 23:43:24.146645 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 43
I0517 23:44:00.185992 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 44
I0517 23:44:36.256315 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 45
I0517 23:45:12.324440 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 46
I0517 23:45:48.364183 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 47
I0517 23:46:24.408018 23033969231680 main_interval.py:215] sampling -- ckpt: 15, round: 48
I0517 23:47:00.447186 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth
W0517 23:47:00.447543 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth. Returned the same state as input
I0517 23:47:00.457606 23033969231680 main_interval.py:156] 1 is converged model
I0517 23:47:00.457731 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0517 23:48:03.361163 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0517 23:48:03.371546 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 0
I0517 23:48:39.438911 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 1
I0517 23:49:15.346342 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 2
I0517 23:49:51.389880 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 3
I0517 23:50:27.398744 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 4
I0517 23:51:03.428202 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 5
I0517 23:51:39.460624 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 6
I0517 23:52:15.560929 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 7
I0517 23:52:51.583269 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 8
I0517 23:53:27.657670 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 9
I0517 23:54:03.702428 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 10
I0517 23:54:39.722846 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 11
I0517 23:55:15.757911 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 12
I0517 23:55:51.793345 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 13
I0517 23:56:27.813301 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 14
I0517 23:57:03.848011 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 15
I0517 23:57:39.936892 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 16
I0517 23:58:15.972965 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 17
I0517 23:58:52.026755 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 18
I0517 23:59:28.048165 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 19
I0518 00:00:04.068624 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 20
I0518 00:00:40.093505 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 21
I0518 00:01:16.163456 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 22
I0518 00:01:52.190697 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 23
I0518 00:02:28.278590 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 24
I0518 00:03:04.323353 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 25
I0518 00:03:40.360319 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 26
I0518 00:04:16.432901 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 27
I0518 00:04:52.513513 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 28
I0518 00:05:28.553122 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 29
I0518 00:06:04.594456 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 30
I0518 00:06:40.670538 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 31
I0518 00:07:16.698559 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 32
I0518 00:07:52.729386 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 33
I0518 00:08:28.759374 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 34
I0518 00:09:04.841301 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 35
I0518 00:09:40.870504 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 36
I0518 00:10:16.888180 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 37
I0518 00:10:52.912505 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 38
I0518 00:11:28.927326 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 39
I0518 00:12:04.924754 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 40
I0518 00:12:40.931033 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 41
I0518 00:13:16.929957 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 42
I0518 00:13:52.949246 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 43
I0518 00:14:29.007159 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 44
I0518 00:15:05.008928 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 45
I0518 00:15:41.021086 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 46
I0518 00:16:17.042654 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 47
I0518 00:16:53.063442 23033969231680 main_interval.py:215] sampling -- ckpt: 20, round: 48
I0518 00:17:29.111038 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth
W0518 00:17:29.111410 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth. Returned the same state as input
I0518 00:17:29.121516 23033969231680 main_interval.py:156] 1 is converged model
I0518 00:17:29.121645 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 00:17:49.560353 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 00:17:49.560857 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 0
I0518 00:18:25.743915 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 1
I0518 00:19:01.715451 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 2
I0518 00:19:37.719122 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 3
I0518 00:20:13.767519 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 4
I0518 00:20:49.822360 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 5
I0518 00:21:25.895998 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 6
I0518 00:22:01.945047 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 7
I0518 00:22:38.098726 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 8
I0518 00:23:14.157740 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 9
I0518 00:23:50.195682 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 10
I0518 00:24:26.231662 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 11
I0518 00:25:02.297666 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 12
I0518 00:25:38.358795 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 13
I0518 00:26:14.412707 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 14
I0518 00:26:50.449108 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 15
I0518 00:27:26.512026 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 16
I0518 00:28:02.561817 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 17
I0518 00:28:38.590875 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 18
I0518 00:29:14.625267 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 19
I0518 00:29:50.664750 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 20
I0518 00:30:26.746763 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 21
I0518 00:31:02.779983 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 22
I0518 00:31:38.818807 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 23
I0518 00:32:14.928936 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 24
I0518 00:32:50.992287 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 25
I0518 00:33:27.026983 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 26
I0518 00:34:03.102734 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 27
I0518 00:34:39.135370 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 28
I0518 00:35:15.173939 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 29
I0518 00:35:51.201529 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 30
I0518 00:36:27.229432 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 31
I0518 00:37:03.313058 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 32
I0518 00:37:39.433678 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 33
I0518 00:38:15.473019 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 34
I0518 00:38:51.511081 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 35
I0518 00:39:27.556193 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 36
I0518 00:40:03.584829 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 37
I0518 00:40:39.656404 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 38
I0518 00:41:15.696674 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 39
I0518 00:41:51.734737 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 40
I0518 00:42:27.777076 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 41
I0518 00:43:03.820714 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 42
I0518 00:43:39.884017 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 43
I0518 00:44:15.917082 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 44
I0518 00:44:52.000792 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 45
I0518 00:45:28.080671 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 46
I0518 00:46:04.110329 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 47
I0518 00:46:40.140341 23033969231680 main_interval.py:215] sampling -- ckpt: 25, round: 48
I0518 00:47:16.189783 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth
W0518 00:47:16.190284 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth. Returned the same state as input
I0518 00:47:16.225859 23033969231680 main_interval.py:156] 1 is converged model
I0518 00:47:16.226039 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 00:48:05.127767 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 00:48:05.141750 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 0
I0518 00:48:41.233184 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 1
I0518 00:49:17.160374 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 2
I0518 00:49:53.159720 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 3
I0518 00:50:29.185414 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 4
I0518 00:51:05.205229 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 5
I0518 00:51:41.226852 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 6
I0518 00:52:17.308000 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 7
I0518 00:52:53.341645 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 8
I0518 00:53:29.371566 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 9
I0518 00:54:05.405748 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 10
I0518 00:54:41.436108 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 11
I0518 00:55:17.468953 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 12
I0518 00:55:53.495854 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 13
I0518 00:56:29.517261 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 14
I0518 00:57:05.540316 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 15
I0518 00:57:41.589982 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 16
I0518 00:58:17.623880 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 17
I0518 00:58:53.648505 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 18
I0518 00:59:29.683277 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 19
I0518 01:00:05.705334 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 20
I0518 01:00:41.767063 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 21
I0518 01:01:17.790539 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 22
I0518 01:01:53.844487 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 23
I0518 01:02:29.875783 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 24
I0518 01:03:05.935166 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 25
I0518 01:03:41.968447 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 26
I0518 01:04:18.001889 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 27
I0518 01:04:54.065682 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 28
I0518 01:05:30.098568 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 29
I0518 01:06:06.163010 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 30
I0518 01:06:42.197935 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 31
I0518 01:07:18.236107 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 32
I0518 01:07:54.270975 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 33
I0518 01:08:30.307578 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 34
I0518 01:09:06.333687 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 35
I0518 01:09:42.371020 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 36
I0518 01:10:18.408916 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 37
I0518 01:10:54.486618 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 38
I0518 01:11:30.529344 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 39
I0518 01:12:06.560264 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 40
I0518 01:12:42.627998 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 41
I0518 01:13:18.657565 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 42
I0518 01:13:54.894726 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 43
I0518 01:14:30.932466 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 44
I0518 01:15:06.954042 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 45
I0518 01:15:42.982254 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 46
I0518 01:16:19.021934 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 47
I0518 01:16:55.047884 23033969231680 main_interval.py:215] sampling -- ckpt: 30, round: 48
I0518 01:17:31.088392 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth
W0518 01:17:31.088881 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth. Returned the same state as input
I0518 01:17:31.098915 23033969231680 main_interval.py:156] 1 is converged model
I0518 01:17:31.099049 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 01:17:51.804239 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 01:17:51.804720 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 0
I0518 01:18:28.009690 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 1
I0518 01:19:04.038609 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 2
I0518 01:19:40.064459 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 3
I0518 01:20:16.101541 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 4
I0518 01:20:52.144825 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 5
I0518 01:21:28.185097 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 6
I0518 01:22:04.211627 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 7
I0518 01:22:40.287432 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 8
I0518 01:23:16.324246 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 9
I0518 01:23:52.498189 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 10
I0518 01:24:28.530172 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 11
I0518 01:25:04.610700 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 12
I0518 01:25:40.650748 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 13
I0518 01:26:16.697828 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 14
I0518 01:26:52.729111 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 15
I0518 01:27:28.760216 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 16
I0518 01:28:04.802398 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 17
I0518 01:28:40.913692 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 18
I0518 01:29:16.942109 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 19
I0518 01:29:53.021144 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 20
I0518 01:30:29.046007 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 21
I0518 01:31:05.076982 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 22
I0518 01:31:41.116295 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 23
I0518 01:32:17.154980 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 24
I0518 01:32:53.183388 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 25
I0518 01:33:29.425886 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 26
I0518 01:34:05.552453 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 27
I0518 01:34:41.592558 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 28
I0518 01:35:17.628663 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 29
I0518 01:35:53.711676 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 30
I0518 01:36:29.736979 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 31
I0518 01:37:05.800894 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 32
I0518 01:37:41.837512 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 33
I0518 01:38:17.878223 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 34
I0518 01:38:53.930276 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 35
I0518 01:39:29.972566 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 36
I0518 01:40:06.038747 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 37
I0518 01:40:42.084091 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 38
I0518 01:41:18.126971 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 39
I0518 01:41:54.203039 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 40
I0518 01:42:30.247258 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 41
I0518 01:43:06.290749 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 42
I0518 01:43:42.557038 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 43
I0518 01:44:18.602513 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 44
I0518 01:44:54.647850 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 45
I0518 01:45:30.687564 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 46
I0518 01:46:06.693889 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 47
I0518 01:46:42.739880 23033969231680 main_interval.py:215] sampling -- ckpt: 35, round: 48
I0518 01:47:18.825260 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth
W0518 01:47:18.825760 23033969231680 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth. Returned the same state as input
I0518 01:47:18.835943 23033969231680 main_interval.py:156] 1 is converged model
I0518 01:47:18.836076 23033969231680 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 01:48:13.265125 23033969231680 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 01:48:13.295218 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 0
I0518 01:48:49.451668 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 1
I0518 01:49:25.363178 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 2
I0518 01:50:01.398155 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 3
I0518 01:50:37.458331 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 4
I0518 01:51:13.477389 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 5
I0518 01:51:49.495984 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 6
I0518 01:52:25.569478 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 7
I0518 01:53:01.645756 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 8
I0518 01:53:37.804075 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 9
I0518 01:54:13.827917 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 10
I0518 01:54:49.850944 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 11
I0518 01:55:25.890193 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 12
I0518 01:56:01.918574 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 13
I0518 01:56:37.957244 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 14
I0518 01:57:14.020551 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 15
I0518 01:57:50.057947 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 16
I0518 01:58:26.070783 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 17
I0518 01:59:02.317413 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 18
I0518 01:59:38.395855 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 19
I0518 02:00:23.521893 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 20
I0518 02:00:59.515253 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 21
I0518 02:01:35.537309 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 22
I0518 02:02:11.583850 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 23
I0518 02:02:47.626164 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 24
I0518 02:03:23.679398 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 25
I0518 02:03:59.720344 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 26
I0518 02:04:35.779233 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 27
I0518 02:05:11.866562 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 28
I0518 02:05:47.909191 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 29
I0518 02:06:23.944761 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 30
I0518 02:07:00.017079 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 31
I0518 02:07:36.049232 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 32
I0518 02:08:12.082443 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 33
I0518 02:08:48.192685 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 34
I0518 02:09:24.219580 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 35
I0518 02:10:00.244089 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 36
I0518 02:10:36.283441 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 37
I0518 02:11:12.343938 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 38
I0518 02:11:48.367636 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 39
I0518 02:12:24.443299 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 40
I0518 02:13:00.480952 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 41
I0518 02:13:36.516438 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 42
I0518 02:14:12.550200 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 43
I0518 02:14:48.587429 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 44
I0518 02:15:24.666865 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 45
I0518 02:16:00.693148 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 46
I0518 02:16:36.739125 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 47
I0518 02:17:12.759773 23033969231680 main_interval.py:215] sampling -- ckpt: 40, round: 48
2023-05-18 02:17:57.607519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-18 02:17:57.716961: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-18 02:17:59.511432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 02:17:59.524871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 02:17:59.524885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/absl/flags/_validators.py:254: UserWarning: Flag --eval_folder has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
I0518 02:18:09.049496 22440024426304 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
2023-05-18 02:18:11.466677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43102 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:1f:00.0, compute capability: 8.6
I0518 02:18:13.550455 22440024426304 evaluation_fromsample.py:48] begin checkpoint: 5
I0518 02:18:13.550724 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:18:13.551442 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 0
I0518 02:18:15.145635 22440024426304 xla_bridge.py:440] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 02:18:15.145787 22440024426304 xla_bridge.py:440] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 02:18:15.146431 22440024426304 xla_bridge.py:440] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0518 02:18:15.146534 22440024426304 xla_bridge.py:440] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0518 02:18:15.146587 22440024426304 xla_bridge.py:448] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0518 02:18:15.567196 22440024426304 deprecation.py:350] From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
2023-05-18 02:18:20.047015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
2023-05-18 02:18:21.464970: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2023-05-18 02:18:28.069811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.
  structure[0], [func(*x) for x in entries],
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:627: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS
I0518 02:18:28.630122 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 1
I0518 02:18:30.606975 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 10
I0518 02:18:35.212459 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 11
I0518 02:18:37.619079 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 12
I0518 02:18:40.251076 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 13
I0518 02:18:42.447116 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 14
I0518 02:18:45.424992 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 15
I0518 02:18:48.536603 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 16
I0518 02:18:50.255674 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 17
I0518 02:18:53.454794 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 18
I0518 02:18:57.548151 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 19
I0518 02:18:59.683285 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 2
I0518 02:19:04.154658 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 20
I0518 02:19:06.292214 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 21
I0518 02:19:08.186068 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 22
I0518 02:19:10.666884 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 23
I0518 02:19:13.502506 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 24
I0518 02:19:15.342683 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 25
I0518 02:19:17.834287 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 26
I0518 02:19:20.091952 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 27
I0518 02:19:23.592442 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 28
I0518 02:19:25.638330 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 29
I0518 02:19:27.669579 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 3
I0518 02:19:32.215155 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 30
I0518 02:19:37.388399 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 31
I0518 02:19:38.968804 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 32
I0518 02:19:41.339430 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 33
I0518 02:19:43.462639 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 34
I0518 02:19:47.228703 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 35
I0518 02:19:49.321665 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 36
I0518 02:19:52.988344 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 37
I0518 02:19:54.994760 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 38
I0518 02:19:58.235183 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 39
I0518 02:20:00.414838 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 4
I0518 02:20:02.338089 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 40
I0518 02:20:04.602168 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 41
I0518 02:20:06.116621 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 42
I0518 02:20:08.562783 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 43
I0518 02:20:10.293170 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 44
I0518 02:20:13.344768 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 45
I0518 02:20:15.105339 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 46
I0518 02:20:17.911029 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 47
I0518 02:20:19.570841 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 48
I0518 02:20:23.044365 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 5
I0518 02:20:25.565350 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 6
I0518 02:20:27.628839 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 7
I0518 02:20:29.934963 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 8
I0518 02:20:33.284850 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 9
I0518 02:21:00.921924 22440024426304 evaluation_fromsample.py:105] ckpt-5 --- FID: 2.995937e+00
I0518 02:21:00.922998 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:21:00.923559 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 0
I0518 02:21:03.287186 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 1
I0518 02:21:05.597649 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 10
I0518 02:21:07.938260 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 11
I0518 02:21:10.243376 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 12
I0518 02:21:12.644484 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 13
I0518 02:21:15.071695 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 14
I0518 02:21:16.871424 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 15
I0518 02:21:21.348447 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 16
I0518 02:21:23.589072 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 17
I0518 02:21:27.634450 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 18
I0518 02:21:29.663165 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 19
I0518 02:21:32.377363 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 2
I0518 02:21:34.279800 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 20
I0518 02:21:37.030816 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 21
I0518 02:21:40.029521 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 22
I0518 02:21:42.159297 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 23
I0518 02:21:44.615763 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 24
I0518 02:21:46.882785 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 25
I0518 02:21:48.844583 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 26
I0518 02:21:51.148125 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 27
I0518 02:21:53.464430 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 28
I0518 02:21:55.856020 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 29
I0518 02:21:59.107567 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 3
I0518 02:22:00.918025 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 30
I0518 02:22:04.337155 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 31
I0518 02:22:07.167801 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 32
I0518 02:22:10.250319 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 33
I0518 02:22:12.616402 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 34
I0518 02:22:16.812551 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 35
I0518 02:22:20.595962 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 36
I0518 02:22:22.298118 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 37
I0518 02:22:24.704236 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 38
I0518 02:22:26.166481 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 39
I0518 02:22:28.362283 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 4
I0518 02:22:30.325382 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 40
I0518 02:22:32.057281 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 41
I0518 02:22:35.041574 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 42
I0518 02:22:37.039408 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 43
I0518 02:22:40.366698 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 44
I0518 02:22:43.506002 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 45
I0518 02:22:46.097009 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 46
I0518 02:22:48.197554 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 47
I0518 02:22:51.820184 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 48
I0518 02:22:53.657597 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 5
I0518 02:22:56.103917 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 6
I0518 02:22:58.181527 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 7
I0518 02:23:02.516188 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 8
I0518 02:23:07.394326 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 9
I0518 02:23:50.745515 22440024426304 evaluation_fromsample.py:105] ckpt-10 --- FID: 3.001324e+00
I0518 02:23:50.746589 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:23:50.747141 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 0
I0518 02:23:52.619239 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 1
I0518 02:23:54.650492 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 10
I0518 02:23:56.621566 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 11
I0518 02:23:59.784744 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 12
I0518 02:24:01.568285 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 13
I0518 02:24:05.084145 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 14
I0518 02:24:07.498861 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 15
I0518 02:24:09.787733 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 16
I0518 02:24:12.223769 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 17
I0518 02:24:13.987020 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 18
I0518 02:24:19.395610 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 19
I0518 02:24:22.535552 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 2
I0518 02:24:24.664395 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 20
I0518 02:24:26.905174 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 21
I0518 02:24:29.140980 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 22
I0518 02:24:31.349878 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 23
I0518 02:24:33.773725 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 24
I0518 02:24:36.311598 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 25
I0518 02:24:38.540961 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 26
I0518 02:24:40.149075 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 27
I0518 02:24:42.766380 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 28
I0518 02:24:44.805547 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 29
I0518 02:24:46.822030 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 3
I0518 02:24:48.731764 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 30
I0518 02:24:51.262907 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 31
I0518 02:24:53.754842 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 32
I0518 02:24:56.312640 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 33
I0518 02:24:58.434380 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 34
I0518 02:25:02.962969 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 35
I0518 02:25:05.989450 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 36
I0518 02:25:08.977688 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 37
I0518 02:25:11.423882 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 38
I0518 02:25:13.650546 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 39
I0518 02:25:16.027662 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 4
I0518 02:25:19.233807 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 40
I0518 02:25:22.796422 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 41
I0518 02:25:25.599385 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 42
I0518 02:25:28.649954 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 43
I0518 02:25:30.560408 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 44
I0518 02:25:32.659453 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 45
I0518 02:25:34.992166 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 46
I0518 02:25:38.339615 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 47
I0518 02:25:40.882300 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 48
I0518 02:25:44.828076 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 5
I0518 02:25:47.362877 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 6
I0518 02:25:49.504016 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 7
I0518 02:25:52.271817 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 8
I0518 02:25:54.080994 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 9
I0518 02:26:14.422185 22440024426304 evaluation_fromsample.py:105] ckpt-15 --- FID: 2.992329e+00
I0518 02:26:14.423286 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:26:14.423824 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 0
I0518 02:26:16.142073 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 1
I0518 02:26:18.161734 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 10
I0518 02:26:20.175327 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 11
I0518 02:26:22.768820 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 12
I0518 02:26:26.308683 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 13
I0518 02:26:28.056413 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 14
I0518 02:26:29.998809 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 15
I0518 02:26:32.376774 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 16
I0518 02:26:34.609615 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 17
I0518 02:26:36.826665 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 18
I0518 02:26:39.245502 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 19
I0518 02:26:41.343659 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 2
I0518 02:26:44.324799 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 20
I0518 02:26:47.357120 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 21
I0518 02:26:48.878816 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 22
I0518 02:26:51.542621 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 23
I0518 02:26:53.997753 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 24
I0518 02:26:57.176729 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 25
I0518 02:26:59.658969 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 26
I0518 02:27:02.006781 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 27
I0518 02:27:05.908788 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 28
I0518 02:27:07.774949 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 29
I0518 02:27:09.513203 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 3
I0518 02:27:12.796414 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 30
I0518 02:27:15.015204 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 31
I0518 02:27:19.032602 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 32
I0518 02:27:22.588084 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 33
I0518 02:27:24.777016 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 34
I0518 02:27:27.137084 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 35
I0518 02:27:28.808272 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 36
I0518 02:27:34.096857 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 37
I0518 02:27:37.872145 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 38
I0518 02:27:40.386046 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 39
I0518 02:27:42.274886 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 4
I0518 02:27:45.506496 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 40
I0518 02:27:49.032983 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 41
I0518 02:27:50.953162 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 42
I0518 02:27:53.410755 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 43
I0518 02:27:55.006987 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 44
I0518 02:27:59.220451 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 45
I0518 02:28:01.582234 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 46
I0518 02:28:04.324125 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 47
I0518 02:28:05.884329 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 48
I0518 02:28:09.600156 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 5
I0518 02:28:12.421675 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 6
I0518 02:28:14.526356 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 7
I0518 02:28:16.226002 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 8
I0518 02:28:19.843278 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 9
I0518 02:29:19.388421 22440024426304 evaluation_fromsample.py:105] ckpt-20 --- FID: 3.033583e+00
I0518 02:29:19.389666 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:29:19.390335 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 0
I0518 02:29:23.085674 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 1
I0518 02:29:25.329315 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 10
I0518 02:29:28.559259 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 11
I0518 02:29:30.566308 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 12
I0518 02:29:33.478902 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 13
I0518 02:29:35.225019 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 14
I0518 02:29:38.239185 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 15
I0518 02:29:40.951936 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 16
I0518 02:29:43.538506 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 17
I0518 02:29:46.424819 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 18
I0518 02:29:48.776915 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 19
I0518 02:29:51.601421 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 2
I0518 02:29:55.645524 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 20
I0518 02:29:57.768429 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 21
I0518 02:30:01.174088 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 22
I0518 02:30:02.977965 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 23
I0518 02:30:05.993994 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 24
I0518 02:30:08.066356 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 25
I0518 02:30:11.189087 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 26
I0518 02:30:13.555090 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 27
I0518 02:30:18.045826 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 28
I0518 02:30:19.773997 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 29
I0518 02:30:21.500005 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 3
I0518 02:30:25.321952 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 30
I0518 02:30:27.525140 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 31
I0518 02:30:29.040984 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 32
I0518 02:30:31.761155 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 33
I0518 02:30:33.584611 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 34
I0518 02:30:35.993422 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 35
I0518 02:30:37.759283 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 36
I0518 02:30:39.912186 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 37
I0518 02:30:41.623002 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 38
I0518 02:30:43.863083 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 39
I0518 02:30:45.704200 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 4
I0518 02:30:50.188439 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 40
I0518 02:30:51.858340 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 41
I0518 02:30:54.647578 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 42
I0518 02:30:57.053396 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 43
I0518 02:31:00.725006 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 44
I0518 02:31:02.560671 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 45
I0518 02:31:04.962702 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 46
I0518 02:31:07.761305 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 47
I0518 02:31:09.900394 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 48
I0518 02:31:12.907362 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 5
I0518 02:31:15.498689 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 6
I0518 02:31:17.458910 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 7
I0518 02:31:19.456692 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 8
I0518 02:31:22.194861 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 9
I0518 02:31:40.090259 22440024426304 evaluation_fromsample.py:105] ckpt-25 --- FID: 3.072460e+00
I0518 02:31:40.091610 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:31:40.092302 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 0
I0518 02:31:42.213276 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 1
I0518 02:31:44.373985 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 10
I0518 02:31:46.718716 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 11
I0518 02:31:48.232472 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 12
I0518 02:31:51.290985 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 13
I0518 02:31:53.182332 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 14
I0518 02:31:54.683952 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 15
I0518 02:31:56.577116 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 16
I0518 02:31:59.049651 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 17
I0518 02:32:00.923208 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 18
I0518 02:32:03.452052 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 19
I0518 02:32:05.552151 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 2
I0518 02:32:08.013511 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 20
I0518 02:32:10.520847 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 21
I0518 02:32:13.955934 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 22
I0518 02:32:15.697255 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 23
I0518 02:32:18.672181 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 24
I0518 02:32:20.659380 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 25
I0518 02:32:23.579864 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 26
I0518 02:32:26.267903 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 27
I0518 02:32:28.646317 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 28
I0518 02:32:30.677916 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 29
I0518 02:32:32.944807 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 3
I0518 02:32:35.709998 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 30
I0518 02:32:37.524118 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 31
I0518 02:32:39.967386 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 32
I0518 02:32:42.503218 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 33
I0518 02:32:45.477906 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 34
I0518 02:32:47.094719 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 35
I0518 02:32:49.718280 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 36
I0518 02:32:51.460134 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 37
I0518 02:32:53.439514 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 38
I0518 02:32:55.008570 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 39
I0518 02:32:57.846278 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 4
I0518 02:33:01.412971 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 40
I0518 02:33:03.503777 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 41
I0518 02:33:05.580325 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 42
I0518 02:33:07.573405 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 43
I0518 02:33:09.689693 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 44
I0518 02:33:11.826702 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 45
I0518 02:33:15.029073 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 46
I0518 02:33:17.875427 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 47
I0518 02:33:19.496932 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 48
I0518 02:33:22.345153 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 5
I0518 02:33:25.316614 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 6
I0518 02:33:27.576684 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 7
I0518 02:33:30.151401 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 8
I0518 02:33:32.135973 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 9
I0518 02:34:19.861429 22440024426304 evaluation_fromsample.py:105] ckpt-30 --- FID: 2.996425e+00
I0518 02:34:19.862944 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:34:19.863674 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 0
I0518 02:34:21.753731 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 1
I0518 02:34:23.877936 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 10
I0518 02:34:25.954888 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 11
I0518 02:34:27.728042 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 12
I0518 02:34:29.257119 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 13
I0518 02:34:31.565122 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 14
I0518 02:34:33.720597 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 15
I0518 02:34:36.093870 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 16
I0518 02:34:38.175397 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 17
I0518 02:34:40.361026 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 18
I0518 02:34:42.565590 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 19
I0518 02:34:46.279094 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 2
I0518 02:34:47.849805 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 20
I0518 02:34:51.370770 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 21
I0518 02:34:53.303692 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 22
I0518 02:34:55.147309 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 23
I0518 02:34:57.790269 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 24
I0518 02:35:00.032899 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 25
I0518 02:35:01.969480 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 26
I0518 02:35:03.855106 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 27
I0518 02:35:05.935425 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 28
I0518 02:35:08.221864 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 29
I0518 02:35:10.481826 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 3
I0518 02:35:12.304466 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 30
I0518 02:35:15.488744 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 31
I0518 02:35:17.530693 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 32
I0518 02:35:20.628335 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 33
I0518 02:35:22.915559 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 34
I0518 02:35:25.188440 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 35
I0518 02:35:27.271806 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 36
I0518 02:35:28.867281 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 37
I0518 02:35:30.374355 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 38
I0518 02:35:33.024180 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 39
I0518 02:35:34.903609 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 4
I0518 02:35:36.565443 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 40
I0518 02:35:38.847539 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 41
I0518 02:35:40.750795 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 42
I0518 02:35:42.869823 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 43
I0518 02:35:45.545969 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 44
I0518 02:35:47.065682 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 45
I0518 02:35:48.565268 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 46
I0518 02:35:50.542996 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 47
I0518 02:35:52.175008 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 48
I0518 02:35:54.057850 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 5
I0518 02:35:55.959924 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 6
I0518 02:35:57.485721 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 7
I0518 02:35:59.562969 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 8
I0518 02:36:01.159600 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 9
I0518 02:36:21.271519 22440024426304 evaluation_fromsample.py:105] ckpt-35 --- FID: 3.000301e+00
I0518 02:36:21.273005 22440024426304 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval0_control
I0518 02:36:21.273713 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 0
I0518 02:36:22.845105 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 1
I0518 02:36:24.774511 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 10
I0518 02:36:26.243427 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 11
I0518 02:36:27.731048 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 12
I0518 02:36:29.961337 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 13
I0518 02:36:32.117562 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 14
I0518 02:36:33.715547 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 15
I0518 02:36:35.535541 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 16
I0518 02:36:37.528144 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 17
I0518 02:36:39.591237 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 18
I0518 02:36:41.569495 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 19
I0518 02:36:43.102918 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 2
I0518 02:36:44.602759 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 20
I0518 02:36:46.133312 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 21
I0518 02:36:48.363206 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 22
I0518 02:36:49.919732 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 23
I0518 02:36:51.889297 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 24
I0518 02:36:53.768783 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 25
I0518 02:36:55.734042 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 26
I0518 02:36:57.220145 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 27
I0518 02:36:58.975661 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 28
I0518 02:37:00.759700 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 29
I0518 02:37:02.461359 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 3
I0518 02:37:04.524278 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 30
I0518 02:37:06.693165 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 31
I0518 02:37:08.448596 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 32
I0518 02:37:09.998818 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 33
I0518 02:37:11.478883 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 34
I0518 02:37:13.634559 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 35
I0518 02:37:15.442779 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 36
I0518 02:37:18.054268 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 37
I0518 02:37:20.372313 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 38
I0518 02:37:22.374292 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 39
I0518 02:37:23.956849 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 4
I0518 02:37:25.429017 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 40
I0518 02:37:27.733634 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 41
I0518 02:37:30.076548 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 42
I0518 02:37:32.064755 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 43
I0518 02:37:33.524451 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 44
I0518 02:37:35.384443 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 45
I0518 02:37:36.957453 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 46
I0518 02:37:38.601076 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 47
I0518 02:37:40.610347 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 48
I0518 02:37:42.442866 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 5
I0518 02:37:44.173251 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 6
I0518 02:37:46.202672 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 7
I0518 02:37:48.135483 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 8
I0518 02:37:49.899733 22440024426304 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 9
I0518 02:38:06.256154 22440024426304 evaluation_fromsample.py:105] ckpt-40 --- FID: 2.959060e+00
