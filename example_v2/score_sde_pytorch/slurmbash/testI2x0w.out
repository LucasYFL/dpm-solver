4
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

I0404 16:23:31.477980 23443585951552 main.py:54] Conditional: True
W0404 16:23:35.457060 23443585951552 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_I2_x0_weighted/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0404 16:23:35.459179 23443585951552 xla_bridge.py:355] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0404 16:23:35.459399 23443585951552 xla_bridge.py:355] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0404 16:23:35.459482 23443585951552 xla_bridge.py:355] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0404 16:23:35.461311 23443585951552 xla_bridge.py:355] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0404 16:23:35.461436 23443585951552 xla_bridge.py:355] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0404 16:23:35.461528 23443585951552 xla_bridge.py:362] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0404 16:23:35.464543 23443585951552 dataset_info.py:358] Load dataset info from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0404 16:23:35.473330 23443585951552 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0404 16:23:35.473452 23443585951552 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0404 16:23:35.473589 23443585951552 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0404 16:23:35.473694 23443585951552 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split train, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
W0404 16:23:35.673404 23443585951552 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
W0404 16:23:35.673651 23443585951552 options.py:503] options.experimental_threading is deprecated. Use options.threading instead.
I0404 16:23:35.673789 23443585951552 dataset_builder.py:351] Reusing dataset cifar10 (/home/yifulu/tensorflow_datasets/cifar10/3.0.2)
I0404 16:23:35.673877 23443585951552 logging_logger.py:35] Constructing tf.data.Dataset cifar10 for split test, from /home/yifulu/tensorflow_datasets/cifar10/3.0.2
I0404 16:23:35.781043 23443585951552 losses.py:104] Sde loss
I0404 16:23:35.781279 23443585951552 losses.py:107] Fewer: 4
I0404 16:23:35.781366 23443585951552 losses.py:126] (0.676, 1]
I0404 16:23:35.781442 23443585951552 losses.py:104] Sde loss
I0404 16:23:35.781503 23443585951552 losses.py:107] Fewer: 4
I0404 16:23:35.781557 23443585951552 losses.py:126] (0.676, 1]
I0404 16:23:35.781629 23443585951552 sampling.py:98] dpm_solver
I0404 16:23:35.781761 23443585951552 run_lib.py:130] Starting training loop at step 0.
I0404 16:23:45.779543 23443585951552 run_lib.py:140] step: 0, training_loss: 6.04551e-04
I0404 16:23:48.340922 23443585951552 run_lib.py:153] step: 0, eval_loss: 4.99586e-04
I0404 16:24:12.010001 23443585951552 run_lib.py:140] step: 50, training_loss: 4.73777e-04
I0404 16:24:35.593691 23443585951552 run_lib.py:140] step: 100, training_loss: 4.76585e-04
I0404 16:24:35.752459 23443585951552 run_lib.py:153] step: 100, eval_loss: 4.81518e-04
I0404 16:24:59.547820 23443585951552 run_lib.py:140] step: 150, training_loss: 4.47669e-04
I0404 16:25:20.895857 23443585951552 run_lib.py:140] step: 200, training_loss: 4.10585e-04
I0404 16:25:21.054506 23443585951552 run_lib.py:153] step: 200, eval_loss: 5.16038e-04
I0404 16:25:42.629867 23443585951552 run_lib.py:140] step: 250, training_loss: 4.72565e-04
I0404 16:26:04.040891 23443585951552 run_lib.py:140] step: 300, training_loss: 4.30674e-04
I0404 16:26:04.197062 23443585951552 run_lib.py:153] step: 300, eval_loss: 3.91612e-04
I0404 16:26:25.374784 23443585951552 run_lib.py:140] step: 350, training_loss: 4.24185e-04
I0404 16:26:46.685832 23443585951552 run_lib.py:140] step: 400, training_loss: 4.33089e-04
I0404 16:26:46.859920 23443585951552 run_lib.py:153] step: 400, eval_loss: 4.36188e-04
I0404 16:27:08.243434 23443585951552 run_lib.py:140] step: 450, training_loss: 4.18268e-04
I0404 16:27:29.198959 23443585951552 run_lib.py:140] step: 500, training_loss: 4.40978e-04
I0404 16:27:29.353676 23443585951552 run_lib.py:153] step: 500, eval_loss: 4.32339e-04
I0404 16:27:51.030415 23443585951552 run_lib.py:140] step: 550, training_loss: 3.77475e-04
I0404 16:28:12.479872 23443585951552 run_lib.py:140] step: 600, training_loss: 4.82262e-04
I0404 16:28:12.635471 23443585951552 run_lib.py:153] step: 600, eval_loss: 4.20084e-04
I0404 16:28:34.030471 23443585951552 run_lib.py:140] step: 650, training_loss: 4.15902e-04
I0404 16:28:55.257978 23443585951552 run_lib.py:140] step: 700, training_loss: 3.96851e-04
I0404 16:28:55.413088 23443585951552 run_lib.py:153] step: 700, eval_loss: 3.99345e-04
I0404 16:29:16.975836 23443585951552 run_lib.py:140] step: 750, training_loss: 4.24849e-04
I0404 16:29:38.122438 23443585951552 run_lib.py:140] step: 800, training_loss: 4.60747e-04
I0404 16:29:38.288110 23443585951552 run_lib.py:153] step: 800, eval_loss: 4.20483e-04
I0404 16:29:59.695911 23443585951552 run_lib.py:140] step: 850, training_loss: 4.40643e-04
I0404 16:30:21.270054 23443585951552 run_lib.py:140] step: 900, training_loss: 4.18145e-04
I0404 16:30:21.430745 23443585951552 run_lib.py:153] step: 900, eval_loss: 4.25786e-04
I0404 16:30:42.715253 23443585951552 run_lib.py:140] step: 950, training_loss: 4.37475e-04
I0404 16:31:04.036501 23443585951552 run_lib.py:140] step: 1000, training_loss: 4.36637e-04
I0404 16:31:04.195888 23443585951552 run_lib.py:153] step: 1000, eval_loss: 4.12434e-04
I0404 16:31:25.532244 23443585951552 run_lib.py:140] step: 1050, training_loss: 4.77890e-04
I0404 16:31:46.408820 23443585951552 run_lib.py:140] step: 1100, training_loss: 3.99094e-04
I0404 16:31:46.565827 23443585951552 run_lib.py:153] step: 1100, eval_loss: 3.72468e-04
I0404 16:32:08.092940 23443585951552 run_lib.py:140] step: 1150, training_loss: 3.46413e-04
I0404 16:32:29.604427 23443585951552 run_lib.py:140] step: 1200, training_loss: 4.41792e-04
I0404 16:32:29.757160 23443585951552 run_lib.py:153] step: 1200, eval_loss: 4.46623e-04
I0404 16:32:51.098927 23443585951552 run_lib.py:140] step: 1250, training_loss: 3.95412e-04
I0404 16:33:12.437952 23443585951552 run_lib.py:140] step: 1300, training_loss: 4.02118e-04
I0404 16:33:12.607294 23443585951552 run_lib.py:153] step: 1300, eval_loss: 3.87832e-04
I0404 16:33:33.636266 23443585951552 run_lib.py:140] step: 1350, training_loss: 4.35212e-04
I0404 16:33:55.110111 23443585951552 run_lib.py:140] step: 1400, training_loss: 4.26234e-04
I0404 16:33:55.275600 23443585951552 run_lib.py:153] step: 1400, eval_loss: 4.05060e-04
I0404 16:34:16.428395 23443585951552 run_lib.py:140] step: 1450, training_loss: 4.30139e-04
I0404 16:34:37.652684 23443585951552 run_lib.py:140] step: 1500, training_loss: 3.68280e-04
I0404 16:34:37.810240 23443585951552 run_lib.py:153] step: 1500, eval_loss: 4.77315e-04
I0404 16:34:59.280187 23443585951552 run_lib.py:140] step: 1550, training_loss: 4.09896e-04
I0404 16:35:20.838210 23443585951552 run_lib.py:140] step: 1600, training_loss: 4.48808e-04
I0404 16:35:20.990568 23443585951552 run_lib.py:153] step: 1600, eval_loss: 3.86353e-04
I0404 16:35:42.754893 23443585951552 run_lib.py:140] step: 1650, training_loss: 3.60441e-04
I0404 16:36:04.195858 23443585951552 run_lib.py:140] step: 1700, training_loss: 4.26795e-04
I0404 16:36:04.354685 23443585951552 run_lib.py:153] step: 1700, eval_loss: 3.97838e-04
I0404 16:36:25.860895 23443585951552 run_lib.py:140] step: 1750, training_loss: 4.27384e-04
I0404 16:36:47.227862 23443585951552 run_lib.py:140] step: 1800, training_loss: 4.82118e-04
I0404 16:36:47.384165 23443585951552 run_lib.py:153] step: 1800, eval_loss: 4.03028e-04
I0404 16:37:08.902584 23443585951552 run_lib.py:140] step: 1850, training_loss: 4.24685e-04
I0404 16:37:30.290845 23443585951552 run_lib.py:140] step: 1900, training_loss: 5.15650e-04
I0404 16:37:30.447830 23443585951552 run_lib.py:153] step: 1900, eval_loss: 4.07919e-04
I0404 16:37:51.993359 23443585951552 run_lib.py:140] step: 1950, training_loss: 3.86048e-04
I0404 16:38:13.302286 23443585951552 run_lib.py:140] step: 2000, training_loss: 4.00057e-04
I0404 16:38:13.458723 23443585951552 run_lib.py:153] step: 2000, eval_loss: 3.70712e-04
I0404 16:38:34.517153 23443585951552 run_lib.py:140] step: 2050, training_loss: 4.58738e-04
I0404 16:38:55.959030 23443585951552 run_lib.py:140] step: 2100, training_loss: 3.91021e-04
I0404 16:38:56.110858 23443585951552 run_lib.py:153] step: 2100, eval_loss: 3.25292e-04
I0404 16:39:17.336245 23443585951552 run_lib.py:140] step: 2150, training_loss: 4.22860e-04
I0404 16:39:38.703141 23443585951552 run_lib.py:140] step: 2200, training_loss: 4.58286e-04
I0404 16:39:38.862317 23443585951552 run_lib.py:153] step: 2200, eval_loss: 3.71457e-04
I0404 16:40:00.328131 23443585951552 run_lib.py:140] step: 2250, training_loss: 3.90299e-04
I0404 16:40:22.072072 23443585951552 run_lib.py:140] step: 2300, training_loss: 4.15682e-04
I0404 16:40:22.232326 23443585951552 run_lib.py:153] step: 2300, eval_loss: 3.99788e-04
I0404 16:40:43.399823 23443585951552 run_lib.py:140] step: 2350, training_loss: 4.31849e-04
I0404 16:41:05.170536 23443585951552 run_lib.py:140] step: 2400, training_loss: 4.85816e-04
I0404 16:41:05.329932 23443585951552 run_lib.py:153] step: 2400, eval_loss: 4.47872e-04
I0404 16:41:26.454667 23443585951552 run_lib.py:140] step: 2450, training_loss: 3.86717e-04
I0404 16:41:47.706484 23443585951552 run_lib.py:140] step: 2500, training_loss: 3.96093e-04
I0404 16:41:47.862353 23443585951552 run_lib.py:153] step: 2500, eval_loss: 4.05868e-04
I0404 16:42:09.370495 23443585951552 run_lib.py:140] step: 2550, training_loss: 4.20833e-04
I0404 16:42:30.975806 23443585951552 run_lib.py:140] step: 2600, training_loss: 4.10035e-04
I0404 16:42:31.128095 23443585951552 run_lib.py:153] step: 2600, eval_loss: 4.20204e-04
I0404 16:42:52.275974 23443585951552 run_lib.py:140] step: 2650, training_loss: 3.81120e-04
I0404 16:43:13.583590 23443585951552 run_lib.py:140] step: 2700, training_loss: 3.61504e-04
I0404 16:43:13.741079 23443585951552 run_lib.py:153] step: 2700, eval_loss: 3.71964e-04
I0404 16:43:35.407673 23443585951552 run_lib.py:140] step: 2750, training_loss: 4.35416e-04
I0404 16:43:56.765366 23443585951552 run_lib.py:140] step: 2800, training_loss: 4.55317e-04
I0404 16:43:56.922832 23443585951552 run_lib.py:153] step: 2800, eval_loss: 4.27325e-04
I0404 16:44:18.246962 23443585951552 run_lib.py:140] step: 2850, training_loss: 3.72177e-04
I0404 16:44:39.420945 23443585951552 run_lib.py:140] step: 2900, training_loss: 4.52617e-04
I0404 16:44:39.578927 23443585951552 run_lib.py:153] step: 2900, eval_loss: 3.60206e-04
I0404 16:45:00.795792 23443585951552 run_lib.py:140] step: 2950, training_loss: 3.51536e-04
I0404 16:45:22.321504 23443585951552 run_lib.py:140] step: 3000, training_loss: 3.82420e-04
I0404 16:45:22.477070 23443585951552 run_lib.py:153] step: 3000, eval_loss: 4.07699e-04
I0404 16:45:43.518887 23443585951552 run_lib.py:140] step: 3050, training_loss: 3.84721e-04
I0404 16:46:05.037843 23443585951552 run_lib.py:140] step: 3100, training_loss: 3.98342e-04
I0404 16:46:05.189755 23443585951552 run_lib.py:153] step: 3100, eval_loss: 3.92384e-04
I0404 16:46:26.472512 23443585951552 run_lib.py:140] step: 3150, training_loss: 4.39974e-04
I0404 16:46:48.145334 23443585951552 run_lib.py:140] step: 3200, training_loss: 4.09710e-04
I0404 16:46:48.313110 23443585951552 run_lib.py:153] step: 3200, eval_loss: 3.49297e-04
I0404 16:47:10.043702 23443585951552 run_lib.py:140] step: 3250, training_loss: 4.21186e-04
I0404 16:47:31.532077 23443585951552 run_lib.py:140] step: 3300, training_loss: 4.27745e-04
I0404 16:47:31.688006 23443585951552 run_lib.py:153] step: 3300, eval_loss: 4.01231e-04
I0404 16:47:53.143639 23443585951552 run_lib.py:140] step: 3350, training_loss: 3.63848e-04
I0404 16:48:14.779256 23443585951552 run_lib.py:140] step: 3400, training_loss: 4.12262e-04
I0404 16:48:14.935010 23443585951552 run_lib.py:153] step: 3400, eval_loss: 4.18266e-04
I0404 16:48:36.451035 23443585951552 run_lib.py:140] step: 3450, training_loss: 4.08499e-04
I0404 16:48:57.878084 23443585951552 run_lib.py:140] step: 3500, training_loss: 3.43124e-04
I0404 16:48:58.031896 23443585951552 run_lib.py:153] step: 3500, eval_loss: 3.93182e-04
I0404 16:49:19.326396 23443585951552 run_lib.py:140] step: 3550, training_loss: 4.43072e-04
I0404 16:49:40.709563 23443585951552 run_lib.py:140] step: 3600, training_loss: 4.72233e-04
I0404 16:49:40.869867 23443585951552 run_lib.py:153] step: 3600, eval_loss: 3.80776e-04
I0404 16:50:02.190879 23443585951552 run_lib.py:140] step: 3650, training_loss: 4.24578e-04
I0404 16:50:23.242282 23443585951552 run_lib.py:140] step: 3700, training_loss: 3.64278e-04
I0404 16:50:23.400106 23443585951552 run_lib.py:153] step: 3700, eval_loss: 4.43330e-04
I0404 16:50:44.611470 23443585951552 run_lib.py:140] step: 3750, training_loss: 3.81853e-04
I0404 16:51:06.136456 23443585951552 run_lib.py:140] step: 3800, training_loss: 4.07081e-04
I0404 16:51:06.303678 23443585951552 run_lib.py:153] step: 3800, eval_loss: 4.62789e-04
I0404 16:51:27.998520 23443585951552 run_lib.py:140] step: 3850, training_loss: 3.97066e-04
I0404 16:51:49.297709 23443585951552 run_lib.py:140] step: 3900, training_loss: 4.13687e-04
I0404 16:51:49.460028 23443585951552 run_lib.py:153] step: 3900, eval_loss: 3.84724e-04
I0404 16:52:10.855722 23443585951552 run_lib.py:140] step: 3950, training_loss: 4.47341e-04
I0404 16:52:32.315208 23443585951552 run_lib.py:140] step: 4000, training_loss: 4.18137e-04
I0404 16:52:32.479255 23443585951552 run_lib.py:153] step: 4000, eval_loss: 4.13972e-04
I0404 16:52:54.204961 23443585951552 run_lib.py:140] step: 4050, training_loss: 3.93546e-04
I0404 16:53:15.815965 23443585951552 run_lib.py:140] step: 4100, training_loss: 3.73624e-04
I0404 16:53:15.977255 23443585951552 run_lib.py:153] step: 4100, eval_loss: 4.39212e-04
I0404 16:53:37.185369 23443585951552 run_lib.py:140] step: 4150, training_loss: 4.42811e-04
I0404 16:53:58.509597 23443585951552 run_lib.py:140] step: 4200, training_loss: 4.27338e-04
I0404 16:53:58.684272 23443585951552 run_lib.py:153] step: 4200, eval_loss: 4.62882e-04
I0404 16:54:20.038503 23443585951552 run_lib.py:140] step: 4250, training_loss: 4.31134e-04
I0404 16:54:41.636574 23443585951552 run_lib.py:140] step: 4300, training_loss: 4.20299e-04
I0404 16:54:41.793124 23443585951552 run_lib.py:153] step: 4300, eval_loss: 3.90628e-04
I0404 16:55:02.915021 23443585951552 run_lib.py:140] step: 4350, training_loss: 3.63351e-04
I0404 16:55:24.513659 23443585951552 run_lib.py:140] step: 4400, training_loss: 3.82018e-04
I0404 16:55:24.672305 23443585951552 run_lib.py:153] step: 4400, eval_loss: 4.59052e-04
I0404 16:55:46.513190 23443585951552 run_lib.py:140] step: 4450, training_loss: 3.84997e-04
I0404 16:56:08.005854 23443585951552 run_lib.py:140] step: 4500, training_loss: 4.38240e-04
I0404 16:56:08.158446 23443585951552 run_lib.py:153] step: 4500, eval_loss: 4.46550e-04
I0404 16:56:29.631364 23443585951552 run_lib.py:140] step: 4550, training_loss: 4.10714e-04
I0404 16:56:51.212419 23443585951552 run_lib.py:140] step: 4600, training_loss: 4.09054e-04
I0404 16:56:51.366442 23443585951552 run_lib.py:153] step: 4600, eval_loss: 3.70758e-04
I0404 16:57:12.787133 23443585951552 run_lib.py:140] step: 4650, training_loss: 4.61818e-04
I0404 16:57:34.351431 23443585951552 run_lib.py:140] step: 4700, training_loss: 4.04328e-04
I0404 16:57:34.526418 23443585951552 run_lib.py:153] step: 4700, eval_loss: 4.11403e-04
I0404 16:57:56.089108 23443585951552 run_lib.py:140] step: 4750, training_loss: 4.39627e-04
I0404 16:58:17.911679 23443585951552 run_lib.py:140] step: 4800, training_loss: 3.71940e-04
I0404 16:58:18.067288 23443585951552 run_lib.py:153] step: 4800, eval_loss: 3.90053e-04
I0404 16:58:39.562800 23443585951552 run_lib.py:140] step: 4850, training_loss: 4.11513e-04
I0404 16:59:01.100635 23443585951552 run_lib.py:140] step: 4900, training_loss: 4.34041e-04
I0404 16:59:01.262174 23443585951552 run_lib.py:153] step: 4900, eval_loss: 3.69644e-04
I0404 16:59:22.955664 23443585951552 run_lib.py:140] step: 4950, training_loss: 3.86325e-04
I0404 16:59:44.536162 23443585951552 run_lib.py:140] step: 5000, training_loss: 4.40486e-04
I0404 16:59:44.686604 23443585951552 run_lib.py:153] step: 5000, eval_loss: 4.56609e-04
I0404 17:00:06.019571 23443585951552 run_lib.py:140] step: 5050, training_loss: 3.91542e-04
I0404 17:00:27.618531 23443585951552 run_lib.py:140] step: 5100, training_loss: 4.28999e-04
I0404 17:00:27.783046 23443585951552 run_lib.py:153] step: 5100, eval_loss: 3.86486e-04
I0404 17:00:49.416918 23443585951552 run_lib.py:140] step: 5150, training_loss: 3.76394e-04
I0404 17:01:10.774514 23443585951552 run_lib.py:140] step: 5200, training_loss: 3.87130e-04
I0404 17:01:10.930595 23443585951552 run_lib.py:153] step: 5200, eval_loss: 3.98190e-04
I0404 17:01:32.386551 23443585951552 run_lib.py:140] step: 5250, training_loss: 4.02004e-04
I0404 17:01:54.137893 23443585951552 run_lib.py:140] step: 5300, training_loss: 4.42551e-04
I0404 17:01:54.291773 23443585951552 run_lib.py:153] step: 5300, eval_loss: 3.95215e-04
I0404 17:02:15.327282 23443585951552 run_lib.py:140] step: 5350, training_loss: 4.19445e-04
I0404 17:02:37.100801 23443585951552 run_lib.py:140] step: 5400, training_loss: 4.19241e-04
I0404 17:02:37.257502 23443585951552 run_lib.py:153] step: 5400, eval_loss: 3.72210e-04
I0404 17:02:58.661859 23443585951552 run_lib.py:140] step: 5450, training_loss: 4.09460e-04
I0404 17:03:19.927528 23443585951552 run_lib.py:140] step: 5500, training_loss: 4.15829e-04
I0404 17:03:20.077571 23443585951552 run_lib.py:153] step: 5500, eval_loss: 3.71938e-04
I0404 17:03:41.457870 23443585951552 run_lib.py:140] step: 5550, training_loss: 4.51198e-04
I0404 17:04:02.931288 23443585951552 run_lib.py:140] step: 5600, training_loss: 3.78300e-04
I0404 17:04:03.106927 23443585951552 run_lib.py:153] step: 5600, eval_loss: 3.99860e-04
I0404 17:04:24.333885 23443585951552 run_lib.py:140] step: 5650, training_loss: 4.54512e-04
I0404 17:04:45.812649 23443585951552 run_lib.py:140] step: 5700, training_loss: 4.34306e-04
I0404 17:04:45.970677 23443585951552 run_lib.py:153] step: 5700, eval_loss: 3.92952e-04
I0404 17:05:07.148695 23443585951552 run_lib.py:140] step: 5750, training_loss: 4.41400e-04
I0404 17:05:28.522280 23443585951552 run_lib.py:140] step: 5800, training_loss: 4.06000e-04
I0404 17:05:28.689937 23443585951552 run_lib.py:153] step: 5800, eval_loss: 3.84172e-04
I0404 17:05:50.077016 23443585951552 run_lib.py:140] step: 5850, training_loss: 4.53137e-04
I0404 17:06:11.363589 23443585951552 run_lib.py:140] step: 5900, training_loss: 4.63843e-04
I0404 17:06:11.518753 23443585951552 run_lib.py:153] step: 5900, eval_loss: 4.07788e-04
I0404 17:06:32.761906 23443585951552 run_lib.py:140] step: 5950, training_loss: 4.65422e-04
I0404 17:06:54.065830 23443585951552 run_lib.py:140] step: 6000, training_loss: 4.23373e-04
I0404 17:06:54.216328 23443585951552 run_lib.py:153] step: 6000, eval_loss: 3.90067e-04
I0404 17:07:15.588685 23443585951552 run_lib.py:140] step: 6050, training_loss: 4.00754e-04
I0404 17:07:36.693466 23443585951552 run_lib.py:140] step: 6100, training_loss: 3.59730e-04
I0404 17:07:36.869843 23443585951552 run_lib.py:153] step: 6100, eval_loss: 4.27026e-04
I0404 17:07:58.175922 23443585951552 run_lib.py:140] step: 6150, training_loss: 3.75814e-04
I0404 17:08:19.272789 23443585951552 run_lib.py:140] step: 6200, training_loss: 4.29501e-04
I0404 17:08:19.428360 23443585951552 run_lib.py:153] step: 6200, eval_loss: 4.11969e-04
I0404 17:08:40.954900 23443585951552 run_lib.py:140] step: 6250, training_loss: 3.54690e-04
I0404 17:09:02.005746 23443585951552 run_lib.py:140] step: 6300, training_loss: 4.79417e-04
I0404 17:09:02.168712 23443585951552 run_lib.py:153] step: 6300, eval_loss: 4.03052e-04
I0404 17:09:23.863556 23443585951552 run_lib.py:140] step: 6350, training_loss: 4.09305e-04
I0404 17:09:45.267608 23443585951552 run_lib.py:140] step: 6400, training_loss: 4.17059e-04
I0404 17:09:45.418277 23443585951552 run_lib.py:153] step: 6400, eval_loss: 4.18203e-04
I0404 17:10:06.632122 23443585951552 run_lib.py:140] step: 6450, training_loss: 4.12320e-04
I0404 17:10:28.047118 23443585951552 run_lib.py:140] step: 6500, training_loss: 3.84491e-04
I0404 17:10:28.202776 23443585951552 run_lib.py:153] step: 6500, eval_loss: 4.32434e-04
I0404 17:10:49.520526 23443585951552 run_lib.py:140] step: 6550, training_loss: 3.55528e-04
I0404 17:11:11.187345 23443585951552 run_lib.py:140] step: 6600, training_loss: 4.15444e-04
I0404 17:11:11.352192 23443585951552 run_lib.py:153] step: 6600, eval_loss: 3.31426e-04
I0404 17:11:32.879066 23443585951552 run_lib.py:140] step: 6650, training_loss: 3.18943e-04
I0404 17:11:54.040145 23443585951552 run_lib.py:140] step: 6700, training_loss: 4.49740e-04
I0404 17:11:54.195455 23443585951552 run_lib.py:153] step: 6700, eval_loss: 4.31804e-04
I0404 17:12:15.191555 23443585951552 run_lib.py:140] step: 6750, training_loss: 4.31636e-04
I0404 17:12:37.215679 23443585951552 run_lib.py:140] step: 6800, training_loss: 4.25079e-04
I0404 17:12:37.368889 23443585951552 run_lib.py:153] step: 6800, eval_loss: 3.71401e-04
I0404 17:12:58.649103 23443585951552 run_lib.py:140] step: 6850, training_loss: 3.43022e-04
I0404 17:13:19.593023 23443585951552 run_lib.py:140] step: 6900, training_loss: 4.09417e-04
I0404 17:13:19.743642 23443585951552 run_lib.py:153] step: 6900, eval_loss: 3.23095e-04
I0404 17:13:40.944408 23443585951552 run_lib.py:140] step: 6950, training_loss: 4.23351e-04
I0404 17:14:02.201416 23443585951552 run_lib.py:140] step: 7000, training_loss: 3.81407e-04
I0404 17:14:02.368894 23443585951552 run_lib.py:153] step: 7000, eval_loss: 4.39418e-04
I0404 17:14:23.654754 23443585951552 run_lib.py:140] step: 7050, training_loss: 3.69141e-04
I0404 17:14:44.858212 23443585951552 run_lib.py:140] step: 7100, training_loss: 4.20674e-04
I0404 17:14:45.019684 23443585951552 run_lib.py:153] step: 7100, eval_loss: 3.42575e-04
I0404 17:15:07.013086 23443585951552 run_lib.py:140] step: 7150, training_loss: 3.51793e-04
I0404 17:15:28.206951 23443585951552 run_lib.py:140] step: 7200, training_loss: 3.55611e-04
I0404 17:15:28.375557 23443585951552 run_lib.py:153] step: 7200, eval_loss: 4.24174e-04
I0404 17:15:49.483879 23443585951552 run_lib.py:140] step: 7250, training_loss: 4.56042e-04
I0404 17:16:10.903535 23443585951552 run_lib.py:140] step: 7300, training_loss: 3.56155e-04
I0404 17:16:11.057065 23443585951552 run_lib.py:153] step: 7300, eval_loss: 3.99213e-04
I0404 17:16:32.229193 23443585951552 run_lib.py:140] step: 7350, training_loss: 4.23178e-04
I0404 17:16:53.362370 23443585951552 run_lib.py:140] step: 7400, training_loss: 4.49532e-04
I0404 17:16:53.513759 23443585951552 run_lib.py:153] step: 7400, eval_loss: 4.06808e-04
I0404 17:17:14.838838 23443585951552 run_lib.py:140] step: 7450, training_loss: 4.14870e-04
I0404 17:17:36.379914 23443585951552 run_lib.py:140] step: 7500, training_loss: 4.24698e-04
I0404 17:17:36.539780 23443585951552 run_lib.py:153] step: 7500, eval_loss: 4.76588e-04
I0404 17:17:58.089146 23443585951552 run_lib.py:140] step: 7550, training_loss: 3.52563e-04
I0404 17:18:19.394266 23443585951552 run_lib.py:140] step: 7600, training_loss: 4.35358e-04
I0404 17:18:19.551872 23443585951552 run_lib.py:153] step: 7600, eval_loss: 3.69236e-04
I0404 17:18:41.104527 23443585951552 run_lib.py:140] step: 7650, training_loss: 3.88599e-04
I0404 17:19:02.281658 23443585951552 run_lib.py:140] step: 7700, training_loss: 4.05544e-04
I0404 17:19:02.438720 23443585951552 run_lib.py:153] step: 7700, eval_loss: 4.23217e-04
I0404 17:19:24.154152 23443585951552 run_lib.py:140] step: 7750, training_loss: 4.38498e-04
I0404 17:19:45.176810 23443585951552 run_lib.py:140] step: 7800, training_loss: 4.03445e-04
I0404 17:19:45.329380 23443585951552 run_lib.py:153] step: 7800, eval_loss: 3.88066e-04
I0404 17:20:06.627410 23443585951552 run_lib.py:140] step: 7850, training_loss: 3.34761e-04
I0404 17:20:28.458712 23443585951552 run_lib.py:140] step: 7900, training_loss: 4.17522e-04
I0404 17:20:28.625064 23443585951552 run_lib.py:153] step: 7900, eval_loss: 3.64851e-04
I0404 17:20:50.056097 23443585951552 run_lib.py:140] step: 7950, training_loss: 3.79970e-04
I0404 17:21:10.898109 23443585951552 run_lib.py:140] step: 8000, training_loss: 3.92685e-04
I0404 17:21:11.055171 23443585951552 run_lib.py:153] step: 8000, eval_loss: 4.22712e-04
I0404 17:21:32.202359 23443585951552 run_lib.py:140] step: 8050, training_loss: 3.83557e-04
I0404 17:21:53.435391 23443585951552 run_lib.py:140] step: 8100, training_loss: 3.77362e-04
I0404 17:21:53.601718 23443585951552 run_lib.py:153] step: 8100, eval_loss: 4.30964e-04
I0404 17:22:14.626117 23443585951552 run_lib.py:140] step: 8150, training_loss: 4.49655e-04
I0404 17:22:35.936517 23443585951552 run_lib.py:140] step: 8200, training_loss: 3.73416e-04
I0404 17:22:36.092969 23443585951552 run_lib.py:153] step: 8200, eval_loss: 4.33006e-04
I0404 17:22:57.640353 23443585951552 run_lib.py:140] step: 8250, training_loss: 4.41241e-04
I0404 17:23:18.813010 23443585951552 run_lib.py:140] step: 8300, training_loss: 3.60489e-04
I0404 17:23:18.964937 23443585951552 run_lib.py:153] step: 8300, eval_loss: 4.13820e-04
I0404 17:23:39.933733 23443585951552 run_lib.py:140] step: 8350, training_loss: 3.51632e-04
I0404 17:24:01.027025 23443585951552 run_lib.py:140] step: 8400, training_loss: 4.19565e-04
I0404 17:24:01.195859 23443585951552 run_lib.py:153] step: 8400, eval_loss: 3.50934e-04
I0404 17:24:22.621230 23443585951552 run_lib.py:140] step: 8450, training_loss: 3.87210e-04
I0404 17:24:44.005082 23443585951552 run_lib.py:140] step: 8500, training_loss: 4.16294e-04
I0404 17:24:44.167000 23443585951552 run_lib.py:153] step: 8500, eval_loss: 4.31811e-04
I0404 17:25:05.547472 23443585951552 run_lib.py:140] step: 8550, training_loss: 4.13786e-04
I0404 17:25:27.270948 23443585951552 run_lib.py:140] step: 8600, training_loss: 4.21651e-04
I0404 17:25:27.439845 23443585951552 run_lib.py:153] step: 8600, eval_loss: 3.90682e-04
I0404 17:25:48.673540 23443585951552 run_lib.py:140] step: 8650, training_loss: 4.20596e-04
I0404 17:26:10.467368 23443585951552 run_lib.py:140] step: 8700, training_loss: 4.01441e-04
I0404 17:26:10.623852 23443585951552 run_lib.py:153] step: 8700, eval_loss: 3.87798e-04
I0404 17:26:32.260462 23443585951552 run_lib.py:140] step: 8750, training_loss: 4.05003e-04
I0404 17:26:53.949568 23443585951552 run_lib.py:140] step: 8800, training_loss: 3.94986e-04
I0404 17:26:54.100018 23443585951552 run_lib.py:153] step: 8800, eval_loss: 4.21970e-04
I0404 17:27:15.541131 23443585951552 run_lib.py:140] step: 8850, training_loss: 4.09298e-04
I0404 17:27:37.041631 23443585951552 run_lib.py:140] step: 8900, training_loss: 3.81216e-04
I0404 17:27:37.202045 23443585951552 run_lib.py:153] step: 8900, eval_loss: 4.40231e-04
I0404 17:27:58.483749 23443585951552 run_lib.py:140] step: 8950, training_loss: 3.81568e-04
I0404 17:28:19.769118 23443585951552 run_lib.py:140] step: 9000, training_loss: 3.94422e-04
I0404 17:28:19.928413 23443585951552 run_lib.py:153] step: 9000, eval_loss: 4.28622e-04
I0404 17:28:40.112563 23443585951552 run_lib.py:140] step: 9050, training_loss: 3.74305e-04
I0404 17:28:57.551084 23443585951552 run_lib.py:140] step: 9100, training_loss: 3.54007e-04
I0404 17:28:57.704998 23443585951552 run_lib.py:153] step: 9100, eval_loss: 4.08753e-04
I0404 17:29:15.186409 23443585951552 run_lib.py:140] step: 9150, training_loss: 3.78518e-04
I0404 17:29:32.525547 23443585951552 run_lib.py:140] step: 9200, training_loss: 4.13097e-04
I0404 17:29:32.676561 23443585951552 run_lib.py:153] step: 9200, eval_loss: 3.73054e-04
I0404 17:29:50.059840 23443585951552 run_lib.py:140] step: 9250, training_loss: 4.19808e-04
I0404 17:30:07.480360 23443585951552 run_lib.py:140] step: 9300, training_loss: 3.76030e-04
I0404 17:30:07.636622 23443585951552 run_lib.py:153] step: 9300, eval_loss: 4.03226e-04
I0404 17:30:25.124001 23443585951552 run_lib.py:140] step: 9350, training_loss: 3.68186e-04
I0404 17:30:42.655432 23443585951552 run_lib.py:140] step: 9400, training_loss: 3.89183e-04
I0404 17:30:42.825752 23443585951552 run_lib.py:153] step: 9400, eval_loss: 3.95403e-04
I0404 17:31:00.285226 23443585951552 run_lib.py:140] step: 9450, training_loss: 3.82028e-04
I0404 17:31:17.723162 23443585951552 run_lib.py:140] step: 9500, training_loss: 4.72759e-04
I0404 17:31:17.876986 23443585951552 run_lib.py:153] step: 9500, eval_loss: 3.56754e-04
I0404 17:31:35.492952 23443585951552 run_lib.py:140] step: 9550, training_loss: 4.38008e-04
I0404 17:31:52.946398 23443585951552 run_lib.py:140] step: 9600, training_loss: 3.54537e-04
I0404 17:31:53.096473 23443585951552 run_lib.py:153] step: 9600, eval_loss: 4.34162e-04
I0404 17:32:10.550851 23443585951552 run_lib.py:140] step: 9650, training_loss: 4.58647e-04
I0404 17:32:28.210665 23443585951552 run_lib.py:140] step: 9700, training_loss: 4.09215e-04
I0404 17:32:28.365047 23443585951552 run_lib.py:153] step: 9700, eval_loss: 4.02577e-04
I0404 17:32:45.855056 23443585951552 run_lib.py:140] step: 9750, training_loss: 3.78851e-04
I0404 17:33:03.445940 23443585951552 run_lib.py:140] step: 9800, training_loss: 4.60671e-04
I0404 17:33:03.599775 23443585951552 run_lib.py:153] step: 9800, eval_loss: 3.79483e-04
I0404 17:33:21.009789 23443585951552 run_lib.py:140] step: 9850, training_loss: 4.03279e-04
I0404 17:33:38.418578 23443585951552 run_lib.py:140] step: 9900, training_loss: 3.75250e-04
I0404 17:33:38.592848 23443585951552 run_lib.py:153] step: 9900, eval_loss: 4.19185e-04
I0404 17:33:56.248775 23443585951552 run_lib.py:140] step: 9950, training_loss: 4.25047e-04
I0404 17:34:13.752614 23443585951552 run_lib.py:140] step: 10000, training_loss: 3.64906e-04
I0404 17:34:15.966890 23443585951552 run_lib.py:153] step: 10000, eval_loss: 3.72956e-04
I0404 17:34:35.558821 23443585951552 run_lib.py:140] step: 10050, training_loss: 4.08629e-04
I0404 17:34:53.149406 23443585951552 run_lib.py:140] step: 10100, training_loss: 4.08927e-04
I0404 17:34:53.302916 23443585951552 run_lib.py:153] step: 10100, eval_loss: 4.21195e-04
I0404 17:35:10.734323 23443585951552 run_lib.py:140] step: 10150, training_loss: 4.17111e-04
I0404 17:35:28.215272 23443585951552 run_lib.py:140] step: 10200, training_loss: 4.38275e-04
I0404 17:35:28.365977 23443585951552 run_lib.py:153] step: 10200, eval_loss: 4.34685e-04
I0404 17:35:45.941903 23443585951552 run_lib.py:140] step: 10250, training_loss: 4.06828e-04
I0404 17:36:03.381637 23443585951552 run_lib.py:140] step: 10300, training_loss: 3.75693e-04
I0404 17:36:03.535741 23443585951552 run_lib.py:153] step: 10300, eval_loss: 3.69427e-04
I0404 17:36:20.932838 23443585951552 run_lib.py:140] step: 10350, training_loss: 3.85807e-04
I0404 17:36:38.350039 23443585951552 run_lib.py:140] step: 10400, training_loss: 4.20421e-04
I0404 17:36:38.507000 23443585951552 run_lib.py:153] step: 10400, eval_loss: 3.83024e-04
I0404 17:36:56.187699 23443585951552 run_lib.py:140] step: 10450, training_loss: 4.21930e-04
I0404 17:37:17.353825 23443585951552 run_lib.py:140] step: 10500, training_loss: 3.65606e-04
I0404 17:37:17.520594 23443585951552 run_lib.py:153] step: 10500, eval_loss: 3.66227e-04
I0404 17:37:39.200831 23443585951552 run_lib.py:140] step: 10550, training_loss: 3.94259e-04
I0404 17:38:00.571240 23443585951552 run_lib.py:140] step: 10600, training_loss: 3.61379e-04
I0404 17:38:00.723916 23443585951552 run_lib.py:153] step: 10600, eval_loss: 3.46826e-04
I0404 17:38:22.423744 23443585951552 run_lib.py:140] step: 10650, training_loss: 3.54613e-04
I0404 17:38:44.074649 23443585951552 run_lib.py:140] step: 10700, training_loss: 4.12283e-04
I0404 17:38:44.233272 23443585951552 run_lib.py:153] step: 10700, eval_loss: 3.43780e-04
I0404 17:39:05.811278 23443585951552 run_lib.py:140] step: 10750, training_loss: 4.39422e-04
I0404 17:39:27.116716 23443585951552 run_lib.py:140] step: 10800, training_loss: 3.62121e-04
I0404 17:39:27.280693 23443585951552 run_lib.py:153] step: 10800, eval_loss: 3.77784e-04
I0404 17:39:48.867357 23443585951552 run_lib.py:140] step: 10850, training_loss: 4.12865e-04
I0404 17:40:10.450058 23443585951552 run_lib.py:140] step: 10900, training_loss: 3.97519e-04
I0404 17:40:10.605954 23443585951552 run_lib.py:153] step: 10900, eval_loss: 4.52549e-04
I0404 17:40:31.910148 23443585951552 run_lib.py:140] step: 10950, training_loss: 4.43706e-04
I0404 17:40:53.646556 23443585951552 run_lib.py:140] step: 11000, training_loss: 3.69043e-04
I0404 17:40:53.805502 23443585951552 run_lib.py:153] step: 11000, eval_loss: 3.89111e-04
I0404 17:41:15.330966 23443585951552 run_lib.py:140] step: 11050, training_loss: 4.27703e-04
I0404 17:41:36.825428 23443585951552 run_lib.py:140] step: 11100, training_loss: 3.80198e-04
I0404 17:41:36.978014 23443585951552 run_lib.py:153] step: 11100, eval_loss: 3.47664e-04
I0404 17:41:58.575034 23443585951552 run_lib.py:140] step: 11150, training_loss: 4.43305e-04
I0404 17:42:20.634307 23443585951552 run_lib.py:140] step: 11200, training_loss: 3.79703e-04
I0404 17:42:20.793027 23443585951552 run_lib.py:153] step: 11200, eval_loss: 4.34486e-04
I0404 17:42:42.576161 23443585951552 run_lib.py:140] step: 11250, training_loss: 3.54757e-04
I0404 17:43:04.507602 23443585951552 run_lib.py:140] step: 11300, training_loss: 4.11213e-04
I0404 17:43:04.665271 23443585951552 run_lib.py:153] step: 11300, eval_loss: 4.28606e-04
I0404 17:43:25.932586 23443585951552 run_lib.py:140] step: 11350, training_loss: 4.23333e-04
I0404 17:43:47.389365 23443585951552 run_lib.py:140] step: 11400, training_loss: 3.23566e-04
I0404 17:43:47.548251 23443585951552 run_lib.py:153] step: 11400, eval_loss: 3.52530e-04
I0404 17:44:08.956161 23443585951552 run_lib.py:140] step: 11450, training_loss: 4.19022e-04
I0404 17:44:30.117655 23443585951552 run_lib.py:140] step: 11500, training_loss: 3.42989e-04
I0404 17:44:30.272004 23443585951552 run_lib.py:153] step: 11500, eval_loss: 4.88747e-04
I0404 17:44:51.914635 23443585951552 run_lib.py:140] step: 11550, training_loss: 3.89440e-04
I0404 17:45:13.730585 23443585951552 run_lib.py:140] step: 11600, training_loss: 3.88023e-04
I0404 17:45:13.891531 23443585951552 run_lib.py:153] step: 11600, eval_loss: 4.05580e-04
I0404 17:45:35.352037 23443585951552 run_lib.py:140] step: 11650, training_loss: 4.57734e-04
I0404 17:45:57.288061 23443585951552 run_lib.py:140] step: 11700, training_loss: 4.16264e-04
I0404 17:45:57.443241 23443585951552 run_lib.py:153] step: 11700, eval_loss: 4.64371e-04
I0404 17:46:19.093987 23443585951552 run_lib.py:140] step: 11750, training_loss: 4.63841e-04
I0404 17:46:40.456531 23443585951552 run_lib.py:140] step: 11800, training_loss: 4.12443e-04
I0404 17:46:40.631210 23443585951552 run_lib.py:153] step: 11800, eval_loss: 4.53319e-04
I0404 17:47:02.350778 23443585951552 run_lib.py:140] step: 11850, training_loss: 4.11636e-04
I0404 17:47:23.934923 23443585951552 run_lib.py:140] step: 11900, training_loss: 4.17323e-04
I0404 17:47:24.090219 23443585951552 run_lib.py:153] step: 11900, eval_loss: 4.76651e-04
I0404 17:47:45.684085 23443585951552 run_lib.py:140] step: 11950, training_loss: 4.42559e-04
I0404 17:48:07.055868 23443585951552 run_lib.py:140] step: 12000, training_loss: 3.70378e-04
I0404 17:48:07.215009 23443585951552 run_lib.py:153] step: 12000, eval_loss: 3.88162e-04
I0404 17:48:28.480455 23443585951552 run_lib.py:140] step: 12050, training_loss: 4.57532e-04
I0404 17:48:50.159425 23443585951552 run_lib.py:140] step: 12100, training_loss: 3.93446e-04
I0404 17:48:50.316262 23443585951552 run_lib.py:153] step: 12100, eval_loss: 3.62352e-04
I0404 17:49:11.826671 23443585951552 run_lib.py:140] step: 12150, training_loss: 3.91762e-04
I0404 17:49:33.554623 23443585951552 run_lib.py:140] step: 12200, training_loss: 3.66837e-04
I0404 17:49:33.707527 23443585951552 run_lib.py:153] step: 12200, eval_loss: 4.54284e-04
I0404 17:49:55.207177 23443585951552 run_lib.py:140] step: 12250, training_loss: 4.14094e-04
I0404 17:50:16.965336 23443585951552 run_lib.py:140] step: 12300, training_loss: 4.52226e-04
I0404 17:50:17.125393 23443585951552 run_lib.py:153] step: 12300, eval_loss: 3.89444e-04
I0404 17:50:38.592706 23443585951552 run_lib.py:140] step: 12350, training_loss: 4.30924e-04
I0404 17:51:00.302716 23443585951552 run_lib.py:140] step: 12400, training_loss: 3.80578e-04
I0404 17:51:00.457491 23443585951552 run_lib.py:153] step: 12400, eval_loss: 3.91617e-04
I0404 17:51:21.863712 23443585951552 run_lib.py:140] step: 12450, training_loss: 4.42373e-04
I0404 17:51:43.573727 23443585951552 run_lib.py:140] step: 12500, training_loss: 4.17156e-04
I0404 17:51:43.734958 23443585951552 run_lib.py:153] step: 12500, eval_loss: 4.15720e-04
I0404 17:52:05.383718 23443585951552 run_lib.py:140] step: 12550, training_loss: 4.62516e-04
I0404 17:52:26.769689 23443585951552 run_lib.py:140] step: 12600, training_loss: 4.40201e-04
I0404 17:52:26.928761 23443585951552 run_lib.py:153] step: 12600, eval_loss: 4.03561e-04
I0404 17:52:48.333815 23443585951552 run_lib.py:140] step: 12650, training_loss: 4.01747e-04
I0404 17:53:09.835272 23443585951552 run_lib.py:140] step: 12700, training_loss: 4.02239e-04
I0404 17:53:10.004998 23443585951552 run_lib.py:153] step: 12700, eval_loss: 4.07878e-04
I0404 17:53:31.645778 23443585951552 run_lib.py:140] step: 12750, training_loss: 3.79919e-04
I0404 17:53:53.210624 23443585951552 run_lib.py:140] step: 12800, training_loss: 3.82421e-04
I0404 17:53:53.370061 23443585951552 run_lib.py:153] step: 12800, eval_loss: 4.42088e-04
I0404 17:54:15.165904 23443585951552 run_lib.py:140] step: 12850, training_loss: 4.08713e-04
I0404 17:54:36.530390 23443585951552 run_lib.py:140] step: 12900, training_loss: 4.37300e-04
I0404 17:54:36.690707 23443585951552 run_lib.py:153] step: 12900, eval_loss: 3.32334e-04
I0404 17:54:57.929715 23443585951552 run_lib.py:140] step: 12950, training_loss: 4.11986e-04
I0404 17:55:19.685319 23443585951552 run_lib.py:140] step: 13000, training_loss: 4.04369e-04
I0404 17:55:19.840199 23443585951552 run_lib.py:153] step: 13000, eval_loss: 4.29117e-04
I0404 17:55:41.284322 23443585951552 run_lib.py:140] step: 13050, training_loss: 3.92019e-04
I0404 17:56:03.056492 23443585951552 run_lib.py:140] step: 13100, training_loss: 4.06773e-04
I0404 17:56:03.212700 23443585951552 run_lib.py:153] step: 13100, eval_loss: 3.99928e-04
I0404 17:56:24.592679 23443585951552 run_lib.py:140] step: 13150, training_loss: 4.24097e-04
I0404 17:56:46.321293 23443585951552 run_lib.py:140] step: 13200, training_loss: 4.28649e-04
I0404 17:56:46.487541 23443585951552 run_lib.py:153] step: 13200, eval_loss: 4.20285e-04
I0404 17:57:08.316409 23443585951552 run_lib.py:140] step: 13250, training_loss: 4.30215e-04
I0404 17:57:28.764855 23443585951552 run_lib.py:140] step: 13300, training_loss: 4.12099e-04
I0404 17:57:28.922940 23443585951552 run_lib.py:153] step: 13300, eval_loss: 3.98280e-04
I0404 17:57:50.369598 23443585951552 run_lib.py:140] step: 13350, training_loss: 4.22348e-04
I0404 17:58:12.068170 23443585951552 run_lib.py:140] step: 13400, training_loss: 4.02947e-04
I0404 17:58:12.226496 23443585951552 run_lib.py:153] step: 13400, eval_loss: 3.61637e-04
I0404 17:58:33.756197 23443585951552 run_lib.py:140] step: 13450, training_loss: 4.26013e-04
I0404 17:58:55.424176 23443585951552 run_lib.py:140] step: 13500, training_loss: 4.37446e-04
I0404 17:58:55.573452 23443585951552 run_lib.py:153] step: 13500, eval_loss: 4.02764e-04
I0404 17:59:17.087006 23443585951552 run_lib.py:140] step: 13550, training_loss: 3.96458e-04
I0404 17:59:38.591490 23443585951552 run_lib.py:140] step: 13600, training_loss: 3.86933e-04
I0404 17:59:38.758011 23443585951552 run_lib.py:153] step: 13600, eval_loss: 4.47748e-04
I0404 18:00:00.339219 23443585951552 run_lib.py:140] step: 13650, training_loss: 3.67166e-04
I0404 18:00:21.740792 23443585951552 run_lib.py:140] step: 13700, training_loss: 4.03007e-04
I0404 18:00:21.907011 23443585951552 run_lib.py:153] step: 13700, eval_loss: 4.08345e-04
I0404 18:00:43.605258 23443585951552 run_lib.py:140] step: 13750, training_loss: 4.08436e-04
I0404 18:01:04.937703 23443585951552 run_lib.py:140] step: 13800, training_loss: 3.90831e-04
I0404 18:01:05.105127 23443585951552 run_lib.py:153] step: 13800, eval_loss: 4.50933e-04
I0404 18:01:26.596041 23443585951552 run_lib.py:140] step: 13850, training_loss: 4.71180e-04
I0404 18:01:48.031604 23443585951552 run_lib.py:140] step: 13900, training_loss: 4.20618e-04
I0404 18:01:48.188101 23443585951552 run_lib.py:153] step: 13900, eval_loss: 3.92248e-04
I0404 18:02:09.573139 23443585951552 run_lib.py:140] step: 13950, training_loss: 4.29070e-04
I0404 18:02:30.949798 23443585951552 run_lib.py:140] step: 14000, training_loss: 4.19852e-04
I0404 18:02:31.101314 23443585951552 run_lib.py:153] step: 14000, eval_loss: 4.32238e-04
I0404 18:02:52.693032 23443585951552 run_lib.py:140] step: 14050, training_loss: 3.44251e-04
I0404 18:03:14.299817 23443585951552 run_lib.py:140] step: 14100, training_loss: 3.95461e-04
I0404 18:03:14.460113 23443585951552 run_lib.py:153] step: 14100, eval_loss: 3.71619e-04
I0404 18:03:36.012713 23443585951552 run_lib.py:140] step: 14150, training_loss: 4.25125e-04
I0404 18:03:57.638950 23443585951552 run_lib.py:140] step: 14200, training_loss: 4.01896e-04
I0404 18:03:57.797302 23443585951552 run_lib.py:153] step: 14200, eval_loss: 4.30490e-04
I0404 18:04:19.405043 23443585951552 run_lib.py:140] step: 14250, training_loss: 4.49097e-04
I0404 18:04:40.810107 23443585951552 run_lib.py:140] step: 14300, training_loss: 4.08623e-04
I0404 18:04:40.966149 23443585951552 run_lib.py:153] step: 14300, eval_loss: 3.81551e-04
I0404 18:05:02.856657 23443585951552 run_lib.py:140] step: 14350, training_loss: 4.18830e-04
I0404 18:05:24.217937 23443585951552 run_lib.py:140] step: 14400, training_loss: 3.66133e-04
I0404 18:05:24.372874 23443585951552 run_lib.py:153] step: 14400, eval_loss: 3.73217e-04
I0404 18:05:45.726246 23443585951552 run_lib.py:140] step: 14450, training_loss: 4.52375e-04
I0404 18:06:07.860331 23443585951552 run_lib.py:140] step: 14500, training_loss: 4.79684e-04
I0404 18:06:08.014194 23443585951552 run_lib.py:153] step: 14500, eval_loss: 4.23360e-04
I0404 18:06:29.656943 23443585951552 run_lib.py:140] step: 14550, training_loss: 4.03262e-04
I0404 18:06:51.118022 23443585951552 run_lib.py:140] step: 14600, training_loss: 3.40032e-04
I0404 18:06:51.272142 23443585951552 run_lib.py:153] step: 14600, eval_loss: 3.87019e-04
I0404 18:07:12.709533 23443585951552 run_lib.py:140] step: 14650, training_loss: 4.22154e-04
I0404 18:07:34.377997 23443585951552 run_lib.py:140] step: 14700, training_loss: 3.84969e-04
I0404 18:07:34.534812 23443585951552 run_lib.py:153] step: 14700, eval_loss: 4.27130e-04
I0404 18:07:56.064254 23443585951552 run_lib.py:140] step: 14750, training_loss: 4.16639e-04
I0404 18:08:17.402630 23443585951552 run_lib.py:140] step: 14800, training_loss: 4.28416e-04
I0404 18:08:17.557488 23443585951552 run_lib.py:153] step: 14800, eval_loss: 4.61523e-04
I0404 18:08:39.160614 23443585951552 run_lib.py:140] step: 14850, training_loss: 4.41626e-04
I0404 18:09:00.710037 23443585951552 run_lib.py:140] step: 14900, training_loss: 3.31072e-04
I0404 18:09:00.862835 23443585951552 run_lib.py:153] step: 14900, eval_loss: 4.45442e-04
I0404 18:09:22.394139 23443585951552 run_lib.py:140] step: 14950, training_loss: 4.01617e-04
I0404 18:09:44.115783 23443585951552 run_lib.py:140] step: 15000, training_loss: 4.14458e-04
I0404 18:09:44.271282 23443585951552 run_lib.py:153] step: 15000, eval_loss: 3.90064e-04
I0404 18:10:05.817560 23443585951552 run_lib.py:140] step: 15050, training_loss: 4.39371e-04
I0404 18:10:27.648034 23443585951552 run_lib.py:140] step: 15100, training_loss: 3.78228e-04
I0404 18:10:27.818684 23443585951552 run_lib.py:153] step: 15100, eval_loss: 4.69099e-04
I0404 18:10:49.367428 23443585951552 run_lib.py:140] step: 15150, training_loss: 4.23949e-04
I0404 18:11:11.060508 23443585951552 run_lib.py:140] step: 15200, training_loss: 4.05939e-04
I0404 18:11:11.214771 23443585951552 run_lib.py:153] step: 15200, eval_loss: 4.42264e-04
I0404 18:11:32.703767 23443585951552 run_lib.py:140] step: 15250, training_loss: 4.07881e-04
I0404 18:11:54.813215 23443585951552 run_lib.py:140] step: 15300, training_loss: 4.00148e-04
I0404 18:11:54.970371 23443585951552 run_lib.py:153] step: 15300, eval_loss: 3.41487e-04
I0404 18:12:16.575443 23443585951552 run_lib.py:140] step: 15350, training_loss: 4.29246e-04
I0404 18:12:37.929615 23443585951552 run_lib.py:140] step: 15400, training_loss: 4.09124e-04
I0404 18:12:38.079674 23443585951552 run_lib.py:153] step: 15400, eval_loss: 4.47689e-04
I0404 18:12:59.542391 23443585951552 run_lib.py:140] step: 15450, training_loss: 3.50446e-04
I0404 18:13:21.249582 23443585951552 run_lib.py:140] step: 15500, training_loss: 4.02517e-04
I0404 18:13:21.410418 23443585951552 run_lib.py:153] step: 15500, eval_loss: 5.03262e-04
I0404 18:13:42.737164 23443585951552 run_lib.py:140] step: 15550, training_loss: 3.90612e-04
I0404 18:14:04.612499 23443585951552 run_lib.py:140] step: 15600, training_loss: 3.58131e-04
I0404 18:14:04.769214 23443585951552 run_lib.py:153] step: 15600, eval_loss: 4.03417e-04
I0404 18:14:26.442856 23443585951552 run_lib.py:140] step: 15650, training_loss: 5.33602e-04
I0404 18:14:47.743786 23443585951552 run_lib.py:140] step: 15700, training_loss: 3.92857e-04
I0404 18:14:47.901553 23443585951552 run_lib.py:153] step: 15700, eval_loss: 3.71118e-04
I0404 18:15:09.333629 23443585951552 run_lib.py:140] step: 15750, training_loss: 3.65720e-04
I0404 18:15:30.888449 23443585951552 run_lib.py:140] step: 15800, training_loss: 4.01260e-04
I0404 18:15:31.042804 23443585951552 run_lib.py:153] step: 15800, eval_loss: 3.93561e-04
I0404 18:15:52.305635 23443585951552 run_lib.py:140] step: 15850, training_loss: 4.17383e-04
I0404 18:16:13.662189 23443585951552 run_lib.py:140] step: 15900, training_loss: 4.07727e-04
I0404 18:16:13.818937 23443585951552 run_lib.py:153] step: 15900, eval_loss: 4.68274e-04
I0404 18:16:35.424780 23443585951552 run_lib.py:140] step: 15950, training_loss: 4.07472e-04
I0404 18:16:57.325058 23443585951552 run_lib.py:140] step: 16000, training_loss: 3.90195e-04
I0404 18:16:57.480980 23443585951552 run_lib.py:153] step: 16000, eval_loss: 3.76455e-04
I0404 18:17:19.065574 23443585951552 run_lib.py:140] step: 16050, training_loss: 3.77487e-04
I0404 18:17:40.589987 23443585951552 run_lib.py:140] step: 16100, training_loss: 3.77529e-04
I0404 18:17:40.754935 23443585951552 run_lib.py:153] step: 16100, eval_loss: 4.09714e-04
I0404 18:18:02.733777 23443585951552 run_lib.py:140] step: 16150, training_loss: 3.97176e-04
I0404 18:18:24.317398 23443585951552 run_lib.py:140] step: 16200, training_loss: 3.66403e-04
I0404 18:18:24.472187 23443585951552 run_lib.py:153] step: 16200, eval_loss: 3.86288e-04
I0404 18:18:45.902868 23443585951552 run_lib.py:140] step: 16250, training_loss: 4.17197e-04
I0404 18:19:07.531767 23443585951552 run_lib.py:140] step: 16300, training_loss: 4.42219e-04
I0404 18:19:07.687694 23443585951552 run_lib.py:153] step: 16300, eval_loss: 4.02412e-04
I0404 18:19:29.151191 23443585951552 run_lib.py:140] step: 16350, training_loss: 4.34268e-04
I0404 18:19:51.096885 23443585951552 run_lib.py:140] step: 16400, training_loss: 3.58508e-04
I0404 18:19:51.257949 23443585951552 run_lib.py:153] step: 16400, eval_loss: 4.09865e-04
I0404 18:20:13.053478 23443585951552 run_lib.py:140] step: 16450, training_loss: 4.23157e-04
I0404 18:20:34.356512 23443585951552 run_lib.py:140] step: 16500, training_loss: 4.30251e-04
I0404 18:20:34.525441 23443585951552 run_lib.py:153] step: 16500, eval_loss: 4.10879e-04
I0404 18:20:56.493322 23443585951552 run_lib.py:140] step: 16550, training_loss: 3.36099e-04
I0404 18:21:17.656095 23443585951552 run_lib.py:140] step: 16600, training_loss: 4.41354e-04
I0404 18:21:17.810777 23443585951552 run_lib.py:153] step: 16600, eval_loss: 4.21082e-04
I0404 18:21:39.380995 23443585951552 run_lib.py:140] step: 16650, training_loss: 4.31888e-04
I0404 18:22:00.763795 23443585951552 run_lib.py:140] step: 16700, training_loss: 3.82854e-04
I0404 18:22:00.920226 23443585951552 run_lib.py:153] step: 16700, eval_loss: 3.57884e-04
I0404 18:22:22.050644 23443585951552 run_lib.py:140] step: 16750, training_loss: 3.84668e-04
I0404 18:22:43.983703 23443585951552 run_lib.py:140] step: 16800, training_loss: 4.07426e-04
I0404 18:22:44.138397 23443585951552 run_lib.py:153] step: 16800, eval_loss: 3.96998e-04
I0404 18:23:05.572987 23443585951552 run_lib.py:140] step: 16850, training_loss: 3.54672e-04
I0404 18:23:26.754173 23443585951552 run_lib.py:140] step: 16900, training_loss: 3.80362e-04
I0404 18:23:26.917364 23443585951552 run_lib.py:153] step: 16900, eval_loss: 4.08509e-04
I0404 18:23:48.667901 23443585951552 run_lib.py:140] step: 16950, training_loss: 3.59352e-04
I0404 18:24:10.300361 23443585951552 run_lib.py:140] step: 17000, training_loss: 4.48613e-04
I0404 18:24:10.464094 23443585951552 run_lib.py:153] step: 17000, eval_loss: 4.28632e-04
I0404 18:24:32.283133 23443585951552 run_lib.py:140] step: 17050, training_loss: 4.07998e-04
I0404 18:24:54.178967 23443585951552 run_lib.py:140] step: 17100, training_loss: 3.92547e-04
I0404 18:24:54.333852 23443585951552 run_lib.py:153] step: 17100, eval_loss: 3.76422e-04
I0404 18:25:16.153228 23443585951552 run_lib.py:140] step: 17150, training_loss: 4.33711e-04
I0404 18:25:37.846605 23443585951552 run_lib.py:140] step: 17200, training_loss: 4.52248e-04
I0404 18:25:38.001169 23443585951552 run_lib.py:153] step: 17200, eval_loss: 3.81320e-04
I0404 18:25:59.943023 23443585951552 run_lib.py:140] step: 17250, training_loss: 4.33904e-04
I0404 18:26:21.494239 23443585951552 run_lib.py:140] step: 17300, training_loss: 4.49413e-04
I0404 18:26:21.646950 23443585951552 run_lib.py:153] step: 17300, eval_loss: 4.21226e-04
I0404 18:26:43.341433 23443585951552 run_lib.py:140] step: 17350, training_loss: 3.87225e-04
I0404 18:27:05.389349 23443585951552 run_lib.py:140] step: 17400, training_loss: 4.31236e-04
I0404 18:27:05.561923 23443585951552 run_lib.py:153] step: 17400, eval_loss: 3.91642e-04
I0404 18:27:27.394575 23443585951552 run_lib.py:140] step: 17450, training_loss: 3.95521e-04
I0404 18:27:49.285175 23443585951552 run_lib.py:140] step: 17500, training_loss: 4.00321e-04
I0404 18:27:49.442130 23443585951552 run_lib.py:153] step: 17500, eval_loss: 4.14094e-04
I0404 18:28:11.026808 23443585951552 run_lib.py:140] step: 17550, training_loss: 4.15057e-04
I0404 18:28:32.755645 23443585951552 run_lib.py:140] step: 17600, training_loss: 4.88925e-04
I0404 18:28:32.928180 23443585951552 run_lib.py:153] step: 17600, eval_loss: 4.04622e-04
I0404 18:28:54.895421 23443585951552 run_lib.py:140] step: 17650, training_loss: 4.07731e-04
I0404 18:29:16.401221 23443585951552 run_lib.py:140] step: 17700, training_loss: 3.89003e-04
I0404 18:29:16.556530 23443585951552 run_lib.py:153] step: 17700, eval_loss: 4.97794e-04
I0404 18:29:38.188202 23443585951552 run_lib.py:140] step: 17750, training_loss: 3.95265e-04
I0404 18:30:00.045592 23443585951552 run_lib.py:140] step: 17800, training_loss: 3.85667e-04
I0404 18:30:00.203218 23443585951552 run_lib.py:153] step: 17800, eval_loss: 4.04318e-04
I0404 18:30:21.702283 23443585951552 run_lib.py:140] step: 17850, training_loss: 4.25743e-04
I0404 18:30:43.624037 23443585951552 run_lib.py:140] step: 17900, training_loss: 3.65539e-04
I0404 18:30:43.785974 23443585951552 run_lib.py:153] step: 17900, eval_loss: 4.00587e-04
I0404 18:31:05.758582 23443585951552 run_lib.py:140] step: 17950, training_loss: 4.62339e-04
I0404 18:31:27.551105 23443585951552 run_lib.py:140] step: 18000, training_loss: 4.11170e-04
I0404 18:31:27.720294 23443585951552 run_lib.py:153] step: 18000, eval_loss: 3.99787e-04
I0404 18:31:49.579735 23443585951552 run_lib.py:140] step: 18050, training_loss: 3.10940e-04
I0404 18:32:11.379190 23443585951552 run_lib.py:140] step: 18100, training_loss: 4.12827e-04
I0404 18:32:11.538906 23443585951552 run_lib.py:153] step: 18100, eval_loss: 3.94474e-04
I0404 18:32:33.182704 23443585951552 run_lib.py:140] step: 18150, training_loss: 4.42547e-04
I0404 18:32:54.888131 23443585951552 run_lib.py:140] step: 18200, training_loss: 4.18064e-04
I0404 18:32:55.048823 23443585951552 run_lib.py:153] step: 18200, eval_loss: 3.42611e-04
I0404 18:33:16.739732 23443585951552 run_lib.py:140] step: 18250, training_loss: 4.47273e-04
I0404 18:33:38.188300 23443585951552 run_lib.py:140] step: 18300, training_loss: 3.76715e-04
I0404 18:33:38.354990 23443585951552 run_lib.py:153] step: 18300, eval_loss: 3.82366e-04
I0404 18:34:00.359244 23443585951552 run_lib.py:140] step: 18350, training_loss: 3.81711e-04
I0404 18:34:21.819885 23443585951552 run_lib.py:140] step: 18400, training_loss: 3.77088e-04
I0404 18:34:21.980443 23443585951552 run_lib.py:153] step: 18400, eval_loss: 4.19216e-04
I0404 18:34:43.631276 23443585951552 run_lib.py:140] step: 18450, training_loss: 3.81152e-04
I0404 18:35:05.396650 23443585951552 run_lib.py:140] step: 18500, training_loss: 3.75313e-04
I0404 18:35:05.569866 23443585951552 run_lib.py:153] step: 18500, eval_loss: 4.16581e-04
I0404 18:35:27.469712 23443585951552 run_lib.py:140] step: 18550, training_loss: 3.40237e-04
I0404 18:35:49.276608 23443585951552 run_lib.py:140] step: 18600, training_loss: 4.07986e-04
I0404 18:35:49.432927 23443585951552 run_lib.py:153] step: 18600, eval_loss: 4.30369e-04
I0404 18:36:11.242469 23443585951552 run_lib.py:140] step: 18650, training_loss: 4.41180e-04
I0404 18:36:32.799685 23443585951552 run_lib.py:140] step: 18700, training_loss: 4.52553e-04
I0404 18:36:32.964632 23443585951552 run_lib.py:153] step: 18700, eval_loss: 4.26967e-04
I0404 18:36:54.999651 23443585951552 run_lib.py:140] step: 18750, training_loss: 3.90569e-04
I0404 18:37:16.781391 23443585951552 run_lib.py:140] step: 18800, training_loss: 4.19317e-04
I0404 18:37:16.944225 23443585951552 run_lib.py:153] step: 18800, eval_loss: 4.30711e-04
I0404 18:37:38.617385 23443585951552 run_lib.py:140] step: 18850, training_loss: 3.67764e-04
I0404 18:38:00.510549 23443585951552 run_lib.py:140] step: 18900, training_loss: 4.46539e-04
I0404 18:38:00.674838 23443585951552 run_lib.py:153] step: 18900, eval_loss: 4.20493e-04
I0404 18:38:22.106599 23443585951552 run_lib.py:140] step: 18950, training_loss: 3.85017e-04
I0404 18:38:43.790032 23443585951552 run_lib.py:140] step: 19000, training_loss: 4.93699e-04
I0404 18:38:43.947107 23443585951552 run_lib.py:153] step: 19000, eval_loss: 4.30549e-04
I0404 18:39:05.760563 23443585951552 run_lib.py:140] step: 19050, training_loss: 4.18313e-04
I0404 18:39:27.496219 23443585951552 run_lib.py:140] step: 19100, training_loss: 3.81171e-04
I0404 18:39:27.660852 23443585951552 run_lib.py:153] step: 19100, eval_loss: 3.75306e-04
I0404 18:39:49.176512 23443585951552 run_lib.py:140] step: 19150, training_loss: 3.91873e-04
I0404 18:40:10.941244 23443585951552 run_lib.py:140] step: 19200, training_loss: 3.89847e-04
I0404 18:40:11.100132 23443585951552 run_lib.py:153] step: 19200, eval_loss: 3.98785e-04
I0404 18:40:33.057080 23443585951552 run_lib.py:140] step: 19250, training_loss: 3.81584e-04
I0404 18:40:54.924410 23443585951552 run_lib.py:140] step: 19300, training_loss: 3.87367e-04
I0404 18:40:55.080658 23443585951552 run_lib.py:153] step: 19300, eval_loss: 4.03400e-04
I0404 18:41:16.769289 23443585951552 run_lib.py:140] step: 19350, training_loss: 4.18448e-04
I0404 18:41:38.578165 23443585951552 run_lib.py:140] step: 19400, training_loss: 4.21910e-04
I0404 18:41:38.741138 23443585951552 run_lib.py:153] step: 19400, eval_loss: 3.55268e-04
I0404 18:42:00.626679 23443585951552 run_lib.py:140] step: 19450, training_loss: 3.83332e-04
I0404 18:42:22.405008 23443585951552 run_lib.py:140] step: 19500, training_loss: 4.04984e-04
I0404 18:42:22.564474 23443585951552 run_lib.py:153] step: 19500, eval_loss: 4.38480e-04
I0404 18:42:44.322265 23443585951552 run_lib.py:140] step: 19550, training_loss: 3.59926e-04
I0404 18:43:06.403667 23443585951552 run_lib.py:140] step: 19600, training_loss: 4.17054e-04
I0404 18:43:06.563650 23443585951552 run_lib.py:153] step: 19600, eval_loss: 3.88401e-04
I0404 18:43:28.174428 23443585951552 run_lib.py:140] step: 19650, training_loss: 4.36959e-04
I0404 18:43:50.134769 23443585951552 run_lib.py:140] step: 19700, training_loss: 3.64416e-04
I0404 18:43:50.293773 23443585951552 run_lib.py:153] step: 19700, eval_loss: 4.55406e-04
I0404 18:44:12.227851 23443585951552 run_lib.py:140] step: 19750, training_loss: 4.01136e-04
I0404 18:44:34.160077 23443585951552 run_lib.py:140] step: 19800, training_loss: 3.97721e-04
I0404 18:44:34.337439 23443585951552 run_lib.py:153] step: 19800, eval_loss: 4.07897e-04
I0404 18:44:56.084790 23443585951552 run_lib.py:140] step: 19850, training_loss: 4.00379e-04
I0404 18:45:17.612173 23443585951552 run_lib.py:140] step: 19900, training_loss: 4.12516e-04
I0404 18:45:17.772613 23443585951552 run_lib.py:153] step: 19900, eval_loss: 3.35348e-04
I0404 18:45:39.258956 23443585951552 run_lib.py:140] step: 19950, training_loss: 3.88000e-04
I0404 18:46:00.974075 23443585951552 run_lib.py:140] step: 20000, training_loss: 3.39430e-04
I0404 18:46:01.942309 23443585951552 run_lib.py:153] step: 20000, eval_loss: 4.41106e-04
I0404 18:46:24.503899 23443585951552 run_lib.py:140] step: 20050, training_loss: 4.20236e-04
I0404 18:46:46.260788 23443585951552 run_lib.py:140] step: 20100, training_loss: 4.72118e-04
I0404 18:46:46.416597 23443585951552 run_lib.py:153] step: 20100, eval_loss: 3.87838e-04
I0404 18:47:08.133190 23443585951552 run_lib.py:140] step: 20150, training_loss: 4.33768e-04
I0404 18:47:29.881872 23443585951552 run_lib.py:140] step: 20200, training_loss: 4.10415e-04
I0404 18:47:30.037704 23443585951552 run_lib.py:153] step: 20200, eval_loss: 4.07900e-04
I0404 18:47:51.726219 23443585951552 run_lib.py:140] step: 20250, training_loss: 4.28941e-04
I0404 18:48:13.318320 23443585951552 run_lib.py:140] step: 20300, training_loss: 3.81175e-04
I0404 18:48:13.501956 23443585951552 run_lib.py:153] step: 20300, eval_loss: 3.73176e-04
I0404 18:48:35.433351 23443585951552 run_lib.py:140] step: 20350, training_loss: 3.99648e-04
I0404 18:48:57.084021 23443585951552 run_lib.py:140] step: 20400, training_loss: 4.83818e-04
I0404 18:48:57.238948 23443585951552 run_lib.py:153] step: 20400, eval_loss: 3.42308e-04
I0404 18:49:19.036235 23443585951552 run_lib.py:140] step: 20450, training_loss: 3.86079e-04
I0404 18:49:40.871966 23443585951552 run_lib.py:140] step: 20500, training_loss: 4.35644e-04
I0404 18:49:41.034071 23443585951552 run_lib.py:153] step: 20500, eval_loss: 4.19294e-04
I0404 18:50:03.117218 23443585951552 run_lib.py:140] step: 20550, training_loss: 4.24193e-04
I0404 18:50:24.783446 23443585951552 run_lib.py:140] step: 20600, training_loss: 4.29670e-04
I0404 18:50:24.943785 23443585951552 run_lib.py:153] step: 20600, eval_loss: 3.90808e-04
I0404 18:50:46.894304 23443585951552 run_lib.py:140] step: 20650, training_loss: 4.38824e-04
I0404 18:51:08.632866 23443585951552 run_lib.py:140] step: 20700, training_loss: 4.07413e-04
I0404 18:51:08.795130 23443585951552 run_lib.py:153] step: 20700, eval_loss: 3.57709e-04
I0404 18:51:30.738874 23443585951552 run_lib.py:140] step: 20750, training_loss: 3.94242e-04
I0404 18:51:52.421638 23443585951552 run_lib.py:140] step: 20800, training_loss: 3.69501e-04
I0404 18:51:52.586959 23443585951552 run_lib.py:153] step: 20800, eval_loss: 4.13576e-04
I0404 18:52:14.191257 23443585951552 run_lib.py:140] step: 20850, training_loss: 4.38216e-04
I0404 18:52:36.180637 23443585951552 run_lib.py:140] step: 20900, training_loss: 4.08879e-04
I0404 18:52:36.338010 23443585951552 run_lib.py:153] step: 20900, eval_loss: 4.56530e-04
I0404 18:52:58.084581 23443585951552 run_lib.py:140] step: 20950, training_loss: 4.10335e-04
I0404 18:53:19.937775 23443585951552 run_lib.py:140] step: 21000, training_loss: 3.53413e-04
I0404 18:53:20.099104 23443585951552 run_lib.py:153] step: 21000, eval_loss: 4.36429e-04
I0404 18:53:41.723937 23443585951552 run_lib.py:140] step: 21050, training_loss: 4.30692e-04
I0404 18:54:03.550420 23443585951552 run_lib.py:140] step: 21100, training_loss: 4.13833e-04
I0404 18:54:03.711172 23443585951552 run_lib.py:153] step: 21100, eval_loss: 3.55693e-04
I0404 18:54:25.497613 23443585951552 run_lib.py:140] step: 21150, training_loss: 4.38431e-04
I0404 18:54:47.057718 23443585951552 run_lib.py:140] step: 21200, training_loss: 4.31784e-04
I0404 18:54:47.222850 23443585951552 run_lib.py:153] step: 21200, eval_loss: 3.77987e-04
I0404 18:55:08.862136 23443585951552 run_lib.py:140] step: 21250, training_loss: 3.92349e-04
I0404 18:55:30.640536 23443585951552 run_lib.py:140] step: 21300, training_loss: 4.16181e-04
I0404 18:55:30.802296 23443585951552 run_lib.py:153] step: 21300, eval_loss: 3.94432e-04
I0404 18:55:52.279886 23443585951552 run_lib.py:140] step: 21350, training_loss: 4.08824e-04
I0404 18:56:14.159555 23443585951552 run_lib.py:140] step: 21400, training_loss: 3.80688e-04
I0404 18:56:14.322566 23443585951552 run_lib.py:153] step: 21400, eval_loss: 4.02620e-04
I0404 18:56:36.263943 23443585951552 run_lib.py:140] step: 21450, training_loss: 3.52364e-04
I0404 18:56:57.999397 23443585951552 run_lib.py:140] step: 21500, training_loss: 4.19060e-04
I0404 18:56:58.161749 23443585951552 run_lib.py:153] step: 21500, eval_loss: 3.59047e-04
I0404 18:57:19.634385 23443585951552 run_lib.py:140] step: 21550, training_loss: 4.13822e-04
I0404 18:57:41.661596 23443585951552 run_lib.py:140] step: 21600, training_loss: 3.80280e-04
I0404 18:57:41.824578 23443585951552 run_lib.py:153] step: 21600, eval_loss: 3.94739e-04
I0404 18:58:03.494726 23443585951552 run_lib.py:140] step: 21650, training_loss: 3.87275e-04
I0404 18:58:25.170749 23443585951552 run_lib.py:140] step: 21700, training_loss: 4.81293e-04
I0404 18:58:25.326488 23443585951552 run_lib.py:153] step: 21700, eval_loss: 4.23497e-04
I0404 18:58:47.356683 23443585951552 run_lib.py:140] step: 21750, training_loss: 4.33854e-04
I0404 18:59:09.420802 23443585951552 run_lib.py:140] step: 21800, training_loss: 3.93166e-04
I0404 18:59:09.596096 23443585951552 run_lib.py:153] step: 21800, eval_loss: 4.19103e-04
I0404 18:59:31.469335 23443585951552 run_lib.py:140] step: 21850, training_loss: 4.13817e-04
I0404 18:59:53.193318 23443585951552 run_lib.py:140] step: 21900, training_loss: 3.75822e-04
I0404 18:59:53.355609 23443585951552 run_lib.py:153] step: 21900, eval_loss: 4.41926e-04
I0404 19:00:15.106426 23443585951552 run_lib.py:140] step: 21950, training_loss: 4.00664e-04
I0404 19:00:36.832568 23443585951552 run_lib.py:140] step: 22000, training_loss: 3.88209e-04
I0404 19:00:36.994483 23443585951552 run_lib.py:153] step: 22000, eval_loss: 4.10669e-04
I0404 19:00:58.692361 23443585951552 run_lib.py:140] step: 22050, training_loss: 3.75064e-04
I0404 19:01:20.303119 23443585951552 run_lib.py:140] step: 22100, training_loss: 3.74962e-04
I0404 19:01:20.457523 23443585951552 run_lib.py:153] step: 22100, eval_loss: 4.36212e-04
I0404 19:01:42.507908 23443585951552 run_lib.py:140] step: 22150, training_loss: 4.57978e-04
I0404 19:02:04.143469 23443585951552 run_lib.py:140] step: 22200, training_loss: 4.34125e-04
I0404 19:02:04.301225 23443585951552 run_lib.py:153] step: 22200, eval_loss: 4.28705e-04
I0404 19:02:25.935707 23443585951552 run_lib.py:140] step: 22250, training_loss: 4.12637e-04
I0404 19:02:47.749640 23443585951552 run_lib.py:140] step: 22300, training_loss: 4.35083e-04
I0404 19:02:47.907169 23443585951552 run_lib.py:153] step: 22300, eval_loss: 4.47239e-04
I0404 19:03:09.653769 23443585951552 run_lib.py:140] step: 22350, training_loss: 3.91579e-04
I0404 19:03:31.064656 23443585951552 run_lib.py:140] step: 22400, training_loss: 4.01478e-04
I0404 19:03:31.217633 23443585951552 run_lib.py:153] step: 22400, eval_loss: 4.33710e-04
I0404 19:03:53.064390 23443585951552 run_lib.py:140] step: 22450, training_loss: 3.61694e-04
I0404 19:04:15.254801 23443585951552 run_lib.py:140] step: 22500, training_loss: 3.68921e-04
I0404 19:04:15.409089 23443585951552 run_lib.py:153] step: 22500, eval_loss: 4.14179e-04
I0404 19:04:37.640533 23443585951552 run_lib.py:140] step: 22550, training_loss: 3.68583e-04
I0404 19:04:59.328333 23443585951552 run_lib.py:140] step: 22600, training_loss: 4.58998e-04
I0404 19:04:59.488072 23443585951552 run_lib.py:153] step: 22600, eval_loss: 3.84165e-04
I0404 19:05:21.378288 23443585951552 run_lib.py:140] step: 22650, training_loss: 4.65210e-04
I0404 19:05:42.457288 23443585951552 run_lib.py:140] step: 22700, training_loss: 3.68637e-04
I0404 19:05:42.633133 23443585951552 run_lib.py:153] step: 22700, eval_loss: 4.02718e-04
I0404 19:06:04.179720 23443585951552 run_lib.py:140] step: 22750, training_loss: 3.68062e-04
I0404 19:06:25.646826 23443585951552 run_lib.py:140] step: 22800, training_loss: 3.49488e-04
I0404 19:06:25.810478 23443585951552 run_lib.py:153] step: 22800, eval_loss: 3.86303e-04
I0404 19:06:47.571251 23443585951552 run_lib.py:140] step: 22850, training_loss: 3.96207e-04
I0404 19:07:09.319017 23443585951552 run_lib.py:140] step: 22900, training_loss: 3.96751e-04
I0404 19:07:09.475142 23443585951552 run_lib.py:153] step: 22900, eval_loss: 4.00920e-04
I0404 19:07:31.329596 23443585951552 run_lib.py:140] step: 22950, training_loss: 3.27214e-04
I0404 19:07:49.367454 23443585951552 run_lib.py:140] step: 23000, training_loss: 3.70602e-04
I0404 19:07:49.527358 23443585951552 run_lib.py:153] step: 23000, eval_loss: 4.46958e-04
I0404 19:08:06.992001 23443585951552 run_lib.py:140] step: 23050, training_loss: 3.82189e-04
I0404 19:08:24.399977 23443585951552 run_lib.py:140] step: 23100, training_loss: 4.57685e-04
I0404 19:08:24.558718 23443585951552 run_lib.py:153] step: 23100, eval_loss: 3.61576e-04
I0404 19:08:42.119218 23443585951552 run_lib.py:140] step: 23150, training_loss: 3.92812e-04
I0404 19:08:59.652745 23443585951552 run_lib.py:140] step: 23200, training_loss: 4.21945e-04
I0404 19:08:59.828758 23443585951552 run_lib.py:153] step: 23200, eval_loss: 3.64348e-04
I0404 19:09:17.294947 23443585951552 run_lib.py:140] step: 23250, training_loss: 3.66154e-04
I0404 19:09:34.993549 23443585951552 run_lib.py:140] step: 23300, training_loss: 3.88468e-04
I0404 19:09:35.145207 23443585951552 run_lib.py:153] step: 23300, eval_loss: 4.03848e-04
I0404 19:09:52.613433 23443585951552 run_lib.py:140] step: 23350, training_loss: 4.19805e-04
I0404 19:10:10.043993 23443585951552 run_lib.py:140] step: 23400, training_loss: 3.77471e-04
I0404 19:10:10.197842 23443585951552 run_lib.py:153] step: 23400, eval_loss: 3.88859e-04
I0404 19:10:27.737893 23443585951552 run_lib.py:140] step: 23450, training_loss: 3.09009e-04
I0404 19:10:45.217996 23443585951552 run_lib.py:140] step: 23500, training_loss: 4.08164e-04
I0404 19:10:45.373137 23443585951552 run_lib.py:153] step: 23500, eval_loss: 3.54261e-04
I0404 19:11:02.841977 23443585951552 run_lib.py:140] step: 23550, training_loss: 3.84900e-04
I0404 19:11:20.329562 23443585951552 run_lib.py:140] step: 23600, training_loss: 4.04056e-04
I0404 19:11:20.488009 23443585951552 run_lib.py:153] step: 23600, eval_loss: 4.19867e-04
I0404 19:11:38.101819 23443585951552 run_lib.py:140] step: 23650, training_loss: 4.08444e-04
I0404 19:11:55.627935 23443585951552 run_lib.py:140] step: 23700, training_loss: 4.40041e-04
I0404 19:11:55.802832 23443585951552 run_lib.py:153] step: 23700, eval_loss: 4.91019e-04
I0404 19:12:13.300069 23443585951552 run_lib.py:140] step: 23750, training_loss: 3.48663e-04
I0404 19:12:30.766930 23443585951552 run_lib.py:140] step: 23800, training_loss: 4.00521e-04
I0404 19:12:30.922177 23443585951552 run_lib.py:153] step: 23800, eval_loss: 3.65517e-04
I0404 19:12:48.554425 23443585951552 run_lib.py:140] step: 23850, training_loss: 4.53239e-04
I0404 19:13:05.970373 23443585951552 run_lib.py:140] step: 23900, training_loss: 4.50729e-04
I0404 19:13:06.122864 23443585951552 run_lib.py:153] step: 23900, eval_loss: 3.90537e-04
I0404 19:13:23.520029 23443585951552 run_lib.py:140] step: 23950, training_loss: 3.50353e-04
I0404 19:13:41.193293 23443585951552 run_lib.py:140] step: 24000, training_loss: 4.29154e-04
I0404 19:13:41.356089 23443585951552 run_lib.py:153] step: 24000, eval_loss: 3.70860e-04
I0404 19:13:58.805147 23443585951552 run_lib.py:140] step: 24050, training_loss: 4.22016e-04
I0404 19:14:16.486095 23443585951552 run_lib.py:140] step: 24100, training_loss: 4.24287e-04
I0404 19:14:16.644075 23443585951552 run_lib.py:153] step: 24100, eval_loss: 4.01375e-04
I0404 19:14:37.526958 23443585951552 run_lib.py:140] step: 24150, training_loss: 4.53980e-04
I0404 19:14:59.305520 23443585951552 run_lib.py:140] step: 24200, training_loss: 3.96145e-04
I0404 19:14:59.462872 23443585951552 run_lib.py:153] step: 24200, eval_loss: 3.78089e-04
I0404 19:15:20.742890 23443585951552 run_lib.py:140] step: 24250, training_loss: 4.24720e-04
I0404 19:15:42.100459 23443585951552 run_lib.py:140] step: 24300, training_loss: 4.38373e-04
I0404 19:15:42.256581 23443585951552 run_lib.py:153] step: 24300, eval_loss: 3.89894e-04
I0404 19:16:03.486253 23443585951552 run_lib.py:140] step: 24350, training_loss: 3.94689e-04
I0404 19:16:25.223462 23443585951552 run_lib.py:140] step: 24400, training_loss: 3.41508e-04
I0404 19:16:25.375975 23443585951552 run_lib.py:153] step: 24400, eval_loss: 3.99830e-04
I0404 19:16:47.019029 23443585951552 run_lib.py:140] step: 24450, training_loss: 3.76153e-04
I0404 19:17:08.763506 23443585951552 run_lib.py:140] step: 24500, training_loss: 4.21420e-04
I0404 19:17:08.925693 23443585951552 run_lib.py:153] step: 24500, eval_loss: 4.22297e-04
I0404 19:17:30.535409 23443585951552 run_lib.py:140] step: 24550, training_loss: 4.16375e-04
I0404 19:17:52.274711 23443585951552 run_lib.py:140] step: 24600, training_loss: 4.03453e-04
I0404 19:17:52.432965 23443585951552 run_lib.py:153] step: 24600, eval_loss: 3.82054e-04
I0404 19:18:14.193140 23443585951552 run_lib.py:140] step: 24650, training_loss: 3.92127e-04
I0404 19:18:35.929997 23443585951552 run_lib.py:140] step: 24700, training_loss: 3.89643e-04
I0404 19:18:36.087470 23443585951552 run_lib.py:153] step: 24700, eval_loss: 3.77906e-04
I0404 19:18:57.648448 23443585951552 run_lib.py:140] step: 24750, training_loss: 3.89500e-04
I0404 19:19:19.243175 23443585951552 run_lib.py:140] step: 24800, training_loss: 4.25471e-04
I0404 19:19:19.399757 23443585951552 run_lib.py:153] step: 24800, eval_loss: 4.10636e-04
I0404 19:19:40.806042 23443585951552 run_lib.py:140] step: 24850, training_loss: 4.34179e-04
I0404 19:20:02.418857 23443585951552 run_lib.py:140] step: 24900, training_loss: 4.91082e-04
I0404 19:20:02.574496 23443585951552 run_lib.py:153] step: 24900, eval_loss: 4.33844e-04
I0404 19:20:24.472917 23443585951552 run_lib.py:140] step: 24950, training_loss: 4.84995e-04
I0404 19:20:46.186475 23443585951552 run_lib.py:140] step: 25000, training_loss: 4.28510e-04
I0404 19:20:46.342122 23443585951552 run_lib.py:153] step: 25000, eval_loss: 4.22383e-04
I0404 19:21:07.763336 23443585951552 run_lib.py:140] step: 25050, training_loss: 4.77912e-04
I0404 19:21:29.484800 23443585951552 run_lib.py:140] step: 25100, training_loss: 3.72692e-04
I0404 19:21:29.663276 23443585951552 run_lib.py:153] step: 25100, eval_loss: 4.64654e-04
I0404 19:21:51.187142 23443585951552 run_lib.py:140] step: 25150, training_loss: 3.96426e-04
I0404 19:22:12.996310 23443585951552 run_lib.py:140] step: 25200, training_loss: 4.27889e-04
I0404 19:22:13.154372 23443585951552 run_lib.py:153] step: 25200, eval_loss: 3.65944e-04
I0404 19:22:34.739520 23443585951552 run_lib.py:140] step: 25250, training_loss: 3.75843e-04
I0404 19:22:56.211108 23443585951552 run_lib.py:140] step: 25300, training_loss: 4.00514e-04
I0404 19:22:56.367786 23443585951552 run_lib.py:153] step: 25300, eval_loss: 4.06123e-04
I0404 19:23:17.945406 23443585951552 run_lib.py:140] step: 25350, training_loss: 4.26368e-04
I0404 19:23:39.398292 23443585951552 run_lib.py:140] step: 25400, training_loss: 3.87635e-04
I0404 19:23:39.555660 23443585951552 run_lib.py:153] step: 25400, eval_loss: 4.48870e-04
I0404 19:24:00.888224 23443585951552 run_lib.py:140] step: 25450, training_loss: 4.30187e-04
I0404 19:24:22.450075 23443585951552 run_lib.py:140] step: 25500, training_loss: 3.90702e-04
I0404 19:24:22.620656 23443585951552 run_lib.py:153] step: 25500, eval_loss: 4.19208e-04
I0404 19:24:44.308849 23443585951552 run_lib.py:140] step: 25550, training_loss: 3.32697e-04
I0404 19:25:05.491498 23443585951552 run_lib.py:140] step: 25600, training_loss: 4.37548e-04
I0404 19:25:05.651857 23443585951552 run_lib.py:153] step: 25600, eval_loss: 3.71929e-04
I0404 19:25:27.100850 23443585951552 run_lib.py:140] step: 25650, training_loss: 4.04658e-04
I0404 19:25:48.785309 23443585951552 run_lib.py:140] step: 25700, training_loss: 4.27057e-04
I0404 19:25:48.954233 23443585951552 run_lib.py:153] step: 25700, eval_loss: 4.34192e-04
I0404 19:26:10.454961 23443585951552 run_lib.py:140] step: 25750, training_loss: 4.36515e-04
I0404 19:26:31.795675 23443585951552 run_lib.py:140] step: 25800, training_loss: 3.89538e-04
I0404 19:26:31.955138 23443585951552 run_lib.py:153] step: 25800, eval_loss: 4.08212e-04
I0404 19:26:53.766269 23443585951552 run_lib.py:140] step: 25850, training_loss: 4.08026e-04
I0404 19:27:15.446151 23443585951552 run_lib.py:140] step: 25900, training_loss: 4.29021e-04
I0404 19:27:15.602241 23443585951552 run_lib.py:153] step: 25900, eval_loss: 3.72457e-04
I0404 19:27:37.105210 23443585951552 run_lib.py:140] step: 25950, training_loss: 4.07184e-04
I0404 19:27:58.771728 23443585951552 run_lib.py:140] step: 26000, training_loss: 4.22458e-04
I0404 19:27:58.934599 23443585951552 run_lib.py:153] step: 26000, eval_loss: 4.47926e-04
I0404 19:28:20.645146 23443585951552 run_lib.py:140] step: 26050, training_loss: 3.93274e-04
I0404 19:28:42.204849 23443585951552 run_lib.py:140] step: 26100, training_loss: 3.81607e-04
I0404 19:28:42.366193 23443585951552 run_lib.py:153] step: 26100, eval_loss: 3.79128e-04
I0404 19:29:04.131854 23443585951552 run_lib.py:140] step: 26150, training_loss: 3.82755e-04
I0404 19:29:26.149763 23443585951552 run_lib.py:140] step: 26200, training_loss: 3.90288e-04
I0404 19:29:26.304735 23443585951552 run_lib.py:153] step: 26200, eval_loss: 4.09547e-04
I0404 19:29:47.747437 23443585951552 run_lib.py:140] step: 26250, training_loss: 4.00519e-04
I0404 19:30:09.490814 23443585951552 run_lib.py:140] step: 26300, training_loss: 3.76837e-04
I0404 19:30:09.644323 23443585951552 run_lib.py:153] step: 26300, eval_loss: 3.93413e-04
I0404 19:30:31.312250 23443585951552 run_lib.py:140] step: 26350, training_loss: 4.56034e-04
I0404 19:30:53.191620 23443585951552 run_lib.py:140] step: 26400, training_loss: 3.93747e-04
I0404 19:30:53.357197 23443585951552 run_lib.py:153] step: 26400, eval_loss: 4.07749e-04
I0404 19:31:15.101031 23443585951552 run_lib.py:140] step: 26450, training_loss: 4.26601e-04
I0404 19:31:36.811324 23443585951552 run_lib.py:140] step: 26500, training_loss: 3.84665e-04
I0404 19:31:36.979194 23443585951552 run_lib.py:153] step: 26500, eval_loss: 4.08507e-04
I0404 19:31:58.306767 23443585951552 run_lib.py:140] step: 26550, training_loss: 4.46085e-04
I0404 19:32:20.375245 23443585951552 run_lib.py:140] step: 26600, training_loss: 3.78805e-04
I0404 19:32:20.534374 23443585951552 run_lib.py:153] step: 26600, eval_loss: 3.86916e-04
I0404 19:32:42.194183 23443585951552 run_lib.py:140] step: 26650, training_loss: 4.56362e-04
I0404 19:33:03.955896 23443585951552 run_lib.py:140] step: 26700, training_loss: 4.53561e-04
I0404 19:33:04.111104 23443585951552 run_lib.py:153] step: 26700, eval_loss: 3.38257e-04
I0404 19:33:25.902781 23443585951552 run_lib.py:140] step: 26750, training_loss: 3.83083e-04
I0404 19:33:47.308979 23443585951552 run_lib.py:140] step: 26800, training_loss: 4.21834e-04
I0404 19:33:47.465399 23443585951552 run_lib.py:153] step: 26800, eval_loss: 3.96687e-04
I0404 19:34:09.355958 23443585951552 run_lib.py:140] step: 26850, training_loss: 3.96782e-04
I0404 19:34:30.952131 23443585951552 run_lib.py:140] step: 26900, training_loss: 4.51112e-04
I0404 19:34:31.118383 23443585951552 run_lib.py:153] step: 26900, eval_loss: 3.50119e-04
I0404 19:34:52.773786 23443585951552 run_lib.py:140] step: 26950, training_loss: 4.36926e-04
I0404 19:35:14.164358 23443585951552 run_lib.py:140] step: 27000, training_loss: 4.41784e-04
I0404 19:35:14.346962 23443585951552 run_lib.py:153] step: 27000, eval_loss: 4.33808e-04
I0404 19:35:36.132143 23443585951552 run_lib.py:140] step: 27050, training_loss: 3.74137e-04
I0404 19:35:57.663273 23443585951552 run_lib.py:140] step: 27100, training_loss: 4.71409e-04
I0404 19:35:57.821773 23443585951552 run_lib.py:153] step: 27100, eval_loss: 3.92485e-04
I0404 19:36:19.840103 23443585951552 run_lib.py:140] step: 27150, training_loss: 4.04899e-04
I0404 19:36:41.407633 23443585951552 run_lib.py:140] step: 27200, training_loss: 3.85163e-04
I0404 19:36:41.563086 23443585951552 run_lib.py:153] step: 27200, eval_loss: 4.34946e-04
I0404 19:37:03.258130 23443585951552 run_lib.py:140] step: 27250, training_loss: 3.88078e-04
I0404 19:37:24.732374 23443585951552 run_lib.py:140] step: 27300, training_loss: 3.92448e-04
I0404 19:37:24.892222 23443585951552 run_lib.py:153] step: 27300, eval_loss: 4.42543e-04
I0404 19:37:46.808312 23443585951552 run_lib.py:140] step: 27350, training_loss: 4.20139e-04
I0404 19:38:08.832079 23443585951552 run_lib.py:140] step: 27400, training_loss: 3.90414e-04
I0404 19:38:08.989195 23443585951552 run_lib.py:153] step: 27400, eval_loss: 3.83597e-04
I0404 19:38:30.565014 23443585951552 run_lib.py:140] step: 27450, training_loss: 3.57511e-04
I0404 19:38:52.251789 23443585951552 run_lib.py:140] step: 27500, training_loss: 3.74219e-04
I0404 19:38:52.411052 23443585951552 run_lib.py:153] step: 27500, eval_loss: 3.49668e-04
I0404 19:39:14.028793 23443585951552 run_lib.py:140] step: 27550, training_loss: 4.06513e-04
I0404 19:39:35.330138 23443585951552 run_lib.py:140] step: 27600, training_loss: 4.31948e-04
I0404 19:39:35.489799 23443585951552 run_lib.py:153] step: 27600, eval_loss: 4.11405e-04
I0404 19:39:57.245049 23443585951552 run_lib.py:140] step: 27650, training_loss: 4.31563e-04
I0404 19:40:18.831622 23443585951552 run_lib.py:140] step: 27700, training_loss: 3.68325e-04
I0404 19:40:18.988803 23443585951552 run_lib.py:153] step: 27700, eval_loss: 4.61329e-04
I0404 19:40:40.385148 23443585951552 run_lib.py:140] step: 27750, training_loss: 3.93783e-04
I0404 19:41:01.773044 23443585951552 run_lib.py:140] step: 27800, training_loss: 3.72804e-04
I0404 19:41:01.928127 23443585951552 run_lib.py:153] step: 27800, eval_loss: 4.03290e-04
I0404 19:41:23.515005 23443585951552 run_lib.py:140] step: 27850, training_loss: 4.32839e-04
I0404 19:41:45.113934 23443585951552 run_lib.py:140] step: 27900, training_loss: 4.18572e-04
I0404 19:41:45.291260 23443585951552 run_lib.py:153] step: 27900, eval_loss: 4.17566e-04
I0404 19:42:06.842353 23443585951552 run_lib.py:140] step: 27950, training_loss: 3.59702e-04
I0404 19:42:28.334369 23443585951552 run_lib.py:140] step: 28000, training_loss: 4.29577e-04
I0404 19:42:28.492568 23443585951552 run_lib.py:153] step: 28000, eval_loss: 4.06011e-04
I0404 19:42:50.324827 23443585951552 run_lib.py:140] step: 28050, training_loss: 3.97717e-04
I0404 19:43:11.954739 23443585951552 run_lib.py:140] step: 28100, training_loss: 4.18517e-04
I0404 19:43:12.107027 23443585951552 run_lib.py:153] step: 28100, eval_loss: 3.63571e-04
I0404 19:43:33.785698 23443585951552 run_lib.py:140] step: 28150, training_loss: 4.20465e-04
I0404 19:43:55.320231 23443585951552 run_lib.py:140] step: 28200, training_loss: 4.41703e-04
I0404 19:43:55.473869 23443585951552 run_lib.py:153] step: 28200, eval_loss: 4.26892e-04
I0404 19:44:17.252541 23443585951552 run_lib.py:140] step: 28250, training_loss: 4.23155e-04
I0404 19:44:38.957238 23443585951552 run_lib.py:140] step: 28300, training_loss: 4.19316e-04
I0404 19:44:39.114214 23443585951552 run_lib.py:153] step: 28300, eval_loss: 4.18810e-04
I0404 19:45:00.789019 23443585951552 run_lib.py:140] step: 28350, training_loss: 4.08934e-04
I0404 19:45:22.696849 23443585951552 run_lib.py:140] step: 28400, training_loss: 3.73191e-04
I0404 19:45:22.855853 23443585951552 run_lib.py:153] step: 28400, eval_loss: 4.13862e-04
I0404 19:45:44.520532 23443585951552 run_lib.py:140] step: 28450, training_loss: 3.39262e-04
I0404 19:46:06.563997 23443585951552 run_lib.py:140] step: 28500, training_loss: 4.18622e-04
I0404 19:46:06.719335 23443585951552 run_lib.py:153] step: 28500, eval_loss: 4.05841e-04
I0404 19:46:28.082545 23443585951552 run_lib.py:140] step: 28550, training_loss: 4.11309e-04
I0404 19:46:49.695352 23443585951552 run_lib.py:140] step: 28600, training_loss: 4.93933e-04
I0404 19:46:49.851514 23443585951552 run_lib.py:153] step: 28600, eval_loss: 4.30440e-04
I0404 19:47:12.000520 23443585951552 run_lib.py:140] step: 28650, training_loss: 4.29259e-04
I0404 19:47:33.125540 23443585951552 run_lib.py:140] step: 28700, training_loss: 3.46369e-04
I0404 19:47:33.278208 23443585951552 run_lib.py:153] step: 28700, eval_loss: 4.45684e-04
I0404 19:47:54.749401 23443585951552 run_lib.py:140] step: 28750, training_loss: 4.07795e-04
I0404 19:48:16.777427 23443585951552 run_lib.py:140] step: 28800, training_loss: 3.79932e-04
I0404 19:48:16.948262 23443585951552 run_lib.py:153] step: 28800, eval_loss: 4.64302e-04
I0404 19:48:38.477586 23443585951552 run_lib.py:140] step: 28850, training_loss: 4.09454e-04
I0404 19:49:00.332222 23443585951552 run_lib.py:140] step: 28900, training_loss: 3.65665e-04
I0404 19:49:00.489144 23443585951552 run_lib.py:153] step: 28900, eval_loss: 3.60778e-04
I0404 19:49:22.305315 23443585951552 run_lib.py:140] step: 28950, training_loss: 4.52147e-04
I0404 19:49:43.823021 23443585951552 run_lib.py:140] step: 29000, training_loss: 4.22022e-04
I0404 19:49:43.992574 23443585951552 run_lib.py:153] step: 29000, eval_loss: 4.23125e-04
I0404 19:50:05.513414 23443585951552 run_lib.py:140] step: 29050, training_loss: 4.27064e-04
I0404 19:50:26.940972 23443585951552 run_lib.py:140] step: 29100, training_loss: 4.03470e-04
I0404 19:50:27.093927 23443585951552 run_lib.py:153] step: 29100, eval_loss: 4.30048e-04
I0404 19:50:48.222183 23443585951552 run_lib.py:140] step: 29150, training_loss: 4.23732e-04
I0404 19:51:09.554678 23443585951552 run_lib.py:140] step: 29200, training_loss: 3.84997e-04
I0404 19:51:09.707120 23443585951552 run_lib.py:153] step: 29200, eval_loss: 4.13758e-04
I0404 19:51:30.956950 23443585951552 run_lib.py:140] step: 29250, training_loss: 4.54443e-04
I0404 19:51:52.129399 23443585951552 run_lib.py:140] step: 29300, training_loss: 3.88029e-04
I0404 19:51:52.302563 23443585951552 run_lib.py:153] step: 29300, eval_loss: 3.81118e-04
I0404 19:52:13.803831 23443585951552 run_lib.py:140] step: 29350, training_loss: 4.08378e-04
I0404 19:52:34.967889 23443585951552 run_lib.py:140] step: 29400, training_loss: 4.34038e-04
I0404 19:52:35.124076 23443585951552 run_lib.py:153] step: 29400, eval_loss: 5.08534e-04
I0404 19:52:56.542009 23443585951552 run_lib.py:140] step: 29450, training_loss: 3.56261e-04
I0404 19:53:18.031322 23443585951552 run_lib.py:140] step: 29500, training_loss: 3.96202e-04
I0404 19:53:18.196931 23443585951552 run_lib.py:153] step: 29500, eval_loss: 4.06785e-04
I0404 19:53:39.553141 23443585951552 run_lib.py:140] step: 29550, training_loss: 3.49725e-04
I0404 19:54:00.617988 23443585951552 run_lib.py:140] step: 29600, training_loss: 3.59996e-04
I0404 19:54:00.774651 23443585951552 run_lib.py:153] step: 29600, eval_loss: 4.74530e-04
I0404 19:54:21.660493 23443585951552 run_lib.py:140] step: 29650, training_loss: 3.47351e-04
I0404 19:54:42.604807 23443585951552 run_lib.py:140] step: 29700, training_loss: 4.07156e-04
I0404 19:54:42.758892 23443585951552 run_lib.py:153] step: 29700, eval_loss: 4.08735e-04
I0404 19:55:03.742429 23443585951552 run_lib.py:140] step: 29750, training_loss: 4.21092e-04
I0404 19:55:25.034924 23443585951552 run_lib.py:140] step: 29800, training_loss: 4.12221e-04
I0404 19:55:25.200011 23443585951552 run_lib.py:153] step: 29800, eval_loss: 3.83249e-04
I0404 19:55:46.141694 23443585951552 run_lib.py:140] step: 29850, training_loss: 4.81303e-04
I0404 19:56:07.415797 23443585951552 run_lib.py:140] step: 29900, training_loss: 3.32561e-04
I0404 19:56:07.571272 23443585951552 run_lib.py:153] step: 29900, eval_loss: 4.05534e-04
I0404 19:56:28.670522 23443585951552 run_lib.py:140] step: 29950, training_loss: 3.76969e-04
I0404 19:56:49.409698 23443585951552 run_lib.py:140] step: 30000, training_loss: 4.17612e-04
I0404 19:56:50.457965 23443585951552 run_lib.py:153] step: 30000, eval_loss: 4.08802e-04
I0404 19:57:12.167737 23443585951552 run_lib.py:140] step: 30050, training_loss: 4.14365e-04
I0404 19:57:33.175212 23443585951552 run_lib.py:140] step: 30100, training_loss: 3.60302e-04
I0404 19:57:33.327535 23443585951552 run_lib.py:153] step: 30100, eval_loss: 4.64256e-04
I0404 19:57:54.289380 23443585951552 run_lib.py:140] step: 30150, training_loss: 3.90835e-04
I0404 19:58:15.475567 23443585951552 run_lib.py:140] step: 30200, training_loss: 3.57587e-04
I0404 19:58:15.641175 23443585951552 run_lib.py:153] step: 30200, eval_loss: 4.05814e-04
I0404 19:58:37.317439 23443585951552 run_lib.py:140] step: 30250, training_loss: 4.31395e-04
I0404 19:58:58.547255 23443585951552 run_lib.py:140] step: 30300, training_loss: 3.60593e-04
I0404 19:58:58.705412 23443585951552 run_lib.py:153] step: 30300, eval_loss: 3.99601e-04
I0404 19:59:19.668540 23443585951552 run_lib.py:140] step: 30350, training_loss: 3.60429e-04
I0404 19:59:40.453507 23443585951552 run_lib.py:140] step: 30400, training_loss: 4.02746e-04
I0404 19:59:40.614804 23443585951552 run_lib.py:153] step: 30400, eval_loss: 3.94799e-04
I0404 20:00:01.804330 23443585951552 run_lib.py:140] step: 30450, training_loss: 4.19424e-04
I0404 20:00:22.849653 23443585951552 run_lib.py:140] step: 30500, training_loss: 3.92154e-04
I0404 20:00:23.012321 23443585951552 run_lib.py:153] step: 30500, eval_loss: 4.06990e-04
I0404 20:00:44.145112 23443585951552 run_lib.py:140] step: 30550, training_loss: 4.77629e-04
I0404 20:01:05.384192 23443585951552 run_lib.py:140] step: 30600, training_loss: 4.65015e-04
I0404 20:01:05.534718 23443585951552 run_lib.py:153] step: 30600, eval_loss: 4.70939e-04
I0404 20:01:26.288484 23443585951552 run_lib.py:140] step: 30650, training_loss: 4.00009e-04
I0404 20:01:47.508095 23443585951552 run_lib.py:140] step: 30700, training_loss: 4.10464e-04
I0404 20:01:47.676376 23443585951552 run_lib.py:153] step: 30700, eval_loss: 3.96270e-04
I0404 20:02:08.802030 23443585951552 run_lib.py:140] step: 30750, training_loss: 4.01576e-04
I0404 20:02:29.813104 23443585951552 run_lib.py:140] step: 30800, training_loss: 4.06445e-04
I0404 20:02:29.970465 23443585951552 run_lib.py:153] step: 30800, eval_loss: 4.10307e-04
I0404 20:02:50.922345 23443585951552 run_lib.py:140] step: 30850, training_loss: 3.36882e-04
I0404 20:03:11.995009 23443585951552 run_lib.py:140] step: 30900, training_loss: 3.94607e-04
I0404 20:03:12.168281 23443585951552 run_lib.py:153] step: 30900, eval_loss: 4.06196e-04
I0404 20:03:33.519492 23443585951552 run_lib.py:140] step: 30950, training_loss: 3.48006e-04
I0404 20:03:54.923062 23443585951552 run_lib.py:140] step: 31000, training_loss: 4.02313e-04
I0404 20:03:55.076301 23443585951552 run_lib.py:153] step: 31000, eval_loss: 4.31241e-04
I0404 20:04:16.264421 23443585951552 run_lib.py:140] step: 31050, training_loss: 4.21203e-04
I0404 20:04:37.215047 23443585951552 run_lib.py:140] step: 31100, training_loss: 3.66137e-04
I0404 20:04:37.373782 23443585951552 run_lib.py:153] step: 31100, eval_loss: 3.72126e-04
I0404 20:04:58.537858 23443585951552 run_lib.py:140] step: 31150, training_loss: 4.20256e-04
I0404 20:05:19.735899 23443585951552 run_lib.py:140] step: 31200, training_loss: 4.05620e-04
I0404 20:05:19.895043 23443585951552 run_lib.py:153] step: 31200, eval_loss: 4.21364e-04
I0404 20:05:40.596750 23443585951552 run_lib.py:140] step: 31250, training_loss: 4.30844e-04
I0404 20:06:01.616088 23443585951552 run_lib.py:140] step: 31300, training_loss: 4.06977e-04
I0404 20:06:01.777282 23443585951552 run_lib.py:153] step: 31300, eval_loss: 4.24464e-04
I0404 20:06:23.226304 23443585951552 run_lib.py:140] step: 31350, training_loss: 3.85860e-04
I0404 20:06:44.499041 23443585951552 run_lib.py:140] step: 31400, training_loss: 3.36641e-04
I0404 20:06:44.656961 23443585951552 run_lib.py:153] step: 31400, eval_loss: 3.52995e-04
I0404 20:07:05.835125 23443585951552 run_lib.py:140] step: 31450, training_loss: 3.90074e-04
I0404 20:07:26.878245 23443585951552 run_lib.py:140] step: 31500, training_loss: 4.32992e-04
I0404 20:07:27.033537 23443585951552 run_lib.py:153] step: 31500, eval_loss: 3.63928e-04
I0404 20:07:48.330651 23443585951552 run_lib.py:140] step: 31550, training_loss: 3.74153e-04
I0404 20:08:09.477834 23443585951552 run_lib.py:140] step: 31600, training_loss: 4.18371e-04
I0404 20:08:09.634446 23443585951552 run_lib.py:153] step: 31600, eval_loss: 3.92350e-04
I0404 20:08:31.080476 23443585951552 run_lib.py:140] step: 31650, training_loss: 4.17695e-04
I0404 20:08:52.071141 23443585951552 run_lib.py:140] step: 31700, training_loss: 3.89259e-04
I0404 20:08:52.231909 23443585951552 run_lib.py:153] step: 31700, eval_loss: 3.51602e-04
I0404 20:09:13.534543 23443585951552 run_lib.py:140] step: 31750, training_loss: 3.99359e-04
I0404 20:09:34.921697 23443585951552 run_lib.py:140] step: 31800, training_loss: 4.18443e-04
I0404 20:09:35.078128 23443585951552 run_lib.py:153] step: 31800, eval_loss: 3.86272e-04
I0404 20:09:56.241149 23443585951552 run_lib.py:140] step: 31850, training_loss: 4.32402e-04
I0404 20:10:17.483813 23443585951552 run_lib.py:140] step: 31900, training_loss: 4.22534e-04
I0404 20:10:17.639805 23443585951552 run_lib.py:153] step: 31900, eval_loss: 4.01831e-04
I0404 20:10:39.164532 23443585951552 run_lib.py:140] step: 31950, training_loss: 4.01017e-04
I0404 20:11:00.574111 23443585951552 run_lib.py:140] step: 32000, training_loss: 4.65963e-04
I0404 20:11:00.726970 23443585951552 run_lib.py:153] step: 32000, eval_loss: 4.39402e-04
I0404 20:11:21.643693 23443585951552 run_lib.py:140] step: 32050, training_loss: 3.82162e-04
I0404 20:11:42.863081 23443585951552 run_lib.py:140] step: 32100, training_loss: 3.73880e-04
I0404 20:11:43.032264 23443585951552 run_lib.py:153] step: 32100, eval_loss: 4.58424e-04
I0404 20:12:04.323594 23443585951552 run_lib.py:140] step: 32150, training_loss: 3.78318e-04
I0404 20:12:25.388748 23443585951552 run_lib.py:140] step: 32200, training_loss: 3.51395e-04
I0404 20:12:25.547546 23443585951552 run_lib.py:153] step: 32200, eval_loss: 3.83229e-04
I0404 20:12:47.139586 23443585951552 run_lib.py:140] step: 32250, training_loss: 3.94610e-04
I0404 20:13:08.260937 23443585951552 run_lib.py:140] step: 32300, training_loss: 3.41546e-04
I0404 20:13:08.428636 23443585951552 run_lib.py:153] step: 32300, eval_loss: 3.94438e-04
I0404 20:13:29.629401 23443585951552 run_lib.py:140] step: 32350, training_loss: 4.10235e-04
I0404 20:13:50.825122 23443585951552 run_lib.py:140] step: 32400, training_loss: 4.19749e-04
I0404 20:13:50.980296 23443585951552 run_lib.py:153] step: 32400, eval_loss: 4.08957e-04
I0404 20:14:12.135978 23443585951552 run_lib.py:140] step: 32450, training_loss: 4.30461e-04
I0404 20:14:33.382187 23443585951552 run_lib.py:140] step: 32500, training_loss: 4.04421e-04
I0404 20:14:33.536320 23443585951552 run_lib.py:153] step: 32500, eval_loss: 3.96840e-04
I0404 20:14:54.559902 23443585951552 run_lib.py:140] step: 32550, training_loss: 3.99967e-04
I0404 20:15:15.801975 23443585951552 run_lib.py:140] step: 32600, training_loss: 4.32727e-04
I0404 20:15:15.970888 23443585951552 run_lib.py:153] step: 32600, eval_loss: 4.05310e-04
I0404 20:15:37.342430 23443585951552 run_lib.py:140] step: 32650, training_loss: 3.80204e-04
I0404 20:15:58.562046 23443585951552 run_lib.py:140] step: 32700, training_loss: 4.66628e-04
I0404 20:15:58.720867 23443585951552 run_lib.py:153] step: 32700, eval_loss: 4.39846e-04
I0404 20:16:20.076540 23443585951552 run_lib.py:140] step: 32750, training_loss: 3.50742e-04
I0404 20:16:41.565028 23443585951552 run_lib.py:140] step: 32800, training_loss: 4.06713e-04
I0404 20:16:41.728118 23443585951552 run_lib.py:153] step: 32800, eval_loss: 4.41362e-04
I0404 20:17:02.966916 23443585951552 run_lib.py:140] step: 32850, training_loss: 4.25091e-04
I0404 20:17:24.417180 23443585951552 run_lib.py:140] step: 32900, training_loss: 3.93806e-04
I0404 20:17:24.573305 23443585951552 run_lib.py:153] step: 32900, eval_loss: 4.00429e-04
I0404 20:17:45.886227 23443585951552 run_lib.py:140] step: 32950, training_loss: 4.24456e-04
I0404 20:18:07.026932 23443585951552 run_lib.py:140] step: 33000, training_loss: 4.54334e-04
I0404 20:18:07.196325 23443585951552 run_lib.py:153] step: 33000, eval_loss: 4.44985e-04
I0404 20:18:28.433723 23443585951552 run_lib.py:140] step: 33050, training_loss: 4.01615e-04
I0404 20:18:49.597841 23443585951552 run_lib.py:140] step: 33100, training_loss: 3.63978e-04
I0404 20:18:49.757355 23443585951552 run_lib.py:153] step: 33100, eval_loss: 3.76981e-04
I0404 20:19:10.555670 23443585951552 run_lib.py:140] step: 33150, training_loss: 3.98070e-04
I0404 20:19:31.928715 23443585951552 run_lib.py:140] step: 33200, training_loss: 4.05331e-04
I0404 20:19:32.084350 23443585951552 run_lib.py:153] step: 33200, eval_loss: 3.98999e-04
I0404 20:19:53.366466 23443585951552 run_lib.py:140] step: 33250, training_loss: 3.93900e-04
I0404 20:20:14.601738 23443585951552 run_lib.py:140] step: 33300, training_loss: 4.25772e-04
I0404 20:20:14.759960 23443585951552 run_lib.py:153] step: 33300, eval_loss: 4.12278e-04
I0404 20:20:36.038485 23443585951552 run_lib.py:140] step: 33350, training_loss: 3.94031e-04
I0404 20:20:57.286359 23443585951552 run_lib.py:140] step: 33400, training_loss: 3.95024e-04
I0404 20:20:57.441715 23443585951552 run_lib.py:153] step: 33400, eval_loss: 3.92380e-04
I0404 20:21:18.683850 23443585951552 run_lib.py:140] step: 33450, training_loss: 4.54524e-04
I0404 20:21:39.820475 23443585951552 run_lib.py:140] step: 33500, training_loss: 3.61037e-04
I0404 20:21:39.982196 23443585951552 run_lib.py:153] step: 33500, eval_loss: 4.14787e-04
I0404 20:22:01.435376 23443585951552 run_lib.py:140] step: 33550, training_loss: 4.33920e-04
I0404 20:22:22.775829 23443585951552 run_lib.py:140] step: 33600, training_loss: 4.02081e-04
I0404 20:22:22.936719 23443585951552 run_lib.py:153] step: 33600, eval_loss: 3.83342e-04
I0404 20:22:44.040119 23443585951552 run_lib.py:140] step: 33650, training_loss: 3.64077e-04
I0404 20:23:04.906214 23443585951552 run_lib.py:140] step: 33700, training_loss: 3.89583e-04
I0404 20:23:05.059871 23443585951552 run_lib.py:153] step: 33700, eval_loss: 4.20920e-04
I0404 20:23:26.407291 23443585951552 run_lib.py:140] step: 33750, training_loss: 4.27223e-04
I0404 20:23:47.549509 23443585951552 run_lib.py:140] step: 33800, training_loss: 4.21700e-04
I0404 20:23:47.708473 23443585951552 run_lib.py:153] step: 33800, eval_loss: 3.78446e-04
I0404 20:24:08.930464 23443585951552 run_lib.py:140] step: 33850, training_loss: 3.69683e-04
I0404 20:24:30.349897 23443585951552 run_lib.py:140] step: 33900, training_loss: 4.63442e-04
I0404 20:24:30.504760 23443585951552 run_lib.py:153] step: 33900, eval_loss: 3.96359e-04
I0404 20:24:51.136078 23443585951552 run_lib.py:140] step: 33950, training_loss: 3.97578e-04
I0404 20:25:12.156819 23443585951552 run_lib.py:140] step: 34000, training_loss: 4.14886e-04
I0404 20:25:12.328148 23443585951552 run_lib.py:153] step: 34000, eval_loss: 3.66589e-04
I0404 20:25:33.409165 23443585951552 run_lib.py:140] step: 34050, training_loss: 3.75287e-04
I0404 20:25:54.397919 23443585951552 run_lib.py:140] step: 34100, training_loss: 4.66380e-04
I0404 20:25:54.556184 23443585951552 run_lib.py:153] step: 34100, eval_loss: 4.19887e-04
I0404 20:26:15.939722 23443585951552 run_lib.py:140] step: 34150, training_loss: 4.22205e-04
I0404 20:26:37.095202 23443585951552 run_lib.py:140] step: 34200, training_loss: 4.11877e-04
I0404 20:26:37.249037 23443585951552 run_lib.py:153] step: 34200, eval_loss: 3.76413e-04
I0404 20:26:58.409523 23443585951552 run_lib.py:140] step: 34250, training_loss: 3.82639e-04
I0404 20:27:19.827937 23443585951552 run_lib.py:140] step: 34300, training_loss: 3.06313e-04
I0404 20:27:19.983530 23443585951552 run_lib.py:153] step: 34300, eval_loss: 4.14182e-04
I0404 20:27:41.050690 23443585951552 run_lib.py:140] step: 34350, training_loss: 3.84534e-04
I0404 20:28:02.087399 23443585951552 run_lib.py:140] step: 34400, training_loss: 3.91202e-04
I0404 20:28:02.243088 23443585951552 run_lib.py:153] step: 34400, eval_loss: 3.71677e-04
I0404 20:28:23.631021 23443585951552 run_lib.py:140] step: 34450, training_loss: 4.64176e-04
I0404 20:28:44.850305 23443585951552 run_lib.py:140] step: 34500, training_loss: 4.16216e-04
I0404 20:28:45.008188 23443585951552 run_lib.py:153] step: 34500, eval_loss: 3.97382e-04
I0404 20:29:06.065449 23443585951552 run_lib.py:140] step: 34550, training_loss: 4.41599e-04
I0404 20:29:27.047004 23443585951552 run_lib.py:140] step: 34600, training_loss: 4.23988e-04
I0404 20:29:27.205474 23443585951552 run_lib.py:153] step: 34600, eval_loss: 4.00583e-04
I0404 20:29:48.614326 23443585951552 run_lib.py:140] step: 34650, training_loss: 4.15093e-04
I0404 20:30:09.526214 23443585951552 run_lib.py:140] step: 34700, training_loss: 3.65721e-04
I0404 20:30:09.681808 23443585951552 run_lib.py:153] step: 34700, eval_loss: 4.16193e-04
I0404 20:30:30.798696 23443585951552 run_lib.py:140] step: 34750, training_loss: 4.65350e-04
I0404 20:30:52.045640 23443585951552 run_lib.py:140] step: 34800, training_loss: 3.73771e-04
I0404 20:30:52.203033 23443585951552 run_lib.py:153] step: 34800, eval_loss: 4.43559e-04
I0404 20:31:13.264125 23443585951552 run_lib.py:140] step: 34850, training_loss: 3.72454e-04
I0404 20:31:34.416307 23443585951552 run_lib.py:140] step: 34900, training_loss: 3.91105e-04
I0404 20:31:34.568965 23443585951552 run_lib.py:153] step: 34900, eval_loss: 4.17900e-04
I0404 20:31:55.673939 23443585951552 run_lib.py:140] step: 34950, training_loss: 3.33743e-04
I0404 20:32:17.071329 23443585951552 run_lib.py:140] step: 35000, training_loss: 4.75306e-04
I0404 20:32:17.230948 23443585951552 run_lib.py:153] step: 35000, eval_loss: 3.73227e-04
I0404 20:32:38.478567 23443585951552 run_lib.py:140] step: 35050, training_loss: 3.91352e-04
I0404 20:32:59.704031 23443585951552 run_lib.py:140] step: 35100, training_loss: 3.59815e-04
I0404 20:32:59.865182 23443585951552 run_lib.py:153] step: 35100, eval_loss: 4.18249e-04
I0404 20:33:21.159761 23443585951552 run_lib.py:140] step: 35150, training_loss: 3.90821e-04
I0404 20:33:42.236158 23443585951552 run_lib.py:140] step: 35200, training_loss: 4.12794e-04
I0404 20:33:42.392784 23443585951552 run_lib.py:153] step: 35200, eval_loss: 3.84036e-04
I0404 20:34:03.825869 23443585951552 run_lib.py:140] step: 35250, training_loss: 4.47762e-04
I0404 20:34:24.836988 23443585951552 run_lib.py:140] step: 35300, training_loss: 4.23997e-04
I0404 20:34:24.992021 23443585951552 run_lib.py:153] step: 35300, eval_loss: 3.82730e-04
I0404 20:34:46.037279 23443585951552 run_lib.py:140] step: 35350, training_loss: 3.56681e-04
I0404 20:35:07.485408 23443585951552 run_lib.py:140] step: 35400, training_loss: 3.92534e-04
I0404 20:35:07.652815 23443585951552 run_lib.py:153] step: 35400, eval_loss: 3.82453e-04
I0404 20:35:28.925690 23443585951552 run_lib.py:140] step: 35450, training_loss: 3.71374e-04
I0404 20:35:50.363234 23443585951552 run_lib.py:140] step: 35500, training_loss: 4.13022e-04
I0404 20:35:50.519824 23443585951552 run_lib.py:153] step: 35500, eval_loss: 4.08881e-04
I0404 20:36:12.284567 23443585951552 run_lib.py:140] step: 35550, training_loss: 3.84230e-04
I0404 20:36:33.809834 23443585951552 run_lib.py:140] step: 35600, training_loss: 4.38104e-04
I0404 20:36:33.968836 23443585951552 run_lib.py:153] step: 35600, eval_loss: 4.38498e-04
I0404 20:36:55.320234 23443585951552 run_lib.py:140] step: 35650, training_loss: 3.51650e-04
I0404 20:37:16.650222 23443585951552 run_lib.py:140] step: 35700, training_loss: 3.69992e-04
I0404 20:37:16.809327 23443585951552 run_lib.py:153] step: 35700, eval_loss: 3.83359e-04
I0404 20:37:38.273567 23443585951552 run_lib.py:140] step: 35750, training_loss: 4.10790e-04
I0404 20:37:59.626569 23443585951552 run_lib.py:140] step: 35800, training_loss: 3.77093e-04
I0404 20:37:59.779240 23443585951552 run_lib.py:153] step: 35800, eval_loss: 4.01898e-04
I0404 20:38:20.950023 23443585951552 run_lib.py:140] step: 35850, training_loss: 3.00242e-04
I0404 20:38:42.273128 23443585951552 run_lib.py:140] step: 35900, training_loss: 4.07816e-04
I0404 20:38:42.440976 23443585951552 run_lib.py:153] step: 35900, eval_loss: 3.71517e-04
I0404 20:39:03.384013 23443585951552 run_lib.py:140] step: 35950, training_loss: 4.23693e-04
I0404 20:39:24.032453 23443585951552 run_lib.py:140] step: 36000, training_loss: 4.63929e-04
I0404 20:39:24.195974 23443585951552 run_lib.py:153] step: 36000, eval_loss: 4.33537e-04
I0404 20:39:45.837945 23443585951552 run_lib.py:140] step: 36050, training_loss: 3.82886e-04
I0404 20:40:07.405573 23443585951552 run_lib.py:140] step: 36100, training_loss: 3.99455e-04
I0404 20:40:07.572171 23443585951552 run_lib.py:153] step: 36100, eval_loss: 3.87563e-04
I0404 20:40:28.993675 23443585951552 run_lib.py:140] step: 36150, training_loss: 4.02741e-04
I0404 20:40:50.805222 23443585951552 run_lib.py:140] step: 36200, training_loss: 4.46419e-04
I0404 20:40:50.963270 23443585951552 run_lib.py:153] step: 36200, eval_loss: 3.84658e-04
I0404 20:41:12.427019 23443585951552 run_lib.py:140] step: 36250, training_loss: 4.38386e-04
I0404 20:41:34.041880 23443585951552 run_lib.py:140] step: 36300, training_loss: 3.88986e-04
I0404 20:41:34.196084 23443585951552 run_lib.py:153] step: 36300, eval_loss: 4.33837e-04
I0404 20:41:55.669135 23443585951552 run_lib.py:140] step: 36350, training_loss: 4.49074e-04
I0404 20:42:17.065321 23443585951552 run_lib.py:140] step: 36400, training_loss: 3.56814e-04
I0404 20:42:17.230251 23443585951552 run_lib.py:153] step: 36400, eval_loss: 3.89859e-04
I0404 20:42:38.704133 23443585951552 run_lib.py:140] step: 36450, training_loss: 4.12992e-04
I0404 20:43:00.264640 23443585951552 run_lib.py:140] step: 36500, training_loss: 4.45912e-04
I0404 20:43:00.421343 23443585951552 run_lib.py:153] step: 36500, eval_loss: 4.32364e-04
I0404 20:43:21.890626 23443585951552 run_lib.py:140] step: 36550, training_loss: 3.45309e-04
I0404 20:43:43.203933 23443585951552 run_lib.py:140] step: 36600, training_loss: 4.03091e-04
I0404 20:43:43.374772 23443585951552 run_lib.py:153] step: 36600, eval_loss: 4.19390e-04
I0404 20:44:05.283210 23443585951552 run_lib.py:140] step: 36650, training_loss: 4.02806e-04
I0404 20:44:26.821423 23443585951552 run_lib.py:140] step: 36700, training_loss: 4.55963e-04
I0404 20:44:26.970758 23443585951552 run_lib.py:153] step: 36700, eval_loss: 3.80340e-04
I0404 20:44:48.439150 23443585951552 run_lib.py:140] step: 36750, training_loss: 4.43166e-04
I0404 20:45:09.952733 23443585951552 run_lib.py:140] step: 36800, training_loss: 4.00404e-04
I0404 20:45:10.104892 23443585951552 run_lib.py:153] step: 36800, eval_loss: 3.96785e-04
I0404 20:45:28.381326 23443585951552 run_lib.py:140] step: 36850, training_loss: 4.02175e-04
I0404 20:45:45.941605 23443585951552 run_lib.py:140] step: 36900, training_loss: 4.06335e-04
I0404 20:45:46.149042 23443585951552 run_lib.py:153] step: 36900, eval_loss: 4.12592e-04
I0404 20:46:03.642613 23443585951552 run_lib.py:140] step: 36950, training_loss: 4.55587e-04
I0404 20:46:21.096295 23443585951552 run_lib.py:140] step: 37000, training_loss: 4.32918e-04
I0404 20:46:21.252054 23443585951552 run_lib.py:153] step: 37000, eval_loss: 4.35729e-04
I0404 20:46:38.941831 23443585951552 run_lib.py:140] step: 37050, training_loss: 4.23739e-04
I0404 20:46:56.385489 23443585951552 run_lib.py:140] step: 37100, training_loss: 3.79128e-04
I0404 20:46:56.540038 23443585951552 run_lib.py:153] step: 37100, eval_loss: 4.03628e-04
I0404 20:47:13.943786 23443585951552 run_lib.py:140] step: 37150, training_loss: 4.27577e-04
I0404 20:47:31.574313 23443585951552 run_lib.py:140] step: 37200, training_loss: 3.71898e-04
I0404 20:47:31.728076 23443585951552 run_lib.py:153] step: 37200, eval_loss: 3.81755e-04
I0404 20:47:49.178926 23443585951552 run_lib.py:140] step: 37250, training_loss: 3.77805e-04
I0404 20:48:06.821805 23443585951552 run_lib.py:140] step: 37300, training_loss: 3.67134e-04
I0404 20:48:06.975838 23443585951552 run_lib.py:153] step: 37300, eval_loss: 3.69061e-04
I0404 20:48:24.397883 23443585951552 run_lib.py:140] step: 37350, training_loss: 4.07550e-04
I0404 20:48:42.044829 23443585951552 run_lib.py:140] step: 37400, training_loss: 3.85582e-04
I0404 20:48:42.275045 23443585951552 run_lib.py:153] step: 37400, eval_loss: 4.47586e-04
I0404 20:49:00.000625 23443585951552 run_lib.py:140] step: 37450, training_loss: 3.56317e-04
I0404 20:49:17.501679 23443585951552 run_lib.py:140] step: 37500, training_loss: 5.14910e-04
I0404 20:49:17.657116 23443585951552 run_lib.py:153] step: 37500, eval_loss: 3.81254e-04
I0404 20:49:35.117169 23443585951552 run_lib.py:140] step: 37550, training_loss: 4.11874e-04
I0404 20:49:52.781017 23443585951552 run_lib.py:140] step: 37600, training_loss: 3.76209e-04
I0404 20:49:52.945839 23443585951552 run_lib.py:153] step: 37600, eval_loss: 3.93628e-04
I0404 20:50:10.400533 23443585951552 run_lib.py:140] step: 37650, training_loss: 3.98520e-04
I0404 20:50:27.891524 23443585951552 run_lib.py:140] step: 37700, training_loss: 4.12972e-04
I0404 20:50:28.044023 23443585951552 run_lib.py:153] step: 37700, eval_loss: 3.72434e-04
I0404 20:50:45.668788 23443585951552 run_lib.py:140] step: 37750, training_loss: 3.88290e-04
I0404 20:51:03.325779 23443585951552 run_lib.py:140] step: 37800, training_loss: 4.41520e-04
I0404 20:51:03.486253 23443585951552 run_lib.py:153] step: 37800, eval_loss: 4.75556e-04
I0404 20:51:21.049077 23443585951552 run_lib.py:140] step: 37850, training_loss: 4.41315e-04
I0404 20:51:38.663391 23443585951552 run_lib.py:140] step: 37900, training_loss: 3.79810e-04
I0404 20:51:38.822209 23443585951552 run_lib.py:153] step: 37900, eval_loss: 4.22717e-04
I0404 20:51:56.779895 23443585951552 run_lib.py:140] step: 37950, training_loss: 4.16638e-04
I0404 20:52:18.121750 23443585951552 run_lib.py:140] step: 38000, training_loss: 3.67642e-04
I0404 20:52:18.285210 23443585951552 run_lib.py:153] step: 38000, eval_loss: 4.41340e-04
I0404 20:52:39.760598 23443585951552 run_lib.py:140] step: 38050, training_loss: 3.60341e-04
I0404 20:53:00.885282 23443585951552 run_lib.py:140] step: 38100, training_loss: 4.24855e-04
I0404 20:53:01.042275 23443585951552 run_lib.py:153] step: 38100, eval_loss: 4.31917e-04
I0404 20:53:22.573650 23443585951552 run_lib.py:140] step: 38150, training_loss: 4.16047e-04
I0404 20:53:44.360783 23443585951552 run_lib.py:140] step: 38200, training_loss: 4.57065e-04
I0404 20:53:44.515315 23443585951552 run_lib.py:153] step: 38200, eval_loss: 3.57638e-04
I0404 20:54:05.952196 23443585951552 run_lib.py:140] step: 38250, training_loss: 4.04112e-04
I0404 20:54:27.508430 23443585951552 run_lib.py:140] step: 38300, training_loss: 3.86378e-04
I0404 20:54:27.669684 23443585951552 run_lib.py:153] step: 38300, eval_loss: 3.75389e-04
I0404 20:54:49.146401 23443585951552 run_lib.py:140] step: 38350, training_loss: 4.36349e-04
I0404 20:55:10.511179 23443585951552 run_lib.py:140] step: 38400, training_loss: 4.37318e-04
I0404 20:55:10.669561 23443585951552 run_lib.py:153] step: 38400, eval_loss: 3.27010e-04
I0404 20:55:32.250075 23443585951552 run_lib.py:140] step: 38450, training_loss: 4.17088e-04
I0404 20:55:53.866861 23443585951552 run_lib.py:140] step: 38500, training_loss: 3.84661e-04
I0404 20:55:54.019753 23443585951552 run_lib.py:153] step: 38500, eval_loss: 3.89920e-04
I0404 20:56:15.311960 23443585951552 run_lib.py:140] step: 38550, training_loss: 4.08405e-04
I0404 20:56:36.775813 23443585951552 run_lib.py:140] step: 38600, training_loss: 4.35849e-04
I0404 20:56:36.930260 23443585951552 run_lib.py:153] step: 38600, eval_loss: 4.53601e-04
I0404 20:56:58.047933 23443585951552 run_lib.py:140] step: 38650, training_loss: 3.93819e-04
I0404 20:57:19.582447 23443585951552 run_lib.py:140] step: 38700, training_loss: 5.15892e-04
I0404 20:57:19.744194 23443585951552 run_lib.py:153] step: 38700, eval_loss: 4.22315e-04
I0404 20:57:40.838701 23443585951552 run_lib.py:140] step: 38750, training_loss: 3.41719e-04
I0404 20:58:02.030009 23443585951552 run_lib.py:140] step: 38800, training_loss: 4.04003e-04
I0404 20:58:02.233063 23443585951552 run_lib.py:153] step: 38800, eval_loss: 4.56070e-04
I0404 20:58:23.749570 23443585951552 run_lib.py:140] step: 38850, training_loss: 4.31008e-04
I0404 20:58:45.254538 23443585951552 run_lib.py:140] step: 38900, training_loss: 4.57815e-04
I0404 20:58:45.408128 23443585951552 run_lib.py:153] step: 38900, eval_loss: 3.85669e-04
I0404 20:59:07.017885 23443585951552 run_lib.py:140] step: 38950, training_loss: 3.86477e-04
I0404 20:59:28.661963 23443585951552 run_lib.py:140] step: 39000, training_loss: 4.09712e-04
I0404 20:59:28.823077 23443585951552 run_lib.py:153] step: 39000, eval_loss: 3.58821e-04
I0404 20:59:50.250924 23443585951552 run_lib.py:140] step: 39050, training_loss: 3.69371e-04
I0404 21:00:11.905719 23443585951552 run_lib.py:140] step: 39100, training_loss: 4.30199e-04
I0404 21:00:12.069540 23443585951552 run_lib.py:153] step: 39100, eval_loss: 4.69774e-04
I0404 21:00:33.457746 23443585951552 run_lib.py:140] step: 39150, training_loss: 3.88240e-04
I0404 21:00:54.658466 23443585951552 run_lib.py:140] step: 39200, training_loss: 4.06331e-04
I0404 21:00:54.820347 23443585951552 run_lib.py:153] step: 39200, eval_loss: 4.15420e-04
I0404 21:01:16.547169 23443585951552 run_lib.py:140] step: 39250, training_loss: 3.89172e-04
I0404 21:01:37.796281 23443585951552 run_lib.py:140] step: 39300, training_loss: 3.91946e-04
I0404 21:01:37.971249 23443585951552 run_lib.py:153] step: 39300, eval_loss: 3.88584e-04
I0404 21:01:59.342902 23443585951552 run_lib.py:140] step: 39350, training_loss: 3.92632e-04
I0404 21:02:20.808075 23443585951552 run_lib.py:140] step: 39400, training_loss: 3.62701e-04
I0404 21:02:20.966026 23443585951552 run_lib.py:153] step: 39400, eval_loss: 3.76091e-04
I0404 21:02:41.797015 23443585951552 run_lib.py:140] step: 39450, training_loss: 4.56475e-04
I0404 21:03:03.793440 23443585951552 run_lib.py:140] step: 39500, training_loss: 3.92501e-04
I0404 21:03:03.950308 23443585951552 run_lib.py:153] step: 39500, eval_loss: 3.64681e-04
I0404 21:03:25.379366 23443585951552 run_lib.py:140] step: 39550, training_loss: 3.92852e-04
I0404 21:03:46.703011 23443585951552 run_lib.py:140] step: 39600, training_loss: 4.27504e-04
I0404 21:03:46.854999 23443585951552 run_lib.py:153] step: 39600, eval_loss: 4.01089e-04
I0404 21:04:08.502538 23443585951552 run_lib.py:140] step: 39650, training_loss: 3.86190e-04
I0404 21:04:29.873902 23443585951552 run_lib.py:140] step: 39700, training_loss: 4.88291e-04
I0404 21:04:30.055086 23443585951552 run_lib.py:153] step: 39700, eval_loss: 4.05856e-04
I0404 21:04:51.248501 23443585951552 run_lib.py:140] step: 39750, training_loss: 4.54631e-04
I0404 21:05:12.588426 23443585951552 run_lib.py:140] step: 39800, training_loss: 4.25094e-04
I0404 21:05:12.747417 23443585951552 run_lib.py:153] step: 39800, eval_loss: 4.07124e-04
I0404 21:05:33.682466 23443585951552 run_lib.py:140] step: 39850, training_loss: 3.94818e-04
I0404 21:05:54.400139 23443585951552 run_lib.py:140] step: 39900, training_loss: 4.75957e-04
I0404 21:05:54.554015 23443585951552 run_lib.py:153] step: 39900, eval_loss: 3.61197e-04
I0404 21:06:15.813862 23443585951552 run_lib.py:140] step: 39950, training_loss: 3.99135e-04
I0404 21:06:36.619275 23443585951552 run_lib.py:140] step: 40000, training_loss: 3.82407e-04
I0404 21:06:37.455143 23443585951552 run_lib.py:153] step: 40000, eval_loss: 4.05268e-04
I0404 21:06:59.121425 23443585951552 run_lib.py:140] step: 40050, training_loss: 3.91855e-04
I0404 21:07:20.901204 23443585951552 run_lib.py:140] step: 40100, training_loss: 4.38910e-04
I0404 21:07:21.190183 23443585951552 run_lib.py:153] step: 40100, eval_loss: 4.31313e-04
I0404 21:07:42.690782 23443585951552 run_lib.py:140] step: 40150, training_loss: 4.18395e-04
I0404 21:08:03.848070 23443585951552 run_lib.py:140] step: 40200, training_loss: 4.39511e-04
I0404 21:08:04.003180 23443585951552 run_lib.py:153] step: 40200, eval_loss: 3.94470e-04
I0404 21:08:25.529376 23443585951552 run_lib.py:140] step: 40250, training_loss: 4.45839e-04
I0404 21:08:47.065464 23443585951552 run_lib.py:140] step: 40300, training_loss: 3.65149e-04
I0404 21:08:47.250974 23443585951552 run_lib.py:153] step: 40300, eval_loss: 4.04466e-04
I0404 21:09:09.107389 23443585951552 run_lib.py:140] step: 40350, training_loss: 4.47569e-04
I0404 21:09:30.323306 23443585951552 run_lib.py:140] step: 40400, training_loss: 4.07651e-04
I0404 21:09:30.481423 23443585951552 run_lib.py:153] step: 40400, eval_loss: 4.15151e-04
I0404 21:09:51.590981 23443585951552 run_lib.py:140] step: 40450, training_loss: 3.96696e-04
I0404 21:10:12.938174 23443585951552 run_lib.py:140] step: 40500, training_loss: 3.93750e-04
I0404 21:10:13.094317 23443585951552 run_lib.py:153] step: 40500, eval_loss: 4.21758e-04
I0404 21:10:34.030529 23443585951552 run_lib.py:140] step: 40550, training_loss: 3.61500e-04
I0404 21:10:55.326072 23443585951552 run_lib.py:140] step: 40600, training_loss: 3.94712e-04
I0404 21:10:55.497137 23443585951552 run_lib.py:153] step: 40600, eval_loss: 3.56958e-04
I0404 21:11:16.656291 23443585951552 run_lib.py:140] step: 40650, training_loss: 4.30831e-04
I0404 21:11:37.767050 23443585951552 run_lib.py:140] step: 40700, training_loss: 4.30204e-04
I0404 21:11:37.925447 23443585951552 run_lib.py:153] step: 40700, eval_loss: 3.73946e-04
I0404 21:11:59.742571 23443585951552 run_lib.py:140] step: 40750, training_loss: 4.34442e-04
I0404 21:12:21.069007 23443585951552 run_lib.py:140] step: 40800, training_loss: 3.91524e-04
I0404 21:12:21.224228 23443585951552 run_lib.py:153] step: 40800, eval_loss: 4.25456e-04
I0404 21:12:42.975840 23443585951552 run_lib.py:140] step: 40850, training_loss: 4.35667e-04
I0404 21:13:04.581702 23443585951552 run_lib.py:140] step: 40900, training_loss: 4.05051e-04
I0404 21:13:04.741178 23443585951552 run_lib.py:153] step: 40900, eval_loss: 4.18495e-04
I0404 21:13:26.229032 23443585951552 run_lib.py:140] step: 40950, training_loss: 4.18349e-04
I0404 21:13:47.628507 23443585951552 run_lib.py:140] step: 41000, training_loss: 4.12138e-04
I0404 21:13:47.783606 23443585951552 run_lib.py:153] step: 41000, eval_loss: 4.61621e-04
I0404 21:14:09.038465 23443585951552 run_lib.py:140] step: 41050, training_loss: 4.00160e-04
I0404 21:14:30.513118 23443585951552 run_lib.py:140] step: 41100, training_loss: 3.78065e-04
I0404 21:14:30.669776 23443585951552 run_lib.py:153] step: 41100, eval_loss: 4.44817e-04
I0404 21:14:52.092049 23443585951552 run_lib.py:140] step: 41150, training_loss: 3.96432e-04
I0404 21:15:13.577084 23443585951552 run_lib.py:140] step: 41200, training_loss: 3.83971e-04
I0404 21:15:13.757750 23443585951552 run_lib.py:153] step: 41200, eval_loss: 4.06640e-04
I0404 21:15:35.448220 23443585951552 run_lib.py:140] step: 41250, training_loss: 4.05631e-04
I0404 21:15:57.375452 23443585951552 run_lib.py:140] step: 41300, training_loss: 3.57877e-04
I0404 21:15:57.532331 23443585951552 run_lib.py:153] step: 41300, eval_loss: 3.95194e-04
I0404 21:16:19.015373 23443585951552 run_lib.py:140] step: 41350, training_loss: 3.69122e-04
I0404 21:16:40.774153 23443585951552 run_lib.py:140] step: 41400, training_loss: 3.87475e-04
I0404 21:16:40.937223 23443585951552 run_lib.py:153] step: 41400, eval_loss: 4.14933e-04
I0404 21:17:02.480761 23443585951552 run_lib.py:140] step: 41450, training_loss: 4.15889e-04
I0404 21:17:23.929609 23443585951552 run_lib.py:140] step: 41500, training_loss: 3.85094e-04
I0404 21:17:24.090156 23443585951552 run_lib.py:153] step: 41500, eval_loss: 4.39477e-04
I0404 21:17:46.270136 23443585951552 run_lib.py:140] step: 41550, training_loss: 4.15149e-04
I0404 21:18:07.696682 23443585951552 run_lib.py:140] step: 41600, training_loss: 3.56753e-04
I0404 21:18:07.851845 23443585951552 run_lib.py:153] step: 41600, eval_loss: 3.78099e-04
I0404 21:18:29.484701 23443585951552 run_lib.py:140] step: 41650, training_loss: 3.88171e-04
I0404 21:18:51.013078 23443585951552 run_lib.py:140] step: 41700, training_loss: 3.69560e-04
I0404 21:18:51.174137 23443585951552 run_lib.py:153] step: 41700, eval_loss: 4.19823e-04
I0404 21:19:12.377878 23443585951552 run_lib.py:140] step: 41750, training_loss: 3.32884e-04
I0404 21:19:33.570292 23443585951552 run_lib.py:140] step: 41800, training_loss: 4.37055e-04
I0404 21:19:33.729511 23443585951552 run_lib.py:153] step: 41800, eval_loss: 4.37777e-04
I0404 21:19:55.582852 23443585951552 run_lib.py:140] step: 41850, training_loss: 4.16968e-04
I0404 21:20:17.174282 23443585951552 run_lib.py:140] step: 41900, training_loss: 4.36503e-04
I0404 21:20:17.333600 23443585951552 run_lib.py:153] step: 41900, eval_loss: 3.92106e-04
I0404 21:20:38.636788 23443585951552 run_lib.py:140] step: 41950, training_loss: 4.47882e-04
I0404 21:21:00.045311 23443585951552 run_lib.py:140] step: 42000, training_loss: 3.77683e-04
I0404 21:21:00.205092 23443585951552 run_lib.py:153] step: 42000, eval_loss: 3.78814e-04
I0404 21:21:21.704556 23443585951552 run_lib.py:140] step: 42050, training_loss: 4.04185e-04
I0404 21:21:43.097006 23443585951552 run_lib.py:140] step: 42100, training_loss: 3.67377e-04
I0404 21:21:43.272851 23443585951552 run_lib.py:153] step: 42100, eval_loss: 3.77202e-04
I0404 21:22:05.277698 23443585951552 run_lib.py:140] step: 42150, training_loss: 4.02215e-04
I0404 21:22:26.730202 23443585951552 run_lib.py:140] step: 42200, training_loss: 3.60540e-04
I0404 21:22:26.886358 23443585951552 run_lib.py:153] step: 42200, eval_loss: 4.25593e-04
I0404 21:22:48.359155 23443585951552 run_lib.py:140] step: 42250, training_loss: 4.21474e-04
I0404 21:23:09.972158 23443585951552 run_lib.py:140] step: 42300, training_loss: 3.42708e-04
I0404 21:23:10.139216 23443585951552 run_lib.py:153] step: 42300, eval_loss: 3.90906e-04
I0404 21:23:32.085425 23443585951552 run_lib.py:140] step: 42350, training_loss: 4.42005e-04
I0404 21:23:53.654815 23443585951552 run_lib.py:140] step: 42400, training_loss: 4.43064e-04
I0404 21:23:53.814337 23443585951552 run_lib.py:153] step: 42400, eval_loss: 3.89665e-04
I0404 21:24:15.174817 23443585951552 run_lib.py:140] step: 42450, training_loss: 3.69274e-04
I0404 21:24:36.434190 23443585951552 run_lib.py:140] step: 42500, training_loss: 3.44398e-04
I0404 21:24:36.599461 23443585951552 run_lib.py:153] step: 42500, eval_loss: 3.81480e-04
I0404 21:24:58.358336 23443585951552 run_lib.py:140] step: 42550, training_loss: 4.25713e-04
I0404 21:25:19.878632 23443585951552 run_lib.py:140] step: 42600, training_loss: 3.46999e-04
I0404 21:25:20.047055 23443585951552 run_lib.py:153] step: 42600, eval_loss: 3.84114e-04
I0404 21:25:41.684714 23443585951552 run_lib.py:140] step: 42650, training_loss: 4.23810e-04
I0404 21:26:03.183730 23443585951552 run_lib.py:140] step: 42700, training_loss: 4.38373e-04
I0404 21:26:03.338009 23443585951552 run_lib.py:153] step: 42700, eval_loss: 4.07552e-04
I0404 21:26:25.027493 23443585951552 run_lib.py:140] step: 42750, training_loss: 3.87439e-04
I0404 21:26:46.778472 23443585951552 run_lib.py:140] step: 42800, training_loss: 4.45748e-04
I0404 21:26:46.934129 23443585951552 run_lib.py:153] step: 42800, eval_loss: 3.73087e-04
I0404 21:27:08.436935 23443585951552 run_lib.py:140] step: 42850, training_loss: 3.90962e-04
I0404 21:27:29.685301 23443585951552 run_lib.py:140] step: 42900, training_loss: 4.24320e-04
I0404 21:27:29.844532 23443585951552 run_lib.py:153] step: 42900, eval_loss: 4.18913e-04
I0404 21:27:51.044503 23443585951552 run_lib.py:140] step: 42950, training_loss: 3.66205e-04
I0404 21:28:12.261721 23443585951552 run_lib.py:140] step: 43000, training_loss: 4.03467e-04
I0404 21:28:12.428075 23443585951552 run_lib.py:153] step: 43000, eval_loss: 3.33703e-04
I0404 21:28:33.963800 23443585951552 run_lib.py:140] step: 43050, training_loss: 4.17565e-04
I0404 21:28:55.394397 23443585951552 run_lib.py:140] step: 43100, training_loss: 3.81634e-04
I0404 21:28:55.549257 23443585951552 run_lib.py:153] step: 43100, eval_loss: 3.67384e-04
I0404 21:29:16.910151 23443585951552 run_lib.py:140] step: 43150, training_loss: 4.83957e-04
I0404 21:29:38.213811 23443585951552 run_lib.py:140] step: 43200, training_loss: 4.06786e-04
I0404 21:29:38.369073 23443585951552 run_lib.py:153] step: 43200, eval_loss: 4.09631e-04
I0404 21:29:59.404571 23443585951552 run_lib.py:140] step: 43250, training_loss: 3.70815e-04
I0404 21:30:20.958022 23443585951552 run_lib.py:140] step: 43300, training_loss: 4.35824e-04
I0404 21:30:21.111847 23443585951552 run_lib.py:153] step: 43300, eval_loss: 3.98907e-04
I0404 21:30:42.802242 23443585951552 run_lib.py:140] step: 43350, training_loss: 3.90920e-04
I0404 21:31:04.376693 23443585951552 run_lib.py:140] step: 43400, training_loss: 3.82402e-04
I0404 21:31:04.525623 23443585951552 run_lib.py:153] step: 43400, eval_loss: 4.19371e-04
I0404 21:31:26.050199 23443585951552 run_lib.py:140] step: 43450, training_loss: 3.92817e-04
I0404 21:31:47.788105 23443585951552 run_lib.py:140] step: 43500, training_loss: 4.32192e-04
I0404 21:31:47.963251 23443585951552 run_lib.py:153] step: 43500, eval_loss: 4.08250e-04
I0404 21:32:09.507988 23443585951552 run_lib.py:140] step: 43550, training_loss: 3.93205e-04
I0404 21:32:31.205160 23443585951552 run_lib.py:140] step: 43600, training_loss: 4.41372e-04
I0404 21:32:31.364158 23443585951552 run_lib.py:153] step: 43600, eval_loss: 4.20713e-04
I0404 21:32:52.741806 23443585951552 run_lib.py:140] step: 43650, training_loss: 4.02391e-04
I0404 21:33:13.642043 23443585951552 run_lib.py:140] step: 43700, training_loss: 4.57064e-04
I0404 21:33:13.803877 23443585951552 run_lib.py:153] step: 43700, eval_loss: 4.19691e-04
I0404 21:33:34.932540 23443585951552 run_lib.py:140] step: 43750, training_loss: 3.98742e-04
I0404 21:33:56.775930 23443585951552 run_lib.py:140] step: 43800, training_loss: 4.44641e-04
I0404 21:33:56.927797 23443585951552 run_lib.py:153] step: 43800, eval_loss: 3.67097e-04
I0404 21:34:18.165539 23443585951552 run_lib.py:140] step: 43850, training_loss: 3.79749e-04
I0404 21:34:39.448797 23443585951552 run_lib.py:140] step: 43900, training_loss: 3.63140e-04
I0404 21:34:39.601743 23443585951552 run_lib.py:153] step: 43900, eval_loss: 3.24580e-04
I0404 21:35:01.629148 23443585951552 run_lib.py:140] step: 43950, training_loss: 3.74049e-04
I0404 21:35:22.858917 23443585951552 run_lib.py:140] step: 44000, training_loss: 4.12736e-04
I0404 21:35:23.020928 23443585951552 run_lib.py:153] step: 44000, eval_loss: 3.82190e-04
I0404 21:35:44.631931 23443585951552 run_lib.py:140] step: 44050, training_loss: 4.47437e-04
I0404 21:36:06.098855 23443585951552 run_lib.py:140] step: 44100, training_loss: 4.53206e-04
I0404 21:36:06.271800 23443585951552 run_lib.py:153] step: 44100, eval_loss: 3.35971e-04
I0404 21:36:27.433935 23443585951552 run_lib.py:140] step: 44150, training_loss: 3.85200e-04
I0404 21:36:49.367166 23443585951552 run_lib.py:140] step: 44200, training_loss: 3.88398e-04
I0404 21:36:49.527107 23443585951552 run_lib.py:153] step: 44200, eval_loss: 4.03329e-04
I0404 21:37:11.060910 23443585951552 run_lib.py:140] step: 44250, training_loss: 3.63979e-04
I0404 21:37:32.567172 23443585951552 run_lib.py:140] step: 44300, training_loss: 4.10542e-04
I0404 21:37:32.726395 23443585951552 run_lib.py:153] step: 44300, eval_loss: 4.90127e-04
I0404 21:37:54.358056 23443585951552 run_lib.py:140] step: 44350, training_loss: 3.89631e-04
I0404 21:38:15.686670 23443585951552 run_lib.py:140] step: 44400, training_loss: 4.74140e-04
I0404 21:38:15.852379 23443585951552 run_lib.py:153] step: 44400, eval_loss: 4.38092e-04
I0404 21:38:37.445685 23443585951552 run_lib.py:140] step: 44450, training_loss: 4.25195e-04
I0404 21:38:59.288346 23443585951552 run_lib.py:140] step: 44500, training_loss: 4.08193e-04
I0404 21:38:59.452630 23443585951552 run_lib.py:153] step: 44500, eval_loss: 3.84940e-04
I0404 21:39:21.209271 23443585951552 run_lib.py:140] step: 44550, training_loss: 4.15791e-04
I0404 21:39:42.707874 23443585951552 run_lib.py:140] step: 44600, training_loss: 4.84191e-04
I0404 21:39:42.867052 23443585951552 run_lib.py:153] step: 44600, eval_loss: 4.26131e-04
I0404 21:40:04.022509 23443585951552 run_lib.py:140] step: 44650, training_loss: 4.03680e-04
I0404 21:40:25.649459 23443585951552 run_lib.py:140] step: 44700, training_loss: 4.18943e-04
I0404 21:40:25.803638 23443585951552 run_lib.py:153] step: 44700, eval_loss: 4.10894e-04
I0404 21:40:47.617760 23443585951552 run_lib.py:140] step: 44750, training_loss: 4.18034e-04
I0404 21:41:09.114582 23443585951552 run_lib.py:140] step: 44800, training_loss: 4.43873e-04
I0404 21:41:09.266064 23443585951552 run_lib.py:153] step: 44800, eval_loss: 4.22552e-04
I0404 21:41:30.552551 23443585951552 run_lib.py:140] step: 44850, training_loss: 4.70769e-04
I0404 21:41:52.415108 23443585951552 run_lib.py:140] step: 44900, training_loss: 4.09114e-04
I0404 21:41:52.570903 23443585951552 run_lib.py:153] step: 44900, eval_loss: 4.21702e-04
I0404 21:42:13.848699 23443585951552 run_lib.py:140] step: 44950, training_loss: 3.58685e-04
I0404 21:42:35.242352 23443585951552 run_lib.py:140] step: 45000, training_loss: 3.89110e-04
I0404 21:42:35.413423 23443585951552 run_lib.py:153] step: 45000, eval_loss: 3.72921e-04
I0404 21:42:56.666873 23443585951552 run_lib.py:140] step: 45050, training_loss: 3.94597e-04
I0404 21:43:18.108543 23443585951552 run_lib.py:140] step: 45100, training_loss: 4.64205e-04
I0404 21:43:18.263928 23443585951552 run_lib.py:153] step: 45100, eval_loss: 3.46097e-04
I0404 21:43:39.632085 23443585951552 run_lib.py:140] step: 45150, training_loss: 4.47684e-04
I0404 21:44:00.905136 23443585951552 run_lib.py:140] step: 45200, training_loss: 3.96282e-04
I0404 21:44:01.060015 23443585951552 run_lib.py:153] step: 45200, eval_loss: 4.08731e-04
I0404 21:44:22.080621 23443585951552 run_lib.py:140] step: 45250, training_loss: 4.39901e-04
I0404 21:44:44.309017 23443585951552 run_lib.py:140] step: 45300, training_loss: 4.28437e-04
I0404 21:44:44.470444 23443585951552 run_lib.py:153] step: 45300, eval_loss: 3.47488e-04
I0404 21:45:05.896393 23443585951552 run_lib.py:140] step: 45350, training_loss: 3.93218e-04
I0404 21:45:27.235854 23443585951552 run_lib.py:140] step: 45400, training_loss: 3.65436e-04
I0404 21:45:27.395402 23443585951552 run_lib.py:153] step: 45400, eval_loss: 4.30362e-04
I0404 21:45:48.934450 23443585951552 run_lib.py:140] step: 45450, training_loss: 3.88677e-04
I0404 21:46:10.595447 23443585951552 run_lib.py:140] step: 45500, training_loss: 3.87344e-04
I0404 21:46:10.753384 23443585951552 run_lib.py:153] step: 45500, eval_loss: 3.63389e-04
I0404 21:46:31.686266 23443585951552 run_lib.py:140] step: 45550, training_loss: 4.66641e-04
I0404 21:46:53.381194 23443585951552 run_lib.py:140] step: 45600, training_loss: 4.00530e-04
I0404 21:46:53.536979 23443585951552 run_lib.py:153] step: 45600, eval_loss: 3.64552e-04
I0404 21:47:15.085094 23443585951552 run_lib.py:140] step: 45650, training_loss: 3.95469e-04
I0404 21:47:36.411795 23443585951552 run_lib.py:140] step: 45700, training_loss: 3.42334e-04
I0404 21:47:36.568793 23443585951552 run_lib.py:153] step: 45700, eval_loss: 4.05958e-04
I0404 21:47:57.921661 23443585951552 run_lib.py:140] step: 45750, training_loss: 4.31671e-04
I0404 21:48:19.189027 23443585951552 run_lib.py:140] step: 45800, training_loss: 4.18670e-04
I0404 21:48:19.349446 23443585951552 run_lib.py:153] step: 45800, eval_loss: 4.31216e-04
I0404 21:48:41.113158 23443585951552 run_lib.py:140] step: 45850, training_loss: 4.02976e-04
I0404 21:49:02.207426 23443585951552 run_lib.py:140] step: 45900, training_loss: 3.76452e-04
I0404 21:49:02.369479 23443585951552 run_lib.py:153] step: 45900, eval_loss: 4.05441e-04
I0404 21:49:23.537036 23443585951552 run_lib.py:140] step: 45950, training_loss: 4.41388e-04
I0404 21:49:45.525490 23443585951552 run_lib.py:140] step: 46000, training_loss: 4.13053e-04
I0404 21:49:45.683147 23443585951552 run_lib.py:153] step: 46000, eval_loss: 3.88600e-04
I0404 21:50:07.212232 23443585951552 run_lib.py:140] step: 46050, training_loss: 3.40928e-04
I0404 21:50:28.481336 23443585951552 run_lib.py:140] step: 46100, training_loss: 4.51139e-04
I0404 21:50:28.640886 23443585951552 run_lib.py:153] step: 46100, eval_loss: 4.37689e-04
I0404 21:50:50.049313 23443585951552 run_lib.py:140] step: 46150, training_loss: 4.13103e-04
I0404 21:51:11.411493 23443585951552 run_lib.py:140] step: 46200, training_loss: 4.63554e-04
I0404 21:51:11.567328 23443585951552 run_lib.py:153] step: 46200, eval_loss: 3.76401e-04
I0404 21:51:32.708689 23443585951552 run_lib.py:140] step: 46250, training_loss: 3.50784e-04
I0404 21:51:54.334197 23443585951552 run_lib.py:140] step: 46300, training_loss: 4.05589e-04
I0404 21:51:54.496484 23443585951552 run_lib.py:153] step: 46300, eval_loss: 4.00504e-04
I0404 21:52:15.626661 23443585951552 run_lib.py:140] step: 46350, training_loss: 4.01058e-04
I0404 21:52:37.066280 23443585951552 run_lib.py:140] step: 46400, training_loss: 3.76192e-04
I0404 21:52:37.226090 23443585951552 run_lib.py:153] step: 46400, eval_loss: 4.22279e-04
I0404 21:52:58.493243 23443585951552 run_lib.py:140] step: 46450, training_loss: 4.31873e-04
I0404 21:53:19.678313 23443585951552 run_lib.py:140] step: 46500, training_loss: 4.10526e-04
I0404 21:53:19.843335 23443585951552 run_lib.py:153] step: 46500, eval_loss: 4.18637e-04
I0404 21:53:41.190202 23443585951552 run_lib.py:140] step: 46550, training_loss: 3.88402e-04
I0404 21:54:02.354768 23443585951552 run_lib.py:140] step: 46600, training_loss: 4.07320e-04
I0404 21:54:02.511402 23443585951552 run_lib.py:153] step: 46600, eval_loss: 3.75430e-04
I0404 21:54:23.722554 23443585951552 run_lib.py:140] step: 46650, training_loss: 3.90331e-04
I0404 21:54:45.722740 23443585951552 run_lib.py:140] step: 46700, training_loss: 3.92572e-04
I0404 21:54:45.874077 23443585951552 run_lib.py:153] step: 46700, eval_loss: 3.46910e-04
I0404 21:55:07.259091 23443585951552 run_lib.py:140] step: 46750, training_loss: 3.67925e-04
I0404 21:55:29.033351 23443585951552 run_lib.py:140] step: 46800, training_loss: 4.80518e-04
I0404 21:55:29.206028 23443585951552 run_lib.py:153] step: 46800, eval_loss: 3.85076e-04
I0404 21:55:50.559413 23443585951552 run_lib.py:140] step: 46850, training_loss: 4.11803e-04
I0404 21:56:11.530161 23443585951552 run_lib.py:140] step: 46900, training_loss: 4.46334e-04
I0404 21:56:11.712225 23443585951552 run_lib.py:153] step: 46900, eval_loss: 3.57874e-04
I0404 21:56:32.897244 23443585951552 run_lib.py:140] step: 46950, training_loss: 3.86888e-04
I0404 21:56:54.115186 23443585951552 run_lib.py:140] step: 47000, training_loss: 3.83262e-04
I0404 21:56:54.270313 23443585951552 run_lib.py:153] step: 47000, eval_loss: 4.31078e-04
I0404 21:57:15.698448 23443585951552 run_lib.py:140] step: 47050, training_loss: 3.75485e-04
I0404 21:57:37.182247 23443585951552 run_lib.py:140] step: 47100, training_loss: 3.78661e-04
I0404 21:57:37.344962 23443585951552 run_lib.py:153] step: 47100, eval_loss: 4.21920e-04
I0404 21:57:58.822859 23443585951552 run_lib.py:140] step: 47150, training_loss: 3.58109e-04
I0404 21:58:20.423048 23443585951552 run_lib.py:140] step: 47200, training_loss: 4.37909e-04
I0404 21:58:20.581231 23443585951552 run_lib.py:153] step: 47200, eval_loss: 3.66392e-04
I0404 21:58:41.908300 23443585951552 run_lib.py:140] step: 47250, training_loss: 3.24055e-04
I0404 21:59:03.371942 23443585951552 run_lib.py:140] step: 47300, training_loss: 4.02245e-04
I0404 21:59:03.541210 23443585951552 run_lib.py:153] step: 47300, eval_loss: 3.52936e-04
I0404 21:59:25.333765 23443585951552 run_lib.py:140] step: 47350, training_loss: 4.12847e-04
I0404 21:59:46.647478 23443585951552 run_lib.py:140] step: 47400, training_loss: 3.74841e-04
I0404 21:59:46.809283 23443585951552 run_lib.py:153] step: 47400, eval_loss: 4.18867e-04
I0404 22:00:08.419442 23443585951552 run_lib.py:140] step: 47450, training_loss: 4.11487e-04
I0404 22:00:30.188943 23443585951552 run_lib.py:140] step: 47500, training_loss: 3.81995e-04
I0404 22:00:30.343970 23443585951552 run_lib.py:153] step: 47500, eval_loss: 3.61039e-04
I0404 22:00:51.711190 23443585951552 run_lib.py:140] step: 47550, training_loss: 3.63748e-04
I0404 22:01:13.233834 23443585951552 run_lib.py:140] step: 47600, training_loss: 4.43144e-04
I0404 22:01:13.389317 23443585951552 run_lib.py:153] step: 47600, eval_loss: 3.85590e-04
I0404 22:01:35.240701 23443585951552 run_lib.py:140] step: 47650, training_loss: 3.79922e-04
I0404 22:01:56.899861 23443585951552 run_lib.py:140] step: 47700, training_loss: 3.85650e-04
I0404 22:01:57.052922 23443585951552 run_lib.py:153] step: 47700, eval_loss: 4.30089e-04
I0404 22:02:18.416139 23443585951552 run_lib.py:140] step: 47750, training_loss: 4.06557e-04
I0404 22:02:40.067717 23443585951552 run_lib.py:140] step: 47800, training_loss: 4.42277e-04
I0404 22:02:40.245120 23443585951552 run_lib.py:153] step: 47800, eval_loss: 3.33151e-04
I0404 22:03:02.409529 23443585951552 run_lib.py:140] step: 47850, training_loss: 3.99546e-04
I0404 22:03:24.077929 23443585951552 run_lib.py:140] step: 47900, training_loss: 4.04230e-04
I0404 22:03:24.236103 23443585951552 run_lib.py:153] step: 47900, eval_loss: 4.08651e-04
I0404 22:03:46.180784 23443585951552 run_lib.py:140] step: 47950, training_loss: 4.36277e-04
I0404 22:04:08.040319 23443585951552 run_lib.py:140] step: 48000, training_loss: 3.30738e-04
I0404 22:04:08.200604 23443585951552 run_lib.py:153] step: 48000, eval_loss: 4.45043e-04
I0404 22:04:30.301492 23443585951552 run_lib.py:140] step: 48050, training_loss: 3.88060e-04
I0404 22:04:52.064251 23443585951552 run_lib.py:140] step: 48100, training_loss: 4.19610e-04
I0404 22:04:52.226802 23443585951552 run_lib.py:153] step: 48100, eval_loss: 3.79364e-04
I0404 22:05:13.521088 23443585951552 run_lib.py:140] step: 48150, training_loss: 3.51828e-04
I0404 22:05:35.348472 23443585951552 run_lib.py:140] step: 48200, training_loss: 3.89013e-04
I0404 22:05:35.506436 23443585951552 run_lib.py:153] step: 48200, eval_loss: 4.06195e-04
I0404 22:05:57.339293 23443585951552 run_lib.py:140] step: 48250, training_loss: 4.39363e-04
I0404 22:06:19.483052 23443585951552 run_lib.py:140] step: 48300, training_loss: 4.18876e-04
I0404 22:06:19.644944 23443585951552 run_lib.py:153] step: 48300, eval_loss: 4.09960e-04
I0404 22:06:41.664506 23443585951552 run_lib.py:140] step: 48350, training_loss: 3.79487e-04
I0404 22:07:03.135777 23443585951552 run_lib.py:140] step: 48400, training_loss: 4.20376e-04
I0404 22:07:03.298781 23443585951552 run_lib.py:153] step: 48400, eval_loss: 3.79614e-04
I0404 22:07:25.162607 23443585951552 run_lib.py:140] step: 48450, training_loss: 4.27808e-04
I0404 22:07:46.787822 23443585951552 run_lib.py:140] step: 48500, training_loss: 3.92228e-04
I0404 22:07:46.952585 23443585951552 run_lib.py:153] step: 48500, eval_loss: 3.72073e-04
I0404 22:08:08.560417 23443585951552 run_lib.py:140] step: 48550, training_loss: 3.64939e-04
I0404 22:08:30.044093 23443585951552 run_lib.py:140] step: 48600, training_loss: 4.52874e-04
I0404 22:08:30.202087 23443585951552 run_lib.py:153] step: 48600, eval_loss: 3.81193e-04
I0404 22:08:51.631260 23443585951552 run_lib.py:140] step: 48650, training_loss: 4.31467e-04
I0404 22:09:13.367145 23443585951552 run_lib.py:140] step: 48700, training_loss: 3.48624e-04
I0404 22:09:13.532031 23443585951552 run_lib.py:153] step: 48700, eval_loss: 4.12304e-04
I0404 22:09:35.029031 23443585951552 run_lib.py:140] step: 48750, training_loss: 4.21659e-04
I0404 22:09:56.736881 23443585951552 run_lib.py:140] step: 48800, training_loss: 3.33433e-04
I0404 22:09:56.900969 23443585951552 run_lib.py:153] step: 48800, eval_loss: 3.43701e-04
I0404 22:10:18.276668 23443585951552 run_lib.py:140] step: 48850, training_loss: 3.99791e-04
I0404 22:10:40.096995 23443585951552 run_lib.py:140] step: 48900, training_loss: 4.39375e-04
I0404 22:10:40.263679 23443585951552 run_lib.py:153] step: 48900, eval_loss: 3.93497e-04
I0404 22:11:02.126438 23443585951552 run_lib.py:140] step: 48950, training_loss: 3.61904e-04
I0404 22:11:23.984789 23443585951552 run_lib.py:140] step: 49000, training_loss: 3.95280e-04
I0404 22:11:24.143965 23443585951552 run_lib.py:153] step: 49000, eval_loss: 3.97227e-04
I0404 22:11:45.176529 23443585951552 run_lib.py:140] step: 49050, training_loss: 3.79423e-04
I0404 22:12:06.949241 23443585951552 run_lib.py:140] step: 49100, training_loss: 3.90875e-04
I0404 22:12:07.113135 23443585951552 run_lib.py:153] step: 49100, eval_loss: 3.84691e-04
I0404 22:12:29.115632 23443585951552 run_lib.py:140] step: 49150, training_loss: 4.19710e-04
I0404 22:12:50.474748 23443585951552 run_lib.py:140] step: 49200, training_loss: 4.05712e-04
I0404 22:12:50.630869 23443585951552 run_lib.py:153] step: 49200, eval_loss: 3.93332e-04
I0404 22:13:12.106446 23443585951552 run_lib.py:140] step: 49250, training_loss: 4.41001e-04
I0404 22:13:33.747862 23443585951552 run_lib.py:140] step: 49300, training_loss: 4.11482e-04
I0404 22:13:33.926053 23443585951552 run_lib.py:153] step: 49300, eval_loss: 4.47276e-04
I0404 22:13:55.661288 23443585951552 run_lib.py:140] step: 49350, training_loss: 3.94474e-04
I0404 22:14:17.462462 23443585951552 run_lib.py:140] step: 49400, training_loss: 3.91842e-04
I0404 22:14:17.620197 23443585951552 run_lib.py:153] step: 49400, eval_loss: 3.40518e-04
I0404 22:14:39.414512 23443585951552 run_lib.py:140] step: 49450, training_loss: 3.86637e-04
I0404 22:15:00.908106 23443585951552 run_lib.py:140] step: 49500, training_loss: 4.33751e-04
I0404 22:15:01.069602 23443585951552 run_lib.py:153] step: 49500, eval_loss: 3.84672e-04
I0404 22:15:23.005536 23443585951552 run_lib.py:140] step: 49550, training_loss: 4.30521e-04
I0404 22:15:44.315730 23443585951552 run_lib.py:140] step: 49600, training_loss: 4.17606e-04
I0404 22:15:44.471076 23443585951552 run_lib.py:153] step: 49600, eval_loss: 4.42221e-04
I0404 22:16:06.100218 23443585951552 run_lib.py:140] step: 49650, training_loss: 3.70402e-04
I0404 22:16:27.726921 23443585951552 run_lib.py:140] step: 49700, training_loss: 4.10298e-04
I0404 22:16:27.899697 23443585951552 run_lib.py:153] step: 49700, eval_loss: 4.24501e-04
I0404 22:16:49.594774 23443585951552 run_lib.py:140] step: 49750, training_loss: 3.55226e-04
I0404 22:17:11.001407 23443585951552 run_lib.py:140] step: 49800, training_loss: 4.17256e-04
I0404 22:17:11.158475 23443585951552 run_lib.py:153] step: 49800, eval_loss: 4.37592e-04
I0404 22:17:32.833424 23443585951552 run_lib.py:140] step: 49850, training_loss: 4.32859e-04
I0404 22:17:54.510543 23443585951552 run_lib.py:140] step: 49900, training_loss: 4.44787e-04
I0404 22:17:54.677156 23443585951552 run_lib.py:153] step: 49900, eval_loss: 4.06611e-04
I0404 22:18:16.258533 23443585951552 run_lib.py:140] step: 49950, training_loss: 4.04737e-04
I0404 22:18:37.916393 23443585951552 run_lib.py:140] step: 50000, training_loss: 4.55922e-04
I0404 22:18:38.813576 23443585951552 run_lib.py:153] step: 50000, eval_loss: 4.36668e-04
I0404 22:19:01.598012 23443585951552 run_lib.py:140] step: 50050, training_loss: 4.07304e-04
I0404 22:19:23.437936 23443585951552 run_lib.py:140] step: 50100, training_loss: 3.78544e-04
I0404 22:19:23.602918 23443585951552 run_lib.py:153] step: 50100, eval_loss: 3.87713e-04
I0404 22:19:45.518684 23443585951552 run_lib.py:140] step: 50150, training_loss: 4.07447e-04
I0404 22:20:07.534875 23443585951552 run_lib.py:140] step: 50200, training_loss: 4.04396e-04
I0404 22:20:07.699854 23443585951552 run_lib.py:153] step: 50200, eval_loss: 3.68897e-04
I0404 22:20:29.479243 23443585951552 run_lib.py:140] step: 50250, training_loss: 3.53649e-04
I0404 22:20:50.841472 23443585951552 run_lib.py:140] step: 50300, training_loss: 3.33486e-04
I0404 22:20:50.996663 23443585951552 run_lib.py:153] step: 50300, eval_loss: 3.98443e-04
I0404 22:21:12.964333 23443585951552 run_lib.py:140] step: 50350, training_loss: 3.53152e-04
I0404 22:21:34.407441 23443585951552 run_lib.py:140] step: 50400, training_loss: 4.34425e-04
I0404 22:21:34.573888 23443585951552 run_lib.py:153] step: 50400, eval_loss: 3.95335e-04
I0404 22:21:56.228139 23443585951552 run_lib.py:140] step: 50450, training_loss: 4.32824e-04
I0404 22:22:17.929478 23443585951552 run_lib.py:140] step: 50500, training_loss: 4.52639e-04
I0404 22:22:18.086995 23443585951552 run_lib.py:153] step: 50500, eval_loss: 3.11732e-04
I0404 22:22:39.869788 23443585951552 run_lib.py:140] step: 50550, training_loss: 3.99633e-04
I0404 22:23:01.782702 23443585951552 run_lib.py:140] step: 50600, training_loss: 4.11096e-04
I0404 22:23:01.958992 23443585951552 run_lib.py:153] step: 50600, eval_loss: 3.75501e-04
I0404 22:23:23.810412 23443585951552 run_lib.py:140] step: 50650, training_loss: 4.19565e-04
I0404 22:23:45.350982 23443585951552 run_lib.py:140] step: 50700, training_loss: 4.14845e-04
I0404 22:23:45.590667 23443585951552 run_lib.py:153] step: 50700, eval_loss: 4.08095e-04
I0404 22:24:07.549154 23443585951552 run_lib.py:140] step: 50750, training_loss: 3.55716e-04
I0404 22:24:27.407850 23443585951552 run_lib.py:140] step: 50800, training_loss: 4.01192e-04
I0404 22:24:27.564464 23443585951552 run_lib.py:153] step: 50800, eval_loss: 3.61043e-04
I0404 22:24:45.033080 23443585951552 run_lib.py:140] step: 50850, training_loss: 4.11454e-04
I0404 22:25:02.475859 23443585951552 run_lib.py:140] step: 50900, training_loss: 4.27380e-04
I0404 22:25:02.628746 23443585951552 run_lib.py:153] step: 50900, eval_loss: 3.57691e-04
I0404 22:25:20.208709 23443585951552 run_lib.py:140] step: 50950, training_loss: 4.56729e-04
I0404 22:25:37.628790 23443585951552 run_lib.py:140] step: 51000, training_loss: 4.22465e-04
I0404 22:25:37.837148 23443585951552 run_lib.py:153] step: 51000, eval_loss: 3.59890e-04
I0404 22:25:55.344851 23443585951552 run_lib.py:140] step: 51050, training_loss: 3.78122e-04
I0404 22:26:12.832072 23443585951552 run_lib.py:140] step: 51100, training_loss: 4.29506e-04
I0404 22:26:12.988546 23443585951552 run_lib.py:153] step: 51100, eval_loss: 4.51370e-04
I0404 22:26:30.633191 23443585951552 run_lib.py:140] step: 51150, training_loss: 4.19026e-04
I0404 22:26:48.145722 23443585951552 run_lib.py:140] step: 51200, training_loss: 4.08603e-04
I0404 22:26:48.303027 23443585951552 run_lib.py:153] step: 51200, eval_loss: 4.21319e-04
I0404 22:27:05.734539 23443585951552 run_lib.py:140] step: 51250, training_loss: 4.24333e-04
I0404 22:27:23.128644 23443585951552 run_lib.py:140] step: 51300, training_loss: 3.85045e-04
I0404 22:27:23.289436 23443585951552 run_lib.py:153] step: 51300, eval_loss: 4.00411e-04
I0404 22:27:40.876601 23443585951552 run_lib.py:140] step: 51350, training_loss: 3.69326e-04
I0404 22:27:58.412464 23443585951552 run_lib.py:140] step: 51400, training_loss: 3.54856e-04
I0404 22:27:58.571940 23443585951552 run_lib.py:153] step: 51400, eval_loss: 4.77106e-04
I0404 22:28:16.038934 23443585951552 run_lib.py:140] step: 51450, training_loss: 4.00824e-04
I0404 22:28:33.712921 23443585951552 run_lib.py:140] step: 51500, training_loss: 4.47105e-04
I0404 22:28:33.863837 23443585951552 run_lib.py:153] step: 51500, eval_loss: 3.54789e-04
I0404 22:28:51.281923 23443585951552 run_lib.py:140] step: 51550, training_loss: 4.36110e-04
I0404 22:29:08.875644 23443585951552 run_lib.py:140] step: 51600, training_loss: 3.59958e-04
I0404 22:29:09.037720 23443585951552 run_lib.py:153] step: 51600, eval_loss: 4.01899e-04
I0404 22:29:26.552747 23443585951552 run_lib.py:140] step: 51650, training_loss: 3.09479e-04
I0404 22:29:44.056478 23443585951552 run_lib.py:140] step: 51700, training_loss: 3.84298e-04
I0404 22:29:44.210831 23443585951552 run_lib.py:153] step: 51700, eval_loss: 3.86448e-04
I0404 22:30:01.860422 23443585951552 run_lib.py:140] step: 51750, training_loss: 3.75132e-04
I0404 22:30:19.291725 23443585951552 run_lib.py:140] step: 51800, training_loss: 3.97265e-04
I0404 22:30:19.446930 23443585951552 run_lib.py:153] step: 51800, eval_loss: 3.49173e-04
I0404 22:30:36.941824 23443585951552 run_lib.py:140] step: 51850, training_loss: 4.30164e-04
I0404 22:30:54.761399 23443585951552 run_lib.py:140] step: 51900, training_loss: 3.94075e-04
I0404 22:30:54.915186 23443585951552 run_lib.py:153] step: 51900, eval_loss: 4.47590e-04
I0404 22:31:15.887639 23443585951552 run_lib.py:140] step: 51950, training_loss: 3.91129e-04
I0404 22:31:37.797278 23443585951552 run_lib.py:140] step: 52000, training_loss: 3.77657e-04
I0404 22:31:37.960023 23443585951552 run_lib.py:153] step: 52000, eval_loss: 3.90218e-04
I0404 22:32:00.000257 23443585951552 run_lib.py:140] step: 52050, training_loss: 4.12655e-04
I0404 22:32:22.110621 23443585951552 run_lib.py:140] step: 52100, training_loss: 4.09461e-04
I0404 22:32:22.275798 23443585951552 run_lib.py:153] step: 52100, eval_loss: 3.86724e-04
I0404 22:32:43.867727 23443585951552 run_lib.py:140] step: 52150, training_loss: 4.18910e-04
I0404 22:33:05.743010 23443585951552 run_lib.py:140] step: 52200, training_loss: 3.70049e-04
I0404 22:33:05.907135 23443585951552 run_lib.py:153] step: 52200, eval_loss: 3.87439e-04
I0404 22:33:27.727171 23443585951552 run_lib.py:140] step: 52250, training_loss: 3.56361e-04
I0404 22:33:49.711456 23443585951552 run_lib.py:140] step: 52300, training_loss: 3.85916e-04
I0404 22:33:49.866876 23443585951552 run_lib.py:153] step: 52300, eval_loss: 3.81750e-04
I0404 22:34:11.793929 23443585951552 run_lib.py:140] step: 52350, training_loss: 3.73623e-04
I0404 22:34:33.967473 23443585951552 run_lib.py:140] step: 52400, training_loss: 4.03627e-04
I0404 22:34:34.125552 23443585951552 run_lib.py:153] step: 52400, eval_loss: 4.15397e-04
I0404 22:34:56.181008 23443585951552 run_lib.py:140] step: 52450, training_loss: 4.13004e-04
I0404 22:35:18.137850 23443585951552 run_lib.py:140] step: 52500, training_loss: 4.47086e-04
I0404 22:35:18.320334 23443585951552 run_lib.py:153] step: 52500, eval_loss: 3.35665e-04
I0404 22:35:40.282093 23443585951552 run_lib.py:140] step: 52550, training_loss: 4.14656e-04
I0404 22:36:02.402362 23443585951552 run_lib.py:140] step: 52600, training_loss: 3.91455e-04
I0404 22:36:02.580546 23443585951552 run_lib.py:153] step: 52600, eval_loss: 4.02747e-04
I0404 22:36:24.552738 23443585951552 run_lib.py:140] step: 52650, training_loss: 4.52443e-04
I0404 22:36:46.744657 23443585951552 run_lib.py:140] step: 52700, training_loss: 3.56726e-04
I0404 22:36:46.899804 23443585951552 run_lib.py:153] step: 52700, eval_loss: 4.30909e-04
I0404 22:37:08.974259 23443585951552 run_lib.py:140] step: 52750, training_loss: 3.99030e-04
I0404 22:37:30.612097 23443585951552 run_lib.py:140] step: 52800, training_loss: 3.99199e-04
I0404 22:37:30.773927 23443585951552 run_lib.py:153] step: 52800, eval_loss: 4.05955e-04
I0404 22:37:52.693148 23443585951552 run_lib.py:140] step: 52850, training_loss: 3.96190e-04
I0404 22:38:14.271982 23443585951552 run_lib.py:140] step: 52900, training_loss: 3.95719e-04
I0404 22:38:14.429691 23443585951552 run_lib.py:153] step: 52900, eval_loss: 3.95563e-04
I0404 22:38:36.446249 23443585951552 run_lib.py:140] step: 52950, training_loss: 4.07235e-04
I0404 22:38:58.496975 23443585951552 run_lib.py:140] step: 53000, training_loss: 4.58478e-04
I0404 22:38:58.677401 23443585951552 run_lib.py:153] step: 53000, eval_loss: 4.01297e-04
I0404 22:39:20.337071 23443585951552 run_lib.py:140] step: 53050, training_loss: 3.84773e-04
I0404 22:39:41.982164 23443585951552 run_lib.py:140] step: 53100, training_loss: 3.48741e-04
I0404 22:39:42.145750 23443585951552 run_lib.py:153] step: 53100, eval_loss: 4.23053e-04
I0404 22:40:04.257178 23443585951552 run_lib.py:140] step: 53150, training_loss: 3.94795e-04
I0404 22:40:25.885334 23443585951552 run_lib.py:140] step: 53200, training_loss: 4.16650e-04
I0404 22:40:26.046593 23443585951552 run_lib.py:153] step: 53200, eval_loss: 3.29835e-04
I0404 22:40:48.133867 23443585951552 run_lib.py:140] step: 53250, training_loss: 4.38651e-04
I0404 22:41:10.282436 23443585951552 run_lib.py:140] step: 53300, training_loss: 4.04052e-04
I0404 22:41:10.442167 23443585951552 run_lib.py:153] step: 53300, eval_loss: 4.17159e-04
I0404 22:41:32.228817 23443585951552 run_lib.py:140] step: 53350, training_loss: 3.95012e-04
I0404 22:41:53.742959 23443585951552 run_lib.py:140] step: 53400, training_loss: 4.06126e-04
I0404 22:41:53.904357 23443585951552 run_lib.py:153] step: 53400, eval_loss: 4.20765e-04
I0404 22:42:15.593970 23443585951552 run_lib.py:140] step: 53450, training_loss: 4.51816e-04
I0404 22:42:37.448394 23443585951552 run_lib.py:140] step: 53500, training_loss: 4.09463e-04
I0404 22:42:37.625817 23443585951552 run_lib.py:153] step: 53500, eval_loss: 4.58608e-04
I0404 22:42:59.849440 23443585951552 run_lib.py:140] step: 53550, training_loss: 4.25011e-04
I0404 22:43:21.644836 23443585951552 run_lib.py:140] step: 53600, training_loss: 4.21741e-04
I0404 22:43:21.800059 23443585951552 run_lib.py:153] step: 53600, eval_loss: 3.92925e-04
I0404 22:43:43.514842 23443585951552 run_lib.py:140] step: 53650, training_loss: 3.62430e-04
I0404 22:44:05.657275 23443585951552 run_lib.py:140] step: 53700, training_loss: 4.14318e-04
I0404 22:44:05.819593 23443585951552 run_lib.py:153] step: 53700, eval_loss: 4.47368e-04
I0404 22:44:27.300964 23443585951552 run_lib.py:140] step: 53750, training_loss: 3.61633e-04
I0404 22:44:49.235894 23443585951552 run_lib.py:140] step: 53800, training_loss: 4.29367e-04
I0404 22:44:49.392582 23443585951552 run_lib.py:153] step: 53800, eval_loss: 4.21810e-04
I0404 22:45:11.023013 23443585951552 run_lib.py:140] step: 53850, training_loss: 3.82490e-04
I0404 22:45:32.753204 23443585951552 run_lib.py:140] step: 53900, training_loss: 4.01755e-04
I0404 22:45:32.917008 23443585951552 run_lib.py:153] step: 53900, eval_loss: 4.00805e-04
I0404 22:45:54.865685 23443585951552 run_lib.py:140] step: 53950, training_loss: 4.59607e-04
I0404 22:46:16.773199 23443585951552 run_lib.py:140] step: 54000, training_loss: 4.36250e-04
I0404 22:46:16.975042 23443585951552 run_lib.py:153] step: 54000, eval_loss: 3.38835e-04
I0404 22:46:38.495840 23443585951552 run_lib.py:140] step: 54050, training_loss: 3.70774e-04
I0404 22:47:00.261247 23443585951552 run_lib.py:140] step: 54100, training_loss: 4.17416e-04
I0404 22:47:00.417999 23443585951552 run_lib.py:153] step: 54100, eval_loss: 4.32670e-04
I0404 22:47:22.092617 23443585951552 run_lib.py:140] step: 54150, training_loss: 4.81862e-04
I0404 22:47:43.836632 23443585951552 run_lib.py:140] step: 54200, training_loss: 3.94133e-04
I0404 22:47:43.994967 23443585951552 run_lib.py:153] step: 54200, eval_loss: 4.39468e-04
I0404 22:48:05.616169 23443585951552 run_lib.py:140] step: 54250, training_loss: 3.57871e-04
I0404 22:48:27.492475 23443585951552 run_lib.py:140] step: 54300, training_loss: 4.01821e-04
I0404 22:48:27.654353 23443585951552 run_lib.py:153] step: 54300, eval_loss: 4.27124e-04
I0404 22:48:49.620888 23443585951552 run_lib.py:140] step: 54350, training_loss: 3.95165e-04
I0404 22:49:11.299095 23443585951552 run_lib.py:140] step: 54400, training_loss: 4.50995e-04
I0404 22:49:11.454792 23443585951552 run_lib.py:153] step: 54400, eval_loss: 4.08025e-04
I0404 22:49:33.207718 23443585951552 run_lib.py:140] step: 54450, training_loss: 3.89426e-04
I0404 22:49:55.015248 23443585951552 run_lib.py:140] step: 54500, training_loss: 4.35128e-04
I0404 22:49:55.195903 23443585951552 run_lib.py:153] step: 54500, eval_loss: 3.89088e-04
I0404 22:50:16.728529 23443585951552 run_lib.py:140] step: 54550, training_loss: 4.33545e-04
I0404 22:50:38.459142 23443585951552 run_lib.py:140] step: 54600, training_loss: 4.29197e-04
I0404 22:50:38.622244 23443585951552 run_lib.py:153] step: 54600, eval_loss: 3.75222e-04
I0404 22:51:00.649023 23443585951552 run_lib.py:140] step: 54650, training_loss: 3.97877e-04
I0404 22:51:22.318155 23443585951552 run_lib.py:140] step: 54700, training_loss: 3.93318e-04
I0404 22:51:22.479952 23443585951552 run_lib.py:153] step: 54700, eval_loss: 4.19642e-04
I0404 22:51:44.294155 23443585951552 run_lib.py:140] step: 54750, training_loss: 4.62201e-04
I0404 22:52:06.493140 23443585951552 run_lib.py:140] step: 54800, training_loss: 4.43593e-04
I0404 22:52:06.657943 23443585951552 run_lib.py:153] step: 54800, eval_loss: 4.34058e-04
I0404 22:52:28.646170 23443585951552 run_lib.py:140] step: 54850, training_loss: 4.50653e-04
I0404 22:52:50.500210 23443585951552 run_lib.py:140] step: 54900, training_loss: 4.46010e-04
I0404 22:52:50.663462 23443585951552 run_lib.py:153] step: 54900, eval_loss: 4.47697e-04
I0404 22:53:12.410733 23443585951552 run_lib.py:140] step: 54950, training_loss: 3.21913e-04
I0404 22:53:34.570875 23443585951552 run_lib.py:140] step: 55000, training_loss: 4.16753e-04
I0404 22:53:34.733533 23443585951552 run_lib.py:153] step: 55000, eval_loss: 4.30993e-04
I0404 22:53:56.962423 23443585951552 run_lib.py:140] step: 55050, training_loss: 4.43112e-04
I0404 22:54:18.763739 23443585951552 run_lib.py:140] step: 55100, training_loss: 3.78345e-04
I0404 22:54:18.919015 23443585951552 run_lib.py:153] step: 55100, eval_loss: 3.71998e-04
I0404 22:54:40.673021 23443585951552 run_lib.py:140] step: 55150, training_loss: 3.91187e-04
I0404 22:55:02.826987 23443585951552 run_lib.py:140] step: 55200, training_loss: 4.01139e-04
I0404 22:55:02.983365 23443585951552 run_lib.py:153] step: 55200, eval_loss: 3.91423e-04
I0404 22:55:24.738711 23443585951552 run_lib.py:140] step: 55250, training_loss: 3.72325e-04
I0404 22:55:46.151332 23443585951552 run_lib.py:140] step: 55300, training_loss: 4.02603e-04
I0404 22:55:46.305661 23443585951552 run_lib.py:153] step: 55300, eval_loss: 3.91214e-04
I0404 22:56:08.349115 23443585951552 run_lib.py:140] step: 55350, training_loss: 3.41077e-04
I0404 22:56:29.942558 23443585951552 run_lib.py:140] step: 55400, training_loss: 3.80330e-04
I0404 22:56:30.144007 23443585951552 run_lib.py:153] step: 55400, eval_loss: 3.87886e-04
I0404 22:56:51.585124 23443585951552 run_lib.py:140] step: 55450, training_loss: 4.22555e-04
I0404 22:57:13.317000 23443585951552 run_lib.py:140] step: 55500, training_loss: 4.42192e-04
I0404 22:57:13.485831 23443585951552 run_lib.py:153] step: 55500, eval_loss: 4.79037e-04
I0404 22:57:35.421121 23443585951552 run_lib.py:140] step: 55550, training_loss: 4.40592e-04
I0404 22:57:57.094005 23443585951552 run_lib.py:140] step: 55600, training_loss: 4.10147e-04
I0404 22:57:57.251921 23443585951552 run_lib.py:153] step: 55600, eval_loss: 3.59578e-04
I0404 22:58:18.949797 23443585951552 run_lib.py:140] step: 55650, training_loss: 3.85168e-04
I0404 22:58:40.801181 23443585951552 run_lib.py:140] step: 55700, training_loss: 4.20455e-04
I0404 22:58:40.962156 23443585951552 run_lib.py:153] step: 55700, eval_loss: 4.11986e-04
I0404 22:59:02.890066 23443585951552 run_lib.py:140] step: 55750, training_loss: 4.38944e-04
I0404 22:59:24.592013 23443585951552 run_lib.py:140] step: 55800, training_loss: 3.69578e-04
I0404 22:59:24.746829 23443585951552 run_lib.py:153] step: 55800, eval_loss: 4.09076e-04
I0404 22:59:46.630797 23443585951552 run_lib.py:140] step: 55850, training_loss: 4.04200e-04
I0404 23:00:08.530153 23443585951552 run_lib.py:140] step: 55900, training_loss: 3.32998e-04
I0404 23:00:08.696244 23443585951552 run_lib.py:153] step: 55900, eval_loss: 3.76382e-04
I0404 23:00:30.323920 23443585951552 run_lib.py:140] step: 55950, training_loss: 4.02557e-04
I0404 23:00:52.195487 23443585951552 run_lib.py:140] step: 56000, training_loss: 4.35620e-04
I0404 23:00:52.360643 23443585951552 run_lib.py:153] step: 56000, eval_loss: 3.80245e-04
I0404 23:01:13.875120 23443585951552 run_lib.py:140] step: 56050, training_loss: 4.26169e-04
I0404 23:01:35.379955 23443585951552 run_lib.py:140] step: 56100, training_loss: 3.91606e-04
I0404 23:01:35.539005 23443585951552 run_lib.py:153] step: 56100, eval_loss: 3.97723e-04
I0404 23:01:57.289890 23443585951552 run_lib.py:140] step: 56150, training_loss: 4.37976e-04
I0404 23:02:19.118329 23443585951552 run_lib.py:140] step: 56200, training_loss: 4.42412e-04
I0404 23:02:19.271172 23443585951552 run_lib.py:153] step: 56200, eval_loss: 3.93063e-04
I0404 23:02:40.750962 23443585951552 run_lib.py:140] step: 56250, training_loss: 3.20235e-04
I0404 23:03:02.574658 23443585951552 run_lib.py:140] step: 56300, training_loss: 3.91459e-04
I0404 23:03:02.743193 23443585951552 run_lib.py:153] step: 56300, eval_loss: 3.95417e-04
I0404 23:03:24.727355 23443585951552 run_lib.py:140] step: 56350, training_loss: 3.88106e-04
I0404 23:03:46.559058 23443585951552 run_lib.py:140] step: 56400, training_loss: 3.70756e-04
I0404 23:03:46.723069 23443585951552 run_lib.py:153] step: 56400, eval_loss: 4.08065e-04
I0404 23:04:09.095215 23443585951552 run_lib.py:140] step: 56450, training_loss: 4.07101e-04
I0404 23:04:31.409756 23443585951552 run_lib.py:140] step: 56500, training_loss: 3.71114e-04
I0404 23:04:31.574996 23443585951552 run_lib.py:153] step: 56500, eval_loss: 4.38645e-04
I0404 23:04:53.997614 23443585951552 run_lib.py:140] step: 56550, training_loss: 3.97600e-04
I0404 23:05:16.688905 23443585951552 run_lib.py:140] step: 56600, training_loss: 3.50212e-04
I0404 23:05:16.855782 23443585951552 run_lib.py:153] step: 56600, eval_loss: 3.68497e-04
I0404 23:05:39.347763 23443585951552 run_lib.py:140] step: 56650, training_loss: 4.02322e-04
I0404 23:06:02.067362 23443585951552 run_lib.py:140] step: 56700, training_loss: 4.61187e-04
I0404 23:06:02.228513 23443585951552 run_lib.py:153] step: 56700, eval_loss: 4.47162e-04
I0404 23:06:24.812786 23443585951552 run_lib.py:140] step: 56750, training_loss: 4.62160e-04
I0404 23:06:47.033447 23443585951552 run_lib.py:140] step: 56800, training_loss: 3.98028e-04
I0404 23:06:47.201955 23443585951552 run_lib.py:153] step: 56800, eval_loss: 3.85354e-04
I0404 23:07:09.702003 23443585951552 run_lib.py:140] step: 56850, training_loss: 3.79997e-04
I0404 23:07:32.118607 23443585951552 run_lib.py:140] step: 56900, training_loss: 3.56011e-04
I0404 23:07:32.292894 23443585951552 run_lib.py:153] step: 56900, eval_loss: 4.16307e-04
I0404 23:07:54.791246 23443585951552 run_lib.py:140] step: 56950, training_loss: 4.11545e-04
I0404 23:08:17.453392 23443585951552 run_lib.py:140] step: 57000, training_loss: 3.72980e-04
I0404 23:08:17.690267 23443585951552 run_lib.py:153] step: 57000, eval_loss: 3.63482e-04
I0404 23:08:40.309721 23443585951552 run_lib.py:140] step: 57050, training_loss: 3.49338e-04
I0404 23:09:02.961644 23443585951552 run_lib.py:140] step: 57100, training_loss: 4.08510e-04
I0404 23:09:03.124689 23443585951552 run_lib.py:153] step: 57100, eval_loss: 3.71140e-04
I0404 23:09:25.433348 23443585951552 run_lib.py:140] step: 57150, training_loss: 4.54462e-04
I0404 23:09:47.887738 23443585951552 run_lib.py:140] step: 57200, training_loss: 4.32866e-04
I0404 23:09:48.061584 23443585951552 run_lib.py:153] step: 57200, eval_loss: 3.78085e-04
I0404 23:10:10.502777 23443585951552 run_lib.py:140] step: 57250, training_loss: 4.42396e-04
I0404 23:10:32.722737 23443585951552 run_lib.py:140] step: 57300, training_loss: 3.58634e-04
I0404 23:10:32.879998 23443585951552 run_lib.py:153] step: 57300, eval_loss: 4.10163e-04
I0404 23:10:55.445318 23443585951552 run_lib.py:140] step: 57350, training_loss: 4.01791e-04
I0404 23:11:18.048316 23443585951552 run_lib.py:140] step: 57400, training_loss: 4.67196e-04
I0404 23:11:18.235482 23443585951552 run_lib.py:153] step: 57400, eval_loss: 4.03152e-04
I0404 23:11:40.494590 23443585951552 run_lib.py:140] step: 57450, training_loss: 3.87685e-04
I0404 23:12:02.882580 23443585951552 run_lib.py:140] step: 57500, training_loss: 3.73935e-04
I0404 23:12:03.050232 23443585951552 run_lib.py:153] step: 57500, eval_loss: 3.07656e-04
I0404 23:12:25.716226 23443585951552 run_lib.py:140] step: 57550, training_loss: 4.13032e-04
I0404 23:12:48.115648 23443585951552 run_lib.py:140] step: 57600, training_loss: 4.35287e-04
I0404 23:12:48.283293 23443585951552 run_lib.py:153] step: 57600, eval_loss: 3.78362e-04
I0404 23:13:10.662576 23443585951552 run_lib.py:140] step: 57650, training_loss: 3.72904e-04
I0404 23:13:33.005513 23443585951552 run_lib.py:140] step: 57700, training_loss: 4.38637e-04
I0404 23:13:33.161785 23443585951552 run_lib.py:153] step: 57700, eval_loss: 3.90880e-04
I0404 23:13:55.728585 23443585951552 run_lib.py:140] step: 57750, training_loss: 4.33274e-04
I0404 23:14:18.222530 23443585951552 run_lib.py:140] step: 57800, training_loss: 3.87058e-04
I0404 23:14:18.415084 23443585951552 run_lib.py:153] step: 57800, eval_loss: 3.46805e-04
I0404 23:14:40.557856 23443585951552 run_lib.py:140] step: 57850, training_loss: 3.85674e-04
I0404 23:15:03.041913 23443585951552 run_lib.py:140] step: 57900, training_loss: 4.02902e-04
I0404 23:15:03.215387 23443585951552 run_lib.py:153] step: 57900, eval_loss: 3.52008e-04
I0404 23:15:25.411425 23443585951552 run_lib.py:140] step: 57950, training_loss: 4.18620e-04
I0404 23:15:47.697433 23443585951552 run_lib.py:140] step: 58000, training_loss: 4.43501e-04
I0404 23:15:47.855910 23443585951552 run_lib.py:153] step: 58000, eval_loss: 4.30084e-04
I0404 23:16:10.083189 23443585951552 run_lib.py:140] step: 58050, training_loss: 4.59748e-04
I0404 23:16:32.771415 23443585951552 run_lib.py:140] step: 58100, training_loss: 4.17898e-04
I0404 23:16:32.938078 23443585951552 run_lib.py:153] step: 58100, eval_loss: 4.08338e-04
I0404 23:16:55.193953 23443585951552 run_lib.py:140] step: 58150, training_loss: 4.28245e-04
I0404 23:17:17.829674 23443585951552 run_lib.py:140] step: 58200, training_loss: 4.13486e-04
I0404 23:17:17.998968 23443585951552 run_lib.py:153] step: 58200, eval_loss: 3.87636e-04
I0404 23:17:39.898809 23443585951552 run_lib.py:140] step: 58250, training_loss: 4.08572e-04
I0404 23:18:02.372162 23443585951552 run_lib.py:140] step: 58300, training_loss: 3.71640e-04
I0404 23:18:02.548199 23443585951552 run_lib.py:153] step: 58300, eval_loss: 3.88066e-04
I0404 23:18:25.139316 23443585951552 run_lib.py:140] step: 58350, training_loss: 3.97243e-04
I0404 23:18:47.305472 23443585951552 run_lib.py:140] step: 58400, training_loss: 3.87153e-04
I0404 23:18:47.475803 23443585951552 run_lib.py:153] step: 58400, eval_loss: 3.56445e-04
I0404 23:19:09.790173 23443585951552 run_lib.py:140] step: 58450, training_loss: 3.97818e-04
I0404 23:19:32.098414 23443585951552 run_lib.py:140] step: 58500, training_loss: 3.79964e-04
I0404 23:19:32.266109 23443585951552 run_lib.py:153] step: 58500, eval_loss: 3.74689e-04
I0404 23:19:54.823138 23443585951552 run_lib.py:140] step: 58550, training_loss: 3.98269e-04
I0404 23:20:17.191603 23443585951552 run_lib.py:140] step: 58600, training_loss: 4.27816e-04
I0404 23:20:17.358878 23443585951552 run_lib.py:153] step: 58600, eval_loss: 3.81022e-04
I0404 23:20:39.702850 23443585951552 run_lib.py:140] step: 58650, training_loss: 4.18482e-04
I0404 23:21:02.039981 23443585951552 run_lib.py:140] step: 58700, training_loss: 3.87985e-04
I0404 23:21:02.212708 23443585951552 run_lib.py:153] step: 58700, eval_loss: 4.24725e-04
I0404 23:21:24.832913 23443585951552 run_lib.py:140] step: 58750, training_loss: 4.41339e-04
I0404 23:21:47.159269 23443585951552 run_lib.py:140] step: 58800, training_loss: 4.54367e-04
I0404 23:21:47.326621 23443585951552 run_lib.py:153] step: 58800, eval_loss: 4.25677e-04
I0404 23:22:09.995247 23443585951552 run_lib.py:140] step: 58850, training_loss: 3.89699e-04
I0404 23:22:32.183052 23443585951552 run_lib.py:140] step: 58900, training_loss: 4.19397e-04
I0404 23:22:32.355129 23443585951552 run_lib.py:153] step: 58900, eval_loss: 4.41834e-04
I0404 23:22:54.823348 23443585951552 run_lib.py:140] step: 58950, training_loss: 4.58436e-04
I0404 23:23:17.345146 23443585951552 run_lib.py:140] step: 59000, training_loss: 4.33365e-04
I0404 23:23:17.510267 23443585951552 run_lib.py:153] step: 59000, eval_loss: 3.50743e-04
I0404 23:23:40.247544 23443585951552 run_lib.py:140] step: 59050, training_loss: 4.38969e-04
I0404 23:24:02.293805 23443585951552 run_lib.py:140] step: 59100, training_loss: 4.74431e-04
I0404 23:24:02.448400 23443585951552 run_lib.py:153] step: 59100, eval_loss: 3.77318e-04
I0404 23:24:24.462633 23443585951552 run_lib.py:140] step: 59150, training_loss: 4.11128e-04
I0404 23:24:46.814898 23443585951552 run_lib.py:140] step: 59200, training_loss: 3.68662e-04
I0404 23:24:46.987516 23443585951552 run_lib.py:153] step: 59200, eval_loss: 4.42508e-04
I0404 23:25:09.037836 23443585951552 run_lib.py:140] step: 59250, training_loss: 3.80127e-04
I0404 23:25:31.400852 23443585951552 run_lib.py:140] step: 59300, training_loss: 4.07762e-04
I0404 23:25:31.567988 23443585951552 run_lib.py:153] step: 59300, eval_loss: 4.02092e-04
I0404 23:25:53.938550 23443585951552 run_lib.py:140] step: 59350, training_loss: 4.47698e-04
I0404 23:26:16.287380 23443585951552 run_lib.py:140] step: 59400, training_loss: 3.77878e-04
I0404 23:26:16.452460 23443585951552 run_lib.py:153] step: 59400, eval_loss: 4.56370e-04
I0404 23:26:38.955112 23443585951552 run_lib.py:140] step: 59450, training_loss: 3.61043e-04
I0404 23:27:01.287785 23443585951552 run_lib.py:140] step: 59500, training_loss: 4.25579e-04
I0404 23:27:01.448861 23443585951552 run_lib.py:153] step: 59500, eval_loss: 4.05141e-04
I0404 23:27:23.908212 23443585951552 run_lib.py:140] step: 59550, training_loss: 4.13294e-04
I0404 23:27:46.329016 23443585951552 run_lib.py:140] step: 59600, training_loss: 4.32252e-04
I0404 23:27:46.518432 23443585951552 run_lib.py:153] step: 59600, eval_loss: 4.42274e-04
I0404 23:28:08.823115 23443585951552 run_lib.py:140] step: 59650, training_loss: 4.29873e-04
I0404 23:28:31.345799 23443585951552 run_lib.py:140] step: 59700, training_loss: 4.02151e-04
I0404 23:28:31.538484 23443585951552 run_lib.py:153] step: 59700, eval_loss: 4.54303e-04
I0404 23:28:54.015218 23443585951552 run_lib.py:140] step: 59750, training_loss: 4.93938e-04
I0404 23:29:16.513002 23443585951552 run_lib.py:140] step: 59800, training_loss: 3.48498e-04
I0404 23:29:16.678033 23443585951552 run_lib.py:153] step: 59800, eval_loss: 3.45297e-04
I0404 23:29:39.081762 23443585951552 run_lib.py:140] step: 59850, training_loss: 3.80146e-04
I0404 23:30:01.421770 23443585951552 run_lib.py:140] step: 59900, training_loss: 4.54268e-04
I0404 23:30:01.585126 23443585951552 run_lib.py:153] step: 59900, eval_loss: 4.48367e-04
I0404 23:30:23.790262 23443585951552 run_lib.py:140] step: 59950, training_loss: 4.01880e-04
I0404 23:30:45.793694 23443585951552 run_lib.py:140] step: 60000, training_loss: 3.79140e-04
I0404 23:30:46.722066 23443585951552 run_lib.py:153] step: 60000, eval_loss: 4.30826e-04
I0404 23:31:08.698824 23443585951552 run_lib.py:140] step: 60050, training_loss: 4.34197e-04
I0404 23:31:30.362893 23443585951552 run_lib.py:140] step: 60100, training_loss: 3.69191e-04
I0404 23:31:30.522980 23443585951552 run_lib.py:153] step: 60100, eval_loss: 4.36493e-04
I0404 23:31:52.020246 23443585951552 run_lib.py:140] step: 60150, training_loss: 4.38009e-04
I0404 23:32:13.334286 23443585951552 run_lib.py:140] step: 60200, training_loss: 4.18079e-04
I0404 23:32:13.510246 23443585951552 run_lib.py:153] step: 60200, eval_loss: 4.07035e-04
I0404 23:32:34.736919 23443585951552 run_lib.py:140] step: 60250, training_loss: 3.71105e-04
I0404 23:32:56.575523 23443585951552 run_lib.py:140] step: 60300, training_loss: 4.09925e-04
I0404 23:32:56.743031 23443585951552 run_lib.py:153] step: 60300, eval_loss: 4.01656e-04
I0404 23:33:18.550813 23443585951552 run_lib.py:140] step: 60350, training_loss: 3.86220e-04
I0404 23:33:40.654030 23443585951552 run_lib.py:140] step: 60400, training_loss: 3.64274e-04
I0404 23:33:40.822008 23443585951552 run_lib.py:153] step: 60400, eval_loss: 4.31053e-04
I0404 23:34:02.616442 23443585951552 run_lib.py:140] step: 60450, training_loss: 3.89764e-04
I0404 23:34:24.255217 23443585951552 run_lib.py:140] step: 60500, training_loss: 3.45879e-04
I0404 23:34:24.413298 23443585951552 run_lib.py:153] step: 60500, eval_loss: 3.70184e-04
I0404 23:34:46.340972 23443585951552 run_lib.py:140] step: 60550, training_loss: 4.06850e-04
I0404 23:35:07.950242 23443585951552 run_lib.py:140] step: 60600, training_loss: 3.55685e-04
I0404 23:35:08.129524 23443585951552 run_lib.py:153] step: 60600, eval_loss: 3.60462e-04
I0404 23:35:29.884351 23443585951552 run_lib.py:140] step: 60650, training_loss: 4.64587e-04
I0404 23:35:51.674152 23443585951552 run_lib.py:140] step: 60700, training_loss: 3.80216e-04
I0404 23:35:51.854163 23443585951552 run_lib.py:153] step: 60700, eval_loss: 4.05406e-04
I0404 23:36:13.755983 23443585951552 run_lib.py:140] step: 60750, training_loss: 3.80457e-04
I0404 23:36:35.599735 23443585951552 run_lib.py:140] step: 60800, training_loss: 3.68886e-04
I0404 23:36:35.774975 23443585951552 run_lib.py:153] step: 60800, eval_loss: 3.87588e-04
I0404 23:36:57.543337 23443585951552 run_lib.py:140] step: 60850, training_loss: 4.30803e-04
I0404 23:37:19.384869 23443585951552 run_lib.py:140] step: 60900, training_loss: 3.84573e-04
I0404 23:37:19.543703 23443585951552 run_lib.py:153] step: 60900, eval_loss: 4.22775e-04
I0404 23:37:41.211945 23443585951552 run_lib.py:140] step: 60950, training_loss: 4.07358e-04
I0404 23:38:02.969508 23443585951552 run_lib.py:140] step: 61000, training_loss: 3.31824e-04
I0404 23:38:03.144488 23443585951552 run_lib.py:153] step: 61000, eval_loss: 4.19916e-04
I0404 23:38:25.298490 23443585951552 run_lib.py:140] step: 61050, training_loss: 4.48070e-04
I0404 23:38:47.153125 23443585951552 run_lib.py:140] step: 61100, training_loss: 4.58017e-04
I0404 23:38:47.360214 23443585951552 run_lib.py:153] step: 61100, eval_loss: 4.22067e-04
I0404 23:39:09.555949 23443585951552 run_lib.py:140] step: 61150, training_loss: 4.00689e-04
I0404 23:39:31.695604 23443585951552 run_lib.py:140] step: 61200, training_loss: 4.26725e-04
I0404 23:39:31.868314 23443585951552 run_lib.py:153] step: 61200, eval_loss: 4.35187e-04
I0404 23:39:54.005954 23443585951552 run_lib.py:140] step: 61250, training_loss: 3.66817e-04
I0404 23:40:15.834657 23443585951552 run_lib.py:140] step: 61300, training_loss: 3.89442e-04
I0404 23:40:15.998028 23443585951552 run_lib.py:153] step: 61300, eval_loss: 4.43340e-04
I0404 23:40:37.790979 23443585951552 run_lib.py:140] step: 61350, training_loss: 3.95927e-04
I0404 23:40:59.667379 23443585951552 run_lib.py:140] step: 61400, training_loss: 3.47436e-04
I0404 23:40:59.827726 23443585951552 run_lib.py:153] step: 61400, eval_loss: 4.34084e-04
I0404 23:41:21.867025 23443585951552 run_lib.py:140] step: 61450, training_loss: 4.07747e-04
I0404 23:41:43.741844 23443585951552 run_lib.py:140] step: 61500, training_loss: 4.10933e-04
I0404 23:41:43.899143 23443585951552 run_lib.py:153] step: 61500, eval_loss: 4.17878e-04
I0404 23:42:06.063218 23443585951552 run_lib.py:140] step: 61550, training_loss: 4.05893e-04
I0404 23:42:27.655321 23443585951552 run_lib.py:140] step: 61600, training_loss: 3.81023e-04
I0404 23:42:27.820959 23443585951552 run_lib.py:153] step: 61600, eval_loss: 4.27375e-04
I0404 23:42:49.957816 23443585951552 run_lib.py:140] step: 61650, training_loss: 3.83882e-04
I0404 23:43:12.058689 23443585951552 run_lib.py:140] step: 61700, training_loss: 4.62038e-04
I0404 23:43:12.226147 23443585951552 run_lib.py:153] step: 61700, eval_loss: 4.19557e-04
I0404 23:43:34.337586 23443585951552 run_lib.py:140] step: 61750, training_loss: 4.34206e-04
I0404 23:43:55.745114 23443585951552 run_lib.py:140] step: 61800, training_loss: 4.18014e-04
I0404 23:43:55.913076 23443585951552 run_lib.py:153] step: 61800, eval_loss: 3.93046e-04
I0404 23:44:17.686613 23443585951552 run_lib.py:140] step: 61850, training_loss: 3.50380e-04
I0404 23:44:39.818022 23443585951552 run_lib.py:140] step: 61900, training_loss: 3.92575e-04
I0404 23:44:39.981316 23443585951552 run_lib.py:153] step: 61900, eval_loss: 4.00270e-04
I0404 23:45:01.999843 23443585951552 run_lib.py:140] step: 61950, training_loss: 4.05653e-04
I0404 23:45:23.919326 23443585951552 run_lib.py:140] step: 62000, training_loss: 3.78051e-04
I0404 23:45:24.076199 23443585951552 run_lib.py:153] step: 62000, eval_loss: 4.32635e-04
I0404 23:45:46.212582 23443585951552 run_lib.py:140] step: 62050, training_loss: 4.29024e-04
I0404 23:46:08.261741 23443585951552 run_lib.py:140] step: 62100, training_loss: 4.61493e-04
I0404 23:46:08.440640 23443585951552 run_lib.py:153] step: 62100, eval_loss: 4.17121e-04
I0404 23:46:30.457542 23443585951552 run_lib.py:140] step: 62150, training_loss: 4.64389e-04
I0404 23:46:52.408552 23443585951552 run_lib.py:140] step: 62200, training_loss: 4.02157e-04
I0404 23:46:52.577968 23443585951552 run_lib.py:153] step: 62200, eval_loss: 3.78001e-04
I0404 23:47:14.640067 23443585951552 run_lib.py:140] step: 62250, training_loss: 4.20545e-04
I0404 23:47:36.359707 23443585951552 run_lib.py:140] step: 62300, training_loss: 3.83734e-04
I0404 23:47:36.525737 23443585951552 run_lib.py:153] step: 62300, eval_loss: 3.80796e-04
I0404 23:47:58.645012 23443585951552 run_lib.py:140] step: 62350, training_loss: 3.63286e-04
I0404 23:48:20.072153 23443585951552 run_lib.py:140] step: 62400, training_loss: 3.82229e-04
I0404 23:48:20.228468 23443585951552 run_lib.py:153] step: 62400, eval_loss: 3.68480e-04
I0404 23:48:41.811639 23443585951552 run_lib.py:140] step: 62450, training_loss: 4.63933e-04
I0404 23:49:03.382828 23443585951552 run_lib.py:140] step: 62500, training_loss: 4.08026e-04
I0404 23:49:03.560221 23443585951552 run_lib.py:153] step: 62500, eval_loss: 4.04629e-04
I0404 23:49:25.145407 23443585951552 run_lib.py:140] step: 62550, training_loss: 3.82905e-04
I0404 23:49:46.402848 23443585951552 run_lib.py:140] step: 62600, training_loss: 4.75426e-04
I0404 23:49:46.563069 23443585951552 run_lib.py:153] step: 62600, eval_loss: 3.96804e-04
I0404 23:50:07.598706 23443585951552 run_lib.py:140] step: 62650, training_loss: 3.59043e-04
I0404 23:50:28.824826 23443585951552 run_lib.py:140] step: 62700, training_loss: 3.53231e-04
I0404 23:50:28.983235 23443585951552 run_lib.py:153] step: 62700, eval_loss: 3.32465e-04
I0404 23:50:51.306286 23443585951552 run_lib.py:140] step: 62750, training_loss: 4.06094e-04
I0404 23:51:13.127768 23443585951552 run_lib.py:140] step: 62800, training_loss: 3.75313e-04
I0404 23:51:13.289993 23443585951552 run_lib.py:153] step: 62800, eval_loss: 3.76809e-04
I0404 23:51:34.942577 23443585951552 run_lib.py:140] step: 62850, training_loss: 3.90249e-04
I0404 23:51:56.740357 23443585951552 run_lib.py:140] step: 62900, training_loss: 4.53486e-04
I0404 23:51:56.907239 23443585951552 run_lib.py:153] step: 62900, eval_loss: 4.07631e-04
I0404 23:52:18.932734 23443585951552 run_lib.py:140] step: 62950, training_loss: 3.64031e-04
I0404 23:52:40.772970 23443585951552 run_lib.py:140] step: 63000, training_loss: 4.28519e-04
I0404 23:52:40.935087 23443585951552 run_lib.py:153] step: 63000, eval_loss: 3.84483e-04
I0404 23:53:02.910213 23443585951552 run_lib.py:140] step: 63050, training_loss: 4.26964e-04
I0404 23:53:24.760161 23443585951552 run_lib.py:140] step: 63100, training_loss: 4.20460e-04
I0404 23:53:24.928626 23443585951552 run_lib.py:153] step: 63100, eval_loss: 4.16509e-04
I0404 23:53:46.743952 23443585951552 run_lib.py:140] step: 63150, training_loss: 4.35032e-04
I0404 23:54:08.827419 23443585951552 run_lib.py:140] step: 63200, training_loss: 3.76148e-04
I0404 23:54:08.990220 23443585951552 run_lib.py:153] step: 63200, eval_loss: 3.76148e-04
I0404 23:54:30.933850 23443585951552 run_lib.py:140] step: 63250, training_loss: 4.09570e-04
I0404 23:54:52.485523 23443585951552 run_lib.py:140] step: 63300, training_loss: 4.29972e-04
I0404 23:54:52.646973 23443585951552 run_lib.py:153] step: 63300, eval_loss: 3.67342e-04
I0404 23:55:14.801204 23443585951552 run_lib.py:140] step: 63350, training_loss: 4.68805e-04
I0404 23:55:36.501253 23443585951552 run_lib.py:140] step: 63400, training_loss: 4.15668e-04
I0404 23:55:36.665026 23443585951552 run_lib.py:153] step: 63400, eval_loss: 4.20524e-04
I0404 23:55:58.417927 23443585951552 run_lib.py:140] step: 63450, training_loss: 3.78334e-04
I0404 23:56:20.246866 23443585951552 run_lib.py:140] step: 63500, training_loss: 4.91807e-04
I0404 23:56:20.418421 23443585951552 run_lib.py:153] step: 63500, eval_loss: 4.30639e-04
I0404 23:56:41.925961 23443585951552 run_lib.py:140] step: 63550, training_loss: 4.00517e-04
I0404 23:57:03.826444 23443585951552 run_lib.py:140] step: 63600, training_loss: 3.53252e-04
I0404 23:57:03.995942 23443585951552 run_lib.py:153] step: 63600, eval_loss: 3.62242e-04
I0404 23:57:25.697980 23443585951552 run_lib.py:140] step: 63650, training_loss: 4.32036e-04
I0404 23:57:47.692327 23443585951552 run_lib.py:140] step: 63700, training_loss: 4.05312e-04
I0404 23:57:47.853908 23443585951552 run_lib.py:153] step: 63700, eval_loss: 3.84517e-04
I0404 23:58:09.698452 23443585951552 run_lib.py:140] step: 63750, training_loss: 3.68447e-04
I0404 23:58:31.780567 23443585951552 run_lib.py:140] step: 63800, training_loss: 4.04297e-04
I0404 23:58:31.939134 23443585951552 run_lib.py:153] step: 63800, eval_loss: 4.25400e-04
I0404 23:58:54.144518 23443585951552 run_lib.py:140] step: 63850, training_loss: 3.52737e-04
I0404 23:59:16.019401 23443585951552 run_lib.py:140] step: 63900, training_loss: 3.83067e-04
I0404 23:59:16.186021 23443585951552 run_lib.py:153] step: 63900, eval_loss: 4.13961e-04
I0404 23:59:38.080476 23443585951552 run_lib.py:140] step: 63950, training_loss: 3.97941e-04
I0405 00:00:00.031648 23443585951552 run_lib.py:140] step: 64000, training_loss: 4.27052e-04
I0405 00:00:00.207959 23443585951552 run_lib.py:153] step: 64000, eval_loss: 4.07122e-04
I0405 00:00:21.825431 23443585951552 run_lib.py:140] step: 64050, training_loss: 4.01449e-04
I0405 00:00:43.693044 23443585951552 run_lib.py:140] step: 64100, training_loss: 4.57264e-04
I0405 00:00:43.857883 23443585951552 run_lib.py:153] step: 64100, eval_loss: 4.01385e-04
I0405 00:01:05.830060 23443585951552 run_lib.py:140] step: 64150, training_loss: 3.99690e-04
I0405 00:01:27.615813 23443585951552 run_lib.py:140] step: 64200, training_loss: 4.54494e-04
I0405 00:01:27.775182 23443585951552 run_lib.py:153] step: 64200, eval_loss: 3.60958e-04
I0405 00:01:49.491174 23443585951552 run_lib.py:140] step: 64250, training_loss: 4.36270e-04
I0405 00:02:11.387209 23443585951552 run_lib.py:140] step: 64300, training_loss: 3.86932e-04
I0405 00:02:11.548206 23443585951552 run_lib.py:153] step: 64300, eval_loss: 3.84008e-04
I0405 00:02:33.794201 23443585951552 run_lib.py:140] step: 64350, training_loss: 3.59346e-04
I0405 00:02:55.881541 23443585951552 run_lib.py:140] step: 64400, training_loss: 4.08359e-04
I0405 00:02:56.048221 23443585951552 run_lib.py:153] step: 64400, eval_loss: 3.88165e-04
I0405 00:03:17.913138 23443585951552 run_lib.py:140] step: 64450, training_loss: 3.78214e-04
I0405 00:03:39.913534 23443585951552 run_lib.py:140] step: 64500, training_loss: 4.14705e-04
I0405 00:03:40.079157 23443585951552 run_lib.py:153] step: 64500, eval_loss: 3.99333e-04
I0405 00:04:01.892194 23443585951552 run_lib.py:140] step: 64550, training_loss: 3.98664e-04
I0405 00:04:21.078553 23443585951552 run_lib.py:140] step: 64600, training_loss: 4.12972e-04
I0405 00:04:21.236064 23443585951552 run_lib.py:153] step: 64600, eval_loss: 4.19240e-04
I0405 00:04:38.765307 23443585951552 run_lib.py:140] step: 64650, training_loss: 4.11112e-04
I0405 00:04:56.402884 23443585951552 run_lib.py:140] step: 64700, training_loss: 4.39876e-04
I0405 00:04:56.561912 23443585951552 run_lib.py:153] step: 64700, eval_loss: 3.83619e-04
I0405 00:05:14.235603 23443585951552 run_lib.py:140] step: 64750, training_loss: 4.51663e-04
I0405 00:05:32.000281 23443585951552 run_lib.py:140] step: 64800, training_loss: 4.18902e-04
I0405 00:05:32.159081 23443585951552 run_lib.py:153] step: 64800, eval_loss: 4.18372e-04
I0405 00:05:49.682538 23443585951552 run_lib.py:140] step: 64850, training_loss: 4.24090e-04
I0405 00:06:07.196606 23443585951552 run_lib.py:140] step: 64900, training_loss: 3.86522e-04
I0405 00:06:07.362073 23443585951552 run_lib.py:153] step: 64900, eval_loss: 3.65934e-04
I0405 00:06:25.144978 23443585951552 run_lib.py:140] step: 64950, training_loss: 3.53688e-04
I0405 00:06:42.780811 23443585951552 run_lib.py:140] step: 65000, training_loss: 3.63900e-04
I0405 00:06:42.937068 23443585951552 run_lib.py:153] step: 65000, eval_loss: 4.10796e-04
I0405 00:07:00.519970 23443585951552 run_lib.py:140] step: 65050, training_loss: 4.16786e-04
I0405 00:07:18.274946 23443585951552 run_lib.py:140] step: 65100, training_loss: 4.04721e-04
I0405 00:07:18.429754 23443585951552 run_lib.py:153] step: 65100, eval_loss: 4.33047e-04
I0405 00:07:35.944386 23443585951552 run_lib.py:140] step: 65150, training_loss: 4.18560e-04
I0405 00:07:53.487804 23443585951552 run_lib.py:140] step: 65200, training_loss: 4.86951e-04
I0405 00:07:53.644189 23443585951552 run_lib.py:153] step: 65200, eval_loss: 3.94722e-04
I0405 00:08:11.331097 23443585951552 run_lib.py:140] step: 65250, training_loss: 4.25382e-04
I0405 00:08:28.903723 23443585951552 run_lib.py:140] step: 65300, training_loss: 3.99564e-04
I0405 00:08:29.062386 23443585951552 run_lib.py:153] step: 65300, eval_loss: 4.21936e-04
I0405 00:08:46.666239 23443585951552 run_lib.py:140] step: 65350, training_loss: 3.21053e-04
I0405 00:09:04.213665 23443585951552 run_lib.py:140] step: 65400, training_loss: 4.04393e-04
I0405 00:09:04.374256 23443585951552 run_lib.py:153] step: 65400, eval_loss: 3.92634e-04
I0405 00:09:22.075634 23443585951552 run_lib.py:140] step: 65450, training_loss: 4.27528e-04
I0405 00:09:39.698228 23443585951552 run_lib.py:140] step: 65500, training_loss: 4.04914e-04
I0405 00:09:39.866823 23443585951552 run_lib.py:153] step: 65500, eval_loss: 4.42291e-04
I0405 00:09:57.508719 23443585951552 run_lib.py:140] step: 65550, training_loss: 4.21851e-04
I0405 00:10:15.108270 23443585951552 run_lib.py:140] step: 65600, training_loss: 4.06140e-04
I0405 00:10:15.262668 23443585951552 run_lib.py:153] step: 65600, eval_loss: 3.50664e-04
I0405 00:10:33.056089 23443585951552 run_lib.py:140] step: 65650, training_loss: 4.32282e-04
I0405 00:10:50.757332 23443585951552 run_lib.py:140] step: 65700, training_loss: 3.66283e-04
I0405 00:10:50.917390 23443585951552 run_lib.py:153] step: 65700, eval_loss: 4.16425e-04
I0405 00:11:08.780607 23443585951552 run_lib.py:140] step: 65750, training_loss: 3.96991e-04
I0405 00:11:31.037636 23443585951552 run_lib.py:140] step: 65800, training_loss: 4.18268e-04
I0405 00:11:31.222448 23443585951552 run_lib.py:153] step: 65800, eval_loss: 3.74712e-04
I0405 00:11:52.605852 23443585951552 run_lib.py:140] step: 65850, training_loss: 3.99022e-04
I0405 00:12:14.749521 23443585951552 run_lib.py:140] step: 65900, training_loss: 3.87096e-04
I0405 00:12:14.931375 23443585951552 run_lib.py:153] step: 65900, eval_loss: 4.16473e-04
I0405 00:12:36.935939 23443585951552 run_lib.py:140] step: 65950, training_loss: 3.90276e-04
I0405 00:12:58.827598 23443585951552 run_lib.py:140] step: 66000, training_loss: 4.86530e-04
I0405 00:12:58.988794 23443585951552 run_lib.py:153] step: 66000, eval_loss: 4.19379e-04
I0405 00:13:20.936982 23443585951552 run_lib.py:140] step: 66050, training_loss: 4.22651e-04
I0405 00:13:42.898123 23443585951552 run_lib.py:140] step: 66100, training_loss: 4.87018e-04
I0405 00:13:43.065969 23443585951552 run_lib.py:153] step: 66100, eval_loss: 4.21575e-04
I0405 00:14:05.313337 23443585951552 run_lib.py:140] step: 66150, training_loss: 3.70970e-04
I0405 00:14:28.039167 23443585951552 run_lib.py:140] step: 66200, training_loss: 4.04103e-04
I0405 00:14:28.200345 23443585951552 run_lib.py:153] step: 66200, eval_loss: 3.92555e-04
I0405 00:14:50.690041 23443585951552 run_lib.py:140] step: 66250, training_loss: 4.50528e-04
I0405 00:15:13.086980 23443585951552 run_lib.py:140] step: 66300, training_loss: 4.38227e-04
I0405 00:15:13.258364 23443585951552 run_lib.py:153] step: 66300, eval_loss: 4.04610e-04
I0405 00:15:35.600812 23443585951552 run_lib.py:140] step: 66350, training_loss: 3.96660e-04
I0405 00:15:57.879772 23443585951552 run_lib.py:140] step: 66400, training_loss: 4.09938e-04
I0405 00:15:58.047426 23443585951552 run_lib.py:153] step: 66400, eval_loss: 4.01744e-04
I0405 00:16:20.252257 23443585951552 run_lib.py:140] step: 66450, training_loss: 3.98689e-04
I0405 00:16:42.571046 23443585951552 run_lib.py:140] step: 66500, training_loss: 4.39800e-04
I0405 00:16:42.731573 23443585951552 run_lib.py:153] step: 66500, eval_loss: 3.89912e-04
I0405 00:17:04.738128 23443585951552 run_lib.py:140] step: 66550, training_loss: 3.22443e-04
I0405 00:17:26.499902 23443585951552 run_lib.py:140] step: 66600, training_loss: 4.00177e-04
I0405 00:17:26.658715 23443585951552 run_lib.py:153] step: 66600, eval_loss: 4.26567e-04
I0405 00:17:48.640352 23443585951552 run_lib.py:140] step: 66650, training_loss: 4.50922e-04
I0405 00:18:10.356972 23443585951552 run_lib.py:140] step: 66700, training_loss: 4.58007e-04
I0405 00:18:10.526171 23443585951552 run_lib.py:153] step: 66700, eval_loss: 4.36507e-04
I0405 00:18:32.230219 23443585951552 run_lib.py:140] step: 66750, training_loss: 3.87728e-04
I0405 00:18:54.380920 23443585951552 run_lib.py:140] step: 66800, training_loss: 4.77091e-04
I0405 00:18:54.549982 23443585951552 run_lib.py:153] step: 66800, eval_loss: 4.48300e-04
I0405 00:19:16.807928 23443585951552 run_lib.py:140] step: 66850, training_loss: 4.02896e-04
I0405 00:19:39.534910 23443585951552 run_lib.py:140] step: 66900, training_loss: 4.55600e-04
I0405 00:19:39.727422 23443585951552 run_lib.py:153] step: 66900, eval_loss: 4.32880e-04
I0405 00:20:01.793727 23443585951552 run_lib.py:140] step: 66950, training_loss: 4.25133e-04
I0405 00:20:24.121913 23443585951552 run_lib.py:140] step: 67000, training_loss: 3.88309e-04
I0405 00:20:24.290241 23443585951552 run_lib.py:153] step: 67000, eval_loss: 3.44103e-04
I0405 00:20:46.374547 23443585951552 run_lib.py:140] step: 67050, training_loss: 4.60453e-04
I0405 00:21:08.443711 23443585951552 run_lib.py:140] step: 67100, training_loss: 3.58390e-04
I0405 00:21:08.596161 23443585951552 run_lib.py:153] step: 67100, eval_loss: 4.16860e-04
I0405 00:21:30.967434 23443585951552 run_lib.py:140] step: 67150, training_loss: 3.67366e-04
I0405 00:21:53.054101 23443585951552 run_lib.py:140] step: 67200, training_loss: 3.71527e-04
I0405 00:21:53.224468 23443585951552 run_lib.py:153] step: 67200, eval_loss: 4.55052e-04
I0405 00:22:14.974797 23443585951552 run_lib.py:140] step: 67250, training_loss: 3.91026e-04
I0405 00:22:37.168958 23443585951552 run_lib.py:140] step: 67300, training_loss: 4.08822e-04
I0405 00:22:37.346008 23443585951552 run_lib.py:153] step: 67300, eval_loss: 3.61459e-04
I0405 00:22:59.582360 23443585951552 run_lib.py:140] step: 67350, training_loss: 3.73191e-04
I0405 00:23:21.893365 23443585951552 run_lib.py:140] step: 67400, training_loss: 4.12866e-04
I0405 00:23:22.070665 23443585951552 run_lib.py:153] step: 67400, eval_loss: 3.65121e-04
I0405 00:23:44.875783 23443585951552 run_lib.py:140] step: 67450, training_loss: 4.43685e-04
I0405 00:24:07.242032 23443585951552 run_lib.py:140] step: 67500, training_loss: 4.36230e-04
I0405 00:24:07.397765 23443585951552 run_lib.py:153] step: 67500, eval_loss: 3.93389e-04
I0405 00:24:29.946929 23443585951552 run_lib.py:140] step: 67550, training_loss: 3.84352e-04
I0405 00:24:52.357943 23443585951552 run_lib.py:140] step: 67600, training_loss: 3.70646e-04
I0405 00:24:52.515313 23443585951552 run_lib.py:153] step: 67600, eval_loss: 4.43752e-04
I0405 00:25:15.133214 23443585951552 run_lib.py:140] step: 67650, training_loss: 4.19099e-04
I0405 00:25:37.708919 23443585951552 run_lib.py:140] step: 67700, training_loss: 4.07053e-04
I0405 00:25:37.881422 23443585951552 run_lib.py:153] step: 67700, eval_loss: 4.35593e-04
I0405 00:25:59.860338 23443585951552 run_lib.py:140] step: 67750, training_loss: 3.65673e-04
I0405 00:26:22.028964 23443585951552 run_lib.py:140] step: 67800, training_loss: 4.09139e-04
I0405 00:26:22.185365 23443585951552 run_lib.py:153] step: 67800, eval_loss: 4.02060e-04
I0405 00:26:45.033058 23443585951552 run_lib.py:140] step: 67850, training_loss: 4.03265e-04
I0405 00:27:07.248335 23443585951552 run_lib.py:140] step: 67900, training_loss: 3.97514e-04
I0405 00:27:07.410509 23443585951552 run_lib.py:153] step: 67900, eval_loss: 4.08875e-04
I0405 00:27:29.944056 23443585951552 run_lib.py:140] step: 67950, training_loss: 4.05411e-04
I0405 00:27:52.886510 23443585951552 run_lib.py:140] step: 68000, training_loss: 3.73999e-04
I0405 00:27:53.052453 23443585951552 run_lib.py:153] step: 68000, eval_loss: 3.51414e-04
I0405 00:28:15.157109 23443585951552 run_lib.py:140] step: 68050, training_loss: 4.40393e-04
I0405 00:28:37.603618 23443585951552 run_lib.py:140] step: 68100, training_loss: 4.04386e-04
I0405 00:28:37.766762 23443585951552 run_lib.py:153] step: 68100, eval_loss: 3.80995e-04
I0405 00:29:00.126860 23443585951552 run_lib.py:140] step: 68150, training_loss: 3.64330e-04
I0405 00:29:22.398730 23443585951552 run_lib.py:140] step: 68200, training_loss: 3.60691e-04
I0405 00:29:22.564936 23443585951552 run_lib.py:153] step: 68200, eval_loss: 3.95157e-04
I0405 00:29:45.085003 23443585951552 run_lib.py:140] step: 68250, training_loss: 3.93583e-04
I0405 00:30:07.560243 23443585951552 run_lib.py:140] step: 68300, training_loss: 4.56372e-04
I0405 00:30:07.752005 23443585951552 run_lib.py:153] step: 68300, eval_loss: 4.31565e-04
I0405 00:30:29.919256 23443585951552 run_lib.py:140] step: 68350, training_loss: 4.01434e-04
I0405 00:30:52.574223 23443585951552 run_lib.py:140] step: 68400, training_loss: 3.91413e-04
I0405 00:30:52.739976 23443585951552 run_lib.py:153] step: 68400, eval_loss: 4.24908e-04
I0405 00:31:14.923918 23443585951552 run_lib.py:140] step: 68450, training_loss: 3.63394e-04
I0405 00:31:37.534791 23443585951552 run_lib.py:140] step: 68500, training_loss: 3.49760e-04
I0405 00:31:37.702363 23443585951552 run_lib.py:153] step: 68500, eval_loss: 4.17667e-04
I0405 00:32:00.061424 23443585951552 run_lib.py:140] step: 68550, training_loss: 3.83958e-04
I0405 00:32:22.568889 23443585951552 run_lib.py:140] step: 68600, training_loss: 3.82106e-04
I0405 00:32:22.747668 23443585951552 run_lib.py:153] step: 68600, eval_loss: 4.24437e-04
I0405 00:32:45.018432 23443585951552 run_lib.py:140] step: 68650, training_loss: 4.10420e-04
I0405 00:33:07.660505 23443585951552 run_lib.py:140] step: 68700, training_loss: 3.34963e-04
I0405 00:33:07.835921 23443585951552 run_lib.py:153] step: 68700, eval_loss: 4.16716e-04
I0405 00:33:30.543048 23443585951552 run_lib.py:140] step: 68750, training_loss: 4.10557e-04
I0405 00:33:53.012302 23443585951552 run_lib.py:140] step: 68800, training_loss: 3.72106e-04
I0405 00:33:53.171299 23443585951552 run_lib.py:153] step: 68800, eval_loss: 4.44016e-04
I0405 00:34:15.538460 23443585951552 run_lib.py:140] step: 68850, training_loss: 4.42755e-04
I0405 00:34:37.898189 23443585951552 run_lib.py:140] step: 68900, training_loss: 4.12811e-04
I0405 00:34:38.083056 23443585951552 run_lib.py:153] step: 68900, eval_loss: 3.79211e-04
I0405 00:35:00.368074 23443585951552 run_lib.py:140] step: 68950, training_loss: 3.99552e-04
I0405 00:35:21.916915 23443585951552 run_lib.py:140] step: 69000, training_loss: 3.91386e-04
I0405 00:35:22.072232 23443585951552 run_lib.py:153] step: 69000, eval_loss: 3.82653e-04
I0405 00:35:43.865725 23443585951552 run_lib.py:140] step: 69050, training_loss: 3.93055e-04
I0405 00:36:05.992365 23443585951552 run_lib.py:140] step: 69100, training_loss: 4.64523e-04
I0405 00:36:06.149047 23443585951552 run_lib.py:153] step: 69100, eval_loss: 4.47238e-04
I0405 00:36:27.807891 23443585951552 run_lib.py:140] step: 69150, training_loss: 3.98086e-04
I0405 00:36:49.846077 23443585951552 run_lib.py:140] step: 69200, training_loss: 4.26828e-04
I0405 00:36:50.028735 23443585951552 run_lib.py:153] step: 69200, eval_loss: 4.00787e-04
I0405 00:37:11.774617 23443585951552 run_lib.py:140] step: 69250, training_loss: 4.34473e-04
I0405 00:37:33.686590 23443585951552 run_lib.py:140] step: 69300, training_loss: 3.77319e-04
I0405 00:37:33.932271 23443585951552 run_lib.py:153] step: 69300, eval_loss: 4.07952e-04
I0405 00:37:55.736686 23443585951552 run_lib.py:140] step: 69350, training_loss: 4.76633e-04
I0405 00:38:17.532920 23443585951552 run_lib.py:140] step: 69400, training_loss: 4.09683e-04
I0405 00:38:17.696177 23443585951552 run_lib.py:153] step: 69400, eval_loss: 4.47176e-04
I0405 00:38:39.576102 23443585951552 run_lib.py:140] step: 69450, training_loss: 4.40377e-04
I0405 00:39:01.265300 23443585951552 run_lib.py:140] step: 69500, training_loss: 3.90748e-04
I0405 00:39:01.422813 23443585951552 run_lib.py:153] step: 69500, eval_loss: 4.27641e-04
I0405 00:39:23.029754 23443585951552 run_lib.py:140] step: 69550, training_loss: 3.76999e-04
I0405 00:39:45.018931 23443585951552 run_lib.py:140] step: 69600, training_loss: 3.95219e-04
I0405 00:39:45.195430 23443585951552 run_lib.py:153] step: 69600, eval_loss: 3.82439e-04
I0405 00:40:06.768988 23443585951552 run_lib.py:140] step: 69650, training_loss: 4.27480e-04
I0405 00:40:28.822273 23443585951552 run_lib.py:140] step: 69700, training_loss: 4.00120e-04
I0405 00:40:28.985575 23443585951552 run_lib.py:153] step: 69700, eval_loss: 4.06166e-04
I0405 00:40:50.945833 23443585951552 run_lib.py:140] step: 69750, training_loss: 3.86867e-04
I0405 00:41:13.068817 23443585951552 run_lib.py:140] step: 69800, training_loss: 4.10043e-04
I0405 00:41:13.235626 23443585951552 run_lib.py:153] step: 69800, eval_loss: 4.36157e-04
I0405 00:41:34.993732 23443585951552 run_lib.py:140] step: 69850, training_loss: 3.87229e-04
I0405 00:41:56.951574 23443585951552 run_lib.py:140] step: 69900, training_loss: 4.13681e-04
I0405 00:41:57.287757 23443585951552 run_lib.py:153] step: 69900, eval_loss: 3.79314e-04
I0405 00:42:19.093169 23443585951552 run_lib.py:140] step: 69950, training_loss: 3.32067e-04
I0405 00:42:40.848628 23443585951552 run_lib.py:140] step: 70000, training_loss: 3.92653e-04
I0405 00:42:41.752911 23443585951552 run_lib.py:153] step: 70000, eval_loss: 4.25454e-04
I0405 00:43:04.468728 23443585951552 run_lib.py:140] step: 70050, training_loss: 4.41176e-04
I0405 00:43:26.234126 23443585951552 run_lib.py:140] step: 70100, training_loss: 3.97036e-04
I0405 00:43:26.394144 23443585951552 run_lib.py:153] step: 70100, eval_loss: 3.83804e-04
I0405 00:43:48.488429 23443585951552 run_lib.py:140] step: 70150, training_loss: 3.86924e-04
I0405 00:44:10.419883 23443585951552 run_lib.py:140] step: 70200, training_loss: 3.96474e-04
I0405 00:44:10.581887 23443585951552 run_lib.py:153] step: 70200, eval_loss: 4.22994e-04
I0405 00:44:32.171017 23443585951552 run_lib.py:140] step: 70250, training_loss: 4.30152e-04
I0405 00:44:54.220735 23443585951552 run_lib.py:140] step: 70300, training_loss: 4.00635e-04
I0405 00:44:54.385700 23443585951552 run_lib.py:153] step: 70300, eval_loss: 3.75192e-04
I0405 00:45:16.259582 23443585951552 run_lib.py:140] step: 70350, training_loss: 4.26385e-04
I0405 00:45:38.035418 23443585951552 run_lib.py:140] step: 70400, training_loss: 4.06469e-04
I0405 00:45:38.183140 23443585951552 run_lib.py:153] step: 70400, eval_loss: 4.54591e-04
I0405 00:46:00.061631 23443585951552 run_lib.py:140] step: 70450, training_loss: 3.70249e-04
I0405 00:46:22.160758 23443585951552 run_lib.py:140] step: 70500, training_loss: 5.11033e-04
I0405 00:46:22.322930 23443585951552 run_lib.py:153] step: 70500, eval_loss: 4.21632e-04
I0405 00:46:44.429384 23443585951552 run_lib.py:140] step: 70550, training_loss: 3.63267e-04
I0405 00:47:06.023028 23443585951552 run_lib.py:140] step: 70600, training_loss: 3.93999e-04
I0405 00:47:06.183439 23443585951552 run_lib.py:153] step: 70600, eval_loss: 3.94759e-04
I0405 00:47:28.077215 23443585951552 run_lib.py:140] step: 70650, training_loss: 4.53870e-04
I0405 00:47:50.220646 23443585951552 run_lib.py:140] step: 70700, training_loss: 4.77698e-04
I0405 00:47:50.393908 23443585951552 run_lib.py:153] step: 70700, eval_loss: 3.96913e-04
I0405 00:48:12.473138 23443585951552 run_lib.py:140] step: 70750, training_loss: 4.43989e-04
I0405 00:48:34.346036 23443585951552 run_lib.py:140] step: 70800, training_loss: 3.77701e-04
I0405 00:48:34.500611 23443585951552 run_lib.py:153] step: 70800, eval_loss: 3.75651e-04
I0405 00:48:56.446377 23443585951552 run_lib.py:140] step: 70850, training_loss: 4.31375e-04
I0405 00:49:18.165396 23443585951552 run_lib.py:140] step: 70900, training_loss: 4.18864e-04
I0405 00:49:18.525958 23443585951552 run_lib.py:153] step: 70900, eval_loss: 4.11048e-04
I0405 00:49:40.209878 23443585951552 run_lib.py:140] step: 70950, training_loss: 3.54324e-04
I0405 00:50:02.202451 23443585951552 run_lib.py:140] step: 71000, training_loss: 3.76807e-04
I0405 00:50:02.362033 23443585951552 run_lib.py:153] step: 71000, eval_loss: 3.27046e-04
I0405 00:50:24.166143 23443585951552 run_lib.py:140] step: 71050, training_loss: 3.98631e-04
I0405 00:50:45.746008 23443585951552 run_lib.py:140] step: 71100, training_loss: 3.47612e-04
I0405 00:50:45.906635 23443585951552 run_lib.py:153] step: 71100, eval_loss: 4.66969e-04
I0405 00:51:07.758118 23443585951552 run_lib.py:140] step: 71150, training_loss: 4.22526e-04
I0405 00:51:29.672416 23443585951552 run_lib.py:140] step: 71200, training_loss: 3.90604e-04
I0405 00:51:29.827645 23443585951552 run_lib.py:153] step: 71200, eval_loss: 3.61668e-04
I0405 00:51:51.839819 23443585951552 run_lib.py:140] step: 71250, training_loss: 3.46857e-04
I0405 00:52:13.621989 23443585951552 run_lib.py:140] step: 71300, training_loss: 3.78534e-04
I0405 00:52:13.779703 23443585951552 run_lib.py:153] step: 71300, eval_loss: 4.53813e-04
I0405 00:52:35.500868 23443585951552 run_lib.py:140] step: 71350, training_loss: 4.19448e-04
I0405 00:52:57.085123 23443585951552 run_lib.py:140] step: 71400, training_loss: 3.42015e-04
I0405 00:52:57.256390 23443585951552 run_lib.py:153] step: 71400, eval_loss: 3.73385e-04
I0405 00:53:19.233578 23443585951552 run_lib.py:140] step: 71450, training_loss: 3.50226e-04
I0405 00:53:40.966045 23443585951552 run_lib.py:140] step: 71500, training_loss: 4.41088e-04
I0405 00:53:41.128286 23443585951552 run_lib.py:153] step: 71500, eval_loss: 4.48166e-04
I0405 00:54:03.018261 23443585951552 run_lib.py:140] step: 71550, training_loss: 4.77581e-04
I0405 00:54:24.789569 23443585951552 run_lib.py:140] step: 71600, training_loss: 3.55693e-04
I0405 00:54:24.966083 23443585951552 run_lib.py:153] step: 71600, eval_loss: 4.26680e-04
I0405 00:54:46.973447 23443585951552 run_lib.py:140] step: 71650, training_loss: 3.58553e-04
I0405 00:55:09.009834 23443585951552 run_lib.py:140] step: 71700, training_loss: 4.47309e-04
I0405 00:55:09.165785 23443585951552 run_lib.py:153] step: 71700, eval_loss: 3.95834e-04
I0405 00:55:31.060537 23443585951552 run_lib.py:140] step: 71750, training_loss: 4.63551e-04
I0405 00:55:53.081228 23443585951552 run_lib.py:140] step: 71800, training_loss: 3.54796e-04
I0405 00:55:53.234989 23443585951552 run_lib.py:153] step: 71800, eval_loss: 3.72001e-04
I0405 00:56:15.104196 23443585951552 run_lib.py:140] step: 71850, training_loss: 4.23515e-04
I0405 00:56:36.619389 23443585951552 run_lib.py:140] step: 71900, training_loss: 3.86838e-04
I0405 00:56:36.783767 23443585951552 run_lib.py:153] step: 71900, eval_loss: 4.13596e-04
I0405 00:56:58.321913 23443585951552 run_lib.py:140] step: 71950, training_loss: 4.31731e-04
I0405 00:57:20.244062 23443585951552 run_lib.py:140] step: 72000, training_loss: 4.65292e-04
I0405 00:57:20.409275 23443585951552 run_lib.py:153] step: 72000, eval_loss: 3.79778e-04
I0405 00:57:41.758978 23443585951552 run_lib.py:140] step: 72050, training_loss: 4.01175e-04
I0405 00:58:03.283751 23443585951552 run_lib.py:140] step: 72100, training_loss: 2.98427e-04
I0405 00:58:03.441424 23443585951552 run_lib.py:153] step: 72100, eval_loss: 4.10134e-04
I0405 00:58:25.282133 23443585951552 run_lib.py:140] step: 72150, training_loss: 3.67436e-04
I0405 00:58:46.828962 23443585951552 run_lib.py:140] step: 72200, training_loss: 3.61927e-04
I0405 00:58:46.985578 23443585951552 run_lib.py:153] step: 72200, eval_loss: 4.43369e-04
I0405 00:59:08.937779 23443585951552 run_lib.py:140] step: 72250, training_loss: 3.98320e-04
I0405 00:59:30.577026 23443585951552 run_lib.py:140] step: 72300, training_loss: 3.99082e-04
I0405 00:59:30.735522 23443585951552 run_lib.py:153] step: 72300, eval_loss: 4.31921e-04
I0405 00:59:52.392808 23443585951552 run_lib.py:140] step: 72350, training_loss: 3.90005e-04
I0405 01:00:13.921622 23443585951552 run_lib.py:140] step: 72400, training_loss: 3.59112e-04
I0405 01:00:14.076138 23443585951552 run_lib.py:153] step: 72400, eval_loss: 4.08630e-04
I0405 01:00:35.880275 23443585951552 run_lib.py:140] step: 72450, training_loss: 4.28934e-04
I0405 01:00:57.652967 23443585951552 run_lib.py:140] step: 72500, training_loss: 3.99946e-04
I0405 01:00:57.838313 23443585951552 run_lib.py:153] step: 72500, eval_loss: 3.72944e-04
I0405 01:01:19.711784 23443585951552 run_lib.py:140] step: 72550, training_loss: 3.53121e-04
I0405 01:01:41.509984 23443585951552 run_lib.py:140] step: 72600, training_loss: 3.94349e-04
I0405 01:01:41.664300 23443585951552 run_lib.py:153] step: 72600, eval_loss: 3.81451e-04
I0405 01:02:03.712114 23443585951552 run_lib.py:140] step: 72650, training_loss: 4.41594e-04
I0405 01:02:25.167274 23443585951552 run_lib.py:140] step: 72700, training_loss: 3.48239e-04
I0405 01:02:25.320707 23443585951552 run_lib.py:153] step: 72700, eval_loss: 3.75468e-04
I0405 01:02:46.854788 23443585951552 run_lib.py:140] step: 72750, training_loss: 4.23771e-04
I0405 01:03:08.565680 23443585951552 run_lib.py:140] step: 72800, training_loss: 3.55365e-04
I0405 01:03:08.722125 23443585951552 run_lib.py:153] step: 72800, eval_loss: 3.78981e-04
I0405 01:03:30.406804 23443585951552 run_lib.py:140] step: 72850, training_loss: 4.42685e-04
I0405 01:03:51.804115 23443585951552 run_lib.py:140] step: 72900, training_loss: 3.95528e-04
I0405 01:03:51.966749 23443585951552 run_lib.py:153] step: 72900, eval_loss: 4.75905e-04
I0405 01:04:13.269478 23443585951552 run_lib.py:140] step: 72950, training_loss: 3.36590e-04
I0405 01:04:35.004351 23443585951552 run_lib.py:140] step: 73000, training_loss: 3.87672e-04
I0405 01:04:35.188259 23443585951552 run_lib.py:153] step: 73000, eval_loss: 3.86351e-04
I0405 01:04:56.792235 23443585951552 run_lib.py:140] step: 73050, training_loss: 3.58883e-04
I0405 01:05:18.457653 23443585951552 run_lib.py:140] step: 73100, training_loss: 4.03864e-04
I0405 01:05:18.623939 23443585951552 run_lib.py:153] step: 73100, eval_loss: 4.04632e-04
I0405 01:05:40.415872 23443585951552 run_lib.py:140] step: 73150, training_loss: 3.71562e-04
I0405 01:06:02.084306 23443585951552 run_lib.py:140] step: 73200, training_loss: 3.64851e-04
I0405 01:06:02.239009 23443585951552 run_lib.py:153] step: 73200, eval_loss: 3.96981e-04
I0405 01:06:23.840224 23443585951552 run_lib.py:140] step: 73250, training_loss: 4.23661e-04
I0405 01:06:45.503855 23443585951552 run_lib.py:140] step: 73300, training_loss: 3.71679e-04
I0405 01:06:45.655990 23443585951552 run_lib.py:153] step: 73300, eval_loss: 4.52864e-04
I0405 01:07:07.620433 23443585951552 run_lib.py:140] step: 73350, training_loss: 3.71225e-04
I0405 01:07:28.951410 23443585951552 run_lib.py:140] step: 73400, training_loss: 3.68829e-04
I0405 01:07:29.134749 23443585951552 run_lib.py:153] step: 73400, eval_loss: 3.90864e-04
I0405 01:07:51.070424 23443585951552 run_lib.py:140] step: 73450, training_loss: 4.25198e-04
I0405 01:08:12.887471 23443585951552 run_lib.py:140] step: 73500, training_loss: 4.10929e-04
I0405 01:08:13.042281 23443585951552 run_lib.py:153] step: 73500, eval_loss: 4.52208e-04
I0405 01:08:34.757878 23443585951552 run_lib.py:140] step: 73550, training_loss: 3.93584e-04
I0405 01:08:56.491873 23443585951552 run_lib.py:140] step: 73600, training_loss: 4.74221e-04
I0405 01:08:56.669157 23443585951552 run_lib.py:153] step: 73600, eval_loss: 4.44976e-04
I0405 01:09:18.198240 23443585951552 run_lib.py:140] step: 73650, training_loss: 3.44978e-04
I0405 01:09:40.195105 23443585951552 run_lib.py:140] step: 73700, training_loss: 4.01013e-04
I0405 01:09:40.355201 23443585951552 run_lib.py:153] step: 73700, eval_loss: 3.78209e-04
I0405 01:10:02.402035 23443585951552 run_lib.py:140] step: 73750, training_loss: 4.13458e-04
I0405 01:10:24.159875 23443585951552 run_lib.py:140] step: 73800, training_loss: 4.12678e-04
I0405 01:10:24.321448 23443585951552 run_lib.py:153] step: 73800, eval_loss: 3.98160e-04
I0405 01:10:45.790434 23443585951552 run_lib.py:140] step: 73850, training_loss: 4.19864e-04
I0405 01:11:07.764126 23443585951552 run_lib.py:140] step: 73900, training_loss: 3.91334e-04
I0405 01:11:07.927572 23443585951552 run_lib.py:153] step: 73900, eval_loss: 4.27750e-04
I0405 01:11:29.686563 23443585951552 run_lib.py:140] step: 73950, training_loss: 3.88645e-04
I0405 01:11:51.364713 23443585951552 run_lib.py:140] step: 74000, training_loss: 4.16589e-04
I0405 01:11:51.518826 23443585951552 run_lib.py:153] step: 74000, eval_loss: 4.07935e-04
I0405 01:12:13.188702 23443585951552 run_lib.py:140] step: 74050, training_loss: 3.61303e-04
I0405 01:12:34.998786 23443585951552 run_lib.py:140] step: 74100, training_loss: 4.19844e-04
I0405 01:12:35.159956 23443585951552 run_lib.py:153] step: 74100, eval_loss: 4.24506e-04
I0405 01:12:56.916021 23443585951552 run_lib.py:140] step: 74150, training_loss: 3.74584e-04
I0405 01:13:18.503939 23443585951552 run_lib.py:140] step: 74200, training_loss: 4.09224e-04
I0405 01:13:18.662806 23443585951552 run_lib.py:153] step: 74200, eval_loss: 4.25183e-04
I0405 01:13:40.334468 23443585951552 run_lib.py:140] step: 74250, training_loss: 3.51315e-04
I0405 01:14:02.281995 23443585951552 run_lib.py:140] step: 74300, training_loss: 4.29152e-04
I0405 01:14:02.451268 23443585951552 run_lib.py:153] step: 74300, eval_loss: 3.63674e-04
I0405 01:14:24.333061 23443585951552 run_lib.py:140] step: 74350, training_loss: 4.26893e-04
I0405 01:14:46.189063 23443585951552 run_lib.py:140] step: 74400, training_loss: 4.32510e-04
I0405 01:14:46.355944 23443585951552 run_lib.py:153] step: 74400, eval_loss: 3.53622e-04
I0405 01:15:08.468089 23443585951552 run_lib.py:140] step: 74450, training_loss: 3.93369e-04
I0405 01:15:30.251875 23443585951552 run_lib.py:140] step: 74500, training_loss: 4.81988e-04
I0405 01:15:30.408230 23443585951552 run_lib.py:153] step: 74500, eval_loss: 4.11074e-04
I0405 01:15:52.354421 23443585951552 run_lib.py:140] step: 74550, training_loss: 4.16816e-04
I0405 01:16:14.300320 23443585951552 run_lib.py:140] step: 74600, training_loss: 4.10154e-04
I0405 01:16:14.455540 23443585951552 run_lib.py:153] step: 74600, eval_loss: 3.71554e-04
I0405 01:16:36.177892 23443585951552 run_lib.py:140] step: 74650, training_loss: 4.63398e-04
I0405 01:16:57.977919 23443585951552 run_lib.py:140] step: 74700, training_loss: 3.53991e-04
I0405 01:16:58.129847 23443585951552 run_lib.py:153] step: 74700, eval_loss: 3.46879e-04
I0405 01:17:19.925520 23443585951552 run_lib.py:140] step: 74750, training_loss: 4.36948e-04
I0405 01:17:41.490720 23443585951552 run_lib.py:140] step: 74800, training_loss: 3.45771e-04
I0405 01:17:41.652204 23443585951552 run_lib.py:153] step: 74800, eval_loss: 4.12311e-04
I0405 01:18:03.307940 23443585951552 run_lib.py:140] step: 74850, training_loss: 4.68538e-04
I0405 01:18:25.036604 23443585951552 run_lib.py:140] step: 74900, training_loss: 3.85719e-04
I0405 01:18:25.195977 23443585951552 run_lib.py:153] step: 74900, eval_loss: 3.56407e-04
I0405 01:18:47.018041 23443585951552 run_lib.py:140] step: 74950, training_loss: 4.29001e-04
I0405 01:19:08.983140 23443585951552 run_lib.py:140] step: 75000, training_loss: 3.94723e-04
I0405 01:19:09.138042 23443585951552 run_lib.py:153] step: 75000, eval_loss: 3.96594e-04
I0405 01:19:30.463071 23443585951552 run_lib.py:140] step: 75050, training_loss: 3.55429e-04
I0405 01:19:52.172194 23443585951552 run_lib.py:140] step: 75100, training_loss: 3.67635e-04
I0405 01:19:52.329724 23443585951552 run_lib.py:153] step: 75100, eval_loss: 3.57739e-04
I0405 01:20:14.046818 23443585951552 run_lib.py:140] step: 75150, training_loss: 4.29626e-04
I0405 01:20:35.888383 23443585951552 run_lib.py:140] step: 75200, training_loss: 4.31253e-04
I0405 01:20:36.057106 23443585951552 run_lib.py:153] step: 75200, eval_loss: 3.82270e-04
I0405 01:20:57.713879 23443585951552 run_lib.py:140] step: 75250, training_loss: 3.70476e-04
I0405 01:21:19.203753 23443585951552 run_lib.py:140] step: 75300, training_loss: 3.77437e-04
I0405 01:21:19.370045 23443585951552 run_lib.py:153] step: 75300, eval_loss: 4.03627e-04
I0405 01:21:41.131998 23443585951552 run_lib.py:140] step: 75350, training_loss: 4.04618e-04
I0405 01:22:02.719059 23443585951552 run_lib.py:140] step: 75400, training_loss: 4.24462e-04
I0405 01:22:02.877072 23443585951552 run_lib.py:153] step: 75400, eval_loss: 3.78992e-04
I0405 01:22:24.767084 23443585951552 run_lib.py:140] step: 75450, training_loss: 4.42890e-04
I0405 01:22:46.532487 23443585951552 run_lib.py:140] step: 75500, training_loss: 4.46592e-04
I0405 01:22:46.695344 23443585951552 run_lib.py:153] step: 75500, eval_loss: 4.68490e-04
I0405 01:23:08.861184 23443585951552 run_lib.py:140] step: 75550, training_loss: 3.78387e-04
I0405 01:23:30.697075 23443585951552 run_lib.py:140] step: 75600, training_loss: 3.78135e-04
I0405 01:23:30.856897 23443585951552 run_lib.py:153] step: 75600, eval_loss: 4.43651e-04
I0405 01:23:52.437213 23443585951552 run_lib.py:140] step: 75650, training_loss: 4.32205e-04
I0405 01:24:14.427105 23443585951552 run_lib.py:140] step: 75700, training_loss: 4.01303e-04
I0405 01:24:14.597555 23443585951552 run_lib.py:153] step: 75700, eval_loss: 4.00708e-04
I0405 01:24:36.112829 23443585951552 run_lib.py:140] step: 75750, training_loss: 4.04347e-04
I0405 01:24:58.102216 23443585951552 run_lib.py:140] step: 75800, training_loss: 3.75375e-04
I0405 01:24:58.259034 23443585951552 run_lib.py:153] step: 75800, eval_loss: 4.33700e-04
I0405 01:25:19.902041 23443585951552 run_lib.py:140] step: 75850, training_loss: 4.16799e-04
I0405 01:25:41.699418 23443585951552 run_lib.py:140] step: 75900, training_loss: 3.68586e-04
I0405 01:25:41.875254 23443585951552 run_lib.py:153] step: 75900, eval_loss: 3.84070e-04
I0405 01:26:03.781713 23443585951552 run_lib.py:140] step: 75950, training_loss: 3.59186e-04
I0405 01:26:25.644928 23443585951552 run_lib.py:140] step: 76000, training_loss: 3.45082e-04
I0405 01:26:25.806081 23443585951552 run_lib.py:153] step: 76000, eval_loss: 3.65913e-04
I0405 01:26:47.378884 23443585951552 run_lib.py:140] step: 76050, training_loss: 3.97890e-04
I0405 01:27:09.255699 23443585951552 run_lib.py:140] step: 76100, training_loss: 4.25646e-04
I0405 01:27:09.412159 23443585951552 run_lib.py:153] step: 76100, eval_loss: 4.30562e-04
I0405 01:27:31.210754 23443585951552 run_lib.py:140] step: 76150, training_loss: 3.75819e-04
I0405 01:27:52.998448 23443585951552 run_lib.py:140] step: 76200, training_loss: 3.55714e-04
I0405 01:27:53.158940 23443585951552 run_lib.py:153] step: 76200, eval_loss: 4.62776e-04
I0405 01:28:14.654654 23443585951552 run_lib.py:140] step: 76250, training_loss: 4.76542e-04
I0405 01:28:36.397304 23443585951552 run_lib.py:140] step: 76300, training_loss: 3.89909e-04
I0405 01:28:36.561494 23443585951552 run_lib.py:153] step: 76300, eval_loss: 4.06168e-04
I0405 01:28:58.039274 23443585951552 run_lib.py:140] step: 76350, training_loss: 3.82497e-04
I0405 01:29:19.766308 23443585951552 run_lib.py:140] step: 76400, training_loss: 3.86241e-04
I0405 01:29:19.921307 23443585951552 run_lib.py:153] step: 76400, eval_loss: 4.05972e-04
I0405 01:29:41.648812 23443585951552 run_lib.py:140] step: 76450, training_loss: 3.92886e-04
I0405 01:30:03.348833 23443585951552 run_lib.py:140] step: 76500, training_loss: 3.81169e-04
I0405 01:30:03.507681 23443585951552 run_lib.py:153] step: 76500, eval_loss: 3.99092e-04
I0405 01:30:25.249917 23443585951552 run_lib.py:140] step: 76550, training_loss: 4.09192e-04
I0405 01:30:47.102136 23443585951552 run_lib.py:140] step: 76600, training_loss: 4.21581e-04
I0405 01:30:47.257023 23443585951552 run_lib.py:153] step: 76600, eval_loss: 3.91374e-04
I0405 01:31:09.105838 23443585951552 run_lib.py:140] step: 76650, training_loss: 3.64365e-04
I0405 01:31:30.963587 23443585951552 run_lib.py:140] step: 76700, training_loss: 4.30262e-04
I0405 01:31:31.118668 23443585951552 run_lib.py:153] step: 76700, eval_loss: 4.28230e-04
I0405 01:31:52.819082 23443585951552 run_lib.py:140] step: 76750, training_loss: 3.74621e-04
I0405 01:32:14.515625 23443585951552 run_lib.py:140] step: 76800, training_loss: 3.08408e-04
I0405 01:32:14.690163 23443585951552 run_lib.py:153] step: 76800, eval_loss: 4.27029e-04
I0405 01:32:36.211618 23443585951552 run_lib.py:140] step: 76850, training_loss: 3.84426e-04
I0405 01:32:58.242291 23443585951552 run_lib.py:140] step: 76900, training_loss: 4.03113e-04
I0405 01:32:58.396645 23443585951552 run_lib.py:153] step: 76900, eval_loss: 3.85682e-04
I0405 01:33:20.110069 23443585951552 run_lib.py:140] step: 76950, training_loss: 4.33665e-04
I0405 01:33:41.923845 23443585951552 run_lib.py:140] step: 77000, training_loss: 3.86679e-04
I0405 01:33:42.086996 23443585951552 run_lib.py:153] step: 77000, eval_loss: 4.12186e-04
I0405 01:34:04.007217 23443585951552 run_lib.py:140] step: 77050, training_loss: 4.07874e-04
I0405 01:34:25.752304 23443585951552 run_lib.py:140] step: 77100, training_loss: 4.00386e-04
I0405 01:34:25.915498 23443585951552 run_lib.py:153] step: 77100, eval_loss: 3.82690e-04
I0405 01:34:47.451474 23443585951552 run_lib.py:140] step: 77150, training_loss: 4.01243e-04
I0405 01:35:09.402962 23443585951552 run_lib.py:140] step: 77200, training_loss: 3.85509e-04
I0405 01:35:09.572197 23443585951552 run_lib.py:153] step: 77200, eval_loss: 4.49514e-04
I0405 01:35:31.804513 23443585951552 run_lib.py:140] step: 77250, training_loss: 4.08891e-04
I0405 01:35:53.547516 23443585951552 run_lib.py:140] step: 77300, training_loss: 3.61238e-04
I0405 01:35:53.706290 23443585951552 run_lib.py:153] step: 77300, eval_loss: 4.35343e-04
I0405 01:36:15.401320 23443585951552 run_lib.py:140] step: 77350, training_loss: 3.98821e-04
I0405 01:36:36.905192 23443585951552 run_lib.py:140] step: 77400, training_loss: 4.13312e-04
I0405 01:36:37.074823 23443585951552 run_lib.py:153] step: 77400, eval_loss: 4.25946e-04
I0405 01:36:58.625077 23443585951552 run_lib.py:140] step: 77450, training_loss: 4.11195e-04
I0405 01:37:20.523458 23443585951552 run_lib.py:140] step: 77500, training_loss: 3.89905e-04
I0405 01:37:20.680771 23443585951552 run_lib.py:153] step: 77500, eval_loss: 4.01287e-04
I0405 01:37:41.885244 23443585951552 run_lib.py:140] step: 77550, training_loss: 3.86838e-04
I0405 01:38:03.697035 23443585951552 run_lib.py:140] step: 77600, training_loss: 4.58389e-04
I0405 01:38:03.860121 23443585951552 run_lib.py:153] step: 77600, eval_loss: 3.73142e-04
I0405 01:38:25.780643 23443585951552 run_lib.py:140] step: 77650, training_loss: 4.58424e-04
I0405 01:38:47.361591 23443585951552 run_lib.py:140] step: 77700, training_loss: 4.21445e-04
I0405 01:38:47.518982 23443585951552 run_lib.py:153] step: 77700, eval_loss: 3.95974e-04
I0405 01:39:09.459182 23443585951552 run_lib.py:140] step: 77750, training_loss: 3.60044e-04
I0405 01:39:31.112497 23443585951552 run_lib.py:140] step: 77800, training_loss: 3.66264e-04
I0405 01:39:31.273235 23443585951552 run_lib.py:153] step: 77800, eval_loss: 3.49375e-04
I0405 01:39:52.740775 23443585951552 run_lib.py:140] step: 77850, training_loss: 4.38668e-04
I0405 01:40:14.613267 23443585951552 run_lib.py:140] step: 77900, training_loss: 4.15170e-04
I0405 01:40:14.774519 23443585951552 run_lib.py:153] step: 77900, eval_loss: 4.07177e-04
I0405 01:40:36.658983 23443585951552 run_lib.py:140] step: 77950, training_loss: 4.09648e-04
I0405 01:40:58.415100 23443585951552 run_lib.py:140] step: 78000, training_loss: 3.51463e-04
I0405 01:40:58.567228 23443585951552 run_lib.py:153] step: 78000, eval_loss: 3.51396e-04
I0405 01:41:20.500308 23443585951552 run_lib.py:140] step: 78050, training_loss: 4.23851e-04
I0405 01:41:42.165755 23443585951552 run_lib.py:140] step: 78100, training_loss: 3.36014e-04
I0405 01:41:42.326571 23443585951552 run_lib.py:153] step: 78100, eval_loss: 3.83050e-04
I0405 01:42:04.415031 23443585951552 run_lib.py:140] step: 78150, training_loss: 3.91398e-04
I0405 01:42:26.141435 23443585951552 run_lib.py:140] step: 78200, training_loss: 4.02970e-04
I0405 01:42:26.311385 23443585951552 run_lib.py:153] step: 78200, eval_loss: 3.91915e-04
I0405 01:42:48.284652 23443585951552 run_lib.py:140] step: 78250, training_loss: 3.87698e-04
I0405 01:43:09.844419 23443585951552 run_lib.py:140] step: 78300, training_loss: 3.32590e-04
I0405 01:43:10.005973 23443585951552 run_lib.py:153] step: 78300, eval_loss: 3.53709e-04
I0405 01:43:27.546770 23443585951552 run_lib.py:140] step: 78350, training_loss: 4.05585e-04
I0405 01:43:44.985582 23443585951552 run_lib.py:140] step: 78400, training_loss: 3.79818e-04
I0405 01:43:45.138870 23443585951552 run_lib.py:153] step: 78400, eval_loss: 4.51939e-04
I0405 01:44:02.658995 23443585951552 run_lib.py:140] step: 78450, training_loss: 4.12439e-04
I0405 01:44:20.084851 23443585951552 run_lib.py:140] step: 78500, training_loss: 3.69093e-04
I0405 01:44:20.242497 23443585951552 run_lib.py:153] step: 78500, eval_loss: 3.75536e-04
I0405 01:44:37.746877 23443585951552 run_lib.py:140] step: 78550, training_loss: 3.91369e-04
I0405 01:44:55.171939 23443585951552 run_lib.py:140] step: 78600, training_loss: 3.69008e-04
I0405 01:44:55.326649 23443585951552 run_lib.py:153] step: 78600, eval_loss: 4.13371e-04
I0405 01:45:12.912647 23443585951552 run_lib.py:140] step: 78650, training_loss: 3.85277e-04
I0405 01:45:30.433035 23443585951552 run_lib.py:140] step: 78700, training_loss: 3.57696e-04
I0405 01:45:30.586243 23443585951552 run_lib.py:153] step: 78700, eval_loss: 4.25440e-04
I0405 01:45:48.004545 23443585951552 run_lib.py:140] step: 78750, training_loss: 4.29349e-04
I0405 01:46:05.474152 23443585951552 run_lib.py:140] step: 78800, training_loss: 4.90820e-04
I0405 01:46:05.631148 23443585951552 run_lib.py:153] step: 78800, eval_loss: 3.90802e-04
I0405 01:46:23.244812 23443585951552 run_lib.py:140] step: 78850, training_loss: 4.29688e-04
I0405 01:46:40.709375 23443585951552 run_lib.py:140] step: 78900, training_loss: 4.15869e-04
I0405 01:46:40.861993 23443585951552 run_lib.py:153] step: 78900, eval_loss: 4.55848e-04
I0405 01:46:58.278701 23443585951552 run_lib.py:140] step: 78950, training_loss: 3.42601e-04
I0405 01:47:15.864059 23443585951552 run_lib.py:140] step: 79000, training_loss: 3.53749e-04
I0405 01:47:16.014714 23443585951552 run_lib.py:153] step: 79000, eval_loss: 3.94254e-04
I0405 01:47:33.457087 23443585951552 run_lib.py:140] step: 79050, training_loss: 3.89067e-04
I0405 01:47:51.051677 23443585951552 run_lib.py:140] step: 79100, training_loss: 3.82382e-04
I0405 01:47:51.237719 23443585951552 run_lib.py:153] step: 79100, eval_loss: 3.66564e-04
I0405 01:48:08.699892 23443585951552 run_lib.py:140] step: 79150, training_loss: 3.94635e-04
I0405 01:48:26.193753 23443585951552 run_lib.py:140] step: 79200, training_loss: 3.91404e-04
I0405 01:48:26.350226 23443585951552 run_lib.py:153] step: 79200, eval_loss: 3.74724e-04
I0405 01:48:44.029708 23443585951552 run_lib.py:140] step: 79250, training_loss: 4.60698e-04
I0405 01:49:01.481075 23443585951552 run_lib.py:140] step: 79300, training_loss: 3.88912e-04
I0405 01:49:01.653625 23443585951552 run_lib.py:153] step: 79300, eval_loss: 4.05211e-04
I0405 01:49:19.070024 23443585951552 run_lib.py:140] step: 79350, training_loss: 4.01908e-04
I0405 01:49:36.649043 23443585951552 run_lib.py:140] step: 79400, training_loss: 3.93711e-04
I0405 01:49:36.802152 23443585951552 run_lib.py:153] step: 79400, eval_loss: 3.87335e-04
I0405 01:49:54.466436 23443585951552 run_lib.py:140] step: 79450, training_loss: 4.32800e-04
I0405 01:50:11.895168 23443585951552 run_lib.py:140] step: 79500, training_loss: 3.71913e-04
I0405 01:50:12.057470 23443585951552 run_lib.py:153] step: 79500, eval_loss: 4.37349e-04
I0405 01:50:31.964072 23443585951552 run_lib.py:140] step: 79550, training_loss: 3.95305e-04
I0405 01:50:53.498732 23443585951552 run_lib.py:140] step: 79600, training_loss: 4.23507e-04
I0405 01:50:53.684180 23443585951552 run_lib.py:153] step: 79600, eval_loss: 4.12498e-04
I0405 01:51:15.385805 23443585951552 run_lib.py:140] step: 79650, training_loss: 3.98459e-04
I0405 01:51:37.067881 23443585951552 run_lib.py:140] step: 79700, training_loss: 4.26441e-04
I0405 01:51:37.232373 23443585951552 run_lib.py:153] step: 79700, eval_loss: 3.42581e-04
I0405 01:51:59.235132 23443585951552 run_lib.py:140] step: 79750, training_loss: 3.75988e-04
I0405 01:52:20.471317 23443585951552 run_lib.py:140] step: 79800, training_loss: 4.36003e-04
I0405 01:52:20.633856 23443585951552 run_lib.py:153] step: 79800, eval_loss: 4.29110e-04
I0405 01:52:42.035367 23443585951552 run_lib.py:140] step: 79850, training_loss: 3.44694e-04
I0405 01:53:03.536540 23443585951552 run_lib.py:140] step: 79900, training_loss: 3.49558e-04
I0405 01:53:03.693988 23443585951552 run_lib.py:153] step: 79900, eval_loss: 3.57632e-04
I0405 01:53:25.505782 23443585951552 run_lib.py:140] step: 79950, training_loss: 4.16559e-04
I0405 01:53:47.230490 23443585951552 run_lib.py:140] step: 80000, training_loss: 3.75688e-04
I0405 01:53:48.309665 23443585951552 run_lib.py:153] step: 80000, eval_loss: 4.04142e-04
I0405 01:54:10.918642 23443585951552 run_lib.py:140] step: 80050, training_loss: 4.41781e-04
I0405 01:54:32.244825 23443585951552 run_lib.py:140] step: 80100, training_loss: 3.52842e-04
I0405 01:54:32.424440 23443585951552 run_lib.py:153] step: 80100, eval_loss: 3.64679e-04
I0405 01:54:54.112177 23443585951552 run_lib.py:140] step: 80150, training_loss: 3.89363e-04
I0405 01:55:15.752189 23443585951552 run_lib.py:140] step: 80200, training_loss: 5.03185e-04
I0405 01:55:15.908302 23443585951552 run_lib.py:153] step: 80200, eval_loss: 3.96839e-04
I0405 01:55:37.283337 23443585951552 run_lib.py:140] step: 80250, training_loss: 3.83936e-04
I0405 01:55:58.855443 23443585951552 run_lib.py:140] step: 80300, training_loss: 4.15627e-04
I0405 01:55:59.008752 23443585951552 run_lib.py:153] step: 80300, eval_loss: 4.12150e-04
I0405 01:56:20.362246 23443585951552 run_lib.py:140] step: 80350, training_loss: 4.29716e-04
I0405 01:56:42.127478 23443585951552 run_lib.py:140] step: 80400, training_loss: 4.34087e-04
I0405 01:56:42.287181 23443585951552 run_lib.py:153] step: 80400, eval_loss: 3.89717e-04
I0405 01:57:03.789734 23443585951552 run_lib.py:140] step: 80450, training_loss: 4.42868e-04
I0405 01:57:25.259680 23443585951552 run_lib.py:140] step: 80500, training_loss: 4.22186e-04
I0405 01:57:25.431235 23443585951552 run_lib.py:153] step: 80500, eval_loss: 3.90326e-04
I0405 01:57:46.641603 23443585951552 run_lib.py:140] step: 80550, training_loss: 4.35872e-04
I0405 01:58:08.407604 23443585951552 run_lib.py:140] step: 80600, training_loss: 3.65878e-04
I0405 01:58:08.566104 23443585951552 run_lib.py:153] step: 80600, eval_loss: 3.47744e-04
I0405 01:58:30.167007 23443585951552 run_lib.py:140] step: 80650, training_loss: 4.06632e-04
I0405 01:58:51.438901 23443585951552 run_lib.py:140] step: 80700, training_loss: 3.94699e-04
I0405 01:58:51.612533 23443585951552 run_lib.py:153] step: 80700, eval_loss: 3.77003e-04
I0405 01:59:13.222243 23443585951552 run_lib.py:140] step: 80750, training_loss: 3.97589e-04
I0405 01:59:34.992384 23443585951552 run_lib.py:140] step: 80800, training_loss: 4.20275e-04
I0405 01:59:35.153851 23443585951552 run_lib.py:153] step: 80800, eval_loss: 4.21018e-04
I0405 01:59:56.763287 23443585951552 run_lib.py:140] step: 80850, training_loss: 4.00682e-04
I0405 02:00:18.426011 23443585951552 run_lib.py:140] step: 80900, training_loss: 4.02195e-04
I0405 02:00:18.596170 23443585951552 run_lib.py:153] step: 80900, eval_loss: 4.56570e-04
I0405 02:00:40.163302 23443585951552 run_lib.py:140] step: 80950, training_loss: 4.00188e-04
I0405 02:01:01.331402 23443585951552 run_lib.py:140] step: 81000, training_loss: 4.27397e-04
I0405 02:01:01.491258 23443585951552 run_lib.py:153] step: 81000, eval_loss: 3.81885e-04
I0405 02:01:23.106997 23443585951552 run_lib.py:140] step: 81050, training_loss: 3.96829e-04
I0405 02:01:42.544717 23443585951552 run_lib.py:140] step: 81100, training_loss: 3.85197e-04
I0405 02:01:42.715216 23443585951552 run_lib.py:153] step: 81100, eval_loss: 4.27285e-04
I0405 02:02:04.220464 23443585951552 run_lib.py:140] step: 81150, training_loss: 3.73206e-04
I0405 02:02:25.974730 23443585951552 run_lib.py:140] step: 81200, training_loss: 4.30713e-04
I0405 02:02:26.145186 23443585951552 run_lib.py:153] step: 81200, eval_loss: 3.87352e-04
I0405 02:02:46.378105 23443585951552 run_lib.py:140] step: 81250, training_loss: 4.55318e-04
I0405 02:03:11.581392 23443585951552 run_lib.py:140] step: 81300, training_loss: 3.87288e-04
I0405 02:03:11.733863 23443585951552 run_lib.py:153] step: 81300, eval_loss: 4.00132e-04
I0405 02:03:33.295118 23443585951552 run_lib.py:140] step: 81350, training_loss: 4.24378e-04
I0405 02:03:53.962362 23443585951552 run_lib.py:140] step: 81400, training_loss: 4.23258e-04
I0405 02:04:00.027924 23443585951552 run_lib.py:153] step: 81400, eval_loss: 3.74403e-04
I0405 02:04:22.170151 23443585951552 run_lib.py:140] step: 81450, training_loss: 4.15663e-04
I0405 02:04:43.965138 23443585951552 run_lib.py:140] step: 81500, training_loss: 4.06972e-04
I0405 02:04:44.124837 23443585951552 run_lib.py:153] step: 81500, eval_loss: 3.98169e-04
I0405 02:05:04.475173 23443585951552 run_lib.py:140] step: 81550, training_loss: 3.80926e-04
I0405 02:05:31.658371 23443585951552 run_lib.py:140] step: 81600, training_loss: 4.03437e-04
I0405 02:05:31.818194 23443585951552 run_lib.py:153] step: 81600, eval_loss: 4.05098e-04
I0405 02:05:53.585815 23443585951552 run_lib.py:140] step: 81650, training_loss: 4.04960e-04
I0405 02:06:14.157240 23443585951552 run_lib.py:140] step: 81700, training_loss: 3.72570e-04
I0405 02:06:20.277456 23443585951552 run_lib.py:153] step: 81700, eval_loss: 4.62300e-04
I0405 02:06:41.736111 23443585951552 run_lib.py:140] step: 81750, training_loss: 3.81677e-04
I0405 02:07:03.286875 23443585951552 run_lib.py:140] step: 81800, training_loss: 3.90210e-04
I0405 02:07:03.444466 23443585951552 run_lib.py:153] step: 81800, eval_loss: 4.05214e-04
I0405 02:07:24.084038 23443585951552 run_lib.py:140] step: 81850, training_loss: 3.69245e-04
I0405 02:07:51.852964 23443585951552 run_lib.py:140] step: 81900, training_loss: 4.64530e-04
I0405 02:07:52.017194 23443585951552 run_lib.py:153] step: 81900, eval_loss: 3.85088e-04
I0405 02:08:13.524143 23443585951552 run_lib.py:140] step: 81950, training_loss: 3.80419e-04
I0405 02:08:35.542599 23443585951552 run_lib.py:140] step: 82000, training_loss: 4.06744e-04
I0405 02:08:35.707523 23443585951552 run_lib.py:153] step: 82000, eval_loss: 4.09469e-04
I0405 02:08:57.355020 23443585951552 run_lib.py:140] step: 82050, training_loss: 3.56905e-04
I0405 02:09:18.827475 23443585951552 run_lib.py:140] step: 82100, training_loss: 4.27227e-04
I0405 02:09:18.984280 23443585951552 run_lib.py:153] step: 82100, eval_loss: 4.74259e-04
I0405 02:09:41.137930 23443585951552 run_lib.py:140] step: 82150, training_loss: 3.53415e-04
I0405 02:10:02.728106 23443585951552 run_lib.py:140] step: 82200, training_loss: 4.06016e-04
I0405 02:10:02.882386 23443585951552 run_lib.py:153] step: 82200, eval_loss: 4.16471e-04
I0405 02:10:24.724277 23443585951552 run_lib.py:140] step: 82250, training_loss: 4.22833e-04
I0405 02:10:46.280628 23443585951552 run_lib.py:140] step: 82300, training_loss: 3.74748e-04
I0405 02:10:46.456111 23443585951552 run_lib.py:153] step: 82300, eval_loss: 4.29406e-04
I0405 02:11:08.134484 23443585951552 run_lib.py:140] step: 82350, training_loss: 4.03021e-04
I0405 02:11:29.494515 23443585951552 run_lib.py:140] step: 82400, training_loss: 4.56475e-04
I0405 02:11:29.656335 23443585951552 run_lib.py:153] step: 82400, eval_loss: 3.68831e-04
I0405 02:11:51.203134 23443585951552 run_lib.py:140] step: 82450, training_loss: 3.83709e-04
I0405 02:12:12.960275 23443585951552 run_lib.py:140] step: 82500, training_loss: 4.42596e-04
I0405 02:12:13.125703 23443585951552 run_lib.py:153] step: 82500, eval_loss: 3.86667e-04
I0405 02:12:34.694533 23443585951552 run_lib.py:140] step: 82550, training_loss: 4.45139e-04
I0405 02:12:56.765291 23443585951552 run_lib.py:140] step: 82600, training_loss: 3.68173e-04
I0405 02:12:56.923217 23443585951552 run_lib.py:153] step: 82600, eval_loss: 3.87388e-04
I0405 02:13:18.539267 23443585951552 run_lib.py:140] step: 82650, training_loss: 4.05382e-04
I0405 02:13:39.800486 23443585951552 run_lib.py:140] step: 82700, training_loss: 3.91554e-04
I0405 02:13:39.958671 23443585951552 run_lib.py:153] step: 82700, eval_loss: 3.93553e-04
I0405 02:14:01.660720 23443585951552 run_lib.py:140] step: 82750, training_loss: 4.26186e-04
I0405 02:14:23.384466 23443585951552 run_lib.py:140] step: 82800, training_loss: 3.76917e-04
I0405 02:14:23.670129 23443585951552 run_lib.py:153] step: 82800, eval_loss: 3.46656e-04
I0405 02:14:44.834187 23443585951552 run_lib.py:140] step: 82850, training_loss: 4.07192e-04
I0405 02:15:06.409725 23443585951552 run_lib.py:140] step: 82900, training_loss: 3.58765e-04
I0405 02:15:06.577520 23443585951552 run_lib.py:153] step: 82900, eval_loss: 4.21864e-04
I0405 02:15:28.157719 23443585951552 run_lib.py:140] step: 82950, training_loss: 3.98627e-04
I0405 02:15:49.964094 23443585951552 run_lib.py:140] step: 83000, training_loss: 3.89085e-04
I0405 02:15:50.120424 23443585951552 run_lib.py:153] step: 83000, eval_loss: 4.37690e-04
I0405 02:16:11.677885 23443585951552 run_lib.py:140] step: 83050, training_loss: 4.22241e-04
I0405 02:16:33.438209 23443585951552 run_lib.py:140] step: 83100, training_loss: 4.35874e-04
I0405 02:16:33.597704 23443585951552 run_lib.py:153] step: 83100, eval_loss: 3.58395e-04
I0405 02:16:55.064320 23443585951552 run_lib.py:140] step: 83150, training_loss: 3.57684e-04
I0405 02:17:16.652876 23443585951552 run_lib.py:140] step: 83200, training_loss: 4.86609e-04
I0405 02:17:16.813461 23443585951552 run_lib.py:153] step: 83200, eval_loss: 4.35522e-04
I0405 02:17:38.627806 23443585951552 run_lib.py:140] step: 83250, training_loss: 4.31432e-04
I0405 02:18:00.127442 23443585951552 run_lib.py:140] step: 83300, training_loss: 3.94285e-04
I0405 02:18:00.283027 23443585951552 run_lib.py:153] step: 83300, eval_loss: 3.92793e-04
I0405 02:18:22.006647 23443585951552 run_lib.py:140] step: 83350, training_loss: 4.18649e-04
I0405 02:18:43.846298 23443585951552 run_lib.py:140] step: 83400, training_loss: 3.71197e-04
I0405 02:18:44.023094 23443585951552 run_lib.py:153] step: 83400, eval_loss: 4.09779e-04
I0405 02:19:05.954779 23443585951552 run_lib.py:140] step: 83450, training_loss: 3.79278e-04
I0405 02:19:27.689857 23443585951552 run_lib.py:140] step: 83500, training_loss: 4.18481e-04
I0405 02:19:27.843710 23443585951552 run_lib.py:153] step: 83500, eval_loss: 4.06900e-04
I0405 02:19:49.672130 23443585951552 run_lib.py:140] step: 83550, training_loss: 3.67060e-04
I0405 02:20:10.823282 23443585951552 run_lib.py:140] step: 83600, training_loss: 4.16952e-04
I0405 02:20:10.983407 23443585951552 run_lib.py:153] step: 83600, eval_loss: 4.09645e-04
I0405 02:20:32.912784 23443585951552 run_lib.py:140] step: 83650, training_loss: 3.72744e-04
I0405 02:20:54.632359 23443585951552 run_lib.py:140] step: 83700, training_loss: 4.71166e-04
I0405 02:20:54.786481 23443585951552 run_lib.py:153] step: 83700, eval_loss: 4.21390e-04
I0405 02:21:16.395930 23443585951552 run_lib.py:140] step: 83750, training_loss: 4.98905e-04
I0405 02:21:37.983940 23443585951552 run_lib.py:140] step: 83800, training_loss: 4.01157e-04
I0405 02:21:38.141982 23443585951552 run_lib.py:153] step: 83800, eval_loss: 3.96998e-04
I0405 02:21:59.932218 23443585951552 run_lib.py:140] step: 83850, training_loss: 3.97100e-04
I0405 02:22:21.651030 23443585951552 run_lib.py:140] step: 83900, training_loss: 4.52100e-04
I0405 02:22:21.810057 23443585951552 run_lib.py:153] step: 83900, eval_loss: 3.75219e-04
I0405 02:22:43.173093 23443585951552 run_lib.py:140] step: 83950, training_loss: 4.08085e-04
I0405 02:23:04.633549 23443585951552 run_lib.py:140] step: 84000, training_loss: 3.53626e-04
I0405 02:23:04.791209 23443585951552 run_lib.py:153] step: 84000, eval_loss: 3.87162e-04
I0405 02:23:26.435678 23443585951552 run_lib.py:140] step: 84050, training_loss: 3.95410e-04
I0405 02:23:48.205113 23443585951552 run_lib.py:140] step: 84100, training_loss: 4.18375e-04
I0405 02:23:48.360299 23443585951552 run_lib.py:153] step: 84100, eval_loss: 3.90375e-04
I0405 02:24:09.981346 23443585951552 run_lib.py:140] step: 84150, training_loss: 3.86024e-04
I0405 02:24:31.512850 23443585951552 run_lib.py:140] step: 84200, training_loss: 3.99014e-04
I0405 02:24:31.666280 23443585951552 run_lib.py:153] step: 84200, eval_loss: 3.73301e-04
I0405 02:24:53.074117 23443585951552 run_lib.py:140] step: 84250, training_loss: 4.28350e-04
I0405 02:25:14.368134 23443585951552 run_lib.py:140] step: 84300, training_loss: 4.36655e-04
I0405 02:25:14.545050 23443585951552 run_lib.py:153] step: 84300, eval_loss: 3.82994e-04
I0405 02:25:36.286303 23443585951552 run_lib.py:140] step: 84350, training_loss: 4.76534e-04
I0405 02:25:57.915675 23443585951552 run_lib.py:140] step: 84400, training_loss: 4.15472e-04
I0405 02:25:58.073063 23443585951552 run_lib.py:153] step: 84400, eval_loss: 3.63124e-04
I0405 02:26:19.825199 23443585951552 run_lib.py:140] step: 84450, training_loss: 4.14669e-04
I0405 02:26:41.158596 23443585951552 run_lib.py:140] step: 84500, training_loss: 3.87325e-04
I0405 02:26:41.328474 23443585951552 run_lib.py:153] step: 84500, eval_loss: 3.69430e-04
I0405 02:27:03.252808 23443585951552 run_lib.py:140] step: 84550, training_loss: 4.02445e-04
I0405 02:27:24.561678 23443585951552 run_lib.py:140] step: 84600, training_loss: 4.16412e-04
I0405 02:27:24.713066 23443585951552 run_lib.py:153] step: 84600, eval_loss: 4.03864e-04
I0405 02:27:46.097375 23443585951552 run_lib.py:140] step: 84650, training_loss: 3.87549e-04
I0405 02:28:07.336592 23443585951552 run_lib.py:140] step: 84700, training_loss: 3.65010e-04
I0405 02:28:07.492171 23443585951552 run_lib.py:153] step: 84700, eval_loss: 4.25489e-04
I0405 02:28:29.493253 23443585951552 run_lib.py:140] step: 84750, training_loss: 3.72344e-04
I0405 02:28:51.367144 23443585951552 run_lib.py:140] step: 84800, training_loss: 4.24582e-04
I0405 02:28:51.536229 23443585951552 run_lib.py:153] step: 84800, eval_loss: 4.46293e-04
I0405 02:29:13.245010 23443585951552 run_lib.py:140] step: 84850, training_loss: 4.33135e-04
I0405 02:29:34.786313 23443585951552 run_lib.py:140] step: 84900, training_loss: 4.28429e-04
I0405 02:29:34.946432 23443585951552 run_lib.py:153] step: 84900, eval_loss: 3.83803e-04
I0405 02:29:56.235226 23443585951552 run_lib.py:140] step: 84950, training_loss: 4.36725e-04
I0405 02:30:17.907180 23443585951552 run_lib.py:140] step: 85000, training_loss: 3.66440e-04
I0405 02:30:18.065562 23443585951552 run_lib.py:153] step: 85000, eval_loss: 4.06552e-04
I0405 02:30:39.879767 23443585951552 run_lib.py:140] step: 85050, training_loss: 4.21683e-04
I0405 02:31:01.618787 23443585951552 run_lib.py:140] step: 85100, training_loss: 4.35179e-04
I0405 02:31:01.770153 23443585951552 run_lib.py:153] step: 85100, eval_loss: 4.23505e-04
I0405 02:31:23.319159 23443585951552 run_lib.py:140] step: 85150, training_loss: 4.24597e-04
I0405 02:31:44.876726 23443585951552 run_lib.py:140] step: 85200, training_loss: 3.89409e-04
I0405 02:31:45.049483 23443585951552 run_lib.py:153] step: 85200, eval_loss: 3.54309e-04
I0405 02:32:06.933049 23443585951552 run_lib.py:140] step: 85250, training_loss: 3.59923e-04
I0405 02:32:28.714542 23443585951552 run_lib.py:140] step: 85300, training_loss: 3.56674e-04
I0405 02:32:28.874106 23443585951552 run_lib.py:153] step: 85300, eval_loss: 4.29723e-04
I0405 02:32:50.223145 23443585951552 run_lib.py:140] step: 85350, training_loss: 3.81725e-04
I0405 02:33:11.725236 23443585951552 run_lib.py:140] step: 85400, training_loss: 4.12225e-04
I0405 02:33:11.882727 23443585951552 run_lib.py:153] step: 85400, eval_loss: 3.80838e-04
I0405 02:33:33.546006 23443585951552 run_lib.py:140] step: 85450, training_loss: 3.98776e-04
I0405 02:33:55.215155 23443585951552 run_lib.py:140] step: 85500, training_loss: 3.92547e-04
I0405 02:33:55.376337 23443585951552 run_lib.py:153] step: 85500, eval_loss: 4.25581e-04
I0405 02:34:17.157761 23443585951552 run_lib.py:140] step: 85550, training_loss: 4.01993e-04
I0405 02:34:38.457988 23443585951552 run_lib.py:140] step: 85600, training_loss: 3.80756e-04
I0405 02:34:38.614701 23443585951552 run_lib.py:153] step: 85600, eval_loss: 3.53308e-04
I0405 02:35:00.340179 23443585951552 run_lib.py:140] step: 85650, training_loss: 3.88791e-04
I0405 02:35:21.778472 23443585951552 run_lib.py:140] step: 85700, training_loss: 4.45217e-04
I0405 02:35:21.936784 23443585951552 run_lib.py:153] step: 85700, eval_loss: 4.38964e-04
I0405 02:35:43.033438 23443585951552 run_lib.py:140] step: 85750, training_loss: 3.99247e-04
I0405 02:36:04.462345 23443585951552 run_lib.py:140] step: 85800, training_loss: 4.07064e-04
I0405 02:36:04.625411 23443585951552 run_lib.py:153] step: 85800, eval_loss: 3.69267e-04
I0405 02:36:26.023392 23443585951552 run_lib.py:140] step: 85850, training_loss: 3.42951e-04
I0405 02:36:47.863176 23443585951552 run_lib.py:140] step: 85900, training_loss: 3.81659e-04
I0405 02:36:48.019287 23443585951552 run_lib.py:153] step: 85900, eval_loss: 3.98385e-04
I0405 02:37:09.642067 23443585951552 run_lib.py:140] step: 85950, training_loss: 3.81880e-04
I0405 02:37:31.091091 23443585951552 run_lib.py:140] step: 86000, training_loss: 3.43301e-04
I0405 02:37:31.245788 23443585951552 run_lib.py:153] step: 86000, eval_loss: 3.93385e-04
I0405 02:37:53.002605 23443585951552 run_lib.py:140] step: 86050, training_loss: 3.84765e-04
I0405 02:38:14.823382 23443585951552 run_lib.py:140] step: 86100, training_loss: 4.56121e-04
I0405 02:38:14.980006 23443585951552 run_lib.py:153] step: 86100, eval_loss: 3.93246e-04
I0405 02:38:36.322526 23443585951552 run_lib.py:140] step: 86150, training_loss: 3.30674e-04
I0405 02:38:57.754117 23443585951552 run_lib.py:140] step: 86200, training_loss: 3.85728e-04
I0405 02:38:57.911148 23443585951552 run_lib.py:153] step: 86200, eval_loss: 4.12523e-04
I0405 02:39:19.269257 23443585951552 run_lib.py:140] step: 86250, training_loss: 3.81184e-04
I0405 02:39:41.024761 23443585951552 run_lib.py:140] step: 86300, training_loss: 3.88316e-04
I0405 02:39:41.196537 23443585951552 run_lib.py:153] step: 86300, eval_loss: 3.64948e-04
I0405 02:40:03.039041 23443585951552 run_lib.py:140] step: 86350, training_loss: 3.82008e-04
I0405 02:40:24.611336 23443585951552 run_lib.py:140] step: 86400, training_loss: 3.75269e-04
I0405 02:40:24.769397 23443585951552 run_lib.py:153] step: 86400, eval_loss: 4.05052e-04
I0405 02:40:46.287584 23443585951552 run_lib.py:140] step: 86450, training_loss: 3.71201e-04
I0405 02:41:07.547136 23443585951552 run_lib.py:140] step: 86500, training_loss: 4.18313e-04
I0405 02:41:07.735216 23443585951552 run_lib.py:153] step: 86500, eval_loss: 4.07810e-04
I0405 02:41:29.608016 23443585951552 run_lib.py:140] step: 86550, training_loss: 3.64330e-04
I0405 02:41:51.385628 23443585951552 run_lib.py:140] step: 86600, training_loss: 4.18509e-04
I0405 02:41:51.542285 23443585951552 run_lib.py:153] step: 86600, eval_loss: 4.34531e-04
I0405 02:42:13.171027 23443585951552 run_lib.py:140] step: 86650, training_loss: 3.91509e-04
I0405 02:42:34.596284 23443585951552 run_lib.py:140] step: 86700, training_loss: 4.02872e-04
I0405 02:42:34.778367 23443585951552 run_lib.py:153] step: 86700, eval_loss: 3.87880e-04
I0405 02:42:56.598323 23443585951552 run_lib.py:140] step: 86750, training_loss: 4.21618e-04
I0405 02:43:18.102095 23443585951552 run_lib.py:140] step: 86800, training_loss: 4.04076e-04
I0405 02:43:18.266179 23443585951552 run_lib.py:153] step: 86800, eval_loss: 4.61742e-04
I0405 02:43:39.826082 23443585951552 run_lib.py:140] step: 86850, training_loss: 4.02526e-04
I0405 02:44:01.238143 23443585951552 run_lib.py:140] step: 86900, training_loss: 3.68645e-04
I0405 02:44:01.398056 23443585951552 run_lib.py:153] step: 86900, eval_loss: 4.44588e-04
I0405 02:44:23.236703 23443585951552 run_lib.py:140] step: 86950, training_loss: 3.87345e-04
I0405 02:44:45.164583 23443585951552 run_lib.py:140] step: 87000, training_loss: 4.09489e-04
I0405 02:44:45.322756 23443585951552 run_lib.py:153] step: 87000, eval_loss: 4.37432e-04
I0405 02:45:07.120254 23443585951552 run_lib.py:140] step: 87050, training_loss: 3.59404e-04
I0405 02:45:28.385279 23443585951552 run_lib.py:140] step: 87100, training_loss: 4.48496e-04
I0405 02:45:28.542619 23443585951552 run_lib.py:153] step: 87100, eval_loss: 4.66601e-04
I0405 02:45:50.035921 23443585951552 run_lib.py:140] step: 87150, training_loss: 4.24728e-04
I0405 02:46:11.644475 23443585951552 run_lib.py:140] step: 87200, training_loss: 4.44895e-04
I0405 02:46:11.806906 23443585951552 run_lib.py:153] step: 87200, eval_loss: 4.34446e-04
I0405 02:46:33.199245 23443585951552 run_lib.py:140] step: 87250, training_loss: 4.00001e-04
I0405 02:46:54.580849 23443585951552 run_lib.py:140] step: 87300, training_loss: 3.88527e-04
I0405 02:46:54.740656 23443585951552 run_lib.py:153] step: 87300, eval_loss: 4.02964e-04
I0405 02:47:16.339836 23443585951552 run_lib.py:140] step: 87350, training_loss: 3.61825e-04
I0405 02:47:38.275509 23443585951552 run_lib.py:140] step: 87400, training_loss: 3.64346e-04
I0405 02:47:38.441637 23443585951552 run_lib.py:153] step: 87400, eval_loss: 3.92304e-04
I0405 02:47:59.954794 23443585951552 run_lib.py:140] step: 87450, training_loss: 3.81539e-04
I0405 02:48:21.460811 23443585951552 run_lib.py:140] step: 87500, training_loss: 3.78483e-04
I0405 02:48:21.613922 23443585951552 run_lib.py:153] step: 87500, eval_loss: 3.58012e-04
I0405 02:48:43.137465 23443585951552 run_lib.py:140] step: 87550, training_loss: 4.04354e-04
I0405 02:49:04.533371 23443585951552 run_lib.py:140] step: 87600, training_loss: 4.26659e-04
I0405 02:49:04.694258 23443585951552 run_lib.py:153] step: 87600, eval_loss: 3.77108e-04
I0405 02:49:26.739107 23443585951552 run_lib.py:140] step: 87650, training_loss: 4.41247e-04
I0405 02:49:48.417947 23443585951552 run_lib.py:140] step: 87700, training_loss: 4.17885e-04
I0405 02:49:48.577066 23443585951552 run_lib.py:153] step: 87700, eval_loss: 4.37182e-04
I0405 02:50:10.447775 23443585951552 run_lib.py:140] step: 87750, training_loss: 3.79910e-04
I0405 02:50:31.954218 23443585951552 run_lib.py:140] step: 87800, training_loss: 3.75373e-04
I0405 02:50:32.116368 23443585951552 run_lib.py:153] step: 87800, eval_loss: 3.91136e-04
I0405 02:50:53.788021 23443585951552 run_lib.py:140] step: 87850, training_loss: 3.79959e-04
I0405 02:51:15.431219 23443585951552 run_lib.py:140] step: 87900, training_loss: 3.97151e-04
I0405 02:51:15.588635 23443585951552 run_lib.py:153] step: 87900, eval_loss: 4.08022e-04
I0405 02:51:37.150120 23443585951552 run_lib.py:140] step: 87950, training_loss: 3.65597e-04
I0405 02:51:58.704507 23443585951552 run_lib.py:140] step: 88000, training_loss: 4.59601e-04
I0405 02:51:58.859025 23443585951552 run_lib.py:153] step: 88000, eval_loss: 4.18479e-04
I0405 02:52:20.767152 23443585951552 run_lib.py:140] step: 88050, training_loss: 3.88885e-04
I0405 02:52:42.592653 23443585951552 run_lib.py:140] step: 88100, training_loss: 3.66053e-04
I0405 02:52:42.754166 23443585951552 run_lib.py:153] step: 88100, eval_loss: 3.78057e-04
I0405 02:53:04.197062 23443585951552 run_lib.py:140] step: 88150, training_loss: 3.87101e-04
I0405 02:53:25.938240 23443585951552 run_lib.py:140] step: 88200, training_loss: 3.99583e-04
I0405 02:53:26.093905 23443585951552 run_lib.py:153] step: 88200, eval_loss: 4.13016e-04
I0405 02:53:47.716785 23443585951552 run_lib.py:140] step: 88250, training_loss: 4.77208e-04
I0405 02:54:09.813384 23443585951552 run_lib.py:140] step: 88300, training_loss: 3.85386e-04
I0405 02:54:09.971369 23443585951552 run_lib.py:153] step: 88300, eval_loss: 4.17487e-04
I0405 02:54:31.338828 23443585951552 run_lib.py:140] step: 88350, training_loss: 4.15732e-04
I0405 02:54:52.786898 23443585951552 run_lib.py:140] step: 88400, training_loss: 4.40088e-04
I0405 02:54:52.934030 23443585951552 run_lib.py:153] step: 88400, eval_loss: 3.89113e-04
I0405 02:55:14.430355 23443585951552 run_lib.py:140] step: 88450, training_loss: 3.64902e-04
I0405 02:55:36.032876 23443585951552 run_lib.py:140] step: 88500, training_loss: 4.33729e-04
I0405 02:55:36.199349 23443585951552 run_lib.py:153] step: 88500, eval_loss: 4.29126e-04
I0405 02:55:57.943441 23443585951552 run_lib.py:140] step: 88550, training_loss: 3.41517e-04
I0405 02:56:19.572024 23443585951552 run_lib.py:140] step: 88600, training_loss: 4.39579e-04
I0405 02:56:19.734266 23443585951552 run_lib.py:153] step: 88600, eval_loss: 3.85970e-04
I0405 02:56:41.327961 23443585951552 run_lib.py:140] step: 88650, training_loss: 4.32159e-04
I0405 02:57:03.086405 23443585951552 run_lib.py:140] step: 88700, training_loss: 4.02769e-04
I0405 02:57:03.250939 23443585951552 run_lib.py:153] step: 88700, eval_loss: 3.85021e-04
I0405 02:57:24.945117 23443585951552 run_lib.py:140] step: 88750, training_loss: 4.27940e-04
I0405 02:57:46.317835 23443585951552 run_lib.py:140] step: 88800, training_loss: 4.31974e-04
I0405 02:57:46.478167 23443585951552 run_lib.py:153] step: 88800, eval_loss: 3.60451e-04
I0405 02:58:08.037683 23443585951552 run_lib.py:140] step: 88850, training_loss: 4.45105e-04
I0405 02:58:29.584020 23443585951552 run_lib.py:140] step: 88900, training_loss: 3.50912e-04
I0405 02:58:29.738042 23443585951552 run_lib.py:153] step: 88900, eval_loss: 3.45505e-04
I0405 02:58:51.718870 23443585951552 run_lib.py:140] step: 88950, training_loss: 4.37088e-04
I0405 02:59:13.290819 23443585951552 run_lib.py:140] step: 89000, training_loss: 4.12321e-04
I0405 02:59:13.449032 23443585951552 run_lib.py:153] step: 89000, eval_loss: 4.24243e-04
I0405 02:59:34.968580 23443585951552 run_lib.py:140] step: 89050, training_loss: 4.63289e-04
I0405 02:59:56.558492 23443585951552 run_lib.py:140] step: 89100, training_loss: 5.12960e-04
I0405 02:59:56.718182 23443585951552 run_lib.py:153] step: 89100, eval_loss: 3.69793e-04
I0405 03:00:18.515426 23443585951552 run_lib.py:140] step: 89150, training_loss: 4.14026e-04
I0405 03:00:40.472358 23443585951552 run_lib.py:140] step: 89200, training_loss: 4.39435e-04
I0405 03:00:40.634437 23443585951552 run_lib.py:153] step: 89200, eval_loss: 3.76883e-04
I0405 03:01:02.206591 23443585951552 run_lib.py:140] step: 89250, training_loss: 3.82876e-04
I0405 03:01:23.736400 23443585951552 run_lib.py:140] step: 89300, training_loss: 3.57842e-04
I0405 03:01:23.893070 23443585951552 run_lib.py:153] step: 89300, eval_loss: 3.36698e-04
I0405 03:01:45.578041 23443585951552 run_lib.py:140] step: 89350, training_loss: 4.30173e-04
I0405 03:02:07.361391 23443585951552 run_lib.py:140] step: 89400, training_loss: 4.20873e-04
I0405 03:02:07.518538 23443585951552 run_lib.py:153] step: 89400, eval_loss: 4.08207e-04
I0405 03:02:29.176088 23443585951552 run_lib.py:140] step: 89450, training_loss: 3.91773e-04
I0405 03:02:50.774784 23443585951552 run_lib.py:140] step: 89500, training_loss: 4.00015e-04
I0405 03:02:50.932093 23443585951552 run_lib.py:153] step: 89500, eval_loss: 4.35987e-04
I0405 03:03:12.359309 23443585951552 run_lib.py:140] step: 89550, training_loss: 4.09076e-04
I0405 03:03:34.030223 23443585951552 run_lib.py:140] step: 89600, training_loss: 4.45819e-04
I0405 03:03:34.196311 23443585951552 run_lib.py:153] step: 89600, eval_loss: 4.19528e-04
I0405 03:03:55.450093 23443585951552 run_lib.py:140] step: 89650, training_loss: 3.87121e-04
I0405 03:04:17.070662 23443585951552 run_lib.py:140] step: 89700, training_loss: 3.47200e-04
I0405 03:04:17.230805 23443585951552 run_lib.py:153] step: 89700, eval_loss: 4.21437e-04
I0405 03:04:38.740163 23443585951552 run_lib.py:140] step: 89750, training_loss: 4.22195e-04
I0405 03:05:00.263846 23443585951552 run_lib.py:140] step: 89800, training_loss: 4.86915e-04
I0405 03:05:00.418734 23443585951552 run_lib.py:153] step: 89800, eval_loss: 4.66760e-04
I0405 03:05:21.884458 23443585951552 run_lib.py:140] step: 89850, training_loss: 4.12092e-04
I0405 03:05:43.599778 23443585951552 run_lib.py:140] step: 89900, training_loss: 4.41095e-04
I0405 03:05:43.760267 23443585951552 run_lib.py:153] step: 89900, eval_loss: 3.72172e-04
I0405 03:06:05.567291 23443585951552 run_lib.py:140] step: 89950, training_loss: 4.34403e-04
I0405 03:06:27.128278 23443585951552 run_lib.py:140] step: 90000, training_loss: 3.61227e-04
I0405 03:06:28.048056 23443585951552 run_lib.py:153] step: 90000, eval_loss: 3.73134e-04
I0405 03:06:50.304597 23443585951552 run_lib.py:140] step: 90050, training_loss: 3.98212e-04
I0405 03:07:11.892163 23443585951552 run_lib.py:140] step: 90100, training_loss: 3.89473e-04
I0405 03:07:12.062200 23443585951552 run_lib.py:153] step: 90100, eval_loss: 3.96154e-04
I0405 03:07:33.781280 23443585951552 run_lib.py:140] step: 90150, training_loss: 3.56816e-04
I0405 03:07:55.593141 23443585951552 run_lib.py:140] step: 90200, training_loss: 3.87860e-04
I0405 03:07:55.750114 23443585951552 run_lib.py:153] step: 90200, eval_loss: 4.05569e-04
I0405 03:08:17.490934 23443585951552 run_lib.py:140] step: 90250, training_loss: 3.56324e-04
I0405 03:08:39.221954 23443585951552 run_lib.py:140] step: 90300, training_loss: 4.46157e-04
I0405 03:08:39.376392 23443585951552 run_lib.py:153] step: 90300, eval_loss: 3.55342e-04
I0405 03:09:00.767830 23443585951552 run_lib.py:140] step: 90350, training_loss: 3.85804e-04
I0405 03:09:22.306094 23443585951552 run_lib.py:140] step: 90400, training_loss: 4.24962e-04
I0405 03:09:22.461145 23443585951552 run_lib.py:153] step: 90400, eval_loss: 3.77007e-04
I0405 03:09:44.118052 23443585951552 run_lib.py:140] step: 90450, training_loss: 4.70621e-04
I0405 03:10:05.779392 23443585951552 run_lib.py:140] step: 90500, training_loss: 4.11154e-04
I0405 03:10:05.955157 23443585951552 run_lib.py:153] step: 90500, eval_loss: 4.56328e-04
I0405 03:10:27.463655 23443585951552 run_lib.py:140] step: 90550, training_loss: 3.88893e-04
I0405 03:10:49.185310 23443585951552 run_lib.py:140] step: 90600, training_loss: 4.24807e-04
I0405 03:10:49.341259 23443585951552 run_lib.py:153] step: 90600, eval_loss: 4.44576e-04
I0405 03:11:11.225947 23443585951552 run_lib.py:140] step: 90650, training_loss: 5.47494e-04
I0405 03:11:32.772500 23443585951552 run_lib.py:140] step: 90700, training_loss: 4.04907e-04
I0405 03:11:32.931986 23443585951552 run_lib.py:153] step: 90700, eval_loss: 3.32552e-04
I0405 03:11:54.746027 23443585951552 run_lib.py:140] step: 90750, training_loss: 3.73773e-04
I0405 03:12:16.027801 23443585951552 run_lib.py:140] step: 90800, training_loss: 4.02995e-04
I0405 03:12:16.183254 23443585951552 run_lib.py:153] step: 90800, eval_loss: 3.95135e-04
I0405 03:12:37.790224 23443585951552 run_lib.py:140] step: 90850, training_loss: 4.60461e-04
I0405 03:12:59.005259 23443585951552 run_lib.py:140] step: 90900, training_loss: 3.78867e-04
I0405 03:12:59.161101 23443585951552 run_lib.py:153] step: 90900, eval_loss: 3.53523e-04
I0405 03:13:21.145861 23443585951552 run_lib.py:140] step: 90950, training_loss: 4.39043e-04
I0405 03:13:42.707592 23443585951552 run_lib.py:140] step: 91000, training_loss: 3.61210e-04
I0405 03:13:42.865295 23443585951552 run_lib.py:153] step: 91000, eval_loss: 3.97355e-04
I0405 03:14:04.464045 23443585951552 run_lib.py:140] step: 91050, training_loss: 4.00934e-04
I0405 03:14:25.867535 23443585951552 run_lib.py:140] step: 91100, training_loss: 4.25147e-04
I0405 03:14:26.022214 23443585951552 run_lib.py:153] step: 91100, eval_loss: 3.69845e-04
I0405 03:14:47.223290 23443585951552 run_lib.py:140] step: 91150, training_loss: 4.04282e-04
I0405 03:15:08.603645 23443585951552 run_lib.py:140] step: 91200, training_loss: 4.59214e-04
I0405 03:15:08.759068 23443585951552 run_lib.py:153] step: 91200, eval_loss: 3.48636e-04
I0405 03:15:30.237599 23443585951552 run_lib.py:140] step: 91250, training_loss: 3.45058e-04
I0405 03:15:51.756677 23443585951552 run_lib.py:140] step: 91300, training_loss: 4.29680e-04
I0405 03:15:51.909037 23443585951552 run_lib.py:153] step: 91300, eval_loss: 3.76860e-04
I0405 03:16:13.300256 23443585951552 run_lib.py:140] step: 91350, training_loss: 3.86045e-04
I0405 03:16:34.852416 23443585951552 run_lib.py:140] step: 91400, training_loss: 4.51389e-04
I0405 03:16:35.023216 23443585951552 run_lib.py:153] step: 91400, eval_loss: 4.48233e-04
I0405 03:16:56.242027 23443585951552 run_lib.py:140] step: 91450, training_loss: 4.13660e-04
I0405 03:17:17.792623 23443585951552 run_lib.py:140] step: 91500, training_loss: 4.41549e-04
I0405 03:17:17.950165 23443585951552 run_lib.py:153] step: 91500, eval_loss: 3.57049e-04
I0405 03:17:39.764411 23443585951552 run_lib.py:140] step: 91550, training_loss: 3.98185e-04
I0405 03:18:01.266326 23443585951552 run_lib.py:140] step: 91600, training_loss: 4.32149e-04
I0405 03:18:01.421652 23443585951552 run_lib.py:153] step: 91600, eval_loss: 4.19925e-04
I0405 03:18:23.130036 23443585951552 run_lib.py:140] step: 91650, training_loss: 4.13335e-04
I0405 03:18:44.742135 23443585951552 run_lib.py:140] step: 91700, training_loss: 3.93904e-04
I0405 03:18:44.898375 23443585951552 run_lib.py:153] step: 91700, eval_loss: 4.20601e-04
I0405 03:19:06.433891 23443585951552 run_lib.py:140] step: 91750, training_loss: 3.60235e-04
I0405 03:19:27.779097 23443585951552 run_lib.py:140] step: 91800, training_loss: 3.96723e-04
I0405 03:19:27.934587 23443585951552 run_lib.py:153] step: 91800, eval_loss: 3.83550e-04
I0405 03:19:49.595457 23443585951552 run_lib.py:140] step: 91850, training_loss: 3.62034e-04
I0405 03:20:11.336575 23443585951552 run_lib.py:140] step: 91900, training_loss: 4.37951e-04
I0405 03:20:11.515815 23443585951552 run_lib.py:153] step: 91900, eval_loss: 3.76809e-04
I0405 03:20:32.986997 23443585951552 run_lib.py:140] step: 91950, training_loss: 4.28179e-04
I0405 03:20:54.398583 23443585951552 run_lib.py:140] step: 92000, training_loss: 3.57867e-04
I0405 03:20:54.554023 23443585951552 run_lib.py:153] step: 92000, eval_loss: 4.57211e-04
I0405 03:21:15.952804 23443585951552 run_lib.py:140] step: 92050, training_loss: 3.62029e-04
I0405 03:21:37.551985 23443585951552 run_lib.py:140] step: 92100, training_loss: 3.93081e-04
I0405 03:21:37.713577 23443585951552 run_lib.py:153] step: 92100, eval_loss: 4.03621e-04
I0405 03:21:59.307058 23443585951552 run_lib.py:140] step: 92150, training_loss: 3.36328e-04
I0405 03:22:20.276349 23443585951552 run_lib.py:140] step: 92200, training_loss: 3.90250e-04
I0405 03:22:20.428189 23443585951552 run_lib.py:153] step: 92200, eval_loss: 3.99601e-04
I0405 03:22:38.039984 23443585951552 run_lib.py:140] step: 92250, training_loss: 4.16928e-04
I0405 03:22:55.487658 23443585951552 run_lib.py:140] step: 92300, training_loss: 4.00648e-04
I0405 03:22:55.640897 23443585951552 run_lib.py:153] step: 92300, eval_loss: 4.71580e-04
I0405 03:23:13.119314 23443585951552 run_lib.py:140] step: 92350, training_loss: 4.49393e-04
I0405 03:23:30.726415 23443585951552 run_lib.py:140] step: 92400, training_loss: 4.34227e-04
I0405 03:23:30.905316 23443585951552 run_lib.py:153] step: 92400, eval_loss: 4.27698e-04
I0405 03:23:48.405601 23443585951552 run_lib.py:140] step: 92450, training_loss: 4.62882e-04
I0405 03:24:06.081942 23443585951552 run_lib.py:140] step: 92500, training_loss: 4.01525e-04
I0405 03:24:06.263078 23443585951552 run_lib.py:153] step: 92500, eval_loss: 4.10797e-04
I0405 03:24:23.748372 23443585951552 run_lib.py:140] step: 92550, training_loss: 4.80166e-04
I0405 03:24:41.188222 23443585951552 run_lib.py:140] step: 92600, training_loss: 3.87702e-04
I0405 03:24:41.341937 23443585951552 run_lib.py:153] step: 92600, eval_loss: 4.36711e-04
I0405 03:24:58.928483 23443585951552 run_lib.py:140] step: 92650, training_loss: 3.90519e-04
I0405 03:25:16.398392 23443585951552 run_lib.py:140] step: 92700, training_loss: 4.61515e-04
I0405 03:25:16.553093 23443585951552 run_lib.py:153] step: 92700, eval_loss: 4.13003e-04
I0405 03:25:34.128100 23443585951552 run_lib.py:140] step: 92750, training_loss: 3.79276e-04
I0405 03:25:51.847278 23443585951552 run_lib.py:140] step: 92800, training_loss: 3.68035e-04
I0405 03:25:52.004998 23443585951552 run_lib.py:153] step: 92800, eval_loss: 3.42617e-04
I0405 03:26:09.491425 23443585951552 run_lib.py:140] step: 92850, training_loss: 3.89938e-04
I0405 03:26:27.006567 23443585951552 run_lib.py:140] step: 92900, training_loss: 3.38449e-04
I0405 03:26:27.166324 23443585951552 run_lib.py:153] step: 92900, eval_loss: 4.39084e-04
I0405 03:26:44.782312 23443585951552 run_lib.py:140] step: 92950, training_loss: 3.66205e-04
I0405 03:27:02.306069 23443585951552 run_lib.py:140] step: 93000, training_loss: 3.82438e-04
I0405 03:27:02.470036 23443585951552 run_lib.py:153] step: 93000, eval_loss: 3.74149e-04
I0405 03:27:20.028897 23443585951552 run_lib.py:140] step: 93050, training_loss: 3.76932e-04
I0405 03:27:37.613283 23443585951552 run_lib.py:140] step: 93100, training_loss: 4.03227e-04
I0405 03:27:37.773739 23443585951552 run_lib.py:153] step: 93100, eval_loss: 4.09299e-04
I0405 03:27:55.553228 23443585951552 run_lib.py:140] step: 93150, training_loss: 3.64513e-04
I0405 03:28:13.191897 23443585951552 run_lib.py:140] step: 93200, training_loss: 4.17495e-04
I0405 03:28:13.344698 23443585951552 run_lib.py:153] step: 93200, eval_loss: 3.42432e-04
I0405 03:28:30.850618 23443585951552 run_lib.py:140] step: 93250, training_loss: 4.45273e-04
I0405 03:28:48.419120 23443585951552 run_lib.py:140] step: 93300, training_loss: 4.37649e-04
I0405 03:28:48.590119 23443585951552 run_lib.py:153] step: 93300, eval_loss: 4.09962e-04
I0405 03:29:06.425981 23443585951552 run_lib.py:140] step: 93350, training_loss: 4.04590e-04
I0405 03:29:24.060965 23443585951552 run_lib.py:140] step: 93400, training_loss: 3.79140e-04
I0405 03:29:24.227052 23443585951552 run_lib.py:153] step: 93400, eval_loss: 3.57189e-04
I0405 03:29:44.560228 23443585951552 run_lib.py:140] step: 93450, training_loss: 4.34603e-04
I0405 03:30:06.203171 23443585951552 run_lib.py:140] step: 93500, training_loss: 4.34752e-04
I0405 03:30:06.360250 23443585951552 run_lib.py:153] step: 93500, eval_loss: 3.83030e-04
I0405 03:30:27.938435 23443585951552 run_lib.py:140] step: 93550, training_loss: 3.64909e-04
I0405 03:30:50.096330 23443585951552 run_lib.py:140] step: 93600, training_loss: 3.36525e-04
I0405 03:30:50.252511 23443585951552 run_lib.py:153] step: 93600, eval_loss: 4.24857e-04
I0405 03:31:11.588019 23443585951552 run_lib.py:140] step: 93650, training_loss: 4.13883e-04
I0405 03:31:33.175830 23443585951552 run_lib.py:140] step: 93700, training_loss: 3.82480e-04
I0405 03:31:33.332089 23443585951552 run_lib.py:153] step: 93700, eval_loss: 3.55534e-04
I0405 03:31:54.792296 23443585951552 run_lib.py:140] step: 93750, training_loss: 4.17980e-04
I0405 03:32:16.335742 23443585951552 run_lib.py:140] step: 93800, training_loss: 3.99886e-04
I0405 03:32:16.516148 23443585951552 run_lib.py:153] step: 93800, eval_loss: 3.91663e-04
I0405 03:32:38.139842 23443585951552 run_lib.py:140] step: 93850, training_loss: 3.76781e-04
I0405 03:32:59.861570 23443585951552 run_lib.py:140] step: 93900, training_loss: 3.86039e-04
I0405 03:33:00.019951 23443585951552 run_lib.py:153] step: 93900, eval_loss: 3.82073e-04
I0405 03:33:21.610836 23443585951552 run_lib.py:140] step: 93950, training_loss: 3.65889e-04
I0405 03:33:43.409712 23443585951552 run_lib.py:140] step: 94000, training_loss: 3.58577e-04
I0405 03:33:43.568401 23443585951552 run_lib.py:153] step: 94000, eval_loss: 4.58685e-04
I0405 03:34:05.398978 23443585951552 run_lib.py:140] step: 94050, training_loss: 4.10566e-04
I0405 03:34:27.041195 23443585951552 run_lib.py:140] step: 94100, training_loss: 3.64169e-04
I0405 03:34:27.220807 23443585951552 run_lib.py:153] step: 94100, eval_loss: 4.05494e-04
I0405 03:34:48.543881 23443585951552 run_lib.py:140] step: 94150, training_loss: 3.90541e-04
I0405 03:35:10.117126 23443585951552 run_lib.py:140] step: 94200, training_loss: 3.89353e-04
I0405 03:35:10.320093 23443585951552 run_lib.py:153] step: 94200, eval_loss: 4.02954e-04
I0405 03:35:32.296569 23443585951552 run_lib.py:140] step: 94250, training_loss: 3.98342e-04
I0405 03:35:53.536482 23443585951552 run_lib.py:140] step: 94300, training_loss: 4.12673e-04
I0405 03:35:53.695179 23443585951552 run_lib.py:153] step: 94300, eval_loss: 3.58100e-04
I0405 03:36:15.316234 23443585951552 run_lib.py:140] step: 94350, training_loss: 4.27335e-04
I0405 03:36:36.289152 23443585951552 run_lib.py:140] step: 94400, training_loss: 3.91046e-04
I0405 03:36:36.449157 23443585951552 run_lib.py:153] step: 94400, eval_loss: 4.57281e-04
I0405 03:36:58.180570 23443585951552 run_lib.py:140] step: 94450, training_loss: 4.83937e-04
I0405 03:37:19.570538 23443585951552 run_lib.py:140] step: 94500, training_loss: 3.98210e-04
I0405 03:37:19.734656 23443585951552 run_lib.py:153] step: 94500, eval_loss: 4.16323e-04
I0405 03:37:41.388896 23443585951552 run_lib.py:140] step: 94550, training_loss: 3.64409e-04
I0405 03:38:03.036909 23443585951552 run_lib.py:140] step: 94600, training_loss: 4.58036e-04
I0405 03:38:03.189786 23443585951552 run_lib.py:153] step: 94600, eval_loss: 4.38373e-04
I0405 03:38:24.812546 23443585951552 run_lib.py:140] step: 94650, training_loss: 4.68310e-04
I0405 03:38:46.869405 23443585951552 run_lib.py:140] step: 94700, training_loss: 4.28795e-04
I0405 03:38:47.040978 23443585951552 run_lib.py:153] step: 94700, eval_loss: 4.48921e-04
I0405 03:39:08.617172 23443585951552 run_lib.py:140] step: 94750, training_loss: 3.86430e-04
I0405 03:39:30.051911 23443585951552 run_lib.py:140] step: 94800, training_loss: 3.91332e-04
I0405 03:39:30.217548 23443585951552 run_lib.py:153] step: 94800, eval_loss: 4.25478e-04
I0405 03:39:51.684706 23443585951552 run_lib.py:140] step: 94850, training_loss: 3.93769e-04
I0405 03:40:13.578085 23443585951552 run_lib.py:140] step: 94900, training_loss: 4.35880e-04
I0405 03:40:13.744584 23443585951552 run_lib.py:153] step: 94900, eval_loss: 4.03094e-04
I0405 03:40:35.383792 23443585951552 run_lib.py:140] step: 94950, training_loss: 3.86221e-04
I0405 03:40:57.132358 23443585951552 run_lib.py:140] step: 95000, training_loss: 3.84462e-04
I0405 03:40:57.286073 23443585951552 run_lib.py:153] step: 95000, eval_loss: 4.19498e-04
I0405 03:41:18.759894 23443585951552 run_lib.py:140] step: 95050, training_loss: 3.88167e-04
I0405 03:41:40.034444 23443585951552 run_lib.py:140] step: 95100, training_loss: 3.67767e-04
I0405 03:41:40.196063 23443585951552 run_lib.py:153] step: 95100, eval_loss: 3.61001e-04
I0405 03:42:02.077451 23443585951552 run_lib.py:140] step: 95150, training_loss: 3.98975e-04
I0405 03:42:23.974573 23443585951552 run_lib.py:140] step: 95200, training_loss: 4.43438e-04
I0405 03:42:24.131393 23443585951552 run_lib.py:153] step: 95200, eval_loss: 4.42271e-04
I0405 03:42:45.825043 23443585951552 run_lib.py:140] step: 95250, training_loss: 4.47106e-04
I0405 03:43:07.748762 23443585951552 run_lib.py:140] step: 95300, training_loss: 3.79111e-04
I0405 03:43:07.925625 23443585951552 run_lib.py:153] step: 95300, eval_loss: 4.21274e-04
I0405 03:43:29.825235 23443585951552 run_lib.py:140] step: 95350, training_loss: 4.09777e-04
I0405 03:43:51.873082 23443585951552 run_lib.py:140] step: 95400, training_loss: 4.74763e-04
I0405 03:43:52.032118 23443585951552 run_lib.py:153] step: 95400, eval_loss: 4.19337e-04
I0405 03:44:13.614150 23443585951552 run_lib.py:140] step: 95450, training_loss: 4.17248e-04
I0405 03:44:35.414630 23443585951552 run_lib.py:140] step: 95500, training_loss: 3.94993e-04
I0405 03:44:35.573872 23443585951552 run_lib.py:153] step: 95500, eval_loss: 4.28331e-04
I0405 03:44:57.470237 23443585951552 run_lib.py:140] step: 95550, training_loss: 4.11427e-04
I0405 03:45:19.054326 23443585951552 run_lib.py:140] step: 95600, training_loss: 3.98860e-04
I0405 03:45:19.212033 23443585951552 run_lib.py:153] step: 95600, eval_loss: 3.88854e-04
I0405 03:45:40.756760 23443585951552 run_lib.py:140] step: 95650, training_loss: 4.14812e-04
I0405 03:46:02.436600 23443585951552 run_lib.py:140] step: 95700, training_loss: 3.60836e-04
I0405 03:46:02.736389 23443585951552 run_lib.py:153] step: 95700, eval_loss: 4.26858e-04
I0405 03:46:23.769424 23443585951552 run_lib.py:140] step: 95750, training_loss: 4.47904e-04
I0405 03:46:45.582862 23443585951552 run_lib.py:140] step: 95800, training_loss: 3.83137e-04
I0405 03:46:45.740507 23443585951552 run_lib.py:153] step: 95800, eval_loss: 4.39749e-04
I0405 03:47:07.193905 23443585951552 run_lib.py:140] step: 95850, training_loss: 4.30334e-04
I0405 03:47:28.688607 23443585951552 run_lib.py:140] step: 95900, training_loss: 3.77750e-04
I0405 03:47:28.845004 23443585951552 run_lib.py:153] step: 95900, eval_loss: 4.54924e-04
I0405 03:47:50.509069 23443585951552 run_lib.py:140] step: 95950, training_loss: 3.59138e-04
I0405 03:48:12.164209 23443585951552 run_lib.py:140] step: 96000, training_loss: 4.76336e-04
I0405 03:48:12.324410 23443585951552 run_lib.py:153] step: 96000, eval_loss: 4.06052e-04
I0405 03:48:33.901664 23443585951552 run_lib.py:140] step: 96050, training_loss: 4.24114e-04
I0405 03:48:55.779788 23443585951552 run_lib.py:140] step: 96100, training_loss: 3.53314e-04
I0405 03:48:55.945052 23443585951552 run_lib.py:153] step: 96100, eval_loss: 4.50036e-04
I0405 03:49:17.469012 23443585951552 run_lib.py:140] step: 96150, training_loss: 4.60347e-04
I0405 03:49:39.006084 23443585951552 run_lib.py:140] step: 96200, training_loss: 3.74003e-04
I0405 03:49:39.183396 23443585951552 run_lib.py:153] step: 96200, eval_loss: 4.23239e-04
I0405 03:50:01.116534 23443585951552 run_lib.py:140] step: 96250, training_loss: 3.95373e-04
I0405 03:50:22.748539 23443585951552 run_lib.py:140] step: 96300, training_loss: 4.63147e-04
I0405 03:50:22.906629 23443585951552 run_lib.py:153] step: 96300, eval_loss: 3.67882e-04
I0405 03:50:44.204682 23443585951552 run_lib.py:140] step: 96350, training_loss: 4.20870e-04
I0405 03:51:05.707833 23443585951552 run_lib.py:140] step: 96400, training_loss: 4.01302e-04
I0405 03:51:05.865917 23443585951552 run_lib.py:153] step: 96400, eval_loss: 4.22392e-04
I0405 03:51:27.809856 23443585951552 run_lib.py:140] step: 96450, training_loss: 3.81120e-04
I0405 03:51:49.571782 23443585951552 run_lib.py:140] step: 96500, training_loss: 3.99192e-04
I0405 03:51:49.729074 23443585951552 run_lib.py:153] step: 96500, eval_loss: 4.52110e-04
I0405 03:52:11.331822 23443585951552 run_lib.py:140] step: 96550, training_loss: 4.22544e-04
I0405 03:52:32.811278 23443585951552 run_lib.py:140] step: 96600, training_loss: 4.26643e-04
I0405 03:52:32.967928 23443585951552 run_lib.py:153] step: 96600, eval_loss: 4.31373e-04
I0405 03:52:54.674594 23443585951552 run_lib.py:140] step: 96650, training_loss: 4.15707e-04
I0405 03:53:16.128114 23443585951552 run_lib.py:140] step: 96700, training_loss: 4.12069e-04
I0405 03:53:16.292908 23443585951552 run_lib.py:153] step: 96700, eval_loss: 4.04009e-04
I0405 03:53:37.728178 23443585951552 run_lib.py:140] step: 96750, training_loss: 3.56957e-04
I0405 03:53:59.132735 23443585951552 run_lib.py:140] step: 96800, training_loss: 3.89614e-04
I0405 03:53:59.295468 23443585951552 run_lib.py:153] step: 96800, eval_loss: 4.29916e-04
I0405 03:54:20.612427 23443585951552 run_lib.py:140] step: 96850, training_loss: 3.89703e-04
I0405 03:54:42.547443 23443585951552 run_lib.py:140] step: 96900, training_loss: 3.55762e-04
I0405 03:54:42.710465 23443585951552 run_lib.py:153] step: 96900, eval_loss: 3.68035e-04
I0405 03:55:04.403422 23443585951552 run_lib.py:140] step: 96950, training_loss: 3.77042e-04
I0405 03:55:26.051433 23443585951552 run_lib.py:140] step: 97000, training_loss: 4.39953e-04
I0405 03:55:26.206690 23443585951552 run_lib.py:153] step: 97000, eval_loss: 3.84926e-04
I0405 03:55:47.951644 23443585951552 run_lib.py:140] step: 97050, training_loss: 4.18866e-04
I0405 03:56:09.574331 23443585951552 run_lib.py:140] step: 97100, training_loss: 3.88125e-04
I0405 03:56:09.749925 23443585951552 run_lib.py:153] step: 97100, eval_loss: 3.62359e-04
I0405 03:56:31.543891 23443585951552 run_lib.py:140] step: 97150, training_loss: 4.24824e-04
I0405 03:56:53.224088 23443585951552 run_lib.py:140] step: 97200, training_loss: 4.02977e-04
I0405 03:56:53.393402 23443585951552 run_lib.py:153] step: 97200, eval_loss: 4.12931e-04
I0405 03:57:14.595696 23443585951552 run_lib.py:140] step: 97250, training_loss: 3.74152e-04
I0405 03:57:36.017134 23443585951552 run_lib.py:140] step: 97300, training_loss: 3.34705e-04
I0405 03:57:36.183157 23443585951552 run_lib.py:153] step: 97300, eval_loss: 4.27174e-04
I0405 03:57:57.743840 23443585951552 run_lib.py:140] step: 97350, training_loss: 4.21299e-04
I0405 03:58:19.478607 23443585951552 run_lib.py:140] step: 97400, training_loss: 3.43696e-04
I0405 03:58:19.631267 23443585951552 run_lib.py:153] step: 97400, eval_loss: 4.18622e-04
I0405 03:58:41.322211 23443585951552 run_lib.py:140] step: 97450, training_loss: 4.12587e-04
I0405 03:59:02.963355 23443585951552 run_lib.py:140] step: 97500, training_loss: 4.10977e-04
I0405 03:59:03.118263 23443585951552 run_lib.py:153] step: 97500, eval_loss: 4.31078e-04
I0405 03:59:24.588724 23443585951552 run_lib.py:140] step: 97550, training_loss: 4.18983e-04
I0405 03:59:46.156325 23443585951552 run_lib.py:140] step: 97600, training_loss: 4.49995e-04
I0405 03:59:46.311013 23443585951552 run_lib.py:153] step: 97600, eval_loss: 4.56531e-04
I0405 04:00:07.935606 23443585951552 run_lib.py:140] step: 97650, training_loss: 4.38816e-04
I0405 04:00:29.153287 23443585951552 run_lib.py:140] step: 97700, training_loss: 3.89089e-04
I0405 04:00:29.342308 23443585951552 run_lib.py:153] step: 97700, eval_loss: 3.66227e-04
I0405 04:00:51.109066 23443585951552 run_lib.py:140] step: 97750, training_loss: 4.06761e-04
I0405 04:01:12.945306 23443585951552 run_lib.py:140] step: 97800, training_loss: 3.64087e-04
I0405 04:01:13.100285 23443585951552 run_lib.py:153] step: 97800, eval_loss: 3.62757e-04
I0405 04:01:35.279086 23443585951552 run_lib.py:140] step: 97850, training_loss: 4.28792e-04
I0405 04:01:56.631170 23443585951552 run_lib.py:140] step: 97900, training_loss: 3.62208e-04
I0405 04:01:56.780573 23443585951552 run_lib.py:153] step: 97900, eval_loss: 3.95169e-04
I0405 04:02:18.503799 23443585951552 run_lib.py:140] step: 97950, training_loss: 4.15122e-04
I0405 04:02:39.932506 23443585951552 run_lib.py:140] step: 98000, training_loss: 4.26127e-04
I0405 04:02:40.086918 23443585951552 run_lib.py:153] step: 98000, eval_loss: 4.36865e-04
I0405 04:03:01.727656 23443585951552 run_lib.py:140] step: 98050, training_loss: 4.19193e-04
I0405 04:03:23.092014 23443585951552 run_lib.py:140] step: 98100, training_loss: 4.09444e-04
I0405 04:03:23.257978 23443585951552 run_lib.py:153] step: 98100, eval_loss: 3.85483e-04
I0405 04:03:45.137263 23443585951552 run_lib.py:140] step: 98150, training_loss: 4.01465e-04
I0405 04:04:06.928317 23443585951552 run_lib.py:140] step: 98200, training_loss: 4.39681e-04
I0405 04:04:07.088190 23443585951552 run_lib.py:153] step: 98200, eval_loss: 4.12335e-04
I0405 04:04:28.609513 23443585951552 run_lib.py:140] step: 98250, training_loss: 3.85849e-04
I0405 04:04:50.339747 23443585951552 run_lib.py:140] step: 98300, training_loss: 3.81743e-04
I0405 04:04:50.493921 23443585951552 run_lib.py:153] step: 98300, eval_loss: 4.24415e-04
I0405 04:05:11.998667 23443585951552 run_lib.py:140] step: 98350, training_loss: 4.19895e-04
I0405 04:05:33.366964 23443585951552 run_lib.py:140] step: 98400, training_loss: 3.65396e-04
I0405 04:05:33.521975 23443585951552 run_lib.py:153] step: 98400, eval_loss: 3.85617e-04
I0405 04:05:54.909188 23443585951552 run_lib.py:140] step: 98450, training_loss: 3.75017e-04
I0405 04:06:16.105309 23443585951552 run_lib.py:140] step: 98500, training_loss: 4.09035e-04
I0405 04:06:16.259834 23443585951552 run_lib.py:153] step: 98500, eval_loss: 3.99315e-04
I0405 04:06:37.905423 23443585951552 run_lib.py:140] step: 98550, training_loss: 3.72246e-04
I0405 04:06:59.630065 23443585951552 run_lib.py:140] step: 98600, training_loss: 3.90931e-04
I0405 04:06:59.805099 23443585951552 run_lib.py:153] step: 98600, eval_loss: 3.85048e-04
I0405 04:07:21.514848 23443585951552 run_lib.py:140] step: 98650, training_loss: 4.23248e-04
I0405 04:07:43.218604 23443585951552 run_lib.py:140] step: 98700, training_loss: 4.38782e-04
I0405 04:07:43.374598 23443585951552 run_lib.py:153] step: 98700, eval_loss: 4.07033e-04
I0405 04:08:04.777700 23443585951552 run_lib.py:140] step: 98750, training_loss: 4.23055e-04
I0405 04:08:26.097504 23443585951552 run_lib.py:140] step: 98800, training_loss: 3.82450e-04
I0405 04:08:26.251828 23443585951552 run_lib.py:153] step: 98800, eval_loss: 3.33246e-04
I0405 04:08:47.785754 23443585951552 run_lib.py:140] step: 98850, training_loss: 4.62814e-04
I0405 04:09:09.324206 23443585951552 run_lib.py:140] step: 98900, training_loss: 3.90484e-04
I0405 04:09:09.483201 23443585951552 run_lib.py:153] step: 98900, eval_loss: 3.78406e-04
I0405 04:09:31.003258 23443585951552 run_lib.py:140] step: 98950, training_loss: 4.64305e-04
I0405 04:09:52.810360 23443585951552 run_lib.py:140] step: 99000, training_loss: 4.33801e-04
I0405 04:09:52.968770 23443585951552 run_lib.py:153] step: 99000, eval_loss: 4.11669e-04
I0405 04:10:14.266107 23443585951552 run_lib.py:140] step: 99050, training_loss: 4.47931e-04
I0405 04:10:35.813960 23443585951552 run_lib.py:140] step: 99100, training_loss: 3.59514e-04
I0405 04:10:35.975008 23443585951552 run_lib.py:153] step: 99100, eval_loss: 4.07911e-04
I0405 04:10:57.677310 23443585951552 run_lib.py:140] step: 99150, training_loss: 3.93188e-04
I0405 04:11:19.329363 23443585951552 run_lib.py:140] step: 99200, training_loss: 4.25022e-04
I0405 04:11:19.483648 23443585951552 run_lib.py:153] step: 99200, eval_loss: 3.56774e-04
I0405 04:11:40.841359 23443585951552 run_lib.py:140] step: 99250, training_loss: 4.09726e-04
I0405 04:12:02.492864 23443585951552 run_lib.py:140] step: 99300, training_loss: 4.61013e-04
I0405 04:12:02.650156 23443585951552 run_lib.py:153] step: 99300, eval_loss: 3.64436e-04
I0405 04:12:24.252132 23443585951552 run_lib.py:140] step: 99350, training_loss: 4.61785e-04
I0405 04:12:46.113871 23443585951552 run_lib.py:140] step: 99400, training_loss: 3.70211e-04
I0405 04:12:46.268536 23443585951552 run_lib.py:153] step: 99400, eval_loss: 3.63135e-04
I0405 04:13:07.843754 23443585951552 run_lib.py:140] step: 99450, training_loss: 4.32801e-04
I0405 04:13:29.366021 23443585951552 run_lib.py:140] step: 99500, training_loss: 4.32649e-04
I0405 04:13:29.544871 23443585951552 run_lib.py:153] step: 99500, eval_loss: 3.71165e-04
I0405 04:13:51.364951 23443585951552 run_lib.py:140] step: 99550, training_loss: 4.06521e-04
I0405 04:14:12.915121 23443585951552 run_lib.py:140] step: 99600, training_loss: 3.69789e-04
I0405 04:14:13.071745 23443585951552 run_lib.py:153] step: 99600, eval_loss: 4.00083e-04
I0405 04:14:34.634862 23443585951552 run_lib.py:140] step: 99650, training_loss: 3.67343e-04
I0405 04:14:56.239664 23443585951552 run_lib.py:140] step: 99700, training_loss: 3.71010e-04
I0405 04:14:56.405880 23443585951552 run_lib.py:153] step: 99700, eval_loss: 3.66433e-04
I0405 04:15:18.200449 23443585951552 run_lib.py:140] step: 99750, training_loss: 4.53760e-04
I0405 04:15:40.042508 23443585951552 run_lib.py:140] step: 99800, training_loss: 3.92842e-04
I0405 04:15:40.200045 23443585951552 run_lib.py:153] step: 99800, eval_loss: 3.96727e-04
I0405 04:16:01.987477 23443585951552 run_lib.py:140] step: 99850, training_loss: 4.15708e-04
I0405 04:16:23.812740 23443585951552 run_lib.py:140] step: 99900, training_loss: 4.78448e-04
I0405 04:16:23.969926 23443585951552 run_lib.py:153] step: 99900, eval_loss: 4.02069e-04
I0405 04:16:45.736641 23443585951552 run_lib.py:140] step: 99950, training_loss: 3.91769e-04
I0405 04:17:07.289023 23443585951552 run_lib.py:140] step: 100000, training_loss: 4.07715e-04
I0405 04:17:08.152800 23443585951552 run_lib.py:153] step: 100000, eval_loss: 3.93352e-04
I0405 04:17:30.752441 23443585951552 run_lib.py:140] step: 100050, training_loss: 4.28784e-04
I0405 04:17:52.131091 23443585951552 run_lib.py:140] step: 100100, training_loss: 4.77117e-04
I0405 04:17:52.290177 23443585951552 run_lib.py:153] step: 100100, eval_loss: 3.99414e-04
I0405 04:18:14.034860 23443585951552 run_lib.py:140] step: 100150, training_loss: 4.45556e-04
I0405 04:18:35.944999 23443585951552 run_lib.py:140] step: 100200, training_loss: 4.15675e-04
I0405 04:18:36.102475 23443585951552 run_lib.py:153] step: 100200, eval_loss: 3.90310e-04
I0405 04:18:57.789762 23443585951552 run_lib.py:140] step: 100250, training_loss: 3.91722e-04
I0405 04:19:19.608775 23443585951552 run_lib.py:140] step: 100300, training_loss: 4.46172e-04
I0405 04:19:19.762050 23443585951552 run_lib.py:153] step: 100300, eval_loss: 3.98434e-04
I0405 04:19:41.788742 23443585951552 run_lib.py:140] step: 100350, training_loss: 4.42584e-04
I0405 04:20:03.529881 23443585951552 run_lib.py:140] step: 100400, training_loss: 4.10842e-04
I0405 04:20:03.701815 23443585951552 run_lib.py:153] step: 100400, eval_loss: 4.25602e-04
I0405 04:20:25.627481 23443585951552 run_lib.py:140] step: 100450, training_loss: 4.07455e-04
I0405 04:20:47.069455 23443585951552 run_lib.py:140] step: 100500, training_loss: 4.23922e-04
I0405 04:20:47.232099 23443585951552 run_lib.py:153] step: 100500, eval_loss: 3.93500e-04
I0405 04:21:08.653763 23443585951552 run_lib.py:140] step: 100550, training_loss: 4.33341e-04
I0405 04:21:30.365299 23443585951552 run_lib.py:140] step: 100600, training_loss: 3.52970e-04
I0405 04:21:30.527088 23443585951552 run_lib.py:153] step: 100600, eval_loss: 3.85384e-04
I0405 04:21:52.011416 23443585951552 run_lib.py:140] step: 100650, training_loss: 3.99123e-04
I0405 04:22:13.843128 23443585951552 run_lib.py:140] step: 100700, training_loss: 4.50662e-04
I0405 04:22:14.002625 23443585951552 run_lib.py:153] step: 100700, eval_loss: 4.24505e-04
I0405 04:22:35.808049 23443585951552 run_lib.py:140] step: 100750, training_loss: 4.00764e-04
I0405 04:22:57.408710 23443585951552 run_lib.py:140] step: 100800, training_loss: 4.26602e-04
I0405 04:22:57.562895 23443585951552 run_lib.py:153] step: 100800, eval_loss: 3.96063e-04
I0405 04:23:19.295181 23443585951552 run_lib.py:140] step: 100850, training_loss: 4.26948e-04
I0405 04:23:40.816941 23443585951552 run_lib.py:140] step: 100900, training_loss: 3.94365e-04
I0405 04:23:40.985999 23443585951552 run_lib.py:153] step: 100900, eval_loss: 3.73314e-04
I0405 04:24:02.719552 23443585951552 run_lib.py:140] step: 100950, training_loss: 3.51360e-04
I0405 04:24:24.062762 23443585951552 run_lib.py:140] step: 101000, training_loss: 4.15907e-04
I0405 04:24:24.227355 23443585951552 run_lib.py:153] step: 101000, eval_loss: 4.20484e-04
I0405 04:24:45.883167 23443585951552 run_lib.py:140] step: 101050, training_loss: 3.99289e-04
I0405 04:25:07.491716 23443585951552 run_lib.py:140] step: 101100, training_loss: 4.42342e-04
I0405 04:25:07.645390 23443585951552 run_lib.py:153] step: 101100, eval_loss: 4.19987e-04
I0405 04:25:29.181067 23443585951552 run_lib.py:140] step: 101150, training_loss: 3.70403e-04
I0405 04:25:50.521858 23443585951552 run_lib.py:140] step: 101200, training_loss: 4.59606e-04
I0405 04:25:50.684760 23443585951552 run_lib.py:153] step: 101200, eval_loss: 4.25626e-04
I0405 04:26:12.260427 23443585951552 run_lib.py:140] step: 101250, training_loss: 4.28510e-04
I0405 04:26:34.163173 23443585951552 run_lib.py:140] step: 101300, training_loss: 4.78617e-04
I0405 04:26:34.327882 23443585951552 run_lib.py:153] step: 101300, eval_loss: 4.08563e-04
I0405 04:26:55.901904 23443585951552 run_lib.py:140] step: 101350, training_loss: 3.59281e-04
I0405 04:27:17.241705 23443585951552 run_lib.py:140] step: 101400, training_loss: 4.46508e-04
I0405 04:27:17.401094 23443585951552 run_lib.py:153] step: 101400, eval_loss: 3.95719e-04
I0405 04:27:39.449930 23443585951552 run_lib.py:140] step: 101450, training_loss: 3.67564e-04
I0405 04:28:00.512600 23443585951552 run_lib.py:140] step: 101500, training_loss: 3.69114e-04
I0405 04:28:00.693239 23443585951552 run_lib.py:153] step: 101500, eval_loss: 3.84549e-04
I0405 04:28:22.311528 23443585951552 run_lib.py:140] step: 101550, training_loss: 4.00331e-04
I0405 04:28:43.891671 23443585951552 run_lib.py:140] step: 101600, training_loss: 4.03002e-04
I0405 04:28:44.050722 23443585951552 run_lib.py:153] step: 101600, eval_loss: 3.94109e-04
I0405 04:29:05.964679 23443585951552 run_lib.py:140] step: 101650, training_loss: 3.63744e-04
I0405 04:29:27.952174 23443585951552 run_lib.py:140] step: 101700, training_loss: 4.37798e-04
I0405 04:29:28.104117 23443585951552 run_lib.py:153] step: 101700, eval_loss: 3.97708e-04
I0405 04:29:49.797741 23443585951552 run_lib.py:140] step: 101750, training_loss: 4.01258e-04
I0405 04:30:11.452245 23443585951552 run_lib.py:140] step: 101800, training_loss: 3.87237e-04
I0405 04:30:11.632109 23443585951552 run_lib.py:153] step: 101800, eval_loss: 4.19794e-04
I0405 04:30:33.604593 23443585951552 run_lib.py:140] step: 101850, training_loss: 3.96451e-04
I0405 04:30:55.618754 23443585951552 run_lib.py:140] step: 101900, training_loss: 4.03564e-04
I0405 04:30:55.779911 23443585951552 run_lib.py:153] step: 101900, eval_loss: 3.69274e-04
I0405 04:31:17.546209 23443585951552 run_lib.py:140] step: 101950, training_loss: 4.34756e-04
I0405 04:31:39.402718 23443585951552 run_lib.py:140] step: 102000, training_loss: 5.08008e-04
I0405 04:31:39.561214 23443585951552 run_lib.py:153] step: 102000, eval_loss: 3.85981e-04
I0405 04:32:01.279085 23443585951552 run_lib.py:140] step: 102050, training_loss: 4.11059e-04
I0405 04:32:22.792518 23443585951552 run_lib.py:140] step: 102100, training_loss: 3.80293e-04
I0405 04:32:22.957788 23443585951552 run_lib.py:153] step: 102100, eval_loss: 3.51318e-04
I0405 04:32:44.794251 23443585951552 run_lib.py:140] step: 102150, training_loss: 4.04367e-04
I0405 04:33:06.281523 23443585951552 run_lib.py:140] step: 102200, training_loss: 3.37801e-04
I0405 04:33:06.439819 23443585951552 run_lib.py:153] step: 102200, eval_loss: 4.17151e-04
I0405 04:33:28.110350 23443585951552 run_lib.py:140] step: 102250, training_loss: 3.49834e-04
I0405 04:33:49.282769 23443585951552 run_lib.py:140] step: 102300, training_loss: 3.75158e-04
I0405 04:33:49.439962 23443585951552 run_lib.py:153] step: 102300, eval_loss: 3.98857e-04
I0405 04:34:10.597625 23443585951552 run_lib.py:140] step: 102350, training_loss: 3.50925e-04
I0405 04:34:31.880073 23443585951552 run_lib.py:140] step: 102400, training_loss: 4.05966e-04
I0405 04:34:32.056263 23443585951552 run_lib.py:153] step: 102400, eval_loss: 3.91843e-04
I0405 04:34:53.341637 23443585951552 run_lib.py:140] step: 102450, training_loss: 4.04595e-04
I0405 04:35:14.291884 23443585951552 run_lib.py:140] step: 102500, training_loss: 4.45985e-04
I0405 04:35:14.449821 23443585951552 run_lib.py:153] step: 102500, eval_loss: 4.18253e-04
I0405 04:35:36.026081 23443585951552 run_lib.py:140] step: 102550, training_loss: 3.86785e-04
I0405 04:35:57.246475 23443585951552 run_lib.py:140] step: 102600, training_loss: 3.77932e-04
I0405 04:35:57.401704 23443585951552 run_lib.py:153] step: 102600, eval_loss: 4.33673e-04
I0405 04:36:18.604818 23443585951552 run_lib.py:140] step: 102650, training_loss: 4.26983e-04
I0405 04:36:39.913655 23443585951552 run_lib.py:140] step: 102700, training_loss: 4.08790e-04
I0405 04:36:40.067863 23443585951552 run_lib.py:153] step: 102700, eval_loss: 3.86465e-04
I0405 04:37:01.323889 23443585951552 run_lib.py:140] step: 102750, training_loss: 3.74447e-04
I0405 04:37:22.151875 23443585951552 run_lib.py:140] step: 102800, training_loss: 3.71465e-04
I0405 04:37:22.314388 23443585951552 run_lib.py:153] step: 102800, eval_loss: 4.10409e-04
I0405 04:37:43.619218 23443585951552 run_lib.py:140] step: 102850, training_loss: 4.36081e-04
I0405 04:38:04.802192 23443585951552 run_lib.py:140] step: 102900, training_loss: 3.73685e-04
I0405 04:38:04.970522 23443585951552 run_lib.py:153] step: 102900, eval_loss: 4.23572e-04
I0405 04:38:25.952246 23443585951552 run_lib.py:140] step: 102950, training_loss: 3.97309e-04
I0405 04:38:46.921930 23443585951552 run_lib.py:140] step: 103000, training_loss: 3.52899e-04
I0405 04:38:47.078058 23443585951552 run_lib.py:153] step: 103000, eval_loss: 3.76804e-04
I0405 04:39:08.531791 23443585951552 run_lib.py:140] step: 103050, training_loss: 4.10589e-04
I0405 04:39:29.662275 23443585951552 run_lib.py:140] step: 103100, training_loss: 4.72713e-04
I0405 04:39:29.838158 23443585951552 run_lib.py:153] step: 103100, eval_loss: 3.52434e-04
I0405 04:39:50.795876 23443585951552 run_lib.py:140] step: 103150, training_loss: 3.99861e-04
I0405 04:40:11.900143 23443585951552 run_lib.py:140] step: 103200, training_loss: 4.00476e-04
I0405 04:40:12.064364 23443585951552 run_lib.py:153] step: 103200, eval_loss: 3.54608e-04
I0405 04:40:33.064402 23443585951552 run_lib.py:140] step: 103250, training_loss: 5.00872e-04
I0405 04:40:53.934446 23443585951552 run_lib.py:140] step: 103300, training_loss: 3.64189e-04
I0405 04:40:54.093147 23443585951552 run_lib.py:153] step: 103300, eval_loss: 4.27290e-04
I0405 04:41:15.077115 23443585951552 run_lib.py:140] step: 103350, training_loss: 4.10916e-04
I0405 04:41:36.398742 23443585951552 run_lib.py:140] step: 103400, training_loss: 3.52027e-04
I0405 04:41:36.555982 23443585951552 run_lib.py:153] step: 103400, eval_loss: 4.21569e-04
I0405 04:41:57.993954 23443585951552 run_lib.py:140] step: 103450, training_loss: 4.16563e-04
I0405 04:42:19.279002 23443585951552 run_lib.py:140] step: 103500, training_loss: 4.73738e-04
I0405 04:42:19.434029 23443585951552 run_lib.py:153] step: 103500, eval_loss: 3.88646e-04
I0405 04:42:40.489241 23443585951552 run_lib.py:140] step: 103550, training_loss: 4.00910e-04
I0405 04:43:01.571793 23443585951552 run_lib.py:140] step: 103600, training_loss: 3.87494e-04
I0405 04:43:01.728100 23443585951552 run_lib.py:153] step: 103600, eval_loss: 4.32777e-04
I0405 04:43:22.883510 23443585951552 run_lib.py:140] step: 103650, training_loss: 4.35664e-04
I0405 04:43:43.998656 23443585951552 run_lib.py:140] step: 103700, training_loss: 3.93666e-04
I0405 04:43:44.156058 23443585951552 run_lib.py:153] step: 103700, eval_loss: 3.74567e-04
I0405 04:44:05.416398 23443585951552 run_lib.py:140] step: 103750, training_loss: 3.57540e-04
I0405 04:44:26.461358 23443585951552 run_lib.py:140] step: 103800, training_loss: 3.73783e-04
I0405 04:44:26.639258 23443585951552 run_lib.py:153] step: 103800, eval_loss: 4.16464e-04
I0405 04:44:47.950054 23443585951552 run_lib.py:140] step: 103850, training_loss: 3.84133e-04
I0405 04:45:08.968046 23443585951552 run_lib.py:140] step: 103900, training_loss: 3.84013e-04
I0405 04:45:09.125923 23443585951552 run_lib.py:153] step: 103900, eval_loss: 4.59291e-04
I0405 04:45:30.320812 23443585951552 run_lib.py:140] step: 103950, training_loss: 3.55551e-04
I0405 04:45:51.290878 23443585951552 run_lib.py:140] step: 104000, training_loss: 3.89221e-04
I0405 04:45:51.444393 23443585951552 run_lib.py:153] step: 104000, eval_loss: 4.52411e-04
I0405 04:46:12.333646 23443585951552 run_lib.py:140] step: 104050, training_loss: 3.83995e-04
I0405 04:46:33.340258 23443585951552 run_lib.py:140] step: 104100, training_loss: 4.78255e-04
I0405 04:46:33.498018 23443585951552 run_lib.py:153] step: 104100, eval_loss: 3.45653e-04
I0405 04:46:54.679599 23443585951552 run_lib.py:140] step: 104150, training_loss: 4.00533e-04
I0405 04:47:15.840082 23443585951552 run_lib.py:140] step: 104200, training_loss: 3.68757e-04
I0405 04:47:15.993378 23443585951552 run_lib.py:153] step: 104200, eval_loss: 4.00212e-04
I0405 04:47:37.131371 23443585951552 run_lib.py:140] step: 104250, training_loss: 3.84056e-04
I0405 04:47:58.368552 23443585951552 run_lib.py:140] step: 104300, training_loss: 3.89732e-04
I0405 04:47:58.524828 23443585951552 run_lib.py:153] step: 104300, eval_loss: 4.20182e-04
I0405 04:48:19.649704 23443585951552 run_lib.py:140] step: 104350, training_loss: 3.81605e-04
I0405 04:48:40.639516 23443585951552 run_lib.py:140] step: 104400, training_loss: 3.92697e-04
I0405 04:48:40.793819 23443585951552 run_lib.py:153] step: 104400, eval_loss: 4.43948e-04
I0405 04:49:01.844790 23443585951552 run_lib.py:140] step: 104450, training_loss: 3.87217e-04
I0405 04:49:22.960297 23443585951552 run_lib.py:140] step: 104500, training_loss: 4.67054e-04
I0405 04:49:23.115387 23443585951552 run_lib.py:153] step: 104500, eval_loss: 3.57242e-04
I0405 04:49:44.163718 23443585951552 run_lib.py:140] step: 104550, training_loss: 3.99262e-04
I0405 04:50:05.507236 23443585951552 run_lib.py:140] step: 104600, training_loss: 4.21766e-04
I0405 04:50:05.674908 23443585951552 run_lib.py:153] step: 104600, eval_loss: 4.25601e-04
I0405 04:50:26.691780 23443585951552 run_lib.py:140] step: 104650, training_loss: 3.52232e-04
I0405 04:50:47.415256 23443585951552 run_lib.py:140] step: 104700, training_loss: 3.87869e-04
I0405 04:50:47.589480 23443585951552 run_lib.py:153] step: 104700, eval_loss: 4.18428e-04
I0405 04:51:08.713255 23443585951552 run_lib.py:140] step: 104750, training_loss: 4.21029e-04
I0405 04:51:29.877942 23443585951552 run_lib.py:140] step: 104800, training_loss: 3.85870e-04
I0405 04:51:30.032878 23443585951552 run_lib.py:153] step: 104800, eval_loss: 4.57526e-04
I0405 04:51:50.862241 23443585951552 run_lib.py:140] step: 104850, training_loss: 4.79710e-04
I0405 04:52:12.058597 23443585951552 run_lib.py:140] step: 104900, training_loss: 4.13475e-04
I0405 04:52:12.222685 23443585951552 run_lib.py:153] step: 104900, eval_loss: 4.68902e-04
I0405 04:52:33.331891 23443585951552 run_lib.py:140] step: 104950, training_loss: 3.96148e-04
I0405 04:52:54.572228 23443585951552 run_lib.py:140] step: 105000, training_loss: 3.94475e-04
I0405 04:52:54.726496 23443585951552 run_lib.py:153] step: 105000, eval_loss: 4.26638e-04
I0405 04:53:15.818271 23443585951552 run_lib.py:140] step: 105050, training_loss: 4.47533e-04
I0405 04:53:36.336898 23443585951552 run_lib.py:140] step: 105100, training_loss: 4.05170e-04
I0405 04:53:36.494072 23443585951552 run_lib.py:153] step: 105100, eval_loss: 4.40663e-04
I0405 04:53:57.402479 23443585951552 run_lib.py:140] step: 105150, training_loss: 3.21906e-04
I0405 04:54:18.185750 23443585951552 run_lib.py:140] step: 105200, training_loss: 4.40222e-04
I0405 04:54:18.345842 23443585951552 run_lib.py:153] step: 105200, eval_loss: 3.84525e-04
I0405 04:54:39.830721 23443585951552 run_lib.py:140] step: 105250, training_loss: 4.03464e-04
I0405 04:55:00.864199 23443585951552 run_lib.py:140] step: 105300, training_loss: 3.71283e-04
I0405 04:55:01.027179 23443585951552 run_lib.py:153] step: 105300, eval_loss: 3.95159e-04
I0405 04:55:22.016711 23443585951552 run_lib.py:140] step: 105350, training_loss: 3.86002e-04
I0405 04:55:43.189475 23443585951552 run_lib.py:140] step: 105400, training_loss: 3.95890e-04
I0405 04:55:43.345147 23443585951552 run_lib.py:153] step: 105400, eval_loss: 3.92151e-04
I0405 04:56:04.768592 23443585951552 run_lib.py:140] step: 105450, training_loss: 3.91121e-04
I0405 04:56:25.813090 23443585951552 run_lib.py:140] step: 105500, training_loss: 4.21761e-04
I0405 04:56:25.963816 23443585951552 run_lib.py:153] step: 105500, eval_loss: 4.31873e-04
I0405 04:56:46.900130 23443585951552 run_lib.py:140] step: 105550, training_loss: 3.71657e-04
I0405 04:57:08.515590 23443585951552 run_lib.py:140] step: 105600, training_loss: 4.37830e-04
I0405 04:57:08.683285 23443585951552 run_lib.py:153] step: 105600, eval_loss: 4.55176e-04
I0405 04:57:29.879659 23443585951552 run_lib.py:140] step: 105650, training_loss: 3.84831e-04
I0405 04:57:51.113555 23443585951552 run_lib.py:140] step: 105700, training_loss: 4.26041e-04
I0405 04:57:51.271007 23443585951552 run_lib.py:153] step: 105700, eval_loss: 4.37713e-04
I0405 04:58:12.318413 23443585951552 run_lib.py:140] step: 105750, training_loss: 3.87538e-04
I0405 04:58:33.679419 23443585951552 run_lib.py:140] step: 105800, training_loss: 4.29286e-04
I0405 04:58:33.834463 23443585951552 run_lib.py:153] step: 105800, eval_loss: 4.14558e-04
I0405 04:58:54.923929 23443585951552 run_lib.py:140] step: 105850, training_loss: 3.92722e-04
I0405 04:59:15.663534 23443585951552 run_lib.py:140] step: 105900, training_loss: 4.16963e-04
I0405 04:59:15.818621 23443585951552 run_lib.py:153] step: 105900, eval_loss: 4.26379e-04
I0405 04:59:37.050493 23443585951552 run_lib.py:140] step: 105950, training_loss: 4.24182e-04
I0405 04:59:58.101105 23443585951552 run_lib.py:140] step: 106000, training_loss: 4.59429e-04
I0405 04:59:58.258203 23443585951552 run_lib.py:153] step: 106000, eval_loss: 4.13377e-04
I0405 05:00:19.540313 23443585951552 run_lib.py:140] step: 106050, training_loss: 3.86144e-04
I0405 05:00:40.443105 23443585951552 run_lib.py:140] step: 106100, training_loss: 4.08062e-04
I0405 05:00:40.599595 23443585951552 run_lib.py:153] step: 106100, eval_loss: 4.16076e-04
I0405 05:01:00.972690 23443585951552 run_lib.py:140] step: 106150, training_loss: 4.24469e-04
I0405 05:01:18.460330 23443585951552 run_lib.py:140] step: 106200, training_loss: 4.84802e-04
I0405 05:01:18.614087 23443585951552 run_lib.py:153] step: 106200, eval_loss: 4.14217e-04
I0405 05:01:36.131006 23443585951552 run_lib.py:140] step: 106250, training_loss: 4.16202e-04
I0405 05:01:53.723102 23443585951552 run_lib.py:140] step: 106300, training_loss: 4.45444e-04
I0405 05:01:53.883337 23443585951552 run_lib.py:153] step: 106300, eval_loss: 4.50222e-04
I0405 05:02:11.617186 23443585951552 run_lib.py:140] step: 106350, training_loss: 3.66658e-04
I0405 05:02:29.182950 23443585951552 run_lib.py:140] step: 106400, training_loss: 3.95927e-04
I0405 05:02:29.334455 23443585951552 run_lib.py:153] step: 106400, eval_loss: 3.80734e-04
I0405 05:02:46.828153 23443585951552 run_lib.py:140] step: 106450, training_loss: 4.31356e-04
I0405 05:03:04.403104 23443585951552 run_lib.py:140] step: 106500, training_loss: 3.66708e-04
I0405 05:03:04.560109 23443585951552 run_lib.py:153] step: 106500, eval_loss: 4.01684e-04
I0405 05:03:22.280750 23443585951552 run_lib.py:140] step: 106550, training_loss: 3.45344e-04
I0405 05:03:39.813627 23443585951552 run_lib.py:140] step: 106600, training_loss: 3.73557e-04
I0405 05:03:39.972786 23443585951552 run_lib.py:153] step: 106600, eval_loss: 4.39325e-04
I0405 05:03:57.484887 23443585951552 run_lib.py:140] step: 106650, training_loss: 4.10518e-04
I0405 05:04:15.123780 23443585951552 run_lib.py:140] step: 106700, training_loss: 3.58266e-04
I0405 05:04:15.277929 23443585951552 run_lib.py:153] step: 106700, eval_loss: 4.17134e-04
I0405 05:04:32.804236 23443585951552 run_lib.py:140] step: 106750, training_loss: 4.27788e-04
I0405 05:04:50.534251 23443585951552 run_lib.py:140] step: 106800, training_loss: 3.86238e-04
I0405 05:04:50.696567 23443585951552 run_lib.py:153] step: 106800, eval_loss: 4.34802e-04
I0405 05:05:08.244387 23443585951552 run_lib.py:140] step: 106850, training_loss: 4.25438e-04
I0405 05:05:25.746188 23443585951552 run_lib.py:140] step: 106900, training_loss: 4.83305e-04
I0405 05:05:25.906875 23443585951552 run_lib.py:153] step: 106900, eval_loss: 3.96636e-04
I0405 05:05:43.579107 23443585951552 run_lib.py:140] step: 106950, training_loss: 4.62011e-04
I0405 05:06:01.101999 23443585951552 run_lib.py:140] step: 107000, training_loss: 3.52132e-04
I0405 05:06:01.255836 23443585951552 run_lib.py:153] step: 107000, eval_loss: 3.66781e-04
I0405 05:06:18.784171 23443585951552 run_lib.py:140] step: 107050, training_loss: 3.78756e-04
I0405 05:06:36.484568 23443585951552 run_lib.py:140] step: 107100, training_loss: 3.94397e-04
I0405 05:06:36.640780 23443585951552 run_lib.py:153] step: 107100, eval_loss: 3.87899e-04
I0405 05:06:54.165538 23443585951552 run_lib.py:140] step: 107150, training_loss: 3.94127e-04
I0405 05:07:11.653048 23443585951552 run_lib.py:140] step: 107200, training_loss: 3.92269e-04
I0405 05:07:11.807777 23443585951552 run_lib.py:153] step: 107200, eval_loss: 3.80838e-04
I0405 05:07:29.356914 23443585951552 run_lib.py:140] step: 107250, training_loss: 3.82782e-04
I0405 05:07:46.844681 23443585951552 run_lib.py:140] step: 107300, training_loss: 3.58066e-04
I0405 05:07:47.002763 23443585951552 run_lib.py:153] step: 107300, eval_loss: 4.17102e-04
I0405 05:08:07.938206 23443585951552 run_lib.py:140] step: 107350, training_loss: 4.05417e-04
I0405 05:08:29.256858 23443585951552 run_lib.py:140] step: 107400, training_loss: 3.38189e-04
I0405 05:08:29.410057 23443585951552 run_lib.py:153] step: 107400, eval_loss: 3.92081e-04
I0405 05:08:50.718667 23443585951552 run_lib.py:140] step: 107450, training_loss: 3.69603e-04
I0405 05:09:11.957296 23443585951552 run_lib.py:140] step: 107500, training_loss: 3.93368e-04
I0405 05:09:12.111173 23443585951552 run_lib.py:153] step: 107500, eval_loss: 4.27765e-04
I0405 05:09:33.326731 23443585951552 run_lib.py:140] step: 107550, training_loss: 4.02856e-04
I0405 05:09:54.388245 23443585951552 run_lib.py:140] step: 107600, training_loss: 4.16009e-04
I0405 05:09:54.556107 23443585951552 run_lib.py:153] step: 107600, eval_loss: 3.95910e-04
I0405 05:10:15.829754 23443585951552 run_lib.py:140] step: 107650, training_loss: 4.06933e-04
I0405 05:10:36.854919 23443585951552 run_lib.py:140] step: 107700, training_loss: 4.25855e-04
I0405 05:10:37.009021 23443585951552 run_lib.py:153] step: 107700, eval_loss: 3.74231e-04
I0405 05:10:58.051702 23443585951552 run_lib.py:140] step: 107750, training_loss: 3.83932e-04
I0405 05:11:19.353946 23443585951552 run_lib.py:140] step: 107800, training_loss: 4.09246e-04
I0405 05:11:19.509125 23443585951552 run_lib.py:153] step: 107800, eval_loss: 4.30021e-04
I0405 05:11:40.553837 23443585951552 run_lib.py:140] step: 107850, training_loss: 4.35338e-04
I0405 05:12:02.062333 23443585951552 run_lib.py:140] step: 107900, training_loss: 4.18047e-04
I0405 05:12:02.216839 23443585951552 run_lib.py:153] step: 107900, eval_loss: 4.04064e-04
I0405 05:12:23.242698 23443585951552 run_lib.py:140] step: 107950, training_loss: 3.93493e-04
I0405 05:12:44.520203 23443585951552 run_lib.py:140] step: 108000, training_loss: 4.03136e-04
I0405 05:12:44.688956 23443585951552 run_lib.py:153] step: 108000, eval_loss: 3.29556e-04
I0405 05:13:05.938220 23443585951552 run_lib.py:140] step: 108050, training_loss: 4.56573e-04
I0405 05:13:27.084062 23443585951552 run_lib.py:140] step: 108100, training_loss: 4.08005e-04
I0405 05:13:27.240283 23443585951552 run_lib.py:153] step: 108100, eval_loss: 4.01589e-04
I0405 05:13:48.380504 23443585951552 run_lib.py:140] step: 108150, training_loss: 4.29949e-04
I0405 05:14:09.846503 23443585951552 run_lib.py:140] step: 108200, training_loss: 4.06934e-04
I0405 05:14:10.002696 23443585951552 run_lib.py:153] step: 108200, eval_loss: 4.04810e-04
I0405 05:14:31.264478 23443585951552 run_lib.py:140] step: 108250, training_loss: 4.30297e-04
I0405 05:14:52.139200 23443585951552 run_lib.py:140] step: 108300, training_loss: 4.05677e-04
I0405 05:14:52.290757 23443585951552 run_lib.py:153] step: 108300, eval_loss: 3.81051e-04
I0405 05:15:13.204063 23443585951552 run_lib.py:140] step: 108350, training_loss: 4.18400e-04
I0405 05:15:34.272860 23443585951552 run_lib.py:140] step: 108400, training_loss: 3.73576e-04
I0405 05:15:34.434046 23443585951552 run_lib.py:153] step: 108400, eval_loss: 3.89765e-04
I0405 05:15:55.259219 23443585951552 run_lib.py:140] step: 108450, training_loss: 3.64721e-04
I0405 05:16:16.289007 23443585951552 run_lib.py:140] step: 108500, training_loss: 3.87499e-04
I0405 05:16:16.573330 23443585951552 run_lib.py:153] step: 108500, eval_loss: 4.03238e-04
I0405 05:16:37.800825 23443585951552 run_lib.py:140] step: 108550, training_loss: 4.27191e-04
I0405 05:16:59.618425 23443585951552 run_lib.py:140] step: 108600, training_loss: 4.03976e-04
I0405 05:16:59.788779 23443585951552 run_lib.py:153] step: 108600, eval_loss: 3.62739e-04
I0405 05:17:20.905635 23443585951552 run_lib.py:140] step: 108650, training_loss: 3.63580e-04
I0405 05:17:42.400229 23443585951552 run_lib.py:140] step: 108700, training_loss: 4.11910e-04
I0405 05:17:42.555299 23443585951552 run_lib.py:153] step: 108700, eval_loss: 4.17954e-04
I0405 05:18:03.955369 23443585951552 run_lib.py:140] step: 108750, training_loss: 4.26321e-04
I0405 05:18:25.321360 23443585951552 run_lib.py:140] step: 108800, training_loss: 3.37461e-04
I0405 05:18:25.475613 23443585951552 run_lib.py:153] step: 108800, eval_loss: 3.76168e-04
I0405 05:18:47.214419 23443585951552 run_lib.py:140] step: 108850, training_loss: 4.03634e-04
I0405 05:19:08.770411 23443585951552 run_lib.py:140] step: 108900, training_loss: 3.91494e-04
I0405 05:19:08.925040 23443585951552 run_lib.py:153] step: 108900, eval_loss: 4.11610e-04
I0405 05:19:29.951130 23443585951552 run_lib.py:140] step: 108950, training_loss: 3.68796e-04
I0405 05:19:51.229215 23443585951552 run_lib.py:140] step: 109000, training_loss: 3.58368e-04
I0405 05:19:51.411232 23443585951552 run_lib.py:153] step: 109000, eval_loss: 4.08969e-04
I0405 05:20:12.771421 23443585951552 run_lib.py:140] step: 109050, training_loss: 4.29279e-04
I0405 05:20:33.722570 23443585951552 run_lib.py:140] step: 109100, training_loss: 4.00223e-04
I0405 05:20:33.877905 23443585951552 run_lib.py:153] step: 109100, eval_loss: 4.67342e-04
I0405 05:20:55.252837 23443585951552 run_lib.py:140] step: 109150, training_loss: 3.90988e-04
I0405 05:21:16.117014 23443585951552 run_lib.py:140] step: 109200, training_loss: 3.62815e-04
I0405 05:21:16.271858 23443585951552 run_lib.py:153] step: 109200, eval_loss: 4.28868e-04
I0405 05:21:37.378265 23443585951552 run_lib.py:140] step: 109250, training_loss: 4.33103e-04
I0405 05:21:58.874907 23443585951552 run_lib.py:140] step: 109300, training_loss: 3.45287e-04
I0405 05:21:59.031250 23443585951552 run_lib.py:153] step: 109300, eval_loss: 3.87997e-04
I0405 05:22:20.199395 23443585951552 run_lib.py:140] step: 109350, training_loss: 4.26059e-04
I0405 05:22:41.666678 23443585951552 run_lib.py:140] step: 109400, training_loss: 4.36325e-04
I0405 05:22:41.820707 23443585951552 run_lib.py:153] step: 109400, eval_loss: 4.31622e-04
I0405 05:23:03.039791 23443585951552 run_lib.py:140] step: 109450, training_loss: 4.35230e-04
I0405 05:23:23.922193 23443585951552 run_lib.py:140] step: 109500, training_loss: 3.68083e-04
I0405 05:23:24.080460 23443585951552 run_lib.py:153] step: 109500, eval_loss: 3.83031e-04
I0405 05:23:45.234625 23443585951552 run_lib.py:140] step: 109550, training_loss: 3.92055e-04
I0405 05:24:06.079238 23443585951552 run_lib.py:140] step: 109600, training_loss: 3.46537e-04
I0405 05:24:06.239164 23443585951552 run_lib.py:153] step: 109600, eval_loss: 4.02750e-04
I0405 05:24:27.737197 23443585951552 run_lib.py:140] step: 109650, training_loss: 4.31425e-04
I0405 05:24:49.090140 23443585951552 run_lib.py:140] step: 109700, training_loss: 4.10541e-04
I0405 05:24:49.245147 23443585951552 run_lib.py:153] step: 109700, eval_loss: 3.87880e-04
I0405 05:25:10.423100 23443585951552 run_lib.py:140] step: 109750, training_loss: 3.70382e-04
I0405 05:25:31.483271 23443585951552 run_lib.py:140] step: 109800, training_loss: 4.20927e-04
I0405 05:25:31.634886 23443585951552 run_lib.py:153] step: 109800, eval_loss: 4.19752e-04
I0405 05:25:52.831007 23443585951552 run_lib.py:140] step: 109850, training_loss: 4.28119e-04
I0405 05:26:14.027693 23443585951552 run_lib.py:140] step: 109900, training_loss: 3.76528e-04
I0405 05:26:14.207946 23443585951552 run_lib.py:153] step: 109900, eval_loss: 3.87593e-04
I0405 05:26:35.496576 23443585951552 run_lib.py:140] step: 109950, training_loss: 3.72066e-04
I0405 05:26:56.800620 23443585951552 run_lib.py:140] step: 110000, training_loss: 3.90653e-04
I0405 05:26:57.770752 23443585951552 run_lib.py:153] step: 110000, eval_loss: 3.22950e-04
I0405 05:27:19.733161 23443585951552 run_lib.py:140] step: 110050, training_loss: 4.40638e-04
I0405 05:27:40.890148 23443585951552 run_lib.py:140] step: 110100, training_loss: 3.75370e-04
I0405 05:27:41.067688 23443585951552 run_lib.py:153] step: 110100, eval_loss: 3.92676e-04
I0405 05:28:02.008447 23443585951552 run_lib.py:140] step: 110150, training_loss: 4.44126e-04
I0405 05:28:23.370356 23443585951552 run_lib.py:140] step: 110200, training_loss: 3.88758e-04
I0405 05:28:23.526190 23443585951552 run_lib.py:153] step: 110200, eval_loss: 4.05833e-04
I0405 05:28:44.994751 23443585951552 run_lib.py:140] step: 110250, training_loss: 4.17698e-04
I0405 05:29:06.204004 23443585951552 run_lib.py:140] step: 110300, training_loss: 3.28827e-04
I0405 05:29:06.355992 23443585951552 run_lib.py:153] step: 110300, eval_loss: 3.79740e-04
I0405 05:29:27.595986 23443585951552 run_lib.py:140] step: 110350, training_loss: 4.29129e-04
I0405 05:29:48.867551 23443585951552 run_lib.py:140] step: 110400, training_loss: 3.80407e-04
I0405 05:29:49.037981 23443585951552 run_lib.py:153] step: 110400, eval_loss: 4.08997e-04
I0405 05:30:10.031116 23443585951552 run_lib.py:140] step: 110450, training_loss: 3.60294e-04
I0405 05:30:31.243784 23443585951552 run_lib.py:140] step: 110500, training_loss: 4.05625e-04
I0405 05:30:31.399245 23443585951552 run_lib.py:153] step: 110500, eval_loss: 3.80876e-04
I0405 05:30:52.532771 23443585951552 run_lib.py:140] step: 110550, training_loss: 3.89056e-04
I0405 05:31:13.703882 23443585951552 run_lib.py:140] step: 110600, training_loss: 4.72353e-04
I0405 05:31:13.867409 23443585951552 run_lib.py:153] step: 110600, eval_loss: 3.75499e-04
I0405 05:31:35.148610 23443585951552 run_lib.py:140] step: 110650, training_loss: 4.91877e-04
I0405 05:31:55.885728 23443585951552 run_lib.py:140] step: 110700, training_loss: 4.39556e-04
I0405 05:31:56.037914 23443585951552 run_lib.py:153] step: 110700, eval_loss: 3.73915e-04
I0405 05:32:17.107995 23443585951552 run_lib.py:140] step: 110750, training_loss: 3.93199e-04
I0405 05:32:38.607093 23443585951552 run_lib.py:140] step: 110800, training_loss: 3.80872e-04
I0405 05:32:38.771303 23443585951552 run_lib.py:153] step: 110800, eval_loss: 4.39971e-04
I0405 05:33:00.059078 23443585951552 run_lib.py:140] step: 110850, training_loss: 4.08946e-04
I0405 05:33:21.119266 23443585951552 run_lib.py:140] step: 110900, training_loss: 4.25613e-04
I0405 05:33:21.280161 23443585951552 run_lib.py:153] step: 110900, eval_loss: 4.03971e-04
I0405 05:33:42.278934 23443585951552 run_lib.py:140] step: 110950, training_loss: 4.50472e-04
I0405 05:34:03.133892 23443585951552 run_lib.py:140] step: 111000, training_loss: 4.13321e-04
I0405 05:34:03.290696 23443585951552 run_lib.py:153] step: 111000, eval_loss: 4.56677e-04
I0405 05:34:24.334455 23443585951552 run_lib.py:140] step: 111050, training_loss: 4.12742e-04
I0405 05:34:45.563008 23443585951552 run_lib.py:140] step: 111100, training_loss: 3.56005e-04
I0405 05:34:45.716719 23443585951552 run_lib.py:153] step: 111100, eval_loss: 3.79490e-04
I0405 05:35:06.775509 23443585951552 run_lib.py:140] step: 111150, training_loss: 4.46024e-04
I0405 05:35:28.228482 23443585951552 run_lib.py:140] step: 111200, training_loss: 4.01871e-04
I0405 05:35:28.389108 23443585951552 run_lib.py:153] step: 111200, eval_loss: 4.82593e-04
I0405 05:35:49.394409 23443585951552 run_lib.py:140] step: 111250, training_loss: 4.26482e-04
I0405 05:36:10.430483 23443585951552 run_lib.py:140] step: 111300, training_loss: 4.65798e-04
I0405 05:36:10.585985 23443585951552 run_lib.py:153] step: 111300, eval_loss: 4.10985e-04
I0405 05:36:31.863174 23443585951552 run_lib.py:140] step: 111350, training_loss: 4.27104e-04
I0405 05:36:52.652332 23443585951552 run_lib.py:140] step: 111400, training_loss: 3.78828e-04
I0405 05:36:52.835170 23443585951552 run_lib.py:153] step: 111400, eval_loss: 3.80573e-04
I0405 05:37:14.033257 23443585951552 run_lib.py:140] step: 111450, training_loss: 4.36421e-04
I0405 05:37:35.312868 23443585951552 run_lib.py:140] step: 111500, training_loss: 3.43390e-04
I0405 05:37:35.466011 23443585951552 run_lib.py:153] step: 111500, eval_loss: 3.71210e-04
I0405 05:37:56.394266 23443585951552 run_lib.py:140] step: 111550, training_loss: 3.50198e-04
I0405 05:38:17.646864 23443585951552 run_lib.py:140] step: 111600, training_loss: 3.79955e-04
I0405 05:38:17.803343 23443585951552 run_lib.py:153] step: 111600, eval_loss: 4.00828e-04
I0405 05:38:38.923317 23443585951552 run_lib.py:140] step: 111650, training_loss: 4.79447e-04
I0405 05:39:00.110473 23443585951552 run_lib.py:140] step: 111700, training_loss: 3.64864e-04
I0405 05:39:00.312351 23443585951552 run_lib.py:153] step: 111700, eval_loss: 3.74180e-04
I0405 05:39:21.286782 23443585951552 run_lib.py:140] step: 111750, training_loss: 3.32209e-04
I0405 05:39:42.319357 23443585951552 run_lib.py:140] step: 111800, training_loss: 3.83358e-04
I0405 05:39:42.484714 23443585951552 run_lib.py:153] step: 111800, eval_loss: 3.55491e-04
I0405 05:40:03.781007 23443585951552 run_lib.py:140] step: 111850, training_loss: 3.95591e-04
I0405 05:40:25.018482 23443585951552 run_lib.py:140] step: 111900, training_loss: 4.97749e-04
I0405 05:40:25.192721 23443585951552 run_lib.py:153] step: 111900, eval_loss: 3.32383e-04
I0405 05:40:46.197546 23443585951552 run_lib.py:140] step: 111950, training_loss: 4.22284e-04
I0405 05:41:07.274299 23443585951552 run_lib.py:140] step: 112000, training_loss: 4.13644e-04
I0405 05:41:07.429547 23443585951552 run_lib.py:153] step: 112000, eval_loss: 4.66149e-04
I0405 05:41:28.738772 23443585951552 run_lib.py:140] step: 112050, training_loss: 4.15846e-04
I0405 05:41:49.802796 23443585951552 run_lib.py:140] step: 112100, training_loss: 4.07084e-04
I0405 05:41:49.955054 23443585951552 run_lib.py:153] step: 112100, eval_loss: 4.27438e-04
I0405 05:42:11.099624 23443585951552 run_lib.py:140] step: 112150, training_loss: 4.00704e-04
I0405 05:42:32.606433 23443585951552 run_lib.py:140] step: 112200, training_loss: 3.92893e-04
I0405 05:42:32.763272 23443585951552 run_lib.py:153] step: 112200, eval_loss: 3.65751e-04
I0405 05:42:53.894980 23443585951552 run_lib.py:140] step: 112250, training_loss: 3.92164e-04
I0405 05:43:14.857193 23443585951552 run_lib.py:140] step: 112300, training_loss: 4.46224e-04
I0405 05:43:15.014211 23443585951552 run_lib.py:153] step: 112300, eval_loss: 4.62426e-04
I0405 05:43:35.771373 23443585951552 run_lib.py:140] step: 112350, training_loss: 3.76136e-04
I0405 05:43:57.088902 23443585951552 run_lib.py:140] step: 112400, training_loss: 4.43172e-04
I0405 05:43:57.249191 23443585951552 run_lib.py:153] step: 112400, eval_loss: 4.43952e-04
I0405 05:44:18.563160 23443585951552 run_lib.py:140] step: 112450, training_loss: 4.52033e-04
I0405 05:44:39.526829 23443585951552 run_lib.py:140] step: 112500, training_loss: 4.23409e-04
I0405 05:44:39.683849 23443585951552 run_lib.py:153] step: 112500, eval_loss: 4.28018e-04
I0405 05:45:00.709918 23443585951552 run_lib.py:140] step: 112550, training_loss: 3.60541e-04
I0405 05:45:21.840657 23443585951552 run_lib.py:140] step: 112600, training_loss: 3.94254e-04
I0405 05:45:21.996571 23443585951552 run_lib.py:153] step: 112600, eval_loss: 3.81991e-04
I0405 05:45:43.140533 23443585951552 run_lib.py:140] step: 112650, training_loss: 4.36466e-04
I0405 05:46:04.162370 23443585951552 run_lib.py:140] step: 112700, training_loss: 4.61895e-04
I0405 05:46:04.325683 23443585951552 run_lib.py:153] step: 112700, eval_loss: 4.06427e-04
I0405 05:46:25.463804 23443585951552 run_lib.py:140] step: 112750, training_loss: 3.93246e-04
I0405 05:46:46.372236 23443585951552 run_lib.py:140] step: 112800, training_loss: 4.29580e-04
I0405 05:46:46.556285 23443585951552 run_lib.py:153] step: 112800, eval_loss: 3.82920e-04
I0405 05:47:07.744948 23443585951552 run_lib.py:140] step: 112850, training_loss: 3.83710e-04
I0405 05:47:28.557370 23443585951552 run_lib.py:140] step: 112900, training_loss: 4.57484e-04
I0405 05:47:28.716299 23443585951552 run_lib.py:153] step: 112900, eval_loss: 3.32355e-04
I0405 05:47:50.359514 23443585951552 run_lib.py:140] step: 112950, training_loss: 4.30159e-04
I0405 05:48:11.353932 23443585951552 run_lib.py:140] step: 113000, training_loss: 4.07276e-04
I0405 05:48:11.511125 23443585951552 run_lib.py:153] step: 113000, eval_loss: 4.13982e-04
I0405 05:48:32.636305 23443585951552 run_lib.py:140] step: 113050, training_loss: 3.96604e-04
I0405 05:48:53.780676 23443585951552 run_lib.py:140] step: 113100, training_loss: 4.08019e-04
I0405 05:48:53.934018 23443585951552 run_lib.py:153] step: 113100, eval_loss: 3.56686e-04
I0405 05:49:15.347121 23443585951552 run_lib.py:140] step: 113150, training_loss: 3.75668e-04
I0405 05:49:36.818104 23443585951552 run_lib.py:140] step: 113200, training_loss: 4.08886e-04
I0405 05:49:36.986019 23443585951552 run_lib.py:153] step: 113200, eval_loss: 3.39777e-04
I0405 05:49:58.296549 23443585951552 run_lib.py:140] step: 113250, training_loss: 3.66561e-04
I0405 05:50:19.553831 23443585951552 run_lib.py:140] step: 113300, training_loss: 4.78494e-04
I0405 05:50:19.719604 23443585951552 run_lib.py:153] step: 113300, eval_loss: 3.97399e-04
I0405 05:50:40.942972 23443585951552 run_lib.py:140] step: 113350, training_loss: 3.78086e-04
I0405 05:51:02.278403 23443585951552 run_lib.py:140] step: 113400, training_loss: 4.06484e-04
I0405 05:51:02.435162 23443585951552 run_lib.py:153] step: 113400, eval_loss: 4.40028e-04
I0405 05:51:23.444212 23443585951552 run_lib.py:140] step: 113450, training_loss: 3.75449e-04
I0405 05:51:44.658117 23443585951552 run_lib.py:140] step: 113500, training_loss: 4.14906e-04
I0405 05:51:44.814158 23443585951552 run_lib.py:153] step: 113500, eval_loss: 3.88449e-04
I0405 05:52:06.112377 23443585951552 run_lib.py:140] step: 113550, training_loss: 4.17852e-04
I0405 05:52:27.128219 23443585951552 run_lib.py:140] step: 113600, training_loss: 4.65305e-04
I0405 05:52:27.281856 23443585951552 run_lib.py:153] step: 113600, eval_loss: 3.84631e-04
I0405 05:52:48.488054 23443585951552 run_lib.py:140] step: 113650, training_loss: 3.85304e-04
I0405 05:53:09.729873 23443585951552 run_lib.py:140] step: 113700, training_loss: 4.27720e-04
I0405 05:53:09.888000 23443585951552 run_lib.py:153] step: 113700, eval_loss: 4.19434e-04
I0405 05:53:31.066338 23443585951552 run_lib.py:140] step: 113750, training_loss: 3.97335e-04
I0405 05:53:52.127346 23443585951552 run_lib.py:140] step: 113800, training_loss: 4.18580e-04
I0405 05:53:52.283118 23443585951552 run_lib.py:153] step: 113800, eval_loss: 4.06942e-04
I0405 05:54:13.260831 23443585951552 run_lib.py:140] step: 113850, training_loss: 3.84257e-04
I0405 05:54:34.245298 23443585951552 run_lib.py:140] step: 113900, training_loss: 3.66777e-04
I0405 05:54:34.400049 23443585951552 run_lib.py:153] step: 113900, eval_loss: 3.99742e-04
I0405 05:54:55.438119 23443585951552 run_lib.py:140] step: 113950, training_loss: 4.58886e-04
I0405 05:55:16.310115 23443585951552 run_lib.py:140] step: 114000, training_loss: 3.84026e-04
I0405 05:55:16.467078 23443585951552 run_lib.py:153] step: 114000, eval_loss: 4.31159e-04
I0405 05:55:37.724263 23443585951552 run_lib.py:140] step: 114050, training_loss: 4.19343e-04
I0405 05:55:58.922433 23443585951552 run_lib.py:140] step: 114100, training_loss: 4.38714e-04
I0405 05:55:59.076046 23443585951552 run_lib.py:153] step: 114100, eval_loss: 4.72215e-04
I0405 05:56:19.964083 23443585951552 run_lib.py:140] step: 114150, training_loss: 4.52099e-04
I0405 05:56:41.106944 23443585951552 run_lib.py:140] step: 114200, training_loss: 4.21660e-04
I0405 05:56:41.281793 23443585951552 run_lib.py:153] step: 114200, eval_loss: 4.15139e-04
I0405 05:57:02.557415 23443585951552 run_lib.py:140] step: 114250, training_loss: 4.22199e-04
I0405 05:57:23.793794 23443585951552 run_lib.py:140] step: 114300, training_loss: 3.42526e-04
I0405 05:57:23.949416 23443585951552 run_lib.py:153] step: 114300, eval_loss: 4.55056e-04
I0405 05:57:44.906295 23443585951552 run_lib.py:140] step: 114350, training_loss: 3.63555e-04
I0405 05:58:05.848716 23443585951552 run_lib.py:140] step: 114400, training_loss: 3.96309e-04
I0405 05:58:06.006046 23443585951552 run_lib.py:153] step: 114400, eval_loss: 4.76140e-04
I0405 05:58:27.047748 23443585951552 run_lib.py:140] step: 114450, training_loss: 3.83718e-04
I0405 05:58:48.279079 23443585951552 run_lib.py:140] step: 114500, training_loss: 3.93453e-04
I0405 05:58:48.432195 23443585951552 run_lib.py:153] step: 114500, eval_loss: 4.17703e-04
I0405 05:59:09.636710 23443585951552 run_lib.py:140] step: 114550, training_loss: 3.86776e-04
I0405 05:59:30.835551 23443585951552 run_lib.py:140] step: 114600, training_loss: 3.76313e-04
I0405 05:59:30.990846 23443585951552 run_lib.py:153] step: 114600, eval_loss: 4.29412e-04
I0405 05:59:52.340033 23443585951552 run_lib.py:140] step: 114650, training_loss: 3.97676e-04
I0405 06:00:13.411375 23443585951552 run_lib.py:140] step: 114700, training_loss: 4.37533e-04
I0405 06:00:13.568982 23443585951552 run_lib.py:153] step: 114700, eval_loss: 4.41973e-04
I0405 06:00:34.543963 23443585951552 run_lib.py:140] step: 114750, training_loss: 4.39039e-04
I0405 06:00:55.931814 23443585951552 run_lib.py:140] step: 114800, training_loss: 4.39726e-04
I0405 06:00:56.086908 23443585951552 run_lib.py:153] step: 114800, eval_loss: 4.19525e-04
I0405 06:01:17.324001 23443585951552 run_lib.py:140] step: 114850, training_loss: 3.81097e-04
I0405 06:01:38.443496 23443585951552 run_lib.py:140] step: 114900, training_loss: 3.94722e-04
I0405 06:01:38.630408 23443585951552 run_lib.py:153] step: 114900, eval_loss: 3.31283e-04
I0405 06:01:59.898974 23443585951552 run_lib.py:140] step: 114950, training_loss: 4.50186e-04
I0405 06:02:20.877066 23443585951552 run_lib.py:140] step: 115000, training_loss: 3.62341e-04
I0405 06:02:21.030837 23443585951552 run_lib.py:153] step: 115000, eval_loss: 4.05540e-04
I0405 06:02:42.135989 23443585951552 run_lib.py:140] step: 115050, training_loss: 4.28532e-04
I0405 06:03:03.003466 23443585951552 run_lib.py:140] step: 115100, training_loss: 3.90553e-04
I0405 06:03:03.176418 23443585951552 run_lib.py:153] step: 115100, eval_loss: 4.48465e-04
I0405 06:03:24.876832 23443585951552 run_lib.py:140] step: 115150, training_loss: 3.78707e-04
I0405 06:03:46.565018 23443585951552 run_lib.py:140] step: 115200, training_loss: 4.18661e-04
I0405 06:03:46.723929 23443585951552 run_lib.py:153] step: 115200, eval_loss: 4.12763e-04
I0405 06:04:08.287015 23443585951552 run_lib.py:140] step: 115250, training_loss: 4.20393e-04
I0405 06:04:29.840207 23443585951552 run_lib.py:140] step: 115300, training_loss: 4.04842e-04
I0405 06:04:29.994539 23443585951552 run_lib.py:153] step: 115300, eval_loss: 3.92652e-04
I0405 06:04:51.831007 23443585951552 run_lib.py:140] step: 115350, training_loss: 4.62780e-04
I0405 06:05:13.587059 23443585951552 run_lib.py:140] step: 115400, training_loss: 4.30763e-04
I0405 06:05:13.741104 23443585951552 run_lib.py:153] step: 115400, eval_loss: 4.09144e-04
I0405 06:05:35.316472 23443585951552 run_lib.py:140] step: 115450, training_loss: 3.90161e-04
I0405 06:05:56.906197 23443585951552 run_lib.py:140] step: 115500, training_loss: 3.40267e-04
I0405 06:05:57.060507 23443585951552 run_lib.py:153] step: 115500, eval_loss: 3.75718e-04
I0405 06:06:18.602899 23443585951552 run_lib.py:140] step: 115550, training_loss: 3.79289e-04
I0405 06:06:40.416079 23443585951552 run_lib.py:140] step: 115600, training_loss: 4.19583e-04
I0405 06:06:40.585014 23443585951552 run_lib.py:153] step: 115600, eval_loss: 3.97920e-04
I0405 06:07:02.204360 23443585951552 run_lib.py:140] step: 115650, training_loss: 3.76899e-04
I0405 06:07:23.558900 23443585951552 run_lib.py:140] step: 115700, training_loss: 3.77457e-04
I0405 06:07:23.716600 23443585951552 run_lib.py:153] step: 115700, eval_loss: 3.92229e-04
I0405 06:07:46.015143 23443585951552 run_lib.py:140] step: 115750, training_loss: 4.45780e-04
I0405 06:08:07.538879 23443585951552 run_lib.py:140] step: 115800, training_loss: 3.37953e-04
I0405 06:08:07.692200 23443585951552 run_lib.py:153] step: 115800, eval_loss: 3.97761e-04
I0405 06:08:28.762815 23443585951552 run_lib.py:140] step: 115850, training_loss: 3.56855e-04
I0405 06:08:50.302388 23443585951552 run_lib.py:140] step: 115900, training_loss: 4.24723e-04
I0405 06:08:50.454434 23443585951552 run_lib.py:153] step: 115900, eval_loss: 4.37239e-04
I0405 06:09:11.612507 23443585951552 run_lib.py:140] step: 115950, training_loss: 4.38717e-04
I0405 06:09:33.364659 23443585951552 run_lib.py:140] step: 116000, training_loss: 4.01496e-04
I0405 06:09:33.536900 23443585951552 run_lib.py:153] step: 116000, eval_loss: 4.03077e-04
I0405 06:09:55.420588 23443585951552 run_lib.py:140] step: 116050, training_loss: 4.40820e-04
I0405 06:10:16.965814 23443585951552 run_lib.py:140] step: 116100, training_loss: 3.43365e-04
I0405 06:10:17.125885 23443585951552 run_lib.py:153] step: 116100, eval_loss: 4.15923e-04
I0405 06:10:38.977615 23443585951552 run_lib.py:140] step: 116150, training_loss: 3.90354e-04
I0405 06:11:00.371619 23443585951552 run_lib.py:140] step: 116200, training_loss: 4.29324e-04
I0405 06:11:00.544068 23443585951552 run_lib.py:153] step: 116200, eval_loss: 4.04240e-04
I0405 06:11:22.400466 23443585951552 run_lib.py:140] step: 116250, training_loss: 3.71478e-04
I0405 06:11:44.150896 23443585951552 run_lib.py:140] step: 116300, training_loss: 3.87413e-04
I0405 06:11:44.306043 23443585951552 run_lib.py:153] step: 116300, eval_loss: 4.87250e-04
I0405 06:12:05.774216 23443585951552 run_lib.py:140] step: 116350, training_loss: 3.50384e-04
I0405 06:12:27.375359 23443585951552 run_lib.py:140] step: 116400, training_loss: 4.19608e-04
I0405 06:12:27.526139 23443585951552 run_lib.py:153] step: 116400, eval_loss: 4.46515e-04
I0405 06:12:49.190738 23443585951552 run_lib.py:140] step: 116450, training_loss: 3.75635e-04
I0405 06:13:10.759326 23443585951552 run_lib.py:140] step: 116500, training_loss: 3.94403e-04
I0405 06:13:10.915402 23443585951552 run_lib.py:153] step: 116500, eval_loss: 3.89767e-04
I0405 06:13:32.886639 23443585951552 run_lib.py:140] step: 116550, training_loss: 4.09908e-04
I0405 06:13:54.497270 23443585951552 run_lib.py:140] step: 116600, training_loss: 4.35450e-04
I0405 06:13:54.655768 23443585951552 run_lib.py:153] step: 116600, eval_loss: 3.99427e-04
I0405 06:14:15.967010 23443585951552 run_lib.py:140] step: 116650, training_loss: 4.54554e-04
I0405 06:14:37.835961 23443585951552 run_lib.py:140] step: 116700, training_loss: 4.37231e-04
I0405 06:14:37.993370 23443585951552 run_lib.py:153] step: 116700, eval_loss: 3.69693e-04
I0405 06:14:59.443998 23443585951552 run_lib.py:140] step: 116750, training_loss: 4.14947e-04
I0405 06:15:21.058100 23443585951552 run_lib.py:140] step: 116800, training_loss: 4.01360e-04
I0405 06:15:21.214742 23443585951552 run_lib.py:153] step: 116800, eval_loss: 3.65978e-04
I0405 06:15:43.017314 23443585951552 run_lib.py:140] step: 116850, training_loss: 4.01261e-04
I0405 06:16:04.485068 23443585951552 run_lib.py:140] step: 116900, training_loss: 4.25034e-04
I0405 06:16:04.646448 23443585951552 run_lib.py:153] step: 116900, eval_loss: 4.76828e-04
I0405 06:16:26.243618 23443585951552 run_lib.py:140] step: 116950, training_loss: 3.63179e-04
I0405 06:16:47.778102 23443585951552 run_lib.py:140] step: 117000, training_loss: 3.90784e-04
I0405 06:16:47.934170 23443585951552 run_lib.py:153] step: 117000, eval_loss: 3.47011e-04
I0405 06:17:09.389906 23443585951552 run_lib.py:140] step: 117050, training_loss: 3.77231e-04
I0405 06:17:30.944324 23443585951552 run_lib.py:140] step: 117100, training_loss: 3.72623e-04
I0405 06:17:31.121270 23443585951552 run_lib.py:153] step: 117100, eval_loss: 4.20023e-04
I0405 06:17:52.479276 23443585951552 run_lib.py:140] step: 117150, training_loss: 4.00538e-04
I0405 06:18:13.612738 23443585951552 run_lib.py:140] step: 117200, training_loss: 4.13610e-04
I0405 06:18:13.774173 23443585951552 run_lib.py:153] step: 117200, eval_loss: 4.49446e-04
I0405 06:18:34.917683 23443585951552 run_lib.py:140] step: 117250, training_loss: 4.22277e-04
I0405 06:18:56.670774 23443585951552 run_lib.py:140] step: 117300, training_loss: 3.76760e-04
I0405 06:18:56.826998 23443585951552 run_lib.py:153] step: 117300, eval_loss: 4.50085e-04
I0405 06:19:18.162972 23443585951552 run_lib.py:140] step: 117350, training_loss: 4.11835e-04
I0405 06:19:39.445015 23443585951552 run_lib.py:140] step: 117400, training_loss: 3.99839e-04
I0405 06:19:39.601060 23443585951552 run_lib.py:153] step: 117400, eval_loss: 4.34849e-04
I0405 06:20:00.663938 23443585951552 run_lib.py:140] step: 117450, training_loss: 3.36421e-04
I0405 06:20:22.076242 23443585951552 run_lib.py:140] step: 117500, training_loss: 4.51706e-04
I0405 06:20:22.235146 23443585951552 run_lib.py:153] step: 117500, eval_loss: 3.75823e-04
I0405 06:20:43.737077 23443585951552 run_lib.py:140] step: 117550, training_loss: 3.77490e-04
I0405 06:21:05.299916 23443585951552 run_lib.py:140] step: 117600, training_loss: 3.69673e-04
I0405 06:21:05.463059 23443585951552 run_lib.py:153] step: 117600, eval_loss: 4.75254e-04
I0405 06:21:27.183145 23443585951552 run_lib.py:140] step: 117650, training_loss: 4.13706e-04
I0405 06:21:48.864440 23443585951552 run_lib.py:140] step: 117700, training_loss: 4.01256e-04
I0405 06:21:49.024837 23443585951552 run_lib.py:153] step: 117700, eval_loss: 3.70010e-04
I0405 06:22:10.363473 23443585951552 run_lib.py:140] step: 117750, training_loss: 4.07357e-04
I0405 06:22:32.168542 23443585951552 run_lib.py:140] step: 117800, training_loss: 3.87856e-04
I0405 06:22:32.322537 23443585951552 run_lib.py:153] step: 117800, eval_loss: 4.07652e-04
I0405 06:22:54.015022 23443585951552 run_lib.py:140] step: 117850, training_loss: 4.38608e-04
I0405 06:23:15.730471 23443585951552 run_lib.py:140] step: 117900, training_loss: 3.91907e-04
I0405 06:23:15.893261 23443585951552 run_lib.py:153] step: 117900, eval_loss: 3.80849e-04
I0405 06:23:37.435466 23443585951552 run_lib.py:140] step: 117950, training_loss: 4.89212e-04
I0405 06:23:59.190533 23443585951552 run_lib.py:140] step: 118000, training_loss: 4.05204e-04
I0405 06:23:59.355112 23443585951552 run_lib.py:153] step: 118000, eval_loss: 4.27610e-04
I0405 06:24:20.646390 23443585951552 run_lib.py:140] step: 118050, training_loss: 3.79610e-04
I0405 06:24:42.387439 23443585951552 run_lib.py:140] step: 118100, training_loss: 3.99546e-04
I0405 06:24:42.551409 23443585951552 run_lib.py:153] step: 118100, eval_loss: 4.39205e-04
I0405 06:25:03.936643 23443585951552 run_lib.py:140] step: 118150, training_loss: 3.91282e-04
I0405 06:25:25.037320 23443585951552 run_lib.py:140] step: 118200, training_loss: 4.29427e-04
I0405 06:25:25.199125 23443585951552 run_lib.py:153] step: 118200, eval_loss: 4.42864e-04
I0405 06:25:47.181116 23443585951552 run_lib.py:140] step: 118250, training_loss: 4.13786e-04
I0405 06:26:08.789688 23443585951552 run_lib.py:140] step: 118300, training_loss: 4.27032e-04
I0405 06:26:08.942083 23443585951552 run_lib.py:153] step: 118300, eval_loss: 4.09030e-04
I0405 06:26:30.670587 23443585951552 run_lib.py:140] step: 118350, training_loss: 3.96539e-04
I0405 06:26:52.366779 23443585951552 run_lib.py:140] step: 118400, training_loss: 4.05494e-04
I0405 06:26:52.528919 23443585951552 run_lib.py:153] step: 118400, eval_loss: 4.26088e-04
I0405 06:27:14.336460 23443585951552 run_lib.py:140] step: 118450, training_loss: 4.07039e-04
I0405 06:27:35.819518 23443585951552 run_lib.py:140] step: 118500, training_loss: 4.09198e-04
I0405 06:27:35.978782 23443585951552 run_lib.py:153] step: 118500, eval_loss: 3.90363e-04
I0405 06:27:57.555312 23443585951552 run_lib.py:140] step: 118550, training_loss: 4.30564e-04
I0405 06:28:19.278158 23443585951552 run_lib.py:140] step: 118600, training_loss: 3.69568e-04
I0405 06:28:19.435314 23443585951552 run_lib.py:153] step: 118600, eval_loss: 4.27274e-04
I0405 06:28:41.016299 23443585951552 run_lib.py:140] step: 118650, training_loss: 4.47125e-04
I0405 06:29:02.734929 23443585951552 run_lib.py:140] step: 118700, training_loss: 4.10189e-04
I0405 06:29:02.895354 23443585951552 run_lib.py:153] step: 118700, eval_loss: 4.02971e-04
I0405 06:29:24.545250 23443585951552 run_lib.py:140] step: 118750, training_loss: 3.96585e-04
I0405 06:29:46.267442 23443585951552 run_lib.py:140] step: 118800, training_loss: 4.25054e-04
I0405 06:29:46.420328 23443585951552 run_lib.py:153] step: 118800, eval_loss: 3.71779e-04
I0405 06:30:07.803445 23443585951552 run_lib.py:140] step: 118850, training_loss: 4.09492e-04
I0405 06:30:29.322813 23443585951552 run_lib.py:140] step: 118900, training_loss: 3.77787e-04
I0405 06:30:29.502862 23443585951552 run_lib.py:153] step: 118900, eval_loss: 4.00296e-04
I0405 06:30:51.272073 23443585951552 run_lib.py:140] step: 118950, training_loss: 3.81328e-04
I0405 06:31:12.485482 23443585951552 run_lib.py:140] step: 119000, training_loss: 4.45492e-04
I0405 06:31:12.640267 23443585951552 run_lib.py:153] step: 119000, eval_loss: 4.30885e-04
I0405 06:31:34.595040 23443585951552 run_lib.py:140] step: 119050, training_loss: 3.97181e-04
I0405 06:31:56.191084 23443585951552 run_lib.py:140] step: 119100, training_loss: 4.59838e-04
I0405 06:31:56.351535 23443585951552 run_lib.py:153] step: 119100, eval_loss: 3.70605e-04
I0405 06:32:17.737184 23443585951552 run_lib.py:140] step: 119150, training_loss: 4.03479e-04
I0405 06:32:39.550649 23443585951552 run_lib.py:140] step: 119200, training_loss: 4.00464e-04
I0405 06:32:39.706081 23443585951552 run_lib.py:153] step: 119200, eval_loss: 4.24397e-04
I0405 06:33:01.175216 23443585951552 run_lib.py:140] step: 119250, training_loss: 3.78796e-04
I0405 06:33:22.784255 23443585951552 run_lib.py:140] step: 119300, training_loss: 3.83300e-04
I0405 06:33:22.944851 23443585951552 run_lib.py:153] step: 119300, eval_loss: 3.92188e-04
I0405 06:33:44.542579 23443585951552 run_lib.py:140] step: 119350, training_loss: 3.93861e-04
I0405 06:34:05.983098 23443585951552 run_lib.py:140] step: 119400, training_loss: 4.01300e-04
I0405 06:34:06.155794 23443585951552 run_lib.py:153] step: 119400, eval_loss: 3.92389e-04
I0405 06:34:27.478157 23443585951552 run_lib.py:140] step: 119450, training_loss: 3.35191e-04
I0405 06:34:48.960143 23443585951552 run_lib.py:140] step: 119500, training_loss: 3.48222e-04
I0405 06:34:49.116213 23443585951552 run_lib.py:153] step: 119500, eval_loss: 3.71479e-04
I0405 06:35:11.073481 23443585951552 run_lib.py:140] step: 119550, training_loss: 3.70301e-04
I0405 06:35:32.511611 23443585951552 run_lib.py:140] step: 119600, training_loss: 3.77039e-04
I0405 06:35:32.676843 23443585951552 run_lib.py:153] step: 119600, eval_loss: 4.54095e-04
I0405 06:35:54.039962 23443585951552 run_lib.py:140] step: 119650, training_loss: 4.42717e-04
I0405 06:36:15.804671 23443585951552 run_lib.py:140] step: 119700, training_loss: 4.41011e-04
I0405 06:36:15.958952 23443585951552 run_lib.py:153] step: 119700, eval_loss: 3.90920e-04
I0405 06:36:37.645729 23443585951552 run_lib.py:140] step: 119750, training_loss: 3.52387e-04
I0405 06:36:59.191374 23443585951552 run_lib.py:140] step: 119800, training_loss: 4.04176e-04
I0405 06:36:59.353993 23443585951552 run_lib.py:153] step: 119800, eval_loss: 4.07116e-04
I0405 06:37:21.094968 23443585951552 run_lib.py:140] step: 119850, training_loss: 3.89398e-04
I0405 06:37:43.340045 23443585951552 run_lib.py:140] step: 119900, training_loss: 4.44685e-04
I0405 06:37:43.522561 23443585951552 run_lib.py:153] step: 119900, eval_loss: 3.85208e-04
I0405 06:38:05.907442 23443585951552 run_lib.py:140] step: 119950, training_loss: 3.61448e-04
I0405 06:38:27.798992 23443585951552 run_lib.py:140] step: 120000, training_loss: 4.56320e-04
I0405 06:38:28.860411 23443585951552 run_lib.py:153] step: 120000, eval_loss: 3.61639e-04
I0405 06:38:51.865623 23443585951552 run_lib.py:140] step: 120050, training_loss: 3.82800e-04
I0405 06:39:13.768824 23443585951552 run_lib.py:140] step: 120100, training_loss: 4.14679e-04
I0405 06:39:13.932766 23443585951552 run_lib.py:153] step: 120100, eval_loss: 4.37725e-04
I0405 06:39:36.481996 23443585951552 run_lib.py:140] step: 120150, training_loss: 4.77868e-04
I0405 06:39:58.470826 23443585951552 run_lib.py:140] step: 120200, training_loss: 3.91507e-04
I0405 06:39:58.659586 23443585951552 run_lib.py:153] step: 120200, eval_loss: 3.75529e-04
I0405 06:40:16.510218 23443585951552 run_lib.py:140] step: 120250, training_loss: 3.60240e-04
I0405 06:40:34.096307 23443585951552 run_lib.py:140] step: 120300, training_loss: 3.96564e-04
I0405 06:40:34.267002 23443585951552 run_lib.py:153] step: 120300, eval_loss: 3.77440e-04
I0405 06:40:51.948526 23443585951552 run_lib.py:140] step: 120350, training_loss: 4.65160e-04
I0405 06:41:09.629045 23443585951552 run_lib.py:140] step: 120400, training_loss: 3.81588e-04
I0405 06:41:09.793995 23443585951552 run_lib.py:153] step: 120400, eval_loss: 4.13879e-04
I0405 06:41:27.490908 23443585951552 run_lib.py:140] step: 120450, training_loss: 4.19572e-04
I0405 06:41:45.119715 23443585951552 run_lib.py:140] step: 120500, training_loss: 3.59539e-04
I0405 06:41:45.289860 23443585951552 run_lib.py:153] step: 120500, eval_loss: 3.60751e-04
I0405 06:42:02.907330 23443585951552 run_lib.py:140] step: 120550, training_loss: 3.88652e-04
I0405 06:42:20.650196 23443585951552 run_lib.py:140] step: 120600, training_loss: 4.13906e-04
I0405 06:42:20.803191 23443585951552 run_lib.py:153] step: 120600, eval_loss: 3.50400e-04
I0405 06:42:38.709098 23443585951552 run_lib.py:140] step: 120650, training_loss: 3.70588e-04
I0405 06:42:56.449319 23443585951552 run_lib.py:140] step: 120700, training_loss: 4.48505e-04
I0405 06:42:56.607823 23443585951552 run_lib.py:153] step: 120700, eval_loss: 4.18596e-04
I0405 06:43:14.259667 23443585951552 run_lib.py:140] step: 120750, training_loss: 3.98514e-04
I0405 06:43:31.879867 23443585951552 run_lib.py:140] step: 120800, training_loss: 3.91883e-04
I0405 06:43:32.061852 23443585951552 run_lib.py:153] step: 120800, eval_loss: 4.06794e-04
I0405 06:43:50.009513 23443585951552 run_lib.py:140] step: 120850, training_loss: 4.20055e-04
I0405 06:44:07.737316 23443585951552 run_lib.py:140] step: 120900, training_loss: 3.97851e-04
I0405 06:44:07.893715 23443585951552 run_lib.py:153] step: 120900, eval_loss: 3.87061e-04
I0405 06:44:25.555561 23443585951552 run_lib.py:140] step: 120950, training_loss: 4.12160e-04
I0405 06:44:43.298191 23443585951552 run_lib.py:140] step: 121000, training_loss: 3.62172e-04
I0405 06:44:43.496656 23443585951552 run_lib.py:153] step: 121000, eval_loss: 4.85945e-04
I0405 06:45:01.161409 23443585951552 run_lib.py:140] step: 121050, training_loss: 4.09839e-04
I0405 06:45:19.021151 23443585951552 run_lib.py:140] step: 121100, training_loss: 4.06214e-04
I0405 06:45:19.174549 23443585951552 run_lib.py:153] step: 121100, eval_loss: 3.91267e-04
I0405 06:45:36.832358 23443585951552 run_lib.py:140] step: 121150, training_loss: 3.43069e-04
I0405 06:45:54.528848 23443585951552 run_lib.py:140] step: 121200, training_loss: 4.08965e-04
I0405 06:45:54.681591 23443585951552 run_lib.py:153] step: 121200, eval_loss: 3.86336e-04
I0405 06:46:12.461927 23443585951552 run_lib.py:140] step: 121250, training_loss: 4.30192e-04
I0405 06:46:30.051813 23443585951552 run_lib.py:140] step: 121300, training_loss: 4.01142e-04
I0405 06:46:30.215053 23443585951552 run_lib.py:153] step: 121300, eval_loss: 4.40280e-04
I0405 06:46:48.137770 23443585951552 run_lib.py:140] step: 121350, training_loss: 3.86995e-04
I0405 06:47:06.626910 23443585951552 run_lib.py:140] step: 121400, training_loss: 3.61671e-04
I0405 06:47:06.782180 23443585951552 run_lib.py:153] step: 121400, eval_loss: 3.69440e-04
I0405 06:47:28.609242 23443585951552 run_lib.py:140] step: 121450, training_loss: 4.25365e-04
I0405 06:47:50.703746 23443585951552 run_lib.py:140] step: 121500, training_loss: 4.00968e-04
I0405 06:47:50.865501 23443585951552 run_lib.py:153] step: 121500, eval_loss: 4.26411e-04
I0405 06:48:12.666819 23443585951552 run_lib.py:140] step: 121550, training_loss: 4.29616e-04
I0405 06:48:34.975585 23443585951552 run_lib.py:140] step: 121600, training_loss: 4.19157e-04
I0405 06:48:35.187473 23443585951552 run_lib.py:153] step: 121600, eval_loss: 3.30203e-04
I0405 06:48:56.962745 23443585951552 run_lib.py:140] step: 121650, training_loss: 4.45538e-04
I0405 06:49:19.082326 23443585951552 run_lib.py:140] step: 121700, training_loss: 3.88339e-04
I0405 06:49:19.242195 23443585951552 run_lib.py:153] step: 121700, eval_loss: 4.09395e-04
I0405 06:49:41.828041 23443585951552 run_lib.py:140] step: 121750, training_loss: 4.72433e-04
I0405 06:50:03.750782 23443585951552 run_lib.py:140] step: 121800, training_loss: 4.09099e-04
I0405 06:50:03.965916 23443585951552 run_lib.py:153] step: 121800, eval_loss: 3.42869e-04
I0405 06:50:25.591516 23443585951552 run_lib.py:140] step: 121850, training_loss: 4.20269e-04
I0405 06:50:47.546792 23443585951552 run_lib.py:140] step: 121900, training_loss: 3.42091e-04
I0405 06:50:47.701691 23443585951552 run_lib.py:153] step: 121900, eval_loss: 3.74146e-04
I0405 06:51:09.996374 23443585951552 run_lib.py:140] step: 121950, training_loss: 3.91741e-04
I0405 06:51:31.661414 23443585951552 run_lib.py:140] step: 122000, training_loss: 4.38870e-04
I0405 06:51:31.824396 23443585951552 run_lib.py:153] step: 122000, eval_loss: 3.90354e-04
I0405 06:51:53.891573 23443585951552 run_lib.py:140] step: 122050, training_loss: 4.29463e-04
I0405 06:52:15.867435 23443585951552 run_lib.py:140] step: 122100, training_loss: 4.62658e-04
I0405 06:52:16.042491 23443585951552 run_lib.py:153] step: 122100, eval_loss: 4.17353e-04
I0405 06:52:38.051593 23443585951552 run_lib.py:140] step: 122150, training_loss: 3.84163e-04
I0405 06:53:00.499570 23443585951552 run_lib.py:140] step: 122200, training_loss: 4.08032e-04
I0405 06:53:00.670296 23443585951552 run_lib.py:153] step: 122200, eval_loss: 3.91525e-04
I0405 06:53:22.957098 23443585951552 run_lib.py:140] step: 122250, training_loss: 4.02444e-04
I0405 06:53:44.871232 23443585951552 run_lib.py:140] step: 122300, training_loss: 3.59111e-04
I0405 06:53:45.040148 23443585951552 run_lib.py:153] step: 122300, eval_loss: 4.18220e-04
I0405 06:54:06.878033 23443585951552 run_lib.py:140] step: 122350, training_loss: 4.07535e-04
I0405 06:54:29.181746 23443585951552 run_lib.py:140] step: 122400, training_loss: 3.56215e-04
I0405 06:54:29.344212 23443585951552 run_lib.py:153] step: 122400, eval_loss: 4.34141e-04
I0405 06:54:51.800367 23443585951552 run_lib.py:140] step: 122450, training_loss: 3.63215e-04
I0405 06:55:14.282938 23443585951552 run_lib.py:140] step: 122500, training_loss: 3.94154e-04
I0405 06:55:14.437037 23443585951552 run_lib.py:153] step: 122500, eval_loss: 4.12666e-04
I0405 06:55:36.885934 23443585951552 run_lib.py:140] step: 122550, training_loss: 4.49899e-04
I0405 06:55:58.960671 23443585951552 run_lib.py:140] step: 122600, training_loss: 4.94641e-04
I0405 06:55:59.129598 23443585951552 run_lib.py:153] step: 122600, eval_loss: 3.58400e-04
I0405 06:56:20.941473 23443585951552 run_lib.py:140] step: 122650, training_loss: 3.77954e-04
I0405 06:56:43.127073 23443585951552 run_lib.py:140] step: 122700, training_loss: 4.33466e-04
I0405 06:56:43.334690 23443585951552 run_lib.py:153] step: 122700, eval_loss: 4.18774e-04
I0405 06:57:05.277096 23443585951552 run_lib.py:140] step: 122750, training_loss: 3.77989e-04
I0405 06:57:27.396518 23443585951552 run_lib.py:140] step: 122800, training_loss: 4.51572e-04
I0405 06:57:27.572546 23443585951552 run_lib.py:153] step: 122800, eval_loss: 3.67004e-04
I0405 06:57:50.549073 23443585951552 run_lib.py:140] step: 122850, training_loss: 4.54042e-04
I0405 06:58:12.781868 23443585951552 run_lib.py:140] step: 122900, training_loss: 4.05133e-04
I0405 06:58:12.947520 23443585951552 run_lib.py:153] step: 122900, eval_loss: 4.07286e-04
I0405 06:58:34.564772 23443585951552 run_lib.py:140] step: 122950, training_loss: 3.87029e-04
I0405 06:58:56.718507 23443585951552 run_lib.py:140] step: 123000, training_loss: 3.95562e-04
I0405 06:58:56.878381 23443585951552 run_lib.py:153] step: 123000, eval_loss: 3.73567e-04
I0405 06:59:19.338460 23443585951552 run_lib.py:140] step: 123050, training_loss: 3.61603e-04
I0405 06:59:41.684568 23443585951552 run_lib.py:140] step: 123100, training_loss: 3.80919e-04
I0405 06:59:41.841379 23443585951552 run_lib.py:153] step: 123100, eval_loss: 3.91735e-04
I0405 07:00:04.004860 23443585951552 run_lib.py:140] step: 123150, training_loss: 4.03409e-04
I0405 07:00:26.278906 23443585951552 run_lib.py:140] step: 123200, training_loss: 4.39275e-04
I0405 07:00:26.457543 23443585951552 run_lib.py:153] step: 123200, eval_loss: 3.06467e-04
I0405 07:00:48.414081 23443585951552 run_lib.py:140] step: 123250, training_loss: 4.41635e-04
I0405 07:01:11.002650 23443585951552 run_lib.py:140] step: 123300, training_loss: 4.27213e-04
I0405 07:01:11.166351 23443585951552 run_lib.py:153] step: 123300, eval_loss: 4.36679e-04
I0405 07:01:33.363084 23443585951552 run_lib.py:140] step: 123350, training_loss: 4.58560e-04
I0405 07:01:55.255617 23443585951552 run_lib.py:140] step: 123400, training_loss: 3.64002e-04
I0405 07:01:55.433510 23443585951552 run_lib.py:153] step: 123400, eval_loss: 3.62087e-04
I0405 07:02:17.536911 23443585951552 run_lib.py:140] step: 123450, training_loss: 4.08728e-04
I0405 07:02:39.728448 23443585951552 run_lib.py:140] step: 123500, training_loss: 4.23414e-04
I0405 07:02:39.886927 23443585951552 run_lib.py:153] step: 123500, eval_loss: 3.95434e-04
I0405 07:03:01.876661 23443585951552 run_lib.py:140] step: 123550, training_loss: 3.75628e-04
I0405 07:03:24.258035 23443585951552 run_lib.py:140] step: 123600, training_loss: 3.71976e-04
I0405 07:03:24.420097 23443585951552 run_lib.py:153] step: 123600, eval_loss: 4.66002e-04
I0405 07:03:46.272055 23443585951552 run_lib.py:140] step: 123650, training_loss: 3.59794e-04
I0405 07:04:08.411583 23443585951552 run_lib.py:140] step: 123700, training_loss: 3.91101e-04
I0405 07:04:08.572901 23443585951552 run_lib.py:153] step: 123700, eval_loss: 4.45752e-04
I0405 07:04:31.004377 23443585951552 run_lib.py:140] step: 123750, training_loss: 4.32263e-04
I0405 07:04:52.444380 23443585951552 run_lib.py:140] step: 123800, training_loss: 4.21777e-04
I0405 07:04:52.599015 23443585951552 run_lib.py:153] step: 123800, eval_loss: 3.97746e-04
I0405 07:05:14.313284 23443585951552 run_lib.py:140] step: 123850, training_loss: 4.39855e-04
I0405 07:05:36.217230 23443585951552 run_lib.py:140] step: 123900, training_loss: 3.98750e-04
I0405 07:05:36.376736 23443585951552 run_lib.py:153] step: 123900, eval_loss: 4.36754e-04
I0405 07:05:58.025536 23443585951552 run_lib.py:140] step: 123950, training_loss: 3.74581e-04
I0405 07:06:19.323435 23443585951552 run_lib.py:140] step: 124000, training_loss: 3.60455e-04
I0405 07:06:19.477828 23443585951552 run_lib.py:153] step: 124000, eval_loss: 5.07033e-04
I0405 07:06:40.924725 23443585951552 run_lib.py:140] step: 124050, training_loss: 4.42910e-04
I0405 07:07:02.380552 23443585951552 run_lib.py:140] step: 124100, training_loss: 3.78768e-04
I0405 07:07:02.551692 23443585951552 run_lib.py:153] step: 124100, eval_loss: 4.03394e-04
I0405 07:07:24.436747 23443585951552 run_lib.py:140] step: 124150, training_loss: 3.82676e-04
I0405 07:07:45.870631 23443585951552 run_lib.py:140] step: 124200, training_loss: 3.96665e-04
I0405 07:07:46.029154 23443585951552 run_lib.py:153] step: 124200, eval_loss: 3.81785e-04
I0405 07:08:07.235212 23443585951552 run_lib.py:140] step: 124250, training_loss: 4.36465e-04
I0405 07:08:28.926352 23443585951552 run_lib.py:140] step: 124300, training_loss: 4.55934e-04
I0405 07:08:29.088557 23443585951552 run_lib.py:153] step: 124300, eval_loss: 4.16338e-04
I0405 07:08:50.400882 23443585951552 run_lib.py:140] step: 124350, training_loss: 3.63725e-04
I0405 07:09:12.265355 23443585951552 run_lib.py:140] step: 124400, training_loss: 3.58319e-04
I0405 07:09:12.420189 23443585951552 run_lib.py:153] step: 124400, eval_loss: 4.05950e-04
I0405 07:09:33.755357 23443585951552 run_lib.py:140] step: 124450, training_loss: 3.83638e-04
I0405 07:09:55.234783 23443585951552 run_lib.py:140] step: 124500, training_loss: 4.07281e-04
I0405 07:09:55.388976 23443585951552 run_lib.py:153] step: 124500, eval_loss: 3.89964e-04
I0405 07:10:17.008715 23443585951552 run_lib.py:140] step: 124550, training_loss: 4.89589e-04
I0405 07:10:38.495696 23443585951552 run_lib.py:140] step: 124600, training_loss: 3.85650e-04
I0405 07:10:38.672948 23443585951552 run_lib.py:153] step: 124600, eval_loss: 4.83654e-04
I0405 07:11:00.109352 23443585951552 run_lib.py:140] step: 124650, training_loss: 3.69891e-04
I0405 07:11:21.820187 23443585951552 run_lib.py:140] step: 124700, training_loss: 4.29883e-04
I0405 07:11:21.977188 23443585951552 run_lib.py:153] step: 124700, eval_loss: 4.52397e-04
I0405 07:11:43.615297 23443585951552 run_lib.py:140] step: 124750, training_loss: 4.97657e-04
I0405 07:12:04.680404 23443585951552 run_lib.py:140] step: 124800, training_loss: 3.86409e-04
I0405 07:12:04.844952 23443585951552 run_lib.py:153] step: 124800, eval_loss: 3.40130e-04
I0405 07:12:26.496361 23443585951552 run_lib.py:140] step: 124850, training_loss: 3.93260e-04
I0405 07:12:48.004370 23443585951552 run_lib.py:140] step: 124900, training_loss: 3.40529e-04
I0405 07:12:48.156831 23443585951552 run_lib.py:153] step: 124900, eval_loss: 3.94575e-04
I0405 07:13:09.626356 23443585951552 run_lib.py:140] step: 124950, training_loss: 4.32381e-04
I0405 07:13:31.069708 23443585951552 run_lib.py:140] step: 125000, training_loss: 3.79553e-04
I0405 07:13:31.221757 23443585951552 run_lib.py:153] step: 125000, eval_loss: 4.32975e-04
I0405 07:13:52.847009 23443585951552 run_lib.py:140] step: 125050, training_loss: 4.07060e-04
I0405 07:14:14.188070 23443585951552 run_lib.py:140] step: 125100, training_loss: 3.58197e-04
I0405 07:14:14.349885 23443585951552 run_lib.py:153] step: 125100, eval_loss: 3.51898e-04
I0405 07:14:35.265458 23443585951552 run_lib.py:140] step: 125150, training_loss: 4.08114e-04
I0405 07:14:56.823878 23443585951552 run_lib.py:140] step: 125200, training_loss: 3.59603e-04
I0405 07:14:56.987848 23443585951552 run_lib.py:153] step: 125200, eval_loss: 4.29889e-04
I0405 07:15:18.883931 23443585951552 run_lib.py:140] step: 125250, training_loss: 4.23588e-04
I0405 07:15:40.115547 23443585951552 run_lib.py:140] step: 125300, training_loss: 3.64510e-04
I0405 07:15:40.271266 23443585951552 run_lib.py:153] step: 125300, eval_loss: 3.94218e-04
I0405 07:16:01.470846 23443585951552 run_lib.py:140] step: 125350, training_loss: 4.31915e-04
I0405 07:16:23.067371 23443585951552 run_lib.py:140] step: 125400, training_loss: 3.84461e-04
I0405 07:16:23.218418 23443585951552 run_lib.py:153] step: 125400, eval_loss: 4.82221e-04
I0405 07:16:44.629356 23443585951552 run_lib.py:140] step: 125450, training_loss: 4.33264e-04
I0405 07:17:06.170865 23443585951552 run_lib.py:140] step: 125500, training_loss: 3.71861e-04
I0405 07:17:06.328243 23443585951552 run_lib.py:153] step: 125500, eval_loss: 3.82473e-04
I0405 07:17:27.905980 23443585951552 run_lib.py:140] step: 125550, training_loss: 3.95865e-04
I0405 07:17:48.920279 23443585951552 run_lib.py:140] step: 125600, training_loss: 4.22732e-04
I0405 07:17:49.081154 23443585951552 run_lib.py:153] step: 125600, eval_loss: 4.19058e-04
I0405 07:18:10.348913 23443585951552 run_lib.py:140] step: 125650, training_loss: 3.98042e-04
I0405 07:18:31.809383 23443585951552 run_lib.py:140] step: 125700, training_loss: 4.46510e-04
I0405 07:18:31.966908 23443585951552 run_lib.py:153] step: 125700, eval_loss: 4.26582e-04
I0405 07:18:53.361949 23443585951552 run_lib.py:140] step: 125750, training_loss: 4.23083e-04
I0405 07:19:15.011273 23443585951552 run_lib.py:140] step: 125800, training_loss: 3.81964e-04
I0405 07:19:15.168786 23443585951552 run_lib.py:153] step: 125800, eval_loss: 3.81282e-04
I0405 07:19:36.600046 23443585951552 run_lib.py:140] step: 125850, training_loss: 3.37162e-04
I0405 07:19:57.901579 23443585951552 run_lib.py:140] step: 125900, training_loss: 3.83269e-04
I0405 07:19:58.061348 23443585951552 run_lib.py:153] step: 125900, eval_loss: 4.05167e-04
I0405 07:20:19.563673 23443585951552 run_lib.py:140] step: 125950, training_loss: 3.92915e-04
I0405 07:20:41.286715 23443585951552 run_lib.py:140] step: 126000, training_loss: 4.09312e-04
I0405 07:20:41.456278 23443585951552 run_lib.py:153] step: 126000, eval_loss: 4.20479e-04
I0405 07:21:02.696723 23443585951552 run_lib.py:140] step: 126050, training_loss: 4.13029e-04
I0405 07:21:24.045192 23443585951552 run_lib.py:140] step: 126100, training_loss: 4.52592e-04
I0405 07:21:24.205212 23443585951552 run_lib.py:153] step: 126100, eval_loss: 4.37111e-04
I0405 07:21:45.804199 23443585951552 run_lib.py:140] step: 126150, training_loss: 4.02617e-04
I0405 07:22:07.048288 23443585951552 run_lib.py:140] step: 126200, training_loss: 3.62296e-04
I0405 07:22:07.207471 23443585951552 run_lib.py:153] step: 126200, eval_loss: 3.33162e-04
I0405 07:22:28.331102 23443585951552 run_lib.py:140] step: 126250, training_loss: 4.20231e-04
I0405 07:22:49.716383 23443585951552 run_lib.py:140] step: 126300, training_loss: 3.87238e-04
I0405 07:22:49.870273 23443585951552 run_lib.py:153] step: 126300, eval_loss: 4.12752e-04
I0405 07:23:11.692510 23443585951552 run_lib.py:140] step: 126350, training_loss: 4.30116e-04
I0405 07:23:32.992611 23443585951552 run_lib.py:140] step: 126400, training_loss: 4.63608e-04
I0405 07:23:33.146115 23443585951552 run_lib.py:153] step: 126400, eval_loss: 4.52100e-04
I0405 07:23:54.477439 23443585951552 run_lib.py:140] step: 126450, training_loss: 4.08699e-04
I0405 07:24:16.134010 23443585951552 run_lib.py:140] step: 126500, training_loss: 4.38114e-04
I0405 07:24:16.299912 23443585951552 run_lib.py:153] step: 126500, eval_loss: 3.79570e-04
I0405 07:24:37.188666 23443585951552 run_lib.py:140] step: 126550, training_loss: 4.17643e-04
I0405 07:24:58.360030 23443585951552 run_lib.py:140] step: 126600, training_loss: 4.11784e-04
I0405 07:24:58.517948 23443585951552 run_lib.py:153] step: 126600, eval_loss: 3.88697e-04
I0405 07:25:19.596587 23443585951552 run_lib.py:140] step: 126650, training_loss: 4.38930e-04
I0405 07:25:41.086418 23443585951552 run_lib.py:140] step: 126700, training_loss: 4.28743e-04
I0405 07:25:41.264774 23443585951552 run_lib.py:153] step: 126700, eval_loss: 4.35885e-04
I0405 07:26:02.685163 23443585951552 run_lib.py:140] step: 126750, training_loss: 3.76999e-04
I0405 07:26:23.994234 23443585951552 run_lib.py:140] step: 126800, training_loss: 4.16554e-04
I0405 07:26:24.155933 23443585951552 run_lib.py:153] step: 126800, eval_loss: 4.15254e-04
I0405 07:26:45.428726 23443585951552 run_lib.py:140] step: 126850, training_loss: 3.85785e-04
I0405 07:27:07.040893 23443585951552 run_lib.py:140] step: 126900, training_loss: 4.04124e-04
I0405 07:27:07.205175 23443585951552 run_lib.py:153] step: 126900, eval_loss: 4.05130e-04
I0405 07:27:28.538464 23443585951552 run_lib.py:140] step: 126950, training_loss: 4.55663e-04
I0405 07:27:49.981126 23443585951552 run_lib.py:140] step: 127000, training_loss: 3.99426e-04
I0405 07:27:50.139784 23443585951552 run_lib.py:153] step: 127000, eval_loss: 3.98242e-04
I0405 07:28:11.733942 23443585951552 run_lib.py:140] step: 127050, training_loss: 3.97214e-04
I0405 07:28:32.930326 23443585951552 run_lib.py:140] step: 127100, training_loss: 3.40601e-04
I0405 07:28:33.085891 23443585951552 run_lib.py:153] step: 127100, eval_loss: 4.09349e-04
I0405 07:28:54.669495 23443585951552 run_lib.py:140] step: 127150, training_loss: 3.75248e-04
I0405 07:29:16.102358 23443585951552 run_lib.py:140] step: 127200, training_loss: 3.57867e-04
I0405 07:29:16.262182 23443585951552 run_lib.py:153] step: 127200, eval_loss: 3.97902e-04
I0405 07:29:37.949414 23443585951552 run_lib.py:140] step: 127250, training_loss: 3.53415e-04
I0405 07:29:59.428754 23443585951552 run_lib.py:140] step: 127300, training_loss: 3.35805e-04
I0405 07:29:59.578850 23443585951552 run_lib.py:153] step: 127300, eval_loss: 3.84427e-04
I0405 07:30:21.018608 23443585951552 run_lib.py:140] step: 127350, training_loss: 4.24228e-04
I0405 07:30:42.418721 23443585951552 run_lib.py:140] step: 127400, training_loss: 4.21273e-04
I0405 07:30:42.594270 23443585951552 run_lib.py:153] step: 127400, eval_loss: 4.36262e-04
I0405 07:31:04.351209 23443585951552 run_lib.py:140] step: 127450, training_loss: 3.85278e-04
I0405 07:31:25.862025 23443585951552 run_lib.py:140] step: 127500, training_loss: 4.36446e-04
I0405 07:31:26.018228 23443585951552 run_lib.py:153] step: 127500, eval_loss: 4.49802e-04
I0405 07:31:47.637925 23443585951552 run_lib.py:140] step: 127550, training_loss: 4.33181e-04
I0405 07:32:09.115968 23443585951552 run_lib.py:140] step: 127600, training_loss: 4.30593e-04
I0405 07:32:09.283503 23443585951552 run_lib.py:153] step: 127600, eval_loss: 3.97211e-04
I0405 07:32:30.745004 23443585951552 run_lib.py:140] step: 127650, training_loss: 4.75857e-04
I0405 07:32:52.321568 23443585951552 run_lib.py:140] step: 127700, training_loss: 4.60563e-04
I0405 07:32:52.476310 23443585951552 run_lib.py:153] step: 127700, eval_loss: 4.17790e-04
I0405 07:33:13.767850 23443585951552 run_lib.py:140] step: 127750, training_loss: 4.08686e-04
I0405 07:33:34.652453 23443585951552 run_lib.py:140] step: 127800, training_loss: 4.70863e-04
I0405 07:33:34.817329 23443585951552 run_lib.py:153] step: 127800, eval_loss: 3.36445e-04
I0405 07:33:56.530583 23443585951552 run_lib.py:140] step: 127850, training_loss: 4.18024e-04
I0405 07:34:18.049049 23443585951552 run_lib.py:140] step: 127900, training_loss: 3.80082e-04
I0405 07:34:18.207452 23443585951552 run_lib.py:153] step: 127900, eval_loss: 3.83597e-04
I0405 07:34:39.778748 23443585951552 run_lib.py:140] step: 127950, training_loss: 3.46487e-04
I0405 07:35:01.433960 23443585951552 run_lib.py:140] step: 128000, training_loss: 4.45008e-04
I0405 07:35:01.597455 23443585951552 run_lib.py:153] step: 128000, eval_loss: 3.98733e-04
I0405 07:35:23.494534 23443585951552 run_lib.py:140] step: 128050, training_loss: 3.95164e-04
I0405 07:35:45.325979 23443585951552 run_lib.py:140] step: 128100, training_loss: 3.99921e-04
I0405 07:35:45.487379 23443585951552 run_lib.py:153] step: 128100, eval_loss: 3.97784e-04
I0405 07:36:06.849152 23443585951552 run_lib.py:140] step: 128150, training_loss: 3.90469e-04
I0405 07:36:28.373163 23443585951552 run_lib.py:140] step: 128200, training_loss: 3.67915e-04
I0405 07:36:28.528290 23443585951552 run_lib.py:153] step: 128200, eval_loss: 3.45407e-04
I0405 07:36:49.905716 23443585951552 run_lib.py:140] step: 128250, training_loss: 4.13365e-04
I0405 07:37:11.149160 23443585951552 run_lib.py:140] step: 128300, training_loss: 4.16704e-04
I0405 07:37:11.313057 23443585951552 run_lib.py:153] step: 128300, eval_loss: 3.77683e-04
I0405 07:37:32.944015 23443585951552 run_lib.py:140] step: 128350, training_loss: 4.18579e-04
I0405 07:37:54.362700 23443585951552 run_lib.py:140] step: 128400, training_loss: 3.73696e-04
I0405 07:37:54.527664 23443585951552 run_lib.py:153] step: 128400, eval_loss: 4.06150e-04
I0405 07:38:16.088695 23443585951552 run_lib.py:140] step: 128450, training_loss: 4.34010e-04
I0405 07:38:37.586882 23443585951552 run_lib.py:140] step: 128500, training_loss: 3.73489e-04
I0405 07:38:37.758146 23443585951552 run_lib.py:153] step: 128500, eval_loss: 3.58046e-04
I0405 07:38:59.583049 23443585951552 run_lib.py:140] step: 128550, training_loss: 4.59279e-04
I0405 07:39:21.112211 23443585951552 run_lib.py:140] step: 128600, training_loss: 3.70070e-04
I0405 07:39:21.273833 23443585951552 run_lib.py:153] step: 128600, eval_loss: 4.23834e-04
I0405 07:39:42.650842 23443585951552 run_lib.py:140] step: 128650, training_loss: 3.77448e-04
I0405 07:40:04.255086 23443585951552 run_lib.py:140] step: 128700, training_loss: 4.23392e-04
I0405 07:40:04.414191 23443585951552 run_lib.py:153] step: 128700, eval_loss: 4.43139e-04
I0405 07:40:25.977368 23443585951552 run_lib.py:140] step: 128750, training_loss: 3.83623e-04
I0405 07:40:47.820414 23443585951552 run_lib.py:140] step: 128800, training_loss: 4.23464e-04
I0405 07:40:47.986156 23443585951552 run_lib.py:153] step: 128800, eval_loss: 3.79040e-04
I0405 07:41:09.678673 23443585951552 run_lib.py:140] step: 128850, training_loss: 3.95239e-04
I0405 07:41:31.155585 23443585951552 run_lib.py:140] step: 128900, training_loss: 4.22250e-04
I0405 07:41:31.322414 23443585951552 run_lib.py:153] step: 128900, eval_loss: 4.48731e-04
I0405 07:41:53.132619 23443585951552 run_lib.py:140] step: 128950, training_loss: 3.48991e-04
I0405 07:42:14.647635 23443585951552 run_lib.py:140] step: 129000, training_loss: 4.65714e-04
I0405 07:42:14.808094 23443585951552 run_lib.py:153] step: 129000, eval_loss: 3.65846e-04
I0405 07:42:36.202221 23443585951552 run_lib.py:140] step: 129050, training_loss: 4.07318e-04
I0405 07:42:58.078943 23443585951552 run_lib.py:140] step: 129100, training_loss: 4.38237e-04
I0405 07:42:58.232728 23443585951552 run_lib.py:153] step: 129100, eval_loss: 4.35536e-04
I0405 07:43:20.201719 23443585951552 run_lib.py:140] step: 129150, training_loss: 4.45567e-04
I0405 07:43:41.789091 23443585951552 run_lib.py:140] step: 129200, training_loss: 3.74790e-04
I0405 07:43:41.946255 23443585951552 run_lib.py:153] step: 129200, eval_loss: 4.08957e-04
I0405 07:44:03.481770 23443585951552 run_lib.py:140] step: 129250, training_loss: 3.74496e-04
I0405 07:44:25.113080 23443585951552 run_lib.py:140] step: 129300, training_loss: 3.82776e-04
I0405 07:44:25.268726 23443585951552 run_lib.py:153] step: 129300, eval_loss: 4.46017e-04
I0405 07:44:46.734219 23443585951552 run_lib.py:140] step: 129350, training_loss: 4.34655e-04
I0405 07:45:08.157358 23443585951552 run_lib.py:140] step: 129400, training_loss: 3.72427e-04
I0405 07:45:08.340863 23443585951552 run_lib.py:153] step: 129400, eval_loss: 4.42349e-04
I0405 07:45:30.083307 23443585951552 run_lib.py:140] step: 129450, training_loss: 4.35373e-04
I0405 07:45:51.792640 23443585951552 run_lib.py:140] step: 129500, training_loss: 3.63884e-04
I0405 07:45:51.954252 23443585951552 run_lib.py:153] step: 129500, eval_loss: 4.22426e-04
I0405 07:46:13.476297 23443585951552 run_lib.py:140] step: 129550, training_loss: 4.27381e-04
I0405 07:46:34.920143 23443585951552 run_lib.py:140] step: 129600, training_loss: 4.04696e-04
I0405 07:46:35.078817 23443585951552 run_lib.py:153] step: 129600, eval_loss: 4.49896e-04
I0405 07:46:56.861980 23443585951552 run_lib.py:140] step: 129650, training_loss: 4.36066e-04
I0405 07:47:18.438101 23443585951552 run_lib.py:140] step: 129700, training_loss: 4.15506e-04
I0405 07:47:18.597843 23443585951552 run_lib.py:153] step: 129700, eval_loss: 3.82690e-04
I0405 07:47:40.175754 23443585951552 run_lib.py:140] step: 129750, training_loss: 3.52210e-04
I0405 07:48:01.860257 23443585951552 run_lib.py:140] step: 129800, training_loss: 3.89675e-04
I0405 07:48:02.017071 23443585951552 run_lib.py:153] step: 129800, eval_loss: 4.31013e-04
I0405 07:48:23.908509 23443585951552 run_lib.py:140] step: 129850, training_loss: 4.45344e-04
I0405 07:48:45.685283 23443585951552 run_lib.py:140] step: 129900, training_loss: 4.29348e-04
I0405 07:48:45.847093 23443585951552 run_lib.py:153] step: 129900, eval_loss: 4.47943e-04
I0405 07:49:07.498104 23443585951552 run_lib.py:140] step: 129950, training_loss: 3.92589e-04
I0405 07:49:28.868684 23443585951552 run_lib.py:140] step: 130000, training_loss: 4.16928e-04
I0405 07:49:30.016782 23443585951552 run_lib.py:153] step: 130000, eval_loss: 3.65617e-04
I0405 07:49:52.858850 23443585951552 run_lib.py:140] step: 130050, training_loss: 3.92634e-04
I0405 07:50:14.181271 23443585951552 run_lib.py:140] step: 130100, training_loss: 4.45376e-04
I0405 07:50:14.340968 23443585951552 run_lib.py:153] step: 130100, eval_loss: 4.38617e-04
I0405 07:50:36.330760 23443585951552 run_lib.py:140] step: 130150, training_loss: 4.31853e-04
I0405 07:50:57.867200 23443585951552 run_lib.py:140] step: 130200, training_loss: 4.38955e-04
I0405 07:50:58.022100 23443585951552 run_lib.py:153] step: 130200, eval_loss: 4.03242e-04
I0405 07:51:19.473009 23443585951552 run_lib.py:140] step: 130250, training_loss: 3.78060e-04
I0405 07:51:41.333468 23443585951552 run_lib.py:140] step: 130300, training_loss: 3.54952e-04
I0405 07:51:41.513687 23443585951552 run_lib.py:153] step: 130300, eval_loss: 4.04925e-04
I0405 07:52:03.286000 23443585951552 run_lib.py:140] step: 130350, training_loss: 3.93905e-04
I0405 07:52:24.816469 23443585951552 run_lib.py:140] step: 130400, training_loss: 4.09236e-04
I0405 07:52:24.977240 23443585951552 run_lib.py:153] step: 130400, eval_loss: 4.07819e-04
I0405 07:52:46.324806 23443585951552 run_lib.py:140] step: 130450, training_loss: 3.76182e-04
I0405 07:53:07.889519 23443585951552 run_lib.py:140] step: 130500, training_loss: 3.50365e-04
I0405 07:53:08.048775 23443585951552 run_lib.py:153] step: 130500, eval_loss: 3.74138e-04
I0405 07:53:30.066998 23443585951552 run_lib.py:140] step: 130550, training_loss: 4.64785e-04
I0405 07:53:52.017095 23443585951552 run_lib.py:140] step: 130600, training_loss: 4.36062e-04
I0405 07:53:52.171986 23443585951552 run_lib.py:153] step: 130600, eval_loss: 3.88354e-04
I0405 07:54:13.603306 23443585951552 run_lib.py:140] step: 130650, training_loss: 3.33532e-04
I0405 07:54:35.103211 23443585951552 run_lib.py:140] step: 130700, training_loss: 4.04244e-04
I0405 07:54:35.265304 23443585951552 run_lib.py:153] step: 130700, eval_loss: 3.82279e-04
I0405 07:54:56.811239 23443585951552 run_lib.py:140] step: 130750, training_loss: 3.52091e-04
I0405 07:55:18.526451 23443585951552 run_lib.py:140] step: 130800, training_loss: 4.37513e-04
I0405 07:55:18.702727 23443585951552 run_lib.py:153] step: 130800, eval_loss: 4.33141e-04
I0405 07:55:40.790308 23443585951552 run_lib.py:140] step: 130850, training_loss: 4.30176e-04
I0405 07:56:02.603742 23443585951552 run_lib.py:140] step: 130900, training_loss: 4.03499e-04
I0405 07:56:02.763410 23443585951552 run_lib.py:153] step: 130900, eval_loss: 3.82983e-04
I0405 07:56:24.588985 23443585951552 run_lib.py:140] step: 130950, training_loss: 4.19216e-04
I0405 07:56:46.446981 23443585951552 run_lib.py:140] step: 131000, training_loss: 4.43023e-04
I0405 07:56:46.601309 23443585951552 run_lib.py:153] step: 131000, eval_loss: 3.58012e-04
I0405 07:57:08.364540 23443585951552 run_lib.py:140] step: 131050, training_loss: 3.66168e-04
I0405 07:57:29.851560 23443585951552 run_lib.py:140] step: 131100, training_loss: 4.08698e-04
I0405 07:57:30.020899 23443585951552 run_lib.py:153] step: 131100, eval_loss: 3.55157e-04
I0405 07:57:52.039035 23443585951552 run_lib.py:140] step: 131150, training_loss: 3.96590e-04
I0405 07:58:13.774012 23443585951552 run_lib.py:140] step: 131200, training_loss: 4.02475e-04
I0405 07:58:13.951892 23443585951552 run_lib.py:153] step: 131200, eval_loss: 4.02566e-04
I0405 07:58:35.704515 23443585951552 run_lib.py:140] step: 131250, training_loss: 4.35205e-04
I0405 07:58:57.234635 23443585951552 run_lib.py:140] step: 131300, training_loss: 4.11978e-04
I0405 07:58:57.391695 23443585951552 run_lib.py:153] step: 131300, eval_loss: 3.40028e-04
I0405 07:59:18.816155 23443585951552 run_lib.py:140] step: 131350, training_loss: 4.18497e-04
I0405 07:59:40.128781 23443585951552 run_lib.py:140] step: 131400, training_loss: 3.39775e-04
I0405 07:59:40.286160 23443585951552 run_lib.py:153] step: 131400, eval_loss: 4.15722e-04
I0405 08:00:02.070835 23443585951552 run_lib.py:140] step: 131450, training_loss: 3.65561e-04
I0405 08:00:23.405607 23443585951552 run_lib.py:140] step: 131500, training_loss: 4.73415e-04
I0405 08:00:23.569924 23443585951552 run_lib.py:153] step: 131500, eval_loss: 3.96032e-04
I0405 08:00:45.184939 23443585951552 run_lib.py:140] step: 131550, training_loss: 4.20762e-04
I0405 08:01:06.747657 23443585951552 run_lib.py:140] step: 131600, training_loss: 4.03809e-04
I0405 08:01:06.899914 23443585951552 run_lib.py:153] step: 131600, eval_loss: 3.92851e-04
I0405 08:01:28.620394 23443585951552 run_lib.py:140] step: 131650, training_loss: 4.02316e-04
I0405 08:01:50.252362 23443585951552 run_lib.py:140] step: 131700, training_loss: 3.89290e-04
I0405 08:01:50.427717 23443585951552 run_lib.py:153] step: 131700, eval_loss: 4.30917e-04
I0405 08:02:11.815623 23443585951552 run_lib.py:140] step: 131750, training_loss: 4.14091e-04
I0405 08:02:33.494637 23443585951552 run_lib.py:140] step: 131800, training_loss: 3.84761e-04
I0405 08:02:33.659121 23443585951552 run_lib.py:153] step: 131800, eval_loss: 4.12118e-04
I0405 08:02:55.353298 23443585951552 run_lib.py:140] step: 131850, training_loss: 4.32041e-04
I0405 08:03:17.011560 23443585951552 run_lib.py:140] step: 131900, training_loss: 4.39784e-04
I0405 08:03:17.173860 23443585951552 run_lib.py:153] step: 131900, eval_loss: 3.63348e-04
I0405 08:03:38.921814 23443585951552 run_lib.py:140] step: 131950, training_loss: 4.36009e-04
I0405 08:04:00.926458 23443585951552 run_lib.py:140] step: 132000, training_loss: 4.13896e-04
I0405 08:04:01.080737 23443585951552 run_lib.py:153] step: 132000, eval_loss: 3.75558e-04
I0405 08:04:22.520080 23443585951552 run_lib.py:140] step: 132050, training_loss: 4.04749e-04
I0405 08:04:44.477466 23443585951552 run_lib.py:140] step: 132100, training_loss: 4.10119e-04
I0405 08:04:44.633479 23443585951552 run_lib.py:153] step: 132100, eval_loss: 3.70752e-04
I0405 08:05:05.872962 23443585951552 run_lib.py:140] step: 132150, training_loss: 4.27355e-04
I0405 08:05:27.574160 23443585951552 run_lib.py:140] step: 132200, training_loss: 4.12067e-04
I0405 08:05:27.740085 23443585951552 run_lib.py:153] step: 132200, eval_loss: 4.76204e-04
I0405 08:05:49.179562 23443585951552 run_lib.py:140] step: 132250, training_loss: 3.79114e-04
I0405 08:06:10.664387 23443585951552 run_lib.py:140] step: 132300, training_loss: 4.40291e-04
I0405 08:06:10.826301 23443585951552 run_lib.py:153] step: 132300, eval_loss: 3.78640e-04
I0405 08:06:32.247036 23443585951552 run_lib.py:140] step: 132350, training_loss: 4.49842e-04
I0405 08:06:54.243669 23443585951552 run_lib.py:140] step: 132400, training_loss: 4.41743e-04
I0405 08:06:54.410093 23443585951552 run_lib.py:153] step: 132400, eval_loss: 4.14386e-04
I0405 08:07:16.075821 23443585951552 run_lib.py:140] step: 132450, training_loss: 4.39612e-04
I0405 08:07:37.811454 23443585951552 run_lib.py:140] step: 132500, training_loss: 4.44547e-04
I0405 08:07:37.973366 23443585951552 run_lib.py:153] step: 132500, eval_loss: 3.83359e-04
I0405 08:07:59.353180 23443585951552 run_lib.py:140] step: 132550, training_loss: 4.31974e-04
I0405 08:08:20.918933 23443585951552 run_lib.py:140] step: 132600, training_loss: 3.84145e-04
I0405 08:08:21.077811 23443585951552 run_lib.py:153] step: 132600, eval_loss: 4.61143e-04
I0405 08:08:42.708477 23443585951552 run_lib.py:140] step: 132650, training_loss: 3.93451e-04
I0405 08:09:03.876290 23443585951552 run_lib.py:140] step: 132700, training_loss: 4.27801e-04
I0405 08:09:04.044315 23443585951552 run_lib.py:153] step: 132700, eval_loss: 4.67109e-04
I0405 08:09:25.846751 23443585951552 run_lib.py:140] step: 132750, training_loss: 4.61468e-04
I0405 08:09:47.343601 23443585951552 run_lib.py:140] step: 132800, training_loss: 4.06227e-04
I0405 08:09:47.503904 23443585951552 run_lib.py:153] step: 132800, eval_loss: 3.71889e-04
I0405 08:10:09.150861 23443585951552 run_lib.py:140] step: 132850, training_loss: 4.10694e-04
I0405 08:10:30.232842 23443585951552 run_lib.py:140] step: 132900, training_loss: 3.78037e-04
I0405 08:10:30.394675 23443585951552 run_lib.py:153] step: 132900, eval_loss: 4.44426e-04
I0405 08:10:52.102881 23443585951552 run_lib.py:140] step: 132950, training_loss: 4.09437e-04
I0405 08:11:13.730877 23443585951552 run_lib.py:140] step: 133000, training_loss: 4.03623e-04
I0405 08:11:13.886326 23443585951552 run_lib.py:153] step: 133000, eval_loss: 4.32901e-04
I0405 08:11:35.396811 23443585951552 run_lib.py:140] step: 133050, training_loss: 3.88103e-04
I0405 08:11:57.388689 23443585951552 run_lib.py:140] step: 133100, training_loss: 4.37248e-04
I0405 08:11:57.554994 23443585951552 run_lib.py:153] step: 133100, eval_loss: 4.14478e-04
I0405 08:12:19.337456 23443585951552 run_lib.py:140] step: 133150, training_loss: 3.79184e-04
I0405 08:12:41.167000 23443585951552 run_lib.py:140] step: 133200, training_loss: 3.97705e-04
I0405 08:12:41.331301 23443585951552 run_lib.py:153] step: 133200, eval_loss: 4.33833e-04
I0405 08:13:02.848899 23443585951552 run_lib.py:140] step: 133250, training_loss: 3.69938e-04
I0405 08:13:24.543467 23443585951552 run_lib.py:140] step: 133300, training_loss: 3.56826e-04
I0405 08:13:24.700823 23443585951552 run_lib.py:153] step: 133300, eval_loss: 3.71132e-04
I0405 08:13:46.515221 23443585951552 run_lib.py:140] step: 133350, training_loss: 4.21620e-04
I0405 08:14:08.409165 23443585951552 run_lib.py:140] step: 133400, training_loss: 4.19393e-04
I0405 08:14:08.570094 23443585951552 run_lib.py:153] step: 133400, eval_loss: 4.20083e-04
I0405 08:14:30.117603 23443585951552 run_lib.py:140] step: 133450, training_loss: 3.48622e-04
I0405 08:14:52.081267 23443585951552 run_lib.py:140] step: 133500, training_loss: 3.97681e-04
I0405 08:14:52.229913 23443585951552 run_lib.py:153] step: 133500, eval_loss: 4.43837e-04
I0405 08:15:14.164448 23443585951552 run_lib.py:140] step: 133550, training_loss: 3.93281e-04
I0405 08:15:35.855061 23443585951552 run_lib.py:140] step: 133600, training_loss: 4.07156e-04
I0405 08:15:36.011806 23443585951552 run_lib.py:153] step: 133600, eval_loss: 4.18532e-04
I0405 08:15:57.438979 23443585951552 run_lib.py:140] step: 133650, training_loss: 3.73397e-04
I0405 08:16:19.153949 23443585951552 run_lib.py:140] step: 133700, training_loss: 4.27879e-04
I0405 08:16:19.319627 23443585951552 run_lib.py:153] step: 133700, eval_loss: 4.08130e-04
I0405 08:16:40.643069 23443585951552 run_lib.py:140] step: 133750, training_loss: 4.28681e-04
I0405 08:17:02.236098 23443585951552 run_lib.py:140] step: 133800, training_loss: 3.85645e-04
I0405 08:17:02.393693 23443585951552 run_lib.py:153] step: 133800, eval_loss: 4.11535e-04
I0405 08:17:24.276920 23443585951552 run_lib.py:140] step: 133850, training_loss: 4.27294e-04
I0405 08:17:45.844774 23443585951552 run_lib.py:140] step: 133900, training_loss: 3.30749e-04
I0405 08:17:45.997683 23443585951552 run_lib.py:153] step: 133900, eval_loss: 3.58974e-04
I0405 08:18:07.071879 23443585951552 run_lib.py:140] step: 133950, training_loss: 3.85193e-04
I0405 08:18:28.226083 23443585951552 run_lib.py:140] step: 134000, training_loss: 3.90950e-04
I0405 08:18:28.410937 23443585951552 run_lib.py:153] step: 134000, eval_loss: 4.29055e-04
I0405 08:18:50.007065 23443585951552 run_lib.py:140] step: 134050, training_loss: 3.97750e-04
I0405 08:19:11.338937 23443585951552 run_lib.py:140] step: 134100, training_loss: 4.34157e-04
I0405 08:19:11.498994 23443585951552 run_lib.py:153] step: 134100, eval_loss: 3.73476e-04
I0405 08:19:32.939768 23443585951552 run_lib.py:140] step: 134150, training_loss: 4.19574e-04
I0405 08:19:53.999218 23443585951552 run_lib.py:140] step: 134200, training_loss: 4.04618e-04
I0405 08:19:54.279795 23443585951552 run_lib.py:153] step: 134200, eval_loss: 3.98288e-04
I0405 08:20:13.241855 23443585951552 run_lib.py:140] step: 134250, training_loss: 4.33211e-04
I0405 08:20:30.961369 23443585951552 run_lib.py:140] step: 134300, training_loss: 4.10882e-04
I0405 08:20:31.118460 23443585951552 run_lib.py:153] step: 134300, eval_loss: 4.17755e-04
I0405 08:20:48.703419 23443585951552 run_lib.py:140] step: 134350, training_loss: 3.98908e-04
I0405 08:21:06.204218 23443585951552 run_lib.py:140] step: 134400, training_loss: 3.95779e-04
I0405 08:21:06.355500 23443585951552 run_lib.py:153] step: 134400, eval_loss: 4.28786e-04
I0405 08:21:24.075098 23443585951552 run_lib.py:140] step: 134450, training_loss: 3.41706e-04
I0405 08:21:41.602894 23443585951552 run_lib.py:140] step: 134500, training_loss: 4.43146e-04
I0405 08:21:41.763993 23443585951552 run_lib.py:153] step: 134500, eval_loss: 3.87432e-04
I0405 08:21:59.248751 23443585951552 run_lib.py:140] step: 134550, training_loss: 3.98471e-04
I0405 08:22:16.962403 23443585951552 run_lib.py:140] step: 134600, training_loss: 4.57034e-04
I0405 08:22:17.138084 23443585951552 run_lib.py:153] step: 134600, eval_loss: 3.71150e-04
I0405 08:22:34.725724 23443585951552 run_lib.py:140] step: 134650, training_loss: 3.89967e-04
I0405 08:22:52.247526 23443585951552 run_lib.py:140] step: 134700, training_loss: 4.17061e-04
I0405 08:22:52.402669 23443585951552 run_lib.py:153] step: 134700, eval_loss: 4.64953e-04
I0405 08:23:10.028037 23443585951552 run_lib.py:140] step: 134750, training_loss: 4.33070e-04
I0405 08:23:27.497471 23443585951552 run_lib.py:140] step: 134800, training_loss: 3.52958e-04
I0405 08:23:27.652906 23443585951552 run_lib.py:153] step: 134800, eval_loss: 3.96697e-04
I0405 08:23:45.150435 23443585951552 run_lib.py:140] step: 134850, training_loss: 4.34514e-04
I0405 08:24:02.710755 23443585951552 run_lib.py:140] step: 134900, training_loss: 4.20784e-04
I0405 08:24:02.864060 23443585951552 run_lib.py:153] step: 134900, eval_loss: 3.74766e-04
I0405 08:24:20.604304 23443585951552 run_lib.py:140] step: 134950, training_loss: 3.86765e-04
I0405 08:24:38.190736 23443585951552 run_lib.py:140] step: 135000, training_loss: 4.37163e-04
I0405 08:24:38.348070 23443585951552 run_lib.py:153] step: 135000, eval_loss: 4.14287e-04
I0405 08:24:55.842947 23443585951552 run_lib.py:140] step: 135050, training_loss: 3.73257e-04
I0405 08:25:13.341065 23443585951552 run_lib.py:140] step: 135100, training_loss: 3.81431e-04
I0405 08:25:13.510186 23443585951552 run_lib.py:153] step: 135100, eval_loss: 4.14172e-04
I0405 08:25:31.211762 23443585951552 run_lib.py:140] step: 135150, training_loss: 3.60261e-04
I0405 08:25:48.803405 23443585951552 run_lib.py:140] step: 135200, training_loss: 4.61386e-04
I0405 08:25:48.957693 23443585951552 run_lib.py:153] step: 135200, eval_loss: 3.36338e-04
I0405 08:26:06.485185 23443585951552 run_lib.py:140] step: 135250, training_loss: 3.54549e-04
I0405 08:26:24.144336 23443585951552 run_lib.py:140] step: 135300, training_loss: 4.21073e-04
I0405 08:26:24.301028 23443585951552 run_lib.py:153] step: 135300, eval_loss: 4.23711e-04
I0405 08:26:42.040646 23443585951552 run_lib.py:140] step: 135350, training_loss: 4.06593e-04
I0405 08:26:59.702115 23443585951552 run_lib.py:140] step: 135400, training_loss: 4.19616e-04
I0405 08:26:59.863243 23443585951552 run_lib.py:153] step: 135400, eval_loss: 4.24143e-04
I0405 08:27:17.452017 23443585951552 run_lib.py:140] step: 135450, training_loss: 4.02823e-04
I0405 08:27:35.005831 23443585951552 run_lib.py:140] step: 135500, training_loss: 4.34010e-04
I0405 08:27:35.164039 23443585951552 run_lib.py:153] step: 135500, eval_loss: 3.82926e-04
I0405 08:27:52.854079 23443585951552 run_lib.py:140] step: 135550, training_loss: 4.20837e-04
I0405 08:28:10.318435 23443585951552 run_lib.py:140] step: 135600, training_loss: 3.91318e-04
I0405 08:28:10.490335 23443585951552 run_lib.py:153] step: 135600, eval_loss: 4.49996e-04
I0405 08:28:28.006586 23443585951552 run_lib.py:140] step: 135650, training_loss: 3.79640e-04
I0405 08:28:45.639694 23443585951552 run_lib.py:140] step: 135700, training_loss: 3.66763e-04
I0405 08:28:45.801188 23443585951552 run_lib.py:153] step: 135700, eval_loss: 3.35219e-04
I0405 08:29:03.411143 23443585951552 run_lib.py:140] step: 135750, training_loss: 4.22893e-04
I0405 08:29:21.025456 23443585951552 run_lib.py:140] step: 135800, training_loss: 3.70491e-04
I0405 08:29:21.176793 23443585951552 run_lib.py:153] step: 135800, eval_loss: 4.12725e-04
I0405 08:29:38.804479 23443585951552 run_lib.py:140] step: 135850, training_loss: 4.39981e-04
I0405 08:29:56.299108 23443585951552 run_lib.py:140] step: 135900, training_loss: 4.00111e-04
I0405 08:29:56.450755 23443585951552 run_lib.py:153] step: 135900, eval_loss: 3.36229e-04
I0405 08:30:13.946100 23443585951552 run_lib.py:140] step: 135950, training_loss: 4.19765e-04
I0405 08:30:31.462035 23443585951552 run_lib.py:140] step: 136000, training_loss: 3.49184e-04
I0405 08:30:31.634385 23443585951552 run_lib.py:153] step: 136000, eval_loss: 4.01717e-04
I0405 08:30:49.378685 23443585951552 run_lib.py:140] step: 136050, training_loss: 4.27180e-04
I0405 08:31:07.039425 23443585951552 run_lib.py:140] step: 136100, training_loss: 3.71161e-04
I0405 08:31:07.196132 23443585951552 run_lib.py:153] step: 136100, eval_loss: 3.84984e-04
I0405 08:31:24.696752 23443585951552 run_lib.py:140] step: 136150, training_loss: 4.11692e-04
I0405 08:31:42.200966 23443585951552 run_lib.py:140] step: 136200, training_loss: 3.51364e-04
I0405 08:31:42.354905 23443585951552 run_lib.py:153] step: 136200, eval_loss: 4.37981e-04
I0405 08:31:59.996084 23443585951552 run_lib.py:140] step: 136250, training_loss: 4.02823e-04
I0405 08:32:17.552731 23443585951552 run_lib.py:140] step: 136300, training_loss: 3.68766e-04
I0405 08:32:17.706162 23443585951552 run_lib.py:153] step: 136300, eval_loss: 4.23440e-04
I0405 08:32:35.301450 23443585951552 run_lib.py:140] step: 136350, training_loss: 4.16838e-04
I0405 08:32:53.154215 23443585951552 run_lib.py:140] step: 136400, training_loss: 4.43086e-04
I0405 08:32:53.359120 23443585951552 run_lib.py:153] step: 136400, eval_loss: 3.75267e-04
I0405 08:33:10.910316 23443585951552 run_lib.py:140] step: 136450, training_loss: 4.40240e-04
I0405 08:33:28.653816 23443585951552 run_lib.py:140] step: 136500, training_loss: 4.13940e-04
I0405 08:33:28.810205 23443585951552 run_lib.py:153] step: 136500, eval_loss: 4.16859e-04
I0405 08:33:46.420715 23443585951552 run_lib.py:140] step: 136550, training_loss: 4.31891e-04
I0405 08:34:04.085488 23443585951552 run_lib.py:140] step: 136600, training_loss: 3.85862e-04
I0405 08:34:04.246319 23443585951552 run_lib.py:153] step: 136600, eval_loss: 4.41832e-04
I0405 08:34:22.017455 23443585951552 run_lib.py:140] step: 136650, training_loss: 4.36451e-04
I0405 08:34:39.596416 23443585951552 run_lib.py:140] step: 136700, training_loss: 4.57832e-04
I0405 08:34:39.754965 23443585951552 run_lib.py:153] step: 136700, eval_loss: 4.13260e-04
I0405 08:34:57.374378 23443585951552 run_lib.py:140] step: 136750, training_loss: 4.01838e-04
I0405 08:35:15.127389 23443585951552 run_lib.py:140] step: 136800, training_loss: 4.45293e-04
I0405 08:35:15.283986 23443585951552 run_lib.py:153] step: 136800, eval_loss: 4.31660e-04
I0405 08:35:33.008401 23443585951552 run_lib.py:140] step: 136850, training_loss: 4.02570e-04
I0405 08:35:50.539597 23443585951552 run_lib.py:140] step: 136900, training_loss: 4.35689e-04
I0405 08:35:50.702177 23443585951552 run_lib.py:153] step: 136900, eval_loss: 3.73910e-04
I0405 08:36:08.401412 23443585951552 run_lib.py:140] step: 136950, training_loss: 3.96294e-04
I0405 08:36:25.851253 23443585951552 run_lib.py:140] step: 137000, training_loss: 3.78344e-04
I0405 08:36:26.035107 23443585951552 run_lib.py:153] step: 137000, eval_loss: 3.67874e-04
I0405 08:36:43.508837 23443585951552 run_lib.py:140] step: 137050, training_loss: 3.81121e-04
I0405 08:37:00.992371 23443585951552 run_lib.py:140] step: 137100, training_loss: 3.76420e-04
I0405 08:37:01.208021 23443585951552 run_lib.py:153] step: 137100, eval_loss: 4.63813e-04
I0405 08:37:18.999968 23443585951552 run_lib.py:140] step: 137150, training_loss: 3.82705e-04
I0405 08:37:36.853510 23443585951552 run_lib.py:140] step: 137200, training_loss: 3.96629e-04
I0405 08:37:37.022991 23443585951552 run_lib.py:153] step: 137200, eval_loss: 3.80601e-04
I0405 08:37:54.635808 23443585951552 run_lib.py:140] step: 137250, training_loss: 4.51754e-04
I0405 08:38:12.256304 23443585951552 run_lib.py:140] step: 137300, training_loss: 4.06580e-04
I0405 08:38:12.408899 23443585951552 run_lib.py:153] step: 137300, eval_loss: 4.10428e-04
I0405 08:38:30.107754 23443585951552 run_lib.py:140] step: 137350, training_loss: 4.82740e-04
I0405 08:38:47.740055 23443585951552 run_lib.py:140] step: 137400, training_loss: 4.08476e-04
I0405 08:38:47.915928 23443585951552 run_lib.py:153] step: 137400, eval_loss: 3.49600e-04
I0405 08:39:05.621590 23443585951552 run_lib.py:140] step: 137450, training_loss: 4.53403e-04
I0405 08:39:23.472302 23443585951552 run_lib.py:140] step: 137500, training_loss: 4.67613e-04
I0405 08:39:23.626932 23443585951552 run_lib.py:153] step: 137500, eval_loss: 3.77367e-04
I0405 08:39:41.235528 23443585951552 run_lib.py:140] step: 137550, training_loss: 3.66197e-04
I0405 08:39:58.962807 23443585951552 run_lib.py:140] step: 137600, training_loss: 4.16538e-04
I0405 08:39:59.116627 23443585951552 run_lib.py:153] step: 137600, eval_loss: 3.85902e-04
I0405 08:40:16.707009 23443585951552 run_lib.py:140] step: 137650, training_loss: 4.21673e-04
I0405 08:40:34.329911 23443585951552 run_lib.py:140] step: 137700, training_loss: 3.40814e-04
I0405 08:40:34.482985 23443585951552 run_lib.py:153] step: 137700, eval_loss: 4.68698e-04
I0405 08:40:52.258326 23443585951552 run_lib.py:140] step: 137750, training_loss: 4.35806e-04
I0405 08:41:09.864526 23443585951552 run_lib.py:140] step: 137800, training_loss: 4.23366e-04
I0405 08:41:10.018670 23443585951552 run_lib.py:153] step: 137800, eval_loss: 4.60131e-04
I0405 08:41:27.577930 23443585951552 run_lib.py:140] step: 137850, training_loss: 4.04605e-04
I0405 08:41:45.369199 23443585951552 run_lib.py:140] step: 137900, training_loss: 3.94258e-04
I0405 08:41:45.526074 23443585951552 run_lib.py:153] step: 137900, eval_loss: 4.02287e-04
I0405 08:42:03.089299 23443585951552 run_lib.py:140] step: 137950, training_loss: 3.71427e-04
I0405 08:42:20.627036 23443585951552 run_lib.py:140] step: 138000, training_loss: 4.30828e-04
I0405 08:42:20.795820 23443585951552 run_lib.py:153] step: 138000, eval_loss: 3.79279e-04
I0405 08:42:38.492485 23443585951552 run_lib.py:140] step: 138050, training_loss: 5.07879e-04
I0405 08:42:56.057792 23443585951552 run_lib.py:140] step: 138100, training_loss: 4.29197e-04
I0405 08:42:56.212102 23443585951552 run_lib.py:153] step: 138100, eval_loss: 3.57327e-04
I0405 08:43:13.814044 23443585951552 run_lib.py:140] step: 138150, training_loss: 4.73735e-04
I0405 08:43:31.404952 23443585951552 run_lib.py:140] step: 138200, training_loss: 4.07973e-04
I0405 08:43:31.554739 23443585951552 run_lib.py:153] step: 138200, eval_loss: 3.74975e-04
I0405 08:43:49.281233 23443585951552 run_lib.py:140] step: 138250, training_loss: 4.30134e-04
I0405 08:44:06.919373 23443585951552 run_lib.py:140] step: 138300, training_loss: 3.98503e-04
I0405 08:44:07.089051 23443585951552 run_lib.py:153] step: 138300, eval_loss: 3.86163e-04
I0405 08:44:24.714444 23443585951552 run_lib.py:140] step: 138350, training_loss: 3.63456e-04
I0405 08:44:42.369878 23443585951552 run_lib.py:140] step: 138400, training_loss: 4.08808e-04
I0405 08:44:42.531090 23443585951552 run_lib.py:153] step: 138400, eval_loss: 3.93891e-04
I0405 08:45:00.307154 23443585951552 run_lib.py:140] step: 138450, training_loss: 4.60613e-04
I0405 08:45:17.888226 23443585951552 run_lib.py:140] step: 138500, training_loss: 3.74528e-04
I0405 08:45:18.046971 23443585951552 run_lib.py:153] step: 138500, eval_loss: 4.15855e-04
I0405 08:45:35.701316 23443585951552 run_lib.py:140] step: 138550, training_loss: 3.85763e-04
I0405 08:45:53.601163 23443585951552 run_lib.py:140] step: 138600, training_loss: 3.85698e-04
I0405 08:45:53.756194 23443585951552 run_lib.py:153] step: 138600, eval_loss: 3.85543e-04
I0405 08:46:11.497375 23443585951552 run_lib.py:140] step: 138650, training_loss: 4.21667e-04
I0405 08:46:29.348260 23443585951552 run_lib.py:140] step: 138700, training_loss: 3.49490e-04
I0405 08:46:29.502948 23443585951552 run_lib.py:153] step: 138700, eval_loss: 4.59408e-04
I0405 08:46:47.233914 23443585951552 run_lib.py:140] step: 138750, training_loss: 3.64561e-04
I0405 08:47:04.879150 23443585951552 run_lib.py:140] step: 138800, training_loss: 3.87706e-04
I0405 08:47:05.067085 23443585951552 run_lib.py:153] step: 138800, eval_loss: 4.40574e-04
I0405 08:47:22.974600 23443585951552 run_lib.py:140] step: 138850, training_loss: 3.95422e-04
I0405 08:47:40.656704 23443585951552 run_lib.py:140] step: 138900, training_loss: 4.45405e-04
I0405 08:47:40.815002 23443585951552 run_lib.py:153] step: 138900, eval_loss: 3.81044e-04
I0405 08:47:58.467461 23443585951552 run_lib.py:140] step: 138950, training_loss: 4.34855e-04
I0405 08:48:16.338055 23443585951552 run_lib.py:140] step: 139000, training_loss: 3.92766e-04
I0405 08:48:16.495973 23443585951552 run_lib.py:153] step: 139000, eval_loss: 4.22435e-04
I0405 08:48:34.188653 23443585951552 run_lib.py:140] step: 139050, training_loss: 3.96816e-04
I0405 08:48:51.938535 23443585951552 run_lib.py:140] step: 139100, training_loss: 4.11850e-04
I0405 08:48:52.098307 23443585951552 run_lib.py:153] step: 139100, eval_loss: 4.91389e-04
I0405 08:49:09.975946 23443585951552 run_lib.py:140] step: 139150, training_loss: 4.19908e-04
I0405 08:49:27.666929 23443585951552 run_lib.py:140] step: 139200, training_loss: 3.79370e-04
I0405 08:49:27.829974 23443585951552 run_lib.py:153] step: 139200, eval_loss: 4.14204e-04
I0405 08:49:45.514771 23443585951552 run_lib.py:140] step: 139250, training_loss: 4.38147e-04
I0405 08:50:03.203382 23443585951552 run_lib.py:140] step: 139300, training_loss: 3.87860e-04
I0405 08:50:03.365972 23443585951552 run_lib.py:153] step: 139300, eval_loss: 3.73327e-04
I0405 08:50:21.351959 23443585951552 run_lib.py:140] step: 139350, training_loss: 3.94476e-04
I0405 08:50:39.303302 23443585951552 run_lib.py:140] step: 139400, training_loss: 3.95363e-04
I0405 08:50:39.462352 23443585951552 run_lib.py:153] step: 139400, eval_loss: 4.32493e-04
I0405 08:50:57.143064 23443585951552 run_lib.py:140] step: 139450, training_loss: 4.08267e-04
I0405 08:51:14.830933 23443585951552 run_lib.py:140] step: 139500, training_loss: 5.23785e-04
I0405 08:51:14.996300 23443585951552 run_lib.py:153] step: 139500, eval_loss: 4.08859e-04
I0405 08:51:32.863227 23443585951552 run_lib.py:140] step: 139550, training_loss: 3.63319e-04
I0405 08:51:50.627403 23443585951552 run_lib.py:140] step: 139600, training_loss: 4.07125e-04
I0405 08:51:50.784441 23443585951552 run_lib.py:153] step: 139600, eval_loss: 4.04982e-04
I0405 08:52:08.597138 23443585951552 run_lib.py:140] step: 139650, training_loss: 4.21525e-04
I0405 08:52:26.511364 23443585951552 run_lib.py:140] step: 139700, training_loss: 3.85536e-04
I0405 08:52:26.666951 23443585951552 run_lib.py:153] step: 139700, eval_loss: 3.75573e-04
I0405 08:52:44.351153 23443585951552 run_lib.py:140] step: 139750, training_loss: 3.87957e-04
I0405 08:53:02.307269 23443585951552 run_lib.py:140] step: 139800, training_loss: 4.82978e-04
I0405 08:53:02.466132 23443585951552 run_lib.py:153] step: 139800, eval_loss: 3.40915e-04
I0405 08:53:20.150556 23443585951552 run_lib.py:140] step: 139850, training_loss: 3.63219e-04
I0405 08:53:37.964847 23443585951552 run_lib.py:140] step: 139900, training_loss: 4.64314e-04
I0405 08:53:38.123305 23443585951552 run_lib.py:153] step: 139900, eval_loss: 3.84947e-04
I0405 08:53:56.115046 23443585951552 run_lib.py:140] step: 139950, training_loss: 4.17566e-04
I0405 08:54:13.830639 23443585951552 run_lib.py:140] step: 140000, training_loss: 4.23316e-04
I0405 08:54:14.577700 23443585951552 run_lib.py:153] step: 140000, eval_loss: 4.48299e-04
I0405 08:54:32.758497 23443585951552 run_lib.py:140] step: 140050, training_loss: 3.87725e-04
I0405 08:54:50.627475 23443585951552 run_lib.py:140] step: 140100, training_loss: 4.02186e-04
I0405 08:54:50.781299 23443585951552 run_lib.py:153] step: 140100, eval_loss: 4.09199e-04
I0405 08:55:08.519075 23443585951552 run_lib.py:140] step: 140150, training_loss: 4.79299e-04
I0405 08:55:26.332016 23443585951552 run_lib.py:140] step: 140200, training_loss: 4.10811e-04
I0405 08:55:26.490407 23443585951552 run_lib.py:153] step: 140200, eval_loss: 3.95949e-04
I0405 08:55:44.405027 23443585951552 run_lib.py:140] step: 140250, training_loss: 4.16225e-04
I0405 08:56:02.165630 23443585951552 run_lib.py:140] step: 140300, training_loss: 4.03229e-04
I0405 08:56:02.330188 23443585951552 run_lib.py:153] step: 140300, eval_loss: 4.28262e-04
I0405 08:56:20.117922 23443585951552 run_lib.py:140] step: 140350, training_loss: 3.59844e-04
I0405 08:56:37.791945 23443585951552 run_lib.py:140] step: 140400, training_loss: 3.71302e-04
I0405 08:56:38.041111 23443585951552 run_lib.py:153] step: 140400, eval_loss: 4.34499e-04
I0405 08:56:55.966939 23443585951552 run_lib.py:140] step: 140450, training_loss: 4.11736e-04
I0405 08:57:13.873614 23443585951552 run_lib.py:140] step: 140500, training_loss: 4.35580e-04
I0405 08:57:14.030354 23443585951552 run_lib.py:153] step: 140500, eval_loss: 4.12310e-04
I0405 08:57:31.766483 23443585951552 run_lib.py:140] step: 140550, training_loss: 4.25121e-04
I0405 08:57:49.488039 23443585951552 run_lib.py:140] step: 140600, training_loss: 3.93899e-04
I0405 08:57:49.641179 23443585951552 run_lib.py:153] step: 140600, eval_loss: 3.81630e-04
I0405 08:58:07.507512 23443585951552 run_lib.py:140] step: 140650, training_loss: 4.29011e-04
I0405 08:58:25.192221 23443585951552 run_lib.py:140] step: 140700, training_loss: 3.72861e-04
I0405 08:58:25.370640 23443585951552 run_lib.py:153] step: 140700, eval_loss: 3.76682e-04
I0405 08:58:43.225240 23443585951552 run_lib.py:140] step: 140750, training_loss: 4.08932e-04
I0405 08:59:01.215398 23443585951552 run_lib.py:140] step: 140800, training_loss: 4.08645e-04
I0405 08:59:01.372974 23443585951552 run_lib.py:153] step: 140800, eval_loss: 4.25033e-04
I0405 08:59:19.074744 23443585951552 run_lib.py:140] step: 140850, training_loss: 3.87103e-04
I0405 08:59:36.951749 23443585951552 run_lib.py:140] step: 140900, training_loss: 3.49984e-04
I0405 08:59:37.105758 23443585951552 run_lib.py:153] step: 140900, eval_loss: 3.58080e-04
I0405 08:59:54.837886 23443585951552 run_lib.py:140] step: 140950, training_loss: 3.88626e-04
I0405 09:00:12.595673 23443585951552 run_lib.py:140] step: 141000, training_loss: 3.70156e-04
I0405 09:00:12.751230 23443585951552 run_lib.py:153] step: 141000, eval_loss: 3.70722e-04
I0405 09:00:30.828740 23443585951552 run_lib.py:140] step: 141050, training_loss: 3.95764e-04
I0405 09:00:48.553728 23443585951552 run_lib.py:140] step: 141100, training_loss: 4.37369e-04
I0405 09:00:48.714556 23443585951552 run_lib.py:153] step: 141100, eval_loss: 4.34465e-04
I0405 09:01:06.404782 23443585951552 run_lib.py:140] step: 141150, training_loss: 3.75533e-04
I0405 09:01:24.308949 23443585951552 run_lib.py:140] step: 141200, training_loss: 3.85729e-04
I0405 09:01:24.487242 23443585951552 run_lib.py:153] step: 141200, eval_loss: 4.36037e-04
I0405 09:01:42.336333 23443585951552 run_lib.py:140] step: 141250, training_loss: 4.54916e-04
I0405 09:02:00.100683 23443585951552 run_lib.py:140] step: 141300, training_loss: 4.46541e-04
I0405 09:02:00.257335 23443585951552 run_lib.py:153] step: 141300, eval_loss: 4.08277e-04
I0405 09:02:18.167620 23443585951552 run_lib.py:140] step: 141350, training_loss: 4.16034e-04
I0405 09:02:35.878590 23443585951552 run_lib.py:140] step: 141400, training_loss: 4.12676e-04
I0405 09:02:36.034803 23443585951552 run_lib.py:153] step: 141400, eval_loss: 3.64786e-04
I0405 09:02:53.767957 23443585951552 run_lib.py:140] step: 141450, training_loss: 3.94363e-04
I0405 09:03:11.543522 23443585951552 run_lib.py:140] step: 141500, training_loss: 4.29507e-04
I0405 09:03:11.697729 23443585951552 run_lib.py:153] step: 141500, eval_loss: 4.54504e-04
I0405 09:03:29.691861 23443585951552 run_lib.py:140] step: 141550, training_loss: 4.07526e-04
I0405 09:03:47.535085 23443585951552 run_lib.py:140] step: 141600, training_loss: 3.85391e-04
I0405 09:03:47.700982 23443585951552 run_lib.py:153] step: 141600, eval_loss: 3.64115e-04
I0405 09:04:05.436107 23443585951552 run_lib.py:140] step: 141650, training_loss: 3.76455e-04
I0405 09:04:23.123125 23443585951552 run_lib.py:140] step: 141700, training_loss: 4.49374e-04
I0405 09:04:23.280113 23443585951552 run_lib.py:153] step: 141700, eval_loss: 3.99790e-04
I0405 09:04:41.169895 23443585951552 run_lib.py:140] step: 141750, training_loss: 3.54529e-04
I0405 09:04:58.985657 23443585951552 run_lib.py:140] step: 141800, training_loss: 4.02122e-04
I0405 09:04:59.143374 23443585951552 run_lib.py:153] step: 141800, eval_loss: 3.68731e-04
I0405 09:05:16.848227 23443585951552 run_lib.py:140] step: 141850, training_loss: 4.49304e-04
I0405 09:05:34.770075 23443585951552 run_lib.py:140] step: 141900, training_loss: 3.71795e-04
I0405 09:05:34.933881 23443585951552 run_lib.py:153] step: 141900, eval_loss: 4.17253e-04
I0405 09:05:52.656580 23443585951552 run_lib.py:140] step: 141950, training_loss: 3.29195e-04
I0405 09:06:10.556288 23443585951552 run_lib.py:140] step: 142000, training_loss: 3.96932e-04
I0405 09:06:10.716288 23443585951552 run_lib.py:153] step: 142000, eval_loss: 3.57182e-04
I0405 09:06:28.567480 23443585951552 run_lib.py:140] step: 142050, training_loss: 4.10931e-04
I0405 09:06:46.315253 23443585951552 run_lib.py:140] step: 142100, training_loss: 4.16105e-04
I0405 09:06:46.471392 23443585951552 run_lib.py:153] step: 142100, eval_loss: 4.46205e-04
I0405 09:07:04.481833 23443585951552 run_lib.py:140] step: 142150, training_loss: 3.64116e-04
I0405 09:07:22.207628 23443585951552 run_lib.py:140] step: 142200, training_loss: 4.04303e-04
I0405 09:07:22.366306 23443585951552 run_lib.py:153] step: 142200, eval_loss: 3.86467e-04
I0405 09:07:40.071883 23443585951552 run_lib.py:140] step: 142250, training_loss: 3.75426e-04
I0405 09:07:57.971240 23443585951552 run_lib.py:140] step: 142300, training_loss: 4.05888e-04
I0405 09:07:58.137933 23443585951552 run_lib.py:153] step: 142300, eval_loss: 3.38531e-04
I0405 09:08:15.950630 23443585951552 run_lib.py:140] step: 142350, training_loss: 4.04802e-04
I0405 09:08:33.710274 23443585951552 run_lib.py:140] step: 142400, training_loss: 3.94880e-04
I0405 09:08:33.865775 23443585951552 run_lib.py:153] step: 142400, eval_loss: 3.55991e-04
I0405 09:08:51.744616 23443585951552 run_lib.py:140] step: 142450, training_loss: 4.45684e-04
I0405 09:09:09.414463 23443585951552 run_lib.py:140] step: 142500, training_loss: 3.97174e-04
I0405 09:09:09.568024 23443585951552 run_lib.py:153] step: 142500, eval_loss: 4.37407e-04
I0405 09:09:27.407373 23443585951552 run_lib.py:140] step: 142550, training_loss: 4.31142e-04
I0405 09:09:45.120674 23443585951552 run_lib.py:140] step: 142600, training_loss: 4.24750e-04
I0405 09:09:45.289785 23443585951552 run_lib.py:153] step: 142600, eval_loss: 3.99920e-04
I0405 09:10:03.161747 23443585951552 run_lib.py:140] step: 142650, training_loss: 3.91202e-04
I0405 09:10:20.893117 23443585951552 run_lib.py:140] step: 142700, training_loss: 3.86358e-04
I0405 09:10:21.057123 23443585951552 run_lib.py:153] step: 142700, eval_loss: 4.12136e-04
I0405 09:10:38.792993 23443585951552 run_lib.py:140] step: 142750, training_loss: 4.24622e-04
I0405 09:10:56.467605 23443585951552 run_lib.py:140] step: 142800, training_loss: 3.58068e-04
I0405 09:10:56.630643 23443585951552 run_lib.py:153] step: 142800, eval_loss: 4.12668e-04
I0405 09:11:14.564832 23443585951552 run_lib.py:140] step: 142850, training_loss: 4.12751e-04
I0405 09:11:32.349019 23443585951552 run_lib.py:140] step: 142900, training_loss: 4.34908e-04
I0405 09:11:32.531984 23443585951552 run_lib.py:153] step: 142900, eval_loss: 3.47525e-04
I0405 09:11:50.310536 23443585951552 run_lib.py:140] step: 142950, training_loss: 3.83383e-04
I0405 09:12:08.182431 23443585951552 run_lib.py:140] step: 143000, training_loss: 3.87492e-04
I0405 09:12:08.336961 23443585951552 run_lib.py:153] step: 143000, eval_loss: 4.23127e-04
I0405 09:12:26.043970 23443585951552 run_lib.py:140] step: 143050, training_loss: 4.19721e-04
I0405 09:12:43.912229 23443585951552 run_lib.py:140] step: 143100, training_loss: 3.97381e-04
I0405 09:12:44.070992 23443585951552 run_lib.py:153] step: 143100, eval_loss: 3.84631e-04
I0405 09:13:01.782653 23443585951552 run_lib.py:140] step: 143150, training_loss: 4.46411e-04
I0405 09:13:19.491851 23443585951552 run_lib.py:140] step: 143200, training_loss: 4.18307e-04
I0405 09:13:19.651182 23443585951552 run_lib.py:153] step: 143200, eval_loss: 4.24389e-04
I0405 09:13:37.559244 23443585951552 run_lib.py:140] step: 143250, training_loss: 4.07503e-04
I0405 09:13:55.204013 23443585951552 run_lib.py:140] step: 143300, training_loss: 3.42944e-04
I0405 09:13:55.363533 23443585951552 run_lib.py:153] step: 143300, eval_loss: 3.72880e-04
I0405 09:14:13.075900 23443585951552 run_lib.py:140] step: 143350, training_loss: 4.40120e-04
I0405 09:14:30.882108 23443585951552 run_lib.py:140] step: 143400, training_loss: 3.79356e-04
I0405 09:14:31.038237 23443585951552 run_lib.py:153] step: 143400, eval_loss: 3.92735e-04
I0405 09:14:48.823072 23443585951552 run_lib.py:140] step: 143450, training_loss: 3.84588e-04
I0405 09:15:06.534900 23443585951552 run_lib.py:140] step: 143500, training_loss: 4.34622e-04
I0405 09:15:06.690012 23443585951552 run_lib.py:153] step: 143500, eval_loss: 3.56397e-04
I0405 09:15:24.495424 23443585951552 run_lib.py:140] step: 143550, training_loss: 4.28881e-04
I0405 09:15:42.183755 23443585951552 run_lib.py:140] step: 143600, training_loss: 3.66064e-04
I0405 09:15:42.346087 23443585951552 run_lib.py:153] step: 143600, eval_loss: 3.89364e-04
I0405 09:16:00.006173 23443585951552 run_lib.py:140] step: 143650, training_loss: 3.75773e-04
I0405 09:16:17.675662 23443585951552 run_lib.py:140] step: 143700, training_loss: 4.15549e-04
I0405 09:16:17.844779 23443585951552 run_lib.py:153] step: 143700, eval_loss: 3.60605e-04
I0405 09:16:35.769489 23443585951552 run_lib.py:140] step: 143750, training_loss: 4.40874e-04
I0405 09:16:53.620752 23443585951552 run_lib.py:140] step: 143800, training_loss: 3.96449e-04
I0405 09:16:53.777234 23443585951552 run_lib.py:153] step: 143800, eval_loss: 3.87770e-04
I0405 09:17:11.507104 23443585951552 run_lib.py:140] step: 143850, training_loss: 3.94218e-04
I0405 09:17:29.153693 23443585951552 run_lib.py:140] step: 143900, training_loss: 3.73096e-04
I0405 09:17:29.310847 23443585951552 run_lib.py:153] step: 143900, eval_loss: 4.21535e-04
I0405 09:17:47.142663 23443585951552 run_lib.py:140] step: 143950, training_loss: 3.80450e-04
I0405 09:18:04.911497 23443585951552 run_lib.py:140] step: 144000, training_loss: 3.56581e-04
I0405 09:18:05.083150 23443585951552 run_lib.py:153] step: 144000, eval_loss: 3.94558e-04
I0405 09:18:22.824255 23443585951552 run_lib.py:140] step: 144050, training_loss: 4.51191e-04
I0405 09:18:40.741845 23443585951552 run_lib.py:140] step: 144100, training_loss: 3.67717e-04
I0405 09:18:40.902410 23443585951552 run_lib.py:153] step: 144100, eval_loss: 3.76545e-04
I0405 09:18:58.689154 23443585951552 run_lib.py:140] step: 144150, training_loss: 3.64156e-04
I0405 09:19:16.420092 23443585951552 run_lib.py:140] step: 144200, training_loss: 3.84608e-04
I0405 09:19:16.576797 23443585951552 run_lib.py:153] step: 144200, eval_loss: 3.35713e-04
I0405 09:19:34.140886 23443585951552 run_lib.py:140] step: 144250, training_loss: 4.46175e-04
I0405 09:19:51.860595 23443585951552 run_lib.py:140] step: 144300, training_loss: 4.06018e-04
I0405 09:19:52.014601 23443585951552 run_lib.py:153] step: 144300, eval_loss: 3.92598e-04
I0405 09:20:09.886718 23443585951552 run_lib.py:140] step: 144350, training_loss: 4.24000e-04
I0405 09:20:27.486064 23443585951552 run_lib.py:140] step: 144400, training_loss: 3.78231e-04
I0405 09:20:27.638873 23443585951552 run_lib.py:153] step: 144400, eval_loss: 4.43390e-04
I0405 09:20:45.222759 23443585951552 run_lib.py:140] step: 144450, training_loss: 3.58060e-04
I0405 09:21:02.966245 23443585951552 run_lib.py:140] step: 144500, training_loss: 4.31030e-04
I0405 09:21:03.122060 23443585951552 run_lib.py:153] step: 144500, eval_loss: 3.87820e-04
I0405 09:21:20.754122 23443585951552 run_lib.py:140] step: 144550, training_loss: 3.85158e-04
I0405 09:21:38.335254 23443585951552 run_lib.py:140] step: 144600, training_loss: 4.30514e-04
I0405 09:21:38.493041 23443585951552 run_lib.py:153] step: 144600, eval_loss: 3.71457e-04
I0405 09:21:56.096725 23443585951552 run_lib.py:140] step: 144650, training_loss: 3.66090e-04
I0405 09:22:13.633468 23443585951552 run_lib.py:140] step: 144700, training_loss: 4.13291e-04
I0405 09:22:13.790052 23443585951552 run_lib.py:153] step: 144700, eval_loss: 3.73249e-04
I0405 09:22:31.310281 23443585951552 run_lib.py:140] step: 144750, training_loss: 4.03696e-04
I0405 09:22:48.832874 23443585951552 run_lib.py:140] step: 144800, training_loss: 4.37431e-04
I0405 09:22:48.985190 23443585951552 run_lib.py:153] step: 144800, eval_loss: 4.01951e-04
I0405 09:23:06.777967 23443585951552 run_lib.py:140] step: 144850, training_loss: 4.40432e-04
I0405 09:23:24.512579 23443585951552 run_lib.py:140] step: 144900, training_loss: 4.10576e-04
I0405 09:23:24.709930 23443585951552 run_lib.py:153] step: 144900, eval_loss: 3.96304e-04
I0405 09:23:42.246377 23443585951552 run_lib.py:140] step: 144950, training_loss: 4.17731e-04
I0405 09:23:59.781117 23443585951552 run_lib.py:140] step: 145000, training_loss: 4.21248e-04
I0405 09:23:59.934851 23443585951552 run_lib.py:153] step: 145000, eval_loss: 3.16946e-04
I0405 09:24:17.662284 23443585951552 run_lib.py:140] step: 145050, training_loss: 3.95095e-04
I0405 09:24:35.252795 23443585951552 run_lib.py:140] step: 145100, training_loss: 4.46739e-04
I0405 09:24:35.423807 23443585951552 run_lib.py:153] step: 145100, eval_loss: 4.26049e-04
I0405 09:24:53.025089 23443585951552 run_lib.py:140] step: 145150, training_loss: 3.83432e-04
I0405 09:25:10.899167 23443585951552 run_lib.py:140] step: 145200, training_loss: 4.01549e-04
I0405 09:25:11.053901 23443585951552 run_lib.py:153] step: 145200, eval_loss: 3.95049e-04
I0405 09:25:28.573096 23443585951552 run_lib.py:140] step: 145250, training_loss: 4.65780e-04
I0405 09:25:46.213942 23443585951552 run_lib.py:140] step: 145300, training_loss: 4.16639e-04
I0405 09:25:46.407580 23443585951552 run_lib.py:153] step: 145300, eval_loss: 4.27128e-04
I0405 09:26:03.865236 23443585951552 run_lib.py:140] step: 145350, training_loss: 3.87332e-04
I0405 09:26:21.648896 23443585951552 run_lib.py:140] step: 145400, training_loss: 3.83882e-04
I0405 09:26:21.811147 23443585951552 run_lib.py:153] step: 145400, eval_loss: 3.81619e-04
I0405 09:26:39.484767 23443585951552 run_lib.py:140] step: 145450, training_loss: 3.45587e-04
I0405 09:26:57.067762 23443585951552 run_lib.py:140] step: 145500, training_loss: 3.98285e-04
I0405 09:26:57.262190 23443585951552 run_lib.py:153] step: 145500, eval_loss: 4.43626e-04
I0405 09:27:14.748172 23443585951552 run_lib.py:140] step: 145550, training_loss: 4.76781e-04
I0405 09:27:32.375717 23443585951552 run_lib.py:140] step: 145600, training_loss: 4.32717e-04
I0405 09:27:32.528752 23443585951552 run_lib.py:153] step: 145600, eval_loss: 4.69440e-04
I0405 09:27:50.066421 23443585951552 run_lib.py:140] step: 145650, training_loss: 3.81405e-04
I0405 09:28:07.775707 23443585951552 run_lib.py:140] step: 145700, training_loss: 3.64397e-04
I0405 09:28:07.931431 23443585951552 run_lib.py:153] step: 145700, eval_loss: 3.97704e-04
I0405 09:28:25.753576 23443585951552 run_lib.py:140] step: 145750, training_loss: 3.91594e-04
I0405 09:28:43.329324 23443585951552 run_lib.py:140] step: 145800, training_loss: 3.86671e-04
I0405 09:28:43.488948 23443585951552 run_lib.py:153] step: 145800, eval_loss: 4.25453e-04
I0405 09:29:01.147477 23443585951552 run_lib.py:140] step: 145850, training_loss: 4.07517e-04
I0405 09:29:18.843486 23443585951552 run_lib.py:140] step: 145900, training_loss: 4.12825e-04
I0405 09:29:19.012982 23443585951552 run_lib.py:153] step: 145900, eval_loss: 4.13716e-04
I0405 09:29:36.889786 23443585951552 run_lib.py:140] step: 145950, training_loss: 3.60159e-04
I0405 09:29:54.676450 23443585951552 run_lib.py:140] step: 146000, training_loss: 4.06401e-04
I0405 09:29:54.835168 23443585951552 run_lib.py:153] step: 146000, eval_loss: 4.18435e-04
I0405 09:30:12.491129 23443585951552 run_lib.py:140] step: 146050, training_loss: 3.59898e-04
I0405 09:30:30.133329 23443585951552 run_lib.py:140] step: 146100, training_loss: 3.55468e-04
I0405 09:30:30.288221 23443585951552 run_lib.py:153] step: 146100, eval_loss: 4.16491e-04
I0405 09:30:48.255292 23443585951552 run_lib.py:140] step: 146150, training_loss: 4.50064e-04
I0405 09:31:05.972825 23443585951552 run_lib.py:140] step: 146200, training_loss: 4.93769e-04
I0405 09:31:06.127964 23443585951552 run_lib.py:153] step: 146200, eval_loss: 3.70501e-04
I0405 09:31:23.719048 23443585951552 run_lib.py:140] step: 146250, training_loss: 4.23870e-04
I0405 09:31:41.524511 23443585951552 run_lib.py:140] step: 146300, training_loss: 4.18573e-04
I0405 09:31:41.678344 23443585951552 run_lib.py:153] step: 146300, eval_loss: 3.86383e-04
I0405 09:31:59.135957 23443585951552 run_lib.py:140] step: 146350, training_loss: 4.07835e-04
I0405 09:32:16.765850 23443585951552 run_lib.py:140] step: 146400, training_loss: 3.67871e-04
I0405 09:32:16.923482 23443585951552 run_lib.py:153] step: 146400, eval_loss: 4.13909e-04
I0405 09:32:34.456631 23443585951552 run_lib.py:140] step: 146450, training_loss: 4.19534e-04
I0405 09:32:52.171258 23443585951552 run_lib.py:140] step: 146500, training_loss: 4.04666e-04
I0405 09:32:52.343654 23443585951552 run_lib.py:153] step: 146500, eval_loss: 4.38040e-04
I0405 09:33:10.155513 23443585951552 run_lib.py:140] step: 146550, training_loss: 3.84767e-04
I0405 09:33:27.788105 23443585951552 run_lib.py:140] step: 146600, training_loss: 4.45855e-04
I0405 09:33:27.946570 23443585951552 run_lib.py:153] step: 146600, eval_loss: 3.87184e-04
I0405 09:33:45.570461 23443585951552 run_lib.py:140] step: 146650, training_loss: 4.24203e-04
I0405 09:34:03.282457 23443585951552 run_lib.py:140] step: 146700, training_loss: 3.83018e-04
I0405 09:34:03.444804 23443585951552 run_lib.py:153] step: 146700, eval_loss: 4.08796e-04
I0405 09:34:21.028532 23443585951552 run_lib.py:140] step: 146750, training_loss: 4.36999e-04
I0405 09:34:38.710237 23443585951552 run_lib.py:140] step: 146800, training_loss: 4.01145e-04
I0405 09:34:38.871121 23443585951552 run_lib.py:153] step: 146800, eval_loss: 3.92540e-04
I0405 09:34:56.615472 23443585951552 run_lib.py:140] step: 146850, training_loss: 3.94708e-04
I0405 09:35:14.256276 23443585951552 run_lib.py:140] step: 146900, training_loss: 3.99662e-04
I0405 09:35:14.412971 23443585951552 run_lib.py:153] step: 146900, eval_loss: 4.25242e-04
I0405 09:35:32.206612 23443585951552 run_lib.py:140] step: 146950, training_loss: 4.01877e-04
I0405 09:35:49.716065 23443585951552 run_lib.py:140] step: 147000, training_loss: 3.96800e-04
I0405 09:35:49.869683 23443585951552 run_lib.py:153] step: 147000, eval_loss: 4.27385e-04
I0405 09:36:07.612188 23443585951552 run_lib.py:140] step: 147050, training_loss: 4.06377e-04
I0405 09:36:25.474296 23443585951552 run_lib.py:140] step: 147100, training_loss: 3.60760e-04
I0405 09:36:25.630813 23443585951552 run_lib.py:153] step: 147100, eval_loss: 4.13205e-04
I0405 09:36:43.282544 23443585951552 run_lib.py:140] step: 147150, training_loss: 3.83033e-04
I0405 09:37:00.966268 23443585951552 run_lib.py:140] step: 147200, training_loss: 4.72014e-04
I0405 09:37:01.119028 23443585951552 run_lib.py:153] step: 147200, eval_loss: 3.83810e-04
I0405 09:37:19.041050 23443585951552 run_lib.py:140] step: 147250, training_loss: 4.34436e-04
I0405 09:37:36.789303 23443585951552 run_lib.py:140] step: 147300, training_loss: 3.43674e-04
I0405 09:37:36.963073 23443585951552 run_lib.py:153] step: 147300, eval_loss: 4.04111e-04
I0405 09:37:54.805879 23443585951552 run_lib.py:140] step: 147350, training_loss: 3.40069e-04
I0405 09:38:12.797473 23443585951552 run_lib.py:140] step: 147400, training_loss: 3.95065e-04
I0405 09:38:12.958982 23443585951552 run_lib.py:153] step: 147400, eval_loss: 4.14508e-04
I0405 09:38:30.719418 23443585951552 run_lib.py:140] step: 147450, training_loss: 4.48440e-04
I0405 09:38:48.641440 23443585951552 run_lib.py:140] step: 147500, training_loss: 4.01085e-04
I0405 09:38:48.801732 23443585951552 run_lib.py:153] step: 147500, eval_loss: 4.44038e-04
I0405 09:39:06.533390 23443585951552 run_lib.py:140] step: 147550, training_loss: 3.46420e-04
I0405 09:39:24.244131 23443585951552 run_lib.py:140] step: 147600, training_loss: 4.48178e-04
I0405 09:39:24.405240 23443585951552 run_lib.py:153] step: 147600, eval_loss: 4.35160e-04
I0405 09:39:42.391051 23443585951552 run_lib.py:140] step: 147650, training_loss: 4.21190e-04
I0405 09:40:00.120416 23443585951552 run_lib.py:140] step: 147700, training_loss: 4.40188e-04
I0405 09:40:00.275612 23443585951552 run_lib.py:153] step: 147700, eval_loss: 4.32545e-04
I0405 09:40:17.977356 23443585951552 run_lib.py:140] step: 147750, training_loss: 3.90522e-04
I0405 09:40:35.924728 23443585951552 run_lib.py:140] step: 147800, training_loss: 4.52386e-04
I0405 09:40:36.126291 23443585951552 run_lib.py:153] step: 147800, eval_loss: 3.75745e-04
I0405 09:40:53.819325 23443585951552 run_lib.py:140] step: 147850, training_loss: 4.34700e-04
I0405 09:41:11.550152 23443585951552 run_lib.py:140] step: 147900, training_loss: 4.00341e-04
I0405 09:41:11.727582 23443585951552 run_lib.py:153] step: 147900, eval_loss: 3.40298e-04
I0405 09:41:29.574923 23443585951552 run_lib.py:140] step: 147950, training_loss: 4.20309e-04
I0405 09:41:47.425545 23443585951552 run_lib.py:140] step: 148000, training_loss: 4.27779e-04
I0405 09:41:47.582015 23443585951552 run_lib.py:153] step: 148000, eval_loss: 4.32412e-04
I0405 09:42:05.252464 23443585951552 run_lib.py:140] step: 148050, training_loss: 3.76234e-04
I0405 09:42:22.843694 23443585951552 run_lib.py:140] step: 148100, training_loss: 3.79763e-04
I0405 09:42:23.001943 23443585951552 run_lib.py:153] step: 148100, eval_loss: 4.00411e-04
I0405 09:42:40.832509 23443585951552 run_lib.py:140] step: 148150, training_loss: 4.55128e-04
I0405 09:42:58.648138 23443585951552 run_lib.py:140] step: 148200, training_loss: 3.59669e-04
I0405 09:42:58.812110 23443585951552 run_lib.py:153] step: 148200, eval_loss: 4.08305e-04
I0405 09:43:16.469605 23443585951552 run_lib.py:140] step: 148250, training_loss: 3.95051e-04
I0405 09:43:34.129115 23443585951552 run_lib.py:140] step: 148300, training_loss: 4.36572e-04
I0405 09:43:34.287826 23443585951552 run_lib.py:153] step: 148300, eval_loss: 3.81176e-04
I0405 09:43:52.127912 23443585951552 run_lib.py:140] step: 148350, training_loss: 4.44878e-04
I0405 09:44:09.758805 23443585951552 run_lib.py:140] step: 148400, training_loss: 4.69696e-04
I0405 09:44:10.004674 23443585951552 run_lib.py:153] step: 148400, eval_loss: 4.54507e-04
I0405 09:44:27.616451 23443585951552 run_lib.py:140] step: 148450, training_loss: 3.97837e-04
I0405 09:44:45.518506 23443585951552 run_lib.py:140] step: 148500, training_loss: 3.78571e-04
I0405 09:44:45.675396 23443585951552 run_lib.py:153] step: 148500, eval_loss: 4.32613e-04
I0405 09:45:03.366623 23443585951552 run_lib.py:140] step: 148550, training_loss: 4.13752e-04
I0405 09:45:21.182316 23443585951552 run_lib.py:140] step: 148600, training_loss: 4.23725e-04
I0405 09:45:21.341918 23443585951552 run_lib.py:153] step: 148600, eval_loss: 4.39045e-04
I0405 09:45:38.939961 23443585951552 run_lib.py:140] step: 148650, training_loss: 4.03109e-04
I0405 09:45:56.538103 23443585951552 run_lib.py:140] step: 148700, training_loss: 3.84202e-04
I0405 09:45:56.693958 23443585951552 run_lib.py:153] step: 148700, eval_loss: 4.89973e-04
I0405 09:46:14.479161 23443585951552 run_lib.py:140] step: 148750, training_loss: 3.59480e-04
I0405 09:46:32.192394 23443585951552 run_lib.py:140] step: 148800, training_loss: 4.11927e-04
I0405 09:46:32.374971 23443585951552 run_lib.py:153] step: 148800, eval_loss: 4.30225e-04
I0405 09:46:50.005228 23443585951552 run_lib.py:140] step: 148850, training_loss: 4.07179e-04
I0405 09:47:07.840461 23443585951552 run_lib.py:140] step: 148900, training_loss: 4.41956e-04
I0405 09:47:07.997073 23443585951552 run_lib.py:153] step: 148900, eval_loss: 3.95889e-04
I0405 09:47:25.616007 23443585951552 run_lib.py:140] step: 148950, training_loss: 4.02136e-04
I0405 09:47:43.214143 23443585951552 run_lib.py:140] step: 149000, training_loss: 4.04645e-04
I0405 09:47:43.370918 23443585951552 run_lib.py:153] step: 149000, eval_loss: 3.70902e-04
I0405 09:48:01.102069 23443585951552 run_lib.py:140] step: 149050, training_loss: 4.18296e-04
I0405 09:48:18.803418 23443585951552 run_lib.py:140] step: 149100, training_loss: 3.98737e-04
I0405 09:48:18.959090 23443585951552 run_lib.py:153] step: 149100, eval_loss: 4.07699e-04
I0405 09:48:36.617350 23443585951552 run_lib.py:140] step: 149150, training_loss: 4.08594e-04
I0405 09:48:54.243667 23443585951552 run_lib.py:140] step: 149200, training_loss: 3.99214e-04
I0405 09:48:54.402224 23443585951552 run_lib.py:153] step: 149200, eval_loss: 3.74670e-04
I0405 09:49:12.214724 23443585951552 run_lib.py:140] step: 149250, training_loss: 4.43690e-04
I0405 09:49:29.954705 23443585951552 run_lib.py:140] step: 149300, training_loss: 3.39270e-04
I0405 09:49:30.115996 23443585951552 run_lib.py:153] step: 149300, eval_loss: 3.97384e-04
I0405 09:49:47.781926 23443585951552 run_lib.py:140] step: 149350, training_loss: 4.31226e-04
I0405 09:50:05.470826 23443585951552 run_lib.py:140] step: 149400, training_loss: 3.76381e-04
I0405 09:50:05.628098 23443585951552 run_lib.py:153] step: 149400, eval_loss: 4.29411e-04
I0405 09:50:23.439155 23443585951552 run_lib.py:140] step: 149450, training_loss: 4.11924e-04
I0405 09:50:41.090885 23443585951552 run_lib.py:140] step: 149500, training_loss: 4.06833e-04
I0405 09:50:41.245006 23443585951552 run_lib.py:153] step: 149500, eval_loss: 3.64619e-04
I0405 09:50:58.830424 23443585951552 run_lib.py:140] step: 149550, training_loss: 4.02040e-04
I0405 09:51:16.625427 23443585951552 run_lib.py:140] step: 149600, training_loss: 3.77856e-04
I0405 09:51:16.781989 23443585951552 run_lib.py:153] step: 149600, eval_loss: 3.93218e-04
I0405 09:51:34.448765 23443585951552 run_lib.py:140] step: 149650, training_loss: 4.50878e-04
I0405 09:51:52.270445 23443585951552 run_lib.py:140] step: 149700, training_loss: 4.21880e-04
I0405 09:51:52.431128 23443585951552 run_lib.py:153] step: 149700, eval_loss: 4.07427e-04
I0405 09:52:10.017584 23443585951552 run_lib.py:140] step: 149750, training_loss: 4.35843e-04
I0405 09:52:27.591255 23443585951552 run_lib.py:140] step: 149800, training_loss: 4.25816e-04
I0405 09:52:27.757357 23443585951552 run_lib.py:153] step: 149800, eval_loss: 4.34086e-04
I0405 09:52:45.503475 23443585951552 run_lib.py:140] step: 149850, training_loss: 3.58464e-04
I0405 09:53:03.123805 23443585951552 run_lib.py:140] step: 149900, training_loss: 3.69895e-04
I0405 09:53:03.292845 23443585951552 run_lib.py:153] step: 149900, eval_loss: 4.45912e-04
I0405 09:53:20.930411 23443585951552 run_lib.py:140] step: 149950, training_loss: 4.09090e-04
I0405 09:53:38.752076 23443585951552 run_lib.py:140] step: 150000, training_loss: 3.82453e-04
I0405 09:53:39.412986 23443585951552 run_lib.py:153] step: 150000, eval_loss: 3.82846e-04
I0405 09:53:57.483711 23443585951552 run_lib.py:140] step: 150050, training_loss: 4.56648e-04
I0405 09:54:15.071185 23443585951552 run_lib.py:140] step: 150100, training_loss: 4.12520e-04
I0405 09:54:15.222851 23443585951552 run_lib.py:153] step: 150100, eval_loss: 4.19944e-04
I0405 09:54:32.854347 23443585951552 run_lib.py:140] step: 150150, training_loss: 4.83795e-04
I0405 09:54:50.495830 23443585951552 run_lib.py:140] step: 150200, training_loss: 3.53254e-04
I0405 09:54:50.673794 23443585951552 run_lib.py:153] step: 150200, eval_loss: 4.76457e-04
I0405 09:55:08.296733 23443585951552 run_lib.py:140] step: 150250, training_loss: 3.36976e-04
I0405 09:55:25.955202 23443585951552 run_lib.py:140] step: 150300, training_loss: 4.24396e-04
I0405 09:55:26.110033 23443585951552 run_lib.py:153] step: 150300, eval_loss: 4.28467e-04
I0405 09:55:43.910799 23443585951552 run_lib.py:140] step: 150350, training_loss: 3.75828e-04
I0405 09:56:01.523424 23443585951552 run_lib.py:140] step: 150400, training_loss: 4.07781e-04
I0405 09:56:01.675640 23443585951552 run_lib.py:153] step: 150400, eval_loss: 3.64734e-04
I0405 09:56:19.265122 23443585951552 run_lib.py:140] step: 150450, training_loss: 4.32401e-04
I0405 09:56:36.871682 23443585951552 run_lib.py:140] step: 150500, training_loss: 3.74683e-04
I0405 09:56:37.030138 23443585951552 run_lib.py:153] step: 150500, eval_loss: 4.37522e-04
I0405 09:56:54.869797 23443585951552 run_lib.py:140] step: 150550, training_loss: 4.12252e-04
I0405 09:57:12.410296 23443585951552 run_lib.py:140] step: 150600, training_loss: 4.45806e-04
I0405 09:57:12.562876 23443585951552 run_lib.py:153] step: 150600, eval_loss: 3.63535e-04
I0405 09:57:30.078707 23443585951552 run_lib.py:140] step: 150650, training_loss: 4.39633e-04
I0405 09:57:47.811050 23443585951552 run_lib.py:140] step: 150700, training_loss: 4.20139e-04
I0405 09:57:47.970113 23443585951552 run_lib.py:153] step: 150700, eval_loss: 4.18430e-04
I0405 09:58:05.545670 23443585951552 run_lib.py:140] step: 150750, training_loss: 3.94661e-04
I0405 09:58:23.339542 23443585951552 run_lib.py:140] step: 150800, training_loss: 4.40859e-04
I0405 09:58:23.496967 23443585951552 run_lib.py:153] step: 150800, eval_loss: 4.33388e-04
I0405 09:58:41.041568 23443585951552 run_lib.py:140] step: 150850, training_loss: 4.01029e-04
I0405 09:58:58.594253 23443585951552 run_lib.py:140] step: 150900, training_loss: 3.99099e-04
I0405 09:58:58.746325 23443585951552 run_lib.py:153] step: 150900, eval_loss: 4.15246e-04
I0405 09:59:16.536696 23443585951552 run_lib.py:140] step: 150950, training_loss: 4.15595e-04
I0405 09:59:34.048009 23443585951552 run_lib.py:140] step: 151000, training_loss: 4.18501e-04
I0405 09:59:34.199572 23443585951552 run_lib.py:153] step: 151000, eval_loss: 3.63348e-04
I0405 09:59:51.738718 23443585951552 run_lib.py:140] step: 151050, training_loss: 3.69516e-04
I0405 10:00:09.573747 23443585951552 run_lib.py:140] step: 151100, training_loss: 3.80353e-04
I0405 10:00:09.744884 23443585951552 run_lib.py:153] step: 151100, eval_loss: 4.16331e-04
I0405 10:00:27.409065 23443585951552 run_lib.py:140] step: 151150, training_loss: 4.14749e-04
I0405 10:00:44.993759 23443585951552 run_lib.py:140] step: 151200, training_loss: 3.91835e-04
I0405 10:00:45.153206 23443585951552 run_lib.py:153] step: 151200, eval_loss: 3.78696e-04
I0405 10:01:02.778057 23443585951552 run_lib.py:140] step: 151250, training_loss: 3.83158e-04
I0405 10:01:20.315995 23443585951552 run_lib.py:140] step: 151300, training_loss: 4.40848e-04
I0405 10:01:20.473026 23443585951552 run_lib.py:153] step: 151300, eval_loss: 4.14881e-04
I0405 10:01:38.060092 23443585951552 run_lib.py:140] step: 151350, training_loss: 4.13264e-04
I0405 10:01:55.719765 23443585951552 run_lib.py:140] step: 151400, training_loss: 4.44893e-04
I0405 10:01:55.876092 23443585951552 run_lib.py:153] step: 151400, eval_loss: 3.35701e-04
I0405 10:02:13.665620 23443585951552 run_lib.py:140] step: 151450, training_loss: 3.94936e-04
I0405 10:02:31.314738 23443585951552 run_lib.py:140] step: 151500, training_loss: 4.18486e-04
I0405 10:02:31.472904 23443585951552 run_lib.py:153] step: 151500, eval_loss: 4.10912e-04
I0405 10:02:49.083755 23443585951552 run_lib.py:140] step: 151550, training_loss: 4.43838e-04
I0405 10:03:06.680313 23443585951552 run_lib.py:140] step: 151600, training_loss: 4.08892e-04
I0405 10:03:06.855027 23443585951552 run_lib.py:153] step: 151600, eval_loss: 3.38410e-04
I0405 10:03:24.801042 23443585951552 run_lib.py:140] step: 151650, training_loss: 4.07622e-04
I0405 10:03:42.439282 23443585951552 run_lib.py:140] step: 151700, training_loss: 4.25052e-04
I0405 10:03:42.598901 23443585951552 run_lib.py:153] step: 151700, eval_loss: 4.71153e-04
I0405 10:04:00.215476 23443585951552 run_lib.py:140] step: 151750, training_loss: 4.13407e-04
I0405 10:04:17.963776 23443585951552 run_lib.py:140] step: 151800, training_loss: 3.79932e-04
I0405 10:04:18.121979 23443585951552 run_lib.py:153] step: 151800, eval_loss: 3.92957e-04
I0405 10:04:35.761981 23443585951552 run_lib.py:140] step: 151850, training_loss: 4.04771e-04
I0405 10:04:53.517618 23443585951552 run_lib.py:140] step: 151900, training_loss: 4.26804e-04
I0405 10:04:53.673117 23443585951552 run_lib.py:153] step: 151900, eval_loss: 3.69072e-04
I0405 10:05:11.376304 23443585951552 run_lib.py:140] step: 151950, training_loss: 3.93935e-04
I0405 10:05:28.919119 23443585951552 run_lib.py:140] step: 152000, training_loss: 3.75229e-04
I0405 10:05:29.072352 23443585951552 run_lib.py:153] step: 152000, eval_loss: 3.43456e-04
I0405 10:05:46.766676 23443585951552 run_lib.py:140] step: 152050, training_loss: 4.12691e-04
I0405 10:06:04.318859 23443585951552 run_lib.py:140] step: 152100, training_loss: 4.08442e-04
I0405 10:06:04.479055 23443585951552 run_lib.py:153] step: 152100, eval_loss: 3.90991e-04
I0405 10:06:21.969192 23443585951552 run_lib.py:140] step: 152150, training_loss: 3.88768e-04
I0405 10:06:39.636308 23443585951552 run_lib.py:140] step: 152200, training_loss: 4.12263e-04
I0405 10:06:39.804715 23443585951552 run_lib.py:153] step: 152200, eval_loss: 3.92753e-04
I0405 10:06:57.429864 23443585951552 run_lib.py:140] step: 152250, training_loss: 4.08070e-04
I0405 10:07:15.062433 23443585951552 run_lib.py:140] step: 152300, training_loss: 4.50353e-04
I0405 10:07:15.219207 23443585951552 run_lib.py:153] step: 152300, eval_loss: 4.26195e-04
I0405 10:07:32.874837 23443585951552 run_lib.py:140] step: 152350, training_loss: 4.54469e-04
I0405 10:07:50.358299 23443585951552 run_lib.py:140] step: 152400, training_loss: 3.88050e-04
I0405 10:07:50.509732 23443585951552 run_lib.py:153] step: 152400, eval_loss: 3.60366e-04
I0405 10:08:08.033286 23443585951552 run_lib.py:140] step: 152450, training_loss: 3.95834e-04
I0405 10:08:25.648637 23443585951552 run_lib.py:140] step: 152500, training_loss: 4.22682e-04
I0405 10:08:25.815100 23443585951552 run_lib.py:153] step: 152500, eval_loss: 3.94776e-04
I0405 10:08:43.682494 23443585951552 run_lib.py:140] step: 152550, training_loss: 3.88182e-04
I0405 10:09:01.356623 23443585951552 run_lib.py:140] step: 152600, training_loss: 4.09927e-04
I0405 10:09:01.514001 23443585951552 run_lib.py:153] step: 152600, eval_loss: 3.77121e-04
I0405 10:09:19.068792 23443585951552 run_lib.py:140] step: 152650, training_loss: 3.59439e-04
I0405 10:09:36.680871 23443585951552 run_lib.py:140] step: 152700, training_loss: 3.83552e-04
I0405 10:09:36.835967 23443585951552 run_lib.py:153] step: 152700, eval_loss: 4.38642e-04
I0405 10:09:54.498681 23443585951552 run_lib.py:140] step: 152750, training_loss: 4.04512e-04
I0405 10:10:12.130985 23443585951552 run_lib.py:140] step: 152800, training_loss: 4.25017e-04
I0405 10:10:12.289931 23443585951552 run_lib.py:153] step: 152800, eval_loss: 4.32845e-04
I0405 10:10:29.902960 23443585951552 run_lib.py:140] step: 152850, training_loss: 3.61526e-04
I0405 10:10:47.648172 23443585951552 run_lib.py:140] step: 152900, training_loss: 4.31780e-04
I0405 10:10:47.802971 23443585951552 run_lib.py:153] step: 152900, eval_loss: 3.82471e-04
I0405 10:11:05.385445 23443585951552 run_lib.py:140] step: 152950, training_loss: 3.90849e-04
I0405 10:11:23.122689 23443585951552 run_lib.py:140] step: 153000, training_loss: 4.08978e-04
I0405 10:11:23.284106 23443585951552 run_lib.py:153] step: 153000, eval_loss: 3.89947e-04
I0405 10:11:40.935623 23443585951552 run_lib.py:140] step: 153050, training_loss: 4.34222e-04
I0405 10:11:58.525247 23443585951552 run_lib.py:140] step: 153100, training_loss: 4.34305e-04
I0405 10:11:58.680917 23443585951552 run_lib.py:153] step: 153100, eval_loss: 4.06727e-04
I0405 10:12:16.403021 23443585951552 run_lib.py:140] step: 153150, training_loss: 4.27415e-04
I0405 10:12:33.907693 23443585951552 run_lib.py:140] step: 153200, training_loss: 3.78534e-04
I0405 10:12:34.070612 23443585951552 run_lib.py:153] step: 153200, eval_loss: 4.36609e-04
I0405 10:12:51.610539 23443585951552 run_lib.py:140] step: 153250, training_loss: 3.63710e-04
I0405 10:13:09.427756 23443585951552 run_lib.py:140] step: 153300, training_loss: 4.57291e-04
I0405 10:13:09.605192 23443585951552 run_lib.py:153] step: 153300, eval_loss: 3.90693e-04
I0405 10:13:27.119158 23443585951552 run_lib.py:140] step: 153350, training_loss: 3.75168e-04
I0405 10:13:44.598813 23443585951552 run_lib.py:140] step: 153400, training_loss: 3.79234e-04
I0405 10:13:44.754735 23443585951552 run_lib.py:153] step: 153400, eval_loss: 4.41073e-04
I0405 10:14:02.309867 23443585951552 run_lib.py:140] step: 153450, training_loss: 4.04256e-04
I0405 10:14:19.860274 23443585951552 run_lib.py:140] step: 153500, training_loss: 3.76898e-04
I0405 10:14:20.015593 23443585951552 run_lib.py:153] step: 153500, eval_loss: 4.42656e-04
I0405 10:14:37.581017 23443585951552 run_lib.py:140] step: 153550, training_loss: 4.05638e-04
I0405 10:14:55.122776 23443585951552 run_lib.py:140] step: 153600, training_loss: 4.06499e-04
I0405 10:14:55.284774 23443585951552 run_lib.py:153] step: 153600, eval_loss: 4.17669e-04
I0405 10:15:12.975962 23443585951552 run_lib.py:140] step: 153650, training_loss: 4.03863e-04
I0405 10:15:30.525620 23443585951552 run_lib.py:140] step: 153700, training_loss: 3.81619e-04
I0405 10:15:30.678210 23443585951552 run_lib.py:153] step: 153700, eval_loss: 3.28680e-04
I0405 10:15:48.274940 23443585951552 run_lib.py:140] step: 153750, training_loss: 3.32952e-04
I0405 10:16:05.788934 23443585951552 run_lib.py:140] step: 153800, training_loss: 4.59108e-04
I0405 10:16:05.942991 23443585951552 run_lib.py:153] step: 153800, eval_loss: 3.90722e-04
I0405 10:16:23.660421 23443585951552 run_lib.py:140] step: 153850, training_loss: 3.68318e-04
I0405 10:16:41.193082 23443585951552 run_lib.py:140] step: 153900, training_loss: 3.88586e-04
I0405 10:16:41.345983 23443585951552 run_lib.py:153] step: 153900, eval_loss: 3.97899e-04
I0405 10:16:58.854182 23443585951552 run_lib.py:140] step: 153950, training_loss: 3.58703e-04
I0405 10:17:16.645664 23443585951552 run_lib.py:140] step: 154000, training_loss: 3.96251e-04
I0405 10:17:16.803879 23443585951552 run_lib.py:153] step: 154000, eval_loss: 4.04746e-04
I0405 10:17:34.272299 23443585951552 run_lib.py:140] step: 154050, training_loss: 3.80047e-04
I0405 10:17:51.965196 23443585951552 run_lib.py:140] step: 154100, training_loss: 3.90573e-04
I0405 10:17:52.124887 23443585951552 run_lib.py:153] step: 154100, eval_loss: 3.85459e-04
I0405 10:18:09.714127 23443585951552 run_lib.py:140] step: 154150, training_loss: 4.09237e-04
I0405 10:18:27.295192 23443585951552 run_lib.py:140] step: 154200, training_loss: 4.58666e-04
I0405 10:18:27.457640 23443585951552 run_lib.py:153] step: 154200, eval_loss: 4.64486e-04
I0405 10:18:45.288864 23443585951552 run_lib.py:140] step: 154250, training_loss: 4.10835e-04
I0405 10:19:03.018021 23443585951552 run_lib.py:140] step: 154300, training_loss: 4.21711e-04
I0405 10:19:03.175078 23443585951552 run_lib.py:153] step: 154300, eval_loss: 4.24807e-04
I0405 10:19:20.937313 23443585951552 run_lib.py:140] step: 154350, training_loss: 4.28623e-04
I0405 10:19:38.850711 23443585951552 run_lib.py:140] step: 154400, training_loss: 4.31691e-04
I0405 10:19:39.019349 23443585951552 run_lib.py:153] step: 154400, eval_loss: 3.52415e-04
I0405 10:19:56.882883 23443585951552 run_lib.py:140] step: 154450, training_loss: 3.57795e-04
I0405 10:20:14.597777 23443585951552 run_lib.py:140] step: 154500, training_loss: 4.38181e-04
I0405 10:20:14.763801 23443585951552 run_lib.py:153] step: 154500, eval_loss: 4.18422e-04
I0405 10:20:32.610880 23443585951552 run_lib.py:140] step: 154550, training_loss: 3.75145e-04
I0405 10:20:50.334910 23443585951552 run_lib.py:140] step: 154600, training_loss: 3.42641e-04
I0405 10:20:50.495470 23443585951552 run_lib.py:153] step: 154600, eval_loss: 4.00962e-04
I0405 10:21:08.214676 23443585951552 run_lib.py:140] step: 154650, training_loss: 4.44923e-04
I0405 10:21:25.984458 23443585951552 run_lib.py:140] step: 154700, training_loss: 3.61577e-04
I0405 10:21:26.147074 23443585951552 run_lib.py:153] step: 154700, eval_loss: 4.21499e-04
I0405 10:21:44.016548 23443585951552 run_lib.py:140] step: 154750, training_loss: 4.30970e-04
I0405 10:22:01.812043 23443585951552 run_lib.py:140] step: 154800, training_loss: 4.13740e-04
I0405 10:22:01.969095 23443585951552 run_lib.py:153] step: 154800, eval_loss: 4.61184e-04
I0405 10:22:19.663045 23443585951552 run_lib.py:140] step: 154850, training_loss: 4.16978e-04
I0405 10:22:37.321801 23443585951552 run_lib.py:140] step: 154900, training_loss: 3.64108e-04
I0405 10:22:37.480222 23443585951552 run_lib.py:153] step: 154900, eval_loss: 3.41183e-04
I0405 10:22:55.264641 23443585951552 run_lib.py:140] step: 154950, training_loss: 4.09388e-04
I0405 10:23:12.985798 23443585951552 run_lib.py:140] step: 155000, training_loss: 3.20909e-04
I0405 10:23:13.167080 23443585951552 run_lib.py:153] step: 155000, eval_loss: 4.10316e-04
I0405 10:23:30.880188 23443585951552 run_lib.py:140] step: 155050, training_loss: 3.47116e-04
I0405 10:23:48.744356 23443585951552 run_lib.py:140] step: 155100, training_loss: 3.71479e-04
I0405 10:23:48.905244 23443585951552 run_lib.py:153] step: 155100, eval_loss: 4.08574e-04
I0405 10:24:06.585107 23443585951552 run_lib.py:140] step: 155150, training_loss: 4.18774e-04
I0405 10:24:24.389037 23443585951552 run_lib.py:140] step: 155200, training_loss: 3.66320e-04
I0405 10:24:24.548737 23443585951552 run_lib.py:153] step: 155200, eval_loss: 4.08270e-04
I0405 10:24:42.217468 23443585951552 run_lib.py:140] step: 155250, training_loss: 4.52885e-04
I0405 10:24:59.969565 23443585951552 run_lib.py:140] step: 155300, training_loss: 3.95454e-04
I0405 10:25:00.133089 23443585951552 run_lib.py:153] step: 155300, eval_loss: 3.58252e-04
I0405 10:25:18.034651 23443585951552 run_lib.py:140] step: 155350, training_loss: 3.94419e-04
I0405 10:25:35.706932 23443585951552 run_lib.py:140] step: 155400, training_loss: 4.09412e-04
I0405 10:25:35.864093 23443585951552 run_lib.py:153] step: 155400, eval_loss: 3.75121e-04
I0405 10:25:53.559399 23443585951552 run_lib.py:140] step: 155450, training_loss: 3.95015e-04
I0405 10:26:11.378100 23443585951552 run_lib.py:140] step: 155500, training_loss: 4.41596e-04
I0405 10:26:11.540251 23443585951552 run_lib.py:153] step: 155500, eval_loss: 4.14237e-04
I0405 10:26:29.227527 23443585951552 run_lib.py:140] step: 155550, training_loss: 4.33137e-04
I0405 10:26:46.965319 23443585951552 run_lib.py:140] step: 155600, training_loss: 3.84786e-04
I0405 10:26:47.125173 23443585951552 run_lib.py:153] step: 155600, eval_loss: 3.51573e-04
I0405 10:27:04.898685 23443585951552 run_lib.py:140] step: 155650, training_loss: 3.84903e-04
I0405 10:27:22.545600 23443585951552 run_lib.py:140] step: 155700, training_loss: 3.92105e-04
I0405 10:27:22.703825 23443585951552 run_lib.py:153] step: 155700, eval_loss: 3.78949e-04
I0405 10:27:40.361714 23443585951552 run_lib.py:140] step: 155750, training_loss: 4.16532e-04
I0405 10:27:58.014577 23443585951552 run_lib.py:140] step: 155800, training_loss: 4.19309e-04
I0405 10:27:58.175346 23443585951552 run_lib.py:153] step: 155800, eval_loss: 3.63794e-04
I0405 10:28:16.096072 23443585951552 run_lib.py:140] step: 155850, training_loss: 4.47905e-04
I0405 10:28:34.027807 23443585951552 run_lib.py:140] step: 155900, training_loss: 3.91744e-04
I0405 10:28:34.196187 23443585951552 run_lib.py:153] step: 155900, eval_loss: 4.11943e-04
I0405 10:28:51.858131 23443585951552 run_lib.py:140] step: 155950, training_loss: 4.30233e-04
I0405 10:29:09.525613 23443585951552 run_lib.py:140] step: 156000, training_loss: 3.96610e-04
I0405 10:29:09.685889 23443585951552 run_lib.py:153] step: 156000, eval_loss: 3.95475e-04
I0405 10:29:27.484123 23443585951552 run_lib.py:140] step: 156050, training_loss: 3.57576e-04
I0405 10:29:45.161510 23443585951552 run_lib.py:140] step: 156100, training_loss: 3.96292e-04
I0405 10:29:45.322006 23443585951552 run_lib.py:153] step: 156100, eval_loss: 3.69510e-04
I0405 10:30:03.034877 23443585951552 run_lib.py:140] step: 156150, training_loss: 3.31870e-04
I0405 10:30:20.952211 23443585951552 run_lib.py:140] step: 156200, training_loss: 3.88612e-04
I0405 10:30:21.109318 23443585951552 run_lib.py:153] step: 156200, eval_loss: 3.83981e-04
I0405 10:30:38.796706 23443585951552 run_lib.py:140] step: 156250, training_loss: 4.49120e-04
I0405 10:30:56.610364 23443585951552 run_lib.py:140] step: 156300, training_loss: 3.80533e-04
I0405 10:30:56.768982 23443585951552 run_lib.py:153] step: 156300, eval_loss: 3.74934e-04
I0405 10:31:14.420417 23443585951552 run_lib.py:140] step: 156350, training_loss: 4.33036e-04
I0405 10:31:32.139449 23443585951552 run_lib.py:140] step: 156400, training_loss: 4.36280e-04
I0405 10:31:32.311772 23443585951552 run_lib.py:153] step: 156400, eval_loss: 4.17786e-04
I0405 10:31:50.202228 23443585951552 run_lib.py:140] step: 156450, training_loss: 4.32800e-04
I0405 10:32:07.885875 23443585951552 run_lib.py:140] step: 156500, training_loss: 3.67741e-04
I0405 10:32:08.042469 23443585951552 run_lib.py:153] step: 156500, eval_loss: 4.36538e-04
I0405 10:32:25.675719 23443585951552 run_lib.py:140] step: 156550, training_loss: 4.15535e-04
I0405 10:32:43.466530 23443585951552 run_lib.py:140] step: 156600, training_loss: 4.37008e-04
I0405 10:32:43.627733 23443585951552 run_lib.py:153] step: 156600, eval_loss: 3.81670e-04
I0405 10:33:01.305376 23443585951552 run_lib.py:140] step: 156650, training_loss: 4.27434e-04
I0405 10:33:19.030598 23443585951552 run_lib.py:140] step: 156700, training_loss: 3.68615e-04
I0405 10:33:19.188908 23443585951552 run_lib.py:153] step: 156700, eval_loss: 3.64628e-04
I0405 10:33:37.016152 23443585951552 run_lib.py:140] step: 156750, training_loss: 3.98916e-04
I0405 10:33:54.691054 23443585951552 run_lib.py:140] step: 156800, training_loss: 3.05689e-04
I0405 10:33:54.853645 23443585951552 run_lib.py:153] step: 156800, eval_loss: 3.44695e-04
I0405 10:34:12.532648 23443585951552 run_lib.py:140] step: 156850, training_loss: 4.02795e-04
I0405 10:34:30.286105 23443585951552 run_lib.py:140] step: 156900, training_loss: 4.56064e-04
I0405 10:34:30.467395 23443585951552 run_lib.py:153] step: 156900, eval_loss: 3.81482e-04
I0405 10:34:48.458324 23443585951552 run_lib.py:140] step: 156950, training_loss: 4.42701e-04
I0405 10:35:06.426185 23443585951552 run_lib.py:140] step: 157000, training_loss: 3.54879e-04
I0405 10:35:06.584768 23443585951552 run_lib.py:153] step: 157000, eval_loss: 3.68914e-04
I0405 10:35:24.350777 23443585951552 run_lib.py:140] step: 157050, training_loss: 4.24570e-04
I0405 10:35:42.152161 23443585951552 run_lib.py:140] step: 157100, training_loss: 4.06135e-04
I0405 10:35:42.306625 23443585951552 run_lib.py:153] step: 157100, eval_loss: 3.90952e-04
I0405 10:36:00.248822 23443585951552 run_lib.py:140] step: 157150, training_loss: 3.72517e-04
I0405 10:36:18.112163 23443585951552 run_lib.py:140] step: 157200, training_loss: 3.91006e-04
I0405 10:36:18.273797 23443585951552 run_lib.py:153] step: 157200, eval_loss: 4.14530e-04
I0405 10:36:36.082948 23443585951552 run_lib.py:140] step: 157250, training_loss: 3.88180e-04
I0405 10:36:54.066241 23443585951552 run_lib.py:140] step: 157300, training_loss: 3.87677e-04
I0405 10:36:54.231389 23443585951552 run_lib.py:153] step: 157300, eval_loss: 4.07706e-04
I0405 10:37:12.302866 23443585951552 run_lib.py:140] step: 157350, training_loss: 4.21165e-04
I0405 10:37:30.158476 23443585951552 run_lib.py:140] step: 157400, training_loss: 3.82461e-04
I0405 10:37:30.323446 23443585951552 run_lib.py:153] step: 157400, eval_loss: 4.50667e-04
I0405 10:37:48.055425 23443585951552 run_lib.py:140] step: 157450, training_loss: 4.47873e-04
I0405 10:38:05.770619 23443585951552 run_lib.py:140] step: 157500, training_loss: 4.12237e-04
I0405 10:38:05.935041 23443585951552 run_lib.py:153] step: 157500, eval_loss: 3.89856e-04
I0405 10:38:23.981558 23443585951552 run_lib.py:140] step: 157550, training_loss: 3.74310e-04
I0405 10:38:41.658613 23443585951552 run_lib.py:140] step: 157600, training_loss: 4.00766e-04
I0405 10:38:41.818629 23443585951552 run_lib.py:153] step: 157600, eval_loss: 3.68873e-04
I0405 10:38:59.559951 23443585951552 run_lib.py:140] step: 157650, training_loss: 4.77272e-04
I0405 10:39:17.558346 23443585951552 run_lib.py:140] step: 157700, training_loss: 4.09637e-04
I0405 10:39:17.727322 23443585951552 run_lib.py:153] step: 157700, eval_loss: 4.51683e-04
I0405 10:39:35.452126 23443585951552 run_lib.py:140] step: 157750, training_loss: 4.11284e-04
I0405 10:39:53.144446 23443585951552 run_lib.py:140] step: 157800, training_loss: 4.19844e-04
I0405 10:39:53.307229 23443585951552 run_lib.py:153] step: 157800, eval_loss: 3.59138e-04
I0405 10:40:11.087500 23443585951552 run_lib.py:140] step: 157850, training_loss: 3.85258e-04
I0405 10:40:28.767655 23443585951552 run_lib.py:140] step: 157900, training_loss: 3.63097e-04
I0405 10:40:28.942919 23443585951552 run_lib.py:153] step: 157900, eval_loss: 4.34433e-04
I0405 10:40:46.604845 23443585951552 run_lib.py:140] step: 157950, training_loss: 4.11278e-04
I0405 10:41:04.304359 23443585951552 run_lib.py:140] step: 158000, training_loss: 4.05738e-04
I0405 10:41:04.463818 23443585951552 run_lib.py:153] step: 158000, eval_loss: 3.62575e-04
I0405 10:41:22.427928 23443585951552 run_lib.py:140] step: 158050, training_loss: 3.97084e-04
I0405 10:41:40.255657 23443585951552 run_lib.py:140] step: 158100, training_loss: 4.36516e-04
I0405 10:41:40.410220 23443585951552 run_lib.py:153] step: 158100, eval_loss: 4.59574e-04
I0405 10:41:58.374454 23443585951552 run_lib.py:140] step: 158150, training_loss: 4.43088e-04
I0405 10:42:16.087636 23443585951552 run_lib.py:140] step: 158200, training_loss: 3.87912e-04
I0405 10:42:16.248640 23443585951552 run_lib.py:153] step: 158200, eval_loss: 3.65788e-04
I0405 10:42:34.107231 23443585951552 run_lib.py:140] step: 158250, training_loss: 4.38871e-04
I0405 10:42:51.859081 23443585951552 run_lib.py:140] step: 158300, training_loss: 4.49376e-04
I0405 10:42:52.022499 23443585951552 run_lib.py:153] step: 158300, eval_loss: 3.96885e-04
I0405 10:43:09.718767 23443585951552 run_lib.py:140] step: 158350, training_loss: 4.08048e-04
I0405 10:43:27.603550 23443585951552 run_lib.py:140] step: 158400, training_loss: 3.65691e-04
I0405 10:43:27.763020 23443585951552 run_lib.py:153] step: 158400, eval_loss: 4.54820e-04
I0405 10:43:45.497150 23443585951552 run_lib.py:140] step: 158450, training_loss: 4.18939e-04
I0405 10:44:03.450095 23443585951552 run_lib.py:140] step: 158500, training_loss: 3.90592e-04
I0405 10:44:03.614953 23443585951552 run_lib.py:153] step: 158500, eval_loss: 4.03675e-04
I0405 10:44:21.453424 23443585951552 run_lib.py:140] step: 158550, training_loss: 4.76049e-04
I0405 10:44:39.314797 23443585951552 run_lib.py:140] step: 158600, training_loss: 4.06245e-04
I0405 10:44:39.475096 23443585951552 run_lib.py:153] step: 158600, eval_loss: 4.13135e-04
I0405 10:44:57.485347 23443585951552 run_lib.py:140] step: 158650, training_loss: 4.28817e-04
I0405 10:45:15.293035 23443585951552 run_lib.py:140] step: 158700, training_loss: 3.65037e-04
I0405 10:45:15.454264 23443585951552 run_lib.py:153] step: 158700, eval_loss: 3.56796e-04
I0405 10:45:33.251437 23443585951552 run_lib.py:140] step: 158750, training_loss: 3.70983e-04
I0405 10:45:51.194759 23443585951552 run_lib.py:140] step: 158800, training_loss: 3.87611e-04
I0405 10:45:51.378247 23443585951552 run_lib.py:153] step: 158800, eval_loss: 3.57780e-04
I0405 10:46:09.243003 23443585951552 run_lib.py:140] step: 158850, training_loss: 4.50283e-04
I0405 10:46:27.156292 23443585951552 run_lib.py:140] step: 158900, training_loss: 4.36322e-04
I0405 10:46:27.336811 23443585951552 run_lib.py:153] step: 158900, eval_loss: 3.97131e-04
I0405 10:46:45.224698 23443585951552 run_lib.py:140] step: 158950, training_loss: 4.34669e-04
I0405 10:47:02.898538 23443585951552 run_lib.py:140] step: 159000, training_loss: 4.55351e-04
I0405 10:47:03.055701 23443585951552 run_lib.py:153] step: 159000, eval_loss: 3.92678e-04
I0405 10:47:20.710690 23443585951552 run_lib.py:140] step: 159050, training_loss: 4.36324e-04
I0405 10:47:38.418077 23443585951552 run_lib.py:140] step: 159100, training_loss: 3.60275e-04
I0405 10:47:38.607827 23443585951552 run_lib.py:153] step: 159100, eval_loss: 4.20303e-04
I0405 10:47:56.572857 23443585951552 run_lib.py:140] step: 159150, training_loss: 3.95293e-04
I0405 10:48:14.395659 23443585951552 run_lib.py:140] step: 159200, training_loss: 4.32565e-04
I0405 10:48:14.561942 23443585951552 run_lib.py:153] step: 159200, eval_loss: 4.08458e-04
I0405 10:48:32.249940 23443585951552 run_lib.py:140] step: 159250, training_loss: 4.07977e-04
I0405 10:48:49.910939 23443585951552 run_lib.py:140] step: 159300, training_loss: 3.90252e-04
I0405 10:48:50.074833 23443585951552 run_lib.py:153] step: 159300, eval_loss: 3.79438e-04
I0405 10:49:07.894373 23443585951552 run_lib.py:140] step: 159350, training_loss: 4.60564e-04
I0405 10:49:25.599685 23443585951552 run_lib.py:140] step: 159400, training_loss: 4.41119e-04
I0405 10:49:25.762496 23443585951552 run_lib.py:153] step: 159400, eval_loss: 3.78978e-04
I0405 10:49:43.485168 23443585951552 run_lib.py:140] step: 159450, training_loss: 4.40057e-04
I0405 10:50:01.352261 23443585951552 run_lib.py:140] step: 159500, training_loss: 3.57554e-04
I0405 10:50:01.525433 23443585951552 run_lib.py:153] step: 159500, eval_loss: 4.17871e-04
I0405 10:50:19.219758 23443585951552 run_lib.py:140] step: 159550, training_loss: 3.98225e-04
I0405 10:50:37.028457 23443585951552 run_lib.py:140] step: 159600, training_loss: 3.75643e-04
I0405 10:50:37.190171 23443585951552 run_lib.py:153] step: 159600, eval_loss: 4.09711e-04
I0405 10:50:54.872318 23443585951552 run_lib.py:140] step: 159650, training_loss: 3.84794e-04
I0405 10:51:12.565031 23443585951552 run_lib.py:140] step: 159700, training_loss: 4.16580e-04
I0405 10:51:12.749859 23443585951552 run_lib.py:153] step: 159700, eval_loss: 3.90092e-04
I0405 10:51:30.521690 23443585951552 run_lib.py:140] step: 159750, training_loss: 4.57100e-04
I0405 10:51:47.983203 23443585951552 run_lib.py:140] step: 159800, training_loss: 3.69145e-04
I0405 10:51:48.146717 23443585951552 run_lib.py:153] step: 159800, eval_loss: 4.32503e-04
I0405 10:52:05.598451 23443585951552 run_lib.py:140] step: 159850, training_loss: 4.23095e-04
I0405 10:52:23.191526 23443585951552 run_lib.py:140] step: 159900, training_loss: 4.43522e-04
I0405 10:52:23.347326 23443585951552 run_lib.py:153] step: 159900, eval_loss: 4.15113e-04
I0405 10:52:40.832422 23443585951552 run_lib.py:140] step: 159950, training_loss: 4.12959e-04
I0405 10:52:58.375623 23443585951552 run_lib.py:140] step: 160000, training_loss: 4.01334e-04
I0405 10:52:59.175056 23443585951552 run_lib.py:153] step: 160000, eval_loss: 3.80997e-04
I0405 10:53:17.245064 23443585951552 run_lib.py:140] step: 160050, training_loss: 4.21338e-04
I0405 10:53:34.697545 23443585951552 run_lib.py:140] step: 160100, training_loss: 3.93395e-04
I0405 10:53:34.852874 23443585951552 run_lib.py:153] step: 160100, eval_loss: 3.44085e-04
I0405 10:53:52.265560 23443585951552 run_lib.py:140] step: 160150, training_loss: 4.16770e-04
I0405 10:54:09.713888 23443585951552 run_lib.py:140] step: 160200, training_loss: 4.39397e-04
I0405 10:54:09.879439 23443585951552 run_lib.py:153] step: 160200, eval_loss: 3.75263e-04
I0405 10:54:27.499240 23443585951552 run_lib.py:140] step: 160250, training_loss: 4.63371e-04
I0405 10:54:45.123562 23443585951552 run_lib.py:140] step: 160300, training_loss: 3.84460e-04
I0405 10:54:45.280383 23443585951552 run_lib.py:153] step: 160300, eval_loss: 3.88790e-04
I0405 10:55:02.841106 23443585951552 run_lib.py:140] step: 160350, training_loss: 4.37843e-04
I0405 10:55:20.357499 23443585951552 run_lib.py:140] step: 160400, training_loss: 3.80939e-04
I0405 10:55:20.512946 23443585951552 run_lib.py:153] step: 160400, eval_loss: 4.11652e-04
I0405 10:55:38.205312 23443585951552 run_lib.py:140] step: 160450, training_loss: 3.68812e-04
I0405 10:55:55.789068 23443585951552 run_lib.py:140] step: 160500, training_loss: 4.08741e-04
I0405 10:55:55.945129 23443585951552 run_lib.py:153] step: 160500, eval_loss: 3.59726e-04
I0405 10:56:13.515661 23443585951552 run_lib.py:140] step: 160550, training_loss: 3.93781e-04
I0405 10:56:31.242448 23443585951552 run_lib.py:140] step: 160600, training_loss: 3.56481e-04
I0405 10:56:31.397924 23443585951552 run_lib.py:153] step: 160600, eval_loss: 4.08570e-04
I0405 10:56:48.926968 23443585951552 run_lib.py:140] step: 160650, training_loss: 4.13418e-04
I0405 10:57:06.631520 23443585951552 run_lib.py:140] step: 160700, training_loss: 4.33575e-04
I0405 10:57:06.792200 23443585951552 run_lib.py:153] step: 160700, eval_loss: 3.73397e-04
I0405 10:57:24.329064 23443585951552 run_lib.py:140] step: 160750, training_loss: 4.09540e-04
I0405 10:57:41.956990 23443585951552 run_lib.py:140] step: 160800, training_loss: 4.12998e-04
I0405 10:57:42.117798 23443585951552 run_lib.py:153] step: 160800, eval_loss: 4.29767e-04
I0405 10:57:59.877940 23443585951552 run_lib.py:140] step: 160850, training_loss: 4.72907e-04
I0405 10:58:17.439906 23443585951552 run_lib.py:140] step: 160900, training_loss: 4.15447e-04
I0405 10:58:17.597977 23443585951552 run_lib.py:153] step: 160900, eval_loss: 3.69886e-04
I0405 10:58:35.131563 23443585951552 run_lib.py:140] step: 160950, training_loss: 3.92342e-04
I0405 10:58:52.863106 23443585951552 run_lib.py:140] step: 161000, training_loss: 4.33716e-04
I0405 10:58:53.019262 23443585951552 run_lib.py:153] step: 161000, eval_loss: 4.02250e-04
I0405 10:59:10.653240 23443585951552 run_lib.py:140] step: 161050, training_loss: 4.37626e-04
I0405 10:59:28.197321 23443585951552 run_lib.py:140] step: 161100, training_loss: 4.06307e-04
I0405 10:59:28.379807 23443585951552 run_lib.py:153] step: 161100, eval_loss: 3.63519e-04
I0405 10:59:46.035698 23443585951552 run_lib.py:140] step: 161150, training_loss: 3.49149e-04
I0405 11:00:03.666732 23443585951552 run_lib.py:140] step: 161200, training_loss: 4.05251e-04
I0405 11:00:03.824297 23443585951552 run_lib.py:153] step: 161200, eval_loss: 3.55129e-04
I0405 11:00:21.463735 23443585951552 run_lib.py:140] step: 161250, training_loss: 3.69238e-04
I0405 11:00:39.135904 23443585951552 run_lib.py:140] step: 161300, training_loss: 4.19575e-04
I0405 11:00:39.294672 23443585951552 run_lib.py:153] step: 161300, eval_loss: 4.46415e-04
I0405 11:00:57.020304 23443585951552 run_lib.py:140] step: 161350, training_loss: 3.90402e-04
I0405 11:01:14.694200 23443585951552 run_lib.py:140] step: 161400, training_loss: 3.71741e-04
I0405 11:01:14.848194 23443585951552 run_lib.py:153] step: 161400, eval_loss: 4.03531e-04
I0405 11:01:32.386077 23443585951552 run_lib.py:140] step: 161450, training_loss: 3.94511e-04
I0405 11:01:49.992110 23443585951552 run_lib.py:140] step: 161500, training_loss: 4.07566e-04
I0405 11:01:50.148702 23443585951552 run_lib.py:153] step: 161500, eval_loss: 3.76247e-04
I0405 11:02:07.890302 23443585951552 run_lib.py:140] step: 161550, training_loss: 4.01077e-04
I0405 11:02:25.480716 23443585951552 run_lib.py:140] step: 161600, training_loss: 3.93900e-04
I0405 11:02:25.639838 23443585951552 run_lib.py:153] step: 161600, eval_loss: 4.05665e-04
I0405 11:02:43.160089 23443585951552 run_lib.py:140] step: 161650, training_loss: 4.09728e-04
I0405 11:03:00.859130 23443585951552 run_lib.py:140] step: 161700, training_loss: 3.90161e-04
I0405 11:03:01.013771 23443585951552 run_lib.py:153] step: 161700, eval_loss: 3.65852e-04
I0405 11:03:18.505187 23443585951552 run_lib.py:140] step: 161750, training_loss: 4.45473e-04
I0405 11:03:36.147531 23443585951552 run_lib.py:140] step: 161800, training_loss: 4.08193e-04
I0405 11:03:36.312906 23443585951552 run_lib.py:153] step: 161800, eval_loss: 3.93941e-04
I0405 11:03:53.884663 23443585951552 run_lib.py:140] step: 161850, training_loss: 3.74309e-04
I0405 11:04:11.453976 23443585951552 run_lib.py:140] step: 161900, training_loss: 3.84178e-04
I0405 11:04:11.610360 23443585951552 run_lib.py:153] step: 161900, eval_loss: 3.33842e-04
I0405 11:04:29.307842 23443585951552 run_lib.py:140] step: 161950, training_loss: 4.02600e-04
I0405 11:04:46.794740 23443585951552 run_lib.py:140] step: 162000, training_loss: 3.85055e-04
I0405 11:04:46.951988 23443585951552 run_lib.py:153] step: 162000, eval_loss: 3.51273e-04
I0405 11:05:04.431127 23443585951552 run_lib.py:140] step: 162050, training_loss: 3.40906e-04
I0405 11:05:22.131182 23443585951552 run_lib.py:140] step: 162100, training_loss: 4.01279e-04
I0405 11:05:22.309003 23443585951552 run_lib.py:153] step: 162100, eval_loss: 3.95492e-04
I0405 11:05:39.836613 23443585951552 run_lib.py:140] step: 162150, training_loss: 4.30848e-04
I0405 11:05:57.360067 23443585951552 run_lib.py:140] step: 162200, training_loss: 4.63924e-04
I0405 11:05:57.524483 23443585951552 run_lib.py:153] step: 162200, eval_loss: 4.23167e-04
I0405 11:06:15.160695 23443585951552 run_lib.py:140] step: 162250, training_loss: 4.59592e-04
I0405 11:06:32.650319 23443585951552 run_lib.py:140] step: 162300, training_loss: 4.56843e-04
I0405 11:06:32.806009 23443585951552 run_lib.py:153] step: 162300, eval_loss: 3.51404e-04
I0405 11:06:50.281885 23443585951552 run_lib.py:140] step: 162350, training_loss: 4.33967e-04
I0405 11:07:07.832360 23443585951552 run_lib.py:140] step: 162400, training_loss: 3.84378e-04
I0405 11:07:07.999194 23443585951552 run_lib.py:153] step: 162400, eval_loss: 4.23742e-04
I0405 11:07:25.749768 23443585951552 run_lib.py:140] step: 162450, training_loss: 4.63225e-04
I0405 11:07:43.384648 23443585951552 run_lib.py:140] step: 162500, training_loss: 3.90200e-04
I0405 11:07:43.538935 23443585951552 run_lib.py:153] step: 162500, eval_loss: 4.40944e-04
I0405 11:08:00.999189 23443585951552 run_lib.py:140] step: 162550, training_loss: 4.06073e-04
I0405 11:08:18.501178 23443585951552 run_lib.py:140] step: 162600, training_loss: 3.94968e-04
I0405 11:08:18.663923 23443585951552 run_lib.py:153] step: 162600, eval_loss: 3.50487e-04
I0405 11:08:36.367316 23443585951552 run_lib.py:140] step: 162650, training_loss: 4.24102e-04
I0405 11:08:53.920090 23443585951552 run_lib.py:140] step: 162700, training_loss: 4.20376e-04
I0405 11:08:54.098310 23443585951552 run_lib.py:153] step: 162700, eval_loss: 4.07505e-04
I0405 11:09:11.625180 23443585951552 run_lib.py:140] step: 162750, training_loss: 3.87025e-04
I0405 11:09:29.273807 23443585951552 run_lib.py:140] step: 162800, training_loss: 3.77804e-04
I0405 11:09:29.430054 23443585951552 run_lib.py:153] step: 162800, eval_loss: 4.04269e-04
I0405 11:09:46.910535 23443585951552 run_lib.py:140] step: 162850, training_loss: 4.13319e-04
I0405 11:10:04.575943 23443585951552 run_lib.py:140] step: 162900, training_loss: 3.89946e-04
I0405 11:10:04.737860 23443585951552 run_lib.py:153] step: 162900, eval_loss: 3.94257e-04
I0405 11:10:22.329896 23443585951552 run_lib.py:140] step: 162950, training_loss: 3.97109e-04
I0405 11:10:39.842301 23443585951552 run_lib.py:140] step: 163000, training_loss: 3.89847e-04
I0405 11:10:40.000929 23443585951552 run_lib.py:153] step: 163000, eval_loss: 3.93300e-04
I0405 11:10:57.727510 23443585951552 run_lib.py:140] step: 163050, training_loss: 3.90337e-04
I0405 11:11:15.217458 23443585951552 run_lib.py:140] step: 163100, training_loss: 3.93201e-04
I0405 11:11:15.374526 23443585951552 run_lib.py:153] step: 163100, eval_loss: 3.95842e-04
I0405 11:11:32.883225 23443585951552 run_lib.py:140] step: 163150, training_loss: 4.15411e-04
I0405 11:11:50.608443 23443585951552 run_lib.py:140] step: 163200, training_loss: 3.23787e-04
I0405 11:11:50.765819 23443585951552 run_lib.py:153] step: 163200, eval_loss: 3.94036e-04
I0405 11:12:08.277104 23443585951552 run_lib.py:140] step: 163250, training_loss: 4.00246e-04
I0405 11:12:25.734745 23443585951552 run_lib.py:140] step: 163300, training_loss: 3.90181e-04
I0405 11:12:25.888690 23443585951552 run_lib.py:153] step: 163300, eval_loss: 4.11308e-04
I0405 11:12:43.490188 23443585951552 run_lib.py:140] step: 163350, training_loss: 4.16056e-04
I0405 11:13:00.970538 23443585951552 run_lib.py:140] step: 163400, training_loss: 4.18325e-04
I0405 11:13:01.124849 23443585951552 run_lib.py:153] step: 163400, eval_loss: 4.11319e-04
I0405 11:13:18.623905 23443585951552 run_lib.py:140] step: 163450, training_loss: 3.98088e-04
I0405 11:13:36.135429 23443585951552 run_lib.py:140] step: 163500, training_loss: 3.94164e-04
I0405 11:13:36.292141 23443585951552 run_lib.py:153] step: 163500, eval_loss: 3.82460e-04
I0405 11:13:54.016431 23443585951552 run_lib.py:140] step: 163550, training_loss: 4.37143e-04
I0405 11:14:11.604515 23443585951552 run_lib.py:140] step: 163600, training_loss: 4.25342e-04
I0405 11:14:11.762026 23443585951552 run_lib.py:153] step: 163600, eval_loss: 3.85554e-04
I0405 11:14:29.275819 23443585951552 run_lib.py:140] step: 163650, training_loss: 4.09920e-04
I0405 11:14:46.744791 23443585951552 run_lib.py:140] step: 163700, training_loss: 4.65814e-04
I0405 11:14:46.902591 23443585951552 run_lib.py:153] step: 163700, eval_loss: 3.94113e-04
I0405 11:15:04.579779 23443585951552 run_lib.py:140] step: 163750, training_loss: 3.84452e-04
I0405 11:15:22.149498 23443585951552 run_lib.py:140] step: 163800, training_loss: 4.24692e-04
I0405 11:15:22.303715 23443585951552 run_lib.py:153] step: 163800, eval_loss: 3.92318e-04
I0405 11:15:39.845313 23443585951552 run_lib.py:140] step: 163850, training_loss: 4.23950e-04
I0405 11:15:57.548525 23443585951552 run_lib.py:140] step: 163900, training_loss: 3.15758e-04
I0405 11:15:57.711055 23443585951552 run_lib.py:153] step: 163900, eval_loss: 3.73196e-04
I0405 11:16:15.202669 23443585951552 run_lib.py:140] step: 163950, training_loss: 3.90756e-04
I0405 11:16:32.844656 23443585951552 run_lib.py:140] step: 164000, training_loss: 4.24893e-04
I0405 11:16:33.018911 23443585951552 run_lib.py:153] step: 164000, eval_loss: 3.31889e-04
I0405 11:16:50.579898 23443585951552 run_lib.py:140] step: 164050, training_loss: 4.38807e-04
I0405 11:17:08.067123 23443585951552 run_lib.py:140] step: 164100, training_loss: 4.41278e-04
I0405 11:17:08.227374 23443585951552 run_lib.py:153] step: 164100, eval_loss: 3.91288e-04
I0405 11:17:25.928318 23443585951552 run_lib.py:140] step: 164150, training_loss: 3.90580e-04
I0405 11:17:43.383441 23443585951552 run_lib.py:140] step: 164200, training_loss: 3.83032e-04
I0405 11:17:43.542945 23443585951552 run_lib.py:153] step: 164200, eval_loss: 4.32518e-04
I0405 11:18:01.054190 23443585951552 run_lib.py:140] step: 164250, training_loss: 4.86501e-04
I0405 11:18:18.737445 23443585951552 run_lib.py:140] step: 164300, training_loss: 3.93475e-04
I0405 11:18:18.999260 23443585951552 run_lib.py:153] step: 164300, eval_loss: 4.49916e-04
I0405 11:18:36.563442 23443585951552 run_lib.py:140] step: 164350, training_loss: 4.62854e-04
I0405 11:18:53.999056 23443585951552 run_lib.py:140] step: 164400, training_loss: 4.03487e-04
I0405 11:18:54.153136 23443585951552 run_lib.py:153] step: 164400, eval_loss: 3.60991e-04
I0405 11:19:11.722685 23443585951552 run_lib.py:140] step: 164450, training_loss: 3.97322e-04
I0405 11:19:29.200461 23443585951552 run_lib.py:140] step: 164500, training_loss: 3.85616e-04
I0405 11:19:29.365780 23443585951552 run_lib.py:153] step: 164500, eval_loss: 3.89534e-04
I0405 11:19:46.819773 23443585951552 run_lib.py:140] step: 164550, training_loss: 4.60317e-04
I0405 11:20:04.342204 23443585951552 run_lib.py:140] step: 164600, training_loss: 3.56302e-04
I0405 11:20:04.505268 23443585951552 run_lib.py:153] step: 164600, eval_loss: 4.22654e-04
I0405 11:20:22.199055 23443585951552 run_lib.py:140] step: 164650, training_loss: 4.23988e-04
I0405 11:20:39.752763 23443585951552 run_lib.py:140] step: 164700, training_loss: 4.17367e-04
I0405 11:20:39.904844 23443585951552 run_lib.py:153] step: 164700, eval_loss: 3.99160e-04
I0405 11:20:57.353072 23443585951552 run_lib.py:140] step: 164750, training_loss: 4.10678e-04
I0405 11:21:14.799078 23443585951552 run_lib.py:140] step: 164800, training_loss: 3.80901e-04
I0405 11:21:14.950564 23443585951552 run_lib.py:153] step: 164800, eval_loss: 3.83143e-04
I0405 11:21:32.552366 23443585951552 run_lib.py:140] step: 164850, training_loss: 4.03009e-04
I0405 11:21:50.039568 23443585951552 run_lib.py:140] step: 164900, training_loss: 3.73572e-04
I0405 11:21:50.214943 23443585951552 run_lib.py:153] step: 164900, eval_loss: 3.72261e-04
I0405 11:22:07.731199 23443585951552 run_lib.py:140] step: 164950, training_loss: 4.11927e-04
I0405 11:22:25.449657 23443585951552 run_lib.py:140] step: 165000, training_loss: 4.00014e-04
I0405 11:22:25.644302 23443585951552 run_lib.py:153] step: 165000, eval_loss: 3.55658e-04
I0405 11:22:43.072686 23443585951552 run_lib.py:140] step: 165050, training_loss: 4.40015e-04
I0405 11:23:00.644319 23443585951552 run_lib.py:140] step: 165100, training_loss: 4.06969e-04
I0405 11:23:00.797238 23443585951552 run_lib.py:153] step: 165100, eval_loss: 3.52968e-04
I0405 11:23:18.240158 23443585951552 run_lib.py:140] step: 165150, training_loss: 4.10951e-04
I0405 11:23:35.791328 23443585951552 run_lib.py:140] step: 165200, training_loss: 4.82924e-04
I0405 11:23:35.944615 23443585951552 run_lib.py:153] step: 165200, eval_loss: 4.19631e-04
I0405 11:23:53.644524 23443585951552 run_lib.py:140] step: 165250, training_loss: 3.89582e-04
I0405 11:24:11.080259 23443585951552 run_lib.py:140] step: 165300, training_loss: 4.08890e-04
I0405 11:24:11.234024 23443585951552 run_lib.py:153] step: 165300, eval_loss: 3.89858e-04
I0405 11:24:28.651423 23443585951552 run_lib.py:140] step: 165350, training_loss: 3.91447e-04
I0405 11:24:46.374617 23443585951552 run_lib.py:140] step: 165400, training_loss: 4.21496e-04
I0405 11:24:46.542418 23443585951552 run_lib.py:153] step: 165400, eval_loss: 4.30328e-04
I0405 11:25:04.097804 23443585951552 run_lib.py:140] step: 165450, training_loss: 4.17804e-04
I0405 11:25:21.667482 23443585951552 run_lib.py:140] step: 165500, training_loss: 4.19630e-04
I0405 11:25:21.824244 23443585951552 run_lib.py:153] step: 165500, eval_loss: 4.09408e-04
I0405 11:25:39.463185 23443585951552 run_lib.py:140] step: 165550, training_loss: 4.14205e-04
I0405 11:25:56.926862 23443585951552 run_lib.py:140] step: 165600, training_loss: 3.30140e-04
I0405 11:25:57.082991 23443585951552 run_lib.py:153] step: 165600, eval_loss: 3.88533e-04
I0405 11:26:14.558949 23443585951552 run_lib.py:140] step: 165650, training_loss: 3.81938e-04
I0405 11:26:32.047302 23443585951552 run_lib.py:140] step: 165700, training_loss: 3.87110e-04
I0405 11:26:32.197995 23443585951552 run_lib.py:153] step: 165700, eval_loss: 4.08659e-04
I0405 11:26:49.924189 23443585951552 run_lib.py:140] step: 165750, training_loss: 4.17391e-04
I0405 11:27:07.576792 23443585951552 run_lib.py:140] step: 165800, training_loss: 3.63764e-04
I0405 11:27:07.742496 23443585951552 run_lib.py:153] step: 165800, eval_loss: 4.20927e-04
I0405 11:27:25.220982 23443585951552 run_lib.py:140] step: 165850, training_loss: 4.65360e-04
I0405 11:27:42.639621 23443585951552 run_lib.py:140] step: 165900, training_loss: 4.54279e-04
I0405 11:27:42.809177 23443585951552 run_lib.py:153] step: 165900, eval_loss: 4.07037e-04
I0405 11:28:00.351061 23443585951552 run_lib.py:140] step: 165950, training_loss: 4.24097e-04
I0405 11:28:17.784828 23443585951552 run_lib.py:140] step: 166000, training_loss: 3.47465e-04
I0405 11:28:17.956917 23443585951552 run_lib.py:153] step: 166000, eval_loss: 3.57308e-04
I0405 11:28:35.424271 23443585951552 run_lib.py:140] step: 166050, training_loss: 4.06503e-04
I0405 11:28:53.049387 23443585951552 run_lib.py:140] step: 166100, training_loss: 4.25588e-04
I0405 11:28:53.254316 23443585951552 run_lib.py:153] step: 166100, eval_loss: 3.70118e-04
I0405 11:29:10.773851 23443585951552 run_lib.py:140] step: 166150, training_loss: 4.08027e-04
I0405 11:29:28.374282 23443585951552 run_lib.py:140] step: 166200, training_loss: 3.67939e-04
I0405 11:29:28.526965 23443585951552 run_lib.py:153] step: 166200, eval_loss: 4.59551e-04
I0405 11:29:45.894609 23443585951552 run_lib.py:140] step: 166250, training_loss: 3.75470e-04
I0405 11:30:03.331001 23443585951552 run_lib.py:140] step: 166300, training_loss: 4.13117e-04
I0405 11:30:03.489645 23443585951552 run_lib.py:153] step: 166300, eval_loss: 4.50565e-04
I0405 11:30:21.092736 23443585951552 run_lib.py:140] step: 166350, training_loss: 3.80222e-04
I0405 11:30:38.553929 23443585951552 run_lib.py:140] step: 166400, training_loss: 4.35615e-04
I0405 11:30:38.712898 23443585951552 run_lib.py:153] step: 166400, eval_loss: 4.05477e-04
I0405 11:30:56.080109 23443585951552 run_lib.py:140] step: 166450, training_loss: 3.61317e-04
I0405 11:31:13.693030 23443585951552 run_lib.py:140] step: 166500, training_loss: 4.69542e-04
I0405 11:31:13.846589 23443585951552 run_lib.py:153] step: 166500, eval_loss: 4.54291e-04
I0405 11:31:31.216988 23443585951552 run_lib.py:140] step: 166550, training_loss: 3.39257e-04
I0405 11:31:48.718907 23443585951552 run_lib.py:140] step: 166600, training_loss: 3.93568e-04
I0405 11:31:48.877176 23443585951552 run_lib.py:153] step: 166600, eval_loss: 4.00805e-04
I0405 11:32:06.623584 23443585951552 run_lib.py:140] step: 166650, training_loss: 3.78635e-04
I0405 11:32:24.053916 23443585951552 run_lib.py:140] step: 166700, training_loss: 3.94611e-04
I0405 11:32:24.210854 23443585951552 run_lib.py:153] step: 166700, eval_loss: 4.13730e-04
I0405 11:32:41.623769 23443585951552 run_lib.py:140] step: 166750, training_loss: 4.08106e-04
I0405 11:32:59.036949 23443585951552 run_lib.py:140] step: 166800, training_loss: 4.18433e-04
I0405 11:32:59.197246 23443585951552 run_lib.py:153] step: 166800, eval_loss: 3.95390e-04
I0405 11:33:16.837746 23443585951552 run_lib.py:140] step: 166850, training_loss: 4.20626e-04
I0405 11:33:34.351369 23443585951552 run_lib.py:140] step: 166900, training_loss: 4.27499e-04
I0405 11:33:34.518959 23443585951552 run_lib.py:153] step: 166900, eval_loss: 4.34290e-04
I0405 11:33:52.056476 23443585951552 run_lib.py:140] step: 166950, training_loss: 3.71885e-04
I0405 11:34:09.653916 23443585951552 run_lib.py:140] step: 167000, training_loss: 4.04853e-04
I0405 11:34:09.814671 23443585951552 run_lib.py:153] step: 167000, eval_loss: 4.03871e-04
I0405 11:34:27.543682 23443585951552 run_lib.py:140] step: 167050, training_loss: 3.86007e-04
I0405 11:34:45.052481 23443585951552 run_lib.py:140] step: 167100, training_loss: 3.83033e-04
I0405 11:34:45.202795 23443585951552 run_lib.py:153] step: 167100, eval_loss: 4.48787e-04
I0405 11:35:02.744278 23443585951552 run_lib.py:140] step: 167150, training_loss: 3.70788e-04
I0405 11:35:20.460085 23443585951552 run_lib.py:140] step: 167200, training_loss: 4.22066e-04
I0405 11:35:20.622849 23443585951552 run_lib.py:153] step: 167200, eval_loss: 4.08581e-04
I0405 11:35:38.264860 23443585951552 run_lib.py:140] step: 167250, training_loss: 3.90654e-04
I0405 11:35:56.008910 23443585951552 run_lib.py:140] step: 167300, training_loss: 3.78631e-04
I0405 11:35:56.166234 23443585951552 run_lib.py:153] step: 167300, eval_loss: 3.88066e-04
I0405 11:36:13.702377 23443585951552 run_lib.py:140] step: 167350, training_loss: 4.21932e-04
I0405 11:36:31.185707 23443585951552 run_lib.py:140] step: 167400, training_loss: 4.01674e-04
I0405 11:36:31.339840 23443585951552 run_lib.py:153] step: 167400, eval_loss: 4.74073e-04
I0405 11:36:49.018874 23443585951552 run_lib.py:140] step: 167450, training_loss: 4.30842e-04
I0405 11:37:06.618687 23443585951552 run_lib.py:140] step: 167500, training_loss: 4.10877e-04
I0405 11:37:06.774125 23443585951552 run_lib.py:153] step: 167500, eval_loss: 3.35045e-04
I0405 11:37:24.360667 23443585951552 run_lib.py:140] step: 167550, training_loss: 4.53920e-04
I0405 11:37:42.066603 23443585951552 run_lib.py:140] step: 167600, training_loss: 3.83425e-04
I0405 11:37:42.222827 23443585951552 run_lib.py:153] step: 167600, eval_loss: 3.97776e-04
I0405 11:37:59.706931 23443585951552 run_lib.py:140] step: 167650, training_loss: 3.89261e-04
I0405 11:38:17.216358 23443585951552 run_lib.py:140] step: 167700, training_loss: 3.72758e-04
I0405 11:38:17.370949 23443585951552 run_lib.py:153] step: 167700, eval_loss: 4.24310e-04
I0405 11:38:34.944235 23443585951552 run_lib.py:140] step: 167750, training_loss: 3.83470e-04
I0405 11:38:52.523673 23443585951552 run_lib.py:140] step: 167800, training_loss: 3.94509e-04
I0405 11:38:52.693939 23443585951552 run_lib.py:153] step: 167800, eval_loss: 4.46078e-04
I0405 11:39:10.235283 23443585951552 run_lib.py:140] step: 167850, training_loss: 3.61632e-04
I0405 11:39:27.757760 23443585951552 run_lib.py:140] step: 167900, training_loss: 4.19439e-04
I0405 11:39:27.912083 23443585951552 run_lib.py:153] step: 167900, eval_loss: 3.65547e-04
I0405 11:39:45.634892 23443585951552 run_lib.py:140] step: 167950, training_loss: 4.26208e-04
I0405 11:40:03.169991 23443585951552 run_lib.py:140] step: 168000, training_loss: 4.51028e-04
I0405 11:40:03.321789 23443585951552 run_lib.py:153] step: 168000, eval_loss: 4.46332e-04
I0405 11:40:20.792938 23443585951552 run_lib.py:140] step: 168050, training_loss: 3.91510e-04
I0405 11:40:38.351385 23443585951552 run_lib.py:140] step: 168100, training_loss: 4.03693e-04
I0405 11:40:38.508127 23443585951552 run_lib.py:153] step: 168100, eval_loss: 4.07214e-04
I0405 11:40:56.285022 23443585951552 run_lib.py:140] step: 168150, training_loss: 3.59608e-04
I0405 11:41:13.796671 23443585951552 run_lib.py:140] step: 168200, training_loss: 3.98118e-04
I0405 11:41:13.957090 23443585951552 run_lib.py:153] step: 168200, eval_loss: 3.87987e-04
I0405 11:41:31.430027 23443585951552 run_lib.py:140] step: 168250, training_loss: 3.76194e-04
I0405 11:41:49.064405 23443585951552 run_lib.py:140] step: 168300, training_loss: 4.14995e-04
I0405 11:41:49.229930 23443585951552 run_lib.py:153] step: 168300, eval_loss: 3.95530e-04
I0405 11:42:06.797621 23443585951552 run_lib.py:140] step: 168350, training_loss: 4.13344e-04
I0405 11:42:24.526256 23443585951552 run_lib.py:140] step: 168400, training_loss: 4.42881e-04
I0405 11:42:24.678662 23443585951552 run_lib.py:153] step: 168400, eval_loss: 3.94348e-04
I0405 11:42:42.247924 23443585951552 run_lib.py:140] step: 168450, training_loss: 3.75050e-04
I0405 11:42:59.759146 23443585951552 run_lib.py:140] step: 168500, training_loss: 4.20489e-04
I0405 11:42:59.906492 23443585951552 run_lib.py:153] step: 168500, eval_loss: 4.30696e-04
I0405 11:43:17.595191 23443585951552 run_lib.py:140] step: 168550, training_loss: 3.70240e-04
I0405 11:43:35.186975 23443585951552 run_lib.py:140] step: 168600, training_loss: 3.79981e-04
I0405 11:43:35.345120 23443585951552 run_lib.py:153] step: 168600, eval_loss: 3.89568e-04
I0405 11:43:52.960921 23443585951552 run_lib.py:140] step: 168650, training_loss: 4.20676e-04
I0405 11:44:10.656532 23443585951552 run_lib.py:140] step: 168700, training_loss: 4.20015e-04
I0405 11:44:10.813865 23443585951552 run_lib.py:153] step: 168700, eval_loss: 3.76363e-04
I0405 11:44:28.310930 23443585951552 run_lib.py:140] step: 168750, training_loss: 4.17338e-04
I0405 11:44:45.799694 23443585951552 run_lib.py:140] step: 168800, training_loss: 4.34430e-04
I0405 11:44:45.954907 23443585951552 run_lib.py:153] step: 168800, eval_loss: 3.90323e-04
I0405 11:45:03.548222 23443585951552 run_lib.py:140] step: 168850, training_loss: 3.84817e-04
I0405 11:45:21.124558 23443585951552 run_lib.py:140] step: 168900, training_loss: 4.41040e-04
I0405 11:45:21.281857 23443585951552 run_lib.py:153] step: 168900, eval_loss: 3.83489e-04
I0405 11:45:38.822462 23443585951552 run_lib.py:140] step: 168950, training_loss: 3.91207e-04
I0405 11:45:56.306237 23443585951552 run_lib.py:140] step: 169000, training_loss: 4.29289e-04
I0405 11:45:56.459108 23443585951552 run_lib.py:153] step: 169000, eval_loss: 3.76701e-04
I0405 11:46:14.158282 23443585951552 run_lib.py:140] step: 169050, training_loss: 4.55981e-04
I0405 11:46:31.756289 23443585951552 run_lib.py:140] step: 169100, training_loss: 3.93334e-04
I0405 11:46:31.917990 23443585951552 run_lib.py:153] step: 169100, eval_loss: 3.75573e-04
I0405 11:46:49.516336 23443585951552 run_lib.py:140] step: 169150, training_loss: 4.37124e-04
I0405 11:47:07.096119 23443585951552 run_lib.py:140] step: 169200, training_loss: 4.37256e-04
I0405 11:47:07.253809 23443585951552 run_lib.py:153] step: 169200, eval_loss: 4.14234e-04
I0405 11:47:24.972682 23443585951552 run_lib.py:140] step: 169250, training_loss: 4.43735e-04
I0405 11:47:42.481858 23443585951552 run_lib.py:140] step: 169300, training_loss: 4.16870e-04
I0405 11:47:42.635822 23443585951552 run_lib.py:153] step: 169300, eval_loss: 4.34145e-04
I0405 11:48:00.159768 23443585951552 run_lib.py:140] step: 169350, training_loss: 4.22904e-04
I0405 11:48:17.872998 23443585951552 run_lib.py:140] step: 169400, training_loss: 3.72768e-04
I0405 11:48:18.071073 23443585951552 run_lib.py:153] step: 169400, eval_loss: 4.25816e-04
I0405 11:48:35.678421 23443585951552 run_lib.py:140] step: 169450, training_loss: 4.32620e-04
I0405 11:48:53.439029 23443585951552 run_lib.py:140] step: 169500, training_loss: 4.31543e-04
I0405 11:48:53.598152 23443585951552 run_lib.py:153] step: 169500, eval_loss: 3.95741e-04
I0405 11:49:11.101300 23443585951552 run_lib.py:140] step: 169550, training_loss: 4.16570e-04
I0405 11:49:28.567026 23443585951552 run_lib.py:140] step: 169600, training_loss: 4.53805e-04
I0405 11:49:28.727060 23443585951552 run_lib.py:153] step: 169600, eval_loss: 4.44045e-04
I0405 11:49:46.377284 23443585951552 run_lib.py:140] step: 169650, training_loss: 3.91608e-04
I0405 11:50:03.990812 23443585951552 run_lib.py:140] step: 169700, training_loss: 4.10771e-04
I0405 11:50:04.149908 23443585951552 run_lib.py:153] step: 169700, eval_loss: 4.41224e-04
I0405 11:50:21.665664 23443585951552 run_lib.py:140] step: 169750, training_loss: 4.05790e-04
I0405 11:50:39.354494 23443585951552 run_lib.py:140] step: 169800, training_loss: 3.97513e-04
I0405 11:50:39.512827 23443585951552 run_lib.py:153] step: 169800, eval_loss: 3.87812e-04
I0405 11:50:57.000815 23443585951552 run_lib.py:140] step: 169850, training_loss: 4.29963e-04
I0405 11:51:14.583164 23443585951552 run_lib.py:140] step: 169900, training_loss: 3.67120e-04
I0405 11:51:14.735998 23443585951552 run_lib.py:153] step: 169900, eval_loss: 4.15266e-04
I0405 11:51:32.359480 23443585951552 run_lib.py:140] step: 169950, training_loss: 4.19678e-04
I0405 11:51:50.013927 23443585951552 run_lib.py:140] step: 170000, training_loss: 4.24767e-04
I0405 11:51:50.649055 23443585951552 run_lib.py:153] step: 170000, eval_loss: 3.83660e-04
I0405 11:52:08.808252 23443585951552 run_lib.py:140] step: 170050, training_loss: 4.11746e-04
I0405 11:52:26.358374 23443585951552 run_lib.py:140] step: 170100, training_loss: 3.90227e-04
I0405 11:52:26.518078 23443585951552 run_lib.py:153] step: 170100, eval_loss: 3.94443e-04
I0405 11:52:44.211596 23443585951552 run_lib.py:140] step: 170150, training_loss: 3.30748e-04
I0405 11:53:01.829916 23443585951552 run_lib.py:140] step: 170200, training_loss: 3.89117e-04
I0405 11:53:01.996733 23443585951552 run_lib.py:153] step: 170200, eval_loss: 3.50672e-04
I0405 11:53:19.552187 23443585951552 run_lib.py:140] step: 170250, training_loss: 4.07349e-04
I0405 11:53:37.073607 23443585951552 run_lib.py:140] step: 170300, training_loss: 3.95802e-04
I0405 11:53:37.225351 23443585951552 run_lib.py:153] step: 170300, eval_loss: 4.36185e-04
I0405 11:53:54.964547 23443585951552 run_lib.py:140] step: 170350, training_loss: 3.69902e-04
I0405 11:54:12.440427 23443585951552 run_lib.py:140] step: 170400, training_loss: 3.95931e-04
I0405 11:54:12.597856 23443585951552 run_lib.py:153] step: 170400, eval_loss: 4.08721e-04
I0405 11:54:30.269231 23443585951552 run_lib.py:140] step: 170450, training_loss: 3.94246e-04
I0405 11:54:47.804162 23443585951552 run_lib.py:140] step: 170500, training_loss: 3.61128e-04
I0405 11:54:47.965103 23443585951552 run_lib.py:153] step: 170500, eval_loss: 4.17860e-04
I0405 11:55:05.573998 23443585951552 run_lib.py:140] step: 170550, training_loss: 4.00178e-04
I0405 11:55:23.343852 23443585951552 run_lib.py:140] step: 170600, training_loss: 4.27708e-04
I0405 11:55:23.499926 23443585951552 run_lib.py:153] step: 170600, eval_loss: 3.99232e-04
I0405 11:55:40.986577 23443585951552 run_lib.py:140] step: 170650, training_loss: 4.28210e-04
I0405 11:55:58.492571 23443585951552 run_lib.py:140] step: 170700, training_loss: 3.36562e-04
I0405 11:55:58.646497 23443585951552 run_lib.py:153] step: 170700, eval_loss: 4.02806e-04
I0405 11:56:16.301276 23443585951552 run_lib.py:140] step: 170750, training_loss: 3.92719e-04
I0405 11:56:33.910829 23443585951552 run_lib.py:140] step: 170800, training_loss: 3.81853e-04
I0405 11:56:34.066082 23443585951552 run_lib.py:153] step: 170800, eval_loss: 4.23525e-04
I0405 11:56:51.764109 23443585951552 run_lib.py:140] step: 170850, training_loss: 4.67469e-04
I0405 11:57:09.306001 23443585951552 run_lib.py:140] step: 170900, training_loss: 3.94822e-04
I0405 11:57:09.474036 23443585951552 run_lib.py:153] step: 170900, eval_loss: 3.45432e-04
I0405 11:57:26.944886 23443585951552 run_lib.py:140] step: 170950, training_loss: 4.62150e-04
I0405 11:57:44.661209 23443585951552 run_lib.py:140] step: 171000, training_loss: 4.53882e-04
I0405 11:57:44.832228 23443585951552 run_lib.py:153] step: 171000, eval_loss: 3.73062e-04
I0405 11:58:02.536203 23443585951552 run_lib.py:140] step: 171050, training_loss: 3.35872e-04
I0405 11:58:20.156252 23443585951552 run_lib.py:140] step: 171100, training_loss: 3.49154e-04
I0405 11:58:20.320007 23443585951552 run_lib.py:153] step: 171100, eval_loss: 4.07335e-04
I0405 11:58:37.811458 23443585951552 run_lib.py:140] step: 171150, training_loss: 4.30560e-04
I0405 11:58:55.305227 23443585951552 run_lib.py:140] step: 171200, training_loss: 4.03733e-04
I0405 11:58:55.458856 23443585951552 run_lib.py:153] step: 171200, eval_loss: 4.10294e-04
I0405 11:59:13.221022 23443585951552 run_lib.py:140] step: 171250, training_loss: 4.29439e-04
I0405 11:59:30.880815 23443585951552 run_lib.py:140] step: 171300, training_loss: 4.23487e-04
I0405 11:59:31.034538 23443585951552 run_lib.py:153] step: 171300, eval_loss: 4.19478e-04
I0405 11:59:48.595554 23443585951552 run_lib.py:140] step: 171350, training_loss: 4.01201e-04
I0405 12:00:06.115176 23443585951552 run_lib.py:140] step: 171400, training_loss: 3.69871e-04
I0405 12:00:06.265835 23443585951552 run_lib.py:153] step: 171400, eval_loss: 3.91537e-04
I0405 12:00:23.995110 23443585951552 run_lib.py:140] step: 171450, training_loss: 4.01084e-04
I0405 12:00:41.515483 23443585951552 run_lib.py:140] step: 171500, training_loss: 4.39674e-04
I0405 12:00:41.678017 23443585951552 run_lib.py:153] step: 171500, eval_loss: 3.94720e-04
I0405 12:00:59.368131 23443585951552 run_lib.py:140] step: 171550, training_loss: 4.35525e-04
I0405 12:01:16.944141 23443585951552 run_lib.py:140] step: 171600, training_loss: 4.81982e-04
I0405 12:01:17.104809 23443585951552 run_lib.py:153] step: 171600, eval_loss: 3.94779e-04
I0405 12:01:34.643052 23443585951552 run_lib.py:140] step: 171650, training_loss: 3.49393e-04
I0405 12:01:52.352240 23443585951552 run_lib.py:140] step: 171700, training_loss: 4.20757e-04
I0405 12:01:52.505839 23443585951552 run_lib.py:153] step: 171700, eval_loss: 3.99872e-04
I0405 12:02:10.006008 23443585951552 run_lib.py:140] step: 171750, training_loss: 5.18851e-04
I0405 12:02:27.519292 23443585951552 run_lib.py:140] step: 171800, training_loss: 4.39612e-04
I0405 12:02:27.674149 23443585951552 run_lib.py:153] step: 171800, eval_loss: 3.66358e-04
I0405 12:02:45.339525 23443585951552 run_lib.py:140] step: 171850, training_loss: 3.68118e-04
I0405 12:03:02.884671 23443585951552 run_lib.py:140] step: 171900, training_loss: 4.14253e-04
I0405 12:03:03.035577 23443585951552 run_lib.py:153] step: 171900, eval_loss: 3.99014e-04
I0405 12:03:20.644468 23443585951552 run_lib.py:140] step: 171950, training_loss: 3.89415e-04
I0405 12:03:38.366850 23443585951552 run_lib.py:140] step: 172000, training_loss: 4.36962e-04
I0405 12:03:38.529945 23443585951552 run_lib.py:153] step: 172000, eval_loss: 4.09144e-04
I0405 12:03:56.166535 23443585951552 run_lib.py:140] step: 172050, training_loss: 4.69359e-04
I0405 12:04:13.682328 23443585951552 run_lib.py:140] step: 172100, training_loss: 4.41978e-04
I0405 12:04:13.838470 23443585951552 run_lib.py:153] step: 172100, eval_loss: 4.39097e-04
I0405 12:04:31.422894 23443585951552 run_lib.py:140] step: 172150, training_loss: 3.72221e-04
I0405 12:04:49.062663 23443585951552 run_lib.py:140] step: 172200, training_loss: 3.75645e-04
I0405 12:04:49.217670 23443585951552 run_lib.py:153] step: 172200, eval_loss: 4.10159e-04
I0405 12:05:06.785031 23443585951552 run_lib.py:140] step: 172250, training_loss: 4.04121e-04
I0405 12:05:24.292801 23443585951552 run_lib.py:140] step: 172300, training_loss: 4.12027e-04
I0405 12:05:24.444872 23443585951552 run_lib.py:153] step: 172300, eval_loss: 3.70255e-04
I0405 12:05:42.114560 23443585951552 run_lib.py:140] step: 172350, training_loss: 3.66021e-04
I0405 12:05:59.677270 23443585951552 run_lib.py:140] step: 172400, training_loss: 4.08602e-04
I0405 12:05:59.832211 23443585951552 run_lib.py:153] step: 172400, eval_loss: 4.24268e-04
I0405 12:06:17.511870 23443585951552 run_lib.py:140] step: 172450, training_loss: 4.19680e-04
I0405 12:06:35.150642 23443585951552 run_lib.py:140] step: 172500, training_loss: 4.03714e-04
I0405 12:06:35.307875 23443585951552 run_lib.py:153] step: 172500, eval_loss: 4.31369e-04
I0405 12:06:52.975951 23443585951552 run_lib.py:140] step: 172550, training_loss: 3.98110e-04
I0405 12:07:10.467391 23443585951552 run_lib.py:140] step: 172600, training_loss: 3.66097e-04
I0405 12:07:10.629412 23443585951552 run_lib.py:153] step: 172600, eval_loss: 3.95145e-04
I0405 12:07:28.144231 23443585951552 run_lib.py:140] step: 172650, training_loss: 4.09075e-04
I0405 12:07:45.808674 23443585951552 run_lib.py:140] step: 172700, training_loss: 3.95862e-04
I0405 12:07:45.962667 23443585951552 run_lib.py:153] step: 172700, eval_loss: 3.77769e-04
I0405 12:08:03.573044 23443585951552 run_lib.py:140] step: 172750, training_loss: 4.17051e-04
I0405 12:08:21.316172 23443585951552 run_lib.py:140] step: 172800, training_loss: 3.52599e-04
I0405 12:08:21.465935 23443585951552 run_lib.py:153] step: 172800, eval_loss: 4.08771e-04
I0405 12:08:38.999776 23443585951552 run_lib.py:140] step: 172850, training_loss: 3.84892e-04
I0405 12:08:56.568161 23443585951552 run_lib.py:140] step: 172900, training_loss: 4.24397e-04
I0405 12:08:56.775889 23443585951552 run_lib.py:153] step: 172900, eval_loss: 4.21051e-04
I0405 12:09:14.844550 23443585951552 run_lib.py:140] step: 172950, training_loss: 3.69288e-04
I0405 12:09:32.459702 23443585951552 run_lib.py:140] step: 173000, training_loss: 3.86765e-04
I0405 12:09:32.633915 23443585951552 run_lib.py:153] step: 173000, eval_loss: 4.45095e-04
I0405 12:09:50.225362 23443585951552 run_lib.py:140] step: 173050, training_loss: 3.98865e-04
I0405 12:10:08.004163 23443585951552 run_lib.py:140] step: 173100, training_loss: 3.66294e-04
I0405 12:10:08.158231 23443585951552 run_lib.py:153] step: 173100, eval_loss: 4.45274e-04
I0405 12:10:25.769152 23443585951552 run_lib.py:140] step: 173150, training_loss: 3.50962e-04
I0405 12:10:43.327146 23443585951552 run_lib.py:140] step: 173200, training_loss: 3.96177e-04
I0405 12:10:43.479608 23443585951552 run_lib.py:153] step: 173200, eval_loss: 4.05077e-04
I0405 12:11:01.194355 23443585951552 run_lib.py:140] step: 173250, training_loss: 4.00907e-04
I0405 12:11:18.881577 23443585951552 run_lib.py:140] step: 173300, training_loss: 4.16469e-04
I0405 12:11:19.038189 23443585951552 run_lib.py:153] step: 173300, eval_loss: 4.35798e-04
I0405 12:11:36.616333 23443585951552 run_lib.py:140] step: 173350, training_loss: 4.25333e-04
I0405 12:11:54.231899 23443585951552 run_lib.py:140] step: 173400, training_loss: 4.24230e-04
I0405 12:11:54.394767 23443585951552 run_lib.py:153] step: 173400, eval_loss: 4.10584e-04
I0405 12:12:12.112269 23443585951552 run_lib.py:140] step: 173450, training_loss: 3.59205e-04
I0405 12:12:29.721652 23443585951552 run_lib.py:140] step: 173500, training_loss: 3.65996e-04
I0405 12:12:29.900677 23443585951552 run_lib.py:153] step: 173500, eval_loss: 4.17964e-04
I0405 12:12:47.524304 23443585951552 run_lib.py:140] step: 173550, training_loss: 3.73481e-04
I0405 12:13:05.122059 23443585951552 run_lib.py:140] step: 173600, training_loss: 3.94247e-04
I0405 12:13:05.274435 23443585951552 run_lib.py:153] step: 173600, eval_loss: 4.14435e-04
I0405 12:13:23.029246 23443585951552 run_lib.py:140] step: 173650, training_loss: 4.26827e-04
I0405 12:13:40.505428 23443585951552 run_lib.py:140] step: 173700, training_loss: 3.97396e-04
I0405 12:13:40.658729 23443585951552 run_lib.py:153] step: 173700, eval_loss: 3.89804e-04
I0405 12:13:58.122186 23443585951552 run_lib.py:140] step: 173750, training_loss: 3.80098e-04
I0405 12:14:15.828310 23443585951552 run_lib.py:140] step: 173800, training_loss: 3.80561e-04
I0405 12:14:15.984020 23443585951552 run_lib.py:153] step: 173800, eval_loss: 3.92693e-04
I0405 12:14:33.626102 23443585951552 run_lib.py:140] step: 173850, training_loss: 3.51725e-04
I0405 12:14:51.361075 23443585951552 run_lib.py:140] step: 173900, training_loss: 3.49387e-04
I0405 12:14:51.517849 23443585951552 run_lib.py:153] step: 173900, eval_loss: 4.59186e-04
I0405 12:15:09.052891 23443585951552 run_lib.py:140] step: 173950, training_loss: 4.19972e-04
I0405 12:15:26.553260 23443585951552 run_lib.py:140] step: 174000, training_loss: 4.18333e-04
I0405 12:15:26.707362 23443585951552 run_lib.py:153] step: 174000, eval_loss: 4.51621e-04
I0405 12:15:44.363647 23443585951552 run_lib.py:140] step: 174050, training_loss: 3.84217e-04
I0405 12:16:01.952821 23443585951552 run_lib.py:140] step: 174100, training_loss: 4.09820e-04
I0405 12:16:02.115538 23443585951552 run_lib.py:153] step: 174100, eval_loss: 4.50896e-04
I0405 12:16:19.721441 23443585951552 run_lib.py:140] step: 174150, training_loss: 4.04784e-04
I0405 12:16:37.463400 23443585951552 run_lib.py:140] step: 174200, training_loss: 4.10322e-04
I0405 12:16:37.616144 23443585951552 run_lib.py:153] step: 174200, eval_loss: 4.69193e-04
I0405 12:16:55.121947 23443585951552 run_lib.py:140] step: 174250, training_loss: 3.89895e-04
I0405 12:17:12.633511 23443585951552 run_lib.py:140] step: 174300, training_loss: 3.97019e-04
I0405 12:17:12.786710 23443585951552 run_lib.py:153] step: 174300, eval_loss: 4.27043e-04
I0405 12:17:30.337085 23443585951552 run_lib.py:140] step: 174350, training_loss: 3.64048e-04
I0405 12:17:48.024266 23443585951552 run_lib.py:140] step: 174400, training_loss: 3.82487e-04
I0405 12:17:48.199644 23443585951552 run_lib.py:153] step: 174400, eval_loss: 3.52504e-04
I0405 12:18:05.790306 23443585951552 run_lib.py:140] step: 174450, training_loss: 3.81226e-04
I0405 12:18:23.273167 23443585951552 run_lib.py:140] step: 174500, training_loss: 3.93077e-04
I0405 12:18:23.429204 23443585951552 run_lib.py:153] step: 174500, eval_loss: 3.68621e-04
I0405 12:18:41.119044 23443585951552 run_lib.py:140] step: 174550, training_loss: 3.76987e-04
I0405 12:18:58.737098 23443585951552 run_lib.py:140] step: 174600, training_loss: 4.23148e-04
I0405 12:18:58.895165 23443585951552 run_lib.py:153] step: 174600, eval_loss: 4.15807e-04
I0405 12:19:16.432202 23443585951552 run_lib.py:140] step: 174650, training_loss: 4.48368e-04
I0405 12:19:34.013991 23443585951552 run_lib.py:140] step: 174700, training_loss: 4.31704e-04
I0405 12:19:34.169998 23443585951552 run_lib.py:153] step: 174700, eval_loss: 4.14737e-04
I0405 12:19:51.977270 23443585951552 run_lib.py:140] step: 174750, training_loss: 3.97907e-04
I0405 12:20:09.661275 23443585951552 run_lib.py:140] step: 174800, training_loss: 4.07154e-04
I0405 12:20:09.818932 23443585951552 run_lib.py:153] step: 174800, eval_loss: 4.22911e-04
I0405 12:20:27.419563 23443585951552 run_lib.py:140] step: 174850, training_loss: 3.89485e-04
I0405 12:20:45.203370 23443585951552 run_lib.py:140] step: 174900, training_loss: 3.59440e-04
I0405 12:20:45.369003 23443585951552 run_lib.py:153] step: 174900, eval_loss: 4.05033e-04
I0405 12:21:03.091616 23443585951552 run_lib.py:140] step: 174950, training_loss: 4.00117e-04
I0405 12:21:21.014674 23443585951552 run_lib.py:140] step: 175000, training_loss: 4.13789e-04
I0405 12:21:21.173179 23443585951552 run_lib.py:153] step: 175000, eval_loss: 4.10344e-04
I0405 12:21:38.793116 23443585951552 run_lib.py:140] step: 175050, training_loss: 3.82885e-04
I0405 12:21:56.368245 23443585951552 run_lib.py:140] step: 175100, training_loss: 4.05675e-04
I0405 12:21:56.529825 23443585951552 run_lib.py:153] step: 175100, eval_loss: 4.59956e-04
I0405 12:22:14.319393 23443585951552 run_lib.py:140] step: 175150, training_loss: 4.93507e-04
I0405 12:22:32.021138 23443585951552 run_lib.py:140] step: 175200, training_loss: 4.58713e-04
I0405 12:22:32.183120 23443585951552 run_lib.py:153] step: 175200, eval_loss: 3.33398e-04
I0405 12:22:50.078221 23443585951552 run_lib.py:140] step: 175250, training_loss: 4.06676e-04
I0405 12:23:07.844715 23443585951552 run_lib.py:140] step: 175300, training_loss: 3.76696e-04
I0405 12:23:08.023834 23443585951552 run_lib.py:153] step: 175300, eval_loss: 4.07315e-04
I0405 12:23:25.545086 23443585951552 run_lib.py:140] step: 175350, training_loss: 4.08543e-04
I0405 12:23:43.047233 23443585951552 run_lib.py:140] step: 175400, training_loss: 4.50071e-04
I0405 12:23:43.211124 23443585951552 run_lib.py:153] step: 175400, eval_loss: 4.42094e-04
I0405 12:24:00.964633 23443585951552 run_lib.py:140] step: 175450, training_loss: 4.00404e-04
I0405 12:24:18.496720 23443585951552 run_lib.py:140] step: 175500, training_loss: 4.50726e-04
I0405 12:24:18.650624 23443585951552 run_lib.py:153] step: 175500, eval_loss: 3.90226e-04
I0405 12:24:36.188410 23443585951552 run_lib.py:140] step: 175550, training_loss: 3.77955e-04
I0405 12:24:53.758888 23443585951552 run_lib.py:140] step: 175600, training_loss: 4.02511e-04
I0405 12:24:53.913214 23443585951552 run_lib.py:153] step: 175600, eval_loss: 3.85309e-04
I0405 12:25:11.755092 23443585951552 run_lib.py:140] step: 175650, training_loss: 4.05337e-04
I0405 12:25:29.523819 23443585951552 run_lib.py:140] step: 175700, training_loss: 4.06855e-04
I0405 12:25:29.679942 23443585951552 run_lib.py:153] step: 175700, eval_loss: 4.11459e-04
I0405 12:25:47.446987 23443585951552 run_lib.py:140] step: 175750, training_loss: 4.26040e-04
I0405 12:26:05.070871 23443585951552 run_lib.py:140] step: 175800, training_loss: 3.83608e-04
I0405 12:26:05.230893 23443585951552 run_lib.py:153] step: 175800, eval_loss: 3.63514e-04
I0405 12:26:23.038832 23443585951552 run_lib.py:140] step: 175850, training_loss: 3.69798e-04
I0405 12:26:40.645850 23443585951552 run_lib.py:140] step: 175900, training_loss: 3.63166e-04
I0405 12:26:40.802156 23443585951552 run_lib.py:153] step: 175900, eval_loss: 4.03113e-04
I0405 12:26:58.449926 23443585951552 run_lib.py:140] step: 175950, training_loss: 4.90828e-04
I0405 12:27:16.361868 23443585951552 run_lib.py:140] step: 176000, training_loss: 3.39661e-04
I0405 12:27:16.515505 23443585951552 run_lib.py:153] step: 176000, eval_loss: 4.25166e-04
I0405 12:27:34.194958 23443585951552 run_lib.py:140] step: 176050, training_loss: 4.20358e-04
I0405 12:27:52.016427 23443585951552 run_lib.py:140] step: 176100, training_loss: 3.51362e-04
I0405 12:27:52.169871 23443585951552 run_lib.py:153] step: 176100, eval_loss: 4.13259e-04
I0405 12:28:09.808929 23443585951552 run_lib.py:140] step: 176150, training_loss: 3.84887e-04
I0405 12:28:27.446159 23443585951552 run_lib.py:140] step: 176200, training_loss: 4.08194e-04
I0405 12:28:27.609215 23443585951552 run_lib.py:153] step: 176200, eval_loss: 4.07049e-04
I0405 12:28:45.445738 23443585951552 run_lib.py:140] step: 176250, training_loss: 4.02595e-04
I0405 12:29:03.118247 23443585951552 run_lib.py:140] step: 176300, training_loss: 3.85600e-04
I0405 12:29:03.277772 23443585951552 run_lib.py:153] step: 176300, eval_loss: 3.71869e-04
I0405 12:29:20.922097 23443585951552 run_lib.py:140] step: 176350, training_loss: 4.35261e-04
I0405 12:29:38.829882 23443585951552 run_lib.py:140] step: 176400, training_loss: 4.22458e-04
I0405 12:29:38.986047 23443585951552 run_lib.py:153] step: 176400, eval_loss: 3.68846e-04
I0405 12:29:56.594722 23443585951552 run_lib.py:140] step: 176450, training_loss: 4.45474e-04
I0405 12:30:14.181781 23443585951552 run_lib.py:140] step: 176500, training_loss: 3.53709e-04
I0405 12:30:14.345307 23443585951552 run_lib.py:153] step: 176500, eval_loss: 3.76029e-04
I0405 12:30:32.103328 23443585951552 run_lib.py:140] step: 176550, training_loss: 4.80729e-04
