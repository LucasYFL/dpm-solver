[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
2023-05-18 02:39:00.135624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-18 02:39:00.247078: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-18 02:39:01.168995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 02:39:01.169111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 02:39:01.169124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
I0518 02:39:21.358233 23398153672512 main_interval.py:85] (0.6308,)
I0518 02:39:28.422959 23398153672512 sampling.py:98] dpm_solver
I0518 02:39:28.423312 23398153672512 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
I0518 02:39:31.115874 23398153672512 main_interval.py:152] begin checkpoint: 5
I0518 02:39:31.116047 23398153672512 main_interval.py:156] 0 is converged model
I0518 02:39:31.116101 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 02:42:17.562426 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_5.pth
I0518 02:45:21.087013 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 02:45:21.097006 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 0
[2023-05-18 02:45:21,144] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:21,244] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing get_timestep_embedding
[2023-05-18 02:45:21,257] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing get_timestep_embedding (RETURN_VALUE)
[2023-05-18 02:45:21,259] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:21,259] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:21,276] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:22,797] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-05-18 02:45:23,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-05-18 02:45:23,209] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:23,503] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __getitem__
[2023-05-18 02:45:23,515] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing _get_abs_string_index
[2023-05-18 02:45:23,518] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __len__
[2023-05-18 02:45:25,422] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:25,461] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:25,462] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:25,463] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:25,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1
[2023-05-18 02:45:26,262] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
[2023-05-18 02:45:26,359] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2
[2023-05-18 02:45:26,603] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2
[2023-05-18 02:45:26,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:26,648] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:26,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:26,652] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:26,652] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:26,652] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:26,660] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3
[2023-05-18 02:45:26,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3
[2023-05-18 02:45:26,708] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:26,713] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:26,751] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:26,751] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:26,751] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:26,829] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4
[2023-05-18 02:45:26,896] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4
[2023-05-18 02:45:26,988] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5
[2023-05-18 02:45:27,107] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5
[2023-05-18 02:45:27,117] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:27,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:27,160] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:27,160] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:27,161] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:27,202] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6
[2023-05-18 02:45:27,266] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6
[2023-05-18 02:45:27,360] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7
[2023-05-18 02:45:27,483] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7
[2023-05-18 02:45:27,494] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:27,500] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:27,537] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:27,537] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:27,538] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:27,580] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8
[2023-05-18 02:45:27,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8
[2023-05-18 02:45:27,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9
[2023-05-18 02:45:27,855] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9
[2023-05-18 02:45:27,866] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:27,871] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:27,908] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:27,909] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:27,909] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:27,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 10
[2023-05-18 02:45:28,015] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 10
[2023-05-18 02:45:28,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11
[2023-05-18 02:45:28,224] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11
[2023-05-18 02:45:28,234] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:28,240] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:28,277] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:28,277] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:28,278] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:28,320] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 12
[2023-05-18 02:45:28,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 12
[2023-05-18 02:45:28,480] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 13
[2023-05-18 02:45:28,600] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 13
[2023-05-18 02:45:28,610] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:28,616] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:28,653] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:28,654] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:28,654] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:28,696] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14
[2023-05-18 02:45:28,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14
[2023-05-18 02:45:28,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15
[2023-05-18 02:45:28,970] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15
[2023-05-18 02:45:28,980] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:28,986] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:29,023] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:29,023] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:29,024] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1444352 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:29,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16
[2023-05-18 02:45:29,129] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16
[2023-05-18 02:45:29,220] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 17
[2023-05-18 02:45:29,341] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 17
[2023-05-18 02:45:29,352] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:29,358] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:29,409] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:29,409] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:29,410] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1510400 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │       1024 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:29,462] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 18
[2023-05-18 02:45:29,594] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 18
[2023-05-18 02:45:29,698] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 19
[2023-05-18 02:45:29,908] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 19
[2023-05-18 02:45:29,920] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:29,940] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:29,942] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:29,943] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:29,943] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:29,943] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:29,951] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 20
[2023-05-18 02:45:29,971] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 20
[2023-05-18 02:45:29,971] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:29,976] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:30,016] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:30,016] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:30,017] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2492416 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    1709056 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:30,132] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 21
[2023-05-18 02:45:30,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 21
[2023-05-18 02:45:30,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 22
[2023-05-18 02:45:30,467] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 22
[2023-05-18 02:45:30,470] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:30,494] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:30,495] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:30,496] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:30,496] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:30,496] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:30,504] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 23
[2023-05-18 02:45:30,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 23
[2023-05-18 02:45:30,523] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:30,527] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:30,634] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:30,634] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:30,634] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:30,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 24
[2023-05-18 02:45:30,753] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 24
[2023-05-18 02:45:30,974] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 25
[2023-05-18 02:45:31,194] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 25
[2023-05-18 02:45:31,224] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:31,252] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:31,253] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:31,254] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:31,254] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:31,255] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:31,263] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 26
[2023-05-18 02:45:31,272] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 26
[2023-05-18 02:45:31,272] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:31,276] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:31,313] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:31,313] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:31,314] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:31,429] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 27
[2023-05-18 02:45:31,588] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 27
[2023-05-18 02:45:31,618] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 28
[2023-05-18 02:45:31,644] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 28
[2023-05-18 02:45:31,646] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:31,664] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:31,768] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:31,769] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:31,769] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:31,810] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 29
[2023-05-18 02:45:31,857] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 29
[2023-05-18 02:45:32,077] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 30
[2023-05-18 02:45:32,189] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 30
[2023-05-18 02:45:32,219] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:32,226] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:32,264] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:32,264] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:32,265] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:32,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 31
[2023-05-18 02:45:32,513] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 31
[2023-05-18 02:45:32,543] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 32
[2023-05-18 02:45:32,559] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 32
[2023-05-18 02:45:32,561] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:32,565] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:32,670] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:32,670] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:32,670] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:32,953] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 33
[2023-05-18 02:45:33,001] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 33
[2023-05-18 02:45:33,223] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 34
[2023-05-18 02:45:33,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 34
[2023-05-18 02:45:33,370] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:33,377] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:33,415] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:33,416] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:33,417] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:33,531] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 35
[2023-05-18 02:45:33,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 35
[2023-05-18 02:45:33,692] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 36
[2023-05-18 02:45:33,708] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 36
[2023-05-18 02:45:33,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:33,714] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:33,819] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:33,819] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:33,820] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:33,860] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 37
[2023-05-18 02:45:33,906] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 37
[2023-05-18 02:45:34,126] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 38
[2023-05-18 02:45:34,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 38
[2023-05-18 02:45:34,268] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:34,275] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:34,317] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:34,318] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:34,318] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:34,433] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 39
[2023-05-18 02:45:34,567] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 39
[2023-05-18 02:45:34,597] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 40
[2023-05-18 02:45:34,612] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 40
[2023-05-18 02:45:34,614] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:34,619] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:34,724] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:34,724] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:34,725] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:34,765] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 41
[2023-05-18 02:45:34,812] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 41
[2023-05-18 02:45:35,032] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 42
[2023-05-18 02:45:35,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 42
[2023-05-18 02:45:35,174] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:35,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:35,218] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:35,218] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:35,219] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:35,335] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 43
[2023-05-18 02:45:35,469] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 43
[2023-05-18 02:45:35,498] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 44
[2023-05-18 02:45:35,515] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 44
[2023-05-18 02:45:35,516] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:35,521] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:35,626] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:35,626] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:35,627] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:35,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 45
[2023-05-18 02:45:35,717] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 45
[2023-05-18 02:45:35,935] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 46
[2023-05-18 02:45:36,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 46
[2023-05-18 02:45:36,081] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:36,087] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:36,125] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:36,125] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:36,125] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:36,238] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 47
[2023-05-18 02:45:36,374] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 47
[2023-05-18 02:45:36,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 48
[2023-05-18 02:45:36,420] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 48
[2023-05-18 02:45:36,422] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:36,426] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:36,532] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:36,532] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:36,533] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:36,573] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 49
[2023-05-18 02:45:36,621] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 49
[2023-05-18 02:45:36,840] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 50
[2023-05-18 02:45:36,953] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 50
[2023-05-18 02:45:36,983] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:36,989] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:37,026] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:37,026] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:37,027] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:37,144] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 51
[2023-05-18 02:45:37,277] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 51
[2023-05-18 02:45:37,308] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 52
[2023-05-18 02:45:37,323] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 52
[2023-05-18 02:45:37,325] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:37,330] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:37,435] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:37,435] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:37,436] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:37,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 53
[2023-05-18 02:45:37,524] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 53
[2023-05-18 02:45:37,743] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 54
[2023-05-18 02:45:37,856] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 54
[2023-05-18 02:45:37,886] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:37,892] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:37,941] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:37,942] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:37,942] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:38,193] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 55
[2023-05-18 02:45:38,482] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 55
[2023-05-18 02:45:38,522] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 56
[2023-05-18 02:45:38,554] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 56
[2023-05-18 02:45:38,557] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:38,575] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:38,576] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:38,577] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:38,577] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:38,577] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:38,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 57
[2023-05-18 02:45:38,604] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 57
[2023-05-18 02:45:38,604] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:38,609] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:38,646] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:38,646] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:38,647] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:38,763] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 58
[2023-05-18 02:45:38,931] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 58
[2023-05-18 02:45:38,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 59
[2023-05-18 02:45:38,986] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 59
[2023-05-18 02:45:38,987] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:38,997] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:39,034] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:39,034] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:39,034] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:39,148] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 60
[2023-05-18 02:45:39,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 60
[2023-05-18 02:45:39,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 61
[2023-05-18 02:45:39,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 61
[2023-05-18 02:45:39,330] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:39,335] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:39,372] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:39,372] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:39,373] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:39,486] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 62
[2023-05-18 02:45:39,620] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 62
[2023-05-18 02:45:39,648] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 63
[2023-05-18 02:45:39,664] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 63
[2023-05-18 02:45:39,666] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:39,671] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:39,708] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:39,708] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:39,709] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:39,821] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 64
[2023-05-18 02:45:39,953] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 64
[2023-05-18 02:45:39,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 65
[2023-05-18 02:45:39,998] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 65
[2023-05-18 02:45:39,999] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:40,004] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:40,041] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:40,041] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:40,041] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:40,158] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 66
[2023-05-18 02:45:40,294] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 66
[2023-05-18 02:45:40,324] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 67
[2023-05-18 02:45:40,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 67
[2023-05-18 02:45:40,342] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:40,347] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:40,384] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:40,384] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:40,385] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:40,499] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 68
[2023-05-18 02:45:40,632] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 68
[2023-05-18 02:45:40,660] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 69
[2023-05-18 02:45:40,676] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 69
[2023-05-18 02:45:40,678] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:40,683] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:40,719] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:40,720] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:40,720] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:40,871] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 70
[2023-05-18 02:45:41,003] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 70
[2023-05-18 02:45:41,031] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 71
[2023-05-18 02:45:41,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 71
[2023-05-18 02:45:41,049] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:41,054] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:41,090] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:41,091] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:41,091] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:41,206] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 72
[2023-05-18 02:45:41,340] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 72
[2023-05-18 02:45:41,369] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 73
[2023-05-18 02:45:41,386] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 73
[2023-05-18 02:45:41,387] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:41,393] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:41,727] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:41,728] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:41,728] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:41,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 74
[2023-05-18 02:45:42,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 74
[2023-05-18 02:45:42,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 75
[2023-05-18 02:45:42,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 75
[2023-05-18 02:45:42,210] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:42,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:42,229] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:42,230] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:42,230] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:42,231] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:42,238] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 76
[2023-05-18 02:45:42,256] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 76
[2023-05-18 02:45:42,257] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:42,261] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:42,299] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:42,299] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:42,300] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:42,415] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 77
[2023-05-18 02:45:42,585] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 77
[2023-05-18 02:45:42,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 78
[2023-05-18 02:45:42,641] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 78
[2023-05-18 02:45:42,643] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:42,650] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:42,687] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:42,688] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:42,688] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:42,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 79
[2023-05-18 02:45:42,938] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 79
[2023-05-18 02:45:42,966] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 80
[2023-05-18 02:45:42,985] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 80
[2023-05-18 02:45:42,987] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:42,992] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:43,029] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:43,029] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:43,029] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:43,145] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 81
[2023-05-18 02:45:43,281] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 81
[2023-05-18 02:45:43,312] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 82
[2023-05-18 02:45:43,328] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 82
[2023-05-18 02:45:43,330] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:43,336] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:43,373] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:43,373] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:43,374] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:43,488] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 83
[2023-05-18 02:45:43,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 83
[2023-05-18 02:45:43,652] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 84
[2023-05-18 02:45:43,668] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 84
[2023-05-18 02:45:43,670] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:43,675] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:43,712] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:43,712] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:43,713] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:43,827] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 85
[2023-05-18 02:45:43,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 85
[2023-05-18 02:45:43,990] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 86
[2023-05-18 02:45:44,006] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 86
[2023-05-18 02:45:44,008] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:44,013] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:44,050] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:44,051] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:44,051] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:44,167] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 87
[2023-05-18 02:45:44,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 87
[2023-05-18 02:45:44,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 88
[2023-05-18 02:45:44,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 88
[2023-05-18 02:45:44,351] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:44,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:44,396] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:44,396] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:44,397] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:44,512] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 89
[2023-05-18 02:45:44,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 89
[2023-05-18 02:45:44,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 90
[2023-05-18 02:45:44,691] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 90
[2023-05-18 02:45:44,693] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:44,698] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:44,735] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:44,735] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:44,736] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:44,850] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 91
[2023-05-18 02:45:44,983] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 91
[2023-05-18 02:45:45,013] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 92
[2023-05-18 02:45:45,029] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 92
[2023-05-18 02:45:45,031] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:45,036] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:45,075] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:45,075] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:45,076] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:45,192] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 93
[2023-05-18 02:45:45,327] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 93
[2023-05-18 02:45:45,357] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 94
[2023-05-18 02:45:45,373] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 94
[2023-05-18 02:45:45,375] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:45,379] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:45,484] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:45,485] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:45,485] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:45,526] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 95
[2023-05-18 02:45:45,587] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 95
[2023-05-18 02:45:45,808] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 96
[2023-05-18 02:45:46,040] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 96
[2023-05-18 02:45:46,071] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:46,081] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>
[2023-05-18 02:45:46,082] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)
[2023-05-18 02:45:46,083] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:46,083] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:46,083] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:46,092] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 97
[2023-05-18 02:45:46,101] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 97
[2023-05-18 02:45:46,101] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:46,105] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:46,142] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:46,142] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:46,143] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2360320 │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:46,259] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 98
[2023-05-18 02:45:46,408] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 98
[2023-05-18 02:45:46,438] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 99
[2023-05-18 02:45:46,454] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 99
[2023-05-18 02:45:46,456] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:46,461] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:46,501] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:46,501] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:46,502] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:46,616] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 100
[2023-05-18 02:45:46,813] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 100
[2023-05-18 02:45:46,851] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 101
[2023-05-18 02:45:46,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 101
[2023-05-18 02:45:46,882] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:46,898] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:46,940] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:46,940] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:46,940] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:47,058] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 102
[2023-05-18 02:45:47,201] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 102
[2023-05-18 02:45:47,239] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 103
[2023-05-18 02:45:47,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 103
[2023-05-18 02:45:47,263] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:47,269] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:47,310] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:47,310] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:47,311] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:47,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 104
[2023-05-18 02:45:47,565] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 104
[2023-05-18 02:45:47,602] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 105
[2023-05-18 02:45:47,623] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 105
[2023-05-18 02:45:47,626] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:47,631] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:47,671] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:47,671] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:47,672] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:47,786] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 106
[2023-05-18 02:45:47,925] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 106
[2023-05-18 02:45:47,962] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 107
[2023-05-18 02:45:47,984] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 107
[2023-05-18 02:45:47,987] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:47,993] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:48,033] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:48,033] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:48,034] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:48,164] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 108
[2023-05-18 02:45:48,305] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 108
[2023-05-18 02:45:48,343] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 109
[2023-05-18 02:45:48,365] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 109
[2023-05-18 02:45:48,368] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:48,373] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:48,413] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:48,413] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:48,414] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:48,528] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 110
[2023-05-18 02:45:48,667] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 110
[2023-05-18 02:45:48,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 111
[2023-05-18 02:45:48,725] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 111
[2023-05-18 02:45:48,728] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:48,733] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:48,773] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:48,773] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:48,774] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:48,887] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 112
[2023-05-18 02:45:49,029] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 112
[2023-05-18 02:45:49,068] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 113
[2023-05-18 02:45:49,089] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 113
[2023-05-18 02:45:49,092] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:49,097] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:49,137] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:49,137] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:49,138] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:49,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 114
[2023-05-18 02:45:49,396] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 114
[2023-05-18 02:45:49,435] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 115
[2023-05-18 02:45:49,456] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 115
[2023-05-18 02:45:49,459] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:49,465] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:49,505] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:49,505] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:49,506] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:49,619] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 116
[2023-05-18 02:45:49,758] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 116
[2023-05-18 02:45:49,795] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 117
[2023-05-18 02:45:49,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 117
[2023-05-18 02:45:49,818] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:49,823] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:49,876] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:49,876] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:49,876] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:50,333] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 118
[2023-05-18 02:45:50,551] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 118
[2023-05-18 02:45:50,592] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 119
[2023-05-18 02:45:50,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 119
[2023-05-18 02:45:50,618] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:50,625] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:50,665] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:50,666] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:50,666] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:50,780] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 120
[2023-05-18 02:45:50,958] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 120
[2023-05-18 02:45:50,997] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 121
[2023-05-18 02:45:51,025] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 121
[2023-05-18 02:45:51,027] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:51,043] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:51,084] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:51,085] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:51,085] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:51,199] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 122
[2023-05-18 02:45:51,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 122
[2023-05-18 02:45:51,387] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 123
[2023-05-18 02:45:51,409] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 123
[2023-05-18 02:45:51,412] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:51,417] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:51,457] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:51,457] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:51,458] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:51,572] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 124
[2023-05-18 02:45:51,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 124
[2023-05-18 02:45:51,750] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 125
[2023-05-18 02:45:51,771] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 125
[2023-05-18 02:45:51,773] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:51,778] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:51,820] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:51,820] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:51,821] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:51,936] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 126
[2023-05-18 02:45:52,078] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 126
[2023-05-18 02:45:52,117] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 127
[2023-05-18 02:45:52,138] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 127
[2023-05-18 02:45:52,141] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:52,146] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:52,186] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:52,187] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:52,187] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:52,303] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 128
[2023-05-18 02:45:52,447] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 128
[2023-05-18 02:45:52,485] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 129
[2023-05-18 02:45:52,507] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 129
[2023-05-18 02:45:52,509] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:52,514] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:52,554] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:52,555] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:52,555] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:52,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 130
[2023-05-18 02:45:52,944] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 130
[2023-05-18 02:45:52,982] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 131
[2023-05-18 02:45:53,004] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 131
[2023-05-18 02:45:53,007] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:53,013] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:53,053] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:53,053] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:53,054] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:53,170] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 132
[2023-05-18 02:45:53,311] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 132
[2023-05-18 02:45:53,349] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 133
[2023-05-18 02:45:53,371] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 133
[2023-05-18 02:45:53,373] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:53,379] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:53,419] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:53,419] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:53,419] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:53,675] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 134
[2023-05-18 02:45:53,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 134
[2023-05-18 02:45:53,853] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 135
[2023-05-18 02:45:53,874] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 135
[2023-05-18 02:45:53,876] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:53,882] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:53,921] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:53,922] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:53,922] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:54,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 136
[2023-05-18 02:45:54,179] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 136
[2023-05-18 02:45:54,218] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 137
[2023-05-18 02:45:54,240] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 137
[2023-05-18 02:45:54,242] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:54,248] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:54,299] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:54,299] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:54,299] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2623488 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    2889728 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:54,431] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 138
[2023-05-18 02:45:54,646] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 138
[2023-05-18 02:45:54,686] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 139
[2023-05-18 02:45:54,713] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 139
[2023-05-18 02:45:54,716] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:54,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:54,769] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:54,769] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:54,770] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:54,885] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 140
[2023-05-18 02:45:55,066] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 140
[2023-05-18 02:45:55,105] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 141
[2023-05-18 02:45:55,128] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 141
[2023-05-18 02:45:55,131] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:55,146] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:55,187] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:55,187] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:55,188] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:55,315] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 142
[2023-05-18 02:45:55,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 142
[2023-05-18 02:45:55,495] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 143
[2023-05-18 02:45:55,516] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 143
[2023-05-18 02:45:55,518] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:55,524] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:55,564] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:55,564] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:55,565] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:55,703] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 144
[2023-05-18 02:45:55,845] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 144
[2023-05-18 02:45:55,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 145
[2023-05-18 02:45:55,903] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 145
[2023-05-18 02:45:55,905] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:55,911] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:55,953] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:55,953] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:55,954] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:56,070] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 146
[2023-05-18 02:45:56,213] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 146
[2023-05-18 02:45:56,252] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 147
[2023-05-18 02:45:56,274] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 147
[2023-05-18 02:45:56,276] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:56,282] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:56,322] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:56,322] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:56,323] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:56,438] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 148
[2023-05-18 02:45:56,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 148
[2023-05-18 02:45:56,617] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 149
[2023-05-18 02:45:56,638] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 149
[2023-05-18 02:45:56,640] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:56,645] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:56,685] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:56,685] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:56,686] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:56,800] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 150
[2023-05-18 02:45:56,949] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 150
[2023-05-18 02:45:56,988] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 151
[2023-05-18 02:45:57,010] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 151
[2023-05-18 02:45:57,014] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:57,020] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:57,060] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:57,060] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:57,061] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    2885632 │ self_Conv_2_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_2_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_1_bias        │
├─────────┼────────────┼─────────────────────────┤
│       1 │    5251072 │ self_GroupNorm_1_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_1_bias   │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_weight     │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Dense_0_bias       │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_weight      │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_Conv_0_bias        │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:57,176] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 152
[2023-05-18 02:45:57,318] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 152
[2023-05-18 02:45:57,356] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 153
[2023-05-18 02:45:57,377] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 153
[2023-05-18 02:45:57,380] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:57,383] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (64)
   function: 'forward' (/gpfs/accounts/qingqu_root/qingqu1/yifulu/dpm-solver/example_v2/score_sde_pytorch/models/layerspp.py:242)
   reasons:  ___check_obj_id(self, 23393346973024)
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
[2023-05-18 02:45:57,383] torch._dynamo.convert_frame: [INFO] converting frame raised unsupported, leaving it unconverted
[2023-05-18 02:45:57,395] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:45:57,502] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:57,502] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:57,503] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:45:57,544] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 154
[2023-05-18 02:45:57,595] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 154
[2023-05-18 02:45:57,816] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 155
[2023-05-18 02:45:57,940] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 155
[2023-05-18 02:45:57,970] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:57,975] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:45:57,980] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:45:57,981] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:57,981] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:57,981] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:57,994] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 156
[2023-05-18 02:45:58,050] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 156
[2023-05-18 02:45:58,050] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:58,662] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:45:58,666] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:45:58,667] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:58,667] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:58,667] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:58,678] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 157
[2023-05-18 02:45:58,709] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 157
[2023-05-18 02:45:58,709] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:58,724] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:45:58,727] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:45:58,728] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:58,728] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:58,728] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:58,738] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 158
[2023-05-18 02:45:58,769] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 158
[2023-05-18 02:45:58,769] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:58,776] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_downsample_2d
[2023-05-18 02:45:58,780] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_downsample_2d (RETURN_VALUE)
[2023-05-18 02:45:58,781] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:58,781] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:58,781] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:58,790] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 159
[2023-05-18 02:45:58,818] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 159
[2023-05-18 02:45:58,818] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:58,949] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:45:58,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:45:58,955] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:58,956] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:58,956] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:58,968] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 160
[2023-05-18 02:45:58,991] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 160
[2023-05-18 02:45:58,991] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:45:59,242] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing naive_upsample_2d
[2023-05-18 02:45:59,247] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing naive_upsample_2d (RETURN_VALUE)
[2023-05-18 02:45:59,248] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:45:59,248] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:45:59,248] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬───────────────┐
│ Index   │ Size (b)   │ Param Names   │
├─────────┼────────────┼───────────────┤
└─────────┴────────────┴───────────────┘
[2023-05-18 02:45:59,261] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 161
[2023-05-18 02:45:59,288] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 161
[2023-05-18 02:45:59,288] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:07,532] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:07,638] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:07,638] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:07,639] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:07,679] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 162
[2023-05-18 02:46:07,735] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 162
[2023-05-18 02:46:07,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 163
[2023-05-18 02:46:08,080] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 163
[2023-05-18 02:46:08,110] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:08,116] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:08,220] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:08,220] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:08,272] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:08,313] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 164
[2023-05-18 02:46:08,361] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 164
[2023-05-18 02:46:08,579] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 165
[2023-05-18 02:46:09,046] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 165
[2023-05-18 02:46:09,076] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:09,082] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:09,187] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:09,187] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:09,188] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:09,380] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 166
[2023-05-18 02:46:09,427] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 166
[2023-05-18 02:46:09,647] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 167
[2023-05-18 02:46:09,759] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 167
[2023-05-18 02:46:09,790] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:09,796] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:09,900] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:09,900] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:09,901] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:09,941] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 168
[2023-05-18 02:46:09,989] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 168
[2023-05-18 02:46:10,209] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 169
[2023-05-18 02:46:10,321] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 169
[2023-05-18 02:46:10,350] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:10,356] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:10,461] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:10,461] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:10,462] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:10,501] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 170
[2023-05-18 02:46:10,549] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 170
[2023-05-18 02:46:10,768] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 171
[2023-05-18 02:46:10,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 171
[2023-05-18 02:46:10,912] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:10,918] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:11,023] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:11,023] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:11,024] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:11,065] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 172
[2023-05-18 02:46:11,113] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 172
[2023-05-18 02:46:11,344] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 173
[2023-05-18 02:46:11,457] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 173
[2023-05-18 02:46:11,487] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:11,493] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:11,598] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:11,598] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:11,599] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:11,639] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 174
[2023-05-18 02:46:11,685] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 174
[2023-05-18 02:46:11,910] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 175
[2023-05-18 02:46:12,023] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 175
[2023-05-18 02:46:12,054] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:12,060] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:12,167] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:12,167] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:12,168] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:12,208] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 176
[2023-05-18 02:46:12,257] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 176
[2023-05-18 02:46:12,476] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 177
[2023-05-18 02:46:12,589] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 177
[2023-05-18 02:46:12,618] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:12,634] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:12,739] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:12,740] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:12,740] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:12,781] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 178
[2023-05-18 02:46:12,835] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 178
[2023-05-18 02:46:13,057] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 179
[2023-05-18 02:46:13,185] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 179
[2023-05-18 02:46:13,215] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
[2023-05-18 02:46:13,238] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward
[2023-05-18 02:46:13,344] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function compile_fn
[2023-05-18 02:46:13,344] torch._dynamo.backends.distributed: [INFO] DDPOptimizer used bucket cap 26214400 and produced the following buckets:
[2023-05-18 02:46:13,344] torch._dynamo.backends.distributed: [INFO] 
DDPOptimizer bucket assignments
┌─────────┬────────────┬─────────────────────────┐
│   Index │   Size (b) │ Param Names             │
├─────────┼────────────┼─────────────────────────┤
│       0 │    1052672 │ self_NIN_3_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_3_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_2_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_1_W            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_b            │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_NIN_0_W            │
├─────────┼────────────┼─────────────────────────┤
│       1 │       2048 │ self_GroupNorm_0_weight │
├─────────┼────────────┼─────────────────────────┤
│         │            │ self_GroupNorm_0_bias   │
└─────────┴────────────┴─────────────────────────┘
[2023-05-18 02:46:13,385] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 180
[2023-05-18 02:46:13,434] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 180
[2023-05-18 02:46:13,659] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 181
[2023-05-18 02:46:13,773] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 181
[2023-05-18 02:46:13,803] torch._dynamo.output_graph: [INFO] Step 2: done compiler function compile_fn
I0518 02:46:37.985963 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 1
I0518 02:47:13.770382 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 2
I0518 02:47:49.698710 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 3
I0518 02:48:25.673737 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 4
I0518 02:49:01.681750 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 5
I0518 02:49:37.699584 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 6
I0518 02:50:13.710567 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 7
I0518 02:50:49.730711 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 8
I0518 02:51:25.770084 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 9
I0518 02:52:01.795060 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 10
I0518 02:52:37.866661 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 11
I0518 02:53:13.901461 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 12
I0518 02:53:49.986576 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 13
I0518 02:54:26.019294 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 14
I0518 02:55:02.044350 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 15
I0518 02:55:38.094269 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 16
I0518 02:56:14.116917 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 17
I0518 02:56:50.149576 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 18
I0518 02:57:26.176932 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 19
I0518 02:58:02.200706 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 20
I0518 02:58:38.403040 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 21
I0518 02:59:14.436565 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 22
I0518 02:59:50.460305 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 23
I0518 03:00:26.518800 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 24
I0518 03:01:02.592176 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 25
I0518 03:01:38.609858 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 26
I0518 03:02:14.641071 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 27
I0518 03:02:50.668915 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 28
I0518 03:03:26.693006 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 29
I0518 03:04:02.816052 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 30
I0518 03:04:38.892446 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 31
I0518 03:05:14.912364 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 32
I0518 03:05:50.942709 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 33
I0518 03:06:27.001273 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 34
I0518 03:07:03.026373 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 35
I0518 03:07:39.077332 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 36
I0518 03:08:15.081953 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 37
I0518 03:08:51.091359 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 38
I0518 03:09:27.158656 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 39
I0518 03:10:03.181745 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 40
I0518 03:10:39.204133 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 41
I0518 03:11:15.227319 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 42
I0518 03:11:51.295120 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 43
I0518 03:12:27.306111 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 44
I0518 03:13:03.327332 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 45
I0518 03:13:39.346151 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 46
I0518 03:14:15.364823 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 47
I0518 03:14:51.420591 23398153672512 main_interval.py:215] sampling -- ckpt: 5, round: 48
I0518 03:15:27.465274 23398153672512 main_interval.py:156] 0 is converged model
I0518 03:15:27.465563 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:19:55.486261 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth
W0518 03:19:55.503083 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_10.pth. Returned the same state as input
I0518 03:19:55.513532 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 03:19:55.513649 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 0
I0518 03:20:31.498789 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 1
I0518 03:21:07.331349 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 2
I0518 03:21:43.457231 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 3
I0518 03:22:19.449733 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 4
I0518 03:22:55.471821 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 5
I0518 03:23:31.499529 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 6
I0518 03:24:07.565929 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 7
I0518 03:24:43.606406 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 8
I0518 03:25:19.670908 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 9
I0518 03:25:55.707785 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 10
I0518 03:26:31.745220 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 11
I0518 03:27:07.786054 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 12
I0518 03:27:43.824827 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 13
I0518 03:28:19.850635 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 14
I0518 03:28:55.996206 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 15
I0518 03:29:32.036821 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 16
I0518 03:30:08.079375 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 17
I0518 03:30:44.115894 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 18
I0518 03:31:20.151736 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 19
I0518 03:31:56.222130 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 20
I0518 03:32:32.263331 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 21
I0518 03:33:08.300344 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 22
I0518 03:33:44.476072 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 23
I0518 03:34:20.509396 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 24
I0518 03:34:56.546399 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 25
I0518 03:35:32.583357 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 26
I0518 03:36:08.646059 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 27
I0518 03:36:44.681219 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 28
I0518 03:37:20.723072 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 29
I0518 03:37:56.754263 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 30
I0518 03:38:32.790440 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 31
I0518 03:39:09.045730 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 32
I0518 03:39:45.116367 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 33
I0518 03:40:21.145404 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 34
I0518 03:40:57.177521 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 35
I0518 03:41:33.207450 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 36
I0518 03:42:09.232194 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 37
I0518 03:42:45.272420 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 38
I0518 03:43:21.315202 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 39
I0518 03:43:57.438643 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 40
I0518 03:44:33.485579 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 41
I0518 03:45:09.514345 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 42
I0518 03:45:45.574897 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 43
I0518 03:46:21.608359 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 44
I0518 03:46:57.688446 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 45
I0518 03:47:33.721844 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 46
I0518 03:48:09.749654 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 47
I0518 03:48:46.004813 23398153672512 main_interval.py:215] sampling -- ckpt: 10, round: 48
I0518 03:49:22.047085 23398153672512 main_interval.py:156] 0 is converged model
I0518 03:49:22.047251 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 03:53:33.404008 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth
W0518 03:53:33.426635 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_15.pth. Returned the same state as input
I0518 03:53:33.437535 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 03:53:33.437643 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 0
I0518 03:54:09.574030 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 1
I0518 03:54:45.382685 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 2
I0518 03:55:21.312535 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 3
I0518 03:55:57.289942 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 4
I0518 03:56:33.295964 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 5
I0518 03:57:09.367156 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 6
I0518 03:57:45.404067 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 7
I0518 03:58:21.442818 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 8
I0518 03:58:57.626918 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 9
I0518 03:59:33.706998 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 10
I0518 04:00:09.734873 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 11
I0518 04:00:45.768267 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 12
I0518 04:01:21.809772 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 13
I0518 04:01:57.860499 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 14
I0518 04:02:33.891909 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 15
I0518 04:03:09.960751 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 16
I0518 04:03:46.062442 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 17
I0518 04:04:22.091193 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 18
I0518 04:04:58.120481 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 19
I0518 04:05:34.170390 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 20
I0518 04:06:10.212749 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 21
I0518 04:06:46.251703 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 22
I0518 04:07:22.292049 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 23
I0518 04:07:58.341050 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 24
I0518 04:08:34.383679 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 25
I0518 04:09:10.424718 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 26
I0518 04:09:46.462305 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 27
I0518 04:10:22.509191 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 28
I0518 04:10:58.541902 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 29
I0518 04:11:34.571109 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 30
I0518 04:12:10.594385 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 31
I0518 04:12:46.664820 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 32
I0518 04:13:22.688795 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 33
I0518 04:13:58.843793 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 34
I0518 04:14:34.867465 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 35
I0518 04:15:10.954800 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 36
I0518 04:15:46.993740 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 37
I0518 04:16:23.035484 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 38
I0518 04:16:59.079027 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 39
I0518 04:17:35.167502 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 40
I0518 04:18:11.213505 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 41
I0518 04:18:47.402246 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 42
I0518 04:19:23.481981 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 43
I0518 04:19:59.557841 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 44
I0518 04:20:35.596828 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 45
I0518 04:21:11.625697 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 46
I0518 04:21:47.681085 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 47
I0518 04:22:23.710363 23398153672512 main_interval.py:215] sampling -- ckpt: 15, round: 48
I0518 04:22:59.777947 23398153672512 main_interval.py:156] 0 is converged model
I0518 04:22:59.778237 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:24:14.673441 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth
W0518 04:24:14.702367 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_20.pth. Returned the same state as input
I0518 04:24:14.711613 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 04:24:14.711767 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 0
I0518 04:24:50.757802 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 1
I0518 04:25:26.648487 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 2
I0518 04:26:02.612759 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 3
I0518 04:26:38.631875 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 4
I0518 04:27:14.692606 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 5
I0518 04:27:50.717112 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 6
I0518 04:28:26.780639 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 7
I0518 04:29:02.973754 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 8
I0518 04:29:39.015808 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 9
I0518 04:30:15.059068 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 10
I0518 04:30:51.098007 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 11
I0518 04:31:27.133982 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 12
I0518 04:32:03.173906 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 13
I0518 04:32:39.215326 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 14
I0518 04:33:15.283560 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 15
I0518 04:33:51.535464 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 16
I0518 04:34:27.575870 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 17
I0518 04:35:03.620160 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 18
I0518 04:35:39.663759 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 19
I0518 04:36:15.694308 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 20
I0518 04:36:51.722842 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 21
I0518 04:37:27.774981 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 22
I0518 04:38:03.821895 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 23
I0518 04:38:39.856979 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 24
I0518 04:39:15.886286 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 25
I0518 04:39:51.930697 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 26
I0518 04:40:27.972433 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 27
I0518 04:41:04.027341 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 28
I0518 04:41:40.063857 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 29
I0518 04:42:16.114812 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 30
I0518 04:42:52.168653 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 31
I0518 04:43:28.220993 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 32
I0518 04:44:04.497736 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 33
I0518 04:44:40.534729 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 34
I0518 04:45:16.575855 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 35
I0518 04:45:52.616247 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 36
I0518 04:46:28.654130 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 37
I0518 04:47:04.683271 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 38
I0518 04:47:40.715599 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 39
I0518 04:48:16.795923 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 40
I0518 04:48:52.847666 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 41
I0518 04:49:28.885013 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 42
I0518 04:50:04.924992 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 43
I0518 04:50:40.966417 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 44
I0518 04:51:17.018181 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 45
I0518 04:51:53.057202 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 46
I0518 04:52:29.087006 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 47
I0518 04:53:05.120225 23398153672512 main_interval.py:215] sampling -- ckpt: 20, round: 48
I0518 04:53:41.202116 23398153672512 main_interval.py:156] 0 is converged model
I0518 04:53:41.202395 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 04:54:03.818383 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth
W0518 04:54:03.819029 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_25.pth. Returned the same state as input
I0518 04:54:03.829252 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 04:54:03.829351 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 0
I0518 04:54:40.019931 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 1
I0518 04:55:16.005385 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 2
I0518 04:55:52.018912 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 3
I0518 04:56:28.042607 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 4
I0518 04:57:04.083484 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 5
I0518 04:57:40.155553 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 6
I0518 04:58:16.191137 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 7
I0518 04:58:52.299569 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 8
I0518 04:59:28.343637 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 9
I0518 05:00:04.385251 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 10
I0518 05:00:40.472791 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 11
I0518 05:01:16.508616 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 12
I0518 05:01:52.550359 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 13
I0518 05:02:28.636057 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 14
I0518 05:03:04.668277 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 15
I0518 05:03:40.752259 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 16
I0518 05:04:16.795618 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 17
I0518 05:04:52.873646 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 18
I0518 05:05:28.910720 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 19
I0518 05:06:04.956476 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 20
I0518 05:06:40.992213 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 21
I0518 05:07:17.057787 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 22
I0518 05:07:53.098770 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 23
I0518 05:08:29.140576 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 24
I0518 05:09:05.288507 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 25
I0518 05:09:41.322557 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 26
I0518 05:10:17.364763 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 27
I0518 05:10:53.412966 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 28
I0518 05:11:29.488996 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 29
I0518 05:12:05.567549 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 30
I0518 05:12:41.613471 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 31
I0518 05:13:17.664217 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 32
I0518 05:13:53.752138 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 33
I0518 05:14:29.785787 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 34
I0518 05:15:05.830472 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 35
I0518 05:15:41.889821 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 36
I0518 05:16:17.934759 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 37
I0518 05:16:53.980887 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 38
I0518 05:17:30.034361 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 39
I0518 05:18:06.081373 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 40
I0518 05:18:42.283966 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 41
I0518 05:19:18.334899 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 42
I0518 05:19:54.391295 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 43
I0518 05:20:30.434477 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 44
I0518 05:21:06.477438 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 45
I0518 05:21:42.513870 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 46
I0518 05:22:18.549612 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 47
I0518 05:22:54.587508 23398153672512 main_interval.py:215] sampling -- ckpt: 25, round: 48
I0518 05:23:30.632452 23398153672512 main_interval.py:156] 0 is converged model
I0518 05:23:30.632737 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:24:22.422666 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth
W0518 05:24:22.448443 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_30.pth. Returned the same state as input
I0518 05:24:22.458758 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 05:24:22.458859 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 0
I0518 05:24:58.566501 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 1
I0518 05:25:34.483914 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 2
I0518 05:26:10.469172 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 3
I0518 05:26:46.490297 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 4
I0518 05:27:22.516861 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 5
I0518 05:27:58.579623 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 6
I0518 05:28:34.652652 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 7
I0518 05:29:10.857231 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 8
I0518 05:29:46.888027 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 9
I0518 05:30:22.916706 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 10
I0518 05:30:58.940716 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 11
I0518 05:31:34.971424 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 12
I0518 05:32:10.987864 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 13
I0518 05:32:47.061966 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 14
I0518 05:33:23.084139 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 15
I0518 05:33:59.288817 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 16
I0518 05:34:35.361899 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 17
I0518 05:35:11.376675 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 18
I0518 05:35:47.406538 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 19
I0518 05:36:23.434660 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 20
I0518 05:36:59.485003 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 21
I0518 05:37:35.505545 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 22
I0518 05:38:11.535265 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 23
I0518 05:38:47.586586 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 24
I0518 05:39:23.629257 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 25
I0518 05:39:59.649134 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 26
I0518 05:40:35.715923 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 27
I0518 05:41:11.731454 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 28
I0518 05:41:47.760098 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 29
I0518 05:42:23.793753 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 30
I0518 05:42:59.845951 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 31
I0518 05:43:35.898256 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 32
I0518 05:44:12.085229 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 33
I0518 05:44:48.149527 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 34
I0518 05:45:24.170414 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 35
I0518 05:46:00.180970 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 36
I0518 05:46:36.190027 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 37
I0518 05:47:12.226905 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 38
I0518 05:47:48.282760 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 39
I0518 05:48:24.306890 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 40
I0518 05:49:00.460244 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 41
I0518 05:49:36.480349 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 42
I0518 05:50:12.519083 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 43
I0518 05:50:48.545594 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 44
I0518 05:51:24.624382 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 45
I0518 05:52:00.657462 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 46
I0518 05:52:36.685403 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 47
I0518 05:53:12.725636 23398153672512 main_interval.py:215] sampling -- ckpt: 30, round: 48
I0518 05:53:48.789852 23398153672512 main_interval.py:156] 0 is converged model
I0518 05:53:48.790122 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 05:54:10.668272 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth
W0518 05:54:10.668958 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_35.pth. Returned the same state as input
I0518 05:54:10.678481 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 05:54:10.678589 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 0
I0518 05:54:46.868767 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 1
I0518 05:55:22.852951 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 2
I0518 05:55:58.928559 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 3
I0518 05:56:34.950234 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 4
I0518 05:57:10.980735 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 5
I0518 05:57:47.010760 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 6
I0518 05:58:23.060755 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 7
I0518 05:58:59.297668 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 8
I0518 05:59:35.341566 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 9
I0518 06:00:11.383985 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 10
I0518 06:00:47.415108 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 11
I0518 06:01:23.447180 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 12
I0518 06:01:59.493160 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 13
I0518 06:02:35.529278 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 14
I0518 06:03:11.568793 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 15
I0518 06:03:47.701263 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 16
I0518 06:04:23.734703 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 17
I0518 06:04:59.765170 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 18
I0518 06:05:35.795264 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 19
I0518 06:06:11.828212 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 20
I0518 06:06:47.844830 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 21
I0518 06:07:23.909755 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 22
I0518 06:07:59.922420 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 23
I0518 06:08:35.948192 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 24
I0518 06:09:12.010434 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 25
I0518 06:09:48.030097 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 26
I0518 06:10:24.057589 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 27
I0518 06:11:00.073445 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 28
I0518 06:11:36.096830 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 29
I0518 06:12:12.119757 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 30
I0518 06:12:48.138493 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 31
I0518 06:13:24.181541 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 32
I0518 06:14:00.479469 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 33
I0518 06:14:36.544144 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 34
I0518 06:15:12.589127 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 35
I0518 06:15:48.665452 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 36
I0518 06:16:24.709616 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 37
I0518 06:17:00.753435 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 38
I0518 06:17:36.823259 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 39
I0518 06:18:12.863779 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 40
I0518 06:18:48.981631 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 41
I0518 06:19:25.011083 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 42
I0518 06:20:01.050621 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 43
I0518 06:20:37.090983 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 44
I0518 06:21:13.133103 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 45
I0518 06:21:49.172690 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 46
I0518 06:22:25.249979 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 47
I0518 06:23:01.277340 23398153672512 main_interval.py:215] sampling -- ckpt: 35, round: 48
I0518 06:23:37.353597 23398153672512 main_interval.py:156] 0 is converged model
I0518 06:23:37.353885 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_8.pth
I0518 06:24:20.687480 23398153672512 main_interval.py:160] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth
W0518 06:24:20.704577 23398153672512 utils.py:10] No checkpoint found at /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/dpm_deep/checkpoints/checkpoint_40.pth. Returned the same state as input
I0518 06:24:20.713612 23398153672512 main_interval.py:211] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:24:20.713712 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 0
I0518 06:24:56.809232 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 1
I0518 06:25:32.734653 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 2
I0518 06:26:08.739714 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 3
I0518 06:26:44.764899 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 4
I0518 06:27:20.821260 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 5
I0518 06:27:56.885801 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 6
I0518 06:28:32.923391 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 7
I0518 06:29:08.952638 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 8
I0518 06:29:44.986191 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 9
I0518 06:30:21.015816 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 10
I0518 06:30:57.089549 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 11
I0518 06:31:33.127984 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 12
I0518 06:32:09.164052 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 13
I0518 06:32:45.245135 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 14
I0518 06:33:21.276313 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 15
I0518 06:33:57.309078 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 16
I0518 06:34:33.339015 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 17
I0518 06:35:09.392654 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 18
I0518 06:35:45.428622 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 19
I0518 06:36:21.465993 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 20
I0518 06:36:57.510452 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 21
I0518 06:37:33.551138 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 22
I0518 06:38:09.577760 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 23
I0518 06:38:45.617786 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 24
I0518 06:39:21.659003 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 25
I0518 06:39:57.726304 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 26
I0518 06:40:33.770792 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 27
I0518 06:41:09.796815 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 28
I0518 06:41:45.841250 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 29
I0518 06:42:21.883628 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 30
I0518 06:42:57.918355 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 31
I0518 06:43:33.958464 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 32
I0518 06:44:10.047046 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 33
I0518 06:44:46.092561 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 34
I0518 06:45:22.116203 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 35
I0518 06:45:58.192163 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 36
I0518 06:46:34.227168 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 37
I0518 06:47:10.265738 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 38
I0518 06:47:46.306416 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 39
I0518 06:48:22.343779 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 40
I0518 06:48:58.435863 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 41
I0518 06:49:34.470652 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 42
I0518 06:50:10.513638 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 43
I0518 06:50:46.540506 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 44
I0518 06:51:22.614130 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 45
I0518 06:51:58.649027 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 46
I0518 06:52:34.686443 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 47
I0518 06:53:10.728113 23398153672512 main_interval.py:215] sampling -- ckpt: 40, round: 48
2023-05-18 06:53:55.057427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-18 06:53:55.168829: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-18 06:53:56.752542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 06:53:56.752641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/pkgs/arc/cudnn/11.7-v8.7.0/lib64:/sw/pkgs/arc/cuda/11.7.1/lib64:/opt/slurm/lib64::
2023-05-18 06:53:56.752653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']
  warnings.warn(f"unable to load libtensorflow_io_plugins.so: {e}")
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']
caused by: ['/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: {e}")
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/absl/flags/_validators.py:254: UserWarning: Flag --eval_folder has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
I0518 06:54:05.474064 22667281368896 resolver.py:108] Using /tmp/tfhub_modules to cache modules.
2023-05-18 06:54:07.905536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43102 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:1f:00.0, compute capability: 8.6
I0518 06:54:09.986257 22667281368896 evaluation_fromsample.py:48] begin checkpoint: 5
I0518 06:54:09.986525 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:54:09.987261 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 0
I0518 06:54:11.014379 22667281368896 xla_bridge.py:440] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 06:54:11.014538 22667281368896 xla_bridge.py:440] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0518 06:54:11.015194 22667281368896 xla_bridge.py:440] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
I0518 06:54:11.015303 22667281368896 xla_bridge.py:440] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
W0518 06:54:11.015360 22667281368896 xla_bridge.py:448] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
WARNING:tensorflow:From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0518 06:54:11.251364 22667281368896 deprecation.py:350] From /home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
2023-05-18 06:54:15.648164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
2023-05-18 06:54:17.043036: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2023-05-18 06:54:23.645484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.
  structure[0], [func(*x) for x in entries],
/home/yifulu/.conda/envs/dpm2/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:627: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS
I0518 06:54:24.206327 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 1
I0518 06:54:25.696370 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 10
I0518 06:54:27.174951 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 11
I0518 06:54:28.635194 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 12
I0518 06:54:30.089903 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 13
I0518 06:54:31.562758 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 14
I0518 06:54:33.037590 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 15
I0518 06:54:34.503721 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 16
I0518 06:54:35.975063 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 17
I0518 06:54:37.437588 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 18
I0518 06:54:38.908301 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 19
I0518 06:54:40.374372 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 2
I0518 06:54:41.839349 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 20
I0518 06:54:43.356613 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 21
I0518 06:54:44.833182 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 22
I0518 06:54:46.286575 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 23
I0518 06:54:47.758995 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 24
I0518 06:54:49.219551 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 25
I0518 06:54:50.675575 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 26
I0518 06:54:52.147499 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 27
I0518 06:54:53.614745 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 28
I0518 06:54:55.076414 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 29
I0518 06:54:56.547989 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 3
I0518 06:54:58.013837 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 30
I0518 06:54:59.477384 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 31
I0518 06:55:00.960455 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 32
I0518 06:55:02.443884 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 33
I0518 06:55:03.917309 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 34
I0518 06:55:05.418107 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 35
I0518 06:55:06.908294 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 36
I0518 06:55:08.380637 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 37
I0518 06:55:09.849607 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 38
I0518 06:55:11.386729 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 39
I0518 06:55:12.847344 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 4
I0518 06:55:14.322486 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 40
I0518 06:55:15.783687 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 41
I0518 06:55:17.251698 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 42
I0518 06:55:18.710284 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 43
I0518 06:55:20.178961 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 44
I0518 06:55:21.643140 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 45
I0518 06:55:23.104794 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 46
I0518 06:55:24.575288 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 47
I0518 06:55:26.039017 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 48
I0518 06:55:27.503394 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 5
I0518 06:55:29.211138 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 6
I0518 06:55:30.674566 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 7
I0518 06:55:32.131861 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 8
I0518 06:55:33.587433 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 5, round: 9
I0518 06:55:47.170651 22667281368896 evaluation_fromsample.py:105] ckpt-5 --- FID: 2.814862e+00
I0518 06:55:47.171754 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:55:47.172312 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 0
I0518 06:55:48.648833 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 1
I0518 06:55:50.134296 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 10
I0518 06:55:51.597102 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 11
I0518 06:55:53.052840 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 12
I0518 06:55:54.506967 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 13
I0518 06:55:55.969099 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 14
I0518 06:55:57.442257 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 15
I0518 06:55:58.902046 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 16
I0518 06:56:00.358966 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 17
I0518 06:56:01.820845 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 18
I0518 06:56:03.272126 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 19
I0518 06:56:04.743286 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 2
I0518 06:56:06.206052 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 20
I0518 06:56:07.663790 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 21
I0518 06:56:09.128626 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 22
I0518 06:56:10.591653 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 23
I0518 06:56:12.047915 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 24
I0518 06:56:13.516641 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 25
I0518 06:56:14.980031 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 26
I0518 06:56:16.443316 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 27
I0518 06:56:17.901132 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 28
I0518 06:56:19.374477 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 29
I0518 06:56:20.866469 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 3
I0518 06:56:22.332949 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 30
I0518 06:56:23.790483 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 31
I0518 06:56:25.266080 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 32
I0518 06:56:26.739520 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 33
I0518 06:56:28.205161 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 34
I0518 06:56:29.691772 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 35
I0518 06:56:31.155160 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 36
I0518 06:56:32.648428 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 37
I0518 06:56:34.113889 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 38
I0518 06:56:35.588247 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 39
I0518 06:56:37.043641 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 4
I0518 06:56:38.515983 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 40
I0518 06:56:39.982690 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 41
I0518 06:56:41.441296 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 42
I0518 06:56:42.920455 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 43
I0518 06:56:44.372530 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 44
I0518 06:56:45.828714 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 45
I0518 06:56:47.293323 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 46
I0518 06:56:48.745481 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 47
I0518 06:56:50.215591 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 48
I0518 06:56:51.688376 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 5
I0518 06:56:53.158146 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 6
I0518 06:56:54.638731 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 7
I0518 06:56:56.107138 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 8
I0518 06:56:57.568894 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 10, round: 9
I0518 06:57:10.813678 22667281368896 evaluation_fromsample.py:105] ckpt-10 --- FID: 2.776451e+00
I0518 06:57:10.814770 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:57:10.815335 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 0
I0518 06:57:12.299273 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 1
I0518 06:57:13.766337 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 10
I0518 06:57:15.223284 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 11
I0518 06:57:16.720680 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 12
I0518 06:57:18.238931 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 13
I0518 06:57:19.710294 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 14
I0518 06:57:21.437360 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 15
I0518 06:57:22.914661 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 16
I0518 06:57:24.373276 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 17
I0518 06:57:25.836084 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 18
I0518 06:57:27.322572 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 19
I0518 06:57:28.840057 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 2
I0518 06:57:30.325069 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 20
I0518 06:57:31.782391 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 21
I0518 06:57:33.235481 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 22
I0518 06:57:34.700007 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 23
I0518 06:57:36.153384 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 24
I0518 06:57:37.640633 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 25
I0518 06:57:39.104755 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 26
I0518 06:57:40.568223 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 27
I0518 06:57:42.028808 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 28
I0518 06:57:43.491723 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 29
I0518 06:57:44.940836 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 3
I0518 06:57:46.416746 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 30
I0518 06:57:47.888724 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 31
I0518 06:57:49.355921 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 32
I0518 06:57:50.822624 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 33
I0518 06:57:52.308982 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 34
I0518 06:57:53.768731 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 35
I0518 06:57:55.234242 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 36
I0518 06:57:56.718327 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 37
I0518 06:57:58.193503 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 38
I0518 06:57:59.650876 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 39
I0518 06:58:01.139704 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 4
I0518 06:58:02.596938 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 40
I0518 06:58:04.078405 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 41
I0518 06:58:05.556470 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 42
I0518 06:58:07.020958 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 43
I0518 06:58:08.495160 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 44
I0518 06:58:09.955459 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 45
I0518 06:58:11.439555 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 46
I0518 06:58:12.929038 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 47
I0518 06:58:14.414414 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 48
I0518 06:58:15.884693 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 5
I0518 06:58:17.343497 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 6
I0518 06:58:18.816371 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 7
I0518 06:58:20.271606 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 8
I0518 06:58:21.771383 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 15, round: 9
I0518 06:58:35.276119 22667281368896 evaluation_fromsample.py:105] ckpt-15 --- FID: 2.826041e+00
I0518 06:58:35.277165 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:58:35.277709 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 0
I0518 06:58:36.747704 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 1
I0518 06:58:38.234811 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 10
I0518 06:58:39.699439 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 11
I0518 06:58:41.183810 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 12
I0518 06:58:42.655359 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 13
I0518 06:58:44.122697 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 14
I0518 06:58:45.588624 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 15
I0518 06:58:47.042472 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 16
I0518 06:58:48.502348 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 17
I0518 06:58:49.950770 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 18
I0518 06:58:51.415170 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 19
I0518 06:58:52.878605 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 2
I0518 06:58:54.335613 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 20
I0518 06:58:55.796153 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 21
I0518 06:58:57.260847 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 22
I0518 06:58:58.730440 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 23
I0518 06:59:00.217575 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 24
I0518 06:59:01.702399 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 25
I0518 06:59:03.167155 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 26
I0518 06:59:04.649177 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 27
I0518 06:59:06.134243 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 28
I0518 06:59:07.615802 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 29
I0518 06:59:09.078195 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 3
I0518 06:59:10.532845 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 30
I0518 06:59:11.989006 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 31
I0518 06:59:13.455067 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 32
I0518 06:59:14.934341 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 33
I0518 06:59:16.394780 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 34
I0518 06:59:17.850801 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 35
I0518 06:59:19.320040 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 36
I0518 06:59:20.779471 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 37
I0518 06:59:22.243041 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 38
I0518 06:59:23.719119 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 39
I0518 06:59:25.189273 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 4
I0518 06:59:26.642031 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 40
I0518 06:59:28.095947 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 41
I0518 06:59:29.566031 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 42
I0518 06:59:31.044057 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 43
I0518 06:59:32.516440 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 44
I0518 06:59:33.976402 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 45
I0518 06:59:35.469744 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 46
I0518 06:59:36.925167 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 47
I0518 06:59:38.415792 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 48
I0518 06:59:39.884499 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 5
I0518 06:59:41.339066 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 6
I0518 06:59:42.799357 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 7
I0518 06:59:44.253566 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 8
I0518 06:59:45.754444 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 20, round: 9
I0518 06:59:59.006524 22667281368896 evaluation_fromsample.py:105] ckpt-20 --- FID: 2.816694e+00
I0518 06:59:59.007565 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 06:59:59.008122 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 0
I0518 07:00:00.469218 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 1
I0518 07:00:01.931019 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 10
I0518 07:00:03.390258 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 11
I0518 07:00:04.851066 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 12
I0518 07:00:06.310063 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 13
I0518 07:00:07.770033 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 14
I0518 07:00:09.249030 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 15
I0518 07:00:10.734452 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 16
I0518 07:00:12.193140 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 17
I0518 07:00:13.665900 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 18
I0518 07:00:15.127924 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 19
I0518 07:00:16.606236 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 2
I0518 07:00:18.066298 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 20
I0518 07:00:19.559256 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 21
I0518 07:00:21.022910 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 22
I0518 07:00:22.487878 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 23
I0518 07:00:23.946846 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 24
I0518 07:00:25.432219 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 25
I0518 07:00:26.896143 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 26
I0518 07:00:28.364429 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 27
I0518 07:00:29.825209 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 28
I0518 07:00:31.292665 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 29
I0518 07:00:32.748309 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 3
I0518 07:00:34.231504 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 30
I0518 07:00:35.693590 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 31
I0518 07:00:37.189686 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 32
I0518 07:00:38.655676 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 33
I0518 07:00:40.140206 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 34
I0518 07:00:41.593412 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 35
I0518 07:00:43.075620 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 36
I0518 07:00:44.555572 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 37
I0518 07:00:46.014150 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 38
I0518 07:00:47.484515 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 39
I0518 07:00:48.977953 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 4
I0518 07:00:50.434732 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 40
I0518 07:00:51.913054 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 41
I0518 07:00:53.365900 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 42
I0518 07:00:54.828265 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 43
I0518 07:00:56.328951 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 44
I0518 07:00:57.783670 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 45
I0518 07:00:59.241993 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 46
I0518 07:01:00.729435 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 47
I0518 07:01:02.191104 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 48
I0518 07:01:03.648037 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 5
I0518 07:01:05.124901 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 6
I0518 07:01:06.621064 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 7
I0518 07:01:08.105962 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 8
I0518 07:01:09.565487 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 25, round: 9
I0518 07:01:22.981967 22667281368896 evaluation_fromsample.py:105] ckpt-25 --- FID: 2.813910e+00
I0518 07:01:22.982991 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 07:01:22.983544 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 0
I0518 07:01:24.441114 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 1
I0518 07:01:25.942424 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 10
I0518 07:01:27.414205 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 11
I0518 07:01:28.978529 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 12
I0518 07:01:30.454586 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 13
I0518 07:01:31.921819 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 14
I0518 07:01:33.383312 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 15
I0518 07:01:34.851752 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 16
I0518 07:01:36.324669 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 17
I0518 07:01:37.786685 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 18
I0518 07:01:39.253099 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 19
I0518 07:01:40.724772 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 2
I0518 07:01:42.193600 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 20
I0518 07:01:43.656992 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 21
I0518 07:01:45.127664 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 22
I0518 07:01:46.604137 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 23
I0518 07:01:48.062130 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 24
I0518 07:01:49.526341 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 25
I0518 07:01:51.039368 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 26
I0518 07:01:52.509658 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 27
I0518 07:01:53.983521 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 28
I0518 07:01:55.460323 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 29
I0518 07:01:56.954403 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 3
I0518 07:01:58.422579 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 30
I0518 07:01:59.896338 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 31
I0518 07:02:01.365645 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 32
I0518 07:02:03.068889 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 33
I0518 07:02:04.549071 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 34
I0518 07:02:06.012012 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 35
I0518 07:02:07.467263 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 36
I0518 07:02:08.971175 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 37
I0518 07:02:10.434434 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 38
I0518 07:02:11.929473 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 39
I0518 07:02:13.387424 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 4
I0518 07:02:14.865901 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 40
I0518 07:02:16.336245 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 41
I0518 07:02:17.812694 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 42
I0518 07:02:19.268901 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 43
I0518 07:02:20.743723 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 44
I0518 07:02:22.233445 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 45
I0518 07:02:23.715955 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 46
I0518 07:02:25.194327 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 47
I0518 07:02:26.665537 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 48
I0518 07:02:28.144799 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 5
I0518 07:02:29.614326 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 6
I0518 07:02:31.104151 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 7
I0518 07:02:32.562748 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 8
I0518 07:02:34.041950 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 30, round: 9
I0518 07:02:47.310239 22667281368896 evaluation_fromsample.py:105] ckpt-30 --- FID: 2.828969e+00
I0518 07:02:47.311354 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 07:02:47.311909 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 0
I0518 07:02:48.777515 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 1
I0518 07:02:50.228484 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 10
I0518 07:02:51.693574 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 11
I0518 07:02:53.164267 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 12
I0518 07:02:54.625802 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 13
I0518 07:02:56.076265 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 14
I0518 07:02:57.540840 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 15
I0518 07:02:59.003727 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 16
I0518 07:03:00.464627 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 17
I0518 07:03:01.922508 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 18
I0518 07:03:03.443316 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 19
I0518 07:03:04.941524 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 2
I0518 07:03:06.413400 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 20
I0518 07:03:07.867143 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 21
I0518 07:03:09.336598 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 22
I0518 07:03:10.806345 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 23
I0518 07:03:12.270240 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 24
I0518 07:03:13.727376 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 25
I0518 07:03:15.183764 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 26
I0518 07:03:16.636250 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 27
I0518 07:03:18.102144 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 28
I0518 07:03:19.555917 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 29
I0518 07:03:21.023848 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 3
I0518 07:03:22.480455 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 30
I0518 07:03:23.952137 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 31
I0518 07:03:25.431905 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 32
I0518 07:03:26.894578 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 33
I0518 07:03:28.397160 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 34
I0518 07:03:29.852429 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 35
I0518 07:03:31.306764 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 36
I0518 07:03:32.775334 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 37
I0518 07:03:34.239052 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 38
I0518 07:03:35.708150 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 39
I0518 07:03:37.180514 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 4
I0518 07:03:38.652159 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 40
I0518 07:03:40.111944 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 41
I0518 07:03:41.567102 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 42
I0518 07:03:43.033484 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 43
I0518 07:03:44.522665 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 44
I0518 07:03:45.986246 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 45
I0518 07:03:47.448739 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 46
I0518 07:03:48.928853 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 47
I0518 07:03:50.414500 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 48
I0518 07:03:51.910745 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 5
I0518 07:03:53.394710 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 6
I0518 07:03:54.909822 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 7
I0518 07:03:56.398008 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 8
I0518 07:03:57.855453 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 35, round: 9
I0518 07:04:11.489223 22667281368896 evaluation_fromsample.py:105] ckpt-35 --- FID: 2.836865e+00
I0518 07:04:11.490343 22667281368896 evaluation_fromsample.py:52] /scratch/qingqu_root/qingqu1/shared_data/dpm_experiments/new_interval/interval2_control
I0518 07:04:11.490893 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 0
I0518 07:04:12.978086 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 1
I0518 07:04:14.443217 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 10
I0518 07:04:15.901331 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 11
I0518 07:04:17.374685 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 12
I0518 07:04:18.841098 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 13
I0518 07:04:20.325554 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 14
I0518 07:04:21.787114 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 15
I0518 07:04:23.280717 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 16
I0518 07:04:24.741580 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 17
I0518 07:04:26.214429 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 18
I0518 07:04:27.700029 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 19
I0518 07:04:29.191933 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 2
I0518 07:04:30.675480 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 20
I0518 07:04:32.269643 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 21
I0518 07:04:33.730481 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 22
I0518 07:04:35.207859 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 23
I0518 07:04:36.670667 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 24
I0518 07:04:38.148302 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 25
I0518 07:04:39.619994 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 26
I0518 07:04:41.087572 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 27
I0518 07:04:42.545452 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 28
I0518 07:04:44.033069 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 29
I0518 07:04:45.491869 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 3
I0518 07:04:46.958843 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 30
I0518 07:04:48.423751 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 31
I0518 07:04:49.902142 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 32
I0518 07:04:51.360621 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 33
I0518 07:04:52.853323 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 34
I0518 07:04:54.368566 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 35
I0518 07:04:55.849954 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 36
I0518 07:04:57.337898 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 37
I0518 07:04:58.811777 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 38
I0518 07:05:00.268931 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 39
I0518 07:05:01.749413 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 4
I0518 07:05:03.222714 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 40
I0518 07:05:04.700420 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 41
I0518 07:05:06.171753 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 42
I0518 07:05:07.639909 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 43
I0518 07:05:09.124202 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 44
I0518 07:05:10.591778 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 45
I0518 07:05:12.063779 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 46
I0518 07:05:13.549811 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 47
I0518 07:05:15.028831 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 48
I0518 07:05:16.503198 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 5
I0518 07:05:17.973549 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 6
I0518 07:05:19.463358 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 7
I0518 07:05:20.948130 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 8
I0518 07:05:22.399613 22667281368896 evaluation_fromsample.py:67] evaluation -- ckpt: 40, round: 9
I0518 07:05:35.736238 22667281368896 evaluation_fromsample.py:105] ckpt-40 --- FID: 2.803094e+00
